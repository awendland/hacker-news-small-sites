<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 19 Dec 2020 04:40:50 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 19 Dec 2020 04:40:49 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Deprecating Excalidraw Electron in favor of the Web version]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25454687">thread link</a>) | @markdog12
<br/>
December 17, 2020 | https://blog.excalidraw.com/deprecating-excalidraw-electron/ | <a href="https://web.archive.org/web/*/https://blog.excalidraw.com/deprecating-excalidraw-electron/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>On the <a href="https://github.com/excalidraw/">Excalidraw project</a>, we have decided to deprecate <a href="https://github.com/excalidraw/excalidraw-desktop">Excalidraw Desktop</a>, an <a href="https://www.electronjs.org/">Electron</a> wrapper for Excalidraw, in favor of the Web version that you can—and always could—find at <a href="https://excalidraw.com/">excalidraw.com</a>. After a careful analysis, we have decided that <a href="https://web.dev/pwa/">Progressive Web App</a> (PWA) is the future we want to build upon. Read on to learn more about our rationale.</p>
<!-- end -->
<h2>How Excalidraw Desktop came into being</h2>
<p>Soon after <a href="https://twitter.com/vjeux">@vjeux</a> had created the initial version of Excalidraw in January 2020 and <a href="https://blog.excalidraw.com/reflections-on-excalidraw/">blogged about it</a>, he proposed the following in <a href="https://github.com/excalidraw/excalidraw/issues/561#issue-555138343">Issue #561</a>:</p>
<blockquote>
<p>“Would be great to wrap Excalidraw within Electron (or equivalent) and publish it as a native application to the various app stores.”</p>
</blockquote>
<p>The immediate reaction by <a href="https://github.com/voluntadpear">@voluntadpear</a> was to suggest:</p>
<blockquote>
<p>“What about making it a PWA instead? Android currently supports adding them to the Play Store as Trusted Web Activities and hopefully iOS will do the same soon. On Desktop, Chrome lets you download a desktop shortcut to a PWA.”</p>
</blockquote>
<p>The decision that <a href="https://github.com/vjeux">@vjeux</a> took in the end was simple:</p>
<blockquote>
<p>“We should do both :)”</p>
</blockquote>
<p>While work on converting the version of Excalidraw into a PWA was started by <a href="https://github.com/voluntadpear">@voluntadpear</a> and later others, <a href="https://github.com/lipis">@lipis</a> independently <a href="https://github.com/excalidraw/excalidraw/issues/561#issuecomment-579573783">went ahead</a> and created a <a href="https://github.com/excalidraw/excalidraw-desktop">separate repo</a> for Excalidraw Desktop.</p>
<p>To this day, the initial goal set by <a href="https://github.com/vjeux">@vjeux</a>, that is, to submit Excalidraw to the various app stores, has not been reached yet. Honestly, no one has even started the submission process to any of the stores. But why is that? Before I try to provide an answer, let me quickly look at Electron, the platform.</p>
<h2>What is Electron?</h2>
<p>The unique selling point of <a href="https://www.electronjs.org/">Electron</a> is that it allows you to <em>“build cross-platform desktop apps with JavaScript, HTML, and CSS”</em>. Apps built with Electron are <em>“compatible with Mac, Windows, and Linux”</em>, that is, <em>“Electron apps build and run on three platforms”</em>. According to the homepage, the hard parts that Electron makes easy are <a href="https://www.electronjs.org/docs/api/auto-updater">automatic updates</a>, <a href="https://www.electronjs.org/docs/api/menu">native menus and notifications</a>, <a href="https://www.electronjs.org/docs/api/crash-reporter">crash reporting</a>, <a href="https://www.electronjs.org/docs/api/content-tracing">debugging and profiling</a>, and <a href="https://www.electronjs.org/docs/api/auto-updater#windows">Windows installers</a>. Turns out, some of the promised features need a detailed look at the small print.</p>
<ul>
<li>For example, automatic updates <em>“are [currently] only [supported] on macOS and Windows. There is no built-in support for auto-updater on Linux, so it is recommended to use the distribution’s package manager to update your app”</em>.</li>
<li>Developers can create native menus by calling <code>Menu.setApplicationMenu(menu)</code>. On Windows and Linux, the menu will be set as each window’s top menu, while on macOS there are many system-defined standard menus, like the <a href="https://developer.apple.com/documentation/appkit/nsapplication/1428608-servicesmenu?language=objc">Services</a> menu. To make one’s menus a standard menu, developers should set their menu’s <code>role</code> accordingly, and Electron will recognize them and make them become standard menus. This means that a lot of menu-related code will make use of the following platform check: <code>const isMac = process.platform === 'darwin'</code>.</li>
<li>Windows installers can be made with <a href="https://github.com/electron/windows-installer">windows-installer</a>. The README of the project highlights that <em>“for a production app you need to sign your application. Internet Explorer’s SmartScreen filter will block your app from being downloaded, and many anti-virus vendors will consider your app as malware unless you obtain a valid cert”</em>.</li>
</ul>
<p>Looking at just these three examples, it is clear that Electron is far from “write once, run everywhere”. Distributing an app on app stores requires <a href="https://www.electronjs.org/docs/tutorial/code-signing">code signing</a>, a security technology for certifying app ownership. Packaging an app requires using tools like <a href="https://github.com/electron-userland/electron-forge">electron-forge</a> and thinking about where to host packages for app updates. It gets complex relatively quickly, especially when the objective truly is cross platform support. I want to note that it is <em>abolutely</em> possible to create stunning Electron apps with enough effort and dedication. For Excalidraw Desktop, we were not there.</p>
<h2>Where Excalidraw Desktop left off</h2>
<p>Excalidraw Desktop so far is basically the Excalidraw Web app bundled as an <a href="https://github.com/electron/asar"><code>.asar</code></a> file with an added <strong>About Excalidraw</strong> window. The look and feel of the application is almost identical to the Web version.</p>
<figure>
  <span>
      <a href="https://blog.excalidraw.com/static/261833dc69ad2e3fc4027bf26fcfd62b/1d7f7/excalidraw-desktop.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The Excalidraw Desktop application running in an Electron wrapper." title="The Excalidraw Desktop application running in an Electron wrapper." src="https://blog.excalidraw.com/static/261833dc69ad2e3fc4027bf26fcfd62b/fcda8/excalidraw-desktop.png" srcset="https://blog.excalidraw.com/static/261833dc69ad2e3fc4027bf26fcfd62b/12f09/excalidraw-desktop.png 148w,
https://blog.excalidraw.com/static/261833dc69ad2e3fc4027bf26fcfd62b/e4a3f/excalidraw-desktop.png 295w,
https://blog.excalidraw.com/static/261833dc69ad2e3fc4027bf26fcfd62b/fcda8/excalidraw-desktop.png 590w,
https://blog.excalidraw.com/static/261833dc69ad2e3fc4027bf26fcfd62b/efc66/excalidraw-desktop.png 885w,
https://blog.excalidraw.com/static/261833dc69ad2e3fc4027bf26fcfd62b/c83ae/excalidraw-desktop.png 1180w,
https://blog.excalidraw.com/static/261833dc69ad2e3fc4027bf26fcfd62b/1d7f7/excalidraw-desktop.png 2038w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
  <figcaption>Excalidraw Desktop is almost indistinguishable from the Web version</figcaption>
</figure>
<figure>
  <span>
      <a href="https://blog.excalidraw.com/static/a0a6ce646cf65a72e37db3347d329a88/9cab2/about-excalidraw.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The Excalidraw Desktop 'About' window displaying the version of the Electron wrapper and the Web app." title="The Excalidraw Desktop 'About' window displaying the version of the Electron wrapper and the Web app." src="https://blog.excalidraw.com/static/a0a6ce646cf65a72e37db3347d329a88/fcda8/about-excalidraw.png" srcset="https://blog.excalidraw.com/static/a0a6ce646cf65a72e37db3347d329a88/12f09/about-excalidraw.png 148w,
https://blog.excalidraw.com/static/a0a6ce646cf65a72e37db3347d329a88/e4a3f/about-excalidraw.png 295w,
https://blog.excalidraw.com/static/a0a6ce646cf65a72e37db3347d329a88/fcda8/about-excalidraw.png 590w,
https://blog.excalidraw.com/static/a0a6ce646cf65a72e37db3347d329a88/9cab2/about-excalidraw.png 864w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
  <figcaption>The <strong>About Excalidraw</strong> menu providing insights into the versions</figcaption>
</figure>
<p>On macOS, there is now a native menu at the top of the application, but since none of the menu actions—apart from <strong>Close Window</strong> and <strong>About Excalidraw</strong>—are hooked up to to anything, the menu is, in its current state, pretty useless. Meanwhile, all actions can of course be performed via the regular Excalidraw toolbars and the context menu.</p>
<figure>
  <span>
      <a href="https://blog.excalidraw.com/static/ee571b3d7ed3e69a9d4f98eb59cb29ba/f941f/menu.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The Excalidraw Desktop menu bar on macOS with the 'File', 'Close Window' menu item selected." title="The Excalidraw Desktop menu bar on macOS with the 'File', 'Close Window' menu item selected." src="https://blog.excalidraw.com/static/ee571b3d7ed3e69a9d4f98eb59cb29ba/fcda8/menu.png" srcset="https://blog.excalidraw.com/static/ee571b3d7ed3e69a9d4f98eb59cb29ba/12f09/menu.png 148w,
https://blog.excalidraw.com/static/ee571b3d7ed3e69a9d4f98eb59cb29ba/e4a3f/menu.png 295w,
https://blog.excalidraw.com/static/ee571b3d7ed3e69a9d4f98eb59cb29ba/fcda8/menu.png 590w,
https://blog.excalidraw.com/static/ee571b3d7ed3e69a9d4f98eb59cb29ba/f941f/menu.png 736w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
  <figcaption>The menu bar of Excalidraw Desktop on macOS</figcaption>
</figure>
<p>We use <a href="https://github.com/electron-userland/electron-builder">electron-builder</a>, which supports <a href="https://www.electron.build/configuration/configuration#PlatformSpecificBuildOptions-fileAssociations">file type associations</a>. By double-clicking an <code>.excalidraw</code> file, ideally the Excalidraw Desktop app should open. The relevant excerpt of our <code>electron-builder.json</code> file looks like this:</p>
<div data-language="json"><pre><code><span>{</span>
  <span>"fileAssociations"</span><span>:</span> <span>[</span>
    <span>{</span>
      <span>"ext"</span><span>:</span> <span>"excalidraw"</span><span>,</span>
      <span>"name"</span><span>:</span> <span>"Excalidraw"</span><span>,</span>
      <span>"description"</span><span>:</span> <span>"Excalidraw file"</span><span>,</span>
      <span>"role"</span><span>:</span> <span>"Editor"</span><span>,</span>
      <span>"mimeType"</span><span>:</span> <span>"application/json"</span>
    <span>}</span>
  <span>]</span>
<span>}</span></code></pre></div>
<p>Unfortunately, in practice, this does not always work as intended, since, depending on the installation type (for the current user, for all users), apps on Windows&nbsp;10 do not have the rights to associate a file type to themselves.</p>
<p>These shortcomings and the pending work to make the experience truly native-like on <em>all</em> platforms (which, again, with enough effort <em>is</em> possible) were a strong argument for us to reconsider our investment in Excalidraw Desktop. The way bigger argument for us, though, was that we foresee that for <em>our</em> use case, we do not need all the features Electron offers. The grown and still growing set of capabilities of the Web serves us equally well, if not better.</p>
<h2>How the Web serves us today and in the future</h2>
<p>Even in 2020, <a href="https://jquery.com/">jQuery</a> is still <a href="https://almanac.httparchive.org/en/2020/javascript#libraries">incredibly popular</a>. For many developers it has become a habit to use it, despite the fact that today they <a href="http://youmightnotneedjquery.com/">might not need jQuery</a>. There is a similar resource for Electron, aptly called <a href="https://youmightnotneedelectron.com/">You Might Not Need Electron</a>. Let me outline in the following why we think we do not need Electron.</p>
<h3>Installable Progressive Web App</h3>
<p>Excalidraw today is an <a href="https://web.dev/installable/">installable</a> Progressive Web App with a <a href="https://excalidraw.com/service-worker.js">service worker</a> and a <a href="https://excalidraw.com/manifest.json">Web App Manifest</a>. It caches all its resources in two caches, one for fonts and font-related CSS, and one for everything else.</p>
<figure>
  <span>
      <a href="https://blog.excalidraw.com/static/6de51f0361ad22fbbb52ebe4a2f48227/49ee2/excalidraw-cache.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Chrome DevTools Application tab showing the two Excalidraw caches." title="Chrome DevTools Application tab showing the two Excalidraw caches." src="https://blog.excalidraw.com/static/6de51f0361ad22fbbb52ebe4a2f48227/fcda8/excalidraw-cache.png" srcset="https://blog.excalidraw.com/static/6de51f0361ad22fbbb52ebe4a2f48227/12f09/excalidraw-cache.png 148w,
https://blog.excalidraw.com/static/6de51f0361ad22fbbb52ebe4a2f48227/e4a3f/excalidraw-cache.png 295w,
https://blog.excalidraw.com/static/6de51f0361ad22fbbb52ebe4a2f48227/fcda8/excalidraw-cache.png 590w,
https://blog.excalidraw.com/static/6de51f0361ad22fbbb52ebe4a2f48227/efc66/excalidraw-cache.png 885w,
https://blog.excalidraw.com/static/6de51f0361ad22fbbb52ebe4a2f48227/c83ae/excalidraw-cache.png 1180w,
https://blog.excalidraw.com/static/6de51f0361ad22fbbb52ebe4a2f48227/49ee2/excalidraw-cache.png 1618w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
  <figcaption>Excalidraw's cache contents</figcaption>
</figure>
<p>This means the application is fully offline-capable and can run without a network connection. Chromium-based browsers on both desktop and mobile prompt the user if they want to install the app. You can see the installation prompt in the screenshot below.</p>
<figure>
  <span>
      <a href="https://blog.excalidraw.com/static/16be4e620446e7da17481d3fd520d6b8/d67fd/install-excalidraw.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Excalidraw prompting the user to install the app in Chrome on macOS." title="Excalidraw prompting the user to install the app in Chrome on macOS." src="https://blog.excalidraw.com/static/16be4e620446e7da17481d3fd520d6b8/fcda8/install-excalidraw.png" srcset="https://blog.excalidraw.com/static/16be4e620446e7da17481d3fd520d6b8/12f09/install-excalidraw.png 148w,
https://blog.excalidraw.com/static/16be4e620446e7da17481d3fd520d6b8/e4a3f/install-excalidraw.png 295w,
https://blog.excalidraw.com/static/16be4e620446e7da17481d3fd520d6b8/fcda8/install-excalidraw.png 590w,
https://blog.excalidraw.com/static/16be4e620446e7da17481d3fd520d6b8/d67fd/install-excalidraw.png 670w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
  <figcaption>The Excalidraw install dialog in Chrome</figcaption>
</figure>
<p>Excalidraw is configured to run as a standalone application, so when you install it, you get an app that runs in its own window. It is fully integrated in the operating system’s multitasking UI and gets its own app icon on the home screen, Dock, or task bar; depending on what platform you install it.</p>
<figure>
  <span>
      <a href="https://blog.excalidraw.com/static/dd69b46d69578ef7d0a8020d1f649bf1/d8d63/excalidraw-pwa.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Excalidraw running in its own window." title="Excalidraw running in its own window." src="https://blog.excalidraw.com/static/dd69b46d69578ef7d0a8020d1f649bf1/fcda8/excalidraw-pwa.png" srcset="https://blog.excalidraw.com/static/dd69b46d69578ef7d0a8020d1f649bf1/12f09/excalidraw-pwa.png 148w,
https://blog.excalidraw.com/static/dd69b46d69578ef7d0a8020d1f649bf1/e4a3f/excalidraw-pwa.png 295w,
https://blog.excalidraw.com/static/dd69b46d69578ef7d0a8020d1f649bf1/fcda8/excalidraw-pwa.png 590w,
https://blog.excalidraw.com/static/dd69b46d69578ef7d0a8020d1f649bf1/efc66/excalidraw-pwa.png 885w,
https://blog.excalidraw.com/static/dd69b46d69578ef7d0a8020d1f649bf1/c83ae/excalidraw-pwa.png 1180w,
https://blog.excalidraw.com/static/dd69b46d69578ef7d0a8020d1f649bf1/d8d63/excalidraw-pwa.png 2026w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
  <figcaption>The Excalidraw PWA in a standalone window</figcaption>
</figure>
<figure>
  <span>
      <a href="https://blog.excalidraw.com/static/1769e90d9bfd53401cf1590b5f8926d5/076ca/excalidraw-icon.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Excalidraw icon on the macOS Dock." title="Excalidraw icon on the macOS Dock." src="https://blog.excalidraw.com/static/1769e90d9bfd53401cf1590b5f8926d5/fcda8/excalidraw-icon.png" srcset="https://blog.excalidraw.com/static/1769e90d9bfd53401cf1590b5f8926d5/12f09/excalidraw-icon.png 148w,
https://blog.excalidraw.com/static/1769e90d9bfd53401cf1590b5f8926d5/e4a3f/excalidraw-icon.png 295w,
https://blog.excalidraw.com/static/1769e90d9bfd53401cf1590b5f8926d5/fcda8/excalidraw-icon.png 590w,
https://blog.excalidraw.com/static/1769e90d9bfd53401cf1590b5f8926d5/efc66/excalidraw-icon.png 885w,
https://blog.excalidraw.com/static/1769e90d9bfd53401cf1590b5f8926d5/076ca/excalidraw-icon.png 914w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
  <figcaption>The Excalidraw icon on the macOS Dock</figcaption>
</figure>
<h3>File system access</h3>
<p>Excalidraw makes use of <a href="https://github.com/GoogleChromeLabs/browser-nativefs">browser-nativefs</a> for accessing the file system of the operating system. On supporting browsers, this allows for a true open→edit→save workflow and actual over-saving and “save as”, with a transparent fallback for other browsers. You can learn more about this feature in my blog post <a href="https://blog.excalidraw.com/browser-nativefs/">Reading and writing files and directories with the browser-nativefs library</a>.</p>
<h3>Drag and drop support</h3>
<p>Files can be dragged and dropped onto the Excalidraw window just as in native applications. On a browser that supports the <a href="https://web.dev/file-system-access/">File System Access API</a>, a dropped file can be immediately edited and the modifications be saved to the original file. This is so intuitive that you sometimes forget that you are dealing with a Web app.</p>
<h3>Clipboard access</h3>
<p>Excalidraw works well with the operating system’s clipboard. Entire Excalidraw drawings or also just individual objects can be copied and pasted in <code>image/png</code> and <code>image/svg+xml</code> formats, allowing for an easy integration with other native tools like <a href="https://inkscape.org/">Inkscape</a> or Web-based tools like <a href="https://jakearchibald.github.io/svgomg/">SVGOMG</a>.</p>
<figure>
  <span>
      <a href="https://blog.excalidraw.com/static/9fdb4575d0cdafbc5baa6cf8c9530117/906b5/clipboard.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Excalidraw context menu showing the 'copy to clipboard as SVG' and 'copy to clipboard as PNG' menu items." title="Excalidraw context menu showing the 'copy to clipboard as SVG' and 'copy to clipboard as PNG' menu items." src="https://blog.excalidraw.com/static/9fdb4575d0cdafbc5baa6cf8c9530117/fcda8/clipboard.png" srcset="https://blog.excalidraw.com/static/9fdb4575d0cdafbc5baa6cf8c9530117/12f09/clipboard.png 148w,
https://blog.excalidraw.com/static/9fdb4575d0cdafbc5baa6cf8c9530117/e4a3f/clipboard.png 295w,
https://blog.excalidraw.com/static/9fdb4575d0cdafbc5baa6cf8c9530117/fcda8/clipboard.png 590w,
https://blog.excalidraw.com/static/9fdb4575d0cdafbc5baa6cf8c9530117/efc66/clipboard.png 885w,
https://blog.excalidraw.com/static/9fdb4575d0cdafbc5baa6cf8c9530117/906b5/clipboard.png 950w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
  <figcaption>The Excalidraw context menu offering clipboard actions</figcaption>
</figure>
<h3>File handling</h3>
<p>Excalidraw already supports the experimental <a href="https://web.dev/file-handling/">File Handling API</a>, which means <code>.excalidraw</code> files can be double-clicked in the operating system’s file manager and open directly in the Excalidraw app, since Excalidraw registers as a file handler for <code>.excalidraw</code> files in the operating system.</p>
<h3>Declarative link capturing</h3>
<p>Excalidraw drawings can be shared by link—here is an <a href="https://excalidraw.com/#json=4646308765761536,jwZJW8JsOM75vdhqG2nBgA">example</a>. In the future, if people have Excalidraw installed as a PWA, such links will not open in a browser tab, but launch a new standalone window. This will work thanks to <a href="https://github.com/WICG/sw-launch/blob/master/declarative_link_capturing.md">declarative link capturing</a>, an, at the time of writing, bleeding-edge proposal for a new Web platform feature.</p>
<h2>Conclusion</h2>
<p>The Web has come a long way, with more and more features landing in browsers that only a couple of years or even months ago were unthinkable on the Web and exclusive to native applications. Excalidraw is at the forefront of what is possible in the browser, all while acknowledging that not all browsers on all platforms support each feature we make use of. By betting on a progressive enhancement strategy, we enjoy the latest and greatest wherever possible, but without leaving anyone behind. Best viewed in <em>any</em> browser.</p>
<p>Electron has served us well, but in 2020 and beyond, we can live without it. Oh, and for that objective of <a href="https://github/com/vjeux">@vjeux</a>: since the Android Play Store now accepts PWAs in a container format called <a href="https://web.dev/using-a-pwa-in-your-android-app/">Trusted Web Activity</a> and since the <a href="https://docs.microsoft.com/en-us/microsoft-edge/progressive-web-apps-edgehtml/microsoft-store">Microsoft Store supports PWAs</a>, too, you can expect Excalidraw in these stores in the not too distant future. Meanwhile, you can always use and install <a href="https://excalidraw.com/">Excalidraw in and from the browser</a>.</p></div></div>]]>
            </description>
            <link>https://blog.excalidraw.com/deprecating-excalidraw-electron/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454687</guid>
            <pubDate>Thu, 17 Dec 2020 11:42:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React vs. Angular vs. Vue]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25454595">thread link</a>) | @oczek
<br/>
December 17, 2020 | https://blog.graphqleditor.com/react-angular-vue/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/react-angular-vue/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>After looking at the features, components and libraries for Vue, React and Angular it’s time to do an actual comparison of the three. While in terms of popularity React is still top there are substantial differences in where each of the frameworks excels. So even if you’re already committed to one (or want to switch) it’s probably a good idea to check out exactly how they measure up against each other in a few key aspects.</p>
<h2>Basics</h2>
<p>Before we get to the meat it’s probably prudent to point out what these differences stem from. Each of the three frameworks has a different approach to development and aims at helping devs in a different way. <strong>React and Angular are developed by big companies</strong> namely Facebook and Google while <strong>Vue has started as a side project</strong> of a Google developer. While all are JavaScript based, each presents a slightly different syntax approach. React uses JavaScript and JSX (which combines HTML and JavaScript logic), Angular uses TypeScript (HTML and TypeScript logic is split) Vue uses JavaScript (HTML and JavaScript logic is split). All of them are component-driven, but they treat coding them differently along with a number of default features included.</p>
<ul>
<li><strong>React</strong> combines the UI and behavior of components, the same code is responsible for both creating a UI component and dictating its behavior. </li>
<li><strong>Vue</strong> takes the same approach and even lets you combine the UI and behavior of components from within a script. </li>
<li><strong>Angular</strong> completely separates the two, the UI parts of components are attributes of HTML tags while their behaviors are in the form of JavaScript code. </li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>Components</th>
<th>Lang</th>
<th>Built-in features</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>React</strong></td>
<td><em>same code is responsible for UI &amp; logic</em></td>
<td><em>JavaScript/JSX</em></td>
<td><em>low amount</em></td>
</tr>
<tr>
<td><strong>Angular</strong></td>
<td><em>components’ UI &amp; logic are completely separated</em></td>
<td><em>TypeScript</em></td>
<td><em>high amount</em></td>
</tr>
<tr>
<td><strong>Vue</strong></td>
<td><em>same code is responsible for UI &amp; logic</em></td>
<td><em>JavaScript</em></td>
<td><em>fair amount</em></td>
</tr>
</tbody>
</table>
<h2>Learning curve</h2>
<p>Finally the main difference in approach is probably the learning curve. Vue is the easiest to learn and can even serve as a stepping stone for learning the two others, as there is some overlap especially in handling components. Simplicity and customizability obviously have their advantages, but there are also some drawbacks as it makes it somewhat difficult to debug and test. React is middle of the road, it is harder to get into but has great documentation and an easy to follow starting guide. The drawback is it does require use of third party libraries for more complex stuff. This makes the learning curve not so steep but highly dependent on what you actually want to do and what third party libraries you’ll need to learn to do it. Angular is the complete framework, but also has the steepest learning curve requiring learning TypeScript, RxJS and MVC. The investment of time and effort may prove well worth it as mastering it will make building your app a breeze.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/256ae861e92cff3c9bed714f84a188e0/e3189/charts.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Popularity of React, Vue, Angular" title="Popularity of React, Vue, Angular" src="https://blog.graphqleditor.com/static/256ae861e92cff3c9bed714f84a188e0/fcda8/charts.png" srcset="https://blog.graphqleditor.com/static/256ae861e92cff3c9bed714f84a188e0/12f09/charts.png 148w,
https://blog.graphqleditor.com/static/256ae861e92cff3c9bed714f84a188e0/e4a3f/charts.png 295w,
https://blog.graphqleditor.com/static/256ae861e92cff3c9bed714f84a188e0/fcda8/charts.png 590w,
https://blog.graphqleditor.com/static/256ae861e92cff3c9bed714f84a188e0/efc66/charts.png 885w,
https://blog.graphqleditor.com/static/256ae861e92cff3c9bed714f84a188e0/e3189/charts.png 1035w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h2>Minimalism vs all-in-one</h2>
<p>Approach and philosophy are important and all but that’s mostly just the pitch. For a clearer picture it’s better to look at the features. As mentioned above React takes a minimalistic approach here, it provides you with a library for rendering content to the DOM. It does provide some rudimentary built-in state management support but you’ll likely need to use a state management library like Redux (which is fortunately quite easy to learn). There aren’t any other special features and if you need some other functionalities you’ll need to check out community provided solutions. That does make it a lot slimmer than the other two, but can be a hassle if you’re working on a complex project and looking to get started from the get go. Vue is the middle ground, it provides some features, but isn’t the complete package Angular is. You get built in state management as well as a built-in router. Though for form validation you’ll need something like the Vuelidate library and a library for Http client functions (there’s quite a few to choose from) Angular gives you all these features out of the box and more, there’s an official CLI which helps building, managing, updating and deploying projects even easier.</p>
<table>
<thead>
<tr>
<th></th>
<th>React</th>
<th>Angular</th>
<th>Vue</th>
</tr>
</thead>
<tbody>
<tr>
<td>Backed by</td>
<td><em>Facebook</em></td>
<td><em>Google</em></td>
<td><em>Evan You</em></td>
</tr>
<tr>
<td>Release date</td>
<td><em>2013</em></td>
<td><em>2016</em></td>
<td><em>2014</em></td>
</tr>
<tr>
<td>Lang</td>
<td><em>JavaScript</em></td>
<td><em>TypeScript</em></td>
<td><em>JavaScript</em></td>
</tr>
<tr>
<td>Learning curve</td>
<td><em>medium</em></td>
<td><em>hard</em></td>
<td><em>easy</em></td>
</tr>
<tr>
<td>Documnation</td>
<td><em>good</em></td>
<td><em>good</em></td>
<td><em>good</em></td>
</tr>
<tr>
<td>Features</td>
<td><em>external libraries</em></td>
<td><em>all-in-one</em></td>
<td><em>most-in-one</em></td>
</tr>
<tr>
<td>Production-ready</td>
<td><em>yes</em></td>
<td><em>yes</em></td>
<td><em>yes</em></td>
</tr>
</tbody>
</table>
<h2>Less is more</h2>
<p>The thought that comes to mind is probably, why not go with Angular, after all it has the most features. Well more isn’t always better and as mentioned the steep learning curve can be a turnoff especially if you’re looking to get started right away or working on projects requiring less complex solutions out of the box. Oh and emphasis on ‘out-of-the-box’ here, it’s not like Vue and React are useless when it comes to features. Just the opposite, they’re freely available to you when you need them, you just need to reach out to the community instead of getting them built-in with the framework. As you can see it comes to personal preference and focusing on what fits you best now and what might fit you best in the future, hopefully this little piece helped with that at least a little bit.</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/react-angular-vue/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454595</guid>
            <pubDate>Thu, 17 Dec 2020 11:27:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Covid-19 Pandemic and the Art of Geo Time Series]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25454448">thread link</a>) | @MorganeR
<br/>
December 17, 2020 | https://blog.senx.io/the-covid-19-pandemic-and-the-art-of-geo-time-series/ | <a href="https://web.archive.org/web/*/https://blog.senx.io/the-covid-19-pandemic-and-the-art-of-geo-time-series/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
<p>As <a rel="noreferrer noopener" href="https://senx.io/" target="_blank">SenX</a> enters its second week of remote work, I thought it would be a good time to write about the importance of time and <a href="https://blog.senx.io/working-with-geo-data-in-warp-10/" target="_blank" rel="noreferrer noopener">geo time series</a> during a pandemic like the one we are experiencing with the coronavirus and the associated COVID-19.</p>



<p>For millions if not billions of people on Earth, <strong>some time series has become the most important thing to look at.</strong> Whether it is the #FlattenTheCurve graph or the Hammer and the dance illustration, or the various graphs showing the evolution of the number of cases, recovering patients, and unfortunately deaths, those are all-time series, i.e. graphs whose x-axis represents the time and the y-axis the evolution of tracked quantities.</p>



<figure><img src="https://media.wired.com/photos/5e6aac7295ff060008467cf9/master/w_1600%2Cc_limit/Science_Covid19-Infographic.jpg" alt="Coronavirus COVID-19 #FlattenTheCurve strategy"><figcaption>#FlattenTheCurve</figcaption></figure>



<h2>Contact Tracing</h2>



<p>But another trend about to begin will bring people exposed even more to time series. As the world learns how countries such as Singapore, South Korea, or Taiwan have dealt with the COVID-19 outbreak, the notion of <a href="https://en.wikipedia.org/wiki/Contact_tracing" target="_blank" rel="noreferrer noopener">Contact Tracing</a> has appeared in the media and will soon be in everybody's mouth.</p>



<p>The reaction to that notion, which is widely used in public health but may appear new to many, varies from country to country, and among countries varies with culture, political background, or religious belief. Some are considering it as the end of privacy and liberty. The others as a salvation technique or more moderate ones as a good temporary tactic for fighting the outbreak.</p>



<h3>But what exactly is contact tracing? </h3>



<p>The idea is very simple. It keeps a log of who you came close to so when someone gets tested positive with COVID-19 his or her log can be accessed. The people appearing in the log can be contacted to test them too. Logs used to be your memory, now with the advent of technology they can be tracked automatically.</p>



<p>By relying on those automated logs, the sphere of contagion of the newly discovered patient can easily be determined from the patient's own log and from those of the people that were in contact with that patient with the same process being extended as individuals are tested positive.</p>



<h3>How are the people you came in contact with identified? </h3>



<p>Well, that is rather simple, with the help of technology. Contact tracing relies on a mobile app which exploits the <strong>Bluetooth signal of the phone</strong> it is installed on. Bluetooth is a short-range radio system. It means that it cannot be transmitted more than a few meters. So technically if you can receive the Bluetooth signal from another phone, then this phone is in the vicinity of yours. </p>


<span><span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.senx.io%2F%3Fp%3D9855&amp;text=Due%20to%20COVID-19%2C%20for%20millions%20of%20people%2C%20some%20time%20series%20has%20become%20the%20most%20important%20thing%20to%20look%20at.&amp;via=SenXHQ&amp;related=SenXHQ" target="_blank" rel="noopener noreferrer">Due to COVID-19, for millions of people, some time series has become the most important thing to look at. </a></span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.senx.io%2F%3Fp%3D9855&amp;text=Due%20to%20COVID-19%2C%20for%20millions%20of%20people%2C%20some%20time%20series%20has%20become%20the%20most%20important%20thing%20to%20look%20at.&amp;via=SenXHQ&amp;related=SenXHQ" target="_blank" rel="noopener noreferrer">Click To Tweet</a></span>


<p>When that happens, the mobile application adds an entry to its log, saying it saw a signal from another application. The id logged is a random id that is assigned to your phone at the time you installed the app. <strong>Only the organization responsible for the application can associate this random id with your phone number</strong>. So yes, you should trust this organization for willing to not do evil.</p>



<p>That is all there is to it, contact tracing in a few paragraphs. </p>



<h3>Back to our own topic now </h3>



<p>The log kept by the contact tracing application has one important component, <strong>the timestamping</strong> of the entries. Because if you came in contact with someone more than 21 days ago (roughly the longest incubation period for COVID-19), then there is no need to contact that person as you were probably not contagious when you two came close. So yes, the base of contact tracing is recording time series and later analyzing them to reconstruct a timed graph of interactions.</p>



<figure></figure>



<h2>What about Warp 10?</h2>



<p><a href="https://warp10.io/" target="_blank" rel="noreferrer noopener">Warp 10</a> is our advanced time series platform. It can be used to analyze those time series, even at a large scale, at the scale of a whole population if need be. So any agency willing to put contact tracing in place should contact us, we can help.</p>



<p>Note that beyond the contact tracing some countries have used in the case of the COVID-19 pandemic, there might be some other situations where more information may need to be collected, most notably actual location data when a pathogen agent is really contagious and can stay in the environment and spread without human to human contact. In that case, besides obvious debates about privacy or lack thereof that would be legitimate to have, the data collected are no longer simply time series but geo time series. And there again Warp 10 can help to analyze them.</p>



<p>The weeks to come will undoubtedly bring on the table the question of contact tracing. I hope this article helped you understand better how it works. The social implication of contact tracing will need to be balanced with the benefit that it can bring to fighting the ongoing pandemic. When those debates will have settled, remember that technology such as Warp 10 can help analyze those data fast.</p>



<p><strong>Keep safe, stay at home!</strong></p>



<p>The Ministry of Health of Singapore just announced it would be open-sourcing its own contact tracing application is used for fighting the COVID-19 outbreak.</p>
<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->      
           
    </article></div>]]>
            </description>
            <link>https://blog.senx.io/the-covid-19-pandemic-and-the-art-of-geo-time-series/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454448</guid>
            <pubDate>Thu, 17 Dec 2020 10:59:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[51% of 4M Docker images have critical vulnerabilities]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25454207">thread link</a>) | @AnnieNma
<br/>
December 17, 2020 | https://thechief.io/c/news/51-4-million-docker-images-have-critical-vulnerabilities/ | <a href="https://web.archive.org/web/*/https://thechief.io/c/news/51-4-million-docker-images-have-critical-vulnerabilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://thechief.io/c/news/51-4-million-docker-images-have-critical-vulnerabilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454207</guid>
            <pubDate>Thu, 17 Dec 2020 10:09:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to debug Elixir/Erlang compiler performance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25454147">thread link</a>) | @wojtekmach
<br/>
December 17, 2020 | https://dashbit.co/blog/how-to-debug-elixir-erlang-compiler-performance | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/how-to-debug-elixir-erlang-compiler-performance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> José Valim
  </li>
  <li>
    <i></i> December 15th, 2020
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/compiler">compiler</a>, <a href="https://dashbit.co/blog/tags/performance">performance</a>
  </li>
</ul>
<p>
Recently someone opened up an <a href="https://github.com/elixir-gettext">issue on Gettext</a> saying compilation of Gettext modules got slower in Erlang/OTP 23. In this article, we are going to explore how I have debugged this problem and the three separate pull requests sent to the Erlang/OTP repository to improve compiler performance.</p>
<p>
For those not familar, the Gettext project converts <code>.po</code> files like this:</p>
<pre><code># pt
msgid "Hello world"
msgstr "Olá mundo"

# pl
msgid "Hello world"
msgstr "Witaj świecie"</code></pre>
<p>
Into a module with functions:</p>
<pre><code><span>def</span><span> </span><span>translate</span><span data-group-id="9576884584-1">(</span><span>"pt"</span><span>,</span><span> </span><span>"Hello world"</span><span data-group-id="9576884584-1">)</span><span>,</span><span> </span><span>do</span><span>:</span><span> </span><span>"Olá mundo"</span><span>
</span><span>def</span><span> </span><span>translate</span><span data-group-id="9576884584-2">(</span><span>"pl"</span><span>,</span><span> </span><span>"Hello world"</span><span data-group-id="9576884584-2">)</span><span>,</span><span> </span><span>do</span><span>:</span><span> </span><span>"Witaj świecie"</span></code></pre>
<p>
While we start with an Elixir application, we end-up doing most of the work with the Erlang compiler and tools, so most of the lessons here are applicable to the wider ecosystem. Be sure to read until the end for a welcome surprise.</p>
<h2>
Isolating the slow file</h2>
<p>
When project compilation is slow, the first step is to identify which files are slow. In Elixir v1.11, this can be done like this:</p>
<pre><code>$ mix compile --force --profile time</code></pre>
<p>
The command above will print:</p>
<pre><code>...
[profile] lib/ecto/query/planner.ex compiled in 1376ms (plus 596ms waiting)
[profile] lib/ecto/association.ex compiled in 904ms (plus 1168ms waiting)
[profile] lib/ecto/changeset.ex compiled in 869ms (plus 1301ms waiting)
[profile] Finished compilation cycle of 95 modules in 2579ms
[profile] Finished group pass check of 95 modules in 104ms</code></pre>
<p>
Compilation of each file in your project is done in parallel. The overall message is:</p>
<pre><code>[profile] FILE compiled in COMPILE_TIME (plus WAITING_TIME waiting)</code></pre>
<p>
<code>COMPILE_TIME</code> is the time we were effectively compiling code. However, since a file may depend on a module defined in another file, <code>WAITING_TIME</code> is the time we wait until the file we depend on becomes available. High waiting times are not usually a concern, so we focus on the files with high compilation times.</p>
<p>
At the end, we print two summaries:</p>
<pre><code>[profile] Finished compilation cycle of 95 modules in 2579ms
[profile] Finished group pass check of 95 modules in 104ms</code></pre>
<p>
The first includes the time to compile all files in parallel and includes how many modules have been defined. The second is the time to execute a group pass which looks at all modules at once, in order to find undefined functions, emit deprecations, etc.</p>
<p>
Unless the “group pass check” is the slow one - which would be a bug in the Elixir compiler - we are often looking at a single file being the root cause of slow compilation. With this file in hand, it is time to dig deeper.</p>
<h2>
Timing the slow file</h2>
<p>
Once we have identified the slow file, we need to understand why it is slow. When Elixir compiles a file, it executes code at three distinct stages. For example, let’s assume the slow down was in <code>lib/problematic_file.ex</code> that looks like this:</p>
<pre><code><span># FILE LEVEL</span><span>
</span><span>defmodule</span><span> </span><span>ProblematicModule</span><span> </span><span data-group-id="0623758596-1">do</span><span>
  </span><span># MODULE LEVEL</span><span>
  </span><span>def</span><span> </span><span>function</span><span> </span><span data-group-id="0623758596-2">do</span><span>
    </span><span># FUNCTION LEVEL</span><span>
  </span><span data-group-id="0623758596-2">end</span><span>
</span><span data-group-id="0623758596-1">end</span></code></pre>
<p>
When compiling the file above, Elixir will execute each level in order. If that file has multiple modules, then compilation will happen for each module in the file, first at MODULE LEVEL and then FUNCTION LEVEL.</p>
<blockquote>
  <p>
TIP: If a file with multiple modules is slow, I suggest breaking those modules into separate files and repeating the steps in the previous section.  </p>
</blockquote>
<p>
With this knowledge in hand, we want to compile the file once again, but now passing the <code>ERL_COMPILER_OPTIONS=time</code> flag to the underlying Erlang compiler, which will print time reports. One option is to do this:</p>
<pre><code>$ mix compile
$ touch lib/problematic_file.ex
$ ERL_COMPILER_OPTIONS=time mix compile</code></pre>
<p>
Then, for each module being compiled (which includes the one in your <code>mix.exs</code>), you will see a report like this:</p>
<pre><code>core             :  0.653 s   72136.4 kB
sys_core_fold    :  0.482 s   69055.3 kB
sys_core_alias   :  0.146 s   69055.3 kB
core_transforms  :  0.000 s   69055.3 kB
sys_core_bsm     :  0.098 s   69055.3 kB
v3_kernel        :  2.250 s  169439.0 kB</code></pre>
<p>
Most compilers work by doing multiple passes on your code. Above we can see how much time was spent on each pass and how much memory the code representation, also known as Abstract Syntax Tree (AST), takes after each pass.</p>
<p>
The <code>ERL_COMPILER_OPTIONS=time mix compile</code> command above has one issue though. If other files depend on the problematic file, they may be recompiled too, and that will add noise to your output. If that’s the case, you can also do this:</p>
<pre><code>$ ERL_COMPILER_OPTIONS=time mix run lib/problematic_file.ex</code></pre>
<p>
This is a rather neat trick: we are re-running a file that we have just compiled. You will get warnings about modules being redefined but they are safe to ignore.</p>
<p>
With the time reports in hand, there are two possible scenarios here:</p>
<ol>
  <li>
    <p>
One (or several) of the passes in the report are slow. This means the slow down happens when compiling at the FUNCTION LEVEL and it will be associated with the generation of the <code>.beam</code> file for <code>ProblematicModule</code>    </p>
  </li>
  <li>
    <p>
All passes are fast and the slow down happens before the reports emitted by <code>ERL_COMPILER_OPTIONS=time</code> are printed. If this is the case, the slowdown is actually happening at the MODULE LEVEL, before the generation of the <code>.beam</code> file    </p>
  </li>
</ol>
<p>
Most times, the slowdown is actually at the FUNCTION LEVEL, including the one reported as a Gettext issue, so that’s the one we will explore. Performance issues at the MODULE LEVEL may still happen though, especially in large module bodies as seen in Phoenix’s Router - but don’t worry, those have often already been optimized throughout the years!</p>
<h2>
Moving to Erlang</h2>
<p>
At this point, we have found a module that is slow to compile. Given the original Gettext issue pointed to a difference of performance between Erlang versions, my next step is to remove Elixir from the equation.</p>
<p>
Luckily, this is very easy to do with the <a href="https://github.com/michalmuskala/decompile">decompile</a> project:</p>
<pre><code>$ mix archive.install github michalmuskala/decompile
$ mix decompile ProblematicModule --to erl</code></pre>
<p>
This command will emit a <code>Elixir.ProblematicModule.erl</code> file, which is literally the compiled Elixir code, represented in Erlang. Now, let’s compile it again, but without involving Elixir at all:</p>
<pre><code>$ erlc +time Elixir.ProblematicModule.erl</code></pre>
<blockquote>
  <p>
TIP: the command above may not work out of the box. That’s because the <code>.erl</code> file generated by <code>decompile</code> may have invalid syntax. In those cases, you can manually fix those errors. They are often small nits.  </p>
</blockquote>
<p>
If you want to try it yourself, you can <a href="https://gist.github.com/josevalim/694c1799143fcf25e43aa27e3e11e4c1">find the <code>.erl</code> file for the Gettext report here</a>:</p>
<pre><code>$ erlc +time Elixir.GettextCompile.Gettext.erl</code></pre>
<p>
Here are the relevant snippets of the report I got on my machine:</p>
<pre><code>...
expand_records         :      0.065 s   19988.0 kB
core                   :      3.295 s  373293.3 kB
...
beam_ssa_bool          :      1.125 s   39252.7 kB
...
beam_ssa_bsm           :      2.432 s   39263.1 kB
   ...
beam_ssa_funs          :      0.119 s   39263.1 kB
beam_ssa_opt           :      6.242 s   39298.0 kB
   ...
...
beam_ssa_pre_codegen   :      3.426 s   48897.5 kB
   ...
...</code></pre>
<p>
Looking at the report you can start building an intuition about which passes are slow. Given we were also told the code compiled fast on Erlang/OTP 22.3, I compiled the same file with that Erlang version and compared the reports side by side. Here are my notes:</p>
<ol>
  <li>
    <p>
The <code>core</code> pass got considerably slower between Erlang/OTP versions (from 1.8s to 3.2s)    </p>
  </li>
  <li>
    <p>
Going from the <code>expand_records</code> pass to <code>core</code> increases the memory usage by almost 20 times (although this behaviour was also there on Erlang/OTP 22)    </p>
  </li>
  <li>
    <p>
The <code>beam_ssa_bool</code> did not exist on Erlang/OTP 22    </p>
  </li>
</ol>
<p>
In Erlang/OTP 22.3, the module takes 22 seconds to compile. On version 23.1, it takes 32 seconds. We have some notes and a reasonable target of 22 seconds to optimize towards. Let’s get to work.</p>
<blockquote>
  <p>
Note: it is worth saying that it is very natural for new passes to be added and others to be removed between Erlang/OTP versions, precisely because the compiler is getting smarter all the time! As part of this process, some passes get faster and others get slower. Such is life. :)  </p>
</blockquote>
<h2>
Pull request #1: the profiler option</h2>
<p>
The Erlang compiler also has a neat feature that alows us to profile any compiler pass. Since we have detected the slow down in the <code>core</code> file, let’s profile it:</p>
<pre><code>$ erlc +'{eprof, core}' Elixir.ProblematicModule.erl</code></pre>
<p>
It will print a report like this:</p>
<pre><code>core: Running eprof

****** Process &lt;0.111.0&gt;    -- 100.00 % of profiled time ***
FUNCTION                   CALLS        %      TIME  [uS / CALLS]
--------                   -----  -------      ----  [----------]
gen:do_for_proc/2              1     0.00         0  [      0.00]
gen:'-call/4-fun-0-'/4         1     0.00         0  [      0.00]
v3_core:unforce/2              2     0.00         0  [      0.00]
v3_core:make_bool_switch/5     2     0.00         0  [      0.00]
v3_core:expr_map/4             1     0.00         0  [      0.00]
v3_core:safe_map/2             1     0.00         0  [      0.00]</code></pre>
<p>
With the slowest entries coming at the bottom. In this Gettext module, the slowest entry was:</p>
<pre><code>cerl_trees:mapfold/4     3220377    19.14   2447684  [      0.76]</code></pre>
<p>
Jackpot! 20% of the compilation time was spent on a single function. This is a great opportunity for optimization.</p>
<p>
I usually like to say there are two types of performance improvements. You have semantic improvements, which you can only pull off by having a grasp of the domain. The more you understand, the more likely you are to be able to come up with an improved algorithm (or the more you will be certain you are already implementing the state of the art). There are also mechanical improvements, which are more about how the runtime and the data structures in the language work. Often you work with a mixture of both.</p>
<p>
In this case, the function <code>cerl_trees:mapfold/4</code> is a function that traverses all AST nodes recursively. You can also see it was called more than 3 million times. The <a href="https://github.com/erlang/otp/blob/db13f8883721c7a217a80cb2c73a1e419f462d83/lib/compiler/src/v3_core.erl#L3040">caller of this function in the <code>core</code> pass has the following goal</a>:</p>
<blockquote>
  <p></p></blockquote></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/how-to-debug-elixir-erlang-compiler-performance">https://dashbit.co/blog/how-to-debug-elixir-erlang-compiler-performance</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/how-to-debug-elixir-erlang-compiler-performance</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454147</guid>
            <pubDate>Thu, 17 Dec 2020 09:57:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crypto in Layman's Terms]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25453703">thread link</a>) | @alex_portabella
<br/>
December 17, 2020 | https://portabella.io/blog/2020-11-16-crypto-in-laymans-terms/ | <a href="https://web.archive.org/web/*/https://portabella.io/blog/2020-11-16-crypto-in-laymans-terms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>This is a post I've been wanting to write for a while now. I want to put down in layman's terms what various cryptographic operations represent, and common use cases for them. When designing large systems we don't need to get bogged down in details of how a Diffie-Hellman handshake works, what we need are abstractions, patterns and black boxes we can effectively use together and reason about.</p><p>With this post I hope to present terms you may or may not have heard before, hopefully with a few examples, one for anyone to understand and at least one for developers to understand.</p><p>Before we go any further it's worth mentioning the old adage - never roll your own crypto. Always build on proven, audited libraries and preferably get the implementation looked at by someone who knows what they're doing. Cryptographic operations can fail (often silently) in unpredictable ways, leaving you stuck with the assumption that what you've built is secure, when it's really not.</p><div><h2 id="hashing">Hashing</h2><p>Hashing has many, many use cases in the digital world. For our purposes it can be easiest to explain hashing as a deep check for equality. Given two things (files, sentences, words, images) how do we ascertain that they are identical? This can be hard to reason about outside of computing because almost never are two items perfectly equal.</p><h5 id="in-a-system">In a system</h5><p>The most common use case almost all of us will be familiar with is password hashing. When users enter their password we don’t want to store that in plaintext, if a database of raw user passwords was leaked it’d be catastrophic. What we do instead is hash the password and store that. If the database is ever leaked the user passwords can’t be reversed from the hash.</p><p>I don’t need to provide another example for hashing because it’s so common, however let’s briefly look at how we might leverage hashing to build a custom image caching system. When we browse user profiles on a mobile application, the mobile application (hopefully) doesn’t fetch the images every time you see the image. What it <em>could</em> do, to save bandwidth, is just send the hash of the current image to the server. The server checks if this hash matches the hash of the latest upload, and only sends the new image if it doesn’t match, meaning the clients version is outdated.</p><h2 id="symmetric-encryption">Symmetric encryption</h2><p>Symmetric encryption is something most of us are probably familiar with, however if not, it’s simply the act of encrypting something with a key. If you don’t have the key, you can’t decrypt the data.</p><p>A good analogy can be to liken symmetric encryption with a safe. It’s big, heavy and you know whatever’s in there is going to be private. If you’ve got the combination - awesome - you’ve got full access to it. If not, you’re out of luck and you’re gonna have to try break it open.</p><h5 id="in-a-system-1">In a system</h5><p>As a practical example of symmetric encryption in a wider digital system, imagine you want to save data in the cloud. You’ve run out of space on your laptop and want to use Dropbox to store your data. Just sending your data to Dropbox is a recipe for disaster, anyone at Dropbox would be able to view your private information. However if you generate a symmetric key and encrypt your data with it before sending it to Dropbox, you know no one else is going to be able to see it.</p><h2 id="asymmetric-encryption">Asymmetric encryption</h2><p>Asymmetric encryption is a really powerful concept we can model entire systems around. It all boils down to there being a different key for encryption and decryption.</p><p>As a simple example, let’s liken asymmetric encryption to a letterbox. With a letterbox anyone can put mail in it, however only people with the key can read said mail. This is at odds with symmetric encryption from our previous example, where you need the key to put anything into the box.</p><h5 id="in-a-system-2">In a system</h5><p>I’ve struggled here to just pick one example to explore, but perhaps the most relevant is encrypted communication. With asymmetric encryption you have a public key (this is what others see, like the name on your letterbox) and you have a private key (like the name suggests, this one should be kept secret - otherwise anyone could open your letterbox). When two users want to communicate securely they simply encrypt their messages to the recipients public key. Now no one else other than those two can read their messages. To spell this out:</p><ul><li>User B (recipient) publishes their public key</li><li>User A (sender) encrypts a message to B’s public key</li><li>User A sends the encrypted message to B</li><li>User B receives the message and decrypts it with their private key.</li></ul><h2 id="signatures">Signatures</h2><p>Another great aspect of asymmetric cryptography is the ability to provide proof that a message came from someone in particular. To use the mail analogy again, this can be thought of as a stamp on the letter. You know that only Steve has the stamp “Steve’s stamp”, so you can trust any letter with this to be from him.</p><h5 id="in-a-system-3">In a system</h5><p>Digital signatures are used almost everywhere in the internet today. In the context of cryptocurrency and blockchains, every transaction you send it accompanied by a signature over the payload you’re sending - asserting that it came from you.</p><p>Let’s also take a moment to think about internal or external communication between various services you’ve written. How do you know when a request comes from your payments service that it’s really your payments service sending this message? When a user of your website does an action (buying an item, for example), how do you tie that action to the right user?</p><p>A common solution is signed payloads, <a href="https://jwt.io/">JSON Web Tokens</a> being a popular specification to follow. A session token is any many aspects just a signature over some payload you’ve provided, an assertion that at some point this user authenticated with you. A basic user authentication flow might go:</p><ul><li>User sends you their username and password</li><li>You verify that the password hash matches the saved hash for this username</li><li>You generate a signed payload that includes their unique ID and potentially anything else you don’t want to have to read from the database for every request.</li></ul><p>Now every request that comes to your server can just verify the signature provided, and you allow them access to the system based on that.</p><h2 id="blind-signatures">Blind Signatures</h2><p>A blind signature is one where the signer doesn’t need to about the contents of the message. This can be hard to reason about but one simple example is in an election voting situation. Alice comes in to vote and proves her identity to the officials at the location. After voting (her choice remains a secret) she hands the sealed envelope to the official, who signs and submits it. In this case the signer has no idea what choice Alice has made, however later at the vote counting station we can verify that this envelope is valid because it was signed by an official.</p><h5 id="in-a-system-4">In a system</h5><p>We could improve upon the above voting example and think about payments. Imagine we’re wanting to make a payment somewhere and not have the merchant know our identity, this is where we could leverage blind signatures to make transactions privately.</p><ol><li>We go to the bank and ask for a cheque for $100</li><li>We take this cheque and send our order to a shop (anonymously), asking for $100 worth of goods</li><li>The shop can verify this blind signature with the bank and send our goods to our specified address</li><li>We’ve successfully completed a purchase without either the bank knowing what we’re buying, or the merchant knowing who we are.</li></ol><h2 id="secret-sharing">Secret sharing</h2><p>I’ve wracked my brain for hours trying to think of a good analogy for secret sharing, but I wasn’t able to come up with one. Essentially it comes down to (what seems like) magic, you and another party are able to agree on something without ever communicating, it’s pretty cool.</p><p>What we’re talking about here are Diffie-Hellman key exchanges. They underpin almost all modern communication. Most of your browser traffic these days is secured via TLS (which implies some kind of key exchange between your browser and the server) however I’d like to explore another cool use case in the context of privacy preserving applications.</p><p>Before we dive into the example, at the highest level a Diffie-Hellman key exchange works as follows:</p><ul><li><code>DH(Alice's public key, Bob's private key) = shared_secret</code></li><li><code>DH(Bob's public key, Alice's private key) = shared_secret</code></li></ul><p>This <code>shared_secret</code> is only computable by Alice and Bob, no one else would be able to figure it out.</p><h5 id="a-use-case">A use case</h5><p>Let’s explore how we could build a privacy preserving messaging platform using a centralised database. At its most basic (and totally open) a message between two parties would look like this:</p><table><thead><tr><th>from</th><th>to</th><th>payload</th></tr></thead><tbody><tr><td>Alice</td><td>Bob</td><td>Hi!</td></tr><tr><td>Bob</td><td>Alice</td><td>Hey! What’s up?</td></tr><tr><td>…</td><td>…</td><td></td></tr><tr><td>…</td><td>…</td><td></td></tr><tr><td>…</td><td>…</td><td></td></tr></tbody></table><p>This is how most applications have been built for the last twenty years. Maybe data is encrypted at rest, but in my experience working at software companies encryption at rest means nothing, every employee still has access to this data on demand, in the worst case it’s a Jira ticket away.</p><p>Step one in our privacy preserving journey is to encrypt the data swapped between parties, Alice encrypts messages to Bob’s public key and vice-versa. Now we as the providers of this service can’t see the data being swapped:</p><table><thead><tr><th>from</th><th>to</th><th>payload</th></tr></thead><tbody><tr><td>Alice</td><td>Bob</td><td>XXXXXXXXXXXXXX</td></tr><tr><td>Bob</td><td>Alice</td><td>XXXXXXXXXXXXXX</td></tr><tr><td>…</td><td>…</td><td></td></tr><tr><td>…</td><td>…</td><td></td></tr><tr><td>…</td><td>…</td><td></td></tr></tbody></table><p>However here we can unfortunately still tell that Alice and Bob are communicating. What could we do to hide the communication between these two?</p><p>One solution I’ll propose - which also has the benefit of sender privacy, so we’re killing two birds with one stone here - would be to generate a shared secret and hash it with the recipients identifier. Now messages just have a <code>payload</code> and a <code>to</code> property. The <code>to</code></p><table><thead><tr><th>to</th><th>payload</th></tr></thead><tbody><tr><td>HASH(alice_bob_shared_secret, Bob)</td><td>XXXXXXXXXXXXXX</td></tr><tr><td>HASH(alice_bob_shared_secret, Alice)</td><td>XXXXXXXXXXXXXX</td></tr><tr><td>HASH(alice_bob_shared_secret, Bob)</td><td>XXXXXXXXXXXXXX</td></tr><tr><td>…</td><td>…</td></tr><tr><td>…</td><td>…</td></tr><tr><td>…</td><td>…</td></tr></tbody></table><p>Remember only Alice and Bob can generate this shared secret, and the HASH function is some irreversible function that hides its content. Now whenever Bob wants to find messages from Alice he computes <code>HASH(alice_bob_shared_secret, Bob)</code> and queries all messages that match that <code>to</code> field.</p><p>As you can see now we only …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://portabella.io/blog/2020-11-16-crypto-in-laymans-terms/">https://portabella.io/blog/2020-11-16-crypto-in-laymans-terms/</a></em></p>]]>
            </description>
            <link>https://portabella.io/blog/2020-11-16-crypto-in-laymans-terms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453703</guid>
            <pubDate>Thu, 17 Dec 2020 08:23:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling (organization) by bubbling the problems out]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25453685">thread link</a>) | @liveweird
<br/>
December 17, 2020 | https://no-kill-switch.ghost.io/scaling-organization-by-bubbling-the-problems-out/ | <a href="https://web.archive.org/web/*/https://no-kill-switch.ghost.io/scaling-organization-by-bubbling-the-problems-out/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-post-id="5fda593d1605500039b287da">
	

	<section>
		<p>Working in many different environments provided me a good perspective on what scaling models are applied by different companies. Today I'd like to spend a bunch of keystrokes on one of the worst scaling models I've ever encountered.</p><p>I call it:</p><blockquote>Scaling by bubbling the problems out</blockquote><p>A <em>'busy person'</em>, usually a leader or manager, identifies a persistent problem within the organization: something that consumes focus and time, impacts the quality, slows down the value delivery, etc. This problem is either completely new (caused by the growth) or has evolved over time, but now its severity is more apparent.</p><p>Here are a few examples (of such problems) to make sure we're on the same page:</p><ul><li><strong>the number of quality defects</strong> (for the whole product) is increasing; until now, each team had been able to deal with their deliverables' quality</li><li><strong>the quality of internal communication</strong> deteriorates - people start complaining they don't know what's happening in the org, there are more and more misunderstandings and misalignments</li><li>the engineering unit needs to grow, and the <strong>recruitment takes more time increasingly</strong> - hereby hemorrhaging the last reserves of time of the unit's manager</li></ul><p>Initially, such a problem is dealt with in an ad-hoc way (through a one-off, point-directed action). But it keeps popping up back (as due to its nature, it can't be eliminated permanently). Apparently, that kind of a problem requires continuous effort and ownership (to make sure it doesn't get out of control).</p><p>Finally, the <em>'busy person'</em> (mentioned above) decides that burying her/his head in the sand won't work anymore, so why not do what all the handbooks advise?</p><p>That sounds like a tremendous idea, but the devil is in details. The <em>'busy person'</em> doesn't delegate responsibility, function, or role. (S)he <strong>outsources</strong> the problem by creating a new (formal or no) position (or even a sub-unit) to deal with that problem, so all the annoyances are out of the <em>'busy person's'</em> back.</p><p>This way the problem is contained within some sort of a <strong>bubble</strong>, but it's someone else's bubble! Problem-related black box our <em>'busy person'</em> doesn't have to worry about.</p><p>Got it?</p><ul><li>Problem <strong>X</strong> -&gt; <strong>X</strong> Manager / <strong>X</strong> Team</li><li><strong>Quality </strong>problem -&gt; <strong>Quality </strong>Manager / <strong>Quality </strong>(Assurance) Team</li><li><strong>Communication </strong>problem -&gt; <strong>Communication </strong>Manager / <strong>Communication</strong> Team</li><li><strong>Recruitment </strong>problem -&gt; <strong>Recruitment </strong>Manager / <strong>Recruitment </strong>Team</li></ul><p>Oh, how convenient is that! If the problem re-appears, it's clear who's guilt...^M^M^M to be asked to fix the situation.</p><p>As the crisis is prevented now, the <em>'busy person'</em> continues with her/his quest, smug and oblivious to the consequences of the change just made ...</p><p>Yes, it seems that short-term, we're all good here. Putting someone in charge of the crisis sounds like a decent plan. But it's not really what happened here. A new position has been spawned <strong>not to solve</strong> the actual problem (which may be hidden and unobvious) <strong>but to patch</strong> its visible symptoms, potentially making the organization more complex, inter-dependent, and bureaucratic.</p><p>Instead of well-thought-through systemic change, we're adding a sub-unit (usually with the manager in charge) with the responsibility of dealing with problem X. If you had any hopes for getting rid of problem X permanently - abandon any faith in that. If problem X is the sole reason for the sub-unit's existence, it will subliminally act <strong>to preserve and solidify</strong> that problem (under control, but still).</p><p>In more simple words:</p><ol><li>no wider context</li><li>no holistic view (to understand the flow of work and value, or the nature of the problem)</li><li>no systemic approach (System's Theory)</li></ol><p>While in fact the solutions to before-mentioned problems may be much more simple and straightforward:</p><ul><li><strong>the quality issues</strong> may be a result of reaching the critical capacity of manual regression testing (with test automation as a likely answer) or pushing quality checks towards the end of process (e.g. by not doing proper reviews)</li><li><strong>internal communication</strong> could deteriorate because of the increasing number of actors - a good idea is to check the component/area boundaries to verify the number &amp; validity of dependencies; other potential root cause may be an underlying conflict or misaligned priorities of two (or more) parties</li><li><strong>extensive recruitment</strong> will be a problem if you centralize the 'gating' too much - although acquiring talent is manager's/leader's duty, (s)he should get a lot of control over it directly to the teams (who are looking for more members) - it's their skin in the game of getting the most proper people on board</li></ul><hr><p>Just to make sure I'm clear - what I'm saying here is not against the popular principle of <em>'single-threaded teams'</em> (ones dedicated end-to-end, exclusively to well-defined narrow topic). I'm all for crystal-clear focus and unequivocal responsibility range, but the area covered by such a team should be <strong>defined by product/service vision</strong>, instead of what kind of piece of garbage has been thrown over the fence to save you some time ...</p>
	</section>

	
</article></div>]]>
            </description>
            <link>https://no-kill-switch.ghost.io/scaling-organization-by-bubbling-the-problems-out/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453685</guid>
            <pubDate>Thu, 17 Dec 2020 08:19:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Static Calls in Linux 5.10]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25453663">thread link</a>) | @ingve
<br/>
December 17, 2020 | https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10 | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Dec 16, 2020</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#c">c</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#curiosity">curiosity</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#security">security</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#x86">x86</a>
    
  
  </p>


<p>I was reading the
<a href="https://kernelnewbies.org/Linux_5.10">Linux 5.10 release summary on KernelNewbies</a>, and a
section stood out to me:</p>

<blockquote>
  <p>1.6. Static calls for improved post-Spectre performance</p>

  <p>Static calls are a replacement for global function pointers. They use code patching to allow
direct calls to be used instead of indirect calls. They give the flexibility of function pointers,
but with improved performance. This is especially important for cases where retpolines would
otherwise be used, as retpolines can significantly impact performance.</p>
</blockquote>

<p>I’ve spent a lot of time looking at the Linux kernel, but never directly at its indirect call
setup or post-<a href="https://spectreattack.com/">Spectre</a> mitigations. These changes sound very cool,
so I’m going to use this post to try and explain and understand them (both to myself and others).</p>

<p><strong>Update</strong>: One of the original authors of the patchset has emailed me with some corrections
and answers to the questions that I ask below. I’ve marked each with either “Correction” or
“Update.” Thanks, Peter!</p>

<h2 id="background-indirect-calls-spectre-and-retpolines">Background: indirect calls, Spectre, and retpolines</h2>

<h3 id="indirect-calls">Indirect calls</h3>

<p>Indirect calls are one of C’s most powerful language features, and are critical for writing
higher-order code without a supplementary object or function/method dispatch system.</p>

<p>Most C programmers are familiar with the basics of indirect calls, thanks to standard and POSIX
functions like <code>qsort</code> and <code>pthread_create</code>: each takes a <em>function pointer</em>, which it then
calls internally to complete the functionality of the surrounding call:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td><pre><span>#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;stdio.h&gt;
</span>
<span>/* qsort_strcmp is just the normal stdlib strcmp, with a bit of extra parameter
 * munging to match qsort's API.
 */</span>
<span>static</span> <span>int</span> <span>qsort_strcmp</span><span>(</span><span>const</span> <span>void</span> <span>*</span><span>a</span><span>,</span> <span>const</span> <span>void</span> <span>*</span><span>b</span><span>)</span> <span>{</span>
    <span>return</span> <span>strcmp</span><span>(</span><span>*</span><span>(</span><span>const</span> <span>char</span> <span>**</span><span>)</span><span>a</span><span>,</span> <span>*</span><span>(</span><span>const</span> <span>char</span> <span>**</span><span>)</span><span>b</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>const</span> <span>char</span> <span>*</span><span>strings</span><span>[]</span> <span>=</span> <span>{</span><span>"foo"</span><span>,</span> <span>"bar"</span><span>,</span> <span>"baz"</span><span>};</span>

    <span>/* qsort is a generic sorting function:
     * you give it the a pointer to the base address of things to sort,
     * their number and individual sizes, and a *function* that can compare
     * any two members and provide an ordering between them.
     *
     * in this case, we tell qsort to sort an array of strings, using
     * `qsort_strcmp` for the ordering.
     */</span>
    <span>qsort</span><span>(</span><span>&amp;</span><span>strings</span><span>,</span> <span>3</span><span>,</span> <span>sizeof</span><span>(</span><span>char</span> <span>*</span><span>),</span> <span>qsort_strcmp</span><span>);</span>

    <span>printf</span><span>(</span><span>"%s %s %s</span><span>\n</span><span>"</span><span>,</span> <span>strings</span><span>[</span><span>0</span><span>],</span> <span>strings</span><span>[</span><span>1</span><span>],</span> <span>strings</span><span>[</span><span>2</span><span>]);</span>
    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/vbn7zW">Godbolt</a>).</em></p>

<p>In this case, the indirect call occurs within <code>qsort</code>. But we can see it directly if
we implement our own function that does an indirect call:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td><pre><span>static</span> <span>uint32_t</span> <span>good_rand</span><span>()</span> <span>{</span>
    <span>uint32_t</span> <span>x</span><span>;</span>
    <span>getrandom</span><span>(</span><span>&amp;</span><span>x</span><span>,</span> <span>sizeof</span><span>(</span><span>x</span><span>),</span> <span>GRND_NONBLOCK</span><span>);</span>
    <span>return</span> <span>x</span><span>;</span>
<span>}</span>

<span>static</span> <span>uint32_t</span> <span>bad_rand</span><span>()</span> <span>{</span>
    <span>return</span> <span>rand</span><span>();</span>
<span>}</span>

<span>/* munge takes a function pointer, rand_func, which it calls
 * as part of its returned result.
 */</span>
<span>static</span> <span>uint32_t</span> <span>munge</span><span>(</span><span>uint32_t</span> <span>(</span><span>*</span><span>rand_func</span><span>)(</span><span>void</span><span>))</span> <span>{</span>
    <span>return</span> <span>rand_func</span><span>()</span> <span>&amp;</span> <span>0xFF</span><span>;</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>uint32_t</span> <span>x</span> <span>=</span> <span>munge</span><span>(</span><span>good_rand</span><span>);</span>
    <span>uint32_t</span> <span>y</span> <span>=</span> <span>munge</span><span>(</span><span>bad_rand</span><span>);</span>

    <span>printf</span><span>(</span><span>"%ul, %ul</span><span>\n</span><span>"</span><span>,</span> <span>x</span><span>,</span> <span>y</span><span>);</span>

    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>where <code>munge</code> boils down to:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td><pre><span>munge:</span>
  <span>push</span>    <span>rbp</span>
  <span>mov</span>     <span>rbp</span><span>,</span> <span>rsp</span>
  <span>sub</span>     <span>rsp</span><span>,</span> <span>16</span>
  <span>mov</span>     <span>qword</span> <span>ptr</span> <span>[</span><span>rbp</span> <span>-</span> <span>8</span><span>],</span> <span>rdi</span>  <span>; load rand_func</span>
  <span>call</span>    <span>qword</span> <span>ptr</span> <span>[</span><span>rbp</span> <span>-</span> <span>8</span><span>]</span>       <span>; call rand_func</span>
  <span>and</span>     <span>eax</span><span>,</span> <span>255</span>
  <span>add</span>     <span>rsp</span><span>,</span> <span>16</span>
  <span>pop</span>     <span>rbp</span>
  <span>ret</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/P44Ghq">Godbolt</a>).</em></p>

<p>Observe: our <code>call</code> goes through a memory or register operand (<code>[rbp - 8]</code>)<sup id="fnref:opt" role="doc-noteref"><a href="#fn:opt">1</a></sup> to get the target,
instead of a direct target specified by the operand value itself (like, say,
<code>call 0xacabacab ; @good_rand</code>). That’s what makes it indirect.</p>

<p>But we can go even further than this! Indeed, a common pattern in C is to declare
entire <em>structures</em> of operations, using each to parametrize a lower level set of behaviors
(for example, the core POSIX I/O APIs) over independent implementations.</p>

<p>This is exactly how <a href="https://github.com/libfuse/libfuse">FUSE</a> works: every FUSE client
creates its own <a href="https://github.com/libfuse/libfuse/blob/cd4aae2de6aacad31a15791bbb52adf173561a6d/include/fuse.h#L299-L790"><code>fuse_operations</code></a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td><pre><span>struct</span> <span>fuse_operations</span> <span>{</span>
  <span>int</span> <span>(</span><span>*</span><span>getattr</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>stat</span> <span>*</span><span>,</span> <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>fi</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>readlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>mknod</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>mode_t</span><span>,</span> <span>dev_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>mkdir</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>mode_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>unlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>rmdir</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>symlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>rename</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>unsigned</span> <span>int</span> <span>flags</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>link</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>/* ... */</span>
  <span>int</span> <span>(</span><span>*</span><span>open</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>read</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>,</span> <span>off_t</span><span>,</span>
         <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>write</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>,</span> <span>off_t</span><span>,</span>
          <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>statfs</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>statvfs</span> <span>*</span><span>);</span>
  <span>/* ... */</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Unsurprisingly, this technique isn’t limited to userspace: the Linux kernel itself makes
aggressive use of indirect calls, particularly in architecture-agnostic interfaces
(like the <a href="https://www.kernel.org/doc/html/latest/filesystems/vfs.html">VFS</a> and sub-specializations
like <code>procfs</code>) and the architecture-specific internals of subsystems like
<a href="https://perf.wiki.kernel.org/index.php/Main_Page"><code>perf_events</code></a>.</p>

<p>So that’s neat. It’s so neat that CPU engineers got all
<a href="https://en.wikipedia.org/wiki/Branch_predictor#Indirect_branch_predictor">hot in the pants</a> trying
to squeeze extra performance out of them<sup id="fnref:perf" role="doc-noteref"><a href="#fn:perf">2</a></sup>, and we ended up with
<a href="https://spectreattack.com/spectre.pdf">Spectre v2</a>.</p>

<h3 id="spectre-v2">Spectre (v2)</h3>

<p><img src="https://blog.yossarian.net/assets/spectre.png" alt="The Spectre logo"></p>

<p>The exact mechanism that Spectre v2 (also known as
<a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-5715">CVE-2017-5715</a>) exploits is
<em>slightly</em> out of scope of this post, but at a high level:</p>

<ol>
  <li>
    <p>Modern (x86) CPUs contain an <em>indirect branch predictor</em>, which attempts to guess the target
of an indirect call or jump.</p>

    <p>To actually speed things up, the CPU <strong>speculatively executes</strong> the
 predicted branch:</p>

    <ul>
      <li>
        <p>A correct prediction means that the indirect call completes significantly faster
 (since it’s already executing or has finished executing speculatively);</p>
      </li>
      <li>
        <p>A misprediction <strong>should</strong> result in a slower (but still
 successful) indirect call with <strong>no side effects from the incorrect speculation.</strong></p>
      </li>
    </ul>

    <p>In other words: the CPU is responsible for <strong>rolling back</strong> any side effects associated
 with any misprediction and subsequent speculation. Mis-speculation is a <em>microarchitectural</em>
 detail that should not manifest in <em>architectural</em> changes, like modified registers.</p>
  </li>
  <li>
    <p><strong>Rolling back</strong> any mis-speculated state is a relatively expensive operation, with a lot of
microarchitectural implications: cache lines and other bits of state need to be fixed up so that
the <em>actual</em> program control flow isn’t tainted by failed speculations.</p>

    <p>In practice, rolling back the entire speculated state would undo most of the advantages
 of speculating in the first place. Instead of doing that, x86 and other ISAs will just mark
 (many) of the bits of speculated state (like cache lines) as stale.</p>
  </li>
  <li>
    <p>This fixup behavior (either reverting or marking speculated state) results in a
<a href="https://en.wikipedia.org/wiki/Side-channel_attack"><em>side-channel</em></a>: an attacker can
<em>train</em> the branch predictor to speculatively execute a bit of code
(not unlike a <a href="https://en.wikipedia.org/wiki/Return-oriented_programming">ROP gadget</a>) that modifies
a piece of microarchitectural state in a data-dependent manner, such as a cache entry
whose address is dependent on a secret value that was speculatively fetched.</p>

    <p>The attacker can then <em>probe</em> that microarchitectural state by <strong>timing</strong> access to it:
 fast accesses indicate a speculatively modified state, disclosing the secret.</p>
  </li>
</ol>

<p>The original Spectre v2 attack focused on cache lines since they’re relatively easy to time, even
from high level (and sandboxed!) languages that don’t have access to
<a href="https://c9x.me/x86/html/file_module_x86_id_30.html"><code>clflush</code></a> or other cache-line
primitives on x86. But the concept is a general one: it’s difficult to execute speculatively without
leaking <em>some</em> information, and subsequent vulnerabilities (like <a href="https://mdsattacks.com/">MDS</a> and
<a href="https://zombieloadattack.com/">ZombieLoad</a>) have exposed information leaks in other
microarchitectural features.</p>

<p>This is bad news: an attacker running one of the <strong>safest</strong> contexts (JavaScript or other managed
code, in a sandbox, in userspace) can conceivably train the indirect branch predictor to
speculatively execute a gadget in kernelspace, potentially
<a href="https://cyber.wtf/2017/07/28/negative-result-reading-kernel-memory-from-user-mode/">disclosing kernel memory</a>.</p>

<p>So, the kernel needed a new mitigation. That mitigation is <em>retpolines</em>.</p>

<h3 id="retpolines">Retpolines</h3>

<p>To mitigate Spectre v2, the kernel needs to prevent the CPU from speculating on an attacker
controlled indirect branch.</p>

<p>A retpoline (short for <em>ret</em>urn
<a href="https://en.wikipedia.org/wiki/Trampoline_(computing)"><em>trampoline</em></a>) does exactly that: indirect
jumps and calls are surrounded by a little <a href="https://en.wikipedia.org/wiki/Thunk">thunk</a> that
effectively traps the speculated execution in an infinite loop, spinning it until the misprediction
is resolved.</p>

<p>Intel’s
<a href="https://software.intel.com/security-software-guidance/api-app/sites/default/files/Retpoline-A-Branch-Target-Injection-Mitigation.pdf">Retpoline whitepaper</a>
has some helpful illustrations:</p>

<p><img src="https://blog.yossarian.net/assets/retpoline.png" alt="A visualization of speculative execution with and without a retpoline."></p>

<p>This works by converting the indirect control flow from an <em>indirect branch</em> to an
<em>indirect return</em><sup id="fnref:allreturns" role="doc-noteref"><a href="#fn:allreturns">3</a></sup>, hence the “ret” in retpoline. Returns are <em>also</em> predicted,
but with an additional mechanism given priority: the
<a href="https://blog.stuffedcow.net/2018/04/ras-microbenchmarks/">Return Stack Buffer</a><sup id="fnref:rsb" role="doc-noteref"><a href="#fn:rsb">4</a></sup>. To ensure that
the RSB can’t be maliciously trained away from the infinite loop, the retpoline begins with a
direct <code>CALL</code> that primes the RSB to always<sup id="fnref:notalways" role="doc-noteref"><a href="#fn:notalways">5</a></sup> predict the infinite loop.</p>

<p>Here’s what an indirect call retpoline <em>actually</em> looks like<sup id="fnref:ool" role="doc-noteref"><a href="#fn:ool">6</a></sup>, simplified significantly from
the <a href="https://elixir.bootlin.com/linux/v5.9.14/source/arch/x86/lib/retpoline.S">kernel</a>
<a href="https://elixir.bootlin.com/linux/v5.9.14/source/arch/x86/include/asm/nospec-branch.h">source</a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
</pre></td><td><pre><span>__x86_retpoline_rax:</span>
  <span>call</span> <span>.Ldo_rop_0</span>
<span>.Lspec_trap_0:</span>
  <span>pause</span>
  <span>lfence</span>
  <span>jmp</span> <span>.Lspec_trap_0</span>
<span>.Ldo_rop_0:</span>
  <span>mov</span> <span>[</span><span>rsp</span><span>],</span> <span>rax</span>
  <span>ret</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>…all of that to replace a simple <code>call [rax]</code>!</p>

<h3 id="consequences">Consequences</h3>

<p>There are repercussions for this kind of trickery:</p>

<ul>
  <li>
    <p>It’s slow when correctly predicted: we’ve replaced a single indirect <code>CALL</code> with at least two
direct <code>CALL</code>s, plus a <code>RET</code>.</p>
  </li>
  <li>
    <p>It’s <em>really</em> slow when mispredicted: we <em>literally</em> spin in place using <code>PAUSE</code> and <code>LFENCE</code>.</p>
  </li>
  <li>
    <p>It’s a ROP gadget, so it <em>looks</em> like an exploit primitive. That means it screws with Intel’s
<a href="https://software.intel.com/sites/default/files/managed/4d/2a/control-flow-enforcement-technology-preview.pdf">CET</a>
and similar protections on other platforms. Intel claims that newer hardware will support “enhanced
IBRS”<sup id="fnref:ibrs" role="doc-noteref"><a href="#fn:ibrs">7</a></sup> that will replace the …</p></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10">https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10</a></em></p>]]>
            </description>
            <link>https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453663</guid>
            <pubDate>Thu, 17 Dec 2020 08:13:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin price will hit $1M by the end of the decade: My prediction]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25453620">thread link</a>) | @kprimice
<br/>
December 17, 2020 | https://thenextwave.blog/bitcoin-future-price-prediction/ | <a href="https://web.archive.org/web/*/https://thenextwave.blog/bitcoin-future-price-prediction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://thenextwave.blog/bitcoin-future-price-prediction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453620</guid>
            <pubDate>Thu, 17 Dec 2020 08:03:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Deep learning tool that repairs damaged/faded photos]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25453481">thread link</a>) | @panabee
<br/>
December 16, 2020 | https://hotpot.ai/restore-picture?s=hn | <a href="https://web.archive.org/web/*/https://hotpot.ai/restore-picture?s=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="rootBody">

		


		<div id="rootYield">
			




<div id="pageBox">

	


	<div id="mainBox">

		<div id="controlBox">

			<div>
				<p><img src="https://hotpot.ai/images/site/transparent.gif">
				</p>
			</div>

			

			<p><span>Restore</span>
			</p>

		</div>

		

	</div>


	<article id="apiAccess">
		<h2>API Access</h2>

		<p>
			Add this service to your app, website, or company workflow with the <a href="https://hotpot.ai/docs/api">Hotpot API</a>.
		</p>
	</article>

	


	<article>
		<h2>Directions</h2>

		<p>
			Upload an image.
		</p>

		<p>
			Enable "Has Scratches" to explicitly remove scratches.
		</p>

		<p>
			To turn black &amp; white pictures to color, try our AI <a href="https://hotpot.ai/colorize-picture?s=restorer">Picture Colorizer</a> service.
		</p>
	</article>


	<article>
		<h2>Overview</h2>

		<p>
			This Hotpot AI service restores pictures by automatically performing scratch removal, face enhancement, and color sharpening. What used to require trained professionals hours can now be accomplished in seconds.
		</p>

		<p>
			The service can repair and restore both color and black &amp; white photographs.
		</p>

		<p>
			While this service automates photo restoration, it cannot replace experts for demanding restoration jobs. It is designed to help consumers with lightweight requirements while helping professionals save time on difficult restoration requests.
		</p>

		<p>
			For this service, pictures are not saved without user permission. For storage costs and user privacy, we only retain images for as long as necessary to run our machine learning models, and do not store photos beyond this.
		</p>

		<p>
			Note: the maximum image resolution we support is 1280x1280, but our new model supports larger images and is launching soon. Please contact us to try this newer model.
		</p>
	</article>


	<article>
	<h2>AI Tools</h2>

	<p>
		Explore other Hotpot <a href="https://hotpot.ai/tools">AI tools</a>, including ones for <a href="https://hotpot.ai/remove-background">background removal</a>, <a href="https://hotpot.ai/personalize-art">art personalization</a>, <a href="https://hotpot.ai/enlarge-picture">image upscaler</a> for photo prints, <a href="https://hotpot.ai/restore-picture">picture restoration</a>, <a href="https://hotpot.ai/colorize-picture">picture colorization</a>, and more.
	</p>
</article>


	<article>
		<h2>Research Credit</h2>

		<p>
			Our technology applies proprietary enhancements to the amazing Microsoft research project, <a href="https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life" target="_blank">Bringing Old Photos Back to Life</a>.
		</p>
	</article>


	<article>
		<h2>Contribute</h2>

		<p>
			Help improve our AI by <a href="https://hotpot.ai/contact">sharing images</a> that convert poorly.
		</p>
	</article>


</div>








<!---------------------------- Hotjar BEGIN ---------------------------->



<!---------------------------- Hotjar END ----------------------------->
		</div>

	</div></div>]]>
            </description>
            <link>https://hotpot.ai/restore-picture?s=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453481</guid>
            <pubDate>Thu, 17 Dec 2020 07:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creative Code-Generated Art]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25453252">thread link</a>) | @dzink
<br/>
December 16, 2020 | https://www.editorx.com/shaping-design/article/creative-coding | <a href="https://web.archive.org/web/*/https://www.editorx.com/shaping-design/article/creative-coding">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.7.1"><div dir="ltr"><div><p id="viewer-foo"><span><span>Have you ever experienced true novelty? Something so mind-altering that it questions your definition of what you’ve known to be true for so long. I imagine the first people to watch a film or see an airplane felt this. It’s an inexplicable energy that has the power to redefine. In many ways, artists have been at the center of challenging commonly held beliefs, and using entirely new mediums to express speculative ideas. </span></span></p><p id="viewer-fa7pc"><span><span>While never the first thing to come to mind when discussing art, creative coding is revolutionizing what art is and can be. As we enter a more digital world, creative coding may be the contemporary art movement we need in order to articulate major societal challenges we are facing as technology advances. </span></span></p><p id="viewer-gar4"><span><span>Put simply, creative coding is an emerging specialty that utilizes code and programming as a medium to create art. Programming’s versatility and ubiquitous nature makes it especially expressive, allowing it to manifest itself as digital paintings, data visualization, or even robotics. </span></span></p><p id="viewer-aesrq"><span><span>Unlike the functional focus of most uses of code - like the code lines of a navigation app - creative coding uses programming languages for a solely artistic purpose.</span></span></p><p id="viewer-bg2ev"><span><span>As artists, we generally hold a stigma regarding coding having high barriers to entry, and as engineers, we also hold a stigma surrounding the difficulties of creative expression. However, these fields no longer need to be separate entities, as they are more closely tied than people expect. </span></span></p><p id="viewer-80qt3"><span>With programming resources being incredibly open-source and <a href="https://www.editorx.com/shaping-design/article/drawing-inspiration-for-designers" target="_blank" rel="noopener"><u>creative inspiration</u></a> democratized across the internet, getting into this field is as easy as watching some coding tutorials on Youtube and making a Pinterest board. </span></p><p id="viewer-2vgh3"><span>If you haven’t already, you can <a href="https://www.editorx.com/shaping-design/article/should-designers-code" target="_blank" rel="noopener"><u>learn to code</u></a> by picking up a coding language such as HTML, CSS, and JavaScript. There are many online resources available, such as:</span></p><ul><li id="viewer-27t6d"><p><a href="https://www.w3schools.com/" target="_blank" rel="noopener"><u>W3Schools</u></a></p></li><li id="viewer-5oukm"><p><a href="https://www.youtube.com/watch?v=2qDywOS7VAc" target="_blank" rel="noopener"><u>Youtube Tutorials</u></a></p></li><li id="viewer-4rsku"><p><a href="https://www.linkedin.com/learning/" target="_blank" rel="noopener"><u>LinkedIn Learning</u></a></p></li><li id="viewer-a6fsj"><p><a href="https://www.learnpython.org/" target="_blank" rel="noopener"><u>Learnpython.org</u></a></p></li><li id="viewer-8el3i"><p><a href="https://www.codecademy.com/?g_network=g&amp;g_device=c&amp;g_adid=459321005730&amp;g_keyword=codecademy&amp;g_acctid=243-039-7011&amp;g_adtype=search&amp;g_adgroupid=70946090375&amp;g_keywordid=kwd-41065460761&amp;g_campaign=US_Brand_Core_Exact_Net+New+%28Auto+Tagging%29&amp;g_campaignid=1955172604&amp;utm_id=t_kwd-41065460761:ag_70946090375:cp_1955172604:n_g:d_c&amp;utm_term=codecademy&amp;utm_campaign=US_Brand_Core_Exact_Net%20New%20(Auto%20Tagging)&amp;utm_source=google&amp;utm_medium=paid-search&amp;utm_content=459321005730&amp;hsa_acc=2430397011&amp;hsa_cam=1955172604&amp;hsa_grp=70946090375&amp;hsa_ad=459321005730&amp;hsa_src=g&amp;hsa_tgt=kwd-41065460761&amp;hsa_kw=codecademy&amp;hsa_mt=e&amp;hsa_net=adwords&amp;hsa_ver=3&amp;gclid=CjwKCAiAzNj9BRBDEiwAPsL0d6bnyHp-tuJuJPB6ESAc8vQsGp2os6n9SvJ_fN73bAazebYH-FcctRoCuOMQAvD_BwE" target="_blank" rel="noopener"><u>The Code Academy</u></a> </p></li><li id="viewer-6638e"><p><a href="https://processing.org/" target="_blank" rel="noopener"><u>Processing</u></a></p></li></ul><p id="viewer-cbn64"><span>From there, finding inspiration can be as simple as reading the rest of this article or exploring dedicated art-technology spaces such as <a href="https://www.artechouse.com/" target="_blank" rel="noopener"><u>Artechouse</u></a>.</span></p><p id="viewer-erafq"><span>Here are some interesting fields within creative coding that you can experiment with once you get started:</span></p><ul><li id="viewer-ehb6t"><p><span><strong>Machine learning:</strong> The development of computer algorithms that automatically learn and improve their performance through experience and data.</span>


</p></li><li id="viewer-32vc4"><p><span><strong>Projection mapping:</strong> A technique to project video on irregularly shaped surfaces, such as sculptures or buildings. </span>


</p></li><li id="viewer-f009e"><p><span><strong>Generative design:</strong> An iterative design process in which a program, usually using algorithms, generates a certain number of outputs based on a set of constraints.</span>


</p></li><li id="viewer-5n77p"><p><span><strong>Live coding:</strong> A form of performance art in which coders program in real-time. It usually involves sound, image and light design.</span></p></li></ul><p id="viewer-ep6sm"><span><span>To get some ideas flowing and inspire your own creative coding pieces, here are some examples of how expansive, stunning, and novel creative coding can be.</span></span></p><ol><li id="viewer-eeo5c"><p><span>Audience by Random International</span></p></li><li id="viewer-fha9v"><p><span>New Nature Digital Petting Zoo by Marpi Studio</span></p></li><li id="viewer-a5o8e"><p><span>Everything in Existence by fuse*</span></p></li><li id="viewer-8gq1n"><p><span>Infinite Command Team by Casey Reas </span></p></li><li id="viewer-4eu7u"><p><span>Land Lines by Zach Lieberman </span></p></li><li id="viewer-3unh"><p><span>ALGOBABEZ by Shelly Knotts</span></p></li><li id="viewer-538vu"><p><span>XYZT: Abstract Landscapes by Adrien M &amp; Claire B</span></p></li><li id="viewer-b7vhn"><p><span>Tecnicontrol by Bradley G Munkowitz (GMUNK)</span></p></li><li id="viewer-bprm6"><p><span>PEmbroider created at Frank-Ratchye STUDIO for Creative Inquiry</span></p></li><li id="viewer-akhtn"><p><span>Learning to See by Memo Akten</span></p></li></ol><p id="viewer-bahbh"><span><span>Random International is a London-based experimental art studio that has been pioneering the creative coding space for well over a decade now. Their work touches on deep social themes and has been exhibited internationally in spaces like the MoMa. </span></span></p><p id="viewer-fduu8"><span><span><em>Audience</em>, one of their earlier pieces of work from 2008, uses motion tracking software and creative coding to create an almost uncomfortable, anthropomorphic experience. As a gallery visitor steps in front of rows of individually dancing mirrors, they instantly synchronize and lock onto the viewer. With 100 mirrors now looking right back at you, you then become the focal point of your own onlooking. </span></span></p><p id="viewer-8dmeo"><span><span>Created by Marpi Studio, New Nature is a digitally interactive petting zoo that relies on gesture-based technology and programming to create virtual organisms. </span></span></p><p id="viewer-65ego"><span><span>Through machine learning, Marpi has forged a virtual terrarium of creatures and plants that rely on the physical interactions of the viewers to come alive. As viewers engage with the digital creatures, the artwork responds with real-time computer-generated motions, simulating the movement of an organic creature being pet. </span></span></p><p id="viewer-60ee9"><span><span><em>Everything in Existence</em> questions our perceptions of reality. Using real-time data processing tools and algorithmic software, fuse* creates a living piece of art that constantly evolves and adapts depending on its interactions with onlookers. </span></span></p><p id="viewer-bna5m"><span><span>The artworks are constantly generating new visuals in response to the viewers, their social networks, sound and more. This solo exhibition by fuse*, which premiered in Washington DC in 2019, creates digitally interactive experiences independently of an artist. Its self-sufficient and generative nature suggests an entirely new form of artistic expression.</span></span></p><p id="viewer-274p6"><span><span>Casey Reas’ <em>Infinite Command Team</em> investigates the relationship between particles that are encoded to construct images, and the code that forges those particles. </span></span></p><p id="viewer-c3cum"><span><span>Using pixelation of different weights and sizes, the piece creates a digital mosaic of television signals that become abstract and collage-like, reminiscent of TV channel-surfing. The piece is a celebration of art and technology that showcases the potential of combining digital fragments into a holistic piece of work. </span></span></p><p id="viewer-fhi88"><span><span>One of the most exciting aspects of creative coding is that it’s so readily available. Regardless of where you go in the world, there will always be code present guiding new innovations or digital platforms. </span></span></p><p id="viewer-8344v"><span><span>Creative coder Zach Lieberman takes advantage of how constantly present code is in our lives by using Google Maps to create art. In his proj</span>ect <a href="https://lines.chromeexperiments.com/" target="_blank" rel="noopener"><em><u>Land Lines</u></em></a>, Lieberm<span>an uses machine learning, optimized algorithms, and card power to harness images from Google Maps and match them with viewers’ drawings. </span></span></p><p id="viewer-ab3mh"><span><span>Lieberman asks his viewers to draw shapes and lines on the screen, which in turn are converted into real spaces on earth that resemble the line they drew. </span></span></p><div id="viewer-6292q"><a href="https://lines.chromeexperiments.com/" target="_blank" rel="noopener"><div data-hook="imageViewer"><div role="img" aria-label="Land Lines by Zach Lieberman website screenshot"><p><img data-pin-url="https://www.editorx.com/shaping-design/article/creative-coding" data-pin-media="https://static.wixstatic.com/media/5e5a34_37a32651df7f41128188147e18c73b6c~mv2.png/v1/fit/w_1000%2Ch_715%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/5e5a34_37a32651df7f41128188147e18c73b6c~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png" alt="Land Lines by Zach Lieberman website screenshot"></p></div></div></a></div><p id="viewer-8vtqk"><span><span>Shelly Knotts takes creative coding to an entirely new plane in her live-coding pop band, ALGOBABEZ. Based in the UK, Shelly collaborates with other musicians and programmers in her pseudo-improvised live-coded music performances. Her coded music has been played to international audiences and explores themes of data, music, networks, and code.</span></span></p><p id="viewer-5b9e7"><span><span>Created by the company Adrien M &amp; Claire B, <em>XYZT</em> explores the intersection of mathematics and imaginary landscapes. </span></span></p><p id="viewer-bstnp"><span><span>Leveraging technology, programming, and lighting design, <em>XYZT</em> allows visitors to explore the four primary planes of existence: horizontal (the X axis), vertical (Y), depth (Z), and time (T). The exhibit allows for unparalleled interactivity across each of the planes, responding to visitors’ motion and creating new visuals in real time. </span></span></p><p id="viewer-3jqso"><span><span>In his creative coding work <em>Technicontrol</em>, Bradley Munkowitz, also known as GMUNK in the art community, investigates the ways in which robotics, code and screen content can result in a choreographed piece of work. </span></span></p><p id="viewer-b6arv"><span><span>Rather than using typical projection-mapped canvases, he pushed for LED-screen-wielding robots and a motion-controlled camera. The end result is a whimsical, technology-driven video piece with a truly marvelous storyline tracing the steps of a television abduction.</span></span></p><p id="viewer-178s8"><span><a href="https://github.com/CreativeInquiry/PEmbroider" target="_blank" rel="noopener"><em><u>PEmbroider</u></em></a> is a<span>n open-source computational embroidery library. The goal of the creative coding library is to empower artists and craftspeople to make generative embroidery work for free. </span></span></p><p id="viewer-2ua6k"><span><span>Usually, tools such as this would be costly, and oftentimes are inaccessible to most artists or hobbyists. By creating an open-source repository, PEmbroider allows anyone to forge new, generative embroidery work through code. </span></span></p><div id="viewer-ecl5u"><a href="https://github.com/CreativeInquiry/PEmbroider" target="_blank" rel="noopener"><div data-hook="imageViewer"><div role="img" aria-label="PEmbroider creative coding website screenshot"><p><img data-pin-url="https://www.editorx.com/shaping-design/article/creative-coding" data-pin-media="https://static.wixstatic.com/media/5e5a34_20ee1567d5a340ab973279c47312232e~mv2.png/v1/fit/w_1000%2Ch_661%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/5e5a34_20ee1567d5a340ab973279c47312232e~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png" alt="PEmbroider creative coding website screenshot"></p></div></div></a></div><p id="viewer-18rug"><span><span>Memo Akten is an artist and researcher who examines the nature of vision and perception through computational creativity and artificial intelligence. In his series of works, <em>Learning To See</em>, Akten has developed an artificial neural network to view and make sense of the world around us. </span></span></p><p id="viewer-bnqsf"><span><span>By comparing everyday objects with their interpretations through the eyes of neural networks, Memo Akten is able to digitally emulate the way we humans observe the world and make sense of objects.</span></span></p><p id="viewer-1q52f"><span><span>As he states, “it can only see through the filter of what it already knows. Just like us. Because we too, see things not as they are, but as we are.”</span></span></p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.editorx.com/shaping-design/article/creative-coding</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453252</guid>
            <pubDate>Thu, 17 Dec 2020 06:44:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell with Elm: How to Setup IHP with Elm]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25453058">thread link</a>) | @_query
<br/>
December 16, 2020 | https://driftercode.com/blog/ihp-with-elm/ | <a href="https://web.archive.org/web/*/https://driftercode.com/blog/ihp-with-elm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Get Elm with hot reloading on top of IHP, the new framework that makes Haskell a cool kid in web dev.</p><article><p><a target="_blank" rel="noreferrer noopener" href="https://elm-lang.org/">Elm</a> was my gateway drug into type-safe functional programming. It's such a good tool for making robust frontends. Writing big projects in React and TypeScript honestly bums me out because of it.</p><p>I have always wanted have to have the equivalent type-safe joy on the backend like I have with Elm.</p><p>Now I have it all, with SSR included and an amazing developer experience 😍</p><p><strong><a target="_blank" rel="noreferrer noopener" href="https://ihp.digitallyinduced.com/">IHP</a> is a new web framework that has opened a wide door for the web development community to get into Haskell.</strong> Like Rails and Laravel, it's great for quick prototyping, well documented and easy to use.</p><p>It even has the pipe operator (<code>|&gt;</code>) included making it even more similar to the Elm syntax.</p><p><strong>Disclaimer: This tutorial should work for Mac and Linux. If you develop on Windows, it might not work without some tweaks on your own</strong></p><h2>Create a new IHP Project</h2><p>If you haven't installed IHP already, make sure you do. <a target="_blank" rel="noreferrer noopener" href="https://ihp.digitallyinduced.com/Guide/installation.html">It's surprisingly easy to get going</a>.</p><p>Start a fresh IHP project for this tutorial. Luckily, it couldn't be easier as soon as IHP is properly installed.</p><code-editor language="bash"></code-editor><p>To verify the app is working, cd into the <code>ihp-with-elm</code> folder and run <code>./start</code>.</p><h2>Update .gitignore</h2><p>Let's update <code>.gitignore</code> as soon as possible to avoid pushing unwanted stuff into git.</p><code-editor language="bash"></code-editor><h2>Initialize node and elm</h2><p>In your <code>default.nix</code> file in the root folder, add <code>Node.js</code> and <code>elm</code> to <code>otherDeps</code>:</p><code-editor language="nix"></code-editor><p>To update your local environment, close the server <strong>(ctrl+c)</strong> and run</p><code-editor language="bash"></code-editor><p>Then initialize Node.js and elm at the project root.</p><code-editor language="bash"></code-editor><p>For this tutorial, we will rename the <code>src</code> folder that elm generated into <code>elm</code>.</p><code-editor language="bash"></code-editor><p>Set the source directories folder to <strong>"elm"</strong> in <code>elm.json</code>.</p><code-editor language="json"></code-editor><h2>Getting the Haskell template ready</h2><p>Let's start writing the Elm entrypoint into the Haskel template.</p><p>Go to <code>Web/View/Static/Welcome.hs</code> and replace all the html inside the HSX in <code>VelcomeView</code>:</p><code-editor language="hs"></code-editor><p>If your IHP app is not already running, run it with <code>./start</code> and see the output on <code>localhost:8000</code>.</p><p><img src="https://driftercode.com/images/archive/ihp-with-elm/elm-not-loaded.jpg" alt="Elm not running" loading="lazy"></p><p>As you see, Elm has not been loaded, because we naturally haven't written any Elm code yet. Let's close the server <strong>(ctrl+c)</strong> and do that now.</p><h2>Setting up Elm</h2><p>Install <code>node-elm-compiler</code> for compiling and <code>elm-hot</code> for hot reloading in development. <code>parcel-bundler</code> is a "zero config" JavaScript bundler.</p><code-editor language="bash"></code-editor><p>You could do it all without a bundler like Parcel. IHP discourages bundlers, and I agree that it's not always necessary.</p><p>Still, Parcel provides valuable niceties like tight production minification and good hot reloading in development, so I prefer to use Parcel when things get a bit more advanced.</p><p>Create <code>index.js</code> and <code>Main.elm</code> in the elm folder:</p><code-editor language="bash"></code-editor><p>The <code>elm/index.js</code> should look like this to initialize the Elm file.</p><code-editor language="javascript"></code-editor><p>Finally, lets' insert the code for <code>elm/Main.elm</code>!</p><code-editor language="elm"></code-editor><p>Add the <code>start</code> and <code>build</code> scripts into the <code>package.json</code>:</p><code-editor language="json"></code-editor><p>You should now be able to run <code>npm start</code> in one terminal and <code>./start</code> in another terminal.</p><p>There you should have it! Elm in Haskell with hot reloading and the Elm debugger is ready for you in the bottom right corner. Beautiful!</p><p><img src="https://driftercode.com/images/archive/ihp-with-elm/elm-loaded.jpg" alt="Elm running" loading="lazy"></p><h2>Build for production</h2><p>When pushing your IHP app to production, you need to make sure that it builds the Elm applications.</p><p>Go to the <code>Makefile</code> in the project root and append this line to the list of <code>JS_FILES</code>:</p><code-editor language="makefile"></code-editor><p>And put this at the bottom of the Makefile.</p><code-editor language="makefile"></code-editor><p>It should now be ready to ship to production for example to IHP Cloud.</p><p>For a complete overview of what has been done, see the <a target="_blank" rel="noreferrer noopener" href="https://github.com/kodeFant/ihp-with-elm/commit/485726d51b0c167e27e660d9696f0d289378314a">diff on my demo-repo</a>.</p><h2>Bonus: Run IHP and the frontend in one command</h2><p>Running two commands to start up the service can be difficult for a very lazy developer.</p><p><code>concurrently</code> is a tool that lets you spawn and kill multiple commands as one.</p><p>Install it as a developer dependency through npm:</p><code-editor language="bash"></code-editor><p>Then replace the <code>start</code> script in <code>package.json</code> and add accordingly:</p><code-editor language="json"></code-editor><p>With that you can now run both the IHP app and the JavaScript simultaneously with this single command.</p><code-editor language="bash"></code-editor><p>And quit with <strong>(ctrl+c)</strong> as always.</p><h2>Things I don't use Elm for in IHP</h2><p>IHP gives you HTML templating (HSX) with pure functions, very similar to Elm. In that regard it's partially overlapping with Elm.</p><p>It can be a blurry line for beginners, so here are my recommendations for how to set those lines.</p><ul><li>Use HSX for <strong>basic HTML</strong>, even if it requires a couple of lines of JavaScript. I would for example write a basic hamburger menu in HSX/HTML.</li><li>Use HSX for <strong>forms</strong>. Forms are pretty much always a bigger pain written in app code. If you have been living in the Single Page App world for a while, you will realize forms written in normal HTML is not that bad. IHP gives you a convenient way of writing forms with server-side validation.</li><li>Use Elm for the <strong>advanced UI stuff</strong> requiring heavy use of DOM manipulation. Elm shines in writing user interfaces with high complexity. If the lines of JavaScript are getting too many, turn to Elm!</li><li>Do you want the content to have <strong>SSR</strong> for search engine optimization? Use HSX.</li></ul><p>So unless you really want to write a full Single Page App, Elm should be used with restraint in IHP, for only specific supercharged parts of the site.</p><p><strong>Most sites are actually better off outputting just HTML and CSS.</strong></p><h2>Next up</h2><p>I want to take this application further in future posts showing you how to interact between IHP and Elm, and how use Elm within protected boundaries (requiring authentication). Stay tuned if these are topics that intrigue you 😊</p></article></div>]]>
            </description>
            <link>https://driftercode.com/blog/ihp-with-elm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453058</guid>
            <pubDate>Thu, 17 Dec 2020 06:05:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React's UseRef Deep Dive]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 43 (<a href="https://news.ycombinator.com/item?id=25452146">thread link</a>) | @giovannibenussi
<br/>
December 16, 2020 | https://www.giovannibenussi.com/blog/a-complete-guide-to-useref/?id=1 | <a href="https://web.archive.org/web/*/https://www.giovannibenussi.com/blog/a-complete-guide-to-useref/?id=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article itemscope="" itemtype="http://schema.org/Article"><header></header><p><code>useRef</code> allows you to keep a mutable value within a component, similar to <code>useState</code> or instance variables on a class, without triggering re-renders.</p><p>For example, this component stores the number of clicks for a button:</p><div data-language="jsx"><pre><code><span>function</span> <span>RefButton</span> <span>(</span><span>)</span> <span>{</span>
  <span>const</span> clicks <span>=</span> <span>useRef</span><span>(</span><span>0</span><span>)</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>(</span>clicks<span>.</span>current <span>+=</span> <span>1</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>
      Clicks: </span><span>{</span>clicks<span>.</span>current<span>}</span><span>
    </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div><p>This is how this component looks like (I added a re-render button so you can
actually test it out 😄):</p><div><h2>Interactive Example</h2><p>The example below is completely interactive, try clicking the "Clicks" button and then click on "Re-render".</p></div><p>As you can see, if you click the "Clicks" button it doesn't do anything. However, after click on "Re-render", it gets updated with the number of clicks we did previously.</p><h2>Difference with a variable</h2><p>You might wonder why not just use a simple variable as the example below:</p><div data-language="jsx"><pre><code><span>let</span> clicks <span>=</span> <span>0</span><span>;</span>

<span>function</span> <span>OutsideVariableButton</span><span>(</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>(</span>clicks <span>+=</span> <span>1</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>
      Clicks: </span><span>{</span>clicks<span>}</span><span>
    </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div><p>And here's an interactive example for it:</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>outside variable</span></p></div><p>The button works the same way that our previous example. However, the problem arises when you have multiple instances of the same component like the example below. Try clicking just one of the buttons and then click on re-render to see the result.</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>outside variable</span><span>outside variable</span><span>outside variable</span></p></div><p>As you were able to see, the clicks are not isolated. In fact, all the examples
from this article uses the same button component, so if you click the button
from the first example and then click on "re-render" on the second example, the count it is gonna be
incremented! What a bug 🐛.</p><p>On the other hand, <code>useRef</code> values are completely isolated between components:</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>ref</span><span>ref</span><span>ref</span></p></div><h2>Difference with&nbsp;useState</h2><blockquote><p>The main difference between useState and useRef, is that useState triggers a
re-render and useRef doesn't.</p></blockquote><p>In the following example I added two buttons: one that updates its count with <code>useRef</code> and the other one with <code>useState</code>. I added some labels so you can identify them easily.</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>state</span><span>ref</span></p></div><p>You'll notice that clicking on the button with <code>useRef</code> doesn't trigger a re-render and thus, the view isn't updated. On the other side, when you click on the button that uses <code>useState</code>, it will update its clicks count immediately.</p><p>To perform imperative actions on DOM nodes, React provides a way to get a
reference to them via refs. All you have to do is to assign a <code>ref</code> property to
a node with a ref object like this:</p><div data-language="jsx"><pre><code><span>function</span> <span>CustomInput</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> inputRef <span>=</span> <span>useRef</span><span>(</span><span>)</span>

  <span>return</span> <span><span><span>&lt;</span>input</span> <span>ref</span><span><span>=</span><span>{</span>inputRef<span>}</span></span> <span>/&gt;</span></span>
<span>}</span></code></pre></div><p>The way to get a DOM reference using refs works (informally 😅) as follows:</p><div><p><span>Today</span></p><div><p>React</p><p>Hey, what's up?<span>12:00</span></p></div><div><p>Could you give me a reference to this dom node?<span>12:00<svg style="color:#34B7F1" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg><svg style="color:#34B7F1;margin-left:-12px" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg></span></p></div><div><p>React</p><p>Sure, I assigned it to the 'current' property of your ref.<span>12:00</span></p></div></div><p>On the first render, <code>inputRef</code>'s value will be <code>{ current: null }</code> and in the
following renders it will have its <code>current</code> property assigned to the specified DOM
node:</p><p>However, if you only reference <code>inputRef</code> inside <code>useEffect</code> then it'll always
reference the DOM node so you don't need to worry about it being undefined.</p><p>Let's update our example to get an idea of how this works:</p><div data-language="jsx"><pre><code><span>function</span> <span>AttachingToDomExample</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> inputRef <span>=</span> <span>useRef</span><span>(</span><span>)</span>

  console<span>.</span><span>log</span><span>(</span><span>"Render inputRef value:"</span><span>,</span> inputRef<span>)</span>

  <span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> console<span>.</span><span>log</span><span>(</span><span>"useEffect inputRef value:"</span><span>,</span> inputRef<span>)</span><span>)</span>

  <span>return</span> <span><span><span>&lt;</span>input</span> <span>ref</span><span><span>=</span><span>{</span>inputRef<span>}</span></span> <span>/&gt;</span></span>
<span>}</span></code></pre></div><p>Here's the console output when rendering this component:</p><table><thead><tr><th>Render</th><th>Location</th><th>Value</th></tr></thead><tbody><tr><td>1</td><td>Render</td><td>{ current: undefined }</td></tr><tr><td></td><td>useEffect</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td>2</td><td>Render</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td></td><td>useEffect</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td>3</td><td>Render</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td></td><td>useEffect</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr></tbody></table><p>As you can see, if you access the <code>inputRef</code> inside <code>useEffect</code> then you don't
need to worry about it being <code>undefined</code> because React will assign it
automatically for you.</p><p>Let's start with a simple real-world application for refs: <code>usePrevious</code>. This
hook stores the previous value for a given state variable.
<a href="https://reactjs.org/docs/hooks-faq.html#how-to-get-the-previous-props-or-state" target="_blank" rel="nofollow">It is even referenced on React's docs</a> as a way to "get the previous props or state". Let's see it in
action first:</p><div data-language="jsx"><pre><code><span>function</span> <span>UsePreviousExample</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>clicks<span>,</span> setClicks<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>0</span><span>)</span>
  
  <span>const</span> previousClicks <span>=</span> <span>usePrevious</span><span>(</span>clicks<span>)</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>setClicks</span><span>(</span>clicks <span>+</span> <span>1</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>
        Clicks: </span><span>{</span>clicks<span>}</span><span> - Before: </span><span>{</span>previousClicks<span>}</span><span>
      </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div><p>Here's the output so you can play with it:</p><p>You can notice that the <code>previousClicks</code> variable stores the value for the previous render
for a given variable. Here's its implementation:</p><div data-language="jsx"><pre><code><span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    ref<span>.</span>current <span>=</span> value
  <span>}</span><span>)</span>
  <span>return</span> ref<span>.</span>current
<span>}</span></code></pre></div><p>Let's analyze how it works.</p><p>Let's simulate what happens on the first render. We can remove the call to
<code>useEffect</code> since it doesn't affect the return value on the first render:</p><div data-language="jsx"><pre><code>
<span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>return</span> ref<span>.</span>current
<span>}</span></code></pre></div><p>On the first render it is called with a value of <code>0</code>:</p><div data-language="jsx"><pre><code>
<span>const</span> previousClicks <span>=</span> <span>usePrevious</span><span>(</span><span>0</span><span>)</span></code></pre></div><p>In this case, <code>usePrevious</code> will return <code>undefined</code>:</p><div data-language="jsx"><pre><code>
<span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>return</span> ref<span>.</span>current 
<span>}</span></code></pre></div><p>After increase the value for count, here's how the <code>usePrevious</code> call will look:</p><div data-language="jsx"><pre><code>
<span>const</span> previousClicks <span>=</span> <span>usePrevious</span><span>(</span><span>1</span><span>)</span></code></pre></div><p>Since <code>usePrevious</code> is called again, its effect needs to run:</p><div data-language="jsx"><pre><code><span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  ref<span>.</span>current <span>=</span> <span>0</span>
<span>}</span><span>)</span></code></pre></div><p>After this, the <code>usePrevious</code> function is called again:</p><div data-language="jsx"><pre><code>
<span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>return</span> ref<span>.</span>current 
<span>}</span></code></pre></div><p>And so on. Here's the value for each render for both variables:</p><table><thead><tr><th>Render</th><th>clicks</th><th>previousClicks</th></tr></thead><tbody><tr><td>1</td><td>0</td><td>undefined</td></tr><tr><td>2</td><td>1</td><td>0</td></tr><tr><td>3</td><td>2</td><td>1</td></tr><tr><td>4</td><td>3</td><td>2</td></tr></tbody></table><p>Callback Refs are a different way to set refs. It gives you a fine-grain control
over when refs are attached and detached because you provide a function instead
of a ref variable. This function gets called every time the component mounts and
unmounts.</p><p><a href="https://codesandbox.io/s/callback-ref-example-lqe8w?file=/src/App.js" target="_blank" rel="nofollow">Here's an example</a> that shows/hides an emoji every time you click its button.
The important thing here is the <code>ref</code> prop that we added. We use a function to log
the provided ref:</p><div data-language="jsx"><pre><code><span>const</span> <span>callback</span> <span>=</span> <span>(</span><span>ref</span><span>)</span> <span>=&gt;</span> console<span>.</span><span>log</span><span>(</span><span>"callback:"</span><span>,</span> ref<span>)</span>

<span>function</span> <span>App</span> <span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>show<span>,</span> setShow<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>true</span><span>)</span><span>;</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>setShow</span><span>(</span><span>!</span>show<span>)</span><span>}</span></span><span>&gt;</span></span><span>
        </span><span>{</span>show <span>?</span> <span>"Hide"</span> <span>:</span> <span>"Show"</span><span>}</span><span>
      </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
      </span><span>{</span>show <span>&amp;&amp;</span> <span><span><span>&lt;</span>span</span> <span>ref</span><span><span>=</span><span>{</span>callback<span>}</span></span><span>&gt;</span></span><span>👋</span><span><span><span>&lt;/</span>span</span><span>&gt;</span></span><span>}</span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span>)</span><span>;</span>
<span>}</span></code></pre></div><p>Here's an interactive version of the previous code (you can check the output in
the console to see that I'm not lying 🙃):</p><p><em>Note: If you use callback refs as inline functions, it will be called
twice: one with <code>null</code> and another one with the DOM element.
This is because React needs to clear the previous ref every time the function is
created. A workaround for this is to use a class method.</em></p><div><h2>Warning</h2><p><a href="https://reactjs.org/docs/refs-and-the-dom.html#legacy-api-string-refs" target="_blank" rel="nofollow">String refs</a> are a legacy feature and they are likely to be removed in future React versions.</p></div><p>The way it works is that you provide a string as a ref value like <code>ref="exampleRef"</code> and it automatically gets assigned to <code>this.refs</code>.</p><p><em>Note: String refs can only be used with class components.</em></p><p>Here's an usage example:</p><div data-language="jsx"><pre><code><span>export</span> <span>default</span> <span>class</span> <span>App</span> <span>extends</span> <span>React<span>.</span>Component</span> <span>{</span>
  <span>render</span><span>(</span><span>)</span> <span>{</span>
    console<span>.</span><span>log</span><span>(</span><span>this</span><span>.</span>refs<span>)</span><span>;</span>

    <span>return</span> <span>(</span>
      <span><span><span>&lt;</span>div</span> <span>ref</span><span><span>=</span><span>"</span>exampleRef<span>"</span></span><span>&gt;</span></span><span>
        </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>this</span><span>.</span><span>setState</span><span>(</span><span>{</span> dummy<span>:</span> <span>0</span> <span>}</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>Re-render</span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
    <span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre></div><p>Here's the value for <code>this.refs</code> across renders:</p><table><thead><tr><th>Render</th><th>this.refs</th></tr></thead><tbody><tr><td>1</td><td><code>{}</code></td></tr><tr><td>2</td><td><code>{ exampleRef: &lt;div&gt;...&lt;/div&gt; }</code></td></tr><tr><td>3</td><td><code>{ exampleRef: &lt;div&gt;...&lt;/div&gt; }</code></td></tr><tr><td>4</td><td><code>{ exampleRef: &lt;div&gt;...&lt;/div&gt; }</code></td></tr></tbody></table><p>As you can see, on the first render <code>this.refs.exampleRef</code> will be undefined and
on the following renders it will point out to the specified DOM node.</p><p>We saw what <code>useRef</code> is, how it differentiates with a plain old variable and
state variables, and we saw real world examples that uses it. I hope that most
of the content makes sense to you!</p><p>I'd love to hear your feedback. You can <a href="https://twitter.com/giovannibenussi" target="_blank" rel="nofollow">reach out to me on
Twitter</a> at any time :-)</p><hr></article></div></div>]]>
            </description>
            <link>https://www.giovannibenussi.com/blog/a-complete-guide-to-useref/?id=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25452146</guid>
            <pubDate>Thu, 17 Dec 2020 03:36:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Passing of a Great Mind (1957)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25451727">thread link</a>) | @unclefuzzy
<br/>
December 16, 2020 | https://qualiacomputing.com/2018/06/21/john-von-neumann/ | <a href="https://web.archive.org/web/*/https://qualiacomputing.com/2018/06/21/john-von-neumann/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<h2>Passing of a Great Mind</h2>
<h3>John von Neumann, a Brilliant, Jovial Mathematician, was a Prodigious Servant of Science and his Country</h3>
<p><em>by Clary Blair Jr</em>. –&nbsp;<em>Life Magazine</em>&nbsp;(February 25th, 1957)</p>
<p>The world lost one of its greatest scientists when Professor John von Neumann, 54, died this month of cancer in Washington, D.C. His death, like his life’s work, passed almost unnoticed by the public. But scientists throughout the free world regarded it as a tragic loss. They knew that Von Neumann’s brilliant mind had not only advanced his own special field, pure mathematics, but had also helped put the West in an immeasurably stronger position in the nuclear arms race. Before he was 30 he had established himself as one of the world’s foremost mathematicians. In World War II he was the principal discoverer of the implosion method, the secret of the atomic bomb.</p>
<p>The government officials and scientists who attended the requiem mass at the Walter Reed Hospital chapel last week were there not merely in recognition of his vast contributions to science, but also to pay personal tribute to a warm and delightful personality and a selfless servant of his country.</p>
<p>For more than a year Von Neumann had known he was going to die. But until the illness was far advanced he continued to devote himself to serving the government as a member of the Atomic Energy Commission, to which he was appointed in 1954. A telephone by his bed connected directly with his EAC office. On several occasions he was taken downtown in a limousine to attend commission meetings in a wheelchair. At Walter Reed, where he was moved early last spring, an Air Force officer, Lieut. Colonel Vincent Ford, worked full time assisting him. Eight airmen, all cleared for top secret material, were assigned to help on a 24-hour basis. His work for the Air Force and other government departments continued. Cabinet members and military officials continually came for his advice, and on one occasion Secretary of Defence Charles Wilson, Air Force Secretary Donald Quarles and most of the top Air Force brass gathered in Von Neumann’s suite to consult his judgement while there was still time. So relentlessly did Von Neumann pursue his official duties that he risked neglecting the treatise which was to form the capstone of his work on the scientific specialty, computing machines, to which he had devoted many recent years.</p>
<p><img data-attachment-id="26616" data-permalink="https://qualiacomputing.com/2018/06/21/john-von-neumann/von_neumann_1_1/" data-orig-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?fit=1316%2C920&amp;ssl=1" data-orig-size="1316,920" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="von_neumann_1_1" data-image-description="" data-medium-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?fit=300%2C210&amp;ssl=1" data-large-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?fit=1000%2C699&amp;ssl=1" loading="lazy" src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?resize=1000%2C699&amp;ssl=1" alt="von_neumann_1_1" width="1000" height="699" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?resize=1000%2C699&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>His fellow scientists, however, did not need any further evidence of Von Neumann’s rank as a scientist – or his assured place in history. They knew that during World War II at Los Alamos Von Neumann’s development of the idea of implosion speeded up the making of the atomic bomb by at least a full year. His later work with electronic computers quickened U.S. development of the H-bomb by months. The chief designer of the H-bomb, Edward Teller, once said with wry humor that Von Neumann was “one of those rare mathematicians who could descend to the level of the physicist.” Many theoretical physicists admit that they learned more from Von Neumann in methods of scientific thinking than from any of their colleagues. Hans Bethe, who was director of the theoretical physics division at Los Alamos, says, “I have sometimes wondered whether a brain like Von Neumann’s does not indicate a species superior to that of man.”</p>
<p><img data-attachment-id="26617" data-permalink="https://qualiacomputing.com/2018/06/21/john-von-neumann/von_neumann_2/" data-orig-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?fit=226%2C304&amp;ssl=1" data-orig-size="226,304" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="von_neumann_2" data-image-description="" data-medium-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?fit=223%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?fit=226%2C304&amp;ssl=1" loading="lazy" src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?resize=226%2C304&amp;ssl=1" alt="von_neumann_2" width="226" height="304" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?resize=226%2C304&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>The foremost authority on computing machines in the U.S., Von Neumann was more than anyone else responsible for the increased use of the electronic “brains” in government and industry. The machine he called MANIAC (mathematical analyzer, numerical integrator and computer), which he built at the Institute for Advanced Study in Princeton, N.J., was the prototype for most of the advanced calculating machines now in use. Another machine, NORC, which he built for the Navy, can deliver a full day’s weather prediction in a few minutes. The principal adviser to the U.S. Air Force on nuclear weapons, Von Neumann was the most influential scientific force behind the U.S. decision to embark on accelerated production of intercontinental ballistic missiles. His “theory of games,” outlined in a book which he published in 1944 in collaboration with Economist Oskar Morgenstern, opened up an entirely new branch of mathematics. Analyzing the mathematical probabilities behind games of chance, Von Neumann went on to formulate a mathematical approach to such widespread fields as economics, sociology and even military strategy. His contributions to the quantum theory, the theory which explains the emission and absorption of energy in atoms and the one on which all atomic and nuclear physics are based, were set forth in a work entitled <em>Mathematical Foundations of Quantum Mechanics</em>&nbsp;which he wrote at the age of 23. It is today one of the cornerstones of this highly specialized branch of mathematical thought.</p>
<p>For Von Neumann the road to success was a many-laned highway with little traffic and no speed limit. He was born in 1903 in Budapest and was of the same generation of <a href="http://slatestarcodex.com/2017/05/26/the-atomic-bomb-considered-as-hungarian-high-school-science-fair-project/">Hungarian physicists</a> as Edward Teller, Leo Szilard and Eugene Wigner, all of whom later worked on atomic energy development for the U.S.</p>
<p>The eldest of three sons of a well-to-do Jewish financier who had been decorated by the Emperor Franz Josef, John von Neumann grew up in a society which placed a premium on intellectual achievement. At the age of 6 he was able to divide two eight-digit numbers in his head. By the age of 8 he had mastered college calculus and as a trick could memorize on sight a column in a telephone book and repeat back the names, addresses and numbers. History was only a “hobby,” but by the outbreak of World War I, when he was 10, his photographic mind had absorbed most of the contents of the 46-volume works edited by the German historian Oncken with a sophistication that startled his elders.</p>
<p>Despite his obvious technical ability, as a young man Von Neumann wanted to follow his father’s financial career, but he was soon dissuaded. Under a kind of supertutor, a first-rank mathematician at the University of Budapest named Leopold Fejer, Von Neumann was steered into the academic world. At 21 he received two degrees – one in chemical engineering at Zurich and a PhD in mathematics from the University of Budapest. The following year, 1926, as Admiral Horthy’s rightist regime had been repressing Hungarian Jews, he moved to Göttingen, Germany, then the mathematical center of the world. It was there that he published his major work on quantum mechanics.</p>
<h4>The young professor</h4>
<p>His fame now spreading, Von Neumann at 23 qualified as a <em>Privatdozent</em>&nbsp;(lecturer) at the University of Berlin, one of the youngest in the school’s history. But the Nazis had already begun their march to power. In 1929 Von Neumann accepted a visiting lectureship at Princeton University and in 1930, at the age of 26, he took a job there as professor of mathematical physics – after a quick trip to Budapest to marry a vivacious 18-year-old named Mariette Kovesi. Three years later, when the Institute for Advanced Study was founded at Princeton, Von Neumann was appointed – as was Albert Einstein – to be one of its first full professors. “He was so young,” a member of the institute recalls, “that most people who saw him in the halls mistook him for a graduate student.”</p>
<p><img data-attachment-id="26618" data-permalink="https://qualiacomputing.com/2018/06/21/john-von-neumann/von_neumann_3/" data-orig-file="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?fit=1210%2C1028&amp;ssl=1" data-orig-size="1210,1028" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="von_neumann_3" data-image-description="" data-medium-file="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?fit=300%2C255&amp;ssl=1" data-large-file="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?fit=1000%2C850&amp;ssl=1" loading="lazy" src="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?resize=1000%2C850&amp;ssl=1" alt="von_neumann_3" width="1000" height="850" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?resize=1000%2C850&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>Although they worked near each other in the same building, Einstein and Von Neumann were not intimate, and because their approach to scientific matters was different they never formally collaborated. A member of the institute who worked side by side with both men in the early days recalls, “Einstein’s mind was slow and contemplative. He would think about something for years. Johnny’s mind was just the opposite. It was lightning quick – stunningly fast. If you gave him a problem he either solved it right away or not at all. If he had to think about it a long time and it bored him, hist interest would begin to wander. And Johnny’s mind would not shine unless whatever he was working on had his undivided attention.” But the problems he did care about, such as his “theory of games,” absorbed him for much longer periods.</p>
<h4>‘Proof by erasure’</h4>
<p>Partly because of this quicksilver quality Von Neumann was not an outstanding teacher to many of his students. But for the advanced students who could ascend to his level he was inspirational. His lectures were brilliant, although at times difficult to follow because of his way of erasing and rewriting dozens of formulae on the blackboard. In explaining mathematical problems Von Neumann would write his equations hurriedly, starting at the top of the blackboard and working down. When he reached the bottom, if the problem was unfinished, he would erase the top equations and start down again. By the time he had done this two or three times most other mathematicians would find themselves unable to keep track. On one such occasion a colleague at Princeton waited until Von Neumann had finished and said, “I see. Proof by erasure.”</p>
<p>Von Neumann himself was perpetually interested in many fields unrelated to science. Several years ago his wife gave him a 21-volume Cambridge History set, and she is sure he memorized every name and fact in the books. “He is a major expert on all the royal family trees in Europe,” a friend said once. “He can tell you who fell in love with whom, and why, what obscure cousin this or that czar married, how many illegitimate children he had and so on.” One night during the Princeton days a world-famous expert on Byzantine history came to the Von Neumann house for a party. “Johnny and the professor got into a corner and began discussing some obscure facet,” recalls a friend who was there. “Then an argument arose over a date. Johnny insisted it was this, the professor that. So Johnny said, ‘Let’s get the book.’ They looked it up and Johnny was right. A few weeks later the professor was invited to the Von Neumann house again. He called Mrs. von Neumann and said jokingly, ‘I’ll come if Johnny promises not to discuss Byzantine history. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qualiacomputing.com/2018/06/21/john-von-neumann/">https://qualiacomputing.com/2018/06/21/john-von-neumann/</a></em></p>]]>
            </description>
            <link>https://qualiacomputing.com/2018/06/21/john-von-neumann/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25451727</guid>
            <pubDate>Thu, 17 Dec 2020 02:37:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Graying of Gnome]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25451433">thread link</a>) | @pabs3
<br/>
December 16, 2020 | https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/ | <a href="https://web.archive.org/web/*/https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page"><div id="content"><section id="primary"><main id="main" role="main"><article id="post-622"><div><p><a href="https://gnome.org/">The GNOME project</a> turned 23 this year, and despite equally persistent rumors to the contrary, it’s still alive and kicking.</p><p>Just how alive, though? All I know is this: Where the topic of GNOME’s health goes, accurate data rarely follows. Of course, there <em>is</em> data — lots of it in fact, in public source code repositories. Though flawed in many ways, it allows us to make comparisons to the past — and maybe predictions for the future: Are a few organizations carrying most of the workload, making them critical points of failure? Are new contributors able to pick up the slack from those who leave? Is the project graying (i.e. increasingly dominated by veterans)?</p><p>In one of my occasional fits of hubris, I set out to process this data to see if I could shake out anything meaningful. I’m usually fine with just satisfying my own curiosity and leaving it at that, but it’s one of those times where the results seem interesting enough for a blog post. So here we are.</p><p>I’m going to lead with the nice graphs and follow on with a <a href="https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/#methodology">section on methodology</a>. The latter is long, boring, and mandatory reading.</p><h2 id="contributors">Active contributors</h2><h3>By generation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-1920x900.png" alt="Active GNOME authors per year, first-year cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>The stacked histogram above shows the number of contributors who touched the project on a yearly basis. Each contributor is assigned to a generational cohort based on the year of their first contribution. The cohorts tend to shrink over time as people leave.</p><p>There’s a special “drive-by” cohort (in a fetching shade of off-white) for contributors who were only briefly involved, meaning all their activity fits in a three-month window. It’s a big group. In a typical year, it numbers 200-400 persons who were not seen before or since. Most of them contribute a single commit.</p><p>According to this, GNOME peaked at slightly above 1,400 contributors in 2010 and went into decline with the GNOME 3.0 release the following year. However, 2020 saw the most contributors in a long time, even with preliminary data — there’s still two weeks to go. Who knows if it’s an anomaly or not. It’s been an atypical year across the board.</p><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-1920x900.png" alt="Active GNOME authors per month, first-year cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>This is the same histogram, but with per-month bins. There’s a clear periodicity caused by the semiannual release cycle. The peak month was March 2011, right before the <a href="https://www.gnome.org/press/2011/04/gnome-3-0-released-better-for-users-developers-3/">GNOME 3.0 release</a>. About 450 contributors got involved that month.</p><p>The drive-by cohort is relatively smaller on a monthly basis. This makes sense, as it has little overlap from month to month, and the per-year bins tend to add them all up.</p><h3>By affiliation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-1920x900.png" alt="Active GNOME authors per year, top-15 domain cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>Above, the top 15 affiliations of active contributors. I’ve excluded personal accounts. This is pretty flawed (details below), but interesting nonetheless. For what it’s worth, it mostly lines up with my memory of things.</p><p>The pattern tracks well with the total despite only capturing a minority portion of it. I think this means that paid and unpaid contributions are driven by the same underlying trends, or that there’s a lot of the former hiding in the latter.</p><h2 id="commitcount">Commit count</h2><h3>By generation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-1920x900.png" alt="Number of GNOME commits per year, first-year cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>Here I’m counting the number of commits per year in the various cohorts.</p><p>At first glance, this looks much less dire. However, note how newcomers are having a smaller impact, especially from 2014 on. And the 2018-2020 bounce is entirely due to a handful of veterans making a comeback.</p><p>Half the commits in 2020 were made by contributors who’ve been with the project for ten years or more. Also noteworthy, drive-by commits are a vanishingly small portion of the total.</p><h3>By affiliation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-1920x900.png" alt="Number of GNOME commits per year, top-15 domain cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>Top 15 affiliations again, but now ordered by commit counts. It’s safe to say that GNOME is dependent on paid developers in a big way. Specifically, and to no one’s surprise, it leans heavily on Red Hat.</p><h2 id="observations">General observations</h2><p>A few observations can be made with confidence:</p><ul><li>By F/OSS standards, the project is not <em>un</em>healthy. It has hundreds of experienced and first-time contributors every year. It is well-organized and arguably well-funded compared to its peers. But:</li><li>Every metric has the project peaking around 2010.</li><li>A diminishing number of veterans is doing an increasing share of the work.</li><li>Although recruitment is stable, newcomers don’t seem to be hitting their stride in terms of commits.</li><li>Corporate sponsorship is probably necessary to keep the project going, but the field of sponsors has kept thinning.</li></ul><p>I think GNOME is addressing the risk factors competently by modernizing infrastructure (<a href="https://gitlab.gnome.org/">GitLab</a>, <a href="https://discourse.gnome.org/">Discourse</a>). This has obvious value even in the absence of quantifiable results, but it’ll be interesting to see if the effect can be measured over the next couple of years.</p><p>Diminished enthusiasm may also be due to there being fewer ways for a new contributor to make their mark or assume a role of responsibility. GNOME has become more conservative, certainly much more so than it was a decade ago in the run-up to GNOME 3. The rationale and phrasing in <a href="https://discourse.gnome.org/t/new-gnome-versioning-scheme/4235">the announcement of the new versioning scheme</a> (e.g. <em>“Radical technological and design changes are too disruptive for maintainers, users, and developers”</em>) seems indicative of this trend<sup>1</sup>.</p><h2 id="methodology">Notes on methodology</h2><p>So what’s wrong with this analysis? If you’re so inclined, you can find the details under the next couple of subheadings and pass harsh, harsh judgement.</p><p>I’ve set the unscientific rigor bar high enough to hopefully yield something useful, but low enough that I could do it in my spare time and not get stuck in the dreaded state commonly known as “90% done”.</p><h3>Module selection</h3><p>I aggregated data from <a href="https://github.com/hpjansson/fornalder/blob/45d4e9703dfa1fed1f9396b2cfc6f8425fae9389/projects/gnome-repos">189 Git repositories</a>. The vast majority of these are hosted on <code>gnome.org</code>, with a handful from <code>freedesktop.org</code> and <code>github.com</code>. Commits are uniquely identified by their commit hash, meaning trivial duplicates are counted only once.</p><p>GNOME has always been a decentralized, big-tent project, so it’s not obvious how to delineate it. I’ve tried to be fair by including most of the repositories from a full meta-gnome-desktop jhbuild, including fairly low-level dependencies like Cairo, Pango, and Pipewire, as well as past, present and would-be flagship applications under the GNOME umbrella. Documentation and infrastructure is represented, as are many archived projects (e.g. ORBit2, Bonobo, Sabayon, GAL).</p><p>I was a little uncertain about what to do with X.Org and Wayland. In the end I decided to include the latter, but not the former, since Wayland has close ties to GNOME (it even references GTK+ in its TODO file), while X.Org has its roots in the much older XFree86.</p><p>Mono is another project I resisted including; its development was tangential to GNOME proper, diverging completely in the most recent decade. However, I did include GtkSharp and several GNOME-hosted C# applications common on desktops in the 2005-2010 time frame.</p><p>Since I haven’t established hard criteria for module selection, it’s subject to various biases. Older code is probably underrepresented, since providers of important functionality were more loosely attached to the project early on (e.g. GNOME Online Accounts and Telepathy got pulled in, should I have included Gaim or Pidgin too? How about XChat?).</p><p>Anyway, the list isn’t terrible, but there’s room for improvement.</p><h3>Contributor identities</h3><p>Similar studies often identify contributors by their e-mail addresses. I used full author names instead, since there’s good reason to think they’re more stable over a 20-year time span. We’re fairly consistent in spelling our own names, and we change them rarely (often never). On the other hand, e-mail addresses come and go with different hosting arrangements, employers, etc.</p><p>An added challenge with this approach is that sometimes different people have the exact same name. In practice, I’m not aware of any instances of this happening in GNOME. It seems to be rare enough that I doubt it’d introduce significant error in most projects.</p><p>I should add here that the drive-by cohort depends on a fair amount of hindsight (you never know when someone might come back with more contributions, but the likelihood drops off quickly as time passes). This means the cohorts for 2020 are preliminary. They’ll be a lot more accurate with another run late next year.</p><h3>Domain names</h3><p>I’m using e-mail domain names as a proxy for organizations in some of the graphs. This is a notoriously unreliable approach for at least three reasons:</p><ol><li>Contributors often use personal e-mail addresses for paid work, leading to significant undercounting in general.</li><li>Specific companies may require their employees (or ask them nicely) to use company e-mail for collaboration. Out of the listed companies, I know of at least one that definitely did this. However, there are many that don’t, and these will be comparatively less well represented.</li><li>The mapping between DNS and organizations isn’t one-to-one. A company may operate under multiple names or TLDs (e.g. <code>.co.uk</code> and <code>.com</code>).</li></ol><p>Despite these weaknesses, it’s common to slice the data this way. It’s difficult to do better without access to semi-closed data troves, and depending on your views on privacy and ability to handle <a href="https://en.wikipedia.org/wiki/Personal_data">PII</a> safely, it might not be something you’d want to get into anyway. But I bet you’d be well-positioned for it if you were, say, the corporate owner of both LinkedIn and GitHub.</p><p>When grouping by organization, the goal is to get an idea of which outside entities are sponsoring contributions. Therefore, I’ve filtered out addresses from the biggest mass e-mail providers like <code>@gmail.com</code> and project-centric providers of personal accounts (e.g. <code>@gnome.org</code>, <code>@gtk.org</code>).</p><p>I took the liberty of reassigning the personal domains of a few extra prolific authors who would’ve otherwise showed up as individual organizations. Since there’s no way I’m doing it for everyone, this introduces some bias. The full details are in <a href="https://github.com/hpjansson/fornalder/blob/45d4e9703dfa1fed1f9396b2cfc6f8425fae9389/projects/gnome-meta.json">the project’s metadata file</a> (see: <a href="https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/#code">code</a>).</p><h3>Version control systems</h3><p>Changeovers in version control systems divide GNOME’s VCS history into three eras with noticeable discontinuities between them.</p><h4>Before 1998: Dark ages</h4><p>In the Bad Old Days, Free Software would often use plain <a href="https://en.wikipedia.org/wiki/Revision_Control_System">RCS</a> or no version control at all. I have basically no data for this era: The GIMP, being the ur-project from which …</p></div></article></main></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/">https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/</a></em></p>]]>
            </description>
            <link>https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25451433</guid>
            <pubDate>Thu, 17 Dec 2020 01:57:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine learning could be fundamentally unexplainable]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25451334">thread link</a>) | @eindiran
<br/>
December 16, 2020 | https://cerebralab.com/Machine_learning_could_be_fundamentally_unexplainable | <a href="https://web.archive.org/web/*/https://cerebralab.com/Machine_learning_could_be_fundamentally_unexplainable">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        <p>Published on: 2020-12-16</p>
        
<p>I'm going to consider a fairly unpopular idea: most efforts towards "explainable AI" are essentially pointless. Useful as an academic pursuit and topic for philosophical debate, but not much else.</p>
<p>Consider this article a generator of interesting intuitions and viewpoints, rather than an authoritative take-down of explainability techniques.</p>
<p>That disclaimer aside:</p>
<hr>
<p>What if almost every problem for which it is desirable to use machine learning is unexplainable?</p>
<p>At least unexplainable in an efficient-enough way to be worth explaining. Whether it is an algorithm or a human that is doing the explanation.</p>
<p>Let's define "<a href="https://en.wikipedia.org/wiki/Explainable_artificial_intelligence">explainable AI</a>" in a semi-narrow sense, inspired by the DARPA definition, as an inference system that can answer the questions:</p>
<blockquote>
<p>Why was that prediction made as a function of our inputs and their interactions?</p>
</blockquote>
<blockquote>
<p>Under what conditions would the outcome differ?</p>
</blockquote>
<blockquote>
<p>How confident can we be in this prediction and why is the confidence such?</p>
</blockquote>
<p>Why might we be unable to answer the above questions in a satisfactory manner for most machine learning algorithms? I think I can name four chief reasons:</p>
<ol>
<li>Some problems are just too complex to explain. Often enough, these are perfect problems for machine learning, it's exactly their intractability to our brains that makes them ideal for equation-generating algorithms to solve.</li>
<li>Some problems, while not that complex, are really boring and no human wants or should be forced to understand them.</li>
<li>Some problems can be understood, but understanding in itself is different for every single one of us, and people's culture and background often influence what "understanding" means. So explainable for one person is not explainable for another.</li>
<li>Even given an explanation that everyone agrees on, this usually puts us no closer to most of what we want to achieve with said explanation, things like gathering better data or removing "biases" from our models.</li>
</ol>
<h2>I - Unexplainable due to complexity</h2>
<p>Let's say, physicists, take in 100 PetaBytes of experimental data, reduce them using equations, and claim with a high probability that there exists this thing called a "Higgs Boson" with implications for how gravity works, among other things.</p>
<p>The resulting Boson can probably be defined within a few pages of text via things such as mass, the things it decays into, its charge, its spin, the various interactions it can have with other particles, and so on.</p>
<p>But if a luddite like myself asks the physicists:</p>
<blockquote>
<p>Why did you predict this fundamental particle exists?</p>
</blockquote>
<p>I will either get a "press conference answer" which carries no meaning other than providing a "satisfying" feeling, but it doesn't answer any of the above questions.</p>
<p>It doesn't tell me why the data shows the existence of the Higgs Boson, it doesn't tell me how the data could have been different in order for this not to be the case, and it doesn't tell me how confident they are in this inference and why.</p>
<p>If I press for an answer that roughly satisfies the explainability criteria I mentioned above, I will at best get them to say:</p>
<blockquote>
<p>Look, the standard model is a fairly advanced concept in physics, so you first have to understand that and why it came to be. Then you have to understand the experimental statistics needed to interpret the kind of data we work with here. In the process, you'll obviously learn quantum mechanics, but to understands the significance of the Higgs boson specifically it's very important that you have an amazing grasp of general relativity, since part of the reason we defined it as is and why it's so relevant is because it might be a unifying link between the two theories. Depending on how smart you are this might take 6 to 20 years to wrap your head around, really you won't even be the same person by the time you're done with this. And oh, once you get your Ph.D. and work with us for half a decade there's a chance you'll disagree with your statistics and our model and might think that we are wrong, which is fine, but in that case, you will find the explanation unsatisfactory.</p>
</blockquote>
<p>We are fine with this, since physics is bound to be complex, it earns its keep by being useful and making predictions about very specific things with very tight error margins, its fundamental to all other areas of scientific inquiry.</p>
<p>When we say that we "understand" physics what we really mean is that there are a few dozen of thousands of blokes that spent half their lives turning their brains into hyper-optimized physics-thinking machines and they assure us that they "understand" it.</p>
<p>For the rest of us, the edges of physics are a black box, I know physics works because Nvidia sells me GPUs with more VRAM each year and I'm able to watch videos of nuclear reactors glowing on youtube while patients in the nearby oncology ward are getting treated with radiation therapy.</p>
<p>This is true for many complex areas, we "understand" them because a few specialists say they do, and the knowledge that trickles down from those specialists has results that are obvious to all. Or, more realistically, because a dozen-domain long chain of specialists combined, each relying on the other, is able to produce results that are obvious to all.</p>
<p>As long as there is a group of specialist that understands the field, as long as those specialists can prove to us that their discoveries can affect the real world (thus excluding groups of well-synchronized insane people) and as long as they can teach other people to understand the field... we claim that it's "understood".</p>
<hr>
<p>But what about a credit risk analysis "AI" making a prediction that we should loan Steve at most 14,200$?</p>
<p>The model making this prediction might be operating with TBs worth of data about Steve, his browsing history, his transaction history, his music preferences, a video of him walking into the bank... each time he walked into the bank for the last 20 years, various things data aggregators tell us about him, from his preference about clothing to the likelihood he wants to buy an SUV, and of course, the actual stated purpose Steve gave us for the credit, both in text and as a video recording.</p>
<p>Not only that, but the "AI" has been trained on previous data from millions of people similar to Steve and the outcomes of the loans handed to then, thus working with petabytes of data in order to draw the 1-line conclusion of "You should loan steve, at most, 14,200$, if you want to probabilistically make a profit".</p>
<p>If we ask the AI:</p>
<blockquote>
<p>Why is the maximum loan 14,200$? How did the various inputs and their interactions contribute to coming up with this number?</p>
</blockquote>
<p>Well, the real answer is probably something like:</p>
<blockquote>
<p>Look, I can explain this to you, but 314,667,344,401 parameters had a significant role in coming up with this number, and if you want to "truly" understand that then you'd have to understand my other 696,333,744,001 parameters and the ways they related to each other in the equation. In order to do this, you have to gain an understanding of human-gate analysis as well as how its progress over time relates to life-satisfaction, credit history analysis, shopping preference analysis, error theory behind the certainty of said shopping preferences, and about 100 other mini-models that end up coalescing into the broader model that gave this prediction. And the way they "coalesce" is even more complex than any of the individual models. You can probably do this given 10 or 20 years, but basically, you'd have to re-train your brain from scratch to be like an automated risk analyst, you'd only be able to explain this to another automated risk analysts, and the "you" "understanding" my decision will be quite different from the "you" that is currently asking.</p>
</blockquote>
<p>And even the above is an optimist take assuming the "AI" is made of multiple modules that are somewhat explainable.</p>
<p>So, is the "AI" unexplainable here?</p>
<p>Well, not more so than the physicists are. Both of them can, in theory, explain the reasoning behind their choice. But in both cases, the reasoning is not simple, there's no single data point that is crucial, if even a few inputs were to change slightly the outcome might be completely different, but the input space is so fast it's impossible to reason about all significant changes to it.</p>
<p>This is just the way things are in physics and it might be just the way things are in credit risk analysis. After all, there's no fundamental rule of the universe saying it should be easy to comprehend by the human mind. The reason this is more obvious in physics is simply because physicists have been gathering loads of data for a long time. But it might be equally true in all other fields of inquiry, based on current models, it probably is. It's just that those other fields didn't have enough data nor the intelligence required to grok through it until recently.</p>
<h2>II - Some problems are boring</h2>
<p>There is a class of problems that is complex, but not as complex as to be impenetrable to the vast majority of human minds.</p>
<p>To harken back to the physics example, think classical mechanics. Given the observations made by Galileo and some training in analysis, most of us could, in principle, understand classical mechanics.</p>
<p>But this is still difficult, it requires a lot of background knowledge, although fairly common and useful background knowledge and a significant amount of times. Ranging from, say, a day to several months depending on the person.</p>
<p>This is time well spent learning classical mechanics, but what if the problem domain was something else, say:</p>
<ul>
<li>Figuring out if a blotch on a dental CT scan is more likely to indicate a streptococcus or a lactobacillus infection.</li>
<li>Understanding what makes an image used to advertise a hiking pole attractive to middle-class Slovenians over the age of 54.</li>
<li>Figuring out, using l2 data, if the spread for the price of soybean oil is too wide, and whether the bias is towards the sell or buy.</li>
<li>Finding the optimal price at which to pre-sell a new brand of luxury sparkling water based on yet uncertain …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cerebralab.com/Machine_learning_could_be_fundamentally_unexplainable">https://cerebralab.com/Machine_learning_could_be_fundamentally_unexplainable</a></em></p>]]>
            </description>
            <link>https://cerebralab.com/Machine_learning_could_be_fundamentally_unexplainable</link>
            <guid isPermaLink="false">hacker-news-small-sites-25451334</guid>
            <pubDate>Thu, 17 Dec 2020 01:47:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Kakoune – The quest for a better code editor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25450025">thread link</a>) | @psalminen
<br/>
December 16, 2020 | https://kakoune.org/why-kakoune/why-kakoune.html | <a href="https://web.archive.org/web/*/https://kakoune.org/why-kakoune/why-kakoune.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Up to now, I have used vi as an example for modal text editor, mostly because
I expect most programmers have at least heard of it. However, I don’t believe
vi and clones are the best modal text editor out there.</p>
<p>I have been working, for the last 5 years, on a new modal editor called
Kakoune. It first started as a reimplementation of Vim (the most popular vi
clone) whose source code is quite dated. But, I soon realized that we could
improve a lot on vi editing model.</p>
<div>
<h3 id="_improving_on_the_editing_model">Improving on the editing model</h3>
<p>vi basic grammar is <strong>verb</strong> followed by <strong>object</strong>; it’s nice because it matches
well with the order we use in English, "delete word". On the other hand,
it does not match well with the nature of what we express: There is only
a handful of <strong>verbs</strong> in text editing (<strong>d</strong>elete, <strong>y</strong>ank, <strong>p</strong>aste,
<strong>i</strong>nsert…​), and they don’t compose, contrarily to <strong>objects</strong> which can be
arbitrarily complex, and difficult to express. That means that errors are
not handled well. If you express your object wrongly with a delete verb,
the wrong text will get deleted, you will need to undo, and try again.</p>
<p>Kakoune’s grammar is <strong>object</strong> followed by <strong>verb</strong>, combined with instantaneous
feedback, that means you always see the current object (In Kakoune we call
that the selection) before you apply your change, which allows you to correct
errors on the go.</p>
<p>Kakoune tries hard to fix one of the big problems with the vi model: its
lack of interactivity. Because of the <strong>verb</strong> followed by <strong>object</strong> grammar,
vi changes are made in the dark, we don’t see their effect until the whole
editing <strong>sentence</strong> is finished. <code>5dw</code> will delete to next five words, if
you then realize that was one word too many, you need to undo, go back to
your initial position, and try again with <code>4dw</code>. In Kakoune, you would do
<code>5W</code>, see immediately that one more word than expected was selected, type
<code>BH</code> to remove that word from the selection, then <code>d</code> to delete.  At each
step you get visual feedback, and have the opportunity to correct it.</p>
<p>At the lower level, the problem is that vi treats moving around and selecting
an object as two different things. Kakoune unifies that, moving <strong>is</strong> selecting.
<code>w</code> does not just go to the next word, it selects from current position to
the next word. By convention, capital commands tend to expand the selection,
so <code>W</code> would expand the current selection to the next word.</p>
</div>
<div>
<h3 id="_multiple_selections">Multiple selections</h3>
<p>Another particular feature of Kakoune is its support for, and emphasis
towards the use of multiple selections. Multiple selections in Kakoune
are not just one additional feature, it is the central way of interacting
with your text. For example there is no such thing as a "global replace" in
Kakoune. What you would do is select the whole buffer with the <code>%</code> command,
then select all matches for a regex in the current selections (that is the
whole buffer here) with the <code>s</code> command, which prompts for a regex. You would
end up with one selection for each match of your regex and use the insert
mode to do your change. Globally replacing foo with bar would be done with
<code>%sfoo&lt;ret&gt;cbar&lt;esc&gt;</code> which is just the combination of basic building blocks.</p>
<div>
<p>Global replace</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/global-replace.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Multiple selections provides us with a very powerful to express structural
selection: we can subselect matches inside the current selections, keep
selections containing/not containing a match, split selections on a regex,
swap selections contents…​</p>
<p>For example, convert from <code>snake_case_style</code> to <code>camelCaseStyle</code> can be done
by selecting the word (with <code>w</code> for example) then subselecting underscores
in the word with <code>s_&lt;ret&gt;</code>, deleting these with <code>d</code>, then upper casing the
selected characters with <code>~</code>. The inverse operation could be done by selecting
the word, then subselecting the upper case characters with <code>s[A-Z]&lt;ret&gt;</code>
lower casing them with ` and then inserting an underscore before them with
<code>i_&lt;esc&gt;</code> This operation could be put in a macro, and would be reusable
easily to convert any identifier.</p>
<div>
<p>Camel case to snake case</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/camel.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Another example would be parameter swapping, if you had <code>func(arg2, arg1);</code>
you could select the contents of the parenthesis with <code>&lt;a-i&gt;(</code>, split the
selection on comma with <code>S, &lt;ret&gt;</code>, and swap selection contents with <code>&lt;a-)&gt;</code>.</p>
<div>
<p>Swapping arguments</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/args-swap.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>It is as well easy to use multiple selections for alignment, as the <code>&amp;</code>
command will align all selection cursors by inserting blanks before
selection start</p>
<div>
<p>Aligning variables</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/align.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Or to use multiple selections as a way to gather some text from different
places and regroup it in another place, thanks to a special form of pasting
<code>&lt;a-p&gt;</code> that will paste every yanked selections instead of the first one.</p>
<div>
<p>Regrouping manager objects together</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/regroup.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
</div>
<div>
<h3 id="_interactive_predictable_and_fast">Interactive, predictable and fast</h3>
<p>A design goal of Kakoune is to beat vim at its own game, while providing a
cleaner editing model. The combination of multiple selections and cleaned up
grammar shows that it’s possible to have text edition that is interactive,
predictable, and fast at the same time.</p>
<p>Interactivity comes from providing feedback on every command, made possible by
the inverted <strong>object</strong> then <strong>verb</strong> grammar. Every selection modification
has direct visual feedback; regex-based selections incrementally show what
will get selected, including when the regular expression is invalid; and even
yanking some text displays a message notifying how many selections were yanked.</p>
<p>Predictability comes from the simple effect of most commands. Each command is
conceptually simple, doing one single thing. <code>d</code> deletes whatever is selected,
nothing more. <code>%</code> selects the whole buffer. <code>s</code> prompts for a regex and
selects matches in the previous selection. It is the combination of these
building blocks that allows for complex, but predictable, actions on the text.</p>
<p>Being fast, as in requiring fewer keystrokes, is provided by carefully designing
the set of editing commands so that they interact well together, and by sometimes
sacrificing beauty for useability. For example, <code>&lt;a-s&gt;</code> is equivalent to
<code>S^&lt;ret&gt;</code>: they both split on new lines, but this is such a common use case that
it deserves to have its own key shortcut. As shown in <a href="http://github.com/mawww/golf">http://github.com/mawww/golf</a>,
Kakoune manages to beat Vim at the keystroke count game in most cases,
using much more idiomatic commands.</p>
</div>
<div>
<h3 id="_discoverability">Discoverability</h3>
<p>Keyboard oriented programs tend to be at a disadvantage compared to GUI
applications because they are less discoverable; there is no menu bar on
which to click to see the available options, no tooltip appearing when you
hover above a button explaining what it does.</p>
<p>Kakoune solves this problem through the use of two mechanisms: extensive
completion support, and auto-information display.</p>
<p>When a command is written in a prompt, Kakoune will automatically open a menu
providing you with the available completions for the current parameter. It
will know if the parameter is supposed to be a word against a fixed set
of word, the name of a buffer, a filename, etc…​ Actually, as soon as <code>:</code>
is typed, entering command prompt mode, the list of existing commands will
be displayed in the completion menu.</p>
<p>Additionally, Kakoune will display an information box, describing what the
command does, what optional switches it can take, what they do…​</p>
<div>
<p>Command discoverability</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/discoverability.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>That information box gets displayed in other cases, for example if the <code>g</code>
key is hit, which then waits for another key (<code>g</code> is the <strong>goto</strong> commands
prefix), an information box will display all the recognized keys, informing
the user that Kakoune is waiting on a keystroke, and listing the available
options.</p>
<p>To go even further in discoverability, the auto information system can
be set to display an information box after each normal mode keystroke,
explaining what the key pressed just did.</p>
</div>
<div>
<h3 id="_extensive_completion_support">Extensive completion support</h3>
<p>Keyboard oriented programs are much easier to work with when they provide
extensive completion support. For a long time, completion has been prefix
based, and that has been working very well.</p>
<p>More recently, we started to see more and more programs using the so called
fuzzy completion. Fuzzy completion tends to be subsequence based, instead
of prefix based, which means the typed query needs to be a subsequence of
a candidate to be considered matching, instead of a prefix. That will generate
more candidates (all prefix matches are also subsequence matches), so it
needs a good ranking algorithm to sort the matches and put the best ones first.</p>
<p>Kakoune embraces fuzzy matching for its completion support, which kicks in both
during insert mode, and prompt mode.</p>
<div>
<p>Word completion support</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/completion.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Insert mode completion provides completion suggestions while inserting in the
buffer, it can complete words from the buffer, or from all buffers, lines,
filenames, or get completion candidates from an external source, making it
possible to implement intelligent code completion.</p>
<div>
<p>Language specific completion support</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/cpp-completion.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Prompt completion is displayed whenever we enter command mode, and provides
completion candidates that are adapted to the command being entered, and to
the current argument being edited.</p>
</div>
<div>
<h3 id="_a_better_unix_citizen">A better unix citizen</h3>
<p>Easily making programs cooperate with each others is one of the main strength
of the Unix environment. Kakoune is designed to integrate nicely with a POSIX
system: various text editing commands give direct access to the power of POSIX
tools, like <code>|</code>, which prompts for a shell command and pipe selections through
it, replacing their contents with the command output, or <code>$</code> that prompts for
a command, and keeps selections for which the command returned success.</p>
<div>
<p>Using external commands as filters</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/filters.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>This is only the tip of the iceberg. Kakoune is very easily controllable from</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kakoune.org/why-kakoune/why-kakoune.html">https://kakoune.org/why-kakoune/why-kakoune.html</a></em></p>]]>
            </description>
            <link>https://kakoune.org/why-kakoune/why-kakoune.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25450025</guid>
            <pubDate>Wed, 16 Dec 2020 23:08:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Power of Lampshading]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25449934">thread link</a>) | @ducaale
<br/>
December 16, 2020 | https://www.swyx.io/lampshading/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/lampshading/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<blockquote>
  <p>Author's Note: The latest version of this essay is now a chapter in <a href="https://www.learninpublic.org/#learn-more">the Coding Career Handbook</a>.</p>
</blockquote>
<p>We are often told that <strong>Knowledge is Power</strong>. This is mostly true - except for at least two points in your career.</p>
<p>Have you thought about how <strong>Ignorance can be Power</strong> too? I can think of at least two stages in a career when you can wield lack of knowledge as a form of power (in the neutral, <em>ability to influence others to do what you need</em> sense, not in the petty <em>dominating over others</em> sense).</p>
<p>And we'll talk about how you can wield ignorance throughout the rest of your career too - with <strong>Lampshading</strong>!</p>
<section>
  <h2 id="when-youre-very-senior"><a href="#when-youre-very-senior">When you're very senior</a></h2>
  <p>First, when you're in <strong>senior management</strong>, typically at least a couple layers removed from individual contributors. Beyond a certain level you are not being paid to have the right answers - that's what your reports are for. It's your job to ask the right <em>questions</em>, and to enable your team to figure out how to get the answers.</p>
  <p>In my career so far I've often noticed that it is <em>senior management</em>, not middle or junior people, that are most likely to say "Whoa, whoa, whoa. I don't understand what's going on here. <a href="https://www.dictionary.com/e/slang/eli5/">Can you explain like I'm five?</a>" Done right, it can expose weak reasoning and bust bullshit, particularly when framed with the (mostly correct) belief that <a href="https://www.passiton.com/inspirational-quotes/3363-if-you-cant-explain-it-simply-you-dont">"If you can't explain it simply, you don't understand it well enough."</a>.</p>
  <p>Note I'm not absolving incompetent management of the need to know domain knowledge necessary to be an effective leader. I'm simply observing that at senior levels you are <em>not</em> expected to know everything, and that's an interesting violation of "Knowledge is Power" you have probably experienced.</p>
</section>
<section>
  <h2 id="when-youre-new"><a href="#when-youre-new">When you're new</a></h2>
  <p>Second, <strong>when you're new</strong>, typically entry level in a career or a new joiner to a community or company. At this level, again, nobody expects you to know <em>anything</em>. Sure, you needed to know <em>enough</em> to fool someone into hiring you. But so long as you never lied or lied-by-omission, nobody is going to turn around and fire you for having holes in your knowledge.</p>
  <p>Of course, there are cases where this doesn't apply. Junior talent are the most expendable, and some companies don't have a healthy attitude to mentorship and hiring. But in general, I find the tech industry a lot better for mentoring than, say, finance. Tech companies generally place explicit responsibility on seniors/team leads to mentor juniors, especially as part of their career progression goals.</p>
  <p>You might imagine, having restarted my career 2-4 times depending how you count it, that I have a good deal of personal experience with being a total newbie.</p>
</section>
<section>
  <h2 id="storytime"><a href="#storytime">Storytime!</a></h2>
  <p>Here I can tell you about my first day on my new dev job, fresh out of bootcamp.</p>
  <p>My team all joined on the same day - 3 new hires (me and 2 more experienced devs). My new boss, a confident senior dev who had had a long tenure with the firm, was walking us through our tech stack. All of a sudden he paused, and said, "oh by the way, we're going to use TypeScript. You all know TypeScript, right?". Coworker 1 nodded, Coworker 2 nodded. There was that unspoken sense of <em>duh, we're all professionals here, of course we use TypeScript</em>.</p>
  <p>And then all eyes were on me.</p>
  <p>I don't do well with peer pressure. In Gretchen Rubin's <a href="https://gretchenrubin.com/2015/01/ta-da-the-launch-of-my-quiz-on-the-four-tendencies-learn-about-yourself/">4 Tendencies</a> model, I'm an Obliger - I like to please people and put my own concerns aside. Of course my bootcamp hadn't taught TypeScript, we'd only had 3 months to learn fullstack JS! And of course I wanted to say yes!</p>
  <p>I had a probably visible moment of panic, before going with "no I don't know TypeScript." My boss simply nodded, saying, "you can learn on the job", and moved on.</p>
  <p>I think in my first few months I probably had a dozen little tests like that. Did I know how to do professional code reviews? (No) Did I know how to do BEM naming? (No, and I proudly still don't) Did I know what Clean Code was? (eh.. nope).</p>
  <p>Every time I confessed ignorance, they gave me what I needed to learn, and I caught up. If I made a mistake, they taught me what I did wrong. What were they gonna do, fire me? They knew what they were doing when they hired me out of bootcamp.</p>
</section>
<section>
  <h2 id="lampshading"><a href="#lampshading">Lampshading</a></h2>
  <p>So we see that confessing ignorance works at both the senior and junior stages of careers. But it also works in isolated situations as well, for example when you caveat what you don't know while <a href="https://www.swyx.io/writing/learn-in-public">learning in public</a>.</p>
  <p>Given my casual interest in creative writing, I often compare this technique with <a href="https://tvtropes.org/pmwiki/pmwiki.php/Main/LampshadeHanging">Lampshading</a>. To quote from TV Tropes:</p>
  <blockquote>
    <p>Lampshade Hanging (or, more informally, <strong>Lampshading</strong>) is the writers' trick of dealing with any element of the story that threatens the audience's Willing Suspension of Disbelief, whether a very implausible plot development, or a particularly blatant use of a trope, <strong>by calling attention to it and simply moving on</strong>.</p>
  </blockquote>
  <p>Applied to real life: You call out your own weakness, so that others can't.</p>
  <p>In fact, by most functional team dynamics, others are then obliged to help you fix your weakness. This is <a href="https://en.wikipedia.org/wiki/Soft_power">soft power</a>.</p>
  <p>Many Americans (of a certain age) immediately sympathize with this by linking it to <a href="https://www.youtube.com/watch?v=sHE0wmgljco">the final battle in 8 Mile</a>. In it, Eminem kicks off by naming every single weakness of his that his opponent Papa Doc was going to, literally stealing all the words from Papa Doc's mouth and turning himself into a sympathetic character. <strong>Weakness is strength</strong> here purely because of lampshading.</p>
</section>
<section>
  <h2 id="the-stupid-question-safe-harbor"><a href="#the-stupid-question-safe-harbor">The Stupid Question Safe Harbor</a></h2>
  <p>In real life, I often lampshade by invoking the "Stupid Question Safe Harbor" (SQSH).</p>
  <p>A "<a href="https://en.wikipedia.org/wiki/Safe_harbor_(law)">Safe Harbor</a>" is a legal idea that explicitly okays some behavior that may be in a grey zone due to unclear rules. So I use it as an analogy for how we act when someone says "I have a Stupid Question".</p>
  <p>When we invoke the "Stupid Question Safe Harbor", we are acknowledging the question is potentially stupid, AND that we all know that there's not really such a thing as a stupid question, but we'll just get it out of the way to ask something really basic - because getting mutual understanding is more important than saving face.</p>
  <p>The trick here is you actually are saving face - now you've invoked the SQSH, people understand you’re roleplaying, you're explicitly invoking a well understood mode of conversation, and you're not <em>ACTUALLY</em> that stupid. Right? Right?? <em>nervous laughter</em></p>
  <p>When you are in a group scenario, the SQSH has positive externalities. There may be multiple people wondering the same thing, but only one person has to "take the hit" of asking the "stupid question", and yet all benefit. I like performing this role of <a href="https://twitter.com/swyx/status/1096645037788618752">Stupid Questions as a Service</a>.</p>
</section>
<section>
  <h2 id="advanced-lampshading"><a href="#advanced-lampshading">Advanced Lampshading</a></h2>
  <p>Once you learn to look out for <strong>Lampshading</strong>, you may see powerful users of it out there in the wild who use it to Learn in Public:</p>
  <ul>
    <li>Kyle Simpson famously was told "You Don't Know JS" in an interview, and turned that into his <a href="https://github.com/getify/You-Dont-Know-JS">primary claim to fame</a>, controversial title and all.</li>
    <li>I eventually took my own TypeScript learnings, explicitly lampshaded that I was learning, and put them online and that became the <a href="https://github.com/typescript-cheatsheets/react-typescript-cheatsheet/">React TypeScript Cheatsheets</a></li>
    <li>I <em>frequently</em> lampshade my mistakes during my talks. Clicker not working? Call attention to it. Joke didn't land? Call myself out. Self aware, self deprecating humor is always appreciated by the audience, and fills dead air. But you can also use it to set up <a href="https://www.goodreads.com/quotes/91029-every-great-magic-trick-consists-of-three-parts-or-acts">a Pledge, in advance of a Turn and the final Prestige</a>, which is <a href="https://www.youtube.com/watch?v=KJP1E-Y-xyo">exactly how I set up my own livecoding talks</a>.</li>
    <li><a href="https://twitter.com/Nicolemens/status/1229610008167383040?s=20">This woman lampshading to ward off all trolls</a></li>
    <li><em>who else lampshades very well? let me know</em></li>
  </ul>
  <blockquote>
    <p>Dec 2020 Edit: <a href="https://css-tricks.com/the-power-of-lampshading/">Chris Coyier chimes in</a> with some very kind commentary of his own.</p>
  </blockquote>
</section>
</div></div>]]>
            </description>
            <link>https://www.swyx.io/lampshading/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25449934</guid>
            <pubDate>Wed, 16 Dec 2020 22:57:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New by AngelList: Recurring Transfers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25449913">thread link</a>) | @siddg
<br/>
December 16, 2020 | https://angellist.com/blog/recurring-transfers | <a href="https://web.archive.org/web/*/https://angellist.com/blog/recurring-transfers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article><figure id="w-node-062ee8588b39-d1412f6c"><p><img src="https://assets-global.website-files.com/5f3e7f710351ee0491efb21b/5fd8e8a511c36679f08ad7a7_Article%20Image.png" loading="lazy" alt=""></p></figure><p>The lifeblood of any great technology company is their talent. Unfortunately, when it comes to competing for talent, private companies have always been at a disadvantage to public companies. Let’s imagine a scenario where an employee has two competing offers where the cash offer is the same.</p><ul role="list"><li><strong>Private Company:</strong> $100K worth of stock, 100% YoY Growth</li><li><strong>Public Company:</strong> $100K worth of stock, 35%YoY Growth</li></ul><p>On paper, the private company offer looks better. The company is doubling every year so the stock will grow much faster. In practice, however, people discount the stock because it’s illiquid. That puts the private company at a significant disadvantage.&nbsp;</p><p>We think there’s a better way. <a href="http://www.angellist.com/recurring-transfers">Recurring Transfers</a> enables private companies to offer recurring liquidity as a way to attract and retain great talent. We built the product to provide maximum control on who gets to sell how much and when. </p><ul role="list"><li><strong>Control the process while reducing overhead:</strong> set parameters for incoming LPs, percentages individuals can sell, and more, while AngelList manages the entire process end-to-end on a recurring basis</li><li><strong>Streamline the cap table, future voting, and signatures:</strong> the buying entity will vote with the majority of non-conflicted holders of the same class and only a single signature is needed from AngelList for all buyers</li><li><strong>Protect private information:</strong> information rights are held by the single block and not provided to the underlying investors</li><li><strong>Offer recurring liquidity</strong> as a benefit to employees to differentiate compensation offerings from competitors&nbsp;&nbsp;&nbsp;</li></ul><p><a href="http://www.pipe.com/">Pipe.com</a> uses Recurring Transfers to make sure their employees can get liquidity on a recurring annual basis - something private companies historically haven't actively promoted. </p><p><strong>Harry Hurst, co-founder and co-CEO said, </strong></p><blockquote>“At Pipe, we believe that our entire team should have the same access to liquidity usually only afforded to founders. Everyone at the company may go through life-changing events such as buying a house or starting a family, we want to make sure that our team can get access to liquidity along the way to provide the financial cushion they need and deserve. AngelList's reputation for being startup-friendly gave us the confidence to choose them as our trusted partner.” </blockquote><p>Furthermore, companies can attract investors and talent by offering liquidity as part of a compensation package, reducing pressure for early investors and employees. </p><p>Earlier this year, <a href="https://angellist.com/blog/introducing-transfers-the-company-friendly-liquidity-solution?_ga=2.224275995.1222680455.1608045226-1365692428.1604910835">we introduced Transfers</a>, which enabled companies to take control of their liquidity options, while reducing operations, time, and expenses. With Recurring Transfers, we've further streamlined the process allowing for end-to-end liquidity management on a recurring basis. This added flexibility permits companies to offer shareholders liquidity on a recurring basis without having to incur extra overhead.</p><p><a href="http://www.angellist.com/recurring-transfers">Recurring Transfers</a> allows companies to manage their liquidity without having to manage the process periodically. Interested companies that have a <strong>$100M+ valuation and notable VC investors</strong> should <a href="https://go.pardot.com/l/853403/2020-12-11/77jr6">contact us</a> to learn more.</p></article><div><p>Disclosures</p><p>This blog post and the information contained herein is provided for informational and discussion purposes only and is not intended to be a recommendation for any investment or other advice of any kind, and shall not constitute or imply any offer to purchase, sell or hold any security or to enter into or engage in any type of transaction. Any such offers will only be made pursuant to formal offering materials containing full details regarding risks, minimum investment, fees, and expenses of such transaction. The terms of any particular fund, including size, costs, and other characteristics, are set forth in the applicable constituent documents for such fund and may differ materially from those presented in this presentation. Quotes included in these materials related to AngelList's services and should not be construed in any way as an endorsement of AngelList's advice, analysis, or other service rendered to its clients. Illustrative examples are chosen on basis of their notability and the total amount invested on the AngelList platform. </p></div><div><p>Published: </p><p>December 16, 2020</p></div></div></div><div id="post_list"><div role="list"><div role="listitem"><p><a href="https://angellist.com/blog/disrupting-wall-street-with-a-rolling-fund-an-interview-with-alexander-pack">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/recurring-transfers" aria-current="page">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/gp-correlation">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/q3-2020-saw-a-rebound-in-early-stage-venture-activity">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/angellist-confidential-2020-highlights">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/introducing-transfers-the-company-friendly-liquidity-solution">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/super-angel-gp-launches-rolling-fund-with-global-lp-base">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/what-were-seeing-in-early-stage-vc-so-far-in-2020">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/apply-to-spearhead-2-for-a-fund-up-to-1m">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/congratulations-ubercab">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/q-a-with-angellist-co-founder-naval-ravikant">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/should-seed-investors-follow-on">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/for-seed-funding-safes-have-won-against-convertible-notes">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/what-angellist-data-says-about-power-law-returns-in-venture-capital">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/what-happens-after-you-make-a-seed-investment">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/how-portfolio-size-affects-early-stage-venture-returns">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/past-founders-and-funders-make-for-good-seed-investments">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/angellist-no-longer-charges-carry-on-your-own-lps">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/rolling-venture-fund-launch">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/venture-returns">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/world-positive-investing-1">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/the-state-of-women-in-venture-part-3">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/angellist-access-fund">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/the-w-fund-using-rolling-funds-to-close-the-48-gap">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/the-state-of-women-in-venture-part-2">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/easier-than-expected-gumroad-ceo-on-launching-his-first">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/the-state-of-women-in-venture-part-1">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/from-jakarta-to-silicon-valley-lp-uses-angellist-to-launch-syndicate-angellist-opened-the-world-to-me">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/opportunistic-investing-an-interview-with-sriram-krishnan">Text Link</a></p><p>This is some …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://angellist.com/blog/recurring-transfers">https://angellist.com/blog/recurring-transfers</a></em></p>]]>
            </description>
            <link>https://angellist.com/blog/recurring-transfers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25449913</guid>
            <pubDate>Wed, 16 Dec 2020 22:55:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TikTok Engagement Calculator and Earnings Estimator]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25449426">thread link</a>) | @youriykaplan
<br/>
December 16, 2020 | https://admass.io/tiktok-engagement-calculator | <a href="https://web.archive.org/web/*/https://admass.io/tiktok-engagement-calculator">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
              <p>In 2020 PepsiCo-owned Doritos utilized TikTok and YouTube influencers for their ad camapign.</p>
              <p>One of their TikTok ads was a 60 second video of a comedic dance battle where Sam Elliott battled Lil
                Nas X over Cool Ranch tortilla chips while featuring his “Old Town Road” song.</p>
              <p>Doritos later expanded the ad campagin even further by encouraging viewers to show if their moves using the
                hashtag #CoolRanchDance in a dedicated TikTok challenge.</p>
              <p>Results?</p>
              <p>The video went viral on Doritos’ YouTube page, reaching over 16 million views.</p>
              <p>Almost 3,000 users have created dance videos using their hashtag on TikTok.</p>
            </div>
          </div>
        </div></div>]]>
            </description>
            <link>https://admass.io/tiktok-engagement-calculator</link>
            <guid isPermaLink="false">hacker-news-small-sites-25449426</guid>
            <pubDate>Wed, 16 Dec 2020 22:05:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If everyone else on Earth disappeared, how would you spend your time?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25449176">thread link</a>) | @mcrittenden
<br/>
December 16, 2020 | https://critter.blog/2020/12/16/if-everyone-else-on-earth-disappeared-how-would-you-spend-your-time/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/12/16/if-everyone-else-on-earth-disappeared-how-would-you-spend-your-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-4393">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>I found this thought exercise in the book <a href="https://smile.amazon.com/Happy-More-Less-Everything-Absolutely-ebook/dp/B01HE7TG7Y?sa-no-redirect=1">Happy</a> by Derren Brown.</p>



<p>Imagine <a href="https://critter.blog/2020/10/07/how-easily-our-lives-could-have-gone-differently/">suddenly everyone disappears</a>, but all of the world’s infrastructure and food supply magically continues to work. So you are the only person on Earth and you don’t have to worry about finding food/water/shelter. <a href="https://critter.blog/2020/10/21/non-fluffy-brainstorming-questions-for-long-term-career-planning/">What would you do all day</a>? </p>



<p>It’s a forcing function to make us realize how much of our behavior is driven by status seeking. It might be fun to drive a Ferrari and live in a mansion with no one around to stop you. You could sleep in the Oval Office! But without anyone else to see it, what’s the point? Once the novelty wore off, what would be left?</p>



<p>Would I still <a href="https://critter.blog/2020/09/09/running-advice-i-wish-id-gotten/">exercise</a> or eat well if I didn’t have anyone to look good for? Would I still want a nice house, or would I end up somewhere tiny and easy to clean? Would I even care about cleaning if nobody was around to think I’m a slob? Would I have <a href="https://critter.blog/2019/07/01/learning-to-crochet-as-a-32-year-old-man/">hobbies</a> with no one to try to impress or even talk to about them? Would I travel to beautiful places if I had no one to share them with? Would I bother taking pictures of those places if no one else could see them?</p>



<p>What could I <a href="https://critter.blog/2020/09/10/what-the-heck-do-i-even-want/">possibly care about</a>? I honestly have no idea. Does that mean everything I do is status seeking? Or just that without community, <a href="https://critter.blog/2020/11/04/what-we-have-left/">the human condition</a> does not exist? </p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/12/16/if-everyone-else-on-earth-disappeared-how-would-you-spend-your-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25449176</guid>
            <pubDate>Wed, 16 Dec 2020 21:43:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C/C++ Compiler Cheatsheet]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25448573">thread link</a>) | @dmulholl
<br/>
December 16, 2020 | http://www.dmulholl.com/notes/c-compiler-cheatsheet.html | <a href="https://web.archive.org/web/*/http://www.dmulholl.com/notes/c-compiler-cheatsheet.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-body">
            <ul>
<li>
<a href="#preprocessing">Preprocessing</a>
</li>
<li>
<a href="#compiling">Compiling</a>
</li>
<li>
<a href="#assembling">Assembling</a>
</li>
<li>
<a href="#linking">Linking</a>
</li>
<li>
<a href="#multiple-files">Multiple Files</a>
</li>
<li>
<a href="#warnings-standards">Warnings &amp; Standards</a>
</li>
<li>
<a href="#compiling-static-libraries">Compiling Static Libraries</a>
</li>
<li>
<a href="#compiling-dynamic-libraries">Compiling Dynamic Libraries</a>
</li>
</ul>
<hr>
<p>
There are four distinct steps involved in transforming a C or C++ source file into an executable binary: <i>preprocessing</i>, <i>compiling</i>, <i>assembling</i>, and <i>linking</i>.
</p>
<p>
In theory each step is the responsibility of a dedicated tool: the preprocessor <code>cpp</code>, the compiler <code>cc</code>, the assembler <code>as</code>, and the linker <code>ld</code>. In practice the compiler will happily orchestrate all four steps for us and we can build a simple C or C++ program using a single command:
</p>
<pre>$ cc source.c
</pre>
<p>
By default the resulting executable will be given the rather unappealing name of <code>a.out</code> — short for <i>assembler output</i> — but we can fix this by specifying a custom output name:
</p>
<pre>$ cc -o name source.c
</pre>
<p>
We'll look briefly below at each step of the compilation process and summarize some of the most useful options available.
</p>
<p>
The interface we'll describe was developed originally for <a href="https://en.wikipedia.org/wiki/GNU_Compiler_Collection">GCC</a>  — the GNU C Compiler —  and its supporting toolchain. This interface was later mimicked by <a href="https://en.wikipedia.org/wiki/Clang">Clang</a>, which aimed to be a drop-in replacement for GCC, and so now applies to both. It's a little crufty and inconsistent but the desire for backwards compatibility means we're stuck with it for the foreseeable future.
</p>
<p>
(To avoid repeating the awkward "C or C++" all the time we'll assume below that we're compiling a C program, but the steps and options are identical for both. Just substitute a <code>.cpp</code> extension in place of <code>.c</code> for C++ source files.)
</p>
<h3 id="preprocessing">
Preprocessing
</h3>
<p>
The C preprocessor <code>cpp</code> is responsible for executing <code>#</code> directives and expanding macros. It takes a <code>.c</code> source file as input and outputs an expanded source file, still written in C.
</p>
<p>
Preprocessed files typically aren't retained, but when they are the convention is to give them a <code>.i</code> extension. (I have no idea why.)
</p>
<p>
We can use the compiler's <code>-E</code> flag to view the preprocessed source. Output is printed to standard out by default unless we also use the <code>-o</code> flag to specify an output filename.
</p>
<pre>$ cc -E source.c
</pre>
<p>
The following preprocessor options are available (and can be passed directly to the compiler):
</p>
<table>
<tbody>
<tr>
<td>
<code>-C</code>
</td>
<td>
Retain source comments in the output.
</td>
</tr>
<tr>
<td>
<code>-D&lt;name&gt;=&lt;value&gt;</code>
</td>
<td>
Define the named symbol before preprocessing. If no value is specified the symbol will have a default value of 1.
</td>
</tr>
<tr>
<td>
<code>-I&lt;directory&gt;</code>
</td>
<td>
Add the specified directory to the search path for <code>#include</code> files.
</td>
</tr>
<tr>
<td>
<code>-P</code>
</td>
<td>
Omit debugging information from the output.
</td>
</tr>
<tr>
<td>
<code>-U&lt;name&gt;</code>
</td>
<td>
Undefine the named symbol before preprocessing.
</td>
</tr>
</tbody>
</table>
<h3 id="compiling">
Compiling
</h3>
<p>
The compiler <code>cc</code> translates a source file written in C into <a href="https://en.wikipedia.org/wiki/Assembly_language">assembly language</a>.
</p>
<p>
Assembly language is a human-readable representation of the binary machine code that actually runs on the computer's hardware; as such it's specific to the CPU architecture of the target system.
</p>
<p>
Assembly language files typically aren't retained but we can view them using the compiler's <code>-S</code> flag which halts the compilation process after they've been generated.
</p>
<pre>$ cc -S source.c
</pre>
<p>
This will generate a <code>.s</code> assembly file for each input file provided.
</p>
<h3 id="assembling">
Assembling
</h3>
<p>
The assembler <code>as</code> translates source files written in assembly language into executable binary code. It outputs a single <code>.o</code> object file for each input file provided.
</p>
<p>
The compiler defaults to automatically deleting these object files but we can retain them using the <code>-c</code> flag.
</p>
<pre>$ cc -c source.c
</pre>
<p>
This instructs the compiler to compile and assemble the object files but stop before linking them into an executable.
</p>
<h3 id="linking">
Linking
</h3>
<p>
Linking is the final stage of the compilation process. The linker <code>ld</code> combines multiple object files into a single executable file. It also links in code from the standard library and any other external libraries referenced by the files.
</p>
<p>
The C standard library is linked in automatically. To link in a static library <code>libfoo.a</code> located on the default library search path we use the <code>-l</code> flag:
</p>
<pre>$ cc source.c -lfoo
</pre>
<p>
Note that the standard <code>lib</code> prefix and <code>.a</code> (<i>archive</i>) extension are omitted. To link to a library that isn't on the default search path we have two options:
</p>
<ol>
<li>
<p>
We can specify the library's full filepath as if it were a source or object file:
</p>
</li>
</ol>
<pre>$ cc source.c /path/to/lib/libfoo.a
</pre>
<ol start="2">
<li>
<p>
We can add the containing directory to the search path using the <code>-L</code> flag:
</p>
</li>
</ol>
<pre>$ cc source.c -L/path/to/lib -lfoo
</pre>
<p>
Note that libraries must be specified <i>after</i> the source or object files that reference them.
</p>
<h3 id="multiple-files">
Multiple Files
</h3>
<p>
The compiler will happily accept multiple input files in varying stages of compilation:
</p>
<pre>$ cc src.c asm.s obj.o
</pre>
<p>
In this case <code>src.c</code> will be compiled and assembled, <code>asm.s</code> will be assembled, and the two resulting object files will be linked with <code>obj.o</code> into an executable.
</p>
<h3 id="warnings-standards">
Warnings &amp; Standards
</h3>
<p>
Turn on compiler warnings with the following flags:
</p>
<pre>-Wall -Wextra --std=c99 --pedantic
</pre>
<p>
The <code>-Wall</code> and <code>-Wextra</code> flags turn on most of the compiler's available warnings. The <code>--std=c99</code> flag instructs the compiler to use the C99 standard (available options include <code>c90</code> and <code>c11</code>). The final <code>--pedantic</code> flag turns on a number of additional warnings specific to the particular standard chosen.
</p>
<p>
Warnings can be turned off individually, e.g.
</p>
<pre>-Wno-unused-parameter
</pre>
<p>
will tell the compiler to stop bugging us about unused parameters.
</p>
<h3 id="compiling-static-libraries">
Compiling Static Libraries
</h3>
<p>
A static library is simply a collection or <i>archive</i> of object files. Static libraries are created using the <code>ar</code> (<i>archiver</i>) tool and by convention are given a <code>lib</code> prefix and <code>.a</code> extension.
</p>
<pre>$ ar -rv libfoo.a one.o two.o three.o
</pre>
<p>
Static libraries are built into the executable at compiletime — they do not have to be present on the system at runtime.
</p>
<h3 id="compiling-dynamic-libraries">
Compiling Dynamic Libraries
</h3>
<p>
A dynamic or <i>shared object</i> library is a special collection of object files that can be loaded by a program at runtime. Dynamic libraries are created using the compiler's <code>--shared</code> flag and by convention are given a <code>lib</code> prefix and <code>.so</code> extension.
</p>
<pre>$ cc --shared -o libfoo.so one.o two.o three.o
</pre>
<p>
Dynamic libraries can be used in two ways:
</p>
<ul>
<li>
<p>
An executable can be linked against a dynamic library at compiletime. Multiple executables can then share a single library instance, which must be available on the system at runtime.
</p>
</li>
<li>
<p>
An executable can dynamically load and unload library files at runtime using the system's dynamic linking functions. Libraries used in this way can form the basis of a plugin system for an application.
</p>
</li>
</ul>
        </div></div>]]>
            </description>
            <link>http://www.dmulholl.com/notes/c-compiler-cheatsheet.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25448573</guid>
            <pubDate>Wed, 16 Dec 2020 21:00:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sequoia PGP 1.0 Released: The Seedling Is a Sapling]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25448533">thread link</a>) | @dannyobrien
<br/>
December 16, 2020 | https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/ | <a href="https://web.archive.org/web/*/https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-content">
                          <p>Version 1.0.  It’s here.  After three and a half years of development,
we are happy to announce the release of version 1.0 of Sequoia!</p>
<p>The release includes the low-level crate <a href="https://crates.io/crates/sequoia-openpgp"><code>sequoia-openpgp</code></a>, and a
program to verify detached signatures geared towards software
distribution systems called <a href="https://crates.io/crates/sequoia-sqv"><code>sqv</code></a>.</p>
<p>We will support this API with security updates for at least one year.
In 9 months, we will announce whether we will extend this commitment.
The two main criteria will be our financial situation (please
<a href="https://pep.foundation/support-pep/index.html">donate</a>, or sponsor a developer or two), and the number of users.</p>

<p>We actually <a href="https://mastodon.social/@sequoiapgp/103364362621954545">almost released</a> version 1.0 about a year ago.  All of the
features that we had planned for version 1.0 were implemented, we had
good test coverage, and we even had a few users.  But, we decided to
wait.  We decided to wait not because we thought of another feature,
or because we became aware of a significant bug, but because <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/465">we</a>
<a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/466">decided</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/467">to</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/468">take</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/469">some</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/470">time</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/471">to</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/472">improve</a>
<a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/473">our</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/474">documentation</a>.</p>
<p>Our goal was to make sure that every module had a helpful
introduction, and all public methods had a useful description, a link
to <a href="https://tools.ietf.org/html/rfc4880">the standard</a>, when appropriate, and a meaningful example.
Dividing the task between five people, we figured it would delay the
release by a month, perhaps two.  In the end, well, it took nearly a
year, and we had to scale our ambitions back a bit.  Nevertheless,
we’re quite happy with <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/cert/index.html">the</a> <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/parse/stream/trait.DecryptionHelper.html">result</a>.</p>
<p>First, the documentation is much better.  It’s of course hard to
quantify its quality.  But, we can distill a few numbers.  When we
started our documentation effort shortly after we released version
0.14, the Sequoia library had just over 11k lines of comments
including 53 documentation tests, and 37 kSLOC including 12 kSLOC of
unit tests.  The 1.0 release has over 33k lines of comments (190%
more) including 464 documentation tests (780% more), and 44 kSLOC (21%
or 7.5 kSLOC more) including 8k SLOC of additional unit tests.</p>
<p>Second, in the process of documenting our public API and writing
examples, we discovered many minor annoyances, some inconsistencies,
and more than a few bugs.  Since we hadn’t yet commited to a stable
API, we could and did fix them.</p>
<p>Finally, as the rate of change of the API had decreased, more projects
were willing to try out Sequoia.  They provided additional useful
feedback, which we integrated.</p>
<p>All in all, we feel that with version 1.0 we’ve not only checked the
<a href="https://www.tomsguide.com/news/cyberpunk-2077-is-a-disaster-on-ps4-and-xbox-one-and-it-gets-worse">right boxes</a>, but we also have a high-quality API and implementation
that we can be proud of.</p>

<p>Sequoia was started 3.5 years ago by Justus Winter, Kai Michaelis and
me, Neal Walfield.  Prior to working on Sequoia, the three of us had
worked together at <a href="http://www.g10code.de/">g10code</a> on <a href="https://gnupg.org/">GnuPG</a>.  The <a href="https://pep.foundation/">p≡p foundation</a> hired
us not only to create a new OpenPGP implementation using a new
architecture and programming language, but to improve the ecosystem
around privacy-preserving tools as a whole.</p>
<p>The Sequoia library is a first step in that direction.  But it is not
our end goal.  Indeed, over the past three years, we’ve helped other
OpenPGP implementations.  We’ve reported bugs that we’ve found (thanks
in particular to our <a href="https://tests.sequoia-pgp.org/">OpenPGP interoperability test suite</a>), and even
contributed some fixes to other OpenPGP implementations.</p>
<p>And, we’ve invested in tooling.  We developed <a href="https://gitlab.com/hagrid-keyserver/hagrid">Hagrid</a>, a new
verifying OpenPGP key server, which powers <a href="https://keys.openpgp.org/">keys.openpgp.org</a> and is
now maintained by Vincent Breitmoser.  We’ve helped <a href="https://openpgp-ca.gitlab.io/openpgp-ca/">OpenPGP CA</a>, a
tool written by Heiko Schaefer to create <em>federated</em> CAs for groups
like activists, lawyers, and journalists, but also companies, who
don’t want to trust centralized infrastructure whose primary
incentives are monetary.  OpenPGP CA significantly simplifies key
discovery and authentication for unsophisticated OpenPGP users.  We’ve
developed <a href="https://gitlab.com/koverto/koverto">Koverto</a>, an SMTP proxy, which makes it easy to sign and
encrypt mails sent by services that don’t support OpenPGP out of the
box, like most CMSes.  We developed a tool, <a href="https://gitlab.com/sequoia-pgp/keyring-linter"><code>sq-keyring-linter</code></a>
(<a href="https://packages.debian.org/sid/sq-keyring-linter">Debian</a>), to help users update their OpenPGP Certificates, so that
we can <a href="https://mailarchive.ietf.org/arch/msg/openpgp/Rp-inhYKT8A9H5E34iLTrc9I0gc/">finally get rid of SHA-1</a>.</p>
<p>We’re thinking big.  We’re thinking not only about mail encryption or
even encryption in general, but also about integrity and
authentication.  And, we’re thinking in particular, about <a href="https://en.wikipedia.org/wiki/Public_key_infrastructure">PKI</a>.  If
users can’t easily find the <strong>right</strong> certificate for a communication
partner, encryption and digital signatures are worthless, and possibly
even dangerous.</p>

<p>In designing Sequoia, we took a library-first approach.  Although we
have a command-line tool, <a href="https://docs.sequoia-pgp.org/sq/index.html"><code>sq</code></a>, which we are not yet releasing, we
intend for the library to always provide a richer, more expressive
interface.  We agree that there is value in process separation, but we
want to avoid the dangerous complexity of <em>safely</em> shelling out to
another program.</p>
<p>The sequoia-openpgp crate (Rust’s terminology for a library) is a
low-level, policy-free OpenPGP implementation.  Our goal was to
implement all of <a href="https://tools.ietf.org/html/rfc4880">RFC 4880</a>, and provide an API that can be used to
access and modify pretty much everything, but is simultaneously secure
by default.</p>
<p>We understand low-level to mean not only an API that provides getters
and setters, but an API that provides interfaces to parse and
serialize those fields, and can combine them in ways intended by the
standard, and needed by users.  For instance, the <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/struct.Cert.html"><code>Cert</code></a> data
structure encapsulates an OpenPGP certificate (casually referred to as
an OpenPGP key).  It canonicalizes the structure, and makes it easy to
<a href="https://docs.sequoia-pgp.org/sequoia_openpgp/cert/struct.ValidCert.html#method.revocation_status">query its properties</a>.  But, it does so in such a way that it is
still possible for a user to inspect and modify the low-level bits
themselves without reimplementing the rest of the functionality.
Another example is the <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/parse/stream/trait.DecryptionHelper.html"><code>DecryptionHelper</code></a>, which makes it easy to
parse and decrypt an OpenPGP message.</p>
<p>An example of how we make the API safe by default is that it is hard
to accidentally export secret key material.  In Sequoia, you have to
explicitly <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/struct.Cert.html#secret-keys">opt-in to export it</a>.  Similarly, when <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/packet/signature/struct.SignatureBuilder.html">updating a
signature</a>, the creation time, hash algorithm, and issuer are
automatically updated.  This is usually what the user wants, but is
easy to forget, and hard to debug when forgotten.  Critically, it is
easy to opt out when that behavior is not desired.</p>
<p>While developing Sequoia, we spent a lot of time thinking about
extremes and corner cases.  For instance, OpenPGP supports
notarizations (signatures over signatures), but as far as we know no
OpenPGP implementation supports them.  We implemented support for it
anyway, and it improved the ergonomics of the common case.</p>
<h2 id="notable-details">Notable Details</h2>
<p>The devel is in the details.  And while deviloping Sequoia, we paid
attention.  Here are a few noteworthy details:</p>
<p><a href="https://en.wikipedia.org/wiki/SHA-1">SHA-1</a> has been broken since 2005.  And, in 2011 NIST deprecated its
use.  Initially, we decided to simply reject any signature that used
SHA-1.  However, we were recently forced to <a href="https://mailarchive.ietf.org/arch/msg/openpgp/Rp-inhYKT8A9H5E34iLTrc9I0gc/">reevaluate</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/595">that
decision</a>: 22% of Debian developers use a certificate that relies on
SHA-1 as do 63% of Arch developers.  Even the Fedora release keys use
SHA-1.</p>
<p>We decided that we couldn’t simply reenable SHA-1.  After some
consideration, we’ve opted to <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/policy/enum.HashAlgoSecurity.html">permit it</a> in contexts where collision
attacks similar to the one presented in <a href="https://sha-mbles.github.io/">SHA-1 is a Shambles</a> are
harder.  We also use a variant of SHA-1 called <a href="https://gitlab.com/sequoia-pgp/sha1collisiondetection">SHA1CD</a> (SHA-1
Collision Detection), which detects and neutralizes the known attacks
against SHA-1.  Among others, <a href="https://github.blog/2017-03-20-sha-1-collision-detection-on-github-com/">GitHub uses it</a>.  And, we have also
decided to <strong><a href="https://docs.sequoia-pgp.org/sequoia_openpgp/policy/struct.StandardPolicy.html#method.reject_hash_at">start rejecting SHA-1 by default</a> at the beginning of
2023</strong>, i.e., in a bit more than two years.  This will hopefully give
Debian developers and others sufficient time to <a href="https://gitlab.com/sequoia-pgp/keyring-linter">fix</a> or replace their
certificates.</p>
<p>When we create a signature, we include a <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/597">salt</a>.  This makes it harder
for an attacker to predict what data a user will sign.  And, it foils
attacks where an attacker needs multiple signatures over the same
message.</p>
<p>Similar to <a href="https://www.undeadly.org/cgi?action=article;sid=20190621081455">OpenSSH</a>, we <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/crypto/mem/struct.Encrypted.html">encrypt secret key material</a> while it is in
memory.  This frustrates side-channel attacks.</p>
<p>Sequoia supports <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/serialize/stream/padding/index.html">padding messages</a> to obfuscate an encrypted
message’s length.  We include support for the <a href="https://bford.info/pub/sec/purb.pdf">padmé</a> scheme, but
other schemes can be plugged in.</p>
<p>To allow users to control the policy while still using higher-level
functionality, Sequoia uses a <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/policy/index.html">policy object</a>.  A policy object is
passed to any method that checks something for validity.  For
instance, when a method needs to determine whether a binding signature
should be used, it invokes the policy object’s <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/policy/trait.Policy.html#method.signature"><code>signature</code> callback</a>.
Our experience suggests that this approach greatly simplifies dealing
with this <a href="https://en.wikipedia.org/wiki/Cross-cutting_concern">cross-cutting concern</a> in a highly flexible manner.</p>
<p>Policy objects can also be embedded in other objects.  For instance, a
<a href="https://docs.sequoia-pgp.org/sequoia_openpgp/cert/struct.ValidCert.html"><code>ValidCert</code></a> encapsulates a <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/struct.Cert.html"><code>Cert</code></a> and a policy object.  This
ensures that the application of the policy is consistent, and hard to
forget to apply.</p>
<p>In Sequoia, we prefer the use of formal grammars rather than ad-hoc
parsing when doing any non-trivial parsing.  For instance, when
verifying the structure of <a href="https://tools.ietf.org/html/rfc4880#section-11.1">OpenPGP Certificates</a> and <a href="https://tools.ietf.org/html/rfc4880#section-11.3">OpenPGP
Messages</a>, we use <a href="https://github.com/lalrpop/lalrpop">LALRPOP</a>, a parser generator, to generate the
parser.</p>
<p>Sequoia implements a streaming API.  If not careful, this can lead to
a consumer processing unauthenticated data, which was exploited by
<a href="https://efail.de/">EFAIL</a>.  To mitigate this type of failure, the <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/parse/stream/trait.DecryptionHelper.html"><code>DecryptionHelper</code></a>
withholds the last <code>O(1)</code> bytes of data, and only releases it if the
message can be authenticated.  This makes it harder for an attacker to
control what is released.  And for short messages, nothing is released
since the whole message is buffered.</p>
<p>We’ve tried to ensure that data structures that may be used in a
side-channel sensitive context use constant time comparisons.</p>
<p>Where possible, we use a device driver-style API so that it is
straightforward to add new backends.  For instance, our <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/crypto/trait.Signer.html"><code>Signer</code></a> and
<a href="https://docs.sequoia-pgp.org/sequoia_openpgp/parse/stream/struct.Decryptor.html"><code>Decryptor</code></a> traits make it easy to implement alternative signing and
decryption backends.  In addition to the in-memory implementations, we
already have implementations that use secret key material managed by
<a href="https://docs.sequoia-pgp.org/sequoia_ipc/gnupg/struct.KeyPair.html">gpg agent</a>.</p>
<p>We tried hard to provide helpful error messages.  This is particularly
difficult …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/">https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/</a></em></p>]]>
            </description>
            <link>https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25448533</guid>
            <pubDate>Wed, 16 Dec 2020 20:57:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Researchers Measured the Efficacy of Every Kind of Mask. Here's What They Found]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25448300">thread link</a>) | @hindsightbias
<br/>
December 16, 2020 | https://smosa.com/researchers-measured-the-efficacy-of-every-kind-of-mask-heres-what-they-found/ | <a href="https://web.archive.org/web/*/https://smosa.com/researchers-measured-the-efficacy-of-every-kind-of-mask-heres-what-they-found/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

					<!-- .post-header -->


					<div>
						<p>In a <a href="https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2769443">study published in <em>JAMA Internal Medicine</em></a>, researchers studied 29 different face masks and used fit and use guidelines by the Occupational Safety and Health Administration to evaluate the FFEs in a variety of breathers worn by a male and female volunteers.</p><figure><img src="https://images.unsplash.com/photo-1591034455539-0352f7ed55ee?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI3fHxmYWNlJTIwbWFza3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="A Couple wearing pink accented gas masks joins the Protests in Washington DC" srcset="https://images.unsplash.com/photo-1591034455539-0352f7ed55ee?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI3fHxmYWNlJTIwbWFza3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1591034455539-0352f7ed55ee?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI3fHxmYWNlJTIwbWFza3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1591034455539-0352f7ed55ee?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI3fHxmYWNlJTIwbWFza3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1591034455539-0352f7ed55ee?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI3fHxmYWNlJTIwbWFza3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@thenewmalcolm?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Obi Onyeador</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>When two people wearing masks interact, chance of SARS-CoV-2 transmission is drastically reduced. Some masks were as much as 79 percent effective at blocking particles that could carry the virus. UNC scientists researched the protectiveness of various kinds of consumer-grade and modified masks. Researchers used an approach based on the OSHA Fit Test to determine the fitted filtration efficiency of facemasks. The top-of-the-line N-95 mask proved to be 98 percent effective.</p><p>Fitted filtration efficiency tests were conducted in a custom-built exposure chamber. Masks were fitted with sampling probes using a Fit Test Probe Kit for Disposable Facepieces 8025-N95 (TSI) to allow sampling of aerosol inside the face mask. Three respirator sterilization methods were tested on used masks: ethylene oxide (EtO), steam (121 °C, 15 minutes), and vaporized hydrogen peroxide (8 g/min, 260 PPM, 100-minute cycle) The FFE of these sterilized, used masks was measured after a single sterilization cycle as described above.</p><figure><img src="https://smosa.com/content/images/2020/12/251456_web.jpg" alt="" srcset="https://smosa.com/content/images/size/w600/2020/12/251456_web.jpg 600w, https://smosa.com/content/images/size/w1000/2020/12/251456_web.jpg 1000w, https://smosa.com/content/images/2020/12/251456_web.jpg 1440w" sizes="(min-width: 720px) 720px"><figcaption>CREDIT: UNC School of Medicine, Medical procedure mask and modifications designed to enhance mask fit or comfort for the wearer. A mask w/ear loops (A) modified by tying the ear loops and tucking in the side pleats (B), attaching ear loops to a 3D-printed "ear guard" (C), fastening ear loops with a 23mm claw-type hair clip placed behind the wearer's head (D), placing ring of three, ganged, rubber bands over the mask and around the wearer's ears (E), and sliding a 10-inch segment of nylon hosiery over the fitted mask (F).</figcaption></figure><p>N95 respirators fitted to the face are the preferred choice of protection from bioaerosols. However, availability of these items may be compromised during periods of high demand, such as in a pandemic. Recently, sterilization and decontamination of face masks has emerged as a novel method to prolong the limited supply of existing respirators. The study evaluated particle penetration for commonly available face masks and alternatives. The most effective face mask achieved only 79.7% FFE, and masks with elastic ear loops were the least effective when moving the head left and right (21.2% F FE) and bent at the waist and looked up and down.</p><p>The most penetrating particle size was found to be 30 to 60 nm, which is similar in size to those used for measurements in this study. A limitation of this study is the decision to test each mask on a single man (and woman for a few comparisons) rather than a large number of individuals with a full range of facial configurations.</p><figure><img src="https://smosa.com/content/images/2020/12/IMG_2187.jpeg" alt="" srcset="https://smosa.com/content/images/size/w600/2020/12/IMG_2187.jpeg 600w, https://smosa.com/content/images/size/w1000/2020/12/IMG_2187.jpeg 1000w, https://smosa.com/content/images/2020/12/IMG_2187.jpeg 1057w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://images.unsplash.com/photo-1598207951491-255eaf139751?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDJ8fGZhY2UlMjBtYXNrfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Man wearing a black mask" srcset="https://images.unsplash.com/photo-1598207951491-255eaf139751?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDJ8fGZhY2UlMjBtYXNrfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1598207951491-255eaf139751?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDJ8fGZhY2UlMjBtYXNrfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1598207951491-255eaf139751?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDJ8fGZhY2UlMjBtYXNrfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1598207951491-255eaf139751?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDJ8fGZhY2UlMjBtYXNrfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@gmalhotra?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Gayatri Malhotra</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>Even face masks with less than 95% FFE (eg, surgical masks) are effective in preventing acquisition of epidemic coronaviruses. N95 respirators had no increased prevention benefit over surgical masks. The CDC and Infectious Diseases Society of America has recommended the use of N94 respirators.</p><p><em>Cover Photo Credit: UNC School of Medicine</em></p>
					</div><!-- .post-content -->

					<!-- .post-footer -->


				</article></div>]]>
            </description>
            <link>https://smosa.com/researchers-measured-the-efficacy-of-every-kind-of-mask-heres-what-they-found/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25448300</guid>
            <pubDate>Wed, 16 Dec 2020 20:42:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Old New Adventure]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25448248">thread link</a>) | @Ygg2
<br/>
December 16, 2020 | https://raphlinus.github.io/personal/2020/12/16/an-old-new-adventure.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/personal/2020/12/16/an-old-new-adventure.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>After two and a half years of being independent, I am returning to Google.</p>

<p>The time off was really valuable. I was still feeling residual effects from burnout on the Android team in late 2015, and also drained by family and personal things that were happening and needed more time and energy. I got that, and return recharged and with some insights that I hope will be useful. I’ll touch on a few of those in this post. Each could probably be its own blog post, but today I want to briefly note the event.</p>

<p>I am now a research software engineer on the Google Fonts team, working on a number of topics in font technology, including font design tools, GPU-accelerated font rendering, and evolution of font file formats to be more efficient and capable.</p>

<h2 id="on-open-source-sustainability">On open source sustainability</h2>

<p>Much has been written on open source sustainability, notably <a href="https://nadiaeghbal.com/">Nadia Eghbal</a>’s <em>Working in Public.</em> I won’t speak to open source more broadly (except to note how impressed I am with Blender and Krita), but for the specific task of building an ecosystem for a library, I think there is one model that actually works: being hired by a company that depends on that ecosystem.</p>

<p>To some extent, that’s an indictment of our capitalist system. In an ideal universe, there would be strong institutions dedicated to the public interest where open source developers could develop, researchers could research, and spend an absolute minimum of time and energy hustling for support. For software, in any case, universities are not that (as demonstrated by <a href="https://blog.cocalc.com/2019/04/12/should-i-resign-from-my-full-professor-job-to-work-fulltime-on-cocalc.html">William Stein’s experience with Cocalc at University of Washington</a>), otherwise I’d be quite tempted. In the actual world, working for a company like Google is about as close as you can come.</p>

<p>I remain skeptical of patronage-style platforms such as Patreon or Github Sponsors. I think it’s possible to make them work, but only for a small number of fortunate people, and even then, the incentives for creating maximum value aren’t that well aligned with the incentive structure of hustling on social media.</p>

<p>So me (re-)joining Google full time is basically a statement of confidence in this model of being employed to work on open source. Other models can work, and people should definitely find what works for them, but particularly for the projects I’m interested in, it makes sense.</p>

<h2 id="on-rust">On Rust</h2>

<p>I continue to love Rust, and believe it offers a stronger foundation for building software. I feel like I started my Rust journey in the early ’90s, when I was working on retrofitting <a href="https://theory.stanford.edu/~aiken/publications/papers/pldi95.pdf">static memory management</a> to ML, using explicit lifetime regions.</p>

<p>Rust adoption is trending up, including at Google. The language is in good shape, but the library ecosystem is still fairly immature, missing a number of critical pieces. Building up that ecosystem is an incredibly rewarding project.</p>

<p>I am particularly excited about Rust for font technology and infrastructure. Today, Python rules on the font design and production side, partly to the connection of typeface designer <a href="https://medium.com/type-thursday/learning-python-makes-you-a-better-designer-an-interview-with-just-van-rossum-8d4758c192d8">Just van Rossum</a> being Guido’s brother. The flexibility and expressiveness of Python makes it a good fit, but we’ve also gotten to a place where the <em>production</em> of fonts is done in Python, and the <em>consumption</em> is in C++.</p>

<p>Rust lets us build reliable, performant code that can also be deployed in production, and can be the basis of fluidly interactive UI tools. I’m not the only one who sees this potential; YesLogic is building their next-generation font shaper <a href="https://github.com/yeslogic/allsorts">Allsorts</a> in Rust, for many of the same reasons.</p>

<p>The Google Fonts team has been interested in adopting more Rust for a while, and part of my role is to facilitate that. I’m really looking forward to it.</p>

<h2 id="on-research">On research</h2>

<p>I have rebranded myself somewhat as a researcher, but that doesn’t <em>quite</em> capture the whole story either. I have always loved research, and that love sustained the energy to complete my <a href="https://levien.com/phd/phd.html">PhD</a>, but I also love building real things, and actually feel that many of these practical problems are more interesting than many of the abstract topics fashionable in academia. Just as much as writing papers and so on, I’m trying to build open source software and community around that. There isn’t really a word for this role, but even without such a word I’m trying to consciously create it for myself, and am grateful that Google is allowing me to try.</p>

<h2 id="on-the-work">On the work</h2>

<p>This is the most exciting part for me. I have a very long-term interest in 2D graphics, font technology, and UI, and have been doing a bunch of interesting things on all these fronts. I expect to spend most of my time continuing to advance research on all these frontiers.</p>

<p>The scope of these projects is large, and more ambitious than one person could really do. That’s one reason I’ve been consciously developing an open source community around them. That will continue.</p>

<p>Most of the day-to-day work on <a href="https://github.com/linebender/druid">Druid</a> and <a href="https://github.com/linebender/runebender">Runebender</a> will be done by Colin Rofls, though I very much enjoy getting my elbows in the code too and will be doing some of that.</p>

<p>A major focus will be building out the <a href="https://github.com/linebender/piet-gpu/blob/master/doc/vision.md">piet-gpu vision</a>. I believe a high-performance 2D rendering engine will be a great thing for the Rust ecosystem and with potential for large impact. It feels like good research; whether it goes into production at scale or not, I expect the things we learn from doing it will help inform the next generation of UI technology. That’s equally true for research into fundamental UI principles, for example the <a href="https://raphlinus.github.io/rust/druid/2020/09/25/principled-reactive-ui.html">Crochet</a> architecture for Druid.</p>

<p>There are also really exciting advances in <a href="https://github.com/linebender/spline">spline</a> technology in the pipeline. I think these have the potential to be a more appealing and productive basis for drawing fonts than cubic Béziers. The next big step is to validate whether they actually work as well as I’m hoping. That involves polishing the UX and integrating them into Runebender. If that turns out really well, a longer term (but more speculative) aspiration is to get them into a font format, where they could reduce binary size while increasing quality. It’s obvious the Google Fonts team is the best home for this work.</p>

<p>I have a lot of work in front of me, but am more excited than ever. On to an old new adventure, and may 2021 be a time of healing and renewed energy for all.</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://raphlinus.github.io/personal/2020/12/16/an-old-new-adventure.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25448248</guid>
            <pubDate>Wed, 16 Dec 2020 20:36:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Encapsulate for Easy Refactors]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25448247">thread link</a>) | @jshah111
<br/>
December 16, 2020 | https://www.jshah.dev/ruby/rails/refactor/2020/12/14/encapsulate-for-easy-refactors/ | <a href="https://web.archive.org/web/*/https://www.jshah.dev/ruby/rails/refactor/2020/12/14/encapsulate-for-easy-refactors/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>14 Dec 2020</span></p><p>An application is a living, breathing code base that will continually change over time. As the application evolves, early decisions won’t scale, and shortcuts taken will reveal technical debt. When the time comes to address these problems, one thing you can start doing today to make refactoring tomorrow easier is using encapsulation.</p>



<p>Imagine your application has a <code>User</code> model, and the <code>User</code> can have a role. The role is stored as a column on the model.</p>

<div><div><pre><code><span># == Schema Information</span>
<span>#</span>
<span># Table name: users</span>
<span>#</span>
<span>#  id                     :bigint(8)        not null, primary key</span>
<span>#  email                  :string           default(""), not null</span>
<span>#  first_name             :string</span>
<span>#  last_name              :string</span>
<span>#  role                   :string</span>
<span>#  created_at             :datetime         not null</span>
<span>#  updated_at             :datetime         not null</span>
<span>#</span>
<span>class</span> <span>User</span> <span>&lt;</span> <span>ApplicationRecord</span>
<span>end</span>
</code></pre></div></div>

<p>You might have actions in your controller where you check if a user has a specific role. You might decide to directly access the role attribute and compare it with the role you care about:</p>

<div><div><pre><code><span>class</span> <span>ItemController</span> <span>&lt;</span> <span>ApplicationController</span>
  <span>def</span> <span>update</span>
    <span>if</span> <span>user</span><span>.</span><span>role</span> <span>==</span> <span>'admin'</span> <span>||</span> <span>user</span><span>.</span><span>role</span> <span>==</span> <span>'operations'</span>
       <span>update_item</span><span>(</span><span>params</span><span>[</span><span>:item_id</span><span>])</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>While this seems harmless at first, it becomes painful to refactor when you have to extend the relationship so a user can have many roles.</p>

<h2 id="extending-role-to-its-own-model">Extending Role To Its Own Model</h2>

<p>Imagine your product manager asks you to support users having multiple roles. You will have to move the role attribute from the <code>User</code> model to its own model.</p>

<h3 id="models">Models</h3>

<p>The resulting model design might look like the following. The <code>User</code> model now has a <code>has_many</code> relationship through a joining class (<code>UserRole</code>) to a <code>Role</code> model.</p>

<div><div><pre><code><span># == Schema Information</span>
<span>#</span>
<span># Table name: users</span>
<span>#</span>
<span>#  id                     :bigint(8)        not null, primary key</span>
<span>#  email                  :string           default(""), not null</span>
<span>#  first_name             :string</span>
<span>#  last_name              :string</span>
<span>#  role                   :string</span>
<span>#  created_at             :datetime         not null</span>
<span>#  updated_at             :datetime         not null</span>
<span>#</span>
<span>class</span> <span>User</span> <span>&lt;</span> <span>ApplicationRecord</span>
  <span>has_many</span> <span>:user_roles</span><span>,</span> <span>dependent: :destroy</span>
  <span>has_many</span> <span>:roles</span><span>,</span> <span>through: :user_roles</span>
<span>end</span>
</code></pre></div></div>

<div><div><pre><code><span># == Schema Information</span>
<span>#</span>
<span># Table name: user_roles</span>
<span>#</span>
<span>#  id         :bigint(8)        not null, primary key</span>
<span>#  created_at :datetime         not null</span>
<span>#  updated_at :datetime         not null</span>
<span>#  role_id    :bigint(8)</span>
<span>#  user_id    :bigint(8)</span>
<span>#</span>
<span>class</span> <span>UserRole</span> <span>&lt;</span> <span>ApplicationRecord</span>
  <span>belongs_to</span> <span>:user</span>
  <span>belongs_to</span> <span>:role</span>
<span>end</span>
</code></pre></div></div>

<div><div><pre><code><span># == Schema Information</span>
<span>#</span>
<span># Table name: users</span>
<span>#</span>
<span>#  id                     :bigint(8)        not null, primary key</span>
<span>#  name                   :string</span>
<span>#  created_at             :datetime         not null</span>
<span>#  updated_at             :datetime         not null</span>
<span>#</span>
<span>class</span> <span>Role</span> <span>&lt;</span> <span>ApplicationRecord</span>
  <span>has_many</span> <span>:user_roles</span><span>,</span> <span>dependent: :destroy</span>
  <span>has_many</span> <span>:users</span><span>,</span> <span>through: :user_roles</span>
<span>end</span>
</code></pre></div></div>

<h3 id="usage">Usage</h3>

<p>Instead of checking if a <code>user.role</code> is equal to a role, we’ll now check if a specific role is in the list of roles attached to a user.</p>

<div><div><pre><code><span>admin_role</span> <span>=</span> <span>Role</span><span>.</span><span>create</span><span>(</span><span>name: </span><span>'admin'</span><span>)</span>
<span>operations_role</span> <span>=</span> <span>Role</span><span>.</span><span>create</span><span>(</span><span>name</span> <span>:</span> <span>'operations'</span><span>)</span>
<span>user</span> <span>=</span> <span>User</span><span>.</span><span>find</span><span>(</span><span>1</span><span>)</span>

<span># add roles to user</span>
<span>user</span><span>.</span><span>roles</span> <span>&lt;&lt;</span> <span>admin_role</span>
<span>user</span><span>.</span><span>roles</span> <span>&lt;&lt;</span> <span>operations_role</span>
<span>user</span><span>.</span><span>roles</span> <span># [&lt;Role name: 'admin'&gt;, &lt;Role name: 'operations'&gt;]</span>

<span># check if a user is an admin</span>
<span>user</span><span>.</span><span>roles</span><span>.</span><span>exists?</span><span>(</span><span>name: </span><span>'admin'</span><span>)</span> <span># true</span>
</code></pre></div></div>

<h3 id="refactoring-usages">Refactoring Usages</h3>

<p>When we refactor the <code>ItemController</code> to use these new models and methods, we first want to bring all methods into the <code>User</code> class and then update usages.</p>

<div><div><pre><code><span># Encapsulate all User role related methods.</span>
<span># New feature is also gated behind a feature flag.</span>

<span>class</span> <span>User</span> <span>&lt;</span> <span>ApplicationRecord</span>
  <span>has_many</span> <span>:user_roles</span><span>,</span> <span>dependent: :destroy</span>
  <span>has_many</span> <span>:roles</span><span>,</span> <span>through: :user_roles</span>

  <span>def</span> <span>has_role?</span><span>(</span><span>role_name</span><span>)</span>
    <span>if</span> <span>feature_flag_on?</span>
      <span>roles</span><span>.</span><span>exists?</span><span>(</span><span>name: </span><span>role_name</span><span>)</span>
    <span>else</span>
      <span>role</span> <span>==</span> <span>role_name</span>
    <span>end</span>
  <span>end</span>

  <span>def</span> <span>admin?</span>
    <span>has_role?</span><span>(</span><span>'admin'</span><span>)</span>
  <span>end</span>

  <span>def</span> <span>operations?</span>
    <span>has_role?</span><span>(</span><span>'operations'</span><span>)</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>With these methods now encapsulated in the <code>User</code> class, checking if a user has a certain role becomes easy!</p>

<div><div><pre><code><span># No explicit feature flag check needed.</span>
<span># All logic is encapsulated inside the User methods.</span>

<span>class</span> <span>ItemController</span> <span>&lt;</span> <span>ApplicationController</span>
  <span>def</span> <span>update</span>
    <span>if</span> <span>user</span><span>.</span><span>admin?</span> <span>||</span> <span>user</span><span>.</span><span>operations?</span>
       <span>update_item</span><span>(</span><span>params</span><span>[</span><span>:item_id</span><span>])</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

</div>



    </div></div>]]>
            </description>
            <link>https://www.jshah.dev/ruby/rails/refactor/2020/12/14/encapsulate-for-easy-refactors/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25448247</guid>
            <pubDate>Wed, 16 Dec 2020 20:36:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fight “Cancel Culture” on Campus]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25447993">thread link</a>) | @Reedx
<br/>
December 16, 2020 | https://www.persuasion.community/p/fight-cancel-culture-on-campus | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/fight-cancel-culture-on-campus">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F904a2ea2-8235-4988-9603-e6489cfd4c13_5184x3456.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F904a2ea2-8235-4988-9603-e6489cfd4c13_5184x3456.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/904a2ea2-8235-4988-9603-e6489cfd4c13_5184x3456.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1567070,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>College leaders rarely get it right when it comes to campus free-speech controversies. Too often their responses are confused, slow, ambivalent, contradictory or downright illiberal.</p><p>Take, for example, St. John’s University in Queens, New York. It <a href="https://www.stjohns.edu/about/leadership-and-administration/administrative-offices/office-provost/policies-procedures-and-reports">advertises</a> “freedom of inquiry.” But earlier this fall, it found a professor <a href="https://www.thefire.org/teaching-history-not-permitted-st-johns-bulldozes-academic-freedom-punishes-professor-for-posing-question-about-columbian-exchange/">guilty</a> of “bias, discrimination, and harassment” for asking his introductory history class if the positives of expanding global trade in the 15th and 16th centuries justified the negatives. The slave trade was part of this phenomenon, so some people judged the question off-limits, and a <a href="https://www.instagram.com/p/CE9udVzpYkC/">group</a> of self-declared radicals petitioned to have him fired. Now, adjunct professor Richard Taylor, a former 9/11 first responder, cannot even serve as a guest lecturer about 9/11—<a href="https://www.thefire.org/update-st-johns-limits-academic-freedom-of-history-department-in-ongoing-effort-to-punish-professor-for-asking-question/">he’s barred from teaching</a>.</p><p>Then there’s the case from earlier this year at Babson College. Administrators demonstrated that they understood comedy as poorly as they understood free expression when it came to Professor Asheen Phansey, who made a private, satirical joke on Facebook. He was responding to President Donald Trump’s threat to bomb 52 Iranian locations, including cultural sites. “In retaliation,” Phansey quipped, “Ayatollah Khomenei should tweet a list of 52 sites of beloved American cultural heritage that he would bomb. Um… Mall of America? …Kardashian residence?” The administrators <a href="https://www.thefire.org/babson-college-abandons-freedom-of-expression-fires-professor-over-facebook-post-criticizing-trump-threat-to-bomb-iran-cultural-sites/">fired</a> him.</p><div><p>College leaders please nobody when they try to please everybody in a cancel campaign. So why try? Instead, why not defend the core enlightenment mission of a college, which the University of Chicago describes as the “discovery, improvement, and dissemination of knowledge”? That language appears in the <a href="http://www-news.uchicago.edu/releases/07/pdf/kalverpt.pdf">Kalven Report</a>, which the university commissioned in 1967 to address the tension between open inquiry and activism in a university environment. The report states that “a university must sustain an extraordinary environment of freedom of inquiry and maintain an independence from political fashions, passions, and pressures.”</p><p>Living up to these values may be hard but, with sufficient courage, it’s possible. Perhaps the best example of a college president with backbone when faced with an effort to banish a professor comes from 20 years ago, before “cancel culture” was part of our popular lexicon.</p></div><div><p>In December 2000, the renowned poet and University of Alaska Professor Linda McCarriston published a poem called “<a href="https://www.thefire.org/linda-mccarristons-indian-girls-2/">Indian Girls</a>,” about alcoholism and the sexual abuse of children in Native American communities. Students protested, including some in McCarriston’s class. They <a href="https://www.thefire.org/professors-poem-draws-fiery-conflict/">argued</a> that the poem was insulting and stereotyping of Native communities. Then came the investigation. That is, until the university president, Mark R. Hamilton, heard about it. </p><p>Hamilton was a <a href="https://www.alaska.edu/uajourney/presidents/1998-2010-mark-r.-hamilto/">retired U.S. Army major general</a> who brokered peace negotiations in El Salvador and Somalia. He was also an admirer of the First Amendment’s protection for freedom of speech, and knew it was his job as a government official leading a public university system to guarantee that protection. </p></div><p>Besides the “Indian Girls” imbroglio, there was also a controversy around an invited campus speaker, and an open letter from faculty members written to President Bill Clinton against a proposal to drill within the Arctic National Wildlife Refuge. The open letter prompted Alaska’s governor to call Hamilton to complain: What are you going to do about it?</p><p>Responding to all three matters at once, Hamilton wrote an <a href="https://www.thefire.org/president-hamiltons-memo/">open letter of his own</a>. “What I want to make clear and unambiguous is that responses to complaints or demands for action regarding constitutionally guaranteed freedoms of speech CANNOT BE QUALIFIED,” he wrote. </p><p>“Attempts to assuage anger or to demonstrate concern by qualifying our support for free speech serve to cloud what must be a clear message. Noting that, for example, ‘The University supports the right to free speech, but we intend to check into this matter,’ or ‘The University supports the right of free speech, but I have asked Dean X or Provost Y to investigate the circumstances,’ is unacceptable. There is nothing to ‘check into,’ nothing ‘to investigate.’ ” </p><p>Case closed.</p><p><strong>For years, we at the <a href="http://thefire.org/">Foundation for Individual Rights in Education</a> (FIRE) </strong>have worked to defend free speech and academic freedom on campus. Two observations we can make are: 1) colleges used to get in front of these controversies faster and more categorically than they do now; and 2) when they do remove the possibility of punishment and assert their values from the beginning, the demands tend to peter out, often quickly.&nbsp;</p><p>Qualifying free-speech defenses, we find, only prolongs the fight and emboldens would-be censors. What’s more, leaders at public colleges need to be careful: Investigating protected speech can result in legal liability. As the University of Alaska president Hamilton wrote, when it comes to speech protected by the First Amendment, “There is nothing to ‘check into,’ nothing ‘to investigate.’”</p><p>While rarer, we do see shades of Hamilton’s response from some of today’s more courageous college presidents.&nbsp;Last year, the president of University of the Arts in Philadelphia, David Yager, rejected calls to fire Professor Camille Paglia over her statements surrounding the #MeToo movement and transgender people: “Across our nation it is all too common that opinions expressed that differ from another’s—especially those that are controversial—can spark passion and even outrage, often resulting in calls to suppress that speech,” he wrote <a href="https://www.uarts.edu/node/43674">in a letter</a> to the university community. “That simply cannot be allowed to happen.”&nbsp;</p><p>The would-be censors called his letter “<a href="https://www.change.org/p/uarts-president-david-yager-uarts-support-transgender-students-and-survivors-of-sexual-assault">wildly ignorant</a>.” But the controversy soon fizzled and the demands stopped, much as they did at the University of Alaska. Yager’s letter, like Hamilton’s, left no room for compromise.</p><p>Most recently, the University of Chicago president, Robert Zimmer, wrote a community-wide email of his own, rejecting calls to punish a geophysical sciences professor, Dorian Abbot, for videos he had made critiquing diversity initiatives. A total of 129 students, alumni, and staff wrote <a href="https://docs.google.com/document/d/1fCOezNmxmaeVLSirrYp9y2nzy7m9Yr-rgPulwW-eNDw/edit">an open letter</a> to his faculty alleging that Abbot’s videos “threaten the safety and belonging of all underrepresented groups” and “represent an aggressive act towards the research and teaching communities of which Professor Abbot is a member.”&nbsp;</p><div><p>To this, Zimmer <a href="https://president.uchicago.edu/page/statement-faculty-free-expression-and-diversity">wrote</a> to the campus community: “The University does not limit the comments of faculty members, mandate apologies, or impose other disciplinary consequences for such comments, unless there has been a violation of University policy or the law.” (Under normal circumstances, that last clause about “University Policy” might worry us, but Chicago receives <a href="https://www.thefire.org/schools/university-of-chicago/">a “green-light” rating</a> from FIRE, which means it does not maintain any policies that threaten free expression.)</p><p>Sometimes, college leaders—or, more often, those at the center of the controversy—make matters worse by apologizing for hurt feelings. In a perfect world, a heartfelt, genuine apology would settle matters and placate the mob. But during a cancel campaign, apologies tend to be received as confessions that you <em>are</em> a witch deserving of further persecution.&nbsp;</p></div><p>Research backs this up. <a href="https://www.cambridge.org/core/journals/behavioural-public-policy/article/does-apologizing-work-an-empirical-test-of-the-conventional-wisdom/D34F1D89E6FF6A6E32C22C75F0C5FE24">A 2019 study</a> of whether apologizing works found that “when a prominent figure apologizes for a controversial statement, individuals are either unaffected or become more likely to desire that the individual be punished.” The scholar Cass Sunstein, of Harvard Law School, conducted a similar study and <a href="https://www.nytimes.com/2019/07/27/opinion/sunday/when-should-a-politician-apologize.html">found</a> that “an apology tended to decrease rather than to increase overall support for those who said or did things that many people consider offensive.”</p><p><strong>So what is the antidote to campus cancel campaigns? </strong>A strong, unequivocal defense of the right to free inquiry and expression <em>after</em> the campaign begins is important. But much of the groundwork for a successful defense begins <em>before</em> the campaign. Here are three vital practices.</p><ul><li><p><strong>Stop violating the law</strong>. Public colleges in the United States are bound by the First Amendment, yet <a href="https://www.thefire.org/resources/spotlight/reports/spotlight-on-speech-codes-2021/">85% of them maintain speech codes</a> that restrict speech protected by the Constitution. We have a group of lawyers whose full-time job it is to work collegially with campus administrators to help them fix restrictive speech codes. We are happy to help.</p></li><li><p><strong>Commit and recommit to free speech and inquiry</strong>. Faculty and administrators should seek out opportunities to enshrine protections for free speech and inquiry in campus policy. These policies should be adopted publicly and conspicuously. The <a href="https://www.thefire.org/get-involved/student-network/take-action/adopting-the-chicago-statement/">Chicago Statement</a>—a freedom-of-expression declaration from the University of Chicago in 2014—is one such policy that colleges can easily adopt and adapt, and <a href="https://www.thefire.org/chicago-statement-university-and-faculty-body-support/">78 have already done so</a>. Same goes for the aforementioned <a href="http://www-news.uchicago.edu/releases/07/pdf/kalverpt.pdf">Kalven Report</a>. (There’s a reason <a href="https://www.thefire.org/research/publications/student-surveys/2020-college-free-speech-rankings/2020-college-free-speech-rankings-view-rankings/">student survey data</a> finds the University of Chicago to be the number one school for free speech in the country.) </p></li><li><p><strong>Teach students about free speech from day one</strong>. Principles of free speech can run counter to our moral intuitions, and may be taken for granted. But the principles are essential if colleges are to fulfill their core missions. Sadly, few incoming students are aware of these principles and their role in the larger project of human knowledge. Only a handful of colleges teach them in their orientation programming. That is why we joined with New York University’s First Amendment Watch to create <a href="https://www.thefire.org/resources/free-speech-freshman-orientation/">a series of orientation modules and videos</a> that are ready for colleges to use right away.</p></li></ul><p>Fighting cancel culture isn’t easy for campus leaders. It’s a fight that seems to get more challenging every day. But, while the war might be neverending, individual battles can be won. Courageous leaders have shown us a way—it’s up to others to follow it.</p><p><strong>Greg Lukianoff is president and chief executive and Nico Perrino is vice president for the <a href="https://www.thefire.org/">Foundation for Individual Rights in Education</a> (FIRE). Both are producers of the recently released free-speech documentary, <a href="http://mightyira.com/">Mighty Ira: A Civil Liberties Story</a>.</strong></p></div></div>]]>
            </description>
            <link>https://www.persuasion.community/p/fight-cancel-culture-on-campus</link>
            <guid isPermaLink="false">hacker-news-small-sites-25447993</guid>
            <pubDate>Wed, 16 Dec 2020 20:19:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn Sorbet in Y Minutes]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25447883">thread link</a>) | @jdkaplan
<br/>
December 16, 2020 | https://jdkaplan.dev/blog/learn-sorbet-in-y-minutes/ | <a href="https://web.archive.org/web/*/https://jdkaplan.dev/blog/learn-sorbet-in-y-minutes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>We’ve been increasing our adoption of <a href="https://sorbet.org/">Sorbet</a> at <a href="https://gusto.com/">Gusto</a>!
As I’ve been trying to type more and more complex bits of Ruby, I’ve found it helpful to have a single page of examples that I can search through easily.</p><p>I like learning new programming languages with <a href="https://learnxinyminutes.com/">Learn X in Y minutes</a>, so I tried to make this digestible in the same way.</p><p>If you use this, let me know what you think!
I’m open to improving this to work for more people, and I’m also interested in learning what your value of <code>Y</code> is.</p><p>The easiest way to see this in action is on <a href="https://sorbet.run/">sorbet.run</a>.
Here’s a link for each section below:</p><div><div>
<table><tbody><tr><td>
<pre><code><span>   1
</span><span>   2
</span><span>   3
</span><span>   4
</span><span>   5
</span><span>   6
</span><span>   7
</span><span>   8
</span><span>   9
</span><span>  10
</span><span>  11
</span><span>  12
</span><span>  13
</span><span>  14
</span><span>  15
</span><span>  16
</span><span>  17
</span><span>  18
</span><span>  19
</span><span>  20
</span><span>  21
</span><span>  22
</span><span>  23
</span><span>  24
</span><span>  25
</span><span>  26
</span><span>  27
</span><span>  28
</span><span>  29
</span><span>  30
</span><span>  31
</span><span>  32
</span><span>  33
</span><span>  34
</span><span>  35
</span><span>  36
</span><span>  37
</span><span>  38
</span><span>  39
</span><span>  40
</span><span>  41
</span><span>  42
</span><span>  43
</span><span>  44
</span><span>  45
</span><span>  46
</span><span>  47
</span><span>  48
</span><span>  49
</span><span>  50
</span><span>  51
</span><span>  52
</span><span>  53
</span><span>  54
</span><span>  55
</span><span>  56
</span><span>  57
</span><span>  58
</span><span>  59
</span><span>  60
</span><span>  61
</span><span>  62
</span><span>  63
</span><span>  64
</span><span>  65
</span><span>  66
</span><span>  67
</span><span>  68
</span><span>  69
</span><span>  70
</span><span>  71
</span><span>  72
</span><span>  73
</span><span>  74
</span><span>  75
</span><span>  76
</span><span>  77
</span><span>  78
</span><span>  79
</span><span>  80
</span><span>  81
</span><span>  82
</span><span>  83
</span><span>  84
</span><span>  85
</span><span>  86
</span><span>  87
</span><span>  88
</span><span>  89
</span><span>  90
</span><span>  91
</span><span>  92
</span><span>  93
</span><span>  94
</span><span>  95
</span><span>  96
</span><span>  97
</span><span>  98
</span><span>  99
</span><span> 100
</span><span> 101
</span><span> 102
</span><span> 103
</span><span> 104
</span><span> 105
</span><span> 106
</span><span> 107
</span><span> 108
</span><span> 109
</span><span> 110
</span><span> 111
</span><span> 112
</span><span> 113
</span><span> 114
</span><span> 115
</span><span> 116
</span><span> 117
</span><span> 118
</span><span> 119
</span><span> 120
</span><span> 121
</span><span> 122
</span><span> 123
</span><span> 124
</span><span> 125
</span><span> 126
</span><span> 127
</span><span> 128
</span><span> 129
</span><span> 130
</span><span> 131
</span><span> 132
</span><span> 133
</span><span> 134
</span><span> 135
</span><span> 136
</span><span> 137
</span><span> 138
</span><span> 139
</span><span> 140
</span><span> 141
</span><span> 142
</span><span> 143
</span><span> 144
</span><span> 145
</span><span> 146
</span><span> 147
</span><span> 148
</span><span> 149
</span><span> 150
</span><span> 151
</span><span> 152
</span><span> 153
</span><span> 154
</span><span> 155
</span><span> 156
</span><span> 157
</span><span> 158
</span><span> 159
</span><span> 160
</span><span> 161
</span><span> 162
</span><span> 163
</span><span> 164
</span><span> 165
</span><span> 166
</span><span> 167
</span><span> 168
</span><span> 169
</span><span> 170
</span><span> 171
</span><span> 172
</span><span> 173
</span><span> 174
</span><span> 175
</span><span> 176
</span><span> 177
</span><span> 178
</span><span> 179
</span><span> 180
</span><span> 181
</span><span> 182
</span><span> 183
</span><span> 184
</span><span> 185
</span><span> 186
</span><span> 187
</span><span> 188
</span><span> 189
</span><span> 190
</span><span> 191
</span><span> 192
</span><span> 193
</span><span> 194
</span><span> 195
</span><span> 196
</span><span> 197
</span><span> 198
</span><span> 199
</span><span> 200
</span><span> 201
</span><span> 202
</span><span> 203
</span><span> 204
</span><span> 205
</span><span> 206
</span><span> 207
</span><span> 208
</span><span> 209
</span><span> 210
</span><span> 211
</span><span> 212
</span><span> 213
</span><span> 214
</span><span> 215
</span><span> 216
</span><span> 217
</span><span> 218
</span><span> 219
</span><span> 220
</span><span> 221
</span><span> 222
</span><span> 223
</span><span> 224
</span><span> 225
</span><span> 226
</span><span> 227
</span><span> 228
</span><span> 229
</span><span> 230
</span><span> 231
</span><span> 232
</span><span> 233
</span><span> 234
</span><span> 235
</span><span> 236
</span><span> 237
</span><span> 238
</span><span> 239
</span><span> 240
</span><span> 241
</span><span> 242
</span><span> 243
</span><span> 244
</span><span> 245
</span><span> 246
</span><span> 247
</span><span> 248
</span><span> 249
</span><span> 250
</span><span> 251
</span><span> 252
</span><span> 253
</span><span> 254
</span><span> 255
</span><span> 256
</span><span> 257
</span><span> 258
</span><span> 259
</span><span> 260
</span><span> 261
</span><span> 262
</span><span> 263
</span><span> 264
</span><span> 265
</span><span> 266
</span><span> 267
</span><span> 268
</span><span> 269
</span><span> 270
</span><span> 271
</span><span> 272
</span><span> 273
</span><span> 274
</span><span> 275
</span><span> 276
</span><span> 277
</span><span> 278
</span><span> 279
</span><span> 280
</span><span> 281
</span><span> 282
</span><span> 283
</span><span> 284
</span><span> 285
</span><span> 286
</span><span> 287
</span><span> 288
</span><span> 289
</span><span> 290
</span><span> 291
</span><span> 292
</span><span> 293
</span><span> 294
</span><span> 295
</span><span> 296
</span><span> 297
</span><span> 298
</span><span> 299
</span><span> 300
</span><span> 301
</span><span> 302
</span><span> 303
</span><span> 304
</span><span> 305
</span><span> 306
</span><span> 307
</span><span> 308
</span><span> 309
</span><span> 310
</span><span> 311
</span><span> 312
</span><span> 313
</span><span> 314
</span><span> 315
</span><span> 316
</span><span> 317
</span><span> 318
</span><span> 319
</span><span> 320
</span><span> 321
</span><span> 322
</span><span> 323
</span><span> 324
</span><span> 325
</span><span> 326
</span><span> 327
</span><span> 328
</span><span> 329
</span><span> 330
</span><span> 331
</span><span> 332
</span><span> 333
</span><span> 334
</span><span> 335
</span><span> 336
</span><span> 337
</span><span> 338
</span><span> 339
</span><span> 340
</span><span> 341
</span><span> 342
</span><span> 343
</span><span> 344
</span><span> 345
</span><span> 346
</span><span> 347
</span><span> 348
</span><span> 349
</span><span> 350
</span><span> 351
</span><span> 352
</span><span> 353
</span><span> 354
</span><span> 355
</span><span> 356
</span><span> 357
</span><span> 358
</span><span> 359
</span><span> 360
</span><span> 361
</span><span> 362
</span><span> 363
</span><span> 364
</span><span> 365
</span><span> 366
</span><span> 367
</span><span> 368
</span><span> 369
</span><span> 370
</span><span> 371
</span><span> 372
</span><span> 373
</span><span> 374
</span><span> 375
</span><span> 376
</span><span> 377
</span><span> 378
</span><span> 379
</span><span> 380
</span><span> 381
</span><span> 382
</span><span> 383
</span><span> 384
</span><span> 385
</span><span> 386
</span><span> 387
</span><span> 388
</span><span> 389
</span><span> 390
</span><span> 391
</span><span> 392
</span><span> 393
</span><span> 394
</span><span> 395
</span><span> 396
</span><span> 397
</span><span> 398
</span><span> 399
</span><span> 400
</span><span> 401
</span><span> 402
</span><span> 403
</span><span> 404
</span><span> 405
</span><span> 406
</span><span> 407
</span><span> 408
</span><span> 409
</span><span> 410
</span><span> 411
</span><span> 412
</span><span> 413
</span><span> 414
</span><span> 415
</span><span> 416
</span><span> 417
</span><span> 418
</span><span> 419
</span><span> 420
</span><span> 421
</span><span> 422
</span><span> 423
</span><span> 424
</span><span> 425
</span><span> 426
</span><span> 427
</span><span> 428
</span><span> 429
</span><span> 430
</span><span> 431
</span><span> 432
</span><span> 433
</span><span> 434
</span><span> 435
</span><span> 436
</span><span> 437
</span><span> 438
</span><span> 439
</span><span> 440
</span><span> 441
</span><span> 442
</span><span> 443
</span><span> 444
</span><span> 445
</span><span> 446
</span><span> 447
</span><span> 448
</span><span> 449
</span><span> 450
</span><span> 451
</span><span> 452
</span><span> 453
</span><span> 454
</span><span> 455
</span><span> 456
</span><span> 457
</span><span> 458
</span><span> 459
</span><span> 460
</span><span> 461
</span><span> 462
</span><span> 463
</span><span> 464
</span><span> 465
</span><span> 466
</span><span> 467
</span><span> 468
</span><span> 469
</span><span> 470
</span><span> 471
</span><span> 472
</span><span> 473
</span><span> 474
</span><span> 475
</span><span> 476
</span><span> 477
</span><span> 478
</span><span> 479
</span><span> 480
</span><span> 481
</span><span> 482
</span><span> 483
</span><span> 484
</span><span> 485
</span><span> 486
</span><span> 487
</span><span> 488
</span><span> 489
</span><span> 490
</span><span> 491
</span><span> 492
</span><span> 493
</span><span> 494
</span><span> 495
</span><span> 496
</span><span> 497
</span><span> 498
</span><span> 499
</span><span> 500
</span><span> 501
</span><span> 502
</span><span> 503
</span><span> 504
</span><span> 505
</span><span> 506
</span><span> 507
</span><span> 508
</span><span> 509
</span><span> 510
</span><span> 511
</span><span> 512
</span><span> 513
</span><span> 514
</span><span> 515
</span><span> 516
</span><span> 517
</span><span> 518
</span><span> 519
</span><span> 520
</span><span> 521
</span><span> 522
</span><span> 523
</span><span> 524
</span><span> 525
</span><span> 526
</span><span> 527
</span><span> 528
</span><span> 529
</span><span> 530
</span><span> 531
</span><span> 532
</span><span> 533
</span><span> 534
</span><span> 535
</span><span> 536
</span><span> 537
</span><span> 538
</span><span> 539
</span><span> 540
</span><span> 541
</span><span> 542
</span><span> 543
</span><span> 544
</span><span> 545
</span><span> 546
</span><span> 547
</span><span> 548
</span><span> 549
</span><span> 550
</span><span> 551
</span><span> 552
</span><span> 553
</span><span> 554
</span><span> 555
</span><span> 556
</span><span> 557
</span><span> 558
</span><span> 559
</span><span> 560
</span><span> 561
</span><span> 562
</span><span> 563
</span><span> 564
</span><span> 565
</span><span> 566
</span><span> 567
</span><span> 568
</span><span> 569
</span><span> 570
</span><span> 571
</span><span> 572
</span><span> 573
</span><span> 574
</span><span> 575
</span><span> 576
</span><span> 577
</span><span> 578
</span><span> 579
</span><span> 580
</span><span> 581
</span><span> 582
</span><span> 583
</span><span> 584
</span><span> 585
</span><span> 586
</span><span> 587
</span><span> 588
</span><span> 589
</span><span> 590
</span><span> 591
</span><span> 592
</span><span> 593
</span><span> 594
</span><span> 595
</span><span> 596
</span><span> 597
</span><span> 598
</span><span> 599
</span><span> 600
</span><span> 601
</span><span> 602
</span><span> 603
</span><span> 604
</span><span> 605
</span><span> 606
</span><span> 607
</span><span> 608
</span><span> 609
</span><span> 610
</span><span> 611
</span><span> 612
</span><span> 613
</span><span> 614
</span><span> 615
</span><span> 616
</span><span> 617
</span><span> 618
</span><span> 619
</span><span> 620
</span><span> 621
</span><span> 622
</span><span> 623
</span><span> 624
</span><span> 625
</span><span> 626
</span><span> 627
</span><span> 628
</span><span> 629
</span><span> 630
</span><span> 631
</span><span> 632
</span><span> 633
</span><span> 634
</span><span> 635
</span><span> 636
</span><span> 637
</span><span> 638
</span><span> 639
</span><span> 640
</span><span> 641
</span><span> 642
</span><span> 643
</span><span> 644
</span><span> 645
</span><span> 646
</span><span> 647
</span><span> 648
</span><span> 649
</span><span> 650
</span><span> 651
</span><span> 652
</span><span> 653
</span><span> 654
</span><span> 655
</span><span> 656
</span><span> 657
</span><span> 658
</span><span> 659
</span><span> 660
</span><span> 661
</span><span> 662
</span><span> 663
</span><span> 664
</span><span> 665
</span><span> 666
</span><span> 667
</span><span> 668
</span><span> 669
</span><span> 670
</span><span> 671
</span><span> 672
</span><span> 673
</span><span> 674
</span><span> 675
</span><span> 676
</span><span> 677
</span><span> 678
</span><span> 679
</span><span> 680
</span><span> 681
</span><span> 682
</span><span> 683
</span><span> 684
</span><span> 685
</span><span> 686
</span><span> 687
</span><span> 688
</span><span> 689
</span><span> 690
</span><span> 691
</span><span> 692
</span><span> 693
</span><span> 694
</span><span> 695
</span><span> 696
</span><span> 697
</span><span> 698
</span><span> 699
</span><span> 700
</span><span> 701
</span><span> 702
</span><span> 703
</span><span> 704
</span><span> 705
</span><span> 706
</span><span> 707
</span><span> 708
</span><span> 709
</span><span> 710
</span><span> 711
</span><span> 712
</span><span> 713
</span><span> 714
</span><span> 715
</span><span> 716
</span><span> 717
</span><span> 718
</span><span> 719
</span><span> 720
</span><span> 721
</span><span> 722
</span><span> 723
</span><span> 724
</span><span> 725
</span><span> 726
</span><span> 727
</span><span> 728
</span><span> 729
</span><span> 730
</span><span> 731
</span><span> 732
</span><span> 733
</span><span> 734
</span><span> 735
</span><span> 736
</span><span> 737
</span><span> 738
</span><span> 739
</span><span> 740
</span><span> 741
</span><span> 742
</span><span> 743
</span><span> 744
</span><span> 745
</span><span> 746
</span><span> 747
</span><span> 748
</span><span> 749
</span><span> 750
</span><span> 751
</span><span> 752
</span><span> 753
</span><span> 754
</span><span> 755
</span><span> 756
</span><span> 757
</span><span> 758
</span><span> 759
</span><span> 760
</span><span> 761
</span><span> 762
</span><span> 763
</span><span> 764
</span><span> 765
</span><span> 766
</span><span> 767
</span><span> 768
</span><span> 769
</span><span> 770
</span><span> 771
</span><span> 772
</span><span> 773
</span><span> 774
</span><span> 775
</span><span> 776
</span><span> 777
</span><span> 778
</span><span> 779
</span><span> 780
</span><span> 781
</span><span> 782
</span><span> 783
</span><span> 784
</span><span> 785
</span><span> 786
</span><span> 787
</span><span> 788
</span><span> 789
</span><span> 790
</span><span> 791
</span><span> 792
</span><span> 793
</span><span> 794
</span><span> 795
</span><span> 796
</span><span> 797
</span><span> 798
</span><span> 799
</span><span> 800
</span><span> 801
</span><span> 802
</span><span> 803
</span><span> 804
</span><span> 805
</span><span> 806
</span><span> 807
</span><span> 808
</span><span> 809
</span><span> 810
</span><span> 811
</span><span> 812
</span><span> 813
</span><span> 814
</span><span> 815
</span><span> 816
</span><span> 817
</span><span> 818
</span><span> 819
</span><span> 820
</span><span> 821
</span><span> 822
</span><span> 823
</span><span> 824
</span><span> 825
</span><span> 826
</span><span> 827
</span><span> 828
</span><span> 829
</span><span> 830
</span><span> 831
</span><span> 832
</span><span> 833
</span><span> 834
</span><span> 835
</span><span> 836
</span><span> 837
</span><span> 838
</span><span> 839
</span><span> 840
</span><span> 841
</span><span> 842
</span><span> 843
</span><span> 844
</span><span> 845
</span><span> 846
</span><span> 847
</span><span> 848
</span><span> 849
</span><span> 850
</span><span> 851
</span><span> 852
</span><span> 853
</span><span> 854
</span><span> 855
</span><span> 856
</span><span> 857
</span><span> 858
</span><span> 859
</span><span> 860
</span><span> 861
</span><span> 862
</span><span> 863
</span><span> 864
</span><span> 865
</span><span> 866
</span><span> 867
</span><span> 868
</span><span> 869
</span><span> 870
</span><span> 871
</span><span> 872
</span><span> 873
</span><span> 874
</span><span> 875
</span><span> 876
</span><span> 877
</span><span> 878
</span><span> 879
</span><span> 880
</span><span> 881
</span><span> 882
</span><span> 883
</span><span> 884
</span><span> 885
</span><span> 886
</span><span> 887
</span><span> 888
</span><span> 889
</span><span> 890
</span><span> 891
</span><span> 892
</span><span> 893
</span><span> 894
</span><span> 895
</span><span> 896
</span><span> 897
</span><span> 898
</span><span> 899
</span><span> 900
</span><span> 901
</span><span> 902
</span><span> 903
</span><span> 904
</span><span> 905
</span><span> 906
</span><span> 907
</span><span> 908
</span><span> 909
</span><span> 910
</span><span> 911
</span><span> 912
</span><span> 913
</span><span> 914
</span><span> 915
</span><span> 916
</span><span> 917
</span><span> 918
</span><span> 919
</span><span> 920
</span><span> 921
</span><span> 922
</span><span> 923
</span><span> 924
</span><span> 925
</span><span> 926
</span><span> 927
</span><span> 928
</span><span> 929
</span><span> 930
</span><span> 931
</span><span> 932
</span><span> 933
</span><span> 934
</span><span> 935
</span><span> 936
</span><span> 937
</span><span> 938
</span><span> 939
</span><span> 940
</span><span> 941
</span><span> 942
</span><span> 943
</span><span> 944
</span><span> 945
</span><span> 946
</span><span> 947
</span><span> 948
</span><span> 949
</span><span> 950
</span><span> 951
</span><span> 952
</span><span> 953
</span><span> 954
</span><span> 955
</span><span> 956
</span><span> 957
</span><span> 958
</span><span> 959
</span><span> 960
</span><span> 961
</span><span> 962
</span><span> 963
</span><span> 964
</span><span> 965
</span><span> 966
</span><span> 967
</span><span> 968
</span><span> 969
</span><span> 970
</span><span> 971
</span><span> 972
</span><span> 973
</span><span> 974
</span><span> 975
</span><span> 976
</span><span> 977
</span><span> 978
</span><span> 979
</span><span> 980
</span><span> 981
</span><span> 982
</span><span> 983
</span><span> 984
</span><span> 985
</span><span> 986
</span><span> 987
</span><span> 988
</span><span> 989
</span><span> 990
</span><span> 991
</span><span> 992
</span><span> 993
</span><span> 994
</span><span> 995
</span><span> 996
</span><span> 997
</span><span> 998
</span><span> 999
</span><span>1000
</span><span>1001
</span><span>1002
</span><span>1003
</span><span>1004
</span><span>1005
</span><span>1006
</span><span>1007
</span><span>1008
</span><span>1009
</span><span>1010
</span></code></pre></td>
<td>
<pre><code data-lang="ruby"><span># Every file should have a "typed sigil" that tells Sorbet how strict to be</span>
<span># during static type checking.</span>
<span>#</span>
<span># Strictness levels (lax to strict):</span>
<span>#</span>
<span># ignore: Sorbet won't even read the file.  This means its contents are not</span>
<span># visible during type checking.  Avoid this.</span>
<span>#</span>
<span># false: Sorbet will only report errors related to constant resolution.  This</span>
<span># is the default if no sigil is included.</span>
<span>#</span>
<span># true: Sorbet will report all static type errors.  This is the sweet spot of</span>
<span># safety for effort.</span>
<span>#</span>
<span># strict: Sorbet will require that all methods, constants, and instance</span>
<span># variables have static types.</span>
<span>#</span>
<span># strong: Sorbet will no longer allow anything to be T.untyped, even</span>
<span># explicitly.  Almost nothing satisfies this.</span>

<span># typed: true</span>

<span># Include the runtime type-checking library.  This lets you write inline sigs</span>
<span># and have them checked at runtime (instead of running Sorbet as RBI-only).</span>
<span># These runtime checks happen even for files with `ignore` or `false` sigils.</span>
<span>require</span> <span>'sorbet-runtime'</span>

<span>class</span> <span>BasicSigs</span>
  <span># Bring in the type definition helpers.  You'll almost always need this.</span>
  <span>extend</span> <span>T</span><span>::</span><span>Sig</span>

  <span># Sigs are defined with `sig` and a block.  Define the return value type with</span>
  <span># `returns`.</span>
  <span>#</span>
  <span># This method returns a value whose class is `String`.  These are the most</span>
  <span># common types, and Sorbet calls them "class types".</span>
  <span>sig</span> <span>{</span> <span>returns</span><span>(</span><span>String</span><span>)</span> <span>}</span>
  <span>def</span> <span>greet</span>
    <span>'Hello, World!'</span>
  <span>end</span>

  <span># Define parameter value types with `params`.</span>
  <span>sig</span> <span>{</span> <span>params</span><span>(</span><span>n</span><span>:</span> <span>Integer</span><span>)</span><span>.</span><span>returns</span><span>(</span><span>String</span><span>)</span> <span>}</span>
  <span>def</span> <span>greet_repeat</span><span>(</span><span>n</span><span>)</span>
    <span>(</span><span>1</span><span>..</span><span>n</span><span>)</span><span>.</span><span>map</span> <span>{</span> <span>greet</span> <span>}</span><span>.</span><span>join</span><span>(</span><span>"</span><span>\n</span><span>"</span><span>)</span>
  <span>end</span>

  <span># Define keyword parameters the same way.</span>
  <span>sig</span> <span>{</span> <span>params</span><span>(</span><span>n</span><span>:</span> <span>Integer</span><span>,</span> <span>sep</span><span>:</span> <span>String</span><span>)</span><span>.</span><span>returns</span><span>(</span><span>String</span><span>)</span> <span>}</span>
  <span>def</span> <span>greet_repeat_2</span><span>(</span><span>n</span><span>,</span> <span>sep</span><span>:</span> <span>"</span><span>\n</span><span>"</span><span>)</span>
    <span>(</span><span>1</span><span>..</span><span>n</span><span>)</span><span>.</span><span>map</span> <span>{</span> <span>greet</span> <span>}</span><span>.</span><span>join</span><span>(</span><span>sep</span><span>)</span>
  <span>end</span>

  <span># Notice that positional/keyword and required/optional make no difference</span>
  <span># here.  They're all defined the same way in `params`.</span>

  <span># For lots of parameters, it's nicer to use do..end and a multiline block</span>
  <span># instead of curly braces.</span>
  <span>sig</span> <span>do</span>
    <span>params</span><span>(</span>
      <span>str</span><span>:</span> <span>String</span><span>,</span>
      <span>num</span><span>:</span> <span>Integer</span><span>,</span>
      <span>sym</span><span>:</span> <span>Symbol</span><span>,</span>
    <span>)</span><span>.</span><span>returns</span><span>(</span><span>String</span><span>)</span>
  <span>end</span>
  <span>def</span> <span>uhh</span><span>(</span><span>str</span><span>:,</span> <span>num</span><span>:,</span> <span>sym</span><span>:)</span>
    <span>'What would you even do with these?'</span>
  <span>end</span>

  <span># For a method whose return value is useless, use `void`.</span>
  <span>sig</span> <span>{</span> <span>params</span><span>(</span><span>name</span><span>:</span> <span>String</span><span>)</span><span>.</span><span>void</span> <span>}</span>
  <span>def</span> <span>say_hello</span><span>(</span><span>name</span><span>)</span>
    <span>puts</span> <span>"Hello, </span><span>#{</span><span>name</span><span>}</span><span>!"</span>
  <span>end</span>

  <span># Splats! Also known as "rest parameters", "*args", "**kwargs", and others.</span>
  <span>#</span>
  <span># Type the value that a _member_ of `args` or `kwargs` will have, not `args`</span>
  <span># or `kwargs` itself.</span>
  <span>sig</span> <span>{</span> <span>params</span><span>(</span><span>args</span><span>:</span> <span>Integer</span><span>,</span> <span>kwargs</span><span>:</span> <span>String</span><span>)</span><span>.</span><span>void</span> <span>}</span>
  <span>def</span> <span>no_op</span><span>(</span><span>*</span><span>args</span><span>,</span> <span>**</span><span>kwargs</span><span>)</span>
    <span>if</span> <span>kwargs</span><span>[</span><span>:op</span><span>]</span> <span>==</span> <span>'minus'</span>
      <span>args</span><span>.</span><span>each</span> <span>{</span> <span>|</span><span>i</span><span>|</span> <span>puts</span><span>(</span><span>i</span> <span>-</span> <span>1</span><span>)</span> <span>}</span>
    <span>else</span>
      <span>args</span><span>.</span><span>each</span> <span>{</span> <span>|</span><span>i</span><span>|</span> <span>puts</span><span>(</span><span>i</span> <span>+</span> <span>1</span><span>)</span> <span>}</span>
    <span>end</span>
  <span>end</span>

  <span># Most initializers should be `void`.</span>
  <span>sig</span> <span>{</span> <span>params</span><span>(</span><span>name</span><span>:</span> <span>String</span><span>)</span><span>.</span><span>void</span> <span>}</span>
  <span>def</span> <span>initialize</span><span>(</span><span>name</span><span>:)</span>
    <span># Instance variables must have annotated types to participate in static</span>
    <span># type checking.</span>

    <span># The value in `T.let` is checked statically and at runtime.</span>
    <span>@upname</span> <span>=</span> <span>T</span><span>.</span><span>let</span><span>(</span><span>name</span><span>.</span><span>upcase</span><span>,</span> <span>String</span><span>)</span>

    <span># Sorbet can infer this one!</span>
    <span>@name</span> <span>=</span> <span>name</span>
  <span>end</span>

  <span># Constants also need annotated types.</span>
  <span>SORBET</span> <span>=</span> <span>T</span><span>.</span><span>let</span><span>(</span><span>'A delicious frozen treat'</span><span>,</span> <span>String</span><span>)</span>

  <span># Class variables too.</span>
  <span>@@the_answer</span> <span>=</span> <span>T</span><span>.</span><span>let</span><span>(</span><span>42</span><span>,</span> <span>Integer</span><span>)</span>

  <span># Sorbet knows about the `attr_*` family.</span>
  <span>sig</span> <span>{</span> <span>returns</span><span>(</span><span>String</span><span>)</span> <span>}</span>
  <span>attr_reader</span> <span>:upname</span>

  <span>sig</span> <span>{</span> <span>params</span><span>(</span><span>write_only</span><span>:</span> <span>Integer</span><span>)</span><span>.</span><span>returns</span><span>(</span><span>Integer</span><span>)</span> <span>}</span>
  <span>attr_writer</span> <span>:write_only</span>

  <span># You say the reader part and Sorbet will say the writer part.</span>
  <span>sig</span> <span>{</span> <span>returns</span><span>(</span><span>String</span><span>)</span> <span>}</span>
  <span>attr_accessor</span> <span>:name</span>
<span>end</span>

<span>module</span> <span>Debugging</span>
  <span>extend</span> <span>T</span><span>::</span><span>Sig</span>

  <span># Sometimes it's helpful to know what type Sorbet has inferred for an</span>
  <span># expression.  Use `T.reveal_type` to make type-checking show a special error</span>
  <span># with that information.</span>
  <span>#</span>
  <span># This is most useful if you have Sorbet integrated into your editor so you</span>
  <span># can see the result as soon as you save the file.</span>

  <span>sig</span> <span>{</span> <span>params</span><span>(</span><span>obj</span><span>:</span> <span>Object</span><span>)</span><span>.</span><span>returns</span><span>(</span><span>String</span><span>)</span> <span>}</span>
  <span>def</span> <span>debug</span><span>(</span><span>obj</span><span>)</span>
    <span>T</span><span>.</span><span>reveal_type</span><span>(</span><span>obj</span><span>)</span> <span># Revealed type: Object</span>
    <span>repr</span> <span>=</span> <span>obj</span><span>.</span><span>inspect</span>

    <span># Reminder that Ruby methods can be called without arguments, so you can</span>
    <span># save a couple characters!</span>
    <span>T</span><span>.</span><span>reveal_type</span> <span>repr</span> <span># Revealed type: String</span>

    <span>"DEBUG: "</span> <span>+</span> <span>repr</span>
  <span>end</span>
<span>end</span>

<span>module</span> <span>StandardLibrary</span>
  <span>extend</span> <span>T</span><span>::</span><span>Sig</span>
  <span># Sorbet provides some helpers for typing the Ruby standard library.</span>

  <span># Use T::Boolean to catch both `true` and `false`.</span>
  <span>#</span>
  <span># For the …</span></code></pre></td></tr></tbody></table></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jdkaplan.dev/blog/learn-sorbet-in-y-minutes/">https://jdkaplan.dev/blog/learn-sorbet-in-y-minutes/</a></em></p>]]>
            </description>
            <link>https://jdkaplan.dev/blog/learn-sorbet-in-y-minutes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25447883</guid>
            <pubDate>Wed, 16 Dec 2020 20:11:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Preview in macOS Big Sur is destroying PDFs]]>
            </title>
            <description>
<![CDATA[
Score 346 | Comments 296 (<a href="https://news.ycombinator.com/item?id=25447830">thread link</a>) | @matrixagent
<br/>
December 16, 2020 | https://annoying.technology/posts/86f4ea27e4cd90d0/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/86f4ea27e4cd90d0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/35f98c21da204421e81bcfcb709f0b9a2563fde5/a3843/media/previeweatingpdfs.png"></p><p>This <a href="https://annoying.technology/media/previeweatingpdfs.png">image</a> has three components: On the left is an OCR’ed PDF from my ScanSnap iX500. I have selected most of the text, and on the right side you can see two copy&amp;paste results. In the upper half is the result directly after scanning, right after the bundled ABBYY FineReader that comes with the iX500 did its magic. In the lower half is the result <strong>after</strong> modifying (removed a blank page) and saving that same PDF in <em>Preview</em>.</p><p>Hard to believe, but that’s <a href="https://discourse.devontechnologies.com/t/odd-pdf-behavior/21400">not</a> <a href="http://www.documentsnap.com/ocr-text-macos-sierra-preview/">the</a> <a href="https://discussions.apple.com/thread/8010687">first</a> time Apple <a href="https://mjtsai.com/blog/2016/12/21/more-macos-preview-pdf-trouble/">messed this up</a>. Sure, even Apple can’t account for all use cases when changing complex stuff like internal PDF handling. But:</p><ul><li>The iX500 is an insanely popular and common scanner</li><li>I don’t know any OCR software that is more popular than ABBYY FineReader</li><li>macOS used to be the absolute best in class OS for dealing with PDFs by a <strong>long</strong> shot</li><li>IT HAPPENED BEFORE</li></ul><p>I wish Apple was still charging for OS updates, so I could at least refund it.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> This is such a nasty bug – if you don’t already know to expect it, you will only find out months or possibly years later. I almost missed it this time, because even after modifying and saving the file it’s still not happening. You have to completely close the file and reopen it, only then will you realize that it has been destroyed.</p><section role="doc-endnotes"><hr><ol><li id="fn:1" role="doc-endnote"><p>Yes, I blame only Apple for this. I’ll repeat what I told Philipp (noted Apple apologist!) when we argued about this last week after I discovered the problem: ABBYY says they don’t support Big Sur yet, that’s fine. But Apple didn’t tell me that I can’t upgrade to Big Sur when I use ABBYY. I’d be a lot less angry if there was a changelog or release notes <em>from Apple</em> where it says there is a known problem with OCR’ed PDFs in Preview. <em>Their</em> software is broken, <em>they</em> need to tell me. I don’t care if it only worked because they had workarounds for super shitty PDFs that ABBYY possibly produces, I just need my OS to keep working for me. This bug could hit me without even owning a scanner at all – someone sending me a PDF that I then unknowingly break before archiving it. That’s the part I’m mad about. <a href="#fnref:1" role="doc-backlink">↩︎</a></p></li></ol></section></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/86f4ea27e4cd90d0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25447830</guid>
            <pubDate>Wed, 16 Dec 2020 20:07:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When Google’s Artificial Intelligence Goes Homophobic]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25447655">thread link</a>) | @freshfruitmag
<br/>
December 16, 2020 | https://freshfruitmag.com/when-googles-artificial-intelligence-goes-homophobic/ | <a href="https://web.archive.org/web/*/https://freshfruitmag.com/when-googles-artificial-intelligence-goes-homophobic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://freshfruitmag.com/when-googles-artificial-intelligence-goes-homophobic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25447655</guid>
            <pubDate>Wed, 16 Dec 2020 19:53:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IoT Security at Home]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25447481">thread link</a>) | @henrikwm
<br/>
December 16, 2020 | https://security.christmas/2020/16 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/16">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="main-content"><article><img src="https://i.ibb.co/KzGcFd9/yoonjae-baik-p7-Ms-AMLSbb-U-unsplash.jpg?w=1226&amp;h=400&amp;fit=crop&amp;crop=edges" alt=""><div><section><p>What is the state of your IoT (Internet of Things)-security in your home? Do you have any gadgets on your network that are vulnerable to exploitation? Maybe you have any devices you do not recognize? If you own an IoT-device then you should be curious about how it talks to the Internet and how security is taken care of.</p>
</section><article><section><p>We've all heard the horror stories. Whether it's <a href="https://www.nbcnews.com/news/us-news/stranger-hacks-baby-monitor-tells-child-i-love-you-n1090046">hacked baby monitors</a> or <a href="https://www.theguardian.com/technology/2017/nov/14/retailers-urged-to-withdraw-toys-that-allow-hackers-to-talk-to-children%20">talking toys</a>, <a href="https://auth0.com/blog/surprised-turns-out-consumers-dont-trust-iot-security/%20">consumers and developers seem to agree</a> on one thing; <em>don’t trust your IoT-devices</em>. This article tries to explain common security flaws with IoT-devices and includes a comprehensive "do-it-yourself" guide on how you can minimize the security threat.</p>
<p>Before we dive into the guide, what is an IoT-device and what security concerns should we be aware of?</p>
<h2>IoT-devices in your home</h2>
<p>The Internet of things promises us connected devices in your home talking to each other and the Internet. The connectivity enables your printer, fridge, vacuum cleaning robot or floor-heaters to be automated while you are on-the-go and not at home. Maybe even more efficient home-management. But should we put our trust into the vendor of our IoT coffe-machine that they won't leak our data, won't get hacked and has privacy and GDPR as their core focus? What priorities do these vendors have and how does that affect us?  </p>
<h2>Security concerns</h2>
<p><strong>Default / Weak passwords</strong></p>
<p>"Box fresh" devices often have a default password. If your device has a weak or easy to guess password then it will be susceptible to guessing attacks. Default passwords are <a href="https://www.routerpasswords.com/">easily obtained from the Internet</a></p>
<p><strong>Missing security updates</strong></p>
<p>IoT-devices are often built on pre-existing technologies such as the Linux operating system or using HTTP services such as Apache or NGINX. Over time, flaws are discovered in all software products which should be addressed. Failure to update against known vulnerabilities in supporting software will increase the chances of a remote attacker being able to compromise the device.</p>
<p><strong>Insecure web administration</strong></p>
<p>Some devices offer some form of web application to provision and administer the device. These interfaces are vulnerable to the same risks as enterprise applications or Internet sites. </p>
<p><strong>Use of insecure protocols</strong></p>
<p>An insecure protocol includes (but is not limited to): ftp, telnet, http or SNMP. The protocol is said to be insecure if it employs no transport layer encryption or has known security weaknesses. Those listed all fall into the first category. </p>
<p>It is common to offer administration functions over most of the listed protocols. The impact of using insecure protocols is that an attacker on the same network would be able to conduct a man-in-the-middle (MiTM) exploitation to compromise the device.</p>
<p><strong>Bad configuration</strong></p>
<p>All networked services are potential avenues for an attacker to target your device. A vulnerability assessment of these networked services would uncover known flaws. Most likely your device is powered by an embedded operating system. To gain defence in depth review the operating system for configuration weaknesses such as: processes with elevated privileges, file permissions etc. </p>
<p><strong>Insecure data storage</strong></p>
<p>If your device can store data locally then you need to be aware of the risks of doing so. Are your controls robust enough to prevent trivial retrieval of sensitive information? Do you use some form of encryption to protect data while the device is powered off?</p>
<h2>"Do-it-yourself" security checklist</h2>
<ul>
<li>
<p><strong>Change default passwords:</strong> </p>
<p>Refer to the manual, do an online search, or contact the manufacturer for advice.</p>
</li>
<li>
<p><strong>Check for firmware and system updates:</strong> </p>
<p>Even a brand new device could need a security update. Refer to the manual, do an online search, or contact the manufacturer for advice.</p>
</li>
<li>
<p><strong>Apply updates regularly:</strong></p>
<p>Manufacturers patch bugs and flaws on an ongoing basis – and so should you.Sign up for automatic updates or software update alerts when possible.</p>
</li>
<li>
<p><strong>Set up a guest WiFi network for IoT-devices to connect to:</strong></p>
<p>Isolate your IoT-devices from your home computers to reduce risk to important data. If you need advice, start with an online search for your WiFi router model. Many devices make it easy to set up a guest network.</p>
</li>
<li>
<p><strong>Disable Universal Plug-and-Play (UPnP) functionality:</strong></p>
<p>Some IoT-devices can leave your home firewall vulnerable to attack via UPnP. Unless you specifically need it for an IoT-device, turn off UPnP. An online search can help you find advice for your specific model.</p>
</li>
<li>
<p><strong>Google <em>{name of the device}</em> + CVE:</strong></p>
<p>You should see if there exists one or more <a href="https://www.cvedetails.com/">Common Vulnerabilities and Exposures (CVE) </a> for your device. If there is, see if the manufacturer of your device has patched the CVE in one of the software updates, or consider sending them an email letting them know. If the CVE is serious, you should consider turning your IoT off until there is a fix available. </p>
</li>
<li>
<p><strong>Check for open ports:</strong></p>
<p><a href="https://gist.github.com/rsperl/321aac3d529aa8f8c7924fd12d581b67">Nmap-cheatsheet</a></p>
<p>First obtain the IP-address of your device. This can be done by looking for "connected devices" on your router or do a network scan with <a href="https://nmap.org/">nmap</a>.</p>
<ul>
<li>Does your device expose any ports? </li>
<li>What does that port do? (google port + {port number})</li>
<li>Can you connect to your device through the port? For example through your web browser, ftp client, ssh?</li>
<li>Example of a generic scan for performing host discovery on your subnet:</li>
</ul>
<p><code>nmap -sP 192.168.1.0/24</code></p>
<p>Secondly do a full service scan on your device. Grab a cup of coffee, this usually takes some time.</p>
<ul>
<li>Example of a specific scan to find printer's open ports on your subnet:</li>
</ul>
<p><code>nmap -p 515,9100 192.168.1.0/24 -oG - | grep open</code></p>
</li>
</ul></section></article></div></article></main></div></div>]]>
            </description>
            <link>https://security.christmas/2020/16</link>
            <guid isPermaLink="false">hacker-news-small-sites-25447481</guid>
            <pubDate>Wed, 16 Dec 2020 19:42:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Due to unusually high call volumes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25447367">thread link</a>) | @osmode
<br/>
December 16, 2020 | https://omarmetwally.blog/2020/12/16/due-to-unusually-high-call-volumes/ | <a href="https://web.archive.org/web/*/https://omarmetwally.blog/2020/12/16/due-to-unusually-high-call-volumes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><a href="https://omarmetwally.files.wordpress.com/2020/12/clinical_combat_vest.jpg"><img data-attachment-id="2690" data-permalink="https://omarmetwally.blog/2020/12/16/due-to-unusually-high-call-volumes/clinical_combat_vest/#main" data-orig-file="https://omarmetwally.files.wordpress.com/2020/12/clinical_combat_vest.jpg" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1608121966&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="clinical_combat_vest_hi_res" data-image-description="" data-medium-file="https://omarmetwally.files.wordpress.com/2020/12/clinical_combat_vest.jpg?w=225" data-large-file="https://omarmetwally.files.wordpress.com/2020/12/clinical_combat_vest.jpg?w=720" src="https://omarmetwally.files.wordpress.com/2020/12/clinical_combat_vest.jpg?w=768" alt="" srcset="https://omarmetwally.files.wordpress.com/2020/12/clinical_combat_vest.jpg?w=768 768w, https://omarmetwally.files.wordpress.com/2020/12/clinical_combat_vest.jpg?w=1536 1536w, https://omarmetwally.files.wordpress.com/2020/12/clinical_combat_vest.jpg?w=113 113w, https://omarmetwally.files.wordpress.com/2020/12/clinical_combat_vest.jpg?w=225 225w" sizes="(max-width: 768px) 100vw, 768px"></a></figure></div>



<p>The strain of the COVID-19 pandemic on society and healthcare systems turned fine fault lines into gaping canyons. Reflecting on <a href="https://omarmetwally.blog/2015/07/03/if-hospitals-were-run-like-startups/">my writings about U.S. hospitals 5 years ago</a>, I asked myself what had changed and what still must change to rebuild a healthcare system that can deliver medical care wherever and whenever it’s needed. What problems were prevalent in the healthcare system before the pandemic, and how did the pandemic highlight these deficiencies? In my day-to-day work as a doctor, what diverts my time and energy away from the most important and fulfilling aspect of doctoring – patient care?</p>



<p>Direct and effective communication with patients is the most important aspect of healthcare, in my view. A doctor working in the community who is licensed and certified has demonstrated a body of knowledge and skills to provide medical care within a certain scope of practice. Someone with a health concern is arguably not seeking the smartest doctor they can find; they want a doctor with whom they can communicate their concerns, understand their health issue, and make a mutually acceptable treatment plan. In daily practice, I feel that 95% of my time and energy are consumed by tasks that do not relate directly to patient care. Even more unfortunate is the fact that these 95% of tasks are the ones by which doctors are evaluated and compensated: clicking through electronic health records (EHR), wrestling with flawed communication systems (such as hospital phones, pagers, texting, and email) to receive and share information with other members of the healthcare team, answering “queries” from hospital administration for the purpose of billing patients and insurance companies, and wasting life-years trying to wrangle health information systems as mandated by hospital administrators and insurance companies.</p>







<p>1. The world wide web</p>



<p>The pandemic pushed the role of “telemedicine” (healthcare rendered by phone or digitally) into the foreground as a way to deliver healthcare efficiently while reducing the spread of the coronavirus. Regrettably the first and biggest problem with healthcare is internet connectivity and how EHR software sends and receives information between a doctor’s phone/computer and the hospital server. Even in the year 2020, reliable, high-speed internet is a scarce resource in the United States. Most Americans have no choice of internet service provider, if they are lucky to even have access to one.  In a time where human resources are stretched thin and inefficiently used, trying to reach a human in the event of a service interruption can easily waste hours if not days waiting on hold or confined to chatbot purgatory. Many doctors now work remotely to a large extent, if not entirely. Reliable, fast internet is prerequisite to being able to deliver good healthcare. This is especially true because of the nature of EHRs, which use “Virtual Machines” and “Remote Desktops” that require a reliable, low-latency, high-speed internet connection. A client that runs at a snail’s speed and frequently disconnects, requiring 10 minutes to repeat the authentication process before dropping the connection again, is severely detrimental to patient care.</p>



<p>2. Electronic Health Records</p>



<p>EHRs are essentially spreadsheets in fancy packaging. They’re not smart in the sense that a phone is smart; they don’t learn, predict, or automate tasks. In fact software that is slow, requires a lot of clicking and non-intuitive behavior, and which wastes a lot of time with authentication and logging in, is not much better than typing text into the simplest text editor and saving it in a rudimentary database. That is the core of a hospital or clinic’s information system: text and media files saved chronologically and accessible to the right people at the right time. I prefer to type or dictate notes freestyle rather than use templates because it’s faster for me, gives me more control over the document, and helps me communicate my assessment and treatment plan more effectively than relying on a template created by someonen else who may conceptualize a diagnostic process and treatment plan much differently than their peers. An ideal EHR to me would simply be typed into a Unix terminal (for a reader unfamiliar with Unix, imagine a black screen with a flashing white cursor) and piped into a hospital server, which would then use the text to help doctors appreciate the clinical Gestalt or “big picture”: what could harm or kill the patient in the next few hours? And beyond the first 12-24 hours, how to safely discharge the patient? As an EHR user, I don’t want a fancy front-end trickling through a lagging virtual machine; I want a simple, low-latency, text-focused interface and a smart backend, in other words, very simple software that looks dumb but is actually smart. </p>



<p>3. Communication</p>



<p>On top of the pressure of having to synthesize a huge amount of dynamic information to make fast and sound decisions about patient care, doctors are inundated and constantly interrupted by communications from other members of the care team. Doctors work closely with nurses, aids, phlebotomists, lab and radiology technicians, doctors from different specialties, clerks, social workers, insurance companies, and hospital administrators. There is a lot of information constantly moving back and forth in real-time between all parties. This flow of information is often like a waterfall rather than a water faucet – the communications are not prioritized and frequently fail to reach the right person at the right time. There are times when a doctor’s attention should be focused entirely on the task at hand, for example when assessing or speaking with a patient at bedside. This is no time to be interrupted with billing queries or non-urgent questions about other patients’ care. A constant stream of unprioritized and unfocused information can make it extremely difficult to focus on the critical 1% of information which can hurt patients if this information is not processed correctly at the right time. In order to hold people accountable for their decisions, they need to be given a fair chance, with tools that work without draining life out of the users. A page or phone call that may or may not find the intended recipient, and a note left in the EHR saying, “tried to call you but you didn’t answer your phone,” is subjective and not constructive without a way for all parties to track communications from their origin to their destination.</p>



<figure><a href="https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg"><img data-attachment-id="2706" data-permalink="https://omarmetwally.blog/spam_calls/" data-orig-file="https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg" data-orig-size="1242,2081" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1608127938&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="spam_calls" data-image-description="" data-medium-file="https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg?w=179" data-large-file="https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg?w=611" src="https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg?w=611" alt="" srcset="https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg?w=611 611w, https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg?w=1222 1222w, https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg?w=90 90w, https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg?w=179 179w, https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg?w=768 768w" sizes="(max-width: 611px) 100vw, 611px"></a><figcaption>Automated spam calls, a nuisance in daily life, can be harmful to patient care by hindering timely and effective communication</figcaption></figure>



<p>In addition to the right tools, there is a need for sound systems. A doctor’s extensive education and training culminates in a highly specialized set of skills and knowledge. Doctors should take pride and joy in their work; they endured long, grueling training out of a desire to help humanity. Out of training, doctors traditionally became their own bosses, working in community hospitals or private clinics, practicing medicine the way they were taught in a style that becomes their own. Nowadays doctors are managed by administrators who are not doctors. There is a reason why healthcare systems look and function the way they do, an evolutionary end-product of decades of legislative, financial, operational, and societal forces exerting themselves on doctors and hospitals. Back in the day, doctors saw their own patients in their own clinic and treated their patients when they were hospitalized too. This is exceptional nowadays. There was no, “I’m your doctor for today,” or “I’m your doctor this shift, until 8pm.” The reality is that this mode of doctoring has become rare. Having experienced the modern-day flavor of corporate medicine in urban areas and the more traditional model in rural areas, I appreciate the pros and cons of both models. “I’m your doctor, period” can be spoken by a doctor lucky enough to escape corporate medicine, but also a doctor prepared to withstand the stress of not having any personal or protected time away from work. Too many talented doctors nowadays burn out after short-lived clinical careers, depriving patients of the care of great doctors who fell victim to the 95% non-clinical burden on top of the already stressful 5% clinical work.</p>



<p>4. More communication</p>



<p>There is a clear line between “outpatient” and “inpatient” medicine in most doctors’ minds, that is, healthcare delivered in a clinic, where a patient goes to an appointment and returns home, compared to a hospital, where a patient stays overnight. Patients don’t think in terms of “inpatient” and “outpatient.” A patient who wakes in the middle of the night with a fever and shortness of breath, or a patient with a growing breast lump, have concerns that needs to be addressed immediately by someone who actually cares. It sounds obvious, but I could not copy and paste this phrase too many times: by someone who actually cares. Not a voice menu, not a chatbot, not “Due to unusually high call volumes…,” and not a tired, under-paid clerk who is poorly equipped to do their job. A doctor has the knowledge to assess whether a problem is urgent or not urgent, concerning or likely harmless. It’s not fair or realistic to expect patients, lacking specialized knowledge, exposed to the vast informational waste littering cyberspace, biased by personal experience and anxiety about a health condition, to make those calls.</p>



<p>“Due to unusually high call volumes…” has become this year’s mantra. Nearly every call I attempt to place to an insurance company, hospital, or clinic is met with this phrase and indefinite wait times, now nine months since the start of the pandemic.  Most negative feedback about doctors and hospitals relates to what goes on beyond the few minutes a doctor spends interacting directly with the patient: a medical assistant having a bad day, a disorganized clinic, the insurance labyrinth, bills…human …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://omarmetwally.blog/2020/12/16/due-to-unusually-high-call-volumes/">https://omarmetwally.blog/2020/12/16/due-to-unusually-high-call-volumes/</a></em></p>]]>
            </description>
            <link>https://omarmetwally.blog/2020/12/16/due-to-unusually-high-call-volumes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25447367</guid>
            <pubDate>Wed, 16 Dec 2020 19:33:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Killing Our Help Center Improved CSAT and Revenue over 11%]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25446836">thread link</a>) | @tapneal
<br/>
December 16, 2020 | https://solitaired.com/killing-our-help-center-improved-customer-satisfaction-and-revenue | <a href="https://web.archive.org/web/*/https://solitaired.com/killing-our-help-center-improved-customer-satisfaction-and-revenue">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/Helpcenter.png"></center>
<p>Being card game geeks, we run <a href="https://solitaired.com/">our solitaire site</a> as a fun hobby. As we gained some users though over the last year and launched a subscription service to generate some side income, we had to make sure we had reasonable customer support. </p>
<p>It was a no brainer to create a help center because we didnâ€™t want to spend time managing customer support tickets, and having a workflow where users could be self-directed and answer questions on their own was ideal. </p>
<h2 id="whenirealizedihatedhelpcenters">When I realized I hated help centers</h2>
<p>I had an issue with one of our service providers, and went to their site to figure out how to solve the problem. For 30 minutes, I hopped around their own help center with no luck finding the answer to my question. </p>
<p>I then started looking for a support line. After digging through various questions and hitting â€œNo, this did not answer my question,â€� I  found  that it was discontinued and the page redirected me back. </p>
<p>Needless to say, I wasnâ€™t happy. </p>
<p>It made me realize that instinctually, I always want to talk to someone. Whether it be over email, the phone, or chat, knowing that I was getting personalized attention would give me comfort and confidence that my issues will be resolved. </p>
<p>I decided then and there: We will get rid of our help center!</p>
<h2 id="removingourhelpcenterandimprovingourcustomersatisfactionscoreby12">Removing our help center and improving our customer satisfaction score by 12%</h2>
<p>We analyzed where users visited most in our help center. We found that three issues dominated 95% of requests:</p>
<ol>
<li>We had launched a subscription service and users wanted to understand how to cancel. Having run subscription businesses in the past, this wasnâ€™t too surprising. </li>
<li>How to report bugs in the game. Invariably, users came across some fringe bugs, especially for our <a href="https://solitaired.com/freecell">Freecell</a>, <a href="https://solitaired.com/klondike-solitaire">Klondike</a>, and <a href="https://solitaired.com/spider">Spider Solitaire</a> games, and wanted to report it. </li>
<li>Requests for more games. </li>
</ol>
<p>Addressing these questions were relatively simple, and we figured we can spend a few minutes a day responding to anything that came in. </p>
<p>We responded on average within two days and found that our customer satisfaction score (CSAT) improved from 65% to 73%. </p>
<h2 id="improvingcustomersatisfactionanother22">Improving customer satisfaction another 22%.</h2>
<p>We hypothesized that response time played a major role in improving customer satisfaction. </p>
<p>For the next week we decided to respond within 24 hours and we found that CSAT improved from 73% to 78%.</p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/24hours.png"></center>
<p>Realizing that response time makes a difference, we promised and communicated on our site that weâ€™d respond within 2 hours during business hours. CAST went up 82%. </p>
<p>We didnâ€™t want to stop, and we decided to add live chat and respond immediately during business hours. CSAT shot up to 89%!</p>
<h2 id="improvingrevenueby11">Improving revenue by 11%</h2>
<p>As we started responding and talking to our customers, we learned that many users would cancel their subscription because they didnâ€™t know how to access certain games, customization features, and due to some unknown bugs. </p>
<p>Operating a help center only gave users instructions on how to cancel, and did not give us an opportunity to understand why and course correct.</p>
<p>When we started understanding all the reasons our users were canceling, we were able to address this, improving our retention. In the first month, this improved our very modest subscription revenue by 11%. If you compound the impact of retention, it will likely be more over time. </p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/Retention.png"></center>
<h2 id="ourcustomersupportsetuptodayandidealsolutions">Our customer support set up today, and ideal solutions</h2>
<p>Because we run the site for fun, itâ€™s difficult for us to commit to a SLA when someone responds. Today, we just have a simple contact us page. We try to get back within a day generally, but sometimes we miss that and sometimes weâ€™re able to respond earlier depending on competing priorities. </p>
<p>This has taught us though that many consumers want to talk to someone and want a response right away. With that said, some people are totally fine skipping the human interaction. We think an ideal set up is to:</p>
<ol>
<li>Have a help center that covers very simple questions, like how to use certain features. On those pages, there should be an option to quickly talk to a customer service agent. </li>
<li>Have a page on cancellation, but have a CTA talk to someone with a quick response. This will help you understand issues for paying customers and address it</li>
<li>Have a chatbot in lieu of a help center with similar works flow described above. However, set it up in a way where users understand they are talking to a bot, and at any point they can talk to someone</li>
</ol>
<p>Naturally, everyone has resource limitations. If you were to protoize KPIs like revenue, as I imagine you would, find a way to quickly talk to your paying customers or those most likely to pay to support your business goals.</p></div></div></div></div>]]>
            </description>
            <link>https://solitaired.com/killing-our-help-center-improved-customer-satisfaction-and-revenue</link>
            <guid isPermaLink="false">hacker-news-small-sites-25446836</guid>
            <pubDate>Wed, 16 Dec 2020 19:00:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[O'Reilly book about Google Cloud Run released]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25446614">thread link</a>) | @wietsevenema
<br/>
December 16, 2020 | https://wietsevenema.eu/cloud-run-book/ | <a href="https://web.archive.org/web/*/https://wietsevenema.eu/cloud-run-book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <p><img src="https://wietsevenema.eu/cloud-run-book/lrg.jpg">
        </p>
        <p>
            Ebooks are available now and paperbacks are shipping (<a href="#availability">where to buy</a>)
        </p>
        <h2>Praise</h2>
        <blockquote>
            "I’ve been fortunate enough to be a part of the Google team that helped create Knative and bring Cloud Run
            to market. I’ve watched Cloud Run mature as a product over the years. I’ve onboarded thousands of customers
            and I wrote a framework to help Go developers build Cloud Run applications faster--and even I learned a
            thing or two from this book. What took me three years to learn, Wietse delivers in less than a dozen
            chapters."
            <br> <b>— Kelsey Hightower, Principal Engineer at Google Cloud</b>
        </blockquote>

        <h2 id="availability">Where to Buy</h2>
        <p>
            <em>Ebooks</em> are available here:
        </p><ul>            
            <li><a href="https://play.google.com/store/books/details/Wietse_Venema_Building_Serverless_Applications_wit?id=PV4MEAAAQBAJ">Google
                    Play</a> (DRM free epub)</li>
            <li><a href="https://www.amazon.com/Building-Serverless-Applications-Google-Cloud-ebook/dp/B08PHT7W5T/">amazon.com</a>,
                <a href="https://www.amazon.co.uk/Building-Serverless-Applications-Google-Cloud-ebook/dp/B08PHT7W5T">amazon.co.uk</a>,
                <a href="https://www.amazon.in/Building-Serverless-Applications-Google-Cloud-ebook/dp/B08PHT7W5T">amazon.in</a>
                (Kindle)
            </li>
            <li><a href="https://learning.oreilly.com/library/view/building-serverless-applications/9781492057086/">O'Reilly
                Online Learning</a> (needs subscription)</li>
        </ul>
        
        <p>The <em>paperbacks</em> are shipping, check your favourite (local) bookstore for a delivery estimate. You
            can <a href="https://shop.aer.io/oreilly/p/building-serverless-applications/9781492057093-9149">buy directly
                from
                O'Reilly</a> at a discount if you are in the US or Canada</p>

        <h2>About the Book</h2>
        <p>If you have experience building web applications on traditional infrastructure, this hands-on guide shows you
            how to get started with Cloud Run, a container-based serverless product on Google Cloud.

            Through the course of this book, you'll learn how to deploy several example applications that highlight
            different parts of the serverless stack on Google Cloud. Combining practical examples with fundamentals,
            this book will appeal to developers who are early in their learning journey as well as experienced
            practitioners (<a href="#review">learn what others say about the book</a>).</p>
        
        <h2>Who this Book is For</h2>
        <p>If you build, maintain or deploy web applications, this book is for you. You might go by the title of a
            software engineer, a developer, system administrator, solution architect, or a cloud engineer. I carefully
            balance hands-on demonstrations with deep dives into the fundamentals so that you’ll get value out of it
            whether you’re an aspiring, junior, or experienced developer. </p>

        <p>I tried to stay as programming language agnostic as possible and I use Go for the code listings, because it is easy to read if 
            you haven't worked with it before.</p>

        <h2>Full Chapter Outline</h2>
        <p>Chapter 1 gives a general overview of what a serverless application is, introduces you to Google Cloud and
            their serverless products without going too much in depth. If you are new to Google Cloud, this will be a
            great introduction.</p>
        <p><img src="https://wietsevenema.eu/cloud-run-book/pp1.png">
        </p>
        <p>Chapter 2 is a hands-on introduction to Cloud Run. I’ll show you how to get started with Google Cloud and
            deploy your first Cloud Run service. While the first part of the chapter focuses on using Cloud Run, in the
            second part I explain the runtime characteristics of Cloud Run and how they influence the way you build your
            application. I’ll also compare Cloud Run with the other serverless runtimes on Google Cloud: App Engine and
            Cloud Functions.</p>

        <p><img src="https://wietsevenema.eu/cloud-run-book/pp2.png">
        </p>

        <p>In Chapter 3 you’ll find a thorough introduction to application development with containers. In this chapter
            I show you how to run containers on your local machine with Docker, create your own container images (with
            and without Docker), and dive into the fundamentals of containers. </p>

        <p><img src="https://wietsevenema.eu/cloud-run-book/pp3.png">
        </p>
        <p>The containers on Cloud Run are disposable. This requires you to store data you need to persist beyond the
            lifetime of a single request in a database or another downstream system. In Chapter 4 I dive into the
            managed product Cloud SQL (managed relational databases such as MySQL and PostgreSQL), in Chapter 5 I follow
            up with MemoryStore (Redis). I discuss scalability and reliability, as Cloud Run can scale to 1,000
            containers very fast.</p>

        <p><img src="https://wietsevenema.eu/cloud-run-book/pp4.png">
        </p>

        <p>Especially if you are building a more serious application, you’ll want to make sure that every Cloud Run
            service in your system only has the permissions to do exactly what it needs to do. In information security,
            this is also known as the principle of least privilege: it helps to reduce the impact of a vulnerability in
            one part of the system. This is why I introduce you to Cloud Identity and Access Management (IAM) in Chapter
            6. </p>

        
        <p>Most applications have the need to schedule tasks to be executed later, either immediately after handling an
            HTTP request or at a scheduled time. In Chapter 7 I introduce you to Cloud Tasks when I cover patterns to
            use for task scheduling. </p>
        <p><img src="https://wietsevenema.eu/cloud-run-book/pp5.png">
        </p>

        <p>In Chapter 8 I’ll show you how to work with Terraform, an infrastructure as code (IaC) tool. Terraform lets
            you recreate your entire project using one command, which proves useful if your application grows beyond
            “Hello World”. If you are still getting started with building applications, you might want to skip this
            chapter and the last two chapters for now, to come back to them later.</p>

        <p>I want to make sure that you have proper visibility over what is going on in your system when you go live for
            end users. This is why I cover structured logging and tracing in Chapter 9. Doing this right is
            fundamentally important when you run a system in production. </p>

        <p>Finally, I move beyond the day-to-day concerns and think about the future in Chapter 10. If you build your
            application on top of a vendor-controlled platform, you should consider portability.</p>

        <h2 id="review">Review</h2>
        <blockquote>This is the most comprehensive, yet approachable guide to getting started with Cloud Run (and its
            vast array of accompanying tools and technologies) that currently exists - no small feat for a technology
            that's seen rapid evolution over the past 12 months. From introducing the concept of containers, to
            discussing the real-world considerations when deploying Cloud Run as part of a microservices-based
            architecture, Wietse has written a book that will appeal to both newcomers to Google Cloud and veteran
            developers alike.
            <br><b>Chris Tippett - Principal Consultant at Servian (UK)</b>
        </blockquote>

        <blockquote>Wietse Venema's book goes into significant technical depth while also keeping the reader grounded
            with realistic scenarios. I had the opportunity to review it, and look forward to purchasing a copy of my
            own so that I can read it again. Google Cloud Run may be the most interesting compute platform you'll use in
            the years ahead, and this book will help you build up the knowledge you need to successfully use it.
            <br><b>Richard Seroter, Director of Outbound Product Management at Google Cloud</b>
        </blockquote>

        <blockquote>What can I say... this guy definitely knows what he's talking about. He is as enthusiastic about the
            subject as most people are about little puppies, and manages to explain it in a way that anyone can
            understand it.
            His diagrams are a strong part of the book. They help you understand topics that can be daunting and
            difficult to comprehend, especially for junior backend developers like myself. Go buy this book, it will
            make your life running in the cloud a whole lot easier!
            <br>
            <b>Femke Buijs - Software Engineer at Mollie</b>
        </blockquote>

        <blockquote>Get ready for what I believe is going to be the de facto reference book for Google Cloud Run. Wietse
            Venema explores and explains every facet of the product and goes into details of building production-grade
            serverless apps. As a Cloud Run Product Manager, I helped review every chapter for accuracy.
            <br><b>Steren Giannini, Cloud Run Product Manager at Google Cloud</b>
        </blockquote>

        <blockquote>Wietse has an engaging and personal style that makes this book a pleasure to read. What I like
            especially, is that apart from essential knowledge about Cloud Run, it also contains plenty of anecdotes,
            best practices and useful advice to make you a better application developer. Highly recommended!
            <br><b>Robbert Brak - Principal Software Engineer at 4me</b>
        </blockquote>

        <blockquote>Developers looking to future proof their career for the next decade will love this book because: #1
            It is a practical, easy to read and concise guide on Cloud Run (the technology that finally closes the gap
            between Serverless and Containers). #2 The author covers a broad set of managed services on Google Cloud
            Platform to help you become productive quickly (even if you're new to GCP). #3 If you're skeptical about
            vendor lock-in, you will appreciate the section on how to take your serverless containers and "move out" of
            the Google Cloud.
            <br><b>Daniel Zivkovic, Solution Architect and Organizer of Serverless Toronto User Group</b>
        </blockquote>

        <h2>About the Author</h2>

        <p>Wietse Venema is a software engineer. If he's not training teams to build scalable and reliable software,
            he's figuring out how thing work so he can be a better engineer and teacher. He works at Binx.io to help
            companies build what's next in the public cloud. </p>

        <p>He's proud to be the name twin (not family) of the <a href="http://www.porcupine.org/wietse/">famous</a>
            Wietse Venema, who created Postfix.</p>

        <p>Follow me on <a href="https://www.twitter.com/wietsevenema">twitter.com</a> and connect with me on <a href="https://www.linkedin.com/in/wietse-venema/">linkedin.com</a></p>

    </article></div>]]>
            </description>
            <link>https://wietsevenema.eu/cloud-run-book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25446614</guid>
            <pubDate>Wed, 16 Dec 2020 18:47:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New OpenNebula Managed Services for Corporate Users]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25446322">thread link</a>) | @amarti
<br/>
December 16, 2020 | https://opennebula.io/new-opennebula-managed-services-for-corporate-users/ | <a href="https://web.archive.org/web/*/https://opennebula.io/new-opennebula-managed-services-for-corporate-users/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			    <!-- .entry-header -->

				
					
<article id="post-29462">

    <!-- .entry-header -->

    <div>

		
<p>We are very excited to be announcing that we will now be expanding the support that we make available to <strong>OpenNebula Systems customers </strong>by providing a complete <a href="https://support.opennebula.pro/hc/en-us/articles/360052934231-Managed-Services-Guide">Managed Services extension</a> to those Corporate Users with an active <a href="https://opennebula.io/subscriptions/">OpenNebula Subscription</a>. This comes at a time when many organizations want to have their own private Enterprise Cloud, but are seeking <strong>an alternative to having to manage and administer a cloud solution</strong> by themselves.</p>



<div>
<p>We are aware of the resources, expertise, and effort that are required to run a private or hybrid cloud infrastructure, and many organizations would plainly rather <strong>focus on their business</strong>. And that is OK! For that reason, we have expanded our offering to provide Corporate Users not only with a commercially-supported cloud platform and the underlying benefits of our Subscriptions, but also with the option of <strong>handing the ‘keys’ of your OpenNebula cloud environment to us</strong>, OpenNebula Systems, so that our team of experts can fully manage and administer it for you! 🤓</p>



<div>
<div><figure><img src="https://opennebula.io/wp-content/uploads/2020/12/OpenNebula_SupportModel.png" alt="" width="175" height="180" srcset="https://opennebula.io/wp-content/uploads/2020/12/OpenNebula_SupportModel.png 908w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula_SupportModel-291x300.png 291w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula_SupportModel-768x793.png 768w" sizes="(max-width: 175px) 100vw, 175px"></figure></div>
</div>
</div>



<p>The Managed Services extension converts your OpenNebula Software Subscription into a <strong>Managed Cloud Subscription</strong> that:</p>



<ul><li>Lets you submit through our <a rel="noreferrer noopener" href="https://support.opennebula.pro/" target="_blank">Customer Portal</a> any incidents related to the managed infrastructure and not only with the software stack.</li><li>Includes periodic capacity planning, tuning, maintenance, update and upgrade actions for your OpenNebula cloud and all software components needed for your cloud infrastructure.</li><li>Implements continuous monitoring for availability of your cloud services, and commits to an uptime service level.</li></ul>







<div><figure><a href="https://opennebula.io/true-hybrid/" target="_blank" rel="noopener noreferrer"><img src="https://opennebula.io/wp-content/uploads/2020/12/Consolidated-Infra-Cluster.png" alt="" width="661" height="398"></a></figure></div>







<p>This Managed Services extension goes hand-in-hand with our <a href="https://opennebula.io/true-hybrid">True Hybrid Cloud Architecture</a>, a streamlined platform for running <strong>any workload</strong>, on <strong>any resource</strong>, <strong>anywhere</strong>. And the elastic approach to pricing for this Managed Services extension comes with the flexibility of annual, quarterly, or monthly billing features. This new subscription extension rounds out the recent addition that we announced with our <a href="https://opennebula.io/opennebula-managed-service-provider-partnership/">Managed Service Provider Program</a>, which provides managed services through our <strong>certified partners</strong> for other combinations of storage and networking technologies.</p>



<p>Have a look at our <a href="https://support.opennebula.pro/hc/en-us/articles/360052934231-Managed-Services-Guide" target="_blank" rel="noreferrer noopener">Managed Services Guide</a> and don’t hesitate to <a href="https://opennebula.io/contact/">contact us</a> to discuss your specific needs; our consultants will help you <strong>find the most suitable Managed Services model</strong> for your OpenNebula Enterprise Cloud! 📡</p>
		
		


        <div>
            <p><img alt="" src="https://secure.gravatar.com/avatar/a1737e9efc6920480d8a1abc8d21fd64?s=96&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/a1737e9efc6920480d8a1abc8d21fd64?s=192&amp;d=mm&amp;r=g 2x" height="96" width="96">            </p>
            <div>
                <p><span id="autorblog">Michael Abdou</span></p><p>Customer Success Manager at OpenNebula</p>
            </div>
        </div>
	</div><!-- .entry-content -->

</article><!-- #post-## -->

					
<!-- #comments -->

				
			</div></div>]]>
            </description>
            <link>https://opennebula.io/new-opennebula-managed-services-for-corporate-users/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25446322</guid>
            <pubDate>Wed, 16 Dec 2020 18:31:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Bitcoin Is Called Digital Gold and Why Store of Value Is a Bullshit Argument]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25445705">thread link</a>) | @wiggumspiggums
<br/>
December 16, 2020 | https://prudentlycrypto.com/why-bitcoin-is-called-digital-gold-and-why-store-of-value-is-a-bullshit-argument/ | <a href="https://web.archive.org/web/*/https://prudentlycrypto.com/why-bitcoin-is-called-digital-gold-and-why-store-of-value-is-a-bullshit-argument/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
												
<p>There’s this narrative in the Bitcoin community that you may have heard: The government doesn’t care about you and is printing money with no conscience. Preserve your wealth with Bitcoin! Money printers go brrrr! </p>



<p>It makes Bitcoin sound virtuous. </p>



<p>But it’s a sales pitch.</p>



<p>In this post, we’ll talk about how Bitcoin stacks up to gold as a hedge against inflation and why we don’t think wealth preservation is what really motivates most Bitcoin investors.</p>



<p>Table of Contents:</p>



<ul><li><a href="#Why-Bitcoin-Is-Compared-to-Gold">Why Bitcoin Is Compared to Gold</a></li><li><a href="#Why-Bitcoin-Is-Better-Than-Gold">Why Bitcoin Is Better Than Gold</a></li><li><a href="#The-Store-of-Value-Argument">The “Store of Value” Argument</a></li><li><a href="#Is-Preserving-Wealth-What-People-Really-Care-About">Is Preserving Wealth What People Really Care About?</a></li></ul>



<h2 id="Why-Bitcoin-Is-Compared-to-Gold">Why Bitcoin Is Compared to Gold</h2>



<p>People call Bitcoin “digital gold” because both Bitcoin and gold have a limited supply. Unlike fiat/paper currency, which can be printed at the discretion of the government, Bitcoin will only ever have 21 millions coins unless +51% of its miners agree to change the protocol (which is highly unlikely). As for gold, there’s only so much that can be mined out of the earth.</p>



<h2 id="Why-Bitcoin-Is-Better-Than-Gold">Why Bitcoin Is Better Than Gold</h2>



<p>Many believe Bitcoin is superior to gold because:</p>



<ol><li>It’s digital so potentially harder to get seized by the government or stolen by a criminal. (Of course, if someone knows you own Bitcoin, they could still threaten you with force or violence to access it). </li><li>It’s easy to send. Anyone with a basic internet connection and some sort of computing device can send/receive Bitcoin. But gold is not because it’s a physical object and a heavy one at that.</li><li>It’s easily verifiable through cryptographic technology.</li><li>It’s infinitely divisible, which of course gold is not. There’s actual a unit of currency called a Satoshi, and 1 Bitcoin equals 100 million Satoshis.</li><li>It is somewhat programmable (though not nearly as advanced as a <a href="https://prudentlycrypto.com/why-invest-in-ethereum/" target="_blank" rel="noreferrer noopener">Ethereum</a>).</li></ol>



<p>But Bitcoin has some important disadvantages:</p>



<ol><li>It’s not fully private. Because the Bitcoin ledger aka blockchain is open to the public, Bitcoin transactions can reveal information about the senders and recipients. Authorities have taken advantage of this lack of complete anonymity to catch criminals.</li><li>It’s not as widely accepted or trusted: by society, financial institutions, governments, etc.</li><li>It’s very speculative &amp; volatile and has a much shorter a track record.</li></ol>



<h2 id="The-Store-of-Value-Argument">The “Store of Value” Argument</h2>



<p>Because both Bitcoin and gold are scarce, people think Bitcoin can serve the same purpose as gold: act as a better store of value over paper money and hedge against inflation.</p>



<p>You may have heard worries over inflation because of governments printing money to provide financial relief due to Covid-19. Some notable investors, like Raoul Pal and Ray Dalio, have said so, too.</p>



<p>So in the eyes of many Bitcoin enthusiasts, one of the most compelling arguments in support of Bitcoin is the fact that it can preserve wealth from being inflated away.</p>



<p>(NOTE: We know <a href="https://www.bloomberg.com/news/articles/2020-05-07/paul-tudor-jones-buys-bitcoin-says-he-s-reminded-of-gold-in-70s" target="_blank" rel="noreferrer noopener">Paul Tudor Jones</a> says that a store of value must have purchasing power, trustworthiness, liquidity and portability. But scarcity is what the majority of folks focus on).</p>



<h2 id="Is-Preserving-Wealth-What-People-Really-Care-About">Is Preserving Wealth What People Really Care About?</h2>



<p>Let’s rephrase this question a bit: Let’s say inflation was high at 10% per year. But a total stock market ETF gave a 15% return on the year. Would anyone give a rat’s ass about Bitcoin, if it kept up with inflation but <em>didn’t</em> beat the market?</p>



<p>We think not. Because, let’s be honest, the excitement around Bitcoin <em>as an “investment</em>” is its outstanding returns.&nbsp;</p>



<p>Many people promote Bitcoin, arguing that it is the best inflation hedge. But protecting against inflation is not as important to them as seeing the price of Bitcoin go up. Because Bitcoin is scarce, getting more people to adopt Bitcoin as an inflation hedge drives up the price. So the justification is your wealth preservation. But the motivation is their wealth accumulation.</p>



<p><em>Now, does this detract from Bitcoin as a financial innovation? </em>No.</p>



<p><em>Does this mean Bitcoin does NOT act as a hedge against inflation? </em>No, it can despite other people’s ulterior motives advocating for it.&nbsp;</p>



<p><em>Does this stop us <a href="https://prudentlycrypto.com/about/" target="_blank" rel="noreferrer noopener">Crypto Prudes</a> from buying and hodling Bitcoin? </em>Not at all.</p>



<p>We just think it’s important to have clear eyes when betting on Bitcoin because Bitcoin as a “store of value” is not what is truly motivating current investors. The truth is they wanna see Bitcoin beat the pants off all other investments. Otherwise, nobody would really give a shit (us included). </p>



<p><em>Disclaimer: this article should be treated as informational only and not as financial, investment or any other advice.&nbsp;</em></p>
											</div></div>]]>
            </description>
            <link>https://prudentlycrypto.com/why-bitcoin-is-called-digital-gold-and-why-store-of-value-is-a-bullshit-argument/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25445705</guid>
            <pubDate>Wed, 16 Dec 2020 17:48:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Observer Effect interview with Tobi Lütke]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25445474">thread link</a>) | @matallo
<br/>
December 16, 2020 | https://www.theobservereffect.org/tobi.html | <a href="https://web.archive.org/web/*/https://www.theobservereffect.org/tobi.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><em>
									Welcome to the third interview on 'The Observer Effect'. We are lucky to have one
									of the most interesting founders in technology and commerce - Tobi Lütke, Founder
									and CEO of Shopify. This interview was published on December 16th, 2020.

							</em></p><p><em>Tobi is one of the most thoughtful and first principles oriented founders I've met and
								this was a fascinating conversation. Enjoy!
								</em>
							</p><p><b><a href="https://sriramk.com/">Sriram Krishnan</a></b><br>
								<em><strong>Let’s start with the basics. Walk me through a typical day in the life of
										Tobi Lütke.</strong></em>
							</p><p>
								Here’s the honest answer: obviously I have a schedule and people helping me manage my
								time, however, I think a lot about where to devote my attention. In this way, there is
								no typical day.

							</p><p>My attention is the most liquid and valuable resource that I have. Even back in the day
								when Shopify went public, I spent a good deal of time pre-selling the various investors.
								During meetings, I would say, “Hey, I'm here, and we've been doing this roadshow, but I
								actually spend a lot of my time on the product.” This was to set expectations because I
								knew I wasn't going to attend very many investor conferences. Fundamentally, my
								attention belonged to the product, not to the sales and marketing of it. </p><p>A day in my life really depends on what's happening. That said, usually I have themes.
								For instance, I have a priority list, and I have decision logs that chronicle all the
								things I am trying to figure out. </p><p>
								These cover different questions. For example, if I had just taken the company over, how
								would I change it? How would I build a company to potentially disrupt Shopify? I try to
								make my calendar match these bigger topics and other urgent priorities. In a way, the
								calendar is nothing more than a strategy. Although it's incredibly easy—and it has
								happened to me quite a lot—to have circumstances dictate the calendar. Because of this,
								there’s this constant tug of war between the actual priorities of the company and the
								kind of things that have to be done.

							</p><p>So, I end up trying to insert themes into my days. Like today, for instance, I have a
								meeting with my small team to begin the week; I reserved my afternoon for product
								reviews—what we call “greenpathing exercises”—where, oddly, I'm trying to discern how
								everyone is thinking about the main things we're working on. I do this because
								oftentimes I feel as though I am the connective tissue combining operations, finance,
								and more formal business functions with the product itself. This connection helps me to
								make good decisions.</p><p>Lastly, on Wednesdays, Shopify doesn't do scheduled meetings. Usually, I have a list of
								memos to read or reactions to record to various mock-ups and so on. This is basically my
								very loosely defined schedule.</p><p>
								<b><i>How do you work with your so-called “expansion pack team” on reallocating your
										portfolio management on time? What does that loop look like?
									</i></b>
							</p><p>
								A lot of this is almost automatic by just having a good color coding system, which is
								really fun.
								<i>[laughs]</i>

							</p><p> At one point, I started complaining about blue weeks where every single time slot was
								taken. And someone said, “Well, if you don't like blue, I can make any color.” And I
								replied, “Well, how about we color based on leverage?” And that’s just what we did. </p><p>
								We ended up labeling my product-related things red, investor/Board of Director-related
								things some kind of teal color, et cetera. And the thing I’m looking for is a balanced
								week; a week where, ideally, I manage to devote about 30% of the time—at least—to the
								product and then as much as possible to things like recruiting, bigger picture projects,
								and one-on-ones.

							</p><p>
								And so, if my calendar becomes too external or too much of anything, it's the first
								thing we see when we sit down for our priorities meeting. This makes scheduling a lot
								easier.

							</p><p>
								<b><i>
										This is a very natural segue to my next question. One of the theories behind
										this whole set of interviews is diving into the atomic bits of how we spend our
										time in meetings. This time compounds over the long term and has a massive
										effect. What does a good meeting with Tobi look like? Alternatively, what does a
										bad meeting with you look like?
									</i>
							</b></p><div>
							<p>So actually, agendas are not terribly successful with me. I admire how other CEOs I’ve
								spoken with always have a strict agenda where everyone has a speaking slot. I find that
								absolutely fascinating. Even if I really set myself to an agenda and say, “Okay, great,
								this is going to happen,” I can't get through half of a meeting like this. Partly
								because a good meeting is, for me personally, when I learn something.</p>
								<blockquote>
									<p>..when I have my own ideas, the first thing I tend to do is
										just try to falsify them, to figure out why what I'm thinking about is probably
										incorrect...<em>
									</em></p>
								</blockquote>
							<p>
								I started a company because I love learning. I went into programming because I found it
								fascinating. During meetings, I just love to hear the things that teams have discovered.
								When you're discussing an idea or a decision, I want to know what has been considered.
								To be honest, I find myself more interested in the inputs of an idea than the actual
								decision. I say this because when I have my own ideas, the first thing I tend to do is
								just try to falsify them, to figure out why what I'm thinking about is probably
								incorrect. This is actually something that I have to explain to people that I work with.
								If I like someone's idea, I tend to do the same thing: I try to poke holes in it.
							</p>

							<p>I usually say, “Well, the implication of this choice means you've made the following
								assumptions. What inputs did you use to make these foundational assumptions?”
								Effectively, I'm trying to figure out if an idea is built on solid fundamentals. I find
								that shaky fundamentals tend to be where things often go wrong. The decision being
								discussed could be the perfect decision according to the various assumptions that
								everyone came into the room with. But if those assumptions are faulty, the seemingly
								perfect decision is faulty too. Interestingly, assumptions are rarely mentioned in the
								briefing docs or in the slide deck. Usually, I'm trying to make sure those are rock
								solid. Through this process, I invariably end up learning something completely new about
								a field. That gives me great confidence and comfort both in the decision and the
								direction.</p>

							
							<h2 id="enneagrams"><b>On Enneagrams and Comprehensivists</b></h2>
							<p>


								<b><i>Two words have come up a lot in preparatory conversations: comprehensivist and
										enneagrams. Could you talk about both?

									</i></b>

							</p>

							<p>Interesting.</p>
							<p>
								<i>[Laughs]</i>
								I feel like I'm becoming known for pointing people towards the enneagram. I actually
								don't think it's that valuable on its own. The valuable thing about any of these
								personality-type constructs is that they do a really good job of teaching people that
								other people are very different. That realization is probably one of the biggest growth
								moments for people in general. It tells you that different people play different roles.
								On that note, I do think that, ideally, people should play their own roles really,
								really well.

							</p>
							<p>
								I play the role of challenger, personally. I find that the enneagram helps me remind
								myself that with different people I have to talk about the same things in different
								ways. I think it allows you to skip some time which would otherwise be touch and go at
								the beginning of a relationship and helps build trust better. In short, it enables us to
								have fruitful and effective conversations.
								And comprehensivist, I mean, that's a fancy word.
							</p>
							<p>

								<i>[Laughs]</i> I don't think I've ever used it outside of putting it into my Twitter
								bio when I was reading Buckminster Fuller. That said, I do like range. I find that the
								first 80% of every field is pretty quick to learn—it’s equivalent to the Pareto
								principle—and I think that creativity generally is people using lessons from one field
								in another field in different ways. Because of this, I find learning fascinating.

								</p><blockquote>
									<p>..creativity generally is people using lessons from one field
										in another field in different ways...<em>
									</em></p>
								</blockquote>
							
						


							<h2 id="decisionmaking"><b>On Time and Attention on Shopify<br></b></h2>
							<p>
								<b><i>
										You try and design how your company spends time and attention. One particular
										incident came up recently which I found really fascinating. You wrote a script
										to delete every recurring meeting at Shopify. Talk about why you did that, and
										what you ended up learning from it.


									</i></b>
							</p>


							<p>
								<i>[Laughs]</i>
								So, going back a little bit further there—you know what, I should talk about books. One
								thing that is interesting is how people have accused Shopify of being a book club thinly
								veiled as a public company.

							</p>
							<p>We tend to read a lot and talk about a lot of books. We read Nassim Taleb’s books and one
								person on my team began talking about Antifragile and gave an outline. He said, “I think
								Nassim is putting a word to the thing that you keep talking about…” </p>

							<p>Now, I come from an engineering perspective. One of my biggest beefs with engineers, in
								general, is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.theobservereffect.org/tobi.html">https://www.theobservereffect.org/tobi.html</a></em></p>]]>
            </description>
            <link>https://www.theobservereffect.org/tobi.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25445474</guid>
            <pubDate>Wed, 16 Dec 2020 17:34:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DeskPi Pro and 8GB Pi 4]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25444965">thread link</a>) | @todsacerdoti
<br/>
December 16, 2020 | https://www.earth.li/~noodles/blog/2020/12/deskpi-pro-and-pi4.html | <a href="https://web.archive.org/web/*/https://www.earth.li/~noodles/blog/2020/12/deskpi-pro-and-pi4.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p><img alt="DeskPi Pro Raspberry Pi case" src="https://www.earth.li/~noodles/blog/images/2020/deskpi.jpg"></p>

<p>Despite having worked on a <a href="https://www.earth.li/~noodles/blog/2006/03/more-amstrad-e3-joy.html">number</a> <a href="https://www.earth.li/~noodles/blog/2006/10/progress-with-the-balloon.html">of</a> <a href="https://www.earth.li/~noodles/blog/2019/01/mapleboard.html">ARM</a> <a href="https://www.earth.li/~noodles/blog/2020/09/rb3011-mainline.html">platforms</a> I’ve never actually had an ARM based development box at home. I have a Raspberry Pi B Classic (the original 256MB rev 0002 variant) a coworker gave me some years ago, but it’s not what you’d choose for a build machine and generally gets used as a self contained TFTP/console server for hooking up to devices under test. Mostly I’ve been able to do kernel development with the cross compilers already built as part of Debian, and either use pre-built images or Debian directly when I need userland pieces. At a previous job I had a <a href="http://macchiatobin.net/">Marvell MACCHIATObin</a> available to me, which works out as a nice platform - quad core A72 @ 2GHz with 16GB RAM, proper SATA and a PCIe slot. However they’re still a bit pricey for a casual home machine. I really like the look of the <a href="https://www.solid-run.com/arm-servers-networking-platforms/honeycomb-workstation/">HoneyComb LX2</a> - 16 A72 cores, up to 64GB RAM - but it’s even more expensive.</p>

<p>So when I saw the existence of the <a href="https://www.raspberrypi.org/blog/8gb-raspberry-pi-4-on-sale-now-at-75/">8GB Raspberry Pi 4</a> I was interested. Firstly, the Pi 4 is a proper 64 bit device (my existing Pi B is ARMv6 which means it needs to run Raspbian instead of native Debian armhf), capable of running an upstream kernel and unmodified Debian userspace. Secondly the Pi 4 has a USB 3 controller sitting on a PCIe bus rather than just the limited SoC USB 2 controller. It’s not SATA, but it’s still a fairly decent method of attaching some storage that’s faster/more reliable than an SD card. Finally 8GB RAM is starting to get to a decent amount - for a headless build box 4GB is probably generally enough, but I wanted some headroom.</p>

<p>The Pi comes as a bare board, so I needed a case. Ideally I wanted something self contained that could take the Pi, provide a USB/SATA adaptor and take the drive too. I came across the pre-order for the <a href="https://deskpi.com/products/deskpi-pro-for-raspberry-pi-4">DeskPi Pro</a>, decided it was the sort of thing I was after, and ordered one towards the end of September. It finally arrived at the start of December, at which point I got round to ordering a Pi 4 from <a href="https://cpc.farnell.com/">CPC</a>.</p>

<p>Total cost ~ £120 for the case + Pi.</p>

<h2 id="the-bad">The Bad</h2>

<p>First, let’s get the bad parts out of the way.</p>

<p><img alt="Broken USB port (right)" src="https://www.earth.li/~noodles/blog/images/2020/deskpi-broken-usb.jpg"></p>

<p>I managed to break a USB port on the Desk Pi. It has a pair of forward facing ports, I plugged my wireless keyboard dongle into it and when trying to remove it the solid spacer bit in the socket broke off. I’ve never had this happen to me before and I’ve been using USB devices for 20 years, so I’m putting the blame on a shoddy socket.</p>

<p>The first drive I tried was an old Crucial M500 mSATA device. I have an adaptor that makes it look like a normal 2.5” drive so I used that. Unfortunately it resulted in a boot loop; the Pi would boot its initial firmware, try to talk to the drive and then reboot before even loading Linux. The DeskPi Pro comes with an m2 adaptor and I had a spare m2 drive, so I tried that and it all worked fine. This might just be power issues, but it was an unfortunate experience especially after the USB port had broken off.</p>

<p>(Given I ended up using an M.2 drive another case option would have been the <a href="https://www.argon40.com/argon-one-m-2-case-for-raspberry-pi-4.html">Argon ONE M.2</a>, which is a bit more compact.)</p>

<h2 id="the-annoying">The Annoying</h2>

<p><img alt="DeskPi Pro without rear bezel" src="https://www.earth.li/~noodles/blog/images/2020/deskpi-open.jpg"></p>

<p>The case is a little snug; I was worried I was going to damage things as I slid it in. Additionally the construction process is a little involved. There’s a good set of instructions, but there are a lot of pieces and screws involved. This includes a couple of <a href="https://en.wikipedia.org/wiki/Flexible_flat_cable">FFC cables</a> to join things up. I think this is because they’ve attempted to make a compact case rather than allowing a little extra room, and it does have the advantage that once assembled it feels robust without anything loose in it.</p>

<p><img alt="DeskPi Pro with rear bezel and USB3 dongle" src="https://www.earth.li/~noodles/blog/images/2020/deskpi-rear.jpg"></p>

<p>I hate the need for an external USB3 dongle to bridge from the Pi to the USB/SATA adaptor. All the cases I’ve seen with an internal drive bay have to do this, because the USB3 isn’t brought out internally by the Pi, but it just looks ugly to me. It’s hidden at the back, but meh.</p>

<p>Fan control is via a USB/serial device, which is fine, but it attaches to the USB C power port which defaults to being a USB peripheral. Raspbian based kernels support device tree overlays which allows easy reconfiguration to host mode, but for a Debian based system I ended up rolling my own dtb file. I changed</p>

<div><div><pre><code>#include "bcm283x-rpi-usb-peripheral.dtsi"
</code></pre></div></div>

<p>to</p>

<div><div><pre><code>#include "bcm283x-rpi-usb-host.dtsi"
</code></pre></div></div>

<p>in <code>arch/arm/boot/dts/bcm2711-rpi-4-b.dts</code> and then I did:</p>

<div><div><pre><code>cpp -nostdinc -I include -I arch -undef -x assembler-with-cpp \
    arch/arm/boot/dts/bcm2711-rpi-4-b.dts &gt; rpi4.preprocessed
dtc -I dts -O dtb rpi4.preprocessed -o bcm2711-rpi-4-b.dtb
</code></pre></div></div>

<p>and the resulting <code>bcm2711-rpi-4-b.dtb</code> file replaced the one in <code>/boot/firmware</code>. This isn’t a necessary step if you don’t want to use the cooling fan in the case, or the front USB ports, and it’s not really anyone’s fault, but it was an annoying extra step to have to figure out.</p>

<p>The DeskPi came with a microSD card that was supposed to have RaspiOS already on it. It didn’t, it was blank. In my case that was fine, because I wanted to use Debian, but it was a minor niggle.</p>

<h2 id="the-good">The Good</h2>

<p>I used Gunnar’s <a href="https://raspi.debian.net/">pre-built Pi Debian image</a> and it Just Worked; I dd’d it to the microSD as instructed and the Pi 4 came up with working wifi, video and USB enabling me to get it configured for my network. I did an <code>apt upgrade</code> and got updated to the Buster 10.7 release, as well as the latest 5.9 backport kernel, and everything came back without effort after a reboot. It’s lovely to be able to run Debian on this device without having to futz around with self-compiled kernels.</p>

<p>The DeskPi makes a lot of effort to route things externally. The SD slot is brought out to the front, making it easy to fiddle with the card contents without having to open the case to replace it. All the important ports are brought out to the back either through orientation of the Pi, or extenders in the case. That means the built in Pi USB ports, the HDMI sockets (conveniently converted to full size internally), an audio jack and a USB-C power port. The aforementioned USB3 dongle for the bridge to the drive is the only external thing that’s annoying.</p>

<p>Thermally things seem good too. I haven’t done a full torture test yet, but with the fan off the system is sitting at about 40°C while fairly idle. Some loops in bash that push load up to above 2 get the temperature up to 46°C or so, and turning the fan on brings it down to 40°C again. It’s audible, but quieter than my laptop and not annoying.</p>

<p>I liked the way the case came with everything I needed other than the Pi 4 and a suitable disk drive. There was an included PSU (a proper USB-C PD device, UK plug), the heatsink/fan is there, the USB/SATA converter is there and even an SD card is provided (though that’s just because I had a pre-order).</p>

<p>Speaking of the SD, I only needed it for initial setup. Recent Pi 4 bootloaders are capable of booting directly from USB mass storage devices. So I upgraded using the <a href="https://github.com/raspberrypi/rpi-eeprom/releases/tag/v2020.09.03-138a1">RPi EEPROM Recovery image</a> (which just needs extracted to the SD FAT partition, no need for anything complicated - boot with it and the screen goes all green and you know it’s ok), then created a FAT partition at the start of the drive for the kernel / bootloader config and a regular EXT4 partition for root. Copies everything over, updated paths, took out the SD and it all just works happily.</p>

<h2 id="summary">Summary</h2>

<p>My main complaint is the broken USB port, which feels like the result of a cheap connector. For a front facing port expected to see more use than the rear ports I think there’s a reasonable expectation of robustness. However I’m an early adopter and maybe future runs will be better.</p>

<p>Other than that I’m pretty happy. The case is exactly the sort of thing I wanted; I was looking for something that would turn the Pi into a box that can sit on my desk on the network and that I don’t have to worry about knocking wires out of or lots of cables hooking bits up. Everything being included made it very convenient to get up and running. I still haven’t poked the Pi that hard, but first impressions are looking good for it being a trouble free ARM64 dev box in the corner, until I can justify a HoneyComb.</p>

  </article></div>]]>
            </description>
            <link>https://www.earth.li/~noodles/blog/2020/12/deskpi-pro-and-pi4.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25444965</guid>
            <pubDate>Wed, 16 Dec 2020 17:04:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Risk8s Business: Risk Analysis of Kubernetes Clusters]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25444866">thread link</a>) | @clintgibler
<br/>
December 16, 2020 | https://tldrsec.com/guides/kubernetes/ | <a href="https://web.archive.org/web/*/https://tldrsec.com/guides/kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p><strong>On this page</strong>: A zero-to-hero guide for assessing the security risk of your Kubernetes cluster and hardening it.</p>

<p>Kubernetes is a container orchestrator that has seen year-after-year exponential growth in adoption.</p>

<p>While many organizations have adopted Kubernetes because of its hyped ability to
scale, extensibility, and multi-cloud support, many security teams have been
left playing catch-up.</p>

<blockquote>
  <p>This guide will help you rapidly ramp on what Kubernetes is and what it does
(and doesn’t do).</p>

  <p>You’ll learn how to understand the current state of your
Kubernetes deployment, hone in on what’s most risky, and how to mitigate that
risk.</p>

  <p>We’ll link to the best tools and other resources to learn more, and
include plenty of handy CLI one-liners to get the job done.</p>
</blockquote>

<h2 id="guide-structure">Guide Structure</h2>

<p>The structure of this guide, which you can also quickly navigate by the navbar
links on the left hand side, is the following:</p>

<h3 id="introduction">Introduction</h3>

<p>First we’ll give you an <a href="https://tldrsec.com/guides/kubernetes/overview">overview</a> of Kubernetes, discuss what it means to <a href="https://tldrsec.com/guides/kubernetes/secure-cluster-looks-like">secure a
cluster</a>, and talk about the end
goal here.</p>

<p>We’ll list a number of <a href="https://tldrsec.com/guides/kubernetes/tooling-up">solid tools</a> to get you
started, which will be used throughout this guide.</p>

<h3 id="understanding-your-environment">Understanding Your Environment</h3>

<p>You need to <a href="https://tldrsec.com/guides/kubernetes/understanding-your-environment">understand your environment</a> before you can secure it, so we start
there. We’ll quickly dive in to ways that you can collect information, and which information is relevant in the big picture.</p>

<p>We want to see what your cluster looks like, how you’re <a href="https://tldrsec.com/guides/kubernetes/how-deploying">deploying it</a> (managed vs self-hosted), what’s running
<a href="https://tldrsec.com/guides/kubernetes/whats-running-in-cluster">inside</a> and <a href="https://tldrsec.com/guides/kubernetes/whats-running-nearby-cluster">nearby</a>, and what services are at risk of being compromised throughout the cluster’s lifetime.</p>

<h3 id="understanding-your-risk">Understanding Your Risk</h3>

<p>With all this information we will run through a simple risk analysis that helps us determine how likely an exploit would occur and determine how your cluster will hold up. Finally building
an overall risk baseline for the environment.</p>

<p>We’ll examine:</p>
<ul>
  <li><a href="https://tldrsec.com/guides/kubernetes/understanding-your-risk">Access controls</a>: who can deploy and how are workloads being deployed?</li>
  <li>Which <a href="https://tldrsec.com/guides/kubernetes/services-exposed">services are exposed</a> publicly or internally?</li>
  <li>Do we have visibility into the cluster, and is our <a href="https://tldrsec.com/guides/kubernetes/how-vulnerable-is-cluster">cluster vulnerable</a> due to configuration mistakes or networking-related vulnerabilities?</li>
</ul>

<p>We’ll conclude by discussing <a href="https://tldrsec.com/guides/kubernetes/common-compromise-scenarios">common compromise
scenarios</a>: a pod being
compromised, a developer compromising a cluster, and a developer being
compromised by an attacker. And some stories of what I’ve seen in the real world
during my consulting work, for good measure 😎</p>

<h3 id="wrapping-up">Wrapping Up</h3>
<p>In the end, we’ll <a href="https://tldrsec.com/guides/kubernetes/putting-it-together">put it all together</a>,
and you will hopefully have enough information to get started reviewing your
cluster environment to identify gaps, vulnerabilities, and just questionable
areas that will need further inspection.</p>

<p>Once you have a risk assessment complete, it’ll be your job to continue onto the
risk management phase and find out what mitigations will best fit in to address
all the issues you found.</p>

<p>And of course, we conclude with a variety of <a href="https://tldrsec.com/guides/kubernetes/further-reading">further
resources</a> on Kubernetes threat modeling,
additional tools, and some of our favorite conference talks.</p>



<p>My name is Mark Manning and I’m currently a security architect at <a href="https://www.snowflake.com/">Snowflake</a>. I’ve spent years as a security consultant for a global security consulting firm where I assessed, reviewed, attacked, and sometimes, helped fix problems on a wide range of Kubernetes projects (among other types of projects). I was excited for the opportunity to collaborate with <em>tl;dr sec</em> and write about a topic I’ve dealt with repeatedly over the last 4 years, Kubernetes risk.</p>

<p>I’ve worked with customers just getting started with Kubernetes, cloud providers deploying their own Kubernetes platforms, and large organizations that have invested much of their business into embracing the “digital transformation.”</p>

<p>Today I’m working with Snowflake by focusing some of my experiences and offensive skills towards helping solve some really interesting security challenges. Part of that is Risk Management of Kubernetes clusters at scale.</p>

<p>I’ve seen how things can go right, and wrong, in the real world, in a vast variety of companies. While I don’t have all the answers, I enjoy sharing what I do know with the public, and <a href="https://www.twitter.com/antitree">on Twitter</a> or at <a href="https://www.shmoocon.org/speakers/#kubectl">hacker conferences</a>.</p>

<p>My hope is that some of us will continue to work heavily on Kubernetes security so that even if we don’t fix everything, the rest of the infosec industry can level-up to meet the challenges of securing these modern platforms.</p>










<!-- Begin MailChimp Signup Form -->



<!--End mc_embed_signup-->
        
      </section></div>]]>
            </description>
            <link>https://tldrsec.com/guides/kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25444866</guid>
            <pubDate>Wed, 16 Dec 2020 16:57:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Running Federated Learning Applications on Embedded Devices]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25444353">thread link</a>) | @tanto
<br/>
December 16, 2020 | https://flower.dev/blog/2020-12-16-running_federated_learning_applications_on_embedded_devices_with_flower?s=hn | <a href="https://web.archive.org/web/*/https://flower.dev/blog/2020-12-16-running_federated_learning_applications_on_embedded_devices_with_flower?s=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Federated Learning (FL) is catching traction and it is now being used in several commercial applications and services. For example, Google uses it for mobile <a href="https://arxiv.org/pdf/1812.02903.pdf">keyboard prediction</a>, while Apple uses FL to <a href="https://www.technologyreview.com/2019/12/11/131629/apple-ai-personalizes-siri-federated-learning/">improve Siri</a>. In this blog post, I will first give a primer on FL by comparing it against a standard datacenter setup. Then, I'll motivate the use of Federated Learning on embedded devices and, end this blog post by providing a walk-through on how you can set up and run FL applications on embedded devices using Flower.</p><p>By the end of this post, you will understand the key difference between distributed and federated learning as well as how to apply federated learning to a real problem.</p><h2>What is Federated Learning?</h2><p>We will start by giving a brief overview of what are the unique aspects of Federated Learning (FL) and how it differs from other forms of learning such as datacenter-based distributed learning.</p><ul><li><p><strong>Distributed learning:</strong> Under this setting clients are compute nodes (e.g. a server with a few GPUs) and the dataset is controller by whoever manages the datacenter, thus it can be shuffled and balanced across clients. All clients are almost always available and typically there are 1-1000 of them. The learning process is centrally orchestrated by another server in the datacenter.</p></li><li><p><strong>Federated learning:</strong> By contrast in an FL setting, the clients are independent and often much more constrained compute nodes (e.g your smartphone) that <strong>own</strong> the data and never send it to the central server. In this way, learning happens locally in each node using their own data and, once the on-device learning stage is completed, the nodes send their updates to the central server, where the results get aggregated. Finally, the central server generates a new <em>global model</em>. The number of clients in FL can reach millions of nodes, but only a fraction of them might be available for a given round of training. The amount and quality of data might vastly differ from client to client. Because clients own the data, FL can offer privacy guarantees that aren't possible in datacenter-based learning approach where privacy is mostly based on a trust agreement.</p></li></ul><p>The diagram bellow illustrates the key differences (left: federated learning, right: classical distributed training in datacenter):</p><div><div data-rmiz-wrap="visible"><picture><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/intro_diagram-b7d6672412df666c1cc1d865dcbeb644.webp" media="(max-width: 400px)"><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/intro_diagram-3717f1fd49de4f57238436b6834188a6.webp" media="(min-width: 401px) and (max-width: 800px)"><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/intro_diagram-a369975bc78b7ba6d4f503b3d8e10cb0.webp" media="(min-width: 801px) and (max-width: 1200px)"><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/intro_diagram-7742c1738e0b8935883cb64f9de350ea.webp" media="(min-width: 1201px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/intro_diagram-682846e2e914876775cc51a6d7971561.png" media="(max-width: 400px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/intro_diagram-45202bd75244e2af964f56d786bf6834.png" media="(min-width: 401px) and (max-width: 800px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/intro_diagram-83386a049a9605e0a6a543d8d4822645.png" media="(min-width: 801px) and (max-width: 1200px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/intro_diagram-dae913420dfe5e5ec3e868d9287fa636.png" media="(min-width: 1201px)"><img src="https://flower.dev/_next/static/chunks/images/intro_diagram-dae913420dfe5e5ec3e868d9287fa636.png" alt="Intro Diagram"></picture></div></div><blockquote><p>For a more in-depth analysis of different training setups please check <a href="https://arxiv.org/pdf/1912.04977.pdf">Advances and Open Problems in Federated Learning, Kairouz et al. (2019)</a></p></blockquote><h2>Motivating FL on Embedded Devices</h2><p>Here I present a hypothetical example showing how Federated Learning brings value in privacy sensible contexts such as smart appliances using computer vision. I'll use this example to motivate the use of Federated Learning on embedded devices.</p><p>Let's assume there is a company out there that offers a service by which you can easily keep track of what's in your fridge. Such service only requires you to (1) install a small camera with an embedded computer inside your fridge (we'll refer to this device as a "FridgeCam") and (2) connect the device to your WiFi network. Upon installation, the FridgeCam will download a pretrained model from the server offering the service of detecting and classifying the items in your fridge.</p><p>However, this initial classification model isn't very good. The main reason being that there are not publicly available datasets that capture the wide variety of items that can be found inside a fridge as well as the different levels of occlusion, viewing angles and, illumination conditions. Because of this, the service provider offers an opt-in program for users to collaborate with the images captured by their FridgeCams and use them to build a better classification model.</p><div><div data-rmiz-wrap="visible"><picture><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/fridgecam_diagram-3e4885cd589d501ac7a08cd83f782911.webp" media="(max-width: 400px)"><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/fridgecam_diagram-c437da742eac9221e9c23455edfb0113.webp" media="(min-width: 401px) and (max-width: 800px)"><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/fridgecam_diagram-3581e47721403c07542c3039b03b26e4.webp" media="(min-width: 801px) and (max-width: 1200px)"><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/fridgecam_diagram-3fb3cfc661b335b882c9e83c811bf100.webp" media="(min-width: 1201px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/fridgecam_diagram-50459349e7715d687e896e0b58deb2ba.png" media="(max-width: 400px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/fridgecam_diagram-de054442d7f2ee9a0cb2e1dbb549edab.png" media="(min-width: 401px) and (max-width: 800px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/fridgecam_diagram-6bfab7c98cb8e339fe6099181c14f9fe.png" media="(min-width: 801px) and (max-width: 1200px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/fridgecam_diagram-7d66966788856236c27a8003121310d1.png" media="(min-width: 1201px)"><img src="https://flower.dev/_next/static/chunks/images/fridgecam_diagram-7d66966788856236c27a8003121310d1.png" alt="FridgeCam Diagram"></picture></div></div><p>Privacy is an obvious concern here. As a result, many users might not want to share the content of their fridge. For example, some might not want to share images showing alcoholic drinks, others would be worried about sharing some medication that needs to be stored in the fridge. Whatever the reason is, Federated Learning with its privacy guarantees is currently the best way of training a better global model without sharing any data with the service provider.</p><p>If a sufficiently large pool of users with their FridgeCams joins the service and, if they are willing to contribute towards the FL learning process (which will also involve some regular image annotation effort from their side), this long-awaited service of keeping track of what's on your fridge could become a reality :relieved:.</p><h2>Using Flower on Embedded Devices</h2><p>Using embedded devices as FL clients could be cumbersome as it might require substantial configuration to get the machine learning framework (e.g. PyTorch or Tensorflow) running efficiently on these devices. How can I automate this process as well as setting up the communication with the server?</p><p>With Flower you can <a href="https://github.com/adap/flower/tree/main/examples/embedded_devices">run FL on embedded devices</a> after a minimal setting up process. We have dockerized the Flower clients to make the process of adding them to the FL pool of clients as seamless as possible. This means that the only requirement to use Flower clients is to install Docker in your embedded device (e.g. a Raspberry Pi). We provide a step-by-step guide on how to do this <a href="https://github.com/adap/flower/tree/main/examples/embedded_devices">here</a>. Once Docker is up and running, everything is ready to launch an FL training pipeline that trains on-device an image classification model. The following diagram illustrates the setup for this example.</p><div><div data-rmiz-wrap="visible"><picture><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/demo_diagram-3ae27e7892c0bbcbbe3b93a3105b2881.webp" media="(max-width: 400px)"><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/demo_diagram-035688095262cea6c213a03ea8520013.webp" media="(min-width: 401px) and (max-width: 800px)"><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/demo_diagram-625fba5beee330cebada9a0610fbe9ac.webp" media="(min-width: 801px) and (max-width: 1200px)"><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/demo_diagram-b3383612702a6119acde5f4640bdacd3.webp" media="(min-width: 1201px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/demo_diagram-0fad80335f0842adfd9fbd3ec8897e2e.png" media="(max-width: 400px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/demo_diagram-9814f1da2d7e15c2522882f7c63f6e9c.png" media="(min-width: 401px) and (max-width: 800px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/demo_diagram-536fd0cf9c552493921f8c656c31311b.png" media="(min-width: 801px) and (max-width: 1200px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/demo_diagram-aa32a501ac7d3a407b4e1ade63e08363.png" media="(min-width: 1201px)"><img src="https://flower.dev/_next/static/chunks/images/demo_diagram-aa32a501ac7d3a407b4e1ade63e08363.png" alt="Demo Diagram"></picture></div></div><p>In the example we provide, we present a simpler scenario from what was described in the previous section using FridgeCams. Instead, we will show how to train an image classifier for <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10 dataset</a> in a Federated Learning fashion. An equivalent setup could be used to make FridgeCams a reality so, if this idea sounds exciting to you, feel free to <a href="https://flower.dev/join-slack">join our Slack channel</a> to discuss it! In the meantime, you can run our CIFAR-10 example by:</p><p>First, launch the server in your machine (i.e. your laptop) by specifying your machine's IP address, the number of FL rounds and, the model to use: </p><div><article><p>Copy</p><pre><code><span># launch your server. It will be waiting until two clients connect</span><span>
</span>$ python server.py --server_address &lt;YOUR_SERVER_IP:PORT&gt; --rounds 3 --model Net
</code></pre></article></div><blockquote><p>If you have just one device around to act as a client you can still run this demo by supplying <code>--min_num_clients=1</code> and <code>--min_sample_size=1</code> when you launch the server. Please refer to this example's repository for additional details.</p></blockquote><p>Then, launch the Raspberry Pi client:</p><div><article><p>Copy</p><pre><code><span># where `cid` is your unique client id, and `model` is the architecture to use</span><span>
</span>$ ./run_pi.sh --server_address=&lt;SERVER_ADDRESS&gt; --cid=0 --model=Net
</code></pre></article></div><p>Then, launch the Jetson client:</p><div><article><p>Copy</p><pre><code><span># make sure the --cid is unique</span><span>
</span>$ ./run_jetson.sh --server_address=&lt;SERVER_ADDRESS&gt; --cid=1 --model=Net
</code></pre></article></div><p>Internally, <code>run_pi.sh</code> and <code>run_jetson.sh</code> are identical with the exception that the former pulls a Docker image with PyTorch compiled for Arm CPUs and the latter pulls another with GPU support for NVIDIA-Jetson devices. Then, the Dockerfile recipe (see below) downloads the CIFAR-10 dataset. The last stage in the Docker build process copies the two scripts needed to run the Flower Client: <code>client.py</code> and <code>utils.py</code>. </p><div><article><p>Copy</p><pre><code><span>ARG</span><span> BASE_IMAGE_TYPE=cpu
</span><span></span><span># these images have been pushed to Dockerhub but you can find</span><span>
</span><span></span><span># each Dockerfile used in the `base_images` directory </span><span>
</span><span></span><span>FROM</span><span> jafermarq/jetsonfederated_$BASE_IMAGE_TYPE:latest
</span>
<span></span><span>RUN</span><span> apt-get install wget -y</span><span>
</span>
<span></span><span># Download and extract CIFAR-10</span><span>
</span><span></span><span>ENV</span><span> DATA_DIR=/app/data/cifar-</span><span>10</span><span>
</span><span></span><span>RUN</span><span> mkdir -p </span><span>$DATA_DIR</span><span>
</span><span></span><span>WORKDIR</span><span> </span><span>$DATA_DIR</span><span>
</span><span></span><span>RUN</span><span> wget https://www.cs.toronto.edu/\~kriz/cifar-10-python.tar.gz </span><span>
</span><span></span><span>RUN</span><span> tar -zxvf cifar-10-python.tar.gz</span><span>
</span>
<span></span><span>WORKDIR</span><span> /app</span><span>
</span>
<span></span><span># Scripts needed for Flower client</span><span>
</span><span></span><span>ADD</span><span> client.py /app</span><span>
</span><span></span><span>ADD</span><span> utils.py /app</span><span>
</span>
<span></span><span>ENTRYPOINT</span><span> [</span><span>"python3"</span><span>,</span><span>"-u"</span><span>,</span><span>"./client.py"</span><span>]</span></code></pre></article></div><p>The client will print various messages throughout the process. For this particular example, you should expect to see that a successful connection with the server was established and the duration of each of the three training rounds:</p><div><article><p>Copy</p><pre><code><span>#</span><span> [Docker build output -- omitted]</span><span>
</span>DEBUG flower 2020-12-12 11:52:54,264 | connection.py:36 | ChannelConnectivity.IDLE
<!-- -->DEBUG flower 2020-12-12 11:52:54,267 | connection.py:36 | ChannelConnectivity.CONNECTING
<!-- -->INFO flower 2020-12-12 11:52:54,267 | app.py:60 | Opened (insecure) gRPC connection
<!-- -->DEBUG flower 2020-12-12 11:52:54,337 | connection.py:36 | ChannelConnectivity.READY
<!-- -->Client 0: get_parameters
<!-- -->Client 0: fit
<!-- -->Training 1 epoch(s) w/ 781 batches each
<!-- -->Epoch took: 204.97 seconds
<!-- -->Client 0: fit
<!-- -->Training 1 epoch(s) w/ 781 batches each
<!-- -->Epoch took: 202.48 seconds
<!-- -->Client 0: fit
<!-- -->Training 1 epoch(s) w/ 781 batches each
<!-- -->Epoch took: 197.53 seconds
<!-- -->DEBUG flower 2020-12-12 12:03:19,797 | connection.py:68 | Insecure gRPC channel closed
<!-- -->INFO flower 2020-12-12 12:03:19,798 | app.py:71 | Disconnect and shut down
</code></pre></article></div><p>And that’s how easy it is to deploy and run Federated Learning applications with Flower and PyTorch. If you want to use another image classification model you can do so by editing <code>utils.py</code>. If you want to further customize your FL setup or design it from the grouds up, check <a href="https://flower.dev/blog/2020-12-11-federated-learning-in-less-than-20-lines-of-code">our previous blog</a> where we showed how to do FL in less than 20 lines of code using Flower and Tensorflow.</p></div></div></div>]]>
            </description>
            <link>https://flower.dev/blog/2020-12-16-running_federated_learning_applications_on_embedded_devices_with_flower?s=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-25444353</guid>
            <pubDate>Wed, 16 Dec 2020 16:19:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SaaSy Math: A Resource of SaaS Metrics for Your Startup]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25444277">thread link</a>) | @randrews543
<br/>
December 16, 2020 | https://www.talkinsaasy.com/saasy-math | <a href="https://web.archive.org/web/*/https://www.talkinsaasy.com/saasy-math">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><h2 data-ix="fade-in-on-scroll-2">A collection of simple, easy to use SaaS metrics with formulas, sample calculations, and examples of how to find this data in your own tech stack</h2></p><div><div><p>Net Revenue Retention (NRR)</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fbe4ad78fde0b0a238a1870_Net%20Revenue%20Retention.png" loading="lazy" alt=""></p></div><div><div><p>Net Revenue Retention represents how well you are <strong>retaining</strong> and <strong>expanding</strong> your existing recurring revenue. NRR is most typically measured either annually or month-to-month, but you are always comparing a cohort (a group of customers acquired at the same time) to see how their subscription revenue fares over the given time period. Think about your Netflix subscription, when you first signed up, are you still subscribed? And are you paying the same about as before?</p><p>‍<strong>Quick and SaaSy Way To Calculate:</strong> Go into your billing/subscription management system such as <a href="https://stripe.com/" target="_blank">Stripe</a> or <a href="https://www.zuora.com/" target="_blank">Zuora</a>. Go back twelve months and find all of the customers you acquired in that month, total their MRR and save their Subscription ID (Look for all subscriptions with a created date in that month). Then, go to the most recent full month of billing data and pull all of the invoices the match the Subscription ID for all the new customers 12 months ago (the subscription ID lives on the invoice object and you can join the data using these IDs to only get the invoices tied to those subscriptions). Once you have them all you can calculate the total MRR in the most recent month, then just divide that number by previous years MRR number and you have your annual net revenue retention. If you want to take this analysis to the next level shoot me an <a href="https://www.talkinsaasy.com/contact">email</a> and we can discuss how to segment and find how Net Revenue Retention can differ throughout your customer base.</p><p>Related Blog Posts: <a href="https://www.talkinsaasy.com/blog/net-revenue-retention" target="_blank">Net Revenue Retention</a></p></div></div></div><div><div><p>Gross Revenue Retention (GRR)</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fbe4aa6b26ad627a4efeb0f_Gross%20Revenue%20Retention.png" loading="lazy" alt=""></p></div><div><div><p>Gross Revenue Retention represents how well you are <strong>retaining</strong> your revenue and DOES NOT include how well you are expanding them. Similar to NRR, GRR measures customer cohorts aver a given time period to see how much of the initial MRR still remains over the given time period.</p><p><strong>Quick and SaaSy Way To Calculate:</strong> Similar to NRR, go into your billing/subscription management system such as <a href="https://stripe.com/" target="_blank">Stripe</a> or <a href="https://www.zuora.com/" target="_blank">Zuora</a>. Go back twelve months and find all of the customers you acquired in that month, total their MRR and save their Subscription ID (Look for all subscriptions with a created date in that month). Then, go to the most recent full month of billing data and pull all of the invoices the match the Subscription ID for all the new customers 12 months ago (the subscription ID lives on the invoice object and you can join the data using these IDs to only get the invoices tied to those subscriptions). Once you have them all you can calculate the total MRR in the most recent month but in the case of GRR, any customers who’s revenue expanded, you need to take out the additional revenue and just keep their original MRR. Then just divide that number by previous years MRR number and you have your annual gross revenue retention. If you want to take this analysis to the next level shoot me an <a href="https://www.talkinsaasy.com/contact">email</a> and we can discuss how to segment and find how Gross Revenue Retention can differ throughout your customer base.</p><p>Related Blog Posts: <a href="https://www.talkinsaasy.com/blog/net-vs-gross-revenue-retention" target="_blank">Net vs Gross Revenue Retention</a></p></div></div></div><div><div><p>Customer Churn</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fca548eec3a202105d82b1e_Customer%20Churn.png" loading="lazy" alt=""></p></div><div><div><p>Customer Churn is the measure of how many customers cancel over time from a given cohort. While the goal is to always minimize churn as best possible, SaaS/Subscription will have some churn and tracking it is crucial for success. Similar to Revenue Retention</p><p><strong>Quick and SaaSy Way To Calculate: </strong>Go into your billing/subscription management system such as <a href="https://stripe.com/" target="_blank">Stripe</a> or <a href="https://www.zuora.com/" target="_blank">Zuora</a>, or go into your CRM such as <a href="https://www.salesforce.com/" target="_blank">Salesforce</a> or <a href="https://www.hubspot.com/" target="_blank">HubSpot</a>. From either system you want to look for the Customer/Account table from the systems API. From that table you want to look up and count all of the unique customer ID’s that where created in a given month. Then month-to-month you want to run a check on those same ID’s to see how many of them are still active customers and then divide that number by the initial number in their first month. Typically, startups will look at churn on a monthly and annual basis and we highly recommend you track the changes in churn over time (ie. If the rate of churn is decreasing or increasing over time). If you want to take this analysis to the next level shoot me us <a href="https://www.talkinsaasy.com/contact">email</a> and we can discuss how to segment and find how customer churn can differ throughout your customer base.</p><p>Related Blog Posts: <a href="https://www.talkinsaasy.com/blog/churn-isnt-always-bad" target="_blank">Churn Isn’t Always Bad</a>, <a href="#https://www.talkinsaasy.com/blog/revenue-churn-vs-customer-churn">Revenue Churn vs Customer Churn</a><br><a href="https://www.talkinsaasy.com/blog/net-vs-gross-revenue-retention" target="_blank"></a></p></div></div></div><div><div><p>Customer Acquisition Cost (CAC)</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fca549a64abc2d9c6dfb094_Customer%20Acquisition%20Cost.png" loading="lazy" alt=""></p></div><div><div><p>Customer Acquisition Cost, or CAC, is the measure of how much a company must spend in order to acquire a new customer. Typically you look at CAC over a period of time (annually and/or month-to-month) to understand how it is trending for your business.<br>‍<br><strong>Quick and SaaSy Way To Calculate: </strong>To get your expenses you will need to go into your accounting/financial system such as Quickbooks or Xero, and track down your sales and marketing expenses for a time frame. This will include salaries, tech spend, marketing spend and any other expenses that go into your customer acquisition funnel. You then want to go into your CRM or billing and subscription management system and run a count of all the unique customer ID’s that have a created date in the same time period. You then divide the cost by your new customer count and you have your average CAC. If you want to take this analysis to the next level shoot us an <a href="https://www.talkinsaasy.com/contact">email</a> and we can discuss how to segment and find how customer acquisition cost can differ throughout your customer base.</p><p>Related Blog&nbsp;Posts:<a href="https://www.talkinsaasy.com/blog/dont-get-fooled-by-cac"> Don't Get Fooled By CAC</a></p></div></div></div><div><div><p>Retention Margin</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fd6a337e1ad8f8787d82e4d_Retention%20Margins.png" loading="lazy" alt=""></p></div><div><div><p>Retention Margins is a measurement of the % of top-line revenue that is left over each month once you have taken out the cost of revenue (Gross Margins) and the cost of keeping (retaining) your recurring revenue customers. Think of retention margins as the the home profit on a per customer basis after you have retained them month-over-month<br>‍<br><strong>Quick and SaaSy Way To Calculate: </strong>First you need to calculate your Gross Margin (Revenue-Cost of Revenue/Revenue). Then go into your accounting system like Quickbooks or Xero. You want to total up the amount of spend (payroll, overhead, etc.) for your customer service and success teams. You then want to add that number to your Cost of Revenue number and subtract that from your top-line revenue. That number is your retention profit (Take home $$$) after retaining your customers. Take your retention profit and divide it by your top-line revenue number and that will give you your retention margin.</p><p>Related Blog Posts: <a href="https://www.talkinsaasy.com/blog/why-net-and-gross-revenue-retention-matter">Why Net AND&nbsp;Gross Revenue Retention Matter</a></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.talkinsaasy.com/saasy-math</link>
            <guid isPermaLink="false">hacker-news-small-sites-25444277</guid>
            <pubDate>Wed, 16 Dec 2020 16:14:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Alt-Cities: Why Tech, Finance, and Music Chose Austin, Miami, and Nashville]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25444176">thread link</a>) | @jseliger
<br/>
December 16, 2020 | http://www.yared.com/2020/12/the-alt-cities-why-tech-finance-and.html | <a href="https://web.archive.org/web/*/http://www.yared.com/2020/12/the-alt-cities-why-tech-finance-and.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-1263537399197749957">
<div><p><a href="https://1.bp.blogspot.com/-QZ-6Vs0QrWE/X9j2BGe5B0I/AAAAAAAAnSg/Cj7V2U8ZjQAVBAvjQGNDdQVPpz3I4pfuACLcBGAsYHQ/s1600/alt-cities.jpg"><img data-original-height="900" data-original-width="1600" height="316" src="https://1.bp.blogspot.com/-QZ-6Vs0QrWE/X9j2BGe5B0I/AAAAAAAAnSg/Cj7V2U8ZjQAVBAvjQGNDdQVPpz3I4pfuACLcBGAsYHQ/w563-h316/alt-cities.jpg" width="563"></a></p></div><p><span>Three months ago, my wife and I moved from San Francisco to Miami. I previously lived in San Francisco for over 23 years, where I started multiple companies and worked at companies like Sun Microsystems. Given the spate of people now moving, I thought it would be useful to aggregate the unique characteristics that have turned Austin, Miami, and Nashville into such hot destinations.</span></p><p><span>Globalization and network effects have produced centers of industry in mega-cities, such as finance in New York and technology in San Francisco. It takes a monumental event to displace an industry from a mega-city; the only such event in the modern era is the handover of Hong Kong to China, which shifted Asian finance to Singapore.</span></p><p><span>The coronavirus is now as significant an event as the handover of Hong Kong. Three alt-cities (alternative cities) for key industries are quickly emerging: finance from New York to Miami, technology from San Francisco to Austin, and music from Los Angeles to Nashville. There is also cross-pollination in these emerging centers. Much like New York started to have a tech scene, Miami has a rapidly burgeoning tech scene with </span><a href="https://twitter.com/FrancisSuarez/status/1338605468894244865?s=20"><span>great support from its mayor</span></a><span> Francis Suarez.</span></p><p><span>Alt-cities require multi-faceted kindling to become viable competitors:</span></p><h2><span>Key people</span></h2><p><span>It's all about the key people. You can't move the center of an industry without moving key players. Years of attempts to kindle homegrown Silicon Valleys everywhere from the Silicon Prairie to Silicon Beach have fallen flat as a replacement to Silicon Valley because </span><a href="https://www.statista.com/statistics/424167/venture-capital-investments-usa-by-state/"><span>the key people stayed put</span></a><span>.&nbsp;</span></p><p><span>Rather than going fully remote, key people are aggregating in cities where they will be able to network post-COVID. Austin has attracted well-known technology figures such as </span><a href="https://www.bbc.com/news/technology-55246148"><span>Elon Musk</span></a><span>, </span><a href="https://www.businessinsider.com/dropbox-drew-houston-moving-to-austin-report-2020-11"><span>Drew Houston</span></a><span>, and </span><a href="https://www.cnbc.com/2020/11/06/palantir-co-founder-joe-lonsdale-leaving-silicon-valley.html"><span>Joe Lonsdale</span></a><span>. Miami and South Florida have landed finance billionaires </span><a href="https://www.miamiherald.com/news/business/real-estate-news/article244933672.html"><span>Carl Icahn</span></a><span> and </span><a href="https://www.bloomberg.com/news/articles/2020-10-21/singer-s-41-billion-hedge-fund-moving-headquarters-to-florida"><span>Paul Singer</span></a><span>, as well as prominent technology investors </span><a href="https://fortune.com/2020/11/17/keith-rabois-investor-silicon-valley-loses-another-tech-icon/"><span>Keith Rabois</span></a><span>, </span><a href="https://www.bizjournals.com/sanfrancisco/news/2020/12/01/prominent-venture-capitalist-joins-bay-area-exodus.html"><span>David Blumberg</span></a><span>, and </span><a href="https://www.bizjournals.com/southflorida/news/2018/07/03/shervin-pishevar-buys-miami-beach-home.html"><span>Sherwin Pishevar</span></a><span>. Nashville hosts well-known artists including </span><a href="https://virtualglobetrotting.com/map/jack-whites-house/view/google/"><span>Jack White</span></a><span>, </span><a href="https://www.velvetropes.com/backstage/miley-cyrus-house"><span>Miley Cyrus</span></a><span>, and </span><a href="https://www.velvetropes.com/backstage/taylor-swift-nashville-house"><span>Taylor Swift</span></a><span>, who rejected Los Angeles and helped shift Nashville from country to other forms of music. These cities are attracting free thinkers known to lead the way, leaving the impression that those left behind in the origin cities are clock-punchers at Google.</span></p><h2><span>Prestigious companies</span></h2><p><span>Alt-cities need well-known and prestigious companies to relocate or create significant outposts to help create an ecosystem. These companies help attract new talent to the area as well as transfers from other locations.</span></p><p><span>The Miami area has attracted numerous hedge funds, including </span><a href="https://www.bloomberg.com/news/articles/2020-10-21/singer-s-41-billion-hedge-fund-moving-headquarters-to-florida"><span>Elliott Management</span></a><span>, and even top-tier Wall Street firms such as </span><a href="https://www.bloomberg.com/news/articles/2020-10-08/blackstone-joins-rush-to-miami-with-office-for-technology-staff"><span>Blackstone</span></a><span> and </span><a href="https://therealdeal.com/national/2020/12/07/goldman-sachs-plans-move-to-south-florida/"><span>Goldman Sachs</span></a><span> are relocating key divisions to Miami. In Austin, </span><a href="https://austonia.com/tesla-austin-factory-2021"><span>Tesla is building its largest facility on the outskirts</span></a><span> and </span><a href="https://www.cnbc.com/2020/12/11/oracle-is-moving-its-headquarters-from-silicon-valley-to-austin-texas.html"><span>Oracle is moving its&nbsp; headquarters</span></a><span> there, joining outposts from Amazon, Apple, Facebook, Dell, and many other top-tier technology companies. Brand name Silicon Valley VC firms are closing their </span><a href="https://www.vox.com/2015/4/13/11561376/has-south-park-finally-become-the-new-sand-hill-road"><span>San Francisco South Park outposts</span></a><span> and </span><a href="https://www.theinformation.com/articles/austin-emerges-as-a-hot-spot-for-silicon-valley-investors"><span>setting up shop in Austin</span></a><span>. Nashville has sprung from its country music roots, with Warner, RCA, Sony, Universal, and other top-tier music labels expanding in the city.</span></p><h2><span>Business-friendly</span></h2><p><span>While New York City and San Francisco are mulling converting their emptied </span><a href="https://www.nytimes.com/2020/12/11/nyregion/nyc-commercial-real-estate.html"><span>office buildings into residences</span></a><span>, the alt-cities have seen an increase in </span><a href="https://www.miamiherald.com/news/business/article247261699.html"><span>office space demand</span></a><span> and are quickly green-lighting </span><a href="https://www.cpexecutive.com/post/top-10-office-projects-under-construction-in-miami/"><span>new office space projects</span></a><span>. Tesla's new facility in the outskirts of Austin was fast-tracked and is nearing completion.</span></p><p><span>The coronavirus highlighted how business-friendly a jurisdiction was in terms of using data and science to set rational re-opening parameters. With pandemic protocols in place, Tesla's factory was open in China, Boeing’s factories were open in Washington, and auto factories were open in Detroit, Alabama, and South Carolina. Tesla's San Francisco-area factory was one of the only auto factories in the world that was still closed, forcing Elon Musk to play a </span><a href="https://www.theverge.com/2020/5/11/21255149/elon-musk-tesla-fremont-factory-reopen-order-arrest-alameda"><span>game of brinksmanship</span></a><span> with local authorities, with the county’s assemblywoman </span><a href="https://www.marketwatch.com/story/california-assemblywoman-hits-elon-musk-with-an-f-bomb-after-he-says-will-move-teslas-hq-out-of-state-2020-05-10"><span>sending Musk a vulgar missive</span></a><span>.</span></p><p><span>Escaping increasingly bizarre </span><a href="https://calmatters.org/california-divide/2020/11/san-francisco-ceo-tax-income-gap/"><span>taxes</span></a><span> and </span><a href="https://www.businessinsider.com/california-labor-jobs-law-bad-confusing-freelance-workers-2019-11"><span>regulations</span></a><span>, it’s now no surprise for innovators to start a new </span><a href="https://www.miamitodaynews.com/2020/03/17/sophisticated-professionals-flood-into-miami-with-hedge-funds/"><span>hedge fund in Miami</span></a><span>, a new </span><a href="https://www.bizjournals.com/austin/inno/stories/roundups/2020/11/02/austin-startup-funding-october-2020.html"><span>tech startup in Austin</span></a><span>, or a new </span><a href="https://webcache.googleusercontent.com/search?q=cache:nHBB8x0E5zkJ:https://www.tennessean.com/story/news/2020/12/10/state-music-industry-2020-not-great-nashville-leading/3885391001/+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=us"><span>record label in Nashville</span></a><span>. Access to people and capital will be equivalent to the previous centers of industry.</span></p><h2><span>Affordable suburban living</span></h2><p><span>From the 1980s to the mid-1990s, cities suffered from high crime rates and numerous quality of life issues. New York City, San Francisco, Los Angeles, and some other major cities have recreated the environment of that era, with </span><a href="https://twitter.com/RMB/status/1337629864329961477?s=20"><span>non-scientific pandemic restrictions</span></a><span> that devastated local businesses and a penchant for placing the </span><a href="https://www.nytimes.com/2020/08/18/nyregion/uws-homeless-hotels-nyc.html"><span>mentally ill directly in family-oriented, residential neighborhoods</span></a><span>. These cities have </span><a href="https://sfist.com/2019/11/16/boudin-will-not-prosecute-prostitution-public-camping-and-other-quality-of-life-crimes-once-sworn-in/"><span>stopped prosecuting</span></a><span> many property and quality of life crimes, inevitably leading to </span><a href="https://abc7news.com/society/majority-of-bay-area-residents-say-quality-of-life-is-getting-worse/5963390/"><span>bad quality of life</span></a><span> and </span><a href="https://www.thecity.nyc/2020/9/14/21437309/nypd-crime-response-time-still-lags-three-months-post-protest"><span>apathetic enforcement</span></a><span> of more serious crimes.</span></p><p><span>The coronavirus has reset consumer expectations back to suburban living with the mental health benefits of living in greenspace. There has been an exodus from major industry centers to their suburbs and to the alt-cities. The alt-cities of Miami, Austin, and Nashville all offer car-friendly, suburban living, relatively cheap housing, and continual housing construction. With the acceleration of sustainable building materials and </span><a href="https://www.fastcompany.com/90583426/the-price-of-solar-electricity-has-dropped-89-in-10-years"><span>clean and cheap energy</span></a><span>, the urban planning rationale to pack people into urban cores with mass transportation was already beginning to fray, and the coronavirus has sealed its fate.</span></p><h2><span>Culture and openness</span></h2><p dir="ltr"><span>Miami is incredibly diverse, a nightlife capital of the world, has a booming art scene centered around Art Basel, and is almost as LGBTQ friendly as San Francisco. Austin and Nashville are both well known for live music and vibrant nightlife. All three offer farm-to-table restaurants and craft breweries, as artisans follow their clientele to new locations where they are unlikely to be </span><a href="https://signalscv.com/2020/12/judge-orders-l-a-county-to-provide-evidence-on-outdoor-dining-ban-lawsuit/"><span>arbitrarily shut down</span></a><span> or face inordinately high </span><a href="https://www.nytimes.com/2020/11/09/business/small-business-insurance-unrest-kenosha.html"><span>insurance premiums</span></a><span>.</span></p><p><span>New York City, San Francisco, and Los Angeles are increasingly recognized for only accepting a single, maximalist viewpoint with a </span><a href="https://brokeassstuart.com/2016/02/18/open-letter-to-justin-keller-tech-bro/"><span>rapidly shrinking Overton window</span></a><span> that even excludes working with </span><a href="https://www.cnbc.com/2020/08/26/palantir-makes-denver-the-city-to-watch-amid-silicon-valleys-exodus.html"><span>the defense industry</span></a><span>. In Miami, </span><a href="https://www.miamiherald.com/news/politics-government/article247212794.html"><span>half the people you meet are conservative and half are&nbsp; liberal</span></a><span>, and there is an acceptance that there are alternative viewpoints. A diversity of thought -- rather than a single yet constantly shifting viewpoint -- is attracting "</span><a href="https://www.youtube.com/watch?v=mtftHaK9tYY"><span>the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes</span></a><span>" to the alt-cities.</span></p><h2><span>Low taxes and quality government</span></h2><p><span>People are not moving solely for tax purposes. New York and California’s tax rates are only a few points higher than they were twenty years ago. However, once people decide to move, of course tax rate is a factor in choosing a destination. Florida, Texas, and Tennessee seemingly offer everything that California and New York offer: highways, streets, schools, police departments, fire departments, and such. All the government services one would expect are there, and none of the capital gains taxes that entrepreneurs and venture capitalists typically pay.</span></p><p><span>As comedian and political commentator Bill Maher recently noted, California is </span><a href="https://www.foxnews.com/entertainment/bill-maher-california-super-high-taxes"><span>reminiscent of a 1970s Italy</span></a><span>, with high taxes and terrible government services. In return for high taxes, one would expect to go to Hunter's Point, East Palo Alto, or East San Jose and see excellent schools and services for disadvantaged people. A </span><a href="https://www.fox5vegas.com/news/virgin-hyperloop-completes-first-test-with-actual-passengers-in-las-vegas/article_d17d8d68-418a-5d8e-bf9b-9a28f906c324.html"><span>hyperloop</span></a><span> instead of a </span><a href="https://www.cagw.org/thewastewatcher/californias-100-billion-nightmare-high-speed-rail-project"><span>failed high-speed train</span></a><span>. </span><a href="https://www.sfchronicle.com/bayarea/article/Bay-Area-awakes-to-foreboding-smoke-choked-15553731.php"><span>Fire mitigation</span></a><span> and </span><a href="https://www.sfchronicle.com/bayarea/article/Bay-Area-blackouts-What-you-need-to-know-about-15488351.php"><span>stable power</span></a><span> to complement </span><a href="https://www.wsj.com/articles/california-to-ban-sales-of-new-gas-powered-cars-starting-in-2035-11600882738"><span>long term climate change goals</span></a><span>. A boom in middle-class housing rather than a </span><a href="https://www.nytimes.com/2020/11/30/realestate/california-housing-market-price.html"><span>$700K median house price</span></a><span>. California and New York are becoming bad versions of Singapore, with a wealthy technocratic elite, an immigrant servant class, and a </span><a href="https://www.cnbc.com/2018/03/19/californians-fed-up-with-housing-costs-and-taxes-are-fleeing-state.html"><span>collapsed middle class</span></a><span>.</span></p><h2><span>What’s next for alt-cities?</span></h2><p><span>The alt-city trend has only just begun as legacy cities seem ideologically unwilling to waver on these characteristics. Other industries are starting to relocate, including the Los Angeles entertainment industry to </span><a href="https://www.productionhub.com/directory/profiles/studios-soundstages-production-television-film/us/nevada/las-vegas"><span>Las Vegas by piggybacking on the porn industry</span></a><span>, Seattle aerospace industry to </span><a href="https://abcnews4.com/news/local/boeing-moving-all-787-dreamliner-production-to-north-charleston"><span>Charleston by piggybacking on Boeing</span></a><span>, New York art industry to </span><a href="https://www.nytimes.com/2019/03/04/arts/design/artcenter-south-florida-miami-millions.html"><span>Miami by piggybacking on Art Basel</span></a><span>, Denver building a bigger technology sector by </span><a href="http://www.metrodenver.org/d/m/3T4"><span>piggybacking on it broadcast/telecommunications base</span></a><span>, and the New York retail fashion industry to </span><a href="https://fashion2fiber.osu.edu/exhibits/show/columbus-fashion-story/the-limited"><span>Columbus by piggybacking on L Brands</span></a><span>.</span></p><p><span>We are at a momentous intersection where numerous Hong Kongs are becoming Singapores.</span></p>
</div></div>]]>
            </description>
            <link>http://www.yared.com/2020/12/the-alt-cities-why-tech-finance-and.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25444176</guid>
            <pubDate>Wed, 16 Dec 2020 16:05:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Performance 500: Websites of the Fortune 500 Ranked by Page Speed]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25444128">thread link</a>) | @tomhanlon
<br/>
December 16, 2020 | https://reachlightspeed.com/blog/the-performance-500-websites-of-the-fortune-500-ranked-by-page-speed/ | <a href="https://web.archive.org/web/*/https://reachlightspeed.com/blog/the-performance-500-websites-of-the-fortune-500-ranked-by-page-speed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><h2>The Performance 500</h2><p>Google <a href="https://developers.google.com/search/blog/2020/11/timing-for-page-experience">recently announced</a> that Page Rank changes are coming: performance metrics (Core Web Vitals like Largest Contentful Paint, Cumulative Layout Shift and First Input Delay) will soon be taken into account for prioritizing search listings.</p><p>We wanted to see how some of America's top companies —The Fortune 500— would stack up against each other when viewed in a different light: website performance. Is there a correlation between business performance and Page Speed performance? What else might we find?</p><p>Using Google’s <a href="https://developers.google.com/speed/pagespeed/insights/">PageSpeed Insights API</a> and 2020 Fortune 500 data, we compiled what we’re calling “The Performance 500”.</p><p><a href="https://docs.google.com/spreadsheets/d/17qQh1zKpa5qwNBzXcCgkVbsy-YMHV0DB_doNgktcp8M/edit?usp=sharing"><picture><source srcset="https://reachlightspeed.com/img/blog/post-performance-500-chart.avif" type="image/avif"><source srcset="https://reachlightspeed.com/img/blog/post-performance-500-chart.webp" type="image/webp"><img src="https://reachlightspeed.com/img/blog/post-performance-500-chart.jpg" width="768" loading="lazy" alt="The Performance 500 (Google Sheets)"></picture></a></p><p><a href="https://docs.google.com/spreadsheets/d/17qQh1zKpa5qwNBzXcCgkVbsy-YMHV0DB_doNgktcp8M/edit?usp=sharing">The Performance 500</a></p><h3>And the Winner Is</h3><p>You’ll notice a recognizable name in first place for the Performance 500: <a href="https://www.berkshirehathaway.com/">Berkshire Hathaway</a>. Its Chairman and CEO, Warren Buffet, famous for continuing to live in the same house he purchased in 1958, bested even Google’s parent company in page speed performance using a simple HTML site with minimal resources to deliver content. Hats off to you, Warren and team.</p><h3>Other Interesting Findings</h3><ul><li>Only 4 sites out of the 500 (.8%) scored above a 90% or above on their PageSpeed Insights Performance Score</li><li>~85% (424/500) of sites have a Performance Score of less than 50</li><li>The average Performance Score is ~29</li><li>The average Largest Contentful Paint (LCP) metric is 13.5 seconds(!)</li><li>Less than half of the Fortune 500 had a Cumulative Layout Shift (CLS) Score of better than .1</li><li>Only 11 of the 500 have "Good" First Input Delay (FID) scores</li></ul><h3>Understanding Core Web Vitals (LCP, CLS &amp; FID)</h3><p>A quick reference:</p><ul><li>LCP: Largest Contentful Paint - How long does it take to render the largest element within the viewport (measured in seconds)</li><li>CLS: Cumulative Layout Shift - How often things move around as the page loads (presented as a score value)</li><li>FID: First Input Delay - How soon after a user input does the browser process the event (measured in milliseconds)</li></ul><p>We’ve included <a href="#understanding-core-web-vitals">a section below</a> that explains these in further detail in the language used on <a href="https://web.dev/">web.dev</a>.</p><h3>How We Tested</h3><p>We ran 5 tests at different times of day over a period of two weeks. Those results have been averaged into the scores presented in the table above. PageSpeed Insights never returned a Performance Score for ViacomCBS so we ranked it last.</p><h3>Ranking Methodology</h3><p>We chose to rank these companies “Performance 500” rank first by Google’s PageSpeed Insights Performance Score, then by Largest Contentful Paint (LCP), then by Cumulative Layout Shift (CLS), then First Input Delay (FID). We preferred this ranking order as FID is not assigned a weight in <a href="https://web.dev/performance-scoring/#lighthouse-6">Google’s weighting of the performance score</a>.</p><h3>Color Coding</h3><p>We chose to use the green, yellow and red labels using the same color coding scheme used by Page Speed Insights. These vary by metric and can be found in the <a href="https://developers.google.com/speed/docs/insights/v5/about#categories">PageSpeed Insights documentation</a>.</p><h3>Device Type</h3><p>We also chose to only show the mobile rankings of these sites. A prior version of this table existed with desktop scores as well but we felt it was too cluttered to meaningfully show desktop and mobile metrics in the same table.</p><h2 id="understanding-core-web-vitals">Understanding Core Web Vitals (Loading, Visual Stability, and Interactivity Metrics)</h2><p>Starting next May, as Google Search Results start to take into account Loading (Largest Contentful Paint), Interactivity (First Input Delay) and Visual Stability (Cumulative Layout Shift) metrics, sites that have not focused on improving these metrics will be penalized against sites that are faster to load. Let’s take a look at each of these categories.</p><h3>Loading: Largest Contentful Paint (LCP)</h3><p>Google's Definition: The Largest Contentful Paint (LCP) metric reports the render time of the largest image or text block visible within the viewport. <a href="https://web.dev/lcp/">web.dev</a></p><picture><source srcset="https://reachlightspeed.com/img/blog/post-performance-500-lcp-sm.svg" media="(max-width: 640px)"><img src="https://reachlightspeed.com/img/blog/post-performance-500-lcp-lg.svg" width="768" loading="lazy" alt="Largest Contentful Paint (LCP)"></picture><h3>Visual Stability: Cumulative Layout Shift (CLS)</h3><p>Google's Definition: CLS measures the sum total of all individual layout shift scores for every unexpected layout shift that occurs during the entire lifespan of the page.</p><p>A layout shift occurs any time a visible element changes its position from one rendered frame to the next. <a href="https://web.dev/cls/">web.dev</a></p><picture><source srcset="https://reachlightspeed.com/img/blog/post-performance-500-cls-sm.svg" media="(max-width: 640px)"><img src="https://reachlightspeed.com/img/blog/post-performance-500-cls-lg.svg" width="768" loading="lazy" alt="Cumulative Layout Shift (CLS)"></picture><h3>Interactivity: First Input Delay (FID)</h3><p>Google's Definition: FID measures the time from when a user first interacts with a page (i.e. when they click a link, tap on a button, or use a custom, JavaScript-powered control) to the time when the browser is actually able to begin processing event handlers in response to that interaction. <a href="https://web.dev/fid/">web.dev</a></p><picture><source srcset="https://reachlightspeed.com/img/blog/post-performance-500-fid-sm.svg" media="(max-width: 640px)"><img src="https://reachlightspeed.com/img/blog/post-performance-500-fid-lg.svg" width="768" loading="lazy" alt="First Input Delay (FID)"></picture><h2>Incentivizing A Faster Web</h2><p>We think these Page Rank changes from Google will have a positive impact, incentivizing companies to focus on improving page speed performance and ultimately the user experience.</p><p>Special thanks to Lekshmi Nair’s <a href="https://github.com/lekshmicnair/Fortune500_Financial_Analysis">repo</a> as a starter for most of the 2020 Fortune 500 company data in this table.</p></section></div>]]>
            </description>
            <link>https://reachlightspeed.com/blog/the-performance-500-websites-of-the-fortune-500-ranked-by-page-speed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25444128</guid>
            <pubDate>Wed, 16 Dec 2020 16:01:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Regret Quitting Astrophysics]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 124 (<a href="https://news.ycombinator.com/item?id=25444069">thread link</a>) | @petschge
<br/>
December 16, 2020 | http://www.marcelhaas.com/index.php/2020/12/16/i-regret-quitting-astrophysics/ | <a href="https://web.archive.org/web/*/http://www.marcelhaas.com/index.php/2020/12/16/i-regret-quitting-astrophysics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-223">
	
	<!-- .entry-header -->

	<div>
		
<p>In 2013 I decided to quit my career in astrophysics, move back “home” and become a data scientist. The <a href="http://www.marcelhaas.com/index.php/2018/03/30/leaving-the-field-becoming-an-extronomer/">blog post</a> I wrote about my decision was probably my best read publication as a professional astronomer and it was moving to read all the reactions from people who were struggling with similar decisions. I meant every word in that blog post and I still agree with most of what I said. Now, 7 years after the fact, it is time to confess: I deeply regret quitting.</p>



<p>This post is meant to give my point of view. Many people who left academia are very happy that they did. Here I present some arguments why one might not want to leave, which I hope will be of help for people facing decisions like these.</p>



<p><span>I miss being motivated.</span> In the first few years after jumping ship many people asked me why I would ever wanted to <em>not</em> be a professional astronomer. I have always said that my day-to-day work wasn’t too different, except that what I did with data was about financial services or some other business I was in, rather than about galaxies and the Universe, but that the “core activities” of work were quite similar. That is kind of true. On an hour by hour basis, often I’m just writing (Python) code to figure things out or build a useful software product. The motivation to do what you do, though, is very <em>very</em> different. The duty cycle and technical depth of projects are short and shallow and the emphasis of projects is much more on getting working products than on understanding. I am doing quite well (in my own humble opinion), but it is hard to get satisfaction out of my current job.</p>



<p><img loading="lazy" width="546" height="340" src="http://www.marcelhaas.com/wp-content/uploads/2020/12/academic_hat.png" alt="" srcset="http://www.marcelhaas.com/wp-content/uploads/2020/12/academic_hat.png 546w, http://www.marcelhaas.com/wp-content/uploads/2020/12/academic_hat-300x187.png 300w" sizes="(max-width: 546px) 100vw, 546px"></p>



<p><span>I miss academic research.</span> The seeds of astronomy were planted at very young age (8, if I remember correctly). The fascination for the wonders of the cosmos has changed somewhat in nature while growing up but hasn’t faded. Being at the forefront of figuring things out about the workings of the Universe is amazing, and unparalleled in any business setting. Having the freedom to pick up new techniques that may be useful for your research is something that happened to me only sporadically after the academic years. The freedom to learn and explore are valuable for creative and investigative minds and it doesn’t fit as well in most business settings that I have seen.</p>



<p><span>I miss working at academic institutions.</span> The vibe of being at a large research institute, surrounded by people who are intrinsically motivated to do what they do was of great value to me. Having visitors over from around the globe with interesting, perhaps related work was a big motivator. That journal clubs, coffee discussions, lunch talks, colloquiums etc. are all “part of the job” is something that even most scientists don’t always seem to fully appreciate. Teaching, at the depth of university level classes, as a part of the job is greatly rewarding (I do teach nowadays!).</p>



<p><span>I miss passion and being proud of what I do.</span> The <a href="https://www.google.nl/search?hl=nl&amp;q=sexiest+job+of+the+21st+century">internet </a>says I have ”the sexiest job of the 21<sup>st</sup> century”, but I think my previous job was more enjoyable to brag about at birthday parties. I can do astro as a hobby, but that simply doesn’t give you enough time to do something substantial enough.</p>



<p><span>I don’t miss …</span> Indeed, the academic career also had its downsides. There is strong competition and people typically experience quite some pressure to achieve. The culture wasn’t always very healthy and diversity and equality are in bad shape in academia. Success criteria of your projects and of you as a person are typically better motivated in business. The obligatory nomadic lifestyle that you are bound to have as an early career scientist were a very enjoyable and educational experience, but it can easily become a burden on your personal life. The drawbacks and benefits of any career path will balance out differently for everybody. If you get to such a point, don’t take the decision lightly.</p>



<div><figure><img loading="lazy" src="http://www.marcelhaas.com/wp-content/uploads/2020/12/decision.png" alt="" width="89" height="89" srcset="http://www.marcelhaas.com/wp-content/uploads/2020/12/decision.png 200w, http://www.marcelhaas.com/wp-content/uploads/2020/12/decision-150x150.png 150w" sizes="(max-width: 89px) 100vw, 89px"></figure></div>



<p>The people who questioned my decision to become an extronomer were right. I was wrong. It seems too late to get back in. I think I have gained skills and experience that can be very valuable to the astronomical community, but I know that that is simply not what candidates for academic positions are selected on. On top of that, being geographically bound doesn’t help. At least I will try to stay close to the field and who knows what might once cross my path.</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>http://www.marcelhaas.com/index.php/2020/12/16/i-regret-quitting-astrophysics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25444069</guid>
            <pubDate>Wed, 16 Dec 2020 15:56:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A year's worth of learnings from adopting Mob programming]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25443874">thread link</a>) | @dinispeixoto
<br/>
December 16, 2020 | https://www.farfetchtechblog.com/en/blog/post/a-year-s-worth-of-learnings-from-adopting-mob-programming/ | <a href="https://web.archive.org/web/*/https://www.farfetchtechblog.com/en/blog/post/a-year-s-worth-of-learnings-from-adopting-mob-programming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>At FARFETCH, teams are encouraged to try new development methodologies so that they can deliver even better results while also improving productivity. As a fairly new team, we have continuously been looking for different methodologies that best fit our needs, such as avoiding knowledge silos or a slow-paced reviewing process. Although not every approach that we have tried has worked, the ones that did are now part of our daily development workflow and play a key role in the outcome of the tasks that we deliver.</p><p>A year ago, our team was first introduced to <a href="https://mobprogramming.org/" target="_blank">Mob Programming</a>, and we have been using it since then. The concept that was once hard to fathom is now the go-to approach when dealing with most of our sprint tasks. Although being able to use Mob Programming daily has come with many different types of challenges, the results have been surprisingly good.&nbsp;</p><p>When using Mob Programming, instead of having each team element working on its own task, the whole team gathers together to tackle the same task. It includes using a single workstation and only one person typing - <span>the Driver</span> - while the remaining people are describing the path that should be taken.</p><blockquote><p><span>Itâ€™s a software development approach where the whole team works on the same thing, at the same time, in the same space, and at the same computer. - Woody Zuill (2014)</span></p></blockquote><p>Mob Programming is somewhat similar to Pair Programming. While the latter consists of having two team members sharing the same workstation, Mob Programming goes a bit further and implies having the entire team focused on a single task. Even though Pair Programming is a great tool to share knowledge, improve communication and even bring better outcomes (as a consequence of having multiple people thinking about the same problem), it confines these advantages to only two elements on a team. On the other hand, Mob Programming can amplify these benefits to the whole team.</p><p>Yet, having an entire team working on the same problem brings its own challenges. It's imperative that the team establishes a set of well-defined procedures and rules. Furthermore, Mob Programming may not be suitable for all kinds of tasks or teams. Depending on the task the team is tackling, it should first be established whether Mob, Pair or Solo Programming is the appropriate methodology. None of the three is suitable for all situations. It's up to the teams to give them a try and figure out when to use them.</p><p>A typical Mob Programming setup consists of moving the team to an isolated space (e.g. a meeting room) and bringing one computer that should be connected to either a large monitor or a projector. Having a whiteboard to write down possible solutions and describe the next steps is great to empower collaborative brainstorming. Seats and tables for everyone is a must, as everyone should be comfortable during the session, this is particularly relevant as these sessions tend to be time-consuming. Since the beginning of the Covid-19 pandemic, we have adapted our ways of working to facilitate Remote Mob Programming sessions - but more to come on that later.&nbsp;</p><p><img src="https://www.farfetchtechblog.com/fotos/editor2/Dinis_Peixoto/Image_01.png" alt=""></p><p>Two key roles must be considered when using Mob Programming: the Driver and the Navigator. The Driver is the person at the keyboard, responsible for moving the codebase forward. The Navigator understands what the group has decided to aim for and provides instructions to the Driver. The Navigator shouldn't dictate the actual code that the Driver has to write down, only the expected solution. Sometimes, the Navigator role may not be needed. It is up to the Driver to opt-in or out. Nonetheless, when there's no Navigator, the Driver may get lost by having multiple people explaining what to do. These roles should rotate between all team members at regular intervals (usually monitored by a timer).</p><p>The session should be held continuously until the task is done. Quick breaks, like coffee or bathroom, are allowed and shouldn't require the session to stop. Some longer breaks like lunch must be agreed between the team so that everyone does it at the same time to prevent distractions and absences.</p><div><p>The first thing that may come to one's mind is that Mob Programming jeopardizes the team's overall productivity. After all, having an entire team working on the same task certainly means that both the team's velocity and throughput will be compromised, right?</p></div><div><p>More often than not, people tend to forget that delivering a task includes a lot more than just writing code. It's common that most of the time spent on a particular task is on coming up with the right solution or waiting for the team to review what was done. In our case, each task requires approval from 3 different people, which implies that they stop what they are doing, get up to speed, and finally review the result.</p></div><div><p>When using a development workflow like Solo Programming, once a developer puts the task up for review, the team has to understand all the requirements and review what was done, while also trying to identify what was the problem-solving process that the author took. The fact that the team has to go through someone elseâ€™s work without being completely aware of the decisions behind the proposed solution might take longer and prevent some mistakes from being identified.</p></div><p>Whereas when using Mob Programming, taking advantage of insights and knowledge from the whole team may lead to the task being delivered quicker while also with a better solution. When it comes to the review process, it will also be straightforward as everyone owns the decisions that were made and the solution path that was taken.&nbsp;</p><p>We have been using Mob Programming for over a year. Over this period, we have been trying to refine our methodology so that we can make the most out of our sessions. Some of the phases that have improved our workflow are described below.</p><ol><li><span>Task scouting:</span> each team member should, individually, check the task details prior to the session. Investing time on exploring the task beforehand will considerably shorten the time required on the next phase.</li><li><span>Purpose clarification: </span>at the beginning of the session, someone should present the problem at hand and make sure that everyone has a clear grasp of what the team is trying to achieve. Any questions about the purpose of the task should be raised at this time.</li><li><span>Work breakdown:</span> with the purpose of clarified, it's now time to identify the work blocks that have to be monitored during the session. The different tasks that result from this analysis should be prioritized and can be split into even smaller tasks if needed.</li><li><span>Execution:</span> based on the tasks identified previously, the team must try to work on each task by following the agreed order. The team should expect new tasks to surface throughout the session. If it happens, the order of the tasks can be adjusted.</li><li><span>Debriefing:</span> at the end of the session, the team will need to look at the initially defined tasks and check if everything was tackled. The solution should be carefully reviewed together before submitting it for team review. It's highly recommended to provide some time for an individual review to address groupthink problems.</li></ol><p>Equally important are the rules that our team has defined so far. Periodically, we revisit them and discuss whether or not some updates are required. Trying to make this an iterative process is extremely important to enhance the overall experience of our Mob Programming sessions over time.</p><ol><li><span>Driving/navigation time:</span> each team member will be in the Driver/Navigator role for 15 minutes. If a discussion comes up, the timer should stop so that both the Driver and Navigator can participate.</li><li><span>Complete focus on the session:</span> everyone in the room has to be focused on the session. If someone needs to work on something else, they must leave the room to avoid distracting the team.</li><li><span>Mandatory and optional breaks:</span> there are three mandatory breaks where the session must be stopped: morning coffee, lunch and afternoon coffee. Additional breaks are allowed but should be minimized to reduce the impact on focus. These sessions are very demanding on every team member so, if one cannot focus on the current tasks, taking a break is completely acceptable.</li><li><span>Research time:</span> whenever research is required, it should be done primarily by the Driver with the help of the team. Parallel research streams are allowed, as long as the team is aware of them.</li><li><span>Identify Mob Programming tasks ahead of time:</span> we always try to decide upon whether a specific task is going to be tackled through Mob Programming or not. It facilitates any coordination required during our sprint.</li></ol><p>Due to the COVID-19 global pandemic, we had a new challenge ahead of us: <a href="https://www.remotemobprogramming.org/" target="_blank">Remote Mob Programming</a>. As a consequence, we had to go through the rules above and update them as a means to adapt to the reality of having the whole team working remotely.</p><ol><li><span>Driving/navigation time:</span> this should be increased, in our case, we adjusted it to 45 minutes, due to the extra work required when changing the Driver (e.g. setting up the environment, sync with git's remote repository). It might take up to 5 minutes and wouldn't be worth it to do it every 15 minutes.</li><li><span>Video sharing:</span> everyone should keep the camera on during the session and, when possible, look directly at it. Itâ€™s as close as we can get to face-to-face interaction.</li><li><span>Driver handover:</span> every time a Driver handover is required, the current Driver has to ensure that changes made during their turn are properly committed and pushed to the remote repository. To have a better sense of the changes and their history, usually, the Driver's name is kept on the commit description.</li></ol><p>When it comes to the tools that we use during our mob sessions, it depends on if we are doing it in-person or remotely. When having in-person sessions, the only tool that we make use of is <a href="https://github.com/dillonkearns/mobster" target="_blank">Mobster</a>, which allows us to keep track of the Driver timer, the active and next up Drivers. Whereas when having remote sessions, on top of Mobster we also benefit from <a href="https://slack.com/" target="_blank">Slack</a> for video/screen sharing and live annotations (i.e. being able to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.farfetchtechblog.com/en/blog/post/a-year-s-worth-of-learnings-from-adopting-mob-programming/">https://www.farfetchtechblog.com/en/blog/post/a-year-s-worth-of-learnings-from-adopting-mob-programming/</a></em></p>]]>
            </description>
            <link>https://www.farfetchtechblog.com/en/blog/post/a-year-s-worth-of-learnings-from-adopting-mob-programming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25443874</guid>
            <pubDate>Wed, 16 Dec 2020 15:42:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New GitLab Virtual Appliance for KVM now available from OpenNebula Marketplace]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25443719">thread link</a>) | @amarti
<br/>
December 16, 2020 | https://marketplace.opennebula.io/appliance/6b54a412-03a5-11e9-8652-f0def1753696 | <a href="https://web.archive.org/web/*/https://marketplace.opennebula.io/appliance/6b54a412-03a5-11e9-8652-f0def1753696">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://marketplace.opennebula.io/appliance/6b54a412-03a5-11e9-8652-f0def1753696</link>
            <guid isPermaLink="false">hacker-news-small-sites-25443719</guid>
            <pubDate>Wed, 16 Dec 2020 15:29:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to grow and level up as a software engineer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25443599">thread link</a>) | @hoanhan101
<br/>
December 16, 2020 | https://hoanhan.co/circleci-engineering-competency-matrix | <a href="https://web.archive.org/web/*/https://hoanhan.co/circleci-engineering-competency-matrix">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"><article role="article"><p>Based on CircleCI Engineering Competency Matrix, let's learn more about different growth opportunities as well as how we can level up our career.</p><time datetime="2020-12-15T00:00:00-05:00"> December 15, 2020 · 7 mins read · <a href="https://hoanhan.co/category/Key-takeaways-from-important-reading">Key takeaways from important reading</a><hr> </time><h2> Table of Contents</h2><ul id="markdown-toc"><li><a href="#guidelines" id="markdown-toc-guidelines">Guidelines</a></li><li><a href="#technical-skills" id="markdown-toc-technical-skills">Technical skills</a><ul><li><a href="#writing-code" id="markdown-toc-writing-code">Writing code</a></li><li><a href="#testing" id="markdown-toc-testing">Testing</a></li><li><a href="#debugging" id="markdown-toc-debugging">Debugging</a></li><li><a href="#observability" id="markdown-toc-observability">Observability</a></li><li><a href="#understanding-code" id="markdown-toc-understanding-code">Understanding code</a></li><li><a href="#software-architecture" id="markdown-toc-software-architecture">Software architecture</a></li><li><a href="#security" id="markdown-toc-security">Security</a></li></ul></li><li><a href="#delivery" id="markdown-toc-delivery">Delivery</a><ul><li><a href="#work-breakdown" id="markdown-toc-work-breakdown">Work breakdown</a></li><li><a href="#prioritisation" id="markdown-toc-prioritisation">Prioritisation</a></li><li><a href="#dealing-with-ambiguity" id="markdown-toc-dealing-with-ambiguity">Dealing with ambiguity</a></li><li><a href="#reliability" id="markdown-toc-reliability">Reliability</a></li><li><a href="#economic-thinking" id="markdown-toc-economic-thinking">Economic thinking</a></li></ul></li><li><a href="#feedback-communication-collaboration" id="markdown-toc-feedback-communication-collaboration">Feedback, communication, collaboration</a><ul><li><a href="#deliveringseeking-feedback" id="markdown-toc-deliveringseeking-feedback">Delivering/seeking feedback</a></li><li><a href="#effective-communication" id="markdown-toc-effective-communication">Effective communication</a></li><li><a href="#knowledge-sharing" id="markdown-toc-knowledge-sharing">Knowledge sharing</a></li><li><a href="#team-work" id="markdown-toc-team-work">Team work</a></li><li><a href="#relationship-building" id="markdown-toc-relationship-building">Relationship building</a></li><li><a href="#handling-disagreement" id="markdown-toc-handling-disagreement">Handling disagreement</a></li></ul></li><li><a href="#leadership" id="markdown-toc-leadership">Leadership</a><ul><li><a href="#decision-making" id="markdown-toc-decision-making">Decision making</a></li><li><a href="#driving-alignment" id="markdown-toc-driving-alignment">Driving alignment</a></li><li><a href="#process-thinking" id="markdown-toc-process-thinking">Process thinking</a></li><li><a href="#facilitation" id="markdown-toc-facilitation">Facilitation</a></li><li><a href="#mentoring" id="markdown-toc-mentoring">Mentoring</a></li></ul></li><li><a href="#strategic-impact" id="markdown-toc-strategic-impact">Strategic impact</a><ul><li><a href="#business-acumen" id="markdown-toc-business-acumen">Business acumen</a></li><li><a href="#strategic-work" id="markdown-toc-strategic-work">Strategic work</a></li><li><a href="#product-thinking" id="markdown-toc-product-thinking">Product thinking</a></li></ul></li></ul><hr><h2 id="guidelines">Guidelines</h2><ul><li>A numbered list is used for each theme, where the higher the number is, the higher seniority level one has. Usually, each is built on top of the previous one.</li><li>Junior-Senior levels generally focus on engineers executing works (number 1 and 2) while Staff-Principal levels focus on mentoring and guiding others in their work (number 3 and above).</li><li>Competencies scale through impact: task → project → milestone → team → across teams → organization.</li><li>Competencies also scale through increased frequency: sometimes → usually → always.</li></ul><h2 id="technical-skills">Technical skills</h2><h3 id="writing-code">Writing code</h3><ol><li>Consistently writes code that are testable, easily understood by other developers.</li><li>Document effectively.</li></ol><h3 id="testing">Testing</h3><ol><li>Understands the testing pyramid (unit test, integration test, end-to-end test) and ensures that they are in good places.</li><li>Understands the team testing approach, works to recommend solutions accordingly.</li><li>Works with other teams to recommend solutions</li><li>Drives the company wide testing strategy.</li></ol><h3 id="debugging">Debugging</h3><ol><li>Uses a systematic approach to debug issues located within a single device.</li><li>Proficient at using systematic debugging to diagnose cross services issues.</li><li>Leads incident response across the organization.</li></ol><h3 id="observability">Observability</h3><ol><li>Is aware of the team monitoring philosophy.</li><li>Uses it as a basis for suggesting stability and performance improvements.</li><li>Drives monitoring works</li><li>Fosters a culture of observability across several teams and organization.</li></ol><h3 id="understanding-code">Understanding code</h3><ol><li>Understands a portion of the team domain, knows how to work productively within it.</li><li>Understands the team’s domain at a high level, has expertise in a portion.</li><li>Has expertise in the team’s domain, including the breadth of services, how they interact, and data flows between systems.</li><li>Has expertise in a set of related teams’ domains and organization’s architecture.</li></ol><h3 id="software-architecture">Software architecture</h3><ol><li>Designs functions what are aligned with the overall architecture.</li><li>Utilizes abstractions and code isolation effectively.</li><li>Architects scalable services and systems, makes design decisions, weights trade-offs.</li><li>Guides several teams to foster a culture of scalable architecture.</li></ol><h3 id="security">Security</h3><ol><li>Approaches all engineering work with a security lens, actively looks for vulnerabilities both in code and peer reviews.</li><li>Fosters a security first mindset across the teams/organization.</li></ol><h2 id="delivery">Delivery</h2><h3 id="work-breakdown">Work breakdown</h3><ol><li>Review tasks critically and ensures that they’re appropriately scoped for continuous integration and incremental delivery.</li><li>Reviews epics and projects and ensures that they’re broken down, prioritized properly and well understood by the team.</li><li>Reviews cross-team works and ensures that they’re well understood by all teams.</li></ol><h3 id="prioritisation">Prioritisation</h3><ol><li>Ensures that tasks are prioritised and dependencies are noted correctly.</li><li>Works within team to foster a culture of priority setting and urgency in alignment with organizational strategy.</li><li>Identifies dependencies across organization and work with individual team to resolve them before they become an issue.</li></ol><h3 id="dealing-with-ambiguity">Dealing with ambiguity</h3><ol><li>Handles risk and uncertainty within your personal scope responsibly and effectively.</li><li>Effectively handles risk within the team.</li><li>Effectively handles risk within the across several teams and organization.</li></ol><h3 id="reliability">Reliability</h3><ol><li>Understands the priorities and deliver upon them accordingly.</li><li>Anticipates and communicates blockers, delays before they require escalation.</li><li>Ensures expectations with the team and external stakeholders are clarified.</li><li>Successfully manages cross-team commitments, progress, and roadmap to delivery.</li></ol><h3 id="economic-thinking">Economic thinking</h3><ol><li>When taking action, weighs cost and value in order to make the most economic action.</li><li>Uses this well and make suggestion to teammates.</li><li>Fosters a culture within their team where people apply economic thinking to make timely decisions.</li><li>Fosters a culture across several teams and within the organization.</li></ol><h2 id="feedback-communication-collaboration">Feedback, communication, collaboration</h2><h3 id="deliveringseeking-feedback">Delivering/seeking feedback</h3><ol><li>Delivers praise and constructive feedback to their team, teammates, and manager in a useful manner.</li><li>Delivers feedback to their team’s business stakeholders when opportunities arise.</li><li>Fosters a culture of delivering praise and constructive feedback within the team, across several teams and organization.</li></ol><h3 id="effective-communication">Effective communication</h3><ol><li>Communicates effectively, clearly, concisely in written and verbal form both technical and non technical subjects.</li><li>Is able to communicate effectively with a diverse team, set of team, across the organization.</li></ol><h3 id="knowledge-sharing">Knowledge sharing</h3><ol><li>Understand your domain, share your knowledge and contribute to the team’s documentation frequently.</li><li>Fosters a culture of documentation and knowledge sharing within the team, across team and organization.</li></ol><h3 id="team-work">Team work</h3><ol><li>Consistently helps their teammates overcome obstacles, resolve blockers, and complete work tasks.</li><li>Consistently works across the organization to enable teams to support each other.</li></ol><h3 id="relationship-building">Relationship building</h3><ol><li>Works to build strong relationships with teammates, manager, and senior engineers across the organization.</li><li>Works to build strong relationships across the organization and leverage those to better plan for the engineering organization.</li></ol><h3 id="handling-disagreement">Handling disagreement</h3><ol><li>Approaches disagreement with teammates non-defensively and uses contradictory opinions as a basis for constructive, productive conversations.</li><li>Encourages teammates to do the same.</li><li>Foster a culture where people are encouraged to share opinions and contribute to discussions in a respectful manner.</li></ol><h2 id="leadership">Leadership</h2><h3 id="decision-making">Decision making</h3><ol><li>Strives to be objective, reflects on your own biases, and holds yourself accountable for decision and outcomes.</li><li>Takes ownership of decisions made in their team by helping teammates make clear decisions in alignment with organizational goals, backing decisions made, and taking responsibility for their success.</li><li>Takes ownership of decisions made across teams and organization.</li></ol><h3 id="driving-alignment">Driving alignment</h3><ol><li>Strongly oriented towards goals and ensures the team is continuously working towards shared goals.</li><li>Fosters a culture within the team of having conversations based on organizational strategy and principles to create alignment.</li><li>Fosters a culture across several teams and organization.</li></ol><h3 id="process-thinking">Process thinking</h3><ol><li>Regularly thinks about team practices and processes and discusses improvements with team.</li><li>Thinks about practices and processes that affect several teams, discusses improvements with appropriate parties, and drives implementation.</li><li>Takes ownership and responsibility for organizational practices and processes and their continuous improvement.</li></ol><h3 id="facilitation">Facilitation</h3><ol><li>Facilitates discussions within the team, ensuring that everyone has an opportunity to share their opinion and be heard, and no one person dominates the conversation.</li><li>Facilitates discussions across teams, guides discussions toward decisions, clarifies and gets buy-in.</li><li>Facilitates organization-wide discussions.</li></ol><h3 id="mentoring">Mentoring</h3><ol><li>Seeks out mentorship to grow their own experience.</li><li>Seeks out mentoring opportunities specifically to create team redundancy and backfill ability.</li><li>Mentors across teams and organization in an open, respectful, flexible, empathetic manner.</li></ol><h2 id="strategic-impact">Strategic impact</h2><h3 id="business-acumen">Business acumen</h3><ol><li>Has a thorough understanding of their team’s domain, and how it contributes to overall business strategy.</li><li>Has a thorough understanding of adjacent teams’ strategies and how they map to their team and interaction points.</li><li>Has a thorough understanding of the entire business, including individual domains, and how they contribute to overall business strategy.</li></ol><h3 id="strategic-work">Strategic work</h3><ol><li>Understands the organization’s engineering strategy.</li><li>Collaborates and decides on their team’s engineering work based on organization’s engineering strategy.</li><li>Leads cross-team and organization strategic efforts, influencing decisions to achieve cross-team alignment on major goals.</li></ol><h3 id="product-thinking">Product thinking</h3><ol><li>Understands product area of focus, how it fits into the overall business.</li><li>Looks for opportunities to simplify product &amp; technical design.</li><li>Evaluates and creates new product features in collaboration with the product team.</li><li>Recognizes product opportunities and differentiators in relation to the competition.</li><li>Actively seeks to create or redefine roadmaps across the organization with product &amp; business counterparts.</li></ol><hr><p><strong>References:</strong></p><ul><li><a href="https://docs.google.com/spreadsheets/d/1mtn4QTvqCiS_sf6uxtCiexTo03FVjSbnwbZXE46NdQE/edit?usp=sharing">https://docs.google.com/spreadsheets/d/1mtn4QTvqCiS_sf6uxtCiexTo03FVjSbnwbZXE46NdQE/edit?usp=sharing</a></li></ul><hr><hr><p> Tagged: <a href="https://hoanhan.co/tag/blog">#blog</a>, <a href="https://hoanhan.co/tag/outlier">#outlier</a>, <a href="https://hoanhan.co/tag/success">#success</a></p><br> </article></div></div>]]>
            </description>
            <link>https://hoanhan.co/circleci-engineering-competency-matrix</link>
            <guid isPermaLink="false">hacker-news-small-sites-25443599</guid>
            <pubDate>Wed, 16 Dec 2020 15:22:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to Effective Linux and Bash for Data Scientists]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25443415">thread link</a>) | @tolstoyevsky
<br/>
December 16, 2020 | http://dagshub.com/blog/effective-linux-bash-data-scientists/ | <a href="https://web.archive.org/web/*/http://dagshub.com/blog/effective-linux-bash-data-scientists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>In November 2020, DAGsHub gave a series of guest lectures to the excellent <a href="https://yandexdataschool.com/israel/">Y-DATA</a> course for aspiring data scientists, which we would now like to share with whoever finds it useful, in blog form!</p><h2 id="cut-to-the-chase-">Cut to the chase!</h2><ul><li><a href="#basics">Shell basics</a></li><li><a href="#the-shell">Background on shells</a></li><li><a href="#shell-variables">Shell variables</a></li><li><a href="#pipes">Pipes</a></li><li><a href="#redirects">Redirects</a></li><li><a href="#filesystem">Filesystem</a></li><li><a href="#runnable-files">Runnable files</a></li><li><a href="#package-managers">Package managers</a> (e.g. brew and apt)</li><li><a href="#shell-commands-inside-jupyter-notebooks">Shell commands inside Jupyter notebooks</a></li><li><a href="#text-editors-in-the-terminal">Text editors in the terminal</a></li><li><a href="#other-useful-commands">Other useful commands</a></li><li><a href="#ssh">SSH</a></li><li><a href="#tmux">tmux</a></li><li><a href="#running-commands-in-the-background">Running commands in the background</a></li><li><a href="#symbolic-links">Symbolic links</a></li><li><a href="#zsh-oh-my-zsh-powerlevel10k">Oh-my-zsh</a></li></ul><h2 id="intro">Intro</h2><p>The topic - system, IT, DevOps, MLOps, whatever other name you want to call it - how do you make the computer do what you want, outside the context of Python (or R or Matlab etc., we don't discriminate)? How do you get that beautiful neural network of yours to run on an actual server in the cloud, so that it can serve actual users?</p><blockquote>What to do when the bubble bursts, and you have to step outside the Jupyter notebook to fix things?</blockquote><p>Of course, this is a wide open question which requires a lot of previous knowledge to answer. In our lectures, we wanted to start by building a solid foundation for the students to stand on. So, we went to the classics - what is Linux? Why do people use it? What is Bash? How to use the terminal? How to exit vim?!</p><figure><img src="https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="It's all about that base, no trouble!" srcset="https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>It's all about that base, no trouble! Photo by <a href="https://unsplash.com/@arstyy?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Austin Neill</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>Instead of creating yet-another-tutorial on how to move and copy files in terminals, we wanted to bring perspective: </p><ul><li>Why would you use Linux, Bash, and other system tools?</li><li>What's the smart way to do it, based on our subjective experience? </li><li>What common problems will you come across, and how to solve them?</li><li>What's the mental framework for working with these tools, to gain understanding and learn more by playing?</li></ul><p>So, this guide/cheatsheet is more about our tips and tricks, and is definitely not exhaustive. On the contrary - we wanted to make the most of students' time, and only talk about what's interesting. Other things can be learned on an as-needed basis.</p><h3 id="who-is-this-for">Who is this for?</h3><p>The curriculum and some of the tips are aimed at data scientists who want an introduction to the topics of Linux &amp; Bash. However, the data science orientation mainly comes into play in a few domain specific tips, and in the stated motivations to learn these things - if you're an aspiring web developer, there's no reason not to benefit from this guide as well!</p><h2 id="linux">Linux</h2><h3 id="what-is-linux">What is linux?</h3><ul><li>A family of open source operating systems.</li><li>Developed by Linus Torvalds, who also invented Git to manage the source code for Linux.</li><li>An operating system is a program that takes over a bit after your computer turns on.</li><li>For the first few seconds after your computer switches on, the motherboard runs a small hard-coded operating system called the BIOS, but it quickly hands control over to some operating system<em> kernel</em>, which is installed on one of the hard drives, a USB stick or CD.</li><li>From that point on, the kernel decides which programs to run when, and how to control physical devices (via drivers).</li><li>An <em>operating system</em> is a bundle of programs that come packaged together. The kernel is the most important part, but it comes with more programs which help the users communicate with the kernel.</li><li>e.g. File explorers are part of the OS, but not the kernel - they're just graphical interfaces which sit between the user and the kernel.</li><li>Operating systems normally also handle file systems, user permissions, memory management, and many other things.</li><li>The thing that unites all the different operating systems in the Linux family is they all use the same Linux kernel - other parts differ. More on that later in the section about distributions.</li></ul><figure><img src="https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Penguins" srcset="https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@topcools?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">topcools tee</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><h3 id="what-is-linux-good-for">What is Linux good for?</h3><p>An operating system is, surprisingly, just a type of system. Systems are designed by humans, and better designs lead to better performance, stability, and flexibility. <strong>Linux is simply a better designed operating system</strong>. It's super flexible and stable - "blue screens of death" are exceedingly rare in production Linux servers, and their performance is very reliable. <strong>Which is why a vast majority of production systems run on Linux</strong>, and that's also why it's good for anyone working in tech to be Linux literate. That includes you, dear reader.</p><p>Being open source leads to high quality, as bugs have fewer dark places to hide in. Developers can peer under the covers to make sure their Linux applications will work well, rather than guessing and relying on questionable documentation from closed source operating system developers.</p><p>But with great power and flexibility comes a great ability to shoot yourself in the foot. Linux makes that easy as well.</p><h3 id="what-do-the-different-types-of-linux-mean">What do the different types of Linux mean?</h3><p>One of the confusing things when entering the Linux world is the giant jargon which is thrown in your face. It feels like the explanations expect you to already know and understand a bunch of other terms, without building understanding step by step. So, I'd like to give you a very brief summary of terms you might come across and what they mean.</p><h3 id="linux-like-systems">Linux-like systems</h3><p>Mac and Unix are very similar to, but are not Linux technically. You will have a hard time telling the difference, unless you dive deep.</p><p>Unix is older than Linux and extremely similar - In fact, Linux is an open source re-implementation of Unix (which was closed source, but very good). This is pretty much historic trivia, as Unix is rarely seen nowadays, but know that some people use the words Unix and Linux interchangeably.</p><p>In general, there’s a name for operating systems that look and feel like Unix – POSIX compliant, or *nix. When you see these words, translate them as “follows the conventions of Linux, such as basic commands for file manipulation (ls, cd, mkdir) and "/" as the root of the file system etc.”</p><p>GNU is a large set of free software which is the foundation for much of Linux – compilers, C libraries, programs to zip files, and many others. It's also the name of an independent POSIX operating system, with more hardcore ideology around free software than Linux.</p><p>All of the above systems, as well as Linux itself, are examples of POSIX compliant or *nix systems.</p><h3 id="linux-distributions-distros">Linux Distributions / Distros</h3><p>There are (too?) many flavours of “real Linux”, called distros or distributions. It can be a headache to differentiate them.</p><p>A distribution is like a "company", which invents a new operating system. They wrap the Linux Kernel with a new bundle of peripheral programs - i.e. they may use a different mix of GUI programs, support different hardware by default, etc. They release new versions occasionally.</p><p><strong>The bottom line – unless you know what you’re doing, <a href="https://ubuntu.com/download/desktop">just use Ubuntu</a></strong>. It’s the most user friendly, widely supported, and easy to install.</p><p><a href="https://www.redhat.com/en/technologies/linux-platforms/enterprise-linux">Red Hat Enterprise Linux</a>, or RHEL, is a different distro which is used sometimes in heavy duty production servers. <a href="https://getfedora.org/">Fedora</a> is the desktop equivalent of RHEL - usually, developers aiming to run their applications on RHEL servers will use Fedora for their development computers, to avoid compatibility issues.</p><p><a href="https://alpinelinux.org/">Alpine</a> is a super minimal distro which is used for many Docker images. <a href="https://dagshub.com/blog/setting-up-data-science-workspace-with-docker/">Read our blog post about Docker for more information</a>.</p><h2 id="interfaces">Interfaces</h2><p>When people think of Linux, they usually associate it with a scary terminal (plus attached Anonymous hacker with a hoodie 👩‍💻).</p><p>Don't Panic – it’s not so scary! Today, it’s really easy to install Linux on a computer, with a regular GUI wizard, if you pick a distro that cares about that sort of thing (for example, Ubuntu).</p><p>We'll focus on terminals / shells in this lecture, since that is always available, and generally where "real work" is done. Production servers will rarely have GUIs. Don't let that discourage you - after you get used to it, using the shell can become much more convenient than GUIs!</p><figure><img src="https://dagshub.com/blog/content/images/2020/12/image.png" alt="The Wizard will now install your software."><figcaption>The Wizard will now install your software.</figcaption></figure><h2 id="basics">Basics</h2><p>The following actions are very basic file manipulation commands - moving, copying, deleting, viewing, etc.<br>I think there are enough sources online to learn these basic commands, and so I won't be re-explaining them here. Below the list, I provide my recommended way to learn about them, so don't worry!</p><ul><li>ls</li><li>mv</li><li>cp</li><li>rm</li><li>pwd</li><li>cd</li><li>mkdir</li><li>echo</li><li>cat</li></ul><p><strong>The most convenient way I found to learn about these commands, even if you don't have a Linux terminal available, is to follow these tutorials:</strong></p><ol><li><a href="https://www.webminal.org/terminal/">https://www.webminal.org/terminal/</a><br><strong>Do up to and including lesson 3.</strong><br>Webminal includes an interactive terminal in the browser, which you can play with and use for the next tutorial (which doesn't have an interactive shell, only text and quizzes).</li><li><a href="https://linuxjourney.com/lesson/the-shell">https://linuxjourney.com/lesson/the-shell</a></li></ol><h2 id="the-shell">The Shell</h2><p>The shell (AKA terminal) is itself a program! It's in charge of things like: </p><ul><li>Taking keystrokes from the user</li><li>Displaying text output to the user.</li><li>Remembering what directory you're in currently (changed using <code>cd</code>, shown using <code>pwd</code>)</li><li>Turning your commands into <strong>new</strong> <strong>running programs &nbsp;- processes,</strong> by sending appropriate messages to the kernel</li></ul><p>For example, what does the shell do when I type <code>python hello_world.py</code> and press enter?</p><ul><li>It's in charge of knowing where the actual program called "python" is located in the file system - probably something like <code>/usr/bin/python</code>. In the end, the kernel is the only thing that can run new programs, and it expects absolute paths to files.</li><li>I can check where the shell is actually finding "python" by running <code>which python</code>. &nbsp;The <code>which</code> command outputs the full path found by the shell. How does it know? More on that later, in the section on runnable scripts.</li><li><code>which</code> is a useful command! Maybe you have several conflicting versions of python installed, and you're not sure which one is actually running and giving you problems. <code>which python</code> to the rescue!</li><li>Or maybe I have some runnable script, and I want to edit, delete or rename it, but I forgot where it's located. <code>which</code> to the rescue!</li><li>So, what actually happens is that the shell tells the kernel program: "Please take the program file located at <code>/usr/bin/python</code>, and turn that into a new running process with a single argument <code>/absolute/path/to/hello_world.py</code> , running inside the current …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://dagshub.com/blog/effective-linux-bash-data-scientists/">http://dagshub.com/blog/effective-linux-bash-data-scientists/</a></em></p>]]>
            </description>
            <link>http://dagshub.com/blog/effective-linux-bash-data-scientists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25443415</guid>
            <pubDate>Wed, 16 Dec 2020 15:08:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Matrix: One Chat Protocol to Rule Them All]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25443050">thread link</a>) | @djsumdog
<br/>
December 16, 2020 | https://battlepenguin.com/tech/matrix-one-chat-protocol-to-rule-them-all/ | <a href="https://web.archive.org/web/*/https://battlepenguin.com/tech/matrix-one-chat-protocol-to-rule-them-all/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <section>

  

  <article>
    

    <figure>
  
  <img src="https://battlepenguin.com/images/tech/matrix/matrix.png" alt="Matrix Logo Surrounded by Logos for Hangouts, Telegram, Messenger and Signal pointing to it">
  
  
</figure>

<p>Once upon a time, there were many chat services. AOL Instant Messenger, Yahoo Messenger, ICQ and others. These messengers had their own desktop clients, and developers reverse engineered their protocol to build custom applications, both open and closed source. Trillian, Audium and Pidgin were applications that let people communicate across all these messengers with one program. Over time the old protocols died, and newer chat services like Facebook Messenger and Google Hangouts started storing your entire history on their servers. People started using the web interfaces and mobile apps, no longer caring about desktop programs.</p>

<p>Matrix is an open source communication protocol. It’s similar to XMPP (formerly Jabber) in the sense that anyone can set up a Matrix server and communicate to people on other Matrix servers. It’s a federated protocol, just like e-mail. Google Hangouts used to support XMPP federation, but silently removed support in 2014. Matrix supports bridging other chat services, so they can appear in a unified view. With my current setup of Matrix and appropriate bridges, I’ve combined my view of Facebook Messenger, Google Hangouts, Telegram and native Matrix chats into one convenient user interface. The path to get to that integration was not as simple.</p>

<!--more-->

<p>The dedicated server I use for <a href="https://battlepenguin.com/tech/a-history-of-personal-and-professional-websites/">this website</a> and other self-hosted web applications, is located in Germany. Logging in to Facebook or Google’s chat system from a country I’m not currently in, can raise all sorts of security flags and lock me out of my account. For those bridges, I purchased a small virtual machine in a Chicago data center. I installed a proxy on that server, accessible only via VPN, to view both Google and Facebook, so they record the IP address I’m connecting from with my web browser. This helps minimize security lockouts. Telegram isn’t hostile to third party developers, and has an official API. It doesn’t care my bridge is connecting to it from Germany, so I host it on the dedicated server.</p>

<figure>
  
  <img src="https://battlepenguin.com/images/tech/matrix/server-diagram.png" alt="Server Diagram of Matrix Homeserver and Bridges">
  
  
  <figcaption>
      

      Server Diagram of Matrix Homeserver and Bridges

      
  </figcaption>
  
</figure>

<p>The reference Matrix server is called Synapse. It, as well as the <a href="https://github.com/tulir/mautrix-telegram">mautrix-telegram</a>, <a href="https://github.com/tulir/mautrix-hangouts">mautrix-hangouts</a> and <a href="https://github.com/tulir/mautrix-facebook">mautrix-facebook</a> bridges all have official Docker containers built by their developers. Each bridge must be able to communicate with the Synapse homeserver. Their instructions go through generating configuration and key pairs that are copied over to Synapse in order to form their authentication bridge. The bridges provide chat robots that guide you through getting OAuth tokens or cookies for those respective services.</p>

<figure>
  
  <img src="https://battlepenguin.com/images/tech/matrix/element-screenshot.png" alt="Facebook and Hangouts Chats in Element">
  
  
  <figcaption>
      

      Facebook and Hangouts Chats in Element

      
  </figcaption>
  
</figure>

<p>The wiki for each bridge also has instructions for enabling double-puppeting, making each chat look seamless between myself and the accounts on the other side of each respective bridge. Without double-puppeting, each conversation will be in a three person group with the Matrix user, the bridge user (e.g my Google Hangouts user) and the person I’m talking to.</p>

<figure>
  
  <img src="https://battlepenguin.com/images/tech/matrix/no-double-puppet.png" alt="Chat Without Double-Puppeting Enabled">
  
  
  <figcaption>
      

      Chat Without Double-Puppeting Enabled

      
  </figcaption>
  
</figure>

<p>Enabling double-puppeting via the <code>curl</code> command in the bridge documentation and calling <code>login-matrix</code> on the bot, removes the creation of three person rooms. The bridged accounts will now show up as regular, two-person conversations.</p>

<p>I use the Element desktop app to connect to my matrix server, but I also have a web version of Element running from its own official Docker container in case I need to access chat from another computer. There are other clients, such as <a href="https://github.com/mirukana/mirage">Mirage</a> which is built using Qt and <a href="https://fluffychat.im/">Fluffychat</a> for mobile. Although I use Synapse for my homeserver, there are other servers that support the Matrix protocol that are in use and under active development.</p>

<p>Setting up all the Matrix components wasn’t too difficult, but it does require knowledge or experience with running services. It took a considerable amount of work and debugging to get each bridge operational, compounded slightly by my complex networking setup. Most people would probably just run all of this on a Raspberry Pi at home. I feel that using Matrix with bridges is still somewhat inaccessible to people who aren’t interested in development or server administration. Still, the satisfaction of having unified chat, plus one more layer of abstraction between myself and Google or Facebook, feels like it was wroth the overall effort.</p>


    

  </article>

</section>



    </div></div>]]>
            </description>
            <link>https://battlepenguin.com/tech/matrix-one-chat-protocol-to-rule-them-all/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25443050</guid>
            <pubDate>Wed, 16 Dec 2020 14:44:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Static Calls in Linux 5.10]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25442991">thread link</a>) | @woodruffw
<br/>
December 16, 2020 | https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10 | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Dec 16, 2020</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#c">c</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#curiosity">curiosity</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#security">security</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#x86">x86</a>
    
  
  </p>


<p>I was reading the
<a href="https://kernelnewbies.org/Linux_5.10">Linux 5.10 release summary on KernelNewbies</a>, and a
section stood out to me:</p>

<blockquote>
  <p>1.6. Static calls for improved post-Spectre performance</p>

  <p>Static calls are a replacement for global function pointers. They use code patching to allow
direct calls to be used instead of indirect calls. They give the flexibility of function pointers,
but with improved performance. This is especially important for cases where retpolines would
otherwise be used, as retpolines can significantly impact performance.</p>
</blockquote>

<p>I’ve spent a lot of time looking at the Linux kernel, but never directly at its indirect call
setup or post-<a href="https://spectreattack.com/">Spectre</a> mitigations. These changes sound very cool,
so I’m going to use this post to try and explain and understand them (both to myself and others).</p>

<p><strong>Update</strong>: One of the original authors of the patchset has emailed me with some corrections
and answers to the questions that I ask below. I’ve marked each with either “Correction” or
“Update.” Thanks, Peter!</p>

<h2 id="background-indirect-calls-spectre-and-retpolines">Background: indirect calls, Spectre, and retpolines</h2>

<h3 id="indirect-calls">Indirect calls</h3>

<p>Indirect calls are one of C’s most powerful language features, and are critical for writing
higher-order code without a supplementary object or function/method dispatch system.</p>

<p>Most C programmers are familiar with the basics of indirect calls, thanks to standard and POSIX
functions like <code>qsort</code> and <code>pthread_create</code>: each takes a <em>function pointer</em>, which it then
calls internally to complete the functionality of the surrounding call:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td><pre><span>#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;stdio.h&gt;
</span>
<span>/* qsort_strcmp is just the normal stdlib strcmp, with a bit of extra parameter
 * munging to match qsort's API.
 */</span>
<span>static</span> <span>int</span> <span>qsort_strcmp</span><span>(</span><span>const</span> <span>void</span> <span>*</span><span>a</span><span>,</span> <span>const</span> <span>void</span> <span>*</span><span>b</span><span>)</span> <span>{</span>
    <span>return</span> <span>strcmp</span><span>(</span><span>*</span><span>(</span><span>const</span> <span>char</span> <span>**</span><span>)</span><span>a</span><span>,</span> <span>*</span><span>(</span><span>const</span> <span>char</span> <span>**</span><span>)</span><span>b</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>const</span> <span>char</span> <span>*</span><span>strings</span><span>[]</span> <span>=</span> <span>{</span><span>"foo"</span><span>,</span> <span>"bar"</span><span>,</span> <span>"baz"</span><span>};</span>

    <span>/* qsort is a generic sorting function:
     * you give it the a pointer to the base address of things to sort,
     * their number and individual sizes, and a *function* that can compare
     * any two members and provide an ordering between them.
     *
     * in this case, we tell qsort to sort an array of strings, using
     * `qsort_strcmp` for the ordering.
     */</span>
    <span>qsort</span><span>(</span><span>&amp;</span><span>strings</span><span>,</span> <span>3</span><span>,</span> <span>sizeof</span><span>(</span><span>char</span> <span>*</span><span>),</span> <span>qsort_strcmp</span><span>);</span>

    <span>printf</span><span>(</span><span>"%s %s %s</span><span>\n</span><span>"</span><span>,</span> <span>strings</span><span>[</span><span>0</span><span>],</span> <span>strings</span><span>[</span><span>1</span><span>],</span> <span>strings</span><span>[</span><span>2</span><span>]);</span>
    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/vbn7zW">Godbolt</a>).</em></p>

<p>In this case, the indirect call occurs within <code>qsort</code>. But we can see it directly if
we implement our own function that does an indirect call:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td><pre><span>static</span> <span>uint32_t</span> <span>good_rand</span><span>()</span> <span>{</span>
    <span>uint32_t</span> <span>x</span><span>;</span>
    <span>getrandom</span><span>(</span><span>&amp;</span><span>x</span><span>,</span> <span>sizeof</span><span>(</span><span>x</span><span>),</span> <span>GRND_NONBLOCK</span><span>);</span>
    <span>return</span> <span>x</span><span>;</span>
<span>}</span>

<span>static</span> <span>uint32_t</span> <span>bad_rand</span><span>()</span> <span>{</span>
    <span>return</span> <span>rand</span><span>();</span>
<span>}</span>

<span>/* munge takes a function pointer, rand_func, which it calls
 * as part of its returned result.
 */</span>
<span>static</span> <span>uint32_t</span> <span>munge</span><span>(</span><span>uint32_t</span> <span>(</span><span>*</span><span>rand_func</span><span>)(</span><span>void</span><span>))</span> <span>{</span>
    <span>return</span> <span>rand_func</span><span>()</span> <span>&amp;</span> <span>0xFF</span><span>;</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>uint32_t</span> <span>x</span> <span>=</span> <span>munge</span><span>(</span><span>good_rand</span><span>);</span>
    <span>uint32_t</span> <span>y</span> <span>=</span> <span>munge</span><span>(</span><span>bad_rand</span><span>);</span>

    <span>printf</span><span>(</span><span>"%ul, %ul</span><span>\n</span><span>"</span><span>,</span> <span>x</span><span>,</span> <span>y</span><span>);</span>

    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>where <code>munge</code> boils down to:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td><pre><span>munge:</span>
  <span>push</span>    <span>rbp</span>
  <span>mov</span>     <span>rbp</span><span>,</span> <span>rsp</span>
  <span>sub</span>     <span>rsp</span><span>,</span> <span>16</span>
  <span>mov</span>     <span>qword</span> <span>ptr</span> <span>[</span><span>rbp</span> <span>-</span> <span>8</span><span>],</span> <span>rdi</span>  <span>; load rand_func</span>
  <span>call</span>    <span>qword</span> <span>ptr</span> <span>[</span><span>rbp</span> <span>-</span> <span>8</span><span>]</span>       <span>; call rand_func</span>
  <span>and</span>     <span>eax</span><span>,</span> <span>255</span>
  <span>add</span>     <span>rsp</span><span>,</span> <span>16</span>
  <span>pop</span>     <span>rbp</span>
  <span>ret</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/P44Ghq">Godbolt</a>).</em></p>

<p>Observe: our <code>call</code> goes through a memory or register operand (<code>[rbp - 8]</code>)<sup id="fnref:opt" role="doc-noteref"><a href="#fn:opt">1</a></sup> to get the target,
instead of a direct target specified by the operand value itself (like, say,
<code>call 0xacabacab ; @good_rand</code>). That’s what makes it indirect.</p>

<p>But we can go even further than this! Indeed, a common pattern in C is to declare
entire <em>structures</em> of operations, using each to parametrize a lower level set of behaviors
(for example, the core POSIX I/O APIs) over independent implementations.</p>

<p>This is exactly how <a href="https://github.com/libfuse/libfuse">FUSE</a> works: every FUSE client
creates its own <a href="https://github.com/libfuse/libfuse/blob/cd4aae2de6aacad31a15791bbb52adf173561a6d/include/fuse.h#L299-L790"><code>fuse_operations</code></a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td><pre><span>struct</span> <span>fuse_operations</span> <span>{</span>
  <span>int</span> <span>(</span><span>*</span><span>getattr</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>stat</span> <span>*</span><span>,</span> <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>fi</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>readlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>mknod</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>mode_t</span><span>,</span> <span>dev_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>mkdir</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>mode_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>unlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>rmdir</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>symlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>rename</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>unsigned</span> <span>int</span> <span>flags</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>link</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>/* ... */</span>
  <span>int</span> <span>(</span><span>*</span><span>open</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>read</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>,</span> <span>off_t</span><span>,</span>
         <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>write</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>,</span> <span>off_t</span><span>,</span>
          <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>statfs</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>statvfs</span> <span>*</span><span>);</span>
  <span>/* ... */</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Unsurprisingly, this technique isn’t limited to userspace: the Linux kernel itself makes
aggressive use of indirect calls, particularly in architecture-agnostic interfaces
(like the <a href="https://www.kernel.org/doc/html/latest/filesystems/vfs.html">VFS</a> and sub-specializations
like <code>procfs</code>) and the architecture-specific internals of subsystems like
<a href="https://perf.wiki.kernel.org/index.php/Main_Page"><code>perf_events</code></a>.</p>

<p>So that’s neat. It’s so neat that CPU engineers got all
<a href="https://en.wikipedia.org/wiki/Branch_predictor#Indirect_branch_predictor">hot in the pants</a> trying
to squeeze extra performance out of them<sup id="fnref:perf" role="doc-noteref"><a href="#fn:perf">2</a></sup>, and we ended up with
<a href="https://spectreattack.com/spectre.pdf">Spectre v2</a>.</p>

<h3 id="spectre-v2">Spectre (v2)</h3>

<p><img src="https://blog.yossarian.net/assets/spectre.png" alt="The Spectre logo"></p>

<p>The exact mechanism that Spectre v2 (also known as
<a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-5715">CVE-2017-5715</a>) exploits is
<em>slightly</em> out of scope of this post, but at a high level:</p>

<ol>
  <li>
    <p>Modern (x86) CPUs contain an <em>indirect branch predictor</em>, which attempts to guess the target
of an indirect call or jump.</p>

    <p>To actually speed things up, the CPU <strong>speculatively executes</strong> the
 predicted branch:</p>

    <ul>
      <li>
        <p>A correct prediction means that the indirect call completes significantly faster
 (since it’s already executing or has finished executing speculatively);</p>
      </li>
      <li>
        <p>A misprediction <strong>should</strong> result in a slower (but still
 successful) indirect call with <strong>no side effects from the incorrect speculation.</strong></p>
      </li>
    </ul>

    <p>In other words: the CPU is responsible for <strong>rolling back</strong> any side effects associated
 with any misprediction and subsequent speculation. Mis-speculation is a <em>microarchitectural</em>
 detail that should not manifest in <em>architectural</em> changes, like modified registers.</p>
  </li>
  <li>
    <p><strong>Rolling back</strong> any mis-speculated state is a relatively expensive operation, with a lot of
microarchitectural implications: cache lines and other bits of state need to be fixed up so that
the <em>actual</em> program control flow isn’t tainted by failed speculations.</p>

    <p>In practice, rolling back the entire speculated state would undo most of the advantages
 of speculating in the first place. Instead of doing that, x86 and other ISAs will just mark
 (many) of the bits of speculated state (like cache lines) as stale.</p>
  </li>
  <li>
    <p>This fixup behavior (either reverting or marking speculated state) results in a
<a href="https://en.wikipedia.org/wiki/Side-channel_attack"><em>side-channel</em></a>: an attacker can
<em>train</em> the branch predictor to speculatively execute a bit of code
(not unlike a <a href="https://en.wikipedia.org/wiki/Return-oriented_programming">ROP gadget</a>) that modifies
a piece of microarchitectural state in a data-dependent manner, such as a cache entry
whose address is dependent on a secret value that was speculatively fetched.</p>

    <p>The attacker can then <em>probe</em> that microarchitectural state by <strong>timing</strong> access to it:
 fast accesses indicate a speculatively modified state, disclosing the secret.</p>
  </li>
</ol>

<p>The original Spectre v2 attack focused on cache lines since they’re relatively easy to time, even
from high level (and sandboxed!) languages that don’t have access to
<a href="https://c9x.me/x86/html/file_module_x86_id_30.html"><code>clflush</code></a> or other cache-line
primitives on x86. But the concept is a general one: it’s difficult to execute speculatively without
leaking <em>some</em> information, and subsequent vulnerabilities (like <a href="https://mdsattacks.com/">MDS</a> and
<a href="https://zombieloadattack.com/">ZombieLoad</a>) have exposed information leaks in other
microarchitectural features.</p>

<p>This is bad news: an attacker running one of the <strong>safest</strong> contexts (JavaScript or other managed
code, in a sandbox, in userspace) can conceivably train the indirect branch predictor to
speculatively execute a gadget in kernelspace, potentially
<a href="https://cyber.wtf/2017/07/28/negative-result-reading-kernel-memory-from-user-mode/">disclosing kernel memory</a>.</p>

<p>So, the kernel needed a new mitigation. That mitigation is <em>retpolines</em>.</p>

<h3 id="retpolines">Retpolines</h3>

<p>To mitigate Spectre v2, the kernel needs to prevent the CPU from speculating on an attacker
controlled indirect branch.</p>

<p>A retpoline (short for <em>ret</em>urn
<a href="https://en.wikipedia.org/wiki/Trampoline_(computing)"><em>trampoline</em></a>) does exactly that: indirect
jumps and calls are surrounded by a little <a href="https://en.wikipedia.org/wiki/Thunk">thunk</a> that
effectively traps the speculated execution in an infinite loop, spinning it until the misprediction
is resolved.</p>

<p>Intel’s
<a href="https://software.intel.com/security-software-guidance/api-app/sites/default/files/Retpoline-A-Branch-Target-Injection-Mitigation.pdf">Retpoline whitepaper</a>
has some helpful illustrations:</p>

<p><img src="https://blog.yossarian.net/assets/retpoline.png" alt="A visualization of speculative execution with and without a retpoline."></p>

<p>This works by converting the indirect control flow from an <em>indirect branch</em> to an
<em>indirect return</em><sup id="fnref:allreturns" role="doc-noteref"><a href="#fn:allreturns">3</a></sup>, hence the “ret” in retpoline. Returns are <em>also</em> predicted,
but with an additional mechanism given priority: the
<a href="https://blog.stuffedcow.net/2018/04/ras-microbenchmarks/">Return Stack Buffer</a><sup id="fnref:rsb" role="doc-noteref"><a href="#fn:rsb">4</a></sup>. To ensure that
the RSB can’t be maliciously trained away from the infinite loop, the retpoline begins with a
direct <code>CALL</code> that primes the RSB to always<sup id="fnref:notalways" role="doc-noteref"><a href="#fn:notalways">5</a></sup> predict the infinite loop.</p>

<p>Here’s what an indirect call retpoline <em>actually</em> looks like<sup id="fnref:ool" role="doc-noteref"><a href="#fn:ool">6</a></sup>, simplified significantly from
the <a href="https://elixir.bootlin.com/linux/v5.9.14/source/arch/x86/lib/retpoline.S">kernel</a>
<a href="https://elixir.bootlin.com/linux/v5.9.14/source/arch/x86/include/asm/nospec-branch.h">source</a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
</pre></td><td><pre><span>__x86_retpoline_rax:</span>
  <span>call</span> <span>.Ldo_rop_0</span>
<span>.Lspec_trap_0:</span>
  <span>pause</span>
  <span>lfence</span>
  <span>jmp</span> <span>.Lspec_trap_0</span>
<span>.Ldo_rop_0:</span>
  <span>mov</span> <span>[</span><span>rsp</span><span>],</span> <span>rax</span>
  <span>ret</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>…all of that to replace a simple <code>call [rax]</code>!</p>

<h3 id="consequences">Consequences</h3>

<p>There are repercussions for this kind of trickery:</p>

<ul>
  <li>
    <p>It’s slow when correctly predicted: we’ve replaced a single indirect <code>CALL</code> with at least two
direct <code>CALL</code>s, plus a <code>RET</code>.</p>
  </li>
  <li>
    <p>It’s <em>really</em> slow when mispredicted: we <em>literally</em> spin in place using <code>PAUSE</code> and <code>LFENCE</code>.</p>
  </li>
  <li>
    <p>It’s a ROP gadget, so it <em>looks</em> like an exploit primitive. That means it screws with Intel’s
<a href="https://software.intel.com/sites/default/files/managed/4d/2a/control-flow-enforcement-technology-preview.pdf">CET</a>
and similar protections on other platforms. Intel claims that newer hardware will support “enhanced
IBRS”<sup id="fnref:ibrs" role="doc-noteref"><a href="#fn:ibrs">7</a></sup> that will replace the …</p></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10">https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10</a></em></p>]]>
            </description>
            <link>https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442991</guid>
            <pubDate>Wed, 16 Dec 2020 14:38:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gloo Mesh Enterprise Beta Release – Solo.io Service Mesh Management Plane]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25442825">thread link</a>) | @ilackarms
<br/>
December 16, 2020 | https://www.solo.io/blog/gloo-mesh-enterprise-beta-release/ | <a href="https://web.archive.org/web/*/https://www.solo.io/blog/gloo-mesh-enterprise-beta-release/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img src="https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B.png" data-src="https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B.png" alt="" width="1781" height="397" data-srcset="https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B.png 1781w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-300x67.png 300w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-1024x228.png 1024w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-768x171.png 768w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-1536x342.png 1536w" data-sizes="(max-width: 1781px) 100vw, 1781px" srcset="https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B.png 1781w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-300x67.png 300w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-1024x228.png 1024w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-768x171.png 768w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-1536x342.png 1536w"></p><p><span>From day one, our mission with Gloo Mesh has been to provide a service mesh command center that will give users indispensable features to manage a “glooed” together mix of environments, and today I am excited to announce that Gloo Mesh Enterprise is now available in Beta. We are asking the Gloo community and customers to <a href="https://lp.solo.io/request-trial">request a trial</a>, <a href="https://docs.solo.io/gloo-mesh/latest/">get started</a> and provide <a href="https://slack.solo.io/">feedback</a> via Slack on this latest Gloo Mesh Enterprise Beta so that our teams can continue to improve the features for its upcoming general availability. In addition, Gloo Mesh Enterprise has released its accompanying long term support for Istio, Istio on ARM and FIPS compliant Istio in general availability today with a license.&nbsp;</span></p><p><span>Originally launched in early 2019, Gloo Mesh (previously Service Mesh Hub) aims to provide organizations with a command center for all their service mesh needs, from a single cluster with Istio to stitching together and providing consistency for multiple clusters running different service meshes.&nbsp;</span></p><p><img src="https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2.png" data-src="https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2.png" alt="" width="7272" height="3440" data-srcset="https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2.png 7272w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-300x142.png 300w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-1024x484.png 1024w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-768x363.png 768w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-1536x727.png 1536w" data-sizes="(max-width: 7272px) 100vw, 7272px" srcset="https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2.png 7272w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-300x142.png 300w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-1024x484.png 1024w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-768x363.png 768w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-1536x727.png 1536w"></p><p><span>Some of the exciting features you will find in the Enterprise Beta release includes:</span></p><ul><li><b>A Single Pane of Glass for Every Service Mesh On Every Cluster – </b><span>Gloo Mesh helps users manage similar or mixed service meshes such as Istio and Open Service Mesh (originally from Microsoft) over multiple clusters.&nbsp;&nbsp;</span></li><li><b>Ability to Create a Virtual Mesh that Connects Multiple Clusters </b><span>–&nbsp; Join similar meshes, such as Istio, together in a virtual mesh that makes services discoverable and policies easy to manage anywhere, even across clusters. With Gloo Mesh Enterprise the promise of federated workloads is finally here!&nbsp;</span></li><li><b>Enhanced Security Across Your Mesh – </b><span>Gloo Mesh includes end-to-end security across clusters and meshes and forms a virtual, zero trust, mesh.&nbsp;</span></li><li><b>WebAssembly Modules to Increase Engineer Productivity </b><span>– Extend your service mesh control plane to allow developers to declaratively initialize, build, push, and deploy Wasm filters to Istio workloads over multiple clusters.&nbsp;</span></li><li><b>Easy User Management </b><span>– No more wrangling of users with complex RBAC permissions across clusters and meshes. With Gloo Mesh Enterprise you can now define a single user policy for your service mesh or virtual mesh, and propagate that policy to all your environments.&nbsp;</span></li><li><b>Simplified Failover and Traffic Polices</b><span> – Easy to define policies for service failover and traffic limits that are effortless to migrate throughout your service mesh environments.&nbsp;</span></li></ul><p><span>Istio Support Features:</span></p><ul><li><b>Long Term Enterprise Support for Istio</b><span> – Gloo Mesh enterprise license includes support for N-3 versions of Istio. This long term support aligns Istio support with the underlying Kubernetes cluster and gives organizations the peace of mind that break fixes, security patches, and other Istio issues will be fixed with the type of enterprise support they require.&nbsp;</span></li><li><b>Istio for ARM</b><span> – With new cloud providers releasing ARM instances that boost performance while decreasing cost, organizations’ ARM portfolio has become increasingly important and Solo.io has listened with ARM build.&nbsp;</span></li><li><b>Istio with FIPS – </b><span>&nbsp;Federal government agencies and those organizations serving them often need to comply with the Federal Information Processing Standard (FIPS-2) to maintain a minimum level of security. Solo.io has the option for FIPS-2 compliant build of Istio’s data plane.&nbsp;</span></li></ul><p><span>What’s Next for Gloo Mesh? The </span><span>Gloo Mesh team is working tirelessly on the new set of features based on what our customers and the community require in an Enterprise service mesh.&nbsp;</span></p><ul><li><span>Routing locality rules for cross cluster service failover and ability to access closest geographical workload – e.g. one housed on east coast cluster vs. Asia.</span></li><li><span>Upstream enhancements for Istio</span></li><li><span>Full AWS App Mesh Support</span></li><li><span>Metrics for a single or multiple clusters</span></li><li><span>Virtual Mesh that includes AppMesh and Istio in a single logical mesh.&nbsp;</span></li><li><span>Istio lifecycle management&nbsp;</span></li></ul><p><span>To learn more about the features in the Beta release of Gloo Mesh please see the</span> <a href="https://www.solo.io/products/gloo-mesh/"><span>website</span></a><span>, </span><a href="https://docs.solo.io/gloo-mesh/main/"><span>documentation</span></a><span> and the public </span><a href="https://github.com/solo-io/gloo-mesh"><span>Github</span></a><span>.&nbsp;&nbsp;&nbsp;</span></p><p>You can also read about Making Web Assembly a first-class citizen on Gloo Mesh Enterprise Beta <span><a href="https://www.solo.io/blog/making-web-assem%E2%80%A6-enterprise-beta/">blog.</a></span></p><p><span>You can request a free trial of Gloo Mesh today <a href="https://lp.solo.io/request-trial">here</a>. To connect, join the </span><a href="https://solo-io.slack.com/archives/CJQGK5TQ8"><span>#gloo-mesh</span></a><span> channel in the Solo.io Slack.</span></p></div></div></div>]]>
            </description>
            <link>https://www.solo.io/blog/gloo-mesh-enterprise-beta-release/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442825</guid>
            <pubDate>Wed, 16 Dec 2020 14:26:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experiments in Model Simplification]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25442786">thread link</a>) | @pete_b_condon
<br/>
December 16, 2020 | https://wagtaillabs.com/2020/12/16/experiments-in-model-simplification/ | <a href="https://web.archive.org/web/*/https://wagtaillabs.com/2020/12/16/experiments-in-model-simplification/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-178">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>We were recently challenged by&nbsp;Ali El-Sharif from <a href="https://ai.science/">Aggregate Intellect</a> to run some benchmarks on GRANT, and thought that one of the most interesting direct comparisons would be to compare <a href="https://wagtaillabs.com/2020/11/17/introducing-grant-pt-1/">Amalgamate</a> with Cost Complexity Pruning (CCP).</p>



<p>Cost Complexity Pruning applies a similar philosophy to Amalgamate, aiming to remove parts of each decision tree that don’t carry their weight. There are many descriptions of how CCP works on the web, but <a href="https://www.analyticsvidhya.com/blog/2020/10/cost-complexity-pruning-decision-trees/">this is a good, quick introduction</a>.</p>



<p>First up we tried pruning a Random Forest using Amalgamate with increasing&nbsp;<em>threshold</em> values&nbsp;and compared that to pruning with increasing CCP <em>alpha</em> values. Here’s the result plot comparing Validation Root Mean Squared Error (RMSE) against the number of rules in the model (as found by <a href="https://www.analyticsvidhya.com/blog/2020/10/cost-complexity-pruning-decision-trees/">Graft</a>):</p>



<figure><img loading="lazy" width="735" height="425" src="https://wagtaillabs.com/wp-content/uploads/2020/12/EIMS-1-1.png" alt="" srcset="https://wagtaillabs.com/wp-content/uploads/2020/12/EIMS-1-1.png 735w, https://wagtaillabs.com/wp-content/uploads/2020/12/EIMS-1-1-300x173.png 300w" sizes="(max-width: 735px) 100vw, 735px"></figure>



<p>What’s interesting here is that Amalgamate has a significant early advantage, up to 20% fewer rules for the same Validation RMSE, but that eventually CCP finds a better, ultra-low complexity model. This suggests that CCP misses some easy simplifications because it only works on each decision tree individually, and that these can be found using Amalgamate.</p>



<p>To test this theory we tried running Amalgamate (with a fixed <em>threshold</em> for simplicity) on each CCP pruned model:</p>



<figure><img loading="lazy" width="723" height="428" src="https://wagtaillabs.com/wp-content/uploads/2020/12/EIMS-2-1.png" alt="" srcset="https://wagtaillabs.com/wp-content/uploads/2020/12/EIMS-2-1.png 723w, https://wagtaillabs.com/wp-content/uploads/2020/12/EIMS-2-1-300x178.png 300w" sizes="(max-width: 723px) 100vw, 723px"></figure>



<p>These results show us that Amalgamate always found rules to eliminate, often (but not always) improving Validation RMSE. Overall our experiments showed that Amalgamate can be reduce the number of rules in a model by an average of 5% with no impact on Validation RMSE. This mightn’t sound like a lot, but anything that can be done to reduce the cognitive load required to understand the model without impacting on the results is useful.</p>



<p>By using both CCP and Amalgamate it is possible to find better simple models, and let stakeholders decide where the tradeoff between accuracy and complexity should be.</p>



<p>Check out <a href="http://github.com/wagtaillabs/GRANT">GitHub</a> if you would like to run your own experiments with GRANT.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://wagtaillabs.com/2020/12/16/experiments-in-model-simplification/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442786</guid>
            <pubDate>Wed, 16 Dec 2020 14:23:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SolarWinds leaked FTP credentials through a public GitHub repo since 2018]]>
            </title>
            <description>
<![CDATA[
Score 179 | Comments 90 (<a href="https://news.ycombinator.com/item?id=25442734">thread link</a>) | @hackerpain
<br/>
December 16, 2020 | https://www.savebreach.com/solarwinds-exposed-ftp-credentials-back-in-2018-says-security-researcher-vinoth/ | <a href="https://web.archive.org/web/*/https://www.savebreach.com/solarwinds-exposed-ftp-credentials-back-in-2018-says-security-researcher-vinoth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.savebreach.com/content/images/size/w300/2020/12/ss_solar.png 300w,
                            https://www.savebreach.com/content/images/size/w600/2020/12/ss_solar.png 600w,
                            https://www.savebreach.com/content/images/size/w1000/2020/12/ss_solar.png 1000w,
                            https://www.savebreach.com/content/images/size/w2000/2020/12/ss_solar.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.savebreach.com/content/images/size/w2000/2020/12/ss_solar.png" alt="SolarWinds Leaked FTP Credentials through a Public GitHub Repo &quot;mib-importer&quot; since 2018">
            </figure>

            <section>
                <div>
                    <h2 id="what-could-go-wrong-when-your-employees-commit-internal-information-to-public-github-repos">What could go wrong when your employees commit internal information to public GitHub repos? </h2><p>While <a href="https://savebreach.com/solarwinds-credentials-exposure-led-to-us-government-fireye-breach/">we were the first to report on the SolarWinds security vulnerability that possibly could have exposed their Downloads FTP server</a> credentials letting attackers to push malicious binaries and attack the US government and <a href="https://solarwinds.com/">SolarWinds</a>' other high profile clients, some more information has surfaced regarding the SolarWinds security vulnerability since then, that gives more insight into what possibly was exposed and whether it could have led to this massive breach of the US government. While majority of security researchers are of the opinion that this wasn't the main reason of the breach, and that there was a complex and sophisticated supply chain attack targeting <a href="https://solarwinds.com/">SolarWinds</a>, we believe<strong> these small security lapses could have given the attackers a larger attack surface to carry out their attacks</strong> and eventually might have helped strengthen their foothold into the SolarWinds infrastructure, to perform reconnaissance and evade detection.</p><h3 id="plain-old-ftp-to-the-blame">Plain old FTP to the blame?</h3><p>As per the screenshot posted by Vinoth, which we wrote about in our previous <a href="https://savebreach.com/solarwinds-credentials-exposure-led-to-us-government-fireye-breach/">post</a>, SolarWinds were possibly using unencrypted plain FTP server for their Downloads server in the age of global CDN technologies. However, not a direct attack vector its very likely that the FTP server had more vulnerabilities and unencrypted communication can always be intercepted, and modified. But we don't believe this maybe something as concerning as the FTP password leak.</p><h2 id="solarwinds-credentials-were-possibly-leaking-since-2018">SolarWinds Credentials were possibly leaking since 2018</h2><p>Security researcher Vinoth Kumar, told us that "SolarWinds had been possibly exposing the FTP credentials to the Download server since at least 2018". To corroborate his claim, Vinoth shared the the following link to the Configuration file exposed that was exposed in the mib-importer GitHub repo possibly belonging to a <a href="https://github.com/xkozus00">SolarWinds employee</a>, <a href="https://github.com/xkozus00/mib-importer/blob/master/Src/Lib/PurgeApp/PurgeApp.exe.config">https://github.com/xkozus00/mib-importer/blob/master/Src/Lib/PurgeApp/PurgeApp.exe.config</a> and he further added that, upon supplying the <a href="https://github.com/xkozus00/mib-importer">repo base url</a> to the Web Archive, it shows Web Archive had first archived the page back in June 2018, and that was the last time the page was archived. So we concluded that the credentials to the FTP server and other potentially sensitive information in that exposed repository possibly existed for more than 1 year in the public domain until Vinoth reported it to the SolarWinds PSIRT.</p><figure><img src="https://savebreach.com/content/images/2020/12/image-3.png" alt="" srcset="https://savebreach.com/content/images/size/w600/2020/12/image-3.png 600w, https://savebreach.com/content/images/size/w1000/2020/12/image-3.png 1000w, https://savebreach.com/content/images/2020/12/image-3.png 1411w" sizes="(min-width: 720px) 720px"><figcaption>Screenshot of the SolarWinds GitHub repository archived by Web Archive</figcaption></figure><p>This shows that SolarWinds might have been exposing their sensitive internal credentials since a fairly long time before it was brought to their notice, which in turn might have given its attackers an opportunity to steal certificates and other valuable internal information about SolarWinds to carry out the large scale attack against US government and other top organizations using the backdoored SolarWinds Orion software.</p><h2 id="the-mib-importer-github-repository">The mib-importer GitHub repository</h2><p>A "mib-importer" public GitHub repository, possibly belonging to a SolarWinds employee with secrets (like FTP username and password) exposed, was found on GitHub by the security researcher in November 2019, which is said to have existed from around June 2018</p><p>Upon analyzing, the SaveBreach team found out that SolarWinds Orion lets users import MIB files into it. MIB files are used for monitoring network devices. Apparently, the mib-importer tool was developed by SolarWinds to import MIB files into Orion. We found the following data from the <strong><a href="https://support.solarwinds.com/SuccessCenter/s/article/Add-MIBs-to-the-SolarWinds-MIB-database">SolarWinds documentation pages</a> </strong>regarding importing &nbsp;MIB files (Reference – <a href="https://support.solarwinds.com/SuccessCenter/s/article/Upload-MIB-in-Orion-Universal-Device-Poller">1</a>, <a href="https://thwack.solarwinds.com/t5/NPM-Discussions/Adding-MIBs-to-Orion/m-p/113474">2</a>, <a href="https://thwack.solarwinds.com/t5/NPM-Discussions/Adding-MIBs-to-Orion/m-p/113474">3</a>)</p><p><a href="https://documentation.solarwinds.com/en/Success_Center/orionplatform/Content/Core-Management-Information-Base--MIB--sw1730.htm">From SolarWinds website</a> – </p><blockquote>Management Information Base (MIB) is a structure that describes all objects a device can report on, such as CPU, fan, or temperature. MIB contains the name, datatype, and the object identifier (OID). MIB is a hierarchical structure, displayed as a navigation tree. Every entry in the MIB tree is a value for a specific component on a specific device.</blockquote><blockquote>SolarWinds maintains a MIB database that serves as a repository for the OIDs used to monitor a wide variety of network devices. The MIB database is updated regularly.</blockquote><h2 id="qa-with-cybersecurity-researcher-vinoth">Q&amp;A with cybersecurity researcher Vinoth</h2><p>From our most recent conversation with Vinoth, it appears that the credentials and possibly more sensitive data about SolarWinds was lying in public domain for a long time before finally being taken down. Vinoth doubts that the data might have also included certificates and not just FTP credentials, which was alone sufficient to sign the malicious binaries and upload them to the FTP server while passing off as legitimate software.</p><p><strong>Q: Since when do you think the GitHub repo might have been exposed? Do you think the attackers could have gained persistence into their infrastructure for almost 3 years to carry out the attack?</strong></p><p><strong><a href="https://twitter.com/vinodsparrow">Vinoth</a></strong>: I’m not sure, even on June 2018, 40 commits were there (in that repo). There was only one page available on archive couldn’t find anything else.</p><p><strong>Q: The Attackers had put signed binaries on the Download server. What was the process the attackers might have followed after getting access to the file upload server to sign the binaries?</strong></p><p><strong><a href="https://twitter.com/vinodsparrow">Vinoth</a></strong>: Not sure, but I could have missed checking the repo which could have had the certificate in it.</p><p><strong>Vinoth had tweeted that the GitHub repo was open to public since 17th June, 2018</strong></p><figure><blockquote data-width="550"><p lang="en" dir="ltr">That Github repo was open to the public since 17 Jun 2018 😱 <a href="https://t.co/SHUWaPXIeK">pic.twitter.com/SHUWaPXIeK</a></p>— Vinoth Kumar (@vinodsparrow) <a href="https://twitter.com/vinodsparrow/status/1338956534147993601?ref_src=twsrc%5Etfw">December 15, 2020</a></blockquote>

<figcaption>Tweet by Vinod about the web archived GitHub repository page</figcaption></figure><h2 id="certificates-used-to-sign-malicious-binaries-exposed-through-github-repo">Certificates used to sign malicious binaries exposed through GitHub repo?</h2><p>This raises many questions. Were the certificates used to sign the binaries obtained from that public GitHub repository or, from any other information leaked publicly? &nbsp;Exposed certificate could have allowed hackers to sign their malicious SolarWinds Orion binaries and pass them off as legitimate software developed by SolarWinds, subsequently uploading them to the Downloads server with the previously found leaked FTP credentials.</p><h2 id="was-this-how-solarwinds-got-hacked">Was this How SolarWinds got hacked?</h2><p>We can come to a partial conclusion that the internal information exposed on GitHub was there for a sufficiently long time for the attackers to have already exploited them to gain their initial foothold. Although unclear at this point, as there maybe a more sophisticated and complex attack chain with evasion techniques as being claimed by FireEye and security researchers, but we do feel this might have been a precursor to the SolarWinds breach and the widespread cyber attack against the US Government.</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to SaveBreach | Cyber Security, Bug Hunting &amp; Domain Acquisitions</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.savebreach.com/solarwinds-exposed-ftp-credentials-back-in-2018-says-security-researcher-vinoth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442734</guid>
            <pubDate>Wed, 16 Dec 2020 14:19:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tig – Text-mode interface for Git]]>
            </title>
            <description>
<![CDATA[
Score 290 | Comments 95 (<a href="https://news.ycombinator.com/item?id=25442510">thread link</a>) | @lemonspat
<br/>
December 16, 2020 | https://jonas.github.io/tig/ | <a href="https://web.archive.org/web/*/https://jonas.github.io/tig/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Tig is an ncurses-based text-mode interface for git. It functions mainly
as a Git repository browser, but can also assist in staging changes for
commit at chunk level and act as a pager for output from various Git
commands.</p>
</div></div>]]>
            </description>
            <link>https://jonas.github.io/tig/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442510</guid>
            <pubDate>Wed, 16 Dec 2020 14:00:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Faster Django Apps–Optimizing Templates Part 1]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25442290">thread link</a>) | @brauhaus
<br/>
December 16, 2020 | https://engineertodeveloper.com/faster-django-apps-optimizing-templates-part-1/ | <a href="https://web.archive.org/web/*/https://engineertodeveloper.com/faster-django-apps-optimizing-templates-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>Slow websites are frustrating—and Google doesn’t like them either. In May 2021, Google is releasing a set of new ranking metrics known as <a href="https://moz.com/blog/core-web-vitals">Core Web Vitals</a>.&nbsp;</p>



<p>The core web vitals are a set of metrics used to determine how fast webpages load. The three metrics are:</p>



<ul><li><strong>Largest Contentful Paint:</strong>&nbsp;The time it takes the webpage’s main content to load—should ideally be below 2.5 seconds.</li><li><strong>First Input Delay:</strong>&nbsp;How long it takes before the page is interactive for the user. This should be less than 100 milliseconds.</li><li><strong>Cumulative Layout Shift:</strong>&nbsp;The time it takes for unexpected layout shifts in the page’s content; should be less than 0.1 milliseconds.</li></ul>



<p>Throughout this tutorial, you will learn how to optimize your Django templates for faster page load speeds to get your website ready for the new Google updates. Plus, it will make your visitors happy too! Let’s get started!</p>



<h2>Bundling and Minifying CSS with Django Compressor</h2>



<p>CSS is a render-blocking asset, meaning that it blocks the browser from rendering our webpage until the CSS has been completely downloaded and parsed.&nbsp;&nbsp;</p>



<p>We can optimize this process in our Django templates using <a href="https://django-compressor.readthedocs.io/en/stable/" target="_blank" rel="noreferrer noopener">Django Compressor</a> to minify and bundle our stylesheets. Thus, reducing the CSS’s file size and the amount of network requests the browser has to make. Awesome, let’s see how we can do this.</p>



<p>First, let’s install and configure Django Compressor.</p>



<pre><code lang="python">pip install django_compressor</code></pre>



<p>After installing, add <code>"compressor"</code> to your <code>INSTALLED_APPS</code> in your project settings.</p>



<pre><code lang="python"># myproject/settings.py

INSTALLED_APPS = [
    # apps
    'compressor',
]</code></pre>



<p>Perfect, since we are using Django’s staticfiles contrib app, we have to add Django Compressor’s file finder to our <code>STATICFILES_FINDERS</code> setting. Inside your <code>settings.py</code> file, add:</p>



<pre><code lang="python"># myproject/settings.py 

STATICFILES_FINDERS = (
    'django.contrib.staticfiles.finders.FileSystemFinder',
    'django.contrib.staticfiles.finders.AppDirectoriesFinder',
    'compressor.finders.CompressorFinder',
)</code></pre>



<p>Now Django Compressor can find our static files. By default, Django Compressor will bundle our CSS files but not minify them. To minify the bundled CSS file, we need to pass the bundled file through a CSS filter. Let’s configure our CSS filters. Inside your <code>settings.py</code> file, add:</p>



<pre><code lang="python"># myproject/settings.py

COMPRESS_ENABLED = True
COMPRESS_FILTERS = {
        "css": [
            'compressor.filters.css_default.CssAbsoluteFilter',  
            'compressor.filters.cssmin.CSSMinFilter',
        ]
}</code></pre>



<p>Let’s break down what’s happening here. First, we set <code>COMPRESS_ENABLED</code> to <code>True</code>—this tells Django Compressor to compress our CSS files while in development mode.</p>



<p>Next, we define a list of filters to pass the bundled CSS through. The <code>CssAbsoluteFilter</code> normalizes the URLs in your CSS files to absolute URLs, like the URLs in the CSS <code>url()</code> function, and the <code>CSSMinFilter</code> minifies the bundled CSS.</p>



<p>Perfect, that takes care of the configuration. Let’s set up our templates and start using Django Compressor to minify and bundle our CSS files in the next section.</p>



<h3>Setting Up Templates</h3>



<p>Inside our Django app, let’s create our template folder structure.</p>



<pre><code lang="bash">+-- myapp
    +-- migrations
    +-- templates
        -- base.html
        +-- myapp
            -- mytemplate.html</code></pre>



<p>That takes care of the folder structure. Let’s create our <code>base.html</code> template now. Inside the <code>base.html</code> template, add:</p>



<pre><code lang="markup">{% <em>load</em> compress static %}
&lt;!DOCTYPE <em>html</em>&gt;
&lt;html <em>lang</em>="en"&gt;
    &lt;head&gt;
        &lt;!-- Global StyleSheets --&gt;
        {% <em>compress</em> css %}
           &lt;link <em>rel</em>="stylesheet" <em>href</em>="{% static 'css/base.css' %}"&gt;
        {% <em>endcompress</em> %}

        {% <em>compress</em> css %}
        {% <em>block</em> styles %}
            &lt;!-- Child Template StyleSheets Go Here --&gt;
        {% <em>endblock</em> %}
        {% <em>endcompress</em> %}

        &lt;title&gt;Tutorial&lt;/title&gt;
    &lt;/head&gt;
   ....
&lt;/html&gt;</code></pre>



<p>We load in the compressor template tags and place the files we want to bundle and minify inside the <code>{% compress %}</code> template tag to use Django Compressor. The compress template tag takes one required argument: The filter key from the <code>COMPRESS_FILTERS </code>dictionary that tells Django Compressor which filters to use for these files. </p>



<p>Notice, I placed a style block inside the compressor template tag—this will put the child template stylesheets inside the compressor to be bundled and minified. </p>



<p>Lastly, let’s create a child template and add some stylesheets to it.</p>



<pre><code lang="markup">{% <em>extends</em> 'base.html' %}

{% <em>load</em> static %}

{% <em>block</em> styles %}
&lt;link <em>rel</em>="stylesheet" <em>href</em>="{% static 'css/index.css' %}"&gt;
&lt;link <em>rel</em>="stylesheet" <em>href</em>="{% static 'css/additional.css' %}"&gt;
{% <em>endblock</em> %}

{% <em>block</em> content %}
&lt;h1&gt;Index&lt;/h1&gt;
{% <em>endblock</em> %}</code></pre>



<p>Perfect, now we can test it out in the browser. Save your files and navigate over to <code>localhost:8000</code> in your browser. Inside your developer tools network tab, you should see something similar to this:</p>



<figure><img loading="lazy" width="1024" height="201" src="https://engineertodeveloper.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-14-at-9.07.23-PM-1024x201.png" alt="Compressed CSS file shown in the network tab of the developer tools." srcset="https://engineertodeveloper.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-14-at-9.07.23-PM-1024x201.png 1024w, https://engineertodeveloper.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-14-at-9.07.23-PM-980x192.png 980w, https://engineertodeveloper.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-14-at-9.07.23-PM-480x94.png 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) and (max-width: 980px) 980px, (min-width: 981px) 1024px, 100vw"></figure>



<p>The bundled and minified CSS file <code>output.9a3d8d8fb748.css</code> is on line two. Awesome, Django compressor took our two child template CSS files, bundled them, and minified them—this will reduce network requests and speed up browser download and parsing times!</p>



<p>We can use Django Compressor to do the same with our JavaScript files too. In the next section, let’s learn how we can further optimize our template’s CSS files.</p>



<h2>Reducing Render-Blocking CSS with Media Attributes</h2>



<p>CSS files can quickly become bloated with a bunch of rules our page doesn’t need. For example, if someone accesses your site on a mobile device, they don’t need to parse the tablet and desktop styles before using the webpage. They only need the mobile styles.</p>



<p>Thankfully, we have a way around this with the <code>media</code> attribute. We can add a <code>media</code> attribute to the link tag to conditionally parse styles before rendering, depending on screen size. The other CSS files are still downloaded, but they are no longer render-blocking, meaning the browser doesn’t wait for them to load before rendering the webpage.</p>



<p>Let’s look at an example using our child template and base template. Inside the base template, define a new block called <code>mobile_styles</code>.</p>



<pre><code lang="markup">&lt;head&gt;
    {% <em>compress</em> css %}
    {% <em>block</em> mobile_styles %}

    {% <em>endblock</em> %}
    {% <em>endcompress</em> %}
&lt;/head&gt;</code></pre>



<p>Now, let’s add the mobile stylesheet in the child template.</p>



<pre><code lang="markup">{% <em>block</em> mobile_styles %}
&lt;link <em>rel</em>="stylesheet" <em>href</em>="{% static 'css/index-mobile.css' %}" <em>media</em>="(max-width: 520px)"&gt;
{% <em>endblock</em> %}</code></pre>



<p>If we test this out in the browser, we see that both mobile and desktop stylesheet are still downloaded, but only one was render-blocking depending on our screen size. If we resize the browser window, we will see the mobile stylesheet affect screen sizes below 520px.</p>



<p>Perfect, we are now loading less render-blocking CSS—this will improve our largest contentful paint and first input delay metrics.</p>



<h2>Conclusion</h2>



<p>Congrats on finishing the tutorial! You should now know how to optimize your Django template’s CSS and JavaScript using Django Compressor and reducing render-blocking CSS. </p>



<p>In the <a href="https://engineertodeveloper.com/faster-django-apps-optimizing-templates-part-2/">next tutorial</a>, we will look at optimizing images in our Django templates—images have a massive impact on page load speed performance.</p>



<p>I hope you found this tutorial helpful. If you have any questions leave a comment below and I will do my best to help out!</p>
</div></div>]]>
            </description>
            <link>https://engineertodeveloper.com/faster-django-apps-optimizing-templates-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442290</guid>
            <pubDate>Wed, 16 Dec 2020 13:35:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Large tech company websites contain many spelling mistakes]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25442206">thread link</a>) | @petems
<br/>
December 16, 2020 | https://www.getsiteinspector.com/blog/spelling-errors-on-tech-company-websites/ | <a href="https://web.archive.org/web/*/https://www.getsiteinspector.com/blog/spelling-errors-on-tech-company-websites/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">
        <article>
  

  <div>
    <p>Scanning 5 tech company websites using <a href="https://github.com/siteinspector/siteinspector">SiteInspector</a> open-source tool shows that all of them contain a dozen of errors at the very least.</p>

<h3 id="apple">Apple</h3>

<p><img src="https://www.getsiteinspector.com/blog/images/apl-1.png">
  <img src="https://www.getsiteinspector.com/blog/images/apl-2.png">
  <img src="https://www.getsiteinspector.com/blog/images/apl-3.png">
</p>

<ul>
  <li><strong>turn into turn into</strong> (duplicate)</li>
  <li><strong>acess</strong> (correct <em>access</em>)</li>
  <li><strong>to to</strong> (duplicate)</li>
</ul>

<h3 id="atlassian">Atlassian</h3>

<p><img src="https://www.getsiteinspector.com/blog/images/atl-1.png">
  <img src="https://www.getsiteinspector.com/blog/images/atl-2.png">
  <img src="https://www.getsiteinspector.com/blog/images/atl-3.png">
</p>

<ul>
  <li><strong>responsibilites</strong> (correct <em>responsibilitis</em>)</li>
  <li><strong>the the</strong> (duplicate)</li>
  <li><strong>to get to get</strong> (duplicate)</li>
</ul>

<h3 id="gitlab">Gitlab</h3>

<p><img src="https://www.getsiteinspector.com/blog/images/glb-1.png">
  <img src="https://www.getsiteinspector.com/blog/images/glb-2.png">
  <img src="https://www.getsiteinspector.com/blog/images/glb-3.png">
</p>

<ul>
  <li><strong>toolcahin</strong> (correct <em>toolchain</em>)</li>
  <li><strong>abiity</strong> (correct <em>ability</em>)</li>
  <li><strong>spport</strong> (correct <em>support</em>)</li>
</ul>

<h3 id="salesforce">Salesforce</h3>

<p><img src="https://www.getsiteinspector.com/blog/images/sfs-1.png">
  <img src="https://www.getsiteinspector.com/blog/images/sfs-2.png">
  <img src="https://www.getsiteinspector.com/blog/images/sfs-3.png">
</p>

<ul>
  <li><strong>identites</strong> (correct <em>identities</em>)</li>
  <li><strong>an an</strong> (duplicate)</li>
  <li><strong>sharable</strong> (correct <em>shareable</em>)</li>
</ul>

<h3 id="shopify">Shopify</h3>

<p><img src="https://www.getsiteinspector.com/blog/images/spf-1.png">
  <img src="https://www.getsiteinspector.com/blog/images/spf-2.png">
  <img src="https://www.getsiteinspector.com/blog/images/spf-3.png">
</p>

<ul>
  <li><strong>langauge</strong> (correct <em>language</em>)</li>
  <li><strong>it’s own</strong> (correct <em>its own</em>)</li>
  <li><strong>availabilty</strong> (correct <em>availability</em>)</li>
</ul>

  </div>

  <p>
    Written on December  4, 2020
  </p>

  
<div>
	
	
	
</div>

</article>

      </div></div>]]>
            </description>
            <link>https://www.getsiteinspector.com/blog/spelling-errors-on-tech-company-websites/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442206</guid>
            <pubDate>Wed, 16 Dec 2020 13:26:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting started with C programming a lightning-fast start for absolute beginners]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 39 (<a href="https://news.ycombinator.com/item?id=25442165">thread link</a>) | @hdante
<br/>
December 16, 2020 | https://not.cafe/2020/10/12/getting-started-with-c-programming.html | <a href="https://web.archive.org/web/*/https://not.cafe/2020/10/12/getting-started-with-c-programming.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <article>
    

  <h5>Posted at <time>2020-10-13 00:32+0000</time>
  
          , <em>last edit: <time>2020-12-14 18:47+0000</time></em>
  
  </h5>

  
  

  <p><span>!☕</span> This tutorial will guide you through writing the
“Hello World” program in the C programming language. You’ll use Unix-style terminal
emulators and command-line tools to execute commands, Linux-style package managers to
install programs and libraries, the GNU nano text editor to write C code, the meson build
system to build executable programs and the Gtk+ library to write portable, cross-platform
graphical programs.</p>

<figure>
  <a href="https://commons.wikimedia.org/wiki/File:Ken_Thompson_(sitting)_and_Dennis_Ritchie_at_PDP-11_(2876612463).jpg" target="_blank">
    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8f/Ken_Thompson_%28sitting%29_and_Dennis_Ritchie_at_PDP-11_%282876612463%29.jpg/599px-Ken_Thompson_%28sitting%29_and_Dennis_Ritchie_at_PDP-11_%282876612463%29.jpg" alt="Ken Thompson (sitting) and Dennis Ritchie at PDP-11">
  </a>
  <figcaption>
    <a href="https://en.wikipedia.org/wiki/Dennis_Ritchie" target="_blank">
    Dennis Ritchie
    </a> (standing), the creator of the C programming language, with
    <a href="https://en.wikipedia.org/wiki/Ken_Thompson" target="_blank">Ken Thompson</a>, the
    creator of Unix. Ken is using a
    <a href="https://en.wikipedia.org/wiki/Teleprinter" target="_blank">teletypewriter</a>
    (known as a tty on Unix) typewriter-style
    <a href="https://en.wikipedia.org/wiki/Computer_terminal" target="_blank">physical terminal</a>.
    Behind is the <a href="https://en.wikipedia.org/wiki/PDP-11" target="_blank">DEC PDP-11</a>
    minicomputer.
  </figcaption>
</figure>

<p>Instructions&nbsp;for&nbsp;three operating systems are provided: macOS, Ubuntu Linux and
Windows. The selected tools are personal favorites and were hand picked to allow the
fastest development and to allow identical development flows (and thus seamless
environment switching) on the three operating systems. All tools used in this tutorial are
<a href="https://en.wikipedia.org/wiki/Free_and_open-source_software" target="_blank">free, open source software</a>
and can be downloaded and used without any issues. No programming experience is required,
as this tutorial is for absolute beginners.</p>

<h3 id="before-we-start-terminals">Before we start: terminals</h3>

<p>There are a few notes for absolute beginners that will make our path easier and faster to
understand: to stay short, the tutorial will only guide through the setup process, but
will not teach the C language; references for next steps will be given at the end; some
program downloads may be large and take some time.</p>

<p>Programming languages and textual commands are very different from spoken languages:
programs must be written in a very strict way. Miss a comma and the program will stop
working. The most important rule for a beginner is that the C language, like most other
programming languages, is case sensitive, that is, upper case letters are considered
distinct from lower case letters and one can’t be swapped for the other. Keep this in mind
when typing the code and when in doubt copy and paste it to make sure all symbols are
correctly written.</p>

<figure>
  <a href="https://www.sydney.edu.au/science/psychology/pdp-11/terminals.html" target="_blank">
    <img src="https://not.cafe/assets/2020/terminals.jpeg" alt="PDP-11 terminals">
  </a>
  <figcaption>
    The <a href="https://en.wikipedia.org/wiki/VT52#VT55" target="_blank">DEC VT55</a>
    (display-style terminal, left side), the
    <a href="https://en.wikipedia.org/wiki/DECwriter" target="_blank">DECwriter</a>
    (dot-matrix printer-style terminal) and the
    <a href="https://en.wikipedia.org/wiki/Teletype_Model_33" target="_blank">Teletype ASR-33</a>
    (typewriter-style terminal).
  </figcaption>
</figure>

<p>We’ll&nbsp;use&nbsp;the terminal emulator application to type textual commands. I’ll
succintly explain what each command does and will show each command written after a dollar
sign. The dollar sign represents the terminal emulator’s prompt symbol, and that’s the
usual symbol that the command line input program, called the shell, displays when waiting
for a command. For example:</p>

<pre><code>$ ls -l
</code></pre>

<p>In the above example, we type after the prompt symbol: <code>ls[space][minus]l</code>, then press
<code>[enter]</code> to execute. In this example, we execute the <code>ls</code> program (list directory) with
the <code>-l</code> parameter (a specific parameter for the program, changes the output mode to long,
or more descriptive). Same example, but also showing the resulting output in my computer:</p>

<pre>$ ls -l
total 7344
-rw-r--r-- 1 hdante users    9999 set 19 19:12 coffee-34251.svg
-rw-r--r-- 1 hdante users     347 set 19 19:12 coffee-34251.svg.license
-rw-r--r-- 1 hdante users   16805 set 19 19:12 favicon.ico
-rw-r--r-- 1 hdante users    3253 set 19 19:12 favicon.svg
-rw-r--r-- 1 hdante users   11665 out  2 18:49 index.html
-rw-r--r-- 1 hdante users   17833 set 19 19:12 not-coffee.svg
-rw-r--r-- 1 hdante users 2372085 set 19 19:12 radio.caf
-rw-r--r-- 1 hdante users 2656465 set 19 19:12 radio.mka
-rw-r--r-- 1 hdante users 2401864 set 19 19:12 radio.opus
-rw-r--r-- 1 hdante users    3263 out  2 16:48 site.css
-rw-r--r-- 1 hdante users    2166 set 19 19:12 square.svg
$ </pre>

<p>So,&nbsp;after&nbsp;running the <code>ls</code> program with the <code>-l</code> parameter, it shows the long
description of current directory and another dollar symbol appears at the end, it’s
waiting for a new command. Don’t worry about understanding this example, I’ll also add
references at the end for learning more about using Unix-style command-line tools.</p>

<h3 id="installation">Installation</h3>

<figure>
  <a href="https://not.cafe/assets/2020/macos-terminal-app.jpeg" target="_blank">
    <img src="https://not.cafe/assets/2020/macos-terminal-app.jpeg" alt="macOS Terminal App">
  </a>
  <figcaption>
    The
    <a href="https://en.wikipedia.org/wiki/Terminal_(macOS)" target="_blank">
    macOS Terminal.app
    </a> is a
    <a href="https://en.wikipedia.org/wiki/Terminal_emulator" target="_blank">terminal emulator</a>.
    Modern terminals are software that emulate physical terminals.
  </figcaption>
</figure>

<p>Different&nbsp;procedures&nbsp;are required for each operating system. Pick the best one
for you. After installing, writing and running code will work the same way. We’ll write a
single cross-platform program that works on all three systems and build it using the same
cross-platform build tools.</p>

<h4 id="macos">macOS</h4>

<p>For macOS, only the terminal emulator comes installed with the operating system. The Apple
provided C compiler is the
<a href="https://en.wikipedia.org/wiki/Clang" target="_blank">LLVM clang compiler</a>,
contained in the “Xcode command line tools” package. To install it, open the Terminal
application by opening the Spotlight search input, then typing Terminal (or find it in the
Utilities folder inside Applications). In the terminal emulator, type:</p>

<pre><code>$ xcode-select --install
</code></pre>

<p>The Xcode installation program will start. Follow the instructions that will appear and in
the end, the LLVM clang C compiler will be installed. You can check if it’s working by
executing it with the <code>--version</code> parameter:</p>

<pre><code>$ clang --version
</code></pre>

<p>For installing packages like build tools, text editors and libraries, we’ll install the
<a href="https://en.wikipedia.org/wiki/Homebrew_(package_manager)" target="_blank">Homebrew package manager</a>,
which is the main Linux-style package manager for macOS. The package manager allows
single-command installing, configuring, upgrading and removing of packages from the
command line. Go to <a href="https://brew.sh/" target="_blank">brew.sh</a> and access the
instructions there, or simply execute this command to download and install it:</p>

<pre><code>$ /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)"
</code></pre>

<p>Notice that this command is already more complex than the previous ones, downloading and
executing the install script from the Homebrew source code repository, and gives a hint on
the power and efficiency of the command line. Don’t worry trying to understand it, we’re
installing Homebrew exactly to make it easy to execute complex package installations.
[<strong>edit 20201214</strong>: It might be necessary to restart the Terminal App and configure the
search path after installing <code>brew</code> to be able to use it. When in doubt, check the
<a href="https://docs.brew.sh/">Homebrew documentation</a>.]</p>

<p>Now that Homebrew is installed, you may install packages with <code>brew install</code> and search
packages with <code>brew search</code>. Search and install the GNU nano text editor with:</p>

<pre><code>$ brew search nano
$ brew install nano
</code></pre>

<h4 id="linux">Linux</h4>

<figure>
  <a href="https://not.cafe/assets/2020/gcc-on-ubuntu.png" target="_blank">
    <img src="https://not.cafe/assets/2020/gcc-on-ubuntu.png" alt="gcc on Ubuntu">
  </a>
  <figcaption>
    Installing gcc on Ubuntu Linux.
  </figcaption>
</figure>

<p>We’ll&nbsp;use&nbsp;the apt package manager available in
<a href="https://ubuntu.com/" target="_blank">Ubuntu Linux</a> from the Debian family, but
other Linux distributions using, for example,
<a href="https://www.redhat.com/sysadmin/how-manage-packages" target="_blank">yum</a>,
<a href="https://docs.fedoraproject.org/en-US/quick-docs/dnf/" target="_blank">dnf</a>,
<a href="https://wiki.archlinux.org/index.php/Pacman" target="_blank">pacman</a>,
etc. will work in pretty much the same way. On Linux the
<a href="https://gcc.gnu.org/" target="_blank">GNU Compiler Collection</a>
usually comes preinstalled, so we’ll use it instead of clang, but they work the same way.
Open a terminal by clicking the activities menu on the top left of the screen and writing
terminal in the search input (or click on the terminal icon in the favorites bar). In the
terminal emulator, write:</p>

<pre><code>$ sudo apt-get install gcc
</code></pre>

<p>Ubuntu Linux and most other distributions require switching to administrator (root) mode
to install programs, so we use the <code>sudo</code> program to execute <code>apt-get</code> in root mode (you
may also use the <code>su</code> program, if <code>sudo</code> is not installed). Type your password and follow
the instructions. In the end, check gcc:</p>

<pre><code>$ gcc --version
</code></pre>

<p>You may install packages with <code>sudo apt-get install</code> and search packages with <code>apt-cache
search</code>:</p>

<pre><code>$ apt-cache search nano
$ sudo apt-get install nano
</code></pre>

<p>For other Linux distributions, use the appropriate package manager:</p>

<pre><code>$ yum search nano         # for RedHat Linux/CentOS
$ sudo yum install nano   # for RedHat Linux/CentOS
</code></pre>

<h4 id="windows">Windows</h4>

<figure>
  <a href="https://www.msys2.org/" target="_blank">
    <img src="https://not.cafe/assets/2020/msys2-website.jpeg" alt="MSYS2 website">
  </a>
  <figcaption>
    <a href="https://www.msys2.org/" target="_blank">MSYS2 website</a>. MSYS2 is a
    toolkit for Windows development that contains Unix-style tools.
  </figcaption>
</figure>

<p>For Windows we’ll use the
<a href="https://en.wikipedia.org/wiki/Mingw-w64#MSYS2" target="_blank">MSYS2 toolkit</a>,
which provides a terminal emulator, the pacman package manager and a complete set of
Unix-style command line tools. Download the MSYS2 installer from
<a href="https://www.msys2.org/" target="_blank">www.msys2.org</a> and follow the
instructions to install the package. When installed, MSYS2 will provide three sets of
programs, which are selected whenever opening the terminal emulator. They are called the
MSYS2 shell, the MINGW64 shell (pronounced mingwee 64) and the MINGW32 shell. The MINGW64
shell is the appropriate one to develop Windows programs. The MSYS2 is appropriate for
managing MSYS2 itself and the MINGW32 is the 32-bit version that shouldn’t be used
anymore. After installing MSYS2 it’s necessary to immediatelly upgrade it. Open the MSYS2
shell and type:</p>

<pre><code>$ pacman -Syu
</code></pre>

<p>Follow the instructions and if requested restart the terminal emulator. On Windows we’ll
use the <a href="https://gcc.gnu.org/" target="_blank">GNU Compiler Collection</a> C
compiler (gcc):</p>

<pre><code>$ pacman -S mingw-w64-x86_64-toolchain
</code></pre>

<p>After installing, to test gcc, you must use a MINGW64 shell. If you’re running the MSYS2
shell for executing pacman, open another terminal running the MINGW64 shell and type:</p>

<pre><code>$ gcc --version
</code></pre>

<p>From now on, we’ll assume that the MINGW64 shell is being used. Notice that pacman runs
normally both on MSYS2 and MINGW64 shells. You may install packages with <code>pacman -S</code> and
search packages with <code>pacman -Ss</code>:</p>

<pre><code>$ pacman -Ss nano
$ pacman -S nano
</code></pre>

<h3 id="hello-world-">Hello, World !</h3>

<figure>
  <a href="https://not.cafe/assets/2020/nano-on-macos.jpeg" target="_blank">
    <img src="https://not.cafe/assets/2020/nano-on-macos.jpeg" alt="GNU nano on macOS">
  </a>
  <figcaption>
    Writing the Hello World program using GNU nano on macOS.
  </figcaption>
</figure>

<p>After installing the compilers, remember installing the
<a href="https://en.wikipedia.org/wiki/GNU_nano" target="_blank">GNU nano</a> text editor:</p>

<pre><code>$ brew install nano    # (or apt-get, or pacman)
</code></pre>

<p>Now, let’s create a new root directory to store this project and all future code:</p>

<pre><code>$ mkdir code
$ cd code
</code></pre>

<p>The first command above creates a new directory called <code>code</code>. If it already exists, it
will complain. Change the name if you prefer something else. The second command changes
the current directory to the <code>code</code> directory (the current directory is the directory used
when file operations specify file names without …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://not.cafe/2020/10/12/getting-started-with-c-programming.html">https://not.cafe/2020/10/12/getting-started-with-c-programming.html</a></em></p>]]>
            </description>
            <link>https://not.cafe/2020/10/12/getting-started-with-c-programming.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442165</guid>
            <pubDate>Wed, 16 Dec 2020 13:21:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experiments on a $50 DIY air purifier that takes 30s to assemble]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 52 (<a href="https://news.ycombinator.com/item?id=25442097">thread link</a>) | @dyno-might
<br/>
December 16, 2020 | https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
            
            <p><strong>Dec 15, 2020</strong></p>
            
            



<p>Bad air is bad for you. The air purifier market, though, is a mess. Every purifier uses incompatible proprietary filters, presumably to lock you into buying replacements. How do we know these actually work? Few seem to publish lab tests. And why does it cost $100-$300 for a big plastic box with a fan and a filter inside?</p>

<p>It’s common to build DIY air purifiers by basically strapping a filter to a fan. I like the idea of these, but again, it’s hard to be confident they really work. There’s a few experiments out there, but not enough to make me comfortable. So I decided to do some experimenting of my own. I made a purifier, generated smoke, and measured how well it removes tiny particles.</p>



<p>If you’re in a hurry, this post says that if you strap two HEPA filters to a box fan, it will clear the air of basically all the particles we can measure, and it will do it faster than a commercial filter that costs twice as much.</p>

<p><img src="https://dyno-might.github.io/img/purifier/smallroom_log.jpg" alt="in a large room the DIY filter does slightly better than the commercial filter"></p>



<h3 id="diy-purifier">DIY purifier</h3>

<p>My DIY purifier was <em>very</em> simple. (I don’t want to promote any particular brands here. Contact me if you want the exact products.)</p>

<ul>
  <li>A standard box fan. (Cost: $19)</li>
  <li>Two HEPA air filters, each approximately 32 cm x 22 cm and 5cm thick. (Cost: $35 for both)</li>
  <li>A bungie cord. (Cost: Free)</li>
</ul>

<p>Assembly takes about 30s. You put the filters on the intake side of the fan and strap them on with the bungie cord. Here’s a picture:</p>

<p><img src="https://dyno-might.github.io/img/purifier/filter_notape.jpg" alt="DIY purifier" max-width="60%" min-width="35%"></p>

<p>Timeless elegance and grace, it is not. I get the shakes just looking at that bit of crinkled filter.</p>

<h3 id="commercial-purifier">Commercial purifier</h3>

<p>As a comparison, I got a $100 air purifier from a well-known brand that’s intended for small rooms. It uses uses a single HEPA filter that’s about 25cm x 12cm and 4cm thick. Replacement filters currently cost around $25.</p>

<h3 id="smoke">Smoke</h3>

<p>It’s surprisingly hard to repeatedly generate a consistent amount of smoke. I tried burning various things (paper, cardboard) and found that the number of particles generated can vary by an order of magnitude, depending on the burn pattern. This is difficult to control and effectively random.</p>

<p>Ideally, I’d have liked to burn some food product like oil, since the kitchen is usually the biggest source of indoor air pollution. I couldn’t figure out a good way of doing this, either: You’d need to have the same amount of oil distributed in the same way and heated to the same temperature.</p>

<p>I finally settled on using incense. I cut sticks to the length of a standard credit card and then attached the ends horizontal to the ground. This seemed to be pretty consistent. In retrospect, I bet that burning toast in a toaster would work well. (I didn’t have one on hand.)</p>

<h3 id="measurements">Measurements</h3>

<p>I borrowed a cheap-ish ($100) air quality monitor from a friend. I think it’s made by some company in China and then re-sold by various white-label brands. I can’t figure out who the original manufacturer is. Based on data I’ve seen for the reliability of other air quality monitors, I wouldn’t trust the absolute numbers, but the I think the <em>relative</em> measurements should still be OK.</p>

<p>The typical measurement for particulate pollution is “PM 2.5” which is in units of μg/m³. This is intended to measure what you’d get if you did the following:</p>
<ul>
  <li>Take a cubic meter of air.</li>
  <li>Filter all the solid particles out of the air.</li>
  <li>Keep only the solid particles that are are 2.5 micrometers (μm) or smaller.</li>
  <li>Weigh all the particles you kept in micrograms (μg).</li>
</ul>

<p>Here are some ways to interpret these numbers:</p>
<ul>
  <li>The EPA says yearly averages should be below 12 and daily averages below 35.</li>
  <li>The average outdoor level ranges from 6 in Finland to almost 100 in Nepal. Rich countries are typically under 15. The highest levels are typically found in Asia and Africa.</li>
  <li>Cooking can easily cause PM 2.5 measurements to spike into the hundreds. I’ve observed myself that this can happen with only a small amount of visible smoke.</li>
</ul>

<h3 id="logging">Logging</h3>

<p>Since the air quality monitor doesn’t log data, I used an ultra-hacky alternative: I set the monitor next to a laptop running a stopwatch. I then aimed a tabet at both of those screens and took a timelapse video. Finally, I manually transcribed the data by going to each minute marker in the data. (This was even more tedious than it sounds.)</p>



<p>I ran a first experiment in a tiny room of around 8 ㎥. Due to worries that wind from the purifiers might change the speed the incense burned, I placed it on the opposite side of a wall, with a gap of around 20 cm near the ceiling.</p>

<p><img src="https://dyno-might.github.io/img/purifier/setup_tinyroom.jpg" alt="tiny room setup"></p>

<p>I repeated the experiment once with no filter, once with a commercial filter, and once with the DIY filter. Here are the results:</p>

<p><img src="https://dyno-might.github.io/img/purifier/smallroom_linear.jpg" alt="smallroom measurements in linear space"></p>

<p>Things are a bit random around the beginning, probably due to the drifting of the smoke before it’s equalized in the room. With no filter at all, this spikes all the way to 1000 μg/m³, the maximum the instrument can show.</p>

<p>If we make the y-axis logarithmic, it becomes quite clear that the DIY filter is cleaning the air at a better rate. (This is the picture from the top of this page.)</p>

<p><img src="https://dyno-might.github.io/img/purifier/smallroom_log.jpg" alt="smallroom measurements in log space"></p>

<p>If we take the EPA’s threshold of 12 μg/m³, the DIY filter gets there in around 15 minutes, while the commercial filter take around 25 minutes.</p>



<p>Thankfully, I don’t spend most of my time in an 8 ㎥ room. Thus, I repeated the experiment in a large room of around 100 ㎥. Here there was no wall between incense and purifier. Instead I left around a meter of distance between the incense and purifier and the purifier and the monitor.</p>

<p><img src="https://dyno-might.github.io/img/purifier/setup_largeroom.jpg" alt="large room setup"></p>

<p>Here are the results:</p>

<p><img src="https://dyno-might.github.io/img/purifier/largeroom_linear.jpg" alt="large room measurements in linear space"></p>

<p>There’s even more randomness around the beginning, probably just due to how the smoke drifts around. Based on the room volume we’d expect a peak concentration with no filter of around 80 μg/m³ = 1000 μg/m³ * (8/100). Reassuringly, this is pretty close to what we see.</p>

<p>The DIY purifier looks a bit better. If we plot in log space, it’s more clear that it is indeed filtering at a better rate:</p>

<p><img src="https://dyno-might.github.io/img/purifier/largeroom_log.jpg" alt="large room measurements in log space"></p>



<p>It’s common advice for DIY purifiers like this to seal around the edges of the filter so that all air must pass through it.  I share the intuition that this would help, but it’s hard to be sure: If you block airflow, you slow down the fan. This could be counterproductive.</p>

<p>In this case at least, experiment is easier than theory. I took packing tape and carefully sealed around the intake side.</p>

<p><img src="https://dyno-might.github.io/img/purifier/filter_tape.jpg" alt="DIY purifier with tape" max-width="60%" min-width="35%"></p>

<p>And the results are…</p>

<p><img src="https://dyno-might.github.io/img/purifier/taping.jpg" alt="taping around the filter has no effect"></p>

<p>…nothing!?</p>

<p>This was unexpected. I thought the tape would help, but I wouldn’t have been surprised if it hurt instead. Instead, there’s basically no difference at all. I don’t know enough about fluid dynamics to even speculate about what’s happening here, so I won’t try.</p>

<p>There could be some weird quirk in how I ran this experiment. This doesn’t necessarily mean that all the advice to tape around the filter is <em>wrong</em>. However, I’ve never seen any experriments that show taping helps either.</p>



<p><strong>Cost.</strong> The DIY purifier isn’t dramatically cheaper than the commercial one, but I expect the filters would need to be replaced much less often. The commercial purifier uses a single filter with an area of 300 cm², whereas the DIY purifier uses two filters with a total area of around 1400 cm², and also slightly thicker. It’s reasonable to assume the DIY filters could remove ~4 times as many particles before replacement.</p>

<p><strong>Durability.</strong> One concern is that box fans aren’t meant to be used with filters attached and could wear out. This is reasonable. However, box fans are much cheaper than commercial purifiers, and I’ve been using this particular fan with various filters attached for several years now without issue.</p>

<p><strong>Electricity.</strong> The cost of electricity is another factor. Typical box fans seem to use around 55W, whereas commercial purifiers typically use 30-45W. If electricity costs $0.13 / kWh, the box fan would cost around $62 to operate 24 hours a day for a year, while a 30-watt purifier would cost around $34. Obviously, these numbers decrease if you run the purifier less. Some (more expensive) commercial purifiers have air quality sensors built in and automatically turn on only when needed.</p>

<p><strong>MERV or HEPA?</strong> Most people who build box-fan purifiers use <a href="https://en.wikipedia.org/wiki/Minimum_efficiency_reporting_value">MERV</a>-rated filters intended for furnaces. Commercial air purifiers use <a href="https://en.wikipedia.org/wiki/HEPA">HEPA</a>-rated filters. Roughly speaking, HEPA filters are “better” in that they are rated to remove a higher percentage of particles in one pass. It’s not clear that HEPA filter will actual perform better when attached to a fan, though: A filter that catches fewer particles in one pass might still be better if it allows for faster airflow.</p>

<p><strong>That one video.</strong> If you’re reading this article after it was linked from some forum, I’d bet you that someone in the comments links to <a href="https://www.youtube.com/watch?v=kH5APw_SLUU">this video</a> from the Michigan Sinus Center. I found this inspirational, but note a couple of things: First, while the description says they use HEPA filter, the video clearly indicates a MERV filter. Again, that’s not necessarily bad! They claim that around 90% of particles sized 0.3 microns are larger are eliminated in a single pass. That’s good, but not totally reassuring. The question is, does it remove 99% in two passes? If 90% of the particles in the ambient air were large and the filter only catches large particles, then additional passes would never get rid of the most dangerous small particles. This is why I trust HEPA filters a bit more: since they remove almost all particles in one pass, I’m confident they should remove almost all particles eventually. This is also why I strongly prefer experiments that actually measure particles removed from the air in a room, rather than just the air coming out of the purifier.</p>

<p><strong>Further questions.</strong> There’s a lot of things that further experiments could look at:</p>

<ol>
  <li>Does the fan speed make a huge difference?</li>
  <li>How does the purifier compare to larger commercial purifiers?</li>
  <li>How do MERV-rated furnace-type filters compare under the same conditions?</li>
  <li>How can it not matter if there’s tape around the filters!?</li>
  <li>Does fan speed matter? (I always ran the box fan at maximum speed.)</li>
  <li>Is it better to put the filters on the intake or outtake side of the …</li></ol></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/">https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/</a></em></p>]]>
            </description>
            <link>https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442097</guid>
            <pubDate>Wed, 16 Dec 2020 13:15:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For e-mobility 2020 brought significant progress, this is an extensive overview]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25441956">thread link</a>) | @Pabloemm
<br/>
December 16, 2020 | https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html | <a href="https://web.archive.org/web/*/https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><a href="https://solidstudio.io/index.html">Solidstudio</a>
                    &gt;&gt;
                    <a href="https://solidstudio.io/blog/blog.html">Blog</a>
                    &gt;&gt;
                    &gt;The growing concept of e-Mobility as a Service
                </p>

                

                <h2 id="research-explanation">Research explanation of e-Mobility as a
                    Service</h2>

                <h3 id="emergence-of-emobility">Emergence of mobility concepts</h3>

                <p>
                    Before the digital revolution and user-centric approach, the concept of accessible, new forms of
                    transportation was the future vision of what life could be like. With the rapid growth of
                    technology, mobile devices, enhanced battery capacities, wide Internet connection, investments in
                    new unexplored forms of service delivery, and quick social adaptation in the last ten years we have
                    witnessed a great transformation.
                </p>
                <p>
                    Raising enthusiasm boosted consumption and proved that rapid adaptation is possible and widely
                    accepted. New economic models have begun to take into account sharing concepts and value the
                    tangible benefits of such solutions. In a sharing economy, not used assets such as parked cars and
                    extra bedrooms can be rented out. We transferred from owning to renting. And this concept widely
                    approved first by Uber users moved to other transport areas offering new possibilities. In the
                    Alternative Journal article,
                    <a href="https://www.alternativesjournal.ca/science-and-solutions/ours-better-yours" target="_blank" rel="nofollow">
                        ‘Ours is Better than Yours’
                    </a>
                    , Ray Tumulty (2014) the sharing economy is
                    described as a clearly urban phenomenon. To achieve economies of scale for shared economy services
                    satisfactory population density is required. Moreover, these services are seen as an extra option,
                    not a replacement for traditional sectors. Ridesharing is used along with public transportation in
                    cities.
                </p>
                <p>
                    With the growing success of rented items and services, new forms of transportation options come to
                    the market. The mobility concept grew to form a comprehensive ecosystem offering numerous moving
                    variants, such as city bikes, electric scooters, car rides, ticket purchasing options, city traffic
                    monitoring, planning the most convenient route, parking options, integrated payments, and available
                    charging options for ‘e’ users. All available in real-time from the mobile app on one’s phone. This
                    progress developed the term
                    <a href="https://solidstudio.io/blog/from-maas-to-emaas-how-e-is-taking-a-charge-over-the-markets.html" target="_blank" rel="nofollow">
                        Mobility as a service
                    </a>
                    , which covers a wide range of mobility services
                    available on the market, and its integral part becomes a shared economy providing extra value for
                    participants.
                </p>
                <p>
                    On a high-level, the MaaS ecosystem includes transport infrastructure, transportation services,
                    transport information, and payment services. Within the ecosystem, the common objective is the
                    delivery of a seamless mobility experience and transportation network improvement by utilizing the
                    benefits of each service - public and private. Besides, other participants such as local authorities
                    or data administration companies can collaborate to smooth the operation of the services and improve
                    their profitability.
                </p>
                <p>
                    MaaS as a definition is described as
                </p>
                <p><img src="https://solidstudio.io/img/blog/emobility-ebook/6.jpg" alt="MaaS definition" width="100%" height="auto">
                </p>
                <p>
                    One of the MaaS ecosystem examples was presented by the Siemens Mobility Division in 2016 for
                    Tampere City, Finland. The ecosystem is build of 4 main elements: service providers; a
                    business-to-business (B2B) platform; mobility retailers; and the users. The intention of the project
                    was to unite the existing and upcoming transport services with the operations of the local
                    paratransit services.
                </p>
                <p>
                    A similar approach on a high level was presented by König project ‘Mobility As A Service for Linking
                    Europe’. Four different levels define the public and regulatory level, the transport and logistics
                    service providers level, the mobility service level, and the end-user level. On the basis of similar
                    concepts and definitions, a framework for Mobility as a service was developed.
                </p>
                <p>
                    From a business perspective, MaaS is described by Kamargianni and Matyas in the paper ‘The Business
                    Ecosystem of Mobility-as-a-Service’[1](2017) as ‘the wider network of enterprises that influences how a
                    dominant company, in this case, the MaaS provider, creates and capture value’.
                </p>
                <p><img src="https://solidstudio.io/img/blog/emobility-ebook/7.jpg" alt="MaaS definition" width="100%" height="auto">
                </p>

                <p>
                    To support theoretical premises on shared mobility, a survey conducted by McKinsey&amp;Company (2017)
                    provides some insight into the consumer’s opinion on ride-hailing and car-sharing. Respondents were
                    asked how their usage of ride-hailing and car-sharing services will change within the next two
                    years. In both cases, over 60% responded that it will increase or increase significantly. Shared
                    mobility is mostly favored in urban areas, but seems to be less attractive for running errands or
                    multi-stop shopping trips.
                </p>

                <h3 id="what-is-e">What is ‘e’ all about?</h3>

                <p>
                    We are an integral part of the next global transformation, where alternative fuels and green energy
                    takes charge. The concept explained above has been extended with ‘e’ - a possibility to travel in an
                    eco-friendly way, where ‘e’ stands for electric solutions.
                </p>
                <p>
                    Electric Mobility as a service combines Mobility as a Service (MaaS), Electric Mobility Systems
                    (EMS), and Shared Electric Mobility Services (SEMS) [2]. As a concept eMaaS operates upon MaaS,
                    where the last one became one of the complementary components. With that defined, all MaaS
                    participants become, as a consequence, eMaaS attendees. Providing they offer electric mobility
                    solutions.
                </p>

                <p><img src="https://solidstudio.io/img/blog/emobility-ebook/8.jpg" alt="MaaS definition" width="100%" height="auto">
                </p>

                <p>
                    Electric Mobility System (EMS) covers technologies (batteries, charging technologies, drivetrains,
                    and EVs), infrastructure (physical and organizational of charging stations, electricity grid,
                    information and communication technology), and users (manufacturers, suppliers, end-users, service
                    providers, governments, and agents).
                </p>
                <p>
                    Shared Electric Mobility Services’ (SEMS) applies to a new economy implementation, where instead of
                    ownership there is an on-a-need basis share connected by the technology with users and providers.
                    SEMS replies to the environmental, social, financial, and transportation-related benefits that had
                    already been correlated to emobility and shared mobility practice connecting both. Five business
                    approaches are proposed:
                </p>
                <ul>
                    <li>
                        Membership-based (e.g. e-bike sharing, e-car sharing, e-ridesharing, e-ride hailing, e-scooter
                        sharing, e-bus sharing),
                    </li>
                    <li>
                        Peer-to-Peer(e.g. e-car sharing, e-bike sharing, e-scooter sharing),
                    </li>
                    <li>
                        Non-membership-based (e.g. e-car rental, elimousine rental),
                    </li>
                    <li>
                        For-hire (e.g. e-car/bike/scooter sharing, e-ridesharing e-carpooling),
                    </li>
                    <li>
                        Mass transit systems (e.g. e-Public Transport, airport autonomous shuttles).
                    </li>
                </ul>
                <p>
                    As a part of a wider concept, combined with two other components MaaS &amp; EMS, together provides
                    multiple eco-friendly transportation possibilities. Successful implementation of such a concept
                    requires multi-level support, well-designed system architecture, and an extensive network in public
                    structures.
                </p>

                <h3 id="user-centric">User-centric approach</h3>

                <p>
                    The user-centric approach will always be foreground. It applies to the development of the widely
                    recognized concept of e-mobility as a service. From accessible payment methods for single ticket
                    purchasing, subscriptions, to well-developed charging networks and various means of transport
                    access. At each stage of the proposition should be declared value.
                </p>
                <p>
                    We are still in the early stages of what could be called e-Mobility as a service. Most customer
                    journeys are under development, and achieving overall flow is still in its infancy. There is a lot
                    of research to be done, but there is room for the general necessary approaches. Each of the
                    participants, in order to achieve success and remain successful in this growing market, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html">https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html</a></em></p>]]>
            </description>
            <link>https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25441956</guid>
            <pubDate>Wed, 16 Dec 2020 12:59:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PerceptiLabs – A simple tool to build machine learning models]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25441955">thread link</a>) | @Xubeqi
<br/>
December 16, 2020 | https://perceptilabs.com/product | <a href="https://web.archive.org/web/*/https://perceptilabs.com/product">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-b80770e6=""><div xs="12" data-v-b80770e6=""> <p data-v-b80770e6="">
          PerceptiLabs is a dataflow driven, visual API for TensorFlow,
          carefully designed to make machine learning (or deep learning)
          modeling as intuitive as possible.
        </p></div></div></div>]]>
            </description>
            <link>https://perceptilabs.com/product</link>
            <guid isPermaLink="false">hacker-news-small-sites-25441955</guid>
            <pubDate>Wed, 16 Dec 2020 12:59:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing a recipe for distributed, small-scale food production]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25441679">thread link</a>) | @roboben
<br/>
December 16, 2020 | https://permapeople.org/blog/2020/12/02/designing-and-optimizing-a-recipe-for-distributed-food-production.html | <a href="https://web.archive.org/web/*/https://permapeople.org/blog/2020/12/02/designing-and-optimizing-a-recipe-for-distributed-food-production.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="introduction">Introduction</h2>

<p>I’ve been considering these concepts for a few years, and after spending a few years living in a small, economically-challenged community - I started to develop some ideas on how to power food sovereignty alongside traditional food sources like foraging, hunting, and fishing.</p>

<h2 id="distributed-small-scale-food-production-a-potential-solution">Distributed small-scale food production: A potential solution</h2>

<p>I realize this may be an idealistic approach, assuming people will be willing to take on the burden of learning new skills like animal husbandry, the many aspects of gardening, and the inevitable food preparation skills that are required to manage the outputs of such a system.</p>

<p>This being said, I think this could work for a minority of interested folks, and allow a more refined approach to a more accessible, possibly larger and possibly communal systems.</p>

<p><img src="https://permapeople.org/blog/assets/veg-garden-stella-de-smit.jpg" alt="Vegetable garden by Stella de Smit"></p>

<h2 id="ingredients">Ingredients</h2>

<h3 id="requirements">Requirements</h3>

<p>This list will need to be specific to each region such a system would be rolled out in. For this system to work, we should define each required <em>_niche_</em> or <em>_zone_</em> (medicine, staple, protein, etc) as well as the <em>_method_</em> (intensive row-based or food-forest style) based on an amount of land/space available.</p>

<ul>
  <li><strong>The system should</strong> <strong><em>not</em>:</strong></li>
  <li>Be a replacement for the grocery store</li>
  <li>
    <p>Be expected to feed a whole family exclusively</p>
  </li>
  <li><strong>The system should:</strong></li>
  <li>Follow the principles of permaculture</li>
  <li>Be supplementary to regular food purchasing/foraging/consumption</li>
  <li>Be easy to set up and get rolling (beginner crops for beginners)</li>
  <li>Maintenance should decrease year-over-year</li>
  <li>Material inputs should be free and should utilize waste products (compost, greywater) whenever possible</li>
  <li>Output should increase year-over-year</li>
  <li>Be scalable and easy to replicate</li>
  <li>Be easy to substitute items based on personal preference/needs</li>
  <li>Should support a range of diets</li>
  <li>Each element should serve two or more functions</li>
</ul>

<h3 id="elements">Elements</h3>

<ol>
  <li>
    <p>Staples - Something that is substantial, and worthy of being a main course. At least 2 crops in case of failure, most often annuals</p>
  </li>
  <li>
    <p>Medicine - Teas, herbs, healthful foods. Can easily grow 3+, often perennials</p>
  </li>
  <li>
    <p>Fertilizer/Mulching - Beneficial to growth or maintenance of the entire system (preferably edible)</p>
  </li>
  <li>
    <p>Greens - Important for health, and fulfilling an important niche in western diets</p>
  </li>
  <li>
    <p>Supplementary - Snacking foods, processable foods for jams or sauces</p>
  </li>
  <li>
    <p>Protein - Most likely and accessible item is egg production, but not legal everywhere</p>
  </li>
  <li>
    <p>Surplus - For use in feeding animals, wildlife, crafting, or trading with neighbours</p>
  </li>
</ol>

<h3 id="example-system">Example system</h3>

<p>Based on my experiences living and growing in the temperate coastal rainforests (zone 7b), I’ve developed this example/conceptual list to complement the locally available forage:</p>

<ol>
  <li><strong>Staples (2+)</strong>
    <ul>
      <li>Spaghetti squash / Acorn / butternut - for its many benefits (groundcover, mulch, seed production, hardiness)</li>
      <li>Potatoes - would require creative integration if using <em>_food forest_</em> method</li>
    </ul>
  </li>
  <li><strong>Medicine (2+)</strong>
    <ul>
      <li>Mint / lemonbalm / lavender / rosemary</li>
      <li>Currants / Seabuckthorn</li>
    </ul>
  </li>
  <li><strong>Fertilizer/Mulching (1 per season)</strong>
    <ul>
      <li>Comfrey</li>
      <li>Clover / alfalfa</li>
      <li>Pigeon peas / siberian peas</li>
    </ul>
  </li>
  <li><strong>Greens (2+)</strong>
    <ul>
      <li>Arugula</li>
      <li>Kale</li>
      <li>Giant red mustard</li>
      <li>Bok choi</li>
    </ul>
  </li>
  <li><strong>Supplementary (2)</strong>
    <ul>
      <li>Cucumber</li>
      <li>Apple tree (on Pacific crab-apple stock) / currant / blueberries / strawberry / raspberry</li>
      <li>Tomatoes</li>
      <li>Chives</li>
    </ul>
  </li>
  <li><strong>Protein (either/or)</strong>
    <ul>
      <li>3x hens / ducks</li>
      <li>Chickpeas / beans</li>
    </ul>
  </li>
  <li><strong>Surplus</strong></li>
</ol>

<ul>
  <li>Double-up on at least 2 choices from above</li>
</ul>

<h2 id="other-considerations-to-be-developed-further">Other considerations (to be developed further)</h2>

<ol>
  <li>
    <p>How can we empower economically-challenged communities through the use of food sovereignty?</p>
  </li>
  <li>
    <p>What would it take to convert the average non-gardener to start growing a sufficient amount of food?</p>
  </li>
  <li>
    <p>What would it take for the average non-gardener to benefit (enough to support) from an intensive, cooperative, multi-cultured field-cropping or food forest system?</p>
  </li>
  <li>
    <p>How far can we scale such a system if it does exist?</p>
  </li>
  <li>
    <p>What are the required inputs —  like space, water, and fertilizer?</p>
  </li>
  <li>
    <p>What are the minimal outputs to make this a worthwhile endeavor?</p>
  </li>
</ol>

<h2 id="next-steps">Next steps</h2>

<p>Get creating! As they say:</p>
<blockquote>
  <p>The best time to plant a tree, is 10 years ago. The second best time is now.</p>
  <ul>
    <li>Unknown</li>
  </ul>
</blockquote>

<p>If you have any questions, or want to talk about <em>anything</em>, please reach out. And don’t forget to check out the <a href="https://permapeople.org/">plant database</a>, and create a list of your favourite candidates for your garden.</p>

<ul>
  <li>Simon 🌱✌️</li>
</ul>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://permapeople.org/blog/2020/12/02/designing-and-optimizing-a-recipe-for-distributed-food-production.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25441679</guid>
            <pubDate>Wed, 16 Dec 2020 12:16:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: ThinkType – Write and Search Notes at the Same Time]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25441662">thread link</a>) | @amadeuspagel
<br/>
December 16, 2020 | https://thinktype.app/resubmit | <a href="https://web.archive.org/web/*/https://thinktype.app/resubmit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://thinktype.app/resubmit</link>
            <guid isPermaLink="false">hacker-news-small-sites-25441662</guid>
            <pubDate>Wed, 16 Dec 2020 12:13:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made a crate for creating interactive chord diagrams in Rust]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25440590">thread link</a>) | @DataCrayon
<br/>
December 16, 2020 | https://datacrayon.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<pre>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]</pre>
</div></div>]]>
            </description>
            <link>https://datacrayon.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25440590</guid>
            <pubDate>Wed, 16 Dec 2020 09:31:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elderly patients 23% more likely to die if surgery is on the surgeon’s birthday]]>
            </title>
            <description>
<![CDATA[
Score 349 | Comments 204 (<a href="https://news.ycombinator.com/item?id=25440322">thread link</a>) | @whx23
<br/>
December 16, 2020 | https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5563" role="main"><div><div><div><p>A <a href="https://www.bmj.com/content/371/bmj.m4381" target="_blank" rel="noreferrer noopener">new study has found</a> that elderly patients who underwent emergency surgery on their surgeon’s birthday had significantly higher 30-day mortality rates than patients whose surgery took place on any other day of the year. <span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p><p>The 30-day mortality rate (defined as death within 30 days after surgery)&nbsp;for the “surgeon’s birthday” group was 6.9%. This was 23% higher than the 5.6% rate for the “other day” group.</p><p>The study, which appears today in the <em>British Medical Journal</em> (<a href="https://www.bmj.com/" target="_blank" rel="noreferrer noopener">BMJ</a>),&nbsp;looked at 980,876 procedures performed in US hospitals by 47,489 surgeons.&nbsp;Of those procedures, 2,064 (0.2%) took place on a surgeon’s birthday.&nbsp;The patients were all Medicare beneficiaries aged 65 to 99. They had all undergone one of 17 common emergency surgical procedures between 2011 and 2014.</p><h2>Distractions during the most common emergency surgery types</h2><p>Examples of those 17 procedures included cardiovascular surgeries, hip and femur fracture, appendectomy, and small bowel resection. The study focused on&nbsp;emergency surgery, so as to&nbsp;minimize the potential selection bias. For example, surgeons might otherwise choose patients based on their illness severity, or patients might choose their surgeon.</p><p>As the authors write, “The effect size of surgeons’ birthday observed in our analysis (1.3 percentage point increase or a 23% increase in mortality), though substantial, is comparable to the impact of other events, including holidays (e.g., Christmas and New Year) and weekends.” <span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><p>In fact, the <a href="https://amzn.to/3m5rimG" target="_blank" rel="noreferrer noopener">history of surgery</a> has often demonstrated that external factors can influence surgical outcomes. The authors refer to a 2014 study showing that <a href="https://pubmed.ncbi.nlm.nih.gov/23345314/" target="_blank" rel="noreferrer noopener">patients admitted to Scottish emergency rooms on&nbsp;public holidays had a 27% increase</a> in 30-day mortality.&nbsp;Other research has found, for example,&nbsp;that doctors are more likely to <a href="https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/1910546" target="_blank" rel="noreferrer noopener">prescribe antibiotics</a> and <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2749268" target="_blank" rel="noreferrer noopener">opioids</a> — and <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2733171" target="_blank" rel="noreferrer noopener">less likely to order&nbsp;cancer screening tests</a> — as the workday progresses. This is most likely because the “cumulative cognitive demand” of such decisions gradually takes its toll.&nbsp;</p><p>Research on judges has yielded similar results. It has found, for example, that external factors as diverse as outdoor temperatures and sports results can influence judges’ decisions.&nbsp;</p><h2>A natural experiment: ER surgery on the doctor’s birthday</h2><p>But the authors say the “natural experiment” in the present study is more revealing than, for example, holiday-related mortality rates. That is because “those events not only affect physicians’ performance but also influence patients’ decision to seek care (i.e., patients seeking care on these special days might be sicker than those seeking care on other days), as well as hospital staffing.” Unless, of course, the patients know their surgeon’s birthday, which is unlikely (though that may change if this study becomes widely known).&nbsp;</p><p>The 1.3% effect size was the result after a very through series of controls. These included, for example, excluding those surgeons with the highest patient mortality rates. Other controls included assigning a random “pseudo-birthday” to surgeons to see whether the results still held up, or checking whether the surgeon did an above-average number of procedures on their birthday. <span data-ez-name="psychnewsdaily_com-box-4"></span></p><p>Likewise, the researchers controlled for “milestone” birthdays (such as 40 or 50). They also controlled for whether a birthday fell on a Friday, which might make after-work birthday festivities more likely.&nbsp;Their findings also held up when the analysis was restricted to procedures with the highest average mortality, or to only the most ill patients.&nbsp;In fact, without these adjustments, the 30-day mortality rate difference between the birthday and non-birthday groups (the unadjusted rate) was even higher (7.0% vs. 5.6%, or a 1.4% difference).</p><h2><strong>Why</strong> does emergency surgery suffer on surgeon’s birthday?</h2><p>The authors propose a few potential explanations for this “birthday effect.”&nbsp;</p><p>These include hurrying through an emergency surgery to be on time for after-work birthday events; <a href="https://www.psychnewsdaily.com/study-finds-users-not-notifications-initiate-89-of-smartphone-interactions/" target="_blank" rel="noreferrer noopener">distracting</a> birthday-related phone calls or text messages; more conversations with well-wishing staff members; and a decreased likelihood to go back to the hospital that evening if a patient’s condition deteriorates.</p><p>They also found that some surgeons did not work on their birthdays. While 2,144 surgeons in this study performed procedures one day before their birthday, and 2,027 did so one day after their birthday, only 1,805 surgeons carried out procedures on their actual birthday. This does not affect the results of the study’s analyses. But it does suggest “that birthdays are an important enough factor for some surgeons to choose not to operate on that day, which supports the credibility of our assumption that a birthday could be a distracting factor for those surgeons who choose to operate on that day,” the authors write.&nbsp;</p><h2><strong>Limitations</strong> <strong>and future directions</strong></h2><p>The researchers emphasized that this study focused on common procedures, and on older Medicare patients. This means that the findings may not apply to other types of patients, or to other surgical procedures.</p><p>Still, the authors write, these results may lead to “additional support for surgeons who have potentially distracting events,” such as birthdays, “to make sure that patients receive high quality surgical care regardless of when undergo surgery.”</p><hr><p><strong>Study: </strong>“<a href="https://dx.doi.org/10.1136/bmj.m4381" target="_blank" rel="noreferrer noopener">Patient mortality after surgery on the surgeon’s birthday: observational study</a>“<br><strong>Authors:</strong> Hirotaka Kato, Anupam B. Jena, and Yusuke Tsugawa<br><strong>Published in:</strong> <a href="https://www.bmj.com/" target="_blank" rel="noreferrer noopener"><em>The BMJ</em></a><br><strong>Publication date: </strong>December 10, 2020<br><strong>DOI:</strong> <a href="https://dx.doi.org/10.1136/bmj.m4381" target="_blank" rel="noreferrer noopener">https://dx.doi.org/10.1136/bmj.m4381</a><br><strong>Photo: </strong>by&nbsp;<a href="https://pixabay.com/users/theshiv76-1022681/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=766166">Jason Shivers</a>&nbsp;from&nbsp;<a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=766166">Pixabay</a>&nbsp;</p><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p></div></div></div></article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25440322</guid>
            <pubDate>Wed, 16 Dec 2020 08:38:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CVE-2020-25695 Privilege Escalation in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25440088">thread link</a>) | @arkadiyt
<br/>
December 15, 2020 | https://staaldraad.github.io/post/2020-12-15-cve-2020-25695-postgresql-privesc/ | <a href="https://web.archive.org/web/*/https://staaldraad.github.io/post/2020-12-15-cve-2020-25695-postgresql-privesc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<article>
  
  <div><p>It has been quite a year, I hope everyone is well and staying safe. This is my first and probably only post for the year, and covers a fun privilege escalation vulnerability I found in Postgresql. This affects all supported versions of Postgresql going back to 9.5, it is likely it affects most earlier versions as well.</p>
<p>The vulnerability is similar to a time-of-check to time-of-use (TOCTOU) issue, however in this case it relates to state not being fully cleared/reset before exiting a security restricted operation.</p>
<p>Tested versions:</p>
<ul>
<li>13.0 – PostgreSQL 13.0 (Debian 13.0-1.pgdg100+1)</li>
<li>12.4 – PostgreSQL 12.4 (Debian 12.4-1.pgdg100+1)</li>
<li>12.3 – PostgreSQL 12.3 (Debian 12.3-1.pgdg100+1)</li>
<li>11.9 – PostgreSQL 11.9 (Debian 11.9-1.pgdg90+1)</li>
</ul>
<p>Release notes and updates: <a href="https://www.postgresql.org/about/news/postgresql-131-125-1110-1015-9620-and-9524-released-2111/">https://www.postgresql.org/</a></p>

<p>I set out with the goal of finding a vulnerability which would allow an unprivileged user to elevate their privileges to that of <code>superuser</code>.</p>
<p>There are some legitimate ways to provide users with elevated persmissions in Postgresql, without giving those users full <code>superuser</code> rights. This is typically done using <code>SECURITY DEFINER</code> functions.</p>
<p>When misconfigured, a badly written <code>SECURITY DEFINER</code> function and controllable <code>search_path</code> can be used to elevate privileges (<a href="https://www.cybertec-postgresql.com/en/abusing-security-definer-functions/">Cybertec Blog</a>).</p>
<p>This functionality is explicitely called out in the Postgresql documentation in <a href="https://www.postgresql.org/docs/current/sql-createfunction.html#SQL-CREATEFUNCTION-SECURITY">how to safely write security definer functions</a>.</p>
<blockquote>
<p>Because a SECURITY DEFINER function is executed with the privileges of the user that owns it, care is needed to ensure that the function cannot be misused.</p>
</blockquote>
<p>Even though this is legitimate functionality, it still provided a good starting point, as it gave me an idea of where I should looking in the source code. Maybe there would be a way to use <code>SECURITY DEFINER</code> in another context.</p>

<p>I started off by looking into security definer functions and other locations where Postgresql switches user permissions, I noticed mention of <code>security-restricted operations</code>. This immediately triggered that spidey sense that there might be something to find in these. Out came grep and a search for locations where <code>security-restricted operations</code> are mentioned.</p>
<p>Two places where this term occurs are <code>src/backend/commands/analyze.c</code> (<code>ANALYZE</code> directive) and <code>src/backend/commands/vacuum.c</code> (<code>VACUUM</code> directive), with the same code comment in both:</p>
<pre><code>/*
* Switch to the table owner's userid, so that any index functions are run
* as that user.  Also lock down security-restricted operations and
* arrange to make GUC variable changes local to this command.
*/
</code></pre><p>This leads into the next section;</p>
<h2 id="indexes-and-functions">Indexes and Functions</h2>
<p>This seemed interesting, I didn’t know that an index could run functions. Now it was time to first figure out how to make indexes run user functions.</p>
<p>Turns out this is pretty easy to do, the <a href="https://www.postgresql.org/docs/current/sql-createindex.html">documentation</a> has a bunch of examples of indexes calling functions (even if these aren’t user defined, it shows the syntax on how to structure the sql query.)</p>
<p>For example:</p>
<div><pre><code data-lang="sql"><span>CREATE</span> <span>INDEX</span> <span>ON</span> films ((<span>lower</span>(title)));
</code></pre></div><p>In this, an index is created on the <code>films</code> table, using the <code>title</code> column, cast to lowercase using the <code>lower</code> function. It should be pretty straight forward to simply supply a user created function instead of <code>lower</code>.</p>
<p>I’m skipping a few debugging steps I had to go through, but it boiled down to reading the error messages thrown when trying to use the function. The main thing to note at this point is that an <code>INDEX</code> requires an <code>IMMUTABLE</code> function, meaning the function will always return the same result for a given input. This makes sense, an <code>INDEX</code> is trying to optimise on uniqueness.</p>
<div><pre><code data-lang="sql"><span>CREATE</span> <span>FUNCTION</span> sfunc(integer) 
  <span>RETURNS</span> integer
  <span>LANGUAGE</span> <span>sql</span> <span>IMMUTABLE</span> <span>AS</span>
  <span>'SELECT $1'</span>;
</code></pre></div><p>And now create a table, and an index on that table:</p>
<div><pre><code data-lang="sql"><span>CREATE</span> <span>TABLE</span> blah (a int, b int);
<span>INSERT</span> <span>INTO</span> blah <span>VALUES</span> (<span>1</span>,<span>1</span>);

<span>CREATE</span> <span>INDEX</span> indy <span>ON</span> blah (sfunc(a));
</code></pre></div><p>This isn’t really helpful, I wanted a function that does something more useful, like inserting values into another table. The reason being that I wanted to retrieve the user which was executing to index function. The train of thought I had at this point was:</p>
<pre><code>create index as unpriv --&gt; privileged user executes ANALYZE/VACUUM --&gt; index function executes as privileged user 
</code></pre><p>In this scenario I was planning on using <code>SECURITY INVOKER</code> to trick Postgres into executing the function as the privileged user.</p>
<div><pre><code data-lang="sql"><span>-- create the table to insert the user into
</span><span></span><span>CREATE</span> <span>TABLE</span> t0 (s varchar);

<span>-- create the security invoker function
</span><span></span><span>CREATE</span> <span>FUNCTION</span> sfunc(integer) <span>RETURNS</span> integer
   <span>LANGUAGE</span> <span>sql</span> 
   <span>SECURITY</span> <span>INVOKER</span> <span>AS</span>
   <span>'INSERT INTO t0 VALUES (current_user); SELECT $1'</span>;
</code></pre></div><p>As mentioned earlier, the index requires an <code>IMMUTABLE</code> function. So trying to use the function in an index, would throw an error:</p>
<div><pre><code data-lang="sql">tmp<span>=#</span> <span>CREATE</span> <span>INDEX</span> indy <span>ON</span> blah (sfunc(a));
ERROR:  functions <span>in</span> <span>index</span> expression must be marked <span>IMMUTABLE</span>
</code></pre></div><p>This seemed like a dead-end. Then it occurred to me that functions can be recreated/redefined. As long as you use <code>CREATE OR REPLACE FUNCTION</code>, any existing function will be overridden. Maybe the <code>INDEX</code> doesn’t check if an assigned function has become mutable since it was initially defined (spoiler, it doesn’t!).</p>
<div><pre><code data-lang="sql"><span>CREATE</span> <span>FUNCTION</span> sfunc(integer) 
  <span>RETURNS</span> integer
  <span>LANGUAGE</span> <span>sql</span> <span>IMMUTABLE</span> <span>AS</span>
  <span>'SELECT $1'</span>;

<span>CREATE</span> <span>INDEX</span> indy <span>ON</span> blah (sfunc(a));

<span>CREATE</span> <span>OR</span> <span>REPLACE</span> <span>FUNCTION</span> sfunc(integer) <span>RETURNS</span> integer
   <span>LANGUAGE</span> <span>sql</span> 
   <span>SECURITY</span> <span>INVOKER</span> <span>AS</span>
<span>'INSERT INTO t0 VALUES (current_user); SELECT $1'</span>;
</code></pre></div><p>Now when the index is run the <code>current_user</code> will be inserted into table <code>t0</code>. To check this, I switched to a privileged user (postgres) and executed the <code>ANALYZE</code> function.</p>
<div><pre><code data-lang="sql">tmp<span>=#</span> <span>SELECT</span> <span>*</span> <span>FROM</span> t0;
 s
<span>---
</span><span></span>(<span>0</span> <span>rows</span>)

tmp<span>=#</span> <span>ANALYZE</span>;
<span>ANALYZE</span>
tmp<span>=#</span> <span>SELECT</span> <span>*</span> <span>FROM</span> t0;
  s
<span>-----
</span><span></span> foo
(<span>1</span> <span>row</span>)

tmp<span>=#</span>

</code></pre></div><p>The triggering of the function worked, but we inserted the user <code>foo</code> instead of <code>postgres</code>. This means the <code>SECURITY INVOKER</code> didn’t have an effect. Looking back at the source-code comment from earlier, we can recall that a switch is done to the owner’s uid in security-restricted functions. Yay, we proven that this functionality works, sure we found a nice bypass for the <code>IMMUTABLE</code> check, but this isn’t really a security or world ender.</p>
<h2 id="ill-get-to-it-later---deferred">I’ll get to it later - deferred</h2>
<p>Diving back into the source-code, I had a look at how the security-restricted operation was entered, and subsequently exited.</p>
<p>In the <code>vacuum.c</code> file, there were some interesting comments. Maybe you can spot the bit that caught my eye immediately.</p>
<div><pre><code data-lang="c">
<span>/*
</span><span>  * Switch to the table owner's userid, so that any index functions are run
</span><span>  * as that user.  Also lock down security-restricted operations and
</span><span>  * arrange to make GUC variable changes local to this command. (This is
</span><span>  * unnecessary, but harmless, for lazy VACUUM.)
</span><span>  */</span>
GetUserIdAndSecContext(<span>&amp;</span>save_userid, <span>&amp;</span>save_sec_context);
SetUserIdAndSecContext(onerel<span>-&gt;</span>rd_rel<span>-&gt;</span>relowner,
                                            save_sec_context <span>|</span> SECURITY_RESTRICTED_OPERATION);
save_nestlevel <span>=</span> NewGUCNestLevel();

<span>// DO LOTS OF WORK
</span><span>// &lt;--- SNIP ---&gt;
</span><span></span>
<span>/* Restore userid and security context */</span>
SetUserIdAndSecContext(save_userid, save_sec_context);

<span>/* all done with this class, but hold lock until commit */</span>
<span>if</span> (onerel)
        relation_close(onerel, NoLock);

<span>/*
</span><span>  * Complete the transaction and free all temporary memory used.
</span><span>  */</span>
PopActiveSnapshot();
CommitTransactionCommand();
</code></pre></div><p>See that last comment and function calls? The <code>CommitTransactionCommand()</code> is executed after the <code>SetUserAndSecContext</code>, which resets the context userid to that of the executing user. In SQL you have transactions and a transaction isn’t final until the commit happens. This gives you room to execute some SQL, have part of it fail and then seamlessly rollback any changes to the state before the transaction was entered. The fact that in this code the user is restored before the transaction is committed made me wonder if it would be possible to sneak in some additional commands to execute before the commit is done.</p>
<p>Next ensued a long time of reading documentation and looking for ways to delay execution of SQL commands. I finally happened on <code>INITIALLY DEFERRED</code>, which held the key to unlocking this puzzle. This was part of the documentation for <a href="https://www.postgresql.org/docs/current/sql-createtrigger.html">TRIGGERS</a> which further set the spidey senses tingling.</p>
<p>What is <code>INITIALLY DEFERRED</code>?</p>
<blockquote>
<p>INITIALLY DEFERRED
The default timing of the trigger. See the CREATE TABLE documentation for details of these constraint options. This can only be specified for constraint triggers.</p>
</blockquote>
<p>Going into the <code>CREATE TABLE</code> reference you find:</p>
<blockquote>
<p>If a constraint is deferrable, this clause specifies the default time to check the constraint. If the constraint is INITIALLY IMMEDIATE, it is checked after each statement. This is the default. If the constraint is INITIALLY DEFERRED, it is checked only at the end of the transaction. The constraint check time can be altered with the SET CONSTRAINTS command.</p>
</blockquote>
<p>That sounds exactly like what we want! An initially deferred constraint is only checked at the “<em>end of the transaction</em>”. This indicated that it would happen just before the <code>commit</code> but after the security context switch.</p>
<h2 id="gymnastics">Gymnastics</h2>
<p>The next trick was to figure out how to use the constraint trigger and where this should be placed so that it triggers at the right moment.</p>
<p>Firstly, a <code>CONSTRAINT TRIGGER</code> needs a function to execute. This will be our “final” step, and should thus be executing in the privileged user context. Therefore we should insert our privileged actions into this function. The other trick is that the <code>CONSTRAINT TRIGGER</code> needs to be triggered somehow. Fortunately we’ve already got the initial bits ready. Since the index calls our custom function, which inserts into table <code>t0</code>, we have an action which will cause a constraint trigger to execute.</p>
<pre><code>Index runs --&gt; sfunc inserts into t0 --&gt; constraint trigger fires --&gt; strig function is executed
</code></pre><p>This leaves us with the following SQL:</p>
<div><pre><code data-lang="sql">
<span>CREATE</span> <span>TABLE</span> t1 (s varchar);

<span>-- create a function for inserting current user into another table
</span><span></span>
<span>CREATE</span> <span>OR</span> <span>REPLACE</span> <span>FUNCTION</span> snfunc(integer) <span>RETURNS</span> integer
   <span>LANGUAGE</span> <span>sql</span> 
   <span>SECU…</span></code></pre></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://staaldraad.github.io/post/2020-12-15-cve-2020-25695-postgresql-privesc/">https://staaldraad.github.io/post/2020-12-15-cve-2020-25695-postgresql-privesc/</a></em></p>]]>
            </description>
            <link>https://staaldraad.github.io/post/2020-12-15-cve-2020-25695-postgresql-privesc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25440088</guid>
            <pubDate>Wed, 16 Dec 2020 07:49:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote login is a lot like astral projection]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25439946">thread link</a>) | @samim
<br/>
December 15, 2020 | https://samim.io/p/2020-01-23-remote-login-is-a-lot-like-astral-projection/ | <a href="https://web.archive.org/web/*/https://samim.io/p/2020-01-23-remote-login-is-a-lot-like-astral-projection/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <div>
        <p><b>"Remote login is a lot like astral projection."</b><br></p><div><figure>
    <img src="https://samim.io/static/upload/EOf3B6BW4AAqnZA.jpeg" alt="Remote login is a lot like astral projection">
        
</figure></div><p><a href="https://samim.io/tag/Art">#Art</a> <a href="https://samim.io/tag/Technology">#Technology</a> <a href="https://samim.io/tag/Magic">#Magic</a><br></p>
      </div>
    </div></div>]]>
            </description>
            <link>https://samim.io/p/2020-01-23-remote-login-is-a-lot-like-astral-projection/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25439946</guid>
            <pubDate>Wed, 16 Dec 2020 07:21:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Research in Programming Languages (2012)]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25439629">thread link</a>) | @swyx
<br/>
December 15, 2020 | http://tagide.com/blog/academia/research-in-programming-languages/ | <a href="https://web.archive.org/web/*/http://tagide.com/blog/academia/research-in-programming-languages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p><strong>Is there still research to be done in Programming Languages?</strong> This essay touches both on the topic of programming languages and on the nature of research work. I am mostly concerned in analyzing this question in the context of Academia, i.e. within the expectations of academic programs and research funding agencies that support research work in the STEM disciplines (<span>Science, Technology, Engineering, and Mathematics</span>). This is not the only possible perspective, but it is the one I am taking here.</p>
<p><span id="more-416"></span>PLs are dear to my heart, and a considerable chunk of my career was made in that area. As a designer, there is something fundamentally interesting in designing a language of any kind. It’s even more interesting and gratifying when people actually start exercising those languages to create non-trivial software systems. As a user, I love to use programming languages that I haven’t used before, even when the languages in question make me curse every other line.</p>
<p>But the truth of the matter is that ever since I finished <a href="ftp://ftp.ccs.neu.edu/pub/people/crista/publications/thesis/index.html">my Ph.D.</a> in the late 90s, and especially since I joined the ranks of Academia, I have been having a hard time convincing myself that research in PLs is a worthy endeavor. I feel really bad about my rational arguments against it, though. Hence this essay. Perhaps by the time I am done with it I will have come to terms with this dilemma.</p>
<p>Back in the 50s, 60s and 70s, programming languages were a BigDeal, with large investments, upfront planning, and big drama on standardization committees (Ada was the epitome of that model). Things have changed dramatically during the 80s. Since the 90s, a considerable percentage of new languages that ended up being very popular were designed by lone programmers, some of them kids with no research inclination, some as a side hobby, and without any grand goal other than either making some routine activities easier or for plain hacking fun. Examples:</p>
<ul>
<li>PHP, by Rasmus Lerdorf circa 1994, “originally used for tracking visits to his online resume, he named the suite of scripts ‘Personal Home Page Tools,’ more frequently referenced as ‘PHP Tools.’ ” [<a href="http://www.php.net/manual/en/history.php.php">1</a>] PHP is a marvel of how a horrible language can become the foundation of large numbers of applications… for a second time! <a href="http://www.dreamsongs.com/RiseOfWorseIsBetter.html">Worse is Better</a> redux. According one <a href="http://langpop.com/">informal but interesting survey</a>, PHP is now the 4th most popular programming language out there, losing only to C, Java and C++.</li>
<li>JavaScript, by Brendan Eich circa 1995, “Plus, I had to be done in ten days or something worse than JS would have happened.” [<a href="http://www.jwz.org/blog/2010/10/every-day-i-learn-something-new-and-stupid/#comment-1021">2</a>] According to that same survey, JavaScript is the 5th most popular language, and I suspect it is climbing up that rank really fast. It may be #1 by now.</li>
<li>Python, by Guido van Rossum circa 1990, “I was looking for a ‘hobby’ programming project that would keep me occupied during the week around Christmas.” [<a href="http://www.python.org/doc/essays/foreword/">3</a>] Python comes at #6, and its strong adoption by scientific computing communities is well know.</li>
<li>Ruby, by Yukihiro “Matz” Matsumoto circa 1994, “I wanted a scripting language that was more powerful than Perl, and more object-oriented than Python. That’s why I decided to design my own language.” [<a href="http://linuxdevcenter.com/pub/a/linux/2001/11/29/ruby.html">4</a>] At #10 in that survey.</li>
</ul>
<p>Compare this mindset with the context in which the the older well-known programming languages emerged:</p>
<ul>
<li>Fortran, 50s, originally developed by IBM as part of their core business in computing machines.</li>
<li>Cobol, late 50s, designed by a large committee from the onset, sponsored by the DoD.</li>
<li>Lisp, late 50s, main project occupying 2 professors at MIT and their students, with the grand goal of producing an algebraic list processing language for artificial intelligence work, also funded by the DoD.</li>
<li>C, early 70s, part of the large investment that Bell Labs was doing in the development of Unix.</li>
<li>Smalltalk, early 70s, part of a large investment that Xerox did in “inventing the future” of computers.</li>
</ul>
<p>Back then, developing a language processor was, indeed, a very big deal. Computers were slow, didn’t have a lot of memory, the language processors had to be written in low-level assembly languages… it wasn’t something someone would do in their rooms as a hobby, to put it mildly. Since the 90s, however, with the emergence of PCs and of decent low-level languages like C, developing a language processor is no longer a BigDeal. Hence, languages like PHP and JavaScript.</p>
<p>There is a lot of fun in designing new languages, but this fun is not an exclusive right of researchers with, or working towards, Ph.Ds. Given all the knowledge about programming languages these days, anyone can do it. And many do. And here’s the first itchy point: <em>there appears to be no correlation between the success of a programming language and its emergence in the form of someone’s doctoral or post-doctoral work. </em>This bothers me a lot, as an academic. It appears that deep thoughts, consistency, rigor and all other things we value as scientists aren’t that important for mass adoption of programming languages. But then again, <a href="http://www.dreamsongs.com/RiseOfWorseIsBetter.html">I’m not the first to say it</a>. It’s just that this phenomenon is hard to digest, and if you really grasp it, it has tremendous consequences. If people (the potential users) don’t care about conceptual consistency, why do we keep on trying to achieve that?</p>
<p>To be fair, some of those languages designed in the 90s as side projects, as they became important, eventually became more rigorous and consistent, and attracted a fair amount of academic attention and industry investment. For example, the Netscape JavaScript hacks quickly fell on Guy Steele’s lap resulting in the <a href="http://en.wikipedia.org/wiki/ECMAScript">ECMAScript specification</a>. Python was never a hack even if it started as a Christmas hobby. Ruby is a fun language and quite elegant from the beginning. PHP… well… it’s fun for possibly the wrong reasons. But the core of the matter is that “the right thing” was not the goal. It seems that <span><em>a reliable implementation of a language that addresses an important practical need</em></span> is the key for the popularity of a programming language. But being opportunistic isn’t what research is supposed to be about… (or is it?)</p>
<p>Also to be fair, not all languages designed in the 90s and later started as side projects. For example, Java was a relatively large investment by Sun Microsystems. So was .NET later by Microsoft.</p>
<p>And, finally, all of these new languages, even when created over a week as someone’s pet project, sit on the shoulders of all things that existed before. This leads me to the second itch: <em>one striking commonality in all modern programming languages, especially the popular ones, is how little innovation there is in them</em>! Without exception, including the languages developed in research groups, they all feel like mashups of concepts that already existed in programming languages in 1979, wrapped up in their own idiosyncratic syntax. (I lied: exceptions go to aspects and monads both of which came in the 90s)</p>
<p><a href="http://tagide.com/blog/?attachment_id=544" rel="attachment wp-att-544"><img title="PLs" src="http://tagide.com/blog/wp-content/uploads/2011/09/PLs-300x225.jpg" alt="" width="300" height="225"></a>So one pertinent question is: given that not much seems to have emerged since 1979 (that’s 30+ years!), is there still anything to <em>innovate</em> in programming languages? Or have we reached the asymptotic plateau of innovation in this area?</p>
<p>I need to make an important detour here on the nature of research.</p>
<h3>&lt;Begin Detour&gt;</h3>
<p>Perhaps I’m completely off; perhaps <em>producing innovative new software</em> <em>is not a goal of [STEM] research</em>. Under this approach, any software work is dismissed from STEM pursuits, unless it is necessary for some specific goal — like if you want to study some far-off galaxy and you need an IT infrastructure to collect the data and make simulations (S for Science); or if you need some glue code for piecing existing systems together (T for Technology); or if you need to improve the performance of something that already exists (E for Engineering); or if you are a working on some Mathematical model of computation and want to make your ideas come to life in the form of a language (M for Mathematics). This is an extreme submissive view of software systems, one that places software in the back sit of STEM and that denies the existence of value in research in/by software itself. If we want to lead something on our own, let’s just… do empirical studies of technology or become biologists/physicists/chemists/mathematicians or make existing things perform better or do theoretical/statistical models of universes that already exist or that are created by others. Right?</p>
<p>I confess I have a dysfunctional relationship with this idea. Personally, I can’t be happy without creating software things, but I have been able to make my scientist-self function both as a cold-minded analyst and, at times, as an expert passenger in someone else’s research project. The design work, for me, has moved to sabbatical time, evenings and weekends; I don’t publish it [much] other than the code itself and some informal descriptions. And yet, I loathe this situation.</p>
<p>I loathe it because it’s is clear to me that software systems are something very, <em>very</em> special. Software revolutionized everything in unexpected ways, including the methods and practices that our esteemed colleagues in the “hard” sciences hold near and dear for a very long time. The evolution of information technology in the past 60 years has been _way_ off from what our colleagues thought they needed. Over and over again, software systems have been created that weren’t part of any scientific project, as such, and that ended up playing a central role in Science. Instead of trying to mimic our colleagues’ traditional practices, “computer scientists” ought to be showing the way to a new kind of science — maybe <em>that </em><a href="http://www.wolframscience.com/nksonline/page-1?firstview=1">new kind of science</a> or <a href="http://www.amazon.com/Sciences-Artificial-Herbert-Simon/dp/0262691914">that one</a> or maybe something else. I dare to suggest that the something else is related to the design of things that have software in them. It should not be called Science. It is a bit like Engineering, but it’s not it either because we’re not dealing [just] with physical things. Technology doesn’t cut it either. It needs a new name, something that denotes “the design of things with software in them.” I will call it Design for short, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://tagide.com/blog/academia/research-in-programming-languages/">http://tagide.com/blog/academia/research-in-programming-languages/</a></em></p>]]>
            </description>
            <link>http://tagide.com/blog/academia/research-in-programming-languages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25439629</guid>
            <pubDate>Wed, 16 Dec 2020 06:10:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shell Competency and Prominent Anti-Patterns]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25439561">thread link</a>) | @jkoelndorfer
<br/>
December 15, 2020 | https://www.johnk.io/blog/shell-competency-and-prominent-anti-patterns.html | <a href="https://web.archive.org/web/*/https://www.johnk.io/blog/shell-competency-and-prominent-anti-patterns.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content-pane">
  <div>
    <p>Throughout my career, I’ve crossed paths with quite a few developers whose
chief expertise has run the gamut of programming languages: C, Python,
Java, Ruby, JavaScript, and so on. The programming language(s) in which you
build expertise undoubtedly influence the way you think about problems and
what solutions you’re likely to reach for, and they do so in a big way.
The common thread I’ve noticed, though, is that developers on average lack
competency in their operating system shell. That lack of competency often
manifests as an <em>aversion</em> to the shell.</p>
<p>You may see that a developer prefers to use point-and-click interfaces
when a shell can get the job done more quickly and with exponentially
more flexibility. You might find that they write scripts in their native
language rather than struggle with the intricacies of <code>bash</code>. At one of
my previous workplaces, I uncovered a 30 line Ruby script that could
have been replaced by one pipeline in <code>bash</code>. Yes, a single pipeline.</p>
<p>This shell aversion is a real shame, because the shell can be a very powerful
tool in one’s technical arsenal. The shell is <em>the</em> textual interface to your
computer.  Regardless of familiarity, every developer will be forced to use a
shell in some ongoing capacity. That use may be to invoke <code>git</code>, grab a quick
snapshot of what is happening in the cloud with <code>aws</code>, or start a container
with <code>docker</code> or <code>docker-compose</code>. The uses are there, and they are many.</p>
<p>Because my experience has largely been infrastructure focused, the shell is more
often a sensible tool for me to reach for than it is for other developers.
Consequently, I learned many hard lessons about shell, best practices,
patterns, and anti-patterns.</p>
<p>And that brings us to the topic at hand today. A friend sent me a blog post
claiming to implement a “safe” template for bash. Just insert your shell
into the provided blank. It’s a fairly hefty template too, weighing in at
just under 100 lines.</p>
<p>Complements of <a href="https://betterdev.blog/minimal-safe-bash-script-template/">Better Dev.blog</a>,
the template follows (note: this is the template as originally published, before any edits):</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span><span>37
</span><span>38
</span><span>39
</span><span>40
</span><span>41
</span><span>42
</span><span>43
</span><span>44
</span><span>45
</span><span>46
</span><span>47
</span><span>48
</span><span>49
</span><span>50
</span><span>51
</span><span>52
</span><span>53
</span><span>54
</span><span>55
</span><span>56
</span><span>57
</span><span>58
</span><span>59
</span><span>60
</span><span>61
</span><span>62
</span><span>63
</span><span>64
</span><span>65
</span><span>66
</span><span>67
</span><span>68
</span><span>69
</span><span>70
</span><span>71
</span><span>72
</span><span>73
</span><span>74
</span><span>75
</span><span>76
</span><span>77
</span><span>78
</span><span>79
</span><span>80
</span><span>81
</span><span>82
</span><span>83
</span><span>84
</span><span>85
</span><span>86
</span><span>87
</span><span>88
</span><span>89
</span><span>90
</span><span>91
</span><span>92
</span><span>93
</span><span>94
</span><span>95
</span><span>96
</span><span>97
</span><span>98
</span><span>99
</span></code></pre></td>
<td>
<pre><code data-lang="bash"><span>#!/usr/bin/env bash
</span><span></span>
<span>set</span> -Eeuo pipefail

<span>cd</span> <span>"</span><span>$(</span>dirname <span>"</span><span>${</span><span>BASH_SOURCE</span><span>[0]</span><span>}</span><span>"</span><span>)</span><span>"</span> &gt;/dev/null 2&gt;<span>&amp;</span><span>1</span>

<span>trap</span> cleanup SIGINT SIGTERM ERR EXIT

usage<span>()</span> <span>{</span>
  cat <span>&lt;&lt;EOF
</span><span>Usage: $(basename "$0") [-h] [-v] [-f] -p param_value arg1 [arg2...]
</span><span>
</span><span>Script description here.
</span><span>
</span><span>Available options:
</span><span>
</span><span>-h, --help      Print this help and exit
</span><span>-v, --verbose   Print script debug info
</span><span>-f, --flag      Some flag description
</span><span>-p, --param     Some param description
</span><span>EOF</span>
  <span>exit</span>
<span>}</span>

cleanup<span>()</span> <span>{</span>
  <span>trap</span> - SIGINT SIGTERM ERR EXIT
  <span># script cleanup here</span>
<span>}</span>

setup_colors<span>()</span> <span>{</span>
  <span>if</span> <span>[[</span> -t <span>2</span> <span>]]</span> <span>&amp;&amp;</span> <span>[[</span> -z <span>"</span><span>${</span><span>NO_COLOR</span><span>-</span><span>}</span><span>"</span> <span>]]</span> <span>&amp;&amp;</span> <span>[[</span> <span>"</span><span>${</span><span>TERM</span><span>-</span><span>}</span><span>"</span> !<span>=</span> <span>"dumb"</span> <span>]]</span><span>;</span> <span>then</span>
    <span>NOCOLOR</span><span>=</span><span>'\033[0m'</span> <span>RED</span><span>=</span><span>'\033[0;31m'</span> <span>GREEN</span><span>=</span><span>'\033[0;32m'</span> <span>ORANGE</span><span>=</span><span>'\033[0;33m'</span> <span>BLUE</span><span>=</span><span>'\033[0;34m'</span> <span>PURPLE</span><span>=</span><span>'\033[0;35m'</span> <span>CYAN</span><span>=</span><span>'\033[0;36m'</span> <span>YELLOW</span><span>=</span><span>'\033[1;33m'</span>
  <span>else</span>
    <span>NOCOLOR</span><span>=</span><span>''</span> <span>RED</span><span>=</span><span>''</span> <span>GREEN</span><span>=</span><span>''</span> <span>ORANGE</span><span>=</span><span>''</span> <span>BLUE</span><span>=</span><span>''</span> <span>PURPLE</span><span>=</span><span>''</span> <span>CYAN</span><span>=</span><span>''</span> <span>YELLOW</span><span>=</span><span>''</span>
  <span>fi</span>
<span>}</span>

msg<span>()</span> <span>{</span>
  <span>echo</span> &gt;<span>&amp;</span><span>2</span> -e <span>"</span><span>${</span><span>1</span><span>-</span><span>}</span><span>"</span>
<span>}</span>

die<span>()</span> <span>{</span>
  <span>local</span> <span>msg</span><span>=</span><span>$1</span>
  <span>local</span> <span>code</span><span>=</span><span>${</span><span>2</span><span>-1</span><span>}</span> <span># default exit status 1</span>
  msg <span>"</span><span>$msg</span><span>"</span>
  <span>exit</span> <span>"</span><span>$code</span><span>"</span>
<span>}</span>

parse_params<span>()</span> <span>{</span>
  <span># default values of variables set from params</span>
  <span>flag</span><span>=</span><span>0</span>
  <span>param</span><span>=</span><span>''</span>

  <span>while</span> :<span>;</span> <span>do</span>
    <span>case</span> <span>"</span><span>${</span><span>1</span><span>-</span><span>}</span><span>"</span> in
    -h <span>|</span> --help<span>)</span>
      usage
      <span>;;</span>
    -v <span>|</span> --verbose<span>)</span>
      <span>set</span> -x
      <span>;;</span>
    --no-color<span>)</span>
      <span>NO_COLOR</span><span>=</span><span>1</span>
      <span>;;</span>
    -f <span>|</span> --flag<span>)</span> <span># example flag</span>
      <span>flag</span><span>=</span><span>1</span>
      <span>;;</span>
    -p <span>|</span> --param<span>)</span> <span># example named parameter</span>
      <span>param</span><span>=</span><span>"</span><span>${</span><span>2</span><span>-</span><span>}</span><span>"</span>
      <span>shift</span>
      <span>;;</span>
    -?*<span>)</span>
      die <span>"Unknown option: </span><span>$1</span><span>"</span>
      <span>;;</span>
    *<span>)</span>
      <span>break</span>
      <span>;;</span>
    <span>esac</span>
    <span>shift</span>
  <span>done</span>

  <span>args</span><span>=(</span><span>"</span><span>$@</span><span>"</span><span>)</span>

  <span># check required params and arguments</span>
  <span>[[</span> -z <span>"</span><span>${</span><span>param</span><span>-</span><span>}</span><span>"</span> <span>]]</span> <span>&amp;&amp;</span> die <span>"Missing required parameter: param"</span>
  <span>[[</span> <span>${#</span><span>args</span><span>[@]</span><span>}</span> -eq <span>0</span> <span>]]</span> <span>&amp;&amp;</span> die <span>"Missing script arguments"</span>

  <span>return</span> <span>0</span>
<span>}</span>

parse_params <span>"</span><span>$@</span><span>"</span>
setup_colors

<span># script logic here</span>

msg <span>"</span><span>${</span><span>RED</span><span>}</span><span>Read parameters:</span><span>${</span><span>NOCOLOR</span><span>}</span><span>"</span>
msg <span>"- flag: </span><span>${</span><span>flag</span><span>}</span><span>"</span>
msg <span>"- param: </span><span>${</span><span>param</span><span>}</span><span>"</span>
msg <span>"- arguments: </span><span>${</span><span>args</span><span>[*]-</span><span>}</span><span>"</span></code></pre></td></tr></tbody></table>
</div>
</div>
<p>I won’t sugar coat it. There’s a <em>lot</em> wrong with this. Let’s start
from the top.</p>
<h2 id="the-airing-of-grievances">The Airing of Grievances</h2>
<h3 id="the-shebang">The Shebang</h3>
<pre><code>#!/usr/bin/env bash
</code></pre><p>In case you don’t know what a shebang is for, here’s the quick
rundown: generally, when you execute a file on your computer, it’s a raw
binary that your operating system understands and can execute natively.
Being that scripts aren’t binaries, a file starting with <code>#!</code> signals
that instead, the command that follows should be executed and the the
file path passed to the interpreter.</p>
<p>In this case, we’ve got <code>env</code> searching a user’s <code>PATH</code> and executing
<code>bash</code>. Proponents of this method would tell you that it smooths over
file system hierarchy differences between machines. That’s technically
true.</p>
<p>But there’s a big problem here: if you’re at the level of experience
where you’re copy/pasting a template, your <code>bash</code> script isn’t
going to run on any machine other than the one you wrote it on (or
other very similar systems where <code>bash</code> can be found at the same
place). Using <code>#!/usr/bin/env bash</code> as the shebang gives the
<em>misleading</em> impression that you can just take the script and
run it somewhere else. And that’s just not true unless your script does
almost nothing of interest, or you actually understand the differences
between various platforms and can account for them when writing
your script. Furthermore, as the author, you probably originally
wrote the script with the system-wide <code>bash</code> in mind - so why
shouldn’t you just use that one?</p>
<p>“But John,” you say. “When I use <code>python</code> and <code>ruby</code> and other scripting
languages, I always use <code>#!/usr/bin/env</code>.” You sure do. The difference
between <code>bash</code> and those other languages is that those other ones
have tooling built around them, like <code>pyenv</code>, <code>poetry</code>, <code>rbenv</code> and <code>bundler</code>,
to facilitate running at a non-standard location with a particular
interpreter version and collection of libraries.</p>
<p>Don’t misrepresent your script from the outset. Just use <code>#!/bin/bash</code>
unless you can actually handle running in another environment.</p>
<h3 id="the-set-smorgasbord">The <code>set</code> Smorgasbord</h3>
<pre><code>set -Eeuo pipefail
</code></pre><p>Here we’ve got a smattering of shell options that are commonly used, but
are not universal. Here’s what <code>bash</code> has to say about those options,
with irrelevant options removed for brevity:</p>
<pre><code>$ help set
      -e  Exit immediately if a command exits with a non-zero status.
      -u  Treat unset variables as an error when substituting.
      -o option-name
          Set the variable corresponding to option-name:
              pipefail     the return value of a pipeline is the status of
                           the last command to exit with a non-zero status,
                           or zero if no command exited with a non-zero status
      -E  If set, the ERR trap is inherited by shell functions.
</code></pre><p>Right off the bat, <code>set -e</code> is a giant landmine. What happens when you pipe
some text to <code>grep</code> and nothing matches? Well, <code>grep</code> exits with a non-zero
status. Oops!</p>
<p>You can work around this with an <code>if</code> statement, or slapping an <code>|| true</code>
on the end, but it creates an entirely new problem. It’s still something you
have to remember to do everywhere, but only for very few binaries.</p>
<p><code>grep</code> is not the only binary that uses its exit code informatively.
<code>terraform plan -detailed-exitcode</code>, for example, will let you know whether
the plan showed a diff or not, or if there was an error during the plan
process. In this sort of case, you’d probably want to capture the exit code
with something like <code>rc="$?"</code> immediately after so that you can deal with it
as appropriate.</p>
<p><code>set -u</code> is fine, and I would recommend it generally. That said, you’ve got to
be responsible and initialize anything you’re going expecting to get via the
environment. If you don’t, your program will bomb with a canned error message
and exit code. Your users (or future you) will appreciate a reminder regarding
expected environment variables and what their values ought to be. For example,
you might write something like:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span></code></pre></td>
<td>
<pre><code data-lang="bash"><span>#!/bin/bash
</span><span></span>
<span>set</span> -uo pipefail

<span>MY_SECRET_PASSWORD</span><span>=</span><span>${</span><span>MY_SECRET_PASSWORD</span><span>:-</span><span>}</span>

<span>if</span> <span>[[</span> -z <span>"</span><span>$MY_SECRET_PASSWORD</span><span>"</span> <span>]]</span><span>;</span> <span>then</span>
    <span>echo</span> <span>'you forgot to provide your secret password'</span> &gt;<span>&amp;</span><span>2</span>
    <span>exit</span> <span>1</span>
<span>fi</span></code></pre></td></tr></tbody></table>
</div>
</div>
<p>I don’t take any exceptions with <code>set -o pipefail</code>.</p>
<p>The biggest problem I have with <code>set -E</code> is that its only usefulness comes
from catching unhandled errors in your script. Unhandled errors are
a deficiency with the script as written, and should be corrected. And, like
<code>set -e</code>, you run into the same sort of problem where executables
might use the exit code to communicate some information that is not
necessarily a fatal error.</p>
<h3 id="an-immediate-directory-change">An Immediate Directory Change</h3>
<p>On line 5, before any script logic has been executed, this template will
change the current directory:</p>
<pre><code>cd "$(dirname "${BASH_SOURCE[0]}")" &gt;/dev/null 2&gt;&amp;1
</code></pre><p>Want to pass the script a relative file path? Not on my watch.</p>
<p>Don’t change directories in your script unless you are ready to deal with
the consequences of that.</p>
<p>Additionally, this displays another anti-pattern: the use of <code>$BASH_SOURCE</code>.
It only works in <code>bash</code>, not in any other shell. The manual says that:</p>
<pre><code>BASH_SOURCE
    An array variable whose members are the source filenames where the
    corresponding shell function names in the FUNCNAME array variable are
    defined.  The shell function ${FUNCNAME[$i]} is defined in the file
    ${BASH_SOURCE[$i]} and called from ${BASH_SOURCE[$i+1]}.
</code></pre><p>Proponents of the use of <code>$BASH_SOURCE</code> would argue that <code>$BASH_SOURCE</code> works
both when a script is sourced and when it is executed. That is true,
but also only useful in the rarest of circumstances.</p>
<p>Sourcing functions like an include or import in other programming languages.
The sourced script is effectively inlined. Unless both the sourcing script
and sourced script are built with that in mind, you’re signing up for chaos.</p>
<p>I have been writing bash …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.johnk.io/blog/shell-competency-and-prominent-anti-patterns.html">https://www.johnk.io/blog/shell-competency-and-prominent-anti-patterns.html</a></em></p>]]>
            </description>
            <link>https://www.johnk.io/blog/shell-competency-and-prominent-anti-patterns.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25439561</guid>
            <pubDate>Wed, 16 Dec 2020 06:00:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop Being So Polarized All the Time]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25438822">thread link</a>) | @aswinmohanme
<br/>
December 15, 2020 | https://aswinmohan.me/posts/stop-being-so-polarized-all-the-time/ | <a href="https://web.archive.org/web/*/https://aswinmohan.me/posts/stop-being-so-polarized-all-the-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Remember when we used to joke around, debate about politics, have a drink afterwards and hug your  friend with a  different political view. Remember when we would switch on the news and just casually criticize whatever dumb shit both the  political parties were doing. Ahh those were the days.</p>
<p>Remember when we used to hug our friends with a slightly different political view than us. Remember when we switch on the news and make fun of whatever dumb shit those politicians were pulling of. Remember when opinions were objective and not personal.</p>
<p>Now everyone and their grandmother has a political opinion that is so well formed, so true,  that neither of them is going to entertain any counter argument. I have seen decade old friendships end, careers destroyed, families torn apart because of differing political opinions.</p>
<p>We do have faint memories  of  a time before this, where everyone didn’t make everything a part of their identity. Where you could have a reasonable discussion with someone without it ending in a fist fight. Those times are long gone, but how the hell did we arrive here.</p>

<p>There is point on the slope where shit goes downhill, and for us it was that point when Social Media appeared. Social Media in all it’s glorious forms aren’t  inherently bad, it’s when you add big data magic and billions of dollars of advertisement budget to the mix that messes everything up. Suddenly  the thing  that you use to keep tabs of your friends and family, start to keep tabs on you.</p>
<p>Advertisement has always been about attention, that’s why big billboards are lit up in the middle of the  night showing scantily clad women with legs pointing to some shit your won’t need. The sole purpose is to turn your head and to make you take notice. They don’t care who sees it, they just care a lot of us do.</p>
<p>A lot of advertisement on the early days of the internet were similar, they would put banner ads on the  most busiest sites hoping to gather the most eyeballs. It worked  like that for some time  until they  realized rather than billboards  on the side of the  road,  you could target your users. Rather than  advertising on a generic forum about the world, you could advertise on a blog about cars for your new useless engine oil. The people who would be visiting the car blog would probably be the ones who would be most interested in buying your shitty snake oil. Hence targeting was born. The ROI of Internet advertisement skyrocketed, and everyone wanted a piece of the pie.</p>
<p>Then Social Media came along with a totally different game. They started  to  track your each and every move  building up intricate profiles of you neatly kept on an offshore data-center, opening up an even better gold mine for those sleazy salesmen. Rather than waiting for someone to show up for that stupid  blog post  about that broken down car, they could put the ad for the snake oil right in the feed of a person who loves clicking on car pictures. It was all christmas  in ad town from  then on, and the companies  who had the best  tracking profiles  started swimming in money, and the ones who didn’t started dying out. (Too far ? yeah too far)</p>
<p>After spending a couple of billions and tracking every sneeze and every turn of everyone  who ever set foot in their world,  they started to  realize some thing else. The people who bought the snake oil on the first impression was not the normal person who kind  of loved cars, but the obsessed ones who believed that snake oil was the best oil in the  world and that the best way to save the world was to buy more snake oil. Those were the people that had the most ROI ever, and  the people who wore nice suits in big office buildings decided they wanted more of these obsessed fanatics, and Big Social gladly served them up on a plate.</p>
<p>But even in a large  enough population pool  the people who are obsessed about a lot of shit is really hard to find, and to keep the money flowing they needed more of them. So they did what anyone with a degree in Operations would do, they started manufacturing them.</p>
<p>Big Social realized that the people who  engage  most, who  drive the most revenue are the ones obsessed with the content. They are the most  revenue generating cattle of the ranch, and since everything is a numbers game they started to maximize obsessiveness. Well how do you manufacture people who would die for their views ? How do you manufacture obsessiveness ? Bubbles.</p>
<h2 id="enter-bubbles">Enter Bubbles</h2>
<p>The more the number of positive reinforcement that a person receives about their already existing viewpoints and the more number  of negative reinforcements they see around the opposing ones, the more likely they are to believe their beliefs are true. The more they are engrossed in their bubbles the more they are susceptible to being obsessed.</p>
<p>The  first  time we sign-up for it, they don’t know anything about us. So they ask us for our interests and to add our closest friends. Based on that they show us some generic content  based on our and  our friends interests. Then we start interacting with them, each and every interaction, each and  every pause is recorded and measured and converted  to a  data point. Initially the content is neutral, leaning just to the side  of our interests and our beliefs. The more we interact with it, the more the virtual  profile of ourselves get optimized. With our likes and shares and comments  we build an echo chamber around ourselves, with help from a  black box algorithm designed to optimize  for obsessiveness.</p>
<p>But an echo chamber doesn’t make you and obsessed radical, what makes you one is shock.</p>
<h2 id="enter-shock">Enter Shock</h2>
<p>Shock is what pushes your towards the edge of obsessiveness. Content that has high shock value are borderline impossible to believe. They rock your belief system and lingers on the edge of possibility. It’s purpose is not to make you believe the content right away, but to expand and reinforce your viewpoint so much so that you believe a little more polarized content than what you are used to. That is how you manufacture obsessiveness, that’s how your manufacture  polarization. The cycle is repeated indefinitely nudging you little by little to the edge, until you fall  o ver. Is  it  intentional or  a  byproduct  of an algorithm optimized for profit and engagement maximization is up for debate.</p>
<p>Consider me and Youtube. Like every teenager I had trouble with the ladies and like any other teenager I turned  to the internet for help. I started with dating videos, content which I  was looking for. Then slowly my recommended feed stared to show just one or two videos on how women were the problem of modern society, not enough to turn me to a believer but just enough to shock me. Having been exposed to that I started to normalize videos that bash feminism, SJW’s being owned and rants about how women are the problem. Then my feed started to get populated with  even more  anti-women and videos around red-pill and the manosphere. I am not saying these viewpoints are right or  wrong, but they were shocking  and normalized  a lot  of stuff that I would never have accepted if I was shown then from the start. After a while I started believing a lot of the what was being said, I was starting to suffocate in my own bubble. Luckily I used to read a lot outside the internet and hence had access to contrasting view points. That’s when I realized how deep in the rabbit hole I was. This prompted me to seek out alternate viewpoints and form my own opinions.  If I had kept going I would most probably have turned  into an angry fanatic thirsty for blood on the internet, shouting on some obscure forum on the edge of the internet.</p>
<p>That’s what  the algorithms are designed to do. They have the maximum engagement and attention from how obsessed their users  are. For being obsessed it’s not only vital that you  push the view point forward but also to demean and dehumanize the opposing one, so much so to the point that you believe the views that they hold are clearly wrong.  It pushes us into an us vs them mentality, where we are on right ones  and they are the wrong ones.</p>
<p>After a while we start to internalize what we interact with, it becomes a part of your identity.You start to believe the extreme content that you are exposed to as your own, you start to defend it with all your might.  You can’t entertain an  argument  because it is no  longer an argument  against your opinion,but one against  your identity. To entertain any argument is to acknowledge you are wrong and to prove everything you have interacted with for a long time to be wrong. This is  what  polarizes  us, this is what makes having a friendly conversation about opposing  views impossible in this  day and age. This is what is being done to us. We are divided  by opinions cocooned in our own bubbles, our own  echo chambers which enforce our beliefs and makes us immune to any counter  argument no matter how right or wrong.</p>
<h2 id="breaking-out">Breaking Out</h2>
<p>It’s not easy and fun getting out once you are inside. It’s like the matrix you see and hear and interact with an artificial world designed to hook you in, and like Neo it’s one hell of a ride to unplug. It’s hard but it’s possible, this is how I  did it.</p>
<ul>
<li>Clear the data that they have on you, take away the data and take away the power.</li>
<li>Humanize the opposing view points and the people who make  them. Realize they too have a valid point and that they believe it enough to defend it with all their heart.</li>
<li>Seek out alternate view points, it’s kind of a fun exercise. When you start everything looks stupid and dumb, persist and after a while you will feel a switch inside your brain, when you realize they also have a valid point.</li>
<li>Take some time off and  think deeply about everything and put together a version of the reality and form your own opinions based on them.</li>
<li>Refine those opinions  as you learn more about reality.</li>
</ul>
<p>OR</p>
<ul>
<li>Logout of all your Social Media, it’s not that useful anyway</li>
<li>Get a Flip Phone,  looks cooler than  a dumb phone</li>
<li>Life life  as  nature …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aswinmohan.me/posts/stop-being-so-polarized-all-the-time/">https://aswinmohan.me/posts/stop-being-so-polarized-all-the-time/</a></em></p>]]>
            </description>
            <link>https://aswinmohan.me/posts/stop-being-so-polarized-all-the-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25438822</guid>
            <pubDate>Wed, 16 Dec 2020 03:47:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Daniel Stenberg: How my Twitter hijacks happened]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25438660">thread link</a>) | @sohkamyung
<br/>
December 15, 2020 | https://daniel.haxx.se/blog/2020/12/15/how-my-twitter-hijacks-happened/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/12/15/how-my-twitter-hijacks-happened/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>You might recall that my Twitter account was <a href="https://daniel.haxx.se/blog/2020/11/16/i-lost-my-twitter-account/" data-type="post" data-id="15196">hijacked</a> and then <a href="https://daniel.haxx.se/blog/2020/12/03/twitter-lockout-again/" data-type="post" data-id="15287">again</a> just two weeks later.</p>



<h2>The first: brute-force</h2>



<p>The  first take-over was most likely a case of brute-forcing my weak password while not having 2FA enabled. I have no excuse for either of those lapses. I had convinced myself I had 2fa enabled which made me take a (too) lax attitude to my short 8-character password that was possible to remember. Clearly, 2fa was not enabled and then the only remaining wall against the evil world was that weak password.</p>



<h2>The second time</h2>



<p>After that first hijack, I immediately changed password to a strong many-character one and I made really sure I enabled 2fa with an authenticator app and I felt safe again. Yet it would only take seventeen days until I <em><strong>again</strong></em> was locked out from my account. This second time, I could see how <em>someone had managed to change the email address</em> associated with my account (displayed when I wanted to reset my password). With the password not working and the account not having the correct email address anymore, I could not reset the password, and my 2fa status had no effect. I was locked out. Again.</p>



<p>It felt related to the first case because I’ve had my Twitter account since May 2008. I had never lost it before and then suddenly after 12+ years, within a period of three weeks, it happens twice?</p>



<h2>Why and how</h2>



<p>How this happened was a complete mystery to me. The account was restored fairly swiftly but I learned nothing from that.</p>



<p>Then someone at Twitter contacted me. After they investigated what had happened and how, I had a chat with a responsible person there and he explained for me exactly how this went down.</p>



<p>Had Twitter been hacked? Is there a way to circumvent 2FA? Were my local computer or phone compromised? No, no and no.</p>



<p>Apparently, an agent at Twitter who were going through the backlog of issues, where my previous hijack issue was still present, accidentally changed the email on my account by mistake, probably confusing it with another account in another browser tab.</p>



<p><strong>There was no outside intruder, it was just a user error.</strong></p>



<p>Okay, the cynics will say, this is what he <em>told</em> me and there is no evidence to back it up. That’s right, I’m taking his words as truth here but I also think the description matches my observations. There’s just no way for me or any outsider to verify or fact-check this.</p>



<h2>A brighter future</h2>



<p>They seem to already have identified things to improve to reduce the risk of this happening again and Michael also mentioned a few other items on their agenda that should make hijacks harder to do and help them detect suspicious behavior earlier and faster going forward. I was also happy to provide my feedback on how I think they could’ve made my lost-account experience a little better.</p>



<p>I’m relieved that the second time at least wasn’t my fault and neither of my systems are breached  or hacked (as far as I know).</p>



<p>I’ve also now properly and thoroughly gone over all my accounts on practically all online services I use and made really sure that I have 2fa enabled on them. On some of them I’ve also changed my registered email address to one with 30 random letters to make it truly impossible for any outsider to guess what I use.</p>



<p>(I’m also positively surprised by this extra level of customer care Twitter showed for me and my case.)</p>



<h2>Am I a target?</h2>



<p>I don’t think I am. I think maybe my Twitter account could be interesting to scammers since I have almost 25K followers and I have a verified account. Me personally, I work primarily with open source and most of my works is already made public. I don’t deal in business secrets. I don’t think my personal stuff attracts attackers more than anyone else does.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/08/please-use-backdoor.jpg" alt="" width="184" height="183" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/08/please-use-backdoor.jpg 471w, https://daniel.haxx.se/blog/wp-content/uploads/2017/08/please-use-backdoor-200x200.jpg 200w, https://daniel.haxx.se/blog/wp-content/uploads/2017/08/please-use-backdoor-450x448.jpg 450w" sizes="(max-width: 184px) 100vw, 184px"></figure></div>



<p>What about the risk or the temptation for bad guys in trying to backdoor curl? It is after all installed in some 10 <em>billion</em> systems world-wide. I’ve <a href="https://daniel.haxx.se/blog/2017/09/12/the-backdoor-threat/">elaborated on that before</a>. Summary: I think it is terribly hard for someone to actually manage to do it. Not because of the security of my personal systems perhaps, but because of the entire setup and all processes, signings, reviews, testing and scanning that are involved.</p>



<p>So no. I don’t think my personal systems are a valued singled out target to attackers.</p>



<p>Now, back to work!</p>



<h2>Credits</h2>



<p>Image by <a href="https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3319619">Gerd Altmann</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3319619">Pixabay</a></p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/12/15/how-my-twitter-hijacks-happened/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25438660</guid>
            <pubDate>Wed, 16 Dec 2020 03:19:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Empirical Estimates of Golden Handcuffs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25438546">thread link</a>) | @lemonspat
<br/>
December 15, 2020 | https://applieddivinitystudies.com/handcuffs-empirical/ | <a href="https://web.archive.org/web/*/https://applieddivinitystudies.com/handcuffs-empirical/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
       <p><a href="https://applieddivinitystudies.com/handcuffs/">Last post</a>, I argued against common explanations for Golden Handcuffs.</p>
<p>Before we dive deeper, it’s worth asking, are they even real? Are employees of elite companies actually pathologically unable to leave? Is it just a stereotype with no grounding in reality?</p>
<p>Here are a variety of attempts to estimate the Golden Handcuffs effect empirically.</p>
<h3 id="YC-Founders-Join-Elite-Universities-but-Not-Elite-Companies"><a href="#YC-Founders-Join-Elite-Universities-but-Not-Elite-Companies" title="YC Founders Join Elite Universities, but Not Elite Companies"></a>YC Founders Join Elite Universities, but Not Elite Companies</h3><p>Rather than examining the psychology of employees, let’s just work backwards and count how many founders have big company experience.</p>
<p><a href="https://applieddivinitystudies.com/wilbin-rationalists/">A while back</a>, I published a dataset of the top Y Combinator founders and noticed something odd.</p>
<p>Of the 26 founders, only 1 had held a full-time role at a FAANG company. [2] Two others had worked at Facebook, but only as interns. Outside of FAANG, only 3 founders had worked at companies I recognized at all. [3]</p>
<p>One explanation is the founder-as-monomaniacal-hero. Founders are totally single minded in their devotion, and would never do something as stupid as get sidetracked by prestige or status.</p>
<p>Except that they absolutely do. Of the 26 founders, 21 attended elite universities, mostly MIT and Stanford [1]. So maybe those universities are just incredibly good at fostering entrepreneurs, but more likely, they’re just good at attracting and selecting them. I take this as evidence that founders are not allergic to jumping through conventional hoops, pursuing instrumental goods, sitting down to take the SAT and so on.</p>
<p>It gets weirder when you consider population sizes. Google has around 100,000 employees, whereas MIT and Stanford undergrad programs are just 11,500 combined! And since average tenure at Google is under 4 years, each unit of headcount produces more alumni than a full degree program. [4]</p>
<p>All else equal, we should expect to sample many more founders from Google than from elite universities, but this doesn’t seem to be the case.</p>
<p>What’s going on?</p>
<h3 id="Golden-Handcuffs-as-Selection-Effects"><a href="#Golden-Handcuffs-as-Selection-Effects" title="Golden Handcuffs as Selection Effects"></a>Golden Handcuffs as Selection Effects</h3><p>One explanation is that there are no golden handcuffs and it’s all selection effects. The kinds of people who work for Google are the ones who never intended to leave in the first place. The kinds of people who want to start great companies don’t have any interest in working for somebody else.</p>
<p>This is a reasonable explanation, but applies to less than half of the founders I looked at.</p>
<p>Only 11 of the 26 founders started a company right out of school. 14 have confirmed work experience, and another 2 have scrubbed the employment history, but have long gaps between graduating from school and founding their company.</p>
<p>Maybe working for a small startup shows that you’re less risk averse than a Google employee, but I don’t totally buy this. Brandon Leonardo (Instacart) worked at <a target="_blank" rel="noopener" href="https://www.linkedin.com/company/webs/">Webs</a>, a company I’ve never heard of that claims to make “small business marketing simple”. Dan Kan (Cruise) worked at <a target="_blank" rel="noopener" href="https://www.linkedin.com/company/uservoice/">UserVoice</a>, “the leading product feedback management software”. What exactly do these experiences select for?</p>
<p>In contrast, if you do want to start a company, working at Google seems like a great first step! You can meet co-founders and potential early employees, save money to fund yourself, gain legitimacy for investors and so on.</p>
<p>Of course, it’s possible the kinds of people who think about “gaining legitimacy for investors” are not going to start great companies. Maybe “real founders” don’t pursue instrumental goods.</p>
<h3 id="A-Third-Perspective-Ex-Google-Founded-Companies"><a href="#A-Third-Perspective-Ex-Google-Founded-Companies" title="A Third Perspective: Ex-Google Founded Companies"></a>A Third Perspective: Ex-Google Founded Companies</h3><p>We’ve been dancing around the issue, but why not just go straight to the source and look at outcomes for the population we care about?</p>
<p>Are Google employees actually bad at starting companies?</p>
<p>Looking directly at startups founded by ex-Google employees valued over a billion dollars, we get:</p>
<ul>
<li>Nutanix $5.8B</li>
<li>Cohesity $2.5B</li>
<li>Asana $4.3B</li>
<li>Lucidchart $1B+</li>
<li>Rubrik $3.3B</li>
<li>Instagram (sold for $1B, valued at $100B in 2018)</li>
<li>Pinterest $43B</li>
<li>Flatiron Health $1.9B</li>
<li>Xiaomi $46B</li>
<li>Affirm $2.9B</li>
</ul>
<p>That’s a super impressive list! It doesn’t seem like ex-Google employees are bad at starting companies and pathologically incapable of quitting their jobs. Instead, the oddity is merely that they don’t attend Y Combinator.</p>
<p>That’s a different skew, and much easier to explain. Unlike regular YC founders, ex-Google employees may just be:</p>
<ul>
<li>So wealthy that they self-fund until they can raise a Series A and aren’t willing to sell 7% of their company for $125k.</li>
<li>So tired of bureaucracy that they refuse to join an accelerator.</li>
<li>So credentialed that they don’t feel a need to go through Y Combinator to gain further credibility.</li>
<li>So well connected that they raise a Series A without going through Y Combinator.</li>
</ul>
<p>Whatever the explanation, the fact remains that ex-Google employees do in fact leave to start companies.</p>
<h3 id="Adjustments-and-Proportionality"><a href="#Adjustments-and-Proportionality" title="Adjustments and Proportionality"></a>Adjustments and Proportionality</h3><p>Of course, we now have to ask if they do so proportionally. Even if Google has produced the founders of nearly a dozen billion dollar companies, we shouldn’t be impressed until we’re confident that they’re actually hitting above their weight.</p>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/List_of_unicorn_startup_companies">Wikipedia lists</a> 495 startups worth over a billion dollars, putting Google at 2%. But if you only include US based startups, Google is at 9 out of 122, or 7%.</p>
<p>To figure out the appropriate reference class, we’ll start with the number of software engineers in the US (4 million), then identify how many ex-Google employees there were 10 years ago when most of these founders started their companies.</p>
<p><a target="_blank" rel="noopener" href="https://medium.com/gabor/timeline-employee-count-growth-for-microsoft-yahoo-google-and-facebook-9ede22a37824">A partner at google</a> has compiled and released <a target="_blank" rel="noopener" href="https://docs.google.com/spreadsheets/d/1L0M0u0-C_LoFrGLw0H-9nkgN9wqUhl4bUTcVI0fDZuU/edit#gid=793191479">historical headcount data</a>. This is a good starting point, but remember that we’re actually interested in the total alumni population rathern than point-in-time headcount.</p>
<p>To make this estimate, I assume 3 year average tenure and run a simplified simulation where 33% of the workforce quits at the end of each year, then Google rehires up to next year’s headcount. </p>
<p>Running this simulation from 2000 to 2010, we get that there were 50,000 ex-Google employees in 2010. They’ve <a target="_blank" rel="noopener" href="https://www.quora.com/How-many-software-engineers-does-Google-have">previously said the workforce is 40% technical</a>, so that’s equivalent to 20,000 engineers. [5]</p>
<p>Pitting that against the 4 million software engineers in the US [6], we get that ex-Google engineers were around 0.5% of the relevant population, but started 7% of the US based billion dollar startups. That’s a mulitple of 14x, and fairly good evidence that Google employees are not particularly bad at starting companies. [7]</p>
<h3 id="Conclusion"><a href="#Conclusion" title="Conclusion"></a>Conclusion</h3><p>Taking a step back, recall that what we’re actually curious about is not whether Google engineers are disproportionately successful at starting companies, but whether they even try in the first place. In other words, do they appear irrationally bound by Golden Handcuffs?</p>
<p>Compared to a randomly selected US based engineer, Google engineers have all sorts of benefits. They’re well credentialed, well connected, largely based in Silicon Valley, and supposedly smarter than average.</p>
<p>It’s entirely possible that their success rate is 140x that of a typical engineer, but they only try one tenth as often. The fact that Google engineers start successful companies doesn’t preclude the possibility that Golden Handcuffs are holding them back.</p>
<p>Further, consider that “rationality” in this case is really a function of both odds of success and opportunity cost. Even if Google engineers are less likely to start companies, it could be a perfectly reasonable choice given their relatively high opportunity cost.</p>
<p>So at the end of the day, the empirical data tells us a few interesting things, but can’t present a decisive conclusion.</p>
<hr>
<p>[1] The other universities I count as “elite” are:</p>
<ul>
<li>RISD</li>
<li>Joint RISD/MIT</li>
<li>2 x Harvard</li>
<li>University of Waterloo</li>
<li>Berkeley, Columbia MBA</li>
</ul>
<p>The ones I don’t include are:</p>
<ul>
<li>USD</li>
<li>San Jose State University</li>
<li>Rice</li>
<li>Duke</li>
<li>Claremont McKenna College</li>
</ul>
<p>I do include 4 founders who attended Stanford for grad school, but did not attend an elite undergraduate institution.</p>
<p>[2] Apoorva Mehta of Instacart spent 2 years at Amazon.</p>
<p>[3] Tony Xu of DoorDash was an intern at Square, and worked full time at McKinsey for 2 years, and eBay for another 2. Fred Ehrsam of Coinbase had spent 2 years at Goldman Sachs. Brian Armstrong of same had interned at IBM and Deloitte, then spent a year at Airbnb. Though notably, this was in May 2011, back when Airbnb was a small Series A startup with under $10 million in total funding.</p>
<p>[4] This ends up being a bit complicated. Reportedly, Google has an average tenure of 3.2 years with a median of 1.1. This is possible, but odd, and I’m not sure how they got these numbers. It’s tricky because at any given time, some population of employees has not left and you don’t know how long they’ll stay. If you count their tenure as their tenure-to-date, you’re undercounting how long they’ll actually end up staying. If you only count employees who have left, you’re skewed toward employees with short tenure. Also, Google has grown over the years, and we’re looking at founders who are successful now but started out 10 years ago when Google was around 25,000 employees.</p>
<p>[5] Data <a target="_blank" rel="noopener" href="https://docs.google.com/spreadsheets/d/1FeDDGo_SWeDMMZlTrJ_P2TifyJoOqAuOD8klBKQpUdA/edit?usp=sharing">here</a>. And yes, it’s possible the proportion of engineers has changed over time and this analysis is off.</p>
<p>This also helps explain why there are relatively so many founders from top universities. In the same 10 year time span, Stanford and MIT undergrad graduated around 115,000 alumni.</p>
<p>[6] Maybe we should be looking at the number of people who have been software engineers from 2000 to 2010 including retirements, and this number is actually higher. Assuming 40 year careers, and a constantly total number of engineers, it should be something like 25% higher, and Google is proportionately 25% better than it appears in the main text.</p>
<p>[7] There are lots of over corrections you could apply here, so don’t take this too literally. Maybe the relevant population is all people, not just engineers. In that case, Google ends up looking way better since the general population is much less than 40% engineers. </p>
 
    </div></div>]]>
            </description>
            <link>https://applieddivinitystudies.com/handcuffs-empirical/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25438546</guid>
            <pubDate>Wed, 16 Dec 2020 03:01:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minesweeper in 3D]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25438365">thread link</a>) | @cow9
<br/>
December 15, 2020 | http://egraether.com/mine3d/ | <a href="https://web.archive.org/web/*/http://egraether.com/mine3d/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://egraether.com/mine3d/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25438365</guid>
            <pubDate>Wed, 16 Dec 2020 02:37:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Tale of Static Devirtualization Vol. I: The Lift]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25438149">thread link</a>) | @from
<br/>
December 15, 2020 | https://0xnobody.github.io/devirtualization-intro/ | <a href="https://web.archive.org/web/*/https://0xnobody.github.io/devirtualization-intro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
  
  <time datetime="2020-05-20T00:00:00+00:00">May 20, 2020</time>
</header>

  <blockquote>
  <p>This article is the result of my latest obsession with software virtualization. After years of just skipping virtualized routines, I was finally inspired by <a href="https://blog.can.ac/" target="_blank">Can</a> and started work on this complex topic. What ensued was months of reverse engineering, functional programming, and a LOT of learning. Now that I finally feel comfortable publishing some information on the things I learned in the process, I present unto you the first installment in my devirtualization series, focusing on how virtualization works and the methodology of how we can lift a VM. The aim of this series is to tear down the curtains behind virtualization and hopefully inspire more reverse engineers to research this interesting topic!</p>
</blockquote>

<h2 id="preface">Preface</h2>

<p>Over the last 10 years or so, virtualization based obfuscation has become the de-facto standard in defensive and offensive software alike. As the complexity and power of disassembling tools has improved, software security solutions have kept up rather well. Packers and code mutation tools, being easily defeated by even newbie attackers, have been replaced by these virtual machine based protectors. Today, the two main ‘pioneers’ in this field, controlling the vast majority of the market are <a href="https://vmpsoft.com/" target="_blank">VMProtect</a> and <a href="https://www.oreans.com/" target="_blank">Themida</a>. While we will be looking into analyzing (and breaking) them specifically in some future articles, today we’ll just be looking into how we can lift <em>any</em> VM into <a href="https://blog.can.ac/" target="_blank">Can</a>’s promising <a href="https://vtil.io/" target="_blank">VTIL</a>.</p>

<h2 id="but-first-what-actually-is-virtualization">But first, what actually is virtualization?</h2>
<p>Virtualization is the <strong>recompilation</strong> of instructions to a <strong>custom proprietary architecture</strong>, and the generation of <strong>handler routines</strong> to emulate said architecture. Let’s look at an example of the life of just one simple instruction, <code>push rcx</code>:</p>

<table>
  <thead>
    <tr>
      <th><img src="https://0xnobody.github.io/assets/virtualization-1/vm-flowchart.png" alt="alt text" title="Life of a push rcx instruction"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>The mystical adventure <code>push rcx</code> undertakes when you press ‘Protect’</em></td>
    </tr>
  </tbody>
</table>

<p>The <code>push rcx</code> instruction is decoded, and interpreted by the virtualizer. A handler is generated (or fetched, if it has already been generated and is being reused), which is responsible for executing this instruction in a way that the CPU understands. In our example, I called this handler <code>VPUSH</code> just for explanation’s sake, but obviously they don’t come with names attached to them.</p>

<p>Following this, a ‘virtual instruction’ is then assembled, which contains bytes to identify its handler (in this case, just a table offset) and any operands that are needed for execution. You can see in the diagram above, that the bytes corresponding to the instruction’s <strong>handler offset</strong> are in <strong>green</strong>, whereas the ones corresponding to the <strong>operand</strong> (ie. the <strong>target register</strong>) are in <strong>blue</strong>. This is also reflected in the handler with the corresponding colours.</p>

<p>It’s worth noting, that on handler execution, the virtual instruction pointer (VIP) actually points to the beginning of the <strong>blue</strong> operand bytes. This is because the previous handler has to read (and consume) the next handler’s offset in order to pass control over to it.</p>

<p>Anyways, let’s take a closer look at this <code>VPUSH</code> handler:</p>

<div><div><pre><code><span>movzx</span> <span>rax</span><span>,</span> <span>word</span> <span>ptr</span> <span>[rbp]</span> 
<span>; - rbp is the virtual instruction pointer (VIP) in this case, which contains the pushed register (blue)</span>
<span>; - the pushed register is fetched and stored in ax. In our case this is 0x30</span>

<span>mov</span> <span>rax</span><span>,</span> <span>[</span><span>rsi</span> <span>+</span> <span>rax</span><span>]</span> 
<span>; - rsi is the virtual context; it holds each of the virtual registers. Think of a CONTEXT structure on </span>
<span>; windows.</span>
<span>; - the lower word in rax holds the register offset in the context. The register is fetched from the</span>
<span>; context and stored in rax.</span>

<span>push</span> <span>rax</span>
<span>; - the stored register is pushed to the stack.</span>

<span>movzx</span> <span>rdx</span><span>,</span> <span>word</span> <span>ptr</span> <span>[</span><span>rbp</span><span>+</span><span>0x2</span><span>]</span>
<span>mov</span> <span>rdx</span><span>,</span> <span>[</span><span>rdi</span><span>+</span><span>rdx</span><span>]</span>
<span>; - VIP + 0x2 contains the next handler's offset (green). It is fetched and stored in rdx</span>
<span>; - rdi is the handler table base. The next handler is fetched by offseting it by rdx and storing the</span>
<span>; handler address</span>

<span>add</span> <span>rbp</span><span>,</span> <span>0x4</span>
<span>; - the instruction pointer is incremented by the size of bytes consumed</span>

<span>jmp</span> <span>rdx</span>
<span>; - jump to the next handler, held by rdx, to execute the next instruction's handler</span>
<span>; - the execution loop continues...</span>
</code></pre></div></div>

<p>Virtual machines are basically just very <strong>very</strong> long chains of these handlers, each doing quite rudimentary operations.
It must be said, however, that the example I gave above is an extremely simple one. Modern virtualizers have integrated encryption and obfuscation techniques, and some feature quite advanced custom architectures. Many stray far away from the x86 instruction set to make the analyst’s life harder.</p>

<p>Well, how does this impact analysis, you ask? Well, since you’re reading this article, you must already know ;)
But to name a few:</p>
<ul>
  <li>The original instructions are lost, forever. Only the behaviour is retained, in a proprietary, usually randomized architecture. For example, even after full devirtualization, we can’t for 100% say that the original register used for the push is <code>rcx</code>.</li>
  <li>The VM’s architecture can differ significantly from the original. For example, a single VM instruction could push 3 registers, exchange 2 registers, and write to one register. All in a <em>single</em> virtual instruction!</li>
  <li>Other obfuscation techniques (such as mutation) can now be applied on both the host level (real x86 instructions executing on the PC) and on the guest level (the virtual instructions represented by the handlers).</li>
  <li>Control flow is in most cases highly obscured. Often conditional jumps are manually emulated. This makes tracking basic blocks difficult.</li>
  <li>The VM cannot be statically analyzed in tools like IDA, as it does not function like a conventional program.</li>
</ul>

<p>Needless to say, virtualization is an extremely powerful and effective software protection method.</p>

<h2 id="lets-break-it">Let’s break it!</h2>
<p>In order to break and reverse this protection, we really just need to do three things: gather information in order to determine exactly what each handler does in which order, somehow convert this information into a language that the CPU and disassemblers understand (in our case, x86), and then finally repackage the binary.
This is called <em>lifting</em>, <em>translation</em>, and <em>repackaging</em> respectively, and it is what needs to be done to devirtualize any VM.
Today, we’re just gonna be looking at <em>lifting</em> in particular.</p>

<h2 id="lifting">Lifting</h2>
<p>The dictionary definition for lifting is “raise to a higher position or level”. This is entirely true. We are performing analyis on the virtual routines, in order to determine what each handler does on the instruction level, and then converting this information into a higher level, easy-to-understand representation. This is done in a few steps.</p>

<h3 id="navigation">Navigation</h3>

<table>
  <thead>
    <tr>
      <th><img src="https://0xnobody.github.io/assets/virtualization-1/virt-starter-pack.png" alt="alt text" title="Ha ha xd"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>After analyzing VMs for a few hours (or days), you do begin to notice certain things.</em></td>
    </tr>
  </tbody>
</table>

<p>Before we can perform any handler analysis, we must first be able to navigate our way around the VM. Although this step varies greatly for each VM, certain parts always remain the same.</p>
<ul>
  <li>Every VM routine must begin by saving the value of each register, usually by pushing them to the stack. This is done because the VM needs to use the registers to run its handlers, and it must restore the registers after exiting the VM.</li>
  <li>Each VM must also have some sort of context structure. This is where current executing information about the VM is held, such as register values. It can easily be identified as it is accessed very often in every handler.</li>
  <li>Each VM must have an instruction pointer (VIP) used to determine which handler to execute next and to provide that handler with operands. It is also easy to identify, as it much be adjusted after each handler.</li>
  <li>Many VMs have some sort of stack representation. For example, VMProtect uses a nominated register to access the stack, whereas Themida just uses RSP.</li>
  <li>Code flow must somehow be passed from one handler to the next. This can just be an index in a handler table, an offset to some point in the code, or something entirely different. It is worth noting that the next handler <em>must</em> be computed from the VIP.</li>
</ul>

<p>In order to properly analyze and decode each handler, we must be able to follow the VM’s execution. We must follow the VM’s <em>fetch-&gt;decode-&gt;execute</em> loop, so we are able to determine which handler will be executed next. Once the basics of the VM are reversed and we can step through the handler instructions, the next step is to identify these handlers.</p>

<h3 id="identification">Identification</h3>
<p>Now we need to determine what each handler does. We can achieve this via <em>pattern matching</em> the instructions. Of course, we must remember to keep these patterns balanced, ensuring we match all the relevant instructions but make them generic enough so that we can match with all instances of the handler.</p>

<p><em>Pattern matching</em> is quite a generic method, and can be used in various different flavours alongside many other algorithms depending on the complexity of the VM. But in this example we’re gonna take it easy, and just look at a simple forward matching algorithm. This allows us to specify the patterns we want to match, and the order we want to match them in.</p>

<p>Let’s use the above <code>push</code> handler as an example:</p>

<div><div><pre><code><span>// this class contains templates to pattern match against</span>
<span>//</span>
<span>auto</span> <span>matcher</span> <span>=</span> <span>new</span> <span>pattern_matcher</span><span>(</span><span>stream</span><span>);</span>

<span>// these are the constant registers</span>
<span>// they are hardcoded here for simplicity's sake</span>
<span>//</span>
<span>x86_reg</span> <span>vip_reg</span> <span>=</span> <span>X86_REG_RBP</span><span>;</span>
<span>x86_reg</span> <span>vcontext_reg</span> <span>=</span> <span>X86_REG_RSI</span><span>;</span>

<span>// these values will be set as the patterns are found</span>
<span>// they allow us to ensure that the same register is used for more than one pattern</span>
<span>// they also allow us to retrieve specific information about the handler eg. operand sizes</span>
<span>//</span>
<span>x86_reg</span> <span>pushed_reg_idx_reg</span> <span>=</span> <span>X86_REG_INVALID</span><span>;</span>
<span>uint64_t</span> <span>pushed_reg_idx_offs</span> <span>=</span> <span>-</span><span>1</span><span>;</span>

<span>x86_reg</span> <span>pushed_reg</span> <span>=</span> <span>X86_REG_INVALID</span><span>;</span>
 
<span>auto</span> <span>result</span> <span>=</span> <span>matcher</span>
    <span>// match for `mov %0, [%vip + %1]`</span>
    <span>// %0 is written to pushed_reg_idx_reg, %1 is written to pushed_reg_idx_offs</span>
    <span>//</span>
    <span>-&gt;</span><span>mov_reg_mem</span><span>(</span><span>&amp;</span><span>pushed_reg_idx_reg</span><span>,</span> <span>&amp;</span><span>vip_reg</span><span>,</span> <span>&amp;</span><span>pushed_reg_idx_offs</span><span>)</span>

    <span>// match for `mov %2, [%ctx + %0]`</span>
    <span>// %2 is written to pushed_reg</span>
    <span>//</span>
    <span>-&gt;</span><span>mov_reg_mem_idx</span><span>(</span><span>&amp;</span><span>pushed_reg</span><span>,</span> <span>&amp;</span><span>vcontext_reg</span><span>,</span> <span>&amp;</span><span>pushed_reg_idx</span><span>)</span>
    
    <span>// match for `push %2`</span>
    <span>//</span>
    <span>-&gt;</span><span>push_reg</span><span>(</span><span>&amp;</span><span>pushed_reg</span><span>)</span>

<span>if</span> <span>(</span><span>result</span><span>)</span>
    <span>// matched - the handler is `push`</span>
<span>else</span>
    <span>// not matched - …</span></code></pre></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://0xnobody.github.io/devirtualization-intro/">https://0xnobody.github.io/devirtualization-intro/</a></em></p>]]>
            </description>
            <link>https://0xnobody.github.io/devirtualization-intro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25438149</guid>
            <pubDate>Wed, 16 Dec 2020 02:06:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PyTorch Quantization Aware Training]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25437855">thread link</a>) | @keyboardman
<br/>
December 15, 2020 | https://leimao.github.io/blog/PyTorch-Quantization-Aware-Training/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/PyTorch-Quantization-Aware-Training/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Static quantization allows the user to generate quantized integer model that is highly efficient during inference. However, sometimes, even with careful post-training calibration, the model accuracies might be sacrificed to some extent that is not acceptable. If this is the case, post-training calibration is not sufficient to generate a quantized integer model. We would have train the model in a way so that the quantization effect has been taken into account. Quantization aware training is capable of modeling the quantization effect during training.</p>



<p>The mechanism of quantization aware training is simple, it places fake quantization modules, i.e., quantization and dequantization modules, at the places where quantization happens during floating-point model to quantized integer model conversion, to simulate the effects of clamping and rounding brought by integer quantization. The fake quantization modules will also monitor scales and zero points of the weights and activations. Once the quantization aware training is finished, the floating point model could be converted to quantized integer model immediately using the information stored in the fake quantization modules.</p>



<p>In this blog post, I would like to show how to use PyTorch to do quantization aware training. More details about the mathematical foundations of quantization for neural networks could be found in my article <a href="https://leimao.github.io/article/Neural-Networks-Quantization/">â€œQuantization for Neural Networksâ€�</a>.</p>

<h3 id="pytorch-quantization-aware-training">PyTorch Quantization Aware Training</h3>

<p>Unlike TensorFlow 2.3.0 which supports integer quantization using arbitrary bitwidth from 2 to 16, PyTorch 1.7.0 only supports 8-bit integer quantization. The workflow could be as easy as loading a pre-trained floating point model and apply a quantization aware training wrapper. However, without doing layer fusion, sometimes such kind of easy manipulation would not result in good model performances.</p>



<p>In this case, I will also use the ResNet18 from <a href="https://pytorch.org/docs/stable/torchvision/models.html">TorchVision models</a> as an example. All the steps prior, to the quantization aware training steps, including layer fusion and skip connections replacement, are exactly the same as to the ones used in <a href="https://leimao.github.io/blog/PyTorch-Static-Quantization/">â€œPyTorch Static Quantizationâ€�</a>. The source code could also be downloaded from <a href="https://github.com/leimao/PyTorch-Quantization-Aware-Training">GitHub</a>.</p>



<p>The quantization aware training steps are also very similar to post-training calibration:</p>

<ol>
  <li>Train a floating point model or load a pre-trained floating point model.</li>
  <li>Move the model to CPU and switch model to training mode.</li>
  <li>Apply layer fusion.</li>
  <li>Switch model to evaluation mode, check if the layer fusion results in correct model, and switch back to training mode.</li>
  <li>Apply <code>torch.quantization.QuantStub()</code> and <code>torch.quantization.QuantStub()</code> to the inputs and outputs, respectively.</li>
  <li>Specify quantization configurations, such as symmetric quantization or asymmetric quantization, etc.</li>
  <li>Prepare quantization model for quantization aware training.</li>
  <li>Move the model to CUDA and run quantization aware training using CUDA.</li>
  <li>Move the model to CPU and convert the quantization aware trained floating point model to quantized integer model.</li>
  <li>[Optional] Verify accuracies and inference performance gain.</li>
  <li>Save the quantized integer model.</li>
</ol>

<p>The quantization aware training script is very similar to the one used in <a href="https://leimao.github.io/blog/PyTorch-Static-Quantization/">â€œPyTorch Static Quantizationâ€�</a>:</p>

<div><div><pre><code><span># cifar.py
</span>
<span>import</span> <span>os</span>
<span>import</span> <span>random</span>

<span>import</span> <span>torch</span>
<span>import</span> <span>torch.nn</span> <span>as</span> <span>nn</span>
<span>import</span> <span>torch.optim</span> <span>as</span> <span>optim</span>
<span>import</span> <span>torchvision</span>
<span>from</span> <span>torchvision</span> <span>import</span> <span>datasets</span><span>,</span> <span>transforms</span>

<span>import</span> <span>time</span>
<span>import</span> <span>copy</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>

<span>from</span> <span>resnet</span> <span>import</span> <span>resnet18</span>

<span>def</span> <span>set_random_seeds</span><span>(</span><span>random_seed</span><span>=</span><span>0</span><span>):</span>

    <span>torch</span><span>.</span><span>manual_seed</span><span>(</span><span>random_seed</span><span>)</span>
    <span>torch</span><span>.</span><span>backends</span><span>.</span><span>cudnn</span><span>.</span><span>deterministic</span> <span>=</span> <span>True</span>
    <span>torch</span><span>.</span><span>backends</span><span>.</span><span>cudnn</span><span>.</span><span>benchmark</span> <span>=</span> <span>False</span>
    <span>np</span><span>.</span><span>random</span><span>.</span><span>seed</span><span>(</span><span>random_seed</span><span>)</span>
    <span>random</span><span>.</span><span>seed</span><span>(</span><span>random_seed</span><span>)</span>

<span>def</span> <span>prepare_dataloader</span><span>(</span><span>num_workers</span><span>=</span><span>8</span><span>,</span> <span>train_batch_size</span><span>=</span><span>128</span><span>,</span> <span>eval_batch_size</span><span>=</span><span>256</span><span>):</span>

    <span>train_transform</span> <span>=</span> <span>transforms</span><span>.</span><span>Compose</span><span>([</span>
        <span>transforms</span><span>.</span><span>RandomCrop</span><span>(</span><span>32</span><span>,</span> <span>padding</span><span>=</span><span>4</span><span>),</span>
        <span>transforms</span><span>.</span><span>RandomHorizontalFlip</span><span>(),</span>
        <span>transforms</span><span>.</span><span>ToTensor</span><span>(),</span>
        <span># transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
</span>        <span>transforms</span><span>.</span><span>Normalize</span><span>(</span><span>mean</span><span>=</span><span>(</span><span>0.485</span><span>,</span> <span>0.456</span><span>,</span> <span>0.406</span><span>),</span> <span>std</span><span>=</span><span>(</span><span>0.229</span><span>,</span> <span>0.224</span><span>,</span> <span>0.225</span><span>))</span>
    <span>])</span>

    <span>test_transform</span> <span>=</span> <span>transforms</span><span>.</span><span>Compose</span><span>([</span>
        <span>transforms</span><span>.</span><span>ToTensor</span><span>(),</span>
        <span># transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
</span>        <span>transforms</span><span>.</span><span>Normalize</span><span>(</span><span>mean</span><span>=</span><span>(</span><span>0.485</span><span>,</span> <span>0.456</span><span>,</span> <span>0.406</span><span>),</span> <span>std</span><span>=</span><span>(</span><span>0.229</span><span>,</span> <span>0.224</span><span>,</span> <span>0.225</span><span>))</span>
    <span>])</span>

    <span>train_set</span> <span>=</span> <span>torchvision</span><span>.</span><span>datasets</span><span>.</span><span>CIFAR10</span><span>(</span><span>root</span><span>=</span><span>"data"</span><span>,</span> <span>train</span><span>=</span><span>True</span><span>,</span> <span>download</span><span>=</span><span>True</span><span>,</span> <span>transform</span><span>=</span><span>train_transform</span><span>)</span> 
    <span># We will use test set for validation and test in this project.
</span>    <span># Do not use test set for validation in practice!
</span>    <span>test_set</span> <span>=</span> <span>torchvision</span><span>.</span><span>datasets</span><span>.</span><span>CIFAR10</span><span>(</span><span>root</span><span>=</span><span>"data"</span><span>,</span> <span>train</span><span>=</span><span>False</span><span>,</span> <span>download</span><span>=</span><span>True</span><span>,</span> <span>transform</span><span>=</span><span>test_transform</span><span>)</span>

    <span>train_sampler</span> <span>=</span> <span>torch</span><span>.</span><span>utils</span><span>.</span><span>data</span><span>.</span><span>RandomSampler</span><span>(</span><span>train_set</span><span>)</span>
    <span>test_sampler</span> <span>=</span> <span>torch</span><span>.</span><span>utils</span><span>.</span><span>data</span><span>.</span><span>SequentialSampler</span><span>(</span><span>test_set</span><span>)</span>

    <span>train_loader</span> <span>=</span> <span>torch</span><span>.</span><span>utils</span><span>.</span><span>data</span><span>.</span><span>DataLoader</span><span>(</span>
        <span>dataset</span><span>=</span><span>train_set</span><span>,</span> <span>batch_size</span><span>=</span><span>train_batch_size</span><span>,</span>
        <span>sampler</span><span>=</span><span>train_sampler</span><span>,</span> <span>num_workers</span><span>=</span><span>num_workers</span><span>)</span>

    <span>test_loader</span> <span>=</span> <span>torch</span><span>.</span><span>utils</span><span>.</span><span>data</span><span>.</span><span>DataLoader</span><span>(</span>
        <span>dataset</span><span>=</span><span>test_set</span><span>,</span> <span>batch_size</span><span>=</span><span>eval_batch_size</span><span>,</span>
        <span>sampler</span><span>=</span><span>test_sampler</span><span>,</span> <span>num_workers</span><span>=</span><span>num_workers</span><span>)</span>

    <span>return</span> <span>train_loader</span><span>,</span> <span>test_loader</span>

<span>def</span> <span>evaluate_model</span><span>(</span><span>model</span><span>,</span> <span>test_loader</span><span>,</span> <span>device</span><span>,</span> <span>criterion</span><span>=</span><span>None</span><span>):</span>

    <span>model</span><span>.</span><span>eval</span><span>()</span>
    <span>model</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>

    <span>running_loss</span> <span>=</span> <span>0</span>
    <span>running_corrects</span> <span>=</span> <span>0</span>

    <span>for</span> <span>inputs</span><span>,</span> <span>labels</span> <span>in</span> <span>test_loader</span><span>:</span>

        <span>inputs</span> <span>=</span> <span>inputs</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
        <span>labels</span> <span>=</span> <span>labels</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>

        <span>outputs</span> <span>=</span> <span>model</span><span>(</span><span>inputs</span><span>)</span>
        <span>_</span><span>,</span> <span>preds</span> <span>=</span> <span>torch</span><span>.</span><span>max</span><span>(</span><span>outputs</span><span>,</span> <span>1</span><span>)</span>

        <span>if</span> <span>criterion</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
            <span>loss</span> <span>=</span> <span>criterion</span><span>(</span><span>outputs</span><span>,</span> <span>labels</span><span>).</span><span>item</span><span>()</span>
        <span>else</span><span>:</span>
            <span>loss</span> <span>=</span> <span>0</span>

        <span># statistics
</span>        <span>running_loss</span> <span>+=</span> <span>loss</span> <span>*</span> <span>inputs</span><span>.</span><span>size</span><span>(</span><span>0</span><span>)</span>
        <span>running_corrects</span> <span>+=</span> <span>torch</span><span>.</span><span>sum</span><span>(</span><span>preds</span> <span>==</span> <span>labels</span><span>.</span><span>data</span><span>)</span>

    <span>eval_loss</span> <span>=</span> <span>running_loss</span> <span>/</span> <span>len</span><span>(</span><span>test_loader</span><span>.</span><span>dataset</span><span>)</span>
    <span>eval_accuracy</span> <span>=</span> <span>running_corrects</span> <span>/</span> <span>len</span><span>(</span><span>test_loader</span><span>.</span><span>dataset</span><span>)</span>

    <span>return</span> <span>eval_loss</span><span>,</span> <span>eval_accuracy</span>

<span>def</span> <span>train_model</span><span>(</span><span>model</span><span>,</span> <span>train_loader</span><span>,</span> <span>test_loader</span><span>,</span> <span>device</span><span>,</span> <span>learning_rate</span><span>=</span><span>1e-1</span><span>,</span> <span>num_epochs</span><span>=</span><span>200</span><span>):</span>

    <span># The training configurations were not carefully selected.
</span>
    <span>criterion</span> <span>=</span> <span>nn</span><span>.</span><span>CrossEntropyLoss</span><span>()</span>

    <span>model</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>

    <span># It seems that SGD optimizer is better than Adam optimizer for ResNet18 training on CIFAR10.
</span>    <span>optimizer</span> <span>=</span> <span>optim</span><span>.</span><span>SGD</span><span>(</span><span>model</span><span>.</span><span>parameters</span><span>(),</span> <span>lr</span><span>=</span><span>learning_rate</span><span>,</span> <span>momentum</span><span>=</span><span>0.9</span><span>,</span> <span>weight_decay</span><span>=</span><span>1e-4</span><span>)</span>
    <span># scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500)
</span>    <span>scheduler</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>lr_scheduler</span><span>.</span><span>MultiStepLR</span><span>(</span><span>optimizer</span><span>,</span> <span>milestones</span><span>=</span><span>[</span><span>100</span><span>,</span> <span>150</span><span>],</span> <span>gamma</span><span>=</span><span>0.1</span><span>,</span> <span>last_epoch</span><span>=-</span><span>1</span><span>)</span>
    <span># optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)
</span>
    <span># Evaluation
</span>    <span>model</span><span>.</span><span>eval</span><span>()</span>
    <span>eval_loss</span><span>,</span> <span>eval_accuracy</span> <span>=</span> <span>evaluate_model</span><span>(</span><span>model</span><span>=</span><span>model</span><span>,</span> <span>test_loader</span><span>=</span><span>test_loader</span><span>,</span> <span>device</span><span>=</span><span>device</span><span>,</span> <span>criterion</span><span>=</span><span>criterion</span><span>)</span>
    <span>print</span><span>(</span><span>"Epoch: {:02d} Eval Loss: {:.3f} Eval Acc: {:.3f}"</span><span>.</span><span>format</span><span>(</span><span>-</span><span>1</span><span>,</span> <span>eval_loss</span><span>,</span> <span>eval_accuracy</span><span>))</span>

    <span>for</span> <span>epoch</span> <span>in</span> <span>range</span><span>(</span><span>num_epochs</span><span>):</span>

        <span># Training
</span>        <span>model</span><span>.</span><span>train</span><span>()</span>

        <span>running_loss</span> <span>=</span> <span>0</span>
        <span>running_corrects</span> <span>=</span> <span>0</span>

        <span>for</span> <span>inputs</span><span>,</span> <span>labels</span> <span>in</span> <span>train_loader</span><span>:</span>

            <span>inputs</span> <span>=</span> <span>inputs</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
            <span>labels</span> <span>=</span> <span>labels</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>

            <span># zero the parameter gradients
</span>            <span>optimizer</span><span>.</span><span>zero_grad</span><span>()</span>

            <span># forward + backward + optimize
</span>            <span>outputs</span> <span>=</span> <span>model</span><span>(</span><span>inputs</span><span>)</span>
            <span>_</span><span>,</span> <span>preds</span> <span>=</span> <span>torch</span><span>.</span><span>max</span><span>(</span><span>outputs</span><span>,</span> <span>1</span><span>)</span>
            <span>loss</span> <span>=</span> <span>criterion</span><span>(</span><span>outputs</span><span>,</span> <span>labels</span><span>)</span>
            <span>loss</span><span>.</span><span>backward</span><span>()</span>
            <span>optimizer</span><span>.</span><span>step</span><span>()</span>

            <span># statistics
</span>            <span>running_loss</span> <span>+=</span> <span>loss</span><span>.</span><span>item</span><span>()</span> <span>*</span> <span>inputs</span><span>.</span><span>size</span><span>(</span><span>0</span><span>)</span>
            <span>running_corrects</span> <span>+=</span> <span>torch</span><span>.</span><span>sum</span><span>(</span><span>preds</span> <span>==</span> <span>labels</span><span>.</span><span>data</span><span>)</span>

        <span>train_loss</span> <span>=</span> <span>running_loss</span> <span>/</span> <span>len</span><span>(</span><span>train_loader</span><span>.</span><span>dataset</span><span>)</span>
        <span>train_accuracy</span> <span>=</span> <span>running_corrects</span> <span>/</span> <span>len</span><span>(</span><span>train_loader</span><span>.</span><span>dataset</span><span>)</span>

        <span># Evaluation
</span>        <span>model</span><span>.</span><span>eval</span><span>()</span>
        <span>eval_loss</span><span>,</span> <span>eval_accuracy</span> <span>=</span> <span>evaluate_model</span><span>(</span><span>model</span><span>=</span><span>model</span><span>,</span> <span>test_loader</span><span>=</span><span>test_loader</span><span>,</span> <span>device</span><span>=</span><span>device</span><span>,</span> <span>criterion</span><span>=</span><span>criterion</span><span>)</span>

        <span># Set learning rate scheduler
</span>        <span>scheduler</span><span>.</span><span>step</span><span>()</span>

        <span>print</span><span>(</span><span>"Epoch: {:03d} Train Loss: {:.3f} Train Acc: {:.3f} Eval Loss: {:.3f} Eval Acc: {:.3f}"</span><span>.</span><span>format</span><span>(</span><span>epoch</span><span>,</span> <span>train_loss</span><span>,</span> <span>train_accuracy</span><span>,</span> <span>eval_loss</span><span>,</span> <span>eval_accuracy</span><span>))</span>

    <span>return</span> <span>model</span>

<span>def</span> <span>calibrate_model</span><span>(</span><span>model</span><span>,</span> <span>loader</span><span>,</span> <span>device</span><span>=</span><span>torch</span><span>.</span><span>device</span><span>(</span><span>"cpu:0"</span><span>)):</span>

    <span>model</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
    <span>model</span><span>.</span><span>eval</span><span>()</span>

    <span>for</span> <span>inputs</span><span>,</span> <span>labels</span> <span>in</span> <span>loader</span><span>:</span>
        <span>inputs</span> <span>=</span> <span>inputs</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
        <span>labels</span> <span>=</span> <span>labels</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
        <span>_</span> <span>=</span> <span>model</span><span>(</span><span>inputs</span><span>)</span>

<span>def</span> <span>measure_inference_latency</span><span>(</span><span>model</span><span>,</span> <span>device</span><span>,</span> <span>input_size</span><span>=</span><span>(</span><span>1</span><span>,</span><span>3</span><span>,</span><span>32</span><span>,</span><span>32</span><span>),</span> <span>num_samples</span><span>=</span><span>100</span><span>):</span>

    <span>model</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
    <span>model</span><span>.</span><span>eval</span><span>()</span>

    <span>x</span> <span>=</span> <span>torch</span><span>.</span><span>rand</span><span>(</span><span>size</span><span>=</span><span>input_size</span><span>).</span><span>to</span><span>(</span><span>device</span><span>)</span>

    <span>start_time</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
    <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>num_samples</span><span>):</span>
        <span>_</span> <span>=</span> <span>model</span><span>(</span><span>x</span><span>)</span>
    <span>end_time</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
    <span>elapsed_time</span> <span>=</span> <span>end_time</span> <span>-</span> <span>start_time</span>
    <span>elapsed_time_ave</span> <span>=</span> <span>elapsed_time</span> <span>/</span> <span>num_samples</span>

    <span>return</span> <span>elapsed_time_ave</span>

<span>def</span> <span>save_model</span><span>(</span><span>model</span><span>,</span> <span>model_dir</span><span>,</span> <span>model_filename</span><span>):</span>

    <span>if</span> <span>not</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>exists</span><span>(</span><span>model_dir</span><span>):</span>
        <span>os</span><span>.</span><span>makedirs</span><span>(</span><span>model_dir</span><span>)</span>
    <span>model_filepath</span> <span>=</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>join</span><span>(</span><span>model_dir</span><span>,</span> <span>model_filename</span><span>)</span>
    <span>torch</span><span>.</span><span>save</span><span>(</span><span>model</span><span>.</span><span>state_dict</span><span>(),</span> <span>model_filepath</span><span>)</span>

<span>def</span> <span>load_model</span><span>(</span><span>model</span><span>,</span> <span>model_filepath</span><span>,</span> <span>device</span><span>):</span>

    <span>model</span><span>.</span><span>load_state_dict</span><span>(</span><span>torch</span><span>.</span><span>load</span><span>(</span><span>model_filepath</span><span>,</span> <span>map_location</span><span>=</span><span>device</span><span>))</span>

    <span>return</span> <span>model</span>

<span>def</span> <span>save_torchscript_model</span><span>(</span><span>model</span><span>,</span> <span>model_dir</span><span>,</span> <span>model_filename</span><span>):</span>

    <span>if</span> <span>not</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>exists</span><span>(</span><span>model_dir</span><span>):</span>
        <span>os</span><span>.</span><span>makedirs</span><span>(</span><span>model_dir</span><span>)</span>
    <span>model_filepath</span> <span>=</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>join</span><span>(</span><span>model_dir</span><span>,</span> <span>model_filename</span><span>)</span>
    <span>torch</span><span>.</span><span>jit</span><span>.</span><span>save</span><span>(</span><span>torch</span><span>.</span><span>jit</span><span>.</span><span>script</span><span>(</span><span>model</span><span>),</span> <span>model_filepath</span><span>)</span>

<span>def</span> <span>load_torchscript_model</span><span>(</span><span>model_filepath</span><span>,</span> <span>device</span><span>):</span>

    <span>model</span> <span>=</span> <span>torch</span><span>.</span><span>jit</span><span>.</span><span>load</span><span>(</span><span>model_filepath</span><span>,</span> <span>map_location</span><span>=</span><span>device</span><span>)</span>

    <span>return</span> <span>model</span>

<span>def</span> <span>create_model</span><span>(</span><span>num_classes</span><span>=</span><span>10</span><span>):</span>

    <span># The number of channels in ResNet18 is divisible by 8.
</span>    <span># This is required for fast GEMM integer matrix multiplication.
</span>    <span># model = torchvision.models.resnet18(pretrained=False)
</span>    <span>model</span> <span>=</span> <span>resnet18</span><span>(</span><span>num_classes</span><span>=</span><span>num_classes</span><span>,</span> <span>pretrained</span><span>=</span><span>False</span><span>)</span>

    <span># We would use the pretrained ResNet18 as a feature extractor.
</span>    <span># for …</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/PyTorch-Quantization-Aware-Training/">https://leimao.github.io/blog/PyTorch-Quantization-Aware-Training/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/PyTorch-Quantization-Aware-Training/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25437855</guid>
            <pubDate>Wed, 16 Dec 2020 01:21:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Far Cry: How the Fire Burns and Spreads (2012)]]>
            </title>
            <description>
<![CDATA[
Score 163 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25437800">thread link</a>) | @fctorial
<br/>
December 15, 2020 | https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/ | <a href="https://web.archive.org/web/*/https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
			
<h2>INTRO</h2>



<p>A few years ago, I got the opportunity to architect and code the fire propagation system in Far Cry 2. &nbsp;At that time, &nbsp;it was a gigantic task and it scared the hell out of me. Luckily, it turned out well enough.</p>



<p>With the upcoming Far Cry 3, several people recently asked me how the system worked. I realized that I never took the time to write it down. So, before I forget and also because it might be useful to somebody out there, here’s a high level overview of its inner workings. &nbsp;Pretty programmer art included as a bonus.</p>



<p><em>Disclaimer: Although Far Cry 3 uses the same system I wrote, I was not involved in the project. They may or may not have changed / adapted or modified the algorithms. What I describe below is accurate for Far Cry 2.</em></p>



<figure><p>
<iframe title="Far Cry 3 incredible fire demo video" width="640" height="360" src="https://www.youtube.com/embed/zcmbWqJjCN4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<h2>BASE STRUCTURE</h2>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/ACell1.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/ACell1.jpg 600w, https://jflevesque.com/wp-content/uploads/2020/01/ACell1-300x206.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"><figcaption>A 2D Grid good for grass fire. &nbsp;Here, a fire cell has 50 hitpoints</figcaption></figure></div>



<p>At the core, the fire propagation system is quite simple. Since gameplay is what’s important, we&nbsp;sacrifice some of the realism for fun. The fire propagation in&nbsp;Far Cry 2 &nbsp;(and Far Cry 3) has just enough realism to maintain the player’s&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Suspension_of_disbelief">suspension of disbelief</a>,&nbsp;but certainly not enough to get published anytime soon. Because I like to&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/KISS_principle">keep things simple</a>, it doesn’t involve any complicated mathematics, physics or fluid dynamics. That has the additional advantage to be fast to simulate and easy to understand.</p>



<p>The secret sauce is an&nbsp;equally spaced grid. It is true for grass, for objects as well as for trees. The only difference is that we use a 2D grid for grass and a 3D grid for objects and trees.</p>



<p>Each cell of the grid has a position in the world, a radius and&nbsp;<strong>hitpoints</strong>. The cells have a plethora of&nbsp;properties, but these three are the bare minimum to propagate fire.</p>



<h2>LIGHT MY FIRE! HOW TO START ONE?</h2>



<p>The game engine tracks all damage done in the game, might it be bullet shots, impacts or fire damage. When a game entity is damaged, it is notified by an event. The damage event includes how much damage was done, what kind it was and what caused it.&nbsp;&nbsp;If the kind of damage was fire based and the entity is flammable, then at least two things happen:</p>



<ul><li>Firstly, the fire grid is dynamically created for the damaged entity. We create them dynamically because we don’t want those grids&nbsp;to exist in the wild for no reasons. That would take memory, disk space, etc, so we create them as we go. But, once created, it remains as long as the game entity exists.</li></ul>



<ul><li>Secondly, we figure out which cell in the grid is closest to the damage source. That cell then takes the damage and its hitpoints are reduced accordingly.</li></ul>



<p>That’s where things get interesting – When a cell has been damaged by fire and has lost all its hitpoints;&nbsp;<strong>it catches fire</strong>.</p>



<p>While burning, the cell becomes a damager itself. It deals damage to its neighbour cells on the grid; cells that share an edge with it. By doing so, it reduces their hitpoints and when in turns these cells have lost all their hitpoints, they catch fire. That’s how the propagation is created.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/2DGridBiggerFire1.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/2DGridBiggerFire1.jpg 700w, https://jflevesque.com/wp-content/uploads/2020/01/2DGridBiggerFire1-300x220.jpg 300w" sizes="(max-width: 700px) 100vw, 700px"><figcaption>Fire propagating from left to right. The cells on the fire front are being damaged.</figcaption></figure></div>



<p>Lastly, a cell from the grid as a finite lifetime. Otherwise, it would burn forever. It can be seen as the amount of energy given by the material that is burning. &nbsp;For instance,&nbsp;a piece of paper would most likely burn faster than a wood log, so it would be given a shorter lifetime value.</p>



<p>That’s it. A fully functional fire propagation system good enough for a AAA game!</p>



<h2>TECHNICALITIES</h2>



<p><strong>Simulate wet jungle VS dry patch of grass</strong><br>How to simulate a wet jungle versus a dry patch of grass? They behave differently. Quite easily!<br>Increase the fire cell’s hitpoints and it’s difficult to set it on fire and it’s slow to propagate.&nbsp;Decrease its burning lifetime and the fire dies out quickly. There, you just simulated a wet jungle environment.</p>



<p><strong>How to create the propagation grids</strong></p>



<p><strong><em>Grass / Land</em></strong><br>For grass wildfire, &nbsp;an axis-aligned 2D grid is built in realtime and projected on a 3D terrain. For each of the cell, we take care to determine if the cell position is underwater, or under an object such as a rock or a building. In which case, we disable that cell and it can no longer catch fire. We wouldn’t want to have fire propagating under rock, would we?<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/2DGridDisabled.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/2DGridDisabled.jpg 512w, https://jflevesque.com/wp-content/uploads/2020/01/2DGridDisabled-300x220.jpg 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>2D grid projected on a terrain. The cells under the rock are disabled.</figcaption></figure></div>



<p><strong><em>Objects</em></strong><br>For objects, it’s a little bit more complicated. First, we create an&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Bounding_volume">AABB</a>&nbsp;that entirely surrounds the object. &nbsp;Second, we somehow&nbsp;need to detect the shape of that object. After all, it could be a chair, an oil barrel or a whole house for all we know. To accomplish that, the &nbsp;bounding box is divided in equally spaced cubes.&nbsp;The size of each cube depends of the object size, the number of fire emitter we want to have, performance, memory, etc.</p>



<p>An iterative algorithm then go through all those cubes and test their location against the collision shape of the object.&nbsp;If the test return a positive result, this cube is kept, otherwise it is discarded. At the end, we have a collection of cubes that approximately&nbsp;represent the shape of the object to be burned. That’s our propagation grid.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/3DGrid.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/3DGrid.jpg 800w, https://jflevesque.com/wp-content/uploads/2020/01/3DGrid-300x183.jpg 300w, https://jflevesque.com/wp-content/uploads/2020/01/3DGrid-768x469.jpg 768w" sizes="(max-width: 800px) 100vw, 800px"><figcaption>Detection of the shape of an object</figcaption></figure></div>



<h2><strong>WIND EFFECT</strong></h2>



<p>The wind is an important disruptive factor for a wildfire and it adds a great layer of realism for the player. &nbsp;Here it could be tempting to&nbsp;over-think&nbsp;the design and go with a very complicated system. After all, it’s an active area of research and&nbsp;<a href="http://web.archive.org/web/20160114121147/http://www.sciencedirect.com/science/article/pii/S1540748912001988">several</a>&nbsp;<a href="http://web.archive.org/web/20160114121147/http://www.sciencedirect.com/science/article/pii/S0378475407002030">papers</a>&nbsp;on the subject are available online.</p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/1-s2.0-S0378475407002030-gr3-300x235-1.jpg" alt=""></figure></div>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/1-s2.0-S1540748912001988-gr3.jpg" alt=""></figure></div>



<p>Luckily, with what have been explained thus far, it’s quite easy to simulate if we accept to cut corners a bit.</p>



<p>In our system, the fire propagates by damaging the&nbsp;neighbor&nbsp;cells on a grid. And it is generally accepted that a fire should spread faster in the direction of the wind than against&nbsp;the wind? Then, with that in mind, we can create a rule where a burning cell deals more damage to its&nbsp;neighbor&nbsp;cells if that neighbor is in the direction of the wind.</p>



<p>We do that by getting the&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Dot_product">dot product</a>&nbsp;between the wind direction&nbsp;vector and the direction of the&nbsp;neighbor&nbsp;cell to damage.&nbsp;If the result is greater than zero, then that node is dealt greater damage. &nbsp;Likewise, if the result is negative, &nbsp;the node is against the wind and should be dealt less damage. To be fancy, the amount of damage is interpolated with the dot product result as shown in the picture below.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/ACellWindEffect1.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/ACellWindEffect1.jpg 600w, https://jflevesque.com/wp-content/uploads/2020/01/ACellWindEffect1-300x206.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"><figcaption>The cell on fire causes more damage to its neighbor cells if they are in the direction of the wind.</figcaption></figure></div>



<p>With that rule alone, you will get a nice bell shaped fire front that propagates in the direction of the wind. Simple, yet believable&nbsp;enough to get the player’s stamp of approval.</p>



<p>It’s worth noting that we simulate gravity the exact same way.</p>



<h2>PROPAGATING TO THINGS AROUND AND CHAIN REACTIONS</h2>



<p>When a cell burns, it sends a “I’m on fire and I burn this much in this radius” message down&nbsp;the game event pipeline. This event is caught by objects, AI and other game systems that are in that area. They react&nbsp;to this message their own specific ways. The AI freaks out, the flammable objects get damaged and eventually catch fire. And, &nbsp;it is also true for dynamic objects. &nbsp;For example, if a burning oil barrel goes flying through the map, every step of the way, &nbsp;it will send that “i’m burning” message and a lot of things around might hear it.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/2DGridDmgZone.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/2DGridDmgZone.jpg 719w, https://jflevesque.com/wp-content/uploads/2020/01/2DGridDmgZone-300x284.jpg 300w" sizes="(max-width: 719px) 100vw, 719px"><figcaption>In the absence of wind, a cell on fire damages equally all its neighbors.</figcaption></figure></div>







<p>This causes a chain reaction effect where trees, explosive items, &nbsp;objects and patches of grass set each others on fire. &nbsp;It’s completely&nbsp;systemic and it makes it much more believable. It &nbsp;also scores pretty high on the&nbsp;player’s&nbsp;fun meter because it behaves as one would expect, yet as real fire, it sometimes gets totally out of control.</p>



<h2>OPTIMISATION</h2>



<p><strong>The Hair Transplant Strategy</strong></p>



<p>In an ideal world, we would have access to enough memory to hold&nbsp;an infinite number of particle emitters and we could display an infinite number of particles on screen.&nbsp;Unfortunately, the reality is that those numbers are actually pretty low.</p>



<p>To do more with less, we have to put our emitters where it really counts. Enters the hair transplant strategy! &nbsp;In Far Cry 2, the fire emitters are constantly being teleported around, most importantly, from the back of the camera to the front. The player’s point of view is monitored at all time and emitters that are burning out of sight are moved to a better location where they are also needed.</p>



<p>In addition, the emitters’s density is higher in close proximity of the player and lower as the distance increases. A kind of fire&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Level_of_detail">LOD&nbsp;</a>if you will.&nbsp;If things are getting bad and we still need more emitters but none are available, we increase the particle sizes to give them more volume and fill more space on screen.</p>



<p>With this strategy, and some others, we can simulate a wildfire that is several meters wide with a relatively low number of particle emitters.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/farc2.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/farc2.jpg 600w, https://jflevesque.com/wp-content/uploads/2020/01/farc2-300x169.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"><figcaption>Credits: http://www.rockpapershotgun.com</figcaption></figure></div>



<p><strong>Event Pipeline</strong><br>Since the described system tried to avoid all complicated maths, generally speaking we will be GPU bound before being&nbsp;CPU bound.</p>



<p>That being said, the event pipeline could be a bottleneck. It works well when you have just a few cells on fire. But, it’s another story when you have thousands of them burning and&nbsp;advertising&nbsp;their state to the world. That will likely clog your CPU’s arteries.</p>



<p>The trick for me was to regroup the cells that were burning into&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Axis-aligned_bounding_box#Axis-aligned_minimum_bounding_box" target="_blank" rel="noreferrer noopener">AABB</a>&nbsp;groups. These groups would constantly merge, split and&nbsp;change shape to follow the evolution of the fire. The events would then be sent per AABB instead of per cell, which saves&nbsp;a significant amount of processing power. Additionally, the events would be spread out across several frames in order to distribute the load and avoid framerate spikes.</p>



<p><strong>Keeping things under control.</strong><br>In your game, if you don’t constrain the propagation somehow, it will either</p>



<ul><li>Burn the entire map and kill all the NPCs</li><li>Fill out the …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/">https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/</a></em></p>]]>
            </description>
            <link>https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25437800</guid>
            <pubDate>Wed, 16 Dec 2020 01:13:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Statistical Analysis of Speedrunner's RNG proves game “was modified” [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25437663">thread link</a>) | @linksbro
<br/>
December 15, 2020 | https://mcspeedrun.com/dream.pdf | <a href="https://web.archive.org/web/*/https://mcspeedrun.com/dream.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>] &gt;&gt;
stream
xœcbdàg`b`8	$¸ÚA¬| ÁùH0½ŒE0BÁHˆ±	ö !U$\k˜ý8@ÚG‰!K°-hŒt$ç
´F	ºé¸
endstream
endobj
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      
323 0 obj
&lt;&lt; /Names 320 0 R /OpenAction 334 0 R /PageMode /UseOutlines /Pages 610 0 R /Type /Catalog &gt;&gt;
endobj
324 0 obj
&lt;&lt; /Type /ObjStm /Length 2183 /Filter /FlateDecode /N 90 /First 801 &gt;&gt;
stream
xœÕZÛnÇ}ÏWô£ý�Þ®êª¾Ž],Y€á(¤8ò@Ñ›˜‰Ä%¨¥%ý}ÎrWKj%îî1Ý³55gª«OUuwÎRÈÙÿç¤ñZƒjÃµ-×L f)¸\%Ô$¸jhÆ~½u\-ˆP‘ym”€FSC£ñJ-H&gt;Ôñ2j÷4	^çT
ô¸ÍBL9¨&lt;î$ÃZíÂÇñ—Š¢*lt~J¹$*ÅãPJÁã”kÔÃŸ;5ãßøÙÔy§³D™Ì©¾´`uÐC´
eøO4:.ÊªÏü
tÜ¨¾Zð’xÇƒWB¨%xK€P+0I®
�Íµï4TƒæN¨0_InŠ† ·ŒFeÃB~;Vá�ŠrHZEcnhp00%+?7¡AÍš-ñ4›ñ4{çh®|¼Cs§ýzÁXSs¯6à�†5÷ªâŽ¥ªÁ)rÕ€×€»ºÂ�xM¥é,Î;jK†æ&gt;&lt;Í}xª…&amp;
§šÂHôº†QACBs˜Ö0À­r@$‡ÖáHí]Õ0®=ãÍ†»�®g°QçW¦;ß%=ôš9Ô)Ì�*l
Ã¯h	^e¸/I½ÿá›oÂìIø&lt;«`¢…ÙÓ³eøg˜‡Ù³ÅËExð`y¼x½¸&lt;¾89�ãÙÉoß/Ÿ/O–¼e7/Î—�òO3Üe­nåxãu‡®µ–ïó¡óàA˜½8Y.ç—çtÔk�—‹Óãùg/ž&lt;
³—ó÷„wƒêðŸþþs&nbsp;£W•Ø0Î¯^¿þ¢(Žv[ìa¸þêâäråëMC„Ù£Åå/óKhJø'4Óctdè¢ó]˜=³£ù)ñŠ•·†K¶HwÐl‘þZ¬GÇøÓÆW¯–.æaöýÙùñmCûáùùbù	œ·Pz¶8Ÿ‘”Ø0¡T$ªsb•˜ŠˆH'@äÝ"¦ŸJŽàN�€EÁ´=PžP•(˜S&nbsp;ÛX€Ä›F8ð~€šÄ<p¡š“^£ f¹µh="">9Ì&gt;6"±ØE³GE,ÀŽÝujŸ‘u�ü¦&amp;1�:&gt;”ü²)È¼E†zÌ~p!Âkdü:Ì@e
DWÄ0Õ3C€ÕX}_Ÿ^!ªS µbrR+�þàT{"ºzµ5Ž‹DG¦‡H+â=I�0sl}oCmÂE7°�ÞÄ!³3�L‘‹Ä2k”£¯`Õ3ÓËêpøk˜ª‡rw›À­�9ƒ‹|à&amp;òÝÂÜÁ†j“¸Š‡8ˆ¶m)²7…o‚šÄ©rX2çS¿‰2f¬Iœ
)ÜP–ð~Ó(k�Šz+X©GAêªZ‡3+|Ýö¶Ö
¦&gt;�¯k¹ ™$"Bí€vê“¸º‚Èœ9Á»®•ÈÒpª)|yJ„}p-`(¢´ÈÚh¬)|]]"²€®PjA4,£¬5…¯£ÆŽ¬±5ÓÇ¤=E—QÖ•æ­`ÁÑ-ó
6%Jð`Ý;ïÜD5*·Z¡âØUÜŽÚ]ÁñûŽà�zN‘›KÃ¬3¦ž†~AÕ�cÝ?þ­
Î4$±°ÀS�\“š�4ŒÈ]$MBT‚Z\8n¸xÈÚˆèXS0•°ªb�³¥Þ3ÚþKÀuÚ8›5Ð¥keÉG›¡àB=�ø&lt;¤Y£Á�²Ü
œ°¸!×£&gt;E8œõ	,7ŠéWà�±s5W{‰ž`Ó0ÜNÌ)–‚*üžä.0“´ÐZ,²¯ÿŸ\\ÌÏ9{N²ð]a¢Ô"W‹ªQ·
èÑÕDŽ¥rËI˜ùqmz&lt;—
ØìÎ¡c6£‘ö;Ú{—Šk»¹-\VA†²êYðœnzË½®ãJØqwSÐà.˜Þ¥+ˆ²l[ò
÷,øný6¿_.'Ø¾M¡ïòÖz€J]¶EvÑvW*;½{IrVÞ&gt;;}Ç])Œ8pÛˆÝ•ÌH_È–ŸJjº-i\z�mÖQÝã])GÁÀ³Ïì|÷¯Åb‰Ù5V³&nbsp;6Å,auR¸á†Ä¶°�ê¤ú¾ùöGLc¢©»¥I©,Q@2vU/ªqî6®{=]÷:z«Ý$n§y®«žq—rµít{Štå«ÚººÅŸ£«ÑVØüîñë;a†×&lt;™ÿvv:?zöˆ^±¼¼š¾ôòòäü-Ê”ùùé‡Õ&nbsp;?»\\]üîƒ~�)fÏßœü{þ˜þûÓ__ý‡®NÏßHh+UŸcÞ/Å£MAÔ]Ë°Sï’ÛhëlÆÛÛ¶šÖÌñ·Dv�Ð’gî·Ç‚„|´InaÚù!;M�-d;¦:ÈM‡2ÝÝbâé$á0”�<jr(ÿ�yiÈÜõdä(ñÏ‡Êä"dkû–z1�z�bŠçÎÃ(- kul1ãÁeb^ö­ð="">b³ü“+â¤b5â#Ïì4‰Ò»Jä¾—�áÇ£çk�¡Ä»¾õÕ¯ËåÅÛ?ÍfïÞ½‹WË«Wóxºx3{w²&lt;ýõ/¿ýùoßêÕQùù�?œþøõ&gt;�Mù4Ô#Í�ÎcM%*O”8˜¹�(·uö]IþhÖ1ûƒf0#—½GƒâN¥sçfî}GL×:‡% b&lt;+µÖÉSQ¶þ�¡lý\‡kçõû:Ÿ[Ó\¦âºG-«·k¢–UZóù„‡Ï¬&gt;™dOî7%yÜÄÀ&amp;Vz¼/ñWÔÙ™§ÅPŠeø^³q|Œbãê­#ótk”V÷ZŸ1�ßŸÚâû‡}Þ#¦1OÎð\¦1÷…†i�wü„¦Ì&amp;ÉîÓâÿÉõo×œ_rýMIžýŽ‚"@pa÷^w³7Èã5ó¦!bÚ°G8œåu×…ÚOëámßú?Æ¾nT
endstream
endobj
325 0 obj
&lt;&lt; /Filter /FlateDecode /S 384 /Length 407 &gt;&gt;
stream
xœc```b`ÞÏÀÌÀÀbÇ È`6+™XXfnhsa9´ìcÜáiÜ,™~6ïQ8˜ÀÀ&nbsp;&gt;EtWØ2¶”fÇkD/ðµPœÀpá÷KÖmEŽI&amp;P\Á8-xÆæf¥£;u[¢%=–ežjPôÍ~ÐÚ’j%-y“›9¡µÅ·gÂ²mFN®)†l³üÐ³Ü9^êy�ÓÊœU+©_ÏkšDý[€b@YÓS^dÇÏsäZºñ‚éï'«b–;GŸPyáUbúqí‚ÖVßâ·,Ú5/-Û××$ê�¼PóÂõë50Ö5&nbsp;Ž
S^G=¿åªÛ×r6û±ÍûIN+{K”5/\ÛoýdÂªhYŽS%¦[ÏýTÑÜ0IäP�UðÂµ}?U´d«´®ÜP$¶Ì’;X†² †¯«J%�æbypà10002ÈŸ�ÄÆ%ÅäÂ={{
›®h€¨¼®°t›æFõ�¬A2*qÚ§,Ó´“çD}«×�îŸZ›ÉÑË÷L$d¢L³
endstream
endobj
326 0 obj
&lt;&lt; /Contents 327 0 R /MediaBox [ 0 0 612 792 ] /Parent 527 0 R /Resources 335 0 R /Type /Page &gt;&gt;
endobj
327 0 obj
&lt;&lt; /Filter /FlateDecode /Length 296 &gt;&gt;
stream
xœ…‘OK1ÅïýsLÀ¤™ÉŸM<j­(ˆ¢ëi=l»i»ÐnËîvðÛ›mŠp ^f&Ã¼ïkpp7qÿô›r2�»�xhbk \!jã-8mc€²†w6ëbµãb£f÷íwì‡f]="" Í¾w†½Äþ¸zþy="">Lç…‚DÖÒHZK¯ä¥÷&gt;Óž&gt;”vË¦Ú&amp;9¹$?pAÛóTºa\lÁÉ³ï&lt;›˜/›6.»j5äçkÖÅXwÇ¶mÚu&gt;/¹'6ú=ù	^çNáœ’ˆ”Ü(ðœíù¸Ø6ý&amp;Ö×\&nbsp;2�Íâ2î±ãÂ’eˆWy EjD‚‘…r rÊÌx;ÔÕp&amp;X•ÙÄþ�üþÀt®	B2Hîd¥2„	$5�éx¡¸-'?&gt;ÃsÌ
endstream
endobj
328 0 obj
&lt;&lt; /Filter /FlateDecode /Length1 726 /Length2 7542 /Length3 0 /Length 8143 &gt;&gt;
stream
xœmuePœY´-<xp§qohÜ‚[cÁ‚5ÐhãÜ!¸kwîÁ!ÜÝ%ì23wæÖ«zõýÙ²v�µ×yu>zjY˜«¦—#Är
4d54@\œœN 7:=½”3ÄÔê“6u…t 
ˆ#Äx�€ÐéRŽ^ÎP+kW“9óßE€¶�©ÔêÐv°sp‡š[DÜÝÝÅÝ]Ü€În¢À—!
àj
XBí ©wªz`9“œŠ@ƒ8›ÚTÝÌì&nbsp;æ%¨9æaX:8ìþIæ0è_œ\€€¹Cœ]_ˆY:;Ø”e4%dß©hd¤84¥¦0€’üË8ÌÕEè
1wqùk;6€ë‘�é‘ÙÑ]gÏ" :°€š»Ì VP:Ç_º�a–¾ÊnŽÿ¶^¹¼ð0½hÈ°€X¾&nbsp;ÝììTLí!&amp;){G7Wˆ3@ÙÁâh˜Â\^q†Zþ5µ‡ÚyýÁÿ‹»š¾ˆ!³z‘�óŸÔEê	±P…º¾èmij÷¢ÓßuÈ?—£±€ºÙÿ3yååZ-`v^ÿ{äË.È¡"%¥#­ÉúŸþnËÀÌ,&nbsp;0+€†ë‹&nbsp;¦Îÿþn«šBÿ±Ð¿dþµô¹²©«3Ô`À	üË#œ}ÿFFÿ‡’”tðôf	òØ¹¹@//@@�×÷ÿ¡kîæì�¹þ­úË.ÿæ»	ñ„˜£/Ì9˜‡Ø¤5„•øÉL”"±NŒ™h±Î�àþè85xíµ¶x¿uLz¡Išë�A1hövíh|QOcÁØ�¦Ž0š#½ýB[jåW±üG-ï®:ÂøQ›ÄÞ\ñ4òÜ5ã×B�*Ë(OVÎA…‚Ó×·oä@Ñ&amp;Å-]H8+ñóÓW09f#FÜLý'Èk9Î„uhþ‰™ØíúBxnðÆ)=É{ëü’@Ç­p½K^¦&amp;Áy·=-†×'ï¦Nd{Ç±ëí~“ÌàV�g¨BQ¦ãéñGž?©Cb#ffJ¯a5Ê­ê¾#ÅW\§Kxîò´íˆöË8çA^ß´xá„ÆŠ~ŸÜž{¿6í®t\Å	"ñÒÿ)HÜ1**Ò;™Ø»|6¤Â.çÇÏ?¿pNGïw:Éÿ.‘Ë¸ÑÓ*‰]Iàq·Î4ò~‡³¿Ì&gt;\{V½&amp;wœç²Óäö�í±‹paŠ�ˆ˜óÙÁu�¾æðJºnÅlÔIeÞ’_&nbsp;‹ÉÛ"?9H¸Fö&gt;fÿü,îÔñ«&amp;¨¾Á¶GÄž_‘”“�x—±YÆù­?VìÓÓCÐG¯;ÿg°×�xy vÇá­¤¥^««/’ýVÔ@„Ú¨¬h¶y?7-1¯ÅªQßsœ$#bq˜XÍÇ¬‹I<cøØÁ»š5Èx‹(ÝÄ>µòa„õÏ­¤Ì¸Ö[â��û
#J}©ö.+5#ùô¥»”&gt;vÎ<tÊºveûÞ“ž;í^bÊ±“àçb©aÄý;Üñv›…_súÞiîbÚ_7Õ§[Ÿ· 0¸öÇf="" %“aŠ˜ô}üa¸ž˜6wgÇ¿%?×ÅÁ="">Þù»·_.vŽU‡"6%îú7ª‘ñšÄ¹-N*ÅÆ¢ÇØ£'ÅCZ‘�;¤Ó¤Øu)=r¬öðŽ�ã�GÔÍB€v&lt;¡„Q�&nbsp;LÖ¦þx¶Í6C„Ö1¥€)ASºQˆA˜±»Õuˆ¥«Hü�·&amp;i¼T®Ù¸È!+˜êVÎäöWÞ» Ø…Ê.ÐšßÛ\ïL+º05³n®X×ìÛœ•=Võ¨­±Ö1ÐPSKjY².Ôëj™‚H)2žïgŒ£�Šá;\íFÿw_?LÇ�ôKÙËè¤’Ø2‘Žmtíý„„ô°8êí-àŽÊU$­�gxí¸µü„Mšóü²ý$�•cÄ¾ÓÕ½‘h®AÚŸpžº»kÛ\À)æn¾(º:BK oÏ4�½H@�É?OO-÷ójtUÂîN{Ü4¶Ê�t?”L}´’¬L@@j`è¨¤Û¨#–q®CJÊË=¼z-0³˜^g\HR•¦¤Oü+:*æFå=Z«õ6�MÅÌÒÓfîƒŒ6ê¹.aw&amp;c‡aÔŠcâëvò6cñ©P`ôÂ·Vþ_6N1c†&amp;sy¯ÜßxŽÞª
-²ÝSª3�t8Áq0$w©­|²Þþ%§ì)æ{&amp;¸×Ò_ò÷\Ï&nbsp;!»RÎlHf
loIs‹Œ´áfìÝv]µoçêÀ$èä´	Zõé•(+o,¤ŸYâ&nbsp;«äò§·×Þ³¡�üa7é6÷oM&lt;ô:Â–ah›/ÓûÖ&lt;å˜*&nbsp;nK²uDÄ'd·F•F&gt;›“�,fM”¿y šßL;Aìì›€›öîO´Õcb&nbsp;ã‘Í’ÿî£ÛÅ#–´Ü™¹©µe/uªaYÁÅah³ŸŸ÷ô$Èb”}]"Äã&nbsp;1M?]HÿDÌdO}…€€124—R‡ÔÂMP¹"°?W¾UÚüEƒ×à²êC~ÃC3µ�È^›åžêþz(˜u:àü´`M&lt;ÐÖ¥œQäÜ‰çŠCŒ:ÛCæ[àÉ®ªV‘Å5ÕL
î�y:ž2\?X´0oJ€_Ö„�«º”þNæk¹;\
Ý¼êTûèGî°�¢&amp;·Šf•¿6ŸÜmUC]�¥ÀN´Á°~H¤Ç\`òç”/Ç^
T&amp;
n@Á5ó«i#I8&nbsp;k˜È½vk£ôÞlx¯•âÞ¡ä�O€+µ�:l¨Y~³	ŽøY	½À²ðä…›Jøúv¶E¶¤—æ¼�Rô€ô\ûHý|šíž ©üÀ#e?âT„†Z38¬–ª"•¡i²AÍðÉH£¶m©Sc�@y«£iŠ®|•FiöIè'tk¸úFËæ*ðêCüÇëþÈ?°ny±€"›/þ8QˆºUÀ•ÁÉ±š6MñÜ*Ê£ður,
ŠÂ¥‰¶�é“H®w5KÃ#'MhGÈ–zÒÝx´ƒ3�eê[æoçÂýÅ±Í€L#âOáZ¨ì£+õŒ`™7Éi£™í%›»}Ÿøº×ø½–,1Ÿ£°�+ê@qË™„òÂ‡pÔ~Œð£½™OM?â„ŽìÛ\^™�AÇÆgZï4¦kTl6m•ar=]GlHá‹"NKä˜„8dRI
’áwFkâß‘·é³'Ž~T_QLÓu-í}l—úárAÍ›P°)H”»&nbsp;ö�›Q8ªp*þÝ%è.&amp;_/õÄgÙzå1áý*~â&amp;¼ˆƒJå0ù¢&amp;÷{$uÚ×¯O¥Þ‚t›D0mcQßx:8ª3s;)r"R›2[ÔÂS‡d]Hš~1anÌ¦Z|'77&amp;_6ÿó&gt;ãœIý&gt;ãƒÉšjLÚîx”·ë#�èë{‘rz/Å•„g¹yÆPèLŠæ¨Ò—�n3ìAoÅ‘n³­‹¿·�•ÃÐTþö&lt;Ùˆ9ÛØ"R¸Í¤óp¦~|®È&gt;#»qÜûå®ôIiB°&lt;tvŠ
åòK&nbsp;aû²ÐDH3ã¿
±¥—ãŒóÏÖå¬Â²q‡û¶²·&gt;?¼·úyt?i­!Çÿ¦Ðwÿ“uŒ¶Ã¬ÕýU%ïÛˆ.hæòÎg¸4ñ1\º	ŸnºÕS£?xMª%Š\7öTeOÁð±õxÕêxZa³à1ø&amp;7gƒ
Ê•¹é&gt;Òãÿ×ãÛ½é§fê0&gt;¤ýíínÑ;«{n&gt;•—y¸é»�B|E
çg·îïä®A\Á…&amp;i~”Ó¿@Ôù®,Lþ­´6�ÂA_kš��wRSþö€M«&lt;‘êaÚž¦1	@^Üôƒª£$WÐú#zzÝ!»…5Ö§ˆS^&nbsp;u°Azù\ö$%–ì¿,ÊåéZ_Ö¶lc(ûÆÀ1i‡zWº)Ú^�Ì¼ÅOwÁvLð‰š:67€~¯ì=BÄ	�Àv[5
r&nbsp;OÎ(ø¢'`$û-XÌXprX·µÑÃ¸!_Fé¸è¡Æt¶øàçþÑ†áàj|uÇD[9��÷x™Ã[]P±ÿ”ˆÉÝ÷ ¡°="=·Œ©„”Ž*S¬©‡-7=ÂCR¬B±_ÃÇ
{)	}d1¨©r�¥:£­¡(cB:è§Vûh3,KŒ·É"¶{ôúõ¯�Íj‹$Óƒ &lt;Žõçåá_�Lñ„K¹&amp;ì²ŽúÙõ4*ÈèïÃã÷Þ#€Š=&gt;EUy¹±r¿·)÷ßûy¬On§³Ya×n]ý“à4ä•qyD±‡5_5Tµ2Iß…/x*&nbsp;øO
¨ÅÚŠ²nn‡ãÕ¾~‰ïÖà&amp;Âÿ!Ãÿ&nbsp;´b…°`.ófH#�bêÌ
ä¼ë`°ðFøYðö¶¬gÕ€¸5Œ™è³Wãà ³¦&gt;¤5ÇÞ¬‘zïû£ÈW˜&gt;ËwmÅ¤
Z‡wœþÐ_íFŒYîb«m¼&amp;D!é…ÂÊ¯Ÿy&gt;›l5Õr6#ïÈW¼
ìc¡´÷;©âû-X:'CØ47Có¼Ï;m6"ÿØàõÝÃõ‘�kÇ‘ûìÄô'_ïaî,ªYô½˜?§•í’ç#ø‘Ù”wÌï£ª0o"ûsC²äR!Ä
1'ä2%�Øëzºt&nbsp;MI&lt;¥³*�ø
=%Ñt‹â{*¤8¦‹%Y«Ë¶¸€«€%¯&nbsp;Ä:®²˜êfQ–[‰ÑöË¸~žÑæ­A0»
YQˆzh�‚{õÔí%�ÌþšuåÈ«øêçæ:9›¥*Ñøšˆæºº.ª±™LÉ†ŽÍ\¸{í(ú¼ÔN!~V3²÷q¦ð­E™)ïB¹†Ñ2}½0Y�§sò*|â•uzU�Mô5WÉ(¸¿i’þ²‡6úZÎµÞN[ì�|Hz-™AôEÝ_DoÐrŠ·¶uºXl€NªÖ„›®ˆ
Ì1Åxl‰­K€ÿ±aÛ5£·{Ÿ[e+ÆpOð“GSåBñA6C¹ÝÑ„Å�9÷oaŽ•*|°{!]Á´áOÕQ*“A’¥#ÊQÝËê{ƒÀ¼ŸW+�^f~ƒÉ–+{á›vkaâêV"çèŒ™QÛzäÛÞì™a3A�5ÛºA‡\«gJ¹�ñ'Ys²ÌŠ%#w3‘È”L–	L½í_pÕEÉóMßÁ]JÆ�ÙùyÔN±|)FæƒÏì|§H�r)®Tý°^…¥:x¦]ƒÀ�ßEë˜Ý#qÇ÷v|?ö•`Êýþ…«åU¦ò¾¤L]r'
€*CQuì¥\U½àw§µ/­¥xÅÞ"n›&gt;ëMîX|úŽ™�ˆ¯‚Ï~\UÁõÑ
c3ôFÍ°^V°á5eN¶#/µ�!¯\FÀô¦uýVú°&nbsp;§å­3(`–I$Òð&nbsp;&amp;ÛÜ®òlj©ÌVúõç§³B­p¨�§™ŸßìÖØ™§p³÷†£‚%ë\»p�¸©î;\3!´Ú¾é
^£»~µR®Á•‹c°ÿò•@¡W&lt;5—nÿå45Þ„+×¯rg‰Aû1èý³J,¯aoÑ"ëAõŽ—óñä²;11eœfa=)¸÷�"kÝäñØ¹;¸pÄEÊÛ5·ÔŒ(ü¥BxÌ+_·¯K±LÀëÙhov)pòF��ÝË?*RvœŸÙ4in��î&amp;]…­\ÍÒÄ"˜í2s»¿ÿb	Lw,,p_"Å&nbsp;±ttà¬ðÍxÑ¬k)Ù�VÿìrÐT‹¬AÅ- ¥‰-yšäl–"½©ËýÛ,�’;åêtoÿ�WÖ¸Ô¶³µøõ%&amp;gIêôï™W÷3ö
IÌNY¥»3.»Zß•¼z.c’bt^ëûÕq$4+Ö¹¸ãî‚&amp;'Ñ
òbZ'lÔeWÑDà˜592V°ýœÑãtB_âšÉñrºùžØŸ:­À¤sñÎ†Ð¹~Ô/®ñà•pËêÝ“ÅŽ¢E—r¨£#VÛ
HfËW7ðOvçØõrk–µ¡a6.h§Šó´m‚Xð‹7â#úþi^+`{iÇ‚Ëur7
Î+µúÍ¯!ONeìåÀß+äˆ`m!7“ ë{1Þ²ž»‘-Ý�îûë§™»2Áî£lîê$äs†�ÇÄsù6ÏBÚiã�Î´C¶oOÒÀà/zà]Á¤½gÌ
ð1d[®
Û×D©If…ºŽ§ÇRèu7êv8_!ªS¯D(ªÌÉ.z×ìëÈUjñÚª30Ÿ&nbsp;¥¥©ÈaZˆ]V:C3bu¿ùìûÞ�|�Åsb­"úÓBÜÉ|&amp;7ì4äUBÑ€eŸ‚Ÿ…“ËÒ¬*ð‰@I�…</têºveûþ“ž;í^bê±“àçb©aäý;üñv›…_súþiîbú_7õ§[ÿ·></cøøá»š5èx‹(ýä></xp§qohü‚[cá‚5ðhãü!¸kwîá!üý%ì23wæö«zõýù²v�µ×yu></j­(ˆ¢ëi=l»i»ðnëîvðû›mšp></jr(ÿ�yièüõdä(ñï‡êä"dkû–z1�z�bšçîã(-></p¡š“^£></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mcspeedrun.com/dream.pdf">https://mcspeedrun.com/dream.pdf</a></em></p>]]>
            </description>
            <link>https://mcspeedrun.com/dream.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25437663</guid>
            <pubDate>Wed, 16 Dec 2020 00:57:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write code. Not too much. Mostly functions.]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25437527">thread link</a>) | @brundolf
<br/>
December 15, 2020 | https://www.brandonsmith.ninja/blog/write-code-not-too-much-mostly-functions | <a href="https://web.archive.org/web/*/https://www.brandonsmith.ninja/blog/write-code-not-too-much-mostly-functions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody">
      

      

      

      


      <p>There's a well-known quote by author <a href="https://en.wikipedia.org/wiki/Michael_Pollan">Michael Pollan</a>:
        "Eat food. Not too much. Mostly plants." I like it because it doesn't
        attempt to be dogmatic: it encapsulates some basic guiding principles that get
        you 90% of the way there 90% of the time. Wikipedia describes the book the quote
        is from (emphasis mine):</p>
      <blockquote>
        <p>He explains...the notion that nutritionism and, therefore, the whole Western
          framework through which we intellectualize the value of food <strong>is more a religious
and faddish devotion to the mythology of simple solutions than a convincing and
reliable conclusion of incontrovertible scientific research</strong>.</p>
      </blockquote>
      <p>That...sounds familiar.</p>
      <h2 id="write-code">Write code </h2>
      <p>Code, like food, has value. I think those of us who write it can (hopefully)
        agree on that. Some, though, are so afraid of writing/eating
        <em>too much</em> that they avoid writing/eating what they should.</p>
      <p>In the context of programming, I think this translates to an unhealthy fear
        (again, for some) of duplication. A little bit of duplication - writing
        something in a way that doesn't completely maximize conciseness - isn't the end
        of the world. Sometimes it's the best path forward. Sometimes it's okay to
        copy-and-modify here and there, especially when you're still figuring out what
        your application will end up being.</p>
      <h2 id="not-too-much">Not too much </h2>
      <p>Of course too much code, like too much food, can also be a bad thing. This is
        a well-trodden topic so I don't feel the need to go too far into it here.</p>
      <p>Just be aware of your project's "appetite": write what needs to be written,
        and then try not to over-indulge.</p>
      <h2 id="mostly-functions">Mostly functions </h2>
      <p>By "functions" here I mean "pure functions". You could make a case that pure
        functions aren't the "plants" of code, though I feel
        that they are. In my experience most codebases have a pure functional
        subset, and I believe writing that subset in a pure-functional style is nearly
        always a win for the long-term health of the project.</p>
      <p>Of course the qualifier is "mostly": this isn't a dogma. Writing a 100%
        functional system ("going vegan", if you will) often requires you to jump
        through a bunch of extra hoops to get all the functionality you need. Looking
        at it solely from the perspective of health, those extra complications may not
        be worth it.</p>
      <p>And then different projects have different needs: just as an athlete may need
        a larger percentage of protein, or individuals may have certain nutrient
        deficiencies, a project may only have a very small functional subset, or may not
        be able to afford to return new values each time due to data size or
        performance-sensitivity. There's nothing wrong with that.</p>
      <h2 id="%22real-code%22">"Real code" </h2>
      <p>Pollan later qualifies his snappy statement a bit further:</p>
      <blockquote>
        <p>He contends that most of what Americans now buy in supermarkets, fast food
          stores, and restaurants is not in fact food, and that a practical tip is to eat
          only those things that people of his grandmother's generation would have
          recognized as food.</p>
      </blockquote>
      <p>At the risk of stretching the analogy, maybe the equivalent is
        "code only those things that people at a junior level would recognize for what
        they do". Code in simple, straightforward terms. Don't get too clever,
        "manufacturing artificial ingredients". Use the primitives that are there, when
        possible. Write what is simple, and natural, and human.</p>


    </article></div>]]>
            </description>
            <link>https://www.brandonsmith.ninja/blog/write-code-not-too-much-mostly-functions</link>
            <guid isPermaLink="false">hacker-news-small-sites-25437527</guid>
            <pubDate>Wed, 16 Dec 2020 00:42:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I'm enrolling in Lambda School for web dev training and job placement]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25436727">thread link</a>) | @realtimclemans
<br/>
December 15, 2020 | https://realtimclemans.com/why-im-enrolling-in-lambda-schools-full-time-web-development-training/ | <a href="https://web.archive.org/web/*/https://realtimclemans.com/why-im-enrolling-in-lambda-schools-full-time-web-development-training/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-470" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
<div>

<div itemprop="text">
<p><strong>Update:</strong> Thanks to the feedback I received on Reddit I un-enrolled. “OK I sent&nbsp;<a rel="noreferrer noopener" href="https://realtimclemans.com/cdn-cgi/l/email-protection#a1e0d4d2d5c4cfe1cdc0ccc3c5c0d2c2c9cececd8fc2cecc" target="_blank"><span data-cfemail="5415212720313a1438353936303527373c3b3b387a373b39">[email&nbsp;protected]</span></a>&nbsp;and&nbsp;<a rel="noreferrer noopener" href="https://realtimclemans.com/cdn-cgi/l/email-protection#8cede8e1e5ffffe5e3e2ffcce0ede1eee8edffefe4e3e3e0a2efe3e1" target="_blank"><span data-cfemail="4f2e2b22263c3c2620213c0f232e222d2b2e3c2c27202023612c2022">[email&nbsp;protected]</span></a>&nbsp;“The outcomes data that sold me on Lambda turns out to be useless because of LS’ major changes. Please unenroll me. Thank you.”” in response to “<a href="https://www.reddit.com/user/technicaldebtgames/">technicaldebtgames</a>1 point·<a rel="noreferrer noopener" href="https://www.reddit.com/r/LambdaSchool/comments/kdxf3k/why_im_enrolling_in_lambda_schools_full_time_web/gg02qmm/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3" target="_blank">24 minutes ago</a></p>
<p>Jesus this is a… thing.</p>
<p>Listen, don’t go to LS. It’s a waste of money. If you think you will be working on team projects, you won’t. That was my assumption, too, but the truth is that you are too busy doing course busywork to work on actual projects, and when you finally DO work on a group project, 75% of your group is so unequipped to handle working on literally ANYTHING, that if you are experienced in ANY way, you will be holding everyone’s hand teaching them basic shit that the course should have taught them.</p>
<p>All I got for my time in LS was a github account that looked awful, with half-assed project repos clogging up everything. You will come out of it all and literally remove ALL of them, because they are THAT shameful.</p>
<p>Do not go to this school. Go literally anywhere else.</p>
<p>And in all honesty, if you actually HAVE some experience like your linkedin says, you should just work on your own stuff. Don’t get suckered into this place by slick marketing that sounds like they’re high-speed. They’re just a terrible version of a votech school, except every class will have 200 students and 1 instructor.</p>
<p>HARD PASS on LS. Take Udemy courses and network on slack/discord servers instead, and save yourself months of your life and 10k’s of $.”</p>
<p><strong>Original post: </strong>My mission is to solve the world’s most pressing problems using technology. I’m 30 and haven’t solved a single world pressing problem. So it’s time to stop wasting my time web surfing and go head to head with Bill Gates (put a computer on every desktop running Microsoft software and now reducing inequities and improving lives around the world), Elon Musk (Starlink fast worldwide satellite internet and electric transportation and solar energy generation and storage), John Krafcik (Waymo’s CEO eliminating fatal car crashes with already live self driving cars with no employees inside picking up paying public customers). So my game plan is to spend 15 hours a day starting 12/16/20 going to web development school (starts 1/11/21), reading software development and business books, creating highly profitable startups, writing well researched informative blog posts and daily journal blog posts about my journey, and applying to software development jobs at early stage product market fit companies.</p>
<figure><div>
<p><iframe title="Disappointing news about code bootcamps in 2020" width="1170" height="658" src="https://www.youtube.com/embed/oqnwwlQuh3U?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
</div></figure>
<p>I applied to every school I matched with on <a rel="noreferrer noopener" href="https://careerkarma.com/" data-type="URL" data-id="https://careerkarma.com" target="_blank">CareeerKarma</a> which I found about from <a rel="noreferrer noopener" href="https://techcrunch.com/" data-type="URL" data-id="https://techcrunch.com" target="_blank">TechCrunch</a>. I got so pissed off with failing a basic math/logic, verbal skills, and pattern recognition test and being told I needed a high credit score for income sharing agreements that I decided not to enroll in a school. Then I came across <a rel="noreferrer noopener" href="https://lambdaschool.com/" data-type="URL" data-id="https://lambdaschool.com" target="_blank">Lambda School</a> while surfing <a rel="noreferrer noopener" href="https://youtube.com/" data-type="URL" data-id="https://youtube.com" target="_blank">Youtube</a>. The video that pooped up on my homepage is “<a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=oqnwwlQuh3U&amp;ab_channel=CodeDripbyAaronJack" data-type="URL" target="_blank" data-id="https://www.youtube.com/watch?v=oqnwwlQuh3U&amp;ab_channel=CodeDripbyAaronJack">Disappointing news about code bootcamps in 2020.</a>” by <a rel="noreferrer noopener" href="https://www.youtube.com/channel/UCRLEADhMcb8WUdnQ5_Alk7g" data-type="URL" target="_blank" data-id="https://www.youtube.com/channel/UCRLEADhMcb8WUdnQ5_Alk7g">Aaron Jack</a>. I printed out and read the video’s source material, the article “<a rel="noreferrer noopener" href="https://nymag.com/intelligencer/2020/02/lambda-schools-job-placement-rate-is-lower-than-claimed.html" target="_blank" data-type="URL" data-id="https://nymag.com/intelligencer/2020/02/lambda-schools-job-placement-rate-is-lower-than-claimed.html">Lambda School’s Misleading Promises</a>” by <a rel="noreferrer noopener" href="https://vincentwoo.com/about/" target="_blank" data-type="URL" data-id="https://vincentwoo.com/about/">Vincent Woo</a>, founder of the successful site <a rel="noreferrer noopener" href="https://coderpad.io/" target="_blank" data-type="URL">CodePad.io</a>, and <a rel="noreferrer noopener" href="https://news.ycombinator.com/item?id=22366474" target="_blank" data-type="URL" data-id="https://news.ycombinator.com/item?id=22366474">the Hacker News comments</a>. Then I went to <a rel="noreferrer noopener" href="https://lambdaschool.com/" target="_blank">Lambda School’s website</a> and downloaded their <a rel="noreferrer noopener" href="https://assets-global.website-files.com/5cd091cfb5499f22bdf72905/5fc95f2bb39ee0c8b064088b_Lambda%20School%20H2%202019%20Outcomes%20Report.pdf" data-type="URL" target="_blank">H2 2019 Outcomes report (PDF)</a>. The H2 2019 graduation rate of people who withdrew or graduated is 72% (439/609), 170 students withdrew. The job placement rate for job seeking H2 2019 web development graduates is 73% (181/247) with 66 unemployed when the report’s data was analyzed. 8% got jobs paying $100K+ year which is what I’m aiming for. The annual median salary of employed H2 2019 web development graduates is $60K. I’m convinced I have the work ethic to learn and code at a high skill level needed by small team high growth startups.</p>
<p>There’s absolutely no way I would do a loan even if I qualified for one and I’m not going to wait around trying to get a full tuition scholarship. I have zero interest in trying to go to a community college or university where I would have to take a ton of courses that I don’t need. And again would need a loan, pay up front, or get a scholarship. </p>
<p>While I do write code and learn on my own I don’t get the feedback or experience working in a team that I need. </p>
<p>Some unknowns: do placement rates include those hired as Lambda School TAs? <strong>Edit: </strong>they no longer have TAs “<a href="https://www.reddit.com/r/LambdaSchool/comments/kdxf3k/why_im_enrolling_in_lambda_schools_full_time_web/gfzwpma?utm_source=share&amp;utm_medium=web2x&amp;context=3" data-type="URL" data-id="https://www.reddit.com/r/LambdaSchool/comments/kdxf3k/why_im_enrolling_in_lambda_schools_full_time_web/gfzwpma?utm_source=share&amp;utm_medium=web2x&amp;context=3" target="_blank" rel="noreferrer noopener">To answer your question: no one is hired as a “TA” anymore, but when they existed they were not counted by LS as getting a job. (That would be absurd)</a>” </p>
</div>
</div>
</article></div>]]>
            </description>
            <link>https://realtimclemans.com/why-im-enrolling-in-lambda-schools-full-time-web-development-training/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25436727</guid>
            <pubDate>Tue, 15 Dec 2020 23:16:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fined: Umeå University Failed to Sufficiently Protect Sensitive Personal Data]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25435903">thread link</a>) | @infodocket
<br/>
December 15, 2020 | https://edpb.europa.eu/news/national-news/2020/university-failed-sufficiently-protect-sensitive-personal-data_en | <a href="https://web.archive.org/web/*/https://edpb.europa.eu/news/national-news/2020/university-failed-sufficiently-protect-sensitive-personal-data_en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Umeå University has processed special categories of personal data concerning sexual life and health through, amongst other, storage in a cloud service, without sufficiently protecting the data. The Swedish Data Protection Authority is therefore issuing a fine of SEK 550,000 against the university.</p>
<p>The Swedish Data Protection Authority has now completed an audit of Umeå University, concluding that the University has violated the General Data Protection Regulation by processing special categories of personal data without applying appropriate technical and organisational measures to protect the data.</p>
<p>A research group at the University had requested from the police preliminary investigation reports concerning cases of male rape and, upon receiving such reports, proceeded to scanning and storing them digitally. The reports contained information on, among other things, suspicion of crime, name, personal identity number and contact details, as well as sensitive data about sexual life and health.</p>
<p>The Swedish Data Protection Authority’s investigation shows that the research group stored over a hundred scanned preliminary investigation reports in an American cloud service, despite the University having informed via its intranet that special categories of data should not be stored in the cloud service in question.</p>
<p>— The cloud service and the way the university uses it does not provide sufficient protection for this type of personal data, says Linda Hamidi, who led the Swedish Data Protection Authority’s audit.</p>
<p>When the research group sent an e-mail to the police requesting further information, one of the scanned reports was attached as a reference, a practice that the research group later repeated despite the fact that the police pointed out the inappropriateness in sending sensitive material in unencrypted e-mails.</p>
<p>— These events show that the University has not taken necessary measures to ensure a level of security appropriate in relation to the risk.</p>
<p>The Swedish Data Protection Authority also criticises the University for failing to report the incident as a personal data breach. Since 25 May 2018, organisations are obliged to report personal data breaches to the Swedish Data Protection Authority.</p>
<p>— The controller is obliged to notify the DPA of data breaches and furthermore to present to us what has been done to mitigate the effects of the incident and to prevent similar incidents from happening in the future.</p>
<p>The overall assessment of concluded infringements led to the Swedish Data Protection Authority issuing an administrative fine of SEK 550,000 against the University.</p>
<p>To read the original press release in Swedish, click <a href="https://www.datainspektionen.se/nyheter/universitet-brast-i-skyddet-av-kansliga-personuppgifter/" target="_blank">here</a></p>
<p>For further information, please contact the Swedish SA: <a href="http://datainspektionen@datainspektionen.se/">datainspektionen@datainspektionen.se </a></p>

<p>The press release published here does not constitute official EDPB communication, nor an EDPB endorsement. This press release was originally published by the national supervisory authority and was published here at the request of the SA for information purposes. As the press release is represented here as it appeared on the SA's website or other channels of communication, the news item is only available in English or in the Member State's official language with a short introduction in English. Any questions regarding this press release should be directed to the supervisory authority concerned.</p>
</div></div></div></div>]]>
            </description>
            <link>https://edpb.europa.eu/news/national-news/2020/university-failed-sufficiently-protect-sensitive-personal-data_en</link>
            <guid isPermaLink="false">hacker-news-small-sites-25435903</guid>
            <pubDate>Tue, 15 Dec 2020 22:12:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Design Systems Are Bullsh*t]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25435669">thread link</a>) | @pascaljb
<br/>
December 15, 2020 | https://www.blogofpascal.com/post/design-systems-are-bullsh-t | <a href="https://web.archive.org/web/*/https://www.blogofpascal.com/post/design-systems-are-bullsh-t">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Addressing the Hype</h2><p>There’s no denying the design community has fallen <em>hard </em>for design systems. It’s graduated from popular trend to fully fledged movement. We’re at a point where you can apply for specific design systems jobs and statements like, “<a href="https://uxdesign.cc/everything-you-need-to-know-about-design-systems-54b109851969" target="_blank">in the future, every brand and every product will use a Design System</a>”, appear perfectly reasonable.</p><p>I feel the same way about design systems as I did about design thinking before Natasha Jen gave a talk in 2018 entitled, <a href="https://99u.adobe.com/videos/55967/natasha-jen-design-thinking-is-bullshit" target="_blank">Design Thinking Is Bullsh*t</a>. Namely, why is no one talking about the downsides? </p><p>It turns out that isn’t entirely true. In searching over 200 articles on Medium and other blogs online, I picked up on an undercurrent beneath all the praise that is beginning to check the design systems movement. But it still feels like the criticism has been nervously muted, unnecessarily qualified and caveated. In the name of critical thinking and a healthy debate, I believe it’s time to make the case in no uncertain terms that design systems are, in fact, bullshi*t.</p><h2>Defining Design Systems</h2><p>The root of the problem with design systems can be found in the definition. Here’s a simple description from a popular article on the subject:</p><blockquote>“A Design System is the single source of truth which groups all the elements that will allow the teams to design, realize and develop a product.”<br>~ <a href="https://uxdesign.cc/everything-you-need-to-know-about-design-systems-54b109851969" target="_blank">Everything you need to know about Design Systems</a></blockquote><p>It’s this attempt to take existing tools and practices, like style guides and patterns, and add other less tangible assets such as values and ways or working that, taken together, present a design system as a complete process from start to finish. This is a mistake. The very phrase “design <em>system</em>” should have alarm bells ringing.</p><p>In this quote from Brad Frost defining design systems, we can see further problematic thinking:</p><blockquote>“A kit of UI components without accompanying philosophy, principles, guidelines, processes, and documentation is like dumping a bunch of IKEA components on the floor and saying ‘Here, build a dresser!’ The guidelines and documentation accompanying the UI components serve as the instruction manual that come with the IKEA components to help the user properly and successfully build furniture.”<br>~ <a href="https://bradfrost.com/blog/link/design-systems/" target="_blank">Design Systems</a></blockquote><p>It’s a neat sounding analogy, but it’s like saying we need a design system so our customers know how to assemble their own app from our react components. It reveals the suggestion that anyone should be able to build a design regardless of expertise. It also surfaces the idea that while some designers (presumably a minority) will have the responsibility for creating the principles and processes, the others will be handed the design system Allen key and charged with the robotic, rote assembly. Hardly an inspiring vision.</p><h2>Design Systems Turn Design Into a Check Box</h2><blockquote>“In today’s world design has become this box that people just want to check off.”<br>~ <a href="https://99u.adobe.com/videos/55967/natasha-jen-design-thinking-is-bullshit" target="_blank">Natasha Jen: Design Thinking Is Bullsh*t</a></blockquote><p>There’s a fair amount of crossover in Jen’s critique of design thinking and the issues we can find with design systems. The biggest crossover is at the core of this idea that the design process should be simplified, sped up and accessible to non-designers.</p><p>By attempting to catalogue and rationalise everything, the result of the design system is to atomise and codify a designer’s process in a way that makes it appear understandable and, worryingly, actionable by anyone regardless of their design competence.</p><p>This devalues design and undermines designers.</p><blockquote>“You cannot hold design in high regard while relegating so much of it to a centrally controlled system.”<br>~ <a href="https://modus.medium.com/suburban-tract-housing-and-the-death-of-craftsmanship-a-critique-of-digital-design-systems-34c0fc1e106f" target="_blank">Design Systems Create Bad Designers</a></blockquote><p>We create systems to automate low-level tasks where the pursuit of efficiency is the driving objective. The underlying perspective in the thinking behind design systems, whether deliberate or not, is that design is in the way of more critical work.</p><h2>Design Systems Waste Time</h2><blockquote>“We’ve been developing the contribution model for the GOV.UK Design System for the best part of 2 years, and we’re not done yet. Not even close.”<br>~ <a href="https://amyhupe.co.uk/articles/the-myth-that-design-systems-solve-easy-problems/" target="_blank">The myth that design systems solve easy problems</a></blockquote><p>Design systems take a massive amount of time and effort to create, and require constant work to maintain, update and evolve. The bigger, the more comprehensive, a design system is, the harder it is to reference quickly and keep relevant. Time must be invested to not only update the system but communicate any changes across teams. The deeper you go down the design system rabbit hole, the more quick sand you lay out for your company to wade through in the future.</p><p>Once the design system is up and running, design is now entangled in development. Making changes to the design system will not be straightforward, potentially requiring sign off from people who may not share the same concerns as design. When design is fused with code, it slows down, and even discourages, changes to the product, as engineering is now needed to maintain and evolve the system. </p><p>Many product designers work for startups who undergo rebranding, product pivots and overhauls of their codebase on a dizzying frequency. I’ve worked at a startup that went through multiple rebrands and product pivots in its first three years. Why bother with a design system in this context? No one will thank you for wasting time on an internal product when you could have been working on the actual product, getting feature validation, finding product market fit or helping marketing and sales achieve broader business objectives.</p><p>It’s true that design systems allow you to go faster in one context — when you’re heading in the wrong direction. Once you finally have your design system ready to go, you can have that design request wrapped up before the day’s out. But by truncating the design process and placing too much emphasis on speed, design systems remove the space needed to question the assumptions behind a task, conceive of new possibilities, or even question if that new feature or screen is needed in the first place. </p><h2>Design Systems Don’t Work</h2><blockquote>“The challenge with any design system is they normally don’t work, don’t get adopted, don’t grow or get used if they are imposed top-down without an awful lot of consultation.”<br>~ <a href="https://markboulton.co.uk/journal/design-systems-in-difficult-places/" target="_blank">Design systems in difficult places</a></blockquote><p><a href="https://www.chromatic.com/blog/why-design-systems-are-a-single-point-of-failure/" target="_blank">Design systems are a single point of failure</a>, as they deliver the same components to multiple product and service touch points across an organisation. One bug or unintended error is now multiplied across every interface. Thanks to the nature of software development, a bug while easy to deploy is much harder to debug. The only solution for engineering is to invest even more effort in testing and maintenance.</p><p>The reality is that the only people who truly adopt design systems are the designers who create them. Design systems are the direct descendants of their equally tedious and ignored forefather, the corporate brand guidelines. In a fast-paced work environment, other team members will drop in and find just what they need in order to move on. They will assume that by any kind of lazy reference to the design system they are now good to go. That has serious consequences for communication and collaboration between teams.</p><h2>Design Systems Ignore Context</h2><blockquote>“Designers are trained and expected to make good decisions based on judgment… To bake this judgment into a system manifested through groupthink is submitting the individual designer’s expertise to an outside force.”<br>~ <a href="https://modus.medium.com/suburban-tract-housing-and-the-death-of-craftsmanship-a-critique-of-digital-design-systems-34c0fc1e106f" target="_blank">Design Systems Create Bad Designers</a></blockquote><p>A design system detracts from what should be any designer’s primary reference: context.</p><p>Now there’s a system, the pressure will be for designers to parse everything through its rules and piece together solutions from the available assets within the system. Coupled with the knowledge that the design system exists in order to sped up their work, contextual research and experimentation within those grey areas early on in the process will be squeezed under an excessively performance-focused culture.</p><p>The very objective of a system is to cover all bases. But this approach is destined to produce mediocre results within design, as any pre-defined system will always lack the critical context ingredient. Taking a component out of context, setting rules and a multitude of variables, creates the false illusion that this component can now be applied without reference to the new context. On top of this, by trying to systematically cover all eventualities the design system creates unnecessary bloat, documenting styles and components that may never even be needed.</p><p>The widely held opinion that a design system has to constantly evolve, is a recognition in itself that it will never be adequate enough to deal with the real world problems it faces. This is often presented as a caveat, but it illustrates flawed and misplaced thinking. If something is always in need of being updated whenever it is put into practice, how can it be relied upon?</p><h2>Design Systems Straitjacket Creativity and Kill Craft</h2><blockquote>“Design systems can make designers lazy, driving them to think only in terms of the components that are available in the design system.”<br>~ <a href="https://uxplanet.org/the-hidden-trap-in-design-systems-4540424f8c1" target="_blank">The Hidden Trap in Design Systems</a></blockquote><p>Design systems choose consistency and convenience over creativity and craft. When you overvalue consistency in the pursuit of uniformity, you create too many unnecessary rules that straitjackets creative thinking before it can even get going. When you overvalue convenience in the pursuit of speed, you kill the holistic working process necessary to develop a designer’s craft.</p><p>Design systems are well meaning, and no one can fault their ambition. But by dismembering the design process with prescriptive step-by-step rules, it restricts a designer’s freedom to work creatively.</p><p>One of the main reasons cited for implementing a design system is to achieve consistency. A slavish devotion to<a href="https://www.blogofpascal.com/post/consistency-the-killer" target="_blank"> consistency kills creative thinking</a>. Building a design system encourages designers to lose themselves in the details of components, while losing sight of larger product design issues. Users don’t care if every border-radius on your …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.blogofpascal.com/post/design-systems-are-bullsh-t">https://www.blogofpascal.com/post/design-systems-are-bullsh-t</a></em></p>]]>
            </description>
            <link>https://www.blogofpascal.com/post/design-systems-are-bullsh-t</link>
            <guid isPermaLink="false">hacker-news-small-sites-25435669</guid>
            <pubDate>Tue, 15 Dec 2020 21:50:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Photo of the first computer bug: A Moth (1947)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25435373">thread link</a>) | @samim
<br/>
December 15, 2020 | https://samim.io/p/2020-02-17-photo-of-first-computer-bug-a-moth-1947-via/ | <a href="https://web.archive.org/web/*/https://samim.io/p/2020-02-17-photo-of-first-computer-bug-a-moth-1947-via/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><b>Photo of the first "computer bug": A Moth </b>(1947)</p><div><figure>
    <img src="https://samim.io/static/upload/H96566k.jpg" alt="" data-mfp-src="https://samim.io/static/upload/H96566k.jpg">
        
</figure></div><blockquote><p><b><a href="https://en.wikipedia.org/wiki/Grace_Hopper#Anecdotes">Wikipedia</a>:</b> While Grace Hopper was working on a Mark II Computer at Harvard University in 1947, her associates discovered a moth that was stuck in a relay; the moth impeded the operation of the relay. While neither Hopper nor her crew mentioned the phrase "debugging" in their logs, the case was held as an instance of literal "debugging." For many years, the term bug had been in use in engineering. The remains of the moth can be found in the group's log book at the Smithsonian Institution's National Museum of American History in Washington, D.C.</p></blockquote><p><a href="https://samim.io/tag/Technology">#Technology</a> <a href="https://samim.io/tag/Narrative">#Narrative</a> <a href="https://samim.io/tag/Comedy">#Comedy</a> <br></p>
      </div></div>]]>
            </description>
            <link>https://samim.io/p/2020-02-17-photo-of-first-computer-bug-a-moth-1947-via/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25435373</guid>
            <pubDate>Tue, 15 Dec 2020 21:16:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I wish someone had told me about tensor computation libraries]]>
            </title>
            <description>
<![CDATA[
Score 293 | Comments 85 (<a href="https://news.ycombinator.com/item?id=25435028">thread link</a>) | @_eigenfoo
<br/>
December 15, 2020 | https://eigenfoo.xyz/tensor-computation-libraries/ | <a href="https://web.archive.org/web/*/https://eigenfoo.xyz/tensor-computation-libraries/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section itemprop="text">

<p>I get confused with tensor computation libraries (or computational graph libraries, or symbolic
algebra libraries, or whatever they’re marketing themselves as these days).</p>
<p>I was first introduced to PyTorch and TensorFlow and, having no other reference, thought they were
prototypical examples of tensor computation libraries. Then I learnt about Theano - an older and
less popular project, but different from PyTorch and TensorFlow and better in some meaningful ways.
This was followed by JAX, which seemed to be basically NumPy with more bells and whistles (although
I couldn’t articulate what exactly they were). Then came <a href="https://pymc-devs.medium.com/the-future-of-pymc3-or-theano-is-dead-long-live-theano-d8005f8a0e9b">the announcement by the PyMC developers
that Theano would have a new JAX
backend</a>.</p>
<p>Anyways, this confusion prompted a lot of research and eventually, this blog post.</p>
<p>Similar to <a href="https://eigenfoo.xyz/prob-prog-frameworks/">my previous post on the anatomy of probabilistic programming
frameworks</a>, I’ll first discuss tensor computation
libraries in general - what they are and how they can differ from one another. Then I’ll discuss
some libraries in detail, and finally offer an observation on the future of Theano in the context of
contemporary tensor computation libraries.</p>
<h2 id="dissecting-tensor-computation-libraries">Dissecting Tensor Computation Libraries</h2>
<p>First, a characterization: what do tensor computation libraries even do?</p>
<ol>
<li>They provide ways of specifying and building computational graphs,</li>
<li>They run the computation itself (duh), but also run “related” computations that either (a) <em>use
the computational graph</em>, or (b) operate <em>directly on the computational graph itself</em>,
<ul>
<li>The most salient example of the former is computing gradients via
<a href="https://arxiv.org/abs/1502.05767">autodifferentiation</a>,</li>
<li>A good example of the latter is optimizing the computation itself: think symbolic
simplifications (e.g. <code>xy/x = y</code>) or modifications for numerical stability (e.g. <a href="https://cs.stackexchange.com/q/68411"><code>log(1 + x)</code>
for small values of <code>x</code></a>).</li>
</ul>
</li>
<li>And they provide “best execution” for the computation: whether it’s changing the execution by JIT
(just-in-time) compiling it, by utilizing special hardware (GPUs/TPUs), by vectorizing the
computation, or in any other way.</li>
</ol>
<h3 id="tensor-computation-library---maybe-not-the-best-name">“Tensor Computation Library” - Maybe Not The Best Name</h3>
<p>As an aside: I realize that the name “tensor computation library” is too broad, and that the
characterization above precludes some libraries that might also justifiably be called “tensor
computation libraries”. Better names might be “graph computation library” (although that might get
mixed up with libraries like <a href="https://networkx.org/"><code>networkx</code></a>) or “computational graph management
library” or even “symbolic tensor algebra libraries”.</p>
<p>So for the avoidance of doubt, here is a list of libraries that this blog post is <em>not</em> about:</p>
<ul>
<li>NumPy and SciPy
<ul>
<li>These libraries don’t have a concept of a computational graph - they’re more like a toolbox of
functions, called from Python and executed in C or Fortran.</li>
<li>However, this might be a controversial distinction - as we’ll see later, JAX also doesn’t build
an explicit computational graph either, and I definitely want to include JAX as a “tensor
computation library”… <code>¯\_(ツ)_/¯</code></li>
</ul>
</li>
<li>Numba and Cython
<ul>
<li>These libraries provide best execution for code (and in fact some tensor computation libraries,
such as Theano, make good use them), but like NumPy and SciPy, they do not actually manage the
computational graph itself.</li>
</ul>
</li>
<li>Keras, Trax, Flax and PyTorch-Lightning
<ul>
<li>These libraries are high-level wrappers around tensor computation libraries - they basically
provide abstractions and a user-facing API to utilize tensor computation libraries in a
friendlier way.</li>
</ul>
</li>
</ul>
<h3 id="some-differences-between-tensor-computation-libraries">(Some) Differences Between Tensor Computation Libraries</h3>
<p>Anyways, back to tensor computation libraries.</p>
<p>All three aforementioned goals are ambitious undertakings with sophisticated solutions, so it
shouldn’t be surprising to learn that decisions in pursuit on goal can have implications for (or
even incur a trade-off with!) other goals. Here’s a list of common differences along all three axes:</p>
<ol>
<li>Tensor computation libraries can differ in how they represent the computational graph, and how it
is built.
<ul>
<li>Static or dynamic graphs: do we first define the graph completely and then inject data to run
(a.k.a. define-and-run), or is the graph defined on-the-fly via the actual forward computation
(a.k.a. define-by-run)?
<ul>
<li>TensorFlow 1.x was (in)famous for its static graphs, which made users feel like they were
“working with their computational graph through a keyhole”, especially when <a href="https://news.ycombinator.com/item?id=13429355">compared to
PyTorch’s dynamic graphs</a>.</li>
</ul>
</li>
<li>Lazy or eager execution: do we evaluate variables as soon as they are defined, or only when a
dependent variable is evaluated? Usually, tensor computation libraries either choose to support
dynamic graphs with eager execution, or static graphs with lazy execution - for example,
<a href="https://www.tensorflow.org/guide/eager">TensorFlow 2.0 supports both modes</a>.</li>
<li>Interestingly, some tensor computation libraries (e.g. <a href="https://thinc.ai/">Thinc</a>) don’t even
construct an explicit computational graph: they represent it as <a href="https://thinc.ai/docs/concept">chained higher-order
functions</a>.</li>
</ul>
</li>
<li>Tensor computation libraries can also differ in what they want to use the computational graph
<em>for</em> - for example, are we aiming to do things that basically amount to running the
computational graph in a “different mode”, or are we aiming to modify the computational graph
itself?
<ul>
<li>Almost all tensor computation libraries support autodifferentiation in some capacity (either
forward-mode, backward-mode, or both).</li>
<li>Obviously, how you represent the computational graph and what you want to use it for are very
related questions! For example, if you want to be able to represent aribtrary computation as a
graph, you’ll have to handle control flow like if-else statements or for-loops - this leads to
common gotchas with <a href="https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#%F0%9F%94%AA-Control-Flow">using Python for-loops in
JAX</a>
or needing to use <a href="https://discuss.pytorch.org/t/can-you-have-for-loops-in-the-forward-prop/68295"><code>torch.nn.ModuleList</code> in for-loops with
PyTorch</a>.</li>
<li>Some tensor computation libraries (e.g. <a href="https://github.com/Theano/Theano">Theano</a> and it’s
fork, <a href="https://theano-pymc.readthedocs.io/en/latest/index.html">Theano-PyMC</a>) aim to <a href="https://theano-pymc.readthedocs.io/en/latest/extending/optimization.html">optimize
the computational graph
itself</a>, for which an
<a href="#an-observation-on-static-graphs-and-theano">explicit graph is necessary</a>.</li>
</ul>
</li>
<li>Finally, tensor computation libraries can also differ in how they execute code.
<ul>
<li>All tensor computation libraries run on CPU, but the strength of GPU and TPU support is a major
differentiator among tensor computation libraries.</li>
<li>Another differentiator is how tensor computation libraries compile code to be executed on
hardware. For example, do they use JIT compilation or not? Do they use “vanilla” C or CUDA
compilers, or <a href="https://tensorflow.google.cn/xla">the XLA compiler for machine-learning specific
code</a>?</li>
</ul>
</li>
</ol>
<h2 id="a-zoo-of-tensor-computation-libraries">A Zoo of Tensor Computation Libraries</h2>
<p>Having outlined the basic similarities and differences of tensor computation libraries, I think
it’ll be helpful to go through several of the popular libraries as examples. I’ve tried to link to
the relevant documentation where possible.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup></p>
<h3 id="pytorch"><a href="https://pytorch.org/">PyTorch</a></h3>
<ol>
<li>How is the computational graph represented and built?
<ul>
<li>PyTorch dynamically builds (and eagerly evaluates) an explicit computational graph. For more
detail on how this is done, check out <a href="https://pytorch.org/docs/stable/notes/autograd.html">the PyTorch docs on autograd
mechanics</a>.</li>
<li>For more on how PyTorch computational graphs, see <a href="https://jdhao.github.io/2017/11/12/pytorch-computation-graph/"><code>jdhao</code>’s introductory blog post on
computational graphs in
PyTorch</a>.</li>
</ul>
</li>
<li>What is the computational graph used for?
<ul>
<li>To quote the <a href="https://pytorch.org/docs/stable/index.html">PyTorch docs</a>, “PyTorch is an
optimized tensor library for deep learning using GPUs and CPUs” - as such, the main focus is on
<a href="https://pytorch.org/docs/stable/notes/autograd.html">autodifferentiation</a>.</li>
</ul>
</li>
<li>How does the library ensure “best execution” for computation?
<ul>
<li>PyTorch has <a href="https://pytorch.org/docs/stable/notes/cuda.html">native GPU support</a> via CUDA.</li>
<li>PyTorch also has support for TPU through projects like
<a href="https://github.com/pytorch/xla">PyTorch/XLA</a> and
<a href="https://www.pytorchlightning.ai/">PyTorch-Lightning</a>.</li>
</ul>
</li>
</ol>
<h3 id="jax"><a href="https://jax.readthedocs.io/en/latest/">JAX</a></h3>
<ol>
<li>How is the computational graph represented and built?
<ul>
<li>Instead of building an explicit computational graph to compute gradients, JAX simply supplies a
<code>grad()</code> that returns the gradient function of any supplied function. As such, there is
technically no concept of a computational graph - only pure (i.e. stateless and
side-effect-free) functions and their gradients.</li>
<li>
<p><a href="https://sjmielke.com/jax-purify.htm">Sabrina Mielke summarizes the situation very well</a>:</p>
<blockquote>
<p>PyTorch builds up a graph as you compute the forward pass, and one call to <code>backward()</code> on
some “result” node then augments each intermediate node in the graph with the gradient of the
result node with respect to that intermediate node. JAX on the other hand makes you express
your computation as a Python function, and by transforming it with <code>grad()</code> gives you a
gradient function that you can evaluate like your computation function — but instead of the
output it gives you the gradient of the output with respect to (by default) the first
parameter that your function took as input.</p>
</blockquote>
</li>
</ul>
</li>
<li>What is the computational graph used for?
<ul>
<li>According to the <a href="https://jax.readthedocs.io/en/latest/notebooks/quickstart.html">JAX quickstart</a>,
JAX bills itself as “NumPy on the CPU, GPU, and TPU, with great automatic differentiation for
high-performance machine learning research”. Hence, its focus is heavily on
autodifferentiation.</li>
</ul>
</li>
<li>How does the library ensure “best execution” for computation?
<ul>
<li>
<p>This is best explained by quoting the <a href="https://jax.readthedocs.io/en/latest/notebooks/quickstart.html">JAX quickstart</a>:</p>
<blockquote>
<p>JAX uses XLA to compile and run your NumPy code on […] GPUs and TPUs. Compilation happens
under the hood by default, with library calls getting just-in-time compiled and executed. But
JAX even lets you just-in-time compile your own Python functions into XLA-optimized kernels
[…] Compilation and automatic differentiation can be composed arbitrarily […]</p>
</blockquote>
</li>
<li>
<p>For more detail on JAX’s four-function API (<code>grad</code>, <code>jit</code>, <code>vmap</code> and <code>pmap</code>), see
<a href="http://alexminnaar.com/2020/08/15/jax-overview.html">Alex Minaar’s overview of how JAX works</a>.</p>
</li>
</ul>
</li>
</ol>
<h3 id="theano"><a href="https://theano-pymc.readthedocs.io/en/latest/">Theano</a></h3>
<blockquote>
<p><strong>Note:</strong> the <a href="https://github.com/Theano/Theano">original Theano</a> (maintained by
<a href="https://mila.quebec/en/">MILA</a>) has been discontinued, and the PyMC developers have forked the
project: <a href="https://github.com/pymc-devs/Theano-PyMC">Theano-PyMC</a> (soon to be renamed Aesara). I’ll
discuss both the original and forked projects below.</p>
</blockquote>
<ol>
<li>How is the computational graph represented and built?
<ul>
<li>Theano statically builds (and lazily evaluates) an explicit computational graph.</li>
</ul>
</li>
<li>What is the computational graph used for?
<ul>
<li>Theano is unique among tensor computation libraries in that it places more emphasis on
reasoning about the computational graph itself. In other words, while Theano has <a href="https://theano-pymc.readthedocs.io/en/latest/library/gradient.html">strong
support for
autodifferentiation</a>,
running the computation and computing gradients isn’t the be-all and end-all: Theano has an
entire module for <a href="https://theano-pymc.readthedocs.io/en/latest/optimizations.html">optimizing the computational graph
itself</a>, and makes it fairly
straightforward to compile the …</li></ul></li></ol></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eigenfoo.xyz/tensor-computation-libraries/">https://eigenfoo.xyz/tensor-computation-libraries/</a></em></p>]]>
            </description>
            <link>https://eigenfoo.xyz/tensor-computation-libraries/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25435028</guid>
            <pubDate>Tue, 15 Dec 2020 20:46:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EU Resolution on Encryption]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25434793">thread link</a>) | @mickeyben
<br/>
December 15, 2020 | https://data.consilium.europa.eu/doc/document/ST-13084-2020-REV-1/en/pdf | <a href="https://web.archive.org/web/*/https://data.consilium.europa.eu/doc/document/ST-13084-2020-REV-1/en/pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">%PDF-1.7
%¡³Å×
1 0 obj
&lt;&gt;&gt;&gt;
endobj
2 0 obj
&lt;&gt;/ProcSet[/PDF/Text/ImageB/ImageC/ImageI]/Font&lt;&gt;&gt;&gt;
endobj
3 0 obj
&lt;&gt;stream
xœ½[[s›HVÕì“~E?JSV‹¾[SS•‹3q&amp;÷8ã­šÌ¶�EV�½ÞŸµ¿pÏ9€²ˆ21ÄU–t÷¹ô9ß¹4fÓGiÍƒ«ü—_¦�ò&lt;¸Z„³?§çÉú¯éùÝ:œ¾
®£8È£$ž~Ø\æxëyÌÂô×_?}2ü2äþxž+˜ÃŒo¸’pí*©™§÷…ï{Ò,
‡?ãáãóáô™`B²óùç8L0c¹U&gt;ü(Ïg®W.\Hëv¾Nûà²ëlè°küîá÷?Glü×ù‹áéùðÝðôÕ“áaA'yž¬Úey–$ùN–Vq¯@
Å´'¹ÐŽ#´Õ0ÏíV&nbsp;ïœVê�û¶UVsáÀ••®E=&nbsp;ü
¹¿|/q\É.™µÜ‘0F:&nbsp;jíiî•KYÆ5ì�‡Sæ?­wD¯AÍ8Ü¡+üIØl¡`ëµçI&amp;€‘6
}ë´ã–bTm¥­‚`9OOÅt<q#éÔµÕb®Ðf]it¬ Òú(é÷ã‰�þ1v#&zâb»\yÕø£="" @âÒw¹kÁ¦|¬³aÝ:\z½o5sÂa="">•tƒ€Oeí7ò©ŒNƒ&lt;×ÝÓ’�Šû(µRÆî³û}ósíK.a7„ã{¶…ëWÏ§¯ÞŽ'f4�ý»¾Ç²¡a“
¢€5î7*AÇ÷ŒÏ5È—’b_wß5í0@(É]�QúÒoS�¬ë«KÒÞQÒ{êj8¤ô9}÷­¼vÁ!-ÖcÒá–ã¶áêß�~_•!bËú£×c=z}
&nbsp;ò¯VLé„ßƒ‘eàÚãaRÀ»=±Ðo�¸v8â™£#Úô÷°ù™—D·K6¹1žgôèl,Íˆ7€¹F„(Ã¹UÊýº•õ Ó€}2
IÔ©Ã�ß­VmZ|Ðtâ"Ž×àÝE|¯|R)®j.ôòìÕÙùiò:g@ƒ¾”¥[ÈÀöØ‡&lt;åƒT¡°AÝ÷!ƒKWø²M{š~�y#wq¤#•n2?�|.®@ŠÓ×
|0‚AÜÑíx¨×hÆÂHÓªËï¬&amp;¾–EK�q_ÛÃt©zxeÃ«'gO™3}Ä×£0žüöxü&nbsp;"GîGS˜ç£
¤Ö‚¹�«7ªœÈ6¶ê¸ôà*¡uõšVðÆ&gt;ÇçÛ4„YdCH&nbsp;ØRÔ	M]ŠÞt)…Ãõ6­ƒLRàÅ7Jì¤y’lbL�®@¥ÑËÖ¹Z!çÚ‡yFûª�‘÷áØŽ²d¹OìëÏÎÙ€’‡KŒBÓÆF÷ÒcŒ9JÄ%ÕCè;Åº„.qORø½[ãU?:�HìâÖx-þGé°’‹­k¹Ž†H«øn~&gt;&nbsp;Ô!È�zØà*#ÊïXÕ�„]Ó5ÃáMÝ�'þh§?P-hÀl«ð,«û4f8—Ë`6Þ
ÇæÐúýí�6õ¤»EI­-;Ã•¯¦¿|Û3UZ±ë/ð«Cï‘µ¦–ñ¶�}¸¥îþá{HP½�ê[²›pìŽ°ˆÕå²2Ü²ˆ­[N£¬Ê£„–/R´]ot�V¸¨lË/mk"l1p�G¸`3\&gt;ž10XÀÈÝŠ¢Z'Ï
›Åûš(Ó]Z»mÝÎ•¦¥®•×Ç÷ªi¹êY.d€U5Qs¨ó9úé†°eâ’ÞÙÇ¼œÍ,6KØb¡jZÏ6ëu’æÃ
-Hï³Jñ7ø±LÖ«Ê.âü„‘îWë­­¬Â8G:û›½!xbÉœey:¦í‚eÉdX¹«Àá¡måÝ{C³7æk®‘¤ð]yO��Óv=jgµPmÛ¯ÎÙªÄ*©ka¦{á6óŽPÝÄ[‹K—QŒfö¸|-±`Æò„…qFÊ"U±93ÐÆäk]ÂœÍ¦¬Ýâº„k`b¢˜–º¬ìs±Y1KaË#P€xBÏÆçBrnËi[”&lt;¡ÐÈÑf‚ã&nbsp;5.‰7||Ë¢Â·–e¶*J€®&lt;'+²ò(Þ	…ºËqÀ"¢&nbsp;ÌW	hÁÒNXÒ¹ÈJ[(Í«&nbsp;XæxI\Ç„9(IÆnÑKùŠ;ÉÕPÙ8h¨}jMÂƒÌž\F+JEì(dõk;ØvTUÍ½Sd§)‚fÁxâÖ9e«0£ãH(äÎÙ:…ëC¸3Ÿ¸0–9¹£-R‚Û—�ËˆÈÍ®‘}X°îÕ	iûq²i´Kn&amp;BÖtÑ£ˆ\Š´C‰�w(U'U2š�Ü�ë¥ñ
­&lt;Î3Š¥¸ì&amp;£è›âØ24÷kGJréÞ+—ª,-¹8�BLÐü‚Îå$;—«`h9…Õ¬Â|‚Æ¿eºÉ§bF6JH^¦I÷2"èxØ’6B¸mBRê�q${qYå	.üª±ÒÂ*½ò2*22J‡ÕÖjz9m¸ÑUÁÜÂZp²ZãÖ—©wÞ·)
QkM6Lq“/’Â›À3Œ~µ`(ëw…Uµ¼å0“¸Mà±»2¼éû¥;in´Š¨=RàÅgôðzòÿ
¹O(-æÛ,¹‡H§”W?z&lt;,Ö2¸mT_ó$­U¾�Ï*ù&gt;ofQõ&lt;*Ó«æÖuoAJpã�®ÓnB'=�ÕÇÉöì/Úwj·ƒÈŽÿSAZz}”…„Ë-)[ð÷vN™%[Sf˜Üb¦˜BºLòKîec°µEôšSNÞ¹)J§fŠ-bµ–ÚºÓòZIuœ—ušP+­–0®ÚÂ¢é–EWpUžÖÿ]uÙŽyÑÇyI6)e¶,¯(÷)ôFi*C“$xÔe*ý·2à8kÄíT&lt;Qª:Em„·ñâuÌ‹wœ—Ö
öLëI›züØ�ká6Sî�Î°ðôöëÎFzX–m·ã	eƒ›¸v�CKÑ�å&amp;£™ÄÝGéYî»eˆo‘¬‡
Äó�RÜíœ¬deupñÃ¤UŽ<nvô@Ö;nvÒ=y!¹çw e¶�•ì="" ºkž\rý�2éh€b§åˆ]Ôº­¶öiÔ]]kþ´Ð="ýB?¡Úú" jÚ|™³h5.·xòdçÈù˜@ý_¾2ñiÜ}ÆvÀ­¨`¼7¯3÷ÈºÇÉbŠï{}d·tš,;:dßg¦@”Ëu…~»Š#¼� Ô5¸¦sƒ"#È="" ‚$kÄh="" whÃkt™Í2 Çiz‡c×Émuä™feÀi…œåše‹�ro‚]="" “Ë 3Ý,·ç¤´vv´sây�Î²‡Þ·Åz="yX=Ôü&nbsp;ûZNq�êÙXªQÎn«v2&amp;f�ôS�§†Ô¶qÓwe#l-«¬™)lvçG2ºv$ÛB¸‡ƒ" ÷8uì¾f="">¨:£
ÎŒØûÂVéuøHè`®Þâ-¶÷[›ŽÈm¢OÙŠŒ›=«ú•´F‘jmÛNª�¦£n½®:,ñm²YÎØeÕn(Ï
{°602(ß·ÞÐbn	f27AuòL\%—Ÿ÷Úå7vd›«uò:88²_}_×·ÜÙFó-ÃƒçÀÆàÝà÷ÁSø|†/áË‹ÁOƒdÐˆŸŸF4û�ÿ
þ€«§ƒSøfð’`p1øô	§ÞÃç‡ÁGø{�ÆTL¦e/àÉKZòVxsÏh�ƒ§�
éÉÚ+`-¢G1€¶)Ê…;ø½$¯À×*›°ÉNç\	ƒúý»!3ÚG6ORF¡�Õúw{ú�€Ê55Éö:¯+ä"Ž®èÿ˜XcXŒÒ$^ÑÁMuâ�§©n(ëò®x)ãzÁ¾ÐÐMç›UuÎZÁH¹=²:¡ˆW�¨Ÿ«
ŠC¤*ŽÎ‚&lt;è[#ÐXûå&amp;í�6è3nÝf]Qcx&amp;iŠ÷¬lNŽ=lxUï"àAWÎÖØß‡¨ŸÐÞvÎïÙ§U0¯B�	öªõÿòR
endstream
endobj
4 0 obj
&lt;&gt;
endobj
5 0 obj
&lt;&gt;stream
H‰ì•{pÇÇ{'�dÉ–î¤³%ÝC§·dŸÞ–-KÌÛ
�E%Æá‘
™P¸2ÓfJÓ¦„¦)�&amp;
µ
OSúÌ´�dZ&amp;”IÓÖCé$Jò‡!nÁR÷dC ašéL›VûÑíþ~ûºýí~oª&nbsp;H˜³rYûý±õôãšóøi\µº£]ú[úûˆ°wt¶wÍüJ{€M@lY±jãò=[�=ü.€®Á•xC¬ª°k6ïYÙ¹nC`Îè|ìw„�íº˜öÊ§¾ŠÛë×9´?ºûG4{–w­èl]²`%À�ðx*ÑõÐ²®#ÂI	àgÝzþÁöÎeé}Û6¼¶ÏwºkõÚuEó/ b±2ß]s#ñ÷éÞ-Øû÷�õÆµÿîÍKŒéKZeÙ8}O8­”¿^3—ºªÝ¥;¬�¥þc)1ÎN(~”Â|î_�è¹òâÍ¨Þ¼5”�:¯Ù«=WñuÝsúïVî©zÐ cÞ£gšêÌN–aS½¡&amp;l™k5ØÞùôÁù?ïäÛfÿu~Y¦L™2eÊ”ù¯çµ2eÊ”)Sæÿ	ñ�°7•ù·“-Sæ0]:àœåñ0Þs¾.Ä6°¾Ö^ûB]·<k~>èÀìu‡›Â/GæG'DGbgã™ø¥úM‰©˜áÿ
ú2Ÿ”FÛÇ‘\úq4ÝWæ Ç(éìa½
*8Šý8°¥!-Ð
óáóðEØÏ&nbsp;‘$^ ^wT8lŽˆ÷•+D±ˆG8nèÙ«nÙ‹Å?„Žâ&gt;u].&nbsp;‹¿{óé‹GÿÔ¡~q|U·•×»#‚ &gt;Ü‡ªR_w�ÀÜz¢Àx/›nh›Ò2uÚô3gÍn…»æ|æî¹óæßsï‚…‹`ñí¯óöù�yüšñÒà-»þVÉÎ�ÙŸºS	jA­„¬�L?�F(Í±<kµj„�f5‚À¦¥Ô#9€föu<{Þ*Ó—Ó£é6z8Ý:š† ¶é«8‹e�Œ“ñâ="" *¸ê="" ¯fÕpªa¬†§Š="" v¨¿�,ŽvrŸ}€|="">[QÝÆW¸,®êj
¹zá@«OXÛì6ç¤ÏZeüšÖüp~x´­eÙ”�i½œÎÄ¢ÈÝØ˜4%“�õñšjVC‘~“r»|
‰F4ÙØâz6TíüæÚ�(ó9�–ëÒi4óØKO¡æ†EKÐ[›ÙQ8³›i*&lt;]j«“ÓxW|¤›Ü‹WKƒ³þ‡�HOë%žæ%•Ì7éC´*E¥ì³©)†ÉF5­‰c`=Ö«Õ2¸ÈVYH'KŸ‡_pyf&nbsp;8Ø[ß€‹îÁÆæxö§¥ÀdGs=°|šÎ#Æ”Â¿XtM.9dnT"¼¢†tšor‰Ýb¥ÊÀÒw¸Ý~ƒÏöxa©TUežVç®Õ&amp;î$ÝÈó›uÙÜ&gt;‰<p_ø= l6'v«x÷háuümß*="" ýøt"Ùj`Ùw3´Ù€="" Ì)´tÄ±Ð¬·uw^;‡·‡òÉ­ÉÓ?�e5x%="" ¿Ïçwv»´$js="+â¡TQR31P›Ùµí�®DÀk2j£L�Ü<)¾ðx«³¥øWüÎ">Ðƒý$ÖÝ×z)=–Öºc¶Êk/ÊCf4MÞpœ‡å‰éºº‰û&amp;*9~”Õ¿ŠµkTÏ†$:”=�µõÛˆm¶Ý¶ý6²GØîÿ†ðdè 0ôCÕ1Ó1áDH·BX/lRmd�3ld}–O©\Õ)›Ë\ÝÌñÈhd¤iÐ
†%ZQ#zì¢N$“/FÄ05� ÚÕ"Å?f±¼Ç‰¼*ˆ‚^YMÛ=^Öãñ&amp;ÃA"l0«ƒ„%,j=M¯‡¦i²nS&amp;¢AáŸµX<vÂ qz‚"üdÛÙnh|'ônˆq)â0ŠÁ·ès$="" ÙÒo2z�gé§g-="" o–iu+="">Z{¼©Âcñ4éN¡µhXe™NËÊÎådyÍäÅN‚§8Ø'0&lt;¶»Ïg+ÖRy&lt;„ý¬5%+i!j¾0|¡�¾œ“[‡¯ÊòP$')3Òƒ�ÉgL©H:Oç{aY½‰þ±°LéÁ\8ÿ6Ð—ÐME©eÌÔ¨étº÷GŠZ~UN‘t‘õñÆd=éÆêñùÜn’ªf-5õc•ÎdIðI³Òèv'�¥n~¬17ñä·7ùá&nbsp;wgÀä¾cé£[Í6fÊ†—ßÊy»¯\¬jã&amp;ÞûŽÐÐZ]IþjžWÃ¹îŒ&gt;§&amp;G/Îí*°ÍA9a+dîtq¬aÇ‘B�—¨4	µ[ÉxGÂ'{'ÃRƒ'l5)Š:
&nbsp;¹+*F}6!eëÓleæ´ÈN˜\Úq?U\ Ü+®€~çYñ}Qç~"ËÅíâq‘ô‰(ä¢™fˆâÌ®X?&nbsp;ˆÉódýº`}œc•H@uÈkW!{ˆŒŠëñ‹&gt;UTŒ™EŸ–Œø6Í¤Óôèü;s†1YR9|(·BŠÏ&gt;ážd…J$Í+š}A&lt;Ø¤cD“Wòˆ^@È.ÚY¢½B§³s&lt;Ëq&lt;Â-ð¬ ð¡`Ð-ÙYI²›ÌfÁçõŠ¢&nbsp;�‰ÿ­	Q@$'qñÏÙ%Z7€öõsXmœ"›É¸ì³Š‰’oŸPò{Ù®¤L“pp›¹g8’;Mì„z¼�­Dk³z)K3	)[Y•�Æ'�Æ'TÊ,ƒg’¾ç,’…“âºôê’Ž±�éÑ’6óC%A—LÜPä b,)¼KŠ;–+(Ú4`­õ¨ÂÖ’Hq…u¬F;^3.Ûž/¼®ÔþŠ²FÁŠÏ^tá”Lù^ '#|1#g5þÃÁwð¸|5Îd}ßÍI3r“Je�åtW}lçß»³Ï¾ó9—³Ï_�}±“8ql§Î—¯@7B¾€�–6d0š1ÊBY&nbsp;ka+mPË2&nbsp;¢[QFKi'ÖNb�3Z(å¤MëÕ¤¢ŠµR¤B¥ˆi@µ’ì}ÏN7þèÉ¾çÞ»÷½;Ýïãyžò©&amp;ˆ&lt;²‰Ø³“tÁÎaW´)rÏ#©+}öÙ+ŒÔ¥‡j&gt;»Sñ_áÜFvîaVz²&amp;ƒZ´ucéºwžZ¢Ð4×³åþÑÎ¤æ*Š‡ü
R¸w’ê½öGŠ¢ÑŠ’Žo'oË&gt;ZÁUÖµùÏ­/!§aßYž¿&gt;Uáj·ç¯›ÑÁxì”ã4wÎCõYV†·q»c”­Î–Ê-e¯Jj´A(Eª‚¨MAÀí¬v{(QëN$j#²ÜnApK�„€p)ö
¾2³	¡Q¯M¸yù‚�|FÀx»üí8\e¾^0„åÉP8Oö;²·¢�?›ÀCzÆŒÉZ3BCs&amp;’€‰í�ö„Wð¢{3E²pò~$±U¡
ÎÜ4Ùñ9f
’b�ßJ�²H+Ý&gt;{eFÀ;· G(§`"Ð-0'Ð£´“&nbsp;q­�nL·%«Òš¢´ŒÙà$Ìtµ`atmìêÎlpŸB;N|òð–5±íµmƒ,&lt;Îv-N‡|÷…['ÿò5kÿ¼*¿ÍÒ¥ÁeCs‘QÝhÚñnçØÏÂ#o¦¢)kçðœýîÍß|1Þ²¸fþu(¥T[Q]U?ƒ¼Dî*ÈÂOŸ=b‹fáËðåÄ8|]:�x½î�g’l=f€×á.õm r‰eÂ!û³§¬gœøZ¼½Þµ^²­:4tþìYÏ'ê
•„E�Ç«¨ªèà<z*­*ªa¬i ªeru‹z\–­Š="" ‹ª[ÕtqþÓ©j~e²Îàžsº*òÜ^Ç¸Õ$qýiþiý£h y"Þs2@äÅz‘ü¥Ñ©ÑÉ¾¬x�5ä.="" €="" "i]&Äs½ª–="" Žöe'‚·‚d0�½bŽi_.åÂr*lš©="" z®ð¢©´¿}å±+ÅŠòyô"ÁuÍxÒ[Ê’xøÝ7ï$g’É;3üìw3éÕlÉ¢%}€Æü4¬Äe\eý�¶oþê¾nc”ä?ü“="" “Ùjz="" è<‘èë<Ñ¼â‰ÕïƒìüÇ="" ƒþúü=""  ÍßxmeÃ!é’Ñ`cñzkeqsâ¡y$˜e°·‰–i+a2g*yé²‡dlnÔ–y­="™ôˆ/=ÝÛÕ±éýÛ6´­ãWŒ¥&amp;–Ôl=¶ˆÜ3ûÄ�gçv">8àÛ¸9YÝ°¼óØ’†›&amp;à÷7­2–m­jíŸ›[Òûöß?ïïÂ^sÏ²xAZ~@‚6Òöà1Ë¹*JÅ²*”ÁÑ0ü�L¥å¢¸Ï¼�8¿Ô=õÞn£èÄ=:ësN7Ç9£ñP&gt;ªQ47ˆ³,§èNŽÉ]F�ð~•þM„QIµÞw‘Èã€CJÔg8œ•ô¬T3àÇsf’B�¿È}Äý“#¹"l9­p^NaŠDød™0eGINÏÌ"�ßü¦ú™)”ðµ•ð…‚‰¨�¿;“¼ï"&lt;[[wbDG0”R²\žTLÖ&nbsp;Y¼Äd:K"Hr.jd+Mô^Y÷jÏÓ¯ç¾;8ëc¼·VLVu­¾°o&nbsp;}pRµìŸíZöÚÎ·ç.MŽPÞb€hõë7í‚éÃk6ŽïF&gt;ßŠ¾ý0Ò½9ã;Àð::ÞÕ¡Ì›ÔêôvÐ›-íZ»þ
±/ºG;F�ŸOÅù0Êo	haÝº[…?ÕöjïDI�bë�¬4yÒc¤Çì„~\'t„çG�
u*gh9Æ”ÄPüÔ�CyE#YpÕýc¿Æ!€R\�ëåÖrTæ.��1v!+ºT°öZ×Z·X©Që[ÖÖ‹Ö�¬«¿:ù¨Yö#uußìáçpœ™™F_?™D˜Õu°”›G°b¢H1uH1çP†»BX)�ƒ8‚0TÊââå6Éµ%$Œ;×DJ?~vÿÄ1Ý·yX­ªWW¤W0»þâ’•ÏuüÞµ�?ykì
¨ŸXÔ^#ë!W¤ÖÍŠN÷ÞÚð\÷ÿ‘D©Uˆÿ)Ð?0ŽÐ!è–ý'ƒþ¬‘kÍ0xÇú2Ùk¤Ñ0�ÍHL€}ŠyŠýs�µÄ^q­ØßHýo™ÜœÉe;B-ýucÙ_Ã7Ý‡ÄwÀXdNOe¦²ÎUªÞÎB‡Með|sQ›¡dÛŒXTeÝn1WU×065§ámCÕëêSÝ1wc¾^•šs17éÂÚ#AŠ»T·Ë¥6Æ#t¾8m2”Ïcçf}&gt;'ëjÕUŠ$9¥w±˜L½gúH†ÝËà–&amp;‡Þ|ñ‘*9�.ÞE¸Jîú32ðâ€SB�ÐKJF0nöBH®8•ÈÕoIPò·º¼®V&amp;ýîƒªDÖ;2=ûÎôIþÎæ[˜ùybªØ|±JË"EÔ1uj3…ZróÜŒ&nbsp;¸n]0x0¡µì�ßn±®rÛkŠË˜Kµjî÷U•vN�—ËKrMHûÕs+;»FÞ;ü³æzÔõ,í¨£Þ¬´,ÿÂÜ­Eu‘&lt;÷ßZbÎ·Nz¾¾&amp;¿îùÏm{f®ÜÔ_Ó×(= :+iev›Ñ3·î½Î^øö]ii?0gä*xVññ&gt;…6ÞF}¶vB·'”‡ì-¡¥t‡­Ã¾”°=Æ÷+¨ßR¿sMRg^ÃŸ½MÍÚeÔ&amp;Úd�-Øì6»E6»{%ÃÆ´sRPJI¤$±±¸@[4–�4Wˆa‘è °¬½N©sT_^pèFNèô«ÉË¾…ÜýŸiÜXvÏü—íª�m£&lt;Ã÷ùœ8¶Ïöùî|gÇÉ�ÿÎöù'¶ŸÛi|Mì6ÍÏú“þà4nèXÿÒÒ5+MLFØ
jé´Ñ•©ê6D¡-¤¤3cÓÐ�6@CÚ¤	!
¤eÖYlRU	‰˜}ßùœVhR¾{}Ÿï¾|~ŸïyÞçE¶¬[ÉJ´¦¡„Ù­5Ç�UÔZm„Â·bDc7Ú´h@ÑH&nbsp;ûy"V¡›|æ¾B{CkB•iHî-Ã#“ÃßÌQûë™gª€=;³{pÛ‡Ÿ©;&amp;§vÿÌu{ËçwuÞ¬~óè»²5?1vß*©Ý.õþ¤I¿}uý|}
þ&amp;äú¸ÿ5‡Û™Œp”CzK´Ðªp«¹Á,¦§JJXJûÑ|»ËŸÆx)AÊ—'V2]BÎÂ"k®“ðêõ¥"ð+pìWÈ@kí9·*ÇÈsî€Ñ†–—Ðì£ý(y‰wÝJÔë…\74¨÷ô‚n(4½—‚ý]¾Öxÿ®U]hU´šP‡2“Ë¦’N£Q·%YÕÕç¹”¥ªÃ2I+�¶WŠ'MÝh,¼UY®-Gk+¼«5¶÷D.5Í@vâz|qÑºx¼…\´ö—Wè¦91=LÜ�N7ü&nbsp;÷õó�ÒÏ|¾ødÁ‹.%…nz®2@ŽÛàÇu•…!ˆoFƒ·a†`¿�¶¿·ñA+½�ƒÐd)|Ó&nbsp;›¦Î\7²onjª?"ôˆnÑAŒttzÄk]uõªub°7–ÏŒ\›ê
¡v£ÅUè’ÝÃøì`}´þásnYp…=	ËÒVƒ±Å�Ù¿+rS÷‹AnuùÈ`¹&lt;÷'.2Ñf5˜Âòlþ_&lt;"¨¯ÑG!KØ*l˜”ì™¡‹ÔeúEöÒÐ•µ/S¿ã_®™¨rftŽœ}vô¥ÑV»Í&amp;Œ0#6ûÀˆ~ÀëfOµUñžùùvVoõb†RÀi£ìÌ°.¡o&amp;3^ÂÎé‡SÌoñn¬KB·¬ÇSŠQ"rþÒê\Ço&nbsp;M‚ŒIPs#²„¨-N“xOÒkão�9‘ÚÎ"­­‘Èã~J.C+‹ UG#¨,¾Uƒð× ƒ³\¶	*©2xaÔga6D×f´‘$¢-Œ¨R�¢j5æ8–C°!ÜpI55¸9ƒÊa­á­MìQÔG;Ÿ§Í¾9#3�u¿¿˜î™ûô‡½sO6ê~¤kãcýüO£÷ÆÇËÃ³gwÉ÷ÃuïÆ‰þ­¿|êíÑy|to&amp;ñøž=fOŒ´3^{&lt;˜–K›NŒç¿!G+&lt;½6
Of§·�þˆ÷\Ø0õ÷cã_Ïí~nùÛâ}ƒÑ��ã¡5,�˜Õø%¨°^¹ŸÚlØ*]’ð}­ûŒûù¡9ã,x,Ô6�íê&amp;dädt‘h,†ÑL¦Ô5–“™qà�ƒ.3„àö0n·‹a™˜ïbâñ.JoˆÇLN³»7ìqwÅIæ
«íuÂ zª 0OˆnTfc:|&gt;óç8ò¾Ðò¢8ÏeÕÐ!«³Ð¨1’V£BåäÏâ îêusqÎÝkê~¢Aú¦€#
_‚�Ã#¡v=šúaámi^xœQ±Ü,¼ÇIëÃ‹°ïQ…–ÜÑ—»¡sË@çöŠÇ×�&lt;2Š8‰lÐIüíÍ0¾†”&nbsp;4¾ãw*³U×¨ÌtCÛÇÈ`ðƒ^õÖ ëÊõ�o¼SI*G9»ÙbÏö	¾¹m&gt;1á?Ìº˜N±Xvžˆ¸•�uþ¨@‰Ž–Ó_È€zu°wpG½2Öf¥,±¯ÑòwS	1v&lt;=eœlä[Âk&amp;ÞÕy¨=ÜŠ‡P
¾çËOt]-,fÆ$PBÜÁœÌ~''SQ…’£ŠË�.Àå,'•¼“ápR'°C­Uü§J;a6B²	¼—áy¯ÛÌGÂ^žäN±ÐWmÆC8Qkçñ{mUàÿ•t€â·Ì#Ðrù4¯�‡¢b„hòŠàiÜÑ4›NòOñ:Þá9&gt;bzPÃò”(ßfUj^±ÀZŒµ¨QëuËãKËKÿ$5´U¬ï2XØíÙu=uÉN!˜‚E…/ËAôÐÇ[–SlYMÉ¡�ß¥Íô]x6
Ö
&nbsp;2øc$——¤|®÷-†¶ØÙœ¿8U�Ò®ïy7[jas)Ÿ—"¹úáå¡µV’!ãÜÞµrJ·‚7v°f„Qýçõ5º�Ä(‰}|ƒêVldºýdwH�J§Ež¶L‹ÛƒÛCg“-íH–‚“áD2¹–—0"iÄ #ŠA¶ê�6þ.1Š$ÄJí“"òÓ8Pð
¸ßÖMTñèõõA-÷Ï‚ü�k¯â²bÞL‰œ˜Z¡yû6’ØJMm}´tGQµof2j%áZºUÜ�íŽà�Lß�f&nbsp;ÙXÈ"®Q69VuKwÈ#ƒ÷#ù|Ž\}¹ôßV§&lt;�,å²êp‚Øx8þ‘7êµØ-®‡úõ¾xô?É……m£Ûi³¡E¯ßó,ŽÍÎ û^è–°õ�;¡&amp;vI1b€Â (íòflsÇgÂçœÞä1'ÍŠyƒYoî,9&amp;ÃÉÎqVM¬(CQ›™âÃŠ¼óàÓ¯ÁëpÉ€Bà"…Qà
ê=JGUA^1ñFŠ£xÓƒcšz¡Z¦z
ÂÍY”J—nW�RÂŒzw]d³´ßg½pVA*¤»ñ½Í¥½eåà¬¥ñô‚3K)lÓ¡4}JméÖ¿+_¥¯�FVY*Q0«òÏŒþ�	]äÉ+þ¬VÁÿ!h’B·³~ÙE[!Å³üô†¼ìñ›7æ°�˜,36Æ.mž�ƒi_à~ù°Ý)Dˆ„ÿËOZB2¡+)�»&nbsp;¢öÅAÙ¸�˜¶lc¦ú*¹J~Gÿ–M{é}ìLlŽ˜c�ÆŽôŸÄŸŒ=Ùrè~Þz&gt;saèyð¢åbï}×²×r×òWû//•únän‹û3{{gŠø&amp;¬\Ü´	?™9Qüq	ß•=ú?¾Ë?¸‰´Œãï»›f“Í�n~îfÓfwó;MÒlCÒ’¤?¶¥”¦¥Ð6mo€�ã`&lt;Ëq0‚œÜ€G½³ U~8ôP8Î´¢&nbsp;w¢xÈŒ3þá8£ÔS+ŽS=‡à»»¡”Móî3ï›ä�¾ßçy¾Ÿ§qWvoçîîsm2¡‰áíCU‚·Pî-Ái(&lt;(ú€)KÀ|»‰ÌBÐ›j°XÚ¢pv—‹‹ˆöHD$³Y.×jÏåZA7(tsù^{&gt;ß4ä»»QÂ’‘!ÔX[s½yÊ{D�ÝÐeˆ%9A\�ˆdNoŒü.‚EJXêƒíYx5³2ä:r’/�“Ü5©í9˜ë'!h�ÊÍÀÛ&nbsp;Ãßï�¼›WmS	¾´8%\G?R¶.u[S¶�H¥¶çä±¼k(Bçè&lt;zâ¤‹ú/òRd¦ósE
‘Ö\q:_ä¬c-úk[p×*ä®æ§mvM¾è-Ï•Y½7æ¢òRóÍbBÞÚŒð3=(6ÊÿAu¦Z¡²ŒF
@=,¨�®X±×k[œëòÈ…+¨­Ú2amZdÐô3Ý´˜Â}Mñ&lt;î³5U¶!xóÍZ6¬Mg“ôŠso¬®ÏY_ñëµ$éÊ$×¾µA_"²ŽÃpƒ±º.qä‹«—Ÿ¼\ã¤„@óS®õ_Ÿfˆ0gÊéññrËÙþ×—òR²au6ìílëÈ¶—÷î3›IÂëv„�&amp;EŸø5Ø¾ÝhC
ÎÝ÷‡“ÁŠ›7Ë„�]Må_c‡‡lz§Ï(WNqÝªœFx\e”x…Q¤ÓHÑ%œÀ�¹šbP?èà_ƒ{ããž‹¡óál&amp;h…£á[_«_ëYË+Hø²GBíHÝ@z,ˆêæi Œ*&lt;Wy�o1âg}ÁŸ‹À0
£\,n�Åâ±èc(ŒÇž…²ž£iw	›¸–¾—Ç€(†ƒ˜’à1õC%d• “E¬‚‰1•cJ�D0ù c2&amp;Æþ&amp;Fûæfgç£Ï’âs8%ïNXI]ê)Zü?°ˆ’OPJàÏáÂg8B«ráã-Ê³�ýàg£ÉöÚ=Jo´¤Û¸b![ˆy?ïdm5¡žÉ5	.yâÞÇ=A-J§¤¿Û‘nÞ\^—§Ì6SÝˆíP&amp;Š»àÛ½uvÿå·†_º€íÜA;�Ö�¨°åÌu”3&amp;àSR»ÓãZ?o{�™t_³^sþˆÑ®cÖ¸ÙŽ2¶3Ì+ÑhËºVØò®t#Ö!A�¿�À«ªh¿Æ`/á$+±¿·�"ö/K'ÎábÍòqÈ$ô�–¥�”DË“€G´#�IP&gt;tG?d�BÿTê»¯ŠÕw�qr‹‘j³@WkGÖ-ßŸÕ�®V¹0ån­øõ³åÙ/�O½Ý^¾¸®û�O7æ�}ŠõŸ(ÿæÊÕ¯¼ÃWÞë*¾X^woÃVxq×#O¹ÿ9ºHÂ‚Ô;�Ï§Œ7MUG/è2w9ºë†µ/™w™_c¯„§u7#ÓuwYó2o?1ã"Hy%€C“¿!i6'K‹N‡Ù.:|ËÝ%øÉöŠ¾&gt;à‡‰ îD	?&amp;yåò3ð™9ÖmgYwÐOÐ¯ªYÈ.	»Y*6ƒJèú4!çuD
!%H&gt;MH\z5%¢Ÿx•˜$nUÄ…</z*­*ªa¬i></vâ></p_ø=></kµj„�f5‚à¦¥ô#9€föu<{þ*ó—ó£é6z8ý:š†></k~></nvô@ö;nvò=y!¹çw></q#éôµõb®ðf]it¬></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://data.consilium.europa.eu/doc/document/ST-13084-2020-REV-1/en/pdf">https://data.consilium.europa.eu/doc/document/ST-13084-2020-REV-1/en/pdf</a></em></p>]]>
            </description>
            <link>https://data.consilium.europa.eu/doc/document/ST-13084-2020-REV-1/en/pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25434793</guid>
            <pubDate>Tue, 15 Dec 2020 20:27:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Publicly share your stock portfolio]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25434362">thread link</a>) | @probe
<br/>
December 15, 2020 | https://withlaguna.com/create-your-page | <a href="https://web.archive.org/web/*/https://withlaguna.com/create-your-page">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Use Laguna to import your trades automatically, notify followers, and grow your audience</p><div><p><a href="https://access.withlaguna.com/" target="_blank" rel="noopener noreferrer">Create Your Page</a><a href="http://parth.withlaguna.com/">See Sample Page</a></p></div></div></div></div></div>]]>
            </description>
            <link>https://withlaguna.com/create-your-page</link>
            <guid isPermaLink="false">hacker-news-small-sites-25434362</guid>
            <pubDate>Tue, 15 Dec 2020 19:58:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doom Reinvented for PICO8]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25434166">thread link</a>) | @nallerooth
<br/>
December 15, 2020 | https://freds72.itch.io/poom | <a href="https://web.archive.org/web/*/https://freds72.itch.io/poom">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Mars base, Union Aerospace Corporation experiments opened a portal to Hell. You appear to be the last human, fight your way out!</p>
<blockquote>Beaming up the virtual feed from Mars takes about 20s, be patient while loading the battle simulator soldier.<br><em>If experiencing slowdowns, prefer desktop browser or beefy mobile.</em></blockquote>
<h2>How to Play</h2>
<blockquote><strong>HTML player: click on game to enable mouse support</strong></blockquote>
<p>Recommended controls: ESDF + mouse (automatically selected if mouse detected from title menu)</p>
<p>Second best controls: control scheme 2 (from options menu)</p>
<p><img src="https://img.itch.zone/aW1nLzQ4MTQzMzkucG5n/original/Wq0LqS.png"></p>

<blockquote>mobile menu controls: use left paddle to navigate, use up/down from right paddle to cancel/selec</blockquote>
<p><img src="https://img.itch.zone/aW1nLzQ3NTQ2NzgucG5n/original/Uqw3T%2F.png"></p>
<p>From title screen, use pause menu [P] to switch between control schemes.&nbsp;</p>
<p><img src="https://img.itch.zone/aW1nLzQ3MzYxMzkucG5n/original/6SO90E.png">
</p>
<h2>Soundtrack</h2>
<p><a href="https://t.co/srJyW3DATF?amp=1" rel="nofollow noopener">OST (@ParanoidCactus Youtube channel)</a><br></p>
<h2>Release Notes</h2>
<p>Version 1.5:</p>
<ul><li>added: in-game keyboard controls options</li><li>added: in-game mouse sensitivity (options menu)</li><li>added: standalone zip (for arcade cabinets/devices)</li></ul>
<p>Version 1.2:</p>
<ul><li>Fixed: crash when pressing fire during load (thanks @Rhoq)</li><li>Changed: minor texture fixes</li></ul>
<p>Version 1.1:</p>
<ul><li>Changed: 🅾️=fire/ok&nbsp;❎=open/cancel</li><li>Added linux + Mac OS X binaries (with mouse lock support)</li></ul>
<p>Version 1.0:</p>
<ul><li>HTML player with mouse lock support</li><li>Windows binaries with mouse lock support (new upcoming PICO8 feature)</li></ul>
<blockquote>Mac OS&nbsp;X + linux binaries + standalone versions will be provided later</blockquote>
<h2>Credits</h2>
<p>Original levels + art + sfx by&nbsp;<a href="https://paranoidcactus.itch.io/">@gamecactus</a></p>
<p>Zep for PICO-8 and support (and sneaky versions!)<br></p>
<p>ID Software for producing such a timeless game</p>
<p><a href="https://zdoom.org/wiki/Main_Page" rel="nofollow noopener">ZDoom Wiki</a>&nbsp;for their fantastic compendium of everything DOOM</p>
<p>LZS compression by&nbsp;James Bowman (<a href="https://www.excamera.com/sphinx/article-compression.html" rel="nofollow noopener">https://www.excamera.com/sphinx/article-compression.html</a>)<br></p>
<p>Beta testing &amp; gameplay feedback by&nbsp;Tom Hall &amp; Jusiv&nbsp; (&amp; my kids!)</p></div></div>]]>
            </description>
            <link>https://freds72.itch.io/poom</link>
            <guid isPermaLink="false">hacker-news-small-sites-25434166</guid>
            <pubDate>Tue, 15 Dec 2020 19:44:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No Code Resource List V2]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25434130">thread link</a>) | @richardawoyemi
<br/>
December 15, 2020 | https://www.notion.so/No-Code-Resources-1c9a074f65f2419292558a7023cd97ef | <a href="https://web.archive.org/web/*/https://www.notion.so/No-Code-Resources-1c9a074f65f2419292558a7023cd97ef">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/No-Code-Resources-1c9a074f65f2419292558a7023cd97ef</link>
            <guid isPermaLink="false">hacker-news-small-sites-25434130</guid>
            <pubDate>Tue, 15 Dec 2020 19:40:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sr.ht has dark mode now]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25434025">thread link</a>) | @mariogreymist
<br/>
December 15, 2020 | https://paste.sr.ht/~sircmpwn/9a8365c9cfba623bb58b8b3f3c34d6bc4481a62b | <a href="https://web.archive.org/web/*/https://paste.sr.ht/~sircmpwn/9a8365c9cfba623bb58b8b3f3c34d6bc4481a62b">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div><h2 id="sourcehut-dark-mode"><a href="#sourcehut-dark-mode" rel="nofollow noopener">#</a>sourcehut dark mode</h2>
<p>SourceHut has a dark mode now. You have to enable <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-color-scheme" rel="nofollow noopener">prefers-color-scheme:
dark</a>
in your user agent for it to take effect.</p>
<p>Send bug reports to <a href="mailto:~sircmpwn/sr.ht-discuss@lists.sr.ht" rel="nofollow noopener"></a><a href="mailto:~sircmpwn/sr.ht-discuss@lists.sr.ht" rel="nofollow noopener">~sircmpwn/sr.ht-discuss@lists.sr.ht</a>. Enjoy!</p>
<p><img alt="" src="https://l.sr.ht/dUak.png"></p>
<p><img alt="" src="https://l.sr.ht/1Wyo.png"></p>
</div>
</div></div>]]>
            </description>
            <link>https://paste.sr.ht/~sircmpwn/9a8365c9cfba623bb58b8b3f3c34d6bc4481a62b</link>
            <guid isPermaLink="false">hacker-news-small-sites-25434025</guid>
            <pubDate>Tue, 15 Dec 2020 19:31:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Streaming SQL, Connect multi-tenancy and Kafka message headers]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25433917">thread link</a>) | @Natasha_Fll
<br/>
December 15, 2020 | https://lenses.io/blog/2020/12/lenses-improvements-sql-message-headers-data-masking/ | <a href="https://web.archive.org/web/*/https://lenses.io/blog/2020/12/lenses-improvements-sql-message-headers-data-masking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We’re continuously releasing new capabilities to enable more people to be productive and compliant when working with Apache Kafka.</p><p>Our engineers have been hard at work on a great Christmas present for our amazing community of Kafka users.&nbsp;</p><p>Before unwrapping our latest and greatest release, here’s a sneak peak of what’s inside. </p><h2>Streaming SQL workloads on Kafka Connect</h2><p>In July, we revamped our <a href="https://lenses.io/blog/2020/07/Why-new-Streaming-SQL-opens-up-data-platform/">Streaming SQL engine</a> for powerful data processing minus the typical operational and development complexities.&nbsp;</p><p>This came with a new deployment framework (“DAD” as we call it).</p><p>You’ve got enough distributed technologies to manage. So we built the framework to simplify deploying streaming SQL workloads on your existing infrastructure alongside wherever you run your other applications.&nbsp;&nbsp;</p><p>For our first DAD Release, we included support for Kubernetes. And now we’re extending the framework to deploy your workloads over your Kafka Connect infrastructure too!</p><p>If you want to understand how it works, checkout our recent <a target="_blank" href="https://www.youtube.com/watch?v=oYjVgyWzGVE">CNCF webinar.</a> </p><h2>Powered-up Streaming SQL for complex data structures
</h2><p>Speaking of Streaming SQL, Lenses 4.1 comes packed with new features that make life even easier when processing data with complex data structures.  We’ve introduced<a href="https://docs.lenses.io/4.1/sql/functions/#array-functions"> 6 new functions to work with arrays</a>, better support for array literals, and lateral joins.
</p><p>All these features are available both for our Snapshot and Streaming SQL engines.
</p><p>Lateral joins for example is a new kind of join that allows you to extract and work with the single elements found inside an array, as if the array was a normal table.
</p><p>As a basic example converting the structure:
</p><p><code>{&nbsp;"meter_id":&nbsp;1,&nbsp;"readings":&nbsp;[100,&nbsp;101,&nbsp;102]&nbsp;},</code></p><p>To single-value structure such as:</p><p><code>{&nbsp;"meter_id":&nbsp;1,&nbsp;"reading":&nbsp;100&nbsp;},&nbsp;</code></p><p><code>{&nbsp;"meter_id":&nbsp;1,&nbsp;"reading":&nbsp;101&nbsp;},&nbsp;</code></p><p><code>{&nbsp;"meter_id":&nbsp;1,&nbsp;"reading":&nbsp;102&nbsp;},</code></p><p>This means you can define even more types of data processing workloads with SQL rather than on complex stream-processing frameworks.&nbsp;</p><p>Read Nicolò’s <a href="https://lenses.io/blog/2020/12/exploding-arrays-in-kafka-with-lateral-joins">blog about Lateral Joins</a> for more detail.</p><h2>Explore Kafka Message Headers with SQL</h2><p>Apache Kafka 0.11 introduced headers to messages in Kafka. A very welcome feature.</p><p>Kafka Headers are useful for annotating, auditing, monitoring and routing of events as they flow through Kafka.&nbsp;</p><p>This opens up a number of new use cases, including for monitoring data lineage and distributed tracing, that help make Kafka more governable and allow you to offer higher service-levels to your users.</p><p>Our new release now allows you to query headers alongside Kafka message payload and key with the Lenses snapshot SQL engine. This will radically accelerate the time to investigate incidents and problems. </p><p>See our <a href="https://lenses.io/blog/2020/12/kafka-distributed-tracing-with-message-headers">message headers blog</a> for more information.&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/3DXYl9WI25AbGTgnkvvvnm/b06a02dde2ccc551a77c7e0a63a83fb9/lenses.io_kafka_headers.png" alt="Query Kafka Message Headers with Lenses.io and SQL"></p><h2>Data Policies namespaces</h2><p>Data privacy has been a first-class citizen of Lenses since the beginning.&nbsp; Policies allow you to discover and anonymize data within your streaming data. This means data can be socialized across your business whilst maintaining top notch compliance.</p><p>Data Policies were applied globally across all matching Kafka streams and Elasticsearch indexes. This wasn’t always what everyone needed. As an example, an emailAddress field should be anonymized for production topics and not across dev topics.&nbsp;</p><p>So whilst you're defining Data Policies you can now apply policies based on specific topic namespaces.&nbsp;</p><p>Read more about the latest Data Policies features and how to protect your data in our blog <a href="https://lenses.io/blog/2020/12/life-of-pii-data-masking-and-compliance-for-apache-kafka/">life of PII for Apache Kafka</a>.</p><h2>Kafka Connect multi-tenancy
</h2><p>We see many of you are managing dozens if not hundreds of Kafka Connect clusters. Often in a multi-tenant fashion. 

Operating so many clusters puts a strain on good governance and adds risk. 
</p><p>Not only should you control what topics users and connectors can access but also potentially completely isolate tenants to your platform for compliance. Avoiding them even seeing other tenants clusters let alone having access to them. </p><p>The Lenses security model has protected which Kafka topics users can access (on top of what you may have already with ACLs). We’ve now extended this security model so users can set privileges over which Connect clusters can be accessed by whom. 
</p><p>To understand more about applying compliance and governance to Kafka Connect, <a href="https://lenses.io/blog/2020/12/kafka-connect-top-compliance-controls/">some further reading here.</a></p><h2>App Catalog Drilldown</h2><p>The Topology view is one of our most popular features. It provides a view of the lineage of real-time data flows. Very useful for impact analysis and troubleshooting for example.&nbsp;</p><p>We’re now simplifying the workflow so you can understand the relationships between data and applications with an instant drill down from a data flow to an enhanced view of an App’s metadata.&nbsp;</p><p>This shows detailed information about an application generating data including state, health and business metadata. </p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/27xzELE1DIze9sHpkEFW8O/7531062a27fdecbb10672f03742b1e78/app-catalog-lenses-4.1.png" alt="app-catalog-lenses-4.1"></p><h2>Take her for a spin?</h2><p>The release is packed with more features including support for recursive schemas, new Kafka Connect Alerting and improvements to how you can manage your license keys.&nbsp; Full release notes can be found here: <a href="https://docs.lenses.io/4.1/release-notes/">https://docs.lenses.io/4.1/release-notes</a></p><p>Experience the latest version in a cloud demo environment or as an <a href="https://lenses.io/start/">all-in-one Kafka &amp; Lenses docker now</a>!</p><p>Merry Christmas and a thanks to everyone in the community for their wonderful support.&nbsp;</p></div></div>]]>
            </description>
            <link>https://lenses.io/blog/2020/12/lenses-improvements-sql-message-headers-data-masking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25433917</guid>
            <pubDate>Tue, 15 Dec 2020 19:20:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cotter – Authenticate and authorize users without passwords in Next.js]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25433900">thread link</a>) | @mmarcelline
<br/>
December 15, 2020 | https://blog.cotter.app/passwordless-login-with-email-and-json-web-token-jwt-authentication-with-nextjs/ | <a href="https://web.archive.org/web/*/https://blog.cotter.app/passwordless-login-with-email-and-json-web-token-jwt-authentication-with-nextjs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<div>
<figure><iframe width="480" height="270" src="https://www.youtube.com/embed/D6432VV4TdQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>When you start adding users to your website, the main question that you need to answer is: <strong>how do you log your users in and how do you give them access to the appropriate resources?</strong></p><p>In this tutorial we'll go over how to address both questions and build a Next.js app that only allows logged-in users to access private resources within the app.</p><h2 id="so-you-want-to-have-users-">So you want to have users.</h2><p>Let's go over some concepts: <strong>authentication vs authorization</strong>.</p><h3 id="authentication-how-do-i-log-my-users-in">Authentication: How do I log my users in?</h3><p>Authentication is a way for your server to verify the user's identity. The most common way to authenticate users is by using the email/password combo. Unfortunately, <a href="https://blog.cotter.app/medium-and-slack-moved-away-from-passwords-and-heres-a-reason-why-you-should-too/">passwords have serious disadvantages on both security and user interface</a>. <strong>In this tutorial, we'll use a verification code sent to the user's email to authenticate the user</strong>.</p><p>Authorization is a way for your server to authorize a request. In simpler terms, this is where you pass in a token or session to your backend server when calling an API to view or update some data. The 2 common strategies are <strong>cookie-based sessions</strong> and <strong>JWT tokens</strong>. </p><p>The main advantage for JWT tokens is that it's not stored in your database so you don't need to do a DB check to validate every request. That's why <strong>we're going to use JWT Tokens in this tutorial.</strong></p><p><a href="https://blog.cotter.app/what-on-earth-is-oauth-super-simple-intro-to-oauth-20-access-tokens-and-how-to-implement-it-in-your-site/">Learn more about how OAuth 2.0 and Access Token works.</a></p><h3 id="how-would-the-overall-registration-login-look-like">How would the overall registration/login look like?</h3><p><strong>Authentication: </strong>We'll ask for the user's email and send them an email containing a code. If the user enters the code correctly, we'll get a JWT Token in the frontend and store it in <code>localStorage</code>.</p><p><strong>Authorization: </strong>Every time we want to access a private API endpoint we need to include a header <code>Authorization: Bearer ${token}</code>.</p><blockquote>Storing the token in the browser local storage is susceptible to cross-site scripting (XSS) attack. If an attacker can successfully run JavaScript code in your site, they can retrieve the tokens stored in local storage. XSS vulnerability arises when your website takes data from users without proper validation or from a third-party JavaScript code (like Google Analytics, jQuery, etc) included in the website.</blockquote><h2 id="let-s-start-building">Let's Start Building</h2><p>Create your Next.js app. We'll call the app <code>next-passwordless-login</code> and use the default starter app.</p><pre><code>yarn create next-app
cd next-passwordless-login &amp;&amp; yarn dev</code></pre><h3 id="update-our-website">Update our website</h3><p>Update your <code>pages/index.js</code> . Delete everything except the styling and the container div, then add this inside the container div.</p><figure><pre><code>&lt;main&gt;
    &lt;h1 className="title"&gt;Passwordless App.&lt;/h1&gt;

    {/* 1️⃣ TODO: Setup a div to contain the form */}
    
    &lt;div className="grid"&gt;
        &lt;div className="card"&gt;
            &lt;h3&gt;Public Endpoint&lt;/h3&gt;
            &lt;p&gt;You should be able to access this when not logged in&lt;/p&gt;
        &lt;/div&gt;

        &lt;div className="card"&gt;
            &lt;h3&gt;Private Endpoint&lt;/h3&gt;
            &lt;p&gt;You need to log in to access this endpoint&lt;/p&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/main&gt;</code></pre><figcaption>pages/index.js</figcaption></figure><h3 id="step-1-show-the-register-login-form">Step 1: Show the Register/Login form</h3><p>Install the dependencies:</p><pre><code>yarn add cotter cotter-node</code></pre><p>Add a div to contain the form below our title in <code>pages/index.js</code></p><figure><pre><code>&lt;h1 className="title"&gt;Passwordless App.&lt;/h1&gt;

{/* 1️⃣ TODO: Setup a div to contain the form */}
&lt;div id="cotter-form-container" style={{ width: 300, height: 300 }} /&gt;</code></pre><figcaption>pages/index.js</figcaption></figure><p>Then import and initialize Cotter to embed the email form.</p><figure><pre><code>// 1️⃣ import Cotter verification form and useEffect from react
import Cotter from "cotter";
import { useEffect } from "react";</code></pre><figcaption>top of pages/index.js</figcaption></figure><figure><pre><code>export default function Home() {
  // 1️⃣ Initialize and show the form
  // Add the lines here
  useEffect(() =&gt; {
    var cotter = new Cotter(API_KEY_ID); // 👈 Specify your API KEY ID here
    cotter
      .signInWithOTP()
      .showEmailForm()
      .then(payload =&gt; {
        console.log(payload);
        alert("Success");
      })
      .catch(err =&gt; console.log(err));
      
  }, []);
  // until here

  return (...);
}</code></pre><figcaption>pages/index.js</figcaption></figure><p>You need to add your <code>API_KEY_ID</code> here. <a href="https://dev.cotter.app/">Create a free account</a> at Cotter, then create a Project and take notes of the API Keys.</p><p>Now you should be able to see the login form like below. <br></p><figure><img src="https://blog.cotter.app/content/images/2020/05/image.png"></figure><p>The form will automatically send an email as necessary and show an input to enter the code. It won't send another email if you've already verified your email in this browser.</p><h2 id="step-2-keep-users-logged-in-with-access_token">Step 2: Keep users logged in with <code>access_token</code></h2><h3 id="read-the-console-log">Read the <code>console.log</code> </h3><p>Try entering your email and logging-in. You should see that the <code>payload</code> we receive in the <code>OnSuccess</code> function contains the following object:</p><pre><code>{
  "token": {...},
  "email": "<a href="https://blog.cotter.app/cdn-cgi/l/email-protection" data-cfemail="b2c6d7d3dff2d1ddc6c6d7c09cd3c2c2">[email&nbsp;protected]</a>",
  "oauth_token": {
    "access_token": "eyJhbGciOiJFUzI1NiIsIn...",
    "id_token": "eyJhbGciOiJFUzI1NiIsInR5cC...",
    "refresh_token": "199:doZor3GtgsrYo4R7L...",
    "expires_in": 3600,
    "token_type": "Bearer",
    "auth_method": "OTP"
  },
  "user": {
    "ID": "ecadbd2c-56f8-4078-b45d-f17786ed499e", // Cotter User ID
    ...
  }
}</code></pre><p>We want to use the <code>access_token</code> in this tutorial, so let's grab that and store it in <code>localStorage</code>.</p><figure><pre><code>  useEffect(() =&gt; {
    var cotter = new Cotter(API_KEY_ID); // 👈 Specify your API KEY ID here
    cotter
      .signInWithOTP()
      .showEmailForm()
      .then(payload =&gt; {
        console.log(payload);
-        alert("Success");
        
+        // 2️⃣(a) Store the access token and set logged in
+        localStorage.setItem("ACCESS_TOKEN", payload.oauth_token.access_token);
+        setIsLoggedIn(true);
      })
      .catch(err =&gt; console.log(err));
  }, []);</code></pre><figcaption>pages/index.js</figcaption></figure><p>Now let's define <code>setIsLoggedIn()</code>, this will help us show whether the user is logged in or not.</p><figure><pre><code>     import Cotter from "cotter";
     import { useEffect } from "react";
+    import { useState } from "react";

    export default function Home() {
+      // 2️⃣(a) Show if the user is logged in.
+      var [isLoggedIn, setIsLoggedIn] = useState(false);</code></pre><figcaption>pages/index.js</figcaption></figure><p>We also want to check if the <code>localStorage</code> contains <code>ACCESS_TOKEN</code> every time the page loads and update our <code>isLoggedIn</code> variable. Add this below the first <code>useEffect()</code> .</p><figure><pre><code>// 1️⃣ Initialize and show the form
useEffect(() =&gt; {...}, []);

// Add the lines below here
// 2️⃣(b) Check if the ACCESS_TOKEN exists every time the page loads
useEffect(() =&gt; {
    if (localStorage.getItem("ACCESS_TOKEN") != null) {
        setIsLoggedIn(true);
    }
}, []);</code></pre><figcaption>pages/index.js – below the first useEffect</figcaption></figure><p>Now let's show if the user is logged in below our form:</p><figure><pre><code>{/* 2️⃣(c) Show if the user is logged in. */}
&lt;p&gt;
    {isLoggedIn ? "✅ You are logged in" : "❌ You are not logged in"}
&lt;/p&gt;</code></pre><figcaption>pages/index.js</figcaption></figure><h2 id="step-3-logging-out">Step 3: Logging-out</h2><p>Logging-out is achieved by removing the <code>access_token</code> from our <code>localStorage</code>. Let's add the logout function inside <code>Home</code> before <code>return()</code> in <code>pages/index.js</code></p><figure><pre><code>// 3️⃣ Log out users
const logOut = () =&gt; {
    localStorage.removeItem("ACCESS_TOKEN");
    setIsLoggedIn(false);
};</code></pre><figcaption>pages/index.js inside <code>Home</code> before <code>return</code></figcaption></figure><p>And show the logout button:</p><figure><pre><code>{/* 3️⃣ Show the logout button */}
{isLoggedIn ? (
    &lt;div
        className="card"
        style={{ padding: 10, margin: 5 }}
        onClick={logOut}
    &gt;
    	Log Out
    &lt;/div&gt;
) : null}</code></pre><figcaption>pages/index.js</figcaption></figure><p>You can now see the if you're logged in and the logout button:</p><figure><img src="https://blog.cotter.app/content/images/2020/05/NextEmailLogin-LoginLogout.gif"></figure><h2 id="step-4-allowing-the-user-from-accessing-public-private-endpoints-">Step 4: Allowing the user from accessing public/private endpoints.</h2><p>Let's add 2 routes in our <code>pages/api</code> </p><pre><code>touch pages/api/public.js pages/api/private.js</code></pre><h3 id="defining-the-routes">Defining the routes</h3><p>Let's define our <code>/api/public</code> endpoint in <code>pages/api/public.js</code>. We're just going to return that the request is successful.</p><figure><pre><code>export default (req, res) =&gt; {
  res.statusCode = 200;
  res.end(
    "Success! This is a public resource, you can see it without logging in."
  );
};
</code></pre><figcaption>pages/api/public.js</figcaption></figure><p>Let's define our <code>/api/private</code> endpoint in <code>pages/api/private.js</code>. First we'll check if the authorization header exists.</p><figure><pre><code>// 2) TODO: Import Cotter

const checkJWT = (handler) =&gt; async (req, res) =&gt; {
  // 1) Check that the access_token exists
  if (!("authorization" in req.headers)) {
    res.statusCode = 401;
    res.end("Authorization header missing");
  }
  const auth = await req.headers.authorization;
  const bearer = auth.split(" ");
  const token = bearer[1];
  console.log(token);
    
  // 2) TODO: Validate the access_token
    
  handler(req, res);
}

const handler = (req, res) =&gt; {
  res.statusCode = 200;
  res.end(
    `Success! This is a private resource and you have the access_token to view it.`
  );
};

export default checkJWT(handler);</code></pre><figcaption>pages/api/private.js</figcaption></figure><p><strong>Now let's validate the access token. </strong></p><p>First, import Cotter's jwt validator function at the top of <code>pages/api/private.js</code></p><figure><pre><code>// 2) TODO: Import Cotter
import { CotterValidateJWT } from "cotter-node";</code></pre><figcaption>pages/api/private.js</figcaption></figure><p>Then call <code>CotterValidateJWT(token)</code> under step (2) inside <code>checkJWT</code>.</p><figure><pre><code>  // 2) TODO: Validate the access_token
  var valid = false;
  try {
    valid = await CotterValidateJWT(token);
  } catch (e) {
    console.log(e);
    valid = false;
  }
  if (!valid) {
    res.statusCode = 403;
    res.end("Authorization header is invalid");
  }</code></pre><figcaption>pages/api/private.js inside <code>checkJWT</code></figcaption></figure><h3 id="calling-the-public-and-private-api-endpoints">Calling the <code>/public</code> and <code>/private</code> API endpoints</h3><p>Let's go back to <code>pages/index.js</code> and add 2 functions: <code>getPublicResource</code> and <code>getPrivateResource</code> that will call the endpoint <code>/api/public</code> and <code>/api/private</code>.</p><figure><pre><code>export default function Home() {
  ...
  
  // 4️⃣ Get Public and Private Resources
  // Add the lines here
  var [publicResource, setPublicResource] = useState(null);
  var [privateResource, setPrivateResource] = useState(null);
  
  // Get Public Resource
  const getPublicResource = async () =&gt; {
    var resp = await fetch("/api/public");
    setPublicResource(await resp.text());
  };
    
  // Get Private Resource
  const getPrivateResource = async () =&gt; {
    var token = localStorage.getItem("ACCESS_TOKEN");
    if (token == null) {
      setPrivateResource("Token doesn't exist, you're logged-out");
      return;
    }
    var resp = await fetch("/api/private", {
      headers: {
        Authorization: `Bearer ${token}`,
      },
    });
    setPrivateResource(await resp.text());
  };
  // Until here
  
  return(...);
}</code></pre><figcaption>pages/index.js</figcaption></figure><p>Now let's call the 2 functions from our buttons and …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.cotter.app/passwordless-login-with-email-and-json-web-token-jwt-authentication-with-nextjs/">https://blog.cotter.app/passwordless-login-with-email-and-json-web-token-jwt-authentication-with-nextjs/</a></em></p>]]>
            </description>
            <link>https://blog.cotter.app/passwordless-login-with-email-and-json-web-token-jwt-authentication-with-nextjs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25433900</guid>
            <pubDate>Tue, 15 Dec 2020 19:19:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asset forfeiture is just theft]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25433867">thread link</a>) | @samizdis
<br/>
December 15, 2020 | https://pluralistic.net/2020/12/15/iowa-vs-16-tons-of-bricks/#stand-and-delivery | <a href="https://web.archive.org/web/*/https://pluralistic.net/2020/12/15/iowa-vs-16-tons-of-bricks/#stand-and-delivery">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1710">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
dma, dsa, pornhub, gatekeepers, payment processors, porn, sex workers, censorship, csam, civil forfeiture, civil asset forfeiture, highway robbery, eu, competition, trustbusting, voting, electronic voting, blockchain, distributed sudoku

Summary:
Pornhub and payment processors; Asset forfeiture is just theft; EU competition rules have real teeth; Blockchain voting is bullshit

URL:
https://pluralistic.net/2020/12/15/iowa-vs-16-tons-of-bricks/ 

Title:
Pluralistic: 15 Dec 2020 iowa-vs-16-tons-of-bricks

Bullet:
🥵

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: Bruce Schneier (schneier.com/), Naked Capitalism (https://www.nakedcapitalism.com/).

--><br>
<a href="https://pluralistic.net/2020/12/15/iowa-vs-16-tons-of-bricks/"><img src="https://i2.wp.com/craphound.com/images/15Dec2020.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/15Dec2020.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/15/iowa-vs-16-tons-of-bricks/%20#chokepoints">Pornhub and payment processors</a>: No one elected Visa and Mastercard.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/15/iowa-vs-16-tons-of-bricks/%20#stand-and-delivery">Asset forfeiture is just theft</a>: Cops steal more than robbers.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/15/iowa-vs-16-tons-of-bricks/%20#dsm">EU competition rules have real teeth</a>: The DSA and DMA are unveiled.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/15/iowa-vs-16-tons-of-bricks/%20#sudoku-voting">Blockchain voting is bullshit</a>: Yet another problem blockchain doesn't, can't and won't solve.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/15/iowa-vs-16-tons-of-bricks/%20#retro">This day in history</a>: 2005, 2010, 2015
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/15/iowa-vs-16-tons-of-bricks/%20#bragsheet">Colophon</a>: Recent publications, upcoming/recent appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="chokepoints"></a><br>
<img src="https://i2.wp.com/craphound.com/images/cuAEzvxi.png?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/cuAEzvxi.png?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Today, Pornhub took down all videos from unverified accounts after a New York Times report documented instances of nonconsensual pornography and child sexual abuse material on the service.</p>
<p>But the Times editorial isn't what spurred the shutdown: rather, it was the decision by Visa and Mastercard to withdrawn Pornhub's payment processing that prompted Pornhub to take action.</p>
<p>You may count that as a win. No one with any kind of moral center endorses nonconsensual pornography, especially when it involves children, and the less there is out there, the better the world is. I agree.</p>
<p>But we should also be worried about the growing monopolization of payment processing, and the role that payment processors are coming to play as gatekeepers for all kinds of activities.</p>
<p><a href="https://www.eff.org/deeplinks/2020/12/visa-and-mastercard-are-trying-dictate-what-you-can-watch-pornhub">https://www.eff.org/deeplinks/2020/12/visa-and-mastercard-are-trying-dictate-what-you-can-watch-pornhub</a></p>
<p>Mastercard and Visa are not qualified to make those calls. More importantly, no one elected them to make those calls. No law requires them to make those calls, and any law that tried would likely be unconstitutional.</p>
<p>If you want a sex industry based on consent and dignity, this should doubly worry you. After all, the first group of people shut down by payment processors' arbitrary judgements about what speech should and should exist were independent sex-workers.</p>
<p><a href="https://newrepublic.com/article/160488/nick-kristof-holy-war-pornhub">https://newrepublic.com/article/160488/nick-kristof-holy-war-pornhub</a></p>
<p>It took years for the payment processors to work their way up to the monopolistic, sprawling porn empire behind Pornhub – a Canadian company called Mindgeek that maintains the pretense that it is headquartered in Luxembourg,a notorious tax-evasion jurisdiction.</p>
<p>There's an old saw that the sex industry are early tech adopters. That's not quite true – rather, people with disfavored views are the first people for whom it's worth figuring out new technologies, since the old ones are unavailable to them.</p>
<p>Porn got into home films because most big cinemas wouldn't screen pornography. They got into VHS because it was easier to duplicate than film. They got into the net because it offered access without social costs of being seen in the adult section of the video rental place.</p>
<p>But while pornographers aren't early adopters, they ARE leading indicators. Pornographers' fights with novel censorship tactics are also trial-runs for using those tactics against OTHER people – and payment processors have already been pressed into service.</p>
<p>Visa and Mastercard threats have been used to block or shut down journalism, self-published books, dating services.</p>
<p>Mindgeek and Pornhub don't need our sympathy, but hard cases make bad law.</p>
<p>With only a few payment processors online, our ability to engage in legal conduct will always be at the mercy of Visa, Mastercard and a handful of others.</p>
<hr>
<p><a name="stand-and-delivery"></a><br>
<img src="https://i1.wp.com/craphound.com/images/Highway_Robbery-Clean-6.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/Highway_Robbery-Clean-6.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>If you're charged with a crime, the prosecutor has to prove you did it beyond a reasonable doubt; when it's a civil case, it's up to YOU to prove based on "preponderance of evidence" that you are innocent. A real difference, especially when the accused is an inanimate object.</p>
<p>In civil asset forfeiture, police seize the goods of people they suspect of criminal activity – without the need for a charge or conviction – and sue that property (i.e. "State of Iowa v Six Tons of Bricks") and you pay a lawyer to prove your property's innocence.</p>
<p>If your lawyer loses (or if you can't afford a lawyer), you lose your stuff, and the cops get to keep it or sell it and keep the money as an off-the-books black budget. Cops love this money – it lets them buy military surveillance gear.</p>
<p><a href="https://revealnews.org/article/chicago-and-los-angeles-have-used-dirt-box-surveillance-for-a-decade/">https://revealnews.org/article/chicago-and-los-angeles-have-used-dirt-box-surveillance-for-a-decade/</a></p>
<p>But not just that: one sheriff stole $70k from his townspeople and used the money to buy a muscle car that he only drove to and from work.</p>
<p><a href="https://www.ajc.com/news/local-govt--politics/feds-want-reimbursement-for-gwinnett-sheriff-70k-muscle-car/zkOidGb5oRfCHGO5RlZGsL/">https://www.ajc.com/news/local-govt–politics/feds-want-reimbursement-for-gwinnett-sheriff-70k-muscle-car/zkOidGb5oRfCHGO5RlZGsL/</a></p>
<p>City attorneys have worked with cops in the past to draw up "wish lists" of stuff they'd like to steal. The cops then nose around the owners of that stuff, looking for a pretence to seize it.</p>
<p><a href="https://www.nytimes.com/2014/11/10/us/police-use-department-wish-list-when-deciding-which-assets-to-seize.html">https://www.nytimes.com/2014/11/10/us/police-use-department-wish-list-when-deciding-which-assets-to-seize.html</a></p>
<p>Indeed, police departments future budgets projected their forfeiture revenues for years to come, effectively setting a quota for how much they had to steal from people each year:</p>
<p><a href="https://www.washingtonpost.com/investigations/dc-police-plan-for-future-seizure-proceeds-years-in-advance-in-city-budget-documents/2014/11/15/7025edd2-6b76-11e4-b053-65cea7903f2e_story.html">https://www.washingtonpost.com/investigations/dc-police-plan-for-future-seizure-proceeds-years-in-advance-in-city-budget-documents/2014/11/15/7025edd2-6b76-11e4-b053-65cea7903f2e_story.html</a></p>
<p>By 2014, US police were stealing more from the people they were sworn to protect than all the nation's burglars combined.</p>
<p><a href="https://www.armstrongeconomics.com/international-news/north_america/americas-current-economy/police-civil-asset-forfeitures-exceed-all-burglaries-in-2014/">https://www.armstrongeconomics.com/international-news/north_america/americas-current-economy/police-civil-asset-forfeitures-exceed-all-burglaries-in-2014/</a></p>
<p>No wonder that by 2015 Congress ended the program (don't worry, Trump reinstated and expanded it):</p>
<p><a href="https://www.washingtonpost.com/news/wonk/wp/2015/12/23/the-feds-just-shut-down-a-huge-program-that-lets-cops-take-your-stuff-and-keep-it/">https://www.washingtonpost.com/news/wonk/wp/2015/12/23/the-feds-just-shut-down-a-huge-program-that-lets-cops-take-your-stuff-and-keep-it/</a></p>
<p>Long after the program was ended, cops insisted that without forfeiture, they lacked the "incentive" to fight crime:</p>
<p><a href="https://www.greenvilleonline.com/story/news/taken/2019/02/03/sc-civil-forfeiture-police-defend-practice-say-funds-essential-law-enforcement/2746412002/">https://www.greenvilleonline.com/story/news/taken/2019/02/03/sc-civil-forfeiture-police-defend-practice-say-funds-essential-law-enforcement/2746412002/</a></p>
<p>They predicted that without forfeiture, police budgets would be too strained to fight crime, while criminals' coffers would swell. That was the scare-story New Mexico's legislature heard in 2015 when the state ended civil forfeiture.</p>
<p><a href="https://www.propublica.org/article/police-say-seizing-property-without-trial-helps-keep-crime-down-a-new-study-shows-theyre-wrong">https://www.propublica.org/article/police-say-seizing-property-without-trial-helps-keep-crime-down-a-new-study-shows-theyre-wrong</a></p>
<p>Five years later, the verdict is in, and the cops' predictions were wrong. A new report from The Institute for Justice shows that NM experienced no rise in crime, no drop in arrests, and "arrest/offense rates consistent with trends in two neighboring states, CO and TX."</p>
<p><a href="https://ij.org/report/policing-for-profit-3/">https://ij.org/report/policing-for-profit-3/</a></p>
<p>The study shows that far from being an instrument to return stolen goods or make restitution to crime victims, forfeiture is a way to fatten police budgets and personally enrich police officials. The seizures are mostly small-dollar amounts (not drug dealer money).</p>
<p>The larger seizures tell an even worse story: they include numerous instances in which a family home was seized because an underage offender sold small quantities of drugs from the premises – leaving families to spend fortunes defending their homes, often unsuccessfully.</p>
<hr>
<p><a name="dsm"></a><br>
<img src="https://i2.wp.com/craphound.com/images/flag_yellow_high-7.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/flag_yellow_high-7.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Back in September, we got a glimpse of upcoming EU tech competition rules, courtesy of a leak from the European Commission; they set out an ambitious set of rules on mergers, self-dealing, surveillance, and interoperability.</p>
<p><a href="https://pluralistic.net/2020/09/30/death-to-all-monopoly/#whither-structural-separation">https://pluralistic.net/2020/09/30/death-to-all-monopoly/#whither-structural-separation</a></p>
<p>The proposal wasn't perfect, but it was still exciting and encouraging, especially the interoperability proposals. Interop, after all, is the judo that every one of today's tech giants used to beat the companies that came before them.</p>
<p><a href="https://www.eff.org/deeplinks/2019/07/samba-versus-smb-adversarial-interoperability-judo-network-effects">https://www.eff.org/deeplinks/2019/07/samba-versus-smb-adversarial-interoperability-judo-network-effects</a></p>
<p>Today, the Commission published the first public draft of its rules (these need to get through the EU Parliament and the Council of national governments):</p>
<p><a href="https://ec.europa.eu/info/strategy/priorities-2019-2024/europe-fit-digital-age/digital-markets-act-ensuring-fair-and-open-digital-markets_en">https://ec.europa.eu/info/strategy/priorities-2019-2024/europe-fit-digital-age/digital-markets-act-ensuring-fair-and-open-digital-markets_en</a></p>
<p>The Digital Markets Act and its companion, the Digital Services Act, are the first major update to EU e-commerce rules in nearly two decades. A LOT has changed since the E-Commerce Directive!</p>
<p>For a quick overview, I recommend my EFF colleagues Christoph Schmon and Karen Gullo's analysis:</p>
<p><a href="https://www.eff.org/deeplinks/2020/12/european-commissions-proposed-regulations-require-platforms-let-users-appeal">https://www.eff.org/deeplinks/2020/12/european-commissions-proposed-regulations-require-platforms-let-users-appeal</a></p>
<p>The good news: the proposal requires due process for content removal – not a system where filters remove your content in an eyeblink and then you spend months or years in autoresponder hell trying to get it back up.</p>
<p>It doesn't require giant companies to police their users' speech, a rule that has led to mass-scale censorship, especially targeted against marginalized people who lack the platform and resources to complain when they get blocked.</p>
<p>It includes <em>very</em> steep penalties for companies that don't comply (up to 6% of annual global revenue), and a means to reach beyond EU borders to sanction companies that do business in the EU – both measures are powerful and potentially dangerous, and both need more specifics.</p>
<p>One disappointment: the interoperability measures have been weakened since September's leaks, though Article 6 of the Digital Markets Act is still a strict and far-reaching set of pro-competition rules with some look-in for interop.</p>
<p>Here's some A6 highlights, rules for the largest tech companies ("gatekeeper companies"):</p>
<ul>
<li>A ban on combining platform data with data from third parties and on automatically logging users from one service on a platform to other ones
</li>
<li>
<p>A requirement to let businesses on the platform offer services and pricing that directly competes with the platform owner</p>
</li>
<li>
<p>A requirement to let businesses on the platform do subscription and payment with users on their own terms, without having to use the platform</p>
</li>
<li>
<p>A ban on blocking businesses on the platform from complaining about abuses to regulators</p>
</li>
<li>
<p>A ban on …</p></li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2020/12/15/iowa-vs-16-tons-of-bricks/#stand-and-delivery">https://pluralistic.net/2020/12/15/iowa-vs-16-tons-of-bricks/#stand-and-delivery</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2020/12/15/iowa-vs-16-tons-of-bricks/#stand-and-delivery</link>
            <guid isPermaLink="false">hacker-news-small-sites-25433867</guid>
            <pubDate>Tue, 15 Dec 2020 19:16:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LinkedIn School of SRE]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25433858">thread link</a>) | @pranitbauva1997
<br/>
December 15, 2020 | https://linkedin.github.io/school-of-sre/ | <a href="https://web.archive.org/web/*/https://linkedin.github.io/school-of-sre/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="container">
      
      
        
      
      <main data-md-component="main">
        <div>
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                
                
<p><img src="https://linkedin.github.io/school-of-sre/img/sos.png" width="200"></p>
<p>In early 2019, we started visiting campuses across India to recruit the best and brightest minds to ensure LinkedIn, and all the services that make up its complex technology stack, is always available for everyone. This critical function at Linkedin falls under the purview of the Site Engineering team and Site Reliability Engineers (SREs) who are Software Engineers specializing in reliability. SREs apply the principles of computer science and engineering to the design, development and operation of computer systems: generally, large scale, distributed ones</p>
<p>As we continued on this journey we started getting a lot of questions from these campuses on what exactly the site reliability engineering role entails? And, how could someone learn the skills and the disciplines involved to become a successful site reliability engineer? Fast forward a few months, and a few of these campus students had joined LinkedIn either as interns or as full-time engineers to become a part of the Site Engineering team; we also had a few lateral hires who joined our organization who were not from a traditional SRE background. That's when a few of us got together and started to think about how we can onboard new graduate engineers to the Site Engineering team.</p>
<p>There is a vast amount of resources scattered throughout the web on what the roles and responsibilities of SREs are, how to monitor site health, production incidents, define SLO/SLI etc. But there are very few resources out there guiding someone on the basic skill sets one has to acquire as a beginner. Because of the lack of these resources, we felt that individuals have a tough time getting into open positions in the industry. We created the School Of SRE as a starting point for anyone wanting to build their career as an SRE.</p>
<p>In this course, we are focusing on building strong foundational skills. The course is structured in a way to provide more real life examples and how learning each of these topics can play an important role in day to day SRE life. Currently we are covering the following topics under the School Of SRE:</p>
<ul>
<li>Fundamentals Series<ul>
<li><a href="https://linkedin.github.io/school-of-sre/linux_basics/intro/">Linux Basics</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/git/git-basics/">Git</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/linux_networking/intro/">Linux Networking</a></li>
</ul>
</li>
<li><a href="https://linkedin.github.io/school-of-sre/python_web/intro/">Python and Web</a></li>
<li>Data<ul>
<li><a href="https://linkedin.github.io/school-of-sre/databases_sql/intro/">Relational databases(MySQL)</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/databases_nosql/intro/">NoSQL concepts</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/big_data/intro/">Big Data</a></li>
</ul>
</li>
<li><a href="https://linkedin.github.io/school-of-sre/systems_design/intro/">Systems Design</a></li>
<li><a href="https://linkedin.github.io/school-of-sre/security/intro/">Security</a></li>
</ul>
<p>We believe continuous learning will help in acquiring deeper knowledge and competencies in order to expand your skill sets, every module has added references which could be a guide for further learning. Our hope is that by going through these modules we should be able to build the essential skills required for a Site Reliability Engineer.</p>
<p>At Linkedin, we are using this curriculum for onboarding our non-traditional hires and new college grads into the SRE role. We had multiple rounds of successful onboarding experience with new employees and the course helped them be productive in a very short period of time. This motivated us to open source the content for helping other organizations in onboarding new engineers into the role and provide guidance for aspiring individuals to get into the role. We realize that the initial content we created is just a starting point and we hope that the community can help in the journey of refining and expanding the content. Checkout <a href="https://linkedin.github.io/school-of-sre/CONTRIBUTING/">the contributing guide</a> to get started.</p>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        

      
    </div></div>]]>
            </description>
            <link>https://linkedin.github.io/school-of-sre/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25433858</guid>
            <pubDate>Tue, 15 Dec 2020 19:15:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Estimated 1.56B face masks will have entered oceans in 2020]]>
            </title>
            <description>
<![CDATA[
Score 125 | Comments 163 (<a href="https://news.ycombinator.com/item?id=25433475">thread link</a>) | @Element_
<br/>
December 15, 2020 | https://oceansasia.org/covid-19-facemasks/ | <a href="https://web.archive.org/web/*/https://oceansasia.org/covid-19-facemasks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrap">

		
		<div id="primary">

			
			<div id="content">

				
				
<article>

	
<div itemprop="text">

	
			<div data-elementor-type="wp-page" data-elementor-id="847" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="3bc37af" data-element_type="section">
						<div>
							<div>
					<div data-id="b3f8c7c" data-element_type="column">
			<div>
							<div>
						<div data-id="11406f6" data-element_type="widget" data-settings="{&quot;aspect_ratio&quot;:&quot;169&quot;}" data-widget_type="video.default">
				<div>
					<p>
			<iframe allowfullscreen="" title="vimeo Video Player" src="https://player.vimeo.com/video/487781778?color&amp;autopause=0&amp;loop=0&amp;muted=0&amp;title=1&amp;portrait=1&amp;byline=1#t="></iframe>		</p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="b9da48f" data-element_type="section">
						<div>
							<div>
					<div data-id="0a02902" data-element_type="column">
			<div>
							<div>
						<div data-id="1d6a43b" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>Estimated 1.56 billion face masks will have entered oceans in 2020 - OceansAsia Report  
For Immediate Release: December 7, 2020
</h2>		</p>
				</div>
				<div data-id="e99a48e" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Our oceans will be flooded with an estimated 1.56 billion face masks in 2020 says a report released today by Hong-Kong-based marine conservation organization OceansAsia. This will result in an additional 4,680 to 6,240 metric tonnes of marine plastic pollution, says the report, entitled “Masks on the Beach: The Impact of COVID-19 on Marine Plastic Pollution.” These masks will take as long as 450 years to break down, slowly turning into&nbsp; micro plastics while negatively impacting marine wildlife and ecosystems.</p>
<p>The report used a global production estimate of 52 billion masks being manufactured in 2020, a conservative loss rate of 3%, and the average weight of 3 to 4 grams for a single-use polypropylene surgical face mask to arrive at the estimate.&nbsp;</p>
<p>“The 1.56 billion face masks that will likely enter our oceans in 2020 are just the tip of the iceberg,” says Dr. Teale Phelps Bondaroff, Director of Research for OceansAsia, and lead author of the report. “The 4,680 to 6,240 metric tonnes of face masks are just a small fraction of the estimated 8 to 12 million metric tonnes of plastic that enter our oceans each year.”</p></div>
				</div>
				</div>
				<div data-id="7f1289a" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="1024" height="384" src="https://oceansasia.org/wp-content/uploads/2020/12/facemasks2-1024x384.jpg" alt="" loading="lazy" srcset="https://oceansasia.org/wp-content/uploads/2020/12/facemasks2-1024x384.jpg 1024w, https://oceansasia.org/wp-content/uploads/2020/12/facemasks2-300x113.jpg 300w, https://oceansasia.org/wp-content/uploads/2020/12/facemasks2-768x288.jpg 768w, https://oceansasia.org/wp-content/uploads/2020/12/facemasks2-1536x576.jpg 1536w, https://oceansasia.org/wp-content/uploads/2020/12/facemasks2-2048x768.jpg 2048w, https://oceansasia.org/wp-content/uploads/2020/12/facemasks2-600x225.jpg 600w" sizes="(max-width: 1024px) 100vw, 1024px">											</p>
				</div>
				</div>
				<div data-id="793f0a3" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Plastic consumption, which has been steadily rising for years, increased significantly as a result of the COVID-19 pandemic.</p><p>“Hygiene concerns and greater reliance on take-away food has led to increased use of plastics, particularly plastic packaging,” says Gary Stokes, Director of Operations of OceansAsia. “Meanwhile, a number of measures designed to reduce plastic consumption, like single-use plastic bag bans, have been delayed, paused, or rolled back.”</p><p>The use of PPE, in particular face masks, has become a common tool used in preventing the spread of the virus, with many jurisdictions mandating the wearing of masks in public. The production of PPE has expanded in an attempt to meet skyrocketing demand, and PPE waste has also increased dramatically.&nbsp;</p><p>Single-use face masks are made from a variety of meltblown plastics and are difficult to recycle due to both composition and risk of contamination and infection. They enter oceans when they are littered, when waste management systems are inadequate or non-existent, or when these systems become overwhelmed due to increased volumes of waste.</p><p>“Marine plastic pollution is devastating our oceans,” says Gary Stokes, Operations Director of OceansAsia. “Plastic pollution kills an estimated 100,000 marine mammals and turtles, over a million seabirds, and even greater numbers of fish, invertebrates and other animals each year. It also negatively impacts fisheries and the tourism industry, and costs the global economy an estimated $13 billion USD per year.”</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="0dff72a" data-element_type="section">
						<div>
							<div>
					<div data-id="9ffb5fd" data-element_type="column">
			<div>
							<div>
						
				<div data-id="6dd1cc3" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>The report asks people to wear reusable masks whenever possible, dispose of masks responsibly and reduce their overall consumption of single-use plastic. It also calls on governments to:</p><ul><li>Implement policies designed to encourage the use of reusable masks, such as releasing guidelines regarding the proper manufacture and use of reusable masks.</li><li>Foster innovation and the development of sustainable alternatives to single-use plastic masks.</li><li>Discourage littering by increasing fines, and educate the public about responsible ways to dispose of masks.&nbsp;</li><li>Repair and improve waste management systems to reduce losses and spillage.&nbsp;</li></ul><p>“It is critical that we work to reduce our use of single-use plastics, and we all have a role to play,” says Dr. Phelps Bondaroff. “There are reusable and sustainable options for almost every single single-use plastic item. Please wear a reusable mask, unless absolutely necessary, and be sure to dispose of all masks responsibly.</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="8681e54" data-element_type="section">
						
		</section>
				<section data-id="c420295" data-element_type="section">
						
		</section>
						</div>
						</div>
					</div>
		
	
</div>

</article>

				
			</div><!-- #content -->

			
		</div><!-- #primary -->

		
	</div></div>]]>
            </description>
            <link>https://oceansasia.org/covid-19-facemasks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25433475</guid>
            <pubDate>Tue, 15 Dec 2020 18:45:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nushell 0.24 Released]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25433313">thread link</a>) | @praveenperera
<br/>
December 15, 2020 | https://www.nushell.sh/blog/2020-12-15-nushell_0_24.html | <a href="https://web.archive.org/web/*/https://www.nushell.sh/blog/2020-12-15-nushell_0_24.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>Nushell, or Nu for short, is a new shell that takes a modern, structured approach to your commandline. It works seamlessly with the data from your filesystem, operating system, and a growing number of file formats to make it easy to build powerful commandline pipelines.</p> <p>Today, we're releasing 0.24 of Nu. We've added a few new utilities, improved the existing date functionality, and more.</p>  <p>Nu 0.24 is available as <a href="https://github.com/nushell/nushell/releases/tag/0.24.1" target="_blank" rel="noopener noreferrer">pre-built binaries<span> <span>(opens new window)</span></span></a> or from <a href="https://crates.io/crates/nu" target="_blank" rel="noopener noreferrer">crates.io<span> <span>(opens new window)</span></span></a>. If you have Rust installed you can install it using <code>cargo install nu</code>.</p> <p><strong>Note:</strong> There was a build issue discovered immediately after release, so we've also released a hotfix (0.24.1) to address this issue.</p> <p>If you want all the goodies, you can install <code>cargo install nu --features=extra</code>.</p> <p>As part of this release, we also publish a set of plugins you can install and use with Nu. To install, use <code>cargo install nu_plugin_&lt;plugin name&gt;</code>.</p>  <h2 id="improvements"><a href="#improvements">#</a> Improvements</h2> <ul><li>added a <code>hash</code> command for creating hashes (notryanb, andrasio)</li> <li>impoved the public API by making <code>run_block</code> public (max-sixty)</li> <li><code>version</code> now shows more information about the build (fdncred)</li> <li><code>from csv</code> will show where errors happened if they occur (Dietr1ch)</li> <li><code>date</code> now has some new-and-improved subcommands (jz448)</li> <li>added a new <code>random chars</code> subcommand (gillespiecd)</li> <li>gitpod setup got fixed (jankeronmes)</li> <li>a new <code>math abs</code> command (xolve)</li></ul>  <p>Our work on the big update has continued, and we're looking forward to making it available soon. We're now down to the last three known outstanding issues that need to be resolved before the work can be merged into the main Nushell source code.</p> <p>As it lands, we'll need your help to try it out and give us feedback to help us continue to improve it.</p> <p>As always, if you see somewhere you'd like to help or just want to chat, come by the <a href="https://discord.gg/NtAbbGn" target="_blank" rel="noopener noreferrer">discord<span> <span>(opens new window)</span></span></a> and say hi!</p></div></div>]]>
            </description>
            <link>https://www.nushell.sh/blog/2020-12-15-nushell_0_24.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25433313</guid>
            <pubDate>Tue, 15 Dec 2020 18:32:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Org-Mode Is One of the Most Reasonable Markup Languages to Use for Text (2017)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25433296">thread link</a>) | @Tomte
<br/>
December 15, 2020 | https://karl-voit.at/2017/09/23/orgmode-as-markup-only/ | <a href="https://web.archive.org/web/*/https://karl-voit.at/2017/09/23/orgmode-as-markup-only/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>

Update 2017-09-25: Simplified the table syntax even more

</p>

<p>

Update 2018-04-06: Comments on the standardization argument

</p>

<p>

Update 2019-04-12: Extended syntax examples, "Makes Sense Outside of Emacs", "Tool Support" and added more backlinks

</p>

<p>

Update 2020-05-02: Comment by Ian Zimmerman

</p>

<p>

Disclaimer: this is a very nerdy blog entry. It is about <a href="https://en.wikipedia.org/wiki/Lightweight_markup_language">lightweight markup languages</a> and why I think that Org mode is the best lightweight markup language for many use-cases. And with lightweight markup language, I do mean the syntax, the way you express headings, lists, font variations such as bold face or italic, and such things.

</p>

<p>

Please do note that this is not about Emacs. This is about Org mode syntax and its advantages even when used outside of Emacs. You can type Org mode in <a href="http://www.vim.org/">vim</a>, <a href="https://en.wikipedia.org/wiki/Microsoft_Notepad">notepad.exe</a>, <a href="https://atom.io/">Atom</a>, <a href="https://notepad-plus-plus.org/">Notepad++</a>, and all other text editors out there. And in my opinion it does have advantages compared to the other, common lightweight markup standards such as <a href="https://en.wikipedia.org/wiki/Markdown">Markdown</a>, <a href="https://en.wikipedia.org/wiki/AsciiDoc">AsciiDoc</a>, <a href="https://en.wikipedia.org/wiki/Wiki#Editing">Wikitext</a> or <a href="https://en.wikipedia.org/wiki/ReStructuredText">reStructuredText</a>.

</p>

<p>

Of course, Org mode is my favorite syntax. Despite my personal choice you will see that I've got some pretty convincing arguments that underline my statement as well. So this is not just a matter of personal taste.

</p>

<p>

If you already have a grin on your face because you don't have any clue what this is all about: keep on reading. It makes an excellent example for making fun of nerds at your next dinner party. ;-)

</p>

	  <header><h2>Org-Mode Is Intuitive, Easy to Learn and Remember</h2></header>

<p>

Here you are. This is almost anything you need to know about Org mode syntax:

</p>

	  <div>
	  <pre> * This Is A Heading
 ** This Is A Sub-Heading
 *** And A Sub-Sub-Heading

 Paragraphs are separated by at least one empty line.

 *bold* /italic/ _underlined_ +strikethrough+ =monospaced=
 [[http://Karl-Voit.at][Link description]]
 http://Karl-Voit.at → link without description

 - list item
 - another item
   - sub-item
     1. also enumerated
     2. if you like
 - [ ] yet to be done
 - [X] item which is done

 : Simple pre-formatted text such as for source code.
 : This also respects the line breaks. *bold* is not bold here.	  </pre>
    </div>

<p>

And yes, for the people with advanced syntax in mind, this is not everything. Just the basics. A common objection is that source code needs a begin and an end marker instead of a string prefix like <code>: </code> and Org mode is providing this as well:

</p>

	  <div>
	  <pre> #+BEGIN_SRC python
 myresult = 42 * 23
 print('Hello Europe! ' + str(myresult))
 #+END_SRC	  </pre>
    </div>

<p>

I've seen many coworkers who typed Org mode markup when taking notes in their text editor. And they did not even know anything about it. So it is that intuitive I'd say.

</p>

<p>

While I was learning Org mode, I did not even use a cheat-sheet for the syntax as I normally do. It was very natural for me to type Org mode right from the start.

</p>

<p>

Tables are a bit more complicated like in all other markup languages I know of:

</p>

	  <div>
	  <pre> | My Column 1 | My Column 2 | Last Column |
 |-------------+-------------+-------------|
 |          42 | foo         | bar         |
 |          23 | baz         | abcdefg     |
 |-------------+-------------+-------------|
 |          65 |             |             |	  </pre>
    </div>

<p>

You most probably won't type a table like this outside of Emacs. The manual alignment without tool-support is very tedious. But even here you are able to deliver a perfectly fine Org mode table by simply ignoring the alignment altogether:

</p>

	  <div>
	  <pre> | My Column 1|My Column 2 | Last Column |
 |-
 | 42 | foo | bar|
 | 23 | baz | abcdefg|
 |-
 | 65 |||	  </pre>
    </div>

	  <header><h2>Org-Mode Is Standardized</h2></header>

<p>

This is an almost ridiculous argument because in my opinion a markup is of no use when it is not the same for tool A as for tool B.

</p>

<p>

However, there are markup languages that are different. For example the very widely used markup language named <a href="https://en.wikipedia.org/wiki/Markdown">Markdown</a> has many flavors to choose from:

</p>
<ul>
<li>the original writeup and implementation by John Gruber</li>
<li><a href="https://en.wikipedia.org/wiki/Markdown#Markdown_Extra">Markdown Extra</a></li>
<li><a href="https://en.wikipedia.org/wiki/MultiMarkdown">MultiMarkdown</a></li>
<li><a href="http://github.com/">GitHub</a> Flavored Markdown</li>
<li><a href="https://en.wikipedia.org/wiki/Markdown#CommonMark">CommonMark</a> which tries to standardize the Markdown standard (again)</li>
</ul>

<p>

<a href="https://pandoc.org/">Pandoc</a> lists six different Markdown flavors as output formats. This is an absolutely bad situation which foils the original idea behind lightweight markup languages. When some web service tells me that I can use "Markdown" for a text field, I have to dig deeper to find out which of those many different Markdown standards the web page is talking about. After this I will have to continue and look for a cheat-sheet of this dialect because nothing is more difficult to differentiate than multiple standards that are almost the same but not really the same. A usability hell. I get furious every time I have to enter this hell.

</p>

<p>

An additional notion is the lack of standardization of file extensions using Markdown syntax. I've seen <code>.md</code>, <code>.mkdn</code>, <code>.markdown</code> and even <code>.txt</code> (in Markdown).

</p>

<p>

With Org mode, life is easy. The snippet from the previous section explains all there is. Any tool that interprets Org mode accepts this simple and easy to remember syntax. The extension is always <code>.org</code>.

</p>

	  <header><h2>Org-Mode Is Consistent</h2></header>

<p>

Many lightweight markup languages do offer multiple ways of typing headings. There are basically three ways of defining headings:

</p>
<ol>
<li>Prefix headings</li>
<li>Pre- and postfix headings</li>
<li>Underlined headings</li>
</ol>

<p>

Here are some examples for each category:

</p>

	  <div>
	  <pre> Prefix headings:

 # Heading 1
 ## Heading 2
 ### Heading 3

 Pre- and postfix headings:

 = Heading 1 =
 == Heading 2 ==
 === Heading 3 ===

 Underlined headings:

 Heading 1
 =========

 Heading 2
 ~~~~~~~~~

 Heading 3
 *********	  </pre>
    </div>

<p>

I prefer the prefix heading style. Org mode use this as well with <code>*</code> as prefix characters. The more asterisks, the deeper the level of the heading is.

</p>

<p>

<b>Pre- and postfix headings</b> do offer bad usability. The user has manually synchronize the number of prefix character with the number of postfix characters. And it is totally unclear how something like <code>=<code> heading </code>==</code> with different numbers of pre/postfix characters is going to turn out when being interpreted.

</p>

<p>

And in case the user already used a markup language with simple prefix headings, it is not logical why there is the need for the postfix characters at all.

</p>

<p>

Even worse than this is the <b>underlined heading category</b>. The user is completely irritated for multiple reasons. Besides the tedious manual work to align the stupid heading characters with the heading title, it is not clear what characters must be used for those heading lines. If you've got a bigger document with different levels of headings you get confused which heading character stands for which heading level.

</p>

<p>

Are the tilde characters level one? Or was it the equals characters? And how about asterisks? Without a cheat-sheet, the occasional markup user is completely lost.

</p>

<p>

This gets even more worse: some markup languages let you choose your "order" of heading characters. This results in weird situations. For example one author is starting to write a reStructuredText document using her favorite heading syntax. A second author is joining in and has to analyze the document in order to know what heading syntax he must use.

</p>

<p>

In the <a href="http://docutils.sourceforge.net/docs/user/emacs.html">reStructuredText mode of Emacs</a> you can find following function:

</p>

<blockquote>You can visualize the hierarchy of the section adornments in the
current buffer by invoking <code>rst-display-adornments-hierarchy</code>, bound
on <code>C-c C-a C-d</code>. A temporary buffer will appear with fake section
titles rendered in the style of the current document. This can be
useful when editing other people's documents to find out which section
adornments correspond to which levels.</blockquote>

<p>

Yes, you got it right, it is true: this function's only purpose is to generate a dummy-hierarchy of headings to visualize which markup has to be used for heading 1, which one for heading 2 and so forth just for this single document. What a bad design decision of the markup when you need such hacks just to know how a heading should look like in a markup even if you are familiar with in the first place.

</p>

<p>

Here is one more: some markup languages even allow <b>mixed heading styles</b>. You can use an underlined heading style for heading level 1, a prefix style for level 2, another underlining style for level 3 and so forth. Now the chaos is a perfect one.

</p>

<p>

Let's have a look at a different markup element: <b>external links</b>. As you already remember in Org mode, a link looks like this:

</p>

	  <div>
	  <pre> [[http://Karl-Voit.at][my home page]]	  </pre>
    </div>

<p>

The only difficult thing here is to remember that the URL is at the beginning and the description follows after the URL. Many markup languages do add additional and unnecessary levels of difficulties.

</p>

<p>

Here are some <a href="https://en.wikipedia.org/wiki/Lightweight_markup_language#Link_syntax">examples from Wikipedia</a> and comments by me where a user might be irritated.

</p>

<p>

AsciiDoc:

</p>

	  

<p>

The form is simple but for complex URLs, the <code>[Text]</code> might look like being part of the URL itself. Not beautiful but at least something I could live with.

</p>

<p>

Markdown:

</p>

	  <div>
	  <pre> [Text](http://example.com)
 [Text](http://example.com "Title")	  </pre>
    </div>

<p>

Brackets or parentheses first? Why using different kind of markup characters in the first place like only brackets? Is the <code>Title</code> part of the URL? Why not part of <code>Text</code>? Very confusing design decisions from my point of view.

</p>

<p>

reStructuredText:

</p>

	  <div>
	  <pre> `Text &lt;http://example.com/&gt;`_	  </pre>
    </div>

<p>

Holy moly. This is some weird stuff. First, you have to grave accents <code>`</code> and not apostrophes <code>'</code>. Then what about the underscore character at the end? This is as complicated as you can define a simple URL. I'd even prefer the hard to type HTML version of linking. A disaster for something which has "lightweight" in its class name.

</p>

<p>

Even with the most basic formatting syntax, Markdown (I assume in all flavors of it) shows a high level of inconsistency:

</p>

	  <div>
	  <pre> _italic_, **bold**, `monospace`, ~~strikethrough~~	  </pre>
    </div>

<p>

Why is it that italic and monospace require only one character before and after the string in-between and others require two? It's …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://karl-voit.at/2017/09/23/orgmode-as-markup-only/">https://karl-voit.at/2017/09/23/orgmode-as-markup-only/</a></em></p>]]>
            </description>
            <link>https://karl-voit.at/2017/09/23/orgmode-as-markup-only/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25433296</guid>
            <pubDate>Tue, 15 Dec 2020 18:30:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Expo Application Services (EAS): Build and Submit]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25432692">thread link</a>) | @ccheever
<br/>
December 15, 2020 | https://blog.expo.io/expo-application-services-eas-build-and-submit-fc1d1476aa2e | <a href="https://web.archive.org/web/*/https://blog.expo.io/expo-application-services-eas-build-and-submit-fc1d1476aa2e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@notbrent?source=post_page-----fc1d1476aa2e--------------------------------" rel="noopener"><img alt="Brent Vatne" src="https://miro.medium.com/fit/c/96/96/1*yVR62mI8kYqjUX-xsnGDeA.jpeg" width="48" height="48"></a></p></div></div></div></div><p id="8ba7">Today we’re excited to announce the public preview of two brand new services: EAS Build and Submit. These are the first services available from Expo Application Services (EAS), our new cloud services.</p><h2 id="233e">Feature Preview</h2><p id="1abe">EAS Build is a new service that takes everything good about the Expo build service (<code>expo build:[ios|android]</code>) and makes it available to all React Native apps. You can set your app up to build for distribution in minutes or even less, thanks to <a href="https://docs.expo.io/app-signing/managed-credentials/" rel="noopener">automatically managed app signing credentials</a> and defaults that <em>just work</em> for most Expo and React Native apps.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Terminal window running EAS Build in order to configure a new project, generate a keystore, and start a build." src="https://miro.medium.com/max/2304/1*Yfou6wa_fi05Ps8anXeJBA.png" width="1152" height="684" srcset="https://miro.medium.com/max/552/1*Yfou6wa_fi05Ps8anXeJBA.png 276w, https://miro.medium.com/max/1104/1*Yfou6wa_fi05Ps8anXeJBA.png 552w, https://miro.medium.com/max/1280/1*Yfou6wa_fi05Ps8anXeJBA.png 640w, https://miro.medium.com/max/1400/1*Yfou6wa_fi05Ps8anXeJBA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*Yfou6wa_fi05Ps8anXeJBA.png?q=20"></p></div></div></div><figcaption>In this screenshot, we go from a brand new project to release build running on EAS Build in 30 seconds.</figcaption></figure><p id="83b0">We’ve also added support for “<a href="https://docs.expo.io/build/internal-distribution/" rel="noopener">internal distribution</a>” — a feature that makes it easy for you to share test builds with colleagues and friends without going through an app store, by using <a href="https://expo.canny.io/feature-requests/p/iosbuild-with-adhoc-provision-profile" rel="noopener">ad hoc provisioning</a> on iOS and standard APK side-loading on Android. Generating and updating the ad hoc provisioning profile can be handled entirely for you by EAS Build.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/7148/1*9sydz-IelPB7FDMBSgRpwg.png" width="3574" height="1018" srcset="https://miro.medium.com/max/552/1*9sydz-IelPB7FDMBSgRpwg.png 276w, https://miro.medium.com/max/1104/1*9sydz-IelPB7FDMBSgRpwg.png 552w, https://miro.medium.com/max/1280/1*9sydz-IelPB7FDMBSgRpwg.png 640w, https://miro.medium.com/max/1400/1*9sydz-IelPB7FDMBSgRpwg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*9sydz-IelPB7FDMBSgRpwg.png?q=20"></p></div></div></div><figcaption>Easily share builds with your team using “<a href="https://docs.expo.io/build/internal-distribution/" rel="noopener">internal distribution”</a>.</figcaption></figure><p id="2d9a">EAS Build <em>currently</em> works best with bare React Native apps. If you use the Expo managed workflow and end up needing to move to the bare workflow, you can transition seamlessly to EAS Build — just run <code>eas build</code> instead of <code>expo build</code> after ejecting.</p><h2 id="7c43">Coming later in 2021: full support for Expo managed workflow</h2><p id="608d">With EAS Build, you can include libraries with native code that aren’t part of the Expo standard library. For many of you, the Expo managed workflow is nearly a perfect fit — except for that one piece of functionality you absolutely have to have in your app, but that isn’t part of the Expo standard library (whether that’s <a href="https://expo.canny.io/feature-requests/p/in-app-purchases" rel="noopener">IAP</a> support, <a href="https://expo.canny.io/feature-requests/p/webrtc" rel="noopener">WebRTC</a>, <a href="https://expo.canny.io/feature-requests/p/bluetooth-api" rel="noopener">Bluetooth</a>, or something more <a href="https://expo.canny.io/feature-requests/p/data-over-sound" rel="noopener">esoteric</a>).</p><p id="9e41">EAS Build will let you use any compatible library from GitHub or npm or that you write yourself, even if it has native code in it.</p><p id="c8c2">EAS Build also lets you build smaller, stripped-down binaries that include only the code your application needs, which means <a href="https://github.com/expo/fyi/blob/master/managed-app-size.md" rel="noopener">a smaller install size for your users</a>.</p><p id="339b">There’s already early support for Expo managed apps in EAS Build in the preview, but it’s not quite ready for production yet. There’s also a big missing piece: how do you get a new version of your Expo development client app that includes your bespoke native runtime? We’re working on this, and we’ll have answers for you in the coming months.</p><p id="a288">These are some of the most common requests we hear from Expo developers today, so we’re extremely excited to be close to getting a solution into your hands.</p><h2 id="8c79">Feature Preview</h2><p id="40a1">When you want to put your app into the App Store and Play Store, you can use a single command from your terminal or from CI to submit it.</p><p id="c0ac">When you run <code>eas submit</code>, your app binary will be uploaded to EAS and then submitted to the respective app store from there. This means fewer dependencies to install on your machine, and that you can submit your apps from your Windows, Linux, or macOS computer to any app store.</p><p id="1d7c">We guide you through your first submission and try to make your <em>n</em>th submission as easy as possible by catching common mistakes and giving you guidance on how to resolve them. For example, if you’re missing a privacy policy, <a href="https://expo.fyi/missing-privacy-policy" rel="noopener">we have an FYI for that</a>.</p><p id="4905"><strong><em>Expo</em></strong> is the open source project, and <strong><em>Expo Application Services</em></strong> offers hosted cloud services built for both Expo and React Native.</p><p id="6d1f"><strong>You won’t need EAS to use Expo, </strong>which will always be open source and free. You can choose a different CI/CD service or use your own hardware.</p><p id="0569">Likewise, <strong>you’ll be able to take advantage of EAS with any React Native project, whether or not it uses Expo’s open source tools</strong>. EAS is designed for developers who specifically want their builds, updates and/or other parts of their app operations, development and collaboration workflows streamlined by a cloud service designed purposefully for and deeply integrated with React Native and Expo.</p><p id="ea39">We don’t want to disrupt anyone who is counting on Expo services to make software, and so we’ll continue to operate the existing build, update, and notification services indefinitely. So, if you’re happy with the way you’re using those services now, you don’t need to do anything differently and you can continue using them.</p><p id="84cc">To reduce confusion with EAS versions of the services, we’re going to start calling the existing free services the “Classic” Expo services. So, “Classic” Build, Updates, and Notifications.</p><p id="a6f7">That said, EAS is where most of our investment and effort on the services side will go in the future, so you should expect to see each EAS service keep getting better, more powerful, and easier to use as time goes on. Keep an eye out for the EAS Update preview, launching in early 2021.</p><p id="c6cd">We’ll always maintain a free tier that can meet the needs of individual and hobbyist developers building small apps. We’ll announce further pricing details closer to the date when EAS services graduate from preview in 2021.</p><p id="be36">If you’re currently paying for Expo Developer Services, we’ve automatically updated your plan to EAS Priority Plan. EAS Priority will have the same price point and feature set as your old Developer Services plan, plus preview access to EAS Build and Submit. You don’t need to do anything: you’ll be moved over automatically.</p><p id="7bc9">The previews of EAS Build and Submit are available to developers subscribed to the <a href="https://expo.io/pricing" rel="noopener">EAS Priority Plan</a>. If you’re not yet a subscriber, <a href="https://expo.io/pricing" rel="noopener">you can try it out for free for a month</a>. If you want to try the preview services out but don’t have access to a credit card, please reach out to us <a href="https://www.twitter.com/expo" rel="noopener">on Twitter</a> and we can help you out.</p><p id="9298">Once you’re signed up, you can find everything that you need to know in the <a href="https://docs.expo.io/eas" rel="noopener">Feature Preview documentation</a>. If you’d like to watch a quick video walkthrough of EAS Build and Submit, check out this YouTube video:</p><figure><div></div></figure></div></div></section></div></div>]]>
            </description>
            <link>https://blog.expo.io/expo-application-services-eas-build-and-submit-fc1d1476aa2e</link>
            <guid isPermaLink="false">hacker-news-small-sites-25432692</guid>
            <pubDate>Tue, 15 Dec 2020 17:44:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building and Testing 50 UI States with Decision Tables]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25432524">thread link</a>) | @hachibu
<br/>
December 15, 2020 | https://hachibu.net/posts/2020/building-and-testing-50-ui-states-with-decision-tables/ | <a href="https://web.archive.org/web/*/https://hachibu.net/posts/2020/building-and-testing-50-ui-states-with-decision-tables/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://hachibu.net/posts/2020/building-and-testing-50-ui-states-with-decision-tables/images/featured.png"><figcaption><p>Illustration: Hachibu</p></figcaption></figure><h4 id="introduction">Introduction</h4><p>Decision tables are a useful tool for modeling complex logic. And when you’re
building user interfaces, things can get very complicated – e.g., show a pop-up
every other Monday between Midnight UTC+5:30 and Noon UTC+12:45 to trial
customers born on a Leap Year.</p><p>In this post, I’m going tell you a story about how I lost my cool trying to
build and test 50 different UI states and how decision tables saved my project.
By the end of this post, you’ll have a problem solving tool that is
generalizable across other programming domains besides UI programming.</p><h4 id="what-are-decision-tables">What Are Decision Tables?</h4><p>Decision tables are a visual way to map conditions to outcomes in a tabular
format. Organizing information in a tabular format is nothing new. For example,
Boolean Algebra uses truth tables to map inputs to outputs for logical
operations such as AND and OR.</p><table><thead><tr><th><code>AND (&amp;&amp;)</code></th><th>False</th><th>True</th></tr></thead><tbody><tr><td><strong>False</strong></td><td>False</td><td>False</td></tr><tr><td><strong>True</strong></td><td>False</td><td>True</td></tr></tbody></table><table><thead><tr><th><code>OR (||)</code></th><th>False</th><th>True</th></tr></thead><tbody><tr><td><strong>False</strong></td><td>False</td><td>True</td></tr><tr><td><strong>True</strong></td><td>True</td><td>True</td></tr></tbody></table><p>Since it’s just a table, you get all of the benefits associated with organizing
your information in a tabular format.</p><ul><li>Missing outcomes are visibly obvious so you’re forced to immediately address
any gaps in your logic and ensure that you’ve considered every case.</li><li>They can be used as a design document when communicating with your peers; a
reference when you’re writing code; and a complete specification when you’re
testing code.</li></ul><h4 id="the-setup">The Setup</h4><p>This story took place at a SaaS startup that helped its customers collect and
manage product feedback. They also had a Machine Learning algorithm that could
automatically categorize feedback by topic and sentiment. For example, the
feedback “Constant rendering issues” would be tagged with “BUGS” and given a
negative sentiment by the ML algorithm. Customers could also create their own
tags to match specific words and phrases. These were called text match tags.</p><p>I was teamed up with a designer and a backend engineer to add 2 checkboxes to
the UI which would allow customers to add tighter constraints to their text
match tags. The goal of this feature was to improve the results of text match
tags by letting customers define rules around how their tags would be applied to
feedback. These 2 checkboxes would allow text match tags to be aware of more
information like feedback metadata such as filters and the tags that were
applied by the ML algorithm.</p><p><a href="https://hachibu.net/posts/2020/building-and-testing-50-ui-states-with-decision-tables/images/ui-screenshot.png"><img src="https://hachibu.net/posts/2020/building-and-testing-50-ui-states-with-decision-tables/images/ui-screenshot.png"></a></p><h4 id="the-confrontation">The Confrontation</h4><p>This project appeared to be straight-forward. I just had to build and connect 2
checkboxes. What could be easier? So, I just started coding, and I opened a pull
request for code review shortly thereafter. It wasn’t until I entered QA testing
in our staging environment that my troubles began.</p><p>Every time my code got reviewed, my teammates would keep finding new bugs and
regressions. This went on for days as I attempted to brute-force my way through
the project. I knew that I didn’t have a complete understanding of what I was
supposed to be building, but I soldiered on out of desperation.</p><p>My frustration was growing, and I could sense that I was approaching my limit.
So, I put the project on pause so I could sleep on it. After sleeping on it, I
came to the realization that there were too many states for me to keep track of.
I would need to write down and enumerate every single state so that I could
confidently implement and test this feature.</p><p>Each hide or show decision relied on the value of 2 variables: the parent tag
mode and the child tag mode. This reminded me of something I had studied years
ago while implementing logic gate functions: Boolean Algebra Truth Tables. With
truth tables in mind, I eventually stumbled upon decision tables. Working
together with the backend engineer for this project, we created the following
decision tables.</p><p><a href="https://hachibu.net/posts/2020/building-and-testing-50-ui-states-with-decision-tables/images/spreadsheet-1.png"><img src="https://hachibu.net/posts/2020/building-and-testing-50-ui-states-with-decision-tables/images/spreadsheet-1.png"></a>
<a href="https://hachibu.net/posts/2020/building-and-testing-50-ui-states-with-decision-tables/images/spreadsheet-2.png"><img src="https://hachibu.net/posts/2020/building-and-testing-50-ui-states-with-decision-tables/images/spreadsheet-2.png"></a></p><p>Once we finished the decision tables, I breathed a sigh of relief because all of
the logic was now crystal clear. But I was also shocked to discover that this
seemingly simple feature had 50 different UI states. A parent tag has 5 options,
and a child tag has 5 options. So each checkbox has 5 * 5 combinations: 25
states. And with 2 checkboxes, that’s 25 + 25 combinations: 50 total states.</p><h4 id="the-resolution">The Resolution</h4><p>I was finally ready to start programming but first I would need to decide how to
translate a decision table into a data structure. Building your programs around
well designed data structures is very important, which reminds me of a quote by
Linus Torvalds (the creator of Linux and Git).</p><blockquote><p>git actually has a simple design, with stable and reasonably well-documented
data structures. In fact, I'm a huge proponent of designing your code around
the data, rather than the other way around, and I think it's one of the
reasons git has been fairly successful […] I will, in fact, claim that the
difference between a bad programmer and a good one is whether he considers his
code or his data structures more important.</p></blockquote><p>What kind of data structure could represent a table? Given that a table is
comprised of rows and columns, it seemed obvious to use a 2-dimensional data
structure like an array of arrays or a map of maps.</p><p>I chose a map of maps, because it would allow me to get my answer quickly by
2-dimensionally indexing on parent tag mode and child tag mode. The outer map
would represent the rows which are the parent tag modes; the inner map would
represent the columns which are the child tag modes; and the cells would
represent the hide or show decision as a boolean.</p><p>The following code is written in TypeScript which should seem familiar to you
if you’ve written JavaScript before. That’s because the syntax of TypeScript and
JavaScript are closely related. The biggest difference between TypeScript and
JavaScript is that the former layers additional syntax for types on top of the
latter.</p><div><pre><code data-lang="typescript"><span>type</span> <span>TagMode</span> <span>=</span> <span>'none'</span> <span>|</span> <span>'manual'</span> <span>|</span> <span>'text_match'</span> <span>|</span> <span>'smart'</span> <span>|</span> <span>'managed'</span>

<span>type</span> <span>Tag</span> <span>=</span> <span>{</span>
  <span>mode</span>: <span>TagMode</span>
<span>}</span>

<span>type</span> <span>DecisionTable</span> <span>=</span> <span>Record</span><span>&lt;</span> <span>TagMode</span><span>,</span> <span>Record</span><span>&lt;</span> <span>TagMode</span><span>,</span> <span>boolean</span> <span>&gt;</span> <span>&gt;</span>

<span>class</span> <span>ManageTagsController</span> <span>{</span>
  <span>showUseFeedbackFilters</span><span>(</span><span>parent</span>: <span>Tag</span><span>,</span> <span>child</span>: <span>Tag</span><span>)</span><span>:</span> <span>boolean</span> <span>{</span>
    <span>const</span> <span>table</span>: <span>DecisionTable</span> <span>=</span> <span>{</span>
      <span>none</span><span>:</span>       <span>{</span> <span>none</span>: <span>false</span><span>,</span> <span>manual</span>: <span>false</span><span>,</span> <span>text_match</span>: <span>true</span><span>,</span> <span>smart</span>: <span>true</span><span>,</span> <span>managed</span>: <span>true</span> <span>},</span>
      <span>manual</span><span>:</span>     <span>{</span> <span>none</span>: <span>false</span><span>,</span> <span>manual</span>: <span>false</span><span>,</span> <span>text_match</span>: <span>true</span><span>,</span> <span>smart</span>: <span>true</span><span>,</span> <span>managed</span>: <span>true</span> <span>},</span>
      <span>text_match</span><span>:</span> <span>{</span> <span>none</span>: <span>false</span><span>,</span> <span>manual</span>: <span>false</span><span>,</span> <span>text_match</span>: <span>true</span><span>,</span> <span>smart</span>: <span>true</span><span>,</span> <span>managed</span>: <span>true</span> <span>},</span>
      <span>smart</span><span>:</span>      <span>{</span> <span>none</span>: <span>false</span><span>,</span> <span>manual</span>: <span>false</span><span>,</span> <span>text_match</span>: <span>true</span><span>,</span> <span>smart</span>: <span>true</span><span>,</span> <span>managed</span>: <span>true</span> <span>},</span>
      <span>managed</span><span>:</span>    <span>{</span> <span>none</span>: <span>false</span><span>,</span> <span>manual</span>: <span>false</span><span>,</span> <span>text_match</span>: <span>true</span><span>,</span> <span>smart</span>: <span>true</span><span>,</span> <span>managed</span>: <span>true</span> <span>}</span>
    <span>}</span>
    <span>return</span> <span>table</span><span>[</span><span>parent</span><span>.</span><span>mode</span><span>][</span><span>child</span><span>.</span><span>mode</span><span>]</span>
  <span>}</span>

  <span>showScopeByParent</span><span>(</span><span>parent</span>: <span>Tag</span><span>,</span> <span>child</span>: <span>Tag</span><span>)</span><span>:</span> <span>boolean</span> <span>{</span>
    <span>const</span> <span>table</span>: <span>DecisionTable</span> <span>=</span> <span>{</span>
      <span>none</span><span>:</span>       <span>{</span> <span>none</span>: <span>false</span><span>,</span> <span>manual</span>: <span>false</span><span>,</span> <span>text_match</span>: <span>false</span><span>,</span> <span>smart</span>: <span>false</span><span>,</span> <span>managed</span>: <span>false</span> <span>},</span>
      <span>manual</span><span>:</span>     <span>{</span> <span>none</span>: <span>false</span><span>,</span> <span>manual</span>: <span>false</span><span>,</span> <span>text_match</span>: <span>false</span><span>,</span> <span>smart</span>: <span>false</span><span>,</span> <span>managed</span>: <span>false</span> <span>},</span>
      <span>text_match</span><span>:</span> <span>{</span> <span>none</span>: <span>false</span><span>,</span> <span>manual</span>: <span>false</span><span>,</span> <span>text_match</span>: <span>true</span><span>,</span>  <span>smart</span>: <span>true</span><span>,</span>  <span>managed</span>: <span>true</span>  <span>},</span>
      <span>smart</span><span>:</span>      <span>{</span> <span>none</span>: <span>false</span><span>,</span> <span>manual</span>: <span>false</span><span>,</span> <span>text_match</span>: <span>true</span><span>,</span>  <span>smart</span>: <span>true</span><span>,</span>  <span>managed</span>: <span>true</span>  <span>},</span>
      <span>managed</span><span>:</span>    <span>{</span> <span>none</span>: <span>false</span><span>,</span> <span>manual</span>: <span>false</span><span>,</span> <span>text_match</span>: <span>true</span><span>,</span>  <span>smart</span>: <span>true</span><span>,</span>  <span>managed</span>: <span>true</span>  <span>}</span>
    <span>}</span>
    <span>return</span> <span>table</span><span>[</span><span>parent</span><span>.</span><span>mode</span><span>][</span><span>child</span><span>.</span><span>mode</span><span>]</span>
  <span>}</span>
<span>}</span>
</code></pre></div><p>After adding those functions to the AngularJS controller for that page, all I
had to do was bind those functions to the HTML view. For that, AngularJS has a
built-in directive called <code>ng-show</code> which shows or hides an HTML element based
on an expression.</p><div><pre><code data-lang="html"><span>&lt;</span><span>div</span> <span>ng-show</span><span>=</span><span>"showFeedbackFilters(parentTag, childTag)"</span><span>&gt;</span>
  <span>&lt;</span><span>label</span><span>&gt;</span>
    <span>&lt;</span><span>input</span> <span>ng-model</span><span>=</span><span>"child.scope_by_feedback_filters"</span> <span>type</span><span>=</span><span>"checkbox"</span><span>&gt;</span>
    <span>&lt;</span><span>span</span><span>&gt;</span>Scope tag using feedback filters (Advanced)<span>&lt;/</span><span>span</span><span>&gt;</span>
  <span>&lt;/</span><span>label</span><span>&gt;</span>
<span>&lt;/</span><span>div</span><span>&gt;</span>
...
<span>&lt;</span><span>div</span> <span>ng-show</span><span>=</span><span>"showScopeByParent(parentTag, childTag)"</span><span>&gt;</span>
  <span>&lt;</span><span>label</span><span>&gt;</span>
    <span>&lt;</span><span>input</span> <span>ng-model</span><span>=</span><span>"child.scope_by_parent"</span> <span>type</span><span>=</span><span>"checkbox"</span><span>&gt;</span>
    <span>&lt;</span><span>span</span><span>&gt;</span>Scope By Parent<span>&lt;/</span><span>span</span><span>&gt;</span>
  <span>&lt;/</span><span>label</span><span>&gt;</span>
<span>&lt;/</span><span>div</span><span>&gt;</span></code></pre></div><p>Finally, the code was ready to be deployed to staging for another round of QA
testing. This time would be different. Decision tables in hand, the QA testers
were able to systematically reproduce each case and verify that the code was
behaving correctly. The code moved through QA testing quickly, and it was
deployed to production later that day.</p><p>Lastly, I think it’s worth mentioning that while finalizing this post months
after writing the original code, I realized that I could have written these two
functions as fairly simple one-liners. Even with the benefit of hindsight, I
don’t know which solution I prefer; I could make arguments for and against each
one, but that’s beyond the scope of this post.</p><div><pre><code data-lang="typescript"><span>function</span> <span>showUseFeedbackFilters</span><span>(</span><span>parent</span>: <span>Tag</span><span>,</span> <span>child</span>: <span>Tag</span><span>)</span><span>:</span> <span>boolean</span> <span>{</span>
  <span>return</span> <span>child</span><span>.</span><span>mode</span> <span>===</span> <span>'text_match'</span>
      <span>||</span> <span>child</span><span>.</span><span>mode</span> <span>===</span> <span>'smart'</span>
      <span>||</span> <span>child</span><span>.</span><span>mode</span> <span>===</span> <span>'managed'</span>
<span>}</span>

<span>function</span> <span>showScopeByParent</span><span>(</span><span>parent</span>: <span>Tag</span><span>,</span> <span>child</span>: <span>Tag</span><span>)</span><span>:</span> <span>boolean</span> <span>{</span>
  <span>return</span> <span>(</span><span>parent</span><span>.</span><span>mode</span> <span>===</span> <span>'text_match'</span> <span>||</span> <span>parent</span><span>.</span><span>mode</span> <span>===</span> <span>'smart'</span> <span>||</span> <span>parent</span><span>.</span><span>mode</span> <span>===</span> <span>'managed'</span><span>)</span>
      <span>&amp;&amp;</span> <span>(</span><span>child</span><span>.</span><span>mode</span>  <span>===</span> <span>'text_match'</span> <span>||</span> <span>child</span><span>.</span><span>mode</span>  <span>===</span> <span>'smart'</span> <span>||</span> <span>child</span><span>.</span><span>mode</span>  <span>===</span> <span>'managed'</span><span>)</span>
<span>}</span>
</code></pre></div><h4 id="conclusion">Conclusion</h4><p>I wish I had known about decision tables earlier in my career. I’m a visual
learner and thinker and being able to visually map out states into a table would
have helped me out so much in the past. When you enumerate the states of your
program into a table, the logic becomes obvious and it can also be validated by
anyone on your team because tables are everywhere in daily life.</p></div></div>]]>
            </description>
            <link>https://hachibu.net/posts/2020/building-and-testing-50-ui-states-with-decision-tables/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25432524</guid>
            <pubDate>Tue, 15 Dec 2020 17:31:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Realtime Geostationary Earth Imagery]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25432494">thread link</a>) | @TimBurr
<br/>
December 15, 2020 | https://bluemarble.nitk.in/static.html | <a href="https://web.archive.org/web/*/https://bluemarble.nitk.in/static.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://bluemarble.nitk.in/static.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25432494</guid>
            <pubDate>Tue, 15 Dec 2020 17:28:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Teams Are Noisy]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25432489">thread link</a>) | @mcrittenden
<br/>
December 15, 2020 | https://critter.blog/2020/12/15/good-teams-are-noisy/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/12/15/good-teams-are-noisy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-2993">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>The most productive and jelled teams I’ve seen tend to be the noisiest. The Slack channels for those teams are chaos.</p>



<p>The teams I’ve seen with the worst morale tend to be quiet. People on those teams don’t talk to each other often. They <a href="https://critter.blog/2020/08/17/zombie-standups-try-walking-the-board/">rattle off a standup update</a>, and they ask for help when they get blocked on something, and that’s it.</p>



<p>The book <a href="https://www.goodreads.com/book/show/33517721-the-culture-code">The Culture Code</a> talks about a team’s “notification rate” in the context of airline pilots:</p>



<blockquote><p>The term pilots use to describe this type of short-burst communication is notifications. A notification is not an order or a command. It provides context, telling of something noticed, placing a spotlight on one discrete element of the world. </p><p>Notifications are the humblest and most primitive form of communication, the equivalent of a child’s finger-point: I see this. </p><p>Unlike commands, they carry unspoken questions: Do you agree? What else do you see? In a typical landing or takeoff, a proficient crew averages twenty notifications per minute.</p><cite>Daniel Coyle, The Culture Code</cite></blockquote>



<p>I love the simplicity: <em>you just say stuff</em>. Throw your random thoughts and observations in the chat room. You don’t have to filter out the stuff that isn’t useful to anyone else. Who are you to decide that anyway? You’re increasing the notification rate of the team, and that’s all the reason you need.</p>



<p>This is powerful in 2 ways:</p>



<p><strong>#1: It increases the possibility of <em>serendipitous moments</em>.</strong> Your coworker sees you’re working on X and says “Oh I looked into X last week and I noticed Y!” Or the reverse: you start working on X and you think “wait a second, didn’t someone say something about X in the chat last week?” </p>



<p>Standup is meant to do that kind of thing, but summarizing 8 hours of work into a 15 second update doesn’t provide enough granularity.</p>



<p><strong>#2: It makes a team feel more like a <em>team</em>.</strong> A team that doesn’t talk to each other <a href="https://critter.blog/2020/12/14/are-we-actually-a-team/">isn’t a team</a>. Constant communication helps teams become <em>teams</em> instead of some people who happen to be working from the same kanban board. <a href="https://critter.blog/2020/11/10/death-to-just-add-water-team-jelling/">Trust is built slowly and steadily</a> and increasing notification rates help a lot.</p>



<p>I can hear you now: “<em>But that will be <a href="https://critter.blog/2019/09/05/the-chatodoro-breaking-the-group-chat-addiction/">so distracting</a>! People won’t get any work done! Important messages will be lost!</em>” </p>



<p>Instead of thinking of all the reasons why it will fail, <a href="https://critter.blog/2020/10/26/you-cant-fail-at-experiments/">try it out</a>. Take a team that doesn’t feel much like a team, and encourage everyone to start saying more. <a href="https://critter.blog/2020/08/12/stop-changing-start-experimenting/">Make it an experiment</a>, and lead by example. Keep it up for a couple months and see if people feel more comfortable and honest and vulnerable. See if the team feels more like a <em>team</em>.</p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/12/15/good-teams-are-noisy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25432489</guid>
            <pubDate>Tue, 15 Dec 2020 17:27:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating Custom Postgres Data Types in Django]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25432368">thread link</a>) | @manualwise
<br/>
December 15, 2020 | https://pganalyze.com/blog/custom-postgres-data-types-django-python | <a href="https://web.archive.org/web/*/https://pganalyze.com/blog/custom-postgres-data-types-django-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>
<span>
      <a href="https://pganalyze.com/static/2c0091f36c4cb013824095ab46137ac5/c1b63/custom_postgres_data_types_django_header_pganalyze.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Postgres Custom Data Type Example" title="Postgres Custom Data Type Example" src="https://pganalyze.com/static/2c0091f36c4cb013824095ab46137ac5/8c557/custom_postgres_data_types_django_header_pganalyze.png" srcset="https://pganalyze.com/static/2c0091f36c4cb013824095ab46137ac5/4edbd/custom_postgres_data_types_django_header_pganalyze.png 175w, https://pganalyze.com/static/2c0091f36c4cb013824095ab46137ac5/13ae7/custom_postgres_data_types_django_header_pganalyze.png 350w, https://pganalyze.com/static/2c0091f36c4cb013824095ab46137ac5/8c557/custom_postgres_data_types_django_header_pganalyze.png 700w, https://pganalyze.com/static/2c0091f36c4cb013824095ab46137ac5/e996b/custom_postgres_data_types_django_header_pganalyze.png 1050w, https://pganalyze.com/static/2c0091f36c4cb013824095ab46137ac5/c1b63/custom_postgres_data_types_django_header_pganalyze.png 1200w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
</p>
<p>Postgres allows you to define custom data types when the default types provided don't fit your needs. There are many situations where these custom data types come in handy.</p>
<p>For example, if you have multiple columns in several tables that should be an <code>int</code> between 0 and 255, you could use a custom data type so that you only have to define the constraints once. Or, if you have complex data - like metadata about a file - and you want to save it to a single column instead of spreading it across several, custom data types can help.</p>

<p>No matter how you decide to define your datatype, Django has the functionality to allow you to map custom column data to model attributes. You can achieve this by extending the Django <a href="https://docs.djangoproject.com/en/3.0/ref/models/fields/#django.db.models.Field">field class</a>. In this walkthrough, we'll see <strong>how to create custom types in Postgres</strong> and then use them in Django to <strong>ensure consistent data types across your application</strong>. We will do this by walking you through an <a href="https://github.com/pganalyze-resources/django-custom-data-types-example">example project</a>.</p>
<h2 id="custom-domains-in-postgres"><a href="#custom-domains-in-postgres" aria-label="custom domains in postgres permalink"></a>Custom Domains in Postgres</h2>
<p>There are several different kinds of custom data types in Postgres, including <a href="https://www.postgresql.org/docs/9.5/datatype-enum.html">enums</a> and <a href="https://www.postgresql.org/docs/9.5/rangetypes.html">range types</a>. The two we’ll use in our project today are called domain types and composite types. </p>
<p><strong>First</strong>, let’s take a look at <a href="https://www.postgresql.org/docs/current/sql-createdomain.html">domain types</a>. Domains are a way of adding restrictions to an existing type so that it can be reused in columns across tables. They are particularly useful for columns like email addresses, phone numbers, or <a href="https://postgis.net/docs/stdaddr.html">street addresses</a>, where you might find yourself repeating the same checks over and over. A custom domain allows you to define those checks once and then reuse them making them easier to manage and maintain.</p>
<p>For our example project, we'll start by creating a custom data type that performs a check to ensure a string doesn't contain any spaces:</p>
<div data-language="sql"><pre><code><span>CREATE</span> DOMAIN string_no_spaces <span>as</span> <span>VARCHAR</span> <span>NOT</span> <span>NULL</span> <span>CHECK</span> <span>(</span><span>value</span> <span>!</span><span>~</span> <span>'\s'</span><span>)</span><span>;</span></code></pre></div>
<p>Now we can use this type on as many tables or in as many columns as we like. For example say we don’t want to allow spaces in user_names for a chat app:</p>
<div data-language="sql"><pre><code><span>CREATE</span> <span>TABLE</span> users <span>(</span>
  id <span>serial</span> <span>primary</span> <span>key</span><span>,</span> 
 user_name string_no_spaces
<span>)</span><span>;</span></code></pre></div>
<p>Now if you try to add a value with a space, Postgres will throw an error:</p>
<div data-language="text"><pre><code>INSERT INTO users(user_name) VALUES ('I am a      bad user name');
-- ERROR:  value for domain string_no_spaces violates check constraint "string_no_spaces_check"</code></pre></div>
<p>We can also reuse this domain in the definition of another domain. For example: </p>
<div data-language="sql"><pre><code><span>CREATE</span> DOMAIN email_with_check <span>AS</span> string_no_spaces <span>NOT</span> <span>NULL</span> <span>CHECK</span> <span>(</span><span>value</span> <span>~</span> <span>'@'</span><span>)</span><span>;</span>

<span>CREATE</span> <span>TABLE</span> email_addresses <span>(</span>
  user_id <span>integer</span><span>,</span>
  email email_with_check
<span>)</span><span>;</span>

<span>INSERT</span> <span>INTO</span> email_addresses<span>(</span>email<span>)</span> <span>VALUES</span> <span>(</span><span>'josh @gmail.com'</span><span>)</span><span>;</span>


<span>INSERT</span> <span>INTO</span> email_addresses<span>(</span>email<span>)</span> <span>VALUES</span> <span>(</span><span>'joshgmail.com'</span><span>)</span><span>;</span>
</code></pre></div>
<p>Here, we've created a new check to ensure an email contains <code>@</code> and we've used <code>string_no_spaces</code> as our base type. This allows us to inherit the no spaces check. Now data of datatype <code>email_with_check</code> must contain <code>@</code> and cannot contain spaces.</p>
<h2 id="composite-types-in-postgres"><a href="#composite-types-in-postgres" aria-label="composite types in postgres permalink"></a>Composite Types in Postgres</h2>
<p>The <strong>second</strong> kind of custom data type we’ll look at today is called a <a href="https://www.postgresql.org/docs/current/sql-createtype.html">composite type</a>. A composite type is essentially a group of data that can be held in a single column. Composite types can be helpful if you have lists of data that you don't want to be spread over multiple columns. Perhaps this data only makes sense when grouped together like the <a href="https://til.hashrocket.com/posts/3693c7fc13-creating-custom-types-in-postgresql">dimensions of a package</a>. </p>
<p><a href="https://en.wikipedia.org/wiki/RGB_color_model">RGB color data</a> is another good example because it doesn't make much sense on its own - 255 is just an <code>int</code> - but coupled with some labels and two other numbers (<code>red: 255, green: 0, blue: 0</code>), it becomes the color red. Every time we access a color, we'll want to have all three of these values returned, so it saves us from having to query multiple columns for a group of data that is only meaningful when combined.</p>
<p>Let's start by creating a new RGB color value type:</p>
<div data-language="sql"><pre><code><span>CREATE</span> <span>TYPE</span> rgb_color_value <span>as</span> <span>(</span>
  red <span>integer</span><span>,</span>
  green <span>integer</span><span>,</span>
  blue <span>integer</span>
<span>)</span><span>;</span></code></pre></div>
<p>Next, we can create a new table and use both our domain and custom data type for the columns:</p>
<div data-language="sql"><pre><code><span>CREATE</span> <span>TABLE</span> colors <span>(</span>
  name string_no_spaces<span>,</span>
  rgb rgb_color_value
<span>)</span><span>;</span>

<span>INSERT</span> <span>INTO</span> colors<span>(</span>name<span>,</span> rgb<span>)</span> <span>VALUES</span><span>(</span><span>'pink'</span><span>,</span> <span>(</span><span>252</span><span>,</span><span>15</span><span>,</span><span>192</span><span>)</span><span>)</span><span>;</span>

<span>SELECT</span> <span>*</span> <span>FROM</span> colors<span>;</span>

 name <span>|</span> rgb   

 pink <span>|</span> <span>(</span><span>252</span><span>,</span><span>15</span><span>,</span><span>192</span><span>)</span></code></pre></div>
<p>We can even access the individual values. For example, if all we want is the green value:</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>(</span>rgb<span>)</span><span>.</span>green <span>FROM</span> colors<span>;</span>

  green 
 
   <span>15</span></code></pre></div>
<h2 id="custom-types-in-django"><a href="#custom-types-in-django" aria-label="custom types in django permalink"></a>Custom Types in Django</h2>
<p>Let's use our <code>string_no_spaces</code> domain and our <code>rgb_color_value</code> composite type to create a Django model to define a color. <code>rgb_color_value</code> is going to take the most work, so we'll start there and then come back to <code>string_no_spaces</code>.</p>
<h3 id="registering-a-type-with-psycopg2"><a href="#registering-a-type-with-psycopg2" aria-label="registering a type with psycopg2 permalink"></a>Registering a type with psycopg2</h3>
<p>We'll use the <a href="https://www.psycopg.org/docs/">pyscopg2</a> database adapter in this example. I won't go into how to set it up here, but I recommend <a href="https://www.digitalocean.com/community/tutorials/how-to-use-postgresql-with-your-django-application-on-ubuntu-14-04">this tutorial</a>. It does a good job covering the setup if you aren't familiar with it yet.</p>
<p>We'll need to start by <a href="https://www.psycopg.org/docs/extensions.html#psycopg2.extensions.register_adapter">registering and creating an adapter</a> for our new type so that psycopg2 knows how to handle it. After we register it, psycopg will return values from the database as a named tuple.</p>
<div data-language="python"><pre><code><span>from</span> django<span>.</span>db <span>import</span> connection
<span>from</span> psycopg2<span>.</span>extras <span>import</span> register_composite

Rgb <span>=</span> register_composite<span>(</span>
  <span>'rgb_color_value'</span><span>,</span>
  connection<span>.</span>cursor<span>(</span><span>)</span><span>.</span>cursor<span>,</span>
  globally<span>=</span><span>True</span>
<span>)</span><span>.</span><span>type</span></code></pre></div>
<p>The above code will handle data coming to our app from the database, but <strong>we'll also need to tell psycopg what to do with data sent to the database</strong>. That's where the adapter comes in:</p>
<div data-language="python"><pre><code><span>from</span> django<span>.</span>db <span>import</span> connection
<span>from</span> psycopg2<span>.</span>extras <span>import</span> register_composite
<span>from</span> psycopg2<span>.</span>extensions <span>import</span> register_adapter<span>,</span> adapt<span>,</span> AsIs

Rgb <span>=</span> register_composite<span>(</span>
  <span>'rgb_color_value'</span><span>,</span>
  connection<span>.</span>cursor<span>(</span><span>)</span><span>.</span>cursor<span>,</span>
  globally<span>=</span><span>True</span>
<span>)</span><span>.</span><span>type</span>

<span>def</span> <span>rgb_adapter</span><span>(</span>value<span>)</span><span>:</span>
  <span>return</span> AsIs<span>(</span><span>"(%s, %s, %s)::rgb_color_value"</span> <span>%</span> <span>(</span>
    adapt<span>(</span>value<span>.</span>red<span>)</span><span>.</span>getquoted<span>(</span><span>)</span><span>,</span>
    adapt<span>(</span>value<span>.</span>green<span>)</span><span>.</span>getquoted<span>(</span><span>)</span><span>,</span>
    adapt<span>(</span>value<span>.</span>blue<span>)</span><span>.</span>getquoted<span>(</span><span>)</span>
  <span>)</span><span>)</span>

register_adapter<span>(</span>Rgb<span>,</span> rgb_adapter<span>)</span></code></pre></div>
<p>Now that psycopg knows about our new data type and how to handle it, we can create the same functionality for Django. </p>
<h3 id="representing-composite-types-as-a-python-class"><a href="#representing-composite-types-as-a-python-class" aria-label="representing composite types as a python class permalink"></a>Representing composite types as a Python class</h3>
<p>We want to be able to do things with our objects like this: </p>
<div data-language="python"><pre><code>rgb <span>=</span> Rgb<span>(</span><span>255</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>)</span>

my_color_object<span>.</span>rgb <span>=</span> rgb 

my_color_object<span>.</span>save<span>(</span><span>)</span></code></pre></div>
<p>To do that, we'll need to start with a Python class that represents an RGB value.</p>
<div data-language="python"><pre><code><span>class</span> <span>Rgb</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span>self<span>,</span> red<span>,</span> green<span>,</span> blue<span>)</span><span>:</span>
        self<span>.</span>red <span>=</span> red
        self<span>.</span>green <span>=</span> green
        self<span>.</span>blue <span>=</span> blue</code></pre></div>
<p>We'll come back to this class in a bit, but first, we need to talk about fields.</p>
<h3 id="using-django-fields"><a href="#using-django-fields" aria-label="using django fields permalink"></a>Using Django fields</h3>
<p>You are probably familiar with many of <a href="https://docs.djangoproject.com/en/3.0/ref/models/fields/">Django's built-in model fields</a> like <code>models.CharField</code> or <code>models.IntegerField</code>. You've also probably noticed that many of these fields correspond to data types we often use in Postgres (<code>varchar</code>, <code>int</code> etc.). </p>
<p>For custom data types, Django allows us to create our fields and then use them in our models:</p>
<div data-language="python"><pre><code><span>from</span> django<span>.</span>db <span>import</span> models

<span>class</span> <span>RgbField</span><span>(</span>models<span>.</span>Field<span>)</span><span>:</span>
    
    <span>def</span> <span>db_type</span><span>(</span>self<span>,</span> connection<span>)</span><span>:</span>
        <span>return</span> <span>'rgb_color_value'</span></code></pre></div>
<p>All custom fields inherit from <code>models.Field</code>. You can also inherit from existing fields like <code>models.CharField</code> (which itself inherits from <code>models.Field</code>) This is helpful if your custom type behaves similarly to an existing type. Since ours doesn't, we'll inherit directly from <code>models.Field</code>. </p>
<p>Next, we need to override <a href="https://docs.djangoproject.com/en/3.0/howto/custom-model-fields/#converting-values-to-python-objects">three methods</a> so that they will return instances of our <code>Rgb</code> class. The first, <code>from_db_value()</code> is called when data is loaded from the database. This is the method that will receive our named tuple we set up with Psycopg earlier. The second, <code>to_python()</code> gets called during deserialization. These two need to return an instance of the <code>Rgb</code> class. </p>
<p>The last method we need to override is <code>get_prep_value</code>, where we'll convert our <code>Rgb</code> object back into a tuple before handing it off to Psycopg to save to the database. When we're done, our field class should look like this:</p>
<div data-language="python"><pre><code><span>class</span> <span>RgbField</span><span>(</span>models<span>.</span>Field<span>)</span><span>:</span>
  
  <span>def</span> <span>from_db_value</span><span>(</span>self<span>,</span> value<span>,</span> expression<span>,</span> connection<span>)</span><span>:</span>
      <span>if</span> value <span>is</span> <span>None</span><span>:</span>
          <span>return</span> value
      <span>return</span> Rgb<span>(</span>value<span>.</span>red<span>,</span> value<span>.</span>green<span>,</span> value<span>.</span>blue<span>)</span>

  <span>def</span> <span>to_python</span><span>(</span><span>)</span><span>:</span>
      <span>if</span> <span>isinstance</span><span>(</span>value<span>,</span> Rgb<span>)</span><span>:</span>
          <span>return</span> value

      <span>if</span> value <span>is</span> <span>None</span><span>:</span>
          <span>return</span> value

      <span>return</span> Rgb<span>(</span>value<span>.</span>red<span>,</span> value<span>.</span>green<span>,</span> value<span>.</span>blue<span>)</span>

  <span>def</span> <span>get_prep_value</span><span>(</span>self<span>,</span> value<span>)</span><span>:</span>
      <span>return</span> <span>(</span>value<span>.</span>red<span>,</span> value<span>.</span>green<span>,</span> value<span>.</span>blue<span>)</span>
  
  <span>def</span> <span>db_type</span><span>(</span>self<span>,</span> connection<span>)</span><span>:</span>
      <span>return</span> <span>'rgb_color_value'</span></code></pre></div>
<p>The checks I put in place above are suggestions from the <a href="https://docs.djangoproject.com/en/3.0/howto/custom-model-fields/#converting-values-to-python-objects">Django docs</a>.</p>
<p>Finally, we can create our model using our brand new Rgb field:</p>
<div data-language="python"><pre><code><span>class</span> <span>Color</span><span>(</span>models<span>.</span>Model<span>)</span><span>:</span>
    rgb <span>=</span> RgbField<span>(</span><span>)</span>
    name <span>=</span> models<span>.</span>CharField<span>(</span><span>)</span></code></pre></div>
<p>But wait! Didn't we create a special <code>string_no_spaces</code> domain that we want to use for the <code>name</code> attribute?</p>
<p>Since this type is just a string with checks at the database level, all we need to do is create the field with the appropriate <code>db_type</code> method:</p>
<div data-language="python"><pre><code><span>class</span> <span>StringNoSpacesField</span><span>(</span>models<span>.</span>Field<span>)</span><span>:</span>
    
    <span>def</span> <span>db_type</span><span>(</span>self<span>,</span> connection<span>)</span><span>:</span>
        <span>return</span> <span>'string_no_spaces'</span></code></pre></div>
<p>Now we can update our model and run our migrations:</p>
<div data-language="python"><pre><code><span>class</span> <span>Color</span><span>(</span>models<span>.</span>Model<span>)</span><span>:</span>
    rgb <span>=</span> RgbField<span>(</span><span>)</span>
    name <span>=</span> StringNoSpacesField<span>(</span><span>)</span></code></pre></div>
<p>Let's confirm that everything is working as expected. In the python shell (I'm using <a href="https://django-extensions.readthedocs.io/en/latest/shell_plus.html">shell plus</a>), we'll create a new color:</p>
<div data-language="bash"><pre><code><span>&gt;&gt;</span><span>&gt;</span> from colors.models <span>import</span> Rgb
<span>&gt;&gt;</span><span>&gt;</span> rgb <span>=</span> Rgb<span>(</span><span>255</span>, <span>0</span>, <span>0</span><span>)</span>
<span>&gt;&gt;</span><span>&gt;</span> c <span>=</span> Color.objects.create<span>(</span>name<span>=</span><span>'red'</span>, <span>rgb</span><span>=</span>rgb<span>)</span>
<span>&gt;&gt;</span><span>&gt;</span> c.rgb
<span>&lt;</span>colors.models.Rgb object at 0x104e3d6d<span><span>8</span>&gt;</span>
<span>&gt;&gt;</span><span>&gt;</span> c.rgb.red
<span>255</span></code></pre></div>
<p>If you try to create a color with a name that has a space in it, you will get an error like this: </p>
<div data-language="text"><pre><code>django.db.utils.IntegrityError: value for domain string_no_spaces violates check constraint "string_no_spaces_check"</code></pre></div>
<p>Now, let's check the database and make sure everything got saved as the correct type:</p>
<div data-language="psql"><pre><code>customdt=# SELECT pg_typeof(rgb), pg_typeof(name) FROM colors_color;
    pg_typeof | pg_typeof     
-----------------+------------------
 rgb_color_value | string_no_spaces
(1 row)</code></pre></div>
<p>From here, we could ensure that only numbers from 0 - 255 are entered by <a href="https://docs.djangoproject.com/en/3.0/howto/custom-model-fields/#writing-a-field-subclass">overriding the __ init __ </a> method and adding checks at the Postgres level. We could also create a new type for storing the hex code for …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pganalyze.com/blog/custom-postgres-data-types-django-python">https://pganalyze.com/blog/custom-postgres-data-types-django-python</a></em></p>]]>
            </description>
            <link>https://pganalyze.com/blog/custom-postgres-data-types-django-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-25432368</guid>
            <pubDate>Tue, 15 Dec 2020 17:18:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A neural network learns when it should not be trusted [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25432272">thread link</a>) | @mrkn1
<br/>
December 15, 2020 | https://proceedings.neurips.cc/paper/2020/file/aab085461de182608ee9f607f3f7d18f-Paper.pdf | <a href="https://web.archive.org/web/*/https://proceedings.neurips.cc/paper/2020/file/aab085461de182608ee9f607f3f7d18f-Paper.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://proceedings.neurips.cc/paper/2020/file/aab085461de182608ee9f607f3f7d18f-Paper.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25432272</guid>
            <pubDate>Tue, 15 Dec 2020 17:10:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[REST vs. GraphQL – A search for evidence on which is better]]>
            </title>
            <description>
<![CDATA[
Score 183 | Comments 235 (<a href="https://news.ycombinator.com/item?id=25432233">thread link</a>) | @gsvclass
<br/>
December 15, 2020 | https://42papers.com/p/rest-vs-graphql-a-controlled-experiment | <a href="https://web.archive.org/web/*/https://42papers.com/p/rest-vs-graphql-a-controlled-experiment">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://42papers.com/p/rest-vs-graphql-a-controlled-experiment</link>
            <guid isPermaLink="false">hacker-news-small-sites-25432233</guid>
            <pubDate>Tue, 15 Dec 2020 17:08:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taskwarrior, where have you been all my life?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25432057">thread link</a>) | @edward
<br/>
December 15, 2020 | https://blog.djy.io/taskwarrior-where-have-you-been-all-my-life/ | <a href="https://web.archive.org/web/*/https://blog.djy.io/taskwarrior-where-have-you-been-all-my-life/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>
  <img src="https://d33wubrfki0l68.cloudfront.net/7fc7d29badcf4919151960c755cb7574db99a85b/d4acb/assets/2018-04-27-taskwarrior-screenshot.png" alt="Screenshot of Taskwarrior in action" title="Screenshot of Taskwarrior in action" width="800" height="146">
</p>

<p>I’ve been thinking a lot about task management lately. I’ve actually been
thinking about it for years. I’ve always been searching for the optimal way to
sort through the bajillion things I have to do and remain productive.</p>

<p>This all started when, as a programmer, I realized that I had the power to
automate the tasks that I found repetitive in my digital life. I would write
scripts, for example, to do things like organize my photos, clean up my music
library, and back up my data. Over the years, I’ve developed my own homegrown
approach to task management, which has included a couple of attempts at writing
a command-line tool to manage my tasks in a way that’s in line with my approach.
Then, recently, I discovered that there is already a robust command-line tool
that does exactly what I need.</p>

<p>That tool is <a href="https://taskwarrior.org/">Taskwarrior</a>. But before I get into it, here’s a
brief dive into the journey that led me to using it.</p>



<p>Around the same time that I was starting to write scripts to automate the
monotonous parts of my day-to-day life, I was also discovering the joy of <a href="https://www.google.com/search?q=inbox+zero">Inbox
Zero</a>. If you’re unfamiliar with Inbox Zero, the basic idea is that
you endeavor to keep your email inbox empty as much as possible, instead of
letting emails pile up that you’ll get to “later” (which could be days, months,
or even years from now, or perhaps never). You can achieve Inbox Zero by being
disciplined about reviewing your inbox regularly (at least once a day) and
taking action on every email. Taking action on an email can mean deleting or
archiving it, replying (even if a quick reply is all you have time for), or
perhaps making a note for yourself on your calendar to do something later.</p>

<p>(You might be wondering what Inbox Zero has to do with task management. That
will become clear very shortly. Read on!)</p>



<p>Sometime around 2013, I discovered an excellent, free service called
<a href="https://followupthen.com/">FollowUpThen</a>. The elevator pitch for FollowUpThen is that you can send or
forward an email to an address like <code>tomorrow@followupthen.com</code> (or
<code>tomorrow@fut.io</code>, for short) and tomorrow at 6 AM, the email that you sent or
forwarded will arrive in your inbox, like clockwork. FollowUpThen supports a
<a href="https://www.followupthen.com/how#timeformats">wide variety</a> of time and date formats, many of which are highly
useful. I often found myself forwarding an email to <code>2weeks@fut.io</code> or sending
an email to <code>september@fut.io</code>, for example.</p>

<p>FollowUpThen quickly became the primary tool in my Inbox Zero toolbox. If I had
a lot of work to do and a handful of emails that I just didn’t have time for at
the moment, I could use FollowUpThen to “snooze” the emails until a particular
time later in the day when I knew I would be more available.</p>

<p>I also started to use FollowUpThen as a task manager. For example, if I was
planning to mow the lawn on Saturday, I would send an email with the subject
<code>mow the lawn</code> to <code>saturday@fut.io</code>. Then when Saturday rolled around, I would
get an email with the subject <code>mow the lawn</code>, and I would have to mow the lawn
in order to reach Inbox Zero, which motivated me to mow the lawn.</p>

<p>After a while, I started wishing that I could see my upcoming tasks ahead of
time. I wanted to see into the future just slightly, so that I could mentally
prepare myself to work on a task that wasn’t due yet. This would be better than
forgetting that I had a task scheduled, and then <em>BAM</em> – I get an email,
signaling that I needed to do it right now!</p>

<p>Now, to be fair, you <em>can</em> see all of your scheduled follow-ups by logging in at
followupthen.com – and I did that from time to time – but that’s a little
cumbersome for something that I’d ideally like to do on a regular basis. Over
time, I’ve become more and more accustomed to doing things at the command line.
I’m already in a terminal most of the time, so it is typically a lot faster for
me to do something at the command-line as opposed to, say, logging into a
website, navigating to the right page, and clicking a button. I started pining
for a way to manage all of my projects and tasks at the command-line.</p>



<p>As I imagined an ideal command-line task management workflow, I found myself
thinking about the ancient AS400 system that I used in my previous life as a
claims adjudicator.</p>

<p>I was managing a caseload of anywhere from 50 to 200 claims, each of which had a
log of past actions (called <em>log items</em>) and a schedule of upcoming actions
needed (called <em>action items</em>). Some of the action items were designated <code>IA</code>,
which meant that Immediate Action was needed. This was really just a way of
designating some action items as being higher priority than others.</p>

<p>The best part of the system was the case summary screen. This was a top-level
summary of all of my cases, with statistics about how many cases fell into
certain categories.  For example, there was a “Cases needing immediate action”
category, which displayed the number of cases with Immediate Action follow-up
actions either due or overdue. There were also useful categories like “Cases
without action in 30 days.” When I was working at that job, I developed a highly
productive workflow in which I was able to effectively manage large caseloads
and ensure that the most urgent tasks were done first. My daily process was to
go through the categories on the case summary screen in priority order, and
endeavor to get the number to the right of each category down to zero, over
time. I was following the Inbox Zero philosophy with my workload, and it worked
very well for me.</p>

<p>I wanted to replicate this sort of workflow for day-to-day task management in my
personal life. So, I started writing a program that I called <a href="https://github.com/daveyarwood/ews"><code>ews</code></a> (named
after the Electronic Worksheet System that I had used in my past job). I was
envisioning <code>ews</code> as essentially a port of the AS400 system I had used, where
“cases” (i.e. projects, groups of related tasks) could be managed and summarized
in priority order.</p>

<p>I started writing this tool in <a href="https://clojurescript.org/">ClojureScript</a> targeting
<a href="https://nodejs.org/">node.js</a>, but I got frustrated with the need to use callbacks when
interfacing with the node.js ecosystem, which was a show-stopper for me. I was
playing with <a href="https://rust-lang.org/">Rust</a> at the time, so I did a basic rewrite in Rust, which I
was fairly happy with, although I realized that the strictness of the Rust
compiler caused me to work more slowly than I do in less strict languages.</p>

<p>I was on the verge of yet another rewrite in <a href="https://crystal-lang.org/">Crystal</a> when I finally
took a step back and thought about what I really wanted to create. This led me
to my next iteration, which was different enough that I decided to give it a
different name.</p>



<p>I had a shower-thought that Google Calendar provides a database for events and
an API for interacting with them, so I could leverage this platform to build my
tool. So, I started writing <a href="https://github.com/daveyarwood/tdz">tdz</a> as an experiment in that direction. (NB:
I didn’t get very far, so don’t expect to find much in that repo!)</p>

<p>While I was thinking about how my mental model of projects and tasks could map
onto the Google Calendar API, I also realized that the model could be
simplified. I didn’t really need to manage projects; I only needed to manage
individual tasks that have scheduled dates and due dates. (If I could organize
them into projects, that would be icing on the cake, but it wasn’t a
requirement.)</p>

<p>With the conceptual model simplified to just tasks, I (finally) started to
wonder if maybe somebody else had already created something like this. After
some googling, I stumbled upon <a href="https://stackify.com/top-command-line-tools/">this list of useful command-line
tools</a>, which included Taskwarrior, a feature-rich task
management application. So, I decided to give it a try.</p>



<p>I’d briefly encountered Taskwarrior before in the past and thought, “This is
cool, but how is it different from the other command-line TODO apps I’ve seen?”
I’d dismissed it as “just another TODO list app.”</p>

<p>At that point, I’d already come across a number of command-line TODO list
managers in the open source space; it’s a fun, easy project that any beginning
programmer can build and get working in a short amount of time. So, by
association, I had come to expect any command-line TODO manager to be simplistic
and fall short of my task management needs.</p>

<p>I didn’t want a tool that would simply keep track of a list of tasks and let me
check them off when I did them.  This is akin to a traditional pen-and-paper
TODO list; I’ve always hated those because there’s no way to assign dates to
things and filter out the noise of backlog tasks that aren’t yet ready for
action.  It didn’t occur to me that there might be a more sophisticated task
management CLI tool that had all of the features I needed in order to follow an
“Inbox Zero” style of task management. Taskwarrior turned out to be exactly what
I needed and more!</p>

<h2 id="tasks-projects-and-urgency">Tasks, Projects, and Urgency</h2>

<p>Adding and listing tasks is, of course, a breeze:</p>

<figure><pre><code data-lang="text">$ task add mow the lawn
Created task 1.

$ task
[task next]

ID Age Description  Urg
 1 5s  mow the lawn    0

1 task</code></pre></figure>

<p>The default behavior when you run <code>task</code> is to run the command <code>task next</code>,
which lists your most urgent tasks, sorted by urgency.</p>

<p>Tasks can be modified in a number of ways, including, but not limited to:</p>

<ul>
  <li>Adding tags.</li>
  <li>Categorizing the task as being part of a project.</li>
  <li>Setting the dates/times when the task will be visible, scheduled, and due.</li>
  <li>Assigning a priority (the default priorities are L, M, and H, and you can
customize or replace them or add more priorities).</li>
  <li>Marking the task as “active” (i.e. you’ve started working on it).</li>
</ul>

<p>Watch what happens to my task when I designate it as part of the “home” project:</p>

<figure><pre><code data-lang="text">$ task 1 modify project:home
Modifying task 1 'mow the lawn'.
Modified 1 task.
The project 'home' has changed.  Project 'home' is 0% complete (1 task remaining).

$ task
[task next]

ID Age  Project Description  Urg
 1 2min home    mow the lawn    1

1 task</code></pre></figure>

<p>Notice that the urgency level changed from 0 to 1! We can see why if we view
information about the task:</p>

<figure><pre><code data-lang="text">$ task 1
No command specified - assuming 'information'.

Name          Value
ID            1
Description   mow the lawn
Status        Pending
Project       home
Entered       …</code></pre></figure></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.djy.io/taskwarrior-where-have-you-been-all-my-life/">https://blog.djy.io/taskwarrior-where-have-you-been-all-my-life/</a></em></p>]]>
            </description>
            <link>https://blog.djy.io/taskwarrior-where-have-you-been-all-my-life/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25432057</guid>
            <pubDate>Tue, 15 Dec 2020 16:52:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A new way to share beautiful-looking code]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25431830">thread link</a>) | @Brajeshwar
<br/>
December 15, 2020 | https://engineering.scrollstack.com/post/2959/New-features-to-support-Tech-creators- | <a href="https://web.archive.org/web/*/https://engineering.scrollstack.com/post/2959/New-features-to-support-Tech-creators-">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://engineering.scrollstack.com/post/2959/New-features-to-support-Tech-creators-</link>
            <guid isPermaLink="false">hacker-news-small-sites-25431830</guid>
            <pubDate>Tue, 15 Dec 2020 16:33:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Learn Machine Learning and Deep Learning: A Guide for Software Engineers]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25431821">thread link</a>) | @renanmoura
<br/>
December 15, 2020 | https://renanmf.com/machine-learning-and-deep-learning-software-engineers/ | <a href="https://web.archive.org/web/*/https://renanmf.com/machine-learning-and-deep-learning-software-engineers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Introduction</h2><p>The subject of Artificial Intelligence piques my interest and I’m constantly studying and trying new things in this field.</p><p>It is notorious how the technologies related to Natural Language Processing, Computer Vision and such have emerged and evolved into solutions used by millions of users every day.</p><p>Even though people use the term "Artificial Intelligence", we are still far away from something as advanced as a Skynet from the Terminator movies.</p><p>The most common subfield of AI used today is the one called Machine Learning, which, in its turn, has Deep Learning as subfield steeply growing every day for quite some time now.</p><p>In this guide, I aim to describe a path to follow for software engineers to begin understanding how Machine Learning works and how to apply it to your projects.</p><p>Yeah, you can just go to Google API’s or Amazon and pick some magical API to do Speech Recognition for you, but the value of knowing how it works, why it works and even more, how to make your own API as a Service and tune it to your specific needs is incredible.</p><p>Remember, as a developer, every tool is a new power.</p><p>I’ve read, watched and gone through all these resources until the end, even got a paid certification for some, even though it is not necessary to learn, I find myself more engaged to finish when I have some deadline and assessment to prove I actually learned the material.</p><p>Let’s dive into the topics.</p><p>Python is the main language these days when working with Data Science, Machine Learning, and Deep Learning.</p><p>If you need a crash course on Python, here is your guide: <a href="https://renanmf.com/the-python-guide-for-beginners/">The Python Guide for Beginners</a>.</p><h2>The Basics: Math!</h2><p>Maybe you never had the chance to study some college-level math, or you did study it but you can’t remember most of the stuff because JavaScript and CSS took all the memory of those topics away.</p><p>There are 3 topics you must know beforehand, or at least have a decent grasp of to follow any good material on ML and DL: Linear Algebra, Calculus and Statistics.</p><p>If you’d like to go deep in learning the math needed to ML and DL, you can look for MIT OpenCourseWare classes like Professor Strang’s renowned <a href="https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/">Linear Algebra</a> class.</p><p>I’ve watched it in college in parallel with my regular class and it is very good.</p><p>But, let’s face it, most people have no time for that or the patience.</p><p>So I will give you the crash course for the 3 topics mentioned above.</p><h3>Linear Algebra</h3><p>Just watch the whole series <a href="https://www.youtube.com/watch?v=fNk_zzaMoSs&amp;list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Essence of Linear Algebra</a> from the Youtube channel 3Blue1Brown.</p><p>The guy makes visual explanations of once hard concepts incredibly easy!</p><p>It is very far in terms of content compared to Professor Strang’s, but it’s enough, to begin with, and you can go after other topics as you advance in ML and DL.</p><h3>Calculus</h3><p>Guess what?</p><p>3Blue1Brown also has a whole series on Calculus on Youtube for you to watch for free: <a href="https://www.youtube.com/watch?v=WUvTyaaNkzM&amp;list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr">Essence of Calculus</a>.</p><p>Again, he is very good at giving you the intuition of why and how rather than just throw some random equations on your face.</p><h3>Statistics</h3><p>This is a whole field that, in my opinion, you can learn as needed, a good reference is <a href="https://www.amazon.com/Practical-Statistics-Data-Scientists-Essential/dp/1491952962">Practical Statistics for Data Scientists: 50 Essential Concepts</a>.</p><p>An objective book with some good examples for every concept.</p><p>Fast to read too.</p><p>As the title implies, it is more suitable for Data Scientists, but understanding some basics of statistics is always good and this is what this is book is for.</p><p>You won’t become a statistician after reading it, but you will learn some good stuff.</p><h2>The Bypassed: Machine Learning</h2><p>Everybody wants to jump straight into Deep Learning and be the cool guy training a single model for a week on a 12GB GPU.</p><p>But to get Deep Learning right, you need to go through Machine Learning first!</p><h3>Start from the beginning</h3><p>The concepts, the train of thought, the "feeling" of how things work start here and there is no one else more capable of teaching those concepts than Professor Andrew Ng in his course <a href="https://www.coursera.org/learn/machine-learning">Machine Learning</a>.</p><p>You may think this course is old and outdated, well, technology-wise, maybe, but conceptually-wise, it is better than anything else out there.</p><p>Professor Ng makes it easy to understand the math applied in every technique he teaches and gives you a solid understanding of what happens underneath in a very short and concise course.</p><p>All the exercises are made in Octave, a free version of Matlab of sorts, and you finish the course implementing your own Neural Network!</p><p>The syntax in Octave is easy to grasp for any programmer, so don’t let that be a barrier for you.</p><p>Once you finish the course, you will have implemented all the major algorithms and will be able to solve several prediction problems.</p><h3>Random Forests</h3><p>I said all the major algorithms, right?</p><p>Actually, there is but one flaw in Andrew Ng’s course, he doesn’t cover Random Forests.</p><p>An awesome complement to his course is fast.ai’s <a href="http://course18.fast.ai/ml">Introduction to Machine Learning for Coders</a>.</p><p>Jeremy Howard goes super practical on the missing piece in Ng’s course covering a topic that is, for many classical problems, the best solution out there.</p><p>Fast.ai’s approach is what is called Top-Down, meaning they show you how to solve the problem and then explain why it worked, which is the total opposite of what we are used to in school.</p><p>Jeremy also uses real-world tools and libraries, so you learn by coding in industry-tested solutions.</p><h2>Deep Learning</h2><p>Finally!</p><p>The reason why we are all here, Deep Learning!</p><p>Again, the best resource for it is Professor Ng’s course, actually, a series of courses.</p><p>The <a href="https://www.deeplearning.ai/deep-learning-specialization/">Deep Learning Specialization</a> is composed of 5 courses total going from the basics and evolving on specific topics such as language, images, and time-series data.</p><p>One nice thing is that he continues from the very end of his classical Machine Learning course, so it just feels like an extension of the first course.</p><p>The math, the concepts, the notion of how and why it works, he delivers it all very concisely like few I’ve seen.</p><p>The only drawback is that he uses <a href="https://www.tensorflow.org/">Tensorflow</a> 1.x (Google’s DL Framework) in this course, but that’s minimal detail in my opinion since the explanations and exercises are so well delivered.</p><p>You can pick up the most recent version of the framework relatively easy and to do so there is the final piece of this guide, a book.</p><h3>Too much stuff, give me something faster</h3><p>This book might be the only thing you need to start, it is Aurélien Géron’s <a href="https://www.amazon.com.br/Hands-Machine-Learning-Scikit-Learn-TensorFlow-ebook/dp/B07XGF2G87">Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems</a>.</p><p>It covers a lot, from classical Machine Learning to the most recent Deep Learning topics. Good examples and exercises using industry-grade frameworks and libraries.</p><p>I dare say that, if you are really in a rush, you can skip everything I said before and just go for the book.</p><p>You will miss a good amount of information contained on the other resources mentioned, but the practical and actionable knowledge from Géron’s book is enough to work on many ideas for your next project.</p><p>If you feel limited after only reading the book, go back and study the rest of the material, it will fill in the gaps you might have and give you a more solid understanding.</p><h2>What about Framework X or Y?</h2><p>"Hey, I’ve heard about PyTorch and that other framework or library X everybody talks about".</p><p>As a Software Engineer, you know better than anyone how fast technology evolves.</p><p>Don’t go crazy for that, after you learn the basics in this guide, you can easily go, for instance, on <a href="https://pytorch.org/">PyTorch</a> documentation or any other library or framework of sorts and learn how to use it in a week or two.</p><p>The techniques, the concepts, are all the same, it is only a matter of syntax and application or even tastes that you might have for any given tool.</p><h2>Conclusion</h2><p>To wrap it up, I want to say that, even though it might seem a lot, I tried to remove all the noise and at the end of the process, you will feel confident that you understand what is happening behind the curtains, the jargons and even be able to read some papers published in the field to keep up with the latest advances.</p><p>TL;DR Here is the list of resources mentioned in sequence:</p><ul><li><a href="https://renanmf.com/the-python-guide-for-beginners/">The Python Guide for Beginners</a></li><li><a href="https://www.youtube.com/watch?v=fNk_zzaMoSs&amp;list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Essence of Linear Algebra</a></li><li><a href="https://www.youtube.com/watch?v=WUvTyaaNkzM&amp;list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr">Essence of Calculus</a></li><li><a href="https://www.coursera.org/learn/machine-learning">Machine Learning</a></li><li><a href="http://course18.fast.ai/ml">Introduction to Machine Learning for Coders</a></li><li><a href="https://www.deeplearning.ai/deep-learning-specialization/">Deep Learning Specialization</a></li><li><a href="https://www.amazon.com.br/Hands-Machine-Learning-Scikit-Learn-TensorFlow-ebook/dp/B07XGF2G87">Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems</a></li></ul></div></div>]]>
            </description>
            <link>https://renanmf.com/machine-learning-and-deep-learning-software-engineers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25431821</guid>
            <pubDate>Tue, 15 Dec 2020 16:32:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lonely people's brains are different due to excess of imaginary social contact]]>
            </title>
            <description>
<![CDATA[
Score 401 | Comments 243 (<a href="https://news.ycombinator.com/item?id=25431817">thread link</a>) | @Bologo
<br/>
December 15, 2020 | https://www.psychnewsdaily.com/lonely-people-have-a-unique-brain-signature-perhaps-due-to-so-much-imagined-social-contact/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/lonely-people-have-a-unique-brain-signature-perhaps-due-to-so-much-imagined-social-contact/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5697" role="main"><div><div><div><p>A <a rel="noreferrer noopener" href="https://dx.doi.org/10.1038/s41467-020-20039-w" target="_blank">new study of almost 40,000 adults</a> has found that the brains of lonely people differ from those of people who are not lonely, in significant and detectable ways. <span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p><p>This loneliness “signature” consists of variations in the volume of different brain regions, and the way those brain regions communicate. And these variations may be related to the typical thinking patterns of lonely people, which include for example higher than average amounts of reminiscence and imaginary conversations.</p><p>The study compared the MRI scans of people who said they “often” feel lonely with the scans of people do not report feeling that way. The data comes from the <a rel="noreferrer noopener" href="https://www.ukbiobank.ac.uk/" target="_blank">UK Biobank</a>, which is an open-source database containing genetic and health information from about half a million people in the UK.</p><p>The 38,701 participants consisted of 47.5% men and 52.5% women. Their ages ranged from 40 – 69, with an average age of 55. About 13% of them answered “yes” to the question “Do you often feel lonely?” Of those who answered yes, about 39% were men, and 61% women.</p><p>The new paper appeared today (December 15) in <em><a rel="noreferrer noopener" href="https://www.nature.com/ncomms" target="_blank">Nature Communications</a></em>.<span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><h2>Lonely people and the default network</h2><p>The researchers behind the study, from McGill University in Montreal, found that the key differences involved the brain’s “<a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Default_mode_network" target="_blank">default network</a>.” This network is responsible for a wide range of mental processes that take place when the brain is at rest. These processes are often referred to as the “inner voice”, or the “self.”</p><p>The default network plays a crucial role in memory, social cognition (i.e. thinking about other people), and mental time travel (“What will I do tomorrow?”). It involves the medial prefrontal cortex, and the posterior cingulate cortex, along with a number of other structures. It is also responsible for hallucinations and internal imagery.</p><p>The researchers discovered, unexpectedly, that volumes in several of these default network regions were larger in lonely people. They also found equally unexpected patterns of positive associations between some of these regions.</p><h2>Feeling lonely: the typical thought patterns of lonely people</h2><p>The association between the default network and loneliness may be because of the way lonely people think. Lonely people have been found, for example, to focus more on internal thoughts, perhaps to compensate for their lack of actual social experiences. Their thought patterns tend to include above-average levels of reminiscing and imagined social exchanges. And this increase in thoughts about the self might well influence the relationship between the regions of the default network.<span data-ez-name="psychnewsdaily_com-box-4"></span></p><p>“In the absence of desired social experiences,” the authors write, “lonely individuals may be biased towards internally directed cognitions,” as if “to fill the social void.”</p><p>In that sense, then, the physical effects of loneliness on the brain are not surprising. Paying “greater attention to one’s inner milieu, and a heightened focus on the self and self-reflective thoughts,” the authors write, “would naturally engage memory-based functions of the default network.”</p><p>Indeed, <a href="https://amzn.to/3nnJzNk" target="_blank" rel="noreferrer noopener sponsored nofollow">past research on loneliness</a> has found that lonely people are more likely to engage in <a href="https://doi.org/10.1037%2F0022-3514.85.3.409" target="_blank" rel="noreferrer noopener">imaginary social interactions</a>, <a href="https://doi.org/10.1111%2Fj.1467-9280.2008.02194.x" target="_blank" rel="noreferrer noopener">nostalgic reminiscences</a>, and <a href="https://doi.org/10.1037%2F0033-295X.114.4.864" target="_blank" rel="noreferrer noopener">hypothetical conversations</a>, and are also more likely to <a href="https://doi.org/10.1111%2Fj.1467-9280.2008.02056.x" target="_blank" rel="noreferrer noopener">treat pets like people</a>.</p><h2>So lonely: why studying loneliness matters</h2><p>Researchers are increasingly recognizing loneliness as a major health problem. A recent study, for example, found that <a href="https://www.psychnewsdaily.com/loneliness-among-older-americans-doubled-during-pandemic-poll-shows/" target="_blank" rel="noreferrer noopener">loneliness has more than doubled among older people</a> since the Covid-19 pandemic began.</p><p>Past research has also shown that older people who experience loneliness have a higher risk of cognitive decline and dementia. Lonely people get sick more often, and take longer to get over infections. Loneliness also increases blood pressure and levels of stress hormones. Socially isolated people are more likely to be depressed, suffer from memory loss, and use alcohol and drugs. Likewise, evidence suggests that loneliness contributes to ageing in a number of ways, and leads to reduced longevity. In fact, the health risks of loneliness are <a href="https://journals.sagepub.com/doi/10.1177/1745691614568352" target="_blank" rel="noreferrer noopener">equivalent to those related to obesity or smoking 15 cigarettes a day</a>.</p><p>Understanding how loneliness works in the brain could one day help prevent neurological disease, and lead to better treatments.</p><p>“We speculate that the associations between the default network and loneliness revealed here,” the researcher write, “reflect increased demands on episodic mental simulation of inner social events in the absence of desired social experience in the external world.”</p><hr><p><strong>Study:</strong> “<a href="https://www.nature.com/articles/s41467-020-20039-w" target="_blank" rel="noreferrer noopener">The default network of the human brain is associated with perceived social isolation</a>“<br><strong>Authors:</strong> Nathan Spreng et al.<br><strong>Published in:</strong> <em><a rel="noreferrer noopener" href="https://www.nature.com/ncomms" target="_blank">Nature Communications</a></em><br><strong>Publication date: </strong>December 15, 2020<br><strong>DOI:</strong> http://dx.doi.org/10.1038/s41467-020-20039-w<br><strong>Photo:</strong> by&nbsp;<a href="https://unsplash.com/@anthonytran?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Anthony Tran</a>&nbsp;via&nbsp;<a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p></div></div></div></article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/lonely-people-have-a-unique-brain-signature-perhaps-due-to-so-much-imagined-social-contact/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25431817</guid>
            <pubDate>Tue, 15 Dec 2020 16:32:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bring Back Physical Media]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25431639">thread link</a>) | @schwartzworld
<br/>
December 15, 2020 | http://schwartz.world/blog/bring_back_physical_media/ | <a href="https://web.archive.org/web/*/http://schwartz.world/blog/bring_back_physical_media/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="main">

<p>My first computer (Apple IIe) used 5-inch floppy disks. If a program didn’t fit on a single floppy, you might need to spread it across multiples, but otherwise this solution was fine. Floppy disks could hold the application AND the user data, be easily backed up or shared, and storing them was easy enough. The computer was old when I got it, and the former owner included something like 500 programs on floppy disk, an endlessly discoverable mountain of software.</p>
<p>My next computer (90s era IBM clone) had multiple media drives, a 3.5-inch floppy drive and a CD drive. The floppies held more data than the old 5-inchers, and had all the same upsides. I could work on something at home, bring it to a computer at school and just keep going. The CD drive was a big game changer though. A CD can hold 700mb of data, and my hard drive at the time was 600mb. A really common pattern was to run software off a CD, but save your user data on floppies or hard drive. There was internet, initially in the AOL and later dial-up, but bandwidth was expensive and transfer speeds were slow. So slow.</p>
<p>My next computer, a G3 Graphite iMac, had an optical drive that could read and write CDs and read DVDs. I used to rent movies from the Blockbuster where I worked and watch them on the tiny CRT screen. This was in the Napster days, and burning CDs was a boon. I could make mixes for friends or girlfriends, or even share my own music. I burned a lot of CDs in those days. The 100gb hard drive was enough that I didn’t miss my floppy drive, plus we had the internet everywhere by then.</p>
<p>Then came the MacBook Pro, a beast of a machine with a SuperDrive (burns CDs and DVDs), USBs galore and even an SD card reader. I owned two incarnations of this machine, one of which is still in service to this day. Around this time, my college started using Iomega Zip Disks, although I never bought a drive for myself, I did own several of the disks.</p>
<p>Now I have two computers I switch between, but neither accepts any form of physical media beyond a USB stick without the inclusion of an external drive. The Mac (my reluctant work machine), can’t even use these without a dongle. These computers are designed to rely on the internet as a means of installing programs and sharing data, which obviously works fine since everybody in the world is doing it that way.</p>
<h3 id="so-what">So what?</h3>
<p>I miss removeable physical media. I miss having a drawer of disks or CDs. Yes, I can still burn CDs, and do, but the subtle advantages of physical media are hard to fully grasp without an ecosystem.</p>
<p>In high school, every kid had a CD book in their backpack. We would ride the bus on field trips and look through each other’s collections to listen to them on the way. I discovered a lot of great music this way. I guess you could look through someone’s iTunes library or Spotify history, but it wouldn’t be the same.</p>
<p>On the same note, a lot of my early musical tastes were formed by listening to my parents old records. I can play songs I like for my children, but without a physical media library they are unlikely to discover my music on their own, especially without album art. I remember seeing the cover of <code>Eat A Peach</code> and thinking that I really wanted to listen to it.</p>
<p>As a parent I have a lot of pictures of my kids, many of which are precious to me. We’ve printed some out, stored others on a SSD, and the rest are in the cloud. Yes, we could print more/all of them, but we all know this is no longer the norm, and I’m probably never going to meander through the folders on our storage drive the way I used to through old family albums.</p>
<p>I think there was a lot of value in being able to run software directly off a CD instead of kludging up your internal storage with installed apps or relying on the cloud. Most software today is designed with the assumption that you have lots of memory, lots of storage and lots of cloud access. Can I even run a MacOS app directly off a CD? Maybe I should try. Look at your own Applications folder and tell me you really need all that installed on your machine. How easy is all that to uninstall if you want to? How big of a SSD would you actually need if you only stored your user data on your machine? How much less worried would you be about security if your computer didn’t require internet access to function? If, in 10 years I want to fire up an old computer or phone, could I even get software onto it?</p>
</section></div>]]>
            </description>
            <link>http://schwartz.world/blog/bring_back_physical_media/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25431639</guid>
            <pubDate>Tue, 15 Dec 2020 16:17:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some real data on a DIY box fan air purifier]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25431501">thread link</a>) | @dyno-might
<br/>
December 15, 2020 | https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
            
            <p><strong>Dec 15, 2020</strong></p>
            
            



<p>Bad air is bad for you. The air purifier market, though, is a mess. Every purifier uses incompatible proprietary filters, presumably to lock you into buying replacements. How do we know these actually work? Few seem to publish lab tests. And why does it cost $100-$300 for a big plastic box with a fan and a filter inside?</p>

<p>It’s common to build DIY air purifiers by basically strapping a filter to a fan. I like the idea of these, but again, it’s hard to be confident they really work. There’s a few experiments out there, but not enough to make me comfortable. So I decided to do some experimenting of my own. I made a purifier, generated smoke, and measured how well it removes tiny particles.</p>



<p>If you’re in a hurry, this post says that if you strap two HEPA filters to a box fan, it will clear the air of basically all the particles we can measure, and it will do it faster than a commercial filter that costs twice as much.</p>

<p><img src="https://dyno-might.github.io/img/purifier/smallroom_log.jpg" alt="in a large room the DIY filter does slightly better than the commercial filter"></p>



<h3 id="diy-purifier">DIY purifier</h3>

<p>My DIY purifier was <em>very</em> simple. (I don’t want to promote any particular brands here. Contact me if you want the exact products.)</p>

<ul>
  <li>A standard box fan. (Cost: $19)</li>
  <li>Two HEPA air filters, each approximately 32 cm x 22 cm and 5cm thick. (Cost: $35 for both)</li>
  <li>A bungie cord. (Cost: Free)</li>
</ul>

<p>Assembly takes about 30s. You put the filters on the intake side of the fan and strap them on with the bungie cord. Here’s a picture:</p>

<p><img src="https://dyno-might.github.io/img/purifier/filter_notape.jpg" alt="DIY purifier" max-width="60%" min-width="35%"></p>

<p>Timeless elegance and grace, it is not. I get the shakes just looking at that bit of crinkled filter.</p>

<h3 id="commercial-purifier">Commercial purifier</h3>

<p>As a comparison, I got a $100 air purifier from a well-known brand that’s intended for small rooms. It uses uses a single HEPA filter that’s about 25cm x 12cm and 4cm thick. Replacement filters currently cost around $25.</p>

<h3 id="smoke">Smoke</h3>

<p>It’s surprisingly hard to repeatedly generate a consistent amount of smoke. I tried burning various things (paper, cardboard) and found that the number of particles generated can vary by an order of magnitude, depending on the burn pattern. This is difficult to control and effectively random.</p>

<p>Ideally, I’d have liked to burn some food product like oil, since the kitchen is usually the biggest source of indoor air pollution. I couldn’t figure out a good way of doing this, either: You’d need to have the same amount of oil distributed in the same way and heated to the same temperature.</p>

<p>I finally settled on using incense. I cut sticks to the length of a standard credit card and then attached the ends horizontal to the ground. This seemed to be pretty consistent. In retrospect, I bet that burning toast in a toaster would work well. (I didn’t have one on hand.)</p>

<h3 id="measurements">Measurements</h3>

<p>I borrowed a cheap-ish ($100) air quality monitor from a friend. I think it’s made by some company in China and then re-sold by various white-label brands. I can’t figure out who the original manufacturer is. Based on data I’ve seen for the reliability of other air quality monitors, I wouldn’t trust the absolute numbers, but the I think the <em>relative</em> measurements should still be OK.</p>

<p>The typical measurement for particulate pollution is “PM 2.5” which is in units of μg/m³. This is intended to measure what you’d get if you did the following:</p>
<ul>
  <li>Take a cubic meter of air.</li>
  <li>Filter all the solid particles out of the air.</li>
  <li>Keep only the solid particles that are are 2.5 micrometers (μm) or smaller.</li>
  <li>Weigh all the particles you kept in micrograms (μg).</li>
</ul>

<p>Here are some ways to interpret these numbers:</p>
<ul>
  <li>The EPA says yearly averages should be below 12 and daily averages below 35.</li>
  <li>The average outdoor level ranges from 6 in Finland to almost 100 in Nepal. Rich countries are typically under 15. The highest levels are typically found in Asia and Africa.</li>
  <li>Cooking can easily cause PM 2.5 measurements to spike into the hundreds. I’ve observed myself that this can happen with only a small amount of visible smoke.</li>
</ul>

<h3 id="logging">Logging</h3>

<p>Since the air quality monitor doesn’t log data, I used an ultra-hacky alternative: I set the monitor next to a laptop running a stopwatch. I then aimed a tabet at both of those screens and took a timelapse video. Finally, I manually transcribed the data by going to each minute marker in the data. (This was even more tedious than it sounds.)</p>



<p>I ran a first experiment in a tiny room of around 8 ㎥. Due to worries that wind from the purifiers might change the speed the incense burned, I placed it on the opposite side of a wall, with a gap of around 20 cm near the ceiling.</p>

<p><img src="https://dyno-might.github.io/img/purifier/setup_tinyroom.jpg" alt="tiny room setup"></p>

<p>I repeated the experiment once with no filter, once with a commercial filter, and once with the DIY filter. Here are the results:</p>

<p><img src="https://dyno-might.github.io/img/purifier/smallroom_linear.jpg" alt="smallroom measurements in linear space"></p>

<p>Things are a bit random around the beginning, probably due to the drifting of the smoke before it’s equalized in the room. With no filter at all, this spikes all the way to 1000 μg/m³, the maximum the instrument can show.</p>

<p>If we make the y-axis logarithmic, it becomes quite clear that the DIY filter is cleaning the air at a better rate. (This is the picture from the top of this page.)</p>

<p><img src="https://dyno-might.github.io/img/purifier/smallroom_log.jpg" alt="smallroom measurements in log space"></p>

<p>If we take the EPA’s threshold of 12 μg/m³, the DIY filter gets there in around 15 minutes, while the commercial filter take around 25 minutes.</p>



<p>Thankfully, I don’t spend most of my time in an 8 ㎥ room. Thus, I repeated the experiment in a large room of around 100 ㎥. Here there was no wall between incense and purifier. Instead I left around a meter of distance between the incense and purifier and the purifier and the monitor.</p>

<p><img src="https://dyno-might.github.io/img/purifier/setup_largeroom.jpg" alt="large room setup"></p>

<p>Here are the results:</p>

<p><img src="https://dyno-might.github.io/img/purifier/largeroom_linear.jpg" alt="large room measurements in linear space"></p>

<p>There’s even more randomness around the beginning, probably just due to how the smoke drifts around. Based on the room volume we’d expect a peak concentration with no filter of around 80 μg/m³ = 1000 μg/m³ * (8/100). Reassuringly, this is pretty close to what we see.</p>

<p>The DIY purifier looks a bit better. If we plot in log space, it’s more clear that it is indeed filtering at a better rate:</p>

<p><img src="https://dyno-might.github.io/img/purifier/largeroom_log.jpg" alt="large room measurements in log space"></p>



<p>It’s common advice for DIY purifiers like this to seal around the edges of the filter so that all air must pass through it.  I share the intuition that this would help, but it’s hard to be sure: If you block airflow, you slow down the fan. This could be counterproductive.</p>

<p>In this case at least, experiment is easier than theory. I took packing tape and carefully sealed around the intake side.</p>

<p><img src="https://dyno-might.github.io/img/purifier/filter_tape.jpg" alt="DIY purifier with tape" max-width="60%" min-width="35%"></p>

<p>And the results are…</p>

<p><img src="https://dyno-might.github.io/img/purifier/taping.jpg" alt="taping around the filter has no effect"></p>

<p>…nothing!?</p>

<p>This was unexpected. I thought the tape would help, but I wouldn’t have been surprised if it hurt instead. Instead, there’s basically no difference at all. I don’t know enough about fluid dynamics to even speculate about what’s happening here, so I won’t try.</p>

<p>There could be some weird quirk in how I ran this experiment. This doesn’t necessarily mean that all the advice to tape around the filter is <em>wrong</em>. However, I’ve never seen any experriments that show taping helps either.</p>



<p><strong>Cost.</strong> The DIY purifier isn’t dramatically cheaper than the commercial one, but I expect the filters would need to be replaced much less often. The commercial purifier uses a single filter with an area of 300 cm², whereas the DIY purifier uses two filters with a total area of around 1400 cm², and also slightly thicker. It’s reasonable to assume the DIY filters could remove ~4 times as many particles before replacement.</p>

<p><strong>Durability.</strong> One concern is that box fans aren’t meant to be used with filters attached and could wear out. This is reasonable. However, box fans are much cheaper than commercial purifiers, and I’ve been using this particular fan with various filters attached for several years now without issue.</p>

<p><strong>Electricity.</strong> The cost of electricity is another factor. Typical box fans seem to use around 55W, whereas commercial purifiers typically use 30-45W. If electricity costs $0.13 / kWh, the box fan would cost around $62 to operate 24 hours a day for a year, while a 30-watt purifier would cost around $34. Obviously, these numbers decrease if you run the purifier less. Some (more expensive) commercial purifiers have air quality sensors built in and automatically turn on only when needed.</p>

<p><strong>MERV or HEPA?</strong> Most people who build box-fan purifiers use <a href="https://en.wikipedia.org/wiki/Minimum_efficiency_reporting_value">MERV</a>-rated filters intended for furnaces. Commercial air purifiers use <a href="https://en.wikipedia.org/wiki/HEPA">HEPA</a>-rated filters. Roughly speaking, HEPA filters are “better” in that they are rated to remove a higher percentage of particles in one pass. It’s not clear that HEPA filter will actual perform better when attached to a fan, though: A filter that catches fewer particles in one pass might still be better if it allows for faster airflow.</p>

<p><strong>That one video.</strong> If you’re reading this article after it was linked from some forum, I’d bet you that someone in the comments links to <a href="https://www.youtube.com/watch?v=kH5APw_SLUU">this video</a> from the Michigan Sinus Center. I found this inspirational, but note a couple of things: First, while the description says they use HEPA filter, the video clearly indicates a MERV filter. Again, that’s not necessarily bad! They claim that around 90% of particles sized 0.3 microns are larger are eliminated in a single pass. That’s good, but not totally reassuring. The question is, does it remove 99% in two passes? If 90% of the particles in the ambient air were large and the filter only catches large particles, then additional passes would never get rid of the most dangerous small particles. This is why I trust HEPA filters a bit more: since they remove almost all particles in one pass, I’m confident they should remove almost all particles eventually. This is also why I strongly prefer experiments that actually measure particles removed from the air in a room, rather than just the air coming out of the purifier.</p>

<p><strong>Further questions.</strong> There’s a lot of things that further experiments could look at:</p>

<ol>
  <li>Does the fan speed make a huge difference?</li>
  <li>How does the purifier compare to larger commercial purifiers?</li>
  <li>How do MERV-rated furnace-type filters compare under the same conditions?</li>
  <li>How can it not matter if there’s tape around the filters!?</li>
  <li>Does fan speed matter? (I always ran the box fan at maximum speed.)</li>
  <li>Is it better to put the filters on the intake or outtake side of the …</li></ol></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/">https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/</a></em></p>]]>
            </description>
            <link>https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25431501</guid>
            <pubDate>Tue, 15 Dec 2020 16:06:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Easy Versioning CSVs in a Database (with powerful query)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25431469">thread link</a>) | @LukeEF
<br/>
December 15, 2020 | https://terminusdb.com/blog/2020/11/23/creating-a-database-with-csvs-using-terminusdb-console/ | <a href="https://web.archive.org/web/*/https://terminusdb.com/blog/2020/11/23/creating-a-database-with-csvs-using-terminusdb-console/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div id="markdown" itemprop="articleBody">
          <p>Hello everybody! I am going to write a tutorial on how to work with CSVs using TerminusDB. That’s right, TerminusDB 4.0 now has the feature in which you can import and export CSVs, Let’s dive into this.</p>

<h3 id="how-to-create-a-database-with-csvs">How to create a database with CSVs</h3>

<ol>
  <li>Open up the TerminusDB console and create a database</li>
  <li>Fill in the Id, Name and description of your database</li>
  <li>You will find a button Create Database from CSVs <img src="https://terminusdb.com/blog/assets/uploads/1-createdb.png" alt="create database with csvs" title="create database with csvs"></li>
  <li>Click on this button to load which ever CSVs you wish to import to your database, In this blog I am going to use <a href="https://terminusdb.com/blog/2020/09/01/my-first-terminusdb-3-0-graph-bike-share-data/">The Bike Share Data</a></li>
  <li>I have added 2 CSVs into my database as shown below <img src="https://terminusdb.com/blog/assets/uploads/2-createdbwithcsvpreview.png" alt="different csvs loaded into db" title="different csvs loaded into db"></li>
  <li>And that’s it, go ahead and click on Create New database, which includes the 2 CSVs in it 😊😊😊😊😊</li>
</ol>

<h3 id="what-happens-when-you-import-csvs-into-your-database"><strong>What happens when you import CSVs into your Database?</strong></h3>

<p>On creating our database, Go to the Documents Page</p>

<p><img src="https://terminusdb.com/blog/assets/uploads/2-dbdocumentpage.png" alt="document page view" title="document page view"></p>

<p>Each of our CSV files that were loaded on create becomes a separate Document Type. All the columns in the CSV file have been converted into properties and a schema is auto-generated.</p>

<p>Each CSV is of doctype CSV and has rows hanging off them, we can use these auto generated column properties to query the database.</p>

<p>You can also add more CSVs once you have created your database by clicking the Add CSVs</p>

<p>Go to the Schema Page to view the property types which have been generated off the columns</p>

<p><img src="https://terminusdb.com/blog/assets/uploads/3-trasnformcsvtoproperties.png" alt="comaprison between excel and loaded csv" title="comaprison between excel and loaded csv"></p>

<h3 id="lets-query-the-database">Let’s Query the Database</h3>

<p>Get CSV Id’s, Query for type scm:CSV</p>

<div><div><pre><code>and (
    triple('v:CSV ID', 'type','scm:CSV'),
    triple('v:CSV ID', 'label', 'v:CSV Name')
)
</code></pre></div></div>

<p><img src="https://terminusdb.com/blog/assets/uploads/4-querycsvid.png" alt="query database to get csv Id" title="query database to get csv Id"></p>

<p>This query simply gives you the ID and name of available CSVs in the Database. Take a note of the CSV Id you’re interested in, also visit the Schema page to get the Property Id’s your interested in as well.</p>

<p>Open a new Query Pane and try the below query</p>

<div><div><pre><code>const id="doc:CSV_bike_tutorial-1.csv"

WOQL.and (
  .limit(1).triple('v:CSV ID', 'type', 'scm:CSV')
    .eq('v:CSV ID', id)
    .triple('v:CSV ID', 'scm:csv_row', 'v:CSV Row')
    .triple('v:CSV Row', 'type', 'v:Row Type'),
  .quad('v:Property', 'domain', 'v:Row Type', 'schema/main')
    .quad('v:Property', 'label', 'v:Property Name' ,'schema/main')
)
</code></pre></div></div>

<p>This query gets all the property Id and name from the schema graph.</p>

<p>Next, let’s query to display a few columns of our CSV, I plan to display Start Station Number, Start Station, End Station Number, End Station and Duration</p>

<div><div><pre><code>const id="doc:CSV_bike_tutorial-1.csv"

const startStationNumber = "scm:column_Start%20station%20number"
const StartStation = "scm:column_Start%20station"
const endStationNumber = "scm:column_End%20station%20number"
const endStation = "scm:column_End%20station"
const duration = "scm:column_Duration"

and (
	triple('v:CSV ID', 'type','scm:CSV').eq('v:CSV ID', id)
      .triple('v:CSV ID', 'scm:csv_row', 'v:CSV Row')
      .triple('v:CSV Row', startStationNumber, 'v:Start Station Number')
      .triple('v:CSV Row', StartStation, 'v:Start Station')
      .triple('v:CSV Row', endStationNumber, 'v:End Station Number')
      .triple('v:CSV Row', endStation, 'v:End Station')
      .triple('v:CSV Row', duration, 'v:Duration')
)
</code></pre></div></div>

<p>All the rows of CSV matching the column names will be displayed on running this query</p>

<p>So yeah that’s it, you can do all sorts of queries on your CSV</p>

<h3 id="how-to-update-csv">How to update CSV</h3>

<p>I am going to show an example in which I change the duration of Bike number W22558 to 500 in my CSV file and I am going to update this change. So we go to Document Page and click on Add CSVs and add the CSV of interest</p>

<p><img src="https://terminusdb.com/blog/assets/uploads/6-updatcsv.png" alt="update csv" title="update csv"></p>

<p>Since bike_tutorial-1.csv already exists, console will automatically prompt you to update the CSV. Input a commit message of what we have changed and hit on Upload CSV.</p>

<p>The brilliant part about the update is that only diffs are considered and updated which makes update of big sized files more efficient. To understand this, Go to DB Home Page -&gt; Latest Updates</p>

<p><img src="https://terminusdb.com/blog/assets/uploads/7-latestudates.png" alt="DB Home latest updates " title="DB Home latest updates "></p>

<p>Click on your recent update, The only change on update was the row for bike W22558 of duration 417 was removed and a new row for bike W22558 with duration 500 was added instead. This makes updates of CSVs much more quick 😊😊😊😊😊</p>

<p><img src="https://terminusdb.com/blog/assets/uploads/8-updatechange.png" alt="comparison between commits" title="comparison between commits"></p>

<p>You can also time travel on the database to see the diffs on CSV files over time.</p>

<p><img src="https://terminusdb.com/blog/assets/uploads/9-commitime.png" alt="time travel on data" title="time travel on data"></p>

<h3 id="export-your-csv">Export your CSV</h3>

<p>Now that we have imported our CSVs into our database we can do whatever we like or modify it however we want and Export this CSV back.</p>

<p>Go to Documents, and filter for all CSV types to get a download option as shown and download the CSV.</p>

<p><img src="https://terminusdb.com/blog/assets/uploads/5-export.png" alt="export csv from document page " title="export csv from document page "></p>

<p>So here we go, this tutorial shows a very simple way to import  CSVs into TerminusDB and play with them and do all sorts of useful cool queries, whatever you like.</p>

<p>Earlier we had to do all the steps mentioned in <a href="https://terminusdb.com/blog/2020/07/13/terminusdb-importing-reordering-exporting-a-csv/">TerminusDB: Importing, Reordering &amp; Exporting a CSV</a> not anymore!</p>

<p>Now it’s just a few button clicks and voilà!</p>

        </div>

        



      </div>
    </div></div>]]>
            </description>
            <link>https://terminusdb.com/blog/2020/11/23/creating-a-database-with-csvs-using-terminusdb-console/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25431469</guid>
            <pubDate>Tue, 15 Dec 2020 16:03:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Quantitative Approach to Product Market Fit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25431466">thread link</a>) | @pbnjay
<br/>
December 15, 2020 | https://tribecap.co/a-quantitative-approach-to-product-market-fit/ | <a href="https://web.archive.org/web/*/https://tribecap.co/a-quantitative-approach-to-product-market-fit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
<div><div>
<blockquote><p>“The only thing that matters is getting to product-market fit… Product-market fit means being in a good market with a product that can satisfy that market.”</p><cite> MARC ANDREESSEN</cite></blockquote>
</div></div>



<p>Marc Andreessen wrote these words back in 2007, coining the term product-market fit. While the concept has gained widespread adoption there remains a lack of consensus on what it means at a more precise level. For an early stage company, it is still really hard to both recognize the signs of product-market fit, as well as to optimally execute towards amplifying these early signals.</p>



<p>At Tribe Capital we recognize the importance of objectively measuring product-market fit and have developed frameworks to do so using company data. It has not been easy: we have exercised and refined these frameworks hundreds of times across companies in a wide variety of industries across our collective operating and investing history spanning companies such as Facebook, Slack, Front, Carta, and countless other early stage companies. But the payoff has been worth it. These analytical tools are not only useful to inform and improve our investment decisions, but also provide invaluable perspective for founders and operators looking to achieve or amplify existing product-market fit.</p>



<p>This article will first go into greater detail of why we believe a quantitative approach to product-market fit is important. Then it will outline in detail three types of analyses we employ at Tribe Capital to understand product-market fit in a given company. Finally, there are some closing thoughts regarding opportunities for further analysis as well as an appendix that addresses some frequently asked questions.</p>



<h3>Accounting for Product-Market Fit</h3>



<p>A quantitative approach to product-market fit for startups is akin to the discipline of financial accounting. The income statement and balance sheet are the <em>lingua franca</em> for an established company to communicate the financial health of its business. These accounting concepts are often unhelpful when inspecting an unprofitable early-stage company. For a startup, what’s needed is a common quantitative language for what matters, namely, a quantitative framework for assessing product-market fit.</p>



<p>Just as larger companies employ accountants to monitor financial health (cash flows, profitability, etc), so to do product-oriented startups employ people to monitor the health of its product-market fit. They just go by a different name: data scientists. The term “data science” as currently used in the industry is quite broad and covers a wide spectrum of activities spanning what would be better thought of as ML engineering all the way to activities that are typically focused on decision-making and often referred to as “analytics”. For our purposes, we tend to use the latter end of the spectrum as there are numerically more data scientists in analytics style roles than in ML engineering style roles and because the analytics use case is more broadly applicable in early stage companies. In any case, from our point of view, accountants were the first data scientists.</p>



<p>The functional roles of accountants and data scientists are similar: take a big pile of raw data and use it to dig into important aspects of the business. Accountants work with a ledger of every financial transaction to answer whether the business is cash-flow positive, how costs are broken down between fixed and variable, what are the assets and liabilities, etc. Data scientists work with large datasets of customer activity to determine how the product is growing, how retention/churn is playing out, etc. This is why we have chosen to make data science a central component to what we are building at Tribe Capital.</p>



<p><strong>Accounting: Financial Health ↔ “Data Science” : Product-Market Fit</strong></p>



<p>In our development of frameworks for product-market fit, we have taken cues from the principles of accounting and tried to adhere to the following tenets:</p>



<ul><li><strong>Simple</strong>: Definitions should be easy to understand.</li><li><strong>Detailed</strong>: Yet well-defined enough to be useful.</li><li><strong>Universal</strong>: Applicable to a broad range of products and businesses.</li></ul>



<p>In accounting, the three most important frameworks for understanding a business are the balance sheet, income statement, and cash flow statement. These three statements do not provide a complete picture of a company’s health, but they provide a useful snapshot that can be used to benchmark it against other businesses across sectors.</p>



<p>Along those lines, we view product-market fit through three standardized analyses:</p>



<ul><li>Growth Accounting</li><li>Customer Cohorts</li><li>Distribution of Product-Market Fit</li></ul>



<p>As with financial statements, we do not claim these analyses to be an exhaustive definition of product-market fit. Rather, they provide a consistent and extensible method for breaking down customer behavior while being detailed enough to be useful. Also note that most people think of product-market fit in binary terms – either you have it or you don’t. In contrast, we tend to think of it as a spectrum similar to the concept of “financially healthy” for a more mature business.</p>



<p>As investors, we use these analytical techniques to understand whether a company has achieved product-market fit. While these analyses are a critical component of our investment process, they are not the sole deciding factor but are rather a starting point for discussion. We use them the same way Warren Buffet uses financial statements to guide his investments. Does he look at them? Absolutely. Would he ever pass based on financial statements? Absolutely. Would he ever invest based only on financial statements? Hopefully not.</p>



<p>For founders and operators, these frameworks are useful to understand and amplify a company’s growth. We have found that nearly every successful technology company founded in the last two decades has employed them in one form or another. The frameworks provide precise concepts and quantitative relationships that are useful for understanding how customers engage with the company’s product while being universal enough to be applicable in almost any context in which the concept of product-market fit is useful.</p>



<h3>Growth Accounting</h3>



<p>The first technique we use at Tribe Capital when looking at a company is “growth accounting,” which breaks down overall growth in some activity across specific customer segments. The activity can be anything, though revenue and product engagement are the most common examples of growth accounting. To begin, we will focus on revenue and then abstract into engagement later on.</p>



<p>There are six categories that revenue can be bucketed into:</p>



<ul><li><strong>New</strong>: Gained from customers were first active in the present time period.</li><li><strong>Churned</strong>: Lost when a customer who was active in the previous time period has no revenue in the present one.</li><li><strong>Resurrected</strong>: Gained from customers who had churned at some point in the past (and thus generated no revenue in the previous time period) but resumed in the present.</li><li><strong>Expansion</strong>: Gained from customers increasing revenue relative to the previous time period.</li><li><strong>Contraction</strong>: Lost from customers decreasing (but not to zero, otherwise they would be churned) revenue relative to the previous time period.</li><li><strong>Retained: </strong>Carried over by customers from the previous time period to the present one.</li></ul>



<p>For example, a customer who spent $10 last month and $12 this month would have $2 in expansion revenue and $10 in retained revenue. However, if this customer instead spent $8 this month (while still spending $10 last month), then $8 would be counted as retained and $2 as contracted.</p>



<p>There are three important identities that express the definitions above:</p>



<ol start="1"><li>All revenue in the present time period is equal to the sum of the gains in revenue (new, resurrected, and expansion) and retained revenue.</li></ol>



<p>Revenue(t) = retained(t) + new(t) + resurrected(t) + expansion(t)</p>



<ol start="2"><li>All revenue from the previous time period must either churn, contract, or be retained in the present time period.</li></ol>



<p>Revenue(t-1) = retained(t) + churned(t) + contraction(t)</p>



<ol start="3"><li>All <em>change</em> in revenue across a time period is equal to the sum of the gains (new, expansion, and resurrected) minus the sum of the losses (churned and contraction). </li></ol>



<p>Revenue(t) – Revenue(t-1) = new(t) + expansion(t) + resurrected (t) – churned(t) – contraction(t)</p>



<p>For the last identity, we can convert the terms into percentages (e.g. “% New” is new revenue divided by total revenue from the previous time period) to frame everything in terms of the overall growth rate.</p>



<p>Growth_rate ~ New_rate + Resurrected_rate + Expansion_rate – Contraction_rate – Churn_rate</p>



<p>There are three useful statistics that come out of growth accounting:</p>



<p><strong>1. Gross retention</strong> is equal to retained revenue divided by total revenue from the previous time period.</p>



<p>Gross retention = retained(t) / revenue(t-1)</p>



<p><strong>2. Quick ratio</strong> is the sum of gains in revenue (new, resurrected, and expansion) divided by the losses in revenue (churned and contraction).</p>



<p>Quick ratio = [new(t) + resurrected(t) + expansion(t)] / [churned(t) + contraction(t)]</p>



<p>Quick ratio measures how efficiently a company is growing in terms of revenue gained per every unit of revenue lost. (By its definition, a quick ratio below 1.0x means that total revenue must be shrinking.)</p>



<p><strong>3. Net churn </strong>is the sum of losses minus gains in revenue from existing customers only (i.e. excluding new customers) divided by total revenue from the previous time period.</p>



<p>Net_Churn = [churned(t) + contraction(t) – resurrected(t) – expansion(t)] / revenue(t-1)</p>



<p>Note that, by definition…</p>



<p>Growth_rate ~ New_rate – Net_churn</p>



<p>For example, a company with 2% net churn loses 2% of its revenue assuming that it generates no new customers. Note that net churn can be negative, which means that the company will grow revenue even <em>without </em>gaining new customers. Usually, negative net churn is achieved by the company getting significant expansion revenue from its customer base and is a positive signal in any business.</p>


</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tribecap.co/a-quantitative-approach-to-product-market-fit/">https://tribecap.co/a-quantitative-approach-to-product-market-fit/</a></em></p>]]>
            </description>
            <link>https://tribecap.co/a-quantitative-approach-to-product-market-fit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25431466</guid>
            <pubDate>Tue, 15 Dec 2020 16:03:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploring distant space with gravitational waves]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25431430">thread link</a>) | @jroes
<br/>
December 15, 2020 | https://blog.streamlit.io/gravitational-wave-apps-help-students-learn-about-black-holes/ | <a href="https://web.archive.org/web/*/https://blog.streamlit.io/gravitational-wave-apps-help-students-learn-about-black-holes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            <header>

                <section>
                    <a href="https://blog.streamlit.io/tag/community/">Community</a>
                </section>

                

                <p>Exploring distant space with gravitational waves. </p>
            </header>

            <figure>
                <img srcset="https://blog.streamlit.io/content/images/size/w300/2020/12/Ligo_v2-1.gif 300w,
                            https://blog.streamlit.io/content/images/size/w600/2020/12/Ligo_v2-1.gif 600w,
                            https://blog.streamlit.io/content/images/size/w1000/2020/12/Ligo_v2-1.gif 1000w,
                            https://blog.streamlit.io/content/images/size/w2000/2020/12/Ligo_v2-1.gif 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.streamlit.io/content/images/size/w2000/2020/12/Ligo_v2-1.gif" alt="Gravitational-wave apps help students learn about black holes">
            </figure>

            <section>
                <div>
                    <p><em>Written by Jonah Kanner and Jameson Rollins of LIGO Laboratory, California Institute of Technology and Leo Singer of NASA Goddard Space Flight Center.</em></p><p>Gravitational-wave detectors - like <a href="https://ligo.org/">LIGO</a> and <a href="https://www.virgo-gw.eu/">Virgo</a> - are some of the newest tools being used to explore objects in distant galaxies. The current generation of detectors began observing in 2015, and since then, have published observations of 50 collisions of black holes and neutron stars. These exciting discoveries are changing the way astrophysicists are learning about a broad range of topics - including how stars evolve, the expansion rate of the universe, and the deep laws that describe gravity and other fundamental forces.</p><p>LIGO and Virgo data are freely available through the <a href="https://www.gw-openscience.org/about/">Gravitational Wave Open Science Center (GWOSC)</a>. These public data sets are being used all over the world, by scientists, teachers, students, and artists, and have contributed to the publication of over 100 scientific articles over the past year.</p><h2 id="barriers-to-learning">Barriers to learning</h2><p>There’s one challenge encountered by everyone getting started with gravitational-wave data for the first time: &nbsp;most options for working with these data sets demand installing specialized software libraries and writing computer code to process and display the results. For professional scientists, this is often OK - a full-time researcher can afford to spend a few hours installing and learning new software, and likely has already had some experience programming. But for a much broader audience - including high school students, teachers, and artists - writing code in Python to just get started with gravitational-wave data is a significant barrier.</p><p>We’d experimented with a few different options to make this transition easier. In fact, cloud hosted <a href="https://www.gw-openscience.org/tutorials/">Jupyter notebooks</a> provided a big step forward, and we were able to show students how to write code to work with our data, without asking them to install any libraries on their own machines. But when we shared these notebooks with teachers and artists, they were not interested: <strong>they wanted some way to work with gravitational-wave data without using any code at all!</strong></p><p>Moreover, it's not just new students who can benefit from an easier method to access LIGO/Virgo data. Even though professional scientists often <em>could </em>write specialized code to make the plot they want, it’s not efficient to have lots of scientists re-writing code to make the most popular plots.</p><h2 id="enter-streamlit">Enter Streamlit</h2><p>Knowing that we had a need for a web app for the most common plots - both to broaden access and to improve research efficiency - we were excited to discover <a href="https://www.streamlit.io/">Streamlit</a>. Python is very popular in our research community, so Streamlit apps can easily make use of some of the most cutting-edge modules used for gravitational-wave research. For example, <a href="https://pycbc.org/">pycbc</a> and <a href="https://gwpy.github.io/">gwpy</a> are packages used by many gravitational-wave researchers to process and display LIGO/Virgo data. With Streamlit, we can easily write apps that let students and scientists use these packages, without writing any code themselves. Because GWOSC provides data access through a simple API, we found that Streamlit apps can access data on demand, and so process and display any segment of public data.</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/ytV1KhjEQbs?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption><a href="https://www.gw-openscience.org/path/">Getting started video from GWOSC Learning Paths - video created by Cardiff University Physics &amp; Astronomy</a></figcaption></figure><p>Today, we’re using two Streamlit apps to introduce students to LIGO/Virgo data as part of the <a href="https://www.gw-openscience.org/path/">GWOSC Learning Paths</a>, and a third app, the <a href="https://range.ligo.org/">Gravitational Wave Inspiral Range Calculator</a>, allows scientists and astronomers to easily calculate how far into the universe current and future detectors can see.</p><h2 id="working-with-data">Working with data</h2><p>To help students and scientists get started working with gravitational-wave data, we wrote the <a href="https://share.streamlit.io/jkanner/streamlit-dataview/master/app.py/+/">GW Quickview App</a> to make some common plots with any stretch of data. Users can instantly make plots by selecting a published gravitational-wave event from a list, or by entering any time LIGO and Virgo were running. The Quickview App has access to the full public archive of LIGO/Virgo data - around 30 TB and growing! Sliders allow the user to set filter and plotting options, and even to directly download the filtered data. In most cases, you can see the signal from a black hole merger or neutron star collision with just a few clicks. This app is a great way to take a first peak at a segment of data and explore the archive.</p><figure><img src="https://blog.streamlit.io/content/images/2020/12/Screen-Shot-2020-12-07-at-11.10.23-PM.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2020/12/Screen-Shot-2020-12-07-at-11.10.23-PM.png 600w, https://blog.streamlit.io/content/images/size/w1000/2020/12/Screen-Shot-2020-12-07-at-11.10.23-PM.png 1000w, https://blog.streamlit.io/content/images/size/w1600/2020/12/Screen-Shot-2020-12-07-at-11.10.23-PM.png 1600w, https://blog.streamlit.io/content/images/size/w2400/2020/12/Screen-Shot-2020-12-07-at-11.10.23-PM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://share.streamlit.io/jkanner/streamlit-dataview/master/app.py/+/">GW Quickview App</a></figcaption></figure><h2 id="how-far-can-ligo-see">How far can LIGO see?</h2><p>One of the most important things to know about a gravitational-wave detector is how sensitive it is to the kinds of signals it’s capable of detecting. Ground-based gravitational-wave detectors primarily target the mergers of black holes or neutron stars, also known as compact binary coalescences (CBCs). Since the amplitude of a CBC signal is inversely proportional to how far away it is, the question is usually asked in terms of how far away can we detect the signal from a given type of CBC. In LIGO’s first observing run (O1) the LIGO detectors could detect binary neutron star (BNS) mergers out to a distance of roughly 70 megaparcecs (Mpc), or 230 million light-years. As the detectors have improved, the so-called “inspiral range” has increased as well; during the O3 run the LIGO BNS inspiral range was nearly 120 Mpc. Every time the range doubles the volume of space searched goes up by a factor of 8, and the event rate is proportional to volume. That’s a lot more events!</p><p>While plenty of tools exist to calculate the range for a given detector, all of them required special access and knowledge to run. With Streamlit, we were able to create a simple web app tool for anyone to <a href="https://range.ligo.org/">calculate the inspiral range for any type of CBC</a> they wish, for any point of the past observing runs, or even for hypothetical detectors that are yet to be built. This app should be useful for LIGO scientists, for the general astronomy community, and for the public at large.<br></p><figure><img src="https://blog.streamlit.io/content/images/2020/12/Screen-Shot-2020-12-07-at-11.10.00-PM.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2020/12/Screen-Shot-2020-12-07-at-11.10.00-PM.png 600w, https://blog.streamlit.io/content/images/size/w1000/2020/12/Screen-Shot-2020-12-07-at-11.10.00-PM.png 1000w, https://blog.streamlit.io/content/images/size/w1600/2020/12/Screen-Shot-2020-12-07-at-11.10.00-PM.png 1600w, https://blog.streamlit.io/content/images/size/w2400/2020/12/Screen-Shot-2020-12-07-at-11.10.00-PM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://range.ligo.org/">Gravitational Wave Inspiral Range Calculator</a></figcaption></figure><h2 id="finding-signals-in-the-noise">Finding signals in the noise</h2><p>Gravitational wave signals are typically buried in noise; finding them requires a few signal processing tricks. These signal processing concepts are new to many students, and can be a barrier to understanding data from LIGO and Virgo. Working with Professor Amber Stuver at Villanova, we created an app to let students try out some signal processing in an easy to use, interactive environment. The <a href="https://share.streamlit.io/jkanner/streamlit-audio/main/app.py">Signal Processing Tutorial</a> asks visitors to apply high-pass filtering and whitening to noisy data, to find a secret sound hidden in the noise. Then, they can try their new skills on some real data, and try to recreate a well known plot showing the first gravitational-wave observation of a binary black hole merger. Following hints from a <a href="https://blog.streamlit.io/uc-davis-tool-tracks-californias-covid-19-cases-by-region/">post by Pranav Pandit</a>, we found we were able to speed up the app by porting plots from <code>matplotlib</code> to <code>altair</code>, so that students can adjust plot parameters and see updates almost instantly.</p><figure><img src="https://blog.streamlit.io/content/images/2020/12/Screen-Shot-2020-12-07-at-11.12.26-PM.png" alt="" srcset="https://blog.streamlit.io/content/images/size/w600/2020/12/Screen-Shot-2020-12-07-at-11.12.26-PM.png 600w, https://blog.streamlit.io/content/images/size/w1000/2020/12/Screen-Shot-2020-12-07-at-11.12.26-PM.png 1000w, https://blog.streamlit.io/content/images/size/w1600/2020/12/Screen-Shot-2020-12-07-at-11.12.26-PM.png 1600w, https://blog.streamlit.io/content/images/size/w2400/2020/12/Screen-Shot-2020-12-07-at-11.12.26-PM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://share.streamlit.io/jkanner/streamlit-audio/main/app.py">Signal Processing Tutorial</a></figcaption></figure><h2 id="building-the-app">Building the app</h2><p>We built the GW Quickview App partly as an experiment, to see how easy it would be to run some of our favorite python modules in Streamlit. In this case, we tried using gwpy, which has a number of handy methods for finding, processing, and plotting LIGO and Virgo data.</p><h3 id="data-discovery-and-download">Data discovery and download</h3><p>The <a href="https://github.com/jkanner/streamlit-dataview">app code</a> uses the gwosc client for data discovery, to get a list of all published gravitational-wave events, and find their GPS times:</p><pre><code>
from gwosc import datasets
eventlist = datasets.find_datasets(type='events')
chosen_event = st.sidebar.selectbox('Select Event', eventlist)
t0 = datasets.event_gps(chosen_event)

</code></pre><p>Then, it uses gwpy to download the data file with the corresponding time:</p><pre><code>
from gwpy.timeseries import TimeSeries
strain = TimeSeries.fetch_open_data(detector, t0-14, t0+14, cache=False)


</code></pre><p>The strain data are stored in some pretty big files (up to 500 MB), so we used the cache feature of <code>streamlit</code> to allow users to change plot parameters without needing to repeat the data download.</p><h3 id="data-processing">Data processing</h3><p>To make plots where you can see a signal in GW data, some signal processing steps are needed to reduce the impact of noise. The app uses the <a href="https://gwpy.github.io/docs/stable/api/gwpy.timeseries.TimeSeries.html"><code>bandpass()</code> and <code>whiten()</code></a> <a href="https://gwpy.github.io/docs/stable/api/gwpy.timeseries.TimeSeries.html">methods</a> of gwpy to do this. Sliders allow the user to set the limits on the band-pass filter, and to toggle whitening on or off. The app also uses the gwpy <a href="https://gwpy.github.io/docs/stable/examples/timeseries/qscan.html"><code>q_transform</code></a> method to make a beautiful time-frequency plot, which allows most detectable events to be clearly seen in the figure. Additional sliders allow setting plot parameters, so the user can fine-tune the time-frequency plot to look just right. We even used the new <code>streamlit beta_expander<strong>()</strong></code><strong> </strong>to allow the user to display hints about how to understand the plots and set the parameters.</p><h3 id="display-the-plots">Display the plots</h3><p>Finally, the app displays several plots to visualize the data. We opted to use convenient methods in gwpy to make plots with <code>matplotlib</code>, which saved us from writing code to style and label the plots. That fact that Streamlit can easily display these plots with <code>streamlit.pyplot()</code> was a big plus for us, and the Streamlit team helped us fix some <a href="https://blog.streamlit.io/uc-davis-tool-tracks-californias-covid-19-cases-by-region/">issues related to thread-safety</a> when using this feature.</p><p>Though we know that Streamlit apps run faster when plotting with <code>altair</code> (we used this trick in another app!), for the GW Quickview App, we chose to keep the <code>matplotlib</code> plots, mainly to demonstrate the handy plotting features built into gwpy.</p><h2 id="the-big-picture">The big picture </h2><p>A number of break-throughs in the past few years have proved that gravitational-wave detectors represent a new and exciting way to learn about our universe. To make use of this new technology, we’ll need to train the next generation of scientists who will build the instruments of the future and study their observations. After getting started with Streamlit apps and <a href="https://www.gw-openscience.org/path/">GWOSC Learning Paths</a>, we hope some students will move on to use …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.streamlit.io/gravitational-wave-apps-help-students-learn-about-black-holes/">https://blog.streamlit.io/gravitational-wave-apps-help-students-learn-about-black-holes/</a></em></p>]]>
            </description>
            <link>https://blog.streamlit.io/gravitational-wave-apps-help-students-learn-about-black-holes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25431430</guid>
            <pubDate>Tue, 15 Dec 2020 16:00:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made a Value Proposition generator]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25431372">thread link</a>) | @jammingpierce
<br/>
December 15, 2020 | https://www.hashtagslayer.com/value-proposition-generator | <a href="https://web.archive.org/web/*/https://www.hashtagslayer.com/value-proposition-generator">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    <p>Short &amp; simple answers work best <span>ðŸ˜Š</span></p>
    <form action="/value-proposition-generator" accept-charset="UTF-8" method="post">

      <p><label for="team">Is your business an individual or a team?</label><br>
        
      </p>

      <p><label for="client">Who is your ideal client?</label>
        
      </p>

      <p><label for="struggle">What do your clients struggle with? (a painful experience)</label>
        
      </p>

      <p><label for="feeling">How does your clientsâ€™ struggle make them feel?</label>
        
      </p>

      <p><label for="process">What do you use to solve your clientsâ€™ struggle?</label>
        
      </p>

      <p><label for="goal">What is your clientsâ€™ goal?</label>
        
      </p>

      <p><label for="bonus">What is something your clients donâ€™t want to give up, (or dream of being able to do) while working towards their goal?</label>
        
      </p>

      
</form>


  <p>Did you find this helpful? Please share it so we can help your friends, too! <span>ðŸ‘�</span></p>

  <!-- AddToAny BEGIN -->
  
  
  <!-- AddToAny END -->
</div></div>]]>
            </description>
            <link>https://www.hashtagslayer.com/value-proposition-generator</link>
            <guid isPermaLink="false">hacker-news-small-sites-25431372</guid>
            <pubDate>Tue, 15 Dec 2020 15:54:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The unbelievable developers ego]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25431309">thread link</a>) | @jesuisundev
<br/>
December 15, 2020 | https://www.jesuisundev.com/en/the-unbelievable-developers-ego/ | <a href="https://web.archive.org/web/*/https://www.jesuisundev.com/en/the-unbelievable-developers-ego/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			
<!-- Horizontal Top Article -->
<p>I heard a lot about impostor syndrome. But there’s something bigger than that. The size of the developers ego. It’s unbelievable. Let’s talk about it.</p>



<h3>Sunday Rockstar</h3>



<p>By the end of summer 2013, my head was so big I couldn’t get through doors. At that point, I only have two years of experience behind me. So I’m just coming out of the “junior period”. <strong>And above all, <a rel="noreferrer noopener" href="https://www.24joursdeweb.fr/2019/reconnaitre-et-mettre-fin-a-ton-burnout/" target="_blank">in the previous episode of this story</a>(french version), I was doing a complete burn-out because of a project that came straight from hell.</strong> It was basically a trap. Not enough time and a monstrous scope.</p>



<p>After almost two months of work, like a maniac, I shipped a huge app for a big client. I’ve done it ! I did this alone. I did this on time. And i really felt that I had gained expertise.</p>



<p>After a period of post-burnout depression, I came back angry. So angry. <strong>This prowess</strong> <strong>made my head swell up like crazy.</strong> I really thought I was an important person. I would arrive in the morning and walk across the open space without saying hello to anyone.</p>



<div><figure><img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src="https://media.giphy.com/media/NThhQp6mHoFkVuRw9y/giphy.gif" alt="ego"></figure></div>



<p>I would sit at my desk and start my day by complaining about totally stupid customer requests. Then, I would go into meetings and make monologues about how stuff should be made. <strong>I didn’t give a fuck what anybody else was saying.</strong> I was in a special situation. One of the most experienced dev in this little organization. And, in my head, everything I touched turned to gold.</p>



<p>I used to do the same thing all the time. Same technology, same projects, same issues, same context, same load, again and again. In a situation like that, without any challenge, it’s easy to produce fast and well. <strong>It galvanized me in my feeling of being the best. </strong>I told myself that everything was so simple. And if anyone wasn’t keeping pace, I would immediately point the finger at them in the most toxic way possible.</p>



<figure><img src="https://i.imgur.com/k7SWxdv.jpg" data-src="https://i.imgur.com/k7SWxdv.jpg" alt="finger"></figure>



<p>This situation lasted for months. It was bad. And since I was relying only on my past exploits, it was impossible for me to evolve. <strong>And then one day, a major event suddenly changed my approach to everything.</strong></p>



<h3>Why so arrogant?</h3>



<p>Before that, I would like to discuss why this ego overflow is relatively common in tech.</p>



<p>First of all, because companies are at the mercy of technology. In this context, you are the one who gives answers and really knows how the product works. Worse than that, they see what you do like black magic. Like an illusionist, most people don’t understand what you’re doing. But everybody thinks it’s extraordinary. <strong>When people tell you that you’re a magician all the time, you end up believing it.</strong> And each time you do, a dose of ego is injected into your skull.</p>



<p>Juniors are more affected by the phenomenon than seniors. Many companies do the same thing, the same way, all the time. And when it’s so easy, you don’t realize it anymore. <strong>When you don’t know what you don’t know, you think you know everything.</strong> And when a junior is not tutored and/or accompanied by more senior developers, it’s dangerous. You end up with an arrogant kid who thinks he’s a killer.</p>



<figure><img src="https://i.imgur.com/i1DfNLW.jpg" data-src="https://i.imgur.com/i1DfNLW.jpg" alt="ego"></figure>



<p>Also, our field is extremely competitive. Voluntarily or not, companies put developers in competition with each other. Who will be the first to solve the bug? Who has the best architecture? Who knows the most? And I’m not even talking about the competitions that are legion. <strong>And you, <a rel="noreferrer noopener" href="https://www.topcoder.com/tc?module=AlgoRank" target="_blank">how high are you ranked</a> ?</strong> In such an extreme competitive environment, egos can be spectacular.</p>



<p>It’s not reserved to juniors. A lot of developers with more experience are affected, too. What you do is super complicated. <strong>Solving complex problems, faster and faster, of course it flatters ego.</strong> And if you’re not careful, you can quickly fall into disdain for others who don’t keep up. Especially with the juniors. Most developers take a pedagogical and tutoring approach. Others become jerks.</p>



<p>What makes the two profiles quite different is the acceptance of a simple fact. <strong>You don’t know everything, anyone can teach you something, and that’s very positive.</strong> And sometimes it only takes one event to realize that.</p>



<h3>Back to reality</h3>



<p>After several months of nonsense, I was at the top of my bullshit.<strong> King of idiots in a world without any challenges.</strong> And since there was no one to calm me down, it could have gone on for a long time.</p>



<p>And one Friday night, I joined my entire company for drinks at a nearby bar. This company was working in a big co-working space with a lot of other companies. And all these companies were smaller, but their projects were technically very challenging.</p>



<p>I show up and yell at anyone that I’m an expert in just about everything. Oh, yeah, I do architecture and everything else. It was fucking ridiculous. Anyway, at that moment a senior developer from another company hears me talking shit in the distance and comes up to me. He needs to talk to an expert for one of his issues. And in my great kindness, I agree to give him some time.</p>



<figure><img src="https://i.imgur.com/c8Toum8.jpg" data-src="https://i.imgur.com/c8Toum8.jpg" alt="meet"></figure>



<p>And I’m not lying to you, <strong>I didn’t understand all the words in his problem statement</strong>. I was shocked, but I tried to follow what he was telling me as best I could. He exposed to me his problem and asked me what type of data structure, and therefore what algorithm, would be the most optimized for his problem in his existing architecture. </p>



<p>It was an extremely advanced problem. <strong>It dealt with concepts that I had vaguely discussed in school, but never practiced.</strong> He felt that i was confused, so he took it down a notch and asked me what I thought about this or that language for his problem. I had no idea because I was working with only one language and was not interested in anything else. And that’s when he started teaching me about life on my own language that he knocked me out.</p>



<div><figure><img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src="https://qph.fs.quoracdn.net/main-qimg-073103809f1b257a483269bc99d48db5" alt="ego"></figure></div>



<p>The worst part of this story is that in reality, this dude was very nice with me. <strong>I’m the one who mistook this for violence.</strong> It was violence for my ego. I wasn’t ready, but it was exactly what I needed at the time. Pain is a great teacher. And it hurted like hell.</p>



<h3>It’s all relative</h3>



<p>Being efficient and productive for your team is your main goal. Once you get there, there’s something you need to keep in mind. <strong>You are efficient and productive in this context.</strong> Once you’re out of that context, you’re going to have to rethink and question yourself.</p>



<p><strong>The myth of the developer who knows absolutely everything is totally false.</strong> There will always be someone to teach you something, because there’s too much to learn. The problem is that if you convince yourself you’re a god, you’ll end up believing it. The higher your ego will take you, the harder the fall.</p>



<figure><img src="https://i.imgur.com/I2RIDze.jpg" data-src="https://i.imgur.com/I2RIDze.jpg" alt="fall"></figure>



<p>And there are other hellish effects of having so many high ego profiles in our field. First of all, <strong>it’s intimidating for a lot of people</strong>, but more importantly, <strong>it can very quickly jeopardize entire projects</strong>.</p>



<h3>Ego programming</h3>



<p>A long time ago, in a galaxy far, far away, I saw with my own eyes computer projects blown up in mid-air because of overflowing egos.</p>



<p>I saw a team of big senior developers get together for an ambitious project. The idea was to go fast. When the time came to make technical decisions, no one agreed. <strong>Nobody wanted to be wrong and sit on their ego.</strong> And when the first insults appear in pull requests, the project got reboot.</p>



<p>I saw a lead tech forcing his homemade framework. Every developer without exception politely asked for a free and more maintainable solution. <strong>This lead tech decreed that the only choice was his homemade framework.</strong> This dude ego cost the company several developers in a matter of weeks.</p>



<p>I’ve seen so many times entire days of work wasted because a developer was too proud to ask for help. I’ve seen so many times developers redo code they thought was bad without asking the author why. I could go on like that for a long time. </p>



<h3>Egoless programming</h3>



<p>The weekend after this big discussion with this developer, I felt bad. I finally got my head out of my ass and realized I had so much to learn that it was scary. </p>



<p>The more I evolve and learn in this job, the more I realize how much I don’t know. Since that day, I have approached this job with humility. <strong>This trigger tremendously helped me in my career.</strong> And I strongly advise you to do the same. Stay proud of what you’ve accomplished and what you know, but be aware of what you don’t know.</p>



<figure><img src="https://i.imgur.com/NvadHD5.jpg" data-src="https://i.imgur.com/NvadHD5.jpg" alt="rise"></figure>



<p>It’s the same pattern all over the place. <strong>Huge egos, immaturity and a lack of perspective in a highly competitive environment.</strong> When I see initiatives like <a href="https://compassionatecoding.com/" target="_blank" rel="noreferrer noopener">compassionate coding</a> or the well known <a href="https://blog.codinghorror.com/the-ten-commandments-of-egoless-programming/" target="_blank" rel="noreferrer noopener">10 commandments of egoless programming</a>, I tell myself that I’m not the only one to have noticed all this.</p>



<h3>Ego is important</h3>



<p>Now, be careful, ego is still important. <strong>You need confidence in yourself and your abilities.</strong> Approaching this job with humility doesn’t mean letting yourself be stepped on. It means taking the time to listen to everyone before giving your point of view. It means taking everyone’s ideas into account in an unbiased way. <strong>It means making your solution heard when you’re right.</strong> It means accepting when you’re wrong.</p>



<p>Understanding that no one is irreplaceable. <strong>Not you, not me, not your boss, not your CTO</strong>. Understand that calling your colleagues bad is not going to help the project go forward. Understand that just because you consider yourself a god doesn’t mean it’s true. Understand that if you make a mistake it’s not the end of the world. Besides, it’s okay if someone points it out to you. Understanding that it’s your mistakes that will make you grow faster.</p>



<h3>Epilogue</h3>



<p>If this article can even trigger a single click in someone, I would be very happy. There’s still a lot to be said on the subject, but I prefer to stick to the essentials. Your huge misplaced ego won’t get you anywhere. It’s time to keep it out of your career.</p>

			<!-- clearfix -->
			

			
		</div></div>]]>
            </description>
            <link>https://www.jesuisundev.com/en/the-unbelievable-developers-ego/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25431309</guid>
            <pubDate>Tue, 15 Dec 2020 15:47:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SuperRT – Realtime Raytracing on the SNES]]>
            </title>
            <description>
<![CDATA[
Score 335 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25431203">thread link</a>) | @mkeeter
<br/>
December 15, 2020 | https://www.shironekolabs.com/posts/superrt/ | <a href="https://web.archive.org/web/*/https://www.shironekolabs.com/posts/superrt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <header>
        
        
        <h2>
        December 13, 2020
        <br>
        
        </h2>
    </header>
    <section id="post-body">
        <p><strong>Video links for this article:</strong></p>

<ul>
<li><a href="https://youtu.be/VeFF344NbZ4">Short trailer</a></li>
<li><a href="https://youtu.be/2jee4tlakqo">Walkthrough and technical details</a></li>
</ul>

<p>I’m pleased to finally have some results to show for a project I’ve been working on in my spare time for the last year or so.</p>

<p>The idea originated when I was trying to think of an interesting idea for a project to help me learn Verilog and FPGA design, and the notion of building a simple raytracer came to mind (partly inspired by a scarily smart friend of mine who is building his own GPU). A bit later - because sometimes my brain hates me and delights in coming up with silly things to do - this turned into “wouldn’t it be interesting to try making a SNES do raytracing?”, and thus the SuperRT chip idea was born.</p>

<p>What I wanted to try and do was something akin to the Super FX chip used in titles such as Star Fox, where the SNES runs the game logic and hands off a scene description to a chip in the cartridge to generate the visuals. To that end I’ve deliberately tried to restrict myself to just using a single custom chip for the design, not making use of the ARM core available on the DE10 board or any other external processing resources.</p>

<p>The end results look something like this:</p>

<p>
 <video width="320" height="240" autoplay="" loop="">
  <source src="https://www.shironekolabs.com/posts/superrt/Bubbles2.mp4" type="video/mp4">
  SuperRT scene example video
 </video> 
</p>

<blockquote>
<p>Apologies for the poor screenshot quality, incidentally - for some reason my capture card produces terrible results when capturing from my SNES, so I had to resort to the good old “photograph the screen in a darkened room” approach.</p>
</blockquote>

<p><img src="https://www.shironekolabs.com/posts/superrt/Hardware.jpg" alt="SuperRT development hardware"></p>

<p>The Super Nintendo (technically a Super Famicom) seen here has had the case removed to make room for the cabling, but other than that is totally unmodified. Attached to it is the PCB from a copy of an <em>awful</em> Pachinko game I picked up for 100 yen at a local second-hand store, with the game ROM removed and replaced with a cable breakout. This then passes through a set of level shifters to convert the SNES’s 5v down to 3.3v and then into a DE10-Nano FPGA development board with a Cyclone V FPGA. The level shifter boards are anything but pretty - and assembling them was a nightmare thanks to the necessary ICs only being available in surface-mount packages - but they do the job.</p>

<p><img src="https://www.shironekolabs.com/posts/superrt/Slide3.jpg" alt="Hardware layout diagram"></p>

<p>The SuperRT chip constructs the scene using a specialised command language which is executed by one of three parallel execution units on the chip - essentially specialised CISC processors - to perform ray intersection tests. The scene description allows objects to be constructed using a subset of CSG operations, using spheres and planes as the basic building blocks and then performing OR, AND and subtraction operations using them to build up the desired geometry. AABBs are also supported, although primarily for use in culling tests (they can be rendered if desired, but they have a lower positional accuracy than other primitives and thus this is not generally very useful except for debugging purposes).</p>

<p>
 <video width="320" height="240" autoplay="" loop="">
  <source src="https://www.shironekolabs.com/posts/superrt/Artefact.mp4" type="video/mp4">
  SuperRT scene example video
 </video> 
</p>

<p>The renderer casts up to four rays per screen pixel, calculating direct shadows from a directional light source and a single reflection bounce. Surfaces each have a diffuse colour and reflectivity property, and it’s possible to apply modifiers to these based on CSG results or specialised functions - this is used to generate the checkerboard pattern on the floor.</p>

<p><img src="https://www.shironekolabs.com/posts/superrt/Slide2.jpg" alt="SuperRT screenshot"></p>

<p>The ray colour for each pixel is calculated by a “ray engine”, which handles the overall ray lifecycle and uses an “execution engine” module to run the command program describing the scene as many times as is required to resolve the ray. The command program itself is uploaded from the SNES and stored in a local 4K RAM buffer - animation is performed by writing modified commands into this buffer as required. A disassembled command buffer looks like this:</p>

<pre><code>0000 Start
0001 Plane 0, -1, 0, Dist=-2
0002 SphereSub OH 2, 1, 5, Rad=5
0003 SphereSub OH 4, 1, 4, Rad=4
0004 SphereSub OH 5, 1, 9, Rad=9
0005 SphereSub OH 2, 1, 2, Rad=2
0006 SphereSub OH -0.5, 1, 2, Rad=2
0007 RegisterHitNoReset 0, 248, 0, Reflectiveness=0
0008 Checkerboard ORH 48, 152, 48, Reflectiveness=0
0009 ResetHitState
0010 Plane 0, -1, 0, Dist=-2.150146
0011 RegisterHit 0, 0, 248, Reflectiveness=153
0012 AABB 4, -2.5, 11,    8, 3.5, 13
0013 ResetHitStateAndJump NH 44
0014 Origin 6, 2, 12
0015 Plane -0.2929688, 0, -0.9570313, Dist=0.2497559
0016 PlaneAnd OH 0.2919922, 0, 0.9560547, Dist=0.25
0017 PlaneAnd OH 0, 1, 0, Dist=1
0018 PlaneAnd OH 0, -1, 0, Dist=4
0019 PlaneAnd OH -0.9570313, 0, 0.2919922, Dist=-1
0020 PlaneAnd OH 0.9560547, 0, -0.2929688, Dist=1.499756
0021 RegisterHit 248, 0, 0, Reflectiveness=0
</code></pre>

<p>Each execution engine is a processor module with a 14 cycle pipeline, and in general one instruction is retired per cycle, so each execution unit can calculate about 50 million sphere, plane or AABB intersections per second. The exception to this is that branch operations have to flush the entire pipeline and thus have a  16 cycle overhead (14 cycles to flush the pipeline + 2 cycles instruction fetch delay). To try and avoid this as much as possible a branch prediction system is used - fortunately a lot of the time the spatial coherency of nearby rays means that a high prediction hit rate is achievable.</p>

<p><img src="https://www.shironekolabs.com/posts/superrt/Slide5.jpg" alt="SuperRT screenshot"></p>

<p>Intersections in the execution engine are carried out by two pipelines, one handling AABBs and the other spheres and planes. The system as a whole works exclusively using 32-bit integer maths in 18.14 fixed point format, with 16-bit (2.14) format used where values are known to be in the +-1 range, and the sphere/plane intersection pipeline has two dedicated additional maths units that calculate reciprocal and square root operations.</p>

<p>
 <video width="320" height="240" autoplay="" loop="">
  <source src="https://www.shironekolabs.com/posts/superrt/Light.mp4" type="video/mp4">
  SuperRT scene example video
 </video> 
</p>

<p>Once a frame is rendered, the PPU converter module turns the framebuffer into a format that can be DMAed directly to the SNES VRAM for display, reducing it to 256 colours and swizzling it into character tile bitplanes. The screen resolution is 200x160 - this results in exactly 32000 bytes of image data for a full frame, which is transferred to VRAM in two 16000 bytes chunks over successive frames due to bandwidth constraints. Thus the full image can only be refreshed once every two frames, effectively limiting the maximum framerate to 30FPS - although the test scene runs at closer to 20FPS (primarily due to some bottlenecks with the logic on the SNES side at present).</p>

<blockquote>
<p>Many thanks to the participants in <a href="https://forums.nesdev.com/viewtopic.php?f=12&amp;t=20068">this thread</a> over at SNESdev for a lot of useful ideas on fullscreen expansion chip DMA that inspired the solution used here.</p>
</blockquote>

<p><img src="https://www.shironekolabs.com/posts/superrt/Slide4.jpg" alt="SuperRT screenshot"></p>

<p>The chip also implements a number of other basic functions - there is an interface to the SNES cartridge bus, along with a small program ROM holding 32K of code for the SNES (this is constrained by the fact that the interface board currently only connects up the SNES Address Bus A lines, and thus the effective usable address space is a mere 64K, of which 32K is used for memory-mapped IO registers to communicate with the SuperRT chip). There is also a multiplication accelerator unit that lets the SNES perform 16x16bit multiply operations rapidly.</p>

<p><img src="https://www.shironekolabs.com/posts/superrt/Shot13.jpg" alt="SuperRT screenshot"></p>

<p>For debugging, I used the HDMI interface on the DE10 board to output data to a second monitor, along with a Megadrive joypad connected to the GPIO pins to manipulate the debug system. Resource constraints mean that this has to be disabled if all three ray engine cores are enabled, however.</p>

<p>So that’s a broad overview of the system - I intend to post some articles giving more details of how individual components work in the near future. In the meantime, though, if you have any questions or thoughts then please get in touch and I’ll do my best to answer!</p>

<p>Many thanks to Matt, Jaymin, Rick and everyone else who has helped with advice, inspiration and support!</p>

<p>
 <video width="320" height="240" autoplay="" loop="">
  <source src="https://www.shironekolabs.com/posts/superrt/PanDown.mp4" type="video/mp4">
  SuperRT scene example video
 </video> 
</p>

<p><em>“SNES” and “Super Nintendo” are trademarks of Nintendo Co Ltd. This is a hobby project and completely unassociated with Nintendo.</em></p>

    </section>
</article></div>]]>
            </description>
            <link>https://www.shironekolabs.com/posts/superrt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25431203</guid>
            <pubDate>Tue, 15 Dec 2020 15:36:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Zen of Index.html]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25431167">thread link</a>) | @HugoDaniel
<br/>
December 15, 2020 | https://hugodaniel.com/posts/using-just-an-index-to-develop-a-web-app/ | <a href="https://web.archive.org/web/*/https://hugodaniel.com/posts/using-just-an-index-to-develop-a-web-app/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

		<header>
			
			<p> Web development has become a very complex field with many branches and tools to master. In this article, I suggest doing the inverse and use just a simple `index.html` file to manage all of the web app development scripts and assets. This might seem radical but does it make life more complex than using all those front-end tools we have become accustomed to? </p>
			<nav>
				<time datetime="2020-12-15">15-Dec-2020</time>
				<span>
					<a id="back" href="https://hugodaniel.com/">About me</a>
					<a href="https://hugodaniel.com/posts">All posts</a>
				</span>
			</nav>
		</header>
		<p>Using an <code>index.html</code> as the single management file for the app.</p>
<p><img src="https://hugodaniel.com/images/html5-hammer.png" alt="HTML5 badge with a hammer, ready to do some damage" title="That is one big hammer!"></p>
<p><em>"It might work for small things, but I wouldn't use it for something big."</em>
Said someone about something.</p>
<p>These are some of the things that an <code>index.html</code> typically does:</p>
<ul>
<li>Sets the title for the current page</li>
<li>Defines the content and assets</li>
<li>Defines content to be used as a template</li>
<li>Loads styles</li>
<li>Runs scripts and resolves modules dependencies</li>
</ul>
<p>Which are already quite good, but there are many more goodies to be found among the things that a simple <code>index.html</code> allows to do such as:</p>
<ul>
<li>Set a <a href="https://developer.mozilla.org/en-US/docs/Web/Manifest">manifest file</a> for offline usage of the page items</li>
<li>Using the <a href="https://developer.mozilla.org/en-US/docs/Web/API">Web API</a>'s on the scripts (navigation, web components, 3d, audio, network access, etc...)</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Preloading_content">Preload</a> content and assets</li>
<li>Content <a href="https://en.wikipedia.org/wiki/Web_syndication">syndication</a></li>
<li>Social networks <a href="https://ogp.me/">meta information</a></li>
</ul>
<p>In fact, everything that any modern complex Web App does can be fit into a single <code>index.html</code> file.</p>
<p>It is mostly a matter of managing the complexity and growth of files, assets, components, etc...</p>
<p>We have developed a wide range of very complex tools to help us with that. Front-end development has become so complex that it is hard for any single person to master it.</p>
<p>How much harder would life be if a single <code>index.html</code> was used to drive all of the development instead of all those Create-React-App/Babel/WebPack/npm/yarn/d/sass/styled-components/optimizers? </p>
<p>I don't know how to answer this but will try to shed some light on a simpler, more "naked" approach for web app development.</p>
<p>To start <strong>there are at least two problems</strong> with using a single <code>index.html</code> as the only management file for the app:</p>
<ul>
<li>No TypeScript support (or any other transpiler language, only JS, GLSL, and WebASM supported)</li>
<li>No way to easily manage 3rd party dependencies dependencies (dependencies)</li>
</ul>
<p>These two will be the subject of my next post. For now, I am going to lay the ground for a simple <code>index.html</code>-only approach.</p>
<h2 id="a-common-structure-for-most-apps">A common structure for most apps</h2>
<p>The common structure I plan to follow is something like this:</p>
<pre><code><span>&lt;</span><span>head</span><span>&gt;
</span><span>&lt;!-- Page meta --&gt;
&lt;!-- &lt;link&gt;'s go here after the meta stuff --&gt;
&lt;!-- &lt;script type="module"&gt;'s go here --&gt;
</span><span>&lt;/</span><span>head</span><span>&gt;
&lt;</span><span>body</span><span>&gt; </span><span>&lt;!-- Feature flags as class strings in body --&gt;
  &lt;!-- Modals go here --&gt;
  </span><span>&lt;</span><span>main</span><span>&gt;
    </span><span>&lt;!-- The content being shown goes here --&gt;
  </span><span>&lt;/</span><span>main</span><span>&gt;
  </span><span>&lt;!-- &lt;template&gt;'s go here --&gt;
  &lt;!-- &lt;script&gt;'s go here at the end --&gt;
</span><span>&lt;/</span><span>body</span><span>&gt;
</span></code></pre>
<p>This structure makes some compromises but overall is enough for most complex apps. It is not that different from a normal HTML page 🧐.</p>
<p>JavaScript modules are being loaded at the <code>&lt;head&gt;</code>, which is ok because module scripts are deferred by default and do not block the parsing of the rest of the document. They could go anywhere, I prefer to keep the <code>&lt;body&gt;</code> for the main logic and more immediate scripts.</p>
<p>With this in mind, here are 3 common things to a web app that can be done in such a simple structure without much effort:</p>
<ol>
<li>Global loading state (full-screen loading)</li>
<li>Routing (what to show according to the URL being rendered)</li>
<li>Place common HTML parts/assets without repeating them (templating/components)</li>
</ol>
<h2 id="global-loading-page">Global Loading page</h2>
<p>A loading page that fills the whole screen is something that most web apps have, some even distract us with cool animations while loading.</p>
<p>In the above structure, the loading page goes into the modal area. Right before the <code>&lt;main&gt;</code> content. This allows heavy content like <code>&lt;canvas&gt;</code>, <code>&lt;img&gt;</code> to be placed as <code>&lt;main&gt;</code> children and fully load (shaders, image data, etc) behind it, before clearing the loading state and showing them to our friends.</p>
<pre><code><span>...
&lt;</span><span>body</span><span>&gt;
  &lt;</span><span>div </span><span>id</span><span>="</span><span>loading</span><span>"&gt;Loading&lt;/</span><span>div</span><span>&gt;
  &lt;</span><span>main</span><span>&gt;
  ...
</span></code></pre>
<p>The whole visible space gets covered with that loading <code>&lt;div&gt;</code> which is then removed when all the things that the app needs for a good first run are ready.</p>
<p>Having the loading upfront on the <code>index.html</code> without needing any JS to first show it also helps our karma score in the bots&amp;spiders purgatory that purge the web we all love into useful cinder blocks.</p>
<h2 id="routing">Routing</h2>
<p>No lib is going to be used for routing. Routing is going to consist of simple manipulations of the browser history with <code>popstate</code> and <code>pushstate</code>. The basic approach is:</p>
<ol>
<li>Read the current route from the window location</li>
<li>Clone its corresponding <code>&lt;template&gt;</code> into the <code>&lt;main&gt;</code> tag</li>
<li>Inside it adjust the relevant <code>&lt;a&gt;</code>'s and other link navigation tags to perform a <code>pushState</code> instead of their default behavior
<ul>
<li>Filters can be applied to only consider <code>&lt;a&gt;</code>'s that have relative paths, or that do not have the <code>rel=nofollow</code> attribute</li>
</ul>
</li>
<li><code>onpopstate</code> clone the correspnoding <code>&lt;template&gt;</code> into the <code>&lt;main&gt;</code> tag</li>
</ol>
<p>This is intended only for web apps as an effort to reduce the amount of JS and leverage the features already at hand. For anything similar to regular pages the browser behavior is more than good enough, no need for JS there.</p>
<p>This approach should work well if the web app uses less than 20 or 15 possible routing patterns. Most web apps likely average at some number under 10. This simple approach should be more than enough. There is no need in my foreseeable use cases to use anything more complex like the DOM or any big library to manage routes.</p>
<p>I will evolve this into a very simple routing/templating library to be announced soon(ish). For reference, here is some code that I did for a template engine in one of the many Grid iterations: <a href="https://hugodaniel.com/scripts/meander.js">old routing code</a>.</p>
<p>I appreciate the browser's approach of associating page state with history, however, for a web app I find it simpler and more manageable to keep these two things separate:</p>
<ul>
<li>Routing seen as pure functions of navigation only transformations</li>
<li>App state in its own separate tarpit.</li>
</ul>
<h2 id="html-templating">HTML Templating</h2>
<p>Stamping and repeating a common HTML structure in a couple of places is a frequent routine that most web apps do. Be it for menu entries, list items, or even whole parts like sidebars or modal and toast elements. Finding a common HTML structure and repeat it when needed with small adjustments is a stapled practice.</p>
<p>HTML templating has many technicalities and possibilities. Most JS frameworks commonly solve it in their own way with different degrees of justifiable complexity.</p>
<p>Web browsers already provide a very flexible and complex way to do templating through the Web Components suite of technologies. For most of my cases plain HTML will be prefered and written directly at that <code>index.html</code>. For the other cases where DRY speaks louder a simple static "copy/paste" tag will suffice, a small prototype of this could be something like:</p>
<pre><code><span>customElements</span><span>.</span><span>define</span><span>("</span><span>template-content</span><span>", </span><span>class extends </span><span>HTMLElement </span><span>{
  </span><span>constructor</span><span>() {
    </span><span>super</span><span>();
    </span><span>this</span><span>.</span><span>attachShadow</span><span>({ mode: </span><span>"</span><span>open</span><span>" </span><span>})
        .</span><span>appendChild</span><span>(
          document.</span><span>getElementById</span><span>(
            </span><span>this</span><span>.</span><span>getAttribute</span><span>(</span><span>'</span><span>from-id</span><span>'</span><span>)
          ).content.</span><span>cloneNode</span><span>(</span><span>true</span><span>))
  }
}</span><span>);
</span></code></pre>
<p>This small code defines a new WebComponent tag <code>&lt;template-content&gt;</code>, this tag reads an element id from its <code>from-id</code> attribute, then gets the corresponding element on the DOM for that id, clones it, and replaces itself with it.</p>
<p>This is useful because it provides a quick way to stamp HTML/SVG content on the document. Helpful to replicate SVG elements, lists, and node sub-trees on the client-side.</p>
<pre><code><span>&lt;</span><span>nav</span><span>&gt;
	&lt;</span><span>button </span><span>onclick</span><span>="</span><span>tool</span><span>('</span><span>undo</span><span>')"&gt;
		&lt;</span><span>template-content </span><span>from-id</span><span>="</span><span>tools-button-content</span><span>" /&gt;
		&lt;</span><span>template-content </span><span>from-id</span><span>="</span><span>tools-undo</span><span>" /&gt;
	&lt;/</span><span>button</span><span>&gt;
	&lt;</span><span>button </span><span>onclick</span><span>="</span><span>tool</span><span>('</span><span>draw</span><span>')"&gt;
		&lt;</span><span>template-content </span><span>from-id</span><span>="</span><span>tools-button-content</span><span>" /&gt;
		&lt;</span><span>template-content </span><span>from-id</span><span>="</span><span>tools-draw</span><span>" /&gt;
	&lt;/</span><span>button</span><span>&gt;
&lt;/</span><span>nav</span><span>&gt;

&lt;</span><span>template </span><span>id</span><span>="</span><span>tools-button-content</span><span>"&gt;
</span><span>&lt;!-- Some complex content here --&gt;
</span><span>&lt;/</span><span>template</span><span>&gt;
&lt;</span><span>template </span><span>id</span><span>="</span><span>tools-draw</span><span>"&gt;
</span><span>&lt;!-- Some other complex content here --&gt;
</span><span>&lt;/</span><span>template</span><span>&gt;
</span></code></pre><h2 id="conclusion">Conclusion</h2>
<p>Keeping a single <code>index.html</code> might be just enough for a simpler naked approach to app development. If there is no need for big dependencies, versioning tracking files, transpilers, and all that, this could very well be good enough. It works directly on top of what browsers already provide and hints at a simpler, leaner, style of development.</p>
<p>It does not have TypeScript support and it also does not automatically resolve dependencies and bundles them.</p>
<p>These are two open problems with this approach that I plan to show a possible solution that is on par in simplicity with this one. That will be the subject of my next technical post (likely to come out next week). Stay tuned.</p>

	</article></div>]]>
            </description>
            <link>https://hugodaniel.com/posts/using-just-an-index-to-develop-a-web-app/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25431167</guid>
            <pubDate>Tue, 15 Dec 2020 15:33:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Enumerating Trees]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25430607">thread link</a>) | @lelf
<br/>
December 15, 2020 | https://doisinkidney.com/posts/2020-12-14-enumerating-trees.html | <a href="https://web.archive.org/web/*/https://doisinkidney.com/posts/2020-12-14-enumerating-trees.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            <h2>Enumerating Trees</h2>

            <p>
    Posted on December 14, 2020
</p>



<p>Consider the following puzzle:</p>
<blockquote>
<p>Given a list of <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math> labels, list all the trees with those labels in order.</p>
</blockquote>
<p>For instance, given the labels [1,2,3,4], the answer (for binary trees) is the following:</p>
<pre><code>┌1     ┌1      ┌1     ┌1     ┌1
┤      ┤      ┌┤     ┌┤     ┌┤
│┌2    │ ┌2   ││┌2   │└2    │└2
└┤     │┌┤    │└┤    ┤     ┌┤
 │┌3   ││└3   │ └3   │┌3   │└3
 └┤    └┤     ┤      └┤    ┤
  └4    └4    └4      └4   └4</code></pre>
<p>This problem (the “enumeration” problem) turns out to be quite fascinating and deep, with connections to parsing and monoids. It’s also just a classic algorithmic problem which is fun to try and solve.</p>
<p>The most general version of the algorithm is on forests of rose trees:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>data</span> <span>Rose</span> a <span>=</span> a <span>:&amp;</span> <span>Forest</span> a</span>
<span id="cb2-2"><span>type</span> <span>Forest</span> a <span>=</span> [<span>Rose</span> a]</span></code></pre></div>
<p>It’s worth having a go at attempting it yourself, but if you’d just like to see the slick solutions the following is one I’m especially proud of:</p>
<details>
<summary>Solution to the Enumeration Problem on Forests of Rose Trees</summary>
<div id="cb3"><pre><code><span id="cb3-1"><span>enumForests ::</span> [a] <span>-&gt;</span> [<span>Forest</span> a]</span>
<span id="cb3-2">enumForests <span>=</span> foldrM f []</span>
<span id="cb3-3">  <span>where</span></span>
<span id="cb3-4">    f x xs <span>=</span> <span>zipWith</span> ((<span>:</span>) <span>.</span> (<span>:&amp;</span>) x) (inits xs) (tails xs)</span></code></pre></div>
</details>
<p>In the rest of this post I’ll go through the intuition behind solutions like the one above and I’ll try to elucidate some of the connections to other areas of computer science.</p>

<p>I first came across the enumeration problem when I was writing my master’s thesis: I needed to prove (in Agda) that there were finitely many binary trees of a given size, and that I could list them (this proof was part of a larger verified solver for the countdown problem). My first few attempts were unsuccessful: the algorithm presented in the countdown paper <span data-cites="hutton_countdown_2002">(Hutton <a href="#ref-hutton_countdown_2002" role="doc-biblioref">2002</a>)</span> was not structurally recursive, and did not seem amenable to Agda-style proofs.</p>
<p>Instead, I looked for a type which was isomorphic to binary trees, and which might be easier to reason about. One such type is Dyck words.</p>

<p>A “Dyck word” is a string of balanced parentheses.</p>
<pre><code>()()
(()())()
(())()</code></pre>
<p>It’s (apparently) well-known that these strings are isomorphic to binary trees (although the imperative descriptions of algorithms which actually computed this isomorphism addled my brain), but what made them interesting for me was that they are a <em>flat</em> type, structured like a linked list, and as such should be reasonably straightforward to prove to be finite.</p>
<p>Our first task, then, is to write down a type for Dyck words. Te following is a first possibility:</p>
<div id="cb5"><pre><code><span id="cb5-1"><span>data</span> <span>Paren</span> <span>=</span> <span>LParen</span> <span>|</span> <span>RParen</span></span>
<span id="cb5-2"><span>type</span> <span>Dyck</span> <span>=</span> [<span>Paren</span>]</span></code></pre></div>
<p>But this type isn’t correct. It includes many values which <em>don’t</em> represent balanced parentheses, i.e.&nbsp;the expressions <code>[LParen,RParen] :: Dyck</code> are well-typed. To describe dyck words properly we’ll need to reach for the GADTs:</p>
<div id="cb6"><pre><code><span id="cb6-1"><span>data</span> <span>DyckSuff</span> (<span>n ::</span> <span>Nat</span>)<span> ::</span> <span>Type</span> <span>where</span></span>
<span id="cb6-2">  <span>Done</span><span> ::</span> <span>DyckSuff</span> <span>Z</span></span>
<span id="cb6-3">  <span>Open</span><span> ::</span> <span>DyckSuff</span> (<span>S</span> n) <span>-&gt;</span> <span>DyckSuff</span> n</span>
<span id="cb6-4">  <span>Clos</span><span> ::</span> <span>DyckSuff</span> n     <span>-&gt;</span> <span>DyckSuff</span> (<span>S</span> n)</span>
<span id="cb6-5"></span>
<span id="cb6-6"><span>type</span> <span>Dyck</span> <span>=</span> <span>DyckSuff</span> <span>Z</span></span></code></pre></div>
<p>The first type here represents suffixes of Dyck words; a value of type <code>DyckSuff n</code> represents a string of parentheses which is balanced except for <code>n</code> extraneous closing parentheses. <code>DyckSuff Z</code>, then, has no extraneous closing parens, and as such is a proper Dyck word.</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>&gt;&gt;&gt;</span> <span>Open</span> <span>$</span> <span>Clos</span> <span>$</span> <span>Open</span> <span>$</span> <span>Clos</span> <span>$</span> <span>Done</span><span> ::</span> <span>Dyck</span></span>
<span id="cb7-2">()()</span>
<span id="cb7-3"></span>
<span id="cb7-4"><span>&gt;&gt;&gt;</span> <span>Clos</span> <span>$</span> <span>Open</span> <span>$</span> <span>Clos</span> <span>$</span> <span>Done</span><span> ::</span> <span>DyckSuff</span> (<span>S</span> <span>Z</span>)</span>
<span id="cb7-5">)()</span>
<span id="cb7-6"></span>
<span id="cb7-7"><span>&gt;&gt;&gt;</span> <span>Open</span> <span>$</span> <span>Open</span> <span>$</span> <span>Clos</span> <span>$</span> <span>Open</span> <span>$</span> <span>Clos</span> <span>$</span> <span>Clos</span> <span>$</span> <span>Open</span> <span>$</span> <span>Clos</span> <span>$</span> <span>Done</span><span> ::</span> <span>Dyck</span></span>
<span id="cb7-8">(()())()</span>
<span id="cb7-9"></span>
<span id="cb7-10"><span>&gt;&gt;&gt;</span> <span>Open</span> <span>$</span> <span>Open</span> <span>$</span> <span>Clos</span> <span>$</span> <span>Clos</span> <span>$</span> <span>Open</span> <span>$</span> <span>Clos</span> <span>$</span> <span>Done</span><span> ::</span> <span>Dyck</span></span>
<span id="cb7-11">(())()</span></code></pre></div>
<p>The next task is to actually enumerate these words. Here’s an <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false" form="prefix">(</mo><mi>n</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math> algorithm which does just that:</p>
<div id="cb8"><pre><code><span id="cb8-1"><span>enumDyck ::</span> <span>Int</span> <span>-&gt;</span> [<span>Dyck</span>]</span>
<span id="cb8-2">enumDyck sz <span>=</span> go <span>Zy</span> sz <span>Done</span> []</span>
<span id="cb8-3">  <span>where</span></span>
<span id="cb8-4">    go, zero, left,<span> right ::</span> <span>Natty</span> n <span>-&gt;</span> <span>Int</span> <span>-&gt;</span> <span>DyckSuff</span> n <span>-&gt;</span> [<span>Dyck</span>] <span>-&gt;</span> [<span>Dyck</span>]</span>
<span id="cb8-5">    </span>
<span id="cb8-6">    go n m k <span>=</span> zero n m k <span>.</span> left n m k <span>.</span> right n m k</span>
<span id="cb8-7"></span>
<span id="cb8-8">    zero <span>Zy</span> <span>0</span> k <span>=</span> (k<span>:</span>)</span>
<span id="cb8-9">    zero _  _ _ <span>=</span> <span>id</span></span>
<span id="cb8-10">    </span>
<span id="cb8-11">    left (<span>Sy</span> n) m k <span>=</span> go n m (<span>Open</span> k)</span>
<span id="cb8-12">    left <span>Zy</span>     _ _ <span>=</span> <span>id</span></span>
<span id="cb8-13">    </span>
<span id="cb8-14">    right _ <span>0</span> _ <span>=</span> <span>id</span></span>
<span id="cb8-15">    right n m k <span>=</span> go (<span>Sy</span> n) (m<span>-</span><span>1</span>) (<span>Clos</span> k) </span>
<span id="cb8-16"></span>
<span id="cb8-17"><span>&gt;&gt;&gt;</span> <span>mapM_</span> <span>print</span> (enumDyck <span>3</span>)</span>
<span id="cb8-18"><span>"()()()"</span></span>
<span id="cb8-19"><span>"(())()"</span></span>
<span id="cb8-20"><span>"()(())"</span></span>
<span id="cb8-21"><span>"(()())"</span></span>
<span id="cb8-22"><span>"((()))"</span></span></code></pre></div>
<p>A variant of this function was what I needed in my thesis: I also needed to prove that it produced every possible value of the type <code>Dyck</code>, which was not too difficult.</p>
<p>The difficult part is still ahead, though: now we need to convert between this type and a binary tree.</p>

<p>First, for the conversion algorithms we’ll actually need another GADT:</p>
<div id="cb9"><pre><code><span id="cb9-1"><span>infixr</span> <span>5</span> <span>:-</span></span>
<span id="cb9-2"><span>data</span> <span>Stack</span> (<span>a ::</span> <span>Type</span>) (<span>n ::</span> <span>Nat</span>)<span> ::</span> <span>Type</span> <span>where</span></span>
<span id="cb9-3">  <span>Nil</span><span>  ::</span> <span>Stack</span> a <span>Z</span></span>
<span id="cb9-4"><span>  (:-) ::</span> a <span>-&gt;</span> <span>Stack</span> a n <span>-&gt;</span> <span>Stack</span> a (<span>S</span> n)</span></code></pre></div>
<p>The familiar length-indexed vector will be extremely useful for the next few bits of code: it will act as a stack in our stack-based algorithms. Here’s one of those algorithms now:</p>
<div id="cb10"><pre><code><span id="cb10-1"><span>dyckToTree ::</span> <span>Dyck</span> <span>-&gt;</span> <span>Tree</span></span>
<span id="cb10-2">dyckToTree dy <span>=</span> go dy (<span>Leaf</span> <span>:-</span> <span>Nil</span>)</span>
<span id="cb10-3">  <span>where</span></span>
<span id="cb10-4"><span>    go ::</span> <span>DyckSuff</span> n <span>-&gt;</span> <span>Stack</span> <span>Tree</span> (<span>S</span> n) <span>-&gt;</span> <span>Tree</span></span>
<span id="cb10-5">    go (<span>Open</span> d) ts               <span>=</span> go d (<span>Leaf</span> <span>:-</span> ts)</span>
<span id="cb10-6">    go (<span>Clos</span> d) (t1 <span>:-</span> t2 <span>:-</span> ts) <span>=</span> go d (t2 <span>:*:</span> t1 <span>:-</span> ts)</span>
<span id="cb10-7">    go <span>Done</span>     (t  <span>:-</span> <span>Nil</span>)      <span>=</span> t</span></code></pre></div>
<p>This might be familiar: it’s actually shift-reduce parsing dressed up with some types. The nice thing about it is that it’s completely total: all pattern-matches are accounted for here, and when written in Agda it’s clearly structurally terminating.</p>
<p>The function in the other direction is similarly simple:</p>
<div id="cb11"><pre><code><span id="cb11-1"><span>treeToDyck ::</span> <span>Tree</span> <span>-&gt;</span> <span>Dyck</span></span>
<span id="cb11-2">treeToDyck t <span>=</span> go t <span>Done</span></span>
<span id="cb11-3">  <span>where</span></span>
<span id="cb11-4"><span>    go ::</span> <span>Tree</span> <span>-&gt;</span> <span>DyckSuff</span> n <span>-&gt;</span> <span>DyckSuff</span> n</span>
<span id="cb11-5">    go <span>Leaf</span>        <span>=</span> <span>id</span></span>
<span id="cb11-6">    go (xs <span>:*:</span> ys) <span>=</span> go xs <span>.</span> <span>Open</span> <span>.</span> go ys <span>.</span> <span>Clos</span></span></code></pre></div>

<p>Much of this stuff has been on my mind recently because of <a href="https://www.youtube.com/watch?v=T_IINWzQhow">this</a> <span data-cites="riley_program_2020">(<a href="#ref-riley_program_2020" role="doc-biblioref">2020</a>)</span> video on the computerphile channel, in which Graham Hutton goes through using QuickCheck to test an interesting compiler. The compiler itself is explored more in depth in <span data-cites="bahr_calculating_2015">Bahr and Hutton (<a href="#ref-bahr_calculating_2015" role="doc-biblioref">2015</a>)</span>, where the algorithms developed are really quite similar to those that we have here.</p>
<p>The advantage of the code above is that it’s all <em>total</em>: we will never pop items off the stack that aren’t there. This is a nice addition, and it’s surprisingly simple to add: let’s see if we can add it to the compiler presented in the paper.</p>
<p>The first thing we need to change is we need to add a payload to our tree type: the one above is just the <em>shape</em> of a binary tree, but the language presented in the paper contains values.</p>
<div id="cb12"><pre><code><span id="cb12-1"><span>data</span> <span>Expr</span> (<span>a ::</span> <span>Type</span>) <span>where</span></span>
<span id="cb12-2">  <span>Val</span><span>   ::</span> a <span>-&gt;</span> <span>Expr</span> a</span>
<span id="cb12-3"><span>  (:+:) ::</span> <span>Expr</span> a <span>-&gt;</span> <span>Expr</span> a <span>-&gt;</span> <span>Expr</span> a</span></code></pre></div>
<p>We’ll need to change the definition of <code>Dyck</code> similarly:</p>
<div id="cb13"><pre><code><span id="cb13-1"><span>data</span> <span>Code</span> (<span>n ::</span> <span>Nat</span>) (<span>a ::</span> <span>Type</span>)<span> ::</span> <span>Type</span> <span>where</span></span>
<span id="cb13-2">  <span>HALT</span><span> ::</span> <span>Code</span> (<span>S</span> <span>Z</span>) a</span>
<span id="cb13-3">  <span>PUSH</span><span> ::</span> a <span>-&gt;</span> <span>Code</span> (<span>S</span> n) a <span>-&gt;</span> <span>Code</span> n a</span>
<span id="cb13-4">  <span>ADD</span><span>  ::</span> <span>Code</span> (<span>S</span> n) a <span>-&gt;</span> <span>Code</span> (<span>S</span> (<span>S</span> n)) a</span></code></pre></div>
<p>After making it so that these data structures can now store contents, there are two other changes worth pointing out:</p>
<ul>
<li>The names have been changed, to match those in the paper. It’s a little clearer now that the Dyck word is a bit like code for a simple stack machine.</li>
<li>The numbering on <code>Code</code> has changed. Now, the <code>HALT</code> constructor has a parameter of <code>1</code> (well, <code>S Z</code>), where its corresponding constructor in <code>Dyck</code> (<code>Done</code>) had <code>0</code>. Why is this? I am not entirely sure! To get this stuff to all work out nicely took a huge amount of trial and error, I would love to see a more principled reason why the numbering changed here.</li>
</ul>
<p>With these definitions we can actually transcribe the <code>exec</code> and <code>comp</code> functions almost verbatim <span data-cites="bahr_calculating_2015">(from page 11 and 12 of <a href="#ref-bahr_calculating_2015" role="doc-biblioref">2015</a>)</span>.</p>
<div id="cb14"><pre><code><span id="cb14-1"><span>exec ::</span> <span>Code</span> n <span>Int</span> <span>-&gt;</span> <span>Stack</span> <span>Int</span> (n <span>+</span> m) <span>-&gt;</span> <span>Stack</span> <span>Int</span> (<span>S</span> m)</span>
<span id="cb14-2">exec <span>HALT</span>         st              <span>=</span> st</span>
<span id="cb14-3">exec (<span>PUSH</span> v is)  st              <span>=</span> exec is (v <span>:-</span> st)</span>
<span id="cb14-4">exec (<span>ADD</span>    is) (t1 <span>:-</span> t2 <span>:-</span> st) <span>=</span> exec is (t2 <span>+</span> t1 <span>:-</span> st)</span>
<span id="cb14-5"></span>
<span id="cb14-6"><span>comp ::</span> <span>Expr</span> a <span>-&gt;</span> <span>Code</span> <span>Z</span> a</span>
<span id="cb14-7">comp e <span>=</span> comp' e <span>HALT</span></span>
<span id="cb14-8">  <span>where</span></span>
<span id="cb14-9"><span>    comp' ::</span> <span>Expr</span> a <span>-&gt;</span> <span>Code</span> (<span>S</span> n) a <span>-&gt;</span> <span>Code</span> n a</span>
<span id="cb14-10">    comp' (<span>Val</span>     x) <span>=</span> <span>PUSH</span> x</span>
<span id="cb14-11">    comp' (xs <span>:+:</span> ys) <span>=</span> comp' xs <span>.</span> comp' ys <span>.</span> <span>ADD</span></span></code></pre></div>

<p>As I have mentioned, a big benefit of all of this stuff is that it can be translated into Agda readily. The real benefit of <em>that</em> is that we can show the two representations of programs are fully isomorphic. I have proven this <a href="https://github.com/oisdk/agda-playground/blob/d7234c276f063dbb4a2d2cbcedb86dd48501a908/Data/Dyck/Payload.agda">here</a>: the proof is surprisingly short (about 20 lines), and the rest of the code follows the Haskell stuff quite closely. I got the idea for much of the proof from <a href="https://gist.github.com/Boarders/9d83f9cbcfaffb04cf2464588fc46df9">this</a> bit of code by <a href="https://boarders.github.io/">Callan McGill</a> <span data-cites="mcgill_compiler_2020">(<a href="#ref-mcgill_compiler_2020" role="doc-biblioref">2020</a>)</span>.</p>
<p>I’ll include it here as a reference.</p>
<details>
<summary>Agda Code</summary>
<div id="cb15"><pre><code><span id="cb15-1"><span>open</span> <span>import</span> Prelude</span>
<span id="cb15-2"><span>open</span> <span>import</span> Data<span>.</span>Nat <span>using</span> <span>(_</span>+<span>_)</span></span>
<span id="cb15-3"><span>open</span> <span>import</span> Data<span>.</span>Vec<span>.</span>Iterated <span>using</span> <span>(</span>Vec<span>;</span> <span>_</span>∷<span>_;</span> []<span>;</span> foldlN<span>;</span> head<span>)</span></span>
<span id="cb15-4"></span>
<span id="cb15-5"><span>private</span></span>
<span id="cb15-6">  <span>variable</span></span>
<span id="cb15-7">    n <span>:</span> ℕ</span>
<span id="cb15-8"></span>
<span id="cb15-9"><span>--------------------------------------------------------------------------------</span></span>
<span id="cb15-10"><span>-- Binary trees: definition and associated functions</span></span>
<span id="cb15-11"><span>--------------------------------------------------------------------------------</span></span>
<span id="cb15-12"></span>
<span id="cb15-13"><span>data</span> Tree <span>(</span>A <span>:</span> Type a<span>)</span> <span>:</span> Type a <span>where</span></span>
<span id="cb15-14">  [<span>_</span>] <span>:</span> A <span>→</span> Tree A</span>
<span id="cb15-15">  <span>_</span>*<span>_</span> <span>:</span> Tree A <span>→</span> Tree A <span>→</span> Tree A</span>
<span id="cb15-16"></span>
<span id="cb15-17"><span>--------------------------------------------------------------------------------</span></span>
<span id="cb15-18"><span>-- Programs: definition and associated functions</span></span>
<span id="cb15-19"><span>--------------------------------------------------------------------------------</span></span>
<span id="cb15-20"></span>
<span id="cb15-21"><span>data</span> Prog <span>(</span>A <span>:</span> Type a<span>)</span> <span>:</span> ℕ <span>→</span> Type a <span>where</span></span>
<span id="cb15-22">  halt <span>:</span> Prog A <span>1</span></span>
<span id="cb15-23">  push <span>:</span> A <span>→</span> Prog A <span>(</span><span>1</span> + n<span>)</span> <span>→</span> Prog A n</span>
<span id="cb15-24">  pull <span>:</span> Prog A <span>(</span><span>1</span> + n<span>)</span> <span>→</span> Prog A <span>(</span><span>2</span> + n<span>)</span></span>
<span id="cb15-25"></span>
<span id="cb15-26"><span>--------------------------------------------------------------------------------</span></span>
<span id="cb15-27"><span>-- Conversion from a Prog to a Tree</span></span>
<span id="cb15-28"><span>--------------------------------------------------------------------------------</span></span>
<span id="cb15-29"></span>
<span id="cb15-30">prog→tree⊙ <span>:</span> Prog A n <span>→</span> Vec <span>(</span>Tree A<span>)</span> n <span>→</span> Tree A</span>
<span id="cb15-31">prog→tree⊙ halt        <span>(</span>v ∷ []<span>)</span>       <span>=</span> v</span>
<span id="cb15-32">prog→tree⊙ <span>(</span>push v is<span>)</span> st             <span>=</span> prog→tree⊙ is <span>(</span>[ v ] ∷ st<span>)</span></span>
<span id="cb15-33">prog→tree⊙ <span>(</span>pull   is<span>)</span> <span>(</span>t₁ ∷ t₂ ∷ st<span>)</span> <span>=</span> prog→tree⊙ is <span>(</span>t₂ * t₁ ∷ st<span>)</span></span>
<span id="cb15-34"></span>
<span id="cb15-35">prog→tree <span>:</span> Prog A zero <span>→</span> Tree A</span>
<span id="cb15-36">prog→tree ds <span>=</span> prog→tree⊙ ds []</span>
<span id="cb15-37"></span>
<span id="cb15-38"><span>--------------------------------------------------------------------------------</span></span>
<span id="cb15-39"><span>-- Conversion from a Tree to a Prog</span></span>
<span id="cb15-40"><span>--------------------------------------------------------------------------------</span></span>
<span id="cb15-41"></span>
<span id="cb15-42">tree→prog⊙ <span>:</span> Tree A <span>→</span> Prog A <span>(</span>suc n<span>)</span> <span>→</span> Prog A n</span>
<span id="cb15-43">tree→prog⊙ [ x ]     <span>=</span> push x</span>
<span id="cb15-44">tree→prog⊙ <span>(</span>xs * ys<span>)</span> <span>=</span> tree→prog⊙ xs ∘ tree→prog⊙ ys ∘ pull</span>
<span id="cb15-45"></span>
<span id="cb15-46">tree→prog <span>:</span> Tree A <span>→</span> Prog A zero</span>
<span id="cb15-47">tree→prog tr <span>=</span> tree→prog⊙ tr halt</span>
<span id="cb15-48"></span>
<span id="cb15-49"><span>--------------------------------------------------------------------------------</span></span>
<span id="cb15-50"><span>-- Proof of isomorphism</span></span>
<span id="cb15-51"><span>--------------------------------------------------------------------------------</span></span>
<span id="cb15-52"></span>
<span id="cb15-53">tree→prog→tree⊙ <span>:</span> <span>(</span>e <span>:</span> Tree A<span>)</span> <span>(</span>is <span>:</span>…</span></code></pre></div></details></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://doisinkidney.com/posts/2020-12-14-enumerating-trees.html">https://doisinkidney.com/posts/2020-12-14-enumerating-trees.html</a></em></p>]]>
            </description>
            <link>https://doisinkidney.com/posts/2020-12-14-enumerating-trees.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25430607</guid>
            <pubDate>Tue, 15 Dec 2020 14:30:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Create a Technical Blogging Style Guide]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25430402">thread link</a>) | @karlhughes
<br/>
December 15, 2020 | https://draft.dev/learn/posts/styleguide | <a href="https://web.archive.org/web/*/https://draft.dev/learn/posts/styleguide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
<article>
  <div>
    
    <p><img src="https://draft.dev/learn/assets/posts/styleguide.jpg" alt="Lead image for How to Create a Technical Blogging Style Guide">
    </p>
    
    

    <p>
      
      Published in
        
          <a href="https://draft.dev/learn/posts/">posts</a>
        
      by
      
       Karl Hughes&nbsp;&nbsp;&nbsp;—&nbsp;
      8 minute read
    </p>

    
      <p>As your blog grows and you <a href="https://draft.dev/learn/posts/finding-motivating-writers">get more writers to contribute</a>, you need to build documents and processes to help you maintain high quality and consistent style. To serve this goal, you should create a style guide to help writers and editors stay on the same page.</p>

<p>Generally, <strong>a style guide includes expectations for your contributors</strong>. Depending on your priorities, you may include more or less information than we do at <a href="https://draft.dev/">Draft.dev</a>, but our style guide should give you an excellent place to start. We send this style guide to all new contributors to ensure they are familiar with our expectations, and we refer to this guide throughout the editing process.</p>

<p>Of course, ours is not the only example of a technical writing style guide. If you’re looking to compare your options, check out <a href="https://developers.google.com/style">Google’s developer documentation style guide</a>, <a href="https://www.digitalocean.com/community/tutorials/digitalocean-s-technical-writing-guidelines">DigitalOcean’s technical writing guidelines</a>, and some of the <a href="https://medium.com/technical-writing-is-easy/style-guides-for-technical-writers-72b011f84c4b">other guides here</a>. If you’re creating a style guide, I’d recommend reading over several and deciding what you want to include in yours.</p>

<h2 id="the-draftdev-technical-blogging-style-guide">The Draft.dev Technical Blogging Style Guide</h2>

<p>At <a href="https://draft.dev/">Draft.dev</a>, we specialize in creating technical blog content for companies that want to reach software engineers. While most of our writers are software engineers first and authors second, we still expect them to follow consistent standards for each of our clients.</p>

<p>Below is our style guide, which is broken up into four sections:</p>

<ol>
  <li><a href="#voice">Voice</a></li>
  <li><a href="#content">Content</a></li>
  <li><a href="#conventions">Conventions</a></li>
  <li><a href="#communication">Communication</a></li>
</ol>

<h3 id="voice">Voice</h3>

<h4 id="write-in-second-person">Write in Second Person</h4>
<p>Speak to your readers directly using “you” and “your.” Avoid “we” and “our.”</p>

<p>Good:</p>

<blockquote>
  <p>You can use a web browser (like Chrome, Safari, or Edge) to access web sites on the internet.</p>
</blockquote>

<p>Bad:</p>

<blockquote>
  <p>We can use our web browsers (like Chrome, Safari, or Edge) to access web sites on the internet.</p>
</blockquote>

<h4 id="use-conversational-business-appropriate-language">Use Conversational, Business-Appropriate Language</h4>
<p>Read your article out loud and ask yourself, “Would I talk like this at work?” Use your real-world experience, but avoid jargon when possible.</p>

<p>Good:</p>

<blockquote>
  <p>Experts agree that the internet was not the product of any individual mind, but a series of advances in networking and computer science.</p>
</blockquote>

<p>Bad:</p>

<blockquote>
  <p>Many scholars would agree that, had it not been for active networks, the simulation of Lamport clocks might never have occurred. The notion that end-users synchronize with the investigation of Markov models is rarely outdated. A theoretical grand challenge in theory is the important unification of virtual machines and real-time theory. To what extent can web browsers be constructed to achieve this purpose?</p>
</blockquote>

<h4 id="dont-repeat-yourself">Don’t Repeat Yourself</h4>
<p>Eliminate wordiness. You shouldn’t repeat yourself when programming, and you shouldn’t repeat yourself when writing.</p>

<p>Good:</p>

<blockquote>
  <p>A lively debate rages among software developers. The contentious issue is: tabs or spaces?</p>
</blockquote>

<p>Bad:</p>

<blockquote>
  <p>There is currently a lively, ongoing controversy among many computer scientists and other professional in the field of software development: theories are being spun and arguments are being conducted among them about whether the use of tabs to designate indentation in a document is superior to the use of spaces for the same purpose.</p>
</blockquote>

<h3 id="content">Content</h3>

<h4 id="the-introduction">The Introduction</h4>
<p>Every article should have a 1-3 paragraph introduction. This introduction should accomplish two things:</p>

<ol>
  <li>Briefly tell readers what the article is about.</li>
  <li>Hook your readers. Give them a reason to continue reading.</li>
</ol>

<p>Good:</p>

<blockquote>
  <p>I remember the first time I built user preferences into an app. At first, users just needed to be able to opt in or out of our weekly emails. “No big deal,” I thought, “I’ll just add a new field on the Users table.” For a while, that was fine. A few weeks later, my boss asked me if we could let users opt into push notifications. Fine, that’s just one more column on the database. Can’t hurt, right?</p>

  <p>You probably see where this is going.</p>

  <p>Within months, my user table had 40 columns, and while Postgres can handle it, it gets pretty tricky for new devs to keep up with all of them.</p>

  <p>Fortunately, Postgres provides rich support for JSON fields, which can be very handy in situations like mine. Both JSON data types (<code>json</code> and <code>jsonb</code>) allow you to store entire objects or lists directly in your database. This means that you can store any number of user preferences in one column.</p>

  <p>In this post, I’ll show you how to use Postgres’ JSON fields in a Django web application. You’ll learn about the differences between <code>json</code> and <code>jsonb</code>, how to query JSON data and some of the drawbacks of storing your data in JSON.</p>
</blockquote>

<p>Bad (no “hook”):</p>

<blockquote>
  <p>Postgres provides rich support for JSON fields, which can be very handy. Both JSON data types (<code>json</code> and <code>jsonb</code>) allow you to store entire objects or lists directly in your database. This means that you can store any number of user preferences in one column.</p>

  <p>In this post, I’ll show you how to use Postgres’ JSON fields in a Django web application. You’ll learn about the differences between <code>json</code> and <code>jsonb</code>, how to query JSON data and some of the drawbacks of storing your data in JSON.</p>
</blockquote>

<h4 id="support-claims-with-evidence">Support Claims With Evidence</h4>
<p>For every claim you make, ask yourself, “How can I prove this?” You can do this by:</p>

<ul>
  <li>Including a link to a reputable article</li>
  <li>Including a quote from another source</li>
  <li>Citing an academic study</li>
  <li>Linking to the official documentation</li>
  <li>Interviewing knowledgeable professionals</li>
</ul>

<p>Good:</p>

<blockquote>
  <p>While [Postgres can handle hundreds of columns](https://nerderati.com/2017/01/03/postgresql-tables-can-have-at-most-1600-columns/), it might not be a good idea to take advantage of this feature.</p>
</blockquote>

<p>Bad:</p>

<blockquote>
  <p>While I’m guessing Postgres can handle a lot of columns, it might not be a good idea to use more than a hundred if you can help it.</p>
</blockquote>

<h4 id="the-conclusion">The Conclusion</h4>
<p>Every article should include a 1-2 paragraph conclusion. This should restate the thesis of the article and remind readers what they learned. It may also include other resources readers can reference to learn more.</p>

<p>Good:</p>

<blockquote>
  <p>While JSON data types come with some drawbacks, they are useful when you need more flexibility in your data structure. Thanks to Django’s native support for `jsonb`, you can get started using JSON data in your web applications without [learning all the native Postgres query operators](https://www.postgresql.org/docs/current/functions-json.html).</p>

  <p>Next time you need more flexibility in your data model and want to benefit from the strengths of Postgres give `jsonb` fields a try.</p>
</blockquote>

<h3 id="conventions">Conventions</h3>

<h4 id="write-in-markdown">Write in Markdown</h4>
<p>All articles should be written in <a href="https://guides.github.com/features/mastering-markdown/">Markdown</a> and submitted in the <a href="https://docs.google.com/">Google Doc</a> sent to you when you accept the assignment.</p>

<p>Good:</p>

<blockquote>
  <p>Markdown is a formatting language often *used by static site generators* and *blogs*. If you aren’t familiar with its syntax, you can [click here to learn more](https://guides.github.com/features/mastering-markdown/).</p>
</blockquote>

<h4 id="upload-images-to-imgur">Upload Images to <a href="https://imgur.com/">Imgur</a></h4>
<p>If you have screenshots or diagrams in your article, upload them to <a href="https://imgur.com/">Imgur’s free image hosting service</a> and embed them using Markdown. Include descriptive text inside the brackets (<code>[...]</code>) so that screen readers can describe the image.</p>

<p>Good:</p>

<blockquote>
  <p>![A diagram showing different computer hardware](https://i.imgur.com/hBE7ZF8.jpg)</p>
</blockquote>

<p>Bad:</p>

<blockquote>
  <p>![](https://www.my-private-image-server.net/image-1.png)</p>
</blockquote>


<p>Headers make your content more scannable. Use <code>##</code>, <code>###</code>, and <code>####</code> header tags to denote different sections. Headings should be written in <a href="https://apastyle.apa.org/style-grammar-guidelines/capitalization/title-case">title case</a>.</p>

<p>Good:</p>

<blockquote>
  <p>## How to Use JSON Fields in Your Python Application</p>

  <p>…</p>

  <p>### The Two JSON Formats Supported by Postgres</p>

  <p>…</p>
</blockquote>

<p>Bad (not title case):</p>

<blockquote>
  <p>## How to use JSON fields in your Python application</p>

  <p>…
### The two JSON formats supported by Postgres</p>

  <p>…</p>
</blockquote>

<h4 id="denote-code-with-backticks">Denote Code with Backticks</h4>
<p>Use code blocks when the code is one or more lines long or deserves special emphasis.</p>

<p>Good:</p>

<blockquote>
  <p>```</p>

  <p>function snafu() {</p>

  <p>return null;</p>

  <p>}</p>

  <p>```</p>
</blockquote>

<p>Bad:</p>

<blockquote>
  <p>`function snafu() {</p>

  <p>return null;</p>

  <p>}`</p>
</blockquote>

<p>Use inline code when referring to a variable name or short command in context.</p>

<p>Good:</p>

<blockquote>
  <p>Call the `snafu()` method to exit and return to your command line.</p>
</blockquote>

<p>Bad:</p>

<blockquote>
  <p>Call the “snafu()” method to exit and return to your command line.</p>
</blockquote>

<h4 id="use-double-quotes-for-quotations">Use Double Quotes for Quotations</h4>
<p>Use blockquotes when the quote is two or more lines long.</p>

<p>Good:</p>

<blockquote>
  <p>Some text leading up to the quote.</p>

  <p>&gt; “The field/element/path extraction operators return NULL, rather than failing, if the JSON input does not have the right structure to match the request; for example if no such key or array element exists.”</p>

  <p>Some text after the quote.</p>
</blockquote>

<p>Bad:</p>

<blockquote>
  <p>Some text leading up to the quote. “The field/element/path extraction operators return NULL, rather than failing, if the JSON input does not have the right structure to match the request; for example if no such key or array element exists.” Some text after the quote.</p>
</blockquote>

<p>Use inline quotes when the quote is relatively short or when you’re referencing a single word or phrase.</p>

<p>Good:</p>

<blockquote>
  <p>“There’s nothing to see here,” said Davies.</p>
</blockquote>

<p>Bad:</p>

<blockquote>
  <p>&gt; “There’s nothing to see here.” - Davies</p>
</blockquote>

<h4 id="use-emphasis-sparingly">Use Emphasis Sparingly</h4>
<p>Use <em>italics</em> to emphasize text or use <strong>bold</strong> to suggest strong emphasis.</p>

<p>Good:</p>

<blockquote>
  <p>There is *nothing* as important as using **spaces** to indent your code.</p>
</blockquote>

<h3 id="communication">Communication</h3>

<h4 id="communicate-delays-and-roadblocks-to-your-editor-proactively">Communicate Delays and Roadblocks to Your Editor Proactively</h4>
<p>You will not be penalized for late work if you’ve been in communication with us about the assignment. We can offer technical help and extensions, but you must ask two or more days before the due date.</p>

<p>Good:</p>

<blockquote>
  <p>Hey Karl,</p>

  <p>I know the Postgres article is due next week, but I’m running into trouble. Would you be willing to hop on a quick call and explain the JSON fields in Postgres? Or do you have any resources that might help me out?</p>
</blockquote>

<p>Bad:</p>

<blockquote>
  <p>Hey Karl,</p>

  <p>I know my Postgres article was due today, but I’m not able to figure out the JSON fields in Postgres. Could I have an extension until next week to struggle with it more?</p>
</blockquote>

<p>Authors …</p></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://draft.dev/learn/posts/styleguide">https://draft.dev/learn/posts/styleguide</a></em></p>]]>
            </description>
            <link>https://draft.dev/learn/posts/styleguide</link>
            <guid isPermaLink="false">hacker-news-small-sites-25430402</guid>
            <pubDate>Tue, 15 Dec 2020 14:08:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[‘Fast Movers’ and Transmedium Vehicles]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25430225">thread link</a>) | @graderjs
<br/>
December 15, 2020 | https://thedebrief.org/fast-movers-and-transmedium-vehicles-the-pentagons-uap-task-force?space | <a href="https://web.archive.org/web/*/https://thedebrief.org/fast-movers-and-transmedium-vehicles-the-pentagons-uap-task-force?space">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																					<div>
																										<p><span data-preserver-spaces="true">In an exclusive feature for&nbsp;</span><em><span data-preserver-spaces="true">The Debrief</span></em><span data-preserver-spaces="true">, U.S. military and intelligence officials, as well as Pentagon emails, offer an unprecedented glimpse behind the scenes of what’s currently going on with The Pentagon’s investigation into UFOs, or as they term them, “Unidentified Aerial Phenomena” (UAP).&nbsp;&nbsp;</span></p>
<p><span data-preserver-spaces="true">For the last two years, the Department of Defense’s newly revamped “Unidentified Aerial Phenomena Task Force” (or UAPTF) has been busy briefing lawmakers, Intelligence Community stakeholders, and the highest levels of the U.S. military on encounters with what they say are mysterious airborne objects that defy conventional explanations.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Along with classified briefings, multiple senior U.S. officials with direct knowledge of the matter say two classified intelligence reports on UAP have been widely distributed to the U.S. Intelligence Community. Numerous sources from various government agencies told&nbsp;</span><em><span data-preserver-spaces="true">The Debrief</span></em><span data-preserver-spaces="true"> that these reports include clear photographic evidence of UAP. The reports also explicitly state that the Task Force is considering the possibility that these unidentified objects could, as stated by one source from the U.S. Intelligence Community said, be operated by “intelligences of unknown origin.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">Significantly, a retired U.S. Air Force brigadier general and head of RAND corporation’s Space Enterprise Initiative has—for the first time—gone on record to discuss some of the most likely explanations for UAP. His responses were surprising.</span></p>
<figure id="attachment_1293" aria-describedby="caption-attachment-1293"><img src="https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1.jpg" alt="US Navy" width="2560" height="1704" srcset="https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1.jpg 2560w,https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1-300x200.jpg 300w,https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1-1024x682.jpg 1024w,https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1-768x511.jpg 768w,https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1-1536x1022.jpg 1536w,https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1-2048x1363.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px" data-srcset="https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1.jpg 2560w, https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1-300x200.jpg 300w, https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1-1024x682.jpg 1024w, https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1-768x511.jpg 768w, https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1-1536x1022.jpg 1536w, https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1-2048x1363.jpg 2048w" data-src="https://thedebrief.org/wp-content/uploads/2020/12/6101080-scaled-1.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-1293">U.S. Navy photo by Mass Communication Specialist Seaman Hillary Becke</figcaption></figure>
<h2><strong><span data-preserver-spaces="true">Briefings At The Highest Levels&nbsp;</span></strong></h2>
<p><span data-preserver-spaces="true">In June, the Senate Select Committee on Intelligence’s </span><a href="https://www.govinfo.gov/content/pkg/CRPT-116srpt233/pdf/CRPT-116srpt233.pdf" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">FY2021 Intelligence Authorization Act</span></a><span data-preserver-spaces="true"> contained an intriguing section titled report on “Advanced Aerial Threats.” In the inclusion, the committee gave an eye-opening official hint (in recent history) the government takes UFOs seriously by offering its support for the “efforts of the Unidentified Aerial Phenomenon Task Force at the Office of Naval Intelligence.” The Intelligence Committee additionally requested an unclassified report detailing the analysis of “UAP” or “Anomalous Aerial Vehicles.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">Though already acknowledged by the Intelligence Committee, in mid-August, the Pentagon&nbsp;</span><a href="https://www.thedebrief.org/the-dod-has-officially-announced-it-has-a-uap-task-force-heres-what-that-means/" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">formally acknowledged</span></a><span data-preserver-spaces="true">&nbsp;they had established a task force looking into UAP. In a press announcement, the Secretary of Defense’s Office&nbsp;</span><a href="https://www.defense.gov/Newsroom/Releases/Release/Article/2314065/establishment-of-unidentified-aerial-phenomena-task-force/" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">stated</span></a><span data-preserver-spaces="true">, “the UAPTF’s mission will be to detect, analyze and catalog UAPs that could potentially pose a threat to U.S. national security.” According to the release, authority for the Task Force was approved by the DoD’s chief operating officer, Deputy Secretary of Defense David L. Norquist.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The summer news of the establishment of the UAPTF seemingly suggests—for the first time since the shuttering of Project Blue Book (the Air Force’s official investigations into UFOs) in 1969—that the Pentagon is now taking the subject of UFOs seriously.&nbsp;</span></p>
<p><span data-preserver-spaces="true">However, an internal email obtained by&nbsp;</span><em><span data-preserver-spaces="true">The Debrief&nbsp;</span></em><span data-preserver-spaces="true">shows that almost one year before the DoD’s announcement, the highest levels of the U.S. military were already being briefed on UAP.&nbsp;</span></p>
<figure id="attachment_1299" aria-describedby="caption-attachment-1299"><img src="https://thedebrief.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.36.02-AM.png" alt="UAP Task Force Briefs the Joint Chiefs of Staff " width="1424" height="616" srcset="https://thedebrief.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.36.02-AM.png 1424w,https://thedebrief.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.36.02-AM-300x130.png 300w,https://thedebrief.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.36.02-AM-1024x443.png 1024w,https://thedebrief.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.36.02-AM-768x332.png 768w" sizes="(max-width: 1424px) 100vw, 1424px" data-srcset="https://thedebrief.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.36.02-AM.png 1424w, https://thedebrief.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.36.02-AM-300x130.png 300w, https://thedebrief.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.36.02-AM-1024x443.png 1024w, https://thedebrief.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.36.02-AM-768x332.png 768w" data-src="https://thedebrief.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-01-at-11.36.02-AM.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-1299">Copy of the Email Obtained by The Debrief via FOIA.</figcaption></figure>
<p><span data-preserver-spaces="true">The email, obtained via Freedom of Information Act request, shows an October 16th, 2019 exchange between then Vice Chief of Naval Operations, Admiral Robert Burke, and current Vice Chief of Staff for the Air Force General Stephen “Steve” Wilson.&nbsp;</span></p>
<p><span data-preserver-spaces="true">In the email, Adm. Burke tells Gen. Wilson, “Recommend you take the brief I just received from our Director of Naval Intelligence VADM Matt Kohler, on Unidentified Aerial Phenomena (UAP).” Adm. Burke concludes the email, “SECNAV [Secretary of the Navy] will get the same brief tomorrow at 1000.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">The “SECNAV” referenced in Adm. Burke’s email was then-Secretary of the Navy, Richard V. Spencer. A little over a month after this UAP briefing, Spencer was fired by then-Secretary of Defense Mark Esper over public disagreements stemming from a&nbsp;</span><a href="https://www.theguardian.com/us-news/2019/nov/28/navy-secretary-richard-spencer-donald-trump-navy-seal" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">series of controversies&nbsp;</span></a><span data-preserver-spaces="true">involving the court-martial of Navy SEAL Eddie Gallagher.</span></p>
<p><span data-preserver-spaces="true">Speaking on background, one U.S. Defense official lamented that a lack of continuity with DoD leadership might have hindered some of the UAPTF’s work. Within the past 24 months, there have been four different Secretaries of the Navy and five additional Secretaries of Defense. Vice Admiral Matt Kohler, noted for having provided the briefings, retired after 36 years with the Navy in June of this year.&nbsp;</span></p>
<figure id="attachment_1322" aria-describedby="caption-attachment-1322"><img src="https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1.jpg" alt="Vice Adm. Robert Burke" width="2560" height="1707" srcset="https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1.jpg 2560w,https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1-300x200.jpg 300w,https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1-1024x683.jpg 1024w,https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1-768x512.jpg 768w,https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1-1536x1024.jpg 1536w,https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1-2048x1366.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px" data-srcset="https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1.jpg 2560w, https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1-300x200.jpg 300w, https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1-1024x683.jpg 1024w, https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1-768x512.jpg 768w, https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1-1536x1024.jpg 1536w, https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1-2048x1366.jpg 2048w" data-src="https://thedebrief.org/wp-content/uploads/2020/12/3511656-scaled-1.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-1322">Vice Adm. Robert Burke – U.S. Navy photo by Mass Communication Specialist 3rd Class Charles D. Gaddis IV</figcaption></figure>
<p><span data-preserver-spaces="true">Reaching out to several active government officials and individuals who retain their government-issued security clearances,&nbsp;</span><em><span data-preserver-spaces="true">The Debrief</span></em><span data-preserver-spaces="true">&nbsp;learned that last fall was a busy time for the UAPTF.&nbsp;</span><span data-preserver-spaces="true">On October 21st, 2019, a briefing on UAP was conducted at the Pentagon for several Senate Armed Services Committee staffers.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Attendees at the meeting told&nbsp;</span><em><span data-preserver-spaces="true">The Debrief</span></em><span data-preserver-spaces="true">&nbsp;that they were provided information on two previous DoD-backed UFO programs: The Advanced Aerial Weapons Systems Applications Program (AAWSAP) and the Advanced Aerospace Threat Identification Program (AATIP). They were also briefed on “highly sensitive categories of UFO investigations.” Only two days later on October 23rd, staffers with the Senate Select Intelligence Committee were provided the same information in a meeting on Capitol Hill.&nbsp;</span></p>
<p><span data-preserver-spaces="true">A former private contractor for AAWSAP and AATIP, Dr. Hal Puthoff, confirmed for&nbsp;</span><em><span data-preserver-spaces="true">The Debrief&nbsp;</span></em><span data-preserver-spaces="true">he was one of a handful of persons who conducted the October briefings. “I have been invited to brief congressional staffers on the Senate Armed Services Committee on UAP matters in the last couple of years,” Puthoff said in an email, “and have done so on more than one occasion.” Dr. Puthoff described the staffers during these meetings as being “engaged,” and provided “positive responses, [and] more details always being requested.”&nbsp;</span></p>
<figure id="attachment_1325" aria-describedby="caption-attachment-1325"><img src="https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1.jpg" alt="The Pentagon Press Briefing Room" width="2560" height="1709" srcset="https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1.jpg 2560w,https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1-300x200.jpg 300w,https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1-1024x684.jpg 1024w,https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1-768x513.jpg 768w,https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1-1536x1025.jpg 1536w,https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1-2048x1367.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px" data-srcset="https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1.jpg 2560w, https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1-300x200.jpg 300w, https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1-1024x684.jpg 1024w, https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1-768x513.jpg 768w, https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1-1536x1025.jpg 1536w, https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1-2048x1367.jpg 2048w" data-src="https://thedebrief.org/wp-content/uploads/2020/12/6153296-scaled-1.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-1325">The Pentagon Press Briefing Room seal (Credit: DoD/photo by Lisa Ferdinando)</figcaption></figure>
<p><em><span data-preserver-spaces="true">The Debrief&nbsp;</span></em><span data-preserver-spaces="true">reached out to the Assistant Secretary of Defense for Public Affairs Office and DoD Executive Services Office and formally requested an interview with someone authorized to speak on the UAP briefings with the Joint Chiefs of Staff. In an email, Senior Strategist and Pentagon spokesperson Susan Gough responded, “To maintain operations security, which includes not disseminating information publicly that may be useful to our adversaries, DOD does not discuss publicly the details of either the observations or the examination of reported incursions into our training ranges or designated airspace, including those incursions initially designated as UAP – and that includes not discussing the UAPTF publicly, also.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">Official public affairs channels indicate the Pentagon is not interested in sharing any more information on the UAP topic. However, several current and former officials with the DoD and individuals working for multiple U.S. intelligence agencies told&nbsp;</span><em><span data-preserver-spaces="true">The Debrief&nbsp;</span></em><span data-preserver-spaces="true">that there was much more going on behind closed doors.</span></p>
<p><iframe id="_ytid_42263" width="1170" height="878" data-origwidth="1170" data-origheight="878" src="https://www.youtube.com/embed/ua-a838Vw00?enablejsapi=1&amp;autoplay=0&amp;cc_load_policy=0&amp;iv_load_policy=1&amp;loop=0&amp;modestbranding=1&amp;fs=1&amp;playsinline=0&amp;controls=1&amp;color=red&amp;cc_lang_pref=&amp;rel=1&amp;autohide=2&amp;theme=dark&amp;" title="YouTube player" allow="autoplay; encrypted-media" allowfullscreen="" data-no-lazy="1" data-skipgform_ajax_framebjll=""></iframe></p>

<h2><strong><span data-preserver-spaces="true">UAP Intelligence Position Reports</span></strong></h2>
<p><span data-preserver-spaces="true">Multiple sources confirmed for&nbsp;</span><em><span data-preserver-spaces="true">The Debrief</span></em><span data-preserver-spaces="true">&nbsp;that the UAPTF had issued two classified intelligence position reports, which one individual described as “shocking.” Details provided on these reports suggest both a greater degree of Pentagon involvement, and that the UAPTF’s&nbsp;hunt for unidentified objects isn’t confined only to aerial phenomena.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Two officials with the DoD and one from the U.S. Intelligence community were willing to provide details on the contents of the classified report. An additional three other U.S. Intelligence Officials and a federal law enforcement officer confirmed the report’s existence but were only willing to provide comments on their distribution. Given the report’s classification and their discussion of a “sensitive intelligence matter,” the officials we spoke with did so only under strict conditions of anonymity. While&nbsp;</span><em><span data-preserver-spaces="true">The Debrief&nbsp;</span></em><span data-preserver-spaces="true">has agreed not to provide information on sources, identities, and employers, though everyone we spoke with works within the U.S. Intelligence Community and under the authority of the U.S. Director of National Intelligence.&nbsp;</span></p>
<figure id="attachment_1329" aria-describedby="caption-attachment-1329"><img src="https://thedebrief.org/wp-content/uploads/2020/12/National_Reconnaissance_Office_2013.jpg" alt="The National Reconnaissance Office" width="1280" height="853" srcset="https://thedebrief.org/wp-content/uploads/2020/12/National_Reconnaissance_Office_2013.jpg 1280w,https://thedebrief.org/wp-content/uploads/2020/12/National_Reconnaissance_Office_2013-300x200.jpg 300w,https://thedebrief.org/wp-content/uploads/2020/12/National_Reconnaissance_Office_2013-1024x682.jpg 1024w,https://thedebrief.org/wp-content/uploads/2020/12/National_Reconnaissance_Office_2013-768x512.jpg 768w" sizes="(max-width: 1280px) 100vw, 1280px" data-srcset="https://thedebrief.org/wp-content/uploads/2020/12/National_Reconnaissance_Office_2013.jpg 1280w, https://thedebrief.org/wp-content/uploads/2020/12/National_Reconnaissance_Office_2013-300x200.jpg 300w, https://thedebrief.org/wp-content/uploads/2020/12/National_Reconnaissance_Office_2013-1024x682.jpg 1024w, https://thedebrief.org/wp-content/uploads/2020/12/National_Reconnaissance_Office_2013-768x512.jpg 768w" data-src="https://thedebrief.org/wp-content/uploads/2020/12/National_Reconnaissance_Office_2013.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-1329">Aerial view of the headquarters of the National Reconnaissance Office (NRO) in Chantilly, Virginia, by Trevor Paglen.</figcaption></figure>
<p><span data-preserver-spaces="true">One of the intelligence reports, released in 2018, is said to have provided a general overview of the UAP topic and included details of previous military encounters. According to sources who had read it, the report also contained an unreleased photograph of an “aerial phenomena” categorized as “unidentified.”&nbsp;</span></p>
<p><em><span data-preserver-spaces="true">The Debrief&nbsp;</span></em><span data-preserver-spaces="true">was told the accompanying photo was captured from within the cockpit of an F/A-18 fighter jet with a pilot’s personal cell phone. According to three U.S. officials who had seen it, the photo showed an unidentified silver “cube-shaped” object. The report is said to have indicated the object was “hovering” or completely motionless when military pilots encountered it. All three officials agreed that based on the photo, the object appeared to be at an altitude of roughly 30,000 to 35,000 feet and approximately 1,000 feet from the fighter jet.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Defense and intelligence officials willing to discuss the report and those who only wished to confirm its dissemination all expressed shock that it had been so widely distributed amongst the Intelligence community.&nbsp;</span></p>
<p><span data-preserver-spaces="true">“In decades with the [Intelligence Community] I’ve never seen anything like this,” said one intelligence official.&nbsp;</span></p>

<p><span data-preserver-spaces="true">One defense official described the report’s distribution as having gone through “normal, non-public, information sharing channels.” Other officials who’d seen and read the report either declined to elaborate or indicated the report was distributed on various secure systems. One defense official indicated it was distributed on the DoD’s Secret Internet Protocol Router Network (SIPRNet). Two other intelligence officials said they received the information via “NSANet” (the NSA’s official intranet). An additional source said …</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thedebrief.org/fast-movers-and-transmedium-vehicles-the-pentagons-uap-task-force?space">https://thedebrief.org/fast-movers-and-transmedium-vehicles-the-pentagons-uap-task-force?space</a></em></p>]]>
            </description>
            <link>https://thedebrief.org/fast-movers-and-transmedium-vehicles-the-pentagons-uap-task-force?space</link>
            <guid isPermaLink="false">hacker-news-small-sites-25430225</guid>
            <pubDate>Tue, 15 Dec 2020 13:48:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking Istio and Linkerd]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25429765">thread link</a>) | @robertwinter
<br/>
December 15, 2020 | https://elastisys.com/benchmarking-istio-linkerd-erik-dahlberg-master-thesis/ | <a href="https://web.archive.org/web/*/https://elastisys.com/benchmarking-istio-linkerd-erik-dahlberg-master-thesis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><div data-elementor-type="wp-post" data-elementor-id="9087" data-elementor-settings="[]"><div><div><section data-id="2053ba2" data-element_type="section"><div><div><div data-id="74ac41e" data-element_type="column"><div><div><div data-id="0d7bf6b" data-element_type="widget" data-widget_type="text-editor.default"><div><p><a href="https://www.linkedin.com/in/erik-jvd/" rel="noopener" target="_blank">Erik Dahlberg</a> wrote his Master Thesis with us at Elastisys, and successfully defended it in June 2020. In this blog post, we share the major outcomes of his work. With close ties to academia, Elastisys is a great place to do your Master Thesis work. Please <a href="https://elastisys.com/contact-form/">contact us</a> if you want to do like Erik did and dive deep into a cloud-native technology!</p></div></div></div></div></div></div></div></section><section data-id="34fc819" data-element_type="section"><div><div><div data-id="6163e3b" data-element_type="column"><div><div><div data-id="3a83ded" data-element_type="widget" data-widget_type="text-editor.default"><div><div><ul><li>For most intents and purposes, Istio and Linkerd offer equivalent feature sets.&nbsp;</li><li>Istio has a stronger multi-cluster story than Linkerd does.</li><li>Istio has a significantly larger community and thought leadership position.</li><li>Our benchmark results show that Istio consumed more memory, but added less latency.&nbsp;</li><li>Linkerd also seemed to reach some internal limitation sooner than Istio, however, the root cause of this was not analyzed.</li></ul><p>The remainder of this blog post contains the text written by Erik Dahlberg, edited slightly for the web.</p></div></div></div></div></div></div></div></div></section><section data-id="31bc1f9" data-element_type="section"><div><div><div data-id="c6de0fb" data-element_type="column"><div><div><div data-id="cf047e9" data-element_type="widget" data-widget_type="text-editor.default"><div><p>Service mesh is a relatively new subject that has grown in the microservice community over the last few years. To date, there exist multiple service mesh implementations with different architectural approaches ranging from smaller open-source projects to major endeavours being backed by big companies such as Google. This introduces questions about how mature the current service mesh projects are and what performance impact they have.&nbsp;<br></p></div></div><div data-id="caba7b6" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>The goals of this thesis have been to analyze services meshes based on the following criteria:</p><ul><li><b>Features</b>: a<span>nalyze feature sets</span></li><li><span><b>Maturity</b>: a</span><span>nalyze the overall project maturity</span></li><li><span><b>Ease of use</b>: d</span><span>escribe the process and ease of deploying the service mesh into already existing microservice application</span></li><li><span><b>Performance</b>: e</span><span>valuate the overhead introduced by integrating a service mesh into a microservice application</span></li></ul></div></div></div></div></div></div></div></div></section><section data-id="91b6ebd" data-element_type="section"><div><div><div data-id="471ff03" data-element_type="column"><div><div><div data-id="a977e8f" data-element_type="widget" data-widget_type="heading.default"><p><h2>Background: what is a service mesh?</h2></p></div><div data-id="08b931c" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>Trying to describe service mesh in one sentence – “A service mesh is a mesh of useful/necessary features bundled together in a way so they can be applied to your application without the need of doing any code modification (features that you probably needed anyway)”. One example of this is resilience features, “probably” needed for every service you are to create. Instead of rewriting resilience libraries for every service in your application, yes services (they can be in different languages). You instead throw a service mesh in the mix and it’s done without modifying your service. So now you probably asking yourself, what is this magic? It’s actually a pretty easy solution.&nbsp;</span></p><p><span>A services mesh works by intercepting all communication to and from a service. Traffic interception is usually done by deploying proxy instances beside each service, so called sidecar injection, referring the proxy as the sidecar. This allows the service mesh to intercept and manage traffic without application modification. This enables key features such as metric gathering (e.g. latency, error rate), traffic management (e.g. splitting traffic between services, replicating traffic for testing), security (applying authentication and encrypted communication between services with mTLS) and resilience (e.g. retries, timeouts and circuit braking). The behavior of the proxy instances are steered by a set of management components referred to as the control plane. All proxies running alongside the services in the mesh are usually referred to as the data plane.</span></p></div></div></div><div data-id="9a7f5c7" data-element_type="widget" data-widget_type="image.default"><div><p><img width="532" height="310" src="https://elastisys.com/wp-content/uploads/2020/12/dahlberg-pod-injection.png?x58962" alt="" loading="lazy" srcset="https://elastisys.com/wp-content/uploads/2020/12/dahlberg-pod-injection.png 532w, https://elastisys.com/wp-content/uploads/2020/12/dahlberg-pod-injection-300x175.png 300w" sizes="(max-width: 532px) 100vw, 532px"></p></div></div><div data-id="3272f66" data-element_type="widget" data-widget_type="text-editor.default"><div><p>A good article describing why service mesh are useful that also talks about how they work is, “The Service Mesh: What Every Software Engineer Needs to Know about the World’s Most Over-Hyped Technology” by William Morgan. He is the current CEO of Buoyant and was also one of the creators of&nbsp;<a href="https://servicemesh.io/" target="_blank">Linkerd</a>.</p></div></div></div></div></div></div></div></section><section data-id="ceabb3e" data-element_type="section"><div><div><div data-id="e7229e3" data-element_type="column"><div><div><div data-id="7f49cea" data-element_type="widget" data-widget_type="heading.default"><p><h2>Istio and Linkerd: service meshes selected for this thesis</h2></p></div><div data-id="1a419b0" data-element_type="widget" data-widget_type="text-editor.default"><div><p>For finding services meshes to compare I used the Cloud Native Landscape, which is available at the Cloud Native Computing Foundation (CNCF). This site is a resource map to help enterprises and developers to find cloud-native technologies. The service meshes presented by the Cloud Native Landscape can be seen below. Istio was selected due to its popularity (most GitHub stars). Linkerd due to its architectural design being similar to Istio and for being hosted by CNCF.</p></div></div><div data-id="dbec31b" data-element_type="widget" data-widget_type="image.default"><div><p><img width="616" height="235" src="https://elastisys.com/wp-content/uploads/2020/12/dahlberg-cncf-service-meshes.png?x58962" alt="" loading="lazy" srcset="https://elastisys.com/wp-content/uploads/2020/12/dahlberg-cncf-service-meshes.png 616w, https://elastisys.com/wp-content/uploads/2020/12/dahlberg-cncf-service-meshes-300x114.png 300w" sizes="(max-width: 616px) 100vw, 616px"></p></div></div><div data-id="c87ccc9" data-element_type="widget" data-widget_type="text-editor.default"><div><p>Istio is an open-source project publicly released for the first time in May 2017 by Google, IBM and Lyft. Its architecture follows the common approach of using sidecars to integrate into a microservice application. The architecture is divided into two main parts, a data plane and a control plane. The data plane represents the sidecars, intercepting and managing all network communication between services. The control plane manages and configures the behavior of data plane and the service mesh.</p></div></div><div data-id="db897be" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Linkerd was for the first time released in 2016 by Buoyant. It was later to be redesigned and rewritten in Rust and Go for Kubernetes to lower the resource footprint and create a simpler solution. This newer version was introduced in December, 2017 as a separate service mesh project called Conduit. Conduit was later on July 6, 2018 merged into the Linkerd as a separate Linkerd project creating Linkerd 2.0. This thesis henceforth studies Linkerd 2.x and refers to it as Linkerd.</p><p>To date, Linkerd only supports Kubernetes and actually requires it to run compared to Linkerd 1.x that supports multiple environments. The Linkerd architecture is based on the sidecars principle mentioned earlier. The architecture is divided into two parts: the control plane and date plane, the date plane represents the proxy servers running alongside each application and intercept all communication. The control plane is split up into several services control the behavior of the data plane and collect telemetry about the network and service mesh.</p></div></div></div></div></div></div></div></div></section><section data-id="bf8b410" data-element_type="section"><div><div><div data-id="8a7bf68" data-element_type="column"><div><div><div data-id="50e1811" data-element_type="widget" data-widget_type="heading.default"><p><h2>Feature comparison: Istio vs. Linkerd</h2></p></div><div data-id="1decf38" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Linkerd is explicitly written for Kubernetes, to date only supporting Kubernetes. Istio is designed to run in any environment claiming to be platform-independent. To date, Istio runs on Kubernetes, Consul (alpha phase) and individual virtual machines (they can be connected into an existing Istio mesh deployed on Kubernetes).&nbsp;</p><p>Both meshes provide observability by using web-interfaces (dashboard) and preinstalled Grafana dashboards. Grafana is used to display information stored in the Prometheus datebase (e.g. CPU/memory of each pod and container). The web-interface is used to display and interact with the mesh, showing inject/uninjected pods and communication between services. Displaying golden metrics such as success rate, traffic (requests per second), latencies and saturation (system utilization). Both meshes provide distributed tracing but application modification is needed to propagate headers.&nbsp;</p><p>Resiliency features are also supported such as retries and timeouts, allowing the sidecar to retry failed requests and timeouts, if replies are too slow. Fault injection for introducing errors to services. Traffic shifting for dynamically shifting traffic between services. Istio also provides circuit breaking, that breaks all connection to a service after a fixed amount of concurrent connections of failed calls.&nbsp;</p><p>Security with authentication and encryption with mTLS are supported by both meshes. Linkerd automatically enables mTLS for most HTTP traffic, some gaps (e.g. Host header in HTTP request is an IP address). Istio has a strict mode that can be toggled to allow only traffic with mTLS or both mTLS and plain-text.</p><p>A shorter list of some of the features provided by both meshes:</p></div></div></div><div data-id="36c2aea" data-element_type="widget" data-widget_type="image.default"><div><p><img width="612" height="499" src="https://elastisys.com/wp-content/uploads/2020/12/dahlberg-service-meshes.png?x58962" alt="" loading="lazy" srcset="https://elastisys.com/wp-content/uploads/2020/12/dahlberg-service-meshes.png 612w, https://elastisys.com/wp-content/uploads/2020/12/dahlberg-service-meshes-300x245.png 300w" sizes="(max-width: 612px) 100vw, 612px"></p></div></div></div></div></div></div></div></section><section data-id="c10a6d6" data-element_type="section"><div><div><div data-id="752d98a" data-element_type="column"><div><div><div data-id="2db9a53" data-element_type="widget" data-widget_type="heading.default"><p><h2>Project maturity: Istio vs. Linkerd</h2></p></div><div data-id="1f53388" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Both projects give a mature feeling by both having an increasing community growth with an established community governance.&nbsp;</p><p><span>Istio has, to date, 22.8 thousand stars and is steered by their Steering Committee formed to oversee the administrative aspects of the project, including governance, branding, and marketing. The committee has 10 seats held by companies currently from IBM (3 seats), Google (6 seats) and Red Hat (1 seat). They also determine the members of the Technical Oversight Committee (TOC), responsible for project oversight, direction and delivery. The community is organized into working groups focusing on a specific area (e.g. documentation and security).</span><br></p><p><span>Linkerd has, to date, 5.5 thousand stars and is hosted by the CNCF project. The governance is split up into two roles, maintainer (8 people) and super-maintainer (2 people). Maintainer oversees one or more components, handling pull requests, sorting issues, etc. Super-maintainers oversee the project, guiding the general project direction. Project decisions are resolved by consensus otherwise the majority vote by the super-maintainer and maintainer. Maintainers are voted in by a 2/3 majority organization vote.&nbsp;</span><br></p><p><span>The trajectory of GitHub stars and forks from Istio and Linkerd can be seen in the figure below. Displaying an increase for both meshes since their release at GitHub. Istio has had a more rapid increase than Linkerd, especially when Linkerd actually is older than Istio with the predecessor Linkerd 1.</span></p></div></div></div><div data-id="c980f3f" data-element_type="widget" data-widget_type="image.default"><div><p><img width="621" height="419" src="https://elastisys.com/wp-content/uploads/2020/12/dahlberg-stars-forks.png?x58962" alt="" loading="lazy" srcset="https://elastisys.com/wp-content/uploads/2020/12/dahlberg-stars-forks.png 621w, https://elastisys.com/wp-content/uploads/2020/12/dahlberg-stars-forks-300x202.png 300w" sizes="(max-width: 621px) 100vw, 621px"></p></div></div></div></div></div></div></div></section><section data-id="580a042" data-element_type="section"><div><div><div data-id="08d4267" data-element_type="column"><div><div><div data-id="84fd5da" data-element_type="widget" data-widget_type="heading.default"><p><h2>Ease of use: Istio vs. Linkerd</h2></p></div><div data-id="dc97e8a" data-element_type="widget" data-widget_type="text-editor.default"><div><p>Both meshes support deployment with command line interface (CLI) and Helm for deployment. This with automatic sidecar injection makes both meshes fast and easy to deploy, without any application modification. Both meshes can actually be deployed with just CLI commands, first for deploying the mesh and secondly for injecting sidecars. Services injected with side-cars can both be seen through kubectl and provided service meshes dashboard.</p></div></div></div></div></div></div></div></section><section data-id="55e2241" data-element_type="section"><div><div><div data-id="54bce1b" data-element_type="column"><div><div><div data-id="91438b2" data-element_type="widget" data-widget_type="heading.default"><p><h2>Benchmarking performance: Istio vs. Linkerd</h2></p></div><div data-id="efa8e38" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>To evaluate the performance of the two meshes, a testbed was created. The testbed is deployed in a Kubernetes cluster on Google Kubernetes Engine (GKE) consisting of five n1-standard-4 virtual machines, each having 4 vCPUs and 15 GB memory. The benchmark is ran three times: without service mesh (reference point), with Istio version 1.5.0 and with Linkerd version 2.7.1.</p><p>Both service meshes provide a range of features that can be toggled on and off for tuning and performance purposes. However, for fair comparison, they were in stock configuration following installation …</p></div></div></div></div></div></div></div></div></section></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://elastisys.com/benchmarking-istio-linkerd-erik-dahlberg-master-thesis/">https://elastisys.com/benchmarking-istio-linkerd-erik-dahlberg-master-thesis/</a></em></p>]]>
            </description>
            <link>https://elastisys.com/benchmarking-istio-linkerd-erik-dahlberg-master-thesis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25429765</guid>
            <pubDate>Tue, 15 Dec 2020 12:47:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Improving Vim Workflow with Fzf]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25429515">thread link</a>) | @300
<br/>
December 15, 2020 | https://pragmaticpineapple.com/improving-vim-workflow-with-fzf/ | <a href="https://web.archive.org/web/*/https://pragmaticpineapple.com/improving-vim-workflow-with-fzf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><span>
      <span></span>
  <img alt="Pineapple on a beach" title="Pineapple on a beach" src="https://pragmaticpineapple.com/static/d844e61d88396079b127a2cb42ebe966/1c72d/cover.jpg" srcset="https://pragmaticpineapple.com/static/d844e61d88396079b127a2cb42ebe966/a80bd/cover.jpg 148w,
https://pragmaticpineapple.com/static/d844e61d88396079b127a2cb42ebe966/1c91a/cover.jpg 295w,
https://pragmaticpineapple.com/static/d844e61d88396079b127a2cb42ebe966/1c72d/cover.jpg 590w,
https://pragmaticpineapple.com/static/d844e61d88396079b127a2cb42ebe966/a8a14/cover.jpg 885w,
https://pragmaticpineapple.com/static/d844e61d88396079b127a2cb42ebe966/fbd2c/cover.jpg 1180w,
https://pragmaticpineapple.com/static/d844e61d88396079b127a2cb42ebe966/ca2d0/cover.jpg 5776w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>

<p>If you never heard of <a href="https://github.com/junegunn/fzf">fzf</a>, it is a very
handy general-purpose command-line fuzzy finder. Besides command-line, it is
also a popular Vim plugin. If you’re wondering, a fuzzy finder is a tool that
helps you find what you’re looking for without needing to write the full name.</p>
<p>As a Vim user, I am always obsessed with doing a thing in the fewer keystrokes
as possible. Having the ability to open a file in Vim quickly is super useful to
me, and you will see why soon.</p>
<p>But, did you know that this fuzzy finder - fzf, can do a lot more than you
thought? Oh yeah, the fuzzy search is just the tip of the iceberg here.
It is like wine; the more you leave it on your computer, the more flavor and
sweetness it accumulates from that command-line. Let’s dive in and find out how
you can increase your productivity with fzf inside Vim.</p>
<h2 id="starting-off"><a href="#starting-off" aria-label="starting off permalink"></a>Starting off</h2>
<p>To be able to do the things I am doing in this blog post, you will need a couple of
plugins. If you’re not using <a href="https://github.com/junegunn/vim-plug">vim-plug</a>
for installing other Vim plugins, then you are missing out. Go ahead and set
that up, and you can add the following:</p>
<div data-language="vim"><pre><code>Plug <span>'junegunn/fzf'</span><span>,</span> <span>{</span> <span>'do'</span><span>:</span> <span>{</span> <span>-</span><span>&gt;</span> fzf#<span>install</span><span>(</span><span>)</span> <span>}</span> <span>}</span>
Plug <span>'junegunn/fzf.vim'</span></code></pre></div>
<p>Then, install these plugins with <code>:PlugInstall</code> or use this shortcut I use:</p>
<div data-language="vim"><pre><code>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span><span>&lt;</span>leader<span>&gt;</span><span>1</span> <span>:</span><span>source</span> ~<span>/</span><span>.</span>vimrc \| <span>:</span>PlugInstall<span>&lt;</span>CR<span>&gt;</span></code></pre></div>
<p>You can then press your leader key and number 1 to install and apply all the
changes in your <code>.vimrc</code>.</p>
<p>Now, to the coolest part!</p>
<h2 id="the-magic-finder"><a href="#the-magic-finder" aria-label="the magic finder permalink"></a>The magic finder</h2>
<p>Everything we need is installed, and we can get to the practical part. As we
said before, fzf is a fuzzy finder, a file selector if you want. Let’s try
out that feature right off. To get the file picker opened, type <code>:Files</code> in
a Vim session. You should get something like this:</p>
<p><span>
      <span></span>
  <img alt="Open :Files" title="Open :Files" src="https://pragmaticpineapple.com/static/47be299b0a37790ebdd8396d20b872fa/fcda8/open-files.png" srcset="https://pragmaticpineapple.com/static/47be299b0a37790ebdd8396d20b872fa/12f09/open-files.png 148w,
https://pragmaticpineapple.com/static/47be299b0a37790ebdd8396d20b872fa/e4a3f/open-files.png 295w,
https://pragmaticpineapple.com/static/47be299b0a37790ebdd8396d20b872fa/fcda8/open-files.png 590w,
https://pragmaticpineapple.com/static/47be299b0a37790ebdd8396d20b872fa/efc66/open-files.png 885w,
https://pragmaticpineapple.com/static/47be299b0a37790ebdd8396d20b872fa/c83ae/open-files.png 1180w,
https://pragmaticpineapple.com/static/47be299b0a37790ebdd8396d20b872fa/ab40b/open-files.png 1736w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>
<p>What happened is fzf opened a small window at the bottom showing files in our
directory. If you look at the newly opened window, you will see the list of
files, and the <strong>preview</strong> of the currently selected file on the right
of the window. So you got your files on the left and their preview on the
right. Are you already impressed as I was? Cool, let’s move on.</p>
<p>If you don’t like the window, you can fine-tune easily with fzf customization
options. But if you want any fzf command in fullscreen, you can append <code>!</code> at
the end of the command. For example, let’s do <code>:Files!</code> and you should see the
following:</p>
<p><span>
      <span></span>
  <img alt="Open :Files! in fullscreen" title="Open :Files! in fullscreen" src="https://pragmaticpineapple.com/static/71e5fe325ab9a32de02f08763196d067/fcda8/open-files-fullscreen.png" srcset="https://pragmaticpineapple.com/static/71e5fe325ab9a32de02f08763196d067/12f09/open-files-fullscreen.png 148w,
https://pragmaticpineapple.com/static/71e5fe325ab9a32de02f08763196d067/e4a3f/open-files-fullscreen.png 295w,
https://pragmaticpineapple.com/static/71e5fe325ab9a32de02f08763196d067/fcda8/open-files-fullscreen.png 590w,
https://pragmaticpineapple.com/static/71e5fe325ab9a32de02f08763196d067/efc66/open-files-fullscreen.png 885w,
https://pragmaticpineapple.com/static/71e5fe325ab9a32de02f08763196d067/c83ae/open-files-fullscreen.png 1180w,
https://pragmaticpineapple.com/static/71e5fe325ab9a32de02f08763196d067/e67a8/open-files-fullscreen.png 1740w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>
<p>But, I don’t use <code>:Files</code> that often. As a matter of fact, I only use
<code>:GFiles</code> command by fzf. <code>:GFiles</code> will open a file picker for your Git files,
ignoring ones in the <code>.gitignore</code>. Using it is pretty neat in JavaScript
projects where <code>node_modules</code> files tend to kill the mood when running
<code>:Files</code>. Let us compare the same project with <code>:Files</code> and <code>:GFiles</code> commands:</p>
<p><span>
      <span></span>
  <img alt=":Files in a JavaScript project" title=":Files in a JavaScript project" src="https://pragmaticpineapple.com/static/7b9132a9a4e78a2fc2087e4059a22cbf/fcda8/files-js-project.png" srcset="https://pragmaticpineapple.com/static/7b9132a9a4e78a2fc2087e4059a22cbf/12f09/files-js-project.png 148w,
https://pragmaticpineapple.com/static/7b9132a9a4e78a2fc2087e4059a22cbf/e4a3f/files-js-project.png 295w,
https://pragmaticpineapple.com/static/7b9132a9a4e78a2fc2087e4059a22cbf/fcda8/files-js-project.png 590w,
https://pragmaticpineapple.com/static/7b9132a9a4e78a2fc2087e4059a22cbf/efc66/files-js-project.png 885w,
https://pragmaticpineapple.com/static/7b9132a9a4e78a2fc2087e4059a22cbf/c83ae/files-js-project.png 1180w,
https://pragmaticpineapple.com/static/7b9132a9a4e78a2fc2087e4059a22cbf/e67a8/files-js-project.png 1740w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>
<p>
  Yuck! `node_modules` everywhere.
</p>
<p><span>
      <span></span>
  <img alt=":GFiles in a JavaScript project" title=":GFiles in a JavaScript project" src="https://pragmaticpineapple.com/static/6cd545cf7ed03bb38decb5c1ae2d9949/fcda8/git-files-js-project.png" srcset="https://pragmaticpineapple.com/static/6cd545cf7ed03bb38decb5c1ae2d9949/12f09/git-files-js-project.png 148w,
https://pragmaticpineapple.com/static/6cd545cf7ed03bb38decb5c1ae2d9949/e4a3f/git-files-js-project.png 295w,
https://pragmaticpineapple.com/static/6cd545cf7ed03bb38decb5c1ae2d9949/fcda8/git-files-js-project.png 590w,
https://pragmaticpineapple.com/static/6cd545cf7ed03bb38decb5c1ae2d9949/efc66/git-files-js-project.png 885w,
https://pragmaticpineapple.com/static/6cd545cf7ed03bb38decb5c1ae2d9949/c83ae/git-files-js-project.png 1180w,
https://pragmaticpineapple.com/static/6cd545cf7ed03bb38decb5c1ae2d9949/76435/git-files-js-project.png 1742w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>
<p>
  Ah, that's better.
</p>
<p>Notice the difference? It feels like I just dropped a heavy backpack off my
back by not having those <code>node_modules/**</code> files popping up. Anyway, let’s see
this bad boy in action when searching for files to edit.</p>
<p><img src="https://pragmaticpineapple.com/5a84a887e91f3aea28f8692bcc518fc0/gfiles-in-action.gif" alt=":GFiles in action GIF"></p>
<p>That’s it, and it is looking pretty good. Only thing I dislike about using <code>:GFiles</code> is
that it won’t include your new files unless you add them to the Git index with
<code>git add</code>. Also, I’d like some syntax highlighting to be there out of the box
when previewing files, but we will cover that in another blog post. In the
meantime, consider subscribing to the <a href="https://pragmaticpineapple.com/improving-vim-workflow-with-fzf/newsletter">newsletter</a> to get similar
posts like this.</p>
<p>To sum up, fzf is useful and quick as a flash when searching for files. And, as
Drake below says, resort to using <code>:GFiles</code> or try to configure <code>:Files</code> to
ignore certain files and paths.</p>
<p><span>
      <span></span>
  <img alt="Drake fzf choices - go with :GFiles instead of :Files" title="Drake fzf choices - go with :GFiles instead of :Files" src="https://pragmaticpineapple.com/static/643d1c18c9fd8e42484fcaffaa4d99eb/41099/drake-no-files-yes-gfiles.jpg" srcset="https://pragmaticpineapple.com/static/643d1c18c9fd8e42484fcaffaa4d99eb/a80bd/drake-no-files-yes-gfiles.jpg 148w,
https://pragmaticpineapple.com/static/643d1c18c9fd8e42484fcaffaa4d99eb/1c91a/drake-no-files-yes-gfiles.jpg 295w,
https://pragmaticpineapple.com/static/643d1c18c9fd8e42484fcaffaa4d99eb/41099/drake-no-files-yes-gfiles.jpg 500w" sizes="(max-width: 500px) 100vw, 500px" loading="lazy">
    </span></p>
<p>To make this super fast for you, you can create a shortcut. I open <code>:GFiles</code>
with CTRL + p. I got left with this in my muscle memory from the legendary
<a href="https://github.com/kien/ctrlp.vim">ctrlp</a> plugin. To have <code>:GFiles</code> wired
up, so it opens with CTRL + p, you can add the following to your <code>.vimrc</code>:</p>
<div data-language="vim"><pre><code>nnoremap <span>&lt;</span>C<span>-</span><span>p</span><span>&gt;</span> <span>:</span>GFiles<span>&lt;</span>Cr<span>&gt;</span></code></pre></div>
<h2 id="speed-search-your-project"><a href="#speed-search-your-project" aria-label="speed search your project permalink"></a>Speed search your project</h2>
<p>What blows my mind from time to time is other things you can do with fzf in
Vim. For example, you can use
<a href="https://github.com/ggreer/the_silver_searcher">The Silver Searcher</a>
or
<a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> with fzf.
To search with The Silver Searcher, type <code>:Ag</code> and a term you want to
search. And, to search with ripgrep, type <code>:Rg</code> and the term. Of course, to
have these commands work, you need the respective libraries installed in your
environment.</p>
<p>I use <code>:Ag</code>, and it performs wonderfully. It is wired to CTRL + g for me,
so I access it quickly. To have this or a similar setup, add the following
to your <code>.vimrc</code>:</p>

<p>The shortcut above will open up the <code>:Ag</code> search windows at the bottom with the
preview of the file. I find it super helpful and quick when I need to search
for a word in a project. Let’s see <code>:Ag</code> in action.</p>
<p><img src="https://pragmaticpineapple.com/0c1dc6a8efd411223955dd76a20783a6/ag-in-action.gif" alt=":Ag in action"></p>
<h2 id="buffed-up"><a href="#buffed-up" aria-label="buffed up permalink"></a>Buffed up</h2>
<p>You can search all your open buffers with fzf by typing <code>:Buffers</code>. I keep a
shortcut at my leader key (the Space key, BTW) + b. Like so:</p>
<div data-language="vim"><pre><code>nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span><span>&lt;</span>leader<span>&gt;</span><span>l</span> <span>:</span>Buffers<span>&lt;</span>CR<span>&gt;</span></code></pre></div>
<p>With that command, you will get a buffers explorer where you can quickly switch
between open files. I hope that helps. Let’s see how it looks:</p>
<p><span>
      <span></span>
  <img alt=":Buffers in action" title=":Buffers in action" src="https://pragmaticpineapple.com/static/cb72ecbb277eb7bb278051d84c0b5f96/fcda8/buffers.png" srcset="https://pragmaticpineapple.com/static/cb72ecbb277eb7bb278051d84c0b5f96/12f09/buffers.png 148w,
https://pragmaticpineapple.com/static/cb72ecbb277eb7bb278051d84c0b5f96/e4a3f/buffers.png 295w,
https://pragmaticpineapple.com/static/cb72ecbb277eb7bb278051d84c0b5f96/fcda8/buffers.png 590w,
https://pragmaticpineapple.com/static/cb72ecbb277eb7bb278051d84c0b5f96/efc66/buffers.png 885w,
https://pragmaticpineapple.com/static/cb72ecbb277eb7bb278051d84c0b5f96/c83ae/buffers.png 1180w,
https://pragmaticpineapple.com/static/cb72ecbb277eb7bb278051d84c0b5f96/50e7d/buffers.png 1738w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>
<h2 id="ascii-art-kind-of"><a href="#ascii-art-kind-of" aria-label="ascii art kind of permalink"></a>ASCII art (kind of)</h2>
<p>If you are a fan of drawing inside the terminal, then you are going to love this one.
Try typing <code>:Commits</code> if you are using the <a href="https://github.com/tpope/vim-fugitive">vim-fugitive</a> plugin.
The plugin by itself is a pretty awesome wrapper around Git, just if you
never want to leave the warmth of your Vim session. Anyways, if you type
<code>:Commits</code> you should get a tree of your project commits like so:</p>
<p><span>
      <span></span>
  <img alt="Commit art" title="Commit art" src="https://pragmaticpineapple.com/static/4cef7957e6047955944c695930e80804/fcda8/commits-art.png" srcset="https://pragmaticpineapple.com/static/4cef7957e6047955944c695930e80804/12f09/commits-art.png 148w,
https://pragmaticpineapple.com/static/4cef7957e6047955944c695930e80804/e4a3f/commits-art.png 295w,
https://pragmaticpineapple.com/static/4cef7957e6047955944c695930e80804/fcda8/commits-art.png 590w,
https://pragmaticpineapple.com/static/4cef7957e6047955944c695930e80804/efc66/commits-art.png 885w,
https://pragmaticpineapple.com/static/4cef7957e6047955944c695930e80804/c83ae/commits-art.png 1180w,
https://pragmaticpineapple.com/static/4cef7957e6047955944c695930e80804/ab40b/commits-art.png 1736w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>
<p>Pretty cool, huh? You can scroll up and down and checkout changes at each
commit. You can even enter the commit you are interested in and check out
changes made there. All of this is possible thanks to the <code>vim-fugitive</code>, so check
it out. A blog post about using Git inside Vim is coming, so be sure to
subscribe to the <a href="https://pragmaticpineapple.com/newsletter">newsletter</a>.</p>
<h2 id="a-quick-summary"><a href="#a-quick-summary" aria-label="a quick summary permalink"></a>A quick summary</h2>
<p>Vim ecosystem has a lot of plugins, and fzf is one great plugin. You can search
for files with <code>:GFiles</code> and <code>:Files</code>. If you want to do a text search, try using
<code>:Ag</code> or <code>:Rg</code>, which use The Silver Searcher and ripgrep, respectively. Tired of
slow switching between open buffers - try out <code>:Buffers</code>. Or, if you want some
nice commit information, do <code>:Commits</code>.</p>
<p>These are just a couple of commands and tricks fzf has, be sure to check out
their README for more information. Also, stay tuned for more posts like these
from me and consider subscribing to the <a href="https://pragmaticpineapple.com/newsletter">newsletter</a>. If you found
the blog post interesting, make sure to spread the word and share it with
your friends and coworkers:</p>
<blockquote><p lang="en" dir="ltr">I just released a new blog post about using the fzf plugin with Vim. Check it out 👇<a href="https://t.co/fmybAXNNnx">https://t.co/fmybAXNNnx</a></p>— Nikola Đuza (@nikolalsvk) <a href="https://twitter.com/nikolalsvk/status/1328670506803924992?ref_src=twsrc%5Etfw">November 17, 2020</a></blockquote> 
<blockquote>
<p>💡 Are you curious to learn Vim in the most effective way possible? Then check out
the <a href="https://gumroad.com/a/561247347">Mastering Vim Quickly</a> book.</p>
</blockquote>
<p>Until the next one, cheers!</p></section></div>]]>
            </description>
            <link>https://pragmaticpineapple.com/improving-vim-workflow-with-fzf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25429515</guid>
            <pubDate>Tue, 15 Dec 2020 12:08:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shitlist Driven Development (2016)]]>
            </title>
            <description>
<![CDATA[
Score 402 | Comments 136 (<a href="https://news.ycombinator.com/item?id=25429493">thread link</a>) | @r4um
<br/>
December 15, 2020 | https://sirupsen.com/shitlists/ | <a href="https://web.archive.org/web/*/https://sirupsen.com/shitlists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article-content">
    

    <p>Recently the team I work with completed a project to <a href="https://www.youtube.com/watch?v=7UyDK2bDjc4">allow Shopify to run in
multiple datacenters</a>. This project
was a refactoring project in disguise. When you undertake large refactoring of a
code-base with 100s of developers and 100,000s of lines of code, you can’t align
by sending an email. The merge-conflicts a single pull request would entail
makes me shiver. When deprecating in a large code-base the only way to reliably
avoid new deprecated behaviour is a failing test that tells you what to do.
Otherwise the pace that new deprecated code is introduced can easily outpace the
speed at which you can remove them, or be a massive source of frustration.</p>
<p>Typically deprecations come in the form of soft warnings: Logging to <code>stderr</code>,
capital letters and exclamation marks in the documentation, or a legacy prefix
to the method or class name. At the end of the day, everyone needs to get work
done, and if they see a code-path already being used from 10 places in the
code-base despite these soft warnings–it doesn’t seem crazy to introduce
another. However, if another project is blocked on these deprecated code-paths,
piling on may have a large cost.</p>
<p>To solve this problem <a href="https://twitter.com/fw1729">Florian Weingarten</a> on our
team introduced what he calls “shitlists”: a whitelist of deprecated behaviour.
Existing deprecated behaviour is OK and whitelisted. New usage of the deprecated
API is banned and fails a test with a well-defined error.</p>
<p>They come in many forms, but could look like this:</p>
<div><pre><code data-lang="ruby"><span>Shitlist</span> <span>=</span> <span>[</span>
  <span>ClassA</span>,
  <span>ClassB</span>,
  <span>ClassC</span>
<span>]</span>

<span>def</span> <span>push_job_that_does_crazy_things</span>(klass)
  <span>if</span> <span>Shitlist</span><span>.</span>include?(klass)
    <span># Existing deprecated behaviour is called.</span>
  <span>else</span>
    <span>raise</span> <span>Shitlist</span><span>::</span><span>Error</span>, <span>&lt;&lt;-EOS
</span><span></span><span>You</span><span>'</span>re pushing a job that does crazy things<span>.</span> <span>This</span> <span>API</span> has been 
deprecated <span>in</span> this code<span>-</span>base<span>.</span> <span>&lt;</span>team<span>&gt;</span> is actively trying to get
rid of this code<span>-</span>path, because
<span>&lt;</span>reason<span>&gt;.</span> <span>We</span> suggest you instead <span>do</span> <span>&lt;</span>alternative<span>&gt;.</span> <span>If</span> you have questions, please
ping <span>&lt;</span>team<span>&gt;.</span>
  <span>EOS</span>
<span>end</span>
</code></pre></div><p>A shitlist could be something as simple as a <code>git grep</code> for a certain code-path:</p>
<div><pre><code data-lang="ruby"><span>test</span> <span>"no new introductions of legacy code path"</span> <span>do</span>
  actual <span>=</span> <span>`git grep some_legacy_method_with_a_unique_name`</span>
  assert_equal <span>321</span>, actual
<span>end</span>
</code></pre></div><p>Other times you can reach into another API and get a count or shitlist:</p>
<div><pre><code data-lang="ruby"><span>RedisShitlist</span> <span>=</span> <span>[</span>
  <span>Session</span>,
  <span>FragmentCache</span>,
  <span>AuthenticationTokens</span>,
<span>]</span>

<span>test</span> <span>"no new redis models introduced"</span> <span>do</span>
  assert_equal <span>RedisShitlist</span>, <span>RedisModel</span><span>.</span>descendants
<span>end</span>
</code></pre></div><p>Other ways we’ve used shitlists in the past:</p>
<ul>
<li>Make sure that a certain datastore is only read from in a certain context (or
not used at all). This would allow for using a read-only slave, or improving
resiliency in a certain area.</li>
<li>Ensure fallbacks for all uses of a secondary data-store. E.g. if you access
sessions in Redis and Redis is down, you should be able to still render the
page (i.e. have an empty session fallback).</li>
<li>Shitlisting joins between tables that have no business being joined. This is
helpful to keep data-models and scope clean, or separating a part of an
application.</li>
</ul>
<p>If you have a linter for a project, you may be able to encode rules. For example
you might use <a href="http://www.foodcritic.io/">Foodcritic</a> for Chef, or
<a href="https://github.com/bbatsov/rubocop">Rubocop</a> for Ruby.</p>
<p>Sometimes the shitlist is quite complicated, and much more domain-specific.</p>
<p>Building the shitlist gives the team responsible for it a number of advantages:</p>
<ol>
<li><strong>Strong feedback loop.</strong> The goal is to reduce the <code>Shitlist</code> to an empty
Array and always raise or remove the code entirely. Remove a class from the
list, fix the code and the tests, celebrate and move on.</li>
<li><strong>Stopped the bleeding.</strong> New deprecated behaviour is not introduced unless
the team is contacted or some other action defined in the error is taken.</li>
<li><strong>Success metric</strong>. If you have shitlists for everything that needs to be
done for your project, you have metrics that you can track. Every week you
can look at how these lists are shrinking. Refactoring for months at a time
can be exhausting, but if you see that you’re making progress with metrics
moving, it’s much more rewarding.</li>
<li><strong>Enforces a guarantee</strong>. For example, you can have a shitlist that all jobs
have a retry mechanism. In that case, you know that you can kill any worker
gracefully at any time since the job will retry. Because of 1-3 you know how
much work it will take to have this guarantee.</li>
</ol>
<p>It is important that the shitlist errors are actionable. If you hit the shitlist
of another team, you need to know what to do next. Ideally the error explains
exactly what you need to do, and no humans need to talk, but reaching out to the
owner of the shitlist should always be part of the shitlist.</p>
<p>If you own a shitlist, you must empathize with the problems of everyone who’s
running into problems. If you simply deprecate new behaviour and don’t offer an
alternative, you will be the source of frustration. If the value of emptying the
shitlist far outweighs the value of adding to the shitlist, it may be OK to not
offer a direct other solution but ask the person who ran into the error to
revise their solution.</p>
<p>It is important that people run into shitlists as early in development as
possible. If you run into a shitlist after spending hours implementing your
solution, you will be less than popular. Some shitlists may require an entire
re-architecting of some teams’ solutions.</p>
<p>Months, in our case more than a year, of refactoring can be overwhelming and
unrewarding work. With the strong feedback loop that shitlists introduce you can
see the light at the end of the tunnel. You know that nothing is added to the
shitlist without you knowing about it.</p>
<p>Creating shitlists in some cases can be extremely difficult. Some take hours to
create, others weeks, and in our case one took months to come up with. You’ll
have to place the cost of developing the shitlist against the cost of not having
it. In some cases logging when you hit a bad code-path may be enough (simple
soft warning deprecation) if you assert the risk of new behaviour small and the
complexity of introducing the shitlist big.</p>
<p>Delegating with shitlists is great. Due to the tight feedback loop, asking other
teams or onboarding new team members becomes much easier. Remove something on
the shitlist, fix the code and the tests, then move on. Sometimes during large
refactorings you may need other teams with more domain expertise of a certain
area of the code-base to help. The shitlist becomes a great rock to point people
at.</p>
<p>If you are about to embark on a large refactor, I highly recommend adding
shitlists to your toolbox. Your project will look much less daunting when it
goes from an opaque objective to a list of shitlists.</p>


    

    
  </div></div>]]>
            </description>
            <link>https://sirupsen.com/shitlists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25429493</guid>
            <pubDate>Tue, 15 Dec 2020 12:05:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Today is Esperanto Book Day – why I learned it (2018)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25429472">thread link</a>) | @martinrue
<br/>
December 15, 2020 | https://martinrue.com/zamenhofa-tago-18?jaro=20 | <a href="https://web.archive.org/web/*/https://martinrue.com/zamenhofa-tago-18?jaro=20">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            <h3>Feliĉan Zamenhofan Tagon</h3>

            <p>
                Zamenhof Day (also known as Esperanto Book Day) is the birthday of the creator of the constructed
                language Esperanto, <a href="https://en.wikipedia.org/wiki/L._L._Zamenhof">Ludwik Łazarz Zamenhof</a>.
                It’s widely celebrated as the Day of Esperanto by many Esperantists across the world.
            </p>

            <p>
                I even have a t-shirt for the occasion, and you know I’m serious when I have a t-shirt.
            </p>

            <p>
                <img src="https://martinrue.com/assets/by-post/fzt/cxemizo.png">
            </p>

            <p>
                Zamenhof created Esperanto in 1887. His goal was to create an auxillary language that could be shared by
                everyone equally. A language where everyone is an equal and everyone, regardless of where they were
                born, can communicate and understand each other.
            </p>

            <p>
                I first started learning Esperanto out of sheer curiosity. Almost for the same reason I may have
                otherwise pondered to myself “Hey, how do you insult someone’s mother in Klingon?” – which by the way,
                is to suggest that she has a smooth forehead (Hab SoSlI’ Quch).
            </p>

            <p>
                Warning: Please don’t say this to any Klingons you know, as it’s very insulting, and they’re pretty good
                with a <a href="https://en.wikipedia.org/wiki/Bat%27leth">bat’leth</a>.
            </p>

            <p>
                To me, Esperanto was much more interesting than other constructed languages. I quickly realised that
                it’s a complete language with a rich vocabulary, a ridiculously simple grammar, and believe it or not,
                lots of fluent speakers across the world (and even a <a href="https://en.wikipedia.org/wiki/Native_Esperanto_speakers">few native speakers</a>).
            </p>

            <p>
                After dabbling with the language for a long time, and studying it more deliberately in recent years, I
                have to admit that it has been one of the most enjoyable things I’ve done.
            </p>

            <p>
                Esperanto has some unique attributes which makes it a fun hobby to pursue, with some big upsides if you
                decide to take it further.
            </p>

            <p>
                Here’s why I’m a big fan:
            </p>

            <ul>
                <li>
                    ⚡ It’s easy. Esperanto is by far the simplest language to learn, requiring a fraction of the time it
                    would take to learn a national language.
                </li>

                <li>
                    🧠 It’s consistent. It has a regular grammar, with rules that are consistently followed. This is one
                    of the reasons it’s easier to learn. It’s like a programming language for your mouth.
                </li>

                <li>
                    🕺 There’s a strong and very supportive community. Perhaps due to how few speakers there are
                    (relatively speaking), Esperantists always have time for each other. This is a huge benefit for me,
                    because it means I can be in almost any country in the world, and I’ll be able to find an Esperanto
                    speaker who’ll be more than happy to grab a coffee and hang out.
                </li>

                <li>
                    🌎 International friends. Through Esperanto, you can make new friends from all over the world. The
                    first unexpected benefit of this for me was that it gave me a window to a much wider perspective on
                    things, particularly world events. I can read news in Esperanto from different countries, and get a
                    sense of what is happening / what people are thinking in the non-English parts of the big rock we
                    live on.
                </li>

                <li>
                    🗣 It’s a gateway language. While Esperanto probably isn’t the best choice for a language that will
                    open doors to higher paid jobs, it does train your brain in a regular and consistent way to learn a
                    new language. It trains you to think about different aspects of language, including aspects of your
                    native language that you don’t start thinking about until you begin learning a second. Many people
                    go from Esperanto to a third language and find the experience easier with their new
                    language-learning-primed brains.
                </li>

                <li>
                    🛫 Travel. Lots of Esperantists will host other Esperantists in their home towns, for free, making
                    traveling the world even more appealing (and possible). The
                    <a href="https://en.wikipedia.org/wiki/Pasporta_Servo">Pasporta Servo</a> has been going since
                    1966, allowing Esperantists to find hosts to stay with, or host traveling Esperantists themselves.
                    In each different country, you’ll be able to communicate via Esperanto, and have a completely
                    different experience than the typical tourist trails.
                </li>
            </ul>

            <p>
                If all that sounds so sweet that you’ve already cancelled your weekend plans, perhaps your next question
                is “How do I learn it?”
            </p>

            <p>
                Well, since I’m here, allow me to give you a few tips:
            </p>

            <p>
                Saluton.
            </p>

            <p>
                Hello.
            </p>

            <p>
                That’ll nicely open up a conversation with any Esperanto speaker, and you’ll hear it quite often.
            </p>

            <p>
                Just like other languages, you’ll probably immediately throw in:
            </p>

            <p>
                Kiel vi fartas?
            </p>

            <p>
                How are you?
            </p>

            <p>
                To your amazement, you did not in fact ask the other person if they broke wind.
            </p>

            <p>
                Given that you both speak Esperanto, naturally you’re both feeling pretty awesome about things,
                warranting the response:
            </p>

            <p>
                Bonege dankon, kaj vi?
            </p>

            <p>
                Great thanks, and you?
            </p>

            <p>
                Maybe you’re a bit tired:
            </p>

            <p>
                Mi estas iomete laca, sed ne malbona.
            </p>

            <p>
                I'm a bit tired, but not bad.
            </p>

            <p>
                You’ve just noticed your Esperanto friend is
                <a href="https://i.imgur.com/KykL6rx.gifv">eating her peas one-by-one</a>,
                and want to wrap up the conversation as quickly as possible:
            </p>

            <p>
                Ĝis poste!
            </p>

            <p>
                See you later!
            </p>

            <p>
                Here’s a few cool things to note about this conversation.
            </p>

            <p>
                All letters in Esperanto make consistent sounds, so unlike English (where ‘ough’ has approximately 1
                billion different sounds), you can look at a written word and reliably say it.
            </p>

            <p>
                Also notice how we have <strong>-as</strong> on the end of the word fart<strong>as</strong>? That’s how
                you make a verb (a doing-word) refer to the present tense in Esperanto.
            </p>

            <p>
                And guess what? That’s <strong>always</strong> how you get the present tense version of a verb. I mean,
                how easy is that? Want the past tense instead? No problem, just change the <strong>-as</strong> to
                <strong>-is</strong>. The future? <strong>-os</strong> will be your friend. The best bit is that these
                rules never change – all verbs can be produced this way, with no exceptions.
            </p>

            <p>
                You probably don’t believe me, but it’s true – if having the sort of grammar that brings tears of joy to
                the eyes of its learners was a crime, Esperanto would be doing life in maximum security.
            </p>

            <p>
                But there’s more.
            </p>

            <p>
                Pop-quiz. How do you get the plural of a word in English?
            </p>

            <p>
                Add an ‘s’ to the end, you say? Well sometimes, but it doesn’t always work. I definitely don’t have two
                foots. And while I’ve been told I only have <strong>half</strong> a brain, I figure it’s the stronger of
                the two <strong>halves</strong> I’ve kept.
            </p>

            <p>
                In Esperanto, just add <strong>-j</strong>. You can add it to any singular noun or adjective. That rule
                never changes either.
            </p>

            <p>
                If I have more than one <strong>kato</strong> (cat), I most certainly have <strong>katoj</strong>
                (cats). If I were to drink more than one <strong>biero</strong> (beer), and honestly, I never do, then
                I’d have consumed <strong>bieroj</strong> (beers), and would probably slur my <strong>vortoj</strong>
                (words).
            </p>

            <p>
                In Esperanto, we don’t waste space in our dictionaries with both ‘good’ and ‘bad’, ‘left and ‘right’,
                ‘up’ and ‘down’. We just have one of them, and then use the prefix <strong>mal</strong> to create the
                logical opposite. Now you have fewer words to learn.
            </p>

            <p>
                I can only imagine you’re finding this post <strong>bona</strong> (good), but if you aren’t (and let’s
                face it… you are), you’d be finding it <strong>malbona</strong> (bad).
            </p>

            <p>
                The prefix <strong>mal</strong> can be used to prefix anything, assuming it still makes sense. One could
                say <strong>malsaluton</strong>, which despite stepping all over the toes of <strong>ĝis</strong> (bye),
                would make sense to an Esperanto speaker. It would no doubt also make them think you’re a bit weird, but
                that’s beside the point – perhaps you are.
            </p>

            <p>
                Adverbs, adjectives, participles, and every other grammatical aspect of Esperanto has a similar sense of
                structure and consistency like the examples above, making it much easier to learn.
            </p>

            <p>
                At this point, I’m pretty sure you could already have a …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://martinrue.com/zamenhofa-tago-18?jaro=20">https://martinrue.com/zamenhofa-tago-18?jaro=20</a></em></p>]]>
            </description>
            <link>https://martinrue.com/zamenhofa-tago-18?jaro=20</link>
            <guid isPermaLink="false">hacker-news-small-sites-25429472</guid>
            <pubDate>Tue, 15 Dec 2020 12:01:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Non-primitive non-linear data structures: Trees]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25429466">thread link</a>) | @Marv101
<br/>
December 15, 2020 | https://thegreencodes.com/non-primitive-non-linear-data-structures-trees | <a href="https://web.archive.org/web/*/https://thegreencodes.com/non-primitive-non-linear-data-structures-trees">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>Speaking of Christmas trees, let's shake one-two before the carols -  like our fathers and their fathers before them. Literally.</p>
<p>Now, when it comes to data storage, using linear structures, be it <a target="_blank" href="https://thegreencodes.com/data-structures-the-linear-non-primitives">linked lists and arrays</a> or even <a target="_blank" href="https://thegreencodes.com/data-structures-stacking-and-queueing">stacks and queues</a>, we have accountability over time complexity as the size of our data increases. That is, the larger the data being stored, the more time it takes to extract this data or manipulate it.</p>
<p>'<em>Ohh well great! You've shown me how to store data only to give me the cons afterward?! What on earth!</em>'</p>
<p>Hold on for one moment, will you! That's why this piece is here. <strong>The non-primitive non-linear data structures</strong>.</p>
<p>As with family lines, from grandpa to great grandpa and yourself, so is the same applied to data structures.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1608017057888/XWm7wcCVx.png?auto=compress" alt="Trees.png"></p>
<p>A little theory before we get into the why. We'll start off with the parent; the root. 
It's from here that everything emanates. Just like a Linux directory structure. The <code>/</code> directory. </p>
<p>Our tree root has two 'children', <code>A</code> and <code>B</code>, defined by engineers as <code>nodes</code>. From here, we see <code>B</code> with its own pair of children, 'C' and 'D' of whom C proceeds to get a single child node 'E'. We might as well call C a parent at this point.</p>
<p>The little lines marking the links between parent and child would be named <code>edges</code>.
Following a specific path to the final child, for instance, following through to <code>E</code> would name this bottom descendant a leaf node or external node. It's the last child in this specific path with no children. The same applies to A and D.</p>
<h4 id="depth-of-nodes">Depth of nodes</h4>
<p>The number of edges from the root to the node. In our case, E would have a depth of 3.</p>
<h4 id="height-of-a-node">Height of a node</h4>
<p>How far is the smallest child from it in this specific path? B, for instance, will have a height of 2. Given there are two edges before we get to the furthest descendant in its path. Depending on how many children it has, how far is the furthest child of a node? How many nodes does this child have?</p>
<h4 id="height-of-tree">Height of Tree</h4>
<p>The height of a tree's root node.</p>
<h4 id="degree-of-node">Degree of Node</h4>
<p> The number of children of a node. Above, C has a degree of one while B has that of two.</p>
<p>A practical train of thought. We have data to be queried from an API REST endpoint. Our system has users, profiles, and articles. Thinking logically, a user profile is a child node of the user's endpoint. We will have to get a user to log in, get the token, and query the profile based on the token. Something like this:</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1608021263968/inwO5DFit.png?auto=compress" alt="rest-endpoint.png"></p>
<p>So in your thought process, seeing as it is, software development is more of thinking than writing code, it would make sense to create a <code>user model</code> before a <code>profile</code>. Our <code>User</code> model is the parent, the root. </p>
<p>Compare this to having a linear data structure.</p>
<p>We could go on to break trees into more individual types:</p>
<p>a) General Tree</p>
<p>b) Binary Tree</p>
<p>c) Binary Search Tree</p>
<p>d) AVL Tree</p>
<h3 id="binary-tree">Binary Tree</h3>
<p>A tree, as displayed above, in which case parents have at max, two children. Due to this, the children are referred to as the left and right child. Think of how we might have this in decision trees, where we perform an action based on a condition. 
To elaborate further, we have the below groups.</p>
<h4 id="full-binary-tree">Full Binary tree</h4>
<p>Every node of the tree has two or zero children.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1608022900340/czulV8J6u.png?auto=compress" alt="full-binary.png"></p>
<h4 id="perfect-binary-tree">Perfect Binary Tree</h4>
<p>The tree internal nodes have two children. All leaves also have the same depth. A perfect uniform.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1608023219349/ootMFOgFX.png?auto=compress" alt="perfect-binary-tree.png"></p>
<h4 id="balanced-tree">Balanced Tree</h4>
<p>If the height of the left and right subtree at any node differs at most by 1, then the tree is called a balanced tree. So in the case of the perfect binary, if either of the last child nodes had one more child, one and only one, it would become a balanced tree. It's a strange way of calling something balanced, I know!</p>
<h3 id="general-tree">General Tree</h3>
<p>Consider a binary tree. Any type of binary tree, but without limitations to what number of children a node can have. Do you want 4? Do you want 17? Go ahead and fill your database or whatever it is your structuring.</p>
<h3 id="binary-search-tree">Binary Search Tree</h3>
<p>A different way of looking at Binary search trees if you may. Here, the left nodes are always smaller than their parents in terms of the value they possess. The right nodes, however, are a little cocky, always having more value than their parents or being equal. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1608024052809/c5HCm3fgY.png?auto=compress" alt="binary-search-tree.png"></p>
<p>'<em>Well, that's not right. I've never seen this man in my life!</em>'</p>
<p>Used maps/dictionaries before? Yeap. binary search trees you deserter!</p>
<p>Searching for a specific item in an array of 100 or 200 might not be a problem. Increase this to 10 000 or 1 000 000 items, however, no one wants to be the user.</p>
<h3 id="avl-tree">AVL Tree</h3>
<p>Named after Adelson, Velsky, and Landis, this is a self-balancing binary tree in which each node has extra information -  the balance factor-   whose value is either -1, 0, or 1.</p>
<p>You remember <a href="####Height of a node">heights</a>, right? Well, the balance factor comes in as below:</p>
<p><strong>BalanceFactor = height_of_left_subtree - height_of_right_subtree</strong></p>
<p>Whenever a tree is out of balance, AVL trees work around this by rotating nodes. Whether moving the right node to the left or the right, or left-right rotation or perhaps right-left rotation.</p>
<p>What this means is that at one point, the right node which seemed heavy/ larger to the left will become the parent and hence the parent becomes the left child while the left child becomes the new right child and so on. think of it in terms of the hour clock. It will rotate itself in either direction until the tree is balanced. More detail on this can be elaborated on in a later conversation. Keep an eye up!</p>
<h2 id="conclusion">Conclusion</h2>
<p>We've taken a bucket load of information. Trees and searching, children, and siblings. What is all this knowledge without implementation? Fire up that laptop one last time this year and think of how you could have consumed that endpoint differently. Take a sabbatical, if you may, and have the rest you need, then come back and break the time complexity barrier. Write more efficient code, more productive code, and let's make the user experience smoother.</p>
<p>Here, </p>
<p><a target="_blank" href="https://thegreencodes.com/">TheGreenCodes</a></p>
</div></div>]]>
            </description>
            <link>https://thegreencodes.com/non-primitive-non-linear-data-structures-trees</link>
            <guid isPermaLink="false">hacker-news-small-sites-25429466</guid>
            <pubDate>Tue, 15 Dec 2020 11:59:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ebiten in 2020]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25429375">thread link</a>) | @dcu
<br/>
December 15, 2020 | https://ebiten.org/blog/2020.html | <a href="https://web.archive.org/web/*/https://ebiten.org/blog/2020.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        


<p>Hajime Hoshi<br><span id="meta-created">2020-12-15</span></p>
<p lang="en">It's been 7 years since I started to develop Ebiten. This article is a retrospective of Ebiten in 2020.</p>
<p lang="ja">自分が Ebiten を開発し始めてから 7 年になりました。この記事は、 2020 年の Ebiten の回顧録です。</p>
<h2 lang="en">Sponsors</h2>
<h2 lang="ja">スポンサー</h2>
<p lang="en">These people <a href="https://github.com/sponsors/hajimehoshi">sponsored</a> me in between December 2019 and November 2020. I can't thank you enough!</p>
<p lang="ja">2019 年 12 月から 2020 年 11 月の間、以下の方々に<a href="https://github.com/sponsors/hajimehoshi">スポンサー</a>していただきました。心より感謝いたします。</p>
<p lang="en">(In the order of total sponsoring amounts)</p>
<p lang="ja">(スポンサー総額の大きい順、敬称略)</p>

<h2 lang="en">Contributors</h2>
<h2 lang="ja">コントリビューター</h2>
<p lang="en">These people contributed to Ebiten in between December 2019 and November 2020. I appreciate all the contributions!</p>
<p lang="ja">2019 年 12 月から 2020 年 11 月の間、以下の方々にコントリビュートしていただきました。心より感謝いたします。</p>
<p lang="en">(In the order of total commits)</p>
<p lang="ja">(コミット数順、敬称略)</p>
<div>
  
  
  
  
  
  
  
  <div>
    <p lang="en">and many more contributors have contributed to Ebiten.</p>
    <p lang="ja">その他多数のコントリビューターからコントリビュートしていただきました。</p>
  </div>
</div>
<h2 lang="en">Events</h2>
<h2 lang="ja">出来事</h2>
<h3 lang="en">Summary</h3>
<h3 lang="ja">まとめ</h3>
<ul>
  <li lang="en">The most significant change in Ebiten is introducing <a href="https://ebiten.org/documents/shader.html">a Go-flavored shading language</a>. I hope this would be used more in actual applications.</li>
  <li lang="ja">Ebiten 自体の一番大きい変化は、 <a href="https://ebiten.org/documents/shader.html">Go 風味シェーディング言語</a>の導入です。今後もっと実アプリケーションで使われるように慣ればと思います。</li>
  <li lang="en">The second most significant change in Ebiten is updating the major version to v2. This was the first trial, but apparently worked well. v3 will be released in about 5 years.</li>
  <li lang="ja">次に大きい変化は、メジャーバージョンが v2 にアップデートされたことです。初の試みでしたが、うまく行ったように思われます。 v3 が出るのはおおよそ 5 年後くらいでしょう。</li>
  <li lang="en">I have been working on supporting consoles. An actual output will be shown in 2021.</li>
  <li lang="ja">家庭用ゲーム機の対応を行っていました。実際に成果物が出るのは 2021 年でしょう。</li>
  <li lang="en">Compared with <a href="https://ebiten.org/blog/2019.html">the last year</a>, the number of applications with Ebiten has been increased. I am very grateful with that. I picked up some of them in this article.</li>
  <li lang="ja"><a href="https://ebiten.org/blog/2019.html">去年</a>と比べて、 Ebiten を使ったアプリケーションが徐々に増えてきました。大変ありがたいことです。この記事でもいくつかピックアップして紹介しています。</li>
</ul>
<h3 lang="en">December, 2019</h3>
<h3 lang="ja">2019 年 12 月</h3>

<h3 lang="en">January</h3>
<h3 lang="ja">1 月</h3>
<ul>
  <li lang="en"><a href="https://github.com/golang/go/issues/27234#issuecomment-577481562">I've finished supporting Go modules for Gomobile</a>. Gomobile is a very essential product for Ebiten, and supporting Go modules is necessary for Ebiten v2.</li>
  <li lang="ja"><a href="https://github.com/golang/go/issues/27234#issuecomment-577481562">Gomobile の Go modules 対応が完了しました</a>。 Gomobile は Ebiten にとって極めて重要なプロダクトであり、 Go modules の対応は Ebiten v2 のために必要でした。</li>
</ul>
<h3 lang="en">February</h3>
<h3 lang="ja">2 月</h3>
<ul>
  <li lang="en">I was doing an experiment to run the Go toolchains as WebAssembly. The output is in the project <a href="https://github.com/hajimehoshi/asobiba">Asobiba</a>.</li>
  <li lang="ja">Go ツールチェーンを WebAssembly として動かす実験を行っていました。成果物は <a href="https://github.com/hajimehoshi/asobiba">Asobiba</a> リポジトリにあります。</li>
</ul>
<h3 lang="en">March</h3>
<h3 lang="ja">3 月</h3>
<ul>
  <li lang="en">Started to develop <a href="https://github.com/hajimehoshi/go2dotnet">go2dotnet</a>. This is a tool to convert from Go to C# so that an Ebiten game work on <a href="https://www.monogame.net/">MonoGame</a>. With this, I planned to make Ebiten games work on consoles. Actually <a href="https://twitter.com/hajimehoshi/status/1252614478010540034">I've succeeded to make an Ebiten game work on MonoGame</a>, but the output C# was too big to convert into C++ for consoles, then <a href="https://github.com/hajimehoshi/ebiten/issues/1148">I abandoned this project</a>. Instead, I started to develop <a href="https://github.com/hajimehoshi/go2cpp">go2cpp</a> based on my experience of go2dotnet later.</li>
  <li lang="ja"><a href="https://github.com/hajimehoshi/go2dotnet">go2dotnet</a> の開発を開始。これは、 Go を C# に変換するツールで、 Ebiten のゲームを <a href="https://www.monogame.net/">MonoGame</a> で動かすことができ、家庭用ゲーム機で動かすことを目論んだものでした。実際 <a href="https://twitter.com/hajimehoshi/status/1252614478010540034">Ebiten のゲームを MonoGame 上で動かすことは出来た</a>のですが、生成される C# が巨大すぎて家庭用ゲーム機への C++ 変換がうまくいかなかったので<a href="https://github.com/hajimehoshi/ebiten/issues/1148">断念</a>しました。その代わり、 go2dotnet は後に開発する <a href="https://github.com/hajimehoshi/go2cpp">go2cpp</a> の礎となりました。</li>
</ul>
<h3 lang="en">April</h3>
<h3 lang="ja">4 月</h3>
<div>
  <div>
    <ul>
      <li lang="en">Released <a href="https://ebiten.org/documents/1.11.html">Ebiten 1.11</a>. The main feature is <code>Game</code> interface and <code>RunGame</code> function. In addition, you can develop a desktop mascot application.</li>
      <li lang="ja"><a href="https://ebiten.org/documents/1.11.html">Ebiten 1.11</a> をリリース。主な機能は <code>Game</code> インターフェイスと <code>RunGame</code> 関数です。また、デスクトップマスコットが作れるようになりました。</li>
    </ul>
  </div>
  
</div>
<h3 lang="en">May</h3>
<h3 lang="ja">5 月</h3>
<ul>
  <li lang="en">Started to develop <a href="https://github.com/hajimehoshi/go2cpp">go2cpp</a>. This tool converts Go to C++. The purpose is to make Ebiten games works on consoles.</li>
  <li lang="ja"><a href="https://github.com/hajimehoshi/go2cpp">go2cpp</a> の開発を開始。このツールは Go を C++ に変換します。目的は Ebiten のゲームを家庭用ゲーム機で動かすことです。</li>
</ul>
<h3 lang="en">June</h3>
<h3 lang="ja">6 月</h3>
<ul>
  <li lang="en">Introduced <a href="https://ebiten.org/blog/subimage.html">a breaking change</a> to make Ebiten faster.</li>
  <li lang="ja">Ebiten の高速化のために、<a href="https://ebiten.org/blog/subimage.html">破壊的変更</a>を導入しました。</li>
</ul>
<h3 lang="en">July</h3>
<h3 lang="ja">7 月</h3>

<h3 lang="en">August</h3>
<h3 lang="ja">8 月</h3>

<h3 lang="en">September</h3>
<h3 lang="ja">9 月</h3>

<h3 lang="en">October</h3>
<h3 lang="ja">10 月</h3>
<div>
  
  <div>
    <pre><code>package main

// Uniform variables.
var Time float
var Cursor vec2
var ScreenSize vec2

// Fragment is the entry point of the fragment shader.
// Fragment returns the color value for the current position.
func Fragment(position vec4, texCoord vec2, color vec4) vec4 {
	// You can define variables with a short variable declaration like Go.
	lightpos := vec3(Cursor, 50)
	lightdir := normalize(lightpos - position.xyz)
	normal := normalize(imageSrc1UnsafeAt(texCoord) - 0.5)
	ambient := 0.25
	diffuse := 0.75 * max(0.0, dot(normal.xyz, lightdir))

	// You can treat multiple source images by
	// imageSrc[N]At or imageSrc[N]UnsafeAt.
	return imageSrc0UnsafeAt(texCoord) * (ambient + diffuse)
}</code></pre>
  </div>
  
  <p><iframe width="456" height="257" src="https://www.youtube.com/embed/6r6ZH4cA41M" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
</div>  

<h3 lang="en">November</h3>
<h3 lang="ja">11 月</h3>

<h3 lang="en">December</h3>
<h3 lang="ja">12 月</h3>
<ul>
  <li lang="en">I'm now working on supporting consoles, especially Nintendo Switch. Stay tuned!</li>
  <li lang="ja">現在、家庭用ゲーム機、特に Nintendo Switch のサポートに向けて作業中です。お楽しみに!</li>
</ul>
<h2 lang="en">Ebiten in 2021 and after</h2>
<h2 lang="ja">2021 年以降の Ebiten</h2>
<ul>
  <li lang="en">The highest priority task is supporting consoles, especially Nintendo Switch (<a href="https://github.com/hajimehoshi/ebiten/issues/744">Issue 744</a>). I believe this can be done with <a href="https://github.com/hajimehoshi/go2cpp">go2cpp</a>. Due to NDA, I cannot make the work open, but I'd like to release an Ebiten game for Nintendo Switch some day.</li>
  <li lang="ja">最もプライオリティの高いタスクは家庭用ゲーム機、特に Nintendo Switch のサポートです (<a href="https://github.com/hajimehoshi/ebiten/issues/744">Issue 744</a>)。 <a href="https://github.com/hajimehoshi/go2cpp">go2cpp</a> を使って実現可能であると信じています。 NDA の問題があり、成果物は公開できないのですが、いつか Nintendo Switch 向けの Ebiten ゲームをリリースしたいと考えています。</li>
  <li lang="en">The other thing I am interested in is supporting UI (<a href="https://github.com/hajimehoshi/ebiten/issues/1029">Issue 1029</a>). I think that supporting a native text input would be useful.</li>
  <li lang="ja">その他興味があるのは UI のサポートです。ネイティブでテキスト入力ができるようになると便利であると考えています (<a href="https://github.com/hajimehoshi/ebiten/issues/1029">Issue 1029</a>)。</li>
</ul>

      </article></div>]]>
            </description>
            <link>https://ebiten.org/blog/2020.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25429375</guid>
            <pubDate>Tue, 15 Dec 2020 11:47:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Europe adopts resolution on security through and “security despite” encryption]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25429373">thread link</a>) | @azalemeth
<br/>
December 15, 2020 | https://www.consilium.europa.eu/en/press/press-releases/2020/12/14/encryption-council-adopts-resolution-on-security-through-encryption-and-security-despite-encryption/# | <a href="https://web.archive.org/web/*/https://www.consilium.europa.eu/en/press/press-releases/2020/12/14/encryption-council-adopts-resolution-on-security-through-encryption-and-security-despite-encryption/#">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            

        <div>
            
    
    <figure>
        
    </figure>

    <p><small>Council adopts resolution on encryption</small></p>


        </div>

    




<p>The Council today adopted a resolution on encryption, highlighting the need for security through encryption and security despite encryption.</p>
<p>In this resolution, the Council underlines its support for the development, implementation and use of strong encryption as a necessary means of protecting fundamental rights and the digital security of citizens, governments, industry and society. At the same time, the Council notes the need to ensure that competent law enforcement and judicial authorities are able to exercise their legal powers, both online and offline, to protect our societies and citizens.</p>
<p>Law enforcement authorities and the judiciary are increasingly dependent on access to electronic evidence to effectively fight terrorism, organised crime, child sexual abuse, and a range of other cybercrime and cyber-enabled crimes. Such access is essential to the success of law enforcement and criminal justice in cyberspace. However, there are instances where encryption renders access to and analysis of evidence extremely challenging or impossible in practice.</p>
<p>The EU is striving to establish an active discussion with the technology industry, and with close involvement from research, academia, industry, civil society and other stakeholders, so as to strike the right balance between ensuring the continued use of strong encryption technology and guaranteeing the powers of law enforcement and the judiciary to operate on the same terms as in the offline world. Potential technical solutions will need to respect privacy and fundamental rights, and preserve the value that technological progress brings to society.</p>

    
        <ul>
                <li>
                        <a href="https://data.consilium.europa.eu/doc/document/ST-13084-2020-REV-1/en/pdf" rel="nofollow" title="PDF document - Security through encryption and security despite encryption - Council resolution on encryption">Security through encryption and security despite encryption - Council resolution on encryption</a>
                </li>
        </ul>























            

            


        </div></div>]]>
            </description>
            <link>https://www.consilium.europa.eu/en/press/press-releases/2020/12/14/encryption-council-adopts-resolution-on-security-through-encryption-and-security-despite-encryption/#</link>
            <guid isPermaLink="false">hacker-news-small-sites-25429373</guid>
            <pubDate>Tue, 15 Dec 2020 11:47:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ethical Programming – Is It Worth It?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25428862">thread link</a>) | @todsacerdoti
<br/>
December 15, 2020 | https://pragmaticpineapple.com/ethical-programming-is-it-worth-it/ | <a href="https://web.archive.org/web/*/https://pragmaticpineapple.com/ethical-programming-is-it-worth-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><span>
      <span></span>
  <img alt="Charts and trends" title="Charts and trends" src="https://pragmaticpineapple.com/static/c97c5bfa5a063bca20ed4701b885532b/1c72d/cover.jpg" srcset="https://pragmaticpineapple.com/static/c97c5bfa5a063bca20ed4701b885532b/a80bd/cover.jpg 148w,
https://pragmaticpineapple.com/static/c97c5bfa5a063bca20ed4701b885532b/1c91a/cover.jpg 295w,
https://pragmaticpineapple.com/static/c97c5bfa5a063bca20ed4701b885532b/1c72d/cover.jpg 590w,
https://pragmaticpineapple.com/static/c97c5bfa5a063bca20ed4701b885532b/a8a14/cover.jpg 885w,
https://pragmaticpineapple.com/static/c97c5bfa5a063bca20ed4701b885532b/fbd2c/cover.jpg 1180w,
https://pragmaticpineapple.com/static/c97c5bfa5a063bca20ed4701b885532b/06c2a/cover.jpg 4062w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>

<p>The software has poured into almost all areas of our lives throughout the
years. It remembers phone numbers of our loved ones, it finds the best route to
a well-reviewed restaurant we want to eat in, and many many more things. This
ever-presence of software engineering in our day-to-day things brings all
kinds of questions on what is ethical and what is not.</p>
<p>The topic of ethics is significant for us programmers (developers) who
produce living and breathing pieces of code every day. Those pieces of code can
change and affect other people’s lives. So, is being ethical in your work worth
it? And what to do when presented with questionable requirements from your
superiors?</p>
<p>These are all hard questions and topics, but let’s try to break them together.</p>
<h2 id="to-bully-or-to-be-bullied"><a href="#to-bully-or-to-be-bullied" aria-label="to bully or to be bullied permalink"></a>To Bully, or To Be Bullied</h2>
<p>I recently came about a tweet where a company was being called out for planning
to build features that would do surveillance on their users. Here’s the <a href="https://twitter.com/dhh/status/1336266946044686337">tweet</a>:</p>
<blockquote><p lang="en" dir="ltr">The surveillance regime marches on. This is Clockify promising a road map of ever-more oppressive and dehumanizing tracking of employees. If we're just being HONEST here, I'd like to see this blown into a million bits. Source code encrypted and the key lost. Just awful. <a href="https://t.co/OfnjKn6dDp">https://t.co/OfnjKn6dDp</a></p>— DHH (@dhh) <a href="https://twitter.com/dhh/status/1336266946044686337?ref_src=twsrc%5Etfw">December 8, 2020</a></blockquote> 
<p>A company named Clockify, which provides time-tracking features to their users,
exposed a road-map where they will do screenshots and GPS tracking of their
users. Of course, somebody took the picture in the tweet out of context. The
idea was to provide these features to only some portion of their users who
would pay for them. I am not saying it to justify the features they
are adding, just trying to put more context into the conversation.</p>
<p>Of course, the idea of watching over someone while they work is appalling to me,
and I would never work or run a company that does this. What’s more
intriguing to me is the dilemma of what do you do when you work for such a company. We will
always have some persona on social media that will bash the shit out
of ideas like user surveillance, but what can a ground-level developer like
you and me do in this situation?</p>
<p><span>
      <span></span>
  <img alt="Screw you, guys, I'm going home" title="Screw you, guys, I'm going home" src="https://pragmaticpineapple.com/static/39c18535a1cadba7dc8fb1f5eab0bab6/1c72d/screw-you.jpg" srcset="https://pragmaticpineapple.com/static/39c18535a1cadba7dc8fb1f5eab0bab6/a80bd/screw-you.jpg 148w,
https://pragmaticpineapple.com/static/39c18535a1cadba7dc8fb1f5eab0bab6/1c91a/screw-you.jpg 295w,
https://pragmaticpineapple.com/static/39c18535a1cadba7dc8fb1f5eab0bab6/1c72d/screw-you.jpg 590w,
https://pragmaticpineapple.com/static/39c18535a1cadba7dc8fb1f5eab0bab6/a8a14/screw-you.jpg 885w,
https://pragmaticpineapple.com/static/39c18535a1cadba7dc8fb1f5eab0bab6/6a068/screw-you.jpg 960w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>
<p>Let’s say you work in that company, and someone asked you to build a feature that
tracks what users do on their computers. Would you stand up and say a hard ‘no’
to the management? Or, would you nod your head and leave a 👍 reaction.
Answering this question is hard. But to make it a bit easier, I would like to
remind you that even as an engineer, you can be held accountable, even though
you are not the ‘mastermind’ behind all of it.</p>
<p>I’m not trying to scare you or anything, but did you know that Volkswagen’s
engineer got sentenced to more than three years in prison for being involved in a
scheme that allowed VW to sell diesel cars that generated more pollution than
it was allowed? You can read all about it <a href="https://www.reuters.com/article/us-volkswagen-emissions-sentencing/vw-engineer-sentenced-to-40-month-prison-term-in-diesel-case-idUSKCN1B51YP">here</a>.
You decide if it was worth it for that guy.</p>
<h2 id="taking-the-oath"><a href="#taking-the-oath" aria-label="taking the oath permalink"></a>Taking the oath</h2>
<p>No matter what job you do as a developer. You had to start somewhere. Some
folks took the university route. Some did the online courses at
home and honed their craft. But no matter what you did, rarely anyone had a
class or a course to them a thing or two about ethics.</p>
<p>In other professions, such as have their documents with core values and
standards. The most famous one is, of course, the Hippocratic oath medical
doctors need to take. Doctors promise to care responsibly for their patients
and learn ethics as part of their education. It is crucial for doctor’s
patients to feel confident that the doctor has their best interest at heart.</p>
<p>We should have something similar in our line of work but applied
more often. There are a couple of examples where people put together documents
that describe what ethics for software engineers is. For example, the world’s
largest educational and scientific computing society - ACM - has a
<a href="https://www.acm.org/code-of-ethics">Code of Ethics and Professional Conduct</a>.
Check it out, it is an interesting read.</p>
<p>I am not saying that enforcing all computing professionals to take some oath
will drop the surveillance or other unethical software to drop to
zero. People will try to go out of the way whatever we do. What we need to do
instead is to teach about ethics in computer science <strong>more</strong> since our actions
can impact the world more than ever.</p>
<h2 id="field-studies"><a href="#field-studies" aria-label="field studies permalink"></a>Field studies</h2>
<p>An interesting thing I found is that StackOverflow asked a couple of questions
about ethics in 2018 (now two years ago). It turns out that most of the developers
(58.5% to be precise) back then said that they would refuse to write code for
an unethical purpose. Also, a huge portion (almost 80%) said that developers have an
obligation to consider the ethical implications of their code, which is relieving.</p>
<p>Alongside these numbers of ethics awareness, there were a lot of ethical grays.
Devs are not entirely sure who would they report ethical problems. Furthermore,
developers think differently about who is ultimately responsible
for the unethical code. Right there, in those two spots, I see a lot of room for
improvement. There is potential to educate companies and teams and have go-to
persons to report unethical claims in establishments.</p>
<p>I wonder how the survey would perform if the same questions get asked this year. If
you’re interested in the survey, you can check it out
<a href="https://insights.stackoverflow.com/survey/2018/#ethics">on StackOverflow here</a>.</p>
<h2 id="so-is-it-worth-it"><a href="#so-is-it-worth-it" aria-label="so is it worth it permalink"></a>So, is it worth it?</h2>
<p>Well, it depends on who you ask. If you are a person responsible for a company’s income,
your best interest is to see trends on charts go in the upwards
direction. How you do it, it might now be the most ethical way, but you are
still crushing it. Or are you?</p>
<p><span>
      <span></span>
  <img alt="Random chart" title="Random chart" src="https://pragmaticpineapple.com/static/eea6a884861dac2a0650ddcec764face/fcda8/random-chart.png" srcset="https://pragmaticpineapple.com/static/eea6a884861dac2a0650ddcec764face/12f09/random-chart.png 148w,
https://pragmaticpineapple.com/static/eea6a884861dac2a0650ddcec764face/e4a3f/random-chart.png 295w,
https://pragmaticpineapple.com/static/eea6a884861dac2a0650ddcec764face/fcda8/random-chart.png 590w,
https://pragmaticpineapple.com/static/eea6a884861dac2a0650ddcec764face/8c557/random-chart.png 700w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>
<p>I am going back to the example of the Clockify (or Hubstaff, or any other time-tracking)
product. The new features that go over the ethics will probably be the most
expensive ones, and could provide more profit for the company. Is that a good
thing? Not always, I believe. If you’re chasing to increase those fancy
acronyms (ARR and MRR) and do not care about the ethics (and the world) - then
I think it is not a good thing.</p>
<p>Yes, the income will come quicker, but the broader impact on the world can be
detrimental. Imagine if all the time-tracking companies will slowly move to
this approach and that surveillance will become the norm in these apps.</p>
<p>So, in the end, no, I <strong>do think being ethical in your work is worth it</strong>. Maybe
not in a quantifiable way or in a way where you can plot a chart and show it to
your manager. Definitely, the actions you decide to take or not to take can
impact those around you. I feel that the fact that we can influence other
people’s lives is something we, as programmers, often overlook. And we shouldn’t
do that, because what’s most important to remember is that we are all in this
together.</p>
<h2 id="action-points"><a href="#action-points" aria-label="action points permalink"></a>Action points</h2>
<p>Where to go now? I recommend reading or going through a couple of resources here:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Programming_ethics">Programming ethics on Wikipedia</a> - provides a good summary</li>
<li><a href="https://www.acm.org/code-of-ethics">ACM Code of Ethics</a> - in-depth example of an ethics code</li>
<li><a href="https://www.goodreads.com/book/show/10284614-the-clean-coder">The Clean Coder: A Code of Conduct for Professional Programmers</a> - great book overall</li>
<li><a href="https://simpleprogrammer.com/ethical-programming-professional/">What It Takes To Be an Ethical Programming Professional</a> - an insightful blog post</li>
<li>If going through an online course is your thing, maybe try one of those</li>
</ul>
<p>Remember, being ethical won’t be easy, and it won’t look great at times. The
most critical takeaway from this post is to spend time to set up your ethical
boundaries. From then on, it is easier to have conversations and ask questions
like - “is this in the best interest of our users?” and “how does this affect
our organization’s reputation?“.</p>
<p>I hope this post brought some insight or, at least, reminded you that something
like ethics still exists in our profession. If you like topics like these,
consider <a href="https://pragmaticpineapple.com/newsletter">subscribing to the newsletter</a>.</p>
<p>Also, you can discuss and share this post on Twitter with friends and coworkers:</p>
<blockquote><div lang="en" dir="ltr"><p>A new blog post about ethics 🧑‍⚕️</p><p>Were you ever asked to do something unethical at your work?<a href="https://t.co/XzicHONt1A">https://t.co/XzicHONt1A</a></p></div>— Nikola Đuza (@nikolalsvk) <a href="https://twitter.com/nikolalsvk/status/1338783494118518784?ref_src=twsrc%5Etfw">December 15, 2020</a></blockquote> 
<p>Until the next one, cheers!</p></section></div>]]>
            </description>
            <link>https://pragmaticpineapple.com/ethical-programming-is-it-worth-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25428862</guid>
            <pubDate>Tue, 15 Dec 2020 10:24:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minimal safe Bash script template]]>
            </title>
            <description>
<![CDATA[
Score 479 | Comments 259 (<a href="https://news.ycombinator.com/item?id=25428621">thread link</a>) | @signa11
<br/>
December 15, 2020 | https://betterdev.blog/minimal-safe-bash-script-template/ | <a href="https://web.archive.org/web/*/https://betterdev.blog/minimal-safe-bash-script-template/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Bash scripts. Almost anyone needs to write one sooner or later. Almost no one says “yeah, I love writing them”. And that’s why almost everyone is putting low attention while writing them.</p>



<p>I won’t try to make you a Bash expert (since I’m not a one either), but I will show you a minimal template that will make your scripts safer. You don’t need to thank me, your future self will thank you.</p>



<h2><span id="why_scripting_in_bash"></span>Why scripting in Bash?<span></span></h2>



<p>The best summary of Bash scripting appeared recently on my Twitter feed:</p>



<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>The opposite of "it's like riding a bike" is "it's like programming in bash".</p><p>A phrase which means that no matter how many times you do something, you will have to re-learn it every single time.</p></div>— Jake Wharton (@JakeWharton) <a href="https://twitter.com/JakeWharton/status/1334177665356587008?ref_src=twsrc%5Etfw">December 2, 2020</a></blockquote>
</div></figure>



<p>But Bash has something in common with another widely beloved language. Just like JavaScript, it won’t go away easily. While we can hope that Bash won’t become the main language for literally everything, it’s always somewhere near.</p>



<p>Bash <a href="https://www.quora.com/Is-Bash-considered-the-lingua-franca-of-shells/answer/Paul-Reiber">inherited the shell throne</a> and can be found on almost every Linux, including Docker images. And this is the environment in which most of the backend runs. So if you need to script the server application startup, a CI/CD step, or integration test run, Bash is there for you.</p>



<p>To glue few commands together, pass output from one to another, and just start some executable, Bash is the easiest and most native solution. While it makes perfect sense to write bigger, more complicated scripts in other languages, you can’t expect to have Python, Ruby, fish, or whatever another interpreter you believe is the best, available everywhere. And you probably should think twice and then once more before adding it to some prod server, Docker image, or CI environment.</p>



<p>Yet Bash is far from perfect. The syntax is a nightmare. Error handling is difficult. There are landmines everywhere. And we have to deal with it.</p>



<h2><span id="bash_script_template"></span>Bash script template<span></span></h2>



<p>Without further ado, here it is.</p>



<pre><code>#!/usr/bin/env bash

set -Eeuo pipefail
trap cleanup SIGINT SIGTERM ERR EXIT

script_dir=$(cd "$(dirname "${BASH_SOURCE[0]}")" &amp;&gt;/dev/null &amp;&amp; pwd -P)

usage() {
  cat &lt;&lt;EOF
Usage: $(basename "${BASH_SOURCE[0]}") [-h] [-v] [-f] -p param_value arg1 [arg2...]

Script description here.

Available options:

-h, --help      Print this help and exit
-v, --verbose   Print script debug info
-f, --flag      Some flag description
-p, --param     Some param description
EOF
  exit
}

cleanup() {
  trap - SIGINT SIGTERM ERR EXIT
  # script cleanup here
}

setup_colors() {
  if [[ -t 2 ]] &amp;&amp; [[ -z "${NO_COLOR-}" ]] &amp;&amp; [[ "${TERM-}" != "dumb" ]]; then
    NOFORMAT='\033[0m' RED='\033[0;31m' GREEN='\033[0;32m' ORANGE='\033[0;33m' BLUE='\033[0;34m' PURPLE='\033[0;35m' CYAN='\033[0;36m' YELLOW='\033[1;33m'
  else
    NOFORMAT='' RED='' GREEN='' ORANGE='' BLUE='' PURPLE='' CYAN='' YELLOW=''
  fi
}

msg() {
  echo &gt;&amp;2 -e "${1-}"
}

die() {
  local msg=$1
  local code=${2-1} # default exit status 1
  msg "$msg"
  exit "$code"
}

parse_params() {
  # default values of variables set from params
  flag=0
  param=''

  while :; do
    case "${1-}" in
    -h | --help) usage ;;
    -v | --verbose) set -x ;;
    --no-color) NO_COLOR=1 ;;
    -f | --flag) flag=1 ;; # example flag
    -p | --param) # example named parameter
      param="${2-}"
      shift
      ;;
    -?*) die "Unknown option: $1" ;;
    *) break ;;
    esac
    shift
  done

  args=("$@")

  # check required params and arguments
  [[ -z "${param-}" ]] &amp;&amp; die "Missing required parameter: param"
  [[ ${#args[@]} -eq 0 ]] &amp;&amp; die "Missing script arguments"

  return 0
}

parse_params "$@"
setup_colors

# script logic here

msg "${RED}Read parameters:${NOFORMAT}"
msg "- flag: ${flag}"
msg "- param: ${param}"
msg "- arguments: ${args[*]-}"</code></pre>



<p>The idea was to not make it too long. I don’t want to scroll 500 lines to the script logic. At the same time, I want some strong foundations for any script. But Bash is not making this easy, lacking any form of dependencies management.</p>



<p>One solution would be to have a separate script with all the boilerplate and utility functions and execute it at the beginning. The downside would be to have to always attach this second file everywhere, losing the “simple Bash script” idea along the way. So I decided to put in the template only what I consider to be a minimum to keep it possible short.</p>



<p>Now let’s look at it in more detail.</p>



<h3><span id="choose_bash"></span>Choose Bash<span></span></h3>



<pre><code>#!/usr/bin/env bash</code></pre>



<p>Script traditionally starts with a shebang. For the <a href="https://stackoverflow.com/questions/21612980/why-is-usr-bin-env-bash-superior-to-bin-bash">best compatibility</a>, it references <code>/usr/bin/env</code>, not the <code>/bin/bash</code> directly. Although, if you read comments in the linked StackOverflow question, even this can fail sometimes.</p>



<h3><span id="fail_fast"></span>Fail fast<span></span></h3>



<pre><code>set -Eeuo pipefail</code></pre>



<p>The <code>set</code> command changes script execution options. For example, <strong>normally Bash does not care if some command failed</strong>, returning a non-zero exit status code. It just happily jumps to the next one. Now consider this little script:</p>



<pre><code>#!/usr/bin/env bash
cp important_file ./backups/
rm important_file</code></pre>



<p>What will happen, if the <code>backups</code> directory does not exist? Exactly, you will get an error message in the console, but before you will be able to react, the file will be already removed by the second command.</p>



<p>For details on what options exactly <code>set -Eeuo pipefail</code> changes and how they will protect you, I refer you to the <a href="https://vaneyckt.io/posts/safer_bash_scripts_with_set_euxo_pipefail/">article I have in my bookmarks for a few years now</a>.</p>



<p>Although you should know that there are some <a href="https://www.reddit.com/r/commandline/comments/g1vsxk/the_first_two_statements_of_your_bash_script/fniifmk?utm_source=share&amp;utm_medium=web2x&amp;context=3">arguments against setting those options</a>.</p>



<h3><span id="get_the_location"></span>Get the location<span></span></h3>



<pre><code>script_dir=$(cd "$(dirname "${BASH_SOURCE[0]}")" &amp;&gt;/dev/null &amp;&amp; pwd -P)</code></pre>



<p>This line <a href="https://stackoverflow.com/a/246128/2512304">does its best</a> to define the script’s location directory<s>, and then we <code>cd</code> to it. Why?</s></p>



<p>Often our scripts are operating on paths relative to the script location, copying files and executing commands, assuming the script directory is also a working directory. And it is, as long as we execute the script from its directory.</p>



<p>But if, let’s say, our CI config executes script like this:</p>



<pre><code>/opt/ci/project/script.sh</code></pre>



<p>then our script is operating not in project dir, but some completely different workdir of our CI tool. We can fix it, by going to the directory before executing the script:</p>



<pre><code>cd /opt/ci/project &amp;&amp; ./script.sh</code></pre>



<p>But it’s much nicer to solve this on the script side. So, if the script reads some file or executes another program from the same directory, call it like this:</p>



<pre><code>cat "$script_dir/my_file"</code></pre>



<p>At the same time, the script does not change the workdir location. If the script is executed from some other directory and the user provides a relative path to some file, we will still be able to read it.</p>



<h3><span id="try_to_clean_up"></span>Try to clean up<span></span></h3>



<pre><code>trap cleanup SIGINT SIGTERM ERR EXIT

cleanup() {
  trap - SIGINT SIGTERM ERR EXIT
  # script cleanup here
}</code></pre>



<p>Think about the <code>trap</code> like of a <code>finally</code> block for the script. At the end of the script – normal, caused by an error or an external signal – the <code>cleanup()</code> function will be executed. This is a place where you can, for example, try to remove all temporary files created by the script.</p>



<p>Just remember that the <code>cleanup()</code> can be called not only at the end but as well having the script done any part of the work. Not necessarily all the resources you try to cleanup will exist.</p>



<h3><span id="display_helpful_help"></span>Display helpful help<span></span></h3>



<pre><code>usage() {
  cat &lt;&lt;EOF
Usage: $(basename "${BASH_SOURCE[0]}") [-h] [-v] [-f] -p param_value arg1 [arg2...]

Script description here.

...
EOF
  exit
}</code></pre>



<p>Having the <code>usage()</code> relatively close to the top of the script, it will act in two ways:</p>



<ul><li>to <strong>display help</strong> for someone who does not know all the options and does not want to go over the whole script to discover them,</li><li>as a <strong>minimal documentation</strong> when someone modifies the script (for example you, 2 weeks later, not even remembering writing it in the first place).</li></ul>



<p>I don’t argue to document every function here. But a short, nice script usage message is a required minimum.</p>



<h3><span id="print_nice_messages"></span>Print nice messages<span></span></h3>



<pre><code>setup_colors() {
  if [[ -t 2 ]] &amp;&amp; [[ -z "${NO_COLOR-}" ]] &amp;&amp; [[ "${TERM-}" != "dumb" ]]; then
    NOFORMAT='\033[0m' RED='\033[0;31m' GREEN='\033[0;32m' ORANGE='\033[0;33m' BLUE='\033[0;34m' PURPLE='\033[0;35m' CYAN='\033[0;36m' YELLOW='\033[1;33m'
  else
    NOFORMAT='' RED='' GREEN='' ORANGE='' BLUE='' PURPLE='' CYAN='' YELLOW=''
  fi
}

msg() {
  echo &gt;&amp;2 -e "${1-}"
}</code></pre>



<p>Firstly, remove the <code>setup_colors()</code> function if you don’t want to use colors in text anyway. I keep it because I know I would use colors more often if I wouldn’t have to google codes for them every time.</p>



<p>Secondly, those <strong>colors are meant to be used with the <code>msg()</code> function only</strong>, not with the <code>echo</code> command.</p>



<p>The <strong><code>msg()</code> function is meant to be used to print everything that is not a script output</strong>. This includes all logs and messages, not only the errors. Citing the great <a href="https://medium.com/@jdxcode/12-factor-cli-apps-dd3c227a0e46">12 Factor CLI Apps</a> article:</p>



<blockquote><p><strong>In short: stdout is for output, stderr is for messaging.</strong></p><cite><a href="https://jdxcode.com/">Jeff Dickey</a>, who <a href="https://github.com/oclif/oclif/graphs/contributors">knows a little</a> about <a href="https://github.com/heroku/cli/graphs/contributors">building CLI apps</a></cite></blockquote>



<p>That’s why in most cases you shouldn’t use colors for <code>stdout</code> anyway.</p>



<p>Messages printed with <code>msg()</code> are sent to <code>stderr</code> stream and support special sequences, like colors. And colors are disabled anyway if the <code>stderr</code> output is not an interactive terminal or&nbsp;<a target="_blank" href="https://no-color.org/" rel="noreferrer noopener">one of the standard parameters</a>&nbsp;is passed.</p>



<p>Usage:</p>



<pre><code>msg "This is a ${RED}very important${NOFORMAT} message, but not a script output value!"</code></pre>



<p>To check how it behaves when the <code>stderr</code> is not an interactive terminal, add a line like above to the script. Then execute it redirecting <code>stderr</code> to <code>stdout</code> and piping it to <code>cat</code>. Pipe operation makes the output no longer being sent directly to the terminal, but to the next command, so the colors should be disabled now.</p>



<pre><code>$ ./test.sh 2&gt;&amp;1 | cat
This is a very important message, but not a script output value!</code></pre>



<h3><span id="parse_any_parameters"></span>Parse any parameters<span></span></h3>



<pre><code>parse_params() {
  # default values of variables set from params
  flag=0
  param=''

  while :; do
    case "${1-}" in
    -h | --help) usage ;;
    -v | --verbose) set -x ;;
    --no-color) NO_COLOR=1 ;;
    -f | --flag) flag=1 ;; # example flag
    -p | --param) # …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://betterdev.blog/minimal-safe-bash-script-template/">https://betterdev.blog/minimal-safe-bash-script-template/</a></em></p>]]>
            </description>
            <link>https://betterdev.blog/minimal-safe-bash-script-template/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25428621</guid>
            <pubDate>Tue, 15 Dec 2020 09:45:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Writing SQL expressions using Java syntax]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25428589">thread link</a>) | @objsql
<br/>
December 15, 2020 | http://www.objsql.com/t6 | <a href="https://web.archive.org/web/*/http://www.objsql.com/t6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="readme">
    
        

      <div>
        <article itemprop="text"><p>ObjectiveSQL is an ORM framework in Java based on ActiveRecord pattern, which encourages rapid development and clean, codes with the least, and convention over configuration.</p>
<h3>Features</h3>
<ul>
<li>With one annotation your <code>Class</code> has fully featured capabilities of SQL programming</li>
<li>Easy to relational(<code>has_one</code>, <code>has_many</code> and <code>belongs_to</code>) query and paged query</li>
<li>Writing SQL expressions(<code>arithmetic</code>, <code>comparison</code> and <code>logical</code>) using Java syntax</li>
</ul>
<h3>Installation</h3>
<h4>IntelliJ IDEA plugin installation</h4>
<p><code>Preferences/Settings</code> -&gt; <code>Plugins</code> -&gt; <code>Search with "ObjectiveSql" in market</code> -&gt; <code>Install</code></p>
<h4>Maven dependencies</h4>
<div><pre><span><span>&lt;!--</span> In standalone <span>--&gt;</span></span>
&lt;<span>dependency</span>&gt;
    &lt;<span>groupId</span>&gt;com.github.braisdom&lt;/<span>groupId</span>&gt;
    &lt;<span>artifactId</span>&gt;objective-sql&lt;/<span>artifactId</span>&gt;
    &lt;<span>version</span>&gt;1.4.3&lt;/<span>version</span>&gt;
&lt;/<span>dependency</span>&gt;</pre></div>
<div><pre><span><span>&lt;!--</span> In Spring Boot <span>--&gt;</span></span>
&lt;<span>dependency</span>&gt;
  &lt;<span>groupId</span>&gt;com.github.braisdom&lt;/<span>groupId</span>&gt;
  &lt;<span>artifactId</span>&gt;objsql-springboot&lt;/<span>artifactId</span>&gt;
  &lt;<span>version</span>&gt;1.3.1&lt;/<span>version</span>&gt;
&lt;/<span>dependency</span>&gt;</pre></div>
<p>Refer to the <a href="https://github.com/braisdom/ObjectiveSql/blob/master/examples/mysql/pom.xml#L67">pom.xml</a> for more configuration</p>
<h3>Examples</h3>
<p>ObjectiveSQL provides full example for various databases below, You can open it directly with IntelliJ IDEA as a standalone project. In fact, they are not just examples, but also unit tests of ObjectiveSQL in various databases.</p>
<p>If you want to run without configuration, you can try: <a href="https://github.com/braisdom/ObjectiveSql/tree/master/examples/sqlite">SQLite</a></p>
<p>Others: <a href="https://github.com/braisdom/ObjectiveSql/tree/master/examples/mysql">MySQL</a>,  <a href="https://github.com/braisdom/ObjectiveSql/tree/master/examples/oracle">Oracle</a>,  <a href="https://github.com/braisdom/ObjectiveSql/tree/master/examples/sqlserver">MS SQL Server</a>, <a href="https://github.com/braisdom/ObjectiveSql/tree/master/examples/postgres">PostgreSQL</a>,  <a href="https://github.com/braisdom/ObjectiveSql/tree/master/examples/springboot-sample">Spring Boot</a></p>
<h3>Simple SQL programming without coding</h3>
<blockquote>
<p>You define just a JavaBean with one annotation</p>
</blockquote>
<div><pre><span>@DomainModel</span>
<span>public</span> <span>class</span> <span>Member</span> {
    <span>private</span> <span>String</span> no;
    
    <span>@Queryable</span>
    <span>private</span> <span>String</span> name;
    <span>private</span> <span>Integer</span> gender;
    <span>private</span> <span>String</span> mobile;
    <span>private</span> <span>String</span> otherInfo;

    <span>@Relation</span>(<span>relationType</span> <span>=</span> <span>RelationType</span><span><span>.</span>HAS_MANY</span>)
    <span>private</span> <span>List&lt;<span>Order</span>&gt;</span> orders;
}</pre></div>
<h4>Persistence</h4>
<div><pre><span>Member</span><span>.</span>create(newMember);
<span>Member</span><span>.</span>create(<span>new</span> <span>Member</span>[]{newMember1, newMember2, newMember3}, <span>false</span>);

<span>Member</span><span>.</span>update(<span>1L</span>, newMember, <span>true</span>);
<span>Member</span><span>.</span>update(<span><span>"</span>name = 'Smith =&gt; Jackson'<span>"</span></span>, <span><span>"</span>name = ?<span>"</span></span>, <span><span>"</span>Alice<span>"</span></span>);

<span>Member</span><span>.</span>destroy(<span>1L</span>);
<span>Member</span><span>.</span>destroy(<span><span>"</span>name = ?<span>"</span></span>, <span><span>"</span>Mary<span>"</span></span>);</pre></div>
<h4>Counting and querying</h4>
<div><pre><span>Member</span><span>.</span>countAll();
<span>Member</span><span>.</span>count(<span><span>"</span>id &gt; ?<span>"</span></span>, <span>1</span>);
<span>Member</span><span>.</span>queryByPrimaryKey(<span>1</span>);
<span>Member</span><span>.</span>queryFirst(<span><span>"</span>id = ?<span>"</span></span>, <span>1</span>);
<span>Member</span><span>.</span>query(<span><span>"</span>id &gt; ?<span>"</span></span>, <span>1</span>);
<span>Member</span><span>.</span>queryAll();</pre></div>
<h4>Paged querying</h4>
<div><pre><span>Page</span> page <span>=</span> <span>Page</span><span>.</span>create(<span>0</span>, <span>10</span>);
<span>PagedList&lt;<span>Member</span>&gt;</span> members <span>=</span> <span>Member</span><span>.</span>pagedQueryAll(page, <span>Member</span><span><span>.</span>HAS_MANY_ORDERS</span>);</pre></div>
<h4>Relation querying</h4>
<div><pre><span>Member</span><span>.</span>queryAll(<span>Member</span><span><span>.</span>HAS_MANY_ORDERS</span>);
<span>Member</span><span>.</span>queryByPrimary(<span>1</span>, <span>Member</span><span><span>.</span>HAS_MANY_ORDERS</span>);
<span>Member</span><span>.</span>queryByName(<span><span>"</span>demo<span>"</span></span>, <span>Member</span><span><span>.</span>HAS_MANY_ORDERS</span>);
<span>...</span></pre></div>
<h3>Complex SQL programming</h3>
<div><pre><span>Order</span><span>.</span><span>Table</span> orderTable <span>=</span> <span>Order</span><span>.</span>asTable();
<span>Select</span> select <span>=</span> <span>new</span> <span>Select</span>();

<span><span>//</span> In ObjectiveSQL, Java operator can be overloaded</span>
select<span>.</span>project(sum(orderTable<span>.</span>amount) <span>/</span> sum(orderTable<span>.</span>quantity) <span>*</span> <span>100</span>)
        .from(orderTable)
        .where(orderTable<span>.</span>quantity <span>&gt;</span> <span>30</span> <span>&amp;&amp;</span>
            orderTable<span>.</span>salesAt<span>.</span>between(<span><span>"</span>2020-10-10 00:00:00<span>"</span></span>, <span><span>"</span>2020-10-30 23:59:59<span>"</span></span>))
        .groupBy(orderTable<span>.</span>productId);</pre></div>
<div><pre><span>SELECT</span> <span>SUM</span>(<span><span>`</span>T0<span>`</span></span>.<span><span>`</span>amount<span>`</span></span>) <span>/</span> <span>SUM</span>(<span><span>`</span>T0<span>`</span></span>.<span><span>`</span>quantity<span>`</span></span>) <span>*</span> <span>100</span>
<span>FROM</span> <span><span>`</span>orders<span>`</span></span> <span>AS</span> <span><span>`</span>T0<span>`</span></span>
<span>WHERE</span> <span><span>`</span>T0<span>`</span></span>.<span><span>`</span>quantity<span>`</span></span> <span>&gt;</span> <span>30</span> <span>AND</span> 
       <span><span>`</span>T0<span>`</span></span>.<span><span>`</span>sales_at<span>`</span></span> BETWEEN <span><span>'</span>2020-10-10 00:00:00<span>'</span></span> <span>AND</span> <span><span>'</span>2020-10-30 23:59:59<span>'</span></span>)
<span>GROUP BY</span> <span><span>`</span>T0<span>`</span></span>.<span><span>`</span>product_id<span>`</span></span></pre></div>
<h3>Reference documentation</h3>
<ul>
<li><a href="https://github.com/braisdom/ObjectiveSql/wiki/ObjectiveSQL-Tutorial">English</a></li>
<li><a href="https://github.com/braisdom/ObjectiveSql/wiki/ObjectiveSQL-%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97">Chinese(中文)</a></li>
</ul>
</article>
      </div>
  </div></div>]]>
            </description>
            <link>http://www.objsql.com/t6</link>
            <guid isPermaLink="false">hacker-news-small-sites-25428589</guid>
            <pubDate>Tue, 15 Dec 2020 09:38:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exhaustiveness Checking with Mypy]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25428583">thread link</a>) | @rbanffy
<br/>
December 15, 2020 | https://hakibenita.com/python-mypy-exhaustive-checking | <a href="https://web.archive.org/web/*/https://hakibenita.com/python-mypy-exhaustive-checking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-progress-indicator="">
        <hr>
<p><a href="https://mypy-lang.org/" rel="noopener">Mypy</a> is an optional static type checker for Python. It's been around since 2012 and is gaining traction even since. One of the main benefits of using a type checker is getting errors at "compile time" rather than at run time.</p>
<p>Exhaustiveness checking is a common feature of type checkers, and a very useful one! In this article I'm going to show you <strong>how you can get mypy to perform exhaustiveness checking!</strong></p>
<figure><img alt="Playing cards are also useful for explaining enumeration types...<br><small>Photo by <a href=&quot;https://unsplash.com/photos/G6wlppP4EN8&quot;>Daniel Rykhev</a></small>" src="https://hakibenita.com/images/01-python-mypy-exhaustive-checking.png"><figcaption>Playing cards are also useful for explaining enumeration types...<br><small>Photo by <a href="https://unsplash.com/photos/G6wlppP4EN8">Daniel Rykhev</a></small></figcaption>
</figure>
<details open="">
    <summary>Table of Contents</summary>

</details>
<hr>
<h2 id="exhaustiveness-checking"><a href="#exhaustiveness-checking">Exhaustiveness Checking</a></h2>
<p>Say you have a system to manage orders. To represent the status of an order, you have the following enum:</p>
<div><pre><span></span><span>import</span> <span>enum</span>

<span>class</span> <span>OrderStatus</span><span>(</span><span>enum</span><span>.</span><span>Enum</span><span>):</span>
    <span>Ready</span> <span>=</span> <span>'ready'</span>
    <span>Shipped</span> <span>=</span> <span>'shipped'</span>
</pre></div>


<p>You also have the following code to process an <code>Order</code>:</p>
<div><pre><span></span><span>def</span> <span>handle_order</span><span>(</span><span>status</span><span>:</span> <span>OrderStatus</span><span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
    <span>if</span> <span>status</span> <span>is</span> <span>OrderStatus</span><span>.</span><span>Ready</span><span>:</span>
        <span>print</span><span>(</span><span>'ship order'</span><span>)</span>

    <span>elif</span> <span>status</span> <span>is</span> <span>OrderStatus</span><span>.</span><span>Shipped</span><span>:</span>
        <span>print</span><span>(</span><span>'charge order'</span><span>)</span>
</pre></div>


<p>When the order is ready, you ship it; and when it's shipped, you charge it.</p>
<p>A few months go by and your system becomes big. So big in fact, that you can no longer ship orders immediately, and you add a new status:</p>
<div><pre><span></span><span>import</span> <span>enum</span>

<span>class</span> <span>OrderStatus</span><span>(</span><span>enum</span><span>.</span><span>Enum</span><span>):</span>
    <span>Ready</span> <span>=</span> <span>'ready'</span>
<span>    <span>Scheduled</span> <span>=</span> <span>'scheduled'</span>
</span>    <span>Shipped</span> <span>=</span> <span>'shipped'</span>
</pre></div>


<p>Before you push this change to production, you run a quick check with mypy to make sure everything is OK:</p>
<div><pre><span></span>$ mypy main.py
Success: no issues found in <span>1</span> <span>source</span> file
</pre></div>


<p>Mypy does not see anything wrong in this code, Do you? The problem is that <strong>you forgot to handle the new status in your function</strong>.</p>
<p>One way to make sure you always handle all possible order statuses is to add an assert, or throw an exception:</p>
<div><pre><span></span><span>def</span> <span>handle_order</span><span>(</span><span>status</span><span>:</span> <span>OrderStatus</span><span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
    <span>if</span> <span>status</span> <span>is</span> <span>OrderStatus</span><span>.</span><span>Ready</span><span>:</span>
        <span>print</span><span>(</span><span>'ship order'</span><span>)</span>

    <span>elif</span> <span>status</span> <span>is</span> <span>OrderStatus</span><span>.</span><span>Shipped</span><span>:</span>
        <span>print</span><span>(</span><span>'charge order'</span><span>)</span>

<span>    <span>assert</span> <span>False</span><span>,</span> <span>f</span><span>'Unhandled status "{status}"'</span>
</span></pre></div>


<p>Now, when you execute the function with the new status <code>OrderStatus.Scheduled</code>, you will get a runtime error:</p>
<div><pre><span></span><span>&gt;&gt;&gt;</span> <span>handle_order</span><span>(</span><span>OrderStatus</span><span>.</span><span>Scheduled</span><span>)</span>
<span>AssertionError</span><span>:</span> <span>Unhandled</span> <span>status</span> <span>"OrderStatus.Scheduled"</span>
</pre></div>


<p>Another way to with deal with cases like this is to go over your test suite and add scenarios in all the places that use order status. But... if you forgot to change the function when you added the status, what are the chances you'll remember to update the tests? That's not a good solution...</p>
<p><strong>Exhaustiveness Checking in Mypy</strong></p>
<p>What if mypy could warn you at "compile time" about such cases? Well... it can, using this little magic function:</p>
<div><pre><span></span><span>from</span> <span>typing</span> <span>import</span> <span>NoReturn</span>
<span>import</span> <span>enum</span>

<span>def</span> <span>assert_never</span><span>(</span><span>value</span><span>:</span> <span>NoReturn</span><span>)</span> <span>-&gt;</span> <span>NoReturn</span><span>:</span>
    <span>assert</span> <span>False</span><span>,</span> <span>f</span><span>'Unhandled value: {value} ({type(value).__name__})'</span>
</pre></div>


<p>Before you dig into the implementation, try to use it to see how it works. In the function above, place <code>assert_never</code> after you handled all the possible order statuses, where you previously used <code>assert</code> or raises an exception:</p>
<div><pre><span></span><span>def</span> <span>handle_order</span><span>(</span><span>status</span><span>:</span> <span>OrderStatus</span><span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
    <span>if</span> <span>status</span> <span>is</span> <span>OrderStatus</span><span>.</span><span>Ready</span><span>:</span>
        <span>print</span><span>(</span><span>'ship order'</span><span>)</span>

    <span>elif</span> <span>status</span> <span>is</span> <span>OrderStatus</span><span>.</span><span>Shipped</span><span>:</span>
        <span>print</span><span>(</span><span>'charge order'</span><span>)</span>

<span>    <span>else</span><span>:</span>
</span><span>        <span>assert_never</span><span>(</span><span>status</span><span>)</span>
</span></pre></div>


<p>Now, check the code with Mypy:</p>
<div><pre><span></span>$ mypy main.py
error: Argument <span>1</span> to <span>"assert_never"</span> has incompatible <span>type</span> <span>"Literal[OrderStatus.Scheduled]"</span><span>;</span>
expected <span>"NoReturn"</span>
Found <span>1</span> error in <span>1</span> file <span>(</span>checked <span>1</span> <span>source</span> file<span>)</span>
</pre></div>


<p>Amazing! <strong>Mypy warns you about a status you forgot to handle!</strong> The message also includes the value, <code>OrderStatus.Scheduled</code>. If you use a modern editor such as VSCode you can get these warnings immediately as you type:</p>
<figure><img alt="mypy Error in VSCode" src="https://hakibenita.com/images/00-python-mypy-exhaustive-checking.png"><figcaption>mypy Error in VSCode</figcaption>
</figure>
<p>You can now go ahead and fix your function to handle the missing status:</p>
<div><pre><span></span><span>def</span> <span>handle_order</span><span>(</span><span>status</span><span>:</span> <span>OrderStatus</span><span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
    <span>if</span> <span>status</span> <span>is</span> <span>OrderStatus</span><span>.</span><span>Pending</span><span>:</span>
        <span>print</span><span>(</span><span>'schedule order'</span><span>)</span>

<span>    <span>elif</span> <span>status</span> <span>is</span> <span>OrderStatus</span><span>.</span><span>Scheduled</span><span>:</span>
</span><span>        <span>print</span><span>(</span><span>'ship order'</span><span>)</span>
</span>
    <span>elif</span> <span>status</span> <span>is</span> <span>OrderStatus</span><span>.</span><span>Shipped</span><span>:</span>
        <span>print</span><span>(</span><span>'charge order'</span><span>)</span>

    <span>else</span><span>:</span>
        <span>assert_never</span><span>(</span><span>status</span><span>)</span>
</pre></div>


<p>Check with mypy again:</p>
<div><pre><span></span>$ mypy main.py
Success: no issues found in <span>1</span> <span>source</span> file
</pre></div>


<p>Great! You can now rest assure you handled all order statuses. The best part is that you did that with <strong>no unit tests</strong>, and there were <strong>no runtime errors</strong>. If you include mypy in your CI, the <strong>bad code will never make it into production</strong>.</p>
<hr>
<h2 id="enumeration-types"><a href="#enumeration-types">Enumeration types</a></h2>
<p>In the previous section you used mypy to perform exhaustiveness check on an <code>Enum</code>. You can use mypy, and <code>assert_never</code> to perform exhaustiveness check on other enumeration types as well.</p>
<p><strong>Exhaustiveness Checking of a Union</strong></p>
<p>A <code>Union</code> type represents several possible types. For example, a function that casts an argument to <code>float</code> can look like this:</p>
<div><pre><span></span><span><span>from</span> <span>typing</span> <span>import</span> <span>Union</span>
</span>
<span><span>def</span> <span>get_float</span><span>(</span><span>num</span><span>:</span> <span>Union</span><span>[</span><span>str</span><span>,</span> <span>float</span><span>])</span> <span>-&gt;</span> <span>float</span><span>:</span>
</span>    <span>if</span> <span>isinstance</span><span>(</span><span>num</span><span>,</span> <span>str</span><span>):</span>
        <span>return</span> <span>float</span><span>(</span><span>num</span><span>)</span>

    <span>else</span><span>:</span>
        <span>assert_never</span><span>(</span><span>num</span><span>)</span>
</pre></div>


<p>Check the function with mypy:</p>
<div><pre><span></span>$ mypy main.py
error: Argument <span>1</span> to <span>"assert_never"</span> has incompatible <span>type</span> <span>"float"</span><span>;</span> expected <span>"NoReturn"</span>
</pre></div>


<p>Whoops... you forgot to handle the <code>float</code> type in the code:</p>
<div><pre><span></span><span>from</span> <span>typing</span> <span>import</span> <span>Union</span>

<span>def</span> <span>get_float</span><span>(</span><span>num</span><span>:</span> <span>Union</span><span>[</span><span>str</span><span>,</span> <span>float</span><span>])</span> <span>-&gt;</span> <span>float</span><span>:</span>
    <span>if</span> <span>isinstance</span><span>(</span><span>num</span><span>,</span> <span>str</span><span>):</span>
        <span>return</span> <span>float</span><span>(</span><span>num</span><span>)</span>

<span>    <span>elif</span> <span>isinstance</span><span>(</span><span>num</span><span>,</span> <span>float</span><span>):</span>
</span><span>        <span>return</span> <span>num</span>
</span>
    <span>else</span><span>:</span>
        <span>assert_never</span><span>(</span><span>num</span><span>)</span>
</pre></div>


<p>Check again:</p>
<div><pre><span></span>$ mypy main.py
Success: no issues found in <span>1</span> <span>source</span> file
</pre></div>


<p>Great! mypy is happy...</p>
<p><strong>Exhaustiveness Checking of a Literal</strong></p>
<p>Another useful type is <code>Literal</code>. It is included in the built-in <code>typing</code> module since Python3.8, and prior to that it is part of the complementary <a href="https://pypi.org/project/typing-extensions/" rel="noopener"><code>typing_extensions</code> package</a>.</p>
<p>A <code>Literal</code> is used to type primitive values such as strings and numbers. <code>Literal</code> is also an enumeration type, so you can use exhaustiveness checking on it as well:</p>
<div><pre><span></span><span>from</span> <span>typing_extensions</span> <span>import</span> <span>Literal</span>

<span>Color</span> <span>=</span> <span>Literal</span><span>[</span><span>'R'</span><span>,</span> <span>'G'</span><span>,</span> <span>'B'</span><span>]</span>

<span>def</span> <span>get_color_name</span><span>(</span><span>color</span><span>:</span> <span>Color</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>if</span> <span>color</span> <span>==</span> <span>'R'</span><span>:</span>
        <span>return</span> <span>'Red'</span>
    <span>elif</span> <span>color</span> <span>==</span> <span>'G'</span><span>:</span>
        <span>return</span> <span>'Green'</span>
    <span># elif color == 'B':</span>
    <span>#     return 'Blue'</span>
    <span>else</span><span>:</span>
        <span>assert_never</span><span>(</span><span>color</span><span>)</span>
</pre></div>


<p>Checking the code without the commented part will produce the following error:</p>
<div><pre><span></span>$ mypy main.py
error: Argument <span>1</span> to <span>"assert_never"</span> has incompatible <span>type</span> <span>"Literal['B']"</span><span>;</span> expected <span>"NoReturn"</span>
</pre></div>


<p>Very handy indeed!</p>
<hr>
<h2 id="type-narrowing-in-mypy"><a href="#type-narrowing-in-mypy">Type Narrowing in Mypy</a></h2>
<p>Now that you've seen what <code>assert_never</code> can do, you can try and understand how it works. <code>assert_never</code> works alongside <strong>"type narrowing"</strong>, which is a mypy feature where the type of a variable is narrowed based on the control flow of the program. In other words, mypy is gradually eliminating possible types for a variable.</p>
<p>First, it's important to understand how various things translate to a <code>Union</code> type in mypy:</p>
<div><pre><span></span><span>Optional</span><span>[</span><span>int</span><span>]</span>
<span># Equivalent to Union[int, None]</span>

<span>Literal</span><span>[</span><span>'string'</span><span>,</span> <span>42</span><span>,</span> <span>True</span><span>]</span>
<span># Equivalent to Union[Literal['string'], Literal[42], Literal[True]]</span>

<span>class</span> <span>Suit</span><span>(</span><span>Enum</span><span>):</span>
    <span>Clubs</span> <span>=</span> <span>"♣"</span>
    <span>Diamonds</span> <span>=</span> <span>"♦"</span>
    <span>Hearts</span> <span>=</span> <span>"♥"</span>
    <span>Spades</span> <span>=</span> <span>"♠"</span>

<span>Suit</span>
<span># ~Equivalent to Union[</span>
<span>#   Literal[Suit.Clubs],</span>
<span>#   Literal[Suit.Diamonds],</span>
<span>#   Literal[Suit.Hearts],</span>
<span>#   Literal[Suit.Spades]</span>
<span># ]</span>
</pre></div>


<p>To display the type of an expression, mypy provides a useful utility called <a href="https://mypy.readthedocs.io/en/stable/common_issues.html#reveal-type" rel="noopener"><code>reveal_type</code></a>. Using <code>reveal_type</code> you can ask mypy to show you the inferred type for a variable at the point it's called:</p>
<div><pre><span></span><span>def</span> <span>describe_suit</span><span>(</span><span>suit</span><span>:</span> <span>Optional</span><span>[</span><span>Suit</span><span>])</span> <span>-&gt;</span> <span>str</span><span>:</span>
<span>    <span># Revealed type is Union[Suit, None]</span>
</span>    <span>reveal_type</span><span>(</span><span>suit</span><span>)</span>
</pre></div>


<p>In the function above, the reveled type of <code>suit</code> is <code>Union[Suit, None]</code>, which is the type of the argument <code>suit</code>.</p>
<p>At this point you haven't done anything in the function, so mypy is unable to narrow down the type. Next, add some logic and see how mypy narrows down the type of the variable <code>suit</code>:</p>
<div><pre><span></span><span>def</span> <span>describe_suit</span><span>(</span><span>suit</span><span>:</span> <span>Optional</span><span>[</span><span>Suit</span><span>])</span> <span>-&gt;</span> <span>str</span><span>:</span>
<span>    <span>assert</span> <span>suit</span> <span>is</span> <span>not</span> <span>None</span>
</span><span>    <span># Revealed type is Suit</span>
</span>    <span>reveal_type</span><span>(</span><span>suit</span><span>)</span>
</pre></div>


<p>After eliminating the option of suit being <code>None</code>, the revealed type is <code>Suit</code>. Mypy used your program's logic to narrow the type of the variable.</p>
<p>Keep in mind, the type <code>Suit</code> is equivalent to the type <code>Union[Literal[Suit.Clubs], Literal[Suit.Diamonds], Literal[Suit.Hearts], Literal[Suit.Spades]]</code>, so next, try to narrow down the type even more:</p>
<div><pre><span></span><span>def</span> <span>describe_suit</span><span>(</span><span>suit</span><span>:</span> <span>Optional</span><span>[</span><span>Suit</span><span>])</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>assert</span> <span>suit</span> <span>is</span> <span>not</span> <span>None</span>

<span>    <span>if</span> <span>suit</span> <span>is</span> <span>Suit</span><span>.</span><span>Clubs</span><span>:</span>
</span><span>        <span># Revealed type is Literal[Suit.Clubs]</span>
</span>        <span>reveal_type</span><span>(</span><span>suit</span><span>)</span>
        <span>return</span> <span>"Clubs"</span>

<span>    <span># Revealed type is Literal[Suit.Diamonds, Suit.Hearts, Suit.Spades]</span>
</span>    <span>reveal_type</span><span>(</span><span>suit</span><span>)</span>
</pre></div>


<p>After checking if <code>suit</code> is <code>Suit.Clubs</code>, mypy is able to narrow down the type to <code>Suit.Clubs</code>. Mypy is also smart enough to understand that if the condition does not hold, the variable <em>is definitely not</em> <code>Clubs</code>, and narrows down the type to <code>Diamonds</code>, <code>Hearts</code> or <code>Spades</code>.</p>
<p>Mypy can also use other conditional statements to further narrow the type, for example:</p>
<div><pre><span></span><span>def</span> <span>describe_suit</span><span>(</span><span>suit</span><span>:</span> <span>Optional</span><span>[</span><span>Suit</span><span>])</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>assert</span> <span>suit</span> <span>is</span> <span>not</span> <span>None</span>

    <span>if</span> <span>suit</span> <span>is</span> <span>Suit</span><span>.</span><span>Clubs</span><span>:</span>
        <span># Revealed type is Literal[Suit.Clubs]</span>
        <span>reveal_type</span><span>(</span><span>suit</span><span>)</span>
        <span>return</span> <span>"Clubs"</span>

    <span># Revealed type is Literal[Suit.Diamonds, Suit.Hearts, Suit.Spades]</span>
    <span>reveal_type</span><span>(</span><span>suit</span><span>)</span>

<span>    <span># `and`, `or` and `not` also work.</span>
</span><span>    <span>if</span> <span>suit</span> <span>is</span> <span>Suit</span><span>.</span><span>Diamonds</span> <span>or</span> <span>suit</span> <span>is</span> <span>Suit</span><span>.</span><span>Spades</span><span>:</span>
</span><span>        <span># Revealed type is Literal[Suit.Diamonds, Suit.Spades]</span>
</span>        <span>reveal_type</span><span>(</span><span>suit</span><span>)</span>
        <span>return</span> <span>"Diamonds or Spades"</span>

<span>    <span># Revealed type is Literal[Suit.Hearts]</span>
</span><span>    <span>reveal_type</span><span>(</span><span>suit</span><span>)</span>
</span></pre></div>


<p>By the end of the function, mypy narrowed down the type of <code>suit</code> to <code>Suit.Hearts</code>. If, for example, you add a condition that imply a different type for <code>suit</code>, mypy will issue an error:</p>
<div><pre><span></span><span>def</span> <span>describe_suit</span><span>(</span><span>suit</span><span>:</span> <span>Optional</span><span>[</span><span>Suit</span><span>])</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>assert</span> <span>suit</span> <span>is</span> <span>not</span> <span>None</span>

    <span>if</span> <span>suit</span> <span>is</span> <span>Suit</span><span>.</span><span>Clubs</span><span>:</span>
        <span># Revealed type is Literal[Suit.Clubs]</span>
        <span>reveal_type</span><span>(</span><span>suit</span><span>)</span>
        <span>return</span> <span>"Clubs"</span>

    <span># Revealed type is Literal[Suit.Diamonds, Suit.Hearts, Suit.Spades]</span>
    <span>reveal_type</span><span>(</span><span>suit</span><span>)</span>

    <span># `and`, `or` and `not` also work.</span>
    <span>if</span> <span>suit</span> <span>is</span> <span>Suit</span><span>.</span><span>Diamonds</span> <span>or</span> <span>suit</span> <span>is</span> <span>Suit</span><span>.</span><span>Spades</span><span>:</span>
        <span># Revealed type is …</span></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hakibenita.com/python-mypy-exhaustive-checking">https://hakibenita.com/python-mypy-exhaustive-checking</a></em></p>]]>
            </description>
            <link>https://hakibenita.com/python-mypy-exhaustive-checking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25428583</guid>
            <pubDate>Tue, 15 Dec 2020 09:38:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The rise of Japan’s loyalty point influencers]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25428544">thread link</a>) | @imartin2k
<br/>
December 15, 2020 | https://restofworld.org/2020/the-point-hackers/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/the-point-hackers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Chuken, a Japanese Twitter <a href="https://twitter.com/chukenDr">influencer</a> with over 12,000 followers, promises to teach his fans how to escape poverty — not by learning personal finance hacks or leaning on welfare programs, but by using loyalty points.</p>



<p>Chuken, which means “loyal dog,” calls himself one of Japan’s top-tier point stars, someone well-versed in the complicated art of “point alchemy.” The loyalty rewards he’s accumulated have helped him pay for everything from utility bills and vacations to the occasional trip to the salon. “I’m one of probably up to 100 people in Japan who earn more than 1 million yen [nearly $10,000] a year from points,” he told <em>Rest of World</em>.</p>



<p>Despite being the birthplace of payment technology like the QR code, Japan is still <a href="https://www.ft.com/content/fdbdb92c-a6ea-11e9-984c-fac8325aaa04">stubbornly addicted</a> to using cash: Around <a href="https://www.reuters.com/article/us-japan-economy-boj/nearly-20-of-japan-households-using-e-money-but-cash-still-king-idUSKBN1XS0Q1">80% of people in the country</a> say they choose it over debit cards or payment apps for small purchases. The generous rewards programs that Chuken promotes are a way for digital payment companies to encourage consumer adoption. But the incentives have also given rise to an enthusiastic <em>poikatsu</em>, or “point activities,” subculture that wants to max out as much as possible.</p>



<p>“Considering how cash-dependent Japan is, for mobile payments to take off, there needs to be a change in consumer behavior,” said Celeste Goh, a financial technology analyst at the market intelligence firm S&amp;P Global. That’s where loyalty points enter the picture.</p>



<p>A doctor by day, Chuken, who asked to be identified only by his Twitter alias for privacy reasons, first became interested in rewards programs after experiencing his own financial struggles. He’s one of thousands of physicians at university hospitals in Japan who have gone <a href="https://www3.nhk.or.jp/nhkworld/en/news/backstories/606/">regularly unpaid</a>, even during the Covid-19 pandemic. At first, Twitter was where he swapped tips with other poikatsu enthusiasts, but the hobby soon evolved into a full-fledged lifestyle.</p>



<p>Chuken is just one of many poikatsu personalities that have emerged on Japanese social media in recent years. The biggest stars produce content a few times a week, and also earn additional income from sponsored posts and YouTube advertisements.</p>



<div><p>On Instagram there’s <a href="https://www.instagram.com/jojo_secco_point/">Setsuko Kikuhara</a>, or Sekko, who describes herself as a “poikatsu-obsessed woman.” The single mother of a 5-year-old, Sekko caters her content primarily toward other parents. One of her popular hacks is teaching followers how to nab year-long passes to Hong Kong Disneyland. Her extreme point collection even landed her on a popular Japanese <a href="https://www.youtube.com/watch?v=DwueZH3NcnU">talk show</a>.</p><p>One of the most successful poikatsu influencers is <a href="https://www.youtube.com/c/ryogakucho/">Ryogakucho</a>, a YouTube creator with more than 600,000 followers who posts step-by-step guides to point hacking. He regularly preaches the gospel of R-Points, a program run by e-commerce giant Rakuten, which rewards consumers for purchases made on its platform. A cartoon lion cheers on subscribers in every video.</p></div>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/IMG_2078-40x87.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/IMG_2078-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/IMG_2078-400x866.png 400w, https://restofworld.org/wp-content/uploads/2020/12/IMG_2078-600x1299.png 600w, https://restofworld.org/wp-content/uploads/2020/12/IMG_2078-1000x2165.png 1000w, " sizes="(max-width: 640px) 100vw, 300px" alt="Chuken, which means “loyal dog,” calls himself one of Japan’s top-tier point stars.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Twitter</span>
			</figcaption>
		</figure>


<div><p>Two years ago, a Japanese think tank <a href="https://www.nira.or.jp/pdf/cashless.pdf#page=15">surveyed 3,000 people in the country, the vast majority of whom said they used rewards points programs at least sometimes</a>. 37% said a major reason they did so was because it was fun. “It’s just like a math problem, game, or sport, but you’re spotting the loopholes of service providers,” said Chuken. “Poikatsu is a hobby that earns you money, rather than loses you money. The better you get, the more it benefits your life.”</p><p>The popularity of poikatsu is in part a result of Japanese consumers’ <a href="https://www.reuters.com/article/us-japan-economy-cashless-idUSKBN1XF0BT">notorious</a> resistance to cashless technology. Even as neighboring countries like South Korea and China quickly adopted digital payments, Japan has clung to physical currency, said Arnie Cho, a fintech analyst at the research firm GlobalData. In early 2020, upwards of <a href="https://daxueconsulting.com/payment-methods-in-china/">700 million consumers</a> were using mobile payments in China, often relying on WeChat Pay and Alipay’s QR code systems. In Japan, that <a href="https://www.nippon.com/en/news/fnn20191214001/the-little-known-story-of-the-birth-of-the-qr-code.html">homegrown technology</a> has rarely been used in fintech, and Chinese tourists have actually <a href="https://www.wsj.com/articles/smartphone-wielding-chinese-tourists-challenge-cashs-reign-11551609002">helped foster</a> its adoption in the country.</p></div>



<p>International commentators often <a href="https://www.wired.com/story/japan-holdout-asia-cash-free-future/">recycle cultural generalizations </a>to explain Japan’s devotion to cash, but some of the real reasons for the phenomenon may be purely pragmatic. A highly developed banking infrastructure in the country keeps ATMs close, whereas many markets in Southeast Asia are turning to mobile payments to serve the unbanked, said Cho. <a href="https://www.osac.gov/Content/Report/d3d72e3f-6cd9-4fef-9f64-15f4aea79d98#:~:text=There%20is%20minimal%20risk%20from,three%20robberies%20per%20100%2C000%20individuals">Low petty-crime rates</a> also allow the average consumer to feel comfortable carrying a wallet full of cash. Fintech services, meanwhile, <em>have</em> needed to combat problems with fraud. In 2019, <a href="https://www.businessinsider.com/7-eleven-japan-7pay-hackers-passwords-2019-7">over $500,000 was stolen</a> from 7pay, 7-Eleven Japan’s debut in the mobile payment space. Almost three months after it launched, the company shuttered the program.&nbsp;</p>



<p>Rewards programs can be expensive for payment apps, but they’re also a reliable way to convince reluctant consumers to give their services a chance. The social media giant Line has relied heavily on point schemes over the past few years, after struggling to get the majority of Japan’s population who already use its messaging platform onto its digital wallet, Line Pay. “Point rewards are an easy-to-understand way to incentivize users,” said Line Pay spokesperson Mayu Kamioka.</p>



<div><p>Line introduced aggressive rewards campaigns in 2018 and 2019 for Line Pay, shortly after the Japanese government set a goal to increase digital payments to <a href="https://www.japantimes.co.jp/news/2018/12/03/reference/japan-grudgingly-heads-toward-cashless-society/">40% of all transactions by 2027</a> (it later <a href="https://www.meti.go.jp/english/press/2018/0703_001.html">updated</a> the target to 2025). The strategy included the <a href="https://linecorp.com/ja/pr/news/ja/2020/3151">Line Point Club</a>, a tiered system that rewards users based on the number of purchases they make with Line Pay over a six-month span. The company has also used sporadic <a href="https://linecorp.com/ja/pr/news/ja/2019/2672">“Pay-Toku” campaigns</a>, flash deals that give rebates of up to 20% for Line Pay purchases.</p><p>Line said the incentives are working. In a <a href="https://www.linebiz.com/jp/column/research/20200219/">survey</a> the company’s research arm conducted in February, around 38% of smartphone owners said they used a mobile device to make a payment in brick-and-mortar shops in the past 12 months, an increase from 13% from the year before.</p></div>



<p>Line Pay is competing with over a dozen other payment apps in Japan, including PayPay, a service jointly operated by SoftBank and Yahoo! Japan. PayPay said it <a href="https://about.paypay.ne.jp/pr/20201021/01/">doubled its registered users</a> from 10 million to 20 million in three months last year, as it was relying on short-term cash-back <a href="https://image.paypay.ne.jp/pdf/pr20190204_en.pdf">programs</a>, which cost the company around $94 million (10 billion yen) each to run. As <a href="https://www.japantimes.co.jp/news/2020/08/03/business/corporate-business/yahoo-japan-line-to-postpone-merger-pandemic/">Line and Yahoo! Japan consider a merger next spring</a>, these competing promotions may end up benefiting both companies.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-11-at-10.59.41-AM-40x20.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-11-at-10.59.41-AM-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-11-at-10.59.41-AM-400x203.png 400w, https://restofworld.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-11-at-10.59.41-AM-600x304.png 600w, https://restofworld.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-11-at-10.59.41-AM-1000x506.png 1000w, https://restofworld.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-11-at-10.59.41-AM-1600x810.png 1600w, https://restofworld.org/wp-content/uploads/2020/12/Screen-Shot-2020-12-11-at-10.59.41-AM-2800x1418.png 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="Yuzuhiko posts poikatsu vlogs on Youtube, speaking through a 3D-animated avatar of a brown tabby cat in a samurai helmet.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder"><a href="https://www.youtube.com/channel/UCgIUiYo9N8nmubnLNV6DBzA/" target="_blank" rel="noopener noreferrer">https://www.youtube.com/channel/UCgIUiYo9N8nmubnLNV6DBzA/</a></span>
			</figcaption>
		</figure>


<p>Japanese media outlets have dubbed ongoing fights between payment apps as the “Cashless Sengoku Period,” a nod to Japan’s warring feudal era dating back to the 1400s. Some influencers take it upon themselves to chart the competing campaigns, like Twitter user <a href="https://twitter.com/haiji_doctor">Haiji Hakase</a>, who is known for his rewards chart featuring color-coded breakdowns of the 12 major payment services and what they’ll be offering over the next few days. “The best deals have changed so rapidly as poikatsu booms. It’s fun to find the best solutions amid the moving targets,” he said.</p>



<p>Yuzuhiko, a 31-year-old office worker in the southwestern city of Fukuoka, who asked to use only his first name, posts poikatsu vlogs on his <a href="https://www.youtube.com/channel/UCgIUiYo9N8nmubnLNV6DBzA/">YouTube channel</a> three times a week. In his videos, he explains the latest digital payment trends while speaking through a 3D-animated avatar of a brown tabby cat in a samurai helmet. “I am the only ‘cashless VTuber,’” he said, referring to “<a href="https://www.bbc.com/worklife/article/20181002-the-virtual-vloggers-taking-over-youtube">virtual YouTubers</a>” who use computer-generated avatars, a popular genre in Japan.</p>



<p>Yuzuhiko said he’s noticed a big bump in video views this year. In October 2019, <a href="https://www.japantimes.co.jp/news/2019/09/01/business/tax-rebate-small-retailers-cashless-payments/">a government rebate program</a> began awarding 5% back on some cashless payments, in an effort to boost adoption before the since-postponed 2020 Olympics. The increased popularity may also be due to Covid-19. “Because the pandemic brought financial difficulties to some households, now they might care more about making the most of the available point services,” Yuzuhiko said.</p>



<p>It’s not clear how long the boon in poikatsu content will last. The incentives offered by companies like Line and PayPay are designed to lure new users and could be discontinued once the companies establish a core base of customers. “Now might be the fad season for poikatsu,” said Chuken, “but I’m not sure if this trend will still be around in four to five years.”</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/the-point-hackers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25428544</guid>
            <pubDate>Tue, 15 Dec 2020 09:31:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Planning Your Software Distribution Options]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25428509">thread link</a>) | @vasya-gh
<br/>
December 15, 2020 | https://perceptionbox.io/business/planning-your-software-distribution-options/ | <a href="https://web.archive.org/web/*/https://perceptionbox.io/business/planning-your-software-distribution-options/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <div>
                                                    
                                
                                    
<p id="Methods">
            <h2>Methods of software distribution</h2>
    </p>
                                
                                
                                
                                
                                
                                
                                
                                

                            
                                
                                
                                
                                    
<div>
                <div>
                <p>According to CBI Insights, “running out of money” is the second of the <a href="https://www.cbinsights.com/research/startup-failure-reasons-top/" target="_blank" rel="noopener">top 20 reasons why businesses fail</a>. It’s not the only money-related issue. Pricing and cost issues, lack of a business model, and poor marketing intersect with monetization, too. Though monetization potential is very important, distribution is even more important!</p>
<p>A quick note, that the #1 reason, “no market need” is largely addressed by sticking to a <a href="https://perceptionbox.io/business/software-outsourcing-to-boost-startups-and-mvps/" target="_blank" rel="noopener">Minimum Viable Product</a> (MVP) development process. The MVP process focuses on asking the tough questions first. Do customers love your product? Will they buy it? How much will they pay for it? These focus on finding a great product-market fit which also means creating a competitive product.</p>
<p>Distribution methods play a very important part in your software’s monetization potential.<br>
As <a href="https://www.smaato.com/blog/android-vs-ios-app-monetization/" target="_blank" rel="noopener">Smaato</a> points out, “iPhone users spend on average over <a href="https://blog.soomla.com/2019/01/app-monetization-android-vs-ios.html" target="_blank" rel="noopener">$30 per online transaction</a>, compared to an average of $10 that Android users spend.” So, in all cases, you want to do your marketing research. Some of us on the marketing side have heard from tech companies that “They don’t need marketing.” With few exceptions – companies taking that stance either don’t last long or get bought out.</p>
            </div>
    </div>
                                
                                
                                
                                
                                
                                

                            
                                
                                    
<p id="The">
            <h2>The Ease of Electronic vs. Packaged Distribution</h2>
    </p>
                                
                                
                                
                                
                                
                                
                                
                                

                            
                                
                                
                                
                                    
<div>
                <div>
                <p>Say, you’re in the breakfast cereal business. If you get your product in Walmart and Kroger, you’ve done well. Do you stop there? No. There’s still Albertsons, Safeway, HEB, 7-11s, corner stores, restaurants, and hotel chains. But, you have to prove to each that your product is worthy of their shelf space. If your product has a $10 price tag, distributors and retailers will take at least half as their share. You have to cover the warehousing, cost of promotions, and damages.</p>
<p>Many mobile app developers place their apps on Google Play and the App Store and call their distribution efforts “done.” For a very lucky minority, this can work. Even so, it’s by no means optimal and it’s one reason (of many) why so many mobile apps never made money. For one thing, it’s super freakin’ lazy – to be polite about it.</p>
<ul>
<li>If your app meets store guidelines – you’re basically guaranteed “shelf-space.”</li>
<li>It takes, at most, two hours to set up a new app on independent app stores.</li>
<li>No warehousing, no shipping costs for downloads, no damages.</li>
<li>No expensive promotional displays.</li>
<li>Most online stores take just 30% of sales.</li>
</ul>
<p>Granted no independent app stores have nearly the traffic as the Big Two. However, that fact alone also makes it easier to get exposure on them and be a big fish in a small pond.</p>
<p>Your team has spent months developing a software project. It’s worth the effort to have one person spend a few days expanding its distribution channels. Each is a “point of presence” – and helps to develop branding a la McDonald’s or Starbucks. Overall, it costs the same to develop a software product whether it is ultimately delivered to one or one million people. The goal, as with any product, is to get it into the hands of as many customers as inexpensively as possible.</p>
            </div>
    </div>
                                
                                
                                
                                
                                
                                

                            
                                
                                    
<p id="Six">
            <h2>Six Software Distribution Models</h2>
    </p>
                                
                                
                                
                                
                                
                                
                                
                                

                            
                                
                                
                                
                                    
<div>
                <p>Most everyone’s acquainted with packaged and downloadable premium software, freemium apps, and subscription models. Each has its own nuances to consider, but there are also a few options not so widely known – like pre-installed software distribution and white label options. We aren’t aiming to say any one is better than another – as it all depends upon your project, your target audience, and your budget.</p>
    </div>
                                
                                
                                
                                
                                
                                

                            
                                
                                    
<p id="Packaged ">
            <h2>Packaged Software Distribution</h2>
    </p>
                                
                                
                                
                                
                                
                                
                                
                                

                            
                                
                                
                                
                                    
<div>
                <div>
                <p>With the Internet, packaged software is the oddball as it incurs the extra cost and effort of developing <a href="https://site.handshake.com/blog/how-to-wholesale" target="_blank" rel="noopener">brick-n-mortar retail distribution</a> channels. But, it is possible to forego the packaged distribution effort and simply make the hard copy materials a purchase option. Desktop titles typically include a DVD for installation and a user manual. Gaming companies often have collector editions adding maps, art books, and assorted game paraphernalia. Basic options typically incur a $10-20 surcharge on the price of the electronic version. Premium options can add $20 to $80, or more, to the cost.</p>
<p>Companies like Microsoft, Apple, Sony, and Electronic Arts, among others, have the economy of scale and distribution channels to get good mileage from packaged software. Other companies should validate every packaged software aspect with their user-base before jumping into it. Startups are likely better off avoiding packaged software unless there’s active end-user demand.</p>
<p>Demand can be evaluated via crowdfunding campaigns starting off with a small, first-run packaged edition. Additional options can be opened if funding benchmarks are reached. Alternatively, if sales of electronic versions go well, you can always expand your packaged options later. Nevertheless, any effort in selling or developing distribution channels for packaged software involves a very significant physical effort. Print On-Demand services can help streamline portions of the effort.</p>
            </div>
    </div>
                                
                                
                                
                                
                                
                                

                            
                                
                                    
<p id="Premium">
            <h2>Premium Software Downloads</h2>
    </p>
                                
                                
                                
                                
                                
                                
                                
                                

                            
                                
                                
                                
                                    
<div>
                <div>
                <p>Exponentially easier to develop and manage if only because you don’t have to worry about inventory or physical distribution efforts. If you have a software product, a website, and a Paypal account, you could be in business today! Retail shelf space isn’t an issue either. As long as your software meets store policies you should have no problems getting on most online (non-brand specific) software or app stores.</p>
<p>Another advantage is that most online stores only take a 30% commission. Both the App Store and Google Play reduce their commissions on subscription-based apps to 15% after one year. If you are selling internationally, for best effect you should pro-rate your cover price to accommodate purchasing power parity with different countries.</p>
<p>Generally speaking, top-shelf software and brand names do best with premium sales. Their core advantage applies via the marketing and advertising dollars they can throw at promoting their products. Their advantage is magnified by promoting new releases across the user-base of all of their other products. With different product strategies, premium software can employ most other monetization options except in-app advertising.</p>
            </div>
    </div>
          …</div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://perceptionbox.io/business/planning-your-software-distribution-options/">https://perceptionbox.io/business/planning-your-software-distribution-options/</a></em></p>]]>
            </description>
            <link>https://perceptionbox.io/business/planning-your-software-distribution-options/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25428509</guid>
            <pubDate>Tue, 15 Dec 2020 09:24:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mastering Postgres indexes in 10 minutes]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25428453">thread link</a>) | @FabienHerfray
<br/>
December 15, 2020 | https://fabien.herfray.org/posts/mastering-postgres-indexes-in-10-minutes/ | <a href="https://web.archive.org/web/*/https://fabien.herfray.org/posts/mastering-postgres-indexes-in-10-minutes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 id="whats-in-this-post">What’s in this post?</h2><p>Enough about the insides of Postgres indexes to impress your coworkers at the coffee machine or recruiters at a job interview 🤓.</p><p>We’ll have a look at B-Tree, Hash, GIN, GiST, BRIN indexes and focus on demystifying them.</p><h2 id="why-the-hell-do-i-even-need-an-index">Why the hell do I even need an index?</h2><p>Indexes are at the core of any querying in relational databases (the classic SQL databases like Postgres or MySQL). Therefore it is very rewarding and important to have an idea of how they work.</p><p>An illustration is worth a thousand words so let’s take an example. Let’s say we have a <code>user</code> table containing 1M million entries (or rows):</p><div><pre><code data-lang="sql"><span>CREATE</span> <span>TABLE</span> <span>user</span> (
  id   SERIAL <span>PRIMARY</span> <span>KEY</span>,
  name TEXT,
  age  INTEGER
);
</code></pre></div><p>We want to know how many of our users are above 30. We run:</p><div><pre><code data-lang="sql"><span>SELECT</span> <span>COUNT</span>(<span>*</span>) <span>FROM</span> <span>user</span> <span>WHERE</span> age <span>&gt;</span> <span>30</span>;
</code></pre></div><p>Without any extra index, the database would have to go over the 1M entries one by one, look at their age and increment a counter for all the users above 30:</p><p><img src="https://fabien.herfray.org/images/mastering-postgres-indexes-in-10-minutes/scan.png" alt="scan"></p><p>If it feels like an inefficient way of getting the result it’s because it is 💁‍♀️. It would be a slow query (called a “full table scan”, as every row needs to be scanned).</p><p>That’s where indexation comes into play. It will allow us to quickly locate the users we’re interested in, without having to lookup all the rows.</p><p>In Postgres, there are 5 types of indexes:</p><ul><li>B-Trees</li><li>Hashes</li><li>GINs</li><li>GiSTs</li><li>BRINs</li></ul><h2 id="before-we-start">Before we start</h2><h3 id="naming">Naming</h3><ul><li><strong>Row</strong>: An entry in the database (e.g. a user). Also called tuple.</li><li><strong>Column</strong>: An attribute of a row (e.g. the first name of a user).</li><li><strong>Table</strong>: A collection of rows (e.g. a user table).</li><li><strong>TID</strong>: Tuple ID. It’s an internal Postgres ID. It describes where to find the row on the disk.</li><li><strong>Operator</strong>: Reserved keyword representing operations on data (e.g. <code>AND</code>, <code>+</code>, <code>&gt;</code>, <code>=</code>).</li><li><strong>Statement</strong>: Database operation (e.g. <code>CREATE TABLE user (name TEXT);</code>).</li><li><strong>Query</strong>: Statement that returns data (e.g. <code>SELECT * FROM user;</code>)</li></ul><h3 id="core-assumptions">Core assumptions</h3><ul><li>In general, an index needs to be able to fit in RAM to be fully efficient. That’s why having very large indexes can be problematic.</li><li>Fetching the row behind a <code>tid</code> is easy and relatively cheap to do. We consider it roughly equivalent to getting an element from an array by index (e.g. <code>var a = array[i]</code>).</li><li>We’ll only talk about read operations (queries). How to propagate writes to indexes is a whole other story.</li><li>Everything is more complex and complicated in real life, this post tries to explain things on a very high level and may be approximate on some parts. For more details, one should have a look at the <code>Further explanation</code> links.</li></ul><h2 id="b-tree-indexes">B-Tree indexes</h2><h3 id="usecase">Usecase</h3><p>So we want to index this query. We want to make it faster:</p><div><pre><code data-lang="sql"><span>SELECT</span> <span>COUNT</span>(<span>*</span>) <span>FROM</span> <span>user</span> <span>WHERE</span> age <span>&gt;</span> <span>30</span>;
</code></pre></div><p>We create a B-Tree index on the <code>age</code> column.</p><div><pre><code data-lang="sql"><span>CREATE</span> <span>INDEX</span> user_by_age <span>ON</span> <span>user</span> (age);
</code></pre></div><p>No need to specify anything, B-Tree is the default index for Postgres and many other databases including MySQL, Oracle or SQL Server.</p><h3 id="how-does-it-work">How does it work</h3><p>A binary search tree (<strong>different from a B-Tree</strong>) is a well known data structure where every node of the tree has two children nodes. The values of the left and right children being respectively smaller and larger than their parent’s value.</p><p>A B-Tree is a generalised binary search tree where every node can have more than two children.</p><p><img src="https://fabien.herfray.org/images/mastering-postgres-indexes-in-10-minutes/tree_comparison.png" alt="tree comparison"></p><p>A very helpful property of these trees is that their values are sorted. It makes it easy to lookup values. Exactly what we need to speed up our query!</p><p>Now a B-Tree index is slightly more than just a B-Tree. It is a linked list of tids, sorted by value and linked to a B-Tree.</p><p>Let’s run our query again and see how it looks like:</p><div><pre><code data-lang="sql"><span>SELECT</span> <span>COUNT</span>(<span>*</span>) <span>FROM</span> <span>user</span> <span>WHERE</span> age <span>&gt;</span> <span>30</span>;
</code></pre></div><p><img src="https://fabien.herfray.org/images/mastering-postgres-indexes-in-10-minutes/btree.png" alt="btree"></p><p>That was much easier! By using the sorting of the tree nodes, we can now quickly find the first user being above 30 and count from there. Remember? The linked list at the bottom is sorted by age!</p><p>As a side note, you may be wondering about multicolumn indexes, like:</p><div><pre><code data-lang="sql"><span>CREATE</span> <span>INDEX</span> user_by_age_and_height <span>ON</span> <span>user</span> (age, height_cm);
</code></pre></div><p>The simplest way to visualize it is to imagine it as being roughly equivalent to a monocolumn index like:</p><div><pre><code data-lang="sql"><span>CREATE</span> <span>INDEX</span> user_by_age_and_height <span>ON</span> <span>user</span> (age<span>+</span><span>'-'</span><span>+</span>height_cm);
</code></pre></div><p>The B-Tree mechanism stays the same, but the values that are being sorted are now for example <code>28-182</code>.</p><p>This explains why the index wouldn’t help with trying to run:</p><div><pre><code data-lang="sql"><span>SELECT</span> <span>COUNT</span>(<span>*</span>) <span>FROM</span> <span>user</span> <span>WHERE</span> height_cm <span>&gt;</span> <span>160</span>;
</code></pre></div><p>In the tree, values like <code>28-182</code> are not sorted by height. They are sorted by age, and then for every individual age they are sorted by height.</p><p>On the other hand, the index would help us with this query:</p><div><pre><code data-lang="sql"><span>SELECT</span> <span>COUNT</span>(<span>*</span>) <span>FROM</span> <span>user</span> <span>WHERE</span> age <span>=</span> <span>30</span> <span>AND</span> height_cm <span>&gt;</span> <span>160</span>;
</code></pre></div><h3 id="tldr-too-long-didnt-read">TLDR (Too Long Didn’t Read)</h3><ul><li>B-Tree is the default index in many databases.</li><li>Is it so popular because it’s fast, efficient and flexible.</li><li>It makes operations like <code>=</code>, <code>&lt;</code>, <code>&lt;=</code>, <code>&gt;</code>, <code>&gt;=</code>, <code>ORDER BY</code> or even <code>LIKE</code> faster.</li><li>A rule of thumb would be: if you need to speed up the above operations, use a B-Tree index unless there is a specific reason not to.</li></ul><h3 id="further-explanation">Further explanation</h3><ul><li><a href="https://www.qwertee.io/blog/postgresql-b-tree-index-explained-part-1/">https://www.qwertee.io/blog/postgresql-b-tree-index-explained-part-1/</a></li><li><a href="https://habr.com/en/company/postgrespro/blog/443284">https://habr.com/en/company/postgrespro/blog/443284</a></li></ul><h2 id="hash-indexes">Hash indexes</h2><h3 id="usecase-1">Usecase</h3><p>We’re only querying using the <code>=</code> operator and we’re having very specific scaling/performance issues (e.g. our table is huge and a B-Tree would be too large to fit in memory). We want to index:</p><div><pre><code data-lang="sql"><span>SELECT</span> <span>COUNT</span>(<span>*</span>) <span>FROM</span> <span>user</span> <span>WHERE</span> name <span>=</span> <span>'Souleymane Laurence'</span>;
</code></pre></div><p>We create a Hash index on the <code>name</code> column.</p><div><pre><code data-lang="sql"><span>CREATE</span> <span>INDEX</span> user_by_name <span>ON</span> <span>user</span> <span>USING</span> HASH (name);
</code></pre></div><p>This time, we need to specify it explicitely by adding <code>USING HASH</code> to our statement.</p><h3 id="how-does-it-work-1">How does it work</h3><p>Let’s think of our <code>user</code> table as a Java array for one second. We consider the position in the array to be equivalent to a <code>tid</code> in Postgres:</p><p>That’s how we’d naively lookup the users having the name <code>Souleymane Laurence</code>:</p><div><pre><code data-lang="java">User<span>[]</span> userTable <span>=</span> <span>{...}</span>

<span>int</span> i<span>;</span>
List<span>&lt;</span><span>int</span><span>&gt;</span> foundTids <span>=</span> <span>new</span> ArrayList<span>&lt;&gt;();</span>

<span>// Iterating over the rows of our table to find our values in the array.
</span><span></span><span>for</span> <span>(</span>i <span>=</span> 0<span>;</span> i <span>&lt;</span> userTable<span>.</span><span>length</span><span>;</span> i<span>++)</span> <span>{</span>
	<span>if</span> <span>(</span>userTable<span>[</span>i<span>].</span><span>name</span> <span>==</span> <span>"Souleymane Laurence"</span><span>)</span> <span>{</span>
		foundTids<span>.</span><span>add</span><span>(</span>i<span>)</span>
	<span>}</span>
<span>}</span>
</code></pre></div><p>This is slow because we have to go over all the entries of the table one by one (remember, they could be hundreds of millions in a database).</p><p>Now couldn’t we find a way to remove this big for loop and predict in advance where are our rows going to be located in the array? Yes! And it’s called a <strong>hash function</strong>.</p><p>A hash function is capable of taking any input and translating it into a smaller subset of values:</p><div><pre><code data-lang="java"><span>// Returns an int between 0 and 256. Always the same for the same input.
</span><span></span>hash_function_256<span>(</span><span>"Souleymane Laurence"</span><span>)</span>
<span>-&gt;</span> 147
</code></pre></div><p>We could use this as an array position! We just need to rearrange our table first:</p><div><pre><code data-lang="java">User<span>[]</span> userTable <span>=</span> <span>{...}</span>

<span>int</span> i<span>;</span>
List<span>&lt;</span><span>int</span><span>&gt;[]</span> hashIndex <span>=</span> <span>new</span> List<span>&lt;</span><span>int</span><span>&gt;[</span>256<span>];</span> <span>// 256 hash values
</span><span></span>
<span>// Iterating over the rows of our table to populate our index.
</span><span></span><span>for</span> <span>(</span>i <span>=</span> 0<span>;</span> i <span>&lt;</span> userTable<span>.</span><span>length</span><span>;</span> i<span>++)</span> <span>{</span>
	<span>int</span> hash <span>=</span> hash_function<span>(</span>userTable<span>[</span>i<span>].</span><span>name</span><span>)</span>
	hashIndex<span>[</span>hash<span>].</span><span>add</span><span>(</span>i<span>)</span>
<span>}</span>
</code></pre></div><p>We just created our own hash index. Let’s now run our query again:</p><div><pre><code data-lang="java"><span>// Our new index.
</span><span></span>List<span>&lt;</span><span>int</span><span>&gt;[]</span> hashIndex <span>=</span> <span>{...}</span>

<span>int</span> hash <span>=</span> hash_function_256<span>(</span><span>"Souleymane Laurence"</span><span>)</span>
List<span>&lt;</span><span>int</span><span>&gt;</span> foundTids <span>=</span> hashIndex<span>[</span>hash<span>]</span>
</code></pre></div><p>That’s it, and that was quick as hell 🔥. Back to SQL:</p><div><pre><code data-lang="sql"><span>SELECT</span> <span>COUNT</span>(<span>*</span>) <span>FROM</span> <span>user</span> <span>WHERE</span> name <span>=</span> <span>'Souleymane Laurence'</span>;
</code></pre></div><p><img src="https://fabien.herfray.org/images/mastering-postgres-indexes-in-10-minutes/hash.png" alt="hash"></p><h3 id="tldr">TLDR</h3><ul><li>The hash index was never very popular for a few reasons:<ul><li>Before Postgres 10, hash indexes were not properly supported. In particular they were not recorded in the write-ahead log so they could not be recovered after a failure/incident.</li><li>They only index the <code>=</code> operator and also don’t help with sorting. They’re not very flexible and for <code>=</code>, the B-Tree does the job very well too.</li></ul></li><li>So why should you use a hash index? Probably you shouldn’t. But they are smaller in size and can be faster than B-Trees so they can be useful under certain conditions. The read time being constant (<code>O(1)</code> vs <code>O(log n)</code> for B-Trees), they could for example benefit us for a high throughput of lookups by ID on a huge table.</li></ul><h3 id="further-explanation-1">Further explanation</h3><ul><li><a href="https://habr.com/en/company/postgrespro/blog/442776">https://habr.com/en/company/postgrespro/blog/442776</a></li><li><a href="https://medium.com/@jorsol/postgresql-10-features-hash-indexes-484f319db281">https://medium.com/@jorsol/postgresql-10-features-hash-indexes-484f319db281</a></li></ul><h2 id="gin-generalized-inverted-index">GIN (Generalized Inverted Index)</h2><h3 id="usecase-2">Usecase</h3><p>GIN indexes are mostly useful for indexing multi-valued columns (e.g. arrays, full-text search).</p><p>Let’s add a <code>favorite_colors</code> column to our users:</p><div><pre><code data-lang="sql"><span>ALTER</span> <span>TABLE</span> <span>user</span> <span>ADD</span> <span>COLUMN</span> favorite_colors TEXT[];
</code></pre></div><p>We want to be able to index a query that looks up users that have <code>red</code> and <code>blue</code> in their favorite colors:</p><div><pre><code data-lang="sql"><span>SELECT</span> <span>COUNT</span>(<span>*</span>) <span>FROM</span> <span>user</span> <span>WHERE</span> favorite_colors <span>@&gt;</span> <span>'{red,blue}'</span>;
</code></pre></div><p>We now create a GIN index:</p><div><pre><code data-lang="sql"><span>CREATE</span> <span>INDEX</span> user_by_favorite_colors <span>ON</span> <span>user</span> <span>USING</span> GIN (favorite_colors);
</code></pre></div><h3 id="how-does-it-work-2">How does it work</h3><p>Spoiler alert: GIN indexes are actually custom B-Trees where the multi-valued columns (arrays for example) are flattened 😱.
The only difference is that we’re adding a bitmap scan at the end of the operation for multi-value lookups.</p><p>Let’s run our query:</p><div><pre><code data-lang="sql"><span>SELECT</span> <span>COUNT</span>(<span>*</span>) <span>FROM</span> <span>user</span> <span>WHERE</span> favorite_colors <span>@&gt;</span> <span>'{red,blue}'</span>;
</code></pre></div><p><img src="https://fabien.herfray.org/images/mastering-postgres-indexes-in-10-minutes/gin.png" alt="gin"></p><h3 id="tldr-1">TLDR</h3><ul><li>GIN indexes are useful to index multi-valued columns (e.g. arrays or for full-text search).</li><li>It makes the array operations like <code>&amp;&amp;</code>, <code>&lt;@</code>, <code>=</code>, or <code>@&gt;</code> faster.</li><li>Unlike with B-Trees, multicolumn GIN search effectiveness is the same regardless of the columns used in the query conditions. It comes from the fact that, like for array values, GIN indexes the different columns in separate B-Trees and combines the results at querying time with a bitmap scan.</li></ul><h3 id="further-explanation-2">Further explanation</h3><ul><li><a href="http://www.louisemeta.com/blog/indexes-gin/">http://www.louisemeta.com/blog/indexes-gin/</a></li><li><a href="https://towardsdatascience.com/how-gin-indices-can-make-your-postgres-queries-15x-faster-af7a195a3fc5">https://towardsdatascience.com/how-gin-indices-can-make-your-postgres-queries-15x-faster-af7a195a3fc5</a></li><li><a href="https://www.postgresql.org/docs/13/gin-implementation.html">https://www.postgresql.org/docs/13/gin-implementation.html</a></li></ul><h2 id="gist-generalized-inverted-seach-tree">GiST (Generalized Inverted Seach Tree)</h2><h3 id="usecase-3">Usecase</h3><p>Ok let’s sum it up:</p><ul><li>Hash indexes only support the <code>=</code> operator.</li><li>B-Trees support operators like <code>&lt;</code>, <code>&gt;</code> and <code>=</code>.</li><li>GIN support operators like <code>&amp;&amp;</code>, <code>@&gt;</code> or <code>&lt;@</code> for multi-valued column queries.</li></ul><p>GiST indexes go one step further and allow indexation of complex custom operators: geospacial queries for example.</p><p>Let’s add two <code>location_lat</code> and <code>location_lon</code> columns to our users:</p><div><pre><code data-lang="sql"><span>ALTER</span> <span>TABLE</span> <span>user</span> <span>ADD</span> <span>COLUMN</span> location_lat FLOAT8, <span>ADD</span> <span>COLUMN</span> location_lon FLOAT8;
</code></pre></div><p>We want to be able to index a query that returns all …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fabien.herfray.org/posts/mastering-postgres-indexes-in-10-minutes/">https://fabien.herfray.org/posts/mastering-postgres-indexes-in-10-minutes/</a></em></p>]]>
            </description>
            <link>https://fabien.herfray.org/posts/mastering-postgres-indexes-in-10-minutes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25428453</guid>
            <pubDate>Tue, 15 Dec 2020 09:10:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to install FreeBSD on Raspberry Pi? (step-by-step guide) – RaspberryTips]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25428110">thread link</a>) | @rodrigo975
<br/>
December 15, 2020 | https://raspberrytips.com/install-freebsd-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://raspberrytips.com/install-freebsd-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5144"><div itemprop="articleBody"><p><span data-ez-name="raspberrytips_com-box-3"></span>FreeBSD is an original operating system you can install on Raspberry Pi to experiment a bit outside Linux. But the process is not always easy if you are used to working on Debian-like systems.<br>Today, we’ll see how to install it on a Raspberry Pi, to configure it and use it like almost like any other operating system.</p><p><strong>FreeBSD is an open-source operating system, available on Raspberry Pi since 2014. It’s a good solution for any usage (server or desktop)<br>It’s not based on Linux, as they develop their code for everything. Even if there are many similarities, it includes several differences, more or less visible.</strong><span data-ez-name="raspberrytips_com-medrectangle-3"></span></p><p><span data-ez-name="raspberrytips_com-medrectangle-4"></span>To help you as much as possible, I will start by an introduction to FreeBSD, then I’ll show you how to install it, and finally, everything you need to know to use it the way you want.</p><p><strong>Note:</strong> <em>I’m not an expert in BSD systems. I’m a fan of Pfsense which is based on FreeBSD, but I never really used it beside that. The goal here is only to share with you my notes about this system.</em></p><h2><span id="FreeBSD_introduction"></span>FreeBSD introduction<span></span></h2><h3><span id="Presentation"></span>Presentation<span></span></h3><p><strong>FreeBSD is not a new system, far from that. The first release comes in 1993! (same year as Debian).<br></strong>The main goal is to offer a lightweight system, with critical part related to stability. So you can use it almost anywhere.</p><div><figure><img loading="lazy" width="500" height="183" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI1MDAiIGhlaWdodD0iMTgzIj48L3N2Zz4=" alt="" sizes="(max-width: 500px) 100vw, 500px" ezimgfmt="rs rscb30 src ng ngcb30 srcset" data-ezsrc="https://raspberrytips.com/wp-content/uploads/2020/08/freebsd-logo.jpg" data-ezsrcset="https://raspberrytips.com/wp-content/uploads/2020/08/freebsd-logo.jpg 500w,https://raspberrytips.com/wp-content/uploads/2020/08/freebsd-logo-300x110.jpg 300w"></figure></div><p>FreeBSD works on two branches :</p><ul><li><strong>STABLE</strong>: The main branch, each new major version is released from the STABLE branch (<strong>RELEASE</strong>)</li><li><strong>CURRENT</strong>: It’s the development branch, to get the latest improvements, but less speed and stability.</li></ul><div><div><div><p><a href="https://raspberrytips.com/master-raspberry-pi" target="_blank"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMDAiIGhlaWdodD0iMjczIj48L3N2Zz4=" ezimgfmt="rs rscb30 src ng ngcb30" data-ezsrc="https://raspberrytips.com/wp-content/uploads/2020/10/1603165223-300x273.jpg"></a></p><div><p><span>Master your Raspberry Pi in 30 days</span><br>From beginner to expert in Raspberry Pi.<br>Learn useful Linux skills and practice multiples projects with step-by-step guides.</p></div></div></div></div><h3><span id="Usage"></span>Usage<span></span></h3><p><strong>FreeBSD can be used in any situation. It’s fast, stable and secure</strong>. So it’s perfect for a Raspberry Pi, but also for a server or a desktop usage.<br>By the way, the FreeBSD FAQ is pretty clear about this:</p><blockquote><p><strong>Can FreeBSD replace my current operating system?<br></strong>For most people, yes.</p><cite><a href="https://www.freebsd.org/doc/en_US.ISO8859-1/books/faq/introduction.html#:~:text=the%20FreeBSD%20Handbook.-,1.2.,any%20purpose%20without%20strings%20attached." target="_blank" rel="noreferrer noopener">FreeBSD documentation</a></cite></blockquote><p>We’ll see in the next parts how to install it on your Raspberry Pi, but it’s also a solid system for your computer or on server.</p><p><strong>FreeBSD has been adopted by many companies over the world.<br></strong>I already told you about Pfsense, but other brands like IBM, Apple or Sony are using parts of the FreeBSD code (for example, the PlayStation 4 system is a fork from FreeBSD).<br>Some NAS operating systems are also based on FreeBSD (FreeNAS for example).</p><h3><span id="FreeBSD_vs_Linux"></span>FreeBSD vs Linux<span></span></h3><p>As I told you in introduction, <strong>FreeBSD is not a Linux-based system</strong>.<br>Systems on Linux, are all using the same kernel and basic drivers, and then add many applications to offer a specific solution at the end.</p><p><strong>FreeBSD don’t use this base, they develop and release everything, including the kernel and drivers.</strong><br>However, the differences while using it are minimal (I will show you the main ones).<br>But you may have some commands working differently on Linux and FreeBSD.</p><h3><span id="FreeBSD_strengths"></span>FreeBSD strengths<span></span></h3><p>So, why do I need to try FreeBSD if it’s almost the same thing?<br>As always when I test systems, the main goal here is to experiment, and see how it works. So you’ll get more details at the end.</p><p>But in theory, <strong><span data-ez-name="raspberrytips_com-large-leaderboard-2"></span>FreeBSD is a minimal system that should be faster, more secure and with less compatibility issues than most Linux systems</strong>.<br>We’ll see now if this is true for the Raspberry Pi version 🙂</p><h2><span id="Install_FreeBSD_on_Raspberry_Pi"></span>Install FreeBSD on Raspberry Pi<span></span></h2><p>In this part, we’ll see how to install a basic FreeBSD system on your Raspberry Pi.</p><h3><span id="Raspberry_Pi_4"></span>Raspberry Pi 4<span></span></h3><p>During writing this tutorial, <strong>the Raspberry Pi 4 is not yet supported on the RELEASE version</strong> (12.x). But it works on CURRENT version (13.x).</p><p>So, if you have a Raspberry Pi 4, consider taking the latest version available. Currently, the 13.x and above are the only working for Raspberry Pi 4.<br>Unfortunately, if t’s a CURRENT version, it’s a debug one, with less stability and performances issues. But for a test it’s ok.</p><p><span data-ez-name="raspberrytips_com-leader-1"></span>The other option is to use a custom firmware, <a rel="noreferrer noopener" href="https://github.com/pftf/RPi4" target="_blank">available here on GitHub</a>, and replace the files on the SD card for the RELEASE version.</p><div><div><div><p><a href="https://raspberrytips.com/post-bootcamp" target="_blank"><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMDAiIGhlaWdodD0iMjczIj48L3N2Zz4=" ezimgfmt="rs rscb30 src ng ngcb30" data-ezsrc="https://raspberrytips.com/wp-content/uploads/2020/12/course-illustration-1.jpg"></a></p><div><p><span>Raspberry Pi Course</span><br>Let me guide you to discover the Raspberry Pi.<br>A step-by-step course to get started on Raspberry Pi OS and complete your first projects.</p></div></div></div></div><h3><span id="Download"></span>Download<span></span></h3><p><strong>FreeBSD offers pre-built images for the ARM and ARM64 architecture.<br></strong>The ARM64 version is working fine on Pi 3B+ and 4, I didn’t test on other models.</p><p>Here is the general link to the FTP server: <a href="https://download.freebsd.org/ftp/snapshots/">https://download.freebsd.org/ftp/</a><br>Once here, you have two choices:</p><ul><li><strong>Download the RELEASE version:</strong><ul><li>Open the releases subfolder and go to <a rel="noreferrer noopener" href="https://download.freebsd.org/ftp/releases/ISO-IMAGES/" target="_blank">ISO-IMAGES</a>.</li><li>Select the version you want to install (12.1 for example).</li><li>Then, find the image corresponding to your Raspberry Pi model.<br>For example:<br><code>FreeBSD-12.1-RELEASE-arm64-aarch64-RPI3.img.xz</code><br>If you have the Raspberry Pi 3 (look for arm architecture, and the last part of the name correspond to the Raspberry Pi model).</li></ul></li><li><strong>Download the CURRENT version:</strong><ul><li>Go to snapshots and then <a rel="noreferrer noopener" href="https://download.freebsd.org/ftp/snapshots/ISO-IMAGES/" target="_blank">ISO-IMAGES</a>.</li><li>Select the version you want (13.0 for example).</li><li>Same thing here, find the FreeBSD images corresponding to your model, for example:<br><code>FreeBSD-13.0-CURRENT-arm64-aarch64-RPI3-20200813-r364182.img.xz</code><br>Currently, there is no specific version for the Raspberry Pi 4, so take the RPI3 one.</li></ul></li></ul><p>Download the file you need on this server, and feel free to ask in the comments if you are lost with this, or if I need to update it for the latest versions.</p><h3><span id="SD_card_preparation"></span>SD card preparation<span></span></h3><p>Once you have the image on your computer, the installation part is similar to what you may already know with other systems.<br>My favorite tool to create SD card is Etcher, here is how to use it:</p><ul><li><strong>Download Etcher <a rel="noreferrer noopener" href="https://www.balena.io/etcher/" target="_blank">on the official website</a> here if needed.</strong><br>It’s available on any system (Windows, Linux, macOS).<br>I didn’t try on FreeBSD 🙂</li><li><strong>Install it and start the application</strong>, the window looks like this:<br><img loading="lazy" width="1000" height="260" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMDAwIiBoZWlnaHQ9IjI2MCI+PC9zdmc+" alt="etcher menu" sizes="(max-width: 1000px) 100vw, 1000px" ezimgfmt="rs rscb30 src ng ngcb30 srcset" data-ezsrc="https://raspberrytips.com/wp-content/uploads/2019/01/etcher.jpg" data-ezsrcset="https://raspberrytips.com/wp-content/uploads/2019/01/etcher.jpg 1000w,https://raspberrytips.com/wp-content/uploads/2019/01/etcher-300x78.jpg 300w,https://raspberrytips.com/wp-content/uploads/2019/01/etcher-768x200.jpg 768w,https://raspberrytips.com/wp-content/uploads/2019/01/etcher-1024x266.jpg 1024w,https://raspberrytips.com/wp-content/uploads/2019/01/etcher-100x26.jpg 100w,https://raspberrytips.com/wp-content/uploads/2019/01/etcher-864x225.jpg 864w,https://raspberrytips.com/wp-content/uploads/2019/01/etcher-800x208.jpg 800w"></li><li><strong>Click on “Select image” </strong>and browse to the FreeBSD image location (you don’t need to extract the files).</li><li><strong>Insert your SD card</strong> into your computer.<br>Etcher will select it automatically.</li><li>Then, <strong>click on “Flash!” </strong>to start the SD card creation.</li></ul><p>After a few minutes, your SD card is ready to use.</p><h3><span id="First_boot"></span>First boot<span></span></h3><p>On the first boot, a terminal prompt will appear where you need to log in.<br>There are two users available by default:</p><ul><li><strong>freebsd is the default user, the password is freebsd</strong></li><li><strong>root is the administrator, the password is root</strong></li></ul><p>Connect with root for now and continue to the next part.</p><p>If you want,<strong> SSH is enabled by default</strong>, so you can absolutely continue from your computer once the network cable plugged.<br>But the root user is not accessible directly with SSH. You need to connect with “freebsd” and then use “su” to switch to the root user.<br>There is no sudo command available by default.</p><h2><span id="Configure_FreeBSD_on_Raspberry_Pi"></span>Configure FreeBSD on Raspberry Pi<span></span></h2><p>Once installed and logged in, it’s time to check that everything is configured properly.</p><h3><span id="Packages_management"></span>Packages management<span></span></h3><p>With the tool I show you just after, you can manage almost everything in your configuration, but t<strong>he “Packages” part didn’t work for me</strong> (didn’t found the server).<br>So we have to do this manually.</p><p><span data-ez-name="raspberrytips_com-leader-2"></span><strong>The package management tool on FreeBSD is “pkg”.<br></strong>It works almost the same thing as “apt” or any other tool in command line.<br>I’ll show you how to use it later, but for now, you have to install it with this command (with the root user):<br><code>pkg clean -a &amp;&amp; pkg upgrade -f</code></p><h3><span data-ez-name="raspberrytips_com-leader-3"></span><span id="Configuration_tool"></span>Configuration tool<span></span></h3><p><strong>There is a tool on FreeBSD to manage most of the configuration from the terminal </strong>(a bit like “raspi-config” on Raspberry Pi OS).<br>To open it, enter the command:<br><code>bsdconfig</code></p><p>The main menu looks like this:<br><img loading="lazy" width="400" height="394" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI0MDAiIGhlaWdodD0iMzk0Ij48L3N2Zz4=" alt="" sizes="(max-width: 400px) 100vw, 400px" ezimgfmt="rs rscb30 src ng ngcb30 srcset" data-ezsrc="https://raspberrytips.com/wp-content/uploads/2020/08/bsd-config.jpg" data-ezsrcset="https://raspberrytips.com/wp-content/uploads/2020/08/bsd-config.jpg 400w,https://raspberrytips.com/wp-content/uploads/2020/08/bsd-config-300x296.jpg 300w"></p><p>Use the arrows to scroll to the part that you need to change, and follow the instructions to configure it (if you are connected with SSH, the mouse is working).</p><p>For example, to change the root password (which is recommended), go to “Root Password” and enter the new one.</p><h3><span id="Network_configuration"></span>Network configuration<span></span></h3><p><strong>The network will work directly with an Ethernet cable if there is a DHCP server on the network</strong> (your router probably).<br>If not, you can go to “Networking Management” in bsdconfig and set a static IP</p><figure><img loading="lazy" width="400" height="240" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI0MDAiIGhlaWdodD0iMjQwIj48L3N2Zz4=" alt="" sizes="(max-width: 400px) 100vw, 400px" ezimgfmt="rs rscb30 src ng ngcb30 srcset" data-ezsrc="https://raspberrytips.com/wp-content/uploads/2020/08/network-management.jpg" data-ezsrcset="https://raspberrytips.com/wp-content/uploads/2020/08/network-management.jpg 400w,https://raspberrytips.com/wp-content/uploads/2020/08/network-management-300x180.jpg 300w"></figure><p><strong>The Wi-Fi is not supported yet</strong>, as the driver is not included in the image.<br>You can try a USB stick to fix this (<a rel="noreferrer noopener" href="https://www.amazon.com/dp/B002PD61Y4/" target="_blank">my DLINK model</a> didn’t work, but maybe there is something to install).</p><p><strong>Note</strong>: Personally, I’m using a Wi-Fi extender to plug Ethernet cable on systems that doesn’t support Wi-Fi for Raspberry Pi. <a href="https://www.amazon.com/dp/B0195Y0A42/" target="_blank" rel="noreferrer noopener">This one on Amazon</a> is working perfectly in this case if you are interested.</p><h3><span id="Users_and_groups"></span>Users and groups<span></span></h3><p>As I told you, two users are already there after the first boot: freebsd and root. But you can obviously change this as you want.</p><figure><img loading="lazy" width="350" height="268" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzNTAiIGhlaWdodD0iMjY4Ij48L3N2Zz4=" alt="" sizes="(max-width: 350px) 100vw, 350px" ezimgfmt="rs rscb30 src ng ngcb30 srcset" data-ezsrc="https://raspberrytips.com/wp-content/uploads/2020/08/users-management.jpg" data-ezsrcset="https://raspberrytips.com/wp-content/uploads/2020/08/users-management.jpg 350w,https://raspberrytips.com/wp-content/uploads/2020/08/users-management-300x230.jpg 300w"></figure><p>In the “Login/Group Management” from bsdconfig, you can:</p><ul><li><strong>Manage users:</strong><ul><li><span>Add Login</span> to create a new user.</li><li><span>Edit/View Login</span> to see a list of current accounts on the system. In addition to the two we are using, there are many more. You can also change them in this submenu. For example, I recommend editing the password for freebsd too.</li><li><span>Delete Login</span>: only do this once you have tested that everything is working without it. For example, you can create a “pi” account and remove “freebsd”.</li></ul></li><li><strong>Manage groups:</strong><ul><li>It’s almost the same thing as for the users.</li><li>You don’t really need this except for specific applications.</li><li>To add a user in a group, you’ll probably use the Edit/View Login menu.</li></ul></li></ul><p>For your information, <strong>the “wheel” group add the permission to use “su”.</strong><br>So, if you create a new user (like “pi” in my example), you need to add it in the “wheel” group if you want it to switch to the administrator account.</p><h2><span data-ez-name="raspberrytips_com-leader-4"></span>Extra tips<span></span></h2><p>In this last part, I’ll share with you a few other things that may be important depending on your current level on FreeBSD.</p><h3><span id="The_pkg_command"></span>The pkg command<span></span></h3><p>We already used the “pkg” command to manage packages that is the main change with Debian.<br>Here is a few examples on how to use it:</p><ul><li><strong>pkg update</strong>: update the depository sources</li><li><strong>pkg upgrade</strong>: upgrade the packages you are already using on the system</li><li><strong>pkg search &lt;string&gt;</strong>: find the package you want to install, example:<br><img loading="lazy" width="800" height="192" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI4MDAiIGhlaWdodD0iMTkyIj48L3N2Zz4=" alt="" sizes="(max-width: 800px) 100vw, 800px" ezimgfmt="rs rscb30 src ng ngcb30 srcset" data-ezsrc="https://raspberrytips.com/wp-content/uploads/2020/08/sudo.jpg" data-ezsrcset="https://raspberrytips.com/wp-content/uploads/2020/08/sudo.jpg 800w,https://raspberrytips.com/wp-content/uploads/2020/08/sudo-300x72.jpg 300w,https://raspberrytips.com/wp-content/uploads/2020/08/sudo-768x184.jpg 768w"></li><li><strong>pkg install &lt;package&gt;</strong>: install the package you want, example:<br><code>pkg install nano</code></li><li><strong>pkg remove &lt;package&gt;</strong>: uninstall any package on the system</li><li><strong>pkg help</strong>: get a list of all other options available</li></ul><p>As you can see, it’s really close from apt, yum or any other package management tool you might know. So, it should not be complicated to switch for …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raspberrytips.com/install-freebsd-raspberry-pi/">https://raspberrytips.com/install-freebsd-raspberry-pi/</a></em></p>]]>
            </description>
            <link>https://raspberrytips.com/install-freebsd-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25428110</guid>
            <pubDate>Tue, 15 Dec 2020 08:07:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a garbage-free network stack for Kafka streams]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25428063">thread link</a>) | @bluestreak
<br/>
December 14, 2020 | https://questdb.io/blog/2020/12/10/building-a-garbage-free-network-stack-for-kafka-streams | <a href="https://web.archive.org/web/*/https://questdb.io/blog/2020/12/10/building-a-garbage-free-network-stack-for-kafka-streams">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><figure><img alt="Steam network of a Pennsylvania coal power plant" height="433" src="https://questdb.io/img/blog/2020-12-10/banner.jpg" width="650"><figcaption>Photo by <a href="https://unsplash.com/photos/a_PDPUPuNZ8" target="_blank" rel="noopener noreferrer">Martin Adams</a> on <a href="https://unsplash.com/" target="_blank" rel="noopener noreferrer">Unsplash</a></figcaption></figure><p>Garbage collection is a type of automatic memory management that's used in many
modern programming languages. The point of the garbage collector is to free up
memory used by objects which are no longer being used by a program. Although
it's convenient for developers not to think about manually deallocating memory,
it can be a poisoned chalice that comes with several hard-to-predict downsides.</p><h2>When garbage adds up<a href="#when-garbage-adds-up" title="Direct link to heading">#</a></h2><p>Some garbage collectors completely halt the program's execution to make sure no
new objects are created while it cleans up. To avoid these unpredictable
<strong>stop-the-world</strong> pauses in a program, incremental and concurrent garbage
collectors were developed. Although they provide great benefit in many cases,
there's additional design choices that wind up back into development phases
where you have to indirectly deal with memory allocation.</p><p>Another issue is that garbage collectors themselves consume resources to decide
what to free up, which can add considerable overhead. Environments dealing with
real-time data are latency-sensitive and require high performance and
efficiency. In these applications, unpredictable halting behavior combined with
excess computation time or memory usage is not acceptable.</p><p>As we're building an open source high-performance time series database, we have
these environments in mind and use design patterns and tooling that focuses on
writing code that's efficient and reliable. When we need additional
functionality that would introduce performance knocks through standard
libraries, we can leverage our own implementations using native methods. This is
what prompted us to add a network stack that executes garbage-free.</p><p>This component bypasses Java's native non-blocking IO with our own notification
system. This component's job is to delegate tasks to worker threads and use
queues for events and TCP socket connections. The result is a new generic
network stack used to handle all incoming network connections.</p><h2>TCP flow control<a href="#tcp-flow-control" title="Direct link to heading">#</a></h2><p>When we have multiple nodes on a network, there are usually disparities in their
performance in computing power and network bandwidth. Some nodes can read
incoming packets at different rates than others, or conversely, some nodes may
be able to send data at a different rate.</p><p>Let's say we have a network with two nodes; a sender and a receiver. If the
sender can produce a lot more data than the receiver can read, the receiver is
likely to be overwhelmed. We're in luck, though, as TCP uses a built-in flow
control protocol that acts as a pressure valve to ensure the receiver is not
affected by such cases.</p><p>Control flow manifests itself in different ways, depending on whether the
network socket is blocking or non-blocking. If the receiver can process data
faster than a sender, a non-blocking socket is identical to a blocking one, and
the receiver thread would be parked while no data is read. There's not much
concern about this situation if it happens infrequently, but the park and unpark
is a waste of resources and CPU cycles if the receiver is under heavy load.</p><p>Let's assume the receiver gets 0-length data on a non-blocking socket,
indicating no data has arrived from the sender; there are two options:</p><ol><li>Loop over socket reads continuously, waiting for data to arrive.</li><li>Stop looping and consult our parser on two possible actions to take: park for
more reads or switch to write.</li></ol><p>The first option is quite wasteful, so we went with the second approach. To park
socket read operations without blocking the thread, we need a dedicated system
for enqueuing and notifying us when the socket has more data to read. On the OS
kernel level, IO notification utilities exist as <code>epoll</code> on Linux, <code>kqueue</code> on
FreeBSD and OSX, and <code>select</code> on Windows. In QuestDB, we've implemented a
dispatcher that operates exactly as these IO notification systems for enqueuing
sockets, and we named it IODispatcher.</p><h2>Java NIO and garbage collection<a href="#java-nio-and-garbage-collection" title="Direct link to heading">#</a></h2><p>As you would expect from cross-platform languages, the IO Notification system
must be abstracted away to make application code portable. In Java, this
abstraction is called <code>Selector</code>. If we were to oversimplify a typical
interaction with the IO Notification system, it would essentially be a loop.
More often than not, this is an infinite loop, or rather, it executes
continuously during the server's uptime.</p><p>Since we are on a quest to have everything garbage-free, Selector presents a
problem right away - the output of the selector is a set of keys, coming from a
concurrent hash map via an iterator. All of this allocates objects on every
iteration of the loop. If you are not careful, this allocation continues even
when the server is idling. The behavior is intrinsic to the Java Non-blocking
I/O (NIO) implementation and cannot be changed.</p><p>To send or receive data from the network, Java mandates ByteBuffer instances.
When looked at in a vacuum, ByteBuffer may seem like a reasonable abstraction.
But if we look closer, it's easy to see it's a bit confused. It is a concrete
class instead of an interface, meaning that the whole NIO is stuck with the
provided implementation. The API is inconsistent as the OS requires memory
pointers for send and receive methods, but ByteBuffer does not provide an
explicit semantic for each case. So how does ByteBuffer translate to a memory
pointer?</p><p>When your data is on the heap, there is a memory copy for each socket IO. When
ByteBuffer is direct, there is no copy, but there is an issue releasing memory
and general Java paranoia about language safety.</p><div><p>Native Java socket write implementation</p></div><p>Considering the allocating nature of the Selector, that Java NIO libraries are a
layer above the OS, and how computationally expensive the overhead is with
ByteBuffer, we decided to go out on a limb and interact directly with the OS via
the Java Native Interface (JNI). This worked for QuestDB insofar as the API is
non-allocating outside of the normal bootstrap phase and lets us work with the
memory pointers directly.</p><div><p>QuestDB's JNI call for sending data to a socket</p></div><h2>QuestDB's thread model<a href="#questdbs-thread-model" title="Direct link to heading">#</a></h2><p>Starting threads is expensive, and they're more often than not just wrappers for
the connection state. QuestDB operates a fixed number of threads to isolate the
database instance to specific cores and reduce the overhead of starting and
stopping threads at runtime. The actual threads are encapsulated by a WorkerPool
class.</p><p>The worker pool's idea is to have a simple list of "jobs" that all workers will
run all the time. Jobs themselves encapsulate "piece of work" and do not have
tight loops in them. Hence a job can simply return if IO is not available or the
queue is full or empty.</p><p>We have a notion of a "synchronized job." It is different from the definition of
"synchronized" in Java in that the QuestDB's thread never blocks. However,
synchronized jobs guarantee that only one thread can execute a job instance at
any moment in time.</p><h2>Introducing QuestDB's IODispatcher<a href="#introducing-questdbs-iodispatcher" title="Direct link to heading">#</a></h2><p>IODispatcher is QuestDB's implementation of the IO Notification loop. We have
implemented <code>epoll</code>, <code>kqueue</code>, and <code>select</code>, so this works cross-platform. The
appropriate implementation is automatically chosen at runtime based on the OS.
The IODispatched API is message-driven via QuestDB's implementation of
non-blocking and non-allocating queues. These queues are outside of the scope of
this article, but you can read about them in our community
<a href="https://questdb.io/blog/2020/11/26/http-server-contribution">contribution from Alex Pelagenko</a>.</p><figure><img alt="A diagram of QuestDB's IODispatcher" height="284" src="https://questdb.io/img/blog/2020-12-10/iodispatcher-diagram.png" width="650"><figcaption>IODispatcher and queues for events, interest, and disconnections</figcaption></figure><p>IODispatcher is a synchronized job in context of QuestDB's thread model. It
consumes queues on the left and publishes to the queue on the right.
IODispatcher's main responsibility is to deliver socket handles (individual
connection identifiers), that are ready for the IO to the worker threads.
Considering that socket handles are read or written to by one thread at a time
the underlying IO notification system works in ONESHOT mode. This means socket
handle is removed from the IO notification system while there is socket activity
and re-introduced back when activity tapers off. Interacting with the IO
notification system is expensive. Worker thread will only recurse back to the
IODispatcher for enqueueing if there has been zero data from the socket for the
set period of time, which we call hysteresis.</p><p>You can find source code of the implementations of the IODispatcher for
<a href="https://github.com/questdb/questdb/blob/master/core/src/main/java/io/questdb/network/IODispatcherLinux.java" target="_blank" rel="noopener noreferrer">epoll</a>
,
<a href="https://github.com/questdb/questdb/blob/master/core/src/main/java/io/questdb/network/IODispatcherOsx.java" target="_blank" rel="noopener noreferrer">kqueue</a>
and
<a href="https://github.com/questdb/questdb/blob/master/core/src/main/java/io/questdb/network/IODispatcherWindows.java" target="_blank" rel="noopener noreferrer">select</a>
on GitHub. Let's take a look at the components in the diagram above with an
outline of their purpose:</p><p><strong>IO Event Queue:</strong> Single publisher, multiple consumer queue. It is the
recipient of the IO events from as in epoll, kqueue, select. The events are
socket handles and the type of operation the OS has associated them with, e.g.,
read or write. The IODispatcher plays the publisher role, and any number of
worker threads are the consumers.</p><p><strong>Interest Queue:</strong> Multiple publisher, single consumer queue. Worker threads
publish socket handles and operations to this queue when IO is unavailable,
e.g., socket read or write returns zero. The IODispatcher will enqueue the
socket handle for more reads or writes as defined by the operation.</p><p><strong>Disconnect Queue:</strong> Multiple publisher, single consumer queue. Worker threads
publish socket handles to this queue destined to be disconnected from the server
and have their resources reused by other connections. The worker thread does not
disconnect the socket by itself because multiple threads may attempt to access a
data structure that is not thread-safe.</p><h3>Configuration<a href="#configuration" title="Direct link to heading">#</a></h3><p>We disregarded ByteBuffer for not being an interface, so it would only be fair
for us to have interfaces in key places. One of these places is configuration,
which provides IODispatcher with basics such as:</p><ul><li>The IP address of the network interface</li><li>Port to bind to</li><li>Bias</li><li>Buffer sizes</li><li>Network facade</li><li>Clock facade</li><li>Connection context factory</li></ul><p>It's necessary to explain bias here, which might not be so obvious. When the TCP
connection is first accepted, it is enqueued for IO right away. The bias
provides an expectation of the initial …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://questdb.io/blog/2020/12/10/building-a-garbage-free-network-stack-for-kafka-streams">https://questdb.io/blog/2020/12/10/building-a-garbage-free-network-stack-for-kafka-streams</a></em></p>]]>
            </description>
            <link>https://questdb.io/blog/2020/12/10/building-a-garbage-free-network-stack-for-kafka-streams</link>
            <guid isPermaLink="false">hacker-news-small-sites-25428063</guid>
            <pubDate>Tue, 15 Dec 2020 07:59:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Saudi Arabia applied for diplomatic immunity for ten security guards in Norway]]>
            </title>
            <description>
<![CDATA[
Score 169 | Comments 100 (<a href="https://news.ycombinator.com/item?id=25427829">thread link</a>) | @elygre
<br/>
December 14, 2020 | https://www.dagbladet.no/nyheter/the-saudi-security-team-to-norway/73159458 | <a href="https://web.archive.org/web/*/https://www.dagbladet.no/nyheter/the-saudi-security-team-to-norway/73159458">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">

<p>In the early summer of 2018, Norway received an unusual request from Crown Prince Mohammed bin Salman's government.</p><p>Saudi Arabia wanted to send ten men on an official assignment to Norway, the Ministry of Foreign Affairs confirms to Dagbladet. The ten men were all security guards, who were deployed to work at the Saudi Arabian embassy in Norway, according to Dagbladet’s sources. But Saudi Arabia wanted the security guards to be registered as diplomats in Norway. This would give them extended room for manoeuvring in Norway.</p><p><strong>The Ministry of Foreign Affairs intervened, and the Norwegian Police Security Service (PST) has informed Iyad el-Baghdadi (43) - a Norway-based journalist, activist, and critic of the Saudi regime - about the incident. </strong></p><p>Dagbladet has asked the Saudi embassy several questions regarding this article. The embassy has responded with a press release they originally sent out last year, criticising "fabricated and false" accusations, "with the intent to insult Saudi Arabia."</p>
<p><em><strong>Update Thursday 17th of December:</strong> The Saudi Arabian Embassy in Oslo has replied specifically to the deplyment of the security team. Read the full comment further down in this article.</em></p><p>Dagbladet has received confirmation from several sources that there were several issues regarding the ten-man security team that made the Norwegian authorities react.</p><figure data-zoomable="1">
    
<picture>
    <source media="(max-width: 640px)" itemprop="image" srcset="https://www.dagbladet.no/images/73159968.jpg?imageId=73159968&amp;width=760&amp;height=434&amp;compression=70">
    <source media="(min-width: 641px and max-width: 1024px)" itemprop="image" srcset="https://www.dagbladet.no/images/73159968.jpg?imageId=73159968&amp;width=900&amp;height=513&amp;compression=80">
    <source media="(min-width: 1025px)" itemprop="image" srcset="https://www.dagbladet.no/images/73159968.jpg?imageId=73159968&amp;width=980&amp;height=559&amp;compression=80">
<img itemprop="image" data-defer="view" title="INTERVENED: The Norwegian Ministry of Foreign Affairs. Photo: Audun Braastad / NTB" alt="INTERVENED: The Norwegian Ministry of Foreign Affairs. Photo: Audun Braastad / NTB" srcset="https://www.dagbladet.no/images/73159968.jpg?imageId=73159968&amp;width=760&amp;height=434&amp;compression=70 640w,https://www.dagbladet.no/images/73159968.jpg?imageId=73159968&amp;width=900&amp;height=513&amp;compression=80 1024w,https://www.dagbladet.no/images/73159968.jpg?imageId=73159968&amp;width=980&amp;height=559&amp;compression=80 1240w" src="https://www.dagbladet.no/images/73159968.jpg?imageId=73159968&amp;width=980&amp;height=559">
</picture>
      
    
    


      <figcaption itemprop="caption" data-expand="" onclick="this.classList.add('active')">
        <strong>INTERVENED:</strong> The Norwegian Ministry of Foreign Affairs. Photo: Audun Braastad / NTB
          <span role="button">Vis mer</span>
      </figcaption>
</figure>
<h2>The crucial points</h2><p>• <strong>The number:</strong> The number of security guards was unusually high. The Ministry of Foreign Affairs regularly publishes a list of all foreign diplomats accredited to Norway. According to the diplomat list from the summer of 2018, the total number of Saudi diplomats in Norway at the time was 18. Both the Ministry of Foreign Affairs and the PST were surprised that the Saudis were about to almost double the number - with only security people.</p>
<p>• <strong>The status:</strong> Both the Ministry of Foreign Affairs and the PST were surprised that Saudi Arabia requested that the security guards be granted diplomatic status - and registered in the official <a href="https://www.regjeringen.no/no/dep/ud/dep/forbindelser/id447053/">Diplomat List</a>. It is unusual for security people at embassies to be registered as diplomats. Both diplomats and other embassy personell - arriving on a so-called «D-visa» to Norway - is given <a href="https://en.wikipedia.org/wiki/Diplomatic_immunity">diplomatic immunity</a>. Which, as one of several benefits, means that the host country cannot arrest you if you commit a crime. But being registered formally as a diplomat gives you a wider range of benefits.</p><p>• <strong>The increase:</strong> Norwegian authorities reacted to the fact that the major increase in security staff did not reflect what they knew regarding the activity level at the embassy.</p><p>• <strong>The key role:</strong> Officials at PST have later noted that security personnel, from the consulate in Istanbul, played key roles in the murder of the Saudi journalist Jamal Khashoggi, Dagbladet has learned.</p>
<p><strong>The PST declined to comment on this article, however, it has been presented with all the information herein – without finding any errors.</strong></p><figure data-zoomable="1">
    
<picture>
    <source media="(max-width: 640px)" itemprop="image" srcset="https://www.dagbladet.no/images/73159877.jpg?imageId=73159877&amp;width=760&amp;height=434&amp;compression=70">
    <source media="(min-width: 641px and max-width: 1024px)" itemprop="image" srcset="https://www.dagbladet.no/images/73159877.jpg?imageId=73159877&amp;width=900&amp;height=513&amp;compression=80">
    <source media="(min-width: 1025px)" itemprop="image" srcset="https://www.dagbladet.no/images/73159877.jpg?imageId=73159877&amp;width=980&amp;height=559&amp;compression=80">
<img itemprop="image" data-defer="view" title="MURDERED: Jamal Khashoggi was killed inside the Saudi Arabian consulate in Istanbul. The Norwegian PST later took note of the role played by the security staff at the consulate in conducting the killing. Photo: NTB" alt="MURDERED: Jamal Khashoggi was killed inside the Saudi Arabian consulate in Istanbul. The Norwegian PST later took note of the role played by the security staff at the consulate in conducting the killing. Photo: NTB" srcset="https://www.dagbladet.no/images/73159877.jpg?imageId=73159877&amp;width=760&amp;height=434&amp;compression=70 640w,https://www.dagbladet.no/images/73159877.jpg?imageId=73159877&amp;width=900&amp;height=513&amp;compression=80 1024w,https://www.dagbladet.no/images/73159877.jpg?imageId=73159877&amp;width=980&amp;height=559&amp;compression=80 1240w" src="https://www.dagbladet.no/images/73159877.jpg?imageId=73159877&amp;width=980&amp;height=559">
</picture>
      
    
    


      <figcaption itemprop="caption" data-expand="" onclick="this.classList.add('active')">
        <strong>MURDERED:</strong> Jamal Khashoggi was killed inside the Saudi Arabian consulate in Istanbul. The Norwegian PST later took note of the role played by the security staff at the consulate in conducting the killing. Photo: NTB
          <span role="button">Vis mer</span>
      </figcaption>
</figure>
<p>Guri Solberg, spokesperson at the Ministry of Foreign Affairs, confirms in an e-mail to Dagbladet:</p><p>“In the summer of 2018, the Ministry of Foreign Affairs registered ten persons as new envoys at the Saudi Arabian embassy in Oslo. The status of other countries' envoys to embassies is regulated by the Vienna Convention on Diplomatic Relations (1961) and the role of the envoy at the embassy. As these were mainly persons who were to have internal tasks at the embassy, nine of the ten persons were registered as administrative / technical personnel in accordance with normal practice. One of the ten people was registered as a diplomat based on their role and responsibilities. In practice, there is little difference in the degree of immunity and privileges granted to diplomatic, administrative, and technical personnel. The rules on immunity and privileges are dictated by international law by which Norway is bound, in particular the Vienna Convention of Diplomatic Relations, that includes immunity from criminal prosecution in the host state.”</p><figure data-zoomable="1">
    
<picture>
    <source media="(max-width: 640px)" itemprop="image" srcset="https://www.dagbladet.no/images/73159870.jpg?imageId=73159870&amp;x=0&amp;y=18.992654774397&amp;cropw=100&amp;croph=41.238195173137&amp;width=534&amp;height=306&amp;compression=70">
    <source media="(min-width: 641px and max-width: 1024px)" itemprop="image" srcset="https://www.dagbladet.no/images/73159870.jpg?imageId=73159870&amp;x=0&amp;y=18.992654774397&amp;cropw=100&amp;croph=41.238195173137&amp;width=632&amp;height=362&amp;compression=80">
    <source media="(min-width: 1025px)" itemprop="image" srcset="https://www.dagbladet.no/images/73159870.jpg?imageId=73159870&amp;x=0&amp;y=18.992654774397&amp;cropw=100&amp;croph=41.238195173137&amp;width=688&amp;height=394&amp;compression=80">
<img itemprop="image" data-defer="view" title="SPOKESWOMAN: Guri Solberg at the Ministry of Foreign Affairs. Photo: MFA" alt="SPOKESWOMAN: Guri Solberg at the Ministry of Foreign Affairs. Photo: MFA" srcset="https://www.dagbladet.no/images/73159870.jpg?imageId=73159870&amp;x=0&amp;y=18.992654774397&amp;cropw=100&amp;croph=41.238195173137&amp;width=534&amp;height=306&amp;compression=70 640w,https://www.dagbladet.no/images/73159870.jpg?imageId=73159870&amp;x=0&amp;y=18.992654774397&amp;cropw=100&amp;croph=41.238195173137&amp;width=632&amp;height=362&amp;compression=80 1024w,https://www.dagbladet.no/images/73159870.jpg?imageId=73159870&amp;x=0&amp;y=18.992654774397&amp;cropw=100&amp;croph=41.238195173137&amp;width=688&amp;height=394&amp;compression=80 1240w" src="https://www.dagbladet.no/images/73159870.jpg?imageId=73159870&amp;x=0&amp;y=18.992654774397&amp;cropw=100&amp;croph=41.238195173137&amp;width=688&amp;height=394">
</picture>
      
    
    


      <figcaption itemprop="caption" data-expand="" onclick="this.classList.add('active')">
        <strong>SPOKESWOMAN:</strong> Guri Solberg at the Ministry of Foreign Affairs. Photo: MFA
          <span role="button">Vis mer</span>
      </figcaption>
</figure>
<p><strong>Solberg adds: “For reasons of confidentiality, we cannot share details in individual cases.”</strong></p>
<p>The men arrived in Norway at the end of July 2018. The one security guard who received the diplomatic status Saudi Arabia requested, now works as Head of Security at the Saudi Arabian embassy, according to Dagbladet's sources. He is formally listed in the Foreign Ministry's diplomatic list as an "attaché".</p><div>
  <div>
      
<section id="middle-east-tips">
  
  <p> Skjult støtte fra autoritære stater </p>
  
  <img src="https://graphics.dbstatic.no/Grafikk/middle-east/mosk-lilla.svg" alt="moske grafikk">
  <img src="https://graphics.dbstatic.no/Grafikk/middle-east/money2.svg" alt="pengesedler">
  
</section>


  </div>
</div>
<p>“It was a discussion. There are regulations for the type of status that the embassies' security people can hold whilst staying in Norway. They are not diplomats”, a source familiar with the case tells Dagbladet.</p><div id="factbox-73180109" aria-expanded="false" tabindex="1">
    <h2>Facts: Diplomatic immunity in Norway</h2>
        
    
        <p>According to the Vienna Convention on Diplomatic Relations, all envoys from other countries have diplomatic immunity when they are working for their country’s embassy. This applies to both diplomats and administrative personnel, such as security staff. <br></p><p>However, different degrees of immunity are granted, according to the rank of the individual within the system. Only diplomats have full immunity. <br></p><p>Neither diplomats nor security staff at embassies can be prosecuted or subjected to taxation in Norway. Security staff (administrative personnel) do not, however, have immunity from civil proceedings arising from their conduct in private. Whilst diplomats can import as much as they desire tax-free for private use, administrative personnel are only exempt from customs duties on entry to a country. <br></p><p>Norway can sanction an envoy with diplomatic immunity by declaring them persona non grata in Norway.</p><p><em>Source: Ministry of Foreign Affairs</em></p>
            
        
    
</div>
<h2>The Embassy</h2><div id="parallax-73159994">
    <div>

        <div data-parallax-sticky="" data-parallax-fullwidth="" data-parallax-content-type="image" data-parallax-layer="0" data-parallax-height="100" data-parallax-spacebelow="0" data-parallax-horizontalalign-desktop="" data-parallax-horizontalalign-mobile="" data-parallax-verticalalign="top" data-parallax-verticalposition="auto">
            <figure data-zoomable="1">
    
<picture>
    <source media="(max-width: 640px)" itemprop="image" srcset="https://www.dagbladet.no/images/73159833.jpg?imageId=73159833&amp;width=760&amp;height=434&amp;compression=70">
    <source media="(min-width: 641px and max-width: 1024px)" itemprop="image" srcset="https://www.dagbladet.no/images/73159833.jpg?imageId=73159833&amp;width=900&amp;height=513&amp;compression=80">
    <source media="(min-width: 1025px)" itemprop="image" srcset="https://www.dagbladet.no/images/73159833.jpg?imageId=73159833&amp;width=980&amp;height=559&amp;compression=80">
<img itemprop="image" data-defer="view" title="" alt="" srcset="https://www.dagbladet.no/images/73159833.jpg?imageId=73159833&amp;width=760&amp;height=434&amp;compression=70 640w,https://www.dagbladet.no/images/73159833.jpg?imageId=73159833&amp;width=900&amp;height=513&amp;compression=80 1024w,https://www.dagbladet.no/images/73159833.jpg?imageId=73159833&amp;width=980&amp;height=559&amp;compression=80 1240w" src="https://www.dagbladet.no/images/73159833.jpg?imageId=73159833&amp;width=980&amp;height=559">
</picture>
      
    
    


      <figcaption itemprop="caption" data-expand="" onclick="this.classList.add('active')">
        
      </figcaption>
</figure>

        </div>
        <div data-parallax-content-type="text_subtitle" data-parallax-layer="1" data-parallax-height="100" data-parallax-spacebelow="0" data-parallax-horizontalalign-desktop="" data-parallax-horizontalalign-mobile="" data-parallax-verticalalign="top" data-parallax-verticalposition="auto">
            <p>
    <h3 itemprop="name headline">The Saudi Arabian Embassy in Norway is beautifully located on Skarpsno, on the west side of Oslo, its façade faces the Oslofjord.</h3>
</p>
    
        </div>


    </div>
    
</div>


<p>If you travel by sea to the Frognerstranda harbour, at times you can spot the Kingdom's characteristic green flag - with a white sabre, and the inscription "There is no god without Allah, and Muhammad is his prophet" - waving over the hedge. From a magnificent villa, designed in 1899 by the famed Norwegian architect Ingvar Hjorth, Saudi Arabia manages its activities in Norway.</p>
<p>Dagbladet has asked the Embassy in Oslo why they requested the security guards be granted diplomatic immunity, about the points Norway reacted to, about the Embassy’s relationship with the activist Iyad el-Baghdadi, and about why the Embassy wanted to increase the number of security guards by so many.</p><p><strong>The Embassy has declined to meet with Dagbladet, preferring to respond by email, with a press release originally sent out in 2019:</strong></p><p>"The Embassy is informed about what has been circulated in some media in regard to Mr. Iyad el-Baghdadi and the allegations against the Kingdom of Saudi Arabia. The Embassy would like to clarify that this person is not a Saudi citizen and is unknown to the Kingdom. What he said is fabricated and false and aims to offend the Kingdom of Saudi Arabia. We have been in contact with the Norwegian Government to provide the Kingdom of Saudi Arabia with further information in this regard. The Kingdom of Saudi Arabia reserves the right to take the necessary legal measures against the mentioned-above in order to safeguard its rights."</p>
<p><em><strong>Update:</strong></em> <em>Dagbladet received the following statement on Thursday 17th of December:</em></p><p><em>«The Embassy of the Kingdom of Saudi Arabia reiterates what was released in 2019, and denies any previous knowledge or existing relationship between the Kingdom and Iyad el-baghdadi.</em></p><p><em>In regards to the issue concerning the security guards, these guards are positioned at the embassy to provide the necessary protection, around the clock, for both the Embassy building and the Head of Mission’s residence. Saudi embassies in several countries have received threats and have been targeted by terrorist attacks - the most recent of which being the incident at the Embassy of the Kingdom of Saudi Arabia in The Hague.»</em></p><h2>Briefed by the PST</h2><p>In a spartan apartment in Oslo, Dagbladet meets Iyad el-Baghdadi.</p><div id="parallax-73159998">
    <div>

        <div data-parallax-sticky="" data-parallax-fullwidth="" data-parallax-content-type="image" data-parallax-layer="0" data-parallax-height="100" data-parallax-spacebelow="0" data-parallax-horizontalalign-desktop="" data-parallax-horizontalalign-mobile="" data-parallax-verticalalign="top" data-parallax-verticalposition="auto">
            <figure data-zoomable="1">
    
<picture>
    <source media="(max-width: 640px)" itemprop="image" srcset="https://www.dagbladet.no/images/73159867.jpg?imageId=73159867&amp;x=0&amp;y=0&amp;cropw=100&amp;croph=99.13258983891&amp;width=940&amp;height=622&amp;compression=70">
    <source media="(min-width: 641px and max-width: 1024px)" itemprop="image" srcset="https://www.dagbladet.no/images/73159867.jpg?imageId=73159867&amp;x=0&amp;y=0&amp;cropw=100&amp;croph=99.13258983891&amp;width=1113&amp;height=736&amp;compression=80">
    <source media="(min-width: 1025px)" itemprop="image" srcset="https://www.dagbladet.no/images/73159867.jpg?imageId=73159867&amp;x=0&amp;y=0&amp;cropw=100&amp;croph=99.13258983891&amp;width=1212&amp;height=801&amp;compression=80">
<img itemprop="image" data-defer="view" title="" alt="" srcset="https://www.dagbladet.no/images/73159867.jpg?imageId=73159867&amp;x=0&amp;y=0&amp;cropw=100&amp;croph=99.13258983891&amp;width=940&amp;height=622&amp;compression=70 640w,https://www.dagbladet.no/images/73159867.jpg?imageId=73159867&amp;x=0&amp;y=0&amp;cropw=100&amp;croph=99.13258983891&amp;width=1113&amp;height=736&amp;compression=80 1024w,https://www.dagbladet.no/images/73159867.jpg?imageId=73159867&amp;x=0&amp;y=0&amp;cropw=100&amp;croph=99.13258983891&amp;width=1212&amp;height=801&amp;compression=80 1240w" src="https://www.dagbladet.no/images/73159867.jpg?imageId=73159867&amp;x=0&amp;y=0&amp;cropw=100&amp;croph=99.13258983891&amp;width=1212&amp;height=801">
</picture>
      
    
    


      <figcaption itemprop="caption" data-expand="" onclick="this.classList.add('active')">
        
      </figcaption>
</figure>

        </div>
        <div data-parallax-content-type="text_subtitle" data-parallax-layer="1" data-parallax-height="100" data-parallax-spacebelow="0" data-parallax-horizontalalign-desktop="" data-parallax-horizontalalign-mobile="" data-parallax-verticalalign="top" data-parallax-verticalposition="auto">
            <p>
    <h3 itemprop="name headline">He is the critic who was informed by the PST about the Saudi Arabian Embassy requesting diplomatic status for ten security guards.</h3>
</p>
    
        </div>


    </div>
    
</div>


<p>The apartment where he currently lives – he moves regularly - contains little other than various cutlery, some clothes, and computer equipment with heavy encryption. A small room with weights and exercise equipment emphasizes the need, as he says, to always stay “sharp”.</p>
<p>According to Dagbladet’s information it is the Oslo police district which oversee his security.</p><p><strong>He claims they advised him to move out of his previous apartment not too long ago.</strong></p><p>El-Baghdadi, originally a stateless Palestinian, became an influential voice - particularly on Twitter - during the Arab Spring. He was a friend of Jamal Khashoggi, the journalist who was killed in October 2018 at the Saudi consulate in Istanbul.</p><p>He is also a staunch critic of Mohammed bin Salman's Saudi Arabia.</p><figure data-zoomable="1">
    
<picture>
    <source media="(max-width: 640px)" itemprop="image" srcset="https://www.dagbladet.no/images/73159534.jpg?imageId=73159534&amp;width=760&amp;height=434&amp;compression=70">
    <source media="(min-width: 641px and max-width: 1024px)" itemprop="image" srcset="https://www.dagbladet.no/images/73159534.jpg?imageId=73159534&amp;width=900&amp;height=513&amp;compression=80">
    <source media="(min-width: 1025px)" itemprop="image" srcset="https://www.dagbladet.no/images/73159534.jpg?imageId=73159534&amp;width=980&amp;height=559&amp;compression=80">
<img itemprop="image" data-defer="view" title="STAYED HERE: Jamal Khashoggi stayed at the Hotel Christiania Theater when visiting Oslo in May 2018. Photo: NTB/Terje Pedersen" alt="STAYED HERE: Jamal Khashoggi stayed at the Hotel Christiania Theater when visiting Oslo in May 2018. Photo: NTB/Terje Pedersen" srcset="https://www.dagbladet.no/images/73159534.jpg?imageId=73159534&amp;width=760&amp;height=434&amp;compression=70 640w,https://www.dagbladet.no/images/73159534.jpg?imageId=73159534&amp;width=900&amp;height=513&amp;compression=80 1024w,https://www.dagbladet.no/images/73159534.jpg?imageId=73159534&amp;width=980&amp;height=559&amp;compression=80 1240w" src="https://www.dagbladet.no/images/73159534.jpg?imageId=73159534&amp;width=980&amp;height=559">
</picture>
      
    
    


      <figcaption itemprop="caption" data-expand="" onclick="this.classList.add('active')">
        <strong>STAYED HERE:</strong> Jamal Khashoggi stayed at the Hotel …</figcaption></figure></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dagbladet.no/nyheter/the-saudi-security-team-to-norway/73159458">https://www.dagbladet.no/nyheter/the-saudi-security-team-to-norway/73159458</a></em></p>]]>
            </description>
            <link>https://www.dagbladet.no/nyheter/the-saudi-security-team-to-norway/73159458</link>
            <guid isPermaLink="false">hacker-news-small-sites-25427829</guid>
            <pubDate>Tue, 15 Dec 2020 07:16:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust from a Gopher – Testing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25427631">thread link</a>) | @BookPage
<br/>
December 14, 2020 | https://levpaul.com/posts/rust-lesson-11/ | <a href="https://web.archive.org/web/*/https://levpaul.com/posts/rust-lesson-11/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Hello and welcome to the seventh post in my series about learning Rust. In case you want to hit it from the start, <a href="https://levpaul.com/posts/rust-lesson-1/">here’s</a> a link to the first one! This entire series covers my journey from being a completely land-locked Gopher to becoming (hopefully) a hardened Rustacean, able to skitter the hazardous seabed of any application safely.</p><hr><p>This chapter covers a topic that engineers will have strong thoughts and feelings about, myself included. In college, I recall learning precisely zero about testing. This perhaps, because I studied Computer Science rather than Software Engineering? Alas, when I entered into my first real dev job it was a slightly jarring experience, figuring out how write tests for my code. In that nubile period, I can make no mistake in saying that test writing was <em>the</em> most tedious and painstaking task I can recall… (<em>Alongside waiting 2 minutes and thirty seconds for a our Java backend to compile</em>)</p><p>Mercifully, I’ve encountered many great engineers throughout my career whom took time to educate me, and I’ve grown to love testing. It once got to the point where testing was the sole driver for all code I wrote, via <a href="https://en.wikipedia.org/wiki/Test-driven_development">TDD</a>, but now has come back around to something less intense. I find unit tests less helpful and instead, lean on acceptance/integration testing to capture most things.</p><p>Ultimately how and if you write tests will depend on a few key factors;</p><h5 id="1-development-style">1. Development Style</h5><p>Are you practicing Test-Driven Developement, or are you writing in a more conventional or exploratory way? In simpler terms - are you writing your tests before you code, as you code, or after you code?</p><h5 id="2-existing-tests">2. Existing Tests</h5><p>Does the project you’re working on contain existing test infrastructure? Can you answer yes to these questions?</p><ul><li>are unit/integration tests widespread in the project already?</li><li>do existing tests contain scaffolding that enables you to easily add more tests? (i.e. mocks/stubs of major dependencies)</li><li>is the test suite run automatically via continuous integration pipelines? If so, is the pipeline passing a programmatic requirement for all pull requests?</li></ul><p>The more yeses from these questions, the more likely change requests will come with at least a couple new test cases, no matter the development style of a contributor.</p><h5 id="3-barrier-to-extension">3. Barrier to Extension</h5><p>This is simply how hard it would be to add tests had there not been existing infrastructure in place. This could be for a brand-new project or in an older project that was missing a particular type of test (i.e. no integration tests).</p><p>My experience with Java has always been bad in this respect. The testing environment was so fragmented that you had to use different frameworks depending on what style test you were wanting, and you also had to integrate said frameworks with your build framework too, just to make them run. Go was a huge breath of fresh air for me here as it had testing built in as a first class citizen from day one.</p><hr><p>With all these factors in mind, it makes sense to view testing in <em>Rust</em> purely from the third point, as this is where a language has the most potential for enablement.</p><h3 id="11-writing-automated-testshttpsdocrust-langorgbookch11-00-testinghtml">11. <a href="https://doc.rust-lang.org/book/ch11-00-testing.html">Writing Automated Tests</a></h3><p>Not to start on the wrong foot but straight off the bat this chapter managed to annoy me thoroughly by leading with this excerpt:</p><blockquote><p>In his 1972 essay “The Humble Programmer,” Edsger W. Dijkstra said that “Program testing can be a very effective way to show the presence of bugs, but it is hopelessly inadequate for showing their absence.” That doesn’t mean we shouldn’t try to test as much as we can!</p></blockquote><p>I scratched my head and thought, “<em>this doesn’t sound right</em>”. So off I went to read <a href="https://www.cs.utexas.edu/~EWD/transcriptions/EWD03xx/EWD340.html">The Humble Programmer</a> essay (which is fantastic). It became immediately obvious that Dijkstra had anything <em>but</em> an anti-testing sentiment. My guess is that the authors of the Rust Book may have just made a simple translation error. Take for example, the very next line of the essay. Dijkstra writes:</p><blockquote><p>The only effective way to raise the confidence level of a program significantly is to give a convincing proof of its correctness.</p></blockquote><p>No, Dijkstra isn’t talking about a formal proof. He’s talking about Test Driven Development in 1972. He continues:</p><blockquote><p>If one first asks oneself what the structure of a convincing proof would be and, having found this, then constructs a program satisfying this proof’s requirements, then these correctness concerns turn out to be a very effective heuristic guidance.</p></blockquote><p>One can only imagine the “Program testing” Dijkstra referred to in the original quote, could simply mean <em>manual testing</em> in today’s tongue. The Book missed a great opportunity to use Dijkstra to promote testing and instead we got only half of it. Oh well.</p><hr><h3 id="_setup_"><em>Setup</em></h3><p>I got a feeling that this chapter had a different author than previous ones, as the examples were numerous and verbose. I managed to skim over most of them as in essence the concepts were quite basic. Basic though, is a great quality in a testing framework.</p><h4 id="the-_basics_">The <em>Basics</em></h4><p>In no relevant order, let me talk about features of Rust testing that I loved.</p><p>First - tests are simple to add, just a <code>[#test]</code> annotation for a function and you’re off to the races. In Go you have to do two things - create a file that ends in <code>_test.go</code> <em>and then</em> write your test functions as</p><div><pre><code data-lang="go"><span>func</span> <span>TestXxx</span><span>(</span><span>t</span> <span>*</span><span>testing</span><span>.</span><span>T</span><span>)</span>
</code></pre></div><p>… Now let me tell you that I’ve reviewed unit tests in Go which had me scratch my head and ask myself <em>“how the f*** did these tests pass??"</em>. It turned out that after another 10 minutes of faffing about and running the tests locally, did I find the test had never been run! Along with many others in the package for the past 6 months! Why? Because someone forgot to capitalize the first letter of the test function names, meaning their <code>testMyProgramWorks</code> “tests” weren’t exported, meaning Go didn’t classify them as real tests. Add some copy-pasta and there we were…</p><p>Having a much simpler API for specifying tests is a big win in my book. Thank you, Rust.</p><h5 id="seamless-integration">Seamless Integration</h5><p>Next on my testing crushlist is Intellij+Rust-plugin testing integration. I can just hit <code>shift+F10</code> and the IDE will run the tests for my crate and spit out a summary with links to failures and stuff. For one reason or another, I never run my Go tests from Goland (Intellij for Go). I use the command line with filters to run tests in specific packages. I don’t even know if I’ve ever even <em>tried</em> to run Go tests in Goland!?</p><p>After getting excited about this, I decided to try the IDE’s debugger with an integration test. Again, it just worked! I’ve used a debugger once or twice in Go, but you have to use <a href="https://github.com/go-delve/delve">Delve</a>, then find some tutorials for setting that up with your IDE… In practice, I’ve never felt it was worth my time to use a debugger in Go. I’m not <em>sure</em> this would change with Rust - but debuggers are definitely nice to have when you’re a newbie and want to get a stronger feel for what’s happening in your code. Very cool to have it in the IDE with zero effort.</p><h5 id="almost-seamless">Almost, Seamless</h5><p>As I continued my tool-driven gorge, I hovered over a polished button that had inlaid in it, “Run ‘Hello World’ with Coverage”. Oooooh, ahhhh, I ogled.</p><p>*<strong>click</strong>*</p><p><em>BZZZZZRRP!!!!</em></p><p>Oh no.</p><p><em>Code coverage is available only with nightly toolchain.</em></p><p>Well excuuuuuse me for being so <em>basic</em> that I only use the default <a href="https://www.rust-lang.org/tools/install">rustup</a> install… To reinforce this further, the Book slaps me with this one too,</p><blockquote><p>Benchmark tests are, as of this writing, only available in nightly Rust.</p></blockquote><p>I am a big fan of Go benchmarks. Possibly the most underrated aspect of the Go testing ecosystem. It’s basically the standard for figuring out how alloc-y a package is and gives you hard numbers in that respect. Maybe benchmark tests <em>aren’t</em> that good in Rust, given you have much stricter control over your allocs?</p><p>So for now, I’ll add nightly-rust to my list of things to understand, post-Book.</p><h4 id="ok-enough-tool-talk-_the-tests_">Ok enough tool talk, <em>The Tests!</em></h4><p>The Rust testing tool chain is simple and comprehensive. The <code>assert!</code> style macros are a godsend. Every test I write in Go starts with me importing the <a href="https://github.com/stretchr/testify">testify</a> library, just to get access to <code>assert</code>. Rust testing is close to what Go offers, but looks to have a clear edge, out of the box.</p><p>On the opposite end of the stick, I’m not a huge fan of coercing us to put unit tests within the module being tested. Splitting up test code from production code makes for easier reading. Thankfully, <a href="http://xion.io/post/code/rust-unit-test-placement.html">this post</a> showed me how to split your tests into a sibling module, so with some slight hacks it appears my woes are surmountable.</p><p>A point of confusion came about when the Book ended a section saying we can write tests to return <code>Result&lt;T,E&gt;</code>’s. Apparently this is an acceptable way to write tests over <code>assert!</code> macros… The Book doesn’t make a suggestion about which is more idiomatic, so until I’m convinced otherwise, I’ll stick with asserts.</p><h5 id="delight-me-more">Delight me more</h5><p>Rust continued to delight me by doing simple things that Go doesn’t, for example having sane <em>help</em> printouts for the test command. Just trying to figure anything out by running <code>go help test</code> (and yes, in that specific arg order) is an exercise in futility. Any time I have to figure out how to disable test caching in Go, it’s a visit to Uncle Google.</p><p>Simiplicity continues in Rust with sane ways to filter running tests, and a simple mechanism to arbitrarily partition your tests too, using the <code>#[ignore]</code> annotation.</p><h5 id="splitting-hairs">Splitting Hairs</h5><p>There is no logical division in Go to encourage splitting unit tests from integration tests. You have to make such a divide yourself. I love that Rust has thought deeper about this and there are patterns to follow for each case.</p><blockquote><p>There’s debate within the testing community about whether or not private functions should be tested directly, and other languages make it difficult or impossible to test private functions.</p></blockquote><p>I haven’t heard this debate before, I’m guessing it would go something along the lines of “test the contract, if that works then you’re good”. Whilst I wouldn’t buy it completely, I do find substantially more value in integration and acceptance testing than unit testing <em>every function</em>.</p><h3 id="_teardown_"><em>Teardown</em></h3><p>Both Rust and Go have testing as first class citizens, but Rust wins for ease of use and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://levpaul.com/posts/rust-lesson-11/">https://levpaul.com/posts/rust-lesson-11/</a></em></p>]]>
            </description>
            <link>https://levpaul.com/posts/rust-lesson-11/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25427631</guid>
            <pubDate>Tue, 15 Dec 2020 06:32:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Before You Get Mad About the CentOS Stream Change, Think About:]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25427598">thread link</a>) | @yipbub
<br/>
December 14, 2020 | http://crunchtools.com/before-you-get-mad-about-the-centos-stream-change-think-about/ | <a href="https://web.archive.org/web/*/http://crunchtools.com/before-you-get-mad-about-the-centos-stream-change-think-about/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		

<p>Change is hard. Explaining that change in a way that makes sense is hard. Not getting frustrated when someone is explaining change to you, or while explaining it is hard. We are all human, so please be patient. But, before you get angry, please read this. I’ve been surfing <a href="https://twitter.com/hashtag/centos?lang=en">Twitter</a>, <a href="https://www.reddit.com/r/linux/comments/k95dt7/centos_project_shifts_focus_to_centos_stream/">Reddit</a>, and <a href="https://news.ycombinator.com/item?id=25345428">HackerNews</a> threads just like many others. I’ve gathered some major buckets of complaints which seem to come up, and I’d like to address each of them.</p>
<p>Before I start, full disclosure, I work at Red Hat and I’ve been here 9.5 years. I’ve never missed a paycheck. Never. Not one time. It’s always been there on payday. That makes me happy, but just because you work somewhere doesn’t mean you check your brain at the door. I am constantly questioning what we are doing, and coming to my own conclusions. A work relationship is like any other relationship, and it must be evaluated from time to time. Like any rational human being, I do this every now and then. I’m also known for saying my mind, even when the truth is difficult to hear. I think this makes me a decent diplomat for tough conversations. That said, these are my opinions and thoughts, not Red Hat’s.</p>
<p>Let’s have a tough conversation here. There are a lot of complaints and some optimism about the <a href="https://www.redhat.com/en/blog/centos-stream-building-innovative-future-enterprise-linux">CentOS to CentOS Stream change</a>. Let’s dissect each of what I consider legitimate complaints:</p>





<h2><span id="1_This_Was_Communicated_Poorly">#1 This Was Communicated Poorly</span></h2>
<p>As I said in the introduction, messaging is hard. We are all human, even the people at Red Hat. Do I think it’s possible that this could have been communicated better? Sure. That said, I’ve seen a lot of people tossing hate toward Rich Bowen (<a href="https://blog.centos.org/2020/12/future-is-centos-stream/">CentOS Project shifts focus to CentOS Stream</a>) as well as Chris Wright (<a href="https://www.redhat.com/en/blog/centos-stream-building-innovative-future-enterprise-linux">CentOS Stream: Building an innovative future for enterprise Linux</a>) who wrote the two main pieces which communicated this change.</p>
<p>That’s not fair. These are both stand up guys. I mean seriously. I met Rich many moons ago because I had read and used his Apache docs. I went up to him and said thank you with nervousness. This guy believes in open source, more than most. He not only uses, he contributes. Big time. Same with Chris. I’ve never seen anyone who gets open source more than Chris. Seriously, when you listen to him speak you can discern how deeply he thinks about it. He is committed to it. If Red Hat ever changed their stance on open source, I am 100% sure that both of these guys would leave. There’s no conspiracy here, not with these guys. I know them both personally, and I believe in both of them. When these guys get up and say something, it’s true to the best of their knowledge at the given time. But, the world changes, and so do strategies.&nbsp;</p>
<p>Furthermore, this is a big change, and many people were involved, from both the community and from Red Hat. In fact, I’m writing this blog because I have a bias towards contribution and I believe it’s all of our responsibility to try to communicate this change effectively. Will Red Hat live and learn from this messaging? Yes, I believe so.&nbsp;</p>
<p>My only ask is, please extend some goodwill to Red Hat and see how this change goes. Give it a chance. I believe it will actually be better in the long run, and more sustainable.</p>

<h2><span id="2_Things_Changed_I_Don8217t_Like_Change">#2 Things Changed, I Don’t Like Change</span></h2>
<p>This brings me to the next most common gripe I hear. I get it it. Please try to separate your anger that is a direct result of unwanted change, from the other things discussed in this blog. Every time I’ve ever went through a re-org at work, changed roles, changed companies, bought a house, had a child or remodeled a room in my house, I’ve sort of had this “who moved my cheese” feeling. Everything was one way, now it’s another. Being annoyed by change is legitimate, but ask yourself what the benefits might be?</p>

<p><a href="http://crunchtools.com/files/2020/12/9780399144462_l.jpg"><img loading="lazy" src="http://crunchtools.com/files/2020/12/9780399144462_l.jpg" alt="" width="254" height="400"></a></p>
<p>Already, some people have proposed some benefits to this change, and I agree. I’m going to summarize the benefits I’ve seen from three different sources [1][2][3] and add some of my own thoughts:</p>
<ol>
<li><strong>It makes RHEL development more transparent and reliable [1]</strong> – historically, once a RHEL release snapped from Fedora it became a black box. Red Hat tries to solve this by creating Alpha and Beta releases which we share with customers and partners. We spend a tremendous amount of time/energy/money (as a PM I have to answer bunches of questions about Alpha/Beta), but literally almost nobody uses them. It’s expensive and painful. CentOS Stream will change this. Now any CentOS Stream user will have access to and be able to participate in this process. This is amazing.</li>
<li><strong>It provides a way for ISVs and developers to contribute fixes and features [1]</strong> – Even when partners and customers would use Betas/Alphas it was difficult for them to contribute changes back. None of the branches/repositories were public. Remember, the source code at git.centos.org is basically read only, downstream code from RHEL. That’s how Red Hat complies with the GPL. Technically we go above and beyond because we are only legally required to provide code to customers, and not required to provide code for BSD/Apache/etc licensed code, only attribution. Nonetheless, this was not a community, this was a code repository. The RHEL code was more akin to Android’s read-only, versus Kubernetes’ or the Linux kernel’s read-write community. With CentOS Stream, this all changes.</li>
<li><strong>It provides a way for the community to provide feedback [1]</strong> – Partners have special people dedicated to them called partner managers, and historically these partner managers help partners provide feedback and drive changes to the RHEL repositories. Community CentOS users (and even Fedora users) never had a way to drive changes into RHEL minor releases. Fedora drives changes into major releases, but there was a black box with minor releases. This gave RHEL the perception of being insulated from the upstream community, and it was. With CentOS Stream, this all becomes transparent. It’s a noble goal, and I genuinely believe this is better.</li>
<li><strong>Moving to a rolling stream is a consequence of moving to a cloud native world [2]</strong> – this was an interesting one and I hadn’t thought about this. This is a consequence of the world of containers. I always understood the value of containers to control when you absorb updates into your application dependencies, but it also means that a rolling stream of OS updates just doesn’t matter anymore. Now that containers control when the updates occur, why even care about whether it’s a rolling stream or released with version numbers. Do a “podman build” after the minor release drops in RHEL and don’t update again until the next dot release – boom, you have something quite similar to downstream CentOS Stream. A rolling stream lets us move faster and freer.</li>
<li><strong>Don’t underestimate the value of working directly with Red Hat engineering [3]</strong> – As Neal points out, CentOS was always a community driven project. Red Hat had extended it’s brand to the CentOS brand, and perhaps mistakenly given the perception that this was a well funded project when in fact it never was. Like every community driven project I have ever seen, there are more wants and desired than time and energy. Maintenance of community driven projects is not wholly unlike non-profits where a sort of depression permeates because it feels like you are never making enough progress, and worse you feel like you’re not being appreciated by the people who benefit from the charity. CentOS stream will be directly integrated with Red Hat engineering providing a direct line to RHEL. These are people paid to do this work, in service of making RHEL better. This aligns incentives and makes it much more sustainable, but more importantly, it creates a natural communication channel between Red Hat engineering and the community which frankly never existed. This will keep RHEL engineering more in touch with the realities of user needs, and provide the community a sense of connectedness. This is a very positive move.</li>
<li><strong>Don’t underestimate the power picking up a thousand new smart, highly motivated power users with a bias towards contribution, not consumption [4]</strong> – I haven’t seen anyone highlight this value yet. There are thousands of Solutions Architects, Consultants, Engineers, Product Managers, Product and Technical Marketing Managers, and Evangelists at Red Hat. None of them had an incentive to talk about CentOS much less contribute to it. I haven’t used CentOS in 9 years because I like getting a pay check. I was annoyed when customers wanted to talk to me about CentOS. I never contributed. I didn’t hate it, but I always viewed it as a wash – it garnered users of Red Hat technology, but these users very rarely contributed. I’ve never even seen a CentOS user file a RHEL issue (aka Bugzilla) or ping me on Twitter for CRI-O, Podman, Buildah, Skopeo, or anything else I work on at Red Hat. These users weren’t even on my radar. About a month ago, I installed CentOS Stream so that our team could collaborate with a customer on some Podman development. I didn’t have to feel dirty about pointing them to a downstream rebuild. With an upstream rebuild, the feedback is all directly useful to RHEL – feature requests, bugs, etc. This is powerful.&nbsp;</li>
</ol>
<p>[1]: <a href="https://jperrin.org/blog/thoughts-on-stream/">Thoughts on CentOS Stream</a> by Jim Perrin (<a href="https://twitter.com/BitIntegrity">@BitIntegrity</a>)</p>
<p>[2]: <a href="https://threadreaderapp.com/thread/1336603153341550592.html">Unpopular opinion: CentOS switching to Stream is not a bad thing at all</a> by Kristian Köhntopp (<a href="https://twitter.com/isotopp">@isotopp</a>)</p>
<p>[3]: <a href="https://twitter.com/Det_Conan_Kudo/status/1337366036023218177">Don’t underestimate the value of a direct relationship with RHEL engineering</a> by Neal Gompa (<a href="https://twitter.com/Det_Conan_Kudo/">@Det_Conan_Kudo</a>)</p>
<p>[4]: My own thoughts.</p>
<h2><span id="3_The_Life_Cycle_Commitment_Was_Changed">#3 The Life Cycle Commitment Was Changed</span></h2>
<p>The complaint is that the CentOS wiki originally said that CentOS 8 would be supported until 2029, and that this seems particularly egregious since CentOS 6 was recently deprecated. I totally understand being upset by this if you already had your heart set on using this, but think about why you’re upset? Let’s delve into this from an <a href="http://crunchtools.com/the-delicate-art-of-product-management/">open source product management perspective</a>. To the best of my knowledge, I am the first person to attempt to talk about open source in the context of creating and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://crunchtools.com/before-you-get-mad-about-the-centos-stream-change-think-about/">http://crunchtools.com/before-you-get-mad-about-the-centos-stream-change-think-about/</a></em></p>]]>
            </description>
            <link>http://crunchtools.com/before-you-get-mad-about-the-centos-stream-change-think-about/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25427598</guid>
            <pubDate>Tue, 15 Dec 2020 06:25:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking Like it's 1996 – a short history of the stack buffer overflow]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25427520">thread link</a>) | @roberla
<br/>
December 14, 2020 | https://security.christmas/2020/15 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/15">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><section><p>The year was 1996, and it’s the 11th of November. Macarena is topping the charts, Bill Clinton wins his second presidential term, and an article in a very peculiar e-zine is published which would change the world of information security forever. The publication in question was Phrack, an e-zine for and by hackers. The article in question was Aleph One’s “Smashing the Stack for fun and profit”, thus began what many regards as the golden age of software exploitation.</p>
<p>Smashing the stack for fun and profit was the first-ever article to in detail describe the buffer overflow vulnerability. Sure, buffer overflows were already being exploited in the wild prior to the release of Aleph One paper, but it had never been documented to this extent before. A lot has happened since the golden days. We have 64 bit-systems, compiler protections, kernel protections, and so on. While the examples from the paper aren’t possible without some dangerous compiler tweaks, the essence of the stack-based buffer overflow is still the same.</p>
<h2>Buffer Overflows</h2>
<p>So, what is a buffer overflow? An easy way to explain it is to imagine a spreadsheet containing a list of items. Each item has an id, a name, and a price. Imagine has implemented a very poor system for updating the items.</p>
<p>Now, what would happen if someone entered in a bunch of A’s while updating the name? Since this terrible spreadsheet app lacks bounds checking on the name, the value of name overflows into the price field. Now the price of the third item is 9 A’s. If we think a little more creatively about this, this means that we are able to write anything we want to the price field by carefully crafting a payload, that allows us to set the price to 1. Now that would be bad for business.</p>
<p>Ok, now we know the essence of what a buffer flow is, but what about the stack?</p>
<h2>The Stack</h2>
<p>Imagine a stack of plates, you can put (push) another plate on top of the already stacked plates, and you can remove a plate (pop) from the stack. I won’t go into great detail about how it works, but what you need to know is that each program executed by the operating system has its own stack, but instead of dinner plates the stack stores stack frames. You see, every time a program calls a function, it pushes a new stack frame on the stack. This frame contains the parameters for the function, its variables, and data needed to get back to the previous frame.</p>
<h2>The Return Pointer</h2>
<p>An important part of data needed to return from the function is the return pointer. It stores the memory address for where to resume execution after a function has been called. You can think of this part of the stack frame as the price field from the spreadsheet example. If you can overwrite the return pointer, you may redirect the code flow of the program.</p>
<h2>Exploitation</h2>
<p>But how do we redirect the code flow? The classic way, as described in smashing the stack, is to use shellcode. Shellcode is raw machine code, which typically executes a command shell. The attack creates the payload, by figuring out how much input is needed in order to overflow the return pointer. This is typically done by trial and error with the aid of a debugger. Next, the attacker uses the debugger to find the location of where the shellcode will end up in memory. If the exploit is successful, it will overflow the return address with the location of the shellcode, start executing the shellcode.</p>
<p>Now a lot has happened since the 90s, and the buffer overflow like it is presented in smashing the stack for fun and profit is no longer exploitable on modern systems. However, as application hardening evolved so did the techniques for exploitation.</p>
<p>The first defense against these sorts of attacks was NX, non-executable stack. This mitigation prevents code being executed in regions of the stack meant for data. This mitigation prevents the use of shellcode on the stack, but from this a very clever trick was discovered.</p>
<h2>Return-To-Libc</h2>
<p>As I mentioned, the return pointer has to point to a valid memory address. We cannot redirect code execution to somewhere on the stack, as it is marked as non-executable. But what if we point it to somewhere that already exists? Enter the return-to-libc technique. The concept is simple, we jump to a already existing function that will allow us to get code execution. There's multiple way to do this, but the most popular is to jump to the c library function <code>system()</code>.</p>
<p>We can't jump directly into <code>system()</code>, as it needs to be called with a useful string such as <code>/bin/sh</code>. In order to pull this off, we can leverage program instructions that modify cpu registers or the stack, as long as they are followed by a return instruction. The return instruction moves the stack pointer, meaning that we can chain together multiple instructions, as it will return into the next memory address we supply on the chain. These instructions are known as gadgets. By using this technique, we can write the string <code>bin/sh</code> in the register that is used as the first function parameter (on 32-bit systems, functions parameters are pushed onto the stack instead).</p>
<h2>ROP</h2>
<p>Actually, we don't even need access to library functions at all. If we chain together enough gadgets in a clever way, we can execute directly by using a system call. This is known as return-oriented programming (ROP) and is actually Turing complete! Meaning we can make the program to behave in any way we desire. Some people have actually implemented programming languages that run on top of a vulnerable program using return-oriented programming!</p>
<h2>Stack Cookies, ASLR and PIE</h2>
<p>Further attempts were made to stop exploitation, but they only succeed at making exploitation more involved. Like stack cookies, a special numeric value placed before the return pointer. If you corrupt this value, execution will terminate. However, these can be leaked and in some cases brute-forced.</p>
<p>Next we have ASLR, or address space layout randomization. This mitigations offsets memory addresses with a random value. This can be defeated by leaking addresses in order to calculate the offset.</p>
<p>The last one we're going to cover is Position Independent Executables or PIE for short. This mitigation is used in combination with ASLR. PIE randomly shuffles each section of the program i.e., we no longer know where anything is in memory. This makes leaking a lot more complicated, but it is defeatable by getting the right memory leaks.</p></section></article></div></div>]]>
            </description>
            <link>https://security.christmas/2020/15</link>
            <guid isPermaLink="false">hacker-news-small-sites-25427520</guid>
            <pubDate>Tue, 15 Dec 2020 06:11:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Legally Free Python Books List]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 40 (<a href="https://news.ycombinator.com/item?id=25427504">thread link</a>) | @osdotsystem
<br/>
December 14, 2020 | https://www.pythonkitchen.com/legally-free-python-books-list/ | <a href="https://web.archive.org/web/*/https://www.pythonkitchen.com/legally-free-python-books-list/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Here is my personal list of legally free Python books. <strong>Warning: Packt free books are highly unreliable, what can be free today can no longer be free tomorrow They were included as they are free at the time of writing this post. Similarly is Oreilly’s case. The two publishing houses have been annotated as necessary.</strong> In case of no longer free or broken links please mail me at `arj.python at gmail dot com` to update article. I have to thank the internet who took the pain to point these resources to me. I have skimmed through the contents to producs a list of legally free Python books of value. Here’s how i evaluated books (you might not agree, but that’s my personal take on it):</p>




<p>Some popular listed books like Python Module of the Week  is not a book and Tango with Django 1.7 is outdated.  Materials which provide only some free chapters are not free books. Docs manuals are docs manuals, you’d have to include a quarter of pypi’s packages manuals then. github projects are gihub projects unless it’s a book. Mark pilgrim ran away so should we from his book. We don’t want some illegal 100+ free list (Mark Lutz books are not free mind you), you could include all Python books hosted on drive then. Python2 is past, we passed over. Fullstackpython’s list is a collection of various sites’ articles, not a book. Really short books more qualified as leaflets did not make it. Such materials have been deliberately left out. What remains are books that you’ll enjoy!</p><p>


Note: was pythonmembers.club before, so if you have the domain’s link, please update


</p><p>Let’s start! <b>Click on the titles to view/download the book.</b></p>



<h2>INTRODUCTORY MATERIALS</h2>



<h3> <a href="http://greenteapress.com/thinkpython2/thinkpython2.pdf" target="_blank" rel="noopener">Think Python </a></h3>



<p>Allen Downey</p>




<h3><a href="https://anandology.com/python-practice-book/index.html" target="_blank" rel="noopener">Python Practice Book</a> </h3>



<p> Anand Chitipothu</p>



<p> This book is prepared from the training notes of&nbsp;Anand Chitipothu. </p>



<h3><a href="https://dabeaz-course.github.io/practical-python/Notes/Contents.html" target="_blank" rel="noopener">Practical Python Programming</a> </h3>



<p> David Beazley</p>



<p> Highly recommended book. Normally taught in 3/4 days. It offers solid foundations. This course is taught to scientists and engineers. The name of the author is a trademark of excellence. Do read it even if you already know Python! </p>



<h3> <a href="https://www.packtpub.com/free-ebooks/learn-python-programming-second-edition" target="_blank" rel="noopener">Learn Python Programming – Second Edition</a> </h3>



<p> Fabrizio Romano – Packt</p>



<p>Learn Python Programming is a quick, thorough, and practical introduction to Python – an extremely flexible and powerful programming language that can be applied to many disciplines. You will begin by learning the fundamentals of Python so that you have a rock-solid foundation to build upon. Covers some data science, GUI and web (Django).</p>



<h3><a href="http://do1.dr-chuck.com/pythonlearn/EN_us/pythonlearn.pdf" target="_blank" rel="noopener">Python For Everybody</a></h3>



<p>Charles R. Severance</p>



<p>The goal of this book is to provide an Informatics-oriented introduction to programming. The primary approach taken in this book is using Python to solve data analysis problems common in the world of Informatics. </p>



<h3><a href="https://krother.gitbooks.io/python-3-basics-tutorial/content/en/" target="_blank" rel="noopener">Python 3 Basics Tutorial</a></h3>



<p>Dr. Kristian Rother</p>



<p>The perfect introduction for completely new people </p>



<h3><a href="https://en.wikibooks.org/wiki/Non-Programmer%27s_Tutorial_for_Python_3" target="_blank" rel="noopener">Non-Programmer’s Tutorial for Python 3</a></h3>



<p>Josh Cogliati</p>



<p> The Non-Programmers’ Tutorial For Python 3 is a tutorial designed to be an introduction to the Python programming language. This guide is for someone with no programming experience. </p>



<h3> <a href="http://www.spronck.net/pythonbook/pythonbook.pdf" target="_blank" rel="noopener">The Coder’s Apprentice </a></h3>



<p> Pieter Spronck </p>



<p> “The Coder’s Apprentice” aims at teaching Python 3 to students and teenagers who are completely new to programming. Contrary to many of the other books that teach Python programming, this book assumes no previous knowledge of programming on the part of the students, and contains numerous exercises that allow students to train their programming skills. </p>



<h3> <a href="https://www.brianheinold.net/python/python_book.html" target="_blank" rel="noopener">A Practical Introduction to Python Programming </a></h3>



<p> Brian Heinold </p>



<p> The book aims at striking the balance between a tutorial and reference book. Includes some fun exercises at the end! </p>



<h3> <a href="https://python.swaroopch.com/" target="_blank" rel="noopener">A Byte of Python </a></h3>



<p>Swaroop C H</p>



<p>“A Byte of Python” is a free book on programming using the Python language. It serves as a tutorial or guide to the Python language for a beginner audience. If all you know about computers is how to save text files, then this is the book for you. </p>



<h3><a href="https://buildmedia.readthedocs.org/media/pdf/intermediatepythongithubio/latest/intermediatepythongithubio.pdf" target="_blank" rel="noopener">Intermediate Python</a></h3>



<p> Muhammad Yasoob Ullah Khalid </p>



<p> Python is an amazing language with a strong and friendly community of programmers. However, there is a lack of documentation on what to learn after getting the basics of Python down your throat. Through this book I aim to solve this problem. I would give you bits of information about some interesting topics which you can further explore. The topics which are discussed in this book open up your mind towards some nice corners of Python language. This book is an outcome of my desire to have something like this when I was beginning to learn Python. If you are a beginner, intermediate or even an advanced programmer there is something for you in this book. Please note that this book is not a tutorial and does not teach you Python. The topics are not explained in depth, instead only the minimum required information is given.  A true example of legally free Python books. </p>



<h3><a href="http://ralsina.gitlab.io/boxes-book/" target="_blank" rel="noopener">Boxes: Your Second Python Book</a></h3>



<p>Roberto Alcina</p>



<p>This book tries to achieve only one thing: Show you a project go from&nbsp;<strong>nothing</strong>&nbsp;to&nbsp;<strong>OK</strong>. By nothing I mean, no code at all. Not even a fleshed idea of what it does. No goals, no commitments. Just a vague interest. And by OK I mean it will work, it will have tests, it will be available to use, it will be&nbsp;<strong>useful</strong>&nbsp;and be a real thing. Think of it as a sort of documentary on the beginnings of a rock band, only instead of rockers there is a single overweight Argentinian dev, and instead of a band there is a piece of software. So, not much like a documentary on the beginnings of a rock band.</p>



<h3><a href="https://learnpythonbreakpython.com/" target="_blank" rel="noopener">Learn Python, Break Python</a></h3>



<p>Scott Grant</p>



<p>Learn Python, Break Python is a hands-on introduction to the Python programming language, written for people who have no experience with programming whatsoever. Hey, we all have to start somewhere. As such, the examples and teaching style used in this text make absolutely no expectations about your prior programming experience. Anyone can pick up the art of programming with a little time and a bit of patience. However, when learning something new, I try to break things. In fact, in many cases, I go out of my way to break stuff. When picking up a new concept like computer programming, you can actually increase your comfort level by figuring out the type of cases that are likely to break. You’ll see what data can be used and where, and when you inevitably run into errors later (like everyone does), you won’t be surprised.</p>



<h3><a href="https://www.eecs.wsu.edu/~schneidj/PyBook/swan.pdf" target="_blank" rel="noopener">Algorithmic Problem Solving with Python</a> </h3>



<p> John B. Schneider, Shira Lynn Broschat, Jess Dahmen </p>



<p>(Not an algo book) Python’s syntax and idioms are much easier to learn than those of most other full-featured languages. This book uses programming language Python to introduce folks to programming and algorithmic thinking. </p>



<h3> <a href="https://buildmedia.readthedocs.org/media/pdf/python-guide/latest/python-guide.pdf" target="_blank" rel="noopener">The Hitchhiker’s Guide to Python.</a></h3>



<p>Kenneth Reitz</p>



<p> This opinionated guide exists to provide both novice and expert Python developers a best-practice handbook to the installation, configuration, and usage of Python on a daily basis. </p>



<h3><a href="https://www.slitherintopython.com/" target="_blank" rel="noopener">Slither Into Python</a></h3>



<p> Slither into Python is an introduction to Python for complete beginners. No prior programming experience or computer science background is necessary. Unlike any other Python resources I have found (not that they’re not out there), they don’t explain important computer science concepts such as memory or “how computers work”. In this book I will cover the fundamentals of the Python language and also introduce these important concepts. Put simply,&nbsp;<em>coding</em>&nbsp;or&nbsp;<em>computer programming</em>&nbsp;is about making computers do what you want, Computer Science is about&nbsp;<em>how</em>&nbsp;computers do it. Each go hand-in-hand, help you learn faster and improve your overall understanding of a language! This book aims to do exactly that through Python. </p>



<h3><a href="https://www.oreilly.com/programming/free/files/a-whirlwind-tour-of-python.pdf" target="_blank" rel="noopener">A Whirlwind Tour of Python</a></h3>



<p>Jake VanderPlas – Oreilly</p>



<p>The book provides a whirlwind tour of some of Python’s essential syntax and semantics, built-in data types and structures, function definitions, control flow statements, and other aspects of the language. My aim is that readers will walk away with a solid foundation from which to explore the data science stack just outlined. </p>



<h3><a href="https://pymbook.readthedocs.io/en/latest/" target="_blank" rel="noopener">Python For You and Me</a></h3>



<p>Kushal Das (Core Dev)</p>



<p> A book for the total new comers into Python world. Was started as book for students before they read Python tutorial. Given it’s from a core dev, even up to chapter choice order is insightful.</p>



<h3> <a href="https://prappleizer.github.io/textbook.pdf" target="_blank" rel="noopener">Python for Astronomers </a></h3>



<p> Imad Pasha, Christopher Agostino </p>



<p> This text is designed to be an introduction to the Python programming language — which is now used nearly ubiquitously in astronomy — with applications to the types of tasks an undergraduate (or beginning graduate student) might have to tackle. It is not, in any way, meant to be comprehensive; my focus is on bringing you up to speed as efficiently and quickly as possible. This text might have useful information for those with a working knowledge of Python outside of a research setting, but is primarily designed for those with no prior programming experience. By the end of this text, I hope to have shared enough to make you feel comfortable taking the first steps into research-type problems (of which this book will contain several examples), whether in an astronomy course, a research internship, or on-campus research. </p>



<h3><a href="https://leanpub.com/intermediatepython" target="_blank" rel="noopener">OBI Intermediate Python</a></h3>



<p> Obi Ike-Nwosu </p>



<p>The python ecosystem is awash with books for beginners but few books target readers that are past the beginning stages but are not yet advanced users. The book aims to bridge that gap. The content of this book looks primarily at the various means for code organization in Python and provides user with a rigorous grounding in these. it dives into topics such as python object system, functions, decorators, metaprogramming and generators providing the reader with an in-depth knowledge of these topics that is essential for writing idiomatic and robust python code. It aims to&nbsp; provide a reader with not only a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pythonkitchen.com/legally-free-python-books-list/">https://www.pythonkitchen.com/legally-free-python-books-list/</a></em></p>]]>
            </description>
            <link>https://www.pythonkitchen.com/legally-free-python-books-list/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25427504</guid>
            <pubDate>Tue, 15 Dec 2020 06:07:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nexus 1.0: A Major Release for Type-Safe, Code-First GraphQL APIs]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25427285">thread link</a>) | @pantharshit00
<br/>
December 14, 2020 | https://www.prisma.io/blog/announcing-the-release-of-nexus-schema-v1-b5eno5g08d0b | <a href="https://web.archive.org/web/*/https://www.prisma.io/blog/announcing-the-release-of-nexus-schema-v1-b5eno5g08d0b">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><div><p>Nexus is a library originally authored by <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/tgriesser">Tim Griesser</a> that allows developers to build code-first and type-safe GraphQL APIs. Prisma has been a core contributor to the library for over two years and has helped shape its evolution.</p><p>Today, we're happy to announce that we've released Nexus 1.0.</p><p>This release is the culmination of outstanding community feedback and contributions, years of battle-testing Nexus in production, and responding to lessons learned in creating an excellent developer experience for those building GraphQL APIs.</p><p><strong>Note:</strong> Prisma's products are no longer GraphQL-centric. You can use Prisma in a REST API, a GraphQL API, or in any other setting where you want to access a database in Node or Go. Although we contribute to Nexus, it is not necessary to use it alongside Prisma. <a href="https://www.prisma.io/">Find out more</a> about what Prisma offers and how to use it.</p><h2 id="what-is-nexus"><a href="#what-is-nexus" aria-label="what is nexus permalink"></a>What is Nexus?</h2><p>Nexus offers a way to build code-first GraphQL APIs in Node. The code-first approach to building a GraphQL API is in contrast to the (potentially more common) schema-first approach.</p><p>Most developers that are new to building GraphQL APIs start out by taking the schema-first approach that has been popularized by companies like Apollo and their Apollo Server offering.</p><p>With the schema-first approach, writing the GraphQL API requires a set of <strong>type definitions</strong> and accompanying <strong>resolvers</strong>. A simple schema-first server might look like this:</p><pre><code>type Post <span>{</span>
  <span>id</span><span>:</span> ID<span>!</span>
  <span>title</span><span>:</span> String<span>!</span>
  <span>body</span><span>:</span> String<span>!</span>
<span>}</span>
type Query <span>{</span>
  <span>posts</span><span>:</span> <span>[</span>Post<span>]</span><span>!</span>
<span>}</span>
</code></pre><pre><code><span>const</span> Query <span>=</span> <span>{</span>
  posts<span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>[</span>
    <span>{</span>
      id<span>:</span> <span>'1'</span><span>,</span>
      title<span>:</span> <span>'My first GraphQL server'</span><span>,</span>
      body<span>:</span> <span>'How I wrote my first GraphQL server'</span><span>,</span>
    <span>}</span><span>,</span>
  <span>]</span><span>,</span>
<span>}</span>
</code></pre><p>While the schema-first approach is easy to get started with, it comes with some inherent drawbacks that can make development difficult when applications start getting bigger.</p><p>Nexus takes a different approach to building GraphQL APIs. Instead of keeping a separate schema and set of resolvers, with Nexus, schemas and resolvers are written in the same spot using code.</p><p>Refactoring the Post example above to Nexus would look like this:</p><pre><code><span>import</span> <span>{</span> objectType<span>,</span> queryType<span>,</span> makeSchema <span>}</span> <span>from</span> <span>'nexus'</span>

<span>const</span> Post <span>=</span> <span>objectType</span><span>(</span><span>{</span>
  name<span>:</span> <span>'Post'</span><span>,</span>
  <span>definition</span><span>(</span>t<span>)</span> <span>{</span>
    t<span>.</span><span>id</span><span>(</span><span>'id'</span><span>)</span>
    t<span>.</span><span>string</span><span>(</span><span>'title'</span><span>)</span>
    t<span>.</span><span>string</span><span>(</span><span>'body'</span><span>)</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span>

<span>const</span> Query <span>=</span> <span>queryType</span><span>(</span><span>{</span>
  <span>definition</span><span>(</span>t<span>)</span> <span>{</span>
    t<span>.</span>list<span>.</span><span>field</span><span>(</span><span>'posts'</span><span>,</span> <span>{</span>
      resolve<span>:</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>[</span>
        <span>{</span>
          id<span>:</span> <span>'1'</span><span>,</span>
          title<span>:</span> <span>'My first GraphQL server'</span><span>,</span>
          body<span>:</span> <span>'How I wrote my first GraphQL server'</span><span>,</span>
        <span>}</span><span>,</span>
      <span>]</span><span>,</span>
    <span>}</span><span>)</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span>
<span>const</span> schema <span>=</span> <span>makeSchema</span><span>(</span><span>{</span>
  types<span>:</span> <span>[</span>Post<span>,</span> Query<span>]</span><span>,</span>
<span>}</span><span>)</span>
</code></pre><p>There are numerous benefits to taking a code-first approach with Nexus, including:</p><ul><li>Schema and resolver co-location</li><li>SDL and type generation</li><li>No need for extra tooling</li></ul><h3 id="schema-and-resolver-co-location"><a href="#schema-and-resolver-co-location" aria-label="schema and resolver co location permalink"></a>Schema and Resolver Co-location</h3><p>When building a schema-first GraphQL API, it is common to start out by placing all type definitions and resolvers in a single file. When both the schema and the resolvers live next to one another, it's fairly straightforward to work in both at the same time.</p><p>As the application grows, however, it is most often desired to move parts of the schema into their own separate modules and files. It's at this point that working on a GraphQL API becomes a bit more tedious. With this modularization comes the need to switch back and forth between the Schema Definition Language and JavaScript/TypeScript to write the resolvers. Not only does one need to constantly switch between files, they also need to do a context switch mentally to work between the two langauges.</p><p>With Nexus, our schema and its resolvers are always defined together. Nexus also allows us to write everything in a common language. This allows us to side-step the co-location/context switching issue altogether and helps us to be more productive, even as our applications grow to be quite large.</p><h3 id="automatic-type-and-schema-definition-language-generation"><a href="#automatic-type-and-schema-definition-language-generation" aria-label="automatic type and schema definition language generation permalink"></a>Automatic Type and Schema Definition Language Generation</h3><p>One major benefit of using Nexus is its ability to automatically generate TypeScript types and GraphQL Schema Definition Language (SDL) files. The generated types are useful for adding extra type safety to the code used to power your GraphQL API. The generated SDL files can be used for many purposes. For example, we can configure our editors to know about the shape of our APIs to give us introspection for the queries and mutations we write.</p><p>Type and SDL generation comes for free with Nexus and can be enabled by supplying some configuration in the <code>makeSchema</code> call.</p><pre><code><span>import</span> path <span>from</span> <span>'path'</span>
<span>const</span> schema <span>=</span> <span>makeSchema</span><span>(</span><span>{</span>
  types<span>:</span> <span>[</span>Post<span>,</span> Query<span>]</span><span>,</span>
  outputs<span>:</span> <span>{</span>
    schema<span>:</span> path<span>.</span><span>join</span><span>(</span>__dirname<span>,</span> <span>'generated/schema.gen.graphql'</span><span>)</span><span>,</span>
    typegen<span>:</span> path<span>.</span><span>join</span><span>(</span>__dirname<span>,</span> <span>'generated/nexusTypes.gen.ts'</span><span>)</span><span>,</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span>
</code></pre><h2 id="whats-new-at-nexus-10"><a href="#whats-new-at-nexus-10" aria-label="whats new at nexus 10 permalink"></a>What's New at Nexus 1.0?</h2><p>There are a number of changes to Nexus at 1.0. Read the <a target="_blank" rel="noopener noreferrer" href="https://github.com/graphql-nexus/nexus/releases/tag/1.0.0">full changelog</a> and follow along below to see what's new!</p><h3 id="new-package-name"><a href="#new-package-name" aria-label="new package name permalink"></a>New Package Name</h3><p>Nexus 1.0 is now available under the <code>nexus</code> package name. All imports now come from <code>nexus</code> and not <code>@nexus/schema</code>.</p><pre><code><span>import</span> <span>{</span> makeSchema <span>}</span> <span>from</span> <span>'nexus'</span>

</code></pre><h3 id="changes-to-nullability"><a href="#changes-to-nullability" aria-label="changes to nullability permalink"></a>Changes to Nullability</h3><p>In previous versions of Nexus, fields were treated as non-nullable by default. This differed from other GraphQL API frameworks which would treat fields as nullable unless otherwise specified. The Nexus authors took this approach because allowing fields to be non-nullable by default posed some long-term risks for API development.</p><p>The default nullability for fields has now been inverted in Nexus so that we can align with GraphQL best practices and expectations, specifically from the authors of GraphQL.</p><p>At Nexus 1.0, you need to explicitly make fields non-null:</p><pre><code><span>const</span> Post <span>=</span> <span>objectType</span><span>(</span><span>{</span>
  name<span>:</span> <span>'Post'</span><span>,</span>
  <span>definition</span><span>(</span>t<span>)</span> <span>{</span>
    t<span>.</span>nonNull<span>.</span><span>id</span><span>(</span><span>'id'</span><span>)</span>
    t<span>.</span>nonNull<span>.</span><span>string</span><span>(</span><span>'title'</span><span>)</span>
    t<span>.</span>nonNull<span>.</span><span>string</span><span>(</span><span>'body'</span><span>)</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span>
</code></pre><p>The SDL for this type would look like this:</p><pre><code>type Post <span>{</span>
  <span>id</span><span>:</span> ID<span>!</span>
  <span>title</span><span>:</span> String<span>!</span>
  <span>body</span><span>:</span> String<span>!</span>
<span>}</span>
</code></pre><p>The code for the <code>Post</code> object type above uses a property called <code>nonNull</code> which offers a bit more flexibility for specifying that fields should be non-null. It's useful for situations where the chaining API is not ideal, such as expressing deeply-nested types and when programmatically creating non-nullable types.</p><pre><code><span>import</span> <span>{</span> queryType<span>,</span> stringArg<span>,</span> nonNull <span>}</span> <span>from</span> <span>'nexus'</span>

<span>queryType</span><span>(</span><span>{</span>
  <span>definition</span><span>(</span>t<span>)</span> <span>{</span>
    t<span>.</span><span>field</span><span>(</span><span>'tags'</span><span>,</span> <span>{</span>
      <span>type</span><span>:</span> <span>nonNull</span><span>(</span><span>'String'</span><span>)</span> 
      args<span>:</span> <span>{</span>
        id<span>:</span> <span>nonNull</span><span>(</span><span>stringArg</span><span>(</span><span>)</span><span>)</span> 
      <span>}</span><span>,</span>
      <span>resolve</span><span>(</span><span>)</span> <span>{</span>
        
      <span>}</span>
    <span>}</span><span>)</span>
  <span>}</span>
<span>}</span><span>)</span>
</code></pre><p>The <code>nonNull</code> function accepts an argument which can be used to specify the type for a type or argument.</p><p>While fields are now nullable by default, it's possible to change this behavior either globally or at the type level in your Nexus API.</p><div><pre><code><span>queryType</span><span>(</span><span>{</span>
  nonNullDefaults<span>:</span> <span>{</span>
    output<span>:</span> <span>true</span><span>,</span>
  <span>}</span><span>,</span>
  <span>definition</span><span>(</span>t<span>)</span> <span>{</span>
    t<span>.</span><span>string</span><span>(</span><span>'echo'</span><span>,</span> <span>{</span>
      args<span>:</span> <span>{</span>
        message<span>:</span> <span>'String'</span><span>,</span>
      <span>}</span><span>,</span>
      <span>resolve</span><span>(</span>_root<span>,</span> args<span>)</span> <span>{</span>
        <span>return</span> args<span>.</span>message
      <span>}</span><span>,</span>
    <span>}</span><span>)</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span>
</code></pre></div><p>In this example, Nexus now expects that fields should be non-null for all query type fields.</p><p>If you choose to change a type to be non-null by default, you can use the <code>nullable</code> function to specify that certain fields should be nullable.</p><pre><code><span>import</span> <span>{</span> queryType<span>,</span> stringArg<span>,</span> nullable <span>}</span> <span>from</span> <span>'nexus'</span>

<span>queryType</span><span>(</span><span>{</span>
  nonNullDefaults<span>:</span> <span>{</span>
    input<span>:</span> <span>true</span><span>,</span>
    output<span>:</span> <span>true</span><span>,</span>
  <span>}</span><span>,</span>
  <span>definition</span><span>(</span>t<span>)</span> <span>{</span>
    t<span>.</span><span>field</span><span>(</span><span>'echo'</span><span>,</span> <span>{</span>
      <span>type</span><span>:</span> <span>nullable</span><span>(</span><span>'String'</span><span>)</span><span>,</span>
      args<span>:</span> <span>{</span>
        message<span>:</span> <span>nullable</span><span>(</span><span>stringArg</span><span>(</span><span>)</span><span>)</span><span>,</span>
      <span>}</span><span>,</span>
      <span>resolve</span><span>(</span>_root<span>,</span> args<span>)</span> <span>{</span>
        <span>return</span> args<span>.</span>message
      <span>}</span><span>,</span>
    <span>}</span><span>)</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span>
</code></pre><p>To find out more about how Nexus handles nullability, including other ways to interact with the API, read the <a target="_blank" rel="noopener noreferrer" href="https://nexusjs.org/docs/guides/nullability">Nullability guide</a>.</p><h3 id="changes-to-the-list-api"><a href="#changes-to-the-list-api" aria-label="changes to the list api permalink"></a>Changes to the List API</h3><p>Nexus 1.0 introduces a new function for working with list types. The <code>list</code> function can be applied to inputs and outputs similar to how the <code>nonNull</code> and <code>nullable</code> functions are.</p><pre><code><span>import</span> <span>{</span> queryType<span>,</span> stringArg<span>,</span> list <span>}</span> <span>from</span> <span>'nexus'</span>

<span>queryType</span><span>(</span><span>{</span>
  <span>definition</span><span>(</span>t<span>)</span> <span>{</span>
    t<span>.</span><span>field</span><span>(</span><span>'tags'</span><span>,</span> <span>{</span>
      <span>type</span><span>:</span> <span>list</span><span>(</span><span>'String'</span><span>)</span> 
      args<span>:</span> <span>{</span>
        ids<span>:</span> <span>list</span><span>(</span><span>stringArg</span><span>(</span><span>)</span><span>)</span> 
      <span>}</span><span>,</span>
      <span>resolve</span><span>(</span><span>)</span> <span>{</span>
        
      <span>}</span>
    <span>}</span><span>)</span>
  <span>}</span>
<span>}</span><span>)</span>
</code></pre><p>The same chaining API for creating lists still remain, but the <code>list</code> function exist to help for situations where chaining is not ideal.</p><h3 id="abstract-types"><a href="#abstract-types" aria-label="abstract types permalink"></a>Abstract Types</h3><p>In GraphQL, Abstract types refer to Union and Interface types.</p><p>Union types allow you to express polymorphic fields where members types can be totally different.</p><p>Interface types let you express polymorphic fields wherein the field may return a number of different object types but they all share some subset of fields.</p><p>The official GraphQL JavaScript package supports three strategies for implementing Abstract types. Nexus 1.0 now offers an API for implementing these three strategies, providing type safety along the way.</p><p>Note that the following examples work with union types but it works similarly for interface types as well.</p><h4 id="centralized-strategy-resolvetype"><a href="#centralized-strategy-resolvetype" aria-label="centralized strategy resolvetype permalink"></a>Centralized Strategy (<code>resolveType</code>)</h4><p>The <a target="_blank" rel="noopener noreferrer" href="https://nexusjs.org/docs/guides/abstract-types#centralized-strategy-resolvetype">Centralized strategy</a> allows you to discriminate your union member types in a centralized (to the union type) way. For example:</p><pre><code><span>const</span> SearchResult <span>=</span> <span>unionType</span><span>(</span><span>{</span>
  name<span>:</span> <span>'SearchResult'</span><span>,</span>
  <span>resolveType</span><span>(</span>data<span>)</span> <span>{</span>
    <span>const</span> __typename <span>=</span> data<span>.</span>album <span>?</span> <span>'Song'</span> <span>:</span> data<span>.</span>rating <span>?</span> <span>'Movie'</span> <span>:</span> data<span>.</span>width <span>?</span> <span>'Photo'</span> <span>:</span> <span>null</span>
    <span>if</span> <span>(</span><span>!</span>__typename<span>)</span> <span>{</span>
      <span>throw</span> <span>new</span> <span>Error</span><span>(</span><span><span>`Could not resolve the type of data passed to union type "SearchResult"`</span></span><span>)</span>
    <span>}</span>
    <span>return</span> __typename
  <span>}</span><span>,</span>
  <span>definition</span><span>(</span>t<span>)</span> <span>{</span>
    t<span>.</span><span>members</span><span>(</span><span>'Photo'</span><span>,</span> <span>'Movie'</span><span>,</span> <span>'Song'</span><span>)</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span>
</code></pre><h4 id="discriminant-model-field-strategy-__typename"><a href="#discriminant-model-field-strategy-__typename" aria-label="discriminant model field strategy __typename permalink"></a>Discriminant Model Field Strategy (<code>__typename</code>)</h4><p>The <a target="_blank" rel="noopener noreferrer" href="https://nexusjs.org/docs/guides/abstract-types#discriminant-model-field-dmf-strategy-__typename">Discriminant Model Field (DMF) strategy</a> allows you to discriminate your union member types in a potentialy modular way. It is based on supplying at <!-- -->_<!-- -->_<!-- -->typename field in the model data returned by resolvers of fields typed as an abstract type. Here is an example:</p><pre><code><span>const</span> Query <span>=</span> <span>queryType</span><span>(</span><span>{</span>
  <span>definition</span><span>(</span>t<span>)</span> <span>{</span>
    t<span>.</span><span>field</span><span>(</span><span>'search'</span><span>,</span> <span>{</span>
      <span>type</span><span>:</span> <span>'SearchResult'</span><span>,</span>
      args<span>:</span> <span>{</span>
        pattern<span>:</span> <span>stringArg</span><span>(</span><span>)</span><span>,</span>
      <span>}</span><span>,</span>
      <span>resolve</span><span>(</span>root<span>,</span> args<span>,</span> ctx<span>)</span> <span>{</span>
        <span>return</span> ctx<span>.</span>db<span>.</span><span>search</span><span>(</span>args<span>.</span>pattern<span>)</span><span>.</span><span>map</span><span>(</span>result <span>=&gt;</span> <span>{</span>
          <span>const</span> __typename <span>=</span> result<span>.</span>album <span>?</span> <span>'Song'</span> <span>:</span> result<span>.</span>rating <span>?</span> <span>'Movie'</span> <span>:</span> result<span>.</span>width <span>?</span> <span>'Photo'</span> <span>:</span> <span>null</span>
          <span>if</span> <span>(</span><span>!</span>__typename<span>)</span> <span>{</span>
        …</code></pre></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.prisma.io/blog/announcing-the-release-of-nexus-schema-v1-b5eno5g08d0b">https://www.prisma.io/blog/announcing-the-release-of-nexus-schema-v1-b5eno5g08d0b</a></em></p>]]>
            </description>
            <link>https://www.prisma.io/blog/announcing-the-release-of-nexus-schema-v1-b5eno5g08d0b</link>
            <guid isPermaLink="false">hacker-news-small-sites-25427285</guid>
            <pubDate>Tue, 15 Dec 2020 05:19:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Redis Implementation for Cache and Database Consistency]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25427218">thread link</a>) | @wb14123
<br/>
December 14, 2020 | https://www.binwang.me/2020-12-14-Redis-Implementation-for-Cache-and-Database-Consistency.html | <a href="https://web.archive.org/web/*/https://www.binwang.me/2020-12-14-Redis-Implementation-for-Cache-and-Database-Consistency.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article_content">
<article id="post">
  <header>
    
    
      <p>Posted on 14 Dec 2020, tagged <code>Redis</code><code>database</code><code>consistency</code><code>Jepsen</code><code>distributed system</code></p>
    
  </header>

  <p><em>This article belongs to a series of articles about caching. The code in this article can be found at <a href="https://github.com/wb14123/redis_lease">my Github repo</a>.</em></p>

<ol>
  <li><em><a href="https://www.binwang.me/2020-11-02-Use-TLA+-to-Verify-Cache-Consistency.html">Use TLA+ to Verify Cache Consistency</a>.</em></li>
  <li><em>Redis Implementation for Cache and Database Consistency. (This one)</em></li>
</ol>

<p>In the <a href="https://www.binwang.me/2020-11-02-Use-TLA+-to-Verify-Cache-Consistency.html">last article</a>, we introduced an algorithm (described in paper <a href="https://pdos.csail.mit.edu/6.824/papers/memcache-fb.pdf">Scaling Memcache at Facebook</a>) that can do a better job to maintain the data consistency between cache and database. We also used TLA+ to model the algorithm and verified it. In this article, we are going to implement the algorithm in real world for Redis. The implementation is very simple and doesn’t need to change Redis itself. It’s implemented it by using Redis script. However, it’s much harder to verify the correctness. In order to do it, I used <a href="https://jepsen.io/">Jepsen</a> to test it. If you look at the language analysis for the Github repo, you can see most of them are tests. The Redis script implementation, which is written in Lua, is only 5.1% of the project.</p>

<h2 id="algorithm-description">Algorithm Description</h2>

<p>We’ve described the algorithm in the previous article and even write a TLA+ model for it. But just make it easier for the readers, I’ll briefly describe the algorithm here again. Basically, whenever the client get a value from cache, it will be assigned a unique ID (lease) for the key. When the client writes back a new value, it needs to provide the  key’s newest lease ID. And delete the key will also invalidate all its leases.</p>

<h2 id="implementation">Implementation</h2>

<p>The implementation uses <a href="https://redis.io/commands/eval">Redis script</a>, which is written in Lua. It can implement multiple operations and make them atomic. In theory, this can also be done by client, but Redis script provides a consistent implementation across different clients and makes it easier to use. The algorithm is easy, so the implementation is also straight forward. The implementations are under <a href="https://github.com/wb14123/redis_lease/tree/master/scripts">scripts directory of the repo</a>. These scripts also works for Redis cluster (but I didn’t use Jepsen to test it under cluster mode). Here is an example implementation for get:</p>

<div><div>
  <div><pre><span> <a href="#n1" name="n1">1</a></span><span>local</span> <span>key</span> = <span><span>'</span><span>{</span><span>'</span></span>..KEYS[<span>1</span>]..<span><span>'</span><span>}</span><span>'</span></span>
<span> <a href="#n2" name="n2">2</a></span><span>local</span> <span>token</span> = ARGV[<span>1</span>]
<span> <a href="#n3" name="n3">3</a></span><span>local</span> <span>value</span> = redis.call(<span><span>'</span><span>get</span><span>'</span></span>, key)
<span> <a href="#n4" name="n4">4</a></span><span>if</span> <span>not</span> value <span>then</span>
<span> <a href="#n5" name="n5">5</a></span>    redis.replicate_commands()
<span> <a href="#n6" name="n6">6</a></span>    <span>local</span> <span>lease_key</span> = <span><span>'</span><span>lease:</span><span>'</span></span>..key
<span> <a href="#n7" name="n7">7</a></span>    redis.call(<span><span>'</span><span>set</span><span>'</span></span>, lease_key, token)
<span> <a href="#n8" name="n8">8</a></span>    <span>return</span> <span><span>{</span><span>false</span>, token<span>}</span></span>
<span> <a href="#n9" name="n9">9</a></span><span>else</span>
<span><strong><a href="#n10" name="n10">10</a></strong></span>    <span>return</span> <span><span>{</span>value, <span>false</span><span>}</span></span>
<span><a href="#n11" name="n11">11</a></span><span>end</span>
</pre></div>
</div>
</div>

<p>After load the script, you can use it like this:</p>

<div><div>
  <div><pre><span><a href="#n1" name="n1">1</a></span>redis-cli evalsha &lt;script_sha1&gt; 1 &lt;key&gt; &lt;uniq_id&gt;
</pre></div>
</div>
</div>

<p>It will return <code>value, nil</code> if there is value for the key, or <code>nil, lease</code> if there is no value.</p>

<p>One optimization here is, if we have value for the key, we will not store the lease. That’s because in our use case, if we can get the value, we will not get it from database and write back to the cache. This avoids a lot of memory overhead.</p>

<p>Another important decision I made is, when get the value, the client needs to provide a unique ID instead of let Redis provide one. This is because I cannot find a good way to generate unique ID in Redis cluster. In a single instance, it’s easy: just use a key and inc the value each time. You can still generate unique IDs for different keys on a cluster, but it adds a lot of memory overhead. So I decided to let clients provide it. Luckily, it’s not hard, basically every language has UUID implementation and that’s good enough.</p>

<h2 id="testing">Testing</h2>

<p>It’s easy to implement something, but very hard to make sure it’s correct. We can use TLA+ to model the algorithm and explore the state space, or use mathematical method to proof the correctness in theory. But once we implement the algorithm, it’s something different. We cannot make sure it’s exactly the same as what we’ve proofed. That’s why I find using Coq to implement, proof and generate real code is fantastic. But in this case, it’s not implemented in Coq, so we must find some other way to test it. By testing, we still cannot make sure it’s 100% correct, we can just explore as many situations as we can and make sure the system doesn’t behaves in a way we don’t expect.</p>

<p>The tool we use here is <a href="https://jepsen.io/">Jepsen</a>. It provides lots of tools to make it easy to test distributed systems. It can generate many concurrent requests, import different kinds of failures (host down, network partition, clock drift, and so on) to the system, record all the requests and responses, and check the history at the end.</p>

<p>Here is the test case I write: for each client, generate random read and write operations. For read operation, read from cache first, if the value is not found, read from database and write back to the data. For write operations, write to the database and delete the key from cache. Then after all the read and write operations, check whether the data in cache and database are the same. The test case is very simple, it implemented the way we would use the cache.</p>

<p>By providing different arguments to the test command, you can run the test case with raw Redis get/set/del operations, or use get/set/del operation implemented by the scripts. You can also import cache failure during the test.</p>

<p>If we run the test with raw Redis operations, we can find the test is failed. In the last article, we discussed that using plain get/set/del cache operations cannot guarantee cache consistency, so this is expected. If we run the test with our scripts, we can find the test passed. If we run the test with cache system failure, we can see the test failed, which is also expected from last article. The inconsistent because of cache failure can be resolved by clean up cache data after restart. But if the client is failed, it will have the same problem (I didn’t write the test case for this because it’s hard to test client failure in Jepsen), but it’s not a very good idea to cleanup cache in this case. Because client fails all the time, cleanup cache will make operations slow. The best way might be to setup an expire time so the data can be consistent after the key is expired.</p>

<p>Even though all the test result is expected, it doesn’t make sure the implementation is correct, since there are still many situation I didn’t test, like Redis cluster, network partition, database failure and so on. So welcome to add new test cases and break the system!</p>

</article>







<!-- MathJax -->




</div></div>]]>
            </description>
            <link>https://www.binwang.me/2020-12-14-Redis-Implementation-for-Cache-and-Database-Consistency.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25427218</guid>
            <pubDate>Tue, 15 Dec 2020 05:07:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I assume I’m below average (2010)]]>
            </title>
            <description>
<![CDATA[
Score 372 | Comments 221 (<a href="https://news.ycombinator.com/item?id=25426976">thread link</a>) | @enigmatic02
<br/>
December 14, 2020 | https://sive.rs/below-average | <a href="https://web.archive.org/web/*/https://sive.rs/below-average">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<article>
<header>
<div><p>from the book “<a href="https://sive.rs/n">Hell Yeah or No</a>”:</p></div>

<small>2010-07-01</small>
  <audio src="https://m.sive.rs/sive.rs.below-average.mp3" preload="none" controls="controls"></audio>
</header>

<p>
	Ninety-six percent of cancer patients claim to be in better health than the average cancer patient.
</p><p>
	Ninety-four percent of professors say they are better-than-average teachers.
</p><p>
	Ninety percent of students think they are more intelligent than the average student.
</p><p>
	Ninety-three percent of drivers say they are safer-than-average drivers.
</p><p>
	When I learned this, it shook my soul.
	At first, like almost everybody, I thought, “Yes, but I really am above average!”
	Then I realized I was doing it again.
</p><p>
	So I decided to gamble on the opposite.
	Now I just assume I’m below average.
</p><p>
	It serves me well.
	I listen more.
	I ask a lot of questions.
	I’ve stopped thinking <a href="https://sive.rs/ss">others are stupid</a>.
	I assume most people are smarter than me.
</p><p>
<strong>
	To assume you’re below average is to admit you’re still learning.
</strong>
	You focus on what you need to improve, not your <a href="https://sive.rs/expire">past accomplishments</a>.
</p><p>
	Many people are so worried about looking good that they never do anything great.
	Many people are so worried about doing something great that they never do anything at all.
</p><p>
	You destroy that paralysis when you think of yourself as just a student, and your current actions as just practice.
</p>


</article>



</div></div>]]>
            </description>
            <link>https://sive.rs/below-average</link>
            <guid isPermaLink="false">hacker-news-small-sites-25426976</guid>
            <pubDate>Tue, 15 Dec 2020 04:22:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Matter Cannot Travel Faster Than Light]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25426752">thread link</a>) | @keyboardman
<br/>
December 14, 2020 | https://leimao.github.io/blog/Matter-Cannot-Travel-Faster-Than-Light/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Matter-Cannot-Travel-Faster-Than-Light/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">
  <div>
    
	<p><img src="https://leimao.github.io/images/author_images/Lei-Bio-Medium.jpg" alt="Lei Mao bio photo"></p><h3>Lei Mao</h3>
<p>Machine Learning, Artificial Intelligence, Computer Science.</p>
<p>

<a href="http://facebook.com/dukeleimao" target="_blank"><i></i> Facebook</a>
<a href="http://linkedin.com/in/lei-mao" target="_blank"><i></i> LinkedIn</a>


<a href="http://github.com/leimao" target="_blank"><i></i> GitHub</a>
<a href="http://scholar.google.com/citations?user=R2VUf7YAAAAJ" target="_blank"><i></i>&nbsp; G. Scholar</a>






<a href="mailto:dukeleimao@gmail.com" target="_blank"><i></i> E-Mail</a>

<a href="https://leimao.github.io/feed.xml" target="_blank"> RSS</a>
  </p></div>
  <article>
    <!--/ .headline-wrap -->
    <div>
      <h3 id="introduction">Introduction</h3>

<p>Einstein has once confidently pointed out that under the assumptions of special relativity, matter, anything that has weight, cannot travel faster than constant light speed $c$.</p>



<p>In this blog post, I would like to use two mathematical approaches to show that why this is the case.</p>

<h3 id="relativistic-momentum-approach">Relativistic Momentum Approach</h3>

<p>In my previous blog <a href="https://leimao.github.io/blog/Relativistic-Momentum-Relativistic-Mass/">post</a>, I have derived the expression of relativistic momentum.</p><p>

\[\begin{align}
p &amp;= m_r v \\
&amp;= \gamma m_0 v \\
\end{align}\]

</p><p>where $\gamma$ is the Lorentz factor, $m_r$ is the relativistic mass at the velocity of $v$, and $m_0$ is the rest mass which does not change with velocity.</p><p>

\[\gamma = \frac{1}{\sqrt{1 - \frac{v^2}{c^2}}}\]

</p><p>Newtonâ€™s second law states that the rate of change of momentum of a body is directly proportional to the force applied, and this change in momentum takes place in the direction of the applied force.</p><p>

\[\begin{align}
F &amp;= \frac{dp}{dt} \\
&amp;= \frac{d(m_r v)}{dt} \\
&amp;= \frac{d(\gamma m_0 v)}{dt} \\
&amp;= m_0 \frac{d(\gamma v)}{dt} \\
&amp;= m_0 \frac{d\bigg(\frac{v}{\sqrt{1 - \frac{v^2}{c^2}}}\bigg)}{dt} \\
&amp;= m_0 \frac{d\bigg(\frac{1}{\sqrt{\frac{1}{v^2} - \frac{1}{c^2}}}\bigg)}{dt} \\
&amp;= m_0 \frac{d ( v^{-2} - c^{-2} )^{-\frac{1}{2}}}{dt} \\
&amp;= m_0 \frac{-\frac{1}{2} ( v^{-2} - c^{-2} )^{-\frac{3}{2}} (-2) v^{-3} dv}{dt} \\
&amp;= m_0 \frac{ ( v^{-2} - c^{-2} )^{-\frac{3}{2}} (v^{2})^{-\frac{3}{2}} dv}{dt} \\
&amp;= m_0 \frac{ \big( 1 - \frac{v^2}{c^2} \big)^{-\frac{3}{2}} dv}{dt} \\
&amp;= m_0 \big( 1 - \frac{v^2}{c^2} \big)^{-\frac{3}{2}}  \frac{dv}{dt} \\
\end{align}\]

</p><p>We could easily see that if we apply a constant force to matter, as the velocity $v$ of matter approaches $c$, $\big( 1 - \frac{v^2}{c^2} \big)^{-\frac{3}{2}} \rightarrow \infty$, the apparent acceleration $\frac{dv}{dt} \rightarrow 0$, meaning that the apparent acceleration becomes smaller with the constant force applied on the matter. When $v = c$, to make the matter travel faster than light, you would need to have a tiny apparent acceleration $\frac{dv}{dt}$. However, in this time, since $\big( 1 - \frac{v^2}{c^2} \big)^{-\frac{3}{2}} = \infty$, we would need to apply infinity large force $F$ to the matter, which is not plausible.</p>

<h3 id="mass-energy-equivalence-approach">Mass-Energy Equivalence Approach</h3>

<p>In my previous blog <a href="https://leimao.github.io/blog/Mass-Energy-Equivalence-Derivation/">post</a>, I have also derived the mass-energy equivalence.</p><p>

\[\begin{align}
E &amp;= m_r c^2 \\
&amp;= \gamma m_0 c^2 \\
\end{align}\]

</p><p>where $\gamma$ is the Lorentz factor, $m_r$ is the relativistic mass at the velocity of $v$, and $m_0$ is the rest mass.</p>



<p>We could easily see that as the velocity $v$ of matter approaches $c$, the Lorentz factor $\gamma \rightarrow \infty$, and the total energy of the matter $E \rightarrow \infty$. Based on the energy conservation, we would need to supply infinity energy to the matter to archive velocity $c$, which is not plausible.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://leimao.github.io/blog/Relativistic-Momentum-Relativistic-Mass/">Relativistic Momentum and Relativistic Mass</a></li>
  <li><a href="https://leimao.github.io/blog/Mass-Energy-Equivalence-Derivation/">Mass-Energy Equivalence Derivation</a></li>
</ul>

      <hr>
      
    </div><!-- /.article-wrap -->
  
    <!-- /#disqus_thread -->
  
  </article>
</div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Matter-Cannot-Travel-Faster-Than-Light/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25426752</guid>
            <pubDate>Tue, 15 Dec 2020 03:48:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google gets preferential permissions in robots.txt]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25426662">thread link</a>) | @bobsil1
<br/>
December 14, 2020 | https://knuckleheads.club/introduction/ | <a href="https://web.archive.org/web/*/https://knuckleheads.club/introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
<div id="content">
<div id="primary">
<main id="main">
<article id="post-2715" class="page" itemtype="https://schema.org/CreativeWork" itemscope="">
<div>
<div itemprop="text">
<p>In the fall of 2018, we noticed that there was something that set Google apart from other big tech companies. Everybody was talking about how to regulate these tech companies, and everybody had pretty good plans for how to do it — for every company besides Google. In our opinion, it was because nobody really seemed to understand what Google does, or how they do it. So, for the past two years, we’ve been researching and analyzing Google. Through this work, we’ve found some really compelling evidence about what powers Google’s monopoly, so much so that <a href="https://knuckleheads.club/2020/10/07/we-crawled-our-way-into-the-big-tech-antitrust-report/">Congress referenced this work as part of their recently released Big Tech Antitrust Report</a>. The big ideas that we have is that that crawling the web is a natural monopoly, that Google has control of that monopoly, and that once you understand why this is true and what it means it becomes pretty clear about what sorts of regulations should be taken to reign in Google’s power over the internet. </p>
<p>We have published on this website the economic arguments that we have developed that we think help people understand the foundations of Google and how to regulate<a href="https://knuckleheads.club/understanding-google/"> </a>them. Up until now we have done all this work in private, reaching out to and meeting with regulators on an individual basis. With the publishing of an article about this work in <a href="https://www.nytimes.com/2020/12/14/technology/how-google-dominates.html">The New York Times</a>, we are publishing this research for everyone to read and opening up the club for people to join and participate in researching Google’s monopoly. We have a <a href="https://knuckleheads.club/whats-next/" data-type="page" data-id="2518">solid plan for the next year</a> about how to finish this research and work with legislators and governments to get legislation drafted and introduced to regulate Google’s web crawling advantages. If you find yourself agreeing with what you read on this website and get caught up imagining a better future where the internet isn’t just five big tech companies all cutting deals with each other, please consider <a href="https://knuckleheads.club/join-the-club/" data-type="page" data-id="2444">joining the Knuckleheads’ Club</a> and helping us fight to win a better world. </p>
<p>So, with all that said as an introduction, let’s dive into what Google is exactly. </p>


 </div>
</div>
</article>
</main>
</div>

</div>
</div></div>]]>
            </description>
            <link>https://knuckleheads.club/introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25426662</guid>
            <pubDate>Tue, 15 Dec 2020 03:34:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TP-Link Archer VR1600V V2 Super User Password Cracked]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 95 (<a href="https://news.ycombinator.com/item?id=25426566">thread link</a>) | @stubish
<br/>
December 14, 2020 | https://www.marcelvarallo.com/so-we-cracked-the-archer-vr1600v-v2-super-user-password/ | <a href="https://web.archive.org/web/*/https://www.marcelvarallo.com/so-we-cracked-the-archer-vr1600v-v2-super-user-password/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">






<div id="content">
	<div id="primary">
		<main id="main" role="main" itemprop="mainContentOfPage">



<article role="article" id="post-1523" itemscope="" itemprop="blogPost" itemtype="https://schema.org/BlogPosting">

	<meta itemscope="" itemprop="mainEntityOfPage" itemtype="https://schema.org/WebPage">
	<div itemprop="articleBody">

		
		<p>Well the news is out, I won’t explain the method for reasons, but our code warriors have a new fight. After requesting the SU password, they were told flat out it doesn’t exist and referred to the manual by the vendor. Taking that argument to the telco ombudsman got the same response. If there were one and you wanted to change it for security reasons, it looks like you can’t and with the vendors denying it’s existance, there’s no help coming.</p>
<p>So, the password for the SU account that doesn’t exist…</p>
<p>VExy!64a3ng</p>

		
	</div>

	
	<nav role="navigation">
		<h2>Post navigation</h2>
		
	</nav>
</article>


	

	

		</main><!-- /#main -->
	</div><!-- /#primary -->
</div><!-- /#content -->






</div></div>]]>
            </description>
            <link>https://www.marcelvarallo.com/so-we-cracked-the-archer-vr1600v-v2-super-user-password/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25426566</guid>
            <pubDate>Tue, 15 Dec 2020 03:18:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jd.com uses Vitess to manage scaling databases for hyperscale]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25426565">thread link</a>) | @gesaint
<br/>
December 14, 2020 | https://www.cncf.io/case-studies/jdcom-vitess/ | <a href="https://web.archive.org/web/*/https://www.cncf.io/case-studies/jdcom-vitess/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<article>
				<div>
			<section>

<figure>
	<picture><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-2880x520.jpg" media="(min-width: 2880px)"><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-1920x260.jpg" media="(min-width: 1920px)"><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-1440x260.jpg" media="(min-width: 1440px)"><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-1200x220.jpg" media="(min-width: 1200px)"><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-1024x220.jpg" media="(min-width: 1024px)"><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-768x220.jpg" media="(min-width: 768px)"><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-600x220.jpg" media="(min-width: 600px)"><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-414x220.jpg" media="(min-width: 414px)"><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-375x220.jpg" media="(min-width: 375px)"><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-320x220.jpg" media="(min-width: 0px)">
		<img src="https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-320x220.jpg" alt="">
		</picture></figure>


</section>

	

<section>

	<div>

		<div>
		

<h3>Challenge</h3>



<p>China’s largest retailer, JD.com serves more than 300 million active customers with its e-commerce business. “A few years ago, it became apparent that as our data became more extensive, our MySQL databases became larger, resulting in declining performance and higher operations and maintenance costs,” says JD Retail Chief Architect Haifeng Liu. “We needed a solution that would enable us to easily and quickly scale MySQL, facilitate operation and maintenance, and reduce hardware and labor costs.”</p>



<h3>Solution</h3>



<p>JD chose Vitess for scalable management of large-scale database services and the support of online expansion of complex transactional data in MySQL. “We now run MySQL databases in containerized environments with Kubernetes and use Vitess for scalable cluster management and handling large volumes of complex transactional data,” says Liu.</p>



<h3>Impact</h3>



<p>With Vitess, JD has seen improvements in&nbsp;the scalability and elasticity of the database clusters. Increased resource utilization and efficiency and the automation of operation and maintenance functions have also led to reductions in labor and resource costs.</p>

		</div>

		
	</div>
</section>
	

<section>

<div>
<div>

	
		<p>
	<h3>300+ million active e-commerce customers</h3>
</p>
<p>
	<h3>Tens of thousands of MySQL containers</h3>
</p>
<p>
	<h3>Millions of tables, trillions of records</h3>
</p>
</div></div>

</section>
	


<figure><p>
<iframe title="Two Years with Vitess: How JD.com Runs the World's Largest Vitess - Xuhaihua &amp; Jin Ke Xie , JD.com" width="500" height="281" src="https://www.youtube.com/embed/qww4UVNG3Io?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<h3>China’s largest retailer and the world’s third-largest Internet company by revenue, JD.com serves more than 300 million active customers with its e-commerce business.</h3>



<p>The company also owns China’s largest e-commerce logistics infrastructure, which covers an incredible 99% of the country’s population and has achieved delivery rates of more than 90% of orders delivered same- or next-day.</p>



<p>“A few years ago, it became apparent that as our data became more extensive, our MySQL databases became larger, resulting in declining performance and higher operations and maintenance costs,” says JD Retail Chief Architect Haifeng Liu, who leads the Technological Infrastructure Department responsible for driving innovation in containerized infrastructure and developing the hyperscale, containerized, Kubernetes-based platform that powers all facets of JD’s business. “We needed a solution that would enable us to easily and quickly scale MySQL, facilitate operation and maintenance, and reduce hardware and labor costs.”</p>



<p>The company previously used JProxy, a cobar-based database middleware system for MySQL database management. After a thorough evaluation process, Liu says, “we eventually chose Vitess since it was the most suitable solution to address the biggest challenge we were facing: scalable management of large-scale database services and the support of online expansion of complex transactional data in MySQL. We now run MySQL databases in containerized environments with Kubernetes and use Vitess for scalable cluster management and handling large volumes of complex transactional data.”</p>



<figure><ul><li><figure><img loading="lazy" width="1024" height="683" src="https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-1024x683.jpg" alt="" data-id="38735" data-link="https://www.cncf.io/case-studies/jd-com/attachment/a-visit-to-jd-com-new-headquarters-in-yizhuang-of-beijing/" srcset="https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-1024x683.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-300x200.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-768x512.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-1536x1024.jpg 1536w, https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-2048x1365.jpg 2048w, https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-700x467.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-255x170.jpg 255w, https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-405x270.jpg 405w, https://www.cncf.io/wp-content/uploads/2020/07/gettyimages-487083320-510x340.jpg 510w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></li><li><figure><img src="https://www.cncf.io/wp-content/uploads/2020/07/Delivery-by-JD.com_-1024x597-1.jpg" alt="" data-id="38787" data-full-url="https://www.cncf.io/wp-content/uploads/2020/07/Delivery-by-JD.com_.jpg" data-link="https://www.cncf.io/case-studies/jdcom-vitess/attachment/delivery-by-jd-com_/"></figure></li></ul></figure>



<p>Being a very early adopter of Vitess—and with one of the largest and most complex deployments of the technology, to boot—came with some challenges. “The re-sharding process was initially manual, the performance was poor, and the orchestrator could fail in large clusters with more than 5,000 instances,” says Liu.&nbsp;</p>



<p>To make sure that Vitess would work at JD’s scale, Liu’s team made numerous improvements and changes, including bug fixes and new functionalities and features. They have also developed performance optimization and automated management tools for the company’s JDOS Kubernetes platform. Among them:&nbsp;</p>



<ul><li>JTransfer, an online data synchronization and transmission tool that migrates data from JD’s traditional MySQL databases to the Vitess cluster in real time. All topology information in Vitess is stored in etcd.&nbsp;</li><li>BinLake, a MySQL collection tool for real-time collection of Binlog in Vitess and traditional MySQL database services, and publication of the collected Binlog to the Message Queue (JMQ) service. Integrated with Vitess, “BinLake provides intelligent and highly available binlog collection services in clusters,” says Liu. “If there is resharding or failover in Vitess, Binlake will automatically adjust the database instance of the binlog.”</li><li>Mole, a Vitess management system with a GUI console, which improves Vitess service management. “With Mole, we can easily create, reshard, monitor, and back up Vitess’s keyspaces,” says Liu.</li></ul>



<p>“Most of our improvements have been contributed back to the Vitess code base for other developers in the community to benefit from,” says Liu.&nbsp;</p>



<blockquote><p>“We eventually chose Vitess since it was the most suitable solution to address the biggest challenge we were facing: scalable management of large-scale database services.”</p><cite>— HAIFENG LIU, CHIEF ARCHITECT AT JD RETAIL</cite></blockquote>



<p>With Vitess, JD has seen improvements in the scalability and elasticity of the database clusters. Increased resource utilization and efficiency and the automation of operation and maintenance functions have also led to reductions in labor and resource costs.&nbsp;</p>



<p>Additionally, “Vitess helped the team grow their technical knowledge and strength in the areas of scalable management and elastic database,” says Liu. “The fact that Vitess is a CNCF project means we can significantly benefit from working with a large number of developers and end users in the most active and fast-growing open source community. With CNCF’s endorsement, Vitess can gain increasing awareness, attract more end users and bring together developers to the project. This is very beneficial for Vitess and its end users, which is important to us.”</p>



<p>Liu and his team are excited about the future of Vitess. In addition to migrating its systems to the newly-released Vitess 3.0 (which Liu calls “a significant improvement”), they’re working on developing some common functions for the latest version and developing a more complete operations and maintenance monitoring system.&nbsp;</p>



<blockquote><p>“The fact that Vitess is a CNCF project means we can significantly benefit from working with a large number of developers and end users in the most active and fast-growing open source community.”</p><cite>— HAIFENG LIU, CHIEF ARCHITECT AT JD RETAIL</cite></blockquote>



<p>For other organizations considering Vitess, Liu offers this advice: “The most value can be derived from Vitess when it is used in concert with Kubernetes. Before using Vitess, it is imperative to perform more testing and research to determine if Vitess is the right solution for your business, and to better understand what adjustments you might have to make to integrate it with your existing systems.”</p>



<p>For JD, Kubernetes, Vitess, and other cloud native technologies have been a game-changer. “Modern service platforms need to be scalable and extremely efficient and agile,” says Liu. “Cloud native technology is well-suited to handle these ever-changing environments. It offers flexibility, efficiency, scalability, independence, continuous integration and delivery for software services, all of which further enhance the quality of software services and resource efficiency. Kubernetes has become the de facto standard and cloud native is a sure thing to bet on for the future.”</p>
		</div>
				</article>
</div></div>]]>
            </description>
            <link>https://www.cncf.io/case-studies/jdcom-vitess/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25426565</guid>
            <pubDate>Tue, 15 Dec 2020 03:18:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Square: Vitess enables ‘near unlimited scale’ for Cash App]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25426553">thread link</a>) | @gesaint
<br/>
December 14, 2020 | https://www.cncf.io/case-studies/square/ | <a href="https://web.archive.org/web/*/https://www.cncf.io/case-studies/square/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<article>
				<div>
			<section>

<figure>
	<picture><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-2000x520.jpg" media="(min-width: 2880px)"><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-1920x260.jpg" media="(min-width: 1920px)"><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-1440x260.jpg" media="(min-width: 1440px)"><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-1200x220.jpg" media="(min-width: 1200px)"><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-1024x220.jpg" media="(min-width: 1024px)"><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-768x220.jpg" media="(min-width: 768px)"><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-600x220.jpg" media="(min-width: 600px)"><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-414x220.jpg" media="(min-width: 414px)"><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-375x220.jpg" media="(min-width: 375px)"><source srcset="https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-320x220.jpg" media="(min-width: 0px)">
		<img src="https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-320x220.jpg" alt="">
		</picture></figure>


</section>

	

<section>

	<div>

		<div>
		

<h3>Challenge</h3>



<p>Four years ago, <a href="https://squareup.com/us/en" target="_blank" rel="noreferrer noopener">Square</a> branched out into peer-to-peer transactions via its <a href="https://cash.app/" target="_blank" rel="noreferrer noopener">Cash App</a>. After some steady growth, the app rocketed in popularity in 2016, reaching millions of users over just a few months. But its large monolith of a few hundred thousand lines of code was built on the assumption of one single <a href="https://www.mysql.com/" target="_blank" rel="noreferrer noopener">MySQL</a> database and wasn’t designed to scale.</p>



<h3>Solution</h3>



<p>To solve the long-term scalability problem, they turned to <a href="https://vitess.io/" target="_blank" rel="noreferrer noopener">Vitess</a>, the open source database clustering system for horizontal scaling of MySQL. “The nice thing is if we solved it once, then we have a piece of infrastructure that would be the cookie-cutter way we would scale out other systems that are built the same way,” says Engineering Manager Jon Tirsen.</p>



<h3>Impact</h3>



<p>The first shard split with Vitess took place in November 2017, and “there was less than a second of downtime, so it was not user visible,” says Tirsen. Nowadays, “it’s completely routine. We did ten shard splits last week.” Looking ahead at Cash App’s continued growth, Tirsen says, “You have to keep on working on it, but Vitess does provide you essentially with near unlimited scale.</p>

		</div>

		
	</div>
</section>
	

<section>

<div>
<div>

	<div>
<p>
		CNCF projects used</p>
<div>
		<p><img loading="lazy" src="https://www.cncf.io/wp-content/themes/lf-theme/images/projects/vitess-icon-black.svg" alt="Vitess">
</p>
			</div>
</div>
		<p>
	<h3>Only 5% of the system had to be changed</h3>
</p>
<p>
	<h3>10 shard splits a week</h3>
</p>
<p>
	<h3>Shard splits with less than a second of downtime</h3>
</p>
</div></div>

</section>
	


<h3>For millions of people, from taxi drivers to market vendors to big businesses, <a href="https://squareup.com/us/en" target="_blank" rel="noreferrer noopener">Square</a> has made getting paid by credit card much easier since it launched its card reader and mobile app in 2010.</h3>



<p>Four years ago, the company branched out into peer-to-peer transactions via its <a href="https://cash.app/" target="_blank" rel="noreferrer noopener">Cash App</a>. After some steady growth, the app rocketed in popularity in 2016, reaching millions of users over just a few months and landing at the top of the App Store’s most popular downloads.</p>



<p>The only problem? “We had a large monolith of a few hundred thousand lines of code that was built on the assumption of one single MySQL database; it was never really designed to scale from the start,” says Engineering Manager Jon Tirsen. With users increasing by the minute, the company had to dedicate more and more expensive hardware for its database. But that clearly wasn’t a long-term solution, so Tirsen’s team of three was tapped to solve the scalability problem for Cash App. “Because we had the growth trajectory, we really needed to solve it very, very quickly to step up to the challenge of the product side,” he says.</p>



<p>The team’s first pass was trying to pull data out into key value storage that they built on top of MySQL. “It’s an inherently scalable storage platform, but less feature rich,” Tirsen says. Plus, this solution would have required rewriting hundreds of thousands of lines of code and thousands of different queries, and “there was just no way we would have had the time to do it,” he says.</p>



<figure><ul><li><figure><img loading="lazy" width="1024" height="764" src="https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-1024x764.jpg" alt="" data-id="38885" data-full-url="https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03.jpg" data-link="https://www.cncf.io/case-studies/squarespace-2/attachment/bcj_matthew_millman_square_03/" srcset="https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-1024x764.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-300x224.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-768x573.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-1536x1146.jpg 1536w, https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-268x200.jpg 268w, https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-700x522.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-228x170.jpg 228w, https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-362x270.jpg 362w, https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03-456x340.jpg 456w, https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_03.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></li><li><figure><img loading="lazy" width="816" height="489" src="https://www.cncf.io/wp-content/uploads/2020/07/Square_1.32.jpg" alt="" data-id="38886" data-full-url="https://www.cncf.io/wp-content/uploads/2020/07/Square_1.32.jpg" data-link="https://www.cncf.io/case-studies/squarespace-2/attachment/square_1-32/" srcset="https://www.cncf.io/wp-content/uploads/2020/07/Square_1.32.jpg 816w, https://www.cncf.io/wp-content/uploads/2020/07/Square_1.32-300x180.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/Square_1.32-768x460.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/Square_1.32-325x195.jpg 325w, https://www.cncf.io/wp-content/uploads/2020/07/Square_1.32-700x419.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/Square_1.32-284x170.jpg 284w, https://www.cncf.io/wp-content/uploads/2020/07/Square_1.32-451x270.jpg 451w, https://www.cncf.io/wp-content/uploads/2020/07/Square_1.32-567x340.jpg 567w" sizes="(max-width: 816px) 100vw, 816px"></figure></li><li><figure><img loading="lazy" width="1024" height="762" src="https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_08-1024x762.jpg" alt="" data-id="38887" data-full-url="https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_08.jpg" data-link="https://www.cncf.io/case-studies/squarespace-2/attachment/bcj_matthew_millman_square_08/" srcset="https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_08-1024x762.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_08-300x223.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_08-768x572.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_08-1536x1144.jpg 1536w, https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_08-269x200.jpg 269w, https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_08-700x521.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_08-228x170.jpg 228w, https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_08-363x270.jpg 363w, https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_08-457x340.jpg 457w, https://www.cncf.io/wp-content/uploads/2020/07/BCJ_Matthew_Millman_Square_08.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></li></ul></figure>



<p>So the team proposed solving sharded MySQL themselves. At the time, addressing the problem in the application rather than in the infrastructure layer was the default way to solve scale at Square, as well as at many other companies like Facebook or Pinterest. The team had begun drawing up plans, when someone else at Square suggested they look at <a href="https://vitess.io/" target="_blank" rel="noreferrer noopener">Vitess</a>, the open source database clustering system for horizontal scaling of MySQL.</p>



<p>The project was still relatively new, but after Tirsen started digging into the code, he realized it would work for Cash App. Vitess met two of the team’s key requirements: infrastructure or platform layer query routing—sending queries to the right database—and online shard splitting without downtime.</p>



<p>Additionally, “the nice thing is if we solved it once, then we have a piece of infrastructure that would be the cookie-cutter way we would scale out other systems that are built the same way,” says Tirsen. “So that was kind of exciting, and it would mean that we didn’t need to completely rebuild our system. We could just make Vitess work, and the system would work. Maybe we had to change 5% of the system rather than 95% of the system.”</p>



<blockquote><p>“You have to keep on working on it, but Vitess does provide you essentially with near unlimited scale.”</p><cite>— JON TIRSEN, ENGINEERING MANAGER AT SQUARE</cite></blockquote>



<p>Tirsen’s team spent about a year making those changes, as well as adapting Vitess to work inside the overall Square infrastructure. To enable an external database to work with Vitess, the team rebuilt a lot of the shard-splitting workflows.</p>



<p>“The biggest thing we did was we changed the way sharding works,” says Tirsen. “Before, Vitess did shard splits by stopping replication, but because we can’t control our external databases, we changed that to instead use MySQL’s built-in support for consistent snapshots, where you can view the database at a fixed point in time, even if the database is still getting updated. Then you can make a copy of the database based on that consistent snapshot.”</p>



<p>That work has been upstreamed, and is now commonly used throughout the Vitess community. “It’s an amazing bonus that we can work together on solving problems across companies that don’t normally have a formal way of working together,” Tirsen says.</p>



<p>Next, the team practiced the shard splits in staging and testing environments—a lot. “You can practice the entire shard split except the last query reroute, where you basically start writing to the new shard, without affecting any production traffic at all,” says Tirsen.</p>



<blockquote><p>“While we were doing these very dramatic changes to our architecture to make it scalable, the feature teams were building incredible features on top of Cash App.”</p><cite>— JON TIRSEN, ENGINEERING MANAGER AT SQUARE</cite></blockquote>



<p>The first shard split with Vitess took place at 5 a.m. ET in November 2017, and “there was less than a second of downtime, so it was not user visible,” says Tirsen. “It was incredibly exciting.” Nowadays, he adds, “it’s completely routine. We did ten shard splits last week.”</p>



<p>Overall, Tirsen says he is proudest of this fact: “We didn’t have to completely change how developers built applications, so while we were doing these very dramatic changes to our architecture to make it scalable, the feature teams were building incredible features on top of Cash App, on top of our platform. So it was like changing the engines of the airplane while it was still in the air flying.” In fact, during that year of work, marquee features like the Cash card were launched.</p>



<p>Looking ahead at Cash App’s continued growth, Tirsen recognizes that solving the problem of scalability will always be a work in progress for his team. They’re currently building a developer platform based on <a href="https://kubernetes.io/" target="_blank" rel="noreferrer noopener">Kubernetes</a>, <a href="https://prometheus.io/" target="_blank" rel="noreferrer noopener">Prometheus</a>, <a href="https://www.envoyproxy.io/" target="_blank" rel="noreferrer noopener">Envoy</a>, <a href="https://www.jaegertracing.io/" target="_blank" rel="noreferrer noopener">Jaeger</a>, and other CNCF technologies, which Tirsen envisions supporting potentially thousands of developers. “Vitess is going to become part of this essential underlying infrastructure to make sure that everything that we build becomes scalable by default,” he says. “You have to keep on working on it, but Vitess does provide you essentially with near unlimited scale.”</p>
		</div>
				</article>
</div></div>]]>
            </description>
            <link>https://www.cncf.io/case-studies/square/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25426553</guid>
            <pubDate>Tue, 15 Dec 2020 03:16:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Understand Big O]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25426444">thread link</a>) | @behan
<br/>
December 14, 2020 | https://www.chrisbehan.ca/posts/HowToUnderstandBigO | <a href="https://web.archive.org/web/*/https://www.chrisbehan.ca/posts/HowToUnderstandBigO">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p><time datetime="2020-12-13">December 13, 2020</time></p><p>The other I was asked for "The simplest, quickest, easiest to understand explanation of Big O notation as it relates to programming". This blog post is my answer.</p><p>Big O notation (example: <span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>n</mi><mo>)</mo><mo>)</mo></mrow><annotation encoding="application/x-tex">O(n))</annotation></semantics></math></span></span></span> is a notation used to describe the time it takes code (example: a function) to execute on a given input (example: an array of integers). A fancy term often used to describe the time it takes code to execute is "time complexity". If you come across the term "time complexity", think "The speed of the code".</p><p>Big O notation is in the form <span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>f</mi><mo>(</mo><mi>n</mi><mo>)</mo><mo>)</mo></mrow><annotation encoding="application/x-tex">O(f(n))</annotation></semantics></math></span></span></span>, where <span><span><span><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">f(n)</annotation></semantics></math></span></span></span> is a <em>function</em> of <span><span><span><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span>, meaning for every possible value of <span><span><span><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span>, <span><span><span><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">f(n)</annotation></semantics></math></span></span></span> outputs exactly one answer, and that answer does not change.</p><pre><code><span>function</span><span> </span><span>addOne</span><span>(</span><span>n</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>return</span><span> n </span><span>+</span><span> </span><span>1</span><span>
</span><span></span><span>}</span></code></pre><p>To illustrate what I mean by <em>"does not change"</em>, consider the above function, it does not matter when the function is called, <code>addOne(n)</code>will always return n + 1.</p><p>As it relates to programming, we use Big O notation to describe the speed of a piece of code (usually a function). The most common Big O notations, in ascending order of speed, are <code>O(1), O(lg n), O(n), O(n lg n), and O(n^2)</code>.</p><p>I am going to describe each of the common notations with a coding example. The examples are ordered by ease of understanding, not speed.</p><p><span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><mn>1</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span></span></span></p><pre><code><span>function</span><span> </span><span>constant</span><span>(</span><span>n</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>return</span><span> </span><span>1</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>let</span><span> a </span><span>=</span><span> </span><span>constant</span><span>(</span><span>1234</span><span>)</span><span>
</span><span></span><span>console</span><span>.</span><span>log</span><span>(</span><span>a</span><span>)</span><span>
</span><span></span><span>&gt;&gt;&gt;</span><span> </span><span>1</span></code></pre><p>The above function has a time complexity (speed) of <span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><mn>1</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">O(1)</annotation></semantics></math></span></span></span>, which is often referred to as "constant". It is referred to as "constant" because the time it takes to execute the function is the same ("constant") regardless of the size of the input. In the example function above, <code>constant(n)</code>will return 1, no matter what the value of n is.</p><p>Note: "c<em>onstant"</em> and 1 are often used interchangeably.</p><p><span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span></span></span></p><pre><code><span>function</span><span> </span><span>sumOfList</span><span>(</span><span>nums</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> sum </span><span>=</span><span> </span><span>0</span><span>;</span><span>
</span><span>    </span><span>let</span><span> n </span><span>=</span><span> nums</span><span>.</span><span>length</span><span>;</span><span>
</span><span>    </span><span>for</span><span> </span><span>(</span><span>let</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> n</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>        sum </span><span>+=</span><span> nums</span><span>[</span><span>i</span><span>]</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span>    </span><span>return</span><span> sum</span><span>;</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>let</span><span> sum </span><span>=</span><span> </span><span>sumOfList</span><span>(</span><span>[</span><span>1</span><span>,</span><span> </span><span>2</span><span>,</span><span> </span><span>3</span><span>]</span><span>)</span><span>
</span><span></span><span>console</span><span>.</span><span>log</span><span>(</span><span>sum</span><span>)</span><span>
</span><span></span><span>&gt;&gt;&gt;</span><span> </span><span>6</span></code></pre><p>The above function takes an array of integers as input and returns its sum. This function has a time complexity of <span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span></span></span>. This is because it loops through every element in <code>nums</code>, which has a length of n.</p><p>You may be asking yourself, "Well what about the time it takes to create the <code>sum</code> variable, or the time it takes to run <code>sum += nums[i]</code>, shouldn't those be reflected in the Big O notation?". The answer is that they are. To understand how/why they are included in the notation, we need to introduce another concept called "Dropping non-dominant terms".</p><p>Consider the function <span><span><span><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>n</mi><mo>)</mo><mo>=</mo><msup><mi>n</mi><mn>2</mn></msup><mo>+</mo><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">f(n) = n^2 + n + 1</annotation></semantics></math></span></span></span>, this function has a Big O notation of <span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">O(n^2)</annotation></semantics></math></span></span></span>. We do not include the n or 1 in the Big O notation because they are insignificant when compared to the dominant term (<span><span><span><math><semantics><mrow><msup><mi>n</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">n^2</annotation></semantics></math></span></span></span>) .</p><p>Example:</p><p><span><span><span><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>n</mi><mo>)</mo><mo>=</mo><msup><mi>n</mi><mn>2</mn></msup><mo>+</mo><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">f(n) = n^2 + n + 1</annotation></semantics></math></span></span></span></p><p><span><span><span><math><semantics><mrow><mi>f</mi><mo>(</mo><mn>1</mn><mn>0</mn><mn>0</mn><mo>)</mo><mo>=</mo><mn>1</mn><mn>0</mn><msup><mn>0</mn><mn>2</mn></msup><mo>+</mo><mn>1</mn><mn>0</mn><mn>0</mn><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">f(100) = 100^2 + 100 +1 </annotation></semantics></math></span></span></span></p><p><span><span><span><math><semantics><mrow><mi>f</mi><mo>(</mo><mn>1</mn><mn>0</mn><mn>0</mn><mo>)</mo><mo>=</mo><mn>1</mn><mn>0</mn><mn>0</mn><mn>0</mn><mn>0</mn><mo>+</mo><mn>1</mn><mn>0</mn><mn>0</mn><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">f(100) = 10000 + 100 + 1 </annotation></semantics></math></span></span></span></p><p>Notice how the non-dominant terms, <span><span><span><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span> and 1, are insignificant compared to the dominant term <span><span><span><math><semantics><mrow><msup><mi>n</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">n^2</annotation></semantics></math></span></span></span>, and as <span><span><span><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span> gets larger, they only become more insignificant. In Big O notation, we ignore non-dominant terms completely and just say that <span><span><span><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>n</mi><mo>)</mo><mo>=</mo><mi>O</mi><mo>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">f(n) = O(n^2)</annotation></semantics></math></span></span></span></p><p>Now back to our original example, lets break down the time it takes to perform each line, assigning a value of 1 to lines that take "constant" time:</p><pre><code><span>function</span><span> </span><span>sumOfList</span><span>(</span><span>nums</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> sum </span><span>=</span><span> </span><span>0</span><span>;</span><span> </span><span>// 1</span><span>
</span><span>    </span><span>let</span><span> n </span><span>=</span><span> nums</span><span>.</span><span>length</span><span>;</span><span> </span><span>// 1</span><span>
</span><span>    </span><span>for</span><span> </span><span>(</span><span>let</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> n</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span> </span><span>// everything in this for loop is run n times</span><span>
</span><span>        sum </span><span>+=</span><span> nums</span><span>[</span><span>i</span><span>]</span><span>;</span><span> </span><span>// 1</span><span>
</span><span>    </span><span>}</span><span>
</span><span>    </span><span>return</span><span> sum</span><span>;</span><span> </span><span>// 1</span><span>
</span><span></span><span>}</span></code></pre><p>If we add up the time it takes each line to execute, and account for the for loop, we get:</p><p><span><span><span><math><semantics><mrow><mn>1</mn><mo>+</mo><mn>1</mn><mo>+</mo><mo>(</mo><mi>n</mi><mo>∗</mo><mn>1</mn><mo>)</mo><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">1 + 1 + (n * 1) + 1</annotation></semantics></math></span></span></span></p><p><span><span><span><math><semantics><mrow><mo>=</mo><mn>1</mn><mo>+</mo><mn>1</mn><mo>+</mo><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">= 1 + 1 + n + 1</annotation></semantics></math></span></span></span></p><p><span><span><span><math><semantics><mrow><mo>=</mo><mn>3</mn><mo>+</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">= 3 + n</annotation></semantics></math></span></span></span></p><p>We then drop the non-dominant terms and get a Big O notation of <span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span></span></span>.</p><p><span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">O(n^2)</annotation></semantics></math></span></span></span></p><pre><code><span>function</span><span> </span><span>generateAllPairs</span><span>(</span><span>numbers</span><span>)</span><span> </span><span>{</span><span>
</span><span>  </span><span>const</span><span> pairs </span><span>=</span><span> </span><span>[</span><span>]</span><span>;</span><span>
</span><span>  </span><span>const</span><span> n </span><span>=</span><span> numbers</span><span>.</span><span>length</span><span>;</span><span>
</span><span>  </span><span>for</span><span> </span><span>(</span><span>let</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> n</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>for</span><span> </span><span>(</span><span>let</span><span> j </span><span>=</span><span> </span><span>0</span><span>;</span><span> j </span><span>&lt;</span><span> n</span><span>;</span><span> j</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>      pairs</span><span>.</span><span>push</span><span>(</span><span>[</span><span>numbers</span><span>[</span><span>i</span><span>]</span><span>,</span><span> numbers</span><span>[</span><span>j</span><span>]</span><span>]</span><span>)</span><span>;</span><span>
</span><span>    </span><span>}</span><span>
</span><span>  </span><span>}</span><span>
</span><span>  </span><span>return</span><span> pairs</span><span>;</span><span>
</span><span></span><span>}</span></code></pre><p>The above function generates all possible pairs that can be created from a list of numbers. For example, <code>generateAllPairs([1,2,3]) = [[1,1], [1,2], [1,3], [2,1], [2,2], [2,3], [3,1], [3,2],[3,3]]</code>. This function has a time complexity of <span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">O(n^2)</annotation></semantics></math></span></span></span>. This is because, for every element in <code>numbers</code> (which has a length of <span><span><span><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span>), we do some processing on <span><span><span><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span> other elements.</p><p>Let's break down the function line by line:</p><pre><code><span>function</span><span> </span><span>generateAllPairs</span><span>(</span><span>numbers</span><span>)</span><span> </span><span>{</span><span>
</span><span>  </span><span>const</span><span> pairs </span><span>=</span><span> </span><span>[</span><span>]</span><span>;</span><span> </span><span>// 1</span><span>
</span><span>  </span><span>const</span><span> n </span><span>=</span><span> numbers</span><span>.</span><span>length</span><span>;</span><span> </span><span>// 1</span><span>
</span><span>  </span><span>for</span><span> </span><span>(</span><span>let</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> n</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span> </span><span>// everything in this for loop runs n times</span><span>
</span><span>    </span><span>for</span><span> </span><span>(</span><span>let</span><span> j </span><span>=</span><span> </span><span>0</span><span>;</span><span> j </span><span>&lt;</span><span> n</span><span>;</span><span> j</span><span>++</span><span>)</span><span> </span><span>{</span><span> </span><span>// everything in this for loop runs n times</span><span>
</span><span>      pairs</span><span>.</span><span>push</span><span>(</span><span>[</span><span>numbers</span><span>[</span><span>i</span><span>]</span><span>,</span><span> numbers</span><span>[</span><span>j</span><span>]</span><span>]</span><span>)</span><span>;</span><span> </span><span>// 1</span><span>
</span><span>    </span><span>}</span><span>
</span><span>  </span><span>}</span><span>
</span><span>  </span><span>return</span><span> pairs</span><span>;</span><span> </span><span>// 1</span><span>
</span><span></span><span>}</span></code></pre><p>The important part of the above code is the <em>nested</em> for loop (where nested means inside another for loop). The nested for loop</p><pre><code><span>for</span><span> </span><span>(</span><span>let</span><span> j </span><span>=</span><span> </span><span>0</span><span>;</span><span> j </span><span>&lt;</span><span> n</span><span>;</span><span> j</span><span>++</span><span>)</span><span> </span><span>{</span></code></pre><p>executes</p><pre><code><span>pairs</span><span>.</span><span>push</span><span>(</span><span>[</span><span>numbers</span><span>[</span><span>i</span><span>]</span><span>,</span><span> numbers</span><span>[</span><span>j</span><span>]</span><span>]</span><span>)</span><span>;</span><span> </span><span>// takes constant time</span></code></pre><p><span><span><span><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span> times, giving it a time complexity of <span><span><span><math><semantics><mrow><mi>n</mi><mo>∗</mo><mn>1</mn><mo>=</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">n * 1 = n</annotation></semantics></math></span></span></span>.</p><p>However, this for loop is within another for-loop</p><pre><code><span>for</span><span> </span><span>(</span><span>let</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> n</span><span>;</span><span> i</span><span>++</span><span>)</span></code></pre><p>which  executes all code inside itself <span><span><span><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span> times.</p><p>Adding up the cost of every line and dropping the non-dominant terms, we get:</p><p><span><span><span><math><semantics><mrow><mn>1</mn><mo>+</mo><mn>1</mn><mo>+</mo><mo>(</mo><mi>n</mi><mo>∗</mo><mo>(</mo><mi>n</mi><mo>∗</mo><mn>1</mn><mo>)</mo><mo>)</mo><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">1 + 1 + (n *(n*1))+1</annotation></semantics></math></span></span></span></p><p><span><span><span><math><semantics><mrow><mo>=</mo><mn>3</mn><mo>+</mo><mo>(</mo><mi>n</mi><mo>∗</mo><mo>(</mo><mi>n</mi><mo>∗</mo><mn>1</mn><mo>)</mo><mo>)</mo></mrow><annotation encoding="application/x-tex">= 3 + (n*(n*1))</annotation></semantics></math></span></span></span></p><p><span><span><span><math><semantics><mrow><mo>=</mo><mn>3</mn><mo>+</mo><mo>(</mo><mi>n</mi><mo>∗</mo><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">= 3 + (n*n)</annotation></semantics></math></span></span></span></p><p><span><span><span><math><semantics><mrow><mo>=</mo><mn>3</mn><mo>+</mo><msup><mi>n</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">= 3 + n^2</annotation></semantics></math></span></span></span></p><p><span><span><span><math><semantics><mrow><mo>=</mo><msup><mi>n</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">= n^2</annotation></semantics></math></span></span></span></p><p>Thus the time complexity of <code>generateAllPairs</code> is <span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">O(n^2)</annotation></semantics></math></span></span></span>.</p><p>As a rule of thumb, if you see a nested for loop,</p><pre><code><span>for</span><span> </span><span>(</span><span>let</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> n</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>for</span><span> </span><span>(</span><span>let</span><span> j </span><span>=</span><span> </span><span>0</span><span>;</span><span> j </span><span>&lt;</span><span> n</span><span>;</span><span> j</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>		</span><span>//do stuff</span><span>
</span><span>	</span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>where both loops have the same conditional statement (the conditional statement of a for loop is the statement that determines whether or not to perform an iteration, in the above loops, the conditional statements are <code>i &lt; n</code> and <code>j &lt; n</code> ) and the same increment (the increments in the above loops are <code>i++</code> and <code>j++</code> ), then think <span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">O(n^2)</annotation></semantics></math></span></span></span>.</p><p><span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>l</mi><mi>g</mi><mtext>&nbsp;</mtext><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(lg\ n)</annotation></semantics></math></span></span></span></p><pre><code><span>function</span><span> </span><span>base2Log</span><span>(</span><span>num</span><span>)</span><span> </span><span>{</span><span>
</span><span>  </span><span>let</span><span> count </span><span>=</span><span> </span><span>0</span><span>;</span><span>
</span><span>  </span><span>for</span><span> </span><span>(</span><span>;</span><span> num </span><span>&gt;</span><span> </span><span>1</span><span>;</span><span> num </span><span>/=</span><span> </span><span>2</span><span>)</span><span> </span><span>{</span><span>
</span><span>    count</span><span>++</span><span>;</span><span>
</span><span>  </span><span>}</span><span>
</span><span>  </span><span>if</span><span> </span><span>(</span><span>num </span><span>==</span><span> </span><span>1</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>return</span><span> count</span><span>;</span><span>
</span><span>  </span><span>}</span><span>
</span><span>  </span><span>throw</span><span> </span><span>new</span><span> </span><span>Error</span><span>(</span><span>`</span><span>You must input a multiple of 2!</span><span>`</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span></code></pre><p>The above function returns the base 2 logarithm for multiples of 2. In other words, It is a function that returns the answer to <span><span><span><math><semantics><mrow><msub><mi>log</mi><mo>⁡</mo><mn>2</mn></msub><mrow><mi>n</mi><mi>u</mi><mi>m</mi></mrow></mrow><annotation encoding="application/x-tex">\log_2{num}</annotation></semantics></math></span></span></span>, where <span><span><span><math><semantics><mrow><mi>n</mi><mi>u</mi><mi>m</mi></mrow><annotation encoding="application/x-tex">num</annotation></semantics></math></span></span></span> is a multiple of 2. It has a time complexity of <span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>l</mi><mi>g</mi><mtext>&nbsp;</mtext><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(lg\ n)</annotation></semantics></math></span></span></span>. Unlike previous examples which took an array of numbers as input, <code>num</code> in this function is a number, which we will treat as our <span><span><span><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span>.</p><p>"Well how do you know what the <span><span><span><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span> is, if sometimes it can be an array of numbers, and other times a number itself?" Good question, the <span><span><span><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span> of a piece of code as it relates to Big O notation is the input (usually a parameter) to a function that effects how many iterations the code performs. The type of the input does not matter, but rather the size of the input, and how that size effects the number of iterations performed.</p><p>Example 1:</p><pre><code><span>function</span><span> </span><span>exampleOne</span><span>(</span><span>amount</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>for</span><span> </span><span>(</span><span>let</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> amount</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>		</span><span>// do something</span><span>
</span><span>	</span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Here <span><span><span><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span> would be the <code>amount</code> parameter (a number), since the value of <code>amount</code> effects how many iterations are performed by the for loop.</p><p>Example 2:</p><pre><code><span>function</span><span> </span><span>exampleTwo</span><span>(</span><span>amount</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>if</span><span> </span><span>(</span><span>amount </span><span>==</span><span> </span><span>1</span><span>)</span><span> </span><span>{</span><span>
</span><span>		</span><span>return</span><span> </span><span>1</span><span>;</span><span>
</span><span>	</span><span>}</span><span>
</span><span>	</span><span>return</span><span> </span><span>1</span><span> </span><span>+</span><span> </span><span>exampleTwo</span><span>(</span><span>amount </span><span>-</span><span> </span><span>1</span><span>)</span><span>
</span><span></span><span>}</span></code></pre><p>The <span><span><span><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span> in this example is also <code>amount</code>, however instead of using a loop like other examples, we use recursion. The time complexity of this example is <span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span></span></span> since we make <span><span><span><math><semantics><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n-1</annotation></semantics></math></span></span></span> recursive calls, and each recursive call can be thought of as an iteration.</p><p>Example 3:</p><pre><code><span>function</span><span> </span><span>exampleThree</span><span>(</span><span>amount</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>const</span><span> n </span><span>=</span><span> amount</span><span>.</span><span>length</span><span>;</span><span>
</span><span>	</span><span>for</span><span> </span><span>(</span><span>let</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> n</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>		</span><span>// do something</span><span>
</span><span>	</span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Here <code>amount</code> is an array of numbers. The <span><span><span><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span> in this example is the <em>length</em> of <code>amount</code>, since the length determines how many iterations are performed by the for loop.</p><p>Now back to our <span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>l</mi><mi>g</mi><mtext>&nbsp;</mtext><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(lg\ n)</annotation></semantics></math></span></span></span> example, lets break it down line by line:</p><pre><code><span>function</span><span> </span><span>base2Log</span><span>(</span><span>num</span><span>)</span><span> </span><span>{</span><span>
</span><span>  </span><span>let</span><span> count </span><span>=</span><span> </span><span>0</span><span>;</span><span> </span><span>// 1</span><span>
</span><span>  </span><span>for</span><span> </span><span>(</span><span>;</span><span> num </span><span>&gt;</span><span> </span><span>1</span><span>;</span><span> num </span><span>/=</span><span> </span><span>2</span><span>)</span><span> </span><span>{</span><span> </span><span>// everything in this for loop runs lg num times</span><span>
</span><span>    count</span><span>++</span><span>;</span><span> </span><span>// 1</span><span>
</span><span>  </span><span>}</span><span>
</span><span>  </span><span>if</span><span> </span><span>(</span><span>num </span><span>==</span><span> </span><span>1</span><span>)</span><span> </span><span>{</span><span> </span><span>// 1</span><span>
</span><span>    </span><span>return</span><span> log</span><span>;</span><span> </span><span>// 1</span><span>
</span><span>  </span><span>}</span><span>
</span><span>  </span><span>throw</span><span> </span><span>new</span><span> </span><span>Error</span><span>(</span><span>`</span><span>You must input a multiple of 2!</span><span>`</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span></code></pre><p>The for loop in the above code divides <code>num</code> by 2 each iteration, until <code>num</code> ≤ 1. For values of <code>num</code> that are multiples of 2, this loop will perform exactly <span><span><span><math><semantics><mrow><mi>l</mi><mi>g</mi><mtext>&nbsp;</mtext><mi>n</mi></mrow><annotation encoding="application/x-tex">lg\ n</annotation></semantics></math></span></span></span> iterations, where n = <code>num</code>.</p><p>Note: the shorthand for <span><span><span><math><semantics><mrow><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">log_2</annotation></semantics></math></span></span></span> is <span><span><span><math><semantics><mrow><mi>l</mi><mi>g</mi></mrow><annotation encoding="application/x-tex">lg</annotation></semantics></math></span></span></span>.</p><p>Adding the cost of each line and dropping non-dominant terms we get:</p><p><span><span><span><math><semantics><mrow><mn>1</mn><mo>+</mo><mo>(</mo><mi>l</mi><mi>g</mi><mtext>&nbsp;</mtext><mi>n</mi><mo>∗</mo><mn>1</mn><mo>)</mo><mo>+</mo><mn>1</mn><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">1 + (lg\ n*  1) + 1 + 1</annotation></semantics></math></span></span></span></p><p><span><span><span><math><semantics><mrow><mo>=</mo><mn>3</mn><mo>+</mo><mi>l</mi><mi>g</mi><mtext>&nbsp;</mtext><mi>n</mi></mrow><annotation encoding="application/x-tex">= 3 + lg\ n</annotation></semantics></math></span></span></span></p><p><span><span><span><math><semantics><mrow><mo>=</mo><mi>l</mi><mi>g</mi><mtext>&nbsp;</mtext><mi>n</mi></mrow><annotation encoding="application/x-tex">= lg\ n</annotation></semantics></math></span></span></span></p><p>Thus the time complexity of <code>base2Log</code> is <span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>l</mi><mi>g</mi><mtext>&nbsp;</mtext><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(lg\ n)</annotation></semantics></math></span></span></span>.</p><p>To understand why this loop performs exactly <code>lg n</code> iterations when <code>num</code> is a multiple of 2, you have to understand what a logarithm tells us. <span><span><span><math><semantics><mrow><msub><mi>log</mi><mo>⁡</mo><mn>2</mn></msub><mrow><mi>n</mi><mi>u</mi><mi>m</mi></mrow></mrow><annotation encoding="application/x-tex">\log_2{num}</annotation></semantics></math></span></span></span> is the equivalent of saying "2 to the power of what equals <span><span><span><math><semantics><mrow><mi>n</mi><mi>u</mi><mi>m</mi></mrow><annotation encoding="application/x-tex">num</annotation></semantics></math></span></span></span>." So for example: <span><span><span><math><semantics><mrow><msub><mi>log</mi><mo>⁡</mo><mn>2</mn></msub><mrow><mn>8</mn></mrow></mrow><annotation encoding="application/x-tex">\log_2{8}</annotation></semantics></math></span></span></span> is the equivalent of asking "2 to the power of what equals 8?". The answer is 3, since <span><span><span><math><semantics><mrow><mn>2</mn><mo>∗</mo><mn>2</mn><mo>∗</mo><mn>2</mn><mo>=</mo><msup><mn>2</mn><mn>3</mn></msup><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">2 * 2 * 2 = 2^3 = 8</annotation></semantics></math></span></span></span>. This can be rewritten as <span><span><span><math><semantics><mrow><mn>1</mn><mo>∗</mo><mn>2</mn><mo>∗</mo><mn>2</mn><mo>∗</mo><mn>2</mn><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">1 * 2 * 2 * 2 = 8</annotation></semantics></math></span></span></span>. What the above function does is count the number of times <code>num</code> needs to be divided by 2 until it equals 1, which is the equivalent of answering <span><span><span><math><semantics><mrow><msub><mi>log</mi><mo>⁡</mo><mn>2</mn></msub><mrow><mi>n</mi><mi>u</mi><mi>m</mi></mrow></mrow><annotation encoding="application/x-tex">\log_2{num}</annotation></semantics></math></span></span></span>.</p><p>Example:</p><p><span><span><span><math><semantics><mrow><mtext>before&nbsp;1st&nbsp;iteration,&nbsp;</mtext><mi>n</mi><mi>u</mi><mi>m</mi><mo>=</mo><mn>8</mn><mo separator="true">,</mo><mtext>&nbsp;</mtext><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\textnormal{before 1st iteration, } num = 8,\ count = 0</annotation></semantics></math></span></span></span>
<span><span><span><math><semantics><mrow><mtext>after&nbsp;1st&nbsp;iteration,&nbsp;</mtext><mi>n</mi><mi>u</mi><mi>m</mi><mo>=</mo><mn>8</mn><mi mathvariant="normal">/</mi><mn>2</mn><mo>=</mo><mn>4</mn><mo separator="true">,</mo><mtext>&nbsp;</mtext><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\textnormal{after 1st iteration, } num = 8/2 = 4,\ count = 1</annotation></semantics></math></span></span></span>
<span><span><span><math><semantics><mrow><mtext>after&nbsp;2nd&nbsp;iteration,&nbsp;</mtext><mi>n</mi><mi>u</mi><mi>m</mi><mo>=</mo><mn>4</mn><mi mathvariant="normal">/</mi><mn>2</mn><mo>=</mo><mn>2</mn><mo separator="true">,</mo><mtext>&nbsp;</mtext><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">\textnormal{after 2nd iteration, }num = 4/2=2,\ count = 2</annotation></semantics></math></span></span></span>
<span><span><span><math><semantics><mrow><mtext>after&nbsp;3rd&nbsp;iteration,&nbsp;</mtext><mi>n</mi><mi>u</mi><mi>m</mi><mo>=</mo><mn>2</mn><mi mathvariant="normal">/</mi><mn>2</mn><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mtext>&nbsp;</mtext><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">\textnormal{after 3rd iteration, }num = 2/2=1,\ count = 3</annotation></semantics></math></span></span></span></p><p><span><span><span><math><semantics><mrow><mtext>return</mtext><mtext>&nbsp;</mtext><mi>c</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">\textnormal{return}\ count = 3</annotation></semantics></math></span></span></span></p><p>As a rule of thumb, if you see a for loop whose loop counter is divided by a number each iteration,</p><pre><code><span>for</span><span>(</span><span>let</span><span> i </span><span>=</span><span> </span><span>100</span><span>;</span><span> i </span><span>&gt;</span><span> </span><span>1</span><span>;</span><span> i </span><span>=</span><span> i </span><span>/</span><span> </span><span>2</span><span>)</span><span> </span><span>{</span><span>
</span><span>  </span><span>// do stuff</span><span>
</span><span></span><span>}</span></code></pre><p>think <span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>l</mi><mi>g</mi><mtext>&nbsp;</mtext><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(lg\ n)</annotation></semantics></math></span></span></span>.</p><p><span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>n</mi><mtext>&nbsp;</mtext><mi>l</mi><mi>g</mi><mtext>&nbsp;</mtext><mi>m</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(n\ lg\ m)</annotation></semantics></math></span></span></span></p><pre><code><span>function</span><span> </span><span>base2LogList</span><span>(</span><span>nums</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>const</span><span> base2Logs </span><span>=</span><span> </span><span>[</span><span>]</span><span>
</span><span>	</span><span>for</span><span> </span><span>(</span><span>let</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> nums</span><span>.</span><span>length</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>		</span><span>const</span><span> log </span><span>=</span><span> </span><span>base2Log</span><span>(</span><span>nums</span><span>[</span><span>i</span><span>]</span><span>)</span><span>;</span><span>
</span><span>		base2Logs</span><span>.</span><span>push</span><span>(</span><span>log</span><span>)</span><span>;</span><span> 
</span><span>	</span><span>}</span><span>
</span><span>	</span><span>return</span><span> base2Logs</span><span>;</span><span>
</span><span></span><span>}</span><span>
</span>
<span></span><span>function</span><span> </span><span>base2Log</span><span>(</span><span>num</span><span>)</span><span> </span><span>{</span><span>
</span><span>  </span><span>let</span><span> count </span><span>=</span><span> </span><span>0</span><span>;</span><span>
</span><span>  </span><span>for</span><span> </span><span>(</span><span>;</span><span> num </span><span>&gt;</span><span> </span><span>1</span><span>;</span><span> num </span><span>/=</span><span> </span><span>2</span><span>)</span><span> </span><span>{</span><span>
</span><span>    count</span><span>++</span><span>;</span><span>
</span><span>  </span><span>}</span><span>
</span><span>  </span><span>if</span><span> </span><span>(</span><span>num </span><span>==</span><span> </span><span>1</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>return</span><span> log</span><span>;</span><span>
</span><span>  </span><span>}</span><span>
</span><span>  </span><span>throw</span><span> </span><span>new</span><span> </span><span>Error</span><span>(</span><span>`</span><span>You must input a multiple of 2!</span><span>`</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span></code></pre><p>The <code>base2LogList</code> function returns the base 2 logarithms for a list of numbers. For example <code>base2LogList([2,4,8,16])</code> would return <code>[1, 2, 3, 4]</code>. The time complexity of this function is <span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>n</mi><mtext>&nbsp;</mtext><mi>l</mi><mi>g</mi><mtext>&nbsp;</mtext><mi>m</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(n\ lg\ m)</annotation></semantics></math></span></span></span>, where <span><span><span><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span> is the <em>length</em> of <code>nums</code> and where <span><span><span><math><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span></span> is the largest number in <code>nums</code>.</p><p>This example introduces two new concepts:</p><ol><li>Calling a function within another function</li><li>Different variables within the Big O</li></ol><p><strong>Calling a function within another function</strong></p><p>Suppose we have a function called <code>innerFunction</code> with a time complexity of <span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span></span></span>.</p><pre><code><span>function</span><span> </span><span>innerFunction</span><span>(</span><span>n</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>for</span><span> </span><span>(</span><span>let</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> n</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>		</span><span>// do stuff</span><span>
</span><span>	</span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Now suppose we have another function, <code>outerFunction</code>, which calls <code>innerFunction</code>, <span><span><span><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span> times.</p><pre><code><span>function</span><span> </span><span>outerFunction</span><span>(</span><span>n</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>for</span><span> </span><span>(</span><span>let</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> n</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span> </span><span>// everything in the for loop runs n times</span><span>
</span><span>		</span><span>innerFunction</span><span>(</span><span>n</span><span>)</span><span> </span><span>// n</span><span>
</span><span>	</span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>When evaluating the time complexity of <code>outerFunction</code>, we treat the cost of the line that calls <code>innerFunction</code> as <span><span><span><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span>, since <code>innerFunction</code> has a time complexity of <span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math></span></span></span>.</p><p>Since <code>outerFunction</code> calls <code>innerFunction</code> <span><span><span><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span> times, and the cost of calling <code>innerFunction</code> is <span><span><span><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span></span></span>, <code>outerFunction</code> has a time complexity of <span><span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">O(n^2)</annotation></semantics></math></span></span></span>.</p><p><strong>Different variables within the Big O</strong></p><p>If there are multiple …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.chrisbehan.ca/posts/HowToUnderstandBigO">https://www.chrisbehan.ca/posts/HowToUnderstandBigO</a></em></p>]]>
            </description>
            <link>https://www.chrisbehan.ca/posts/HowToUnderstandBigO</link>
            <guid isPermaLink="false">hacker-news-small-sites-25426444</guid>
            <pubDate>Tue, 15 Dec 2020 02:53:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shitlist Driven Development (2016)]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25426232">thread link</a>) | @todsacerdoti
<br/>
December 14, 2020 | https://sirupsen.com/shitlists/ | <a href="https://web.archive.org/web/*/https://sirupsen.com/shitlists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article-content">
    

    <p>Recently the team I work with completed a project to <a href="https://www.youtube.com/watch?v=7UyDK2bDjc4">allow Shopify to run in
multiple datacenters</a>. This project
was a refactoring project in disguise. When you undertake large refactoring of a
code-base with 100s of developers and 100,000s of lines of code, you can’t align
by sending an email. The merge-conflicts a single pull request would entail
makes me shiver. When deprecating in a large code-base the only way to reliably
avoid new deprecated behaviour is a failing test that tells you what to do.
Otherwise the pace that new deprecated code is introduced can easily outpace the
speed at which you can remove them, or be a massive source of frustration.</p>
<p>Typically deprecations come in the form of soft warnings: Logging to <code>stderr</code>,
capital letters and exclamation marks in the documentation, or a legacy prefix
to the method or class name. At the end of the day, everyone needs to get work
done, and if they see a code-path already being used from 10 places in the
code-base despite these soft warnings–it doesn’t seem crazy to introduce
another. However, if another project is blocked on these deprecated code-paths,
piling on may have a large cost.</p>
<p>To solve this problem <a href="https://twitter.com/fw1729">Florian Weingarten</a> on our
team introduced what he calls “shitlists”: a whitelist of deprecated behaviour.
Existing deprecated behaviour is OK and whitelisted. New usage of the deprecated
API is banned and fails a test with a well-defined error.</p>
<p>They come in many forms, but could look like this:</p>
<div><pre><code data-lang="ruby"><span>Shitlist</span> <span>=</span> <span>[</span>
  <span>ClassA</span>,
  <span>ClassB</span>,
  <span>ClassC</span>
<span>]</span>

<span>def</span> <span>push_job_that_does_crazy_things</span>(klass)
  <span>if</span> <span>Shitlist</span><span>.</span>include?(klass)
    <span># Existing deprecated behaviour is called.</span>
  <span>else</span>
    <span>raise</span> <span>Shitlist</span><span>::</span><span>Error</span>, <span>&lt;&lt;-EOS
</span><span></span><span>You</span><span>'</span>re pushing a job that does crazy things<span>.</span> <span>This</span> <span>API</span> has been 
deprecated <span>in</span> this code<span>-</span>base<span>.</span> <span>&lt;</span>team<span>&gt;</span> is actively trying to get
rid of this code<span>-</span>path, because
<span>&lt;</span>reason<span>&gt;.</span> <span>We</span> suggest you instead <span>do</span> <span>&lt;</span>alternative<span>&gt;.</span> <span>If</span> you have questions, please
ping <span>&lt;</span>team<span>&gt;.</span>
  <span>EOS</span>
<span>end</span>
</code></pre></div><p>A shitlist could be something as simple as a <code>git grep</code> for a certain code-path:</p>
<div><pre><code data-lang="ruby"><span>test</span> <span>"no new introductions of legacy code path"</span> <span>do</span>
  actual <span>=</span> <span>`git grep some_legacy_method_with_a_unique_name`</span>
  assert_equal <span>321</span>, actual
<span>end</span>
</code></pre></div><p>Other times you can reach into another API and get a count or shitlist:</p>
<div><pre><code data-lang="ruby"><span>RedisShitlist</span> <span>=</span> <span>[</span>
  <span>Session</span>,
  <span>FragmentCache</span>,
  <span>AuthenticationTokens</span>,
<span>]</span>

<span>test</span> <span>"no new redis models introduced"</span> <span>do</span>
  assert_equal <span>RedisShitlist</span>, <span>RedisModel</span><span>.</span>descendants
<span>end</span>
</code></pre></div><p>Other ways we’ve used shitlists in the past:</p>
<ul>
<li>Make sure that a certain datastore is only read from in a certain context (or
not used at all). This would allow for using a read-only slave, or improving
resiliency in a certain area.</li>
<li>Ensure fallbacks for all uses of a secondary data-store. E.g. if you access
sessions in Redis and Redis is down, you should be able to still render the
page (i.e. have an empty session fallback).</li>
<li>Shitlisting joins between tables that have no business being joined. This is
helpful to keep data-models and scope clean, or separating a part of an
application.</li>
</ul>
<p>If you have a linter for a project, you may be able to encode rules. For example
you might use <a href="http://www.foodcritic.io/">Foodcritic</a> for Chef, or
<a href="https://github.com/bbatsov/rubocop">Rubocop</a> for Ruby.</p>
<p>Sometimes the shitlist is quite complicated, and much more domain-specific.</p>
<p>Building the shitlist gives the team responsible for it a number of advantages:</p>
<ol>
<li><strong>Strong feedback loop.</strong> The goal is to reduce the <code>Shitlist</code> to an empty
Array and always raise or remove the code entirely. Remove a class from the
list, fix the code and the tests, celebrate and move on.</li>
<li><strong>Stopped the bleeding.</strong> New deprecated behaviour is not introduced unless
the team is contacted or some other action defined in the error is taken.</li>
<li><strong>Success metric</strong>. If you have shitlists for everything that needs to be
done for your project, you have metrics that you can track. Every week you
can look at how these lists are shrinking. Refactoring for months at a time
can be exhausting, but if you see that you’re making progress with metrics
moving, it’s much more rewarding.</li>
<li><strong>Enforces a guarantee</strong>. For example, you can have a shitlist that all jobs
have a retry mechanism. In that case, you know that you can kill any worker
gracefully at any time since the job will retry. Because of 1-3 you know how
much work it will take to have this guarantee.</li>
</ol>
<p>It is important that the shitlist errors are actionable. If you hit the shitlist
of another team, you need to know what to do next. Ideally the error explains
exactly what you need to do, and no humans need to talk, but reaching out to the
owner of the shitlist should always be part of the shitlist.</p>
<p>If you own a shitlist, you must empathize with the problems of everyone who’s
running into problems. If you simply deprecate new behaviour and don’t offer an
alternative, you will be the source of frustration. If the value of emptying the
shitlist far outweighs the value of adding to the shitlist, it may be OK to not
offer a direct other solution but ask the person who ran into the error to
revise their solution.</p>
<p>It is important that people run into shitlists as early in development as
possible. If you run into a shitlist after spending hours implementing your
solution, you will be less than popular. Some shitlists may require an entire
re-architecting of some teams’ solutions.</p>
<p>Months, in our case more than a year, of refactoring can be overwhelming and
unrewarding work. With the strong feedback loop that shitlists introduce you can
see the light at the end of the tunnel. You know that nothing is added to the
shitlist without you knowing about it.</p>
<p>Creating shitlists in some cases can be extremely difficult. Some take hours to
create, others weeks, and in our case one took months to come up with. You’ll
have to place the cost of developing the shitlist against the cost of not having
it. In some cases logging when you hit a bad code-path may be enough (simple
soft warning deprecation) if you assert the risk of new behaviour small and the
complexity of introducing the shitlist big.</p>
<p>Delegating with shitlists is great. Due to the tight feedback loop, asking other
teams or onboarding new team members becomes much easier. Remove something on
the shitlist, fix the code and the tests, then move on. Sometimes during large
refactorings you may need other teams with more domain expertise of a certain
area of the code-base to help. The shitlist becomes a great rock to point people
at.</p>
<p>If you are about to embark on a large refactor, I highly recommend adding
shitlists to your toolbox. Your project will look much less daunting when it
goes from an opaque objective to a list of shitlists.</p>


    

    
  </div></div>]]>
            </description>
            <link>https://sirupsen.com/shitlists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25426232</guid>
            <pubDate>Tue, 15 Dec 2020 02:14:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Challenging the ‘Great Reset’ theory of pandemics]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25426174">thread link</a>) | @fremden
<br/>
December 14, 2020 | https://engelsbergideas.com/essays/challenging-the-great-reset-theory-of-pandemics/ | <a href="https://web.archive.org/web/*/https://engelsbergideas.com/essays/challenging-the-great-reset-theory-of-pandemics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="9549bc7" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:500}" data-widget_type="theme-post-content.default">
				<div>
			
<p>Few events are as compelling as an epidemic. When sufficiently severe, an epidemic evokes responses from every sector of society, laying bare&nbsp;social and economic fault lines and presenting politicians with fraught medical and moral choices. In the most extreme cases, an epidemic can foment a full-blown political crisis. Thus,&nbsp;Thucydides describes how the repeated visitations of plague to Athens in 430-426 BC&nbsp;provoked widespread social disorder and the breakdown of civic norms.</p>



<p>‘Men, not knowing what was to become of them, became utterly careless of everything, whether sacred or profane,’ writes Thucydides. ‘All the burial rites before in use were entirely upset and… many had recourse to the most shameless sepulchres.’</p>



<p>As the plague progresses, Thucydides describes how Athenians were swept up in a wave of hedonism and lawlessness, threatening the foundations of Athenian democracy: ‘Men now coolly ventured on what they had formerly done in a corner… fear of gods or law of man there was none to restrain them.’</p>



<p>The resulting crisis, Thucydides claimed, undermined Athenians’ faith in the rule of law and the democratic principles that underpinned the Greek city state, paving the way for the installation of a Spartan oligarchy known as the Thirty Tyrants. Even though the Spartans were later ejected, Athens never regained its confidence.</p>



<p>Covid-19 appears to have engendered a similar crisis in our world, the main difference being in scale. Whereas the crisis Thucydides describes was confined to Athens, the coronavirus pandemic has destabilized governments from Brazil to Belarus,&nbsp;not just that of a 5<sup>th</sup>&nbsp;century city-state. The political reckoning has been particularly rapid in the United States, where Donald Trump’s inability or unwillingness to check the spread of the coronavirus was a key factor in his recent election defeat. Now, the lockdowns and social distancing measures look set&nbsp;to&nbsp;plunge the world into the worst economic depression since the 1930s, raising the spectre of further political instability.</p>



<p>Given the wide-ranging&nbsp;social, economic and political impacts of Covid-19, it is natural to assume that the same must have been true of past epidemics and pandemics. But is this the case? Do pandemics really have the historical impacts that are often claimed for them or are these claims simply the product of particular narratives and readings of history? &nbsp;</p>



<p>For instance, in&nbsp;numerical terms, the most devastating pandemic of all time was the 1918-19 ‘Spanish influenza’. Coinciding with the end of the First World War, the Spanish flu is estimated to have killed between fifty to one hundred million people worldwide. However, while 1919 was the first year since records began that the death rate exceeded the birth rate, those that survived generally enjoyed longer and healthier lifespans and, in many instances, benefited from higher wages too. Moreover, while the global death toll was immense, in developed industrial countries the mortality rate averaged two percent, meaning the Spanish flu left most of society unaffected. Indeed, the Spanish flu appears to have made little impression on public memory and social institutions, hence its historiographical characterisation as the&nbsp;<a href="https://theconversation.com/why-historians-ignored-the-spanish-flu-101950" target="_blank" rel="noreferrer noopener">‘forgotten pandemic’.</a></p>



<h2 id="h-narrating-epidemic-crises">Narrating Epidemic Crises</h2>



<p>A crisis is normally conceived of as an isolated moment in time in which our lives are shattered and plunged into disorder – what the cultural anthropologist Hendrik Vigh has called&nbsp;‘a momentary malformation in the flow of things’.&nbsp;Vigh <a href="https://www.tandfonline.com/doi/abs/10.1080/00141840801927509" target="_blank" rel="noreferrer noopener">observes that</a> for many people crises are ‘endemic rather than episodic’ and cannot be delineated as an aberrant moment of chaos or a period of decisive change.&nbsp;This is particularly the case for those living at the margins of society for whom crises are ever present. Indeed, social critics such as Naomi Klein argue that instability is baked into the capitalist system, hence the way that&nbsp;in the last few decades<strong>&nbsp;</strong>neoliberal societies have lurched from one financial crisis to another.</p>



<p>Nevertheless, crises have long been regarded as a way of accessing deeper historical truths. As Janet Roitman <a href="https://read.dukeupress.edu/books/book/330/Anti-Crisis" target="_blank" rel="noreferrer noopener">has argued</a> in&nbsp;<em>Anti-Crisis</em>&nbsp;(2013), a crisis ‘marks and generates history’. This is particularly the case for epidemics and pandemics which, unlike other natural disasters such as famines, are not limited to a particular region or moment in time but may come to encompass the whole globe. As the medical anthropologist Christos Lynteris <a href="https://www.jstor.org/stable/i40144420" target="_blank" rel="noreferrer noopener">puts it</a>, disease outbreaks involve a ‘radically different ontological order’, a mode of being that is simultaneously ‘pathological and infectious’. Or to put it another way, one could conceivably outrun a famine but those who try to flee a plague may become unwitting carriers, contaminating new communities and introducing the pathogen to new places.</p>



<p>What is also not widely appreciated is that the roots of the term ‘crisis’ lie in the Ancient Greek word&nbsp;<em>krinô</em>&nbsp;(meaning to separate, choose, cut, decide, judge) and can be traced back to Hippocrates, whose scientific method influenced Thucydides’ approach to history. For the Hippocratic school of medicine, prognosis took precedence over diagnosis, the point being to identify the turning point of a disease in order to intervene and bring about a satisfactory resolution to the illness. Similarly, Thucydides hoped that by tracking the social and moral dissolution that envelopes Athens under the strain of the plague, his history could serve as a ‘great case-book of social pathology’, enabling readers to recognise similar historical patterns in future and intervene so as to restore order and stability. In this way, <a href="https://www.waterstones.com/book/the-invention-of-medicine/robin-lane-fox/9780241277058#:~:text=Robin%20Lane%20Fox's%20remarkable%20book,that%20survive%20under%20his%20name." target="_blank" rel="noreferrer noopener">it has been argued</a>, Thucydides applied a medical template to epidemic crises that has coloured our interpretation of them ever since.</p>



<h2 id="h-the-black-death-and-demographic-change">The Black Death and demographic change</h2>



<p>Perhaps the standout example of the transformative power of disease is the fourteenth century Black Death. Caused by the plague bacillus,&nbsp;<em>Yersinia pestis</em>, the pandemic coincided with the transition from medieval to early modern European society and was greatly enhanced by new shipping networks linking Venice and Genoa with Constantinople, Tunis, London and Bruges. The larger broad-bellied ships required for these long voyages provided perfect conveyances for plague-carrying rats and were soon sparking outbreaks across Europe.</p>



<p>Some scholars claim the pandemic killed a third of Europe’s then population between 1347 and 1353; others say up to one half. Whatever the true mortality there is little doubt the Black Death represented a massive external shock to medieval society and, together with the famines that preceded it, contributed to a declining or stagnant population in Europe for almost 150 years afterwards. The result was a demographic, economic and political crisis.</p>



<p>A smaller population meant less demand for grain putting downward pressure on the price of basic foodstuffs. At the same time, a diminished population fuelled competition, exerting upward pressure on wages and challenging the villeinage system of forced labour that underpinned the feudal system. The result was a wave of popular uprisings across Europe, including the Jacquerie in France in 1358, the revolt of the Florentine&nbsp;<em>Ciompi</em>&nbsp;or wool carders in 1378-82, and the 1381 Peasants’ Revolt in England. &nbsp;</p>



<p>The demands of English peasants included the abolition of an inequitable poll tax and the removal of a statute, passed in the wake of the Black Death, that sought to restrict wages to pre-pandemic levels. The Florentine carders meanwhile demanded a more equitable fiscal policy and the right to establish guilds, fore runners of trade unions. Today, we take collective wage bargaining and trade unions for granted, but in the fourteenth century these demands threatened the basis of the feudal system, hence the observation of the French chronicler Jean Froissart that: ‘Never was any land or realm in such great danger as England at that time.’</p>



<p>This economic levelling also spurred a series of social and cultural changes, including the right of everyone except the lowliest manual worker to wear furs – a privilege that previously had been the preserve of nobles and clerics.&nbsp;In most cases the political reforms were short-lived. For instance,&nbsp;<a href="http://www.bl.uk/learning/timeline/item126561.html" target="_blank" rel="noreferrer noopener">Wat Tyler</a>, the leader of the English rebels, marched to London to petition King Richard II with 60,000 peasants at his back. Demanding that ‘all men should be free and of one condition’, the rebels occupied the Tower of London, ransacked the palaces and mansions of wealthy Londoners, and executed the Archbishop of Canterbury and the Lord Chief Justice, as well as other hated representatives of the nobility. Within a few weeks Wat Tyler and other leaders of the revolt had been arrested and executed and the crisis was over. Nonetheless, the movement resulted in concessions to peasants: the poll tax was abandoned, and wage bargaining expanded over time, leading to the emergence of a new yeoman class.</p>



<h2 id="h-the-collapse-of-the-aztec-and-incan-empires">The collapse of the Aztec and Incan empires</h2>



<p>Similar claims&nbsp;have been made about the crisis that enveloped the Aztec and Incan empires following the Spanish Conquest of Central and South America in the early sixteenth century. In&nbsp;<em>Plagues and Peoples</em>, McNeill&nbsp;<a href="https://www.amazon.co.uk/Plagues-People-William-McNeill/dp/0385121229" target="_blank" rel="noreferrer noopener">argued that</a>&nbsp;‘disaster is to be expected whenever some previously remote and isolated tribe comes into contact with the outside world and there encounters a series of destructive and demoralizing epidemics.’</p>



<p>In the case of the Aztecs and Inca, the&nbsp;root cause of crisis and societal collapse&nbsp;was the introduction by Columbus and, later, the conquistador Hernan Cortez, of smallpox, measles and other Old World diseases to which Amerindian populations of modern-day Mexico, Guatemala and Peru had little or no immunity. The result was that&nbsp;within a century of Cortes’s arrival in the Gulf of Mexico in 1518 the population of Central Mexico had been reduced, according to some estimates, from 25 million to 1.5 million. A similar demographic …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engelsbergideas.com/essays/challenging-the-great-reset-theory-of-pandemics/">https://engelsbergideas.com/essays/challenging-the-great-reset-theory-of-pandemics/</a></em></p>]]>
            </description>
            <link>https://engelsbergideas.com/essays/challenging-the-great-reset-theory-of-pandemics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25426174</guid>
            <pubDate>Tue, 15 Dec 2020 02:03:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jekyll Website Performance Improvement]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25425809">thread link</a>) | @dsieger
<br/>
December 14, 2020 | https://www.danielsieger.com/blog/2020/12/14/jekyll-website-performance-improvement.html | <a href="https://web.archive.org/web/*/https://www.danielsieger.com/blog/2020/12/14/jekyll-website-performance-improvement.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  <p><span>14 Dec 2020</span></p><p>This article provides practical tips on how to optimize the loading speed of your website. Some advice specifically aims at users of <a href="https://jekyllrb.com/">Jekyll</a>, the blog-enabled static site generator. However, the basic ideas also apply to other tools and should therefore be easy to transfer.</p> <p>Note: This is an article written by and for the occasional web developer. If you’re a professional full-time web developer, you might know much of the content. I still encourage you to continue reading, though!</p> <h2 id="why-care">Why Care?</h2> <p>Why should you care about performance? We’ve got tiny supercomputers in our pockets, so who cares? And aren’t static websites such as those generated by <a href="https://jekyllrb.com/">Jekyll</a> super fast out of the box? Well, not so fast.</p> <p>Performance matters a lot, and tiny improvements can make a vast difference. According to research from Google, the speed it takes to load a page has an impact of around 75% for user experience, clearly above other criteria such as ease of use or attractiveness:</p> <p><img src="https://www.danielsieger.com/images/speed_impact.jpg" alt="Impact of Speed on UX"></p> <p>If you would like to learn more, have a look at this talk from Google’s 2019 I/O conference:</p> <p> <iframe src="https://www.youtube.com/embed/mLjxXPHuIJo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> </p> <p>When it comes to static websites the situation surely is not as bad as in other cases. Remember Flash, anyone? However, investigating performance more closely reveals opportunities for optimization even for static sites.</p> <h2 id="performance-analysis">Performance Analysis</h2> <p>First, we need to measure performance before we can optimize it. My current tool of choice is Google’s <a href="https://developers.google.com/web/tools/lighthouse">Lighthouse</a>. You can either run it in a browser through <a href="https://developers.google.com/web/tools/chrome-devtools">Chrome Dev Tools</a> or online at Google’s <a href="https://web.dev/measure">web.dev</a> pages.</p> <p>Lighthouse not only analyzes raw performance but also provides insight into how well your website performs according to</p> <ul> <li>Accessibility</li> <li>Best practices</li> <li>Search engine optimization</li> </ul> <p>Here’s what I got for an older version of my site using Chrome Dev Tools:</p> <p><img src="https://www.danielsieger.com/images/lighthouse_perf_old.jpg" alt="Performance results on old website"></p> <p>That’s quite a bit of red and orange. In contrast, this is what I get after optimization, using <a href="https://web.dev/measure">web.dev</a> this time:</p> <p><img src="https://www.danielsieger.com/images/lighthouse_perf_results.jpg" alt="Performance results on current website"></p> <p>Read on to see how you might get there as well.</p> <h2 id="minification">Minification</h2> <p>Low-hanging fruits first.</p> <p>A straightforward way to reduce the size of your pages is to minify the HTML code. Just like other text-based formats, HTML can be minified by reducing white space, comments, newlines, or optional closing tags.</p> <p>There is a Jekyll plugin that exactly does that job for you: <a href="https://github.com/penibelst/jekyll-compress-html">jekyll-compress-html</a>. The usage is super simple:</p> <ol> <li>Download the <code>compress.html</code> file from the repository</li> <li>Copy it to the <code>_layouts</code> folder of your Jekyll website</li> <li> <p>Edit your top-level layout file (usually <code>default.html</code>) to have the following front matter:</p>  </li> </ol> <p>This will change your HTML code from something nicely formatted and human-readable to something much more compact. Here is a comparison before and after enabling minification:</p> <p><img src="https://www.danielsieger.com/images/compress_before_after.png" alt="HTML minification example"></p> <p>This saves about 1K in size on a random HTML page of mine. Doesn’t sound too impressive, but Lighthouse already shows some improvement.</p> <h2 id="only-include-what-you-need">Only Include What You Need</h2> <p>From here on things get slightly more complicated, but the gain in speed is also significantly greater. Hang tight.</p> <p>Depending on your Jekyll setup, you eventually include a <em>lot</em> of additional assets like CSS frameworks, JavaScript libraries, or custom fonts. Chances are that you only need a subset of them.</p> <p>I use <a href="https://getbootstrap.com/">Bootstrap</a> to build this site (see <a href="https://www.danielsieger.com/blog/2019/01/12/creating-jekyll-bootstrap-template.html">this post</a>), which depends on <a href="https://jquery.com/">jQuery</a>. Both libraries are quite heavyweight. Turns out I only need a fraction of them, offering an excellent opportunity for size reduction.</p> <h3 id="bootstrap">Bootstrap</h3> <p>I compile my own version of Bootstrap using <a href="https://en.wikipedia.org/wiki/Sass_(stylesheet_language)">Sass</a>, see this <a href="https://www.danielsieger.com/blog/2019/01/12/creating-jekyll-bootstrap-template.html">post</a> for details. Therefore, I can easily configure which CSS modules to include from the Bootstrap distribution. Here is my top-level <code>bootstrap.scss</code> file with all unused modules commented out:</p> <div><div><pre><code><span>@import</span> <span>"functions"</span><span>;</span>
<span>@import</span> <span>"variables"</span><span>;</span>
<span>@import</span> <span>"mixins"</span><span>;</span>
<span>@import</span> <span>"root"</span><span>;</span>
<span>@import</span> <span>"reboot"</span><span>;</span>
<span>@import</span> <span>"type"</span><span>;</span>
<span>@import</span> <span>"images"</span><span>;</span>
<span>@import</span> <span>"code"</span><span>;</span>
<span>@import</span> <span>"grid"</span><span>;</span>
<span>@import</span> <span>"tables"</span><span>;</span>
<span>/* @import "forms"; */</span>
<span>/* @import "buttons"; */</span>
<span>@import</span> <span>"transitions"</span><span>;</span>
<span>/* @import "dropdown"; */</span>
<span>/* @import "button-group"; */</span>
<span>/* @import "input-group"; */</span>
<span>/* @import "custom-forms"; */</span>
<span>@import</span> <span>"nav"</span><span>;</span>
<span>@import</span> <span>"navbar"</span><span>;</span>
<span>/* @import "card"; */</span>
<span>/* @import "breadcrumb"; */</span>
<span>/* @import "pagination"; */</span>
<span>/* @import "badge"; */</span>
<span>/* @import "jumbotron"; */</span>
<span>/* @import "alert"; */</span>
<span>/* @import "progress"; */</span>
<span>/* @import "media"; */</span>
<span>/* @import "list-group"; */</span>
<span>/* @import "close"; */</span>
<span>/* @import "toasts"; */</span>
<span>/* @import "modal"; */</span>
<span>/* @import "tooltip"; */</span>
<span>/* @import "popover"; */</span>
<span>/* @import "carousel"; */</span>
<span>/* @import "spinners"; */</span>
<span>@import</span> <span>"utilities"</span><span>;</span>
<span>/* @import "print"; */</span>
</code></pre></div></div> <p>That’s more than half of the modules, and I’m sure I could optimize this even further after more careful investigation.</p> <h3 id="jquery">jQuery</h3> <p>The Bootstrap JavaScript code depends on jQuery, which is quite a heavy library providing a lot of functionality. The good news is: As long as you are only using the CSS part of Bootstrap, you are fine <em>not</em> to include it.</p> <p>Check if you really need the Bootstrap JavaScript modules. If not, just remove the corresponding <code>&lt;script&gt;</code> tags for both from your template and watch your performance score improving.</p> <p>In my case, I still use jQuery to retrieve comments on blog posts via GitHub, see <a href="https://www.danielsieger.com/blog/2018/10/23/blog-comments-using-github.html">here</a> for details. However, instead of including jQuery by default on all pages, I now only include it on blog posts using the comment functionality:</p> <div><div><pre><code>{% if page.issue and site.github_comments_repository %}
...
<span>&lt;script </span><span>src=</span><span>"/js/jquery.min.js"</span><span>&gt;&lt;/script&gt;</span>
...
{% endif %}
</code></pre></div></div> <p>I admit that it is still overkill include jQuery just to retrieve some data from GitHub. I’m sure there are more lightweight alternatives. Can you recommend one? Leave a comment below!</p> <h3 id="mathjax">MathJax</h3> <p>Many technical blogs include support for <a href="https://www.mathjax.org/">MathJax</a>, a convenient way to typeset mathematical formulas in your posts. Again, this is quite a heavy dependency pulling in lots of JavaScript code.</p> <p>Similarly, the solution is to use conditional inclusion: Only include MathJax when you really need it. Here, a dedicated front-matter variable in posts needing MathJax support will do the trick:</p> <div><div><pre><code>---
layout: post
title: Fancy Post With Lots of Math
mathjax: true
---
</code></pre></div></div> <p>Next, change your layout or include file (depending on where you actually include MathJax) to check for the variable being defined:</p> <div><div><pre><code>{% if page.mathjax %}
  <span>&lt;script </span><span>type=</span><span>"text/x-mathjax-config"</span><span>&gt;</span>
    <span>&lt;!--</span> <span>your</span> <span>config</span> <span>here</span> <span>--&gt;</span>
  <span>&lt;/script&gt;</span>
  <span>&lt;script </span><span>async</span> <span>src=</span><span>"/MathJax.js?config=TeX-AMS_HTML"</span><span>&gt;&lt;/script&gt;</span>
{% endif %}
</code></pre></div></div> <p>Note the <code>async</code> attribute above to enable asynchronous loading of the script. This eventually enhances performance in case you actually use MathJax.</p> <h2 id="deferred-loading">Deferred Loading</h2> <p>As shown above, adding the <code>async</code> attribute to <code>&lt;script&gt;</code> tags is one way to improve page load time for scripts that you absolutely have to load. Using the <code>defer</code> attribute is another alternative. See the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/script">script</a> HTML element documentation for more information.</p> <p>Another commonly used technique is to defer the loading by placing your <code>&lt;script&gt;</code> tags at the very end of the document. However, you should not need this anymore when using the <code>async</code> or <code>defer</code> attributes.</p> <p>For more information on how to eliminate render-blocking resources, please see the corresponding Google Developers <a href="https://web.dev/render-blocking-resources/">page</a>.</p> <h2 id="inline-critical-css">Inline Critical CSS</h2> <p>Another optimization technique is to <em>inline</em> CSS code directly into the HTML document instead of loading an external script. The key point is to inline only <em>critical</em> CSS styles needed to render the first paint and make the core functionality work.</p> <p>I adopted a simple version of this by using an online critical path CSS <a href="https://jonassebastianohlsson.com/criticalpathcssgenerator/">generator</a>. This takes your website URL and the full CSS code as input and generates a small set of critical CSS styles to include directly in your HTML header.</p> <p>The resulting CSS looks far from being optimal, but for the moment it works fine. I am sure there are better alternatives out there. Maybe you know something that integrates well with Jekyll? Comment below, or drop me a <a href="mailto:dsieger@posteo.de">mail</a>.</p> <h2 id="asynchronous-loading-of-css">Asynchronous Loading of CSS</h2> <p>Another tweak I applied was to defer loading of the full CSS files using a <del>hack</del> creative solution based on the media attribute.</p> <div><div><pre><code> <span>&lt;link</span> <span>rel=</span><span>"stylesheet"</span>
       <span>href=</span><span>"style.css"</span>
       <span>media=</span><span>"print"</span>
       <span>onload=</span><span>"this.media='all'"</span><span>&gt;</span>
</code></pre></div></div> <p>Note that this requires inlining of critical CSS, otherwise you will get ugly “Flashes of Unstyled Content” (FOUC). See the full <a href="https://css-tricks.com/the-simplest-way-to-load-css-asynchronously/">description</a> at <a href="https://css-tricks.com/">css-tricks.com</a> for more details.</p> <h2 id="fonts">Fonts</h2> <p>Custom web fonts are popular and available to everyone through services like <a href="https://fonts.google.com/">Google Fonts</a>. However, ask yourself if you really need them.</p> <p>As an alternative, consider using a system font stack relying on fonts already installed on the user’s system. This offers significant performance gains since</p> <ul> <li>there are no font files to transfer and load</li> <li>the browser likely has the fonts cached</li> </ul> <p>All major operating systems include somewhat decent fonts these days, so this really is an alternative. Plus, the system fonts match the look and feel of the operating system, so users are used to it.</p> <p>Here’s one way to use system fonts:</p> <div><div><pre><code><span>body</span> <span>{</span>
  <span>font-family</span><span>:</span> <span>-apple-system</span><span>,</span> <span>BlinkMacSystemFont</span><span>,</span> <span>"Segoe UI"</span><span>,</span>
               <span>Roboto</span><span>,</span> <span>Helvetica</span><span>,</span> <span>Arial</span><span>,</span> <span>sans-serif</span><span>,</span>
               <span>"Apple Color Emoji"</span><span>,</span> <span>"Segoe UI Emoji"</span><span>,</span>
               <span>"Segoe UI Symbol"</span><span>;</span>
<span>}</span>
</code></pre></div></div> <p>However, if you are like me and want more precise control over the fonts being used, there are some guidelines to do this efficiently:</p> <ul> <li>Host the fonts yourself if possible. This avoids additional connection requests and/or name resolution.</li> <li>Use <code>font-display: swap</code> in the <code>@font-face</code> definition to make sure text remains visible while the browser loads the fonts.</li> <li>Reduce the size of the font files by sub-setting. Only include the glyphs for the languages you are using.</li> <li> <p>Pre-load essential font files by adding appropriate special tags to your header:</p> <div><div><pre><code>  <span>&lt;link</span> <span>rel=</span><span>"preload"</span>
        <span>href=</span><span>"/font.woff2"</span>
        <span>as=</span><span>"font"</span>
        <span>type=</span><span>"font/woff2"</span> <span>crossorigin</span><span>&gt;</span>
</code></pre></div> </div> </li> </ul> <p>Last remark: Popular icon font sets such as <a href="https://fontawesome.com/">Font Awesome</a> are quite heavy as well. The latter contains something around 1000 icons (depending on your version), and I doubt you really need all of them. Consider creating a customized version containing only the icons you actually use. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.danielsieger.com/blog/2020/12/14/jekyll-website-performance-improvement.html">https://www.danielsieger.com/blog/2020/12/14/jekyll-website-performance-improvement.html</a></em></p>]]>
            </description>
            <link>https://www.danielsieger.com/blog/2020/12/14/jekyll-website-performance-improvement.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25425809</guid>
            <pubDate>Tue, 15 Dec 2020 01:14:11 GMT</pubDate>
        </item>
    </channel>
</rss>
