<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 03 Oct 2020 16:32:14 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 03 Oct 2020 16:32:14 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Why Privacy Is the Most Important Concept of Our Time]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24661271">thread link</a>) | @umilegenio
<br/>
October 2, 2020 | https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/ | <a href="https://web.archive.org/web/*/https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-25770" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>I have always believed in the importance of privacy, but I felt that common definitions (e.g., <em>the right to be left alone</em>) were lacking. In fact, I think that the whole conceptualization of privacy as simply a right of an individual as partial and limiting. It could be because privacy, as <a href="https://en.wikipedia.org/wiki/Privacy">it is intended nowadays, originated from the Anglo-American world (that is what Wikipedia says</a>). </p>



<p>You might say that then, maybe, I am not really thinking about privacy, but rather something else. That might be true, so let‚Äôs not talk about privacy, instead let‚Äôs talk about <a href="https://en.wikipedia.org/wiki/Definitions_of_fascism#Umberto_Eco">Ur-Privacy</a>, the properties of any version of the concept of privacy you might have. Take this as the opinion of a random guy that cares about the issue.</p>



<div><h2>What is Ur-Privacy</h2><p><em>A few principles for privacy</em></p></div>







<p><strong>Privacy is about boundaries.</strong> <strong>It is not about hiding something from someone but allowing to create a space with rules</strong> <strong>decided by its members</strong>. I like to compare it to borders. Some people say that borders are a restriction, something that limit freedom of movement and we do not need in the contemporary world. As if they were arbitrary obstacles put there by the ancient petty Greek gods. It almost makes sense if you do not think about them, after all you are actually stopped at a border.</p>



<p>However, that is not true, that is not why they exist. Borders delimit the area that a certain state control, an area where a specific set of rules and laws applies. There was a time before borders, in fact most of human history did not have clear borders. It was not a time of freedom, but anarchy, where bands of barbarians could roam into your home and pillage everything.</p>



<p>In this context is also important to remember that before the <a href="https://en.wikipedia.org/wiki/Peace_of_Westphalia">Peace of Westphalia</a> modern European states were plagued by continual wars. The short version is that this was due to the combination of two facts:</p>



<ul><li>modernity begets differences, different kings choose different religions<sup><a id="link_1" href="#note_1" data-type="internal" data-id="#note_1">1</a></sup> and separated societies</li><li>however, the legitimacy of kings was still based on shared medieval ideals, like the concept of divine rule</li></ul>



<p>In short, the issue was not that leaders wanted to make war all the time, they needed to do so because the legitimacy of their power depended, at least on some level, to what the rest of the European world was doing. If you claim to be a divine king there better be agreement on what the divine is, otherwise a guy that picks a different religion can also rightly pick a different king. To change the situation this peace treaty established the principle that the internal affairs of a state are the exclusive interest of said state.</p>



<p>The connection with privacy is that without clear rules on what is private and what is public, nobody knows which stuff belongs to whom and this means that all belong to the strongest. <strong>Somebody might say that what you do in private, it is not private at all but political, it concerns the society at large. Therefore it must be regulated according to their rules</strong>.</p>



<p><strong>Privacy is about control</strong>. <strong>Without privacy we cannot decide for ourselves how to live our lives.</strong> If there is no privacy all become public. Whoever has more power and an interest can affect your life according to their own rules. Then, I have to care about what other people think, otherwise they will control how I can behave. As before the peace of Westphalia, the issue is not that other people are bad, <em>they have to do it</em>. When everything is subject to public scrutiny, you either control the rules and judge others or you are judged and controlled by others.</p>



<p>Think about this way: we say a lot of things in our private lives that are not meant to be taken literally. In private we say something and then we add: <em>you know what I mean</em>. And that is actually true. We can do that because the people we talk to in private know us; they understand the context in which our words must be understood. When I was a child I would sometimes say and think that I wanted to kill my brother. I did not meant literally and everybody knew it. If I said the same thing now, in public, to somebody that does not know me, the phrase would be different. It would be a <a href="https://en.wikipedia.org/wiki/Threat">threat</a>.</p>



<p>Why is that? They are the exact same words. You know why, of course. I am different and the context is different. The real meaning of something, whether an action or a word, is not absolute, in most cases is relative. When we speak in public, we share a different context, therefore our words have a different meaning.</p>



<p>So even I say something as an hyperbole or as an potentially implicit threat (e.g., <em>they must be stopped at all costs</em>!), they might protest. You might say that they are overreacting, that it was just a joke, but <em>how can they be sure of it</em>? <strong>They do not know me.</strong> <strong>And it is true that acts of violence are prepared by violent words</strong>. Even if you are unsure if something is really violent, you have to take a stand. You have to make clear that any attack against you is not permissible. Otherwise, <a href="https://en.wikipedia.org/wiki/Christchurch_mosque_shootings" data-type="URL" data-id="https://en.wikipedia.org/wiki/Christchurch_mosque_shootings">somebody, maybe a crazy guy, might think that it is permissible and the right course of action</a>. Somebody might feel legitimate to take your land and kingdom.</p>



<p>A clear example of the loss of privacy is the <em>rise of violent rhetoric</em>. Everybody swears and everybody threaten. However, for the most part they do not mean it. We know that because the actual rate of violence has not risen. We simply talk in public as we talk in private, because our private lives have become more public. I mean, some bosses want even to look at your Facebook profile<sup><a href="#note_2">2</a></sup><a id="link_2" href="https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/note_2">.</a></p>



<div><h2>Privacy Affects Everything</h2><p><em>Defending privacy would require all-around changes</em></p></div>







<p><strong>Privacy is the most important concept of our time, because it allows to define everything else. Without privacy we do not know what rules applies. Our lives will be judged according to the rules, even the whims, of somebody else.</strong></p>



<p>People lost jobs and had their lives ruined, because the mob judged something they said in private in a different way from what they expected. And they paid a price. You might say: that was fair. We might judge ourselves by our intentions, but others by their actions, which are real and objective.</p>







<p>I, for once, disagree with XKCD and this view. There are a couple of different issues here:</p>



<ul><li>how we should react to speech we disagree with</li><li>what was meant to be shared among friends was taken out of context and made public</li></ul>



<p>This complicates the whole matter. At a first glance the first issue should not matter here, because we are talking about privacy. However, this is a bit more complicated. Violations of privacy can affect other rights and freedom. Freedom of speech is a right regarding the public sphere. You have always been able to say everything in private, for the simple fact that people cannot control that. If now the private becomes public, then either we get absolute freedom of speech (a sort of <em>speech anarchy</em>, if you will) or we lose freedom of speech.</p>



<p>Okay, then we demand to not violate privacy even in the case of bad speech. If you said something bad in private then I cannot demand your boss to fire you. I cannot do that even by maintaining privacy: <em>trust me on this, they say something really bad</em>,<em> you should fire them</em>. This is a practical example of how privacy might affect everything.</p>



<p>This is crucial, but we have to understand that simply enforcing privacy in the traditional way is not enough anymore. To protect privacy we need to re-interpret some rights we have. For instance, traditionally there have been exceptions to privacy for public interest. If you heard somebody famous saying something controversial in private you could go public about. The issue is that few people (i.e., the press) had that power. Now we all have it. <strong>So, to defend privacy we need to accept shared norms of behavior</strong>. We cannot expect consequences outside the context that caused them.</p>



<p>This is hard to do, because people have different idea of public interest. It is not true that we judge other by their actions. We judge others by <em>our intentions</em>. So, we must be strict about the norm that the answer to some speech should be only some other form speech. In other words, if somebody offended you with some method, you should respond with the same method. If somebody said something bad, you cannot shove them. <strong>Actions by a mob in order to punish an alleged transgressor, punish a convicted transgressor, or intimidate them is not an answer to a bad argument, it is a<a href="https://en.wikipedia.org/wiki/Lynching"> lynching</a></strong>.</p>



<p>There is a difference between killing somebody and just ruining their lives. However, it is still bad. It is still lynching, something we do to one to control one hundred. Making somebody lose their livelihood because of something said in private it is not fair, because they said in a different context. They were not prepared to be judged by their worst enemies. And they should not have. </p>



<p>The philosopher Jeremy Bentham described the perfect prison as the <a href="https://en.wikipedia.org/wiki/Panopticon">Panopticon</a>. A prison where in every cell there was a one-way mirror. This way the guards could watch the inmates without being seen. Therefore the inmates would have to behave as if they were always watched. That kind of sounds like the world right now. And I am ready to lose the power to punish bad people in order to protect me from people that think I am a bad guy.</p>



<p><em>Given the discussion on Hacker News, I think that I was a bit unclear here. The connection between privacy and freedom of speech is just an example. My point is that privacy affects how we enjoy other rights, too. Even though that might not seem obvious at first.  </em></p>



<div><h2>What Should We Do?</h2><p>A modest proposal</p></div>







<p>So what has to be done to defend privacy? <strong>There should be clear boundaries about private, social and public spaces</strong>:</p>



<ul><li>a private space regards only you or your family</li><li>a social space is something involving a community, either a virtual one like a forum or a real one like a city</li><li>a public space is a space for all actors of society</li></ul>



<p>By clear boundaries I mean that we should create rules, ‚Ä¶</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/">https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/</a></em></p>]]>
            </description>
            <link>https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661271</guid>
            <pubDate>Fri, 02 Oct 2020 10:55:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flatpak: A security nightmare ‚Äì two years later]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24661126">thread link</a>) | @krimeo
<br/>
October 2, 2020 | https://www.flatkill.org/2020/ | <a href="https://web.archive.org/web/*/https://www.flatkill.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>Two years ago I <a href="https://flatkill.org/">wrote</a> about then heavily-pushed Flatpak, self-proclaimed "Future of Apps on Linux". The article criticized the following three major flows in Flatpak:</p><ul>
<li>Most of the apps have full access to the host system but users are misled to believe the apps are sandboxed
</li><li>The flatpak runtimes and apps do not get security updates
</li><li>Flatpak breaks many aspects of desktop integration
</li></ul>

<!-- <p>A lot has changed in the 2 years (the company behind Flatpak is now just another IBM's brand for one thing) so let's see how Flatpak developers addressed these fundamental issues.</p> -->
<p>So let's see how Flatpak developers addressed these fundamental issues.</p>

<h2>The sandbox is STILL a lie</h2>

<p>Almost all popular apps on Flathub still come with <span>filesystem=host</span> or <span>filesystem=home</span> permissions, in other words, <b>write access to the user home directory</b> (and more) so all it takes to escape the sandbox is trivial <span>echo download_and_execute_evil &gt;&gt; ~/.bashrc</span>. That's it.</p>


<p>The most popular applications on Flathub still suffer from this - Gimp, VSCodium, PyCharm, Octave, Inkscape, Audacity, VLC are still not sandboxed.</p>

<p>And, indeed, users are still mislead by the reassuring blue "sandboxed" icon. Two years is not enough to add a warning that an application is <b>not</b> sandboxed if it comes with dangerous permissions (like full access to your home directory)? Seriously?</p>

<img src="https://www.flatkill.org/2020/sandboxlie.png" alt="sandboxlie">

<h2>Flatpak apps and runtimes STILL contain long known security holes</h2>
<p>It took me about 20 minutes to find the first vulnerability in a Flathub application with full host access and I didn't even bother to use a vulnerability scanner.</p>

A perfect example is <a href="https://www.cvedetails.com/cve/CVE-2019-17498">CVE-2019-17498</a> with public exploit <a href="https://github.com/github/securitylab/tree/main/SecurityExploits/libssh2/out_of_bounds_read_disconnect_CVE-2019-17498">available</a> for some 8 months. The first app on Flathub I find to use libssh2 library is Gitg and, indeed, it does ship with unpatched libssh2.

<p>But is it just this one application? Let's look at the <b>official runtimes</b> at the heart of Flatpak (org.freedesktop.Platform and org.gnome.Platform <b>3.36</b> - as of time of writing used by most of the applications on Flathub). The first unpatched vulnerable dependency I found in the offical runtime is ffmpeg in version 4.2.1 with no security patches backported, <a href="https://www.cvedetails.com/cve/CVE-2020-12284">CVE-2020-12284</a>.</p><p>Recently I stumbled upon an article from 2011 which started what is today known as flatpak, <a href="https://people.gnome.org/~alexl/glick2">in the words of the project founder:</a></p>

<p><a href="https://people.gnome.org/~alexl/glick2"><b><i>"Another problem is with security (or bugfix) updates in bundled libraries. With bundled libraries its much harder to upgrade a single library, as you need to find and upgrade each app that uses it. Better tooling and upgrader support can lessen the impact of this, but not completely eliminate it."</i></b></a></p>

<p>After reading that it comes as no surprise flatpak still suffers from the same security issues as 2 years ago because flatpak developers knew about these problems from the beginning.</p>

<h2>Local root exploits are NOT considered a minor issue anymore!</h2>
<p>Great! Two years ago I wrote about a trivial local root exploit using flatpak to install suid binaries (<a href="https://www.cvedetails.com/cve/CVE-2017-9780/">CVE-2017-9780</a>) and how it was downplayed by Flatpak developers as a minor security issue <a href="https://github.com/flatpak/flatpak/releases/tag/0.8.7">here</a>. I am happy to see at least the attitude to local root exploits has changed and today <a href="https://github.com/containers/bubblewrap/security/advisories/GHSA-j2qp-rvxj-43vj">local root exploits</a> are considered high severity.

</p><h2>Desktop integration</h2>
<p>System and user fonts are now available to flatpak applications and basic font rendering settings are respected as well, however do not expect your changes in /etc/fonts, typically setting a proper fallback font for CJK characters, to work with flatpak.  KDE applications in flatpak are still ignoring themes, fonts and icon settings (tested with Qt5ct). Applications installed from the distribution sources do not have these problems, of course. <a href="https://www.flatkill.org/2020/desktopbrokenation.mp4">A quick screen capture to demonstrate</a>.</p>

<p>More importantly, fcitx, <i>the</i> IME for Chinese is still broken - it has been 2 years. Here is the <a href="https://github.com/flatpak/flatpak/issues/2031">issue</a> I linked 2 years ago - especially of interest is <a href="https://github.com/flatpak/flatpak/issues/2031#issuecomment-655134889">the following comment</a> directly from fcitx developer:

</p><p><i>"Because fcitx im module in flatpak is from 4.2.97 and using a different dbus object path. <b>It need to be the same version of fcitx on your host</b>."</i></p>

So I need to run multiple fcitx daemons on my desktop and switch between them as I switch flatpak apps depending on which fcitx libraries are bundled with that app or maybe in the future of linux apps it's not possible to type chinese anymore and it's fine?

<p>While the "bundle everything" approach has proven very useful on servers it clearly does not work for desktop applications, let's keep linking system libraries in desktop applications (and use the bundled libraries as a fallback only) to avoid introducing all these problems to Linux desktop.</p>



</div>]]>
            </description>
            <link>https://www.flatkill.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661126</guid>
            <pubDate>Fri, 02 Oct 2020 10:35:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Node.js malware caught posting IPs, username, and device info on GitHub]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660810">thread link</a>) | @axsharma
<br/>
October 2, 2020 | https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/ | <a href="https://web.archive.org/web/*/https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <!-- .entry-header -->

                
                        <div>
                                    <p><img width="1024" height="683" src="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg" alt="red and blue hearts illustration" loading="lazy" srcset="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg 1024w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-300x200.jpg 300w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-768x512.jpg 768w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1536x1024.jpg 1536w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-2048x1365.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg 1024w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-300x200.jpg 300w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-768x512.jpg 768w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1536x1024.jpg 1536w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-2048x1365.jpg 2048w" data-src="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">                </p>
            
                                            </div>

            

        <!-- end slider-section -->
                                    

    <div>
        <div>
            




<p>Multiple NodeJS packages laden with malicious code have been spotted on npm registry.</p>



<p>These ‚Äútyposquatting‚Äù packages served no purpose other than collecting data from the user‚Äôs device and broadcasting it on public GitHub pages.</p>



<p>The findings were spotted by Sonatype‚Äôs <a href="https://blog.sonatype.com/sonatype-spots-malicious-npm-packages" target="_blank" rel="noreferrer noopener">automated malware detection systems</a> and further investigated by the company‚Äôs Security Research team which includes me. </p>



<p>The packages previously present on the open source npm registry included:</p>



<ol><li><a rel="noreferrer noopener" href="https://www.npmjs.com/package/electorn" target="_blank">electorn</a> (intentional misspelling of a legitimate package ‚Äúelectron‚Äù)</li><li><a rel="noreferrer noopener" href="https://www.npmjs.com/package/loadyaml" target="_blank">loadyaml</a> </li><li>loadyml</li><li>lodashs (intentional misspelling of a legitimate package ‚Äúlodash‚Äù)</li></ol>



<p>All four packages were published by the same user ‚Äúsimplelive12‚Äù and have now been removed, with the first two having been taken down by npm as of October 1, 2020. The previous two packages were unpublished by the author themselves.</p>



<p>Once installed, <code>electorn</code> ran a script in the background <strong>every</strong> <strong>hour</strong> which collected the logged-in user‚Äôs IP, geolocation data, username, path to home directory, and CPU model information.</p>



<figure><img loading="lazy" width="1024" height="356" src="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png" alt="" srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-1-300x104.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-1-768x267.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1-1536x534.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image-1-2048x712.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-1-300x104.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-1-768x267.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1-1536x534.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image-1-2048x712.png 2048w" data-src="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>The malicious code within <code>electorn</code> and 3 other identical packages which exfiltrated user information</figcaption></figure>



<p>This information, part of which constitutes the device ‚Äúfingerprint‚Äù was uploaded and published on <a rel="noreferrer noopener" href="http://web.archive.org/web/20201001065601/https://github.com/h4ppyl1ve/collect/issues/4" target="_blank">GitHub</a> in real-time.</p>



<p>Some of the information being published is base64-encoded but this can be trivially decoded by anyone who has access to it:</p>



<figure><img loading="lazy" width="1024" height="488" src="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png" alt="" srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-300x143.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-768x366.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1536x732.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image.png 1632w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-300x143.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-768x366.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1536x732.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image.png 1632w" data-src="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>Sonatype‚Äôs Security Research team has accounted for these malicious packages into their products, and had notified both npm and GitHub teams of the malicious activity stemming from the components. This led to the takedown of these malicious packages. </p>



<p>To this date, all 4 packages have scored a little over <strong>400</strong> total downloads.</p>



<p>It is not exactly clear what was the purpose of collecting this data and why was it being published on the web for the world to see, however, incidents like these highlight the potential of typosquatting attacks on the open-source ecosystem.</p>



<p>We can only imagine what the next possible version of these packages could have been capable of ‚Äì possibly carrying out even more sinister activities. </p>



<p>By tricking an unsuspecting developer into mistakenly installing a misspelled package, attackers can push their malicious code ‚Äúdownstream‚Äù into any other open-source projects that use the misspelled malicious component as a transitive dependency.</p>



<p>Adopting DevSecOps best practices and building security early on into your software development lifecycle can prevent ‚Äúcounterfeit components‚Äù such as electorn and loadyaml from entering, and thriving in your software supply chains.</p>



<p>The complete research findings are available on the <a href="https://blog.sonatype.com/sonatype-spots-malicious-npm-packages" target="_blank" rel="noreferrer noopener">Sonatype blog</a>.</p>
                <div>
                    <h3>About the author</h3>
                                        
        <div>

                <p><a href="https://securityreport.com/author/ax-sharma/"><img alt="" src="https://secure.gravatar.com/avatar/d0d95768ca47b1764f5fb964cf860afa?s=150&amp;d=retro&amp;r=pg" srcset="https://secure.gravatar.com/avatar/d0d95768ca47b1764f5fb964cf860afa?s=300&amp;d=retro&amp;r=pg 2x" height="150" width="150" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></a>
                </p>
                <div>
                    <h4>
                        <a href="https://securityreport.com/author/ax-sharma/">Ax Sharma</a>
                    </h4>

                    
                    
                                            <p>
                        <a href="https://axsharma.com/" target="_blank">https://axsharma.com/</a>
                        </p>
                                        <div>
                        <p>Ax Sharma is a Security Researcher, Engineer, and Tech Columnist. His works and expert analyses have frequently been featured by leading media outlets like Fortune, The Register, TechRepublic, CIO, etc.</p>
<p>Ax‚Äôs expertise lies in vulnerability research, reverse engineering, software development, and web app security. He‚Äôs an active community member of the OWASP Foundation and the British Association of Journalists (BAJ).</p>
<p>Send any tips via email or Twitter DM.</p>
                    </div>
                    
                                    </div>
        </div>

                                            </div>
                                            
                        
	<nav role="navigation" aria-label="Continue Reading">
		<h2>Continue Reading</h2>
		
	</nav>                    </div><!-- .entry-content -->
    </div>
                        </div></div>]]>
            </description>
            <link>https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660810</guid>
            <pubDate>Fri, 02 Oct 2020 09:47:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Please Stop Imposing American Views about Race on Us]]>
            </title>
            <description>
<![CDATA[
Score 297 | Comments 214 (<a href="https://news.ycombinator.com/item?id=24660682">thread link</a>) | @dgellow
<br/>
October 2, 2020 | https://www.persuasion.community/p/please-stop-imposing-american-views | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/please-stop-imposing-american-views">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/e3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:18107111,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>Construction workers reopen Winston Churchill statue in Parliament Square after it was covered with metal panels to protect it against defacement by protestors.</em></p><p>Over the past couple of months, many Britons have imported American discourse on race wholesale. When asked to analyze the experiences of black people in the United Kingdom, we now talk with an American accent.</p><p>Take a look, for instance, at a meme that has been circulating among some of my white friends on Facebook and Instagram:</p><blockquote><p>I have privilege as a White person because I can do all of these things without thinking twice about it ‚Ä¶ I can go jogging (#AmaudArbery). I can relax in the comfort of my own home (#BothemSean and #AtatianaJefferson). I can ask for help after being in a car crash (#Jonathan Ferrell and #RenishaMcBride). I can have a cellphone (#StephonClark). I can leave a party to get to safety (#JordanEdwards). I can play loud music (#JordanDavis). I can sell CDs (#AltonSterling). I can sleep (#AiyanaJones). I can walk from the corner store (#MikeBrown).</p></blockquote><p>The post goes on and on, like an interminable spoken-word poem. All the individuals listed are American, but most of the people who have shared this on my timeline are British. In trying to express their solidarity with black Britons, they are affirming a supposedly transcendental truth: to be black is to live in perpetual terror of being murdered by the state. </p><p>But Britain is not America. And importing American race discourse into the United Kingdom not only prevents us from recognizing the specific ways in which racial injustice manifests in this country‚Äîit cloaks the reality of black British lives behind an abstraction that flattens our humanity. </p><p>Britain has a long and painful history of anti-black racism. In the twentieth century alone, the growing black presence led to a long catalogue of abuses: the 1919 race riots in Liverpool, Cardiff and London; the 1958 race riots in Nottingham and Notting Hill; the 1969 police murder of David Oluwale, a Nigerian immigrant who was tortured, pissed on and finally drowned in a river in Leeds. I could list other examples. It is not hard to see why the horrific killing of George Floyd has evoked such strong feelings in this country as well.</p><p>But for all of the country‚Äôs flaws, Britain is not America. Trying to understand its racial dynamics through the lens of another country‚Äôs does more to obscure than to illuminate the situation that black Britons like myself actually face.</p><p>The average black American in the United States can trace his ancestry further back than the average white American. Most black Americans are descended from enslaved Africans. Their forebears suffered through the segregation and racial terror of the Jim Crow era. The majority of black people in the United Kingdom, by contrast, are immigrants or the children of immigrants. Though many of them have certainly had harrowing experiences with injustice or discrimination, they do not have the same history of racist disadvantage.</p><p>To understand the experience of black Britons, it is not only necessary to grasp how different their history is from that of black Americans: we need to understand the diversity captured by the label ‚Äúblack British.‚Äù For example, around two out of every three students with Congolese or Somali origins get free school meals, a standard indicator that their parents are poor. Among students with Nigerian or Ghanaian origins, only one in five do. It is also noteworthy that black Caribbean students are twice as likely to be excluded from school as black African students. </p><p>The discrepancy in educational attainment is just as stark. On average, 58% of black African students graduate from middle school at grade level (defined as achieving A* to C grades at GCSE)‚Äîabout the same number as white students. But black Caribbean students are significantly less likely to do so‚Äîwhile those whose parents hail from Nigeria actually outperform their white peers by a considerable margin. </p><p>None of this is to disavow the label ‚Äúblack British.‚Äù But we need to invest it with the nuance consonant with its reality‚Äîand to cast doubt on the idea that every discrepancy in representation must be explained by structural injustice or white supremacy.</p><p>There has, for example, been a lot of concern about the underrepresentation of black Britons in professions like the arts and publishing. But why would you choose to go into theater or journalism‚Äîrather than law, medicine or finance‚Äîif you are a talented child of ambitious but not well off immigrants? </p><p>This is not a flippant question. While representation can be important, anybody who actually wants to improve the condition of black Britons should at least be a little curious about why they are overrepresented in some prestigious professions and underrepresented in others. In a country in which black people make up only three percent of the population, for example, six percent of junior doctors are black. Would the country‚Äîor the black community‚Äîreally benefit if more black Britons chose to ditch medicine for the theater? The debate is worth having. But in the place of that debate, there have only been pious paeans to diversity.</p><p>The stereotype of the West African parent who wants their child to study law or medicine bears some relation to reality; but the widespread view of black people as perennial victims devoid of agency is a defamatory abstraction. The black person in Britain, like Ralph Ellison‚Äôs iconic protagonist, is ‚Äúinvisible because no one wants to see him.‚Äù</p><p>So much of the British reaction to the death of George Floyd has constituted a failure of nerve. Desperately seeking to assuage their feelings of guilt, to do <em>something</em>, many Britons have sacrificed their critical faculties to a narrative that does not actually help black people‚Äîa narrative that, by reducing us to passive abstractions, only makes us more invisible.</p><p>Racists assume that black people are all the same. Ironically, anti-racists sometimes do so too. But anybody who is truly committed to racial equality needs to recognize that this kind of simplification neither serves justice nor reflects the truth.</p><p><strong>Tomiwa Owolade is a writer who lives in London.</strong></p></div></div>]]>
            </description>
            <link>https://www.persuasion.community/p/please-stop-imposing-american-views</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660682</guid>
            <pubDate>Fri, 02 Oct 2020 09:20:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quick Test to Figure Out Why You Feel Down Lately]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660666">thread link</a>) | @azarai
<br/>
October 2, 2020 | https://mindfuldevmag.com/issues/issue-8-readers-questions/felling-down-figure-out-why-test | <a href="https://web.archive.org/web/*/https://mindfuldevmag.com/issues/issue-8-readers-questions/felling-down-figure-out-why-test">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            <div>
                                                                            
                                                                         <p>Feeling down lately?</p>
<p>But you don‚Äôt know why?</p>
<p>This quick test helps you to figure it out and gives you tips on getting up again.</p>
<h2>Quick Test</h2>
<blockquote>
<p>Did you sleep 7-8 hours a night for most of the last 7 days?</p>
</blockquote>
<p>Sleep is essential, and we should not skip on that. While we sleep, our brain processes the day and also cleans itself of toxic waste (<a href="https://www.scientificamerican.com/article/deep-sleep-gives-your-brain-a-deep-clean1/#:~:text=Why%20sleep%20has%20restorative%E2%80%94or,is%20hugely%20improved%20during%20sleep.">see</a>)</p>
<blockquote>
<p>Did you drink less than 10 drinks of alcohol in the last 7 days?</p>
</blockquote>
<p>There is nothing to say against a drink or two. But if you take it too far, you start to feel down, groggy and more. Moreover, alcohol can be addictive, and you don‚Äôt want to become an alcoholic.</p>
<blockquote>
<p>Did you drink too much caffeine in the last 7 days? (Coffee, black tea, energy drinks, etc.)</p>
</blockquote>
<p>Caffeine is a short energy booster, but it comes with downsides too. It blocks the body‚Äôs desire to rest for a short time, but then your body is twice as tired, wanting to rest.</p>
<p>Now, if you drink caffeine again, you start a vicious cycle. You‚Äôll only feel productive when you got your dose of caffeine. Otherwise, you feel tired again.</p>
<p>Over time you need to consume more and more caffeine to even get the effect.</p>
<p>Rest. Your body needs rest, and you should give it.</p>
<blockquote>
<p>Do you think you‚Äôre eating healthy in the last 7 days?</p>
</blockquote>
<p>Your body needs proper nutrition to function.</p>
<p>A diet of chips, chocolate bars, ice cream, or fast food is not the right thing to fuel your body the energy it needs.</p>
<p>Once in a while, it is fine but don‚Äôt thrive on it.</p>
<blockquote>
<p>Have you gone outside in the last 7 days?</p>
</blockquote>
<p>Pandemic here, pandemic there. But even without it, many of us don‚Äôt go outside enough‚Äîespecially people working from home.</p>
<p>But we need movement and fresh air. So, enjoy a long walk in nature, or a park or forest near you. Or just stroll through your city.</p>
<blockquote>
<p>Have you exercised in the last 7 days?</p>
</blockquote>
<p>Move your ass. Doesn‚Äôt matter what kind of exercise you like, do it. Movement is king.</p>
<p>Not only will it lift your mood. It will also help you to think fresh and clear again.</p>
<blockquote>
<p>Have you meditated in the last 7 days? Or journaled, etc.</p>
</blockquote>
<p>Meditation is a great tool to clear your thoughts and calming down. But you don‚Äôt need to sit still.</p>
<p>You can do <a href="https://mindfuldevmag.com/issues/issue-3-mindfulness-for-skeptics/walking-meditation">walking meditations</a> or journaling or other kinds of activities that help you to focus and clear your mind.</p>
<blockquote>
<p>Have you done anything to actively relax?</p>
</blockquote>
<p>This can be taking massages, doing yoga, taking a hot bath, sauna, or anything else that helps you relax.</p>
<p>Take your time and do it on purpose.</p>
<p>Btw watching tv might feel like relaxation, but it mostly is not. Our brain‚Äôs on alert mode.</p>
<p>Can‚Äôt decide on one?</p>
<p>Go for a walk in the next park.</p>
<blockquote>
<p>Have you talked to other people or met with your friends? Preferably IRL</p>
</blockquote>
<p>Even the most introverted of us love to talk to somebody. Sure, I can go without days of talking to somebody except my family. But even that has its limit.</p>
<p>Talk or, better yet, meet your friends, and have a great time. None handy at the moment? Talk to your neighbor, cashiers, or anybody else you can have interactions with.</p>
<blockquote>
<p>If you‚Äôre in a relationship, are you with the right person?</p>
</blockquote>
<p>If your relationship sucks, your mood will drop too. But if it is a loveable and stable one, it can lift you up and help through darker times.</p>
<blockquote>
<p>Have you helped someone in the last days with something you‚Äôre good at?</p>
</blockquote>
<p>Believe it or not. It‚Äôs humans to help others and feel good about it at the same time. It‚Äôs totally refreshing and re-energizing.</p>
<blockquote>
<p>Have you made any new experiences in the last month?</p>
</blockquote>
<p>Doing the same old from day to day, week to week, and month to month can drag you down. It feels like a rut. Being stuck.</p>
<p>Energize your life and go for new experiences. Go for a hike, visit a new city, test a new restaurant. Whatever it is, pick something new.</p>
<blockquote>
<p>Are you working on stuff that‚Äôs meaningful to you?</p>
</blockquote>
<p>Does your job or the things you work on in your spare time give you enough meaning? Or does it feel like working for the devil?</p>
<p>Does it fulfill you?</p>
<blockquote>
<p>Does your current situation allow you to do what you really want to do in life?</p>
</blockquote>
<p>If not, think about what you could start to change? What are thing top 3 things holding you back?</p>
<p>How could you remove them?</p>
<blockquote>
<p>Did you create anything in the last week?</p>
</blockquote>
<p>Does not matter what it is. Maybe you draw comics or paint art, make music, build websites, or whatever.</p>
<p>Let your creativity go wild, and your mood will go up.</p>
<blockquote>
<p>Are your working on too many things at the same time?</p>
</blockquote>
<p>Pursuing multiple things at the same time makes you feel like nothing moves forward. Often paired with getting frustrated and then feeling down.</p>
<p>Set your focus on one thing for now and work on that. The down feelings will fade.</p>
<blockquote>
<p>Do you have the feeling that you accomplished something?</p>
</blockquote>
<p>Sometimes we hustle and hustle but have the feeling we got nowhere. Just being tired and running towards a burnout.</p>
<p>Think about what small things you could add that make you feel to have accomplished something? Must not be work-related. It could also be private things you pushed for years in front of you.</p>
<h2>All Positive But Still Feeling Down?</h2>
<p>If you answered all questions positively and are still feeling down, it might be time to visit a therapist. There is no shame in that. We all need help sometimes.</p>
<p>Find someone near you or use an online service like <a href="https://www.talkspace.com/">talkspace</a>.</p>
                                     
                                     <hr>
                                     
                                                                          
                                     
                                       
                                       
                            </div>

                    </div></div>]]>
            </description>
            <link>https://mindfuldevmag.com/issues/issue-8-readers-questions/felling-down-figure-out-why-test</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660666</guid>
            <pubDate>Fri, 02 Oct 2020 09:17:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I can't write a JavaScript for loop, and it does not matter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660465">thread link</a>) | @slorber
<br/>
October 2, 2020 | https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj | <a href="https://web.archive.org/web/*/https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>I've been using JavaScript daily for 7 years, and I'm not able to remember the syntax of a JavaScript for loop.</p>
<p>Despite this fact, I'm a rather successful freelance developer. Recently I even had the awesome opportunity to work for Facebook, as the <a target="_blank" href="https://github.com/facebook/docusaurus/issues/2336">Docusaurus lead maintainer</a>, writing the code for the framework that powers the documentation sites of Babel, Prettier, Jest, ReactNative...</p>
<p>I'll explain why I'm not able to remember such syntax, and why it does not matter much.</p>
<hr>

<p><strong>TLDR</strong>: I'm a functional programmer</p>
<p>I've really started programming at the beginning of my engineer degree, around 2004 (before that, I was only able to hack some scripts for Counter-Strike console or IRC).</p>
<p>Most of our school teaching was based on Java, but we also saw a bit of C, C++, OCaml. </p>
<p>The first loop syntax I learned probably looked like this one:</p>
<pre><code>List&lt;Integer&gt; numbers = Lists.newArrayList(<span>1</span>, <span>2</span>, <span>3</span>);

<span>for</span> (<span>int</span> i = <span>0</span>; i &lt; numbers.length; i++) {
   System.out.println(numbers.get(i));
}
</code></pre>
<p>Before I came out of school, Java 6 brought some new, simpler syntax:</p>
<pre><code>List&lt;Integer&gt; numbers = Lists.newArrayList(<span>1</span>, <span>2</span>, <span>3</span>);

<span>for</span> (Integer number : numbers) {
   System.out.println(number);
}
</code></pre>
<p>At my first job, the <a target="_blank" href="https://github.com/google/guava">Google Guava</a> lib brought some new verbose functional syntax to Java, and I was able to do weird things with it üòÖ.</p>
<pre><code>List&lt;Integer&gt; numbers = Lists.newArrayList(<span>1</span>, <span>2</span>, <span>3</span>);

Lists.newArrayList(Collections2.transform(numbers, <span>new</span> Function&lt;Integer,Void&gt;() {
  <span>@Override</span>
  <span><span>public</span> Void <span>apply</span><span>(Integer number)</span> </span>{
    System.out.println(number);
    <span>return</span> <span>null</span>;
  }
}));
</code></pre>
<p>This Guava lib got me intrigued by functional programming, and lead me to become a Scala developer since 2012, and I was finally able to use functional programming concepts (loops, but not only) without the ugly Java/Guava syntax.</p>
<pre><code>val numbers = List(1, 2, 3)
numbers.foreach(println)
</code></pre>
<p>In 2013, <a target="_blank" href="https://reactjs.org/blog/2013/06/05/why-react.html">ReactJS came out</a>, and this totally changed my career path. At this time, I didn't like JavaScript much and was only able to hack some inline JQuery things in server-rendered pages. But as a startup CTO, I saw my team struggle with architecture, BackboneJS and RequireJS, and thought I had to become better at frontend to lead them.</p>
<p>AngularJS looked like the safer choice at this time, but a Scala developer colleague really pushed for React, which looked fancy and risky. All things made sense with the visionary post of David Nolen (<a target="_blank" href="https://swannodette.github.io/2013/12/17/the-future-of-javascript-mvcs/">The Future of JavaScript MVC Frameworks</a>), and we finally adopted React in January 2014, as it seemed we would be able to use our functional programming knowledge to the frontend app as well, and make the UI more predictable.</p>
<p>Fast forward, it wasn't easy to be a React early-adopter for our critical app. All companies were building their own state management solution, trying to figure things out, <a target="_blank" href="https://github.com/stample/atom-react">and so we did</a>, based on the ideas of David Nolen to hold a single immutable state in an atom (I was able to get a <a target="_blank" href="https://www.youtube.com/watch?v=zxN8FYYBcrI">hacky time-travel working</a> before Redux). </p>
<p>Since then both the JavaScript language and the ReactJS ecosystem have progressed a lot, and it's very common to use functional programming principles nowadays.</p>

<p>As a long-time functional programmer, <strong>I simply don't write for loops</strong> very often. </p>
<p>Like anything you don't use regularly, you end up forgetting the syntax.</p>
<p>Today, many of us use ES5+ syntax (or Lodash/Ramda...) and some functional constructs. Using <code>map</code>, <code>forEach</code>, <code>filter</code> are the most illustrated examples in the JS community.</p>
<pre><code><span>const</span> numbers = [<span>1</span>, <span>2</span>, <span>3</span>]
numbers.forEach(<span><span>number</span> =&gt;</span> <span>console</span>.log(number));
</code></pre>
<p>But we can go much further than that once we are more experienced with functional programming, and almost never write any for loops anymore. </p>
<p>Don't get me wrong, it's not necessarily a goal to not write for loops anymore, and I'm not telling you that you should remove all for loops of your production codebase.</p>
<p>Very often there's an alternative syntax possible for your loops that might be more expressive and easier to understand. After a while, you end up seeing a for loop as an implementation detail of a more elegant functional abstraction.</p>
<p>This more expressive syntax is not only for loops, and you can as well see a functional abstraction being an implementation detail of another higher-level abstraction.</p>
<p>Let's consider we want to increment the age of 2 brothers.</p>
<pre><code><span>const</span> brothers = {
  <span>id1</span>: {<span>name</span>: <span>"S√©bastien"</span>, <span>age</span>: <span>34</span>},
  <span>id2</span>: {<span>name</span>: <span>"Antoine"</span>, <span>age</span>: <span>23</span>}
};
</code></pre>
<p>I very often see the <code>array.reduce()</code> operator used when a more expressive alternative was possible.</p>
<pre><code><span><span>function</span> <span>incrementBrothersAges</span>(<span></span>) </span>{
  <span>return</span> <span>Object</span>.entries(brothers)
    .reduce(<span>(<span>acc,[id,brother]</span>) =&gt;</span> {
      acc[id] = {...brother, <span>age</span>: brother.age + <span>1</span>};
      <span>return</span> acc;  
    },{})
}
</code></pre>
<p>You know what? <strong>I really struggled to write this code</strong>. </p>
<p>My first attempt was not working at all (TypeScript would have helped).</p>
<pre><code><span><span>function</span> <span>incrementBrothersAges</span>(<span></span>) </span>{
  <span>return</span> <span>Object</span>.entries(brothers)
      
      .reduce(<span>(<span>[id,brother],  acc</span>) =&gt;</span> {
        acc[id] = {...brother, <span>age</span>: brother.age + <span>1</span>};
        
      },{});
}
</code></pre>
<p>Yet, writing this kind of transform is idiomatic for me, using higher-level functional programming abstractions, such as <code>mapValues</code> (included in lodash).</p>
<pre><code><span><span>function</span> <span>incrementBrothersAges</span>(<span></span>) </span>{
  <span>return</span> mapValues(
    brothers, 
    <span><span>brother</span> =&gt;</span> ({...brother, <span>age</span>: brother.age + <span>1</span>})
  );
}
</code></pre>
<p>And I think nobody would argue that this is harder to read and maintain right? If junior developers are not familiar with functional programming, they'll catch up fast and get used to it. This might even be harder to learn <code>reduce</code>.</p>

<p>I don't write for loops (or <code>reduce</code>), but I know the concepts. I know that these loops exist in different syntaxes, that can be useful for different use cases, and how to make a choice with a good tradeoff (performance, readability...).</p>
<p>I'll illustrate this with a concrete example from my daily work that actually led me to write this article.</p>
<p>I had this async function that performs some long task for a given country.</p>
<pre><code><span>async</span> <span><span>function</span> <span>runCountryTask</span>(<span>country</span>) </span>{

  
  <span>const</span> taskDuration = <span>1000</span> + <span>Math</span>.random() * <span>4000</span>;
  <span>await</span> <span>new</span> <span>Promise</span>(<span><span>resolve</span> =&gt;</span> <span>setTimeout</span>(resolve, taskDuration));

  <span>console</span>.log(<span>`Task completed for <span>${country}</span>`</span>);
}
</code></pre>
<p>This task had to be run for many countries, but the tasks should be run sequentially, not in parallel.</p>
<p>As I know the concepts, and I knew that the following would not work, as <code>Promise.all</code> would run all tasks in parallel.</p>
<pre><code><span>async</span> <span><span>function</span> <span>runAllCountryTasks</span>(<span></span>) </span>{
  <span>const</span> countries = [<span>"FR"</span>, <span>"EN"</span>, <span>"US"</span>, <span>"DE"</span>, <span>"UK"</span>, <span>"IT"</span>];

  
  <span>await</span> <span>Promise</span>.all(countries.map(runCountryTask))
}
</code></pre>
<p>I also knew that there were multiple possible solutions to solve this problem:</p>
<ul>
<li>use a third-party dependency exposing the higher-level async primitive I need</li>
<li>use <code>Promise.then()</code> recursively</li>
<li>use async/await, using a for loop syntax to iterate over a fixed-size array</li>
</ul>
<p>I didn't want to introduce a new third party dependency just for a tiny utility function. </p>
<p>I also knew that using <code>Promise.then()</code> recursively could be harder to read, write, and maintain. There are many ways to write such a recursion, one of them could be:</p>
<pre><code><span>async</span> <span><span>function</span> <span>forEachAsyncSequential</span>(<span>array, asyncFn</span>) </span>{
  <span>await</span> array.reduce(<span>(<span>acc, item</span>) =&gt;</span> {
    <span>return</span> acc.then(<span>() =&gt;</span> asyncFn(item))
  }, <span>Promise</span>.resolve());
}
</code></pre>
<p>So I opted for a basic for loop, as it seemed the right tradeoff. </p>
<p>As I'm totally unable to remember the syntax (<code>in</code> vs <code>of</code>, can I actually use <code>const</code>?), I had to actually google it, and it didn't take me long to be able to write the TypeScript code that will be shipped in production.</p>
<pre><code><span>export</span> <span>async</span> <span><span>function</span> <span>forEachAsyncSequencial</span>&lt;<span>T</span>&gt;(<span>
  array: T[],
  asyncFn: (t: T) =&gt; <span>Promise</span>&lt;<span>void</span>&gt;,
</span>): <span>Promise</span>&lt;<span>void</span>&gt; </span>{
  <span>for</span> (<span>const</span> item <span>of</span> array) {
    <span>await</span> asyncFn(item);
  }
}
</code></pre>
<pre><code><span>async</span> <span><span>function</span> <span>runAllCountryTasks</span>(<span></span>) </span>{
  <span>const</span> countries = [<span>"FR"</span>, <span>"EN"</span>, <span>"US"</span>, <span>"DE"</span>, <span>"UK"</span>, <span>"IT"</span>];

  
  <span>await</span> forEachAsyncSequencial(countries, runCountryTask);
}
</code></pre>
<p>Believe me or not, but I think It's the only for loop I actually wrote in JavaScript this year. And once it's written, I won't need to write it ever again (at least for this project), as it's now part of my functional programming abstractions, that I can reuse anywhere I need.</p>
<p><a target="_blank" href="https://jsfiddle.net/y17c6et8/1/">JsFiddle playground</a></p>
<hr>

<p>It's not very important to remember every syntax details to be productive in your daily work, particularly when you don't use them often (on purpose), as you prefer to work with more expressive, higher-level abstractions. </p>
<p>I had to google many things to write this article:</p>
<ul>
<li>Syntax for declaring a Java list</li>
<li>Syntax for iterating a Java list</li>
<li>Does <code>System.out.println</code> accept an Integer?</li>
<li>Syntax for Scala string interpolation</li>
<li>Is there a <code>forEach</code> in Guava (actually found <a target="_blank" href="https://stackoverflow.com/questions/38251257/guava-iterators-for-nested-foreach">my own StackOverflow question</a>)</li>
<li>What are the possible syntaxes for iterating over a JavaScript array</li>
<li>Signature of <code>array.reduce()</code></li>
</ul>
<p>Not remembering all this does not matter much, as long as I know what to look for.</p>
<p>In the same way, I don't know much about many other JavaScript things:</p>
<ul>
<li>prototypes: I think I never hard to use them directly in my entire life, and I'm fine</li>
<li>classes: used them temporarily when I really had to in React</li>
<li>JavaScript quirks: I know some of them, but simply avoid the others by using ESLint, <code>===</code>, TypeScript... it's not worth knowing all of them</li>
<li>...</li>
</ul>
<p>The knowledge and concepts you learn are more easily transposable from one language to another. I was able to learn React and contribute to its ecosystem quickly, thanks to my functional programming background. </p>
<p>I would argue that knowing how to do a recursive algorithm is more important than knowing the syntax of a for loop of a particular language. You will likely write many recursive algorithms in your career: the concept of recursion is not going anywhere anytime soon. But it's way more likely that you switch from one language to another from time to time. </p>
<p>Hopefully, writing this post will help me remember the syntax for a while until I forget it again ü§™.</p>
<hr>
<p>üôè If you like this post, please like it, share it or comment it üôè: </p>
<ul>
<li><a target="_blank" href="https://twitter.com/sebastienlorber/status/1311948662843551744">Tweet</a></li>
<li><a target="_blank" href="https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj">Hashnode</a></li>
<li><a target="_blank" href="https://dev.to/sebastienlorber/i-can-t-write-a-javascript-for-loop-and-it-does-not-matter-11jb">Dev</a></li>
<li><a target="_blank" href="https://www.reddit.com/r/javascript/comments/j3r08h/i_cant_write_a_javascript_for_loop_and_it_does/">Reddit</a></li>
<li><a target="_blank" href="https://news.ycombinator.com/item?id=24660465">HackerNews</a></li>
</ul>
<p>For more content like this, subscribe to <a target="_blank" href="https://mailchi.mp/4ea4df0b54f7/sebastienlorber">my mailing list</a> and follow me on <a target="_blank" href="https://twitter.com/sebastienlorber">Twitter</a>.</p>
</div></div>]]>
            </description>
            <link>https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660465</guid>
            <pubDate>Fri, 02 Oct 2020 08:41:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust programming language exploit mitigations]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24659489">thread link</a>) | @lukastyrychtr
<br/>
October 1, 2020 | https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/ | <a href="https://web.archive.org/web/*/https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>By  on <time itemprop="datePublished" datetime="2020-09-16T00:00:00-07:00">September 16, 2020</time>. <a href="https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/#disqus_thread" data-disqus-identifier="/2020/09/16/rust-lang-exploit-mitigations/"></a></p><div itemprop="articleBody">
    <p>The Rust programming language provides memory[1] and thread[2] safety
guarantees via its ownership[3], references and borrowing[4], and slice
types[5] features. However, Unsafe Rust[6] introduces unsafe blocks, unsafe
functions and methods, unsafe traits, and new types that are not subject to
the borrowing rules.</p>

<p>Parts of the Rust standard library are implemented as safe abstractions over
unsafe code (and historically have been vulnerable to memory corruption[7]).
Furthermore, the Rust code and documentation encourage creating safe
abstractions over unsafe code. This can cause a false sense of security if
unsafe code is not properly reviewed and tested.</p>

<p>Unsafe Rust introduces features that do not provide the same memory and
thread safety guarantees. This causes programs or libraries to be
susceptible to memory corruption (CWE-119)[8] and concurrency issues
(CWE-557)[9]. Modern C and C++ compilers provide exploit mitigations to
increase the difficulty to exploit vulnerabilities resulting from these
issues. Therefore, the Rust compiler must also support these exploit
mitigations in order to mitigate vulnerabilities resulting from the use of
Unsafe Rust. This post is going to document these exploit mitigations and
how they apply to Rust.</p>

<h2 id="exploit-mitigations">Exploit mitigations</h2>

<p>This section documents the exploit mitigations applicable to the Rust
compiler when building programs for the Linux operating system on the AMD64
architecture and equivalent.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> All examples in this section were
built using the Rust compiler version 1.40.0 (2019-12-19) on Debian testing
(Bullseye).</p>

<p>The Rust Programming Language currently has no specification. The Rust
compiler (i.e., rustc) is the language reference implementation. All
references to ‚Äúthe Rust compiler‚Äù in this post refer to the language
reference implementation.</p>

<p>Table I <br>
Summary of exploit mitigations supported by the Rust compiler when building
programs for the Linux operating system on the AMD64 architecture and
equivalent.</p>
<table>
  <tbody><tr>
   <td><strong>Exploit mitigation</strong>
   </td>
   <td><strong>Supported and enabled by default</strong>
   </td>
   <td><strong>Since</strong>
   </td>
  </tr>
  <tr>
   <td>Position-independent executable
   </td>
   <td>Yes
   </td>
   <td>0.12.0 (2014-10-09)
   </td>
  </tr>
  <tr>
   <td>Integer overflow checks
   </td>
   <td>Yes (enabled when debug assertions are enabled, and disabled when debug assertions are disabled)
   </td>
   <td>1.1.0 (2015-06-25)
   </td>
  </tr>
  <tr>
   <td>Non-executable memory regions
   </td>
   <td>Yes
   </td>
   <td>1.8.0 (2016-04-14)
   </td>
  </tr>
  <tr>
   <td>Stack clashing protection
   </td>
   <td>Yes
   </td>
   <td>1.20.0 (2017-08-31)
   </td>
  </tr>
  <tr>
   <td>Read-only relocations and immediate binding
   </td>
   <td>Yes
   </td>
   <td>1.21.0 (2017-10-12)
   </td>
  </tr>
  <tr>
   <td>Heap corruption protection
   </td>
   <td>Yes
   </td>
   <td>1.32.0 (2019-01-17) (via operating system default or specified allocator)
   </td>
  </tr>
  <tr>
   <td>Stack smashing protection
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Forward-edge control flow protection
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Backward-edge control flow protection (e.g., shadow and safe stack)
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
</tbody></table>

<p id="fn:1">1. See
<a href="https://github.com/rust-lang/rust/tree/master/compiler/rustc_target/src/spec">https://github.com/rust-lang/rust/tree/master/compiler/rustc_target/src/spec</a>
for a list of targets and their default options. <a href="#fnref:1" role="doc-backlink">‚Ü©</a></p>

<h3 id="position-independent-executable">Position-independent executable</h3>

<p>Position-independent executable increases the difficulty of the use of code
reuse exploitation techniques, such as return-oriented programming (ROP) and
variants, by generating position-independent code for the executable, and
instructing the dynamic linker to load it similarly to a shared object at a
random load address, thus also benefiting from address-space layout
randomization (ASLR). This is also referred to as ‚Äúfull ASLR‚Äù.</p>

<p>The Rust compiler supports position-independent executable, and enables it
by default since version 0.12.0 (2014-10-09)[10]‚Äì[13].</p>

<div><div><pre><code>$ readelf -h target/release/hello-rust | grep Type:
  Type:                              DYN (Shared object file)
</code></pre></div></div>
<p>Fig. 1.‚ÄÉChecking if an executable is a position-independent executable.</p>

<p>An executable with an object type of <code>ET_DYN</code> (i.e., shared object) and not
<code>ET_EXEC</code> (i.e., executable) is a position-independent executable (see Fig.
1).</p>

<h3 id="integer-overflow-checks">Integer overflow checks</h3>

<p>Integer overflow checks protects programs from undefined and unintended
behavior (which may cause vulnerabilities) by checking for results of signed
and unsigned integer computations that cannot be represented in their type,
resulting in an overflow or wraparound.</p>

<p>The Rust compiler supports integer overflow checks, and enables it when
debug assertions are enabled since version 1.0.0 (2015-05-15)[14]‚Äì[17], but
support for it was not completed until version 1.1.0 (2015-06-25)[16]. An
option to control integer overflow checks was later stabilized in version
1.17.0 (2017-04-27)[18]‚Äì[20].</p>

<div><div><pre><code><span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>u</span><span>:</span> <span>u8</span> <span>=</span> <span>255</span><span>;</span>
    <span>println!</span><span>(</span><span>"u: {}"</span><span>,</span> <span>u</span> <span>+</span> <span>1</span><span>);</span>
<span>}</span>
</code></pre></div></div>
<p>Fig. 2.‚ÄÉhello-rust-integer program.</p>

<div><div><pre><code>$ cargo run
   Compiling hello-rust-integer v0.1.0 (/home/rcvalle/hello-rust-integer)
    Finished dev [unoptimized + debuginfo] target(s) in 0.23s
     Running `target/debug/hello-rust-integer`
thread 'main' panicked at 'attempt to add with overflow', src/main.rs:3:23
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace.
</code></pre></div></div>
<p>Fig. 3.‚ÄÉBuild and execution of hello-rust-integer with debug assertions
enabled.</p>

<div><div><pre><code>$ cargo run --release
   Compiling hello-rust-integer v0.1.0 (/home/rcvalle/hello-rust-integer)
    Finished release [optimized] target(s) in 0.23s
     Running `target/release/hello-rust-integer`
u: 0
</code></pre></div></div>
<p>Fig. 4.‚ÄÉBuild and execution of hello-rust-integer with debug assertions
disabled.</p>

<p>Integer overflow checks are enabled when debug assertions are enabled (see
Fig. 3), and disabled when debug assertions are disabled (see Fig. 4). To
enable integer overflow checks independently, use the option to control
integer overflow checks, scoped attributes, or explicit checking methods
such as <code>checked_add</code><sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</p>

<p>It is recommended that explicit wrapping methods such as <code>wrapping_add</code> be
used when wrapping semantics are intended, and that explicit checking and
wrapping methods always be used when using Unsafe Rust.</p>

<p id="fn:2">2. See <a href="https://doc.rust-lang.org/std/primitive.u32.html">https://doc.rust-lang.org/std/primitive.u32.html</a> for more
information on the checked, overflowing, saturating, and wrapping methods
(using u32 as an example). <a href="#fnref:2" role="doc-backlink">‚Ü©</a></p>

<h3 id="non-executable-memory-regions">Non-executable memory regions</h3>

<p>Non-executable memory regions increase the difficulty of exploitation by
limiting the memory regions that can be used to execute arbitrary code. Most
modern processors provide support for the operating system to mark memory
regions as non executable, but it was previously emulated by software, such
as in grsecurity/PaX‚Äôs
<a href="https://pax.grsecurity.net/docs/pageexec.txt">PAGEEXEC</a> and
<a href="https://pax.grsecurity.net/docs/segmexec.txt">SEGMEXEC</a>, on processors that
did not provide support for it. This is also known as ‚ÄúNo Execute (NX) Bit‚Äù,
‚ÄúExecute Disable (XD) Bit‚Äù, ‚ÄúExecute Never (XN) Bit‚Äù, and others.</p>

<p>The Rust compiler supports non-executable memory regions, and enables it by
default since its initial release, version 0.1 (2012-01-20)[21], [22], but
has regressed since then[23]‚Äì[25], and enforced by default since version
1.8.0 (2016-04-14)[25].</p>

<div><div><pre><code>$ readelf -l target/release/hello-rust | grep -A 1 GNU_STACK
  GNU_STACK      0x0000000000000000 0x0000000000000000 0x0000000000000000
                 0x0000000000000000 0x0000000000000000  RW     0x10
</code></pre></div></div>
<p>Fig. 5.‚ÄÉChecking if non-executable memory regions are enabled for a given
binary.</p>

<p>The presence of an element of type <code>PT_GNU_STACK</code> in the program header
table with the <code>PF_X</code> (i.e., executable) flag unset indicates non-executable
memory regions<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> are enabled for a given binary (see Fig. 5).
Conversely, the presence of an element of type <code>PT_GNU_STACK</code> in the program
header table with the <code>PF_X</code> flag set or the absence of an element of type
<code>PT_GNU_STACK</code> in the program header table indicates non-executable memory
regions are not enabled for a given binary.</p>

<p id="fn:3">3. See the Appendix section for more information on why it affects other
memory regions besides the stack. <a href="#fnref:3" role="doc-backlink">‚Ü©</a></p>

<h3 id="stack-clashing-protection">Stack clashing protection</h3>

<p>Stack clashing protection protects the stack from overlapping with another
memory region‚Äîallowing arbitrary data in both to be overwritten using each
other‚Äîby reading from the stack pages as the stack grows to cause a page
fault when attempting to read from the guard page/region. This is also
referred to as ‚Äústack probes‚Äù or ‚Äústack probing‚Äù.</p>

<p>The Rust compiler supports stack clashing protection via stack probing, and
enables it by default since version 1.20.0 (2017-08-31)[26]‚Äì[29].</p>

<p><img src="https://rcvalle.blog/assets/2020/09/16/rust-lang-exploit-mitigations/image1.png" alt="Screenshot listing cross references to __rust_probestack in hello-rust." title="Cross references to __rust_probestack in hello-rust.">
Fig. 6. Cross references to <code>__rust_probestack</code> in hello-rust.</p>

<div><div><pre><code><span>fn</span> <span>hello</span><span>()</span> <span>{</span>
    <span>println!</span><span>(</span><span>"Hello, world!"</span><span>);</span>
<span>}</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>_</span><span>:</span> <span>[</span><span>u64</span><span>;</span> <span>1024</span><span>]</span> <span>=</span> <span>[</span><span>0</span><span>;</span> <span>1024</span><span>];</span>
    <span>hello</span><span>();</span>
<span>}</span>
</code></pre></div></div>
<p>Fig 7. Modified hello-rust.</p>

<p><img src="https://rcvalle.blog/assets/2020/09/16/rust-lang-exploit-mitigations/image2.png" alt="Screenshot listing cross references to __rust_probestack in modified hello-rust." title="Cross references to __rust_probestack in modified hello-rust.">
Fig. 8. Cross references to <code>__rust_probestack</code> in modified hello-rust.</p>

<p>To check if stack clashing protection is enabled for a given binary, search
for cross references to <code>__rust_probestack</code>. The <code>__rust_probestack</code> is
called in the prologue of functions whose stack size is larger than a page
size (see Fig. 6), and can be forced for illustration purposes by modifying
the hello-rust example as seen in Fig. 7 and Fig. 8.</p>

<h3 id="read-only-relocations-and-immediate-binding">Read-only relocations and immediate binding</h3>

<p><strong>Read-only relocations</strong> protect segments containing relocations and
relocation information (i.e., <code>.init_array</code>, <code>.fini_array</code>, <code>.dynamic</code>, and
<code>.got</code>) from being overwritten by marking these segments read only. This is
also referred to as ‚Äúpartial RELRO‚Äù.</p>

<p>The Rust compiler supports read-only relocations, and enables it by default
since version 1.21.0 (2017-10-12)[30], [31].</p>

<div><div><pre><code>$ readelf -l target/release/hello-rust | grep GNU_RELRO
  GNU_RELRO      0x000000000002ee00 0x000000000002fe00 0x000000000002fe00
</code></pre></div></div>
<p>Fig. 9.‚ÄÉChecking if read-only relocations is enabled for a given binary.</p>

<p>The presence of an element of type <code>PT_GNU_RELRO</code> in the program header
table indicates read-only relocations are enabled for a given binary (see
Fig. 9). Conversely, the absence of an element of type <code>PT_GNU_RELRO</code> in the
program header table indicates read-only relocations are not enabled for a
given binary.</p>

<p><strong>Immediate binding</strong> protects additional segments containing relocations
(i.e., <code>.got.plt</code>) from being overwritten by instructing the dynamic linker
to perform all relocations before transferring control to the program during
startup, so all segments containing relocations can be marked ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/">https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/</a></em></p>]]>
            </description>
            <link>https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24659489</guid>
            <pubDate>Fri, 02 Oct 2020 06:16:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interview with Transport Tycoon creator Chris Sawyer]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24658958">thread link</a>) | @wizardfeet
<br/>
October 1, 2020 | https://lifeandtimes.games/episodes/files/28 | <a href="https://web.archive.org/web/*/https://lifeandtimes.games/episodes/files/28">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://pdcn.co/e/traffic.megaphone.fm/ADL8847793182.mp3" target="_blank">Click/tap here to download this episode.</a></p><p><a href="https://ratethispodcast.com/ltvg" target="_blank"><img src="https://storage.googleapis.com/rtp-assets/buttons/lifetimevideogames.png" width="198" height="56" alt="Rate This Podcast"></a></p>
<p><img alt="A screenshot of the main menu from Transport Tycoon for DOS" src="https://lifeandtimes.games/episodes/files/transport-tycoon-dos-screenshot-main-menu.png" width="276" height="212"></p><p>On the rise and, um...<em>fade out(?)</em> of Chris Sawyer, the genius creator of bestselling, critically-acclaimed simulation games Transport Tycoon and RollerCoaster Tycoon ‚Äî who made a career out of working at the cutting-edge, in bare metal assembly code that he wrote and optimised (and optimised again) on his own.</p><p>Until the cutting-edge left him behind.</p><p><strong>Hello Hacker News readers! As of this update, the post there erroneously labels this as an interview. It's not. Chris doesn't do interviews, except via an intermediary (which doesn't really work in an audio format), so the story is based entirely on my in-depth research and analysis. I hope you still enjoy it and learn something interesting. (I have stories on many other things that do involve interviews, though, like </strong><strong><a href="https://lifeandtimes.games/episodes/files/27" title="Episodes:27 - Links">1990 golf game Links</a></strong><strong>, Bungie's </strong><strong><a href="https://lifeandtimes.games/episodes/files/25" title="Episodes:25 - Pimps at Sea">fake game Pimps at Sea</a></strong><strong>, and </strong><strong><a href="https://lifeandtimes.games/episodes/files/22" title="Episodes:22 - Wololo">the "Wololo" sound effect</a></strong><strong> from Age of Empires.)</strong></p><p>Chris was only a design consultant on 2004 game RollerCoaster Tycoon 3, but its remastered "Complete" edition has just come out on Nintendo Switch and the PC version is free on the Epic Games Store right now (until October 2). The original two games are also still sold via the likes of Steam and GOG.</p><p>Transport Tycoon, meanwhile, lives on in open-source project <a href="https://www.openttd.org/" target="_blank">OpenTTD</a> and in a mobile port (<a href="https://play.google.com/store/apps/details?id=com.thirtyonex.TransportTycoon&amp;hl=en_US" target="_blank">Android</a>, <a href="https://apps.apple.com/us/app/transport-tycoon/id634013256" target="_blank">iOS</a>) of the original game by Chris's company 31X. You can see a snippet of his source code in the image below:</p><div><p><img alt="cstg_code1" src="https://lifeandtimes.games/episodes/files/cstg_code1.jpg" width="1262" height="1775"></p></div><div><p>Thanks as always to my supporters on Patreon ‚Äî especially my $10+ backers Carey Clanton, Rob Eberhardt, Simon Moss, Vivek Mohan, Wade Tregaskis, and Seth Robinson. If you'd like to become a supporter, for as little as $1 a month, head to <a href="https://www.patreon.com/lifeandtimesofvideogames">my Patreon page</a> and sign up. Or for one-off donations you can use <a href="https://paypal.me/mossrc">paypal.me/mossrc</a>.</p><p>Please remember to tell other people about the show, and to leave a review by following the links at <a href="https://ratethispodcast.com/ltvg">ratethispodcast.com/ltvg</a>.</p><p>I'm currently writing a new book called Shareware Heroes: Independent Games at the Dawn of the Internet. You can learn more and/or pre-order your copy <a href="https://unbound.com/books/shareware-heroes/" target="_blank">from Unbound</a>.</p></div><hr>
<h3>(Partial) Transcript</h3>
<p><strong><em>[Most episode transcripts/scripts are reserved for my Patreon supporters (at least for the time being), but I like to give you at least a taster here ‚Äî or in this case, the first half of the episode.]</em></strong></p><p><em>Welcome to the Life and Times of Video Games, an audio series about video games and the video game industry, as they were in the past and how they‚Äôve come to be the way they are today. I'm Richard Moss, and this is episode 28, Transport Tycoon, or the tale of the great optimiser and his two greatest works.</em></p><p>We‚Äôll get going in just a moment. </p><p>*pause for pre-roll ad/cross-promo slot*</p><p>***</p><p>You may have heard the expression that every overnight sensation is a decade in the making ‚Äî a decade of hard work, toiling in obscurity‚Ä¶or <em>relative</em> obscurity, honing a talent, perfecting a craft, <em>optimising</em> a skill set and envisioning whatever it is that breaks through.</p><p>In reality the actual duration is rarely a decade ‚Äî it‚Äôs five years or eight years or eighteen years, or however long it takes for the pieces to all fall into place: the talent, timing, and product. But the idea bears repeating: the greatest accolades, the greatest achievements, the greatest games are the product of hard work built atop years of invisible labour.</p><p>And such it was that Chris Sawyer, like John Romero, Carol Shaw, Gunpei Yokoi, and many others before and since ‚Äî such it was that in 1994 Chris Sawyer suddenly shifted from a little-known (though well-respected) figure in the games industry, a programmer who converted Amiga games to the PC, to become an industry icon.</p><p>Nineteen-ninety-four was the year when his first original game was published, the year when big-name PC game publisher Microprose put his transportation-focused business simulation game Transport Tycoon, an incredible solo development effort, in a box and sold it in stores to widespread acclaim. </p><p><img alt="SCR1" src="https://lifeandtimes.games/episodes/files/scr1.jpg" width="866" height="362"><br><em>Transport Tycoon, the game that made Chris Sawyer into a games industry icon (</em><em><a href="https://www.tt-forums.net/viewtopic.php?f=47&amp;t=29058" target="_blank">image source</a></em><em>)</em><br></p><div><p>The game itself had taken Chris just a year to develop, but the journey to making it had begun much earlier.</p><p>Chris had started programming as a teenager in 1981, largely out of curiosity, through trying to make things appear on the screen on a range of different computers he‚Äôd encountered. There was the Commodore PET at his high school, the Sinclair ZX81 demonstration unit in a W H Smiths store, and the Texas Instruments TI99/4A one of his neighbours owned, as well as the Commodore VIC-20 a different neighbour had. And eventually, after diligently saving up his pocket money, he‚Äôd become engrossed in a machine of his own, a Camputers Lynx, a now-forgotten, obscure-even-then 8-bit computer with fancier graphics and more horsepower than the leading systems of its day (the leading systems at the time being the Apple II, ZX Spectrum, and Commodore 64).</p><p>Here, in 1983, is where the journey really starts ‚Äî where Chris set off towards the lands where he‚Äôd make his name. And I find it fascinating how serendipitous this was ‚Äî for, you see, Chris‚Äôs two great successes, Transport Tycoon and RollerCoaster Tycoon, were both made possible by his phenomenal systems knowledge; by his immense capacity to hand-code complex interactions of data at low levels of abstraction.</p><p>And here is where he began to learn those skills, to internalise them to the point of becoming natural talents. He later told Arcade Attack in an interview that he‚Äôd not had access to an assembler for that Lynx computer, so when he‚Äôd wanted to move beyond coding in BASIC he‚Äôd needed to write his programs byte-by-byte in machine code ‚Äî the lowest-level programming language, the numerical instructions that computers themselves use. And with scant resources available to teach him these skills, he mostly figured it out on his own, just trying different things until he got his ideas to work. Always chasing the next exhilarating breakthrough.</p><p>Chris continued to dabble in machine code, though somewhat less than before, when he upgraded to a similarly-obscure machine called the Memotech MTX500, which actually did come with a built-in assembler, which enabled him to write programs in the abbreviation-heavy Z80 assembly language. Programs that, beginning in 1984, he very often had published commercially.</p></div><p><img alt="Memotech_MTX500-wide" src="https://lifeandtimes.games/episodes/files/memotech_mtx500-wide.jpg" width="1020" height="584"><br><em>The Memotech MTX500 (</em><em><a href="https://en.wikipedia.org/wiki/File:Memotech_MTX500.jpg" target="_blank">Image source</a></em><em>)</em><br></p><div><p>Chris had sent Memotech cassette tapes of some games he‚Äôd made through copying the designs of popular titles, like Missile Kommand, which was the 1980 Atari arcade game converted to the capabilities of the MTX500, using a mix of BASIC and machine code, with the name intentionally misspelled (a ‚Äòk‚Äô rather than a ‚Äòc‚Äô) as though that somehow made his unapologetic, blatant clone of another‚Äôs work okay. </p><p>But this was the wild west of the computer games business, and Memotech weren‚Äôt much concerned. Or at least their games guy Jim Wills wasn‚Äôt much concerned, neither at this point nor a few months later when he left to start a company called Megastar Games. Jim liked Chris‚Äôs work enough to publish it, for meagre royalties but invaluable experience. And so Chris was commercially published with his unlicensed MTX500 versions of Missile Command, Q*bert, Manic Miner, and a few others.</p><p>After high school he enrolled in a computer science and microprocessor systems degree, where he studied the fundamentals of both software and hardware design in computers ‚Äî an experience he found invaluable, as it taught him how to push computers further by learning how their hardware worked. And it taught him the theories behind the sorts of nitty-gritty software-systems things he‚Äôd already been practising at home: optimisation, sorting, algorithms, and even more varieties of machine code.</p></div><p><img alt="escape-from-zarcos-memotech-mtx500" src="https://lifeandtimes.games/episodes/files/escape-from-zarcos-memotech-mtx500.png" width="1044" height="788"><em><br>Escape from Zarcos, Chris Sawyer clone of Manic Miner for the Memotech MTX500</em><br></p><div><p>At home, meanwhile, he‚Äôd shifted over to the Amstrad CPC, which technologically-speaking wasn‚Äôt hugely different to the Memotech system he‚Äôd been on before ‚Äî but it was a modest upgrade, and unlike his previous computers it was actually a popular system. And for Chris it was a gateway to the PC, because in the course of studying at university and making computer games on the side he wound up getting an Amstrad-made IBM-PC clone.</p><p>Chris had during this period been getting his games published through Ariolasoft, a German company with a UK subsidiary that promised him a job programming games for them once he graduated. Except some promises can‚Äôt be kept, especially in an industry that moves as fast as computer games publishing.</p><p>The home computer business was by that point deep into its transition from 8-bit to 16-bit hardware, and that transition came with adjustments to the standard of game graphics and design required, and to the way marketing and sales worked, and the cost of publishing, and so on, and Ariolasoft wasn‚Äôt doing too well at managing the transition. </p><p>So Chris didn‚Äôt have a job waiting for him after all, and he‚Äôd missed out on all the great electronics engineering jobs his classmates applied for. (Oops!) But not to worry ‚Äî he‚Äôd made enough connections and enough headway as a programmer that he could get himself a business agent, and that agent in turn connected him to the booming Amiga-to-PC games porting industry.</p><p>He later said he‚Äôd thought it a ‚Äústop-gap‚Äù measure, just ‚Äúa bit of fun‚Äù while he looked for more permanent employment in the electronics industry. But Chris took to his new conversions work like a duck to water. The kid who‚Äôd had to get creative and remain patient to make anything work on his Camputers Lynx machine now excelled in an environment where he had to contend with the vast gap in multimedia capabilities between the Amiga and the PC.</p><p>PCs of the day were pathetically inept as games machines, compared to a system like the Amiga. Whereas the PC had just a CPU, and maybe, in a minority of machines, a dedicated sound card like the SoundBlaster 16, every Amiga came with a custom chipset that contained audio and video co-processors that could take some strain off the ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lifeandtimes.games/episodes/files/28">https://lifeandtimes.games/episodes/files/28</a></em></p>]]>
            </description>
            <link>https://lifeandtimes.games/episodes/files/28</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658958</guid>
            <pubDate>Fri, 02 Oct 2020 04:45:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Jargon File]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24658797">thread link</a>) | @purec
<br/>
October 1, 2020 | http://jargon-file.org/archive/jargon-4.4.7.dos.txt | <a href="https://web.archive.org/web/*/http://jargon-file.org/archive/jargon-4.4.7.dos.txt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://jargon-file.org/archive/jargon-4.4.7.dos.txt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658797</guid>
            <pubDate>Fri, 02 Oct 2020 04:12:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: How to compute a factorial with Œª calculus in a post card]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24658404">thread link</a>) | @martyalain
<br/>
October 1, 2020 | http://lambdaway.free.fr/lambdawalks/?view=lambdafact | <a href="https://web.archive.org/web/*/http://lambdaway.free.fr/lambdawalks/?view=lambdafact">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://lambdaway.free.fr/lambdawalks/?view=lambdafact</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658404</guid>
            <pubDate>Fri, 02 Oct 2020 03:10:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big O, Little N]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24657747">thread link</a>) | @adamzerner
<br/>
October 1, 2020 | https://adamzerner.bearblog.dev/big-o-little-n/ | <a href="https://web.archive.org/web/*/https://adamzerner.bearblog.dev/big-o-little-n/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p>I remember when I was first learning about hash tables. I thought I stumbled across an ingenious optimization for dealing with hash collisions. Before explaining my optimization, let me first briefly explain how hash tables work and what hash collisions are. I also made a video if you're interested.</p>
<p><a href="http://www.youtube.com/watch?v=pM9zhZB2KkM" title="Hash Tables"><img alt="" src="http://img.youtube.com/vi/pM9zhZB2KkM/0.jpg"></a></p>
<p>Say that we have a hash that maps someone's name to their age. <code>"adam"</code> is <code>27</code>, so we want to enter that into our hash.</p>
<p><img alt="" src="https://i.ibb.co/qWdjbhM/Slice.png"></p>
<p>Here's what happens:</p>
<ul>
<li><code>"adam"</code> gets put through a hash function.</li>
<li>The hash function spits out <code>7</code>.</li>
<li><code>7</code> is the index of the array where we are going to store <code>"adam"</code>'s value.</li>
<li>So we store <code>27</code> into <code>array[7]</code>.</li>
</ul>
<p>If we run <code>hash.get("adam")</code> in the future and need to look up the value for <code>"adam"</code>, we:</p>
<ul>
<li>Run <code>"adam"</code> through the hash function.</li>
<li>Get <code>7</code> as the output.</li>
<li>This means we have to look at <code>array[7]</code> to get the value.</li>
<li>So we look at <code>array[7]</code> to get our value.</li>
</ul>
<p>Hopefully if we have a key of <code>"alice"</code> or <code>"bob"</code> it'll hash to a different index. But... what happens if it hashes to the same index? That's called a hash collision.</p>
<p><img alt="" src="https://i.ibb.co/sJbJKnD/Slice.png"></p>
<p>A common approach is that if there's a collision, you store the values in a linked list.</p>
<p><img alt="" src="https://i.ibb.co/VJsSW3T/Slice.png"></p>
<p>Fair enough. That makes sense.</p>
<p>But wait!!! It takes <code>O(n)</code> time to look up a value in a linked list. Can't we use a binary search tree to speed that up to <code>O(log n)</code>???</p>
<p><img alt="" src="https://i.ibb.co/R3Vrc10/Slice.png"></p>
<p>Or... can't we take it a step further and use a <em>hash inside of a hash</em> to get the lookup time all the way down to <code>O(1)</code>?!</p>
<p><img alt="" src="https://i.ibb.co/7CyYNWY/Slice.png"></p>
<p>I hate to say it, but however many years ago when I had these thoughts, there were a few moments where I thought I was a genius. Now when I look back at that former self, I facepalm.</p>
<p>It is true that going from a linked list to a BST to a hash takes you from <code>O(n)</code> to <code>O(logn)</code> to <code>O(1)</code> lookup time. However, since collisions are rare, <code>n</code> is going to be small. And when <code>n</code> is small, <code>O(n)</code> might be faster than <code>O(1)</code>.</p>
<p>To understand why that is, think back to what Big-O really means. I think it helps to think about it as a "math thing" instead of a "programming thing". Consider two functions:</p>
<pre><code>f(n) = 4n + 1000
g(n) = 2n^2 + 5
</code></pre>
<p>Big-O of <code>f</code> is <code>O(n)</code> and Big-O of <code>g</code> is <code>O(n^2)</code>. We just focus on the part that "really matters". When <code>n</code> gets really big, the fact that it's <code>4n</code> doesn't really matter. Nor does the <code>+ 1000</code>.</p>
<p>But what about when <code>n</code> is small? Well, let's look at happens when <code>n</code> is <code>5</code>:</p>
<pre><code>f(5) = 4(5) + 1000 = 20 + 1000 = 1020
g(5) = 2(5^2) + 5 = 2(25) + 5 = 50 + 5 = 55
</code></pre>
<p>Look at that! The <code>O(n^2)</code> function is almost 20 times faster than the <code>O(n)</code> function!</p>
<p>And <em>that</em> is basically why they use a linked list instead of a BST or hash to handle collisions. Since <code>n</code> is small, Big-O isn't the right question to ask.</p>
<hr>
<p>Here's another example. I just wrote the following code while prepping for an interview:</p>
<pre><code>const isVowel = (char) =&gt; ["a", "e", "i", "o", "u"].includes(char);
</code></pre>
<p>Normally I wouldn't think twice about it, but since interviewers care so much about time complexity, I stopped to think about whether it could be improved.</p>
<p>And it hit me that it's actually <code>O(n)</code>, because we've got an array and have to iterate over every element to see if the element matches <code>char</code>. It's easy to overlook this because we're using <code>includes</code> and not writing the code ourselves.</p>
<p>So then I thought that maybe we could use a hash instead to get <code>O(1)</code> lookup. Something like this:</p>
<pre><code>const isVowel = (char) =&gt; {
  const vowels = {
    a: true,
    e: true,
    i: true,
    o: true,
    u: true,
  };

  return !!vowels[char];
};
</code></pre>
<p>But then I realized that this is the same mistake I made with the hash collision stuff however many years ago. <em><code>n</code> is small, so Big-O isn't the question we should be asking</em>. Here <code>n</code> is <code>5</code>.</p>
<p>I think that the array approach would actually be faster than the hash approach, even though it's <code>O(n)</code> instead of <code>O(1)</code>. The reason for this is called locality.</p>
<p>If you dive deep under the hood, when you look up an element in an array, the CPU actually grabs a bunch of adjacent elements as well as the one you wanted, and it stores the adjacent elements in a cache. So here when we look up <code>"a"</code> in the array, it'll probably grab <code>"a"</code>, <code>"e"</code>, <code>"i"</code>, <code>"o"</code>, and <code>"u"</code>. And so next time when we want to grab <code>"e"</code>, it can take it from the cache, which is a lot faster. This works because the elements in the array are close to each other in the physical memory. But with a hash, my understanding is that they wouldn't be so close, and thus we wouldn't benefit from this spatial locality effect.</p>
<p>I'm no low-level programming wiz so I'm not sure about any of this. That's ok, I think it's beside the point of this post. The real point of this post is that when you have a little <code>n</code>, Big-O doesn't matter.</p>
</div>
</div></div>]]>
            </description>
            <link>https://adamzerner.bearblog.dev/big-o-little-n/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657747</guid>
            <pubDate>Fri, 02 Oct 2020 00:59:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Designer's Guide to JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24657624">thread link</a>) | @philipcdavis
<br/>
October 1, 2020 | https://react.design/javascript | <a href="https://web.archive.org/web/*/https://react.design/javascript">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>You can learn the basics of JavaScript quickly. You don't need a engineering degree, or a front end bootcamp.</p><p>Learning the basics of JavaScript is enough to get started with modern frameworks like React.js. Once you know the basics, you can do some truly amazing things.</p><p>You can quickly spin up interactive prototypes.<br>You can use live data sets.<br>You can create web, mobile, and desktop apps.<br>You can define interfaces in high fidelity.<br>You can write scripts to automate daily tasks.<br>You can make plugins for design tools like Sketch and Figma.<br>You can build with modern frameworks like React.js.</p><p>You can't learn JavaScript in a day, but you can learn it quickly. The best way to learn is to build. This guide is meant to give you enough information to start building. </p><h2>Editor</h2><p><img src="https://react.design/assets/javascript/theme.png">
</p><p>Before we write any code, it's a good idea to get comfortable with your text editor. I'd recommend using a text editor like <a href="https://code.visualstudio.com/">VSCode</a>, or <a href="https://atom.io/">Atom</a> as you write JavaScript. They're both free and support lots of plugins to make things easier. You can also find lots of nice themes. Here's a <a href="https://marketplace.visualstudio.com/items?itemName=Framer.framer-syntax">theme</a> for VSCode that I like.</p><p>Learning keyboard shortcuts, and customizing the look of your editor will make for a much more enjoyable coding experience.</p><h2>Setup</h2><p>JavaScript is a scripting language that for our intents and purposes, will be executed by the browser.</p><p>There are multiple ways to include javascript inside your webpage. The way we will use javascript will be by including <code>&lt;script&gt;</code> tags right before the closing <code>&lt;/body&gt;</code> tag. </p><pre><code><span>&lt;!</span><span>DOCTYPE</span><span> </span><span>html</span><span>&gt;</span><span>
</span><span></span><span>&lt;</span><span>html</span><span>&gt;</span><span>
</span><span>  </span><span>&lt;</span><span>head</span><span>&gt;</span><span>&lt;/</span><span>head</span><span>&gt;</span><span>
</span><span>  </span><span>&lt;</span><span>body</span><span>&gt;</span><span>
</span>    
<span>    </span><span>&lt;</span><span>script</span><span>&gt;</span><span>
</span><span>        </span><span>// Javascript will go here</span><span>
</span><span>        </span><span>console</span><span>.</span><span>log</span><span>(</span><span>"Hello friend!"</span><span>)</span><span>
</span><span>    </span><span>&lt;/</span><span>script</span><span>&gt;</span><span>
</span><span>  </span><span>&lt;/</span><span>body</span><span>&gt;</span><span>
</span><span></span><span>&lt;/</span><span>html</span><span>&gt;</span></code></pre><p>We√¢‚Ç¨‚Ñ¢ll put our javascript inside here, but we could also reference an external file.
<code>console.log()</code> is a helpful tool for debugging. Here I'm writing "Hello Friend!" To the console. You an access the console in Chrome using the <code>CMD+Option+J</code> shortcut.</p><p><img src="https://react.design/assets/javascript/console.png">
</p><p>There are 5 core concepts in JavaScript that are important to understand.</p><p><strong>1. Variables</strong><br><strong>2. Data Structures</strong><br><strong>3. Loops</strong><br><strong>4. Conditionals</strong><br><strong>5. Functions</strong></p><h2>Variables</h2><p>Variables are containers that hold values. These values can take lots of different forms. If you wanted a variable to hold a number you could write it as <code>var num = 20;</code>. If I use <code>console.log(num)</code> it should show me the number twenty.</p><p>Variables can be referenced later. <code>var double = num * 2; // 40</code></p><p>Variables can hold lots of different data types. I want to discuss a few different common ways to hold data. There are primitive data types like numbers, which we used earlier, There are strings, which are just a way to store text, and booleans which are values that are either true or false.</p><pre><code><span>var</span><span> days </span><span>=</span><span> </span><span>40</span><span>;</span><span> </span><span>// Number</span><span>
</span><span></span><span>var</span><span> label </span><span>=</span><span> </span><span>"Hello"</span><span>;</span><span> </span><span>// String</span><span>
</span><span></span><span>var</span><span> hidden </span><span>=</span><span> </span><span>true</span><span>;</span><span> </span><span>// Boolean</span></code></pre><h2>Data Structures</h2><p>In addition to primitive data types there are others that have more complex structures. Two of these important types are objects (sometimes called object literals) and arrays. </p><p>Objects can be defined using curly braces. 
<code>var obj = {}</code></p><p>What goes inside the curly braces are a collection of key value pairs. The key goes first, followed by a colon, and then the value. </p><pre><code><span>var</span><span> obj </span><span>=</span><span> </span><span>{</span><span>
</span><span>  key</span><span>:</span><span> value
</span><span></span><span>}</span></code></pre><p>Keys are labels that help you find the data you want to store. Keys in a single object must be unique. Values can be any data type. Numbers, strings, arrays, and even other objects. 
Here's an example Object with multiple key value pairs in action:</p><pre><code><span>var</span><span> profile </span><span>=</span><span> </span><span>{</span><span>
</span><span>	name</span><span>:</span><span> </span><span>'Philip'</span><span>,</span><span> 
</span><span>	age</span><span>:</span><span> </span><span>25</span><span>,</span><span> 
</span><span>	contact</span><span>:</span><span> </span><span>{</span><span>
</span><span>		twitter</span><span>:</span><span> </span><span>'philipcdavis'</span><span>,</span><span> 
</span><span>		email</span><span>:</span><span> </span><span>'reactfordesigners@gmail.com'</span><span>
</span><span>	</span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Name, age, contact, twitter, and email are all different keys in this object. The values are all different and many have different value types. Some are strings, some are numbers, and some are other objects.</p><p>This nested structure is common and you will see it a lot when working with data sets.</p><p>There are two ways to access a value inside an object. The first way is sometimes called dot notation: <code>profile.name</code>. The second way is by using brackets <code>profile['name']</code>. Bracket notion is useful when your key name is dynamic.</p><p>The other data type that√¢‚Ç¨‚Ñ¢s important to know about is the Array. You define an array with square brackets. </p><p><code>var myArr = [];</code></p><p>You can store any type of data inside these arrays and they don't need to all be the same type (though they usually are). An example array might look like this: </p><pre><code><span>var</span><span> teams </span><span>=</span><span> </span><span>[</span><span>'lakers'</span><span>,</span><span> </span><span>'nuggets'</span><span>,</span><span> </span><span>'rockets'</span><span>]</span><span>;</span></code></pre><p>Instead of using keys, arrays use a built in index to keep track of location. The index of arrays starts at 0. If we wanted to access the second value of this array (nuggets) we could do so by typing <code>teams[1];</code></p><p>If your data was as simple as this, using objects and arrays might seem unnecessary. They start to shine when you have data sets that are larger. To work with more data, we'll probably want to use a loop</p><h2>Loops</h2><p>Loops enable you to run a block of code multiple times. You can use a loop with objects and arrays to execute a block of code on each item in the structure. </p><p>To loop through each value in an array you can use a for loop that executes a block. </p><pre><code><span>for</span><span> </span><span>(</span><span>var</span><span> i</span><span>=</span><span>0</span><span>;</span><span> i</span><span>&lt;</span><span>teams</span><span>.</span><span>length</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>// Block to be executed</span><span>
</span><span></span><span>}</span></code></pre><p>What goes into the parenthesis determines how many times the block of code is executed. The first value is a counter variable. <code>i</code> is often used to refer to the fact that it's used as the index value of the array. We will start the counter at 0. </p><p>The next value is called the conditional. Once the conditional is false, the loop will end. We can set the value to be <code>i &lt; teams.length</code>. The <code>.length</code> is a helper value built into every array that will tell you how many items are in the array. Once the value of the counter is as great as the length of the array, we can stop looping. The last value <code>i++</code> is what we want to happen after our loop runs. We want our counter to increase in value by one every time the loop runs.</p><p>If we log a string, you can see that it will print out 4 times.
If we log the value i, you can see that it increments up. If you combine this incremented value i with our array, you can see how we can access each value in our array.</p><pre><code><span>for</span><span> </span><span>(</span><span>var</span><span> i</span><span>=</span><span>0</span><span>;</span><span>i</span><span>&lt;</span><span>teams</span><span>.</span><span>length</span><span>;</span><span>i</span><span>++</span><span>)</span><span> </span><span>{</span><span> 
</span><span>	</span><span>console</span><span>.</span><span>log</span><span>(</span><span>teams</span><span>[</span><span>i</span><span>]</span><span>)</span><span>
</span><span></span><span>}</span><span>;</span></code></pre><p>There are other types of loops but they all are doing something pretty similar, running a block of code multiple times. That√¢‚Ç¨‚Ñ¢s the essential work of a loop.</p><h2>Conditionals</h2><p>Next up on our list is conditionals. The most common type of conditional is the if/else statement. </p><pre><code><span>if</span><span> </span><span>(</span><span>conditional</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>console</span><span>.</span><span>log</span><span>(</span><span>'the conditional evaluated to true'</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span>
</span><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>'the conditional evaluated to false'</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span></code></pre><p>If the <code>conditional</code> value in the parenthesis evaluates to true, the block inside the first set of curly brackets is run, otherwise the else block is run.</p><p>Let√¢‚Ç¨‚Ñ¢s use it in combination with our loop to log only the first two items in our array. Because we don√¢‚Ç¨‚Ñ¢t need the else here, we can remove it, and we√¢‚Ç¨‚Ñ¢ll get the same result.</p><pre><code><span>for</span><span> </span><span>(</span><span>var</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i</span><span>&lt;</span><span>teams</span><span>.</span><span>length</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>if</span><span> </span><span>(</span><span>i </span><span>&lt;</span><span> </span><span>2</span><span>)</span><span> </span><span>{</span><span>
</span><span>	  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>teams</span><span>[</span><span>i</span><span>]</span><span>)</span><span>;</span><span>
</span><span>	</span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>You√¢‚Ç¨‚Ñ¢ll use these conditionals to to control what gets executed when.</p><h2>Functions</h2><p>Functions allow you to create reusable and modular code.</p><p>Another way to say it is that they are blocks of code than can be executed whenever they are needed. </p><p>Here's what one looks like</p><pre><code><span>function</span><span> </span><span>add</span><span> </span><span>(</span><span>a</span><span>,</span><span> b</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>var</span><span> total </span><span>=</span><span> a </span><span>+</span><span> b</span><span>;</span><span>
</span><span>	</span><span>return</span><span> total</span><span>;</span><span>
</span><span></span><span>}</span><span> </span></code></pre><p>Here we have a simple function that takes two input values, adds them together, and then returns the total. We√¢‚Ç¨‚Ñ¢ll use generic names for our input arguments. You can name these pretty much whatever you want, but they will be used within our block so if your function is complex, it√¢‚Ç¨‚Ñ¢s good to have descriptive names. Because this is a pretty simple function we're using <code>a</code> and <code>b</code>. </p><p>What we've created is a function declaration. In order to execute, or invoke our function we can call <code>add(2,50)</code>.
<code>console.log(add(2,50)) // 52</code></p><p><code>console.log</code> is itself a function. Functions can be stored in variables, objects, arrays, or even passed into other functions.</p><p>One other important thing to note about functions is how they affect variables inside them. If you define a variable within a function, the variable cannot be used outside the function. That's because javascript has a function based scope.</p><hr><p>Javascript is a really fun language to learn. If you feel comfortable with the material above you can do a lot! Most of JavaScript is just building on to these core concepts.</p><h2>Modern JavaScript</h2><p>In 2015 a set of new syntax and features were introduced that made writing JavaScript easier. Many of the following updates are meant to help you write code faster and cleaner. If you're using modern frameworks like React you'll often see them in examples.</p><h3>Const / Let</h3><p>This is just a new way to write variables. </p><pre><code><span>const</span><span> height </span><span>=</span><span> </span><span>30</span><span>;</span><span>
</span><span></span><span>let</span><span> height </span><span>=</span><span> </span><span>30</span><span>;</span></code></pre><p><code>const</code> values cannot be reassigned after the initial assignment. This is usually the default way of creating variables. </p><p><code>let</code> values can be reassigned but are scoped to conditionals, the same way all variables are scoped to functions. If you declare one inside an if/else statement it won't be available outside the statement.</p><h3>Arrow Functions</h3><p>This a shorthand for writing functions.
Instead of writing:</p><pre><code><span>const</span><span> </span><span>add</span><span> </span><span>=</span><span> </span><span>function</span><span>(</span><span>a</span><span>,</span><span>b</span><span>)</span><span>{</span><span> </span><span>return</span><span> a </span><span>+</span><span> b </span><span>}</span></code></pre><p>You can use an arrow function which looks like this:</p><pre><code><span>const</span><span> </span><span>add</span><span> </span><span>=</span><span> </span><span>(</span><span>a</span><span>,</span><span>b</span><span>)</span><span> </span><span>=&gt;</span><span> a </span><span>+</span><span> b</span></code></pre><p>If your function takes a single parameter you can omit the parenthesis.</p><pre><code><span>const</span><span> </span><span>getStyle</span><span> </span><span>=</span><span> </span><span>a</span><span> </span><span>=&gt;</span><span> a</span><span>.</span><span>style</span></code></pre><h3>Template Literals</h3><p>Previously is you wanted dynamic strings, you would insert values using the following syntax.</p><pre><code><span>const</span><span> dynamicString </span><span>=</span><span> </span><span>"Hello my name is"</span><span> </span><span>+</span><span> firstName </span><span>+</span><span> </span><span>". Welcome!"</span></code></pre><p>Using template literals, you can use the backtick for strings, and <code>${}</code> to insert variables.</p><pre><code><span>const</span><span> dynamicString </span><span>=</span><span> </span><span>`</span><span>Hello my name is </span><span>${</span><span>firstName</span><span>}</span><span>. Welcome!</span><span>`</span></code></pre><h3>Imports and Exports</h3><p>Instead of using large javascript files, you'll often want to break your code into smaller modules and export anything that other modules need to access.</p><pre><code><span>// Colors.js</span><span>
</span><span></span><span>export</span><span> </span><span>const</span><span> colors </span><span>=</span><span> </span><span>{</span><span>
</span><span>	blue</span><span>:</span><span> </span><span>"#EA3232"</span><span>,</span><span>
</span><span>	red</span><span>:</span><span> </span><span>"#4062F3"</span><span>,</span><span>
</span><span>	yellow</span><span>:</span><span> </span><span>"#FFAD05"</span><span>,</span><span>
</span><span></span><span>}</span></code></pre><p>In a different file you can import these colors using the following syntax.</p><pre><code><span>import</span><span> </span><span>{</span><span>colors</span><span>}</span><span> </span><span>from</span><span> </span><span>'./Color'</span></code></pre><p>You can also define default exports ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://react.design/javascript">https://react.design/javascript</a></em></p>]]>
            </description>
            <link>https://react.design/javascript</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657624</guid>
            <pubDate>Fri, 02 Oct 2020 00:32:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatic-Differentiation-Worked-Examples]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24657571">thread link</a>) | @formalsystem
<br/>
October 1, 2020 | http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/ | <a href="https://web.archive.org/web/*/http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <h3>automatic-differentiation-worked-examples</h3>
  
<p>‚Äì forwards and reverse</p>
<h2 id="introduction">Introduction</h2>
<p>This article demonstrates how to perform source transformations on a program to generate forward mode and reverse mode derivative programs (automatic differentiation, or ‚ÄúAD‚Äù). My aim is to write the shortest possible article that communicates all the essential features of a source-to-source AD system with a particular focus on making the reverse mode transformation clear.</p>
<p>The goal of brevity means that a lot of possible commentary has been omitted. If you find this makes some part of the article hard to understand then please <a href="http://web.jaguarpaw.co.uk/~tom/contact">contact me</a> and I‚Äôll do my best to clarify. In particular this article contains hardly any mathematical content at all. I hope that the reader who is familiar with multivariate calculus will be able to obtain an intuitive understanding of how AD relates to mathematical techniques he or she is already familiar with. A more in-depth description of the relationship will have to wait for another article.</p>
<h2 id="the-program">The program</h2>
<p>Let‚Äôs consider the following pseudocode program that performs some elementary arithmetic through a sequence of assignment statements.</p>
<pre><code>p = 7 * x
r = 1 / y
q = p * x * 5
v = 2 * p * q + 3 * r</code></pre>
<p><code>x</code> and <code>y</code> are not defined in the program so I‚Äôm going to informally consider them to be ‚Äúinputs‚Äù; <code>v</code> is not used anywhere so I‚Äôm going to consider it to be the ‚Äúoutput‚Äù. (I won‚Äôt burden the article by formalising these notions here.)</p>
<h2 id="preparation">Preparation</h2>
<p>We‚Äôll do a small amount of preparation to our original program which will preserve its behaviour and get it into a form in which it is straightforward to apply the automatic differentiation (AD) algorithms. It is possible to apply AD algorithms without doing these transformations first but then the AD algorithms would have to do equivalent operations implicitly. Doing these transformations first is a kind of <a href="https://en.wikipedia.org/wiki/Separation_of_concerns">separation of concerns</a>.</p>
<h3 id="use-prefix-functions-with-exactly-one-argument">Use prefix functions with exactly one argument</h3>
<p>Let‚Äôs use prefix functions instead of <a href="https://en.wikipedia.org/wiki/Infix_notation">infix operators</a>. Infix operators are more familiar for arithmetic but the AD algorithms will be clearer to present if we use prefix functions. Additionally I want every function to have exactly one argument (although that argument may be a tuple). Single-argument style will make the reverse mode transformation much clearer (although it does not make any difference for forward mode). For example, <code>x1 + x2</code> would become <code>add (x1, x2)</code>. Our program becomes</p>
<pre><code>p = mul (7, x)
r = div (1, y)
q = mul (mul (p, x), 5)
v = add (mul (mul (2, p), q), mul (3, r))</code></pre>
<h3 id="no-nested-subexpressions">No nested subexpressions</h3>
<p>Next let‚Äôs convert to a form where every function is applied to (tuples of) variables and constants only, i.e.&nbsp;where there are no nested sub-expressions (besides potentially nested tuples). We assign each nested sub-expression to an intermediate variable. For example</p>
<pre><code>a = add (add (b, c), d)</code></pre>
<p>would become</p>
<pre><code>i = add (b, c)
a = add (i, d)</code></pre>
<p>The choice of <code>i</code> is arbitrary; it just has to be a variable that‚Äôs not used elsewhere in our program. This form without nested subexpressions is a lot like <a href="https://en.wikipedia.org/wiki/A-normal_form">ANF</a> from the field of functional compiler construction. It‚Äôs also a lot like the <a href="https://en.wikipedia.org/wiki/Static_single_assignment_form">SSA form</a> of assembly language. After removing nested subexpressions, our program becomes</p>
<pre><code>p = mul (7, x)
r = div (1, y)
i1 = mul (p, x)
q = mul (i1, 5)
i2 = mul (2, p)
i3 = mul (i2, q)
i4 = mul (3, r)
v = add (i3, i4)</code></pre>
<h2 id="differentiation-line-by-line">Differentiation line-by-line</h2>
<p>We have performed all the transformations needed to prepare our program and we are ready to proceed to differentiation. We will differentiate the program line-by-line, that is, both the forward mode and reverse mode differentiation algorithms will generate one line of derivative code for each line of input code. But what <em>is</em> the derivative of an assignment statement? For forward mode, the derivatives correspond quite closely to what you might be familiar with from a first multivariate calculus course..</p>
<h3 id="examples">Examples</h3>
<h4 id="addition">Addition</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = add (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>dy = add (dx1, dx2)</code></pre>
<h4 id="multiplication">Multiplication</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = mul (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>dy = add (mul (x2, dx1), mul (x1, dx2))</code></pre>
<h4 id="division">Division</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = div (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>dy = add (div (dx1, x2), negate (mul (div (x1, mul (x2, x2)), dx2)))</code></pre>
<h2 id="forward-mode">Forward mode</h2>
<p>The forward mode transformation applies the appropriate differentiation rule to each line in the input program (listed on the left) to obtain a derivative line (listed on the right). To each line we apply exactly one rule and the form of the rule does not depend on any of the other lines.</p>
<pre><code>p = mul (7, x)   | dp = mul (7, dx)
r = div (1, y)   | dr = negate (div (dy, mul (y, y)))
i1 = mul (p, x)  | di1 = add (mul (dp, x), mul (p, dx))
q = mul (i1, 5)  | dq = mul (di1, 5)
i2 = mul (2, p)  | di2 = mul (2, dp)
i3 = mul (i2, q) | di3 = add (mul (di2, q), mul (i2, dq))
i4 = mul (3, r)  | di4 = mul (3, dr)
v = add (i3, i4) | dv = add (di3, di4)</code></pre>
<p>If we form a new program consisting of the sequence of assignments on the left followed by the sequence of assignments on the right then we have a program that calculates the forward derivative! The ‚Äúinputs‚Äù of this program are <code>x</code>, <code>y</code>, <code>dx</code> and <code>dy</code>. The ‚Äúoutputs‚Äù are <code>v</code> and <code>dv</code>.</p>
<p>(The derivatives of constants are zero and I‚Äôve left terms that are zero out for simplicity.)</p>
<p>In fact we can be a little more clever. We can interleave the assignments, so an assignment from the left is immediately followed by its corresponding assignment from the right, that is</p>
<pre><code>p = mul (7, x)
dp = mul (7, dx)
r = div (1, y)
dr = negate (div (dy, mul (y, y)))
i1 = mul (p, x)
di1 = add (mul (dp, x), mul (p, dx))
q = mul (i1, 5)
dq = mul (di1, 5)
i2 = mul (2, p)
di2 = mul (2, dp)
i3 = mul (i2, q)
di3 = add (mul (di2, q), mul (i2, dq))
i4 = mul (3, r)
di4 = mul (3, dr)
v = add (i3, i4)
dv = add (di3, di4)</code></pre>
<p>This interleaving demonstrates an important property of the automatic derivative: that it uses space proportional to the space usage of the original program. Specifically, as soon as we no longer need a variable that was assigned in the original program we no longer need the corresponding <code>d</code> version either.</p>
<p>We can also see another important property of the forward derivative: it runs in time proportional to the run time of the original program (assuming that the derivative of every primitive runs in time proportional to the run time of the primitive itself).</p>
<h2 id="reverse-mode-requires-two-additional-ideas">Reverse mode requires two additional ideas</h2>
<p>Now that we‚Äôve shown how to generate the forward mode derivative we can move on to the reverse mode derivative. Reverse mode requires two additional ideas:</p>
<ol type="1">
<li><p>We need to convert our original program to ‚Äúexplicit duplication‚Äù form: if a variable is used more than once then we make that explicit in the structure of the program. This is unusual but straightforward.</p></li>
<li><p>We need to use a form of the derivative that will be unfamiliar to most readers. It will appear quite bizarre when seeing it for the first time but it is crucial to implementing the reverse mode derivative.</p></li>
</ol>
<h2 id="explicit-duplication-form">Explicit duplication form</h2>
<p>Before applying the reverse mode AD transformation we will convert to ‚Äúexplicit duplication‚Äù form. Again, the transformation is not strictly required but if we omit it then the differentiation pass will have to do it implicitly. We take the ANF form of the program and insert explicit duplications (<code>dup</code>) for any variable that is used more that once. Recall that after removing nested subexpressions our program was</p>
<pre><code>p = mul (7, x)
r = div (1, y)
i1 = mul (p, x)
q = mul (i1, 5)
i2 = mul (2, p)
i3 = mul (i2, q)
i4 = mul (3, r)
v = add (i3, i4)</code></pre>
<p>We can see that <code>x</code> and <code>p</code> appear on the right hand side (i.e.&nbsp;are consumed) twice each. Therefore, they will need explicit duplication, so that each variable in the resulting program is used only once. With explicit duplication the program looks like</p>
<pre><code>(x1, x2) = dup x
p = mul (7, x1)
(p1, p2) = dup p
r = div (1, y)
i1 = mul (p1, x2)
q = mul (i1, 5)
i2 = mul (2, p2)
i3 = mul (i2, q)
i4 = mul (3, r)
v = add (i3, i4)</code></pre>
<p>(If a variable were used <span><em>n</em></span> times then we would have to insert <span><em>n</em>‚ÄÖ‚àí‚ÄÖ1</span> <code>dup</code>s for it. In our example no variable is used more than twice.)</p>
<p>Notice that now not only is every variable defined exactly once, but every variable is also <em>used</em> exactly once (except the inputs and outputs, <code>x</code>, <code>y</code> and <code>v</code> ‚Äì I won‚Äôt say more here about how exactly these seemingly special cases fit into the story). This property is important for a reason which will be explained when we come to generate the reverse mode program.</p>
<h2 id="differentiation-line-by-line-1">Differentiation line-by-line</h2>
<p>The line-by-line differentiation rules for generating the reverse mode need another article to explain thoroughly, but in this article I will hope to provide some basic intuition via examples and the informal notion that the reverse mode program calculates how sensitive the output is to different variables. For example, if the variable <code>y</code> appears in the original program then the variable <code>d_dy</code> will appear in the reverse mode program and measures ‚Äúhow sensitive the output is to small changes in <code>y</code>‚Äù. (I‚Äôll abbreviate this to ‚Äú<code>d_dy</code> is the sensitivity to <code>y</code>‚Äù.)</p>
<h3 id="examples-1">Examples</h3>
<h4 id="addition-1">Addition</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = add (x1, x2)</code></pre>
<p>then the derivatives are</p>
<pre><code>d_dx1 = d_dy
d_dx2 = d_dy</code></pre>
<p>because the sensitivity to <code>x1</code> is the same as the sensitivity to <code>y</code> (and likewise for <code>x2</code>). This is written on a single line as</p>
<pre><code>(d_dx1, d_dx2) = dup (d_dy)</code></pre>
<h4 id="multiplication-1">Multiplication</h4>
<p>If a line of our program was</p>
<pre><code>y = mul (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>(d_dx1, d_dx2) = (mul (x2, d_dy), mul (x1, d_dy))</code></pre>
<p>because the sensitivity to <code>x1</code> is <code>x2</code> times the sensitivity to <code>y</code> (and similarly for <code>x2</code>).</p>
<h4 id="duplication">Duplication</h4>
<p>If a line of our program was</p>
<pre><code>(x1, x2) = dup (x)</code></pre>
<p>then the derivative line is</p>
<pre><code>d_dx = add (d_dx1, d_dx2)</code></pre>
<p>because the sensitivity to <code>x</code> is the sensitivity to <code>x1</code> plus the sensitivity to <code>x2</code>.</p>
<h2 id="generating-reverse-mode-code">Generating reverse mode code</h2>
<p>Like forward mode before it, the reverse mode transformation applies the appropriate differentiation rule to each line in the input program (listed on the left) to obtain a ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/">http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/</a></em></p>]]>
            </description>
            <link>http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657571</guid>
            <pubDate>Fri, 02 Oct 2020 00:21:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Community Moderation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24657148">thread link</a>) | @minimaxir
<br/>
October 1, 2020 | https://www.joinclubhouse.com/on-community-moderation | <a href="https://web.archive.org/web/*/https://www.joinclubhouse.com/on-community-moderation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Oct 1, 2020</p>
      <p>Since <a href="https://www.joinclubhouse.com/check-1-2-3">our last blog post</a>, Clubhouse has gone from a small community of beta testers to a growing network of communities, made up of people with vastly different opinions, experiences, worldviews and perspectives. This past week, people on Clubhouse have hosted several intense conversations on topics of identity, ethnicity, gender, racism, and religion. These conversations led to a number of serious incident reports, and we received questions and concerns from our community about how we plan to scale safety and moderation on Clubhouse. In the wake of this, we wanted to share some thoughts regarding what we stand for as a company, what we will and will not tolerate, what we are doing to prevent abuse, and how we plan to empower conversation hosts with better moderation tools as we grow.</p>
      <p>First, we unequivocally condemn Anti-Blackness, Anti-Semitism, and all other forms of racism, hate speech and abuse on Clubhouse. Our <a href="http://community.joinclubhouse.com/">Community Guidelines</a> and <a href="http://tos.joinclubhouse.com/">Terms of Service</a> make this clear, and we have trust and safety procedures in place to address any violation of these rules. People who violate them are warned, suspended, or removed completely from the platform, depending on the severity of the offense. This is a critical area of investment for us as a company and we are working hard to continue building tools and policies that are robust and that account for the unique dynamics of real-time voice conversations and group discussions.</p>
      <p>Second, we celebrate the fact that Clubhouse is not one single community, but a network of interconnected and diverse communities. As these communities grow, we need to provide moderators and club leaders with better tools and infrastructure to bring people together. Our goal is to empower them to host important, and even difficult, conversations‚Äîbecause some of the most powerful moments on Clubhouse happen when you find yourself speaking with a room full of people whose backgrounds and experiences are completely different from your own. These conversations often go on for hours, spilling out into breakout rooms full of people connecting, debating, evolving their worldviews and recognizing their blindspots. Our hope for Clubhouse is that it can be a new type of network based on empathy, discussion and sensemaking, rather than polarization. We think social media needs more of this.</p>
      <p>PREVENTING ABUSE</p>
      <p>Our Terms of Service and Community Guidelines define what type of behavior is allowed on Clubhouse and we are committed to addressing behavior that violates these rules. Here is what we‚Äôre doing to help with that:</p>
      <ul>
          <li><u>We‚Äôre taking action on all incident reports.</u> Any time someone reports a violation of our Terms of Service or Community Guidelines, we immediately investigate it. We don‚Äôt discuss these investigations publicly for user privacy reasons, but they are happening, and when rules are violated, corrective action is taken. This week, we‚Äôre also shipping real-time systems to investigate incidents more quickly and empower moderators to restrict and end rooms.</li>
          <li><u>We‚Äôre continuing to scale our trust and safety operations</u>. This is an ongoing effort for us that spans people, policy and product. On the people side, we‚Äôre focused on:</li>
          <ul>
              <li><u>Adding advisors.</u> We are building a team of advisors with deep expertise in trust, safety, diversity and inclusion to provide ongoing advice and input.</li>
              <li><u>Engaging directly with the community.</u> Since the earliest days of Clubhouse we‚Äôve been engaging deeply with a diverse cross-section of our community to understand their needs‚Äîthrough weekly Town Halls, New User Orientation sessions and deeper discussions, both on Clubhouse and off. We plan to continue the dialogue and see how these formats can be improved. We also use these discussions to continuously evolve our Terms of Service, Privacy Policy and Community Guidelines. These will be living documents.</li>
              <li><u>Growing our team.</u> Our trust and safety efforts are staffed to respond swiftly to incident reports, and we plan to proactively scale this operation as we grow. </li>
            </ul>
          
          <li><u>We‚Äôre shipping a wave of new safety features</u>. Over the past couple months we introduced blocking, muting, in-room reporting, and the ability for moderators to end a room. This week we are shipping a wave of new enhancements to make in-room reporting more real-time, specific and robust. We are also making the Community Guidelines accessible from every room and shipping new features to empower Clubhouse moderators.</li>
        </ul>
      
      <p>EMPOWERING MODERATORS AND CLUB LEADERS</p>
      <p>As we take these steps, we want to avoid conflating abuse with other things that can feel uncomfortable‚Äîlike differences in opinion or conversational style. Abuse, racism, religious intolerance, sexism and hate speech are never okay. Targeted and coordinated harassment is never okay. But what about general rudeness? Or holding opposing political viewpoints? While these things might seem jarring, we don‚Äôt believe they should be banned. We want to make sure that when you use Clubhouse, you get to choose your communities, your rooms, and your style of conversation. Here‚Äôs what we‚Äôre working on to enable this:</p>
      <ul>
          <li><u>Allowing clubs to set their own norms.</u> With our next release, club founders will be able to write rules that are specific to their clubs‚Äîto share their community values, communicate their norms, and define the dos and don'ts for speaking. When people join the club they'll be asked to agree to the rules. And when the club hosts a public conversation, non-members will be asked to agree to the rules before speaking. We think this will help people create intentional gathering spaces that cater to many interests and styles. These rules will supplement the Community Guidelines, which still apply to everyone.</li>
          <li><u>Hosting formal moderator training sessions.</u> There is no single way to moderate, and each room can have its own style. To help with this, we‚Äôre going to start offering regular moderator training sessions on the app, to ensure that people who wish to host discussions are equipped with the tools and knowledge they need.</li>
          <li><u>Improving moderator tooling.</u> Great moderators create great conversations, and we need to empower them with the right tools. This week we are building infrastructure that will allow us to notify moderators when there is a safety concern related to their room. Moderators can also tap the ‚ÄúEnd Room‚Äù button anytime if they feel the conversation is getting out of hand.</li>
          <li><u>Adding moderator badges.</u> This is a small thing, but it‚Äôs easier to provide a speaker with feedback when you know who‚Äôs in charge of the room. These will be live in the next release.</li>
        </ul>
      
      <p>The world is not a monoculture, and we want Clubhouse to reflect that. Ideally the experience is more like a town square, where people with different backgrounds, religions, political affiliations, sexual orientations, genders, ethnicities, and ideas about the world come together to share their views, be heard and learn. Some of these communities come together to debate. Some come to relax and joke around. Others hold listening parties and fireside chats. We think many styles should be supported, and we‚Äôre working on tools to help everyone create their own space, deepen friendships, meet new people and have meaningful discussions‚Äîin the way that suits them best.</p>
      <p>Clubhouse is nothing without the community, and we are immensely grateful for all of your ideas, emails, tweets, support and critiques. We‚Äôll continue working around the clock on all of this as we open it up to more of the world. Thank you! üôèüèΩ</p>

    </div></div>]]>
            </description>
            <link>https://www.joinclubhouse.com/on-community-moderation</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657148</guid>
            <pubDate>Thu, 01 Oct 2020 23:11:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VMware Fusion 12 Metal Support]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24656836">thread link</a>) | @wila
<br/>
October 1, 2020 | https://www.vimalin.com/blog/fusion-12-0-metal-support/ | <a href="https://web.archive.org/web/*/https://www.vimalin.com/blog/fusion-12-0-metal-support/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>			<div>
				
				<article id="post-1344">	
			<figure>
		<img width="1136" height="918" src="https://www.vimalin.com/wp-content/uploads/2020/10/image.png?is-pending-load=1" alt="VMware Fusion 12 Metal Support" loading="lazy" data-lazy-srcset="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?w=1136&amp;ssl=1 1136w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=300%2C242&amp;ssl=1 300w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1 1024w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=768%2C621&amp;ssl=1 768w" data-lazy-sizes="(max-width: 1136px) 100vw, 1136px" data-lazy-src="https://www.vimalin.com/wp-content/uploads/2020/10/image.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">		</figure>
			<div>
					
				
									<div>
				
<p>Ok.. I‚Äôm so ecstatic.. a quick blog post must be written‚Ä¶</p>



<p>On VMworld‚Äôs ‚ÄúWhat‚Äôs New with VMware Workstation and VMware Fusion‚Äù, Michael Roy dropped a bomb in his last ‚ÄúOne more thing‚Äù note.</p>



<p>He showed off ‚ÄúMetal Support‚Äù in a macOS guest‚Ä¶ Now we have been told for years that we cannot get 3D Acceleration in a macOS guest, so seeing that was already pretty great. Something to look forward to.<br>In that same presentation he also showed the .vmx settings in order to get that working. Once the feature lands‚Ä¶ </p>



<p>So of course immediately after the presentation I _had_ to try, even while it is only supposed to be working in a future version of VMware Fusion 12.0.<br>I got a ‚ÄúInvalid configuration‚Äù error (or something along those lines). <br>OK.<br>Silly me did not look at the vmware.log file, so today I was poking Michael a bit on twitter and asking about how well Metal works on Big Sur beta 9 and that it is ‚Äúso hard to wait‚Äù and he tells me ‚Äúbut you can try it yourself already‚Äù‚Ä¶ üòÆ</p>



<figure><div>
<blockquote data-width="500" data-dnt="true"><div lang="en" dir="ltr"><p>You can totally use it today actually, but AutoFit doesn't work (needs new tools that haven't shipped yet‚Ä¶ future versions won't require Tools at all)</p><p>svga.present="FALSE"<br>appleGPU0.present="TRUE"</p><p>appleGPU0.screenWidth=1680 appleGPU0.screenHeight=1050</p></div>‚Äî Michael Roy (@mikeroySoft) <a href="https://twitter.com/mikeroySoft/status/1311754703055675392?ref_src=twsrc%5Etfw">October 1, 2020</a></blockquote>
</div></figure>



<p>OMG.. that‚Äôs when I realized that I had missed a detail..</p>



<figure><div>
<blockquote data-width="500" data-dnt="true"><div lang="en" dir="ltr"><p>Ohh‚Ä¶ I had not put the svga.present="FALSE" line and now I see what other precondition I missed (silly me)‚Ä¶</p><p>vmx| I005: AppleGPU: Apple GPU support is not available: requires macOS 11.</p><p>Looks like I will update that box to macOS 11 right now.</p></div>‚Äî Wil van Antwerpen (@wilva) <a href="https://twitter.com/wilva/status/1311759349572870144?ref_src=twsrc%5Etfw">October 1, 2020</a></blockquote>
</div></figure>



<p>Also my host wasn‚Äôt running Big Sur yet (I had only run it in a VM)<br>‚Ä¶ so‚Ä¶ next hour or so I was frantically busy installing Big Sur Beta 9 on my 2014 Mac Mini and YES‚Ä¶ IT DOES WORK and it is SOOOO SMOOTH</p>



<figure><img loading="lazy" width="1024" height="827" src="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1" alt="" srcset="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1 1024w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=300%2C242&amp;ssl=1 300w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=768%2C621&amp;ssl=1 768w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?w=1136&amp;ssl=1 1136w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1 1024w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=300%2C242&amp;ssl=1 300w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=768%2C621&amp;ssl=1 768w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?w=1136&amp;ssl=1 1136w" data-lazy-src="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>This is the best thing since sliced bread.</p>



<div><p>THANK YOU VMware Fusion team!</p><p>In summary:<br>This is not an officially released feature, treat it what it is: Experimental<br>Required: minimum of macOS Big Sur as host OS<br>Required: minimum VMware Fusion 12.0<br>Guest OS support: So far I have only gotten this to work with a macOS Big Sur guest (but I haven‚Äôt tried others beyond macOS Mojave)</p><p>You have to add the following lines to the .vmx file of your VM in order to test this:<br><code>svga.present="FALSE"<br>appleGPU0.present="TRUE"<br>appleGPU0.screen0.width = "1680"<br>appleGPU0.screen0.height = "1050"</code></p></div>



<p>To be honest I don‚Äôt even have the lines with width and height, but that‚Äôs how you can define that for now.<br>It will only get better from here on once it is officially supported.</p>
			</div>
					
			<hr>
			
					</div>
</article>						</div>	
			
		<!--/Blog Content-->
		         				</div></div>]]>
            </description>
            <link>https://www.vimalin.com/blog/fusion-12-0-metal-support/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656836</guid>
            <pubDate>Thu, 01 Oct 2020 22:28:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using artificial intelligence to make publishing profitable]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24656437">thread link</a>) | @Sanksshep
<br/>
October 1, 2020 | https://www.aiplusinfo.com/blog/using-artificial-intelligence-to-make-publishing-profitable | <a href="https://web.archive.org/web/*/https://www.aiplusinfo.com/blog/using-artificial-intelligence-to-make-publishing-profitable">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-1fd98981423ebe5f9a2e"><p><h2>Artificial Intelligence has significant implications in making publishing profitable ‚Äì from automation to improvements in advertising. Let‚Äôs dive into what AI is, as well as the potential applications within the publishing industry to make it profitable.</h2></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1601450467819_4883"><div><h3><strong>What is AI?</strong></h3><p>Artificial intelligence, or AI, refers to the ability of tools or technology to perform tasks that would normally require human intelligence to complete.&nbsp;</p><p>Machine learning is a subset of AI in the computer science space ‚Äì where the platform or model learns from an existing data set so that it can understand the underlying trends and patterns. This knowledge is then used by the machine learning models to make predictions or determine outcomes from the new data it encounters.</p><p>In other words, the computer model uses statistical techniques to learn how to get better at a task, whether that be categorizing data or predicting if a client is a good fit for a certain product. For the model to learn to do this without specific programming, it must analyze existing data that is already pre-labeled.</p><p>Deep learning is another subset of artificial intelligence that involves the creation of a neural network, which has layers and layers of data processing. This type of AI can make deep connections and gain valuable insights from a dataset since it processes information almost like the human brain does.</p><h3><strong>Goals of Artificial Intelligence in Publishing</strong></h3><p>The goals of artificial intelligence in publishing include automating story production and evaluating content automatically.&nbsp;</p><p>The Associated Press started using AI back in 2015 for story automation. They understood that machine learning could create content such as public company earnings report recaps since they need details and accuracy but do not require much creativity.&nbsp;</p><p>They took this further in 2016 when they developed an AI platform that could report on Minor League Baseball games ‚Äì the machine learning model could incorporate statistics and highlights that, again, are strictly fact-based.&nbsp;</p><p>This is just the beginning for automatic story production, and as artificial intelligence platforms become more accessible there will be more publishers utilize it to create automated content.</p><p>Another goal of artificial intelligence in publishing is evaluating content. A machine learning model can help an editor when making decisions regarding moderation and editing.&nbsp;</p><p>AI can be used to automate complex tasks, such as comparing the characteristics of a manuscript to those of a bestseller to see where improvements can be made. This can help editors focus on the most marketable content and save time and effort narrowing them down.&nbsp;</p><p>Automated text analysis can optimize plagiarism detection as well as copyright enforcement! Artificial intelligence can eliminate some of the tedious work involved with researching copyrights and ensuring that the content being published is 100% authentic.&nbsp;</p><p>Comment moderation can be significantly improved as a result of artificial intelligence. Machine learning models can save publishers valuable time and resources by automatically detective inappropriate or abusive labels and comments ‚Äì and removing them.&nbsp;</p><p>Reducing the workload of human moderators can allow publishers to open more content for commenting and facilitate a wider scope of articles. The New York Times has already implemented automation within the moderation space, and this has allowed them to open up more content for commenting ‚Äì where previously they capped it at 10% of their articles.&nbsp;</p><h3><strong>Artificial Intelligence and Advertising</strong></h3><p>Artificial intelligence can also help publishing firms when it comes to advertising. It can improve everything from engagement to the structuring and design of content.&nbsp;</p><p>AI platforms allow publishers to personalize content for marketing campaigns since statistics have shown that personal advertisements have a higher level of engagement ‚Äì and therefore, a better return on investment.</p><p>Machine learning models will analyze content and engagement to curate newsletters and articles that fit right in with your audience segment. Research performed by McKinsey found that this level of personalization is essential and can increase the efficiency of marketing budgets by up to 30%!</p><p>This type of personalization can also be used for the automation of recommendations. You can gain insights into what your readers like based on their browsing history, and then the machine learning model can identify trends and patterns.&nbsp;</p><p>With this information, you can give your readers personalized recommendations on other content they may enjoy. This will help your firm boost engagement as well as make your advertisements much more personalized.&nbsp;</p><h3><strong>Conclusion</strong></h3><p>These are just a few aspects in which artificial intelligence can impact publishing by reorganizing the workforce towards better things with the help of automation and improve revenue by personalizing content and experiences for a diverse set of users. Publishing companies can benefit a lot by using artificial intelligence in tough economic climates and weather the storm and keep the lights on. </p></div></div></div>]]>
            </description>
            <link>https://www.aiplusinfo.com/blog/using-artificial-intelligence-to-make-publishing-profitable</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656437</guid>
            <pubDate>Thu, 01 Oct 2020 21:42:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asynchronous Development for Hybrid Remote Dev Teams]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24656046">thread link</a>) | @davetwichell
<br/>
October 1, 2020 | https://linearb.io/blog/asynchronous-development/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/asynchronous-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<p>Hope and optimism are default settings for my LinearB co-founder, Ori Keren. For Ori, one silver lining in this tumultuous year is that 2020 ushered in the age of the hybrid remote work model. </p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1024x429.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-300x126.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-768x322.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1536x644.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM.png.webp 1908w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1024x429.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1024x429.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-300x126.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-768x322.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1536x644.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM.png 1908w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Asynch-2.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>‚ÄúHybrid remote is how software development teams were always meant to work. It just took 20 years and a global pandemic for us to figure that out.‚Äù </p>



<p>Ori believes that, to be highly successful, developers need uninterrupted time to get into a deep state of focus on their task at hand. Getting in ‚Äúthe zone‚Äù is hard and when you get interrupted you can‚Äôt easily get your deep focus back. </p>



<p>Remote work has eliminated most dev interruptions, right? Not so fast. </p>



<p>Company culture is a powerful force. Like gravity, we don‚Äôt see or or think about most days but it effects everything we do. </p>



<div><p>According to Ori, culture is even more powerful than a global pandemic or a new trend like hybrid remote. </p><p>‚ÄúWorking remote was great for our dev team at first. Once we got over the initial disruption of getting equipment and finding a quiet place to work at home, team productivity soared. But then we started noticing our efficiency going down.‚Äù </p></div>



<div><p>What happened? Our in-the-office culture grabbed hold and brought us right back to where we were in March. </p><p>‚ÄúAll of the interruptions crept back in‚Ä¶ scheduled meetings, impromptu Zoom status meetings‚Ä¶‚Äù </p><p>In other words, we were a hybrid remote company with an in-the-office mindset and process. </p><p>You can see the effects here in our Cycle Time trend chart. </p></div>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1024x586.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-300x172.png.webp 300w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-768x440.png.webp 768w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1536x879.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-2048x1172.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1024x586.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1024x586.png 1024w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-300x172.png 300w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-768x440.png 768w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1536x879.png 1536w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-2048x1172.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>







<div><p>‚ÄúBeing a remote employee used to be a semi-unique experience that came with a certain level of trust, preparation and experience. Then the entire global dev community went remote at the same time, without preparation or understanding of what needs to change.‚Äù</p><p>Hybrid remote can be a business advantage for companies embracing it. But only if we adapt our culture and process to make it work. </p></div>



<p>This is how Asynchronous Development was born. </p>







<h2>What is Asynchronous Development?</h2>



<p>Async Dev is an approach to development grounded in asynchronous communication. It works for hybrid remote, full remote and any dev teams that wants to unlock the full creative power of their developers. </p>







<iframe width="560" height="465" src="https://www.youtube.com/embed/w0pw0dcFZ-w?rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>







<p>Async Dev builds on the foundation Agile put in place. Since the Agile Manifesto was published 20 years ago, software development has gone through some drastic changes. Many of those changes like asynchronous communication tools (e.g. Slack &amp; Teams) becoming the default form of communication and hiring remote developers were forced into the spotlight in 2020. </p>



<p>Ori  started wrote the Async Dev manifesto to help engineering and product leaders see how they can change the way they work to turn this new situation into an opportunity. </p>



<p><strong><em>Below Ori explains how Async Dev builds on the Agile and DevOps movements and talk through each of the five core tenets of Async Dev. Listen to the accompanying 60~ second audio clip from Ori in each section or just read the blog</em></strong>. </p>







<h2>The Async Dev Movement</h2>



<p>Hybrid remote development is not new, but 2020 accelerated the adoption of many of the practices already in place. As these hybrid remote methods are normalized globally, we also have to accept the way we work, the processes, and the ceremonies have changed as well. </p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1024x489.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-300x143.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-768x367.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1536x734.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-2048x978.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1024x489.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1024x489.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-768x367.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1536x734.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-2048x978.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/10/history-1.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>Asynchronous Development acknowledges the importance of movements like Agile and DevOps and offers a new way of looking at development that is a better fit for 2020.&nbsp;</p>











<h2>The 5 Tenets of Asynchronous Development</h2>



<p>There are 5 core tenets of Async Dev that we have adopted to transform the hybrid remote reality into an opportunity to strengthen the alignment between development and the business.</p>







<div><div>
<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1024x521.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-300x153.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-768x391.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1536x782.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-2048x1043.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1024x521.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1024x521.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-300x153.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-768x391.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1536x782.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-2048x1043.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>
</div></div>







<ol><li>Asynchronous is the default form of communication</li><li>Git is the central element of your development process</li><li>Project Management tools are for planning, not status updates</li><li>Continuous improvement is a daily practice</li><li>Dev teams are the core of the business</li></ol>











<figure><blockquote><p>LinearB built a new kind of project board exclusively for hybrid remote dev teams.</p><p><span><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noreferrer noopener">Get our Devboard free</a></span></p></blockquote></figure>







<h2>Tenet 1 ‚Äì Asynchronous is the default form of communication</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1024x462.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-300x135.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-768x347.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1536x693.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM.png.webp 1950w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1024x462.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1024x462.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-300x135.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-768x347.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1536x693.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM.png 1950w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet-1.mp3"></audio><figcaption>Click here to listen to Ori</figcaption></figure>







<p>Asynchronous communication means using collaboration tools and mentions by default. It helps reduce context switching, avoid unnecessary interruptions, and increases productivity. </p>



<p>After LinearB went full remote back in April of 2020, we analyzed our development team‚Äôs metrics to understand exactly how this change effected the productivity and efficiency of the team. </p>



<p>In true Asynchronous fashion, 92% of developers at LinearB were writing more code, while PR sizes and Cycle Times increased. This clearly tells us that fewer interruptions means greater individual productivity. It also clearly shows what we needed to adapt the way worked to the new circumstances if we were going to continue delivering at the same level as pre-wfh. </p>



<p>At LinearB we have started taking a closer look at the function of the daily stand-up and how to use that time to best suit our team. Now that we are a hybrid remote development team with up to the minute updates on issue statuses using LinearB, we use our stand-up time to connect on a personal level, and then just talk about blockers. It‚Äôs not perfect, but it‚Äôs been a nice adaptation to our new reality.</p>







<h2>Tenet 2 ‚Äì Git is the central element of your development process</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1024x580.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-300x170.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-768x435.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1536x869.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM.png.webp 1802w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1024x580.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1024x580.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-300x170.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-768x435.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1536x869.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM.png 1802w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet-2_2-1.mp3"></audio><figcaption>Click here to hear Ori</figcaption></figure>







<p>Whether you use GitHub, GitLab, Bitbucket, Azure DevOps or other git flavor, most of the stages of the development cycle either start or involve your git system. How you choose to configure, deploy and utilize it has a great impact on your dev process. </p>



<p>In addition the most up to date status of work progress resides in the git system. Fortunately git was built with open source in mind so most of the phases (coding, review, merge) do not require mandatory synchronous communication and can be executed in different places and different times.</p>











<h2>Tenet 3 ‚Äì Project Management tools are for planning, not status updates</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1024x581.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-300x170.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-768x436.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1536x871.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM.png.webp 1714w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1024x581.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1024x581.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-300x170.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-768x436.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1536x871.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM.png 1714w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet3_2.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>Whether your team uses Jira, Trello or something else, project management tools are great for planning an iteration or the next week, but trying to use them to enrich dozens of micro decisions that dev teams are taking every day will slow down productivity. </p>



<p>Every update to the work status while in ‚Äòbuilding mode‚Äô should be with dev first in mind, meaning it should automatically reflect the status based on actual git activity and it should mainly serve the people that build and ship the software.</p>







<figure><blockquote><p>Does your current project board</p><p>give you more questions than answers?</p><p><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noreferrer noopener">Try the LinearB Devboard free</a></p></blockquote></figure>







<h2>Tenet 4 ‚Äì Continuous improvement is a daily practice</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1024x596.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-300x175.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-768x447.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1536x895.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM.png.webp 1724w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1024x596.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1024x596.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-300x175.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-768x447.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1536x895.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM.png 1724w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/10/tenet4new.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>Data should always be accessible to everyone ‚Äì no gate keepers, not just data engineers, and not just reviewed in meetings by management.</p>



<p>Your KPIs and how you decide to utilized them will define your culture. </p>



<p>Key Principles for Data Usage: </p>



<ul><li>Team-based data over developer stack ranking</li><li>Measure process over output</li><li>Measure empiric over subjective</li><li>Focus on leading indicators vs. lagging indicators</li><li>Establish baseline data points and trends</li><li>Make sure it‚Äôs actionable</li></ul>







<p>Data should be used in an ethical way and cannot replace good managers with good soft skills and human interaction.</p>







<figure><blockquote><p>High-risk code &amp; stuck PR Slack Alerts are pretty amazing.</p><p><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noreferrer noopener">Get them Free with LinearB</a></p></blockquote></figure>







<h2>Tenet 5 ‚Äì Dev teams are the core of the business</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1024x552.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-300x162.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-768x414.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1536x828.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM.png.webp 1988w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1024x552.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1024x552.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-300x162.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-768x414.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1536x828.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM.png 1988w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet-5_1.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>The best companies in the world evolved from developers that were highly aligned with business and market needs. Dev-led companies empower developers to make decisions on behalf of customers and the business by giving them context instead of instructions.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1024x460.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-300x135.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-768x345.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1536x689.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-2048x919.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1024x460.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1024x460.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-300x135.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-768x345.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1536x689.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-2048x919.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>







<p>We believe that ‚Äòdevelopers‚Äô and ‚Äòbusiness‚Äô are not disjoint sets and sometimes the most important business decisions are hiding in code lines. That is why the best businesses should focus on pushing context to dev teams, and dev teams should provide transparency into their decision making so both can enjoy a refinement cycle.</p>



<p>This is probably the hardest part of making Async Dev a reality because, as dev leaders, it is the element we have least control over. We need buy-in from throughout the business. </p>







<h3><strong>Here are 5 practical steps you can take today to start practicing Async Dev:</strong></h3>







<h4>1) Cut status updates from your daily stand-up</h4>



<p>Instead focus on what matters ‚Äì who needs help and whether you‚Äôre going to ship on time. Async Dev means never spending valuable meeting time on status updates when everyone could take 5 minutes on their own before the meeting to see what happened yesterday and what‚Äôs happening today. <a href="https://linearb.io/blog/make-daily-better/" target="_blank" rel="noreferrer noopener">Click here to get 16 tips</a> for how to run a better daily stand-up. </p>







<h4>2) Decouple learning and improvement from your retro. </h4>



<p>We‚Äôre not saying to cancel your retro. Getting together every few weeks to discuss learnings is great. But if you un-gate your team metrics so everyone can see bottlenecks and suggestions for how to improve each day, then improvement can be led everyone on your team (not just managers) and become part of the fabric of your team culture. <a href="https://linearb.io/blog/data-driven-dev-team/" target="_blank" rel="noreferrer noopener">Click here to see how to use data in your day-to-day</a> practices without damaging culture. </p>







<h4>3) Combine quantitative signals &amp; qualitative assessments for team health</h4>



<p>Use multiple data points to identify signs of overload and burnout. Face to face conversation is not the only way to see if a teammate is struggling. Looking at your WIP balance across the team and consecutive days worked, in combination with 1:1 conversation, can tell you a lot about a person‚Äôs work health. <a href="https://linearb.io/blog/dev-team-health/" target="_blank" rel="noreferrer noopener">Click here to see which data points can help you ‚Ä¶</a></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/asynchronous-development/">https://linearb.io/blog/asynchronous-development/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/asynchronous-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656046</guid>
            <pubDate>Thu, 01 Oct 2020 20:53:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interviewing During Covid ‚Äì Google/Apple/ByteDance/Databricks/Citadel/HRT/JS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24655799">thread link</a>) | @oneraynyday
<br/>
October 1, 2020 | https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/ | <a href="https://web.archive.org/web/*/https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><strong>I interviewed for Google√¢‚Ç¨‚Ñ¢s Tensorflow, Apple√¢‚Ç¨‚Ñ¢s MLPT (Machine Learning Platform &amp; Technology), Bytedance√¢‚Ç¨‚Ñ¢s ad infrastructure, Databrick√¢‚Ç¨‚Ñ¢s ML team, Citadel Securities as a quantitative research analyst, Hudson River Trading(HRT) as an algorithm engineer, and Jane Street√¢‚Ç¨‚Ñ¢s research desk as SWE. I received offers from all of the companies except for Jane Street. Here√¢‚Ç¨‚Ñ¢s my experience interviewing during COVID.</strong></p>

<p><em>Disclaimer: I won√¢‚Ç¨‚Ñ¢t be walking on the edge of leaking confidential information like an idiot(yes, I signed an NDA for all of these companies). Don√¢‚Ç¨‚Ñ¢t expect to get any hints for your interviews.</em></p>

<p>The structure of this blog is inspired by my friend <a href="https://medium.com/@XiaohanZeng/i-interviewed-at-five-top-companies-in-silicon-valley-in-five-days-and-luckily-got-five-job-offers-25178cf74e0f">Han√¢‚Ç¨‚Ñ¢s medium blogpost.</a></p>

<p><img src="http://oneraynyday.github.io/assets/interviews.png" alt="interviews"></p>



<ul id="markdown-toc">
  <li><a href="#table-of-contents" id="markdown-toc-table-of-contents">Table of Contents</a></li>
  <li><a href="#preparation" id="markdown-toc-preparation">Preparation</a>    <ul>
      <li><a href="#algorithms" id="markdown-toc-algorithms">Algorithms</a></li>
      <li><a href="#systems-design" id="markdown-toc-systems-design">Systems Design</a></li>
      <li><a href="#math-questions" id="markdown-toc-math-questions">Math Questions</a></li>
    </ul>
  </li>
  <li><a href="#the-interview-process" id="markdown-toc-the-interview-process">The interview process</a>    <ul>
      <li><a href="#more-interview-rounds-during-covid" id="markdown-toc-more-interview-rounds-during-covid">More interview rounds during COVID</a></li>
      <li><a href="#dealing-with-time-zones" id="markdown-toc-dealing-with-time-zones">Dealing with time zones</a></li>
      <li><a href="#which-ones-were-the-hardest" id="markdown-toc-which-ones-were-the-hardest">Which ones were the hardest?</a></li>
    </ul>
  </li>
  <li><a href="#making-a-decision" id="markdown-toc-making-a-decision">Making a decision</a>    <ul>
      <li><a href="#the-culture-and-the-small-things-count" id="markdown-toc-the-culture-and-the-small-things-count">The culture and the √¢‚Ç¨≈ìsmall√¢‚Ç¨ÔøΩ things count</a></li>
    </ul>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
</ul>



<p><strong>Working on machine learning infrastructure is 99% systems engineering and 1% machine learning.</strong> My experience on machine learning infrastructure teams has taught me this, and preparing for systems engineering topics was the right way to go. I did the following to prepare:</p>

<h2 id="algorithms">Algorithms</h2>

<p><strong>~50 leetcode hard questions</strong>. Some of them are DP, some are graph based, some of them are just NP-hard problems that are a pain to code(which is the point), and some include devising some clever data structure that supports a very specific access pattern. I gave myself roughly 40 minutes to solve these problems. ~15%(7 questions) of the time I couldn√¢‚Ç¨‚Ñ¢t figure out the correct solution because time limit exceeded, memory limit exceeded, or I was just flat out wrong. I directly read the solutions and learned the tricks necessary to solve the type of problems moving forward. Don√¢‚Ç¨‚Ñ¢t bother with medium or easy questions since hard questions often contain medium/easy tasks as subroutines, and these companies probably wouldn√¢‚Ç¨‚Ñ¢t ask you easy leetcode questions anyways.</p>

<p>I wrote the solutions in either python and C++(sometimes both) and went back to polish my code for minor optimizations or readability improvements. For C++, I made sure I wasn√¢‚Ç¨‚Ñ¢t using raw pointers unless appropriate and I was using C++17 (<code>constexpr</code> functions, <code>std::array</code> instead of raw arrays, smart pointers, template type deduction with lambdas, etc) features. The reason I wasn√¢‚Ç¨‚Ñ¢t using C++20 was because the online coding platforms(like coderpad) likely use stable distributions of GCC and clang, which means some of the new features are in their experimental phase. <strong>I didn√¢‚Ç¨‚Ñ¢t want to encounter a bug with concepts or <code>std::ranges</code>  in the middle of the interview.</strong> (In fact, I found a <a href="https://stackoverflow.com/questions/62398252/why-likely-attribute-in-c20-raises-a-warning-here">bug with attributes</a> recently in a new version of gcc)</p>

<p>I also spent a few days on problems elsewhere:</p>

<ul>
  <li><a href="https://codingcompetitions.withgoogle.com/codejam/archive">Codejam problems</a>. Round 1 and 2 are feasible, but round 3 was very difficult. I√¢‚Ç¨‚Ñ¢d suggest studying round 1√¢‚Ç¨‚Ñ¢s if you only care about interviews.</li>
  <li><a href="https://codeforces.com/">Codeforce contests</a>. There are 3 tiers(or Divs, as they call it), and for interviews I suggest Div 3 and Div 2. Don√¢‚Ç¨‚Ñ¢t bother with the D+ questions in Div 2, and definitely don√¢‚Ç¨‚Ñ¢t bother with Div 1.</li>
</ul>

<h2 id="systems-design">Systems Design</h2>

<p>Working at Airbnb has made me pretty familiar with high level distributed systems design, but of course I worked only with a subset of them. I think Martin Kleppman√¢‚Ç¨‚Ñ¢s book <a href="https://www.google.com/books/edition/Designing_Data_Intensive_Applications/p1heDgAAQBAJ?hl=en">Designing Data Intensive Applications</a> is a great read, but you√¢‚Ç¨‚Ñ¢ll have to pick and choose which sections you want to go over as it√¢‚Ç¨‚Ñ¢s a pretty dense book. If you don√¢‚Ç¨‚Ñ¢t have time, maybe just try understanding how Kubernetes works with Marko Luksa√¢‚Ç¨‚Ñ¢s <a href="https://www.manning.com/books/kubernetes-in-action">Kubernetes in Action</a>, which is a much easier read. You can then draw parallels with the distributed design for K8s against whatever systems design question the interviewer has for you.</p>

<p>Make sure you know some fundamental ideas about distributed systems like the <strong>map reduce paradigm</strong>, <strong>sharding</strong>, <strong>asynchronous and synchronous follower replicas</strong>, <strong>CAP theorem</strong>, etc. <em>What you don√¢‚Ç¨‚Ñ¢t want to do is read 3 sentences about each of the terms above and regurgitate it in your interviews. Interviewers have been doing this for a while, they know you don√¢‚Ç¨‚Ñ¢t actually understand the concepts.</em> Don√¢‚Ç¨‚Ñ¢t be that guy.</p>

<h2 id="math-questions">Math Questions</h2>

<p><strong>These are only asked in finance firms.</strong> Honestly, these are just all over the place. I read this green book called <a href="http://quantfinanceinterviews.com/">A Practical Guide to Quantitative Finance Interviews</a> by Xinfeng Zhou, but only doing a single problem in each section by myself. Hedge funds will quiz you on discrete math to probability theory to geometry to information theory to literally anything. My advice is if you√¢‚Ç¨‚Ñ¢re a software engineer interviewing for a hybrid of finance and tech places, timebox yourself in this category.</p>

<hr>

<p>I have not seen an interview question this cycle that was an exact question I√¢‚Ç¨‚Ñ¢ve seen online or in books. Your mileage may vary.</p>



<p>Interviewing and talking with all of these companies was a great experience, even with COVID in place. Obviously, as shelter-in-place continues, these companies are conducting virtual on-site interviews and trying to make this process as smooth as possible. Without getting into the specifics, I√¢‚Ç¨‚Ñ¢ll outline some common things I√¢‚Ç¨‚Ñ¢ve noticed during the process in the COVID era.</p>

<ul>
  <li>Many companies use Zoom or Google Hangouts for their on-sites.</li>
  <li>They give you ~15 minute breaks in between interviews for water breaks.</li>
  <li>Some companies give you a longer lunch break (45 mins to an hour).</li>
  <li>If you√¢‚Ç¨‚Ñ¢re interviewing for a company in another time zone, prepare to wake up in the early AM√¢‚Ç¨‚Ñ¢s or interview in the late afternoon (sometimes after dinner).</li>
  <li>Conveying an idea takes slightly longer because you√¢‚Ç¨‚Ñ¢re not drawing on a whiteboard. Some companies have virtual whiteboard apps and others allow the use of Zoom whiteboards.</li>
  <li><strong>Some companies added more interview rounds for virtual on-sites.</strong> Apparently more people are getting into companies with subpar technical skills during COVID and they√¢‚Ç¨‚Ñ¢re making the process more selective. I think this can also be due to the increase in competition due to unemployment rates increasing.</li>
  <li>Feedback and communications with recruiters is generally faster.</li>
</ul>

<h2 id="more-interview-rounds-during-covid">More interview rounds during COVID</h2>

<p>The bolded text might scare you as a potential candidate, but don√¢‚Ç¨‚Ñ¢t worry too much. The added questions aren√¢‚Ç¨‚Ñ¢t testing you if you know how to implement a bloom filter or a fibonacci heap or something niche. They usually test on the <em>coding abilities of the person and how well they√¢‚Ç¨‚Ñ¢d actually ramp up in a novel, collaborative environment</em>. This can manifest itself in multiple ways - live debugging session with a new codebase, reading documentation to work with new technology, or a collaborative brainstorming sesion for a hard(er) problem. If you√¢‚Ç¨‚Ñ¢re a decent software engineer you shouldn√¢‚Ç¨‚Ñ¢t worry about these as much.</p>

<h2 id="dealing-with-time-zones">Dealing with time zones</h2>

<p><em>One of the biggest struggles I had during the interview process was adjusting my sleep schedule to wake up at 5-6AM to make sure I√¢‚Ç¨‚Ñ¢m awake and on time for the interviews in New York/Chicago (I√¢‚Ç¨‚Ñ¢m in California so this was a 3 hour gap)</em>. Usually, companies would fly you out the day-of or the day before the on-site. I√¢‚Ç¨‚Ñ¢ve always felt tired after a plane flight and was able to get a good night√¢‚Ç¨‚Ñ¢s rest before the interviews in the past. With COVID, everything is virtual and the companies expect you to interview at their hours.</p>

<p>Even with slowly adjusting my sleep schedule over a week or two I still had trouble with sleep. Personally, I get pretty nervous before an on-site and I√¢‚Ç¨‚Ñ¢d need to feel adequately tired to get a good night√¢‚Ç¨‚Ñ¢s rest instead of tossing and turning in bed. With the clock turned 3 hours back, I suddenly found myself not tired enough to sleep on time the night before the interview(even with a whole week of adjusting). This led to me consistently getting 6-7 hours of sleep instead of the 9 hours of sleep I usually get on game day, which really sucked.</p>

<p>Ultimately, I have no idea how much the sleep problem really affected my performance, but it was enough to shake my confidence going in.</p>

<p><em>NOTE: +1 to Citadel for proactively breaking my on-site over multiple days so I can have a sane sleep schedule for their interviews. This might depend on the specific team you√¢‚Ç¨‚Ñ¢re interviewing with.</em></p>

<h2 id="which-ones-were-the-hardest">Which ones were the hardest?</h2>

<p>This is subjective, and the question can be broken up into multiple components:</p>

<ul>
  <li><strong>Time pressure - Jane Street</strong>. This is probably why I failed their interviews, which were a bit longer than usual. I tend to explain my approach before coding anything to get a confirmation on the interviewer√¢‚Ç¨‚Ñ¢s side that I√¢‚Ç¨‚Ñ¢m on the right track. I probably spent too much time explaining and didn√¢‚Ç¨‚Ñ¢t have enough time to finish the code for some interviews.</li>
  <li><strong>Math questions - Citadel</strong>. They asked me some <em>really</em> interesting math problems that aren√¢‚Ç¨‚Ñ¢t related to finance at all. I don√¢‚Ç¨‚Ñ¢t think they expect the interviewer to get 100% of the questions since whenever I solved one the interviewer was ready with another. HRT also asked some.</li>
  <li><strong>Systems design - HRT</strong>.</li>
  <li><strong>Outside-the-box problems - Databricks</strong>. They conduct one of the most unique interviews I√¢‚Ç¨‚Ñ¢ve ever had.</li>
  <li><strong>Language specific questions - Citadel/HRT</strong>. Grilled me a lot on low level C++ stuff.</li>
  <li><strong>Length of interview - HRT</strong>. I started at 8AM PST (I requested to move it to 8AM from 7AM) and finished at ~2:30PM. <strong>That is a whopping 6 hours and 30 minutes.</strong> I also did a coding challenge and 2 phone screens before I moved to on-site, totalling almost 10 hours for interviews.</li>
  <li><strong>General algorithm questions - Jane Street/HRT</strong>. I think Jane Street was a bit harder given the time pressure. The flavor of algorithm questions are also different between these firms.</li>
</ul>

<p>Once again, this breakdown is <strong>subjective</strong>. I obviously have a lot of experience interviewing with Silicon Valley companies so the novelty of questions from the finance companies added to the difficulty.</p>



<p>This was the hardest part for me. I spent two weeks suffering from analysis paralysis. I would ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/">https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/</a></em></p>]]>
            </description>
            <link>https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655799</guid>
            <pubDate>Thu, 01 Oct 2020 20:24:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asteroids: By the Numbers]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24655752">thread link</a>) | @rbanffy
<br/>
October 1, 2020 | http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1 | <a href="https://web.archive.org/web/*/http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-3855344372715435262"><p>
By 1979, arcade games were rapidly becoming more complex and colorful, and a game like <i>Asteroids </i>might have seemed quaint by comparison to the likes of <i><a href="http://www.retrogamedeconstructionzone.com/2019/09/galaxian-aesthetics-of-simple-patterns.html">Galaxian</a>, <a href="http://www.retrogamedeconstructionzone.com/2019/09/star-fire-weirdness-of-pseudo-3d.html">Star Fire</a></i>, or <i>Radar Scope.&nbsp; </i>But beneath its simple exterior lies a challenging shooter with surprisingly complex physics.&nbsp; The image below shows a sample still from it, including the player's ship (the triangle on the left), three sizes of asteroids, and an alien ship.</p><p><a href="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s1600/Asteroids_sample%2B%25282%2529.png"><img data-original-height="461" data-original-width="598" height="492" src="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s640/Asteroids_sample%2B%25282%2529.png" width="640"></a></p>

<p>
The goal of the game is to maximize your score, destroying as many asteroids and aliens as possible before you run out of ships.&nbsp; When an asteroid is hit by something (usually the player's bullets), large asteroids turn into two medium ones and medium asteroids turn into two small ones, while small asteroids and aliens are destroyed when hit.</p><p><a href="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s1600/Asteroids%2BPlay.gif"><img data-original-height="357" data-original-width="600" height="237" src="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s400/Asteroids%2BPlay.gif" width="400"></a></p>
<p>
For the designers of the game, balancing the relative sizes of the objects would have been important in such a dense field, because it determines how often things run into one another other.&nbsp; The table below outlines the sizes of the objects in <i>Asteroids</i>, expressed relative to the length of the player's ship.</p><table>
<caption>The approximate horizontal lengths of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Length (in player ship lengths)</th>
    </tr>
<tr>
    <td>Screen</td>
    <td>25 x 36</td>
    </tr>
<tr>
    <td>Large Asteroids</td>
    <td>2.4</td>
    </tr>
<tr>
    <td>Medium Asteroid</td>
    <td>1.2</td>
    </tr>
<tr>
    <td>Small Asteroid</td>
    <td>0.6</td>
    </tr>
<tr>
    <td>Alien Ship (large)</td>
    <td>1.5</td>
    </tr>
<tr>
    <td>Alien Ship (small)</td>
    <td>0.75</td>
    </tr>
</tbody>
    </table>
<p>
Notice how the medium asteroid is twice the size of the small one, and the large is twice the size of the medium.&nbsp; If you think about it, this doesn't actually make much physical sense -- you can break a two-dimensional object into four pieces half its size, not two.&nbsp; But the size ratios do make game sense, because what really matters to the player is not how much area an asteroid takes up, but how likely it is to hit them.</p><p><a href="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"><img data-original-height="281" data-original-width="170" src="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"></a></p>

<p>
In the picture above, you can see that while the four small asteroids take up less area on the screen than the big one, they present the same cross section to your ship.&nbsp; This means that breaking up the asteroids doesn't greatly increase the probability that the player will be struck by one.&nbsp; If the asteroids had been broken up into four half-sized pieces at each blow, each large asteroid would result in sixteen small ones (that's four times the cross section!) and the player would be quickly overwhelmed.&nbsp; Note that the small asteroids do move faster than the large ones, and speed increases the chance of getting hit, but I'll return to that in a moment.</p>

<p>
Another big reason that size matters in <i>Asteroids</i>&nbsp;is that it determines how close something has to be before you're likely to be able to hit it.&nbsp; In 1979, vector arcade cabinet screens had an effective resolution of 1024 x 768, and the player's ship was only connected graphically by about 20 points.&nbsp; This meant, in turn, that there were only a limited number of orientations that they could render for the ship, in this case intervals of 5 degrees.&nbsp; To see how this might affect gameplay, imagine your ship is located at the fixed position shown in the picture below.&nbsp; Anything located entirely between the two solid lines will not be accessible by your bullets because your ship can't turn to the appropriate angle to hit it.&nbsp; This restriction isn't a big deal for large asteroids, which are still accessible over most of the screen, but small asteroids can be out of reach of your guns at relatively close range, sometimes as close as 7 ship lengths away!&nbsp; So even if you aim as accurately as possible, chances are you won't be able to hit a small asteroid on the other side of the screen, at least not on your first shot.&nbsp; This is probably one of the reasons that <i>Asteroids</i>&nbsp;allows you to fire up to four bullets in succession: even if you can't hit an object right away, it will eventually move into your line of fire.</p>

<p><a href="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s1600/Asteroids_hittable%2B%25285%2529.png"><img data-original-height="397" data-original-width="1024" height="248" src="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s640/Asteroids_hittable%2B%25285%2529.png" width="640"></a></p>
<p>
And what about speed?&nbsp; There is some variability in the speeds of individual asteroids, but small asteroids can move as much as 63% faster than large ones (see the table below), meaning that even if four small asteroids present the same cross section for hitting your ship as a large one does, their higher speed means they're more likely to hit you.&nbsp; The reasoning for this is simple: the faster something moves, the longer the path it can traverse in a given amount of time, and the larger the likelihood that you'll be in that path.&nbsp; Fortunately, even the fastest asteroids are much slower than your ship, which can traverse the screen in about two seconds; so if you're skilled enough, you should be able to maneuver around the asteroid field without a problem.</p><table>
<caption>The approximate speeds of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Speed (in ship lengths per second)</th>
    </tr>
<tr>
    <td>Your ship</td>
    <td>0 - 17</td>
    </tr>
<tr>
    <td>Asteroids</td>
    <td>4 - 6.5</td>
    </tr>
<tr>
    <td>Alien ships (both sizes)</td>
    <td>4 - 6.5 (depending on your score)</td>
    </tr>
<tr>
    <td>Bullets</td>
    <td>17 (ship at rest)&nbsp;</td></tr>
</tbody></table>
<p>
One other interesting thing about speed: notice in the table above that the speed of a bullet, when fired at rest, is the same as your ship's maximum speed.&nbsp; This means that when you're moving rapidly and fire a bullet in the opposite direction of your motion, the two speeds should cancel for a stationary observer and the bullet should appear roughly stationary.</p>

<p><a href="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s1600/Asteroids_bullet_stationary.gif"><img data-original-height="175" data-original-width="468" height="239" src="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s640/Asteroids_bullet_stationary.gif" width="640"></a></p>


<div><p>
Sure enough, when I fire a bullet while moving quickly in the opposite direction, it just floats near where I fired it, allowing me to place bullets like mines for the asteroids to run into.</p>
<p>
The developers of <i>Asteroids </i>wanted the game to simulate the real laws of physics (<a href="http://www.technologyuk.net/computing/computer-gaming/gaming-landmarks-1960-1985/asteroids.shtml">see here</a>), and I think in many respects they succeeded, at least compared to most other arcade games of the time.&nbsp; It's not entirely realistic, however.&nbsp; In my article on <a href="http://www.retrogamedeconstructionzone.com/2019/10/impossible-motion-in-video-games.html">motion in early arcade games</a>, I discussed how the acceleration of the ship in <i>Asteroids</i> is too rapid for a human-occupied vehicle.&nbsp; We might suppose that the vehicle is automated, but even then, engineering spacecraft to withstand 30+ g's of acceleration is a non-trivial challenge.</p><p><a href="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s1600/Acceleration%2BAsteroids.gif"><img data-original-height="175" data-original-width="634" height="176" src="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s640/Acceleration%2BAsteroids.gif" width="640"></a></p>
<p>
Another issue is the way the asteroids break up.&nbsp; In physics, there's a principle called the conservation of momentum that says that when objects interact with one another or break apart, the total mass times the velocity must remain the same after the interaction as it was before.&nbsp; In layman's terms, this means that things can't suddenly go from moving one direction to moving in another unless there is something else carry its previous momentum.&nbsp; In the example shown below, an asteroid does just that, and the only thing that could have absorbed its previous momentum is the bullet.&nbsp; But the bullet is so tiny that it's difficult to imagine how that would be possible.</p><p><a href="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s1600/Asteroids_momentum.gif"><img data-original-height="248" data-original-width="533" height="185" src="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s400/Asteroids_momentum.gif" width="400"></a></p>

<p>
These are mere quibbles, however, and shouldn't dissuade you from giving the game a try.&nbsp; <i>Asteroids </i>ended up being one of Atari's biggest arcade hits, selling over 70,000 cabinets, and remains one of their most recognizable games to this day.&nbsp; Many gamers who grew up in the '80s, myself included, are more familiar with the Atari 2600 version of the game.&nbsp; Unfortunately, the designers had to make a lot of sacrifices in game physics in order to make it work on a home console, so I think the arcade version is really the way to go.&nbsp; Outside of visiting a vintage arcade, your best bet is probably the <a href="https://www.mamedev.org/">Multiple Arcade Machine Emulator</a> (MAME).&nbsp; Happy hunting!</p></div><div><p><span>NOTE: &nbsp;A previous version of this article stated that the game has limited pixel resolution, but <i>Asteroids </i>uses a vector display that is not composed of pixels. &nbsp;The resolution of the <i>Asteroids </i>vector display is 1024 x 768.</span></p><p><a href="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s1600/Asteroids_loop_transparent.gif"><img data-original-height="151" data-original-width="600" height="160" src="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s640/Asteroids_loop_transparent.gif" width="640"></a></p>
<br></div>
</div>
</div></div>]]>
            </description>
            <link>http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655752</guid>
            <pubDate>Thu, 01 Oct 2020 20:19:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use the internet, not just companies (2018)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24655745">thread link</a>) | @downshun
<br/>
October 1, 2020 | https://sive.rs/netskill | <a href="https://web.archive.org/web/*/https://sive.rs/netskill">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<article>
<header>


<small>2018-02-12</small>
</header>

<p>
	I‚Äôve been online since 1994, and seen so many companies come and go.
</p><p>
	In the year 2000, the place to be was mp3.com.
	Every musician would keep all of their music and fans there.
	A few years later, it was gone ‚Äî shut down ‚Äî all music and fan lists deleted.
</p><p>
	In 2005, it was MySpace.
	Again, musicians kept all of their music, photos, and fans there.
	A few years later, it was gone.
	Not shut down, but basically moot.
	There was no way to communicate with all of those people, because you didn‚Äôt have their direct contact info ‚Äî you only had their MySpace inbox, which nobody checked anymore.
</p><p>
	As I‚Äôm writing this now in 2018, it‚Äôs Facebook, YouTube, and Spotify.
	Just like with mp3.com and MySpace, people act like these websites are everything, and keep all of their music, photos, and fans there.
	By the time you read this, they might be gone.
</p><p>
<strong>
	Don‚Äôt depend on a company.
	They come and go.
</strong>
	Think long-term.
	You‚Äôre going to be creating stuff, making fans, and building relationships for the rest of your life ‚Äî much longer than these companies will last.
</p><p>
<strong>
	So have your own website.
</strong>
	Instead of sending your fans to some company‚Äôs site, send them to yours.
	Get everyone‚Äôs direct contact information so you don‚Äôt have to go through a company to reach them.
</p><p>
<strong>
	Your website should be the definitive place to get everything you create.
</strong>
	If you put your stuff on some company‚Äôs site, have it be secondary ‚Äî a copy of the stuff that‚Äôs already on your site.
	That way you can use the popular networks without depending on them.
</p><p>
	Only rely on open standards that aren‚Äôt owned by any company ‚Äî like email and the web.
</p>
<h3>
	Email skills:
</h3>
<p>
	Go into your email settings, and make sure you <strong>have a signature</strong>.
	You need this because you‚Äôre going to be emailing people who have no idea who or where you are!
	Give them some context.
	Your signature should say who, what, and where, with a URL or two.
	For example:
</p>
<pre>--
Maya Danub√©, fragrant jazz bass clarinet, New York City
http://mayadanube.com  <a href="https://sive.rs/cdn-cgi/l/email-protection" data-cfemail="3c51597c515d455d585d52495e59125f5351">[email&nbsp;protected]</a>  (917)611-5310
Watch &amp; listen: https://www.youtube.com/user/mayadanube
Friend me, baby: https://www.facebook.com/mayadanube
</pre>
<p>
	When you email people, write a <strong>descriptive subject</strong>.
	Never ‚Äúhey‚Äù or ‚Äúbooking‚Äù.
	Try ‚ÄúAvailable June 6 for showcase?‚Äù or ‚Äúintroduction to photographer‚Äù.
	This is considerate.
	Now when your email is one of hundreds in an inbox, it will say exactly what is contained inside.
</p><p>
	Make it <strong>as short as possible</strong>.
	The shorter your email, the more likely it will get a response.
	Be direct.
	Five sentences is ideal.
	If your email is too long, they are likely to procrastinate, and never get back to it.
</p><p>
	Use short paragraphs.
	Leave plenty of space.
	Reading a screen is different from reading a book.
</p>
<h3>
	Web skills:
</h3>
<p>
<strong>
	Know how to update your website.
</strong>
	Don‚Äôt depend on someone else to do this for you.
	Know how to add new songs or videos, and how to make any changes.
</p><p>
<strong>
	Know your URLs.
</strong>
	Telling someone to go search for you is like telling them to look up your phone number.
	Instead, know your exact URLs (yoursite.com, twitter.com/something, facebook.com/whatever) so you can give it to people directly.
	If you don‚Äôt, they‚Äôll probably never bother to go search for you.
</p><p>
<strong>
	Know how to make an MP3.
</strong>
	Give it a good filename like YOUR_NAME-Song_Title.mp3 (not mix7.mp3)
	Don‚Äôt use spaces in the filename.
	Edit the ID3 tags to put your full name and URL in the info, so whoever has this MP3 knows who it is and how to find you.
</p><p>
	Sorry if these sound too basic to you.
	But you‚Äôd be surprised by how many people don‚Äôt know these skills, and so are silently handicapped when interacting with the world.
</p>
<img alt="" src="https://sive.rs/images/internet-skills.gif">


</article>



</div></div>]]>
            </description>
            <link>https://sive.rs/netskill</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655745</guid>
            <pubDate>Thu, 01 Oct 2020 20:18:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why plain text emails perform better than HTML designed ones]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24655493">thread link</a>) | @pau_alcala
<br/>
October 1, 2020 | https://blog.palabra.io/plain-text-engagement | <a href="https://web.archive.org/web/*/https://blog.palabra.io/plain-text-engagement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><em>By <a href="https://www.linkedin.com/in/naara-abril-taker/">Abril Taker</a> - Content Creator at <a href="https://www.palabra.io/?utm_medium=plain-text&amp;utm_source=blog">Palabra</a></em></p><p>Plain text sounds boring? Well, let me tell you that plain text is more important than you can imagine. At <a href="https://www.palabra.io/?utm_medium=plain-text&amp;utm_source=blog">Palabra</a> we love plain text to send every email, specially our onboarding sequences. And in this article we‚Äôll share why we think you should start using it too.</p><h2>Isn‚Äôt plain text for grannies?üëµüèº</h2><p>Plain text has been around since the beginnings of the Internet. So it is understandable that some people think it is obsolete. Maybe there was a time where HTML emails were on a boom, but plain text today is more functional than ever.</p><p>Before we continue we‚Äôd like all of us to be in the same page about what plain text is:</p><p>The term Plain text, when we talk about an email, refers to the composition that consists of the copy within the style. Which means that it does not include complex formatting or styled fonts. Although it can have images and links.</p><p>Even if plain text could sound boring at first compared with HTML emails, you will discover that their use can bring many benefits in general, and especially for onboarding sequences.</p><h2>Use plain text for onboarding sequences üèÜ</h2><p>When you have a service or a product that depends, on a large portion, of having a constant flow of users, you might want to apply an onboarding sequence in order to avoid the churn rate and to connect with your community.</p><p>If you‚Äôre still in the early stage of your strategy, we recommend to read our article about <strong><a href="https://blog.palabra.io/questions-onboarding">5 questions to ask yourself before creating an onboarding email sequence</a></strong>, it will guide you in the process.</p><p>Over the years, new technologies have risen in the field of user experience. We now have many tools to call the attention of customers. This means people are getting a bunch of emails that now look like ads delivered right to your inbox.</p><p>Onboarding should look nothing like ads. That's when you start a close relationship with early users, you educate them about how to use your product better, and open communication channels.</p><h2>5 reasons why plain text is always a good idea</h2><h3>üì© It ensures deliverability</h3><p>The number one thing that you need to do to engage with someone is to get their attention. And for that, you need to get them to open your emails.</p><p>As we said before, HTML emails have images, links, GIFs, all sorts of things that attract the attention of email filters. So they‚Äôre more susceptible to being redirected to the spam folder if they have broken links or suspicious behaviours.</p><p>Since plain text emails don‚Äôt contain much more information than text, it‚Äôs much more likely that they will not alert spam filters.</p><p>Also, plain text emails seem more ‚Äúreal‚Äù to your email filters. And that's also handy for your readers!</p><h3>üìú It feels more personal</h3><p>Once your customers open your emails, you don‚Äôt want them to say ‚Äúugh, another stupid corporative email. DELETE‚Äù. That‚Äôs probably the worst case scenario.</p><p>Plain text has been proved to have higher click-through rates. Not just because they can pass spam filters, but also because they feel more personal. They look like something a real person sends, to offer information instead of driving sales.</p><p>Then, when you receive a plain text email, it is more associated with a regular person, someone who just wants to talk and know about you as an individual (and not as a target). Your users can perceive you more relatable, human and trust-worthy ‚ú®.</p><h3>üó£Ô∏è Starts 1-1 conversations</h3><p>As you can see, there‚Äôs a progression. And with plain text you help your emails to be delivered and opened. Do you know what is even better? If your users answer the email!</p><p>We like plain text precisely because of this. Through this kind of emails, we‚Äôve received feedback from our users that was very valuable for us to grow as a company and as a team. They respond because there's a real email address from a real person to answer to.</p><p>We send onboarding emails that appeal to conversation. Having a dialog is the fuel to power the relationship with the users. We try to build a space where the user can feel part of the process and can say something to improve the use of a tool that is so necessary in his life.</p><h3>üë©üèº‚Äçü¶Ω Is more accessible</h3><p>Now we want to highlight something that usually goes unnoticed. Plain text is readable for accessibility systems. This kind of emails has an ethical benefit, because they‚Äôre reachable for people with different needs.</p><p>When you send an HTML email, you‚Äôre making it more difficult for a blind person, for example, to understand your message.</p><p>At this point, it is good to ask ourselves if our emails can be accessed by a blind person using a screen reader.</p><h3>üîÆ Adapts to new technology</h3><p>From the previous point it follows the fact that plain text is more readable. I personally was surprised to discover that you can read your emails in smartwatches and smart assisters,or that you can obtain a more comprehensible preview of the content.</p><p>I know, it is super obvious when you think about it. But we do not always have in mind that there are other kinds of displays where people read their emails or notifications. And that we have to be ahead of the new possibilities, because we don‚Äôt know what type of devices will be developed in the future.</p><p>In this case, keeping it simple will ensure you that people can read your messages.</p><p>So, now you know, don‚Äôt be shy and start sending those emails and talking to your users. You may be pleasantly surprised with what you discover.</p><hr><p>Hope you enjoyed this post! If you are curious about what you can do with Palabra or would just like to try it go ahead and <a href="https://www.palabra.io/?utm_medium=plain-text&amp;utm_source=blog">create an account here</a>.</p></section></div>]]>
            </description>
            <link>https://blog.palabra.io/plain-text-engagement</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655493</guid>
            <pubDate>Thu, 01 Oct 2020 19:54:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Next-Gen Rust Web Apps]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654891">thread link</a>) | @yannikyeo
<br/>
October 1, 2020 | https://blog.shortepic.com/blog/first/ | <a href="https://web.archive.org/web/*/https://blog.shortepic.com/blog/first/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>This is an homage to this absolute <a href="http://www.sheshbabu.com/posts/rust-wasm-yew-single-page-application/">work of art</a> by Shesh Babu.</p>

<p>Rust's strong typing and fearless concurrency means we can skip virtual DOM differencing. </p>
<p>In the JavaScript world, avoiding the vDOM is the bread and butter of <a href="https://svelte.dev/">Svelte</a> 
started by Rich Harris, which uses compile-time code generation to assist.</p>
<p>When I can't have static typing I love Clojure, and have spent some time reviewing and 
playing with the stupendous full-stack Clojure SPA framework <a href="http://book.fulcrologic.com/">Fulcro</a> 
by Tony Kay (and associated back-end enabler <a href="https://blog.wsscode.com/pathom/">Pathom</a> 
by Wilker Lucio). It does use vDOM, leveraging Clojure immutable/concurrent data structures 
for time travel superpowers.</p>
<p>For me, the major innovation (among many) in Fulcro is the use of a browser-side normalised database 
which is queried to populate properties for components. This means that updating (<em>mutating</em>) 
a uniquely-keyed item results in the update trivially propagating to any and all components 
referencing the data through that identifier. In Shesh Babu's language: all state is App state.</p>
<p>This article, or series of articles, is going to share my findings and thinking on the 
state of the nation in Rust front-end frameworks which are avoiding the vDOM strategy.</p>
<p>There are actually two Rust front-end frameworks with significant progress already, and they are 
awesome:</p>
<ul>
<li><a href="https://crates.io/crates/mogwai">mogwai</a> by Schell Scivally</li>
<li><a href="https://crates.io/crates/valerie">valerie</a> by Emmanuel Antony</li>
</ul>

<p>The official React site offers a <a href="https://reactjs.org/tutorial/tutorial.html">guided introduction</a> 
by progressively implementing a client-side tic-tac-toe game (also known as <em>noughts and crosses</em>). 
They don't explore a back-end, routing or forms, or many of the other SPA complexities. </p>
<p>For us, it is just enough to highlight the potential of the two Rust frameworks above and paint 
a picture of how those advanced extensions can be easily incorporated, and gives us a solid 
reference point from the old world.</p>

<p>This is the first in a series of articles showing how the two frameworks might attack the example 
application, and then show some code which extends the frameworks to incorporate Fulcro-like app 
state.</p>
<p>My code will concentrate on the ergonomics of the frameworks from the perspective of the SPA-writer.</p>
<p>Next up, I'll show an implementation of the game in Valerie.</p>
<p><a href="https://blog.shortepic.com/blog/second/">On to the first code sample</a>.</p>

  </article></div>]]>
            </description>
            <link>https://blog.shortepic.com/blog/first/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654891</guid>
            <pubDate>Thu, 01 Oct 2020 19:02:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Incarceration in Real Numbers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654820">thread link</a>) | @tmsh
<br/>
October 1, 2020 | https://mkorostoff.github.io/incarceration-in-real-numbers/ | <a href="https://web.archive.org/web/*/https://mkorostoff.github.io/incarceration-in-real-numbers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div id="prisoners">
    
    
    
    

    <div>
      <p>The United States holds more people in jails and prisons than any other country by far, both in absolute numbers and as a percentage of population.</p>
    </div>

    <div id="per-one-hundred">
      <div id="per-one-hundred-inner">
        <h2>Incarcerated per 100,000 residents <sup>[<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#incarceration-rates" target="_blank"></a>]</sup></h2>
        <p><span>USA (698)</span></p>
        <p><span>El Salvador (590)</span></p>
        <p><span>Turkmenistan (552)</span></p>
        <p><span>Thailand (531)</span></p>
        <p><span>Rwanda (511)</span></p>
        <p><span>Cuba (510)</span></p>
        <p><span>Panama (401)</span></p>
        <p><span>Costa Rica (374)</span></p>
        <p><span>Cayman Islands (365)</span></p>
        <p><span>Russia (363)</span></p>
        <p><span>Belize (356)</span></p>
        <p><span>Brazil (348)</span></p>
        <p><span>Belarus (343)</span></p>
        <p><span>Nicaragua (332)</span></p>
        <p><span>Turkey (324)</span></p>
        <p><span>Puerto Rico (313)</span></p>
        <p><span>Brunei Darussalam (307)</span></p>
        <p><span>Cape Verde (296)</span></p>
        <p><span>Uruguay (295)</span></p>
        <p><span>Namibia (295)</span></p>
        <p><span>Iran (294)</span></p>
        <p><span>Trinidad and Tobago (292)</span></p>
        <p><span>Guyana (284)</span></p>
        <p><span>Peru (278)</span></p>
        <p><span>South Africa (275)</span></p>
        <p><span>Georgia (262)</span></p>
        <p><span>Taiwan (258)</span></p>
        <p><span>Swaziland (258)</span></p>
        <p><span>Greenland (249)</span></p>
        <p><span>Colombia (246)</span></p>
        <p><span>French Guiana (243)</span></p>
        <p><span>Gabon (241)</span></p>
        <p><span>Morocco (237)</span></p>
        <p><span>Dominican Republic (237)</span></p>
        <p><span>Cura√É¬ßao (236)</span></p>
        <p><span>Azerbaijan (235)</span></p>
        <p><span>Israel (234)</span></p>
        <p><span>Bahrain (234)</span></p>
        <p><span>Ecuador (233)</span></p>
        <p><span>Macau (233)</span></p>
        <p><span>Chile (232)</span></p>
        <p><span>Argentina (230)</span></p>
        <p><span>Malaysia (230)</span></p>
        <p><span>Honduras (229)</span></p>
        <p><span>Lithuania (221)</span></p>
        <p><span>Cambodia (220)</span></p>
        <p><span>Martinique (215)</span></p>
        <p><span>Fiji (210)</span></p>
        <p><span>Botswana (208)</span></p>
        <p><span>Mauritius (203)</span></p>
        <p><span>New Zealand (201)</span></p>
        <p><span>Paraguay (199)</span></p>
        <p><span>Singapore (199)</span></p>
        <p><span>Jordan (198)</span></p>
        <p><span>Saudi Arabia (197)</span></p>
        <p><span>Czech Republic (197)</span></p>
        <p><span>Poland (195)</span></p>
        <p><span>Tunisia (195)</span></p>
        <p><span>Slovakia (195)</span></p>
        <p><span>Moldova (194)</span></p>
        <p><span>New Caledonia (189)</span></p>
        <p><span>Estonia (187)</span></p>
        <p><span>Latvia (183)</span></p>
        <p><span>Montenegro (183)</span></p>
        <p><span>Suriname (183)</span></p>
        <p><span>Philippines (179)</span></p>
        <p><span>Venezuela (178)</span></p>
        <p><span>Albania (177)</span></p>
        <p><span>Hungary (173)</span></p>
        <p><span>Myanmar (171)</span></p>
        <p><span>Australia (170)</span></p>
        <p><span>Mexico (163)</span></p>
        <p><span>Kyrgyzstan (161)</span></p>
        <p><span>Bolivia (158)</span></p>
        <p><span>Kazakhstan (156)</span></p>
        <p><span>Serbia (156)</span></p>
        <p><span>Algeria (151)</span></p>
        <p><span>Uzbekistan (150)</span></p>
        <p><span>Scotland (149)</span></p>
        <p><span>Ukraine (148)</span></p>
        <p><span>Bhutan (145)</span></p>
        <p><span>Lebanon (144)</span></p>
        <p><span>Guatemala (143)</span></p>
        <p><span>England &amp; Wales (140)</span></p>
        <p><span>Nauru (140)</span></p>
        <p><span>Libya (139)</span></p>
        <p><span>Jamaica (138)</span></p>
        <p><span>Malta (131)</span></p>
        <p><span>Laos (130)</span></p>
        <p><span>Vietnam (128)</span></p>
        <p><span>Ethiopia (127)</span></p>
        <p><span>Micronesia (127)</span></p>
        <p><span>Guernsey (127)</span></p>
        <p><span>Iraq (126)</span></p>
        <p><span>Portugal (125)</span></p>
        <p><span>Bulgaria (125)</span></p>
        <p><span>Isle of Man (125)</span></p>
        <p><span>Spain (124)</span></p>
        <p><span>Uganda (124)</span></p>
        <p><span>Cameroon (124)</span></p>
        <p><span>Zambia (123)</span></p>
        <p><span>Tajikistan (121)</span></p>
        <p><span>China (120)</span></p>
        <p><span>Kuwait (117)</span></p>
        <p><span>Egypt (116)</span></p>
        <p><span>Zimbabwe (114)</span></p>
        <p><span>North Macedonia (112)</span></p>
        <p><span>Mongolia (110)</span></p>
        <p><span>Canada (107)</span></p>
        <p><span>Romania (107)</span></p>
        <p><span>Hong Kong (106)</span></p>
        <p><span>France (105)</span></p>
        <p><span>Sri Lanka (105)</span></p>
        <p><span>Luxembourg (105)</span></p>
        <p><span>UAE (104)</span></p>
        <p><span>Kenya (102)</span></p>
        <p><span>Italy (101)</span></p>
        <p><span>Indonesia (99)</span></p>
        <p><span>Austria (98)</span></p>
        <p><span>Belgium (95)</span></p>
        <p><span>Greece (95)</span></p>
        <p><span>Kosovo (95)</span></p>
        <p><span>Madagascar (93)</span></p>
        <p><span>Angola (93)</span></p>
        <p><span>Lesotho (92)</span></p>
        <p><span>Afghanistan (87)</span></p>
        <p><span>Cyprus (86)</span></p>
        <p><span>Burundi  (85)</span></p>
        <p><span>Monaco (83)</span></p>
        <p><span>Cote d'Ivoire  (82)</span></p>
        <p><span>Switzerland  (81)</span></p>
        <p><span>Haiti  (80)</span></p>
        <p><span>Croatia  (79)</span></p>
        <p><span>Ireland (79)</span></p>
        <p><span>Nepal  (79)</span></p>
        <p><span>Northern Ireland (78)</span></p>
        <p><span>Germany  (77)</span></p>
        <p><span>Armenia  (76)</span></p>
        <p><span>Malawi (76)</span></p>
        <p><span>Slovenia (69)</span></p>
        <p><span>Benin  (68)</span></p>
        <p><span>Senegal  (68)</span></p>
        <p><span>Djibouti (66)</span></p>
        <p><span>Togo (66)</span></p>
        <p><span>Andorra  (64)</span></p>
        <p><span>Denmark  (63)</span></p>
        <p><span>Equatorial Guinea  (63)</span></p>
        <p><span>Mozambique (63)</span></p>
        <p><span>Papua New Guinea (62)</span></p>
        <p><span>Sweden (61)</span></p>
        <p><span>Netherlands  (61)</span></p>
        <p><span>Norway (60)</span></p>
        <p><span>Sierra Leone (60)</span></p>
        <p><span>Syria  (60)</span></p>
        <p><span>Chad (59)</span></p>
        <p><span>Tanzania (59)</span></p>
        <p><span>Finland  (53)</span></p>
        <p><span>Mauritania (53)</span></p>
        <p><span>Qatar  (53)</span></p>
        <p><span>Yemen  (53)</span></p>
        <p><span>Bangladesh (52)</span></p>
        <p><span>Ghana  (52)</span></p>
        <p><span>Sudan  (52)</span></p>
        <p><span>Timor-Leste (52)</span></p>
        <p><span>Liberia  (50)</span></p>
        <p><span>South Sudan  (50)</span></p>
        <p><span>Niger  (44)</span></p>
        <p><span>Burkina Faso (39)</span></p>
        <p><span>Japan  (39)</span></p>
        <p><span>Pakistan (38)</span></p>
        <p><span>Iceland  (37)</span></p>
        <p><span>Nigeria  (36)</span></p>
        <p><span>Oman (36)</span></p>
        <p><span>India  (34)</span></p>
        <p><span>Mali (33)</span></p>
        <p><span>Gambia (31)</span></p>
        <p><span>Liechtenstein  (31)</span></p>
        <p><span>Democratic Republic of Congo (29)</span></p>
        <p><span>Guinea (28)</span></p>
        <p><span>Congo (27)</span></p>
        <p><span>Central African Republic (16)</span></p>
        <p><span>Guinea Bissau  (10)</span></p>
        <p><span>San Marino (6)</span></p>
      <p><a onclick="toggleExpand('per-one-hundred', 'per-one-hundred-inner')">Expand ‚ñº</a>
      </p></div>
    </div>

    <div id="country-rank">
      <div id="country-rank-inner">
        <h2>Number of people incarcerated <sup>[<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#incarceration-rates" target="_blank"></a>]</sup></h2>
        <p>USA (2.3M)</p>
        <p><span>China (1.7M)</span></p>
        <p><span>Brazil (747K)</span></p>
        <p><span>Russian Federation (524K)</span></p>
        <p><span>India (466K)</span></p>
        <p><span>Thailand (368K)</span></p>
        <p><span>Indonesia (267K)</span></p>
        <p><span>Turkey (265K)</span></p>
        <p><span>Iran (240K)</span></p>
        <p><span>Philippines (215K)</span></p>
        <p><span>Mexico (203K)</span></p>
        <p><span>South Africa (163K)</span></p>
        <p><span>Vietnam (124K)</span></p>
        <p><span>Colombia (123K)</span></p>
        <p><span>Ethiopia (114K)</span></p>
        <p><span>Egypt (106K)</span></p>
        <p><span>Argentina (103K)</span></p>
        <p><span>Myanmar  (92K)</span></p>
        <p><span>Peru (91K)</span></p>
        <p><span>Bangladesh (88K)</span></p>
        <p><span>Morocco (86K)</span></p>
        <p><span>United Kingdom: England &amp; Wales (83K)</span></p>
        <p><span>Pakistan (77K)</span></p>
        <p><span>Poland (74K)</span></p>
        <p><span>Malaysia (74K)</span></p>
        <p><span>Nigeria (73K)</span></p>
        <p><span>France (71K)</span></p>
        <p><span>Rwanda (65K)</span></p>
        <p><span>Germany (64K)</span></p>
        <p><span>Algeria (63K)</span></p>
        <p><span>Saudi Arabia (61K)</span></p>
        <p><span>Taiwan (61K)</span></p>
        <p><span>Italy (61K)</span></p>
        <p><span>Spain (58K)</span></p>
        <p><span>Cuba (57K)</span></p>
        <p><span>Venezuela (57K)</span></p>
        <p><span>Uganda (55K)</span></p>
        <p><span>Republic of  (55K)</span></p>
        <p><span>Ukraine (53K)</span></p>
        <p><span>Kenya (51K)</span></p>
        <p><span>Japan (49K)</span></p>
        <p><span>Iraq (45K)</span></p>
        <p><span>Uzbekistan (44K)</span></p>
        <p><span>Australia (43K)</span></p>
        <p><span>Chile (43K)</span></p>
        <p><span>Ecuador (40K)</span></p>
        <p><span>Canada (40K)</span></p>
        <p><span>El Salvador (38K)</span></p>
        <p><span>Cambodia (37K)</span></p>
        <p><span>Tanzania (36K)</span></p>
        <p><span>Belarus (33K)</span></p>
        <p><span>Afghanistan (31K)</span></p>
        <p><span>Cameroon (31K)</span></p>
        <p><span>Turkmenistan (30K)</span></p>
        <p><span>Kazakhstan (29K)</span></p>
        <p><span>Dominican Republic (26K)</span></p>
        <p><span>Guatemala (25K)</span></p>
        <p><span>Madagascar (25K)</span></p>
        <p><span>Angola (24K)</span></p>
        <p><span>Nepal (24K)</span></p>
        <p><span>Sri Lanka (23K)</span></p>
        <p><span>Azerbaijan (23K)</span></p>
        <p><span>Zambia (23K)</span></p>
        <p><span>Tunisia (23K)</span></p>
        <p><span>Cote d'Ivoire (21K)</span></p>
        <p><span>Czech Republic (21K)</span></p>
        <p><span>Sudan (21K)</span></p>
        <p><span>Nicaragua (21K)</span></p>
        <p><span>Romania (21K)</span></p>
        <p><span>Democratic Republic of Congo (21K)</span></p>
        <p><span>Honduras (21K)</span></p>
        <p><span>Jordan (20K)</span></p>
        <p><span>Mozambique (20K)</span></p>
        <p><span>Zimbabwe (19K)</span></p>
        <p><span>Israel (19K)</span></p>
        <p><span>Costa Rica (19K)</span></p>
        <p><span>Bolivia (18K)</span></p>
        <p><span>Panama (17K)</span></p>
        <p><span>Hungary (17K)</span></p>
        <p><span>Ghana (15K)</span></p>
        <p><span>Malawi (15K)</span></p>
        <p><span>Yemen (14K)</span></p>
        <p><span>Paraguay (14K)</span></p>
        <p><span>Portugal (13K)</span></p>
        <p><span>Singapore (12K)</span></p>
        <p><span>Senegal (12K)</span></p>
        <p><span>Belgium (11K)</span></p>
        <p><span>Serbia (11K)</span></p>
        <p><span>Burundi (11K)</span></p>
        <p><span>Slovakia (11K)</span></p>
        <p><span>Syria (11K)</span></p>
        <p><span>Puerto Rico  (10K)</span></p>
        <p><span>Netherlands (10K)</span></p>
        <p><span>Uruguay (10K)</span></p>
        <p><span>Greece (10K)</span></p>
        <p><span>Kyrgyzstan (10K)</span></p>
        <p><span>New Zealand (10K)</span></p>
        <p><span>United Arab Emirates (10K)</span></p>
        <p><span>Georgia (10K)</span></p>
        <p><span>Niger (10K)</span></p>
        <p><span>Tajikistan (9K)</span></p>
        <p><span>Libya (9K)</span></p>
        <p><span>Bulgaria (9K)</span></p>
        <p><span>Laos (9K)</span></p>
        <p><span>Haiti (9K)</span></p>
        <p><span>Chad (9K)</span></p>
        <p><span>Austria (9K)</span></p>
        <p><span>United Kingdom: Scotland (8K)</span></p>
        <p><span>Hong Kong  (8K)</span></p>
        <p><span>Benin (8K)</span></p>
        <p><span>Burkina Faso (8K)</span></p>
        <p><span>Namibia (7K)</span></p>
        <p><span>South Sudan (7K)</span></p>
        <p><span>Lebanon (7K)</span></p>
        <p><span>Switzerland (7K)</span></p>
        <p><span>Moldova  (7K)</span></p>
        <p><span>Sweden (6K)</span></p>
        <p><span>Lithuania (6K)</span></p>
        <p><span>Mali (5K)</span></p>
        <p><span>Togo (5K)</span></p>
        <p><span>Papua New Guinea (5K)</span></p>
        <p><span>Albania (5K)</span></p>
        <p><span>Sierra Leone (5K)</span></p>
        <p><span>Kuwait (5K)</span></p>
        <p><span>Gabon (4K)</span></p>
        <p><span>Botswana (4K)</span></p>
        <p><span>Trinidad and Tobago (4K)</span></p>
        <p><span>Ireland, Republic of (4K)</span></p>
        <p><span>Jamaica (4K)</span></p>
        <p><span>Guinea  (4K)</span></p>
        <p><span>Denmark (4K)</span></p>
        <p><span>Latvia (4K)</span></p>
        <p><span>Bahrain (3K)</span></p>
        <p><span>Swaziland/eSwatini (3K)</span></p>
        <p><span>Mongolia (3K)</span></p>
        <p><span>Croatia (3K)</span></p>
        <p><span>Norway (3K)</span></p>
        <p><span>Finland (3K)</span></p>
        <p><span>Mauritius (3K)</span></p>
        <p><span>Estonia (2K)</span></p>
        <p><span>Liberia (2K)</span></p>
        <p><span>North Macedonia (2K)</span></p>
        <p><span>Mauritania (2K)</span></p>
        <p><span>Armenia (2K)</span></p>
        <p><span>Guyana (2K)</span></p>
        <p><span>Lesotho (2K)</span></p>
        <p><span>Fiji (2K)</span></p>
        <p><span>Maldives (2K)</span></p>
        <p><span>Bahamas (2K)</span></p>
        <p><span>Bosnia and Herzegovina: Federation (2K)</span></p>
        <p><span>Kosovo/Kosova (2K)</span></p>
        <p><span>Macau  (2K)</span></p>
        <p><span>Cape Verde  (2K)</span></p>
        <p><span>United Kingdom: Northern Ireland (1K)</span></p>
        <p><span>Slovenia (1K)</span></p>
        <p><span>Brunei Darussalam (1K)</span></p>
        <p><span>Oman (1K)</span></p>
        <p><span>Belize (1K)</span></p>
        <p><span>Congo  (1K)</span></p>
      <p><a onclick="toggleExpand('country-rank', 'country-rank-inner')">Expand ‚ñº</a>
      </p></div>
    </div>

    <div>
      <p>There are more incarcerated people than members of almost any profession. There are more incarcerated people than military personnel. There are more incarcerated people than bus drivers, bar tenders, and hair dressers combined. [<a target="_blank" href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#incarceration-compared-to-professions"></a>]</p>
    </div>

    <div>
      <p>
        More Americans are incarcerated today than there have been Americans killed in all of the wars in all of history combined.
      </p>
    </div>

    <div id="casualties">
      <div>
        <h2>Incarceration compared to casualties of war <sup>[<a target="_blank" href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#american-war-dead"></a>]</sup></h2>
        <p>Americans currently incarcerated (2.3M)</p>
        <p>American war dead, all of history combined (1.3M)</p>
        <p>American war wounded, all of history combined (1.5M)</p>
      </div>
    </div>

    <div>
      <p>While the incarcerated population is unfathomably large, it is just the tip of the iceberg.</p>
    </div>

    <div id="correctional-population">
      <div>
        <h2>The total correctional population <sup>[<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#total-correctional-population" target="_blank"></a>]</sup></h2>
        <div>

          <div>
            <p>Currently incarcerated (2.3M)</p>
          </div>

          <div>
            <p>Will be incarcerated this year (4.9M)</p>
          </div>

          <div>
            <p>Alive currently, will go to prison ever (10.9M)</p>
          </div>

          <div>
            <p>Has a criminal record (77M)</p>
          </div>

          <div>
            <p>Ever had an immediate family member incarcerated (113M)</p>
          </div>

        </div>
      </div>
    </div>

    <div>
      <p>Almost no one gets a trial.</p>
    </div>

    <div>
      <p><img src="https://mkorostoff.github.io/incarceration-in-real-numbers/img/person/blue.svg">Notice that the background icons have changed. The blue icons are the portion of incarcerated people who got trials, around 2%.</p>
    </div>

    <div>
      <p>Almost all accused people are extorted into taking plea bargains under the threat of a longer sentence, the ruinous cost of mounting a defense, and the wildly under-resourced public defender system. [<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#plea-bargains" target="_blank"></a>]</p>
    </div>

    <div>
      <p>No other country on earth incarcerates so many people without trial. ‚Ä¶</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mkorostoff.github.io/incarceration-in-real-numbers/">https://mkorostoff.github.io/incarceration-in-real-numbers/</a></em></p>]]>
            </description>
            <link>https://mkorostoff.github.io/incarceration-in-real-numbers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654820</guid>
            <pubDate>Thu, 01 Oct 2020 18:57:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hosting a blog on Azure for $2.5 per month]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654536">thread link</a>) | @fleide
<br/>
October 1, 2020 | https://www.eiden.ca/azure-static-blog/ | <a href="https://web.archive.org/web/*/https://www.eiden.ca/azure-static-blog/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
        <p>High level picture of hosting a static site (blog) on Azure with details on how to wire a custom domain (root and www) with HTTPS support. It‚Äôs actually easier that it sounds.</p>

<!--more-->

<p>Let‚Äôs start by noting that $2 out of the $2.5 mentioned in the title are for the custom domain name and associated SSL certificate (for HTTPS). Static content hosting, CDN (<a href="https://en.wikipedia.org/wiki/Content_delivery_network">content delivery network</a>) and networking in Azure cost less than 50 cents per month for this application. To be fair, this is not the most read blog of the Internet.</p>

<p>Also I‚Äôm using <a href="https://jekyllrb.com/">Jekyll</a> for this blog, and it‚Äôs been good to me so far.</p>

<h2 id="summary">Summary</h2>

<p>The main components used are:</p>

<ul>
  <li>From non-Microsoft providers
    <ul>
      <li>a <strong>custom domain name</strong> from a registrar of our choosing (I‚Äôm using <a href="https://www.gandi.net/en-CA">Gandi</a>) - here <code>eiden.ca</code></li>
      <li>a <strong>SSL certificate</strong> to enable HTTPS, I recommend Namecheap (<a href="https://www.namecheap.com/security/ssl-certificates/comodo/positivessl/">PositiveSSL</a>) to procure one. This certificate will need to be generated for the custom domain name we created above (we‚Äôll see how). <strong>THIS IS IF</strong> you want HTTPS for the <strong>root</strong> of the custom domain (<a href="https://eiden.ca/">https://eiden.ca</a>), even if you just want it to redirect to <strong>www</strong>. This was a must have for me, and the reason for the existence of this very article. If you don‚Äôt care about the root, you can use the <a href="https://docs.microsoft.com/en-us/azure/cdn/cdn-custom-ssl?tabs=option-1-default-enable-https-with-a-cdn-managed-certificate">managed certificate included</a> in Azure CDN (which at the time of writing doesn‚Äôt support root).</li>
    </ul>
  </li>
  <li>In Azure
    <ul>
      <li>a <strong>Storage Account</strong> with <a href="https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-static-website">static web hosting</a> enabled. That feature allows to serve static content (html, css, javascript, images) directly from a container</li>
      <li>a <strong>Key Vault</strong> to help generate the certificate and store it once issued by the provider</li>
      <li>a <strong>CDN Profile</strong>, to cache the content and optimize performance and cost. The CDN profile loads our content from the storage account, distributes in its worldwide network, and serves to visitors in a scalable fashion automatically</li>
      <li>a <strong>DNS Zone</strong>, to manage the name resolution of our custom domain and point the traffic towards the CDN profile</li>
    </ul>
  </li>
</ul>

<p>On a picture:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png" alt="Schema of the solution, all details will be explained below in this post"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png">figure 1 : Schema of the solution</a></em></p>

<p>Let‚Äôs jump into it.</p>

<h2 id="step-1-and-2--starting-with-the-static-website-and-the-cdn-profile">Step 1 and 2 : Starting with the Static Website and the CDN Profile</h2>

<p>First we will follow the <strong>parts 1 and 2</strong> from this <a href="https://www.wrightfully.com/azure-static-website-custom-domain-https">awesome tutorial</a> from John M. Wright to get the storage account and CDN profile set up. <strong>Let‚Äôs not go further than part 2</strong>, we‚Äôll switch to another guide for the following step.</p>

<p>In part 2, I‚Äôve personally used the <code>Azure CDN from Microsoft</code> and it went great.</p>

<p>At this point, what we should have is this:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step1.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step1.png" alt="Step 1 : a storage account with static hosting and a CDN endpoint"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step1.png">figure 2 : a storage account with static hosting and a CDN endpoint</a></em></p>

<p>We can already see our content online at the following URLs:</p>

<ul>
  <li><code>https://&lt;sa&gt;.web.core.windows.net</code>, directly from the storage account</li>
  <li><code>https://&lt;cdn&gt;.azureedge.net</code>, from the CDN endpoint</li>
</ul>

<p>To be noted that to upload our content to the <code>$web</code> container of the storage account, the best option is to use the <a href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli">Azure CLI</a> or <a href="https://azure.microsoft.com/en-us/features/storage-explorer/">Azure Storage Explorer</a>. I tend to default on PowerShell but here <code>Set-AzStorageBlobContent</code> doesn‚Äôt manage the content-types of the files it uploads.</p>

<p>The syntax in the CLI is straightforward (in a PowerShell host, cmd or bash terminal) :</p>

<pre><code># Here the parameter syntax is PowerShell and I'm already logged in the CLI via az login
$contentLocalPath = "C:\..."
$storageAccountName = "mystorageaccount"
az storage blob upload-batch -s $contentLocalPath -d '$web' --account-name $storageAccountName
</code></pre>

<h2 id="step-3--adding-a-dns-zone">Step 3 : Adding a DNS Zone</h2>

<p>To add the DNS Zone, let‚Äôs switch to the <strong>part 3</strong> of this <a href="https://the.aamodt.family/rune/2020/01/08/tutorial-azure-website.html#step-3-set-up-dns-configuration">exhaustive guide</a> from Rune Aamodt.</p>

<p>Here we will <strong>not only</strong> create a record for the <strong>www subdomain</strong> (type <code>CNAME</code>, alias record set to the CDN endpoint) like in the guide, but also for the <strong>root (apex) domain</strong> (type <code>A</code>, alias record set to the same CDN endpoint).</p>

<p>This is how it should look now (<strong>bold</strong> being the ones we created above):</p>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>TTL</th>
      <th>Value</th>
      <th>Alias resource type</th>
      <th>Alias target</th>
      <th>Comment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>@</strong></td>
      <td><strong>A</strong></td>
      <td>3600</td>
      <td>-</td>
      <td>Azure CDN</td>
      <td>eiden-ca</td>
      <td><strong>Root/apex domain record</strong></td>
    </tr>
    <tr>
      <td>@</td>
      <td>NS</td>
      <td>172800</td>
      <td>ns1-07.azure-dns.com‚Ä¶</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Azure stuff</td>
    </tr>
    <tr>
      <td>@</td>
      <td>SOA</td>
      <td>3600</td>
      <td>Email:‚Ä¶ Host: ns1-07.azure-dns.com‚Ä¶</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Azure stuff</td>
    </tr>
    <tr>
      <td>@</td>
      <td>MX</td>
      <td>3600</td>
      <td>10 spool.mail.gandi.net.,50 fb.mail.gandi.net.</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Gandi stuff, for the email addresses of the domain</td>
    </tr>
    <tr>
      <td>@</td>
      <td>TXT</td>
      <td>3600</td>
      <td>‚Äúv=spf1 include:_mailcust.gandi‚Ä¶</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Gandi stuff, for the email addresses of the domain</td>
    </tr>
    <tr>
      <td>cdnverify</td>
      <td>CNAME</td>
      <td>3600</td>
      <td>cdnverify.eiden-ca.azure‚Ä¶</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Verification record created automatically for alias record sets</td>
    </tr>
    <tr>
      <td>sa</td>
      <td>CNAME</td>
      <td>3600</td>
      <td>external.simpleanalytics.com.</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Record required by the analytics provider I use here</td>
    </tr>
    <tr>
      <td><strong>www</strong></td>
      <td><strong>CNAME</strong></td>
      <td>3600</td>
      <td>-</td>
      <td>Azure CDN</td>
      <td>eiden-ca</td>
      <td><strong>www subdomain record</strong></td>
    </tr>
    <tr>
      <td>cdnverify.www</td>
      <td>CNAME</td>
      <td>3600</td>
      <td>cdnverify.eiden-ca.azure‚Ä¶</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Verification record created automatically for alias record sets</td>
    </tr>
  </tbody>
</table>

<p>This is where we will have to log in to the admin portal of our Domain Registrar (Gandi for me) to switch our custom domain to use <strong>external nameservers</strong>. We will provide the 4 Azure ones listed in our DNS zone.</p>

<p>This can be a frustrating step since making changes to DNS records can take hours to take effect. Let‚Äôs try and be patient‚Ä¶</p>

<p>On <strong>Gandi</strong> it looks like this:</p>

<p><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3_gandi.jpg" alt="Step 3 : Screenshot of the admin portal in Gandi"></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3_gandi.jpg">figure 3 : updating nameservers in Gandi</a></em></p>

<p>Now that we have the DNS Zone setup, the situation looks like that:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3.png" alt="Step 3 : A DNS Zone is added to the picture, but the CDN profile still needs to be updated"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3.png">figure 4 : A DNS Zone is added to the picture, but the CDN profile still needs to be updated</a></em></p>

<p>Now let‚Äôs head back to the CDN endpoint to add the custom domains we just created here.</p>

<h2 id="step-4--enabling-https-for-the-cdn-endpoint-custom-domains">Step 4 : Enabling HTTPS for the CDN Endpoint Custom Domains</h2>

<p>We will head back to the first tutorial, but <strong>before let‚Äôs quickly sum up the situation</strong>. As I mentioned in the summary, Azure CDN offers managed certificate for HTTPS, but at the time of writing they are not available for the root / apex domain.</p>

<p>This is why we need to bring our own certificate.</p>

<p>Before heading back into the tutorial, let‚Äôs review the 3 high level steps of that process:</p>

<ol>
  <li>In an Azure Key Vault, we will create a new certificate that will be issued by a <strong>non-integrated</strong> CA (Namecheap). <strong>Contrary</strong> to what‚Äôs in the guide, use <strong>PKCS#12</strong> (even if we don‚Äôt understand the details, it‚Äôs just easier)</li>
  <li>We will then download the CSR (<code>Certificate Signing Request</code>) from Azure Key Vault, upload it to our SSL certificate provider to get processed, get the PKCS#12 file generated there back into Azure Key Vault (<code>merge signed request</code>)</li>
  <li>Back in the CDN Endpoint, we will create the custom domains (root and www), with HTTPS, using our own certificate hosted in Key Vault</li>
</ol>

<p>So let‚Äôs head back to <a href="https://www.wrightfully.com/azure-static-website-custom-domain-https">the tutorial</a> from John for <strong>part 4 and 5</strong> (sorry there‚Äôs no direct links) that explains everything in details.</p>

<h2 id="step-5--adding-cdn-rules">Step 5 : Adding CDN rules</h2>

<p>Finally, we need to add some rules in the CDN Rules engine to sort traffic coming from the root and subdomain on both HTTP and HTTPS. I wanted everything to end on <code>https://www.eiden.ca</code>, but you can adapt the rules below for a different result:</p>

<ul>
  <li>Rule 1 : <code>http://</code> requests need to be redirect to <code>https://www...</code></li>
  <li>Rule 2 : root requests need to be redirected to <code>https://www...</code></li>
</ul>

<p>For that we can get inspiration from the <a href="https://the.aamodt.family/rune/2020/01/08/tutorial-azure-website.html#step-5-enforce-https">step 5</a> of the second guide to get something looking like that:</p>

<p><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step5_rules.jpg" alt="Step 5 : Screenshot of the CDN endpoint rules engine configuration, details below"></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step5_rules.jpg">figure 5 : Rules to manage traffic across domains and protocols</a></em></p>

<p>The details of these rules:</p>

<ul>
  <li>Rule 1
    <ul>
      <li>Name : <strong>http2https</strong></li>
      <li>If Request <strong>protocol</strong>
        <ul>
          <li>Operator : <code>Equals</code></li>
          <li>Request URL : <code>HTTP</code></li>
        </ul>
      </li>
      <li>Then URL redirect
        <ul>
          <li>Type : <code>Moved (301)</code></li>
          <li>Protocol : <code>HTTPS</code></li>
          <li>Hostname : <code>www.eiden.ca</code></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Rule 2
    <ul>
      <li>Name : <strong>root2www</strong></li>
      <li>If Request <strong>URL</strong>
        <ul>
          <li>Operator : <code>Begins with</code></li>
          <li>Request URL : <code>https://eiden.ca</code></li>
          <li>Case transform : <code>To lowercase</code></li>
        </ul>
      </li>
      <li>Then URL redirect
        <ul>
          <li>Type : <code>Moved (301)</code></li>
          <li>Protocol : <code>HTTPS</code></li>
          <li>Hostname : <code>www.eiden.ca</code></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>The picture is now complete:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png" alt="Schema of the solution, everything has been explained above"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png">figure 6 : The whole thing wired up together</a></em></p>

<h2 id="step-6--flushing-the-cdn-profile">Step 6 : Flushing the CDN profile</h2>

<p>As discussed earlier, the CDN caches our files to serve them in an optimal fashion. Like any cache, it will need to be expired and reloaded when new content is uploaded to the storage account. This is not done automatically.</p>

<p>In the Azure CDN world, this operation is called a <strong>purge</strong>. It can be done in <a href="https://docs.microsoft.com/en-us/azure/cdn/cdn-purge-endpoint">the Azure portal</a> or via script.</p>

<p>In my case I‚Äôm using the <a href="https://docs.microsoft.com/en-us/powershell/azure/new-azureps-module-az?view=azps-4.7.0">PowerShell Az module</a> (not to be mistaken with the AzureRM module) to do that every time I publish a new article:</p>

<pre><code># Already logged via Connect-AzAccount

$cdnProfileName = "eiden-ca"

Get-AzCdnProfile `
  | Where-Object {$_.Name -eq $cdnProfileName} `
  | Get-AzCdnEndpoint `
  | Unpublish-AzCdnEndpointContent -PurgeContent "/*"

</code></pre>

<h2 id="closing">Closing</h2>

<p>So really, $2.5 per month?</p>

<ul>
  <li><a href="https://www.namecheap.com/security/ssl-certificates/comodo/positivessl/">Namecheap</a> SSL Certificate : $9 per year</li>
  <li><a href="https://www.gandi.net/en-CA">Gandi</a> custom domain (<code>.ca</code>) : $15 per year</li>
  <li>Everything <a href="https://azure.microsoft.com/en-us/free/">Azure</a> : $.5 per month</li>
</ul>

<p><strong>Total : $2.5 per month!</strong></p>

      </article></div>]]>
            </description>
            <link>https://www.eiden.ca/azure-static-blog/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654536</guid>
            <pubDate>Thu, 01 Oct 2020 18:34:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to build an open source business]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654427">thread link</a>) | @mattgreg
<br/>
October 1, 2020 | https://www.ockam.io/learn/blog/zero_ipo/ | <a href="https://web.archive.org/web/*/https://www.ockam.io/learn/blog/zero_ipo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p font-family="body" font-weight="body" font-size="body" color="text">Ockam‚Äôs Zero-to-IPO map is a key strategy input to our tactical short, medium and long-term business planning. It focuses on the one-thing that <em>really</em> matters, at specific points in time. We live our values at Ockam, and as an open source company, we want to share our roadmap.</p><p font-family="body" font-weight="body" font-size="body" color="text">As outlined in the progression below, we‚Äôve plotted a course from stoking awareness to operating an enterprise sales machine.</p><p font-family="body" font-weight="body" font-size="body" color="text"><span>
      <a href="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/dbe83/map.png">
    <span></span>
  </a><a href="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/e3189/map.png" rel="noopener noreferrer" target="_blank"><img src="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/e3189/map.png" alt="Zero to IPO map" title="Zero to IPO map" srcset="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/a2ead/map.png 259w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/6b9fd/map.png 518w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/e3189/map.png 1035w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/44d59/map.png 1553w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/a6d66/map.png 2070w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/dbe83/map.png 3652w" sizes="(max-width: 1035px) 100vw, 1035px" loading="lazy"></a>
  
    </span></p><p font-family="body" font-weight="body" font-size="body" color="text">The time scale for our route to IPO is, as you‚Äôd expect, years long. Given that startups plan around funding cycles, let‚Äôs plot funding cycles as waypoints on our course. It can generally be assumed that there is 18-24 months between these waypoints.</p><p font-family="body" font-weight="body" font-size="body" color="text"><span>
      <a href="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/4eef4/funding.png">
    <span></span>
  </a><a href="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/e3189/funding.png" rel="noopener noreferrer" target="_blank"><img src="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/e3189/funding.png" alt="Funding time scale" title="Funding time scale" srcset="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/a2ead/funding.png 259w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/6b9fd/funding.png 518w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/e3189/funding.png 1035w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/44d59/funding.png 1553w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/a6d66/funding.png 2070w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/4eef4/funding.png 3660w" sizes="(max-width: 1035px) 100vw, 1035px" loading="lazy"></a>
  
    </span></p><p font-family="body" font-weight="body" font-size="body" color="text">The cloud, edge, and open source landscape continues to evolve - which means that we need to chart our own course into the future. However, Ockam‚Äôs route to IPO also considers the various ways that other companies have run the gauntlet from Zero-to-IPO. I‚Äôve been fortunate to have been ‚Äòin the rooms where it happened‚Äô. Over the past 10 years I‚Äôve directly worked with well over 100 companies that were underpinned by open source software projects. I‚Äôve seen spectacular successes, breathtaking failures, modest acquisitions, and some companies that simply fade into the darkness. I'll save those stories for another time, maybe over a beer.</p><p font-family="body" font-weight="body" font-size="body" color="text">In the image below are experiences that I‚Äôve drawn from the previous decade in the open source, cloud, and developer tool space.</p><p font-family="body" font-weight="body" font-size="body" color="text"><span>
      <a href="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/8ddda/rooms.png">
    <span></span>
  </a><a href="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/e3189/rooms.png" rel="noopener noreferrer" target="_blank"><img src="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/e3189/rooms.png" alt="Rooms where it happened" title="Rooms where it happened" srcset="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/a2ead/rooms.png 259w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/6b9fd/rooms.png 518w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/e3189/rooms.png 1035w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/44d59/rooms.png 1553w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/a6d66/rooms.png 2070w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/8ddda/rooms.png 3724w" sizes="(max-width: 1035px) 100vw, 1035px" loading="lazy"></a>
  
    </span></p><p font-family="body" font-weight="body" font-size="body" color="text">Let‚Äôs dive into each stage, in turn, to unpack what we are doing, when we are doing it, and how we are going to measure it.</p><h2 id="motion" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">In order to recruit our team, or for a developer to consider using Ockam, first they have to know we exist. We create and distribute a tremendous amount of content at Ockam with one goal - driving developer awareness.</p><p font-family="body" font-weight="body" font-size="body" color="text">For example, The first product Ockam shipped was <a href="https://www.ockam.io/learn/guides/team/values_and_virtues_on_the_Ockam_Team/">a blog on our Values</a>. The second was a white paper that shared our vision. Even this post is an example!  We have a learning library that outlines our thesis on the open source ecosystem, teaches computer science fundamentals, gives insights into our team culture, and demonstrates our technology. We‚Äôve sat down for dozens of podcasts and interviews over the past two years. Ockam‚Äôs content is based around teaching. Being an effective listener and a great teacher are core underpinnings when building an open source community.</p><h2 id="metrics" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">To gauge awareness we track activity including page views on ockam.io, 'contact us' webform inquiries, GitHub stars, social media mentions, followers and, most importantly, applications to join our team.</p><h2 id="motion-1" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion-1"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">This is a critically important step in our progression to IPO. Building Ockam's community is a never-ending endeavor. It takes years of focus and unrelenting attention to get this step right. For example, Kafka spent it's first 5 years in this phase as an Apache project before Confluent was started.</p><p font-family="body" font-weight="body" font-size="body" color="text">We have three code interfaces to Ockam, which means that there are three different personas in our community:</p><p font-family="body" font-weight="body" font-size="body" color="text"><strong>Application layer developers</strong></p><p font-family="body" font-weight="body" font-size="body" color="text">Ockam‚Äôs users build systems and applications with our simple APIs, OckamD binary downloads, and hosted cloud services.</p><p font-family="body" font-weight="body" font-size="body" color="text">To simplify what‚Äôs going on at this stage, we create packages that any developer can grab in the middle of the night, on the other side of the world, and get a quick win for their demo day at work. You‚Äôve got a job to be done, and we‚Äôve got a simple solution for you. You can get it right now and we will measure your time to a technical-win in the scale of minutes.</p><p font-family="body" font-weight="body" font-size="body" color="text"><strong>Partners</strong></p><p font-family="body" font-weight="body" font-size="body" color="text">Community partners build add-ons, connectors, and plug-ins to connect Ockam to other codebases, cloud services and hardware components. Examples include InfluxData, Confluent - Kafka, Microchip, NXP, MacOS, and Microsoft Azure.</p><p font-family="body" font-weight="body" font-size="body" color="text"><strong>Open source developers</strong></p><p font-family="body" font-weight="body" font-size="body" color="text">Ockam‚Äôs open source builders are engaged in development of Ockam's core codebase. They attend our monthly community meetings, and are hands-on with our OSS codebase on GitHub. Their participation ranges from updating a typo in documentation, to building complex features.</p><h2 id="metrics-1" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics-1"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">We track Monthly Active Users across all three personas in our community:</p><p font-family="body" font-weight="body" font-size="body" color="text">Binary downloads, account signups, or SaaS service IOPS are all indicators of usage. As hinted above, time to ‚Äòtechnical win‚Äô, for an individual developer is also paramount. We‚Äôve defined time to ‚Äòtechnical win‚Äô as the time it takes to go from an individual developer‚Äôs initial discovery to a working prototype that includes Ockam features.</p><p font-family="body" font-weight="body" font-size="body" color="text">The easiest user growth to track is the number of partner integrations. Since partners engage with us 1:1 on an integration, we are highly selective and deliberate about the partnerships that we support. Eventually the development of our technical partnerships will become programmatic. Programmatic examples from my past include the partner program for Heroku Add-ons and the Azure Marketplace partner portal.</p><p font-family="body" font-weight="body" font-size="body" color="text">We also track the intersection of partnerships and usage. For example, the number of Ockam Daemons that run alongside Influx Telegraf, or the number of IOPS in Ockam Routers that securely move packets to a Kafka Connector.</p><p font-family="body" font-weight="body" font-size="body" color="text">Finally open source activity and engagement is transparent through the tools in GitHub. Check out <a href="https://github.com/ockam-network">how we are doing</a> with stars, forks and commits.</p><h2 id="motion-2" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion-2"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">This is a really fun stage for a product-and-pricing-nut like me. By this point in our journey we have users, but not customers. To satisfy investor expectations and to further fund product development, we start to feed our product development machine with revenue.</p><p font-family="body" font-weight="body" font-size="body" color="text">This stage is far simpler than it‚Äôs often made out to be. Here‚Äôs my basic formula;</p><ul><li>If you are an individual developer, then Ockam is free.</li><li>If you are a commercial enterprise, but have not yet had a ‚Äòtechnical win‚Äô with Ockam, then Ockam is free.</li><li>If you are a commercial enterprise, and have had a ‚Äòtechnical win‚Äô with Ockam, then you pay.</li></ul><p font-family="body" font-weight="body" font-size="body" color="text">From here things get a bit more complicated. Services need to be packaged and priced. This, in my opinion, is the most challenging, but also the most fun part of product development. The classic product marketing mix (aka the 4P‚Äôs) framework is durable and applies for Ockam‚Äôs planned product offerings. In this phase we are packaging <strong>P</strong>roducts (say S, M, L sizes), establishing a <strong>P</strong>rice for each product, <strong>P</strong>romoting the product through rigorous segmentation and targeting, and <strong>P</strong>lacing it into various channels and partner marketplaces for distribution.</p><p font-family="body" font-weight="body" font-size="body" color="text">Ockam‚Äôs SaaS products will have a freemium pricing and packaging structure. It‚Äôs worth calling out that freemium is not a pricing strategy. It‚Äôs a customer acquisition tactic that aligns with the formula above.</p><h2 id="metrics-2" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics-2"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">Monthly Recurring Revenue (MRR) is the top line / key metric during this phase.</p><p font-family="body" font-weight="body" font-size="body" color="text">The free-to-paid funnel is another key metric since it is a leading indicator and helps to forecast MRR. We will track both conversion and velocity of our freemium SaaS users.</p><p font-family="body" font-weight="body" font-size="body" color="text">The metrics we track in the Self-Serve SaaS phase allow us to A/B test in our demand generation funnel. A/B testing allows us to optimize month-over-month revenue growth.  The target is 10-15% MoM growth.</p><h2 id="motion-3" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion-3"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">Inside Sales is a channel strategy for specific types of large customers we already have. This is mainly a cultivate-and-grow tactic. Our bottoms-up, Self Serve SaaS product model feeds leads to our Inside Sales Team. This team is technical, includes sales engineers and provides world-class support.</p><p font-family="body" font-weight="body" font-size="body" color="text">There are two separate objectives during this phase.</p><ul><li>Increase MRR through an increase in our customer base, and in the average ticket size.</li><li>Learn about Customer Acquisition Costs (CAC) for specific segments, prior to launching the Enterprise Sales phase.</li></ul><p font-family="body" font-weight="body" font-size="body" color="text">Monthly recurring revenue is still our top priority during the Inside Sales phase.</p><p font-family="body" font-weight="body" font-size="body" color="text">What‚Äôs less obvious is the second objective. Understanding CAC prepares us for an all-in Enterprise Sales motion. Moving from here onto the Enterprise Sales waypoint is probably the most challenging. It‚Äôs fraught with peril. Many, many smart companies, with great products, and ‚Äòdeveloper love‚Äô die right here.</p><p font-family="body" font-weight="body" font-size="body" color="text">How can that be? It‚Äôs because Inside Sales is bottoms-up and Enterprise Sales is tops-down. This means entirely new buyers, new product-marketing mix, and new internal talent. We must hold onto our developer roots, while we also learn to sell to the suits. While we are executing on Inside Sales we are doing the primary research that will help spawn a new company from our company.</p><p font-family="body" font-weight="body" font-size="body" color="text">This is fantastically difficult - mostly from a cultural standpoint. Fortunately there are a lot of people with a lot of scar tissue from the past 10 years - including myself - and we will push through. The key is patience. We need to use our inside sales motion to find specific beachheads to land our Enterprise Sales motion.</p><h2 id="metrics-3" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics-3"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">MRR carries over as our key metric from the Self Serve SaaS phase.</p><p font-family="body" font-weight="body" font-size="body" color="text">CAC analysis for multiple customer segments.</p><h2 id="anti-metrics" color="heading" font-family="heading" font-weight="heading">Anti-Metrics<a href="#anti-metrics"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">There will be noise in our Inside Sales data!</p><p font-family="body" font-weight="body" font-size="body" color="text">The noise is any sale that looks like it could be Enterprise Sales. Up to this point, non-recurring engineering (NRE) and enterprise-like sales don‚Äôt count as Enterprise Sales, as we define the term in the next section. Typically they are one-off deals because the motion to win these deals isn‚Äôt scalable. We will do large custom deals to gain access to smart teams that deploy interesting technology. I prefer to categorize this class of revenue as ‚Äòbusiness development‚Äô or even R&amp;D.</p><p font-family="body" font-weight="body" font-size="body" color="text">Why is this an anti-metric? Because other Open Source startups typically stand up a couple one-off enterprises like sales as a way to puff themselves up and to convince themselves that they are ready to move to the next phase. I strongly caution my future self to parse the noise from the signal prior to launching Enterprise Sales.</p><p font-family="body" font-weight="body" font-size="body" color="text">Furthermore, there are other Open Source companies that entirely bypass the Self Serve SaaS phase in favor of the chunky revenue that comes with Enterprise Sales. Those companies tend not to be product companies. They become ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ockam.io/learn/blog/zero_ipo/">https://www.ockam.io/learn/blog/zero_ipo/</a></em></p>]]>
            </description>
            <link>https://www.ockam.io/learn/blog/zero_ipo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654427</guid>
            <pubDate>Thu, 01 Oct 2020 18:26:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is the difference between Docker and a Virtual Machine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654229">thread link</a>) | @championshuttle
<br/>
October 1, 2020 | https://itsopensource.com/what-is-the-difference-between-docker-and-a-virtual-machine/ | <a href="https://web.archive.org/web/*/https://itsopensource.com/what-is-the-difference-between-docker-and-a-virtual-machine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>While in principle they are very similar, it might be more common to know about Virtual Machines than Docker Containers. Virtual Machines are like Inception, but with computers; you‚Äôre running another computer inside your computer. A usual use-case for this setup that‚Äôs applicable even to people not working in tech, is for example, you have a Windows machine (your Host OS) and you want to somehow have Ubuntu (your Guest OS) just to test a software that only runs on Linux machines. You just want to quickly try it out, so you don‚Äôt want to go through the process of installing another OS in your system (dual booting).</p>
<p><span>
      <a href="https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/f67cc/ubuntu-vm.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Running an Ubuntu session using VirtualBox" title="Running an Ubuntu session using VirtualBox" src="https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/88218/ubuntu-vm.jpg" srcset="https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/7237a/ubuntu-vm.jpg 148w,
https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/0cfdf/ubuntu-vm.jpg 295w,
https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/88218/ubuntu-vm.jpg 590w,
https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/f67cc/ubuntu-vm.jpg 800w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>Now let‚Äôs discuss the underlying technology a bit. A virtual machine is a system which emulates a computer system. It has its own CPU, memory, hard disk, network and other hardware resources which are managed by a ‚Äòvirtualization layer‚Äô. This layer then translates these requests to the physical hardware (host computer).</p>
<p>If you have tried running a VM in your machine, you know how your machine started heating up. This whole process is resource-intensive, because hey, you‚Äôre practically running a full version of another machine! That‚Äôs definitely something you won‚Äôt do when you want to solve a bigger use-case that requires this setup.</p>
<p><span>
      <a href="https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/a8246/vm-architecture.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Virtual Machine Simple Architecture" title="Virtual Machine Simple Architecture" src="https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/a8246/vm-architecture.png" srcset="https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/00d96/vm-architecture.png 148w,
https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/0b23c/vm-architecture.png 295w,
https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/a8246/vm-architecture.png 400w" sizes="(max-width: 400px) 100vw, 400px" loading="lazy">
  </a>
    </span></p>
<p>What if my colleagues also want to try that software? Do they also have to install the same heavy thing on their system? What if their hardware can‚Äôt handle it?</p>
<p>That‚Äôs where Docker comes in. It‚Äôs like milk, but the leanest version with the least amount of fat that you can find (sort of).</p>
<p>With Docker, you can run applications on your host operating system (e.g. Windows), in what is called a Container. A container is almost similar to an operating system minus the graphical user interface (the stuff you can click). It technically functions just like running a session on a VM, but here‚Äôs the magic: unlike in a VM where you have to run a session of an entire OS to use an application, with Docker, you are able to run the application in light-weight containers AND control it from the host OS. The part where you see another OS running? The part where you turn on Ubuntu on your VM Manager that you installed on your Windows machine? That part has been scrapped, making the whole setup way lighter. Instead, you just write some commands on the command line and you go directly into running your application.</p>
<p><em>Whuuuut?</em></p>
<p>Let‚Äôs try to visualize that with this image, compared to our previous one.</p>
<p><span>
      <a href="https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/11d19/docker-vm.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Docker vs VM Visualized" title="Docker vs VM Visualized" src="https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/799d3/docker-vm.png" srcset="https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/00d96/docker-vm.png 148w,
https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/0b23c/docker-vm.png 295w,
https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/799d3/docker-vm.png 590w,
https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/11d19/docker-vm.png 800w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>The game-changing advantage of Docker is that it allows you to package any software with all of its dependencies into a single standardized unit called image.</p>
<p>Virtual machines run on a host OS and make guest OS available inside each VM, each OS needs to be booted individually. On the other hand, Docker containers are hosted on a single docker engine on a host OS. All the containers share the docker instance. Sharing the engine between containers makes them light and decreases the boot time. While Docker Containers boot in a few seconds, VMs take a few minutes to boot. </p>
<p><span>
      <a href="https://itsopensource.com/static/632533cd83014f756c2c557efb650694/7217d/docker-architecture.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Docker Architecture" title="Docker Architecture" src="https://itsopensource.com/static/632533cd83014f756c2c557efb650694/7217d/docker-architecture.png" srcset="https://itsopensource.com/static/632533cd83014f756c2c557efb650694/00d96/docker-architecture.png 148w,
https://itsopensource.com/static/632533cd83014f756c2c557efb650694/0b23c/docker-architecture.png 295w,
https://itsopensource.com/static/632533cd83014f756c2c557efb650694/7217d/docker-architecture.png 500w" sizes="(max-width: 500px) 100vw, 500px" loading="lazy">
  </a>
    </span></p>
<p>Now that we have that background, let‚Äôs take a look at some real examples of how these can be applied:</p>
<p><strong>Virtual machine</strong></p>
<p>You have a Windows machine and want to try out GIMP on Ubuntu. Here‚Äôs how the process will look like:</p>
<ol>
<li>Install an Ubuntu VM on a Windows machine</li>
<li>Go inside the VM window and operate Ubuntu</li>
<li>Install GIMP there and use it.</li>
</ol>
<p>The host OS (Windows) is totally unaware of what is being done inside VM (Ubuntu).</p>
<p><strong>Docker</strong></p>
<p>You use Wordpress.com and discovered that there is an open source version of it that you can run yourself, so you want to test it out on your own computer first. Now, setting up a Wordpress site has dependencies, that is, your system needs to have Apache, MySQL database and PHP installed.</p>
<p>Using Docker, here‚Äôs how the process will look like.</p>
<ol>
<li>Create a container using a <a href="https://hub.docker.com/_/wordpress">Wordpress image</a>. We‚Äôre able to jump directly to this step because the Wordpress image has already been packaged by the Docker community. It contains all the dependencies needed to run Wordpress.</li>
<li>Run Wordpress on your browser!</li>
</ol>
<p>In a nutshell, Docker containers support OS virtualization, and VM supports hardware virtualization.</p></section></div>]]>
            </description>
            <link>https://itsopensource.com/what-is-the-difference-between-docker-and-a-virtual-machine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654229</guid>
            <pubDate>Thu, 01 Oct 2020 18:09:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startup Lessons I Needed to Learn First Hand (But Maybe You Don‚Äôt)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654192">thread link</a>) | @jlrubin
<br/>
October 1, 2020 | http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/ | <a href="https://web.archive.org/web/*/http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="content">

<div>
	<div id="primary">
		<main id="main" role="main">

			
<article id="post-1586">
		<!-- .entry-header -->

	
	<div>
		
<p>When I stepped down as CEO in 2018, I wrote a post mortem and shared it privately with founder friends who directly asked <a rel="noreferrer noopener" href="http://www.nancyhua.com/2020/01/06/2019-2020-post-pre-mortems/" target="_blank">when I blogged here</a>. The company got acquired in 2019 and now I‚Äôm sharing the post mortem publicly because readers told me they saw novel concepts in my document they hadn‚Äôt heard elsewhere (as I write this I wonder if it‚Äôs because I was wrong. LMK!). </p>



<p>I used to abhor failure, but publicly releasing this post mortem no longer holds charge for me. Through Apptimize, I‚Äôve learned and changed such that my subsequent companies will be very different. One of my biggest learnings is that I‚Äôd played a finite game and missed <a rel="noreferrer noopener" href="https://youtu.be/3QyurhNwk14?t=56" target="_blank">the infinite game</a>. I didn‚Äôt know those concepts at the time and saw ‚Äúproduct innovation‚Äù as a separate category of work. After shifting my reference frame, I now know innovation as a sign of infinite game behavior. Anyway, I hope the below is useful to founders whose sales motions aren‚Äôt getting easier years into their venture backed company and want to consider frameworks for evaluating their position.&nbsp;</p>



<p>=================</p>



<p><strong>Startup Post Mortem, </strong>written Q3 2018</p>



<p>At times, the company we founded in 2013 seemed to be doing well by various objective metrics‚Äî we had a prestigious customers list ranging from CNN to Comcast, we raised 3 funding rounds summing to over $20MM in venture capital investment, and our revenue grew exponentially for the first few years (obviously easier to 3x when x is small). As the cofounder and CEO, I always bet on our ability to figure it out and be a financial success. I put in the first $50K and bought our domain for an additional $10K, which isn‚Äôt much money in the scheme of startup funding, but this was before we had users, before we‚Äôd gotten into Y Combinator, before it was anyone other than me and my cofounder. I used to be a trader, so I wasn‚Äôt goofing around‚Äî I fully expected to eventually make tons of money off our startup. I wrote a draft S-1 for how we would IPO, I didn‚Äôt pay myself for the first year, I was the lowest paid person in the company for years, and I guarded our equity like it was the blood of my children. I always wanted more equity because I valued it so highly. When founder friends told me to pay myself more, I asked for more equity instead. When we raised an oversubscribed Series B, founder friends told me to ask if I could sell some of my shares or take money off the table, but again I asked for more equity instead. Suggestions to get cash seemed ridiculous to me because I didn‚Äôt think I deserved cash yet; we weren‚Äôt a success and I, more than anyone, knew all our warts. When we were getting acquired, founder friends suggested I block the acquisition unless I made money off it, but that also sounded ridiculous to me because I felt I deserved money least of all. I‚Äôm sure my VC‚Äôs would‚Äôve agreed.</p>



<p>Our company didn‚Äôt exit at anywhere near as well as I‚Äôd pitched, and I felt sad to fail after so many years of everyone working so hard. For years, we worked weekends and holidays, regularly in the office till 10pm. My VP of marketing was back at work weeks after birthing each of her babies, working through her pregnancies, and we forced anyone who entered my house or office to do user tests. Had it all been a waste? Should we have spent that time partying instead? Being successful is important to me and I felt ashamed my company wasn‚Äôt a financial success despite how hard everyone worked on it and how much money we raised. Sure, I could twist the story to make it sound like a success in terms of learning and building, and we made a product people used, and we got acquired, but the fact is that the company didn‚Äôt make money the way I‚Äôd imagined and pitched. I felt scared my investors would view me as a failure and dislike me or view me as incompetent. We should‚Äôve done better‚Äî we had some of the smartest people you‚Äôd ever meet working on this problem that I convinced them was important enough to warrant their time and resources. How had I been so wrong about the financial outcome?&nbsp;</p>



<p><strong>Two Key Qualifying Questions:</strong></p>



<p>One of my investors put it well: everyone in a company is either a) making the product or b) selling the product. I learned there were 2 key questions that separated successful vs unsuccessful hires in our company:</p>



<ol><li>How hard is it to make this product?</li><li>How hard is it to sell this product?</li></ol>



<p>Our product was both hard to make and hard to sell. What do I mean by this and how does this impact the hiring profile?</p>



<p><strong>Product vs Sales Driven Company:</strong></p>



<p>On the spectrum of how hard it is to build a product, web forms are on the easier side. Easy products are anything that a person could do with a series of google docs and sheets, anything that you‚Äôre 100% sure is possible to make. On the harder side, there are products like a rocket or a flying car, where it‚Äôs &lt;100% guaranteed the engineering will get there in the time required. If the product is easy to build, then engineering is easier and it‚Äôs more on the sales and marketing teams to drive the company forward and show why your company is better even though others can make this commoditizable product (through network effect/ better land grab execution, brand/ trust, integrations/ partnerships, ‚Äúthought leadership,‚Äù customer service/ support, etc).&nbsp;</p>



<p>In contrast, the harder a product is to build, the better engineers you need and the more everything depends on the product team shipping something 10x better.&nbsp;</p>



<p>Our product was nowhere as hard to build as a rocket, but it was harder than a webapp, and we made design choices that increased the difficulty of building and maintaining our product in exchange for gaining competitive advantage, which was high at one point but eroded. This means our company had to be product driven. But after the first few years, we failed to be product driven because 1) I struggled to hire product leadership that was technical enough and 2) I was short term focused on revenue goals. Single-threaded on sales, I didn‚Äôt focus on the product roadmap because all I cared about were short term goals to lead us to the next funding round because I was mainly driven by my fear of the startup failing versus any love for shipping a better product.&nbsp;</p>



<p><strong>Transactional vs. Consultative Sales:</strong></p>



<p>Everyone in B2B SaaS knows from SaaStr etc you‚Äôre supposed to distinguish between sales people who sold to technical vs non-technical teams, and differentiate sales candidates based on the price point they were comfortable selling at, but I learned an additional point of differentiation: how consultative must the sale be? On the spectrum of how hard it is to sell a product, widgets like video conferencing software are on the easier end, easy to explain and demo. On the harder end, there‚Äôs consulting services to suggest TBD process improvements. Even harder is stuff that‚Äôs a new category where you have to educate the buyer on the need. The hardest sales require founders to drive sales; the salesperson needs to be at least as smart as the buyer so they can credibly educate the buyer on how the product will urgently impact their revenue. Buyers of video conferencing software don‚Äôt expect to get promoted because they chose Zoom over Webex or talk about the impact of their choice at a conference, but buyers of analytics software do want to hear how they‚Äôre going to become Chief Product Officer vs VP, that they‚Äôre going to show their CEO a powerpoint with graphs clearly illustrating the revenue their analytics choices have created for their team, and how they‚Äôre going to speak at the conference on their data driven decision making processes.</p>



<p>If the product fulfills a clear, established need, you can hire a wider variety of salespeople. But when the product‚Äôs harder to sell, you need a ‚Äúconsultative‚Äù salesperson, a specific profile correlated but distinct from price point. When the product differences/ usage/ impact are hard to explain, or there‚Äôs no category yet, or it‚Äôs not a drastic, budgeted need, you need sales people who are like consultants, subject matter experts who are smarter than the buyers.&nbsp;</p>



<p>If the sales person is interested in presenting a custom, strategic overview of how our product impacts the buyer‚Äôs product strategy, they eventually want to become customer success managers. Other than our first business hire, who was more like a cofounder to me and eventually founded his own company, I couldn‚Äôt get anyone to do both sales and customer success at the same time. I think our deals weren‚Äôt big enough and our customer success process was in the awkward gap between easy and hard‚Äî not hard enough to warrant consulting services, but not easy enough to remain a yearly check-in to upgrade the account.&nbsp;</p>



<figure><img loading="lazy" width="1024" height="856" src="http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups--1024x856.png" alt="" srcset="http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups--1024x856.png 1024w, http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups--400x334.png 400w, http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups--768x642.png 768w, http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups-.png 1404w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"><figcaption><em>Pros and cons of product vs. sales driven startups</em></figcaption></figure>



<p><strong>Fear/ Ego:</strong></p>



<p>Shifting gears from the tactical company building stuff to the touchy feely, the following section is philosophical.</p>



<p>It had started out really fun. In the 2nd year of the company, one executive told me that she got all her social fulfillment from our work. We were always together, working from my house on weekends, engineers sleeping over when they got tired, cooking together, talking about each other‚Äôs love languages, a group of friends going on an adventure together.&nbsp;</p>



<p>But now I see that I didn‚Äôt start the company with a pure heart. I started the company because I thought it‚Äôd be successful and I wanted to prove I could contribute something to the world, not because I specifically cared about our product or market, which I learned matters for me as time passes.&nbsp;</p>



<p>I thought I could get passionate about anything, and that was true at first, but it drained me to force myself to be an expert on our product for years because it wasn‚Äôt something I would‚Äôve done if it weren‚Äôt for the company, the team, and my ego. For years, I always knew the most about our market and would send links to the rest of the team for news that had come out, anything they ‚Ä¶</p></div></article></main></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/">http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/</a></em></p>]]>
            </description>
            <link>http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654192</guid>
            <pubDate>Thu, 01 Oct 2020 18:06:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programmers need to think like hackers]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24654136">thread link</a>) | @gexos
<br/>
October 1, 2020 | https://gexos.org/2020/10/01/Programmers-need-to-think-like-hackers!/ | <a href="https://web.archive.org/web/*/https://gexos.org/2020/10/01/Programmers-need-to-think-like-hackers!/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://gexos.org/2020/10/01/Programmers-need-to-think-like-hackers!/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654136</guid>
            <pubDate>Thu, 01 Oct 2020 18:01:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Is Not Your Ideal]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24653013">thread link</a>) | @amortize
<br/>
October 1, 2020 | https://sujithjay.com/not-aws | <a href="https://web.archive.org/web/*/https://sujithjay.com/not-aws">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span> 01 Oct 2020  ‚Ä¢ <span>
  
    
    
    <a href="https://sujithjay.com/tag/product"><code><nobr>PRODUCT</nobr></code>&nbsp;</a>
  
    
    
    <a href="https://sujithjay.com/tag/management"><code><nobr>MANAGEMENT</nobr></code>&nbsp;</a>
  
</span></span></p><p>Let me start with an assertion. Every platform engineering team <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> in every organisation aspires to be like AWS <sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</p>

<p>Every platform team wants to be like AWS, because like AWS, they provide infrastructure abstractions to users. AWS provides infrastructure via the abstractions of VMs and disks and write-capacity-units, while platform teams provide infrastructure using higher abstractions which solve service definitions, database or message queue provisioning, and service right-sizing <sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>.</p>

<p>This similarity prompts leaders of platform engineering teams to model their teams as agnostic providers of universal, non-leaky (within SLO bounds), self-served abstractions for their engineering organisation. Platform teams structured as such detached units struggle to define cohesive roadmaps which provide increasing value to business. But how does your platform differ from AWS?</p>

<h2 id="your-platform-vs-the-platform">Your Platform vs. The Platform</h2>

<h3 id="1-the-middle-ground">1. The Middle Ground</h3>
<p>As an agnostic service provider, AWS can afford to cater to median use-cases. The reason platform engineering teams exist is to bridge the gap between PaaS abstractions which work for the median use-case to your business‚Äô specific use-cases. AWS can afford to target the median (economy of scale etc.), but you cannot.</p>

<p><img src="https://sujithjay.com/public/notaws/Median.jpeg" alt="AWS can afford to stay within a single œÉ. You cannot."></p>
<p><span> AWS can afford to stay within a single œÉ. You cannot.</span>
</p>

<p>Agnostic platform engineering teams which emulate AWS try to get away from this responsibility by proposing abstractions which target the median use-case. A tell-tale sign of this is when the lack in wide usability of internal abstractions is compensated for by extensive onboarding &amp; repeated training. This is also a side-effect of the the relative valuation of engineering time vs. the time of another function <sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>.</p>

<h3 id="2-follow-the-money">2. Follow the Money</h3>
<p>The dictum ‚Äòfollow the money‚Äô works beautifully for customer-front products. When faced with a choice between two competing features to prioritise, a common tactical play is to make something which leads to more (immediate &amp; long-term) revenue. The proxy for increased revenue could be increased acquisition conversion, better retention or improved user experience ‚Äì metrics which ensure increased revenue for the company over time. In short, revenue growth is the north star <sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>.</p>

<p>Not so much in platform engineering. There is no revenue since your customers are internal, captive ones. Captive audiences are forced to use a solution by the force of dictum and lack of choice. The metrics used in platform products are proxies for usability and user satisfaction ‚Äì but there are no foolproof ways to measure it for captive audiences. For captive audiences, solutions can not compete and better solutions cannot win. Like a command economy, platform products are designed rather than evolved. Design takes priority over market economy. So why is design bad?</p>

<h2 id="bad-design">Bad Design</h2>
<p>For design to work, there has to be an objective function against which we can design. A specification is an objective function against which engineering teams design a solution. Since we do not have reliable metrics <sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup> to rely on for platform engineering, how do we come up with specifications? And without rigorous specifications, new features created by the platform run a high risk of not solving worthwhile problems for the users.The current accepted methodology among platform engineering leaders to solve this paucity of specifications is to rely on user-interviews. This is, as mentioned before, an unreliable source since captive users do not have the best view of the ideal state of tooling and abstractions that could be available to them.</p>

<p>The only way to flip this situation is to let go of command-economy-style designed abstractions, and to let your platform self-organise along the principle of markets. How does that look in practice?</p>

<h3 id="1-market-ftw">1. Market, FTW</h3>
<p>Camille Fournier mentions in <a href="https://medium.com/@skamille/product-for-internal-platforms-9205c3a08142">Product for Internal Platforms</a> how her team partners with customer teams to develop prototypes for specific problems. These specific solutions are later honed and iterated on to become general solutions provided by your team. I would go a step further on this route, where possible. Partner to prototype with multiple teams facing related problems to develop multiple specific solutions. These specific solutions can be seen as competing candidates to solve a general problem. Bring in user-interviews at this point to gauge pain-points, and iterate individually on these specific solutions. This switches the economy of your team to a self-organised market. Once considerable thought and iteration has gone into each solution, it is time to assimilate. Assimilate the best solution(s) while migrating the rest to the chosen solution. As emphasised in <a href="https://medium.com/@skamille/product-for-internal-platforms-9205c3a08142">Product for Internal Platforms</a>, an early investment of time into migration strategies is essential for such a scheme to sustain.</p>

<p>In platforms designed with experimentation, you will find that innovation continues to thrive at the edges of the platform‚Äôs domain while the stable core of the platform is subject to periodic rework or maintenance. The use-cases a platform supports grows in a controlled manner to address an ever-growing percent of the consumers, and does not stagnate after addressing just the median users.</p>

<h3 id="2-overloaded-use-cases">2. Overloaded Use-cases</h3>
<p>Although agnostic platform engineering teams might only be catering to very specific median use-cases, the customer teams with specific needs cannot afford to be blocked and they cannot stop delivering their deliverables. These teams sometimes create their own solutions, and in such cases the above strategy of assimilation works wonders. You get a prototype for free on which the team can iterate on. However, this scenario is rarer in cases where it requires specific skills to build such solutions, such as in data platforms. One common pattern in such knowledge-constricted situations is that users find ways to overload the existing solutions with minor tweaks to fit their use-case. Look out for such overloaded use-cases within your platform, for they are excellent guides to unmet needs of the users. You can leverage them to advocate for newer features to explicitly support those use-cases.</p>

<h3 id="3-listen-to-them-only-at-the-start">3. Listen To Them (Only At The Start!)</h3>
<p>As a parting note, I will take a jab at user-interviews again. The above tactics work when you are trying to scale your platform from 1 to N. When taking a platform from 0 to 1, the only solution to creating specifications is to listen to the users. Give them exactly what they want. Listen to their exact demands. A propensity of platform product managers is to rely on this excessively at a much later stage in the product‚Äôs lifecycle. User-interviews have their place in evolving products, but the over-reliance on the methodology is a bane to platform product management.</p>

<p><strong>P.S.</strong> As I read back the above essay, the heavy influence of <a href="https://medium.com/@skamille/product-for-internal-platforms-9205c3a08142">Product for Internal Platforms</a> is clear. I would like to say that was the intention: to reassert the ideas in it which resounded with me, while stating a few of my own.</p>

<h3 id="footnotes">Footnotes</h3>


  </div>









      </div></div>]]>
            </description>
            <link>https://sujithjay.com/not-aws</link>
            <guid isPermaLink="false">hacker-news-small-sites-24653013</guid>
            <pubDate>Thu, 01 Oct 2020 16:37:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling a Lisp to x86-64: Let expressions]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 30 (<a href="https://news.ycombinator.com/item?id=24652842">thread link</a>) | @todsacerdoti
<br/>
October 1, 2020 | https://bernsteinbear.com/blog/compiling-a-lisp-7/ | <a href="https://web.archive.org/web/*/https://bernsteinbear.com/blog/compiling-a-lisp-7/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-0/">first</a></em> ‚Äì <em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-6/">previous</a></em></p>

<p>Welcome back to the ‚ÄúCompiling a Lisp‚Äù series. Last time we added a reader
(also known as a parser) to our compiler. This time we‚Äôre going to compile a
new form: <em>let</em> expressions.</p>

<p>Let expressions are a way to bind variables to values in a particular scope.
For example:</p>

<div><div><pre><code><span>(</span><span>let</span> <span>((</span><span>a</span> <span>1</span><span>)</span> <span>(</span><span>b</span> <span>2</span><span>))</span>
  <span>(</span><span>+</span> <span>a</span> <span>b</span><span>))</span>
</code></pre></div></div>

<p>Binds <code>a</code> to <code>1</code> and <code>b</code> to <code>2</code>, but only for the body of the <code>let</code> ‚Äî the
rest of the S-expression ‚Äî and then executes the body.</p>

<p>This is similar in C to opening a new block:</p>

<div><div><pre><code><span>int</span> <span>result</span><span>;</span>
<span>{</span>
  <span>int</span> <span>a</span> <span>=</span> <span>1</span><span>;</span>
  <span>int</span> <span>b</span> <span>=</span> <span>2</span><span>;</span>
  <span>result</span> <span>=</span> <span>a</span> <span>+</span> <span>b</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>but it‚Äôs a little different because C has a divide between <em>statements</em> and
<em>expressions</em>, whereas Lisp does not.</p>

<p>It‚Äôs <em>also</em> different because let-expressions do not make previous binding
names available to expressions being bound. For example, the following program
should fail because it cannot find the name <code>a</code>:</p>



<p>There is a form that makes bindings available serially, but that is called
<code>let*</code> and we are not implementing that today.</p>

<p>For completeness‚Äô sake, there is also <code>let rec</code>, which makes names available
serially and also within the same binding. This is useful for binding recursive
or mutually recursive functions. Again, we are not implementing that today.</p>

<h3 id="name-binding-implementation-strategy">Name binding implementation strategy</h3>

<p>You‚Äôll notice two new things about let expressions:</p>

<ol>
  <li>They introduce ways to bind names to values, something we have to figure out
how to keep track of</li>
  <li>In order to use those names we have to figure out how to look up what the
name means</li>
</ol>

<p>In more technical terms, we have to add <em>environments</em> to our compiler. We can
then use those environments to map <em>names</em> to <em>stack locations</em>.</p>

<p>‚ÄúEnvironment‚Äù is just a fancy word for ‚Äúlook-up table‚Äù. In order to implement
this table, we‚Äôre going to make an <em>association list</em>.</p>

<p>An <em>association list</em> is a list of <code>(key value)</code> pairs. Adding a pair means
tacking it on at the end (or beginning) of the list. Searching through the
table involves a linear scan, checking if keys match.</p>

<blockquote>
  <p>You may be wondering why we‚Äôre using this data structure to implement
environments. Didn‚Äôt I even take a data structures course in college?
Shouldn‚Äôt I know that <em>linear</em> equals <em>slow</em> and that I should <em>obviously</em>
use a hash table?</p>

  <p>Well, hash tables have costs too. They are hard to implement right; they have
high overhead despite being technically constant time; they incur higher
space cost per entry.</p>

  <p>For a compiler as small as this, a tuned hash table could easily be as long
as the rest of the compiler. Since we‚Äôre also compiling small <em>programs</em>,
we‚Äôll worry about time complexity later. It is only an implementation detail.</p>
</blockquote>

<p>In order to do this, we‚Äôll first draw up an association list. We‚Äôll use a
linked list, just like cons cells:</p>

<div><div><pre><code><span>// Env</span>

<span>typedef</span> <span>struct</span> <span>Env</span> <span>{</span>
  <span>const</span> <span>char</span> <span>*</span><span>name</span><span>;</span>
  <span>word</span> <span>value</span><span>;</span>
  <span>struct</span> <span>Env</span> <span>*</span><span>prev</span><span>;</span>
<span>}</span> <span>Env</span><span>;</span>
</code></pre></div></div>

<p>I‚Äôve done the usual thing and overloaded <code>Env</code> to mean both ‚Äúa node in the
environment‚Äù and ‚Äúa whole environment‚Äù. While one little <code>Env</code> struct only
holds a one name and one value, it also points to the rest of them, eventually
ending with <code>NULL</code>.</p>

<p>This <code>Env</code> will map names (symbols) to <em>stack offsets</em>. This is because we‚Äôre
going to continue our strategy of <em>not doing register allocation</em>.</p>

<p>To manipulate this data structure, we will also have two functions<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>:</p>

<div><div><pre><code><span>Env</span> <span>Env_bind</span><span>(</span><span>const</span> <span>char</span> <span>*</span><span>name</span><span>,</span> <span>word</span> <span>value</span><span>,</span> <span>Env</span> <span>*</span><span>prev</span><span>);</span>
<span>bool</span> <span>Env_find</span><span>(</span><span>Env</span> <span>*</span><span>env</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>key</span><span>,</span> <span>word</span> <span>*</span><span>result</span><span>);</span>
</code></pre></div></div>

<p><code>Env_bind</code> creates a new node from the given name and value, borrowing a
reference to the name, and prepends it to <code>prev</code>. Instead of returning an
<code>Env*</code>, it returns a whole struct. We‚Äôll learn more about why later, but the
‚ÄúTL;DR‚Äù is that I think it requires less manual cleanup.</p>

<p><code>Env_find</code> takes an <code>Env*</code> and searches through the linked list for a <code>name</code>
matching the given <code>key</code>. If it finds a match, it returns <code>true</code> and stores the
<code>value</code> in <code>*result</code>. Otherwise, it returns <code>false</code>.</p>

<p>We can stop at the first match because Lisp allows name <em>shadowing</em>. Shadowing
occurs when a binding at a inner scope has the same name as a binding at an
outer scope. The inner binding takes precedence:</p>

<div><div><pre><code><span>(</span><span>let</span> <span>((</span><span>a</span> <span>1</span><span>))</span>
  <span>(</span><span>let</span> <span>((</span><span>a</span> <span>2</span><span>))</span>
    <span>a</span><span>))</span>
<span>; =&gt; 2</span>
</code></pre></div></div>

<p>Let‚Äôs learn about how these functions are implemented.</p>

<h3 id="name-binding-implementation">Name binding implementation</h3>

<p><code>Env_bind</code> is a little silly looking, but it‚Äôs equivalent to prepending a
node onto a chain of linked-list nodes. It returns a struct <code>Env</code> containing
the parameters passed to the function. I opted <em>not</em> to return a heap pointer
(allocated with <code>malloc</code>, etc) so that this can be easily stored in a
stack-allocated variable.</p>

<div><div><pre><code><span>Env</span> <span>Env_bind</span><span>(</span><span>const</span> <span>char</span> <span>*</span><span>name</span><span>,</span> <span>word</span> <span>value</span><span>,</span> <span>Env</span> <span>*</span><span>prev</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span><span>Env</span><span>){.</span><span>name</span> <span>=</span> <span>name</span><span>,</span> <span>.</span><span>value</span> <span>=</span> <span>value</span><span>,</span> <span>.</span><span>prev</span> <span>=</span> <span>prev</span><span>};</span>
<span>}</span>
</code></pre></div></div>

<p><em>Note</em> that we‚Äôre <strong>pre</strong>pending, not <strong>ap</strong>pending, so that names we add deeper
in a let chain shadow names from outside.</p>

<p><code>Env_find</code> does a recursive linear search through the linked list nodes. It may
look familiar to you if you‚Äôve already written such a function in your life.</p>

<div><div><pre><code><span>bool</span> <span>Env_find</span><span>(</span><span>Env</span> <span>*</span><span>env</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>key</span><span>,</span> <span>word</span> <span>*</span><span>result</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>env</span> <span>==</span> <span>NULL</span><span>)</span>
    <span>return</span> <span>false</span><span>;</span>
  <span>if</span> <span>(</span><span>strcmp</span><span>(</span><span>env</span><span>-&gt;</span><span>name</span><span>,</span> <span>key</span><span>)</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
    <span>*</span><span>result</span> <span>=</span> <span>env</span><span>-&gt;</span><span>value</span><span>;</span>
    <span>return</span> <span>true</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>Env_find</span><span>(</span><span>env</span><span>-&gt;</span><span>prev</span><span>,</span> <span>key</span><span>,</span> <span>result</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>We search for the node with the string <code>key</code> and return the stack offset associated
with it.</p>

<p>Alright, now we‚Äôve got names and data structures. Let‚Äôs implement some name
resolution and name binding.</p>

<h3 id="compiling-name-resolution">Compiling name resolution</h3>

<p>Up until now, <code>Compile_expr</code> could only compile integers, characters, booleans,
<code>nil</code>, and some primitive call expressions (via <code>Compile_call</code>). Now we‚Äôre
going to add a new case: symbols.</p>

<p>When a symbol is compiled, the compiler will look up its stack offset in the
current environment and emit a load. This opcode, <code>Emit_load_reg_indirect</code>, is
very similar to <code>Emit_add_reg_indirect</code> that we implemented for primitive
binary functions.</p>

<div><div><pre><code><span>int</span> <span>Compile_expr</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>node</span><span>,</span> <span>word</span> <span>stack_index</span><span>,</span>
                 <span>Env</span> <span>*</span><span>varenv</span><span>)</span> <span>{</span>
  <span>// ...</span>
  <span>if</span> <span>(</span><span>AST_is_symbol</span><span>(</span><span>node</span><span>))</span> <span>{</span>
    <span>const</span> <span>char</span> <span>*</span><span>symbol</span> <span>=</span> <span>AST_symbol_cstr</span><span>(</span><span>node</span><span>);</span>
    <span>word</span> <span>value</span><span>;</span>
    <span>if</span> <span>(</span><span>Env_find</span><span>(</span><span>varenv</span><span>,</span> <span>symbol</span><span>,</span> <span>&amp;</span><span>value</span><span>))</span> <span>{</span>
      <span>Emit_load_reg_indirect</span><span>(</span><span>buf</span><span>,</span> <span>/*dst=*/</span><span>kRax</span><span>,</span> <span>/*src=*/</span><span>Ind</span><span>(</span><span>kRbp</span><span>,</span> <span>value</span><span>));</span>
      <span>return</span> <span>0</span><span>;</span>
    <span>}</span>
    <span>return</span> <span>-</span><span>1</span><span>;</span>
  <span>}</span>
  <span>assert</span><span>(</span><span>0</span> <span>&amp;&amp;</span> <span>"unexpected node type"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>If the variable is not in the environment, this is a compiler error and we
return <code>-1</code> to signal that. This is not a tremendously helpful signal. Maybe
soon we will add more helpful error messages.</p>

<p>Ah, yes, <code>varenv</code>. You will, like I had to, go and add an <code>Env*</code> parameter to
all relevant <code>Compile_XYZ</code> functions and then plumb it through the recursive
calls. Have fun!</p>

<h3 id="compiling-let-finally">Compiling let, finally</h3>

<p>Now that we can resolve the names, let‚Äôs go ahead and compile the expressions
that bind them.</p>

<p>We‚Äôll have to add a case in <code>Compile_expr</code>. We could add it in the body of
<code>Compile_expr</code> itself, but there is some helpful setup in <code>Compile_call</code>
already. It‚Äôs a bit of a misnomer, since it‚Äôs not a call, but oh well.</p>

<div><div><pre><code><span>int</span> <span>Compile_call</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>callable</span><span>,</span> <span>ASTNode</span> <span>*</span><span>args</span><span>,</span>
                 <span>word</span> <span>stack_index</span><span>,</span> <span>Env</span> <span>*</span><span>varenv</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>AST_is_symbol</span><span>(</span><span>callable</span><span>))</span> <span>{</span>
    <span>// ...</span>
    <span>if</span> <span>(</span><span>AST_symbol_matches</span><span>(</span><span>callable</span><span>,</span> <span>"let"</span><span>))</span> <span>{</span>
      <span>return</span> <span>Compile_let</span><span>(</span><span>buf</span><span>,</span> <span>/*bindings=*/</span><span>operand1</span><span>(</span><span>args</span><span>),</span>
                         <span>/*body=*/</span><span>operand2</span><span>(</span><span>args</span><span>),</span> <span>stack_index</span><span>,</span>
                         <span>/*binding_env=*/</span><span>varenv</span><span>,</span>
                         <span>/*body_env=*/</span><span>varenv</span><span>);</span>
    <span>}</span>
  <span>}</span>
  <span>assert</span><span>(</span><span>0</span> <span>&amp;&amp;</span> <span>"unexpected call type"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>We have two cases to handle: no bindings and some bindings. We‚Äôll tackle these
recursively, with no bindings being the base case. For that reason, I added a
helper function <code>Compile_let</code>.</p>

<p>As with all of the other compiler functions, we pass it an machine code buffer,
a stack index, and an environment. Unlike other functions, we passed it two
expressions and two environments.</p>

<p>I split up the bindings and the body so we can more easily recurse on the
bindings as we go through them. When we get to the end (the base case), the
bindings will be <code>nil</code> and we can just compile the <code>body</code>.</p>

<p>We have two environments for the reason I mentioned above: when we‚Äôre
evaluating the expressions that we‚Äôre binding the names to, we can‚Äôt add
bindings iteratively. We have to evaluate them in the parent environment. It‚Äôll
be come clearer in a moment how that works.</p>

<p>We‚Äôll tackle the simple case first ‚Äî no bindings:</p>

<div><div><pre><code><span>int</span> <span>Compile_let</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>bindings</span><span>,</span> <span>ASTNode</span> <span>*</span><span>body</span><span>,</span>
                <span>word</span> <span>stack_index</span><span>,</span> <span>Env</span> <span>*</span><span>binding_env</span><span>,</span> <span>Env</span> <span>*</span><span>body_env</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>AST_is_nil</span><span>(</span><span>bindings</span><span>))</span> <span>{</span>
    <span>// Base case: no bindings. Compile the body</span>
    <span>_</span><span>(</span><span>Compile_expr</span><span>(</span><span>buf</span><span>,</span> <span>body</span><span>,</span> <span>stack_index</span><span>,</span> <span>body_env</span><span>));</span>
    <span>return</span> <span>0</span><span>;</span>
  <span>}</span>
  <span>// ...</span>
<span>}</span>
</code></pre></div></div>

<p>In that case, we compile the body using the <code>body_env</code> as the environment. This
is the environment that we will have added all of the bindings to.</p>

<p>In the case where we <em>do</em> have bindings, we can take the first one off and pull
it apart:</p>

<div><div><pre><code>  <span>// ...</span>
  <span>assert</span><span>(</span><span>AST_is_pair</span><span>(</span><span>bindings</span><span>));</span>
  <span>// Get the next binding</span>
  <span>ASTNode</span> <span>*</span><span>binding</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>bindings</span><span>);</span>
  <span>ASTNode</span> <span>*</span><span>name</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>binding</span><span>);</span>
  <span>assert</span><span>(</span><span>AST_is_symbol</span><span>(</span><span>name</span><span>));</span>
  <span>ASTNode</span> <span>*</span><span>binding_expr</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>AST_pair_cdr</span><span>(</span><span>binding</span><span>));</span>
  <span>// ...</span>
</code></pre></div></div>

<p>Once we have the <code>binding_expr</code>, we should compile it. The result will end up
in <code>rax</code>, per our internal compiler convention. We‚Äôll then store it in the next
available stack location:</p>

<div><div><pre><code>  <span>// ...</span>
  <span>// Compile the binding expression</span>
  <span>_</span><span>(</span><span>Compile_expr</span><span>(</span><span>buf</span><span>,</span> <span>binding_expr</span><span>,</span> <span>stack_index</span><span>,</span> <span>binding_env</span><span>));</span>
  <span>Emit_store_reg_indirect</span><span>(</span><span>buf</span><span>,</span> <span>/*dst=*/</span><span>Ind</span><span>(</span><span>kRbp</span><span>,</span> <span>stack_index</span><span>),</span>
                          <span>/*src=*/</span><span>kRax</span><span>);</span>
  <span>// ...</span>
</code></pre></div></div>

<p>We‚Äôre compiling this binding expression in <code>binding_env</code>, the parent
environment, because we don‚Äôt want the previous bindings to be visible.</p>

<p>Once we‚Äôve generated code to store it on the stack, we should register that
stack location with the binding name in the environment:</p>

<div><div><pre><code>  <span>// ...</span>
  <span>// Bind the name</span>
  <span>Env</span> <span>entry</span> <span>=</span> <span>Env_bind</span><span>(</span><span>AST_symbol_cstr</span><span>(</span><span>name</span><span>),</span> <span>stack_index</span><span>,</span> <span>body_env</span><span>);</span>
  <span>// ...</span>
</code></pre></div></div>

<p>Note that we‚Äôre binding it in the <code>body_env</code> because we want this to be
available to the body, but not the other bindings.</p>

<p>At this point we‚Äôve done all the work required for ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bernsteinbear.com/blog/compiling-a-lisp-7/">https://bernsteinbear.com/blog/compiling-a-lisp-7/</a></em></p>]]>
            </description>
            <link>https://bernsteinbear.com/blog/compiling-a-lisp-7/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652842</guid>
            <pubDate>Thu, 01 Oct 2020 16:26:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Data Science Pull Requests‚Äì Review and merge code, data and experiments]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24652832">thread link</a>) | @Dean-DAGsHub
<br/>
October 1, 2020 | https://dagshub.com/blog/data-science-pull-requests/ | <a href="https://web.archive.org/web/*/https://dagshub.com/blog/data-science-pull-requests/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <h3 id="a-step-forward-for-mlops-and-unlocking-open-source-data-science">A step forward for MLOps and unlocking Open Source Data Science</h3><p>Today, we're releasing Data Science Pull Requests (DS PRs), which are Pull Requests (PRs), re-imagined for the data science (DS) workflow. This new capability unlocks a standard review process for data science teams, enabling them to merge data across different branches and accept data contributions across forks. This provides a better collaborative experience for teams in data science organizations and enables truly Open Source Data Science (OSDS) projects. </p><p>For more details, read on...</p><h2 id="introduction">Introduction</h2><p>When we started DAGsHub, we were focused on making data science collaboration possible. Specifically, we deeply <em>care</em> and <em>rely on</em> Open Source Software (OSS), and we set out on a mission to make OSDS as accessible and prevalent as OSS is today.</p><p>This meant that we were concerned about <strong><em>discoverability </em></strong>of data science projects and experiments to work on, <strong><em>understandability</em></strong> of the context of an experiment, <strong><em>reproducibility</em> of </strong>its results, and finally, <strong><em>contributability</em></strong> of code-, data- and models- changed back to the original project.</p><p>When reviewing these processes and the existing solutions some things become clear:</p><ul><li><em><strong>Discoverability </strong></em>means being able to answer the question "<em>What should I do next?</em>" ‚Äì finding a project to work on, and within that project finding what experiments might be interesting or important. <br>It is solved mainly by <strong>experiment tracking</strong> systems, many of them using proprietary or black box formats that are hard to understand and migrate to/from.<p>DAGsHub goes beyond this by creating an experiment tracking system that relies on simple open formats (<code>YAML</code> and <code>CSV</code>). This means you don't need to add obscure lines of code ‚Äì everything works by automatically scanning and analyzing the git commits pushed into the platform.</p></li><li><em><strong>Understandability</strong></em> means being able to answer the question "<em>How should I do what I want to do?</em>" ‚Äì this usually consists of reviewing why, how, and what was already done in a project or experiment. The solution for this step is mostly manual and relies on self-documenting one's work and discussions with collaborators.<p>DAGsHub improves on this by providing a convenient interface into projects' code, data, models, and pipelines which give users a window into their projects' components, and how they interact with each other.</p></li><li><em><strong>Reproducibility</strong></em> means setting up an exact copy of the experiment you want to work on. Many times this process is reduced to a Git commit and the experiment parameters (logged in the experiment tracking system). However, the true standard for reproducibility involves <em><strong>easily </strong></em>retrieving the same version of data, models, and other artifacts. It is best solved by using Git with some dedicated data versioning solution.<p>DAGsHub solves this by relying on open source tools such as Git and DVC to provide the standard discussed above ‚Äì a complete copy of your project (code, data, models, parameters, and other artifacts) with one (or two) commands.</p></li><li><em><strong>Contributability</strong></em> means that you can take a new experiment or result, and incorporate them back into the project you started from so that you don't need to maintain your result separately. Today, this is entirely manual, full of friction, and fundamentally <strong>non-existent</strong>.</li></ul><p>We have many more things to build, but it was clear that one aspect needed to be covered first ‚Äì a <strong><em>CONTRIBUTION </em></strong>mechanism.</p><h2 id="contributing-data-science-pull-requests">Contributing ‚Äì Data Science Pull Requests</h2><p>The final step of the collaborative process is arguably the most important one. Without it, the workflow is one-sided, a monologue, which means collaboration isn't happening. Practically, <strong><em>Contributing</em></strong> can be broken down into two tasks - <strong>reviewing</strong> and <strong>merging </strong>contributions.</p><p>In software, both reviewing and merging are a part of the <strong>pull request</strong> process, but their focus was solely on code. </p><blockquote>Data Science Pull Requests let you <strong>review experiments<u>,</u></strong> <strong>code, data, models, </strong>and your<strong> pipelines</strong>, and <strong><u>merge changes to all of them automatically.</u></strong> </blockquote><h3 id="data-science-review">Data Science Review</h3><p>If you've ever worked on a data science project with other people or tried reviewing someone else's data science work, you know how hard it is to get the information you need to understand someone else's work, or explain your own, so that the review process is meaningful. The process is slow and manual because systems are not built for review.</p><p>An automatic review process means changes and updates can be discussed and integrated faster into your project.<strong> You need to quickly see what has changed, discuss it, in context, and decide how to move forward.</strong></p><p>What this means in practice:</p><ul><li>Commenting on experiments, in context ‚Äì you can look at the new experiments that are being contributed as part of the DS PR, and compare them to the base experiment in the original project. See all the visualization and information, and add comments on these within the PR discussion with links to the relevant comparison/visualization.</li></ul><figure><img src="https://dagshub.com/blog/content/images/2020/09/exp-comment-long-hq.gif" alt="Commenting on experiments"><figcaption>Commenting on experiments in DS PRs</figcaption></figure><ul><li>See what data and models have changed (not just code) ‚Äì view what data, model, and artifact files were added, removed, or modified. This means you can easily pinpoint changes and focus the discussion on what's important.</li></ul><figure><img src="https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png" alt="Viewing data changes in a DAGsHub project" srcset="https://dagshub.com/blog/content/images/size/w600/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png 1000w, https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png 1189w" sizes="(min-width: 720px) 720px"><figcaption>Data Comparison Example</figcaption></figure><ul><li>Compare and diff notebooks side-by-side ‚Äì notebooks are an important part of many data science projects. However, for a very long time, they haven't received adequate treatment in the review process, relying on diffs to the raw <code>JSON</code> file, which were mostly unreadable. You can now review the changes in an intuitive UI as part of the DS PR. Another benefit of this is that if you require a special visualization, you can commit a notebook with that visualization, and view the changes conveniently.</li></ul><figure><img src="https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png" alt="Notebook comparison" srcset="https://dagshub.com/blog/content/images/size/w600/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 1000w, https://dagshub.com/blog/content/images/size/w1600/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 1600w, https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 2298w" sizes="(min-width: 720px) 720px"><figcaption>Notebook Diffing Example</figcaption></figure><p>After reviewing a collaborator's work, we need a way to incorporate those changes, automatically. That's why we built data science merging.</p><h3 id="data-science-merging">Data Science Merging</h3><p>Merging code is possible with Git, but as we already discussed, that is not the full picture for data science projects. With DS PRs, you can merge your data and other artifacts as well. </p><h4 id="data-merging">Data Merging</h4><p>Everyone knows about bugs in code, but you might also have data bugs that you're not aware of. Examples include data that is not up to date, biased, or mislabeled. Assuming you found out about such a bug and you wanted to fix it ‚Äì that would usually mean you need to agree on and perform some manual operation to update or add new data. With data merging, once you accept a DS PR, the new data would automatically be copied into your project in an entirely automatic process.</p><h4 id="artifact-merging">Artifact Merging</h4><p>This doesn't end with just the <em>raw data ‚Äì </em>data merging lets you merge models and any other artifact of your data pipeline (e.g. preprocessed data or 3d models). Take a case where one of the steps in a pipeline takes 2 weeks to run and results in some trained model or a processed dataset. If only raw data was merged, you'd have to run that excruciating 2-week process again. Artifact merging means that after a DS PR is merged, the resulting project is as reproducible as the original contribution.</p><p>After accepting a DS PR you are in the same state of your DS project, as you would after accepting a PR in a software project.</p><figure><img src="https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png" alt="Data Merging on DAGsHub" srcset="https://dagshub.com/blog/content/images/size/w600/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 1000w, https://dagshub.com/blog/content/images/size/w1600/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 1600w, https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 1846w" sizes="(min-width: 720px) 720px"><figcaption>Data Science Merging ‚Äì Note that 171 MB of data will be copied on accepting this DS PR</figcaption></figure><p>Data merging means you can accept data and models from contributors with ease, without giving each one full access to your data storage. This can reduce friction and speed up team efforts.</p><p>This last capability is especially useful for OSDS.</p><h2 id="what-does-this-mean-for-osds">What does this mean for OSDS?</h2><p><a href="https://dagshub.com/blog/a-case-for-open-source-data-science/">Open Source Data Science (OSDS) has the potential to have a similar effect on the world</a>, as Open Source Software (OSS) had. It is DAGsHub's stated goal to promote OSDS and build the technology to make it as easy as possible. OSDS must come first, and industry workflows will mirror those in OSDS projects, as they have for OSS. </p><p>But let's face it ‚Äì OSDS doesn't <em>really</em> exist yet. If you maintain some OSDS project and you want to accept contributions from people (like you would for OSS) ‚Äì you have to do it entirely manually or <strong>resort to accepting only code changes</strong> (no way to accept data bug fixes ‚Äì and we all know there are plenty).</p><p>From the individual contributor side, if you want to improve your ML portfolio by contributing to some OSDS project, you're also stuck. You have to either fork the project and not contribute your changes (which means their quality is never reviewed ‚Äì you don't learn as much) or go through a painstaking manual effort<sup>[1]</sup>.</p><blockquote>DS PRs make OSDS possible by providing a standard interface and workflow to review and accept contributions from anyone, anywhere, and for any type of data science component.</blockquote><p><strong>We'd love to support open source data science projects that want to accept data science contributions from the community. Please reach out to us at <a href="mailto:osds@dagshub.com">osds@dagshub.com</a> if this is relevant for you.</strong></p><h2 id="thank-you-">Thank You!</h2><p>Thank you to all the people that gave us feedback before and while we were building DS PRs. We'd love to get your feedback as well on how DS PRs could be improved for the community ‚Äì the best way to do this is to join our <a href="https://discord.com/invite/9gU36Y6">Discord channel</a>. Looking forward to hearing your thoughts and seeing what people build with open source data science.</p><hr><!--kg-card-begin: markdown--><p>
[1] Kaggle is worth a mention here ‚Äì It is a common way to show some of your DS chops. However, it's competitive (as opposed to collaborative). Furthermore, data science projects in the wild rarely have one all-encompassing metric to optimize at the expense of everything else - 80% of the work is just gathering data and deciding what is even worth optimizing! 
Our goal with DAGsHub is to enable a collaborative way to showcase your capabilities while encouraging interoperability ‚Äì i.e. working together rather than everyone doing their own thing and ending up with a ton of fragmentation.
</p><!--kg-card-end: markdown-->
                <section>
                  
                  <ul>
                      <li>
                        <a href="https://dagshub.com/blog/tag/data-science/" title="Data Science">Data Science</a>
                      </li>
                      <li>
                        <a href="https://dagshub.com/blog/tag/data-science-workflow/" title="Data Science Workflow">Data Science Workflow</a>
                      </li>
                      <li>
               ‚Ä¶</li></ul></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dagshub.com/blog/data-science-pull-requests/">https://dagshub.com/blog/data-science-pull-requests/</a></em></p>]]>
            </description>
            <link>https://dagshub.com/blog/data-science-pull-requests/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652832</guid>
            <pubDate>Thu, 01 Oct 2020 16:26:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A look at PostGIS vs. Geocoder in Rails]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24652608">thread link</a>) | @leighhalliday
<br/>
October 1, 2020 | https://pganalyze.com/blog/postgis-rails-geocoder | <a href="https://web.archive.org/web/*/https://pganalyze.com/blog/postgis-rails-geocoder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>
This article sets out to compare PostGIS in Rails with Geocoder and to highlight a couple of the areas where you'll want to (or need to) reach for one over the other. I will also present some of the terminology and libraries that I found along the way of working on this project and article as I set out to understand PostGIS better and how it is integrated with Rails.</p>

<p><span>
      <span></span>
  <img alt="PostGIS vs. Geocoder in Rails" title="PostGIS vs. Geocoder in Rails" src="https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/29d31/postgis_rails_geocoder_pganalyze.jpg" srcset="https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/e52aa/postgis_rails_geocoder_pganalyze.jpg 175w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/70ebb/postgis_rails_geocoder_pganalyze.jpg 350w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/29d31/postgis_rails_geocoder_pganalyze.jpg 700w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/9ecec/postgis_rails_geocoder_pganalyze.jpg 1050w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/e5166/postgis_rails_geocoder_pganalyze.jpg 1200w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
    </span>
Picture via <a href="https://unsplash.com/@anniespratt">Annie Spratt</a> on Unsplash</p>
<p>I have built a number of Rails applications over the years that show locations on a map, have nearby search functionality, and I had never used <a href="https://postgis.net/">PostGIS</a> before! How was this possible? The reason is that there is a Ruby gem named <a href="https://github.com/alexreisner/geocoder">Geocoder</a> which enables you to do these sorts of queries, and it's quite efficient! That said, there is a reason that PostGIS exists. For more complex geo queries I‚Äôd recommend reaching beyond Geocoder to PostGIS.</p>
<p>As an example, if you wanted to find homes which have a school within 1km of them, or if you wanted to draw an oddly shaped polygon on a map and search within it, this is the world where PostGIS shines and makes these complex geo queries possible.</p>
<p>In this article we will be covering:</p>
<ul>
<li>PostGIS in Rails setup</li>
<li>Finding nearby records (Geocoder + PostGIS)</li>
<li>Finding records within a bounding box (Geocoder + PostGIS)</li>
<li>Finding records within a polygon (PostGIS)</li>
<li>Finding nearby related records (PostGIS)</li>
</ul>
<p>The source code referenced in this article can be <a href="https://github.com/pganalyze-resources/rails-postgis-demo">found here</a>.</p>
<h2 id="installing-postgis"><a href="#installing-postgis" aria-label="installing postgis permalink"></a>Installing PostGIS</h2>
<p>Postgres comes with a number of built-in extensions that you can enable, but unfortunately PostGIS (Spatial and Geographic objects for Postgres) isn't one of them. In order to enable this extension, you will have to use a Postgres install with PostGIS support. I recommend using the <a href="https://registry.hub.docker.com/r/postgis/postgis">official postgis docker image</a>, but luckily many hosted Postgres solutions come with PostGIS already available. If you are not sure, you can query the available extensions with the following query:</p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span>
<span>from</span> pg_available_extensions
<span>where</span> name <span>like</span> <span>'%postgis%'</span></code></pre></div>
<p>If you'd like to see if the extension is <em>already</em> enabled, you can run this query:</p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span> <span>from</span> pg_extension</code></pre></div>
<p>And finally, to enable this extension, you can use the command <code>create extension postgis</code>, but since we're working within Rails, there is a Gem that will take care of this step for us as we'll see below.</p>
<h2 id="activerecord-postgis-adapter"><a href="#activerecord-postgis-adapter" aria-label="activerecord postgis adapter permalink"></a>ActiveRecord PostGIS Adapter</h2>
<p>If you have confirmed that your version of Postgres supports the <code>postgis</code> extension, you're ready to integrate it with your Rails application. This can be done by using the <a href="https://github.com/rgeo/activerecord-postgis-adapter">activerecord-postgis-adapter</a> gem. Two things need to be done to get up and running. The first is to update the <code>adapter</code> within <code>config/database.yml</code> to be set to <code>postgis</code>. Next, if this is a new application, you can run <code>rails db:create</code> as normal, but if it is an existing one, you'll have to run the command <code>rake db:gis:setup</code>. This command is enabling the postgis extension in your database.</p>
<h2 id="our-example-data"><a href="#our-example-data" aria-label="our example data permalink"></a>Our Example Data</h2>
<p>We'll be working with sample data for a realtor website that allows us to find homes in a variety of ways, including homes that are nearby a local school. There are two models: <code>homes</code> and <code>schools</code>. The Rails migration to create these tables is below:</p>
<div data-language="ruby"><pre><code><span>class</span> <span>CreateHomes</span> <span>&lt;</span> <span>ActiveRecord</span><span>:</span><span>:</span><span>Migration</span><span>[</span><span>6.0</span><span>]</span>
  <span>def</span> <span><span>change</span></span>
    create_table <span>:homes</span> <span>do</span> <span>|</span>t<span>|</span>
      t<span>.</span>string <span>:name</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>string <span>:status</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>bigint <span>:price</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>integer <span>:beds</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> default<span>:</span> <span>0</span>
      t<span>.</span>integer <span>:baths</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> default<span>:</span> <span>0</span>
      t<span>.</span>st_point <span>:coords</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> geographic<span>:</span> <span>true</span>
      t<span>.</span>float <span>:longitude</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>float <span>:latitude</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>timestamps

      t<span>.</span>index <span>:coords</span><span>,</span> using<span>:</span> <span>:gist</span>
      t<span>.</span>index <span>%i[latitude longitude]</span>
      t<span>.</span>index <span>:status</span>
      t<span>.</span>index <span>:price</span>
    <span>end</span>

    create_table <span>:schools</span> <span>do</span> <span>|</span>t<span>|</span>
      t<span>.</span>st_point <span>:coords</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> geographic<span>:</span> <span>true</span>

      t<span>.</span>index <span>:coords</span><span>,</span> using<span>:</span> <span>:gist</span>
      t<span>.</span>timestamps
    <span>end</span>
  <span>end</span>
<span>end</span></code></pre></div>
<p>By using <code>activerecord-postgis-adapter</code> we are able to define PostGIS columns within our migration file. When working with PostGIS you can store a point (latitude + longitude) as a single column of type <code>ts_point</code>, whereas when working with <a href="https://github.com/alexreisner/geocoder">Geocoder</a> the latitude and longitude are stored as floats in separate columns. Because we are comparing the two approaches, we will store the data both ways, but typically you would choose one approach or the other.</p>
<p>PostGIS <strong>geographic</strong> columns can be indexed using <a href="https://www.postgresql.org/docs/current/gist-intro.html">GiST</a> style indexes. GiST indexes are required over B-Tree indexes when working with geographic data because coordinates cannot be easily sorted along a single axis (such as numbers, letters, dates, etc...) in a way that would allow the database to speed up common geographic operations.</p>
<p>The example project for this article contains a seeds file (run with <code>rake db:seed</code>) which will generate 100k homes and 100 schools in and around the Atlanta, Georgia area.</p>
<h2 id="building-a-geo-helper-class-with-postgis"><a href="#building-a-geo-helper-class-with-postgis" aria-label="building a geo helper class with postgis permalink"></a>Building a Geo Helper Class with PostGIS</h2>
<p>The Rails PostGIS adapter is based on a library named <a href="https://github.com/rgeo/rgeo">RGeo</a>, which while incredibly powerful, I found a little bit confusing due to a lack of documentation. I ended up building a small helper class to generate different geo objects for me. The first thing to point out is what <a href="https://en.wikipedia.org/wiki/Spatial_reference_system">SRID</a> is. Just like the imperial and metric systems are used to measure and weigh amounts using an agreed upon reference point, coordinates also need a coordinate reference system to ensure that the latitude and longitude that one uses means the same thing to different people when referring to a single place on earth. <a href="https://spatialreference.org/ref/epsg/wgs-84/">4326</a> is the spatial system used for GPS satellite navigation systems and the one we will be using within this article.</p>
<p>One last thing to define is what <a href="https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry">WKT</a> is. Well-known Text representation of geometry is a string representation of a point, line string, and polygon (among other things) that we will be using in our examples in this article. This is the format Postgres (PostGIS) receives and displays geographic data types in.</p>
<div data-language="ruby"><pre><code><span>class</span> <span>Geo</span>
  <span>SRID</span> <span>=</span> <span>4326</span>

  <span>def</span> <span><span>self</span><span>.</span><span>factory</span></span>
    <span>@@factory</span> <span>||</span><span>=</span> <span>RGeo</span><span>:</span><span>:</span><span>Geographic</span><span>.</span>spherical_factory<span>(</span>srid<span>:</span> <span>SRID</span><span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>pairs_to_points</span></span><span>(</span>pairs<span>)</span>
    pairs<span>.</span>map <span>{</span> <span>|</span>pair<span>|</span> point<span>(</span>pair<span>[</span><span>0</span><span>]</span><span>,</span> pair<span>[</span><span>1</span><span>]</span><span>)</span> <span>}</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>point</span></span><span>(</span>longitude<span>,</span> latitude<span>)</span>
    factory<span>.</span>point<span>(</span>longitude<span>,</span> latitude<span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>line_string</span></span><span>(</span>points<span>)</span>
    factory<span>.</span>line_string<span>(</span>points<span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>polygon</span></span><span>(</span>points<span>)</span>
    line <span>=</span> line_string<span>(</span>points<span>)</span>
    factory<span>.</span>polygon<span>(</span>line<span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>to_wkt</span></span><span>(</span>feature<span>)</span>
    <span>"srid=<span><span>#{</span><span>SRID</span><span>}</span></span>;<span><span>#{</span>feature<span>}</span></span>"</span>
  <span>end</span>
<span>end</span></code></pre></div>
<h2 id="finding-nearby-records-with-postgis-and-geocoder"><a href="#finding-nearby-records-with-postgis-and-geocoder" aria-label="finding nearby records with postgis and geocoder permalink"></a>Finding Nearby Records with PostGIS and Geocoder</h2>
<p>One of the most common geo queries used in applications is to find all records within X distance from a known point (the user's location, an event, a search, etc...). Because we installed <code>Geocoder</code> and added <code>reverse_geocoded_by :latitude, :longitude</code> to our <code>Home</code> class, we can use the <code>nearby</code> method to find all homes within 5km of this latitude and longitude (which happens to be Atlanta, Georgia). Geocoder likes to have arrays with latitude and then longitude, as opposed to PostGIS which <strong>prefers the exact opposite</strong> order!</p>
<div data-language="ruby"><pre><code><span>Home</span><span>.</span>near<span>(</span><span>[</span><span>33.753746</span><span>,</span> <span>-</span><span>84.386330</span><span>]</span><span>,</span> <span>5</span><span>)</span><span>.</span>count<span>(</span><span>:all</span><span>)</span> </code></pre></div>
<p>This query ran in about 5ms on my computer (searching through 100k records)... pretty fast! The reason it is fast is because we added an index on the latitude and longitude fields, but also because Geocoder applies a bounding box filter which utilises the index. Remember the Spatial Reference System (SRID) that we mentioned above? Because our coordinates do not take place on a <a href="https://en.wikipedia.org/wiki/Cartesian_coordinate_system">Cartesian plane</a>, we can‚Äôt use a standard distance formula to calculate the <a href="https://www.mathsisfun.com/algebra/distance-2-points.html">distance between two points</a>. Although we won‚Äôt venture further into the math of this query below, it takes into consideration the Earth‚Äôs spherical nature when calculating the distance between two coordinates as specified by latitude and longitude. <a href="https://www.movable-type.co.uk/scripts/latlong.html">This article</a> dives into more detail on these calculations if you are interested.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>FROM</span> <span>"homes"</span> <span>WHERE</span> <span>(</span>homes<span>.</span>latitude <span>BETWEEN</span> <span>33.708779919704064</span> <span>AND</span> <span>33.798712080295935</span> <span>AND</span> homes<span>.</span>longitude <span>BETWEEN</span> <span>-</span><span>84.44041260768655</span> <span>AND</span> <span>-</span><span>84.33224739231345</span> <span>AND</span> <span>(</span><span>6371.0</span> <span>*</span> <span>2</span> <span>*</span> ASIN<span>(</span>SQRT<span>(</span>POWER<span>(</span>SIN<span>(</span><span>(</span><span>33.753746</span> <span>-</span> homes<span>.</span>latitude<span>)</span> <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span> <span>/</span> <span>2</span><span>)</span><span>,</span> <span>2</span><span>)</span> <span>+</span> COS<span>(</span><span>33.753746</span> <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span><span>)</span> <span>*</span> COS<span>(</span>homes<span>.</span>latitude <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span><span>)</span> <span>*</span> POWER<span>(</span>SIN<span>(</span><span>(</span><span>-</span><span>84.38633</span> <span>-</span> homes<span>.</span>longitude<span>)</span> <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span> <span>/</span> <span>2</span><span>)</span><span>,</span> <span>2</span><span>)</span><span>)</span><span>)</span><span>)</span> <span>BETWEEN</span> <span>0.0</span> <span>AND</span> <span>5</span><span>)</span></code></pre></div>
<p>We'll have to build our own <code>near</code> query when working with PostGIS, but don't worry, it's pretty straight forward! The <code>g_near</code> method lives within the <code>Home</code> model, and takes advantage of the <a href="https://postgis.net/docs/ST_DWithin.html">ST_DWithin</a> function provided by PostGIS. Remember that we have to convert our point into the correct WKT format so that PostGIS understands the data we are passing it.</p>
<div data-language="ruby"><pre><code><span>def</span> <span><span>self</span><span>.</span><span>g_near</span></span><span>(</span>point<span>,</span> distance<span>)</span>
  where<span>(</span>
    <span>'ST_DWithin(coords, :point, :distance)'</span><span>,</span>
    <span>{</span> point<span>:</span> <span>Geo</span><span>.</span>to_wkt<span>(</span>point<span>)</span><span>,</span> distance<span>:</span> distance <span>*</span> <span>1000</span> <span>}</span> 
  <span>)</span>
<span>end</span>

<span>Home</span><span>.</span>g_near<span>(</span><span>Geo</span><span>.</span>point<span>(</span><span>-</span><span>84.386330</span><span>,</span> <span>33.753746</span><span>)</span><span>,</span> <span>5</span><span>)</span><span>.</span>count </code></pre></div>
<p>This query performs just about as fast as the Geocoder version (because of our GiST index on the <code>coords</code> column), but is definitely a little easier on the eyes to read.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>FROM</span> <span>"homes"</span> <span>WHERE</span> <span>(</span>ST_DWithin<span>(</span>coords<span>,</span> <span>'srid=4326;POINT (-84.38633 33.753746)'</span><span>,</span> <span>5000</span><span>)</span><span>)</span></code></pre></div>
<h2 id="finding-records-within-a-bounding-box-with-postgis-and-geocoder"><a href="#finding-records-within-a-bounding-box-with-postgis-and-geocoder" aria-label="finding records within a bounding box with postgis and geocoder permalink"></a>Finding Records Within a Bounding Box with PostGIS and Geocoder</h2>
<p>Geocoder provides us a way to find all records within a bounding box (roughly a rectangle, ignoring projection onto a sphere), and we just have to pass it the bottom left (south west) and top right (north east) coordinates.</p>
<div data-language="ruby"><pre><code><span>Home</span><span>.</span>within_bounding_box<span>(</span>
  <span>[</span><span>33.7250057553</span><span>,</span> <span>-</span><span>84.4224209302</span><span>]</span><span>,</span>
  <span>[</span><span>33.774350796</span><span>,</span> <span>-</span><span>84.3570139222</span><span>]</span>
<span>)</span><span>.</span>count </code></pre></div>
<p>Because it can use the index on latitude and longitude, it is quite efficient.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>FROM</span> <span>"homes"</span> <span>WHERE</span> <span>(</span>homes<span>.</span>latitude <span>BETWEEN</span> <span>33.7250057553</span> <span>AND</span> <span>33.774350796</span> <span>AND</span> homes<span>.</span>longitude <span>BETWEEN</span> <span>-</span><span>84.4224209302</span> <span>AND</span> <span>-</span><span>84.3570139222</span><span>)</span></code></pre></div>
<p>To perform a bounding box query using PostGis, we'll create a method named <code>g_within_box</code> inside of the <code>Home</code> model, and utilize a PostGIS function named <a href="https://postgis.net/docs/ST_MakeEnvelope.html">ST_MakeEnvelope</a> along with the <code>&amp;&amp;</code> operator.</p>
<div data-language="ruby"><pre><code><span>def</span> <span><span>self</span><span>.</span><span>g_within_box</span></span><span>(</span>sw_point<span>,</span> ne_point<span>)</span>
  where<span>(</span>
    <span>"coords &amp;&amp; ST_MakeEnvelope(:sw_lon, ‚Ä¶</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pganalyze.com/blog/postgis-rails-geocoder">https://pganalyze.com/blog/postgis-rails-geocoder</a></em></p>]]>
            </description>
            <link>https://pganalyze.com/blog/postgis-rails-geocoder</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652608</guid>
            <pubDate>Thu, 01 Oct 2020 16:11:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building your own air pollution monitor with a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24652488">thread link</a>) | @stevenhubertron
<br/>
October 1, 2020 | https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
	<article>
		<div>

			<section>
				<p>With all the wildfires happening around the US this summer (2020) I finally got motivated enough to put together an air quality monitor home base station to see air quality in person, on the web and on my phone. &nbsp;If you has a Raspberry Pi plus a few other items you can set this up in an afternoon. I have it tuned to measure PM1.0, PM2.5, PM10, and Carbon Monoxide inside my house. </p><p>As an example, here is what I see in my Adafruit Dashboard</p><figure><img src="https://www.drkpxl.com/content/images/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png" alt="" srcset="https://www.drkpxl.com/content/images/size/w600/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 600w, https://www.drkpxl.com/content/images/size/w1000/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 1000w, https://www.drkpxl.com/content/images/size/w1600/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 1600w, https://www.drkpxl.com/content/images/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 2024w" sizes="(min-width: 720px) 720px"><figcaption>My Adafruit dashboard.&nbsp;</figcaption></figure><p>I already had most of the the supplies but here is a list of what you will need:</p><ul><li><a href="https://shop.pimoroni.com/products/raspberry-pi-zero-wh-with-pre-soldered-header">Raspberry Pi Zero WH</a></li><li><a href="https://shop.pimoroni.com/products/enviro?variant=31155658489939">Enviro+</a></li><li><a href="https://shop.pimoroni.com/products/pms5003-particulate-matter-sensor-with-cable">PMS50003</a> Particulate Matter Sensor with cable</li><li>A free <a href="https://io.adafruit.com/">Adafruit IO</a> account</li></ul><p>Once you get it all plugged into, the Enviro+ into the Pi, and the PMS5003 into the Enviropi you can get the OS setup with a standard install.</p><p>I'll assume you know how to get Raspberry setup on your PI as well as SSH into it. If not there are a great number of <a href="https://desertbot.io/blog/headless-raspberry-pi-4-ssh-wifi-setup">tutorials</a> <a href="https://www.tomshardware.com/reviews/raspberry-pi-headless-setup-how-to,6028.html">out</a> <a href="https://medium.com/@jay_proulx/headless-raspberry-pi-zero-w-setup-with-ssh-and-wi-fi-8ddd8c4d2742">there</a>.</p><p>Once you are SSHed in, you can follow along with the instructions on the Pimoroni site or just run this script after an <code>apt upgrade</code> and <code>apt update</code></p><pre><code>git clone https://github.com/pimoroni/enviroplus-python
cd enviroplus-python
sudo ./install.sh</code></pre><p>This will install all the various code and samples to get playing with the sensors. The Enviro+ has a bunch of different sensors and LCDs in one making it extremely easy.</p><p>My goals for the setup are:</p><figure><img src="https://www.drkpxl.com/content/images/2020/09/IMG_5163-1.jpg" alt="" srcset="https://www.drkpxl.com/content/images/size/w600/2020/09/IMG_5163-1.jpg 600w, https://www.drkpxl.com/content/images/size/w1000/2020/09/IMG_5163-1.jpg 1000w, https://www.drkpxl.com/content/images/2020/09/IMG_5163-1.jpg 1500w" sizes="(min-width: 720px) 720px"></figure><h3 id="lcd">LCD</h3><p>The LCD displays PM10, PM2.5 and PM1, temp, and noise level on the screen by default. If the pollution spikes, or the gas spikes the LCD will turn red and display a warning.</p><h3 id="adafruit-io">Adafruit IO</h3><p>All the LCD data <strong>plus</strong> Carbon Monoxide, CPU Temp, and CPU load so that I just have a view that everything is healthy on the Pi.</p><figure><img src="https://www.drkpxl.com/content/images/2020/09/IMG_5168.jpg" alt="" srcset="https://www.drkpxl.com/content/images/size/w600/2020/09/IMG_5168.jpg 600w, https://www.drkpxl.com/content/images/size/w1000/2020/09/IMG_5168.jpg 1000w, https://www.drkpxl.com/content/images/2020/09/IMG_5168.jpg 1123w" sizes="(min-width: 720px) 720px"></figure><h3 id="ifttt">IFTTT</h3><p>Push alerts to high pollution or gas to my phone so I can be notified immediately if something is at issue.</p><h2 id="key-code-snippets">Key Code Snippets</h2><h3 id="get-the-cpu-temp">Get the CPU Temp</h3><figure><pre><code>def cpu_report_func():
    # Get CPU Info
    cpu = CPUTemperature()
    aio.send('cpu-temp', round(cpu.temperature * 1.8 + 32))
    aio.send('cpu', psutil.cpu_percent())</code></pre><figcaption>Get CPU temp, convert to F and send both temp and usage to Adafruit</figcaption></figure><h3 id="get-noise">Get Noise</h3><figure><pre><code>def noise_func():
    # Get Noise
    global noise_amount, noise_display
    noise_amount = noise.get_amplitude_at_frequency_range(20, 8000)
    noise_display = str(int(round(noise_amount * 100))) + " db"
    aio.send('noise', int(round(noise_amount * 100)))</code></pre><figcaption>Get noise within a wide range, round it and send off to display and Adafruit</figcaption></figure><h3 id="get-ambient-temps-w-corrections">Get Ambient Temps w/ Corrections</h3><pre><code>def temp_func():
    # Read Temp, convert to F and adjust
    global tempf_display
    # Tuning factor for compensation. Decrease this number to adjust the
    # temperature down, and increase to adjust up
    factor = 0.6

    cpu_temp = CPUTemperature().temperature
    cpu_temps.append(cpu_temp)
    avg_cpu_temp = sum(cpu_temps) / float(len(cpu_temps))
    raw_temp = bme280.get_temperature()
    comp_temp = raw_temp - ((avg_cpu_temp - raw_temp) / factor)
    # Convert to America
    tempf = round(comp_temp * 1.8 + 32)
    
    tempf_display = "" + str(tempf) + " F"
    print(tempf_display)

    # Clean up Array so it doesn't overflow memory
    if (len(cpu_temps) &gt; 10):
        cpu_temps.pop(0)
        aio.send('temp', tempf)</code></pre><p>The thing you would think would be the easiest is actually the hardest due mainly to the fact the themometer is so close to the CPU that it's picking up ambient heat from it. What this does (and is heavily cribbed from the Pimoroni example) is use the CPU temp as a baseline measure that fills up an array, correct for it and convert it to F. Since this "app" is basically one big loop I want to clear the array out after 10 readings or 10 minutes. That should give me enough history to get a good average and the temps I see pass the gut check. </p><p>The <code>factor</code> float may need to be adjusted for your specfic needs. For example if you don't have the Pi in a Lego case, or have different airflow the factor you need to adjust it to may need to be different. </p><h3 id="get-gas-specfically-reducing-aka-carbon-monoxide">Get Gas, specfically Reducing AKA Carbon Monoxide </h3><figure><pre><code>def gas_func():
    global gas_reading, gas_average, gas_warning_amount
    # Get Gas
    gas_reading = gas.read_all()
    gas_array.append(gas_reading.reducing)
    # If the array is larger than 8 items dump the first one
    if (len(gas_array) &gt; 8):
        gas_array.pop(0)
        #print("Popped!")
        aio.send('gas', round(gas_reading.reducing))
    gas_average = (sum(gas_array) / len(gas_array))
    gas_warning_amount = str(round(gas_reading.reducing))
</code></pre><figcaption>Get an average gas reading, current reading and send to Adafruit</figcaption></figure><h3 id="get-air-pollution">Get Air Pollution</h3><figure><pre><code>def pollution_func():
    global pm25, pm10_display, pm25_display, pm1_display
    # Read Particulate Matter
    readings = pms5003.read()
    pm25 = readings.pm_ug_per_m3(2.5)
    pm10 = readings.pm_ug_per_m3(10)
    pm1 = readings.pm_ug_per_m3(1)
    # Send to Adafruit
    aio.send('pollution.pm25', pm25)
    aio.send('pollution.pm1', pm1)
    aio.send('pollution.pm10', pm10)
    # Draw on Screen
    pm10_display = "PM10: " + str(pm10) + " ug/m3"
    pm25_display = "PM25: " + str(pm25) + " ug/m3"
    pm1_display = "PM10: " + str(pm1) + " ug/m3"</code></pre><figcaption>Get the standard ug/m3 readings, send to Adafruit and display</figcaption></figure><h3 id="display-logic">Display Logic</h3><pre><code># Display output of sensors on display
        disp.set_backlight(1)
        if (gas_reading.reducing &gt; (gas_average * 1.05) and len(gas_array) == 8):
            print("High Pollution Warning")
            draw.rectangle((0, 0, 160, 80), (255, 0, 0))
            draw.text((10, 20), warning, font=font, fill=text_colour)
            draw.text((10, 40), gas_warning_amount, font=font, fill=text_colour)
        elif (pm25 &gt; 50):
            draw.rectangle((0, 0, 160, 80), (255, 0, 0))
            draw.text((10, 20), warning, font=font, fill=text_colour)
            draw.text((10, 40), pm25_display, font=font, fill=text_colour)
        else:
            draw.rectangle((0, 0, 160, 80), back_colour)
            draw.text((0, 0), pm10_display, font=font, fill=text_colour)
            draw.text((0, 20), pm25_display, font=font, fill=text_colour)
            draw.text((0, 40), pm1_display, font=font, fill=text_colour)
            draw.text((0, 60), tempf_display, font=font, fill=text_colour)
            draw.text((80, 60), noise_display, font=font, fill=text_colour)
        disp.display(img)
        time.sleep(60)</code></pre><p>This is a basic if else statement that has the following rules:</p><ul><li>If gas is higher than the average + 5% (indicating a spike) push an alarm to the Pi's display</li><li>If gas is ok, but PM2.5 pikes over 50 push an alarm to the Pi's display</li><li>Otherwise just show the PM numbers, Temp and Noise</li></ul><p>As you can see it's all pretty straightforward code in one big loop. If you just copy and paste the code following, add your Adafruit key, and do some additional setup in Adafruit IO you can have this up and running very quickly.</p><h2 id="the-complete-code">The Complete Code</h2><pre><code>import psutil
from gpiozero import CPUTemperature
import time
import datetime
from Adafruit_IO import Client
from bme280 import BME280
from enviroplus.noise import Noise
import colorsys
import sys
import ST7735
try:
    # Transitional fix for breaking change in LTR559
    from ltr559 import LTR559
    ltr559 = LTR559()
except ImportError:
    import ltr559

try:
    from smbus2 import SMBus
except ImportError:
    from smbus import SMBus


from pms5003 import PMS5003, ReadTimeoutError as pmsReadTimeoutError, SerialTimeoutError
from enviroplus import gas
from subprocess import PIPE, Popen
from PIL import Image
from PIL import ImageDraw
from PIL import ImageFont
from fonts.ttf import RobotoMedium as UserFont
from datetime import timedelta



# Initial Setup of sensors / API
bus = SMBus(1)
bme280 = BME280(i2c_dev=bus)
aio = Client('XXX', 'aio_XXX')
pms5003 = PMS5003()
noise = Noise()

# Create LCD class instance.
disp = ST7735.ST7735(
    port=0,
    cs=1,
    dc=9,
    backlight=12,
    rotation=270,
    spi_speed_hz=10000000
)

# Create array for averages
gas_array = []
cpu_temps = []

# Initialize display.
disp.begin()

# Width and height to calculate text position.
WIDTH = disp.width
HEIGHT = disp.height

# New canvas to draw on.
img = Image.new('RGB', (WIDTH, HEIGHT), color=(0, 0, 0))
draw = ImageDraw.Draw(img)

# Text settings.
font_size = 20
small_font_size = 12
font = ImageFont.truetype(UserFont, font_size)
small_font = ImageFont.truetype(UserFont, small_font_size)
text_colour = (255, 255, 255)
back_colour = (0, 0, 0)
#size_x, size_y = draw.textsize(message, font)
warning = "Warning!"

# Calculate text position
#x = (WIDTH - size_x) / 2
#y = (HEIGHT / 2) - (size_y / 2)
x = 0
y = 0


def warm_func():
    currentTime = datetime.datetime.now()
    draw.rectangle((0, 0, 160, 80), (30, 160, 30))
    draw.text((10, 20), "Warming Up", font=font, fill=text_colour)
    draw.text((0, 66), currentTime.strftime("%a, %b %d %I:%M:%S %p"), font=small_font, fill=text_colour)
    disp.display(img)
    print("Warming Up at " + currentTime.strftime("%a, %b %d %I:%M:%S %p"))

def cpu_report_func():
    # Get CPU Info
    cpu = CPUTemperature()
    aio.send('cpu-temp', round(cpu.temperature * 1.8 + 32))
    aio.send('cpu', psutil.cpu_percent())

def noise_func():
    # Get Noise
    global noise_amount, noise_display
    noise_amount = noise.get_amplitude_at_frequency_range(20, 8000)
    noise_display = str(int(round(noise_amount * 100))) + " db"
    aio.send('noise', int(round(noise_amount * 100)))

def temp_func():
    # Read Temp, convert to F and adjust
    global tempf_display
    # Tuning factor for compensation. Decrease this number to adjust the
    # temperature down, and increase to adjust up
    factor = 0.6

    cpu_temp = CPUTemperature().temperature
    #print("CPU Temp: " + str(cpu_temp))
    cpu_temps.append(cpu_temp)
    avg_cpu_temp = sum(cpu_temps) / float(len(cpu_temps))
    raw_temp = bme280.get_temperature()
    comp_temp = raw_temp - ((avg_cpu_temp - raw_temp) / factor)
    # Convert to America
    tempf = round(comp_temp * 1.8 + 32)
    
    tempf_display = "" + str(tempf) + " F"
    print(tempf_display)

    # Clean up Array ‚Ä¶</code></pre></section></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/">https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/</a></em></p>]]>
            </description>
            <link>https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652488</guid>
            <pubDate>Thu, 01 Oct 2020 16:03:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing TikTok‚Äôs multi-billion dollar algorithm]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651822">thread link</a>) | @ailon
<br/>
October 1, 2020 | https://blog.ailon.org/testing-tiktoks-multi-billion-dollar-algorithm-af38fdd8225?source=friends_link&sk=a736bbdd904768fa4d7bcfb536615573 | <a href="https://web.archive.org/web/*/https://blog.ailon.org/testing-tiktoks-multi-billion-dollar-algorithm-af38fdd8225?source=friends_link&sk=a736bbdd904768fa4d7bcfb536615573">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p id="aae4">Almost a month ago my wife wanted to register on TikTok and was experiencing some odd difficulties. As our family‚Äôs tech-support person I ended up registering myself in the process of helping her. After posting a random TikTok (again, to help with some issues) I realized that it‚Äôs a good opportunity to put TikTok‚Äôs mighty algorithm to the test.</p><p id="8ee7">Since I went deep(ish) into my music making hobby this year, I decided to make <a href="https://www.tiktok.com/@ailonid" rel="noopener">my TikTok</a> focused on that. Both as a content consumer and creator. To try to preserve the ‚Äúpurity‚Äù of the experiment I decided not to tell anyone about my TikTok for the duration of this experiment. Well, my wife knew, obviously, and ‚Äúcontaminated‚Äù the results a bit. But I don‚Äôt think that was a major factor. So, here‚Äôs what I find out‚Ä¶</p><h2 id="168f">TikTok‚Äôs Algorithm for Consumers</h2><p id="571d">In the onboarding process you get asked very little. You pick some very wide-ranging themes of interest like entertainment, sports, music, etc. And that‚Äôs about it. Not surprisingly the initial experience is quite random ‚Äî you get a bunch of half-naked beautiful people, kitty-puppy videos, poor dad joke reenactments and alike.</p><p id="c9fc">I tried not to ‚Äúlike‚Äù any of the above and not to follow any celebrities. I went into search and tried to look up people posting TikToks about music production, music theory, audio engineering, music business and similar. After I followed a bunch of those not much changed in the first couple of days. But then my ‚ÄúFor You‚Äù feed (TikTok‚Äôs algorithmic feed) improved dramatically and became quite on-point.</p><p id="8d99">Interestingly, I was traveling for a couple of days (yes, this still happens once in a while in our neck of the woods) and didn‚Äôt use TikTok for a day or two. When I launched it after the break I got quite an increase in ‚Äúfunny‚Äù videos again. I guess this is AI‚Äôs idea of how to best ‚Äúreactivate‚Äù churning users. But after a day or two it got back to my regular programming.</p><p id="a2bb">So, from the consumer‚Äôs side the algorithm works quite well. On the other hand, so does the algorithm on YouTube or Instagram. As <a href="https://twitter.com/mattcutts" rel="noopener">Matt Cutts</a> (one of the early Googlers) <a href="https://youtu.be/kpmbptHDVJg?t=1335" rel="noopener">said on TWiT</a>:</p><blockquote><p id="8242">You can probably do a pretty good approximation [of TikTok‚Äôs algorithm] in like a thousand lines of code. You are looking for engagement, you are looking for growth, you are looking at the first derivative‚Ä¶ it‚Äôs gonna be pretty simple‚Ä¶</p></blockquote><p id="4112">In any case, it does work fine but this wasn‚Äôt the most interesting part to me. I‚Äôd be more surprised if it didn‚Äôt work well for consumers.</p><p id="cde4">What I was more interested in is the constant stream of raving comments on how well it works for creators ‚Äî ‚Äúnobodies‚Äù can reach millions with a good video, they said. Let‚Äôs see how that works‚Ä¶</p><h2 id="3e43">TikTok‚Äôs Algorithm for Creators</h2><p id="1833">I tried to post TikToks regularly. Not exactly every day but so far I posted 17 videos in about 4 weeks.</p><p id="8bc1">Quite obviously TikTok‚Äôs ‚Äúhook‚Äù is that they over-expose TikToks from newbies and make you feel really good in your first few days. (How do they deal with bots and trolls trying to abuse this is an interesting question but beside the point here.) My first 5 TikToks (the first one was just a random test) got between 500 and 700 views. Not bad for someone with 1 follower. But then the views started to go down.</p><p id="2433">Obviously, I didn‚Äôt produce any stunning content and I don‚Äôt think I deserve more views from the algorithm pushing me. But I‚Äôve noticed something peculiar‚Ä¶</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2070/1*TlzZOu5ZTizu7xsCT9oaNQ.png" width="1035" height="483" srcset="https://miro.medium.com/max/552/1*TlzZOu5ZTizu7xsCT9oaNQ.png 276w, https://miro.medium.com/max/1104/1*TlzZOu5ZTizu7xsCT9oaNQ.png 552w, https://miro.medium.com/max/1280/1*TlzZOu5ZTizu7xsCT9oaNQ.png 640w, https://miro.medium.com/max/1400/1*TlzZOu5ZTizu7xsCT9oaNQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*TlzZOu5ZTizu7xsCT9oaNQ.png?q=20"></p></div></div></div><figcaption>Typical stats for most of my recent TikToks</figcaption></figure><p id="2de3">While all of my TikToks (except one) are in [mostly broken] English, and I added relevant hashtags and descriptions in English, they were primarily shown in my home country of Lithuania. That‚Äôs a very small niche. Add that TikToks were for a niche subject of ‚Äúmusic-making‚Äù and you get close to zero of overlap.</p><p id="2d64">Interestingly, I got similar results on a couple of videos that I posted from Poland and Germany.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1012/1*A0bxyk6k9iMsg6XC5xs4kg.png" width="506" height="368" srcset="https://miro.medium.com/max/552/1*A0bxyk6k9iMsg6XC5xs4kg.png 276w, https://miro.medium.com/max/1012/1*A0bxyk6k9iMsg6XC5xs4kg.png 506w" sizes="506px" data-old-src="https://miro.medium.com/max/60/1*A0bxyk6k9iMsg6XC5xs4kg.png?q=20"></p></div></div><figcaption>Stats for TikTok posted from Germany</figcaption></figure><p id="d459">As you can see there‚Äôs Germany present here but the majority is still from Lithuania. The one from Poland had more Polish viewers but still fewer than Lithuanians. (FYI, the population of Poland is about 14x of Lithuania)</p><p id="569a">So the ‚Äúalmighty algorithm‚Äù somehow prioritizes your profile‚Äôs country over everything else. Not very smart, if you ask me. You may not notice this if you live in the US or some other big country, or if you create content for your local market. But, anecdotally, it feels like TikTok‚Äôs algorithm is quite discriminatory towards people from small countries trying to create global content.</p><p id="9aa2">To add insult to injury, I‚Äôm pretty sure TikTok never asked me for my country (I registered with email address, not phone or other account), and it doesn‚Äôt require location permissions (kudos for that). So basically they took my IP address at the time of registration and hard-coded my profile‚Äôs country to what they got from the IP lookup. Good thing I didn‚Äôt register at the office as many services think we are in Norway based on that IP. Or maybe that‚Äôs a bad thing given my goals.</p><blockquote><p id="e552"><strong>Untested pro-tip</strong>: create your account over VPN to US (or whatever location you care about) for better distribution.</p></blockquote><p id="5b0f">The bottom line is that TikTok‚Äôs algorithm still gave me more exposure than probably any other service would, considering I didn‚Äôt do anything to assist it (I didn‚Äôt tell anyone about my TikTok, remember?). Having said that, it handicapped me for no apparent reason purely based on my home country.</p><p id="2686">And that‚Äôs the main problem with all the algorithmic social media ‚Äî you are at the mercy of a bunch of ‚Äúif-then‚Äù statements with their bugs, quirks, and oddities.</p><p id="cef8">Now that you know <a href="https://www.tiktok.com/@ailonid" rel="noopener">I have TikTok</a>, we can proceed to the phase 2 of the experiment. If you are even remotely interested in music production and don‚Äôt live in Lithuania, please <a href="https://www.tiktok.com/@ailonid" rel="noopener">follow me on TikTok @ailonid</a> and in another month I will report if having followers outside of Lithuania had any impact on the algorithm.</p></div></div></div>]]>
            </description>
            <link>https://blog.ailon.org/testing-tiktoks-multi-billion-dollar-algorithm-af38fdd8225?source=friends_link&amp;sk=a736bbdd904768fa4d7bcfb536615573</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651822</guid>
            <pubDate>Thu, 01 Oct 2020 15:13:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Julian Assange Acted Responsibly]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651796">thread link</a>) | @DiogenesKynikos
<br/>
October 1, 2020 | https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen | <a href="https://web.archive.org/web/*/https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div data-css-88vvl0=""><p data-pos="0-0" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Der Bieler Professor Christian Grothoff hat keine Ahnung, wer M.√Ç&nbsp;I.√Ç&nbsp;A. ist. Schade eigentlich. Schon allein wegen ihres spektakul√É¬§ren, verst√É¬∂renden und kontrovers diskutierten Ausblicks auf das Trump-Zeitalter aus dem Jahr 2010, des zehn√Ç¬≠min√É¬ºtigen Videos zu ihrer Single √Ç¬´Born Free√Ç¬ª. Darin werden in einer alternativen Realit√É¬§t Rothaarige als verfolgte ethnische Minderheit von para√Ç¬≠milit√É¬§rischen US-Truppen zu Tode gejagt.</p><figure data-pos="0-1" data-css-1esus25=""><a data-css-11au926=""><span data-css-mcluq8=""><svg width="26" height="36.01" viewBox="0 0 26 36"><path d="M25.956 18.188L.894 35.718V.66" fill="#fff"></path></svg></span><span data-css-fijd0m="">Dies ist ein Vimeo-Video. Wenn Sie das Video abspielen, kann Vimeo Sie tracken.</span><span data-css-1bqahl="" role="img" aria-label=""></span></a><figcaption data-css-s9b1dj="" data-css-qc9yqx="">M.I.A, Born Free</figcaption></figure><p data-pos="0-2" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Daf√É¬ºr weiss M.√Ç&nbsp;I.√Ç&nbsp;A. aber, wer Christian Grothoff ist.</p><p data-pos="0-3" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">M.√Ç&nbsp;I.√Ç&nbsp;A.√Ç&nbsp;√¢‚Ç¨‚Äú jene englische Rapperin, die 2012 von der NFL auf eine Million Dollar Schaden√Ç¬≠ersatz verklagt worden war, weil sie w√É¬§hrend ihres Super-Bowl-Pausen√Ç¬≠auftritts mit Nicki Minaj und Madonna den Mittel√Ç¬≠finger <a href="https://www.youtube.com/watch?v=qlEUz1IlN70&amp;ab_channel=ATownHR23" data-css-9r2oe9="" data-css-1exity3="">in die Kameras gehalten hatte</a>. Oder 2016: Verklagt vom Fussball√Ç¬≠club Paris Saint-Germain, weil sie im Video zu ihrem Song √Ç¬´Borders√Ç¬ª ein T-Shirt des franz√É¬∂sischen Vereins trug und dabei den Schrift√Ç¬≠zug des Sponsors √Ç¬´Fly Emirates√Ç¬ª <a href="https://www.youtube.com/watch?v=r-Nw7HbaeWY&amp;ab_channel=MIAVEVO" data-css-9r2oe9="" data-css-1exity3="">in √Ç¬´Fly Pirates√Ç¬ª abge√É¬§ndert hatte</a>. </p><p data-pos="0-4" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Die 45-j√É¬§hrige Musikerin und politische Aktivistin setzt sich derzeit mit zahl√Ç¬≠reichen K√É¬ºnstlerinnen, darunter <a href="https://www.washingtonpost.com/entertainment/dissident-ai-weiwei-protests-possible-extradition-of-assange/2020/09/28/89e17c56-0183-11eb-b92e-029676f9ebec_story.html" data-css-9r2oe9="" data-css-1exity3="">Ai Weiwei oder Designerin Vivienne Westwood</a>, daf√É¬ºr ein, dass Wikileaks-Gr√É¬ºnder Julian Assange nicht an die USA ausgeliefert wird. Seit dem 7.√Ç&nbsp;September l√É¬§uft an einem Londoner Gericht die zweite Runde des Auslieferungs√Ç¬≠verfahrens, das wegen Covid-19 im April unterbrochen worden war. Die USA beschuldigen Assange, mit der Ver√É¬∂ffentlichung von 250√¢‚Ç¨‚Ñ¢000√Ç&nbsp;Depeschen aus US-Botschaften das Leben von Diplomaten und amerikanischen Helfern weltweit gef√É¬§hrdet zu haben.</p><h2 data-css-153qrt7="" data-css-qc9yqx=""><a data-css-1i4zy90="" id="der-zeuge-aus-der-schweiz"></a>Der Zeuge aus der Schweiz</h2><p data-pos="0-6" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">M.√Ç&nbsp;I.√Ç&nbsp;A. war es m√É¬∂glich, das Verfahren per Video√Ç¬≠stream live zu verfolgen√Ç&nbsp;√¢‚Ç¨‚Äú was alles andere als selbst√Ç¬≠verst√É¬§ndlich ist: Im Gericht waren f√É¬ºr die neue Anh√É¬∂rungs√Ç¬≠runde nur noch f√É¬ºnf Journalistinnen und ein paar wenige G√É¬§ste zugelassen, diversen Prozess√Ç¬≠beobachtern wie Amnesty International wurde am ersten Anh√É¬∂rungs√Ç¬≠tag kurzfristig der Zugang verweigert, zugesagte Beobachter√Ç¬≠pl√É¬§tze wurden gestrichen, ihnen wurde zusammen mit vierzig anderen Organisationen oder akkreditierten Medien die M√É¬∂glichkeit entzogen, <a href="https://www.amnesty.org/en/latest/news/2020/09/why-are-amnesty-international-monitors-not-able-to-observe-the-assange-hearing/" data-css-9r2oe9="" data-css-1exity3="">das Verfahren wenigstens per Stream verfolgen zu k√É¬∂nnen</a>.</p><p data-pos="0-7" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Dieser Vorgang wurde laut Amnesty International <a href="https://www.amnesty.org/en/latest/news/2020/09/why-are-amnesty-international-monitors-not-able-to-observe-the-assange-hearing/" data-css-9r2oe9="" data-css-1exity3="">nicht weiter begr√É¬ºndet</a> und sei √Ç¬´sehr beunruhigend√Ç¬ª. √Ç¬´Mit diesem Schritt missachtet das Gericht das Grund√Ç¬≠prinzip der √É‚Äìffentlichkeit√Ç¬ª, schrieb die Menschenrechts√Ç¬≠organisation: √Ç¬´Konkret, dass internationale Prozess√Ç¬≠beobachterinnen nachvollziehen k√É¬∂nnen, ob nationales und internationales Recht eingehalten wird.√Ç¬ª Und dies in einem Verfahren, in dem die Recht√Ç¬≠sprechung sowieso ziemlich eigenwillig interpretiert wird. Assange, dem der Zugang zu seinen eigenen Anw√É¬§lten in den letzten sechs Monaten verweigert worden war, sitzt mittlerweile seit 16√Ç&nbsp;Monaten ohne juristische Grundlage in Isolations√Ç¬≠haft, was√Ç&nbsp;√¢‚Ç¨‚Äú Grundlage hin oder her√Ç&nbsp;√¢‚Ç¨‚Äú als Folter gesehen werden muss. (Sein Vergehen, <a href="https://www.forbes.com/sites/thomasbrewster/2019/05/01/assange-given-50-weeks-in-prison-for-breaking-bail/#2af1cd5fa1d8" data-css-9r2oe9="" data-css-1exity3="">der Verstoss gegen Kautionsauflagen</a>, wird in Grossbritannien normaler√Ç¬≠weise nicht einmal mit einer kurzen Gef√É¬§ngnis√Ç¬≠strafe geahndet.)</p><p data-pos="0-8" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">M.√Ç&nbsp;I.√Ç&nbsp;A. also war es m√É¬∂glich, den Prozess live zu verfolgen.</p><p data-pos="0-9" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Und am Morgen des 21.√Ç&nbsp;September twitterte die Rapperin:</p><div data-css-wnj6iv="" data-pos="0-10"><p data-css-87w1y="" data-css-5rrfwp="">√Ç¬´Ich beobachtete diesen Zeugen. Ziemlich intensive Befragung, sogar die Richterin wurde w√É¬ºtend wegen des schonungs√Ç¬≠losen Kreuz√Ç¬≠verh√É¬∂rs, das er zu erdulden hatte. Ich empfehle es allen: Studiert bei Professor Dr.√Ç&nbsp;Christian Grothoff. Grothoff ist Professor der Informatik in der Schweiz. Er war brillant.√Ç¬ª</p><figcaption data-css-s9b1dj="" data-css-qc9yqx=""><a href="https://twitter.com/MIAuniverse/status/1308129185240580096" data-css-9r2oe9="" data-css-1exity3="">Tweet von @MIAuniverse</a></figcaption></div><p data-pos="0-11" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Am Tag darauf rief ich den Informatik√Ç¬≠professor an. </p><figure data-pos="0-12" data-css-j57vv8=""><figcaption data-css-s9b1dj="" data-css-qc9yqx="">√Ç¬´Mit dem n√É¬∂tigen Fach√Ç¬≠wissen l√É¬§sst sich alles Schritt f√É¬ºr Schritt nachvollziehen√Ç¬ª: Christian Grothoff. <span data-css-puup3u="">Martin Gross/youtube/gnunet</span></figcaption></figure><p data-pos="0-13" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´K√É¬∂nnen Sie mir sagen, was da los war?√Ç¬ª, fragte ich.</p><p data-pos="0-14" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Ja, nat√É¬ºrlich√Ç¬ª, sagt er. √Ç¬´Nach meinem Auftritt vor Gericht ist es mir jetzt erlaubt, meine Erkenntnisse mit der Presse zu teilen.√Ç¬ª</p><p data-pos="0-15" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Sie waren Zeuge im Assange-Prozess?√Ç¬ª</p><p data-pos="0-16" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Ja√Ç¬ª, sagte Professor Grothoff. √Ç¬´Ich habe meine Expertise dem Gericht zur Verf√É¬ºgung gestellt, einen dicken Stapel Unterlagen.√Ç¬ª</p><p data-pos="0-17" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Was f√É¬ºr eine Expertise?√Ç¬ª</p><p data-pos="0-18" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Ich sollte im Auftrag der Verteidigung nach bestem Wissen und Gewissen analysieren, wie es dazu kam, dass die Diplomaten√Ç¬≠depeschen, die Chelsea Manning Wikileaks √É¬ºbergeben hatte, sp√É¬§ter komplett ungeschw√É¬§rzt im Internet kursierten. Das ist ja eigentlich einer der zentralen Anklage√Ç¬≠punkte: Diese Publikation der gesamten Depeschen. Wer hat sie zuerst ins Netz gestellt? Wikileaks, wie es die USA behaupten?√Ç¬ª</p><p data-pos="0-19" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Haben Sie eine Antwort gefunden?√Ç¬ª</p><p data-pos="0-20" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Mit dem n√É¬∂tigen Fach√Ç¬≠wissen l√É¬§sst sich alles Schritt f√É¬ºr Schritt nachvollziehen.√Ç¬ª</p><p data-pos="0-21" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Wir trafen uns einen Tag sp√É¬§ter zum Abend√Ç¬≠essen in einem chinesischen Imbiss in der Berner Altstadt.</p><h2 data-css-153qrt7="" data-css-qc9yqx=""><a data-css-1i4zy90="" id="die-hauptschuld-liegt-beim-guardian"></a>√Ç¬´Die Hauptschuld liegt beim √¢‚Ç¨¬πGuardian√¢‚Ç¨¬∫√Ç¬ª</h2><p data-pos="0-23" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Und die Geschichte, die der Bieler Professor Christian Grothoff an jenem Abend im September zu erz√É¬§hlen hat, ist h√É¬∂chst erstaunlich.</p><figure data-pos="0-24" data-css-j57vv8=""><figcaption data-css-s9b1dj="" data-css-qc9yqx="">Assange-Unterst√É¬ºtzerinnen: Chelsea Manning (Mitte) und Dame Vivienne Westwood, hier mit ihrem Mann Andreas Kronthaler. <span data-css-puup3u="">David M. Benett/Getty Images</span></figcaption></figure><p data-pos="0-25" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Zehn Jahre lang <a href="https://www.bbc.com/news/technology-37165230" data-css-9r2oe9="" data-css-1exity3="">behaupteten die US-Beh√É¬∂rden (ohne jemals einen einzigen Beweis daf√É¬ºr zu erbringen</a>), dass Julian Assange Menschen√Ç¬≠leben gef√É¬§hrdet habe, weil er die ihm von Chelsea Manning anvertrauten diplomatischen Depeschen der US-Regierung komplett und einfach so ins Netz gestellt habe, und deswegen sei Assange kein Journalist.</p><p data-pos="0-26" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Die Erz√É¬§hlung von der Gef√É¬§hrdung hat sich bis heute gehalten, obwohl Mitarbeitende des State Department bereits Ende 2010 gegen√É¬ºber dem US-Kongress hatten durchsickern lassen (w√É¬§hrend die Obama-Administration √É¬∂ffentlich das Gegenteil behauptete), <a href="https://www.reuters.com/article/us-wikileaks-damage-idUSTRE70H6TO20110118" data-css-9r2oe9="" data-css-1exity3="">dass Wikileaks die USA zwar blossgestellt habe, dabei aber niemand zu Schaden gekommen sei</a>.</p><p data-pos="0-27" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Bei seiner Analyse fand Grothoff zudem heraus: Die Behauptung√Ç&nbsp;√¢‚Ç¨‚Äú ein zentraler Anklage√Ç¬≠punkt der US-Justiz√Ç&nbsp;√¢‚Ç¨‚Äú, Wikileaks habe als erste Quelle die Depeschen komplett und unbearbeitet ins Netz gestellt und sei deshalb unter dem √Ç¬´Espionage Act√Ç¬ª zu verfolgen, ist nachweislich falsch. Mit dem n√É¬∂tigen Fach√Ç¬≠wissen sei im Netz nachvollziehbar und unzweifelhaft belegbar, so Grothoff in seiner Expertise, dass Wikileaks erst im Nachgang die gesamten Depeschen publiziert habe√Ç&nbsp;√¢‚Ç¨‚Äú nachdem diese von anderen Quellen bereits online gestellt worden waren.</p><p data-pos="0-28" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Der Informatiker Christian Grothoff mit akademischen und beruflichen Stationen in Los Angeles, Denver, M√É¬ºnchen und Rennes ist ein international angesehener Fachmann unter anderem f√É¬ºr Verschl√É¬ºsselungs√Ç¬≠techniken, aber auch in der Analyse von Peer-to-Peer-Netzwerken und der √É≈ìberlastung von Servern zum Beispiel durch sogenannte DDOS-Angriffe.</p><p data-pos="0-29" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Kurz: Grothoff vereint so ziemlich das ganze Fach√Ç¬≠wissen, das in dieser Angelegenheit gefragt ist.</p><p data-pos="0-30" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Es ist im √É≈ìbrigen so, dass Assange die diplomatischen Depeschen derart gut gesch√É¬ºtzt hat√Ç¬ª, sagte Grothoff im Gespr√É¬§ch mit der Republik und auch vor Gericht, √Ç¬´dass sie auch von der NSA nicht h√É¬§tten geknackt werden k√É¬∂nnen.√Ç¬ª</p><p data-pos="0-31" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Das Bild, das Grothoff stattdessen zeichnet, ist ein Armuts√Ç¬≠zeugnis f√É¬ºr den Journalismus: Die Journalisten des √Ç¬´Guardian√Ç¬ª, mit denen sich Assange bald √É¬ºberwarf, hefteten sich wie Blut√Ç¬≠sauger an den Wikileaks-Gr√É¬ºnder, um mit seiner Hilfe die grossen Geschichten fahren zu k√É¬∂nnen. Der √Ç¬´Guardian√Ç¬ª-Journalist David Leigh √É¬ºbte dabei massiven Druck auf Assange aus: Er solle ihm das Passwort f√É¬ºr die verschl√É¬ºsselten Depeschen nennen, f√É¬ºr den Fall, dass Assange verhaftet werde und dann keine weiteren Geschichten mehr publiziert werden k√É¬∂nnten.</p><p data-pos="0-32" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Die Quelle daf√É¬ºr: das Buch √Ç¬´Wikileaks: Inside Julian Assange√¢‚Ç¨‚Ñ¢s War on Secrecy√Ç¬ª, das David Leigh im Februar 2011 selbst publiziert hatte. Dort steht auch, Assange habe schliesslich eingewilligt, Leigh das Passwort auszuh√É¬§ndigen√Ç&nbsp;√¢‚Ç¨‚Äú mit der eindringlichen Bitte, es niemals irgendwo als Ganzes aufzuschreiben.</p><p data-pos="0-33" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Assange, das steht in meiner Expertise f√É¬ºr das Gericht, ist verantwortungs√Ç¬≠voll mit den Daten umgegangen√Ç¬ª, sagt Grothoff. √Ç¬´Das l√É¬§sst sich alles nachvollziehen und belegen.√Ç¬ª Doch was nach der Passwort√Ç¬≠√É¬ºbergabe passiert sei, k√É¬∂nne er als Fachmann nur als √Ç¬´grob fahrl√É¬§ssig√Ç¬ª bezeichnen, und zwar nicht von Wikileaks, sondern vom √Ç¬´Guardian√Ç¬ª: √Ç¬´Der Journalist David Leigh schwatzt Julian Assange das Passwort ab√Ç&nbsp;√¢‚Ç¨‚Äú und dann publiziert er es ein paar Monate sp√É¬§ter als Kapitel√Ç¬≠titel in seinem Buch √¢‚Ç¨¬πInside Wikileaks√¢‚Ç¨¬∫.√Ç¬ª</p><p data-pos="0-34" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Ja, Sie haben richtig gelesen.</p><p data-pos="0-35" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Das Passwort, 58√Ç&nbsp;Buchstaben, Ziffern und Sonder√Ç¬≠zeichen, als √É≈ìberschrift in einem Buch. Der √Ç¬´Guardian√Ç¬ª-Journalist habe sp√É¬§ter behauptet, er sei davon ausgegangen, das Passwort sei veraltet gewesen. Als Verschl√É¬ºsselungs√Ç¬≠experte, sagte Grothoff, m√É¬ºsse er entgegnen, dass man in der Pflicht sei, sich zu informieren, mit welcher Technik man es zu tun habe, wenn man mit derartig sensiblen Daten operiere. </p><p data-pos="0-36" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Es dauerte nicht lange, da wurde in den Medien (namentlich im √Ç¬´Freitag√Ç¬ª und im √Ç¬´Spiegel√Ç¬ª) ein Zusammen√Ç¬≠hang zwischen dem Passwort aus dem Buch des √Ç¬´Guardian√Ç¬ª-Journalisten und der Depeschen-Datei hergestellt, die nach massiven sogenannten DDOS-Angriffen auf den Wikileaks-Server (Angriffe, um den Server lahmzulegen) und Spiegelungen ebenjenes Servers durch Dritte irgendwo unkontrolliert als Kopie in den Weiten des Netzes umherschwirrte. Am 1.√Ç&nbsp;September 2011 sei diese dann unverschl√É¬ºsselt auf einer Plattform namens √Ç¬´Cryptome√Ç¬ª aufgetaucht. </p><p data-pos="0-37" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Tats√É¬§chlich sagte der Betreiber von √Ç¬´Cryptome√Ç¬ª nun vor dem Londoner Gericht aus, er habe als Erster die Depeschen vollumf√É¬§nglich, ungeschw√É¬§rzt und unverschl√É¬ºsselt hochgeladen√Ç&nbsp;√¢‚Ç¨‚Äú <a href="https://www.fr24news.com/a/2020/09/us-never-asked-wikileaks-rival-to-remove-leaking-cables-court-says-julian-assange.html" data-css-9r2oe9="" data-css-1exity3="">und bis heute habe die US-Regierung bei ihm nichts von sich h√É¬∂ren lassen</a>.</p><p data-pos="0-38" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Die Depeschen finden sich immer noch dort√Ç¬ª, sagt Grothoff. </p><p data-pos="0-39" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Es sei problemlos chronologisch aufzuzeigen, sagte Informatik√Ç¬≠professor Grothoff im Berner Imbiss, dass die Haupt√Ç¬≠schuld f√É¬ºr die Publikation der gesamten Depeschen beim √Ç¬´Guardian√Ç¬ª liege. √Ç¬´W√É¬§re man ‚Ä¶</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen">https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen</a></em></p>]]>
            </description>
            <link>https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651796</guid>
            <pubDate>Thu, 01 Oct 2020 15:11:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on QA]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24651571">thread link</a>) | @tigranhakobian
<br/>
October 1, 2020 | https://blog.superannotate.com/how-to-detect-mislabeled-annotations | <a href="https://web.archive.org/web/*/https://blog.superannotate.com/how-to-detect-mislabeled-annotations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><em>Manual QA is a significant part of the annotation pipeline. Annotation companies report that 40 percent of the annotation time can be spent on manual QA. As a result, finding ways to reduce QA testing time can have a significant impact on annotation costs.&nbsp;</em></p>
<!--more--><p><em>At SuperAnnotate, we‚Äôve developed a tool to accelerate the QA process. This article discusses SuperAnnotate‚Äôs features that speed up the quality assurance process substantially. It presents several automation tools within the platform listing specific use cases in which a major acceleration of the QA process can be obtained. We also explored various ML algorithms that can detect over 90 percent of mislabeled instances in data while accelerating the QA process up to 4 times.&nbsp;</em></p>
<h3><strong><span>Outline</span></strong></h3>
<ul>
<li><em>Problem with noisy annotation in data&nbsp;</em></li>
<li><em>Manual QA acceleration</em></li>
<li><em>QA automation</em></li>
<li><em>Conclusion</em></li>
</ul>
<h2><span>Problem with annotation noise in data</span></h2>
<p><strong><span>1.1. The importance of model accuracy and the impact of annotation noise&nbsp;&nbsp;</span></strong></p>
<p>In real-world applications, the performance of machine learning (ML) systems is of crucial importance. ML models heavily rely on the quality of annotated data, but obtaining high-quality annotations is costly and requires extensive manual labor.&nbsp;</p>
<p><span>In any annotation pipeline, regardless of the data collection method, i.e., human or machine, several factors inject annotation noise in data. As a result, even the most celebrated datasets contain mislabeled annotations.</span></p>

<p><img src="https://lh3.googleusercontent.com/mL1r0JU9VM5-WflEsLU04zQ7vhYhl8cKRux8LvOnUTYEKZvnIUD9Gv8HmkVTqPfgoDtEkb_5ApX3SjgJjdTAHNfG6I-5Q7_fag_cra8IhXTWp-uVdrvQCf7kzoqt03BwtgKlTb4i" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"><em>Figure: Ambiguous or Mislabeled annotations from ImageNet. Source (</em><a href="https://arxiv.org/abs/2001.10528"><em><span>Pleiss et al</span></em></a><em>.)</em></p>

<p><span>Recent studies show that both natural and malicious corruptions of annotations tend to radically degrade the performance of machine learning systems. Deep Neural Networks (DNNs) tend to memorize noisy labels in data, resulting in less generalizable features and poor model performance (<a href="https://arxiv.org/abs/1611.03530">Zhang et al.</a>)</span></p>
<p><span>Therefore, extensive quality control of annotated data is required to clean annotation noise and improve model performance.</span><em><br></em></p>

<p><img src="https://lh4.googleusercontent.com/7BKHH4Am8Z_PZebzMe7mkbGCA6J_UyNRZE-ClAMwP5qVo52ZEuybUx81EOWYSdKrz2Mz7P4zf2cHuoz9nlyl4Alg-D16cD58mSCLf1CAOUwwDEp2MUkIsaTi37D6y9aliNShqdUz" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: Accuracy drop in multiple datasets when injecting label noise. Source (</em><a href="https://arxiv.org/abs/1611.03530"><em><span>Rolnick et al.</span></em></a><em>)</em></p>

<h2>Manual QA Acceleration</h2>
<p><strong><span>2.1 SuperAnnotate‚Äôs QA pipeline&nbsp;</span></strong></p>
<p><span>Quality Assurance of annotated data is time-consuming and requires particular attention. Annotation tools need to provide reliable and scalable QA pipelines to accelerate the QA process. <a href="https://annotate.online/login">SuperAnnotate</a> provides interlinked annotation and QA processes within the same platform. As a result, QA systems do not require additional management.</span></p>
<p><span>The design of SuperAnnotate‚Äôs QA system guarantees an efficient process and ensures a minimal probability of error.&nbsp;</span></p>
<p><strong><span>2.2 Pinning images to reduce common errors&nbsp;</span></strong></p>
<p><span>Sharing repetitive labeling mistakes across the annotation team is essential to reduce systematic errors throughout single or multiple annotation projects. </span>SuperAnnotate‚Äôs pin functionality is designed specifically for this cause.&nbsp;</p>
<p>Once the reviewer notices a recurring error, they can share this information through pinned annotations instead of extensive project instructions. Pinned annotations will appear first in the annotation editor to immediately grab the annotation team‚Äôs attention.&nbsp;</p>
<p>This functionality is highly efficient since it allows the project coordinator to instantly share common instructions, eliminating the spread of systematic errors.&nbsp;</p>

<p><img src="https://lh6.googleusercontent.com/g1sh6D7Xy1hLYBMczMWfFGdO1_1gktJn7dNF1Spx3lwUxeZd8isGaMHgYLB1GoT0lY8jJKTemdqvtExgPJIocgjNEFuzYGjbPQYeRo31873mdN3U4U10DMjW7DZOnr1eAh5_o-bc" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: Pin functionality</em></p>

<p><strong><span>2.3 Approve/Disapprove functionality</span></strong></p>
<p>Apart from various image-level QA tools, SuperAnnotate also provides instance-level QA functionalities. The latter is designed to help the QA focus on a specific instance area. As a result, no error is overlooked, at the time a meticulous QA is time-efficient.</p>
<p>Additionally, the Approve/Disapprove functionality works on the level of individual instances<span>.</span> If a QA specialist disapproves of an annotation, they can send it back to the Annotator for correction. The QA specialist can send the annotation back to the Annotator as many times as needed until the annotation is corrected. Once approved, the annotations can be exported from the platform.</p>

<p><img src="https://lh4.googleusercontent.com/BpQPXRUuTMRYUP-YGJTSRJwFUtdLr6wsB5LVwn66wK6TqFJCTRW5LLwhTp4sRttqgzQaCngKzm7Z6ONZBpPhwzxifj1KlBRs5_FOl_Nk0cFpaC_jn7-l9CMn1WJX2FENx9f9NI24" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p>Figure: Approve/Disapprove functionality</p>

<p><span>The QA mode is another useful tool for manual instance inspection. When enabled, the annotations are visually isolated from the background. This allows the user to distinguish between instances and the underlying objects, making the instance inspection easier.</span></p>
<p><span>All listed features extensively accelerate the manual QA process. However, machine learning techniques that automatically detect annotation noise can provide an additional level of automation.</span></p>

<h2><span>QA Automation</span></h2>
<p><strong><span>3.1 ML for QA Automation</span></strong></p>
<p><span>QA of annotated data takes around 40 percent of the annotation time.</span></p>
<p><span>On average, only a small fraction of annotated data contains noise. Still, QA is applied to the entire dataset, and monitoring clean data costs the annotators extra time and resources. An automation method could substantially cut down the QA process of clean data by isolating a set of risky annotations. So, our goal is to determine ML techniques that identify noisy annotations in data with high precision and recall.</span></p>
<p><strong><span>3.2 Current research</span></strong></p>
<p><span>Learning on datasets that contain annotation noise has been an active research area in ML. Several methods use predictions from DNNs to detect label noise and modify training loss (Reed et al., 2015; Tanaka et al., 2018). These methods do not perform well under high noise ratio as the domination of noisy annotations in data causes overfitting of DNNs. Another approach is to treat small loss samples as clean annotations and allow only clean samples to contribute to the training loss (Jiang et al., 2017). Ultimately, this research area‚Äôs core challenge is to design a reliable criterion capable of identifying the annotation noise.</span></p>
<p><span>A significant amount of research in this area is focused on classification with noisy labels. The proposed methods range from detecting and correcting noisy samples to using noise-robust loss functions. Unsupervised and semi-supervised learning techniques are also relevant to this task since those require few or no labels. Mislabeled samples that are detected without label correction can be used as unlabeled data in a semi-supervised setting (Li et al. 2020).&nbsp;</span></p>
<p><span>Going beyond classification makes things far more challenging. In classification, the existence of an object per image is guaranteed. So, the noisiness criterion can be defined between predicted and annotated image labels. However, in more complex tasks such as object detection, the correspondence between predicted and annotated instances is less trivial. Even though research in this area is in its initial state, several methods suggest valid measures to indicate both localization and label noise in object detection (Pleiss et al 2020, Chadwick et al. 2019).</span></p>
<p><strong><span>3.3&nbsp; Proposed method</span></strong></p>
<p>Consider the task of object detection on a dataset that contains mislabeled annotations. Several techniques use DNN predictions to identify label noise in data. Based on this concept, we propose the following algorithm.</p>
<ul>
<li>For each bounding box annotation, we obtain the matching prediction that has the maximum IOU.&nbsp;</li>
<li><span>Compute <strong>L2 distance</strong> between one hot vector of an annotated class and Fast RCNN softmax logits of the matched prediction. </span>This distance serves as a mislabel metric for annotations. We treat this number as the probability of annotation being mislabeled. As we aim to achieve maximal recall and precision in mislabel detection, we select an optimal threshold to attain the desired objective. This defines the split of data between clean and mislabeled annotations by the given criterion.</li>
</ul>

<p><img src="https://lh6.googleusercontent.com/JJtyM51584r8uJCIbHuW0UKhdgxQIIMm4G23vuD8lxnn5yrYHONPRytIxl-9QjFodM51zy7d8pvswhiMYokXY8XOz-DxqTd4ua-_DHGemiuXULNKqCbq_ePQfzulkbsrNu_jyX0D" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: L2 distance on gt one hot and prediction logits</em></p>

<p>Along with mislabeled detections, we also suggest considering the most confident predictions as missing annotations.&nbsp;</p>
<p><strong><span>3.4 Experiments and results</span></strong></p>
<p>To evaluate the performance of our method, we used PASCAL VOC as a toy dataset. When we manually injected asymmetric label noise in 20 percent of bbox annotations, the described mislabel criterion resulted in the precision-recall curve shown below.</p>
<p><img src="https://lh5.googleusercontent.com/OhgoPNrwmPWqR21Y1jnMY-1rbgKV8cxdFd8F0lZsVCZTcrN9C77EBX-0yqvZfVbYOVAFH_pxHNh88T7r26Gbp6hxWWdF5XqyLkN8SS5G46q512ZOHILlP1wmeR20aCo2QDWsOMms" width="400" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: PR curve with optimal mismatch threshold selected</em></p>

<p>Here, recall determines the portion of annotation noise captured, and precision identifies the fraction of data validated as clean.</p>
<p><span>Based on the PR curve above, using optimal mislabel threshold results in over 93 percent recall. This proves the reliability of our method, as we capture the dominant fraction of annotation noise. Along with high recall, we obtained over 75 percent precision, which attributes to validating ¬æ of annotations as clean. This cuts manual inspection time over the whole dataset by a margin of 4, resulting in extensive automation for the manual QA.&nbsp;</span></p>
<p>Note that detected risky annotations contain clean samples apart from correctly detected mislabeled instances. Those are the images that were hard to capture by the detection model and thus are misclassified as risky. Distinguishing between these two categories is a challenging problem for further research.&nbsp;</p>
<p>You can find the source code for the discussed experiments at our <a href="https://github.com/superannotateai/qa-automation"><span>GitHub repository</span></a>.</p>
<p>Also, consider our <a href="https://colab.research.google.com/drive/1Xbt3dxkmX4ozQhdY_vnHXAH67OUeg0Nj#scrollTo=7unkuuiqLdqd&amp;uniqifier=2"><span>Colab tutorial</span></a> as a step-by-step guide to reproduce the given results.&nbsp;</p>
<p><strong><span>3.5 Automate Approve/Disapprove functionality&nbsp;</span></strong></p>
<p>Once mislabeled annotations are captured by ML techniques, SuperAnnotate allows users to import the detected information to the platform through the <strong>error </strong>key of SA formatted annotations. Just set the <strong>error</strong> key in mislabeled annotations and import SA formatted JSONs to SuperAnnotate via Python SDK.&nbsp;</p>

<p><img src="https://lh3.googleusercontent.com/to5CwRUFKERkSeyPgA1Nzl84I0ijhR8bQCpsUHhIxi_zhsm7FnNGOxSJ-i0V8HXnJSzN4VOxDnVgj_JWo2QCwQF6ECSjO4CrLShBB9V3YPHp8SWxO9D2CEwC6UbfqClElWgxIOf3" width="654" height="183" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: JSON Code Block</em></p>

<p><img src="https://lh3.googleusercontent.com/0SJ8E5OnOSxB50Fh_4d4_qjJNT0lygY1yHzFGuFlZ9fMDjIGyUGQDqxGsDDG9j2dMcfmf6PLOHvj3JRJ4F3UtaQup-muynR2TFd18W6vbjI1ANF8Ll99dK_b8v1GIzkBUbpwVaPn" width="654" height="121" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: SDK Code Block</em></p>

<p><span>Discussed pipeline provides complete automation of Approve/Disapprove functional.</span></p>

<p><img src="https://lh5.googleusercontent.com/w9VXvs6INaP4WaEADW2pW6fEVj6s8sj5FZd44gN-10LcKplspRX3N7tt-aRuV1BUmNFzANwQTjKgq9rt-EbND0_SpY2z5Ikcpc3xo6wZHQMm2-TB3iY6ao5LboT86FK8qaw8ZwPu" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: Before v.s After autoqa in SA platform&nbsp;</em></p>

<h3><span>Conclusion</span></h3>
<p><span>QA automation is of crucial importance as it constitutes a significant portion of annotation time. This article shows that using proper algorithms and associated tools can help us detect mislabeled annotations with high precision while spending 4x less time on QA.</span></p></span>
</p>


</div></div>]]>
            </description>
            <link>https://blog.superannotate.com/how-to-detect-mislabeled-annotations</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651571</guid>
            <pubDate>Thu, 01 Oct 2020 14:57:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CodeShip Status ‚Äì Critical Security Notification]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651240">thread link</a>) | @jwilk
<br/>
October 1, 2020 | https://www.codeshipstatus.com/incidents/91bvlfw9xlm9 | <a href="https://web.archive.org/web/*/https://www.codeshipstatus.com/incidents/91bvlfw9xlm9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
              Dear CodeShip users,</p><p>We are reaching out to inform you of additional information we have uncovered as a result of our continuing investigation of the recent GitHub breach. To provide maximum transparency, we are reporting on the results of our investigation, the impact on users, actions you must take to protect yourself/your organization, and actions we will take to strengthen our security processes going forward.</p><p>On Wednesday, September 16, 2020, CloudBees was notified by GitHub of suspicious activities targeting CodeShip business accounts connected to GitHub via the CodeShip GitHub app and now deprecated CodeShip OAuth tokens. CloudBees immediately initiated an investigation conducted by our security and engineering teams, and on September 27, we identified additional evidence of malicious activity against a failover CodeShip database. On September 29, we uncovered evidence to indicate that a malicious actor had access to this failover instance during the period of June 2019 to June 2020. At this time and to the best of our knowledge, we have no evidence of malicious activity or attempts within CodeShip systems since June 2020. </p><p>*What type of data was affected?*</p><p>The impacted accounts are those of CodeShip users. No other products or accounts were affected and CodeShip is in no way integrated with other CloudBees products or systems.</p><p>*For all CodeShip users:*</p><p>CodeShip users hashed account passwords, one-time password (OTP) recovery codes, and the OTP secret keys used to seed two-factor authentication all may have been exposed.</p><p>Business contact information for invoicing purposes such as company contact name, company name, VAT number, postal address, phone number also may have been exposed. No payment information, such as bank account numbers or credit card numbers, was exposed. No other CloudBees product other than CodeShip was impacted. Also, the logging system was not accessed for any customers.</p><p>*For CodeShip Basic users:*</p><p>Any information contained in CodeShip users‚Äô pipelines may have been exposed. This includes scripts, environment variables, access tokens and other similar data.</p><p>*For CodeShip Pro users:*</p><p>AES encryption keys may have been exposed.</p><p>*Steps you should take*</p><p>Although at this time we have no evidence that the data potentially exfiltrated has been used, all CodeShip users may have been affected (including free, Basic and Pro accounts) and should take the following steps:</p><p>- Immediately rotate any keys or other secrets for cloud providers, third-party tools, or anything else that you used in your CodeShip pipelines.</p><p>- If using CodeShip Pro, rotate your AES key and re-encrypt your secrets.</p><p>- Immediately identify any other sensitive information that is stored in your pipelines and replace them within your pipelines and on any external systems.</p><p>- Determine whether any of your systems accessible from CodeShip have experienced unauthorized access, by contacting your provider or carefully review your access records.</p><p>- Verify that the source code held in repositories that are linked to your CodeShip account have retained their full integrity.</p><p>- Reset your CodeShip 2FA: <a target="_blank" href="https://documentation.codeship.com/general/about/2fa/">https://documentation.codeship.com/general/about/2fa/</a></p><p>At this time and to the best of our knowledge, we have no evidence of malicious activity or attempts within CodeShip systems since June 2020. We are continuing to monitor the situation.</p><p>*Steps we are taking*</p><p>As soon as we were notified by GitHub on September 16, we proceeded to rotate all our applications' internal secrets and rebuilt all our AWS AMIs. We are continuing to scrutinize our AWS security logs to monitor for suspicious activity, such as outbound connections to known malicious IPs. To date, we have not found any such activity.</p><p>We want you to be assured that we are taking steps to increase the security strength of the CodeShip product, including but not limited to:</p><p>- Validation that our product threat modeling and large-scope security reviews are systematically implemented.</p><p>- Validation that the application of production security standards to all operational processes and artifacts is systematically implemented.</p><p>- Enhancement of strict restrictions on access to production data and strict segregation of sensitive data.</p><p>- Improvement of existing SIRT processes to ensure faster and better forensic investigation.</p><p>*Who to contact *</p><p> We will update here with any new developments. </p><p>If you still have questions, please contact <a target="_blank" href="mailto:security@codeship.com">security@codeship.com</a>.</p><p>Last but not least, I‚Äôd like to apologize for the impact this is having on you. In the decade that CloudBees has been operating SaaS applications, we have always taken full responsibility for our products and we do so today. Please be assured that we will do everything we can to prevent this from happening again. </p><p>- Sacha Labourey, CEO, CloudBees
            </p></div></div>]]>
            </description>
            <link>https://www.codeshipstatus.com/incidents/91bvlfw9xlm9</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651240</guid>
            <pubDate>Thu, 01 Oct 2020 14:32:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Memgraph DB 1.1 Up to 50% Better Memory Usage and Higher Throughput]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24651091">thread link</a>) | @karimtr
<br/>
October 1, 2020 | https://memgraph.com/blog/memgraph-1-1-benchmarks | <a href="https://web.archive.org/web/*/https://memgraph.com/blog/memgraph-1-1-benchmarks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Introduction</h2>
<p>At Memgraph, we put great effort into delivering a high-performance in-memory graph storage and analytics engine. We do this by investing a lot of time optimizing and continuously improving various aspects of the Memgraph core engine. In this blog post, we will explore some of the improvements we have made on the storage layer and their impact on performance and memory usage.</p>
<p>The two most significant improvements we introduced in recent years are a new storage engine and a new way of storing properties on both nodes and edges.  Prior to version v0.50.0 Memgraph had an <a href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control">MVCC</a> storage where copies of nodes and edges were used to version the data. <strong>Memgraph v0.50.0</strong> introduced a new way of managing graph data where each node or edge consists of the latest version of data, and associated changes of data required to reconstruct previous versions.</p>
<p><img src="https://i.imgur.com/bQbvvp6.png" alt=""></p>
<p><strong>Memgraph v1.1.0</strong> introduced a new way of storing properties. Each node or edge has a property store that takes at least 16B of memory. Memgraph tries to hold properties data in 16B on the stack, if possible. If the properties data exceeds 16B, the first 8B of the stack buffer indicates the total number of bytes required for the storage of properties, and the second 8B a pointer to the array on the heap that stores properties. This technique is called small buffer optimization.</p>
<p><img src="https://i.imgur.com/LWP2te8.png" alt=""></p>
<p>Additionally, there were various other smaller improvements of existing internal data structures, most notably the <a href="https://en.wikipedia.org/wiki/Skip_list">skip list</a> which is used as an indexing data structure. The combined result was a massive improvement in memory usage with a substantial reduction in memory fragmentation while ensuring equivalent or better performance. Before jumping into the analysis and explanations, let‚Äôs have a look at the benchmark setup.</p>
<h2>Setup</h2>
<h3>Target Systems</h3>
<p>The benchmark tests different Memgraph versions. The release dates and details of each version are the following:</p>
<ul>
<li><strong>v0.15.2</strong>, October 23, 2019, the last version of Memgraph that used an in-memory storage engine based on copies of nodes/edges.</li>
<li><strong>v0.50.0</strong>, December 11, 2019, introduced the new in-memory storage engine based on data changes and a C-based storage API.</li>
<li><strong>v1.0.0</strong>, April 6, 2020, introduced a Python-based storage API.</li>
<li><strong>v1.1.0</strong>, July 1, 2020, added encoding and compression to node and edge properties.</li>
</ul>
<p>The <a href="https://docs.memgraph.com/memgraph/changelog">Memgraph Changelog Docs</a> page contains more details about changes in each version.</p>
<h3>Hardware</h3>
<ul>
<li>Server: HP DL360 G6</li>
<li>CPU: 2x Intel Xeon X5650 6C12T @ 2.67GHz</li>
<li>RAM: 144GB</li>
<li>Disk: 120GB SSD</li>
<li>OS: Debian 9 Stretch</li>
</ul>
<h3>Workload</h3>
<p>The benchmark consists of several different queries that test the performance of the graph database. Typical graph database workloads consist of READ, CREATE, and ANALYZE queries.</p>
<p>Memgraph is particularly well suited for hybrid transactional-analytical workloads where it‚Äôs crucial to ingest data as fast as possible and simultaneously deliver analytics as quickly as possible. For this reason, we are mostly interested in traversal queries (1-Hop, 2-Hop, etc.) which represent the majority of analytical queries.</p>
<p>In the following table, you can find the exact queries we have used for benchmarking.</p>
<pre><code>|            Query Name             |                                                Query                                                        |  Query Type |
| --------------------------------- | ----------------------------------------------------------------------------------------------------------- | ----------- |
| Aggregation                       | `MATCH (n:User) RETURN n.age, COUNT(*);`                                                                    | ANALYZE     |
| 1-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;(n:User) RETURN n.id;`                                                          | ANALYZE     |
| 2-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;()--&gt;(n:User) RETURN DISTINCT n.id;`                                            | ANALYZE     |
| 3-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;()--&gt;()--&gt;(n:User) RETURN DISTINCT n.id;`                                       | ANALYZE     |
| 4-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;()--&gt;()--&gt;()--&gt;(n:User) RETURN DISTINCT n.id;`                                  | ANALYZE     |
| 2-Hop Variable Expand             | `MATCH (s:User {id: $id})-[*1..2]-&gt;(n:User) RETURN DISTINCT n.id;`                                          | ANALYZE     |
| 2-Hop Variable Expand with Result | `MATCH (s:User {id: $id})-[*1..2]-&gt;(n:User) RETURN DISTINCT n.id, n;`                                       | ANALYZE     |
| Shortest Path                     | `MATCH p=(n:User {id: $from})-[*bfs..15]-&gt;(m:User {id: $to}) RETURN extract(n in nodes(p) | n.id) AS path;` | ANALYZE     |
| Insert New Relationship           | `MATCH (n:User {id: $from}), (m:User {id: $to}) WITH n, m CREATE (n)-[e:Temp]-&gt;(m) RETURN e;`               | CREATE      |
| Find Node                         | `MATCH (n:User {id : $id}) RETURN n;`                                                                       | READ        |
| Insert a New Node                 | `CREATE (n:UserTemp {id : $id}) RETURN n;`                                                                  | CREATE      |
</code></pre>
<p>The benchmarking harness executed all queries against the <a href="https://snap.stanford.edu/data/soc-Pokec.html">Pokec dataset</a> which contains 1.6M nodes and 30.6M edges. Given that the goal of each benchmark is to saturate the target system to extract its peak characteristics, we took great care in carefully designing and polishing our setup. Some of the essential elements of the harness are:</p>
<ul>
<li>optimized C/C++ client to minimize client overhead.</li>
<li>fresh dataset load before each execution.</li>
<li>concurrent execution (up to 12 cores) to push Memgraph to its limits.</li>
</ul>
<h2>Data Import Analysis</h2>
<p>Before delving deep into the workload queries execution analysis, a couple of notes about the data import.</p>
<p>The harness imported data in a real-time manner, equivalent to normal query execution by running queries. The data was imported using 8 concurrent clients.  Throughput and peak memory usage were measured during the data import. A couple of interesting insights emerged. On the memory usage side, there is already a massive difference between Memgraph versions. <strong>Before v0.50.0</strong>, Memgraph stored all data modifications as whole copies of the modified objects. By removing the need to make whole copies of database objects, versions <strong>after v0.50.0</strong> provide a significantly less memory usage. The same benefits apply to the runtime environment since the import uses regular queries.</p>
<p><img src="https://i.imgur.com/VfDzuCw.png" alt=""></p>
<p>At this point, you might be wondering about the import speed. As the chart below shows, throughput on basic CREATE queries also improved. Since data copying is generally a fast operation, throughput improvement is not huge but is still significant. One important thing to notice is the difference between v1.0.0 and v1.1.0. <strong>v1.1.0</strong> has almost the same throughput as versions before even though more work is involved in property compression.</p>
<p><img src="https://i.imgur.com/hsh6uDj.png" alt=""></p>
<h2>Query Execution Analysis</h2>
<p>Let‚Äôs start analyzing the <strong>workload queries</strong>. The following radar chart shows peak memory usage during query execution across different Memgraph versions. Keep in mind that less is better.</p>
<p>As you can see, <strong>v1.1.0 uses ~50%</strong> less memory compared to v0.15.2. v0.50.0 and v1.0.0 fall in-between with almost no difference because not much from the storage perspective changed between these two versions. The most significant difference is between v0.15.2 and v0.50.0 (introduction of the new storage engine), and v1.0.0 and v1.1.0 (introduction of encoded and compressed properties).</p>
<p><img src="https://i.imgur.com/4ETpDXT.png" alt=""></p>
<p>On the other hand, while looking at memory, it‚Äôs also critical to observe what is happening with the throughput. Generally, there is a well-known trade-off between space and time. But, as you can see in the following chart, v1.1.0 has the best performance. Please note that in this case, more is better.</p>
<p><img src="https://i.imgur.com/c0nBqJS.png" alt=""></p>
<p>Of course, not all queries yield significant throughput improvements. E.g., the <code>Insert New Node</code> query performance stayed similar across different Memgraph versions. Nonetheless, the following chart illustrates well how Memgraph scales with the number of concurrent requests.</p>
<p><img src="https://i.imgur.com/vIy7rTM.png" alt=""></p>
<p>The new storage engine also introduced a feature where it is possible to disable storing properties on edges. Sometimes graph datasets don‚Äôt have any data attached to edges. Memgraph offers a configuration option to remove all associated data structures required to store data on edges. As you can see in the following chart, by not having properties on edges, memory usage goes down by almost 50% (in addition to the reductions mentioned above). v0.15.2 can‚Äôt disable the property storage on edges, so the chart shows nothing there. Using all the improvements in new versions of Memgraph you can store the same dataset in 3.36x less memory (comparing v0.15.2 with properties enabled and v1.1.0 with properties disabled).</p>
<p><img src="https://i.imgur.com/PtQviBf.png" alt=""></p>
<p>The rest of the charts show performance for each query with regards to linear scalability. Linear scalability is the ability of a system to handle more work by adding more resources linearly. E.g., by doubling the number of cores, the system is capable of executing twice as many queries. In practice, it‚Äôs impossible to reach perfect linear scalability due to various overheads.  The real question is how far Memgraph is from linear scalability? As you can see below, not by a lot.</p>
<p>The following chart shows throughput data for the simple read query (Find Node). The node lookup inside Memgraph has an O(logN) complexity.</p>
<p><img src="https://i.imgur.com/0z46Rg5.png" alt=""></p>
<p>In the next case, instead of reading, Memgraph creates an edge. The operation contains two node lookups and one edge write. Which means it‚Äôs very similar to the Find Node query. Instead of one lookup, the action has two lookups and one write. The chart looks very similar to the Find Node chart.</p>
<p><img src="https://i.imgur.com/ZWzeFc6.png" alt=""></p>
<p>By moving towards more complex queries, there is a more significant scalability difference between previous versions of Memgraph and the latest ones. v0.15.2 is far behind the latest versions.</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://memgraph.com/blog/memgraph-1-1-benchmarks">https://memgraph.com/blog/memgraph-1-1-benchmarks</a></em></p>]]>
            </description>
            <link>https://memgraph.com/blog/memgraph-1-1-benchmarks</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651091</guid>
            <pubDate>Thu, 01 Oct 2020 14:19:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ElasticSearch Query Builder]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650651">thread link</a>) | @piranha
<br/>
October 1, 2020 | https://solovyov.net/blog/2020/elasticsearch-query-builder/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/elasticsearch-query-builder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p>This post strives to be useful to anyone who uses ElasticSearch, but all examples are going to be in Clojure since it‚Äôs what we use.</p>
<p>ElasticSearch is a wildly useful database (if I may say so), but at times it feels like its query language evolved rather than was planned. This manifests in it being rather ad-hoc and non-orthogonal. Plus using JSON with its low expressiveness adds quite a bit of verbosity. All of this leads to code which builds ES queries being messy and unpleasant to use.</p>
<h2 id="jump-in">Jump in</h2>
<p>Certainly, this was our case a few years ago. Our code was a bunch of functions calling one another, which sounds like functional programming and should be fine, right? Well, as always, the devil is in the detail, and:</p>
<ul>
<li><code>if</code>/<code>case</code>/<code>cond</code> everywhere, various cases were piling on top of each other</li>
<li><a href="https://solovyov.net/blog/2020/higher-order-functions/">functions parametrized with functions</a> ‚Äî it‚Äôs a good tool if you make some higher-order well-documented/understood function, but your business logic should be free of this stuff in general; makes logic hard to be understood</li>
<li>code factorization was quite a bit off: function boundaries felt a bit random</li>
<li>it was written at the start of the current codebase, grew with it and just happened, was never planned</li>
</ul>
<p>Our use case, by the way, is a product filtering API (facets and all that stuff) for an ecommerce site, <a href="https://kasta.ua/">Kasta</a>. Apply some filters and retrieve some aggregations, which is enough of a problem to need a proper solution.</p>
<h2 id="what-is-out-there">What is out there</h2>
<p>So where to go? I looked around and saw stuff like <a href="https://elasticsearch-dsl.readthedocs.io/en/latest/">elasticsearch-dsl</a>, which was just like ES data structures, but methods on mutable objects. Ugh. Also, <a href="https://elastic-builder.js.org/docs/">ElasticBuilder</a>, which is similar, but with different names, so you have to remember two layers of abstraction. Thanks, but no.</p>
<p>And there are a lot of articles on how to make a query to get what you need from ES, but nobody wrote an article on how to make an ES query builder! Well, except for me. :-)</p>
<h2 id="solution">Solution</h2>
<p>What I like in terms of API is <a href="https://github.com/seancorfield/honeysql">HoneySQL</a>, which is a compiler from maps/vectors to SQL queries. This got me thinking and it turns out that a good question is half of the answer.</p>
<p>What we need is a compiler from our API interface ‚Äî GET request query string ‚Äî to an ES query.</p>
<p>Rephrased like this it makes the task almost a walk in the park. A long-long walk, but much less ‚Äúhere be dragons‚Äù if-peppered abomination of the past. And the design cornerstones are:</p>
<ul>
<li>branchless pipeline</li>
<li><a href="https://clojuredocs.org/clojure.core/defmulti">multimethods</a></li>
<li>small dictionary of verbs on top of ES incantations</li>
</ul>
<h3 id="data-format">Data format</h3>
<p>Some time ago I stumbled upon a great article about working with ES, and one of its parts <a href="https://project-a.github.io/on-site-search-design-patterns-for-e-commerce/#generic-faceted-search">describes a data model</a> they have used. It proposes that instead of a map like <code>{:brand "wow" :color "red"}</code> you use a following structure:</p>
<pre><code>{:facets [{:name "brand"
           :value "wow"}
          {:name "color"
           :value "red"}]}
</code></pre>
<p>This allows you to query all those facets with a single definition, rather than sending a separate aggregation for every field. More than that, you don‚Äôt need to know which facets are available for filtering upfront, since you‚Äôll receive all of them from ES.</p>
<p>In practice, two lists of facets are needed - regular ones and ranged facets. Regular facets are aggregated by <code>terms</code> aggregation, and ranged are aggregated by a combo of <code>ranges</code> and <code>percentiles</code>.</p>
<h3 id="verbs">Verbs</h3>
<p>So we have several functions like <code>not</code>, <code>and</code>, <code>or</code>, <code>term=</code>. They signal intent rather than what ES is doing inside and make reading aggregations and filters much easier. Or should I say <code>should</code> easier? Or <code>must</code> easier? :-) You can understand what‚Äôs it doing without opening ES docs. Some examples:</p>
<pre><code>(defn or* [&amp; clauses]
  (let [clauses (filterv identity clauses)]
    (cond
      (empty? clauses)
      {:bool {}}

      (= 1 (count clauses))
      (first clauses)

      :else
      {:bool {:should               clauses
              :minimum_should_match 1}})))


(defn facet= [k v]
  {:nested {:path  "facets"
            :query (and* (term= "facets.id" k)
                         (term= "facets.value" v))}})
</code></pre>
<p>What they accomplish is that most of our lower-level use cases are covered with ‚Äúloaded‚Äù terminology rather than ‚Äúneutral‚Äù (and often cryptic) ES maps.</p>
<h3 id="pipeline">Pipeline</h3>
<p>The pipeline is 4 steps:</p>
<ul>
<li><code>qs-&gt;query</code> parses query string, cookies, headers into a basic query data structure</li>
<li><code>make-aggs-q</code> loops through supplied filters and known aggregations, and builds an ES query</li>
<li>then a query is executed</li>
<li><code>aggs-&gt;response</code> converts ES response to what our API returns</li>
</ul>
<p>We represent a user query internally with a map like that:</p>
<pre><code>{:base    {"menu" "pants"}
 :filters {"1" #{"123" "456"}}
 :sort    :default
 :cursor  "ZXCVB"
 :limit   100}
</code></pre>
<p>This is easier to interact with than with just a raw query string.</p>
<h3 id="make-aggs-q">make-aggs-q</h3>
<p>This part is the most convoluted one. It builds the essence of an ES query for aggregations, and consists of:</p>
<ul>
<li>loop over known non-facet aggregations</li>
<li>loop over every facet which was used as a filter in a query</li>
<li>query for regular facets</li>
<li>query for ranged facets</li>
</ul>
<p>What is a facet aggregation is described in <a href="#data-format">data format</a> section. All other aggregations are non-facet and should be explicitly mentioned. Those are filters such as price, depot (whenever they are on stock in our warehouse rather than supplier‚Äôs one), supplier, etc. When I look there it feels like most of them need to be in facets. Historical reasons. :)</p>
<p>Every loop then delegates to <code>make-agg</code> multimethod, which builds its piece of the query. Here is an example of a filter for colors - it‚Äôs one of the simplest aggregations, just generates a list of colors available for selected products.</p>
<pre><code>(def NESTED-AGG :_nest)

(defn agg-filter [agg filter-data]
  {:filter filter-data
   :aggs   {NESTED-AGG agg}})

(defmethod make-agg :color [filter-name _ filters options]
  [filter-name
   (-&gt; {:terms {:field "color_group"
                :size  (:max-buckets options)}}
       (agg-filter (filters/make filters)))])

</code></pre>
<p><code>filters</code> are filters for the given query except for the one for the given aggregation, so that you‚Äôll receive all possible values for the current aggregation in a given context. So we apply them with an <code>agg-filter</code> function.</p>
<p><code>-&gt;</code> could be confusing, but look at it as a pipeline operator: every function you give it is executed in order.</p>
<p>ElasticSearch aggregation rules are nested, read on to discover why we need <code>NESTED-AGG</code>.</p>
<h3 id="aggs-response">aggs-&gt;response</h3>
<p>This stage loops over response and converts data from ES into API response format. Fortunately most parts of the response are independent, so it‚Äôs pretty clean and simple: it‚Äôs a loop, which calls <code>extract-agg</code> on every aggregation:</p>
<pre><code>(defn agg-recur [{:keys [doc_count] :as agg}]
  (loop [agg agg]
    (if-let [nested (get agg NESTED-AGG)]
      (recur nested)
      (if-not (:doc_count agg)
        (assoc agg :doc_count doc_count)
        agg))))

(defn aggs-&gt;response [query es-response]
  (for [[k agg] (:aggregations es-response)
     (extract-agg k (agg-recur agg) query))
</code></pre>
<p><code>agg-recur</code> is a way to get to the real data: ES aggregations are very nested. To get through we use key <code>:_nest</code> (value of <code>NESTED-AGG</code>), and then use this <code>agg-recur</code> function.</p>
<p>Unfortunately, there is no good way to pass additional information from <code>make-agg</code> to <code>extract-agg</code>, so it‚Äôs stringly-typed, as is <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.x/returning-aggregation-type.html">recommended by ES</a>. Look at our <code>extract-agg</code> multimethod (<code>defmulti</code> defines dispatcher, this is a function which determines which method to call):</p>
<pre><code>(defmulti extract-agg
  (fn [filter-name data query]
    (condp #(str/starts-with? %2 %1) filter-name
      "facet_"      :facet
      "percentile_" :percentile
      "range_"      :range
      :else         filter-name)))
</code></pre>
<p><code>extract-agg</code> methods extract data, sort if necessary (so brands are alphabet-sorted rather than count of matches-sorted), fix up document count (in case of nested aggregations). Here‚Äôs an example processing <code>:depot</code>:</p>
<pre><code>(defmethod extract-agg :depot [filter-name agg query]
  (let [cnt (-&gt; agg :real_count :doc_count)]
    [{:id        filter-name
      :widget    :toggle
      :values    [{:key       "true"
                   :doc_count cnt}]
      :doc_count cnt}]))
</code></pre>
<p>That part is pretty simple since you just have to massage data into whatever you need for the API. :)</p>
<h2 id="divide-and-conquer">Divide and conquer</h2>
<p>There is nothing new under the sun. If only the right idea would appear right at the start. :-) Just factor your functions correctly and you‚Äôre golden.</p>
<p>In the end what we‚Äôve got is a straightforward pipeline, no parametrization with functions, every chunk of a query is as simple as it gets, and extensibility is just great! It‚Äôs been in production for 1.5 years now with no significant changes to the logic, received some new features, and doesn‚Äôt feel like it was holding us back.</p>
<p>I hope this post can serve as an inspiration for your code. If you feel confused or have questions, please contact me by email ‚Äî I would love to make this post more approachable.</p>
</div></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/elasticsearch-query-builder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650651</guid>
            <pubDate>Thu, 01 Oct 2020 13:38:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ontario police used Covid-19 database illegally, civil rights groups find]]>
            </title>
            <description>
<![CDATA[
Score 248 | Comments 70 (<a href="https://news.ycombinator.com/item?id=24650515">thread link</a>) | @seigando
<br/>
October 1, 2020 | https://www.cbc.ca/news/canada/toronto/covid-police-database-1.5745481 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/toronto/covid-police-database-1.5745481">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Police forces across&nbsp;Ontario&nbsp;engaged in broad, illegal searches&nbsp;of a now-defunct COVID-19 database, two civil rights groups alleged Wednesday, claiming the use of the portal violated individual privacy rights for months.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5704129.1598642644!/cumulusImage/httpImage/image.jpg_gen/derivatives/16x9_780/shutterstock-medium-file-typing-on-laptop.jpg"></p></div><figcaption>The Canadian Civil Liberties Association and the Canadian&nbsp;Constitution Foundation say in separate reports that many services used the database to look at COVID-19 test results for wide geographic areas and sometimes pulled up personal information unrelated to active calls.<!-- --> <!-- -->(maradon 333 / Shutterstock)</figcaption></figure><p><span><p>Police forces across&nbsp;Ontario&nbsp;engaged in broad, illegal searches&nbsp;of a now-defunct COVID-19 database, two civil rights groups alleged Wednesday, claiming the use of the portal violated individual privacy rights for months.</p>  <p>The Canadian Civil Liberties Association (CCLA) and the Canadian&nbsp;Constitution Foundation (CCF) said in separate reports that many services used the database to look at COVID-19 test results for wide geographic areas and sometimes pulled up personal information unrelated to active calls.</p>  <p>"People weren't told that when they went for COVID tests that&nbsp;this information was being shared with police and they certainly weren't asked for their consent," said Abby Deshman, the criminal&nbsp;justice program director for the CCLA.&nbsp;</p>  <p>"That should be a decision every person makes about what they&nbsp;want to do with their own personal medical information."</p>  <p>In early April, the&nbsp;Ontario&nbsp;government passed an emergency order&nbsp;that allowed police to obtain the names, addresses and dates of birth of Ontarians who had tested positive for COVID-19. The portal was aimed at helping to protect first responders.</p>  <p>Police access to that database ended on Aug. 17, after a legal&nbsp;challenge was filed by a group of human rights&nbsp; organizations.</p>  <p>The group, which included the CCLA, argued that allowing police&nbsp;to access personal health records violated individuals'<br> constitutional rights to privacy and equality.</p>  <h2>Police conducted 95,000 searches of database</h2>  <p>Data released in the context of the legal action showed that&nbsp; Ontario&nbsp;police services conducted over 95,000 searches of the&nbsp;database while it was active.</p>  <p>The CCF filed a freedom of information act request to the&nbsp;province related to police use of the database.&nbsp;</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>Police were caught using the COVID-19 database to look up names&nbsp;unrelated to active calls, to do wholesale postal&nbsp; code searches for COVID-19 cases, and to even do broad based searches outside officers' own cities.<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Christine Van Geyn, Canadian Constitution Foundation</cite></span></blockquote>    <p>On Wednesday, the CCF made public a June memo from the Solicitor&nbsp;General's office to chiefs of police that warned against using the&nbsp;database beyond the "express purpose" of the emergency order.</p>  <p>The CCF said the memo revealed a "shocking misuse" of personal&nbsp;health information by police.</p>  <p>"Police were caught using the COVID-19 database to look up names&nbsp;unrelated to active calls, to do wholesale postal&nbsp; code searches for COVID-19 cases, and to even do broad based searches outside officers' own cities," said CCF litigation director, Christine Van&nbsp;Geyn.&nbsp;<span><ul><li><a href="https://www.cbc.ca/news/canada/toronto/covid-ont-police-database-1.5690220" data-contentid="" flag="" text="Ontario ends police access to COVID-19 database after legal challenge"><span>Ontario ends police access to COVID-19 database after legal challenge</span></a></li></ul></span></p>  <p>The CCF said it has filed a complaint with&nbsp;Ontario's privacy&nbsp;commissioner over violations of the Personal Health Information Protection Act, and with the&nbsp;Ontario&nbsp;Independent Police Review Director for officer misconduct.</p>  <p>Meanwhile, the CCLA sent letters to 37 police forces, asking them&nbsp;for details of how the database was used and if any information was retained from it.</p>  <p>Twenty-three responded and Deshman said she expects more to do&nbsp;so.</p>  <h2>Thunder Bay, Durham police conducted more than 40% of searches</h2>  <p>Many forces found the database difficult to use and resorted to&nbsp;problematic broad searches in an attempt to find workarounds, the CCLA said.</p>  <p>The association notes that more than 40 per cent of the 95,000&nbsp;searches of the database were conducted by either the Thunder Bay police or Durham Region police.&nbsp;</p>    <p>In Durham Region, police continued to run unauthorized searches&nbsp;even after provincial audits called attention to the inappropriate&nbsp;searches taking place, the CCLA said. The force's access to the portal was cut off by the province as a result, the CCLA said.</p>  <p>"Durham is a particularly concerning example," said Deshman.&nbsp;"In those cases there needs to be disclosure (to citizens whose information was accessed) and accountability by following up with the individuals in the police service that looked up information inappropriately."</p>  <h2>Anyone concerned can contact police, privacy commissioner&nbsp;</h2>  <p>Holly Walbourne, the legal counsel for Thunder Bay police, said&nbsp;in a letter sent to the groups that filed the legal challenge that&nbsp;the force understood their concerns but that police had "lawful authority" to use the database to protect first responders.</p>    <p>Durham police Supt. Peter Cousins wrote a report to the force's&nbsp;police services board on the issue on Sept. 1 saying&nbsp; access to theportal and its information was treated "seriously and with due care."&nbsp;</p>  <p>Toronto police never used the database because of "issues with&nbsp;the accuracy and reliability of the information," the CCLA reported. York Region police said they asked the province to revoke access to the database after an internal review found the risks associated with accessing personal health information outweighed any benefits.</p>  <p>Deshman said anyone concerned about police access to the province's COVID-19 database should contact their local police force&nbsp;and the&nbsp;Ontario&nbsp;Privacy Commissioner.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/toronto/covid-police-database-1.5745481</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650515</guid>
            <pubDate>Thu, 01 Oct 2020 13:23:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Not PHP?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650385">thread link</a>) | @muglug
<br/>
October 1, 2020 | https://mattbrown.dev/articles/why-not-php | <a href="https://web.archive.org/web/*/https://mattbrown.dev/articles/why-not-php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <article>
                                
                <p>
                    October 1, 2020 - 
                                            4&nbsp;minute&nbsp;read
                                    </p>
                                <!--
	title: Why not PHP?
	date: 2020-10-01
    author: Matt Brown
    author_link: https://twitter.com/mattbrowndev
-->
<p>I was intrigued by <a href="https://matklad.github.io/2020/09/20/why-not-rust.html">Why Not Rust</a>, a list of compelling disadvantages written by someone who uses Rust a lot, and the author of <a href="https://github.com/rust-analyzer/rust-analyzer">a popular Rust static analysis tool</a>. I have a similar relationship to PHP ‚Äì I use it every day (at <a href="https://vimeo.com/">Vimeo</a>), and I‚Äôm the author of <a href="https://psalm.dev/">a popular PHP static analysis tool</a>.</p>
<p>The similarities end there, though ‚Äì Rust and PHP are very different languages, with very different reputations in the wider programming community. Rust has been getting a lot of hype in the last few years, while PHP has been getting the opposite. Indeed, a lot has been written about PHP from a place of contempt. Here‚Äôs my attempt to argue against PHP, but from a place of admiration:</p>
<h2 id="its-mainly-for-serving-simple-http-requests">It‚Äôs mainly for serving simple HTTP&nbsp;requests</h2>
<p>PHP was originally designed for the then-nascent world wide web, and its popularity has risen (and, lately, fallen) with the popularity of server-rendered HTML.</p>
<p>Its process model (no shared memory between requests) makes it ideal for serving HTML on a case-by-case basis. If that‚Äôs what you‚Äôre after, it‚Äôs incredibly easy to get started.</p>
<p>On the one hand that means the average PHP programmer never has to worry about memory-related race conditions within a single request, because they simply can‚Äôt happen.</p>
<p>But all of PHP‚Äôs optimisations for serving individual HTML requests will get in the way if you do, in fact, want to run your own service with shared memory between requests, or any other long-running process. While PHP <em>can</em> do that, its implementation won‚Äôt be half as pretty as it would be in a language like Go.</p>
<h2 id="its-relatively-old">It‚Äôs (relatively)&nbsp;old</h2>
<p>New programming languages are often a thoughtful combination of languages that came before them. Writing code in a recently-written language can expose you to new idioms, and helps you see the world of programming through a different lens.</p>
<p>PHP is not a new language ‚Äì it‚Äôs 26 years old, and pretty thoroughly-cooked at this point.</p>
<h2 id="no-large-corporate-backers">No large corporate&nbsp;backers</h2>
<p>Some languages come directly from large profitable companies that devote considerable resources to their development (e.g. Go, TypeScript, C#, Swift, Java, Kotlin) while others are sort of adopted by companies (Python at Dropbox, OCaml at Jane St, JS interpreters at Google &amp; Mozilla).</p>
<p>PHP hasn‚Äôt had a large corporate backer for a while. As far as I know, only one PHP core engineer is <a href="https://blog.jetbrains.com/phpstorm/2019/01/nikita-popov-joins-phpstorm-team/">paid to work on the language full-time</a>.</p>
<p>Large corporate sponsors can be great for a language. Sponsorship sends a message to other companies that ‚Äúwe trust X to help run our billion-dollar business‚Äù and also ‚Äúif you use X you‚Äôll benefit from the work we‚Äôre putting into it‚Äù.</p>
<p>PHP‚Äôs community is pretty strong, though, and has produced some <a href="https://getcomposer.org/">great</a> <a href="https://phpunit.de/">pieces</a> of <a href="https://symfony.com/">software</a> that have moved the entire ecosystem forward.</p>
<h2 id="many-beginners-few-experts">Many beginners, few&nbsp;experts</h2>
<p>PHP is very easy to get into, and it‚Äôs easy to make things in PHP that other people find useful.</p>
<p>PHP‚Äôs community is also sort of like a high school, where other language communities (e.g. Rust) are like universities: the teachers in a high school can make you a productive member of society, but if you‚Äôre looking to surround yourself with professors who are specialists in things you find interesting, universities are a better bet.</p>
<p>This reputation problem isn‚Äôt unique to PHP ‚Äì other popular interpreted languages like Ruby have it too ‚Äì but it can deter people who want to feel smart when writing code.</p>
<p>JavaScript had this problem for years, but in the last decade several big internet companies have thrown tons of money at its language ecosystem, and JavaScript experts are now plentiful.</p>
<h2 id="it-has-many-minor-potholes">It has many minor&nbsp;potholes</h2>
<p>API inconsistency comes up repeatedly in peoples‚Äô criticism of PHP. While it‚Äôs something the vast majority of PHP developers get used to quickly, there‚Äôs no getting around the clunkiness of some core library functions: <code>strpos($haystack, $needle)</code> vs <code>in_array($needle, $haystack)</code> and <code>array_map($callback, $array)</code> vs <code>array_filter($array, $callback)</code>.</p>
<hr>
<h2 id="where-do-we-go-from-here">Where do we go from&nbsp;here?</h2>
<p>People have been predicting its demise for a couple of decades, but PHP‚Äôs still a pretty popular option. Why? Despite everything written above, there‚Äôs never been a better time to start a new PHP project.</p>
<p>PHP now has a huge ecosystem of open-source packages, and its main download hub has been accessed <a href="https://packagist.org/statistics">over a billion times last month</a> by developers around the world. That‚Äôs up roughly 50% from the year before, and doubly impressive once you factor in all the things PHP can do natively.</p>
<p>There‚Äôs also good reason to be optimistic about PHP‚Äôs future. Ten years ago, things were looking much more dire, but the community has invested a lot of time and effort into improving things:</p>
<ul>
<li>
<strong>Package management</strong><br>
<a href="https://getcomposer.org/">Composer</a>, introduced in 2012, has made setting up a new project a breeze</li>
<li>
<strong>Static analysis</strong><br>
A bunch of great competing static analysis tools (including my own, <a href="https://psalm.dev/">Psalm</a>) have been released in the last five years</li>
<li>
<strong>Raw performance</strong><br>
At Vimeo time spent in PHP itself has roughly halved since we upgraded from PHP 5 to PHP 7. Each new version squeezes out a little more speed, and PHP handily outperforms similar interpreted languages like Ruby, Python and Node</li>
<li>
<strong>Standard ways to write modern PHP</strong><br>
<a href="https://www.php-fig.org/psr/">PSR</a> emerged from a primordial soup of spaghetti code, and now pretty much all modern PHP looks very similar</li>
</ul>
<hr>
<p><a href="https://www.reddit.com/r/PHP/comments/j37zih/why_not_php/">Discuss on /r/php</a></p>
            </article>
        </div></div>]]>
            </description>
            <link>https://mattbrown.dev/articles/why-not-php</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650385</guid>
            <pubDate>Thu, 01 Oct 2020 13:07:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russian Opposition Leader Navalny on His Poisoning: ‚ÄúPutin Was Behind the Crime‚Äù]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650372">thread link</a>) | @rerx
<br/>
October 1, 2020 | https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;54d78056-207d-4c6f-b894-b46c2774c039&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;c8ac5a08-7653-40d6-92cc-0b44ad2564cc&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/54d78056-207d-4c6f-b894-b46c2774c039_w948_r1.77_fpx58_fpy45.jpg" srcset="https://cdn.prod.www.spiegel.de/images/54d78056-207d-4c6f-b894-b46c2774c039_w520_r1.77_fpx58_fpy45.jpg 520w, https://cdn.prod.www.spiegel.de/images/54d78056-207d-4c6f-b894-b46c2774c039_w948_r1.77_fpx58_fpy45.jpg 948w" width="948" height="536" sizes="948px">
</span>
</span>
</span>

</p>
<figcaption>
<span>
Foto:‚ÄÇ<p>Peter Rigaud / DER SPIEGEL</p>
</span>
</figcaption>
</figure>
</div><div>
<p>It's six o'clock in the morning on Wednesday when Alexei Navalny shows up at the Berlin editorial office of DER SPIEGEL for an interview. The office is located a few hundred meters from Charit√© University Hospital, where Navalny spent a month receiving treatment, hovering between life and death.</p>


<div>
<p>Navalny, who was poisoned with the nerve agent Novichok, was only released from the hospital last week.</p><p>Four agents from the State Office of Criminal Investigation (LKA) accompanied him during his visit. Navalny, who wasn't able to walk not long ago, took the stairs to the office rather than the elevator.</p><p>Alexei Navalny, 44, is Russia's most prominent opposition politician. Following the attempt on his life on August 20 in the Siberian city of Tomsk, however, he is now squarely in the international spotlight. German Chancellor Angela Merkel intervened for him to be allowed to leave Russia for treatment in Germany. Because he was poisoned with a substance that can essentially only come from state-run laboratories in Russia, the question of Russian President Vladimir Putin's personal responsibility is one that many around the world are asking. It's not the first time that a Russian opposition politician was to be killed, but it is the first time that the circumstances seem to so clearly point at the Kremlin.</p>
</div>

<div>
<p>The interview with DER SPIEGEL is the first that Navalny has given since the attack. He is alert at the meeting and he remembers many things - and yet the impact of the poisoning is still clear. Scars on his neck show where he was hooked up to a ventilator. When he pours water from the bottle into his glass, it is obvious that it requires effort and he has to use both hands. But he refuses assistance. "My physical therapist says I should try to do everything myself," he says</p><p>Navalny&nbsp;seems more nervous than he did at previous meetings. His face is gaunter and his figure more angular after losing 12 kilos. But his voice is the same as it has always been, as is his humor, his irony. Sitting next to him is his spokeswoman, Kira Yarmysh, who was with him on the plane on August 20 when he first began showing signs of having been poisoned.</p>
</div>

<p>Before the interview begins, he has something he wants to say.</p>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;02a833ee-fba3-4850-98b7-7c4ed3654454&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;5266851a-6e79-4820-b489-daeee6a84ec7&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w683_r1.3714859437751004_fpx36.46_fpy50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w488_r1.3714859437751004_fpx36.46_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w616_r1.3714859437751004_fpx36.46_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w683_r1.3714859437751004_fpx36.46_fpy50.jpg 718w," width="683" height="498" sizes="683px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w488_r1.3714859437751004_fpx36.46_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w616_r1.3714859437751004_fpx36.46_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w683_r1.3714859437751004_fpx36.46_fpy50.jpg 718w," title="This photo was taken in Navalny's hotel room in Tomsk, where his team secured water bottles and other objects. One of the bottles contained traces of the poison." alt="This photo was taken in Navalny's hotel room in Tomsk, where his team secured water bottles and other objects. One of the bottles contained traces of the poison.">
</span>
</span>
</span>
</p><figcaption>
<p>This photo was taken in Navalny's hotel room in Tomsk, where his team secured water bottles and other objects. One of the bottles contained traces of the poison.</p>
<span>
Foto:‚ÄÇAFP
</span>
</figcaption>
</div>
</div>
</div>
</figure><p><strong>Navalny:</strong> It is important to me that this interview appears in the German press. I have never been closely associated with Germany. I don't know anyone here. I didn't know a single politician. And yet it turned out - you see, my voice is trembling, I have become so emotional - that German politicians and Angela Merkel have taken an interest in my fate and saved my life. The doctors at Charit√© saved my life a second time and, more importantly, they gave me back my personality. So, the first thing I want to say is: I feel a tremendous gratitude to all Germans. I know it sounds a bit overblown, but Germany has become a special country for me. I had few connections here before and only visited Berlin for the first time three years ago! And then so much human compassion from so many people.</p>

<div>
<p><strong>DER SPIEGEL:</strong> Our readers will be happy to hear that. How are you doing Mr. Navalny?</p><p><strong>Navalny:</strong> Much better than three weeks ago, and it is getting better each day. Not long ago, I could only climb 10 steps, but now I can make it up to the 5th floor. The most important thing for me is that my mental abilities have returned. Well, maybe we will find the opposite to be true during this interview (<em>laughs</em>).</p><p><strong>DER SPIEGEL:</strong> You wrote on Instagram that you are no longer able to stand on one foot.</p><p><strong>Navalny:</strong> Now I can again. My next challenge is to stand on one leg and stretch the other leg forward, which I practice every day. These are actually exercises that ninety-year-olds do in the park.</p><p><strong>DER SPIEGEL:</strong> Are you able to sleep well?</p><p><strong>Navalny:</strong> That's my biggest problem. I used to laugh about people with sleep problems because I never had them myself. But then came the coma, the anesthesia, the weaning off of the sedatives, that long hovering state when I was neither asleep nor awake. I haven't been able to sleep without sleeping pills since.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;ae3d6308-8e23-4f16-b6a0-25e3b742c41c&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;a924ceb0-6dc2-48da-8b4e-615bf8308ebc&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w683_r1.3742454728370221_fpx62.38_fpy49.9.jpg" srcset="https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w488_r1.3742454728370221_fpx62.38_fpy49.9.jpg 488w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w616_r1.3742454728370221_fpx62.38_fpy49.9.jpg 616w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w683_r1.3742454728370221_fpx62.38_fpy49.9.jpg 718w," width="683" height="497" sizes="683px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w488_r1.3742454728370221_fpx62.38_fpy49.9.jpg 488w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w616_r1.3742454728370221_fpx62.38_fpy49.9.jpg 616w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w683_r1.3742454728370221_fpx62.38_fpy49.9.jpg 718w," title="Navalny was flown from Omsk to Berlin on this chartered plane." alt="Navalny was flown from Omsk to Berlin on this chartered plane.">
</span>
</span>
</span>
</p><figcaption>
<p>Navalny was flown from Omsk to Berlin on this chartered plane.</p>
<span>
Foto:‚ÄÇKira Yarmysh / dpa
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p><strong>DER SPIEGEL:</strong> When you lost consciousness, you were a figure in Russian politics. When you woke from the coma, you were a global political figure. Chancellor Merkel even visited you at your bedside. What did you talk about?</p><p><strong>Navalny:</strong> That was last week. It was totally unexpected. The door opened, my doctor came in - and Merkel. It was a private meeting with my family - my wife Julia and my son Zahar were there. I can't tell you the details, but we didn't discuss anything secret or sensational. The visit was a gesture. I was impressed by how precisely she knows Russia and my case. She knows some of the details better than I do. She really has a deep understanding of what is going on in Russia. And when you talk to her, you understand why she has been at the top in Germany for so long. I thanked her for her efforts and she said: "I only did my duty."</p><p><strong>DER SPIEGEL:</strong> What has daily life been like for you since you left the hospital? Where are you living?</p><p><strong>Navalny:</strong> I live with my wife and my son here. My daughter has returned to Stanford University. We've rented an apartment. My everyday life is monotonous. I exercise daily - that's all I do. In the morning, I take a walk in the park - that's my job. Then I do the exercises with the doctor. In the evening, I go for another walk. During the day, I try to work on the computer. The doctors say I can be restored to 90 percent of my former self, maybe even 100 percent, but nobody really knows for sure. Basically, I'm a bit of a guinea pig. After all, there aren't many people you can observe who are still alive after being poisoned with a nerve agent. At some point, I will probably be written about in medical journals. And I am happy to share my experiences. Seriously: The Russian leadership has developed such a penchant for poisoning that it is not going to stop doing so anytime soon. My medical history will be instructive.</p><p><strong>DER SPIEGEL:</strong> Going by your posts on social media, it appears that you left your bed in the hospital often.</p><p><strong>Navalny:</strong> The doctors and nurses at Charit√© are the most tolerant people in the world. I was a difficult patient. I would get up at night in the intensive care unit, and one time I tore all the tubes out of my body and started bleeding. Later, when I was already conscious and could recognize and talk to the people around me, I had hysterical fits. I said I was healthy and wanted to go to a hotel. Weeks later, I understood that this strange behavior was a consequence of the poisoning.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;39d3599b-4262-4232-b6f7-b6016c2162e6&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;e755133f-4d90-489d-a52a-7cc85d7786ad&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w718_r1.4145383104125737_fpx49.45_fpy50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w488_r1.4145383104125737_fpx49.45_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w616_r1.4145383104125737_fpx49.45_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w718_r1.4145383104125737_fpx49.45_fpy50.jpg 718w" width="718" height="508" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w488_r1.4145383104125737_fpx49.45_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w616_r1.4145383104125737_fpx49.45_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w718_r1.4145383104125737_fpx49.45_fpy50.jpg 718w" title="A first sign of life: Navalny with his children Daria and Zahar and his wife Yulia in his room at Berlin's Charit√© University Hospital" alt="A first sign of life: Navalny with his children Daria and Zahar and his wife Yulia in his room at Berlin's Charit√© University Hospital">
</span>
</span>
</span>
</p><figcaption>
<p>A first sign of life: Navalny with his children Daria and Zahar and his wife Yulia in his room at Berlin's Charit√© University Hospital</p>
<span>
Foto:‚ÄÇAlexei Navalny / ddp media
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p><strong>DER SPIEGEL:</strong> Let's go over what happened to you, and we'll start with your last memory before you lost consciousness. It's August 20, at eight o'clock in the morning. You're sitting in a plane from Tomsk to Moscow. You had spent a few days in Siberia. What was going through your head?</p><p><strong>Navalny:</strong> It was a wonderful day. I'm on my way home, with a strenuous and successful business trip behind me. We shot videos for the regional election campaign, and everything had gone according to plan. I'm sitting comfortably in my seat and I'm looking forward to a quiet flight during which I can watch a series. Once I get back to Moscow, I am looking forward to recording my weekly YouTube show and then spending the weekend with my family. I feel good, as I did at the airport. And then‚Ä¶ it's hard to describe because there is nothing to compare it with. Organophosphorus compounds attack your nervous system like a DDos attack attacks the computer - it's an overload that breaks you. You can no longer concentrate. I can feel that something is&nbsp;wrong. I break out in a cold sweat. I ask Kira beside me for a tissue. Then I say to her: Speak to me. I need to hear a voice - something's wrong with me. She looks at me like I'm crazy and starts talking.</p><p><strong>DER SPIEGEL:</strong> What happened then?</p><p><strong>Navalny:</strong> I don't understand what is happening to me. The stewards come by with the trolley. I first want to ask them for water, but I then say: No, let me by, I'm going to the bathroom. I wash myself with cold water, sit down and wait and then wash myself again. And then I think: If I don't get out now, I'll never get out. The most important feeling was: You are feeling no pain, but you know you're dying. And I mean, right now, yet nothing hurts. I leave the toilet, turn to the steward - and instead of asking for help, I say, to my own surprise: "I've been poisoned. I'm dying." And then I lay down on the ground in front of him to die. He‚Äôs the last thing I see - a face that looks at me with slight astonishment and a light smile. He says: "Poisoned?" and by that he probably means I was served bad chicken.</p><p>And the last thing I hear, already on the floor is: Do you have heart problems? But my heart doesn't hurt. Nothing hurts. All I know is that I am dying. Then I hear voices growing ever quieter, and a woman calling: "Don't leave us! Don't leave us!" Then it's over. I know I'm dead. Only later would it turn out that I was wrong.</p><p><strong>DER SPIEGEL:</strong> There's a video shot by a passenger in which your screams can be heard on the plane. It sounds horrible, almost like the cries of an animal.</p><p><strong>Navalny:</strong> I've watched it - it's circulating on the internet under the title: "Navalny screaming in pain." But it wasn't pain. It was something else, worse. Pain makes you feel like you're alive. But in this case, you sense: This is the end.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;fe4efb86-8391-4038-9e36-19f7e61bb096&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;147f7a62-e974-4130-ae5f-0c077bc0f71e&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w655_r0.8652575957727873_fpx44.89_fpy38.84.jpg" srcset="https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w488_r0.8652575957727873_fpx44.89_fpy38.84.jpg 488w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w616_r0.8652575957727873_fpx44.89_fpy38.84.jpg 616w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w655_r0.8652575957727873_fpx44.89_fpy38.84.jpg 718w," width="655" height="757" sizes="655px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w488_r0.8652575957727873_fpx44.89_fpy38.84.jpg 488w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w616_r0.8652575957727873_fpx44.89_fpy38.84.jpg 616w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w655_r0.8652575957727873_fpx44.89_fpy38.84.jpg 718w," title="Navalny posted photos of himself on Instagram showing him on the balcony of his room." alt="Navalny posted photos of himself on Instagram showing him on the balcony of his room.">
</span>
</span>
</span>
</p><figcaption>
<p>Navalny posted photos of himself on Instagram showing him on the ‚Ä¶</p></figcaption></div></div></div></figure></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4">https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650372</guid>
            <pubDate>Thu, 01 Oct 2020 13:06:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China forces international birding organization to eject Taiwan, gags employees]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24650128">thread link</a>) | @ilamont
<br/>
October 1, 2020 | https://www.cips-cepi.ca/2020/09/30/ruffled-feathers-why-chinese-interference-in-international-bird-conservation-is-a-threat-to-world-peace/ | <a href="https://web.archive.org/web/*/https://www.cips-cepi.ca/2020/09/30/ruffled-feathers-why-chinese-interference-in-international-bird-conservation-is-a-threat-to-world-peace/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<hr>



<p><strong>The&nbsp;</strong><a href="https://www.theguardian.com/world/2020/sep/25/hawk-or-dove-birdwatching-worlds-feathers-ruffled-over-taiwan-independence"><strong>ejection</strong></a><strong>&nbsp;of Taiwan‚Äôs Chinese Wild Bird Federation (CWBF) from BirdLife International and the subsequent&nbsp;</strong><a href="https://www.reuters.com/article/us-taiwan-environment-politics/british-bird-group-issues-gag-order-over-taiwan-china-issue-idUSKBN2690BX"><strong>gag order</strong></a><strong>&nbsp;asking BirdLife employees to refrain from speaking to the press may appear at first glance to be the smallest of China‚Äôs many micro-aggressions, but is indicative of a serious security threat.&nbsp;</strong></p>



<hr>



<p>BirdLife notified the CWBF on September 7 that their 24-year-old partnership had ended. The reason? BirdLife asked the Taiwanese partner to change their official Chinese name and to sign a document promising to neither promote the independence of Taiwan from China nor to advocate the legitimacy of the Republic of China (Taiwan‚Äôs official name). It didn‚Äôt matter that the Federation had never taken a political stance on Taiwan‚Äôs status. It didn‚Äôt matter that they had already changed their English name three times at the behest of BirdLife, even twisting facts to alter the name from ‚ÄúWild Bird Federation Taiwan‚Äù to ‚ÄúChinese Wild Bird Federation‚Äù in 2007. BirdLife wouldn‚Äôt even give them time, as a democratically run NGO, to debate this at the Annual General Meeting. They simply kicked them out of the nest.&nbsp;</p>



<hr>



<p><strong>Recommended: </strong><a href="https://www.cips-cepi.ca/2020/09/29/mbss-admits-full-responsibility-for-the-khashoggi-murder-what-this-means-for-the-kingdoms-allies/"><strong>üèÖ2020 CIPS Blog Award Winner! MBS admits ‚Äúfull responsibility‚Äù for the Khashoggi murder: What this means for the Kingdom‚Äôs allies</strong></a></p>



<hr>



<p>Taiwan protested. The&nbsp;<a href="https://focustaiwan.tw/politics/202009150029">Ministry of Foreign Affairs</a>&nbsp;condemned China for interfering in international conservation NGOs and BirdLife for cooperating with China to coerce the CWBF into taking a political stance.&nbsp;On September 19, the General Assembly of the CWBF decided to finally revert to the more accurate name in English as the&nbsp;<a href="https://www.bird.org.tw/news/602?fbclid=IwAR1RgQoW9nXgZCHRBxlGgr7qamTs_nRhbUyffndt5WEbziqkX92HmKTIdDA">Taiwan Wild Bird Federation</a>.&nbsp;</p>



<p><strong>What is BirdLife?</strong></p>



<p>BirdLife, a global coalition of scientific and conservation NGOs, is active in Canada through Nature Canada and Birds Canada. It coordinates the IBA (Important Bird and Biodiversity Areas) program that identifies and manages important bird habitat sites. Because birds do not respect borders, collaboration between countries is central to BirdLife‚Äôs mandate. Since 2000, Taiwan‚Äôs Forestry Bureau has contributed to BirdLife conservation projects in Madagascar, Cambodia, and Sao Tome.&nbsp;</p>



<p>Taiwan is second only to Japan in Asia for bird conservation and scientific research. Taiwan hosts 682 bird species, 29 endemic species, and 43 endangered species. Taiwanese birders are active contributors to eBird, the world‚Äôs most comprehensive citizen science project in ornithology. The CWBF does important work to protect the Chinese Crested Tern and Black-faced Spoonbill. In 2020, the 4,864 Black-faced Spoonbills that wintered in Taiwan accounted for 57.3% of the population of that endangered species. Migratory birds along the East Asian-Australasian Flyway depend on Taiwan because of its strategic location on their pathways that stretch from Siberia to Australia. Taiwan‚Äôs expulsion from BirdLife will hinder cross-border cooperation on conservation, just because China prioritizes its political goals over even pragmatic scientific cooperation. China makes everything into a zero-sum game.&nbsp;</p>



<figure><p>
https://twitter.com/TaiwanBirding/status/1309409778393776128?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1309409778393776128%7Ctwgr%5Eshare_3&amp;ref_url=https%3A%2F%2Fpublish.twitter.com%2F%3Fquery%3Dhttps3A2F2Ftwitter.com2FTaiwanBirding2Fstatus2F1309409778393776128widget%3DTweet
</p></figure>



<p><strong>China Curtails Freedom of International Civil Society</strong></p>



<p>BirdLife is a dangerous precedent for other NGOs. Because China can pressure one leading NGO into cutting out Taiwan, they will feel emboldened to go after other NGOs ‚Äì including in Canada. NGOs hoping to expand into China will hesitate to build partnerships with Taiwan. This is a shame because Taiwanese NGOs have strong expertise as well as the financial means to get things done. It is even more unfortunate because democratic Taiwan, like Canada, actually has real social movements run by civilians without government interference. China, on the other hand, strictly limits the freedoms of Chinese NGOs. Since 2017, when China changed its NGO regulations in line with broader security-related legislation, international NGOs have been required to register with the Ministry of Public Security and must have an approved local partner. This means the Chinese Communist Party can use NGOs to export their standards to the world.&nbsp;</p>



<p>Until now, China has not permitted BirdLife to enter China, which means the closest they get is collaboration with the Hong Kong Birdwatching Society. Maybe that is the point. Quite possibly, BirdLife is negotiating with China and took action against Taiwan as a precondition for collaboration. The cost is high. It means letting China dictate the norms of how international NGOs operate. BirdLife even imported Chinese norms on media freedom by issuing a gag order to their employees. And this is in Great Britain, which takes pride in the Magna Charta as one of the founding documents of democracy.&nbsp;</p>



<p>Because of China‚Äôs sheer size and long coastlines used by migratory birds, BirdLife is badly needed in China. International bird conservation would improve if China were to open up its own borders to free, unfettered cooperation between Chinese and international NGOs. Bird habitats along migration routes would be best protected if China were to set aside politics and collaborate with Taiwanese ornithologists and conservation scientists&nbsp;&nbsp;like Japan and Russia do in spite of long-standing territorial disputes that straddle bird habitats.&nbsp;&nbsp;</p>



<p><strong>The Bigger Picture</strong></p>



<p>China‚Äôs pressure on BirdLife is part of a new strategy. For decades, BirdLife‚Äôs Taiwanese partner could simply accept a compromise name of ‚ÄúChinese Wild Bird Federation‚Äù internationally; and ‚ÄúRepublic of China Wild Bird Federation‚Äù at home. BirdLife and the CWBF could collaborate as long as they remained silent about China-Taiwan relations. The most troubling sign is not the requested name change, but the fact that the CWBF was asked to commit themselves to a political stance. China is trying to shape a world in which even silence is not an option. China‚Äôs goal is to get the entire world to parrot its claims that Taiwan is part of the People‚Äôs Republic of China. This must be seen as part of a larger strategy in which the Chinese military during a global pandemic feels emboldened to practice invasion of Taiwan and to regularly send jets into Taiwanese airspace.&nbsp;</p>



<p>BirdLife should be reminding the world that coastal birds inhabiting wetlands along the Taiwan Straits would be the first victims if China were to ever invade Taiwan. Instead, their abandonment of the Taiwan Wild Bird Federation gives Beijing one more sign that the world does not oppose their strategy to annex Taiwan. Acquiescing to Chinese micro-management of international NGOs is not good for the birds and, in the long run, it is dangerous for the security of the entire region.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>



<hr>



<p><strong>Recommended: </strong><a href="https://www.cips-cepi.ca/2020/09/27/twitter-conference-understanding-the-five-eyes/"><strong>Twitter Conference: Understanding the Five Eyes</strong></a></p>




</div></div></div>]]>
            </description>
            <link>https://www.cips-cepi.ca/2020/09/30/ruffled-feathers-why-chinese-interference-in-international-bird-conservation-is-a-threat-to-world-peace/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650128</guid>
            <pubDate>Thu, 01 Oct 2020 12:31:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Segment Tree ‚Äì Competitive Programming Algorithms]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650084">thread link</a>) | @pmoriarty
<br/>
October 1, 2020 | https://cp-algorithms.com/data_structures/segment_tree.html | <a href="https://web.archive.org/web/*/https://cp-algorithms.com/data_structures/segment_tree.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
    


<p>A Segment Tree is a data structure that allows answering range queries over an array effectively, while still being flexible enough to allow modifying the array. 
This includes finding the sum of consecutive array elements $a[l \dots r]$, or finding the minimum element in a such a range in $O(\log n)$ time. 
Between answering such queries the Segment Tree allows modifying the array by replacing one element, or even change the elements of a whole subsegment (e.g. assigning all elements $a[l \dots r]$ to any value, or adding a value to all element in the subsegment).</p>

<p>In general a Segment Tree is a very flexible data structure, and a huge number of problems can be solved with it. 
Additionally it is also possible to apply more complex operations and answer more complex queries (see <a href="https://cp-algorithms.com/data_structures/segment_tree.html#advanced-versions-of-segment-trees">Advanced versions of Segment Trees</a>).
In particular the Segment Tree can be easily generalized to larger dimensions. 
For instance with a two-dimensional Segment Tree you can answer sum or minimum queries over some subrectangle of a given matrix.
However only in $O(\log^2 n)$ time.</p>

<p>One important property of Segment Trees is, that they require only a linear amount of memory.
The standard Segment Tree requires $4n$ vertices for working on an array of size $n$.</p>

<h2>Simplest form of a Segment Tree</h2>

<p>To start easy, we consider the simplest form of a Segment Tree. 
We want to answer sum queries efficiently. 
The formal definition of our task is:
We have an array $a[0 \dots n-1]$, and the Segment Tree must be able to find the sum of elements between the indices $l$ and $r$ (i.e. computing the sum $\sum_{i=l}^r a[i]$), and also handle changing values of the elements in the array (i.e. perform assignments of the form $a[i] = x$). 
The Segment Tree should be able to process both queries in $O(\log n)$ time.</p>

<h3>Structure of the Segment Tree</h3>

<p>So, what is a Segment Tree?</p>

<p>We compute and store the sum of the elements of the whole array, i.e. the sum of the segment $a[0 \dots n-1]$. 
We then split the array into two halves $a[0 \dots n/2]$ and $a[n/2+1 \dots n-1]$ and compute the sum of each halve and store them. 
Each of these two halves in turn also split in half, their sums are computed and stored. 
And this process repeats until all segments reach size $1$. 
In other words we start with the segment $a[0 \dots n-1]$, split the current segment in half (if it has not yet become a segment containing a single element), and then calling the same procedure for both halves. 
For each such segment we store the sum of the numbers on it.</p>

<p>We can say, that these segments form a binary tree: 
the root of this tree is the segment $a[0 \dots n-1]$, and each vertex (except leaf vertices) has exactly two child vertices. 
This is why the data structure is called "Segment Tree", even though in most implementations the tree is not constructed explicitly (see <a href="https://cp-algorithms.com/data_structures/segment_tree.html#implementation">Implementation</a>).</p>

<p>Here is a visual representation of such a Segment Tree over the array $a = [1, 3, -2, 8, -7]$:</p>

<p><img src="https://raw.githubusercontent.com/e-maxx-eng/e-maxx-eng/master/img/sum-segment-tree.png" alt="&quot;Sum Segment Tree&quot;"></p>

<p>From this short description of the data structure, we can already conclude that a Segment Tree only requires a linear number of vertices. 
The first level of the tree contains a single node (the root), the second level will contain two vertices, in the third it will contain four vertices, until the number of vertices reaches $n$. 
Thus the number of vertices in the worst case can be estimated by the sum $1 + 2 + 4 + \dots + 2^{\lceil\log_2 n\rceil} = 2^{\lceil\log_2 n\rceil + 1} \lt 4n$.</p>

<p>It is worth noting that whenever $n$ is not a power of two, not all levels of the Segment Tree will be completely filled. 
We can see that behavior in the image.
For now we can forget about this fact, but it will become important later during the implementation.</p>

<p>The height of the Segment Tree is $O(\log n)$, because when going down from the root to the leaves the size of the segments decreases approximately by half.</p>

<h3>Construction</h3>

<p>Before constructing the segment tree, we need to decide:</p>

<ol>
<li>the <em>value</em> that gets stored at each node of the segment tree.
For example, in a sum segment tree, a node would store the sum of the elements in its range $[l, r]$.</li>
<li>the <em>merge</em> operation that merges two siblings in a segment tree.
For example, in a sum segment tree, the two nodes corresponding to the ranges $a[l_1 \dots r_1]$ and $a[l_2 \dots r_2]$ would be merged into a node corresponding to the range $a[l_1 \dots r_2]$ by adding the values of the two nodes.</li>
</ol>

<p>Note that a vertex is a "leaf vertex", if its corresponding segment covers only one value in the original array. It is present at the lowermost level of a segment tree. Its value would be equal to the (corresponding) element $a[i]$.</p>

<p>Now, for construction of the segment tree, we start at the bottom level (the leaf vertices) and assign them their respective values. On the basis of these values, we can compute the values of the previous level, using the <code>merge</code> function.
And on the basis of those, we can compute the values of the previous, and repeat the procedure until we reach the root vertex.</p>

<p>It is convenient to describe this operation recursively in the other direction, i.e., from the root vertex to the leaf vertices. The construction procedure, if called on a non-leaf vertex, does the following:</p>

<ol>
<li>recursively construct the values of the two child vertices</li>
<li>merge the computed values of these children.</li>
</ol>

<p>We start the construction at the root vertex, and hence, we are able to compute the entire segment tree.</p>

<p>The time complexity of this construction is $O(n)$, assuming that the merge operation is constant time (the merge operation gets called $n$ times, which is equal to the number of internal nodes in the segment tree).</p>

<h3>Sum queries</h3>

<p>For now we are going to answer sum queries. As an input we receive two integers $l$ and $r$, and we have to compute the sum of the segment $a[l \dots r]$ in $O(\log n)$ time.</p>

<p>To do this, we will traverse the Segment Tree and use the precomputed sums of the segments.
Let's assume that we are currently at the vertex that covers the segment $a[tl \dots tr]$.
There are three possible cases.</p>

<p>The easiest case is when the segment $a[l \dots r]$ is equal to the corresponding segment of the current vertex (i.e. $a[l \dots r] = a[tl \dots tr]$), then we are finished and can return the precomputed sum that is stored in the vertex.</p>

<p>Alternatively the segment of the query can fall completely into the domain of either the left or the right child.
Recall that the left child covers the segment $a[tl \dots tm]$ and the right vertex covers the segment $a[tm + 1 \dots tr]$ with $tm = (tl + tr) / 2$. 
In this case we can simply go to the child vertex, which corresponding segment covers the query segment, and execute the algorithm described here with that vertex.</p>

<p>And then there is the last case, the query segment intersects with both children. 
In this case we have no other option as to make two recursive calls, one for each child.
First we go to the left child, compute a partial answer for this vertex (i.e. the sum of values of the intersection between the segment of the query and the segment of the left child), then go to the right child, compute the partial answer using that vertex, and then combine the answers by adding them. 
In other words, since the left child represents the segment $a[tl \dots tm]$ and the right child the segment $a[tm+1 \dots tr]$, we compute the sum query $a[l \dots tm]$ using the left child, and the sum query $a[tm+1 \dots r]$ using the right child.</p>

<p>So processing a sum query is a function that recursively calls itself once with either the left or the right child (without changing the query boundaries), or twice, once for the left and once for the right child (by splitting the query into two subqueries). 
And the recursion ends, whenever the boundaries of the current query segment coincides with the boundaries of the segment of the current vertex. 
In that case the answer will be the precomputed value of the sum of this segment, which is stored in the tree.</p>

<p>In other words, the calculation of the query is a traversal of the tree, which spreads through all necessary branches of the tree, and uses the precomputed sum values of the segments in the tree.</p>

<p>Obviously we will start the traversal from the root vertex of the Segment Tree.</p>

<p>The procedure is illustrated in the following image.
Again the array $a = [1, 3, -2, 8, -7]$ is used, and here we want to compute the sum $\sum_{i=2}^4 a[i]$.
The colored vertices will be visited, and we will use the precomputed values of the green vertices.
This gives us the result $-2 + 1 = -1$.</p>

<p><img src="https://raw.githubusercontent.com/e-maxx-eng/e-maxx-eng/master/img/sum-segment-tree-query.png" alt="&quot;Sum Segment Tree Query&quot;"></p>

<p>Why is the complexity of this algorithm $O(\log n)$?
To show this complexity we look at each level of the tree. 
It turns out, that for each level we only visit not more than four vertices. 
And since the height of the tree is $O(\log n)$, we receive the desired running time.</p>

<p>We can show that this proposition (at most four vertices each level) is true by induction.
At the first level, we only visit one vertex, the root vertex, so here we visit less than four vertices. 
Now let's look at an arbitrary level.
By induction hypothesis, we visit at most four vertices. 
If we only visit at most two vertices, the next level has at most four vertices. That trivial, because each vertex can only cause at most two recursive calls. 
So let's assume that we visit three or four vertices in the current level. 
From those vertices, we will analyze the vertices in the middle more carefully. 
Since the sum query asks for the sum of a continuous subarray, we know that segments corresponding to the visited vertices in the middle will be completely covered by the segment of the sum query. 
Therefore these vertices will not make any recursive calls. 
So only the most left, and the most right vertex will have the potential to make recursive calls. 
And those will only create at most four recursive calls, so also the next level will satisfy the assertion.
We can say that one branch approaches the left boundary of the query, and the ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cp-algorithms.com/data_structures/segment_tree.html">https://cp-algorithms.com/data_structures/segment_tree.html</a></em></p>]]>
            </description>
            <link>https://cp-algorithms.com/data_structures/segment_tree.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650084</guid>
            <pubDate>Thu, 01 Oct 2020 12:25:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MIT new large tokamak to be the first in history to do self-sustaining reaction]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24650030">thread link</a>) | @vermontdevil
<br/>
October 1, 2020 | https://defector.com/if-scientists-are-to-create-and-harness-the-unfathomable-power-of-a-star-they-must-agree-to-hurl-me-into-it/ | <a href="https://web.archive.org/web/*/https://defector.com/if-scientists-are-to-create-and-harness-the-unfathomable-power-of-a-star-they-must-agree-to-hurl-me-into-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico">
<p>Scientists at the Massachusetts Institute of Technology <a href="https://www.nytimes.com/2020/09/29/climate/nuclear-fusion-reactor.html?smtyp=cur&amp;smid=tw-nytimes&amp;utm_source=Default+audience&amp;utm_campaign=88af7df3e9-EMAIL_CAMPAIGN_2020_09_29_06_13&amp;utm_medium=email&amp;utm_term=0_3cb9478f4c-88af7df3e9-193252502" target="_blank">are developing</a> a type of reactor, called a tokamak, which if it works as intended will generate conditions of sufficient intensity to fuse hydrogen isotopes and harness all the incredible energy released in the process. Their goal is super ambitious: There are other tokamaks, but the MIT scientists expect their large tokamak to be the first in history that is capable of a self-sustaining reaction, and the first that generates more energy than it uses. And they expect to pivot immediately from this historic engineering feat to commercial energy production, and to do all of this on a relatively modest budget, and on a timeline of just three to four years. They expect, in other words, to build the world‚Äôs first fully operational thermonuclear fusion reactor, pumping out infinitely sustainable energy right here in the U.S. of A.</p>



<p>I expect to walk up to this tokamak, engage the help of several brawny nuclear engineers, and to be hurled bodily into the inconceivable heat and indescribable beauty of the radiant plasma cloud magnetically suspended in its core, so that I am instantaneously vaporized and eradicated altogether from this plane of existence. The sooner the better.</p>



<p>Initially it seemed that the best choice for this job would be the International Thermonuclear Experimental Reactor, or ITER, in Provence, France. Whereas the <a href="https://www.psfc.mit.edu/sparc" target="_blank">SPARC tokamak</a> being developed by MIT will be the size of a tennis court, <a href="https://www.iter.org/mach" target="_blank">the ITER</a>, which has been in various phases of development and construction for something like 13 years, will eventually be the size of a soccer field. The specs on this thing <a href="https://www.newyorker.com/magazine/2014/03/03/a-star-in-a-bottle" target="_blank">are mind-boggling</a>:</p>



<blockquote><p>At its core, densely packed high-precision equipment will encase a cavernous vacuum chamber, in which a super-hot cloud of heavy hydrogen will rotate faster than the speed of sound, twisting like a strand of DNA as it circulates. The cloud will be scorched by electric current (a surge so forceful that it will make lightning seem like a tiny arc of static electricity), and bombarded by concentrated waves of radiation. Beams of uncharged particles‚Äîthe energy in them so great it could vaporize a car in seconds‚Äîwill pour into the chamber, adding tremendous heat. In this way, the circulating hydrogen will become ionized, and achieve temperatures exceeding two hundred million degrees Celsius‚Äîmore than ten times as hot as the sun at its blazing core.</p><cite>&nbsp;Raffi Khatchadourian, <em><a href="https://www.newyorker.com/magazine/2014/03/03/a-star-in-a-bottle" target="_blank">The New Yorker</a></em></cite></blockquote>



<p>‚ÄúTremendous heat‚Äù is an understatement of brain-scrambling, laugh-out-loud proportions. This cloud of plasma will be so hot that no physical substance on Earth or known to humankind could contain it for even a fraction of a second: ‚ÄúMetals, plastics, ceramics, concrete, even pure diamond‚Äîall would be obliterated on contact.‚Äù The only way to keep the plasma cloud in place, and thus concentrated enough to trigger nuclear fusion, is to squeeze it into a pocket of space using the ‚Äútitanic forces‚Äù of ‚Äúthe largest system of superconducting magnets in the world,‚Äù actively cooled to deep-space temperatures in order to survive the heat of an actual star.</p>



<p>So in an ultra-secure chamber in a pit in the countryside of Provence, a blob of the hottest substance in our entire solar system will hang in the air, consuming hydrogen isotopes and generating enough energy to turn diamonds into vapor on contact. There are those who would point out that it is probably a bad idea to let humanity just have the Sun, that inevitably some technician is going to want to pull a viral YouTube prank by aiming a beam of the God Cloud at his buddy‚Äôs balls and wind up boring a hole through the planet itself. Or that a janitor will absentmindedly unplug the supercooling systems that allow the mega-magnets to contain the reaction and accidentally atomize the Western Hemisphere. Those people are probably right. Humanity can‚Äôt be counted upon to safely handle livestock‚Äîputting it in charge of a star seems like something that should not be allowed, by the universe.</p>



<p>But since we are building these things anyway, all I ask is that I be lifted by the scruff of my shirt and the seat of my pants by two strong nuclear technicians and, on the count of three, heaved face-first into whichever of the two God Clouds is completed first. It‚Äôs nice to think of all my atoms instantly dispersing into the fabric of the universe, but mostly it will be extremely bitchin‚Äô to be devoured by a star. If this cannot be arranged for whatever reason, I will accept having a beam of the star juice fired into my chest, so that I may utter ‚Äúfuck yeah‚Äù before it is over.</p>
</div></div></div></div></div>]]>
            </description>
            <link>https://defector.com/if-scientists-are-to-create-and-harness-the-unfathomable-power-of-a-star-they-must-agree-to-hurl-me-into-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650030</guid>
            <pubDate>Thu, 01 Oct 2020 12:19:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Neural Network API]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24649616">thread link</a>) | @rajveermalviya
<br/>
October 1, 2020 | https://webmachinelearning.github.io/webnn/ | <a href="https://web.archive.org/web/*/https://webmachinelearning.github.io/webnn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <h2 data-level="1" id="intro"><span>1. </span><span>Introduction</span><a href="#intro"></a></h2>
   <p>We‚Äôre working on this section. Meanwhile, please take a look at the <a href="https://github.com/webmachinelearning/webnn/blob/master/explainer.md">explainer</a>.</p>
   <h2 data-level="2" id="usecases"><span>2. </span><span>Use cases</span><a href="#usecases"></a></h2>
   <h3 data-level="2.1" id="usecases-application"><span>2.1. </span><span>Application Use Cases</span><a href="#usecases-application"></a></h3>
   <p>This section illustrates application-level use cases for neural network
inference hardware acceleration. All applications in those use cases can be
built on top of pre-trained deep neural network (DNN) models.</p>
   <h4 data-level="2.1.1" id="usecase-person-detection"><span>2.1.1. </span><span>Person Detection</span><a href="#usecase-person-detection"></a></h4>
   <p>A user opens a web-based video conferencing application, but she temporarily
leaves from her room. The application is watching whether she is in front of her
PC by using object detection (for example, using object detection approaches
such as <a data-link-type="biblio" href="#biblio-ssd">[SSD]</a> or <a data-link-type="biblio" href="#biblio-yolo">[YOLO]</a> that use a single DNN) to detect regions in a camera
input frame that include persons.</p>
   <p>When she comes back, the application automatically detects her and notifies
other online users that she is active now.</p>
   <h4 data-level="2.1.2" id="usecase-segmentation"><span>2.1.2. </span><span>Semantic Segmentation</span><a href="#usecase-segmentation"></a></h4>
   <p>A user joins a teleconference via a web-based video conferencing application at
her desk since no meeting room in her office is available. During the
teleconference, she does not wish that her room and people in the background are
visible. To protect the privacy of the other people and the surroundings, the
application runs a machine learning model such as <a data-link-type="biblio" href="#biblio-deeplabv3">[DeepLabv3+]</a> or <a data-link-type="biblio" href="#biblio-maskr-cnn">[MaskR-CNN]</a> to semantically split an image into segments and replaces
segments that represent other people and background with another picture.</p>
   <h4 data-level="2.1.3" id="usecase-skeleton-detection"><span>2.1.3. </span><span>Skeleton Detection</span><a href="#usecase-skeleton-detection"></a></h4>
   <p>A web-based video conferencing application tracks a pose of user‚Äôs skeleton by
running a machine learning model, which allows for real-time human pose
estimation, such as <a data-link-type="biblio" href="#biblio-posenet">[PoseNet]</a> to recognize her gesture and body language. When
she raises her hand, her microphone is automatically unmuted and she can start
speaking on the teleconference.</p>
   <h4 data-level="2.1.4" id="usecase-face-recognition"><span>2.1.4. </span><span>Face Recognition</span><a href="#usecase-face-recognition"></a></h4>
   <p>There are multiple people in the conference room and they join an online meeting
using a web-based video conferencing application. The application detects faces
of participants by using object detection (for example, using object detection
approaches such as <a data-link-type="biblio" href="#biblio-ssd">[SSD]</a>) and checks whether each face was present at the
previous meeting or not by running a machine learning model such as <a data-link-type="biblio" href="#biblio-facenet">[FaceNet]</a>,
which verifies whether two faces would be identical or not.</p>
   <h4 data-level="2.1.5" id="usecase-facial-landmarks"><span>2.1.5. </span><span>Facial Landmark Detection</span><a href="#usecase-facial-landmarks"></a></h4>
   <p>A user wants to find new glasses that beautifully fits her on an online glasses
store. The online store offers web-based try-on simulator that runs a machine
learning model such as Face Alignment Network <a data-link-type="biblio" href="#biblio-fan">[FAN]</a> to detect facial landmarks
like eyes, nose, mouth, etc. When she chooses a pair of glasses, the simulator
properly render the selected glasses on the detected position of eyes on her
facial image.</p>
   <h4 data-level="2.1.6" id="usecase-style-transfer"><span>2.1.6. </span><span>Style Transfer</span><a href="#usecase-style-transfer"></a></h4>
   <p>A user is looking for cosmetics on an online store and wondering which color may
fit her face. The online store shows sample facial makeup images of cosmetics,
and offers makeup simulator that runs a machine learning model like <a data-link-type="biblio" href="#biblio-contextualloss">[ContextualLoss]</a> or <a data-link-type="biblio" href="#biblio-pairedcyclegan">[PairedCycleGAN]</a> to transfer the makeup style of the
sample makeup image to her facial image. She can check how the selected makeup
looks like on her face by the simulator.</p>
   <h4 data-level="2.1.7" id="usecase-super-resolution"><span>2.1.7. </span><span>Super Resolution</span><a href="#usecase-super-resolution"></a></h4>
   <p>A web-based video conferencing is receiving a video stream from its peer, but
the resolution of the video becomes lower due to network congestion. To prevent
degradation of the perceived video quality, the application runs a machine
learning model for super-resolution such as <a data-link-type="biblio" href="#biblio-srgan">[SRGAN]</a> to generate
higher-resolution video frames.</p>
   <h4 data-level="2.1.8" id="usecase-image-captioning"><span>2.1.8. </span><span>Image Captioning</span><a href="#usecase-image-captioning"></a></h4>
   <p>For better accessibility, a web-based presentation application provides
automatic image captioning by running a machine learning model such as <a data-link-type="biblio" href="#biblio-im2txt">[im2txt]</a> which predicts explanatory words of the presentation slides.</p>
   <h4 data-level="2.1.9" id="usecase-translation"><span>2.1.9. </span><span>Machine Translation</span><a href="#usecase-translation"></a></h4>
   <p>Multiple people from various countries are talking via a web-based real-time
text chat application. The application translates their conversation by using a
machine learning model such as <a data-link-type="biblio" href="#biblio-gnmt">[GNMT]</a> or <a data-link-type="biblio" href="#biblio-opennmt">[OpenNMT]</a>, which translates every
text into different language.</p>
   <h4 data-level="2.1.10" id="usecase-emotion-analysis"><span>2.1.10. </span><span>Emotion Analysis</span><a href="#usecase-emotion-analysis"></a></h4>
   <p>A user is talking to her friend via a web-based real-time text chat application,
and she is wondering how the friend feels because she cannot see the friend‚Äôs
face. The application analyses the friend‚Äôs emotion by using a machine learning
model such as <a data-link-type="biblio" href="#biblio-deepmoji">[DeepMoji]</a>, which infers emotion from input texts, and displays
an emoji that represents the estimated emotion.</p>
   <h4 data-level="2.1.11" id="usecase-video-summalization"><span>2.1.11. </span><span>Video Summarization</span><a href="#usecase-video-summalization"></a></h4>
   <p>A web-based video conferencing application records received video streams, and
it needs to reduce recorded video data to be stored. The application generates
the short version of the recorded video by using a machine learning model for
video summarization such as <a data-link-type="biblio" href="#biblio-video-summarization-with-lstm">[Video-Summarization-with-LSTM]</a>.</p>
   <h4 data-level="2.1.12" id="usecase-noise-suppression"><span>2.1.12. </span><span>Noise Suppression</span><a href="#usecase-noise-suppression"></a></h4>
   <p>A web-based video conferencing application records received audio streams, but
usually the background noise is everywhere. The application leverages real-time 
noise suppression using Recurrent Neural Network such as <a data-link-type="biblio" href="#biblio-rnnoise">[RNNoise]</a> for 
suppressing background dynamic noise like baby cry or dog barking to improve 
audio experiences in video conferences.</p>
   <h3 data-level="2.2" id="usecases-framework"><span>2.2. </span><span>Framework Use Cases</span><a href="#usecases-framework"></a></h3>
   <p>This section collects framework-level use cases for a dedicated low-level API
for neural network inference hardware acceleration. It is expected that Machine
Learning frameworks will be key consumers of the Web Neural Network API (WebNN
API) and the low-level details exposed through the WebNN API are abstracted out
from typical web developers. However, it is also expected that web developers
with specific interest and competence in Machine Learning will want to interface
with the WebNN API directly instead of a higher-level ML framework.</p>
   <h4 data-level="2.2.1" id="usecase-custom-layer"><span>2.2.1. </span><span>Custom Layer</span><a href="#usecase-custom-layer"></a></h4>
   <p>A web application developer wants to run a DNN model on the WebNN API. However,
she has found that some of activation functions like <a data-link-type="biblio" href="#biblio-leakyrelu">[LeakyReLU]</a>, <a data-link-type="biblio" href="#biblio-elu">[ELU]</a>,
etc. are not included in the WebNN API. To address this issue, she constructs
custom layers of the additional activation functions on top of the WebNN API.
Note that the scope of custom layers may include convolution, normalization,
etc. as well as activation.</p>
   <h4 data-level="2.2.2" id="usecase-network-concat"><span>2.2.2. </span><span>Network Concatenation</span><a href="#usecase-network-concat"></a></h4>
   <p>A web application uses a DNN model, and its model data of upper convolutional
layers and lower fully-connected layers are stored in separate files, since
model data of the fully-connected layers are periodically updated due to fine
tuning at the server side.</p>
   <p>Therefore, the application downloads both partial model files at first and
concatenates them into a single model. When the model is updated, the
application downloads fine-tuned part of the model and replace only the
fully-connected layers with it.</p>
   <h4 data-level="2.2.3" id="usecase-perf-adapt"><span>2.2.3. </span><span>Performance Adaptation</span><a href="#usecase-perf-adapt"></a></h4>
   <p>A web application developer has a concern about performance of her DNN model on
mobile devices. She has confirmed that it may run too slow on mobile devices
which do not have GPU acceleration. To address this issue, her web application
refers to the WebNN API to confirm whether acceleration is available or not, so
that the application can display the warning for devices without acceleration.</p>
   <p>After several weeks, she has developed a tiny DNN model that can even run on
CPU. In order to accommodate CPU execution, she modifies the application
so that the application loads the tiny model in the case of CPU-only devices.</p>
   <h2 data-level="3" id="api"><span>3. </span><span>API</span><a href="#api"></a></h2>
   <h3 data-level="3.1" id="api-navigator"><span>3.1. </span><span>Navigator</span><a href="#api-navigator"></a></h3>
<pre><c- b="">partial</c-> <c- b="">interface</c-> <a data-link-type="interface" href="https://html.spec.whatwg.org/multipage/system-state.html#navigator" id="ref-for-navigator"><c- g="">Navigator</c-></a> {
  <c- b="">readonly</c-> <c- b="">attribute</c-> <a data-link-type="idl-name" href="#ml" id="ref-for-ml"><c- n="">ML</c-></a> <dfn data-dfn-for="Navigator" data-dfn-type="attribute" data-export="" data-readonly="" data-type="ML" id="dom-navigator-ml"><code><c- g="">ml</c-></code><a href="#dom-navigator-ml"></a></dfn>;
};
</pre>
   <h3 data-level="3.2" id="api-ml"><span>3.2. </span><span>ML</span><a href="#api-ml"></a></h3>
<pre><c- b="">interface</c-> <dfn data-dfn-type="interface" data-export="" id="ml"><code><c- g="">ML</c-></code></dfn> {
  <a data-link-type="idl-name" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext"><c- n="">NeuralNetworkContext</c-></a> <dfn data-dfn-for="ML" data-dfn-type="method" data-export="" data-lt="getNeuralNetworkContext()" id="dom-ml-getneuralnetworkcontext"><code><c- g="">getNeuralNetworkContext</c-></code><a href="#dom-ml-getneuralnetworkcontext"></a></dfn>();
};
</pre>
   <h3 data-level="3.3" id="api-operanddescriptor"><span>3.3. </span><span>OperandDescriptor</span><a href="#api-operanddescriptor"></a></h3>
<pre><c- b="">enum</c-> <dfn data-dfn-type="enum" data-export="" id="enumdef-operandlayout"><code><c- g="">OperandLayout</c-></code></dfn> {
  <dfn data-dfn-for="OperandLayout" data-dfn-type="enum-value" data-export="" id="dom-operandlayout-nchw"><code><c- s="">"nchw"</c-></code><a href="#dom-operandlayout-nchw"></a></dfn>,
  <dfn data-dfn-for="OperandLayout" data-dfn-type="enum-value" data-export="" id="dom-operandlayout-nhwc"><code><c- s="">"nhwc"</c-></code><a href="#dom-operandlayout-nhwc"></a></dfn>
};

<c- b="">enum</c-> <dfn data-dfn-type="enum" data-export="" id="enumdef-operandtype"><code><c- g="">OperandType</c-></code></dfn> {
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-float32"><code><c- s="">"float32"</c-></code><a href="#dom-operandtype-float32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-float16"><code><c- s="">"float16"</c-></code><a href="#dom-operandtype-float16"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-int32"><code><c- s="">"int32"</c-></code><a href="#dom-operandtype-int32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-uint32"><code><c- s="">"uint32"</c-></code><a href="#dom-operandtype-uint32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-float32"><code><c- s="">"tensor-float32"</c-></code><a href="#dom-operandtype-tensor-float32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-float16"><code><c- s="">"tensor-float16"</c-></code><a href="#dom-operandtype-tensor-float16"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-int32"><code><c- s="">"tensor-int32"</c-></code><a href="#dom-operandtype-tensor-int32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-quant8-asymm"><code><c- s="">"tensor-quant8-asymm"</c-></code><a href="#dom-operandtype-tensor-quant8-asymm"></a></dfn>
};

<c- b="">dictionary</c-> <dfn data-dfn-type="dictionary" data-export="" id="dictdef-operanddescriptor"><code><c- g="">OperandDescriptor</c-></code></dfn> {
  // The operand type.
  <c- b="">required</c-> <a data-link-type="idl-name" href="#enumdef-operandtype" id="ref-for-enumdef-operandtype"><c- n="">OperandType</c-></a> <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="OperandType " id="dom-operanddescriptor-type"><code><c- g="">type</c-></code><a href="#dom-operanddescriptor-type"></a></dfn>;

  // The dimensions field is only required for tensor operands.
  // The negative value means an unknown dimension.
  <c- b="">sequence</c->&lt;<a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long"><c- b="">long</c-></a>&gt; <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="sequence<long> " id="dom-operanddescriptor-dimensions"><code><c- g="">dimensions</c-></code><a href="#dom-operanddescriptor-dimensions"></a></dfn>;

  // The following two fields are only required for quantized operand.
  // scale: an non-negative floating point value
  // zeroPoint: an integer, in range [0, 255]
  // The real value is (value - zeroPoint) * scale
  <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float"><c- b="">float</c-></a> <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="float " id="dom-operanddescriptor-scale"><code><c- g="">scale</c-></code><a href="#dom-operanddescriptor-scale"></a></dfn>;
  <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long‚ë†"><c- b="">long</c-></a> <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="long " id="dom-operanddescriptor-zeropoint"><code><c- g="">zeroPoint</c-></code><a href="#dom-operanddescriptor-zeropoint"></a></dfn>;
};
</pre>
   <h3 data-level="3.4" id="api-operand"><span>3.4. </span><span>Operand</span><a href="#api-operand"></a></h3>
<pre><c- b="">interface</c-> <dfn data-dfn-type="interface" data-export="" id="operand"><code><c- g="">Operand</c-></code></dfn> {};
</pre>
   <h3 data-level="3.5" id="api-neuralnetworkcontext"><span>3.5. </span><span>NeuralNetworkContext</span><a href="#api-neuralnetworkcontext"></a></h3>
   <p>The <code><a data-link-type="idl" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext‚ë†">NeuralNetworkContext</a></code> defines a set of operations derived from the first-wave models <a data-link-type="biblio" href="#biblio-models">[Models]</a> that address identified <a href="#usecases">¬ß‚ÄØ2 Use cases</a>.</p>
<pre><c- b="">typedef</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-double" id="ref-for-idl-double"><c- b="">double</c-></a> <dfn data-dfn-type="typedef" data-export="" id="typedefdef-number"><code><c- g="">number</c-></code></dfn>;

<c- b="">dictionary</c-> <dfn data-dfn-type="dictionary" data-export="" id="dictdef-namedoperand"><code><c- g="">NamedOperand</c-></code></dfn> {
  <c- b="">required</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString" id="ref-for-idl-DOMString"><c- b="">DOMString</c-></a> <dfn data-dfn-for="NamedOperand" data-dfn-type="dict-member" data-export="" data-type="DOMString " id="dom-namedoperand-name"><code><c- g="">name</c-></code><a href="#dom-namedoperand-name"></a></dfn>;
  <c- b="">required</c-> <a data-link-type="idl-name" href="#operand" id="ref-for-operand"><c- n="">Operand</c-></a> <dfn data-dfn-for="NamedOperand" data-dfn-type="dict-member" data-export="" data-type="Operand " id="dom-namedoperand-operand"><code><c- g="">operand</c-></code><a href="#dom-namedoperand-operand"></a></dfn>;
};

<c- b="">interface</c-> <dfn data-dfn-type="interface" data-export="" id="neuralnetworkcontext"><code><c- g="">NeuralNetworkContext</c-></code></dfn> {
  // Create an Operand object that represents a model input.
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand‚ë†"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="input(name, desc)" id="dom-neuralnetworkcontext-input"><code><c- g="">input</c-></code><a href="#dom-neuralnetworkcontext-input"></a></dfn>(<a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString" id="ref-for-idl-DOMString‚ë†"><c- b="">DOMString</c-></a> <dfn data-dfn-for="NeuralNetworkContext/input(name, desc)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-input-name-desc-name"><code><c- g="">name</c-></code><a href="#dom-neuralnetworkcontext-input-name-desc-name"></a></dfn>, <a data-link-type="idl-name" href="#dictdef-operanddescriptor" id="ref-for-dictdef-operanddescriptor"><c- n="">OperandDescriptor</c-></a> <dfn data-dfn-for="NeuralNetworkContext/input(name, desc)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-input-name-desc-desc"><code><c- g="">desc</c-></code><a href="#dom-neuralnetworkcontext-input-name-desc-desc"></a></dfn>);

  // Create an Operand object that represents a model constant.
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand‚ë°"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="constant(desc, value)" id="dom-neuralnetworkcontext-constant"><code><c- g="">constant</c-></code><a href="#dom-neuralnetworkcontext-constant"></a></dfn>(<a data-link-type="idl-name" href="#dictdef-operanddescriptor" id="ref-for-dictdef-operanddescriptor‚ë†"><c- n="">OperandDescriptor</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(desc, value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-desc-value-desc"><code><c- g="">desc</c-></code><a href="#dom-neuralnetworkcontext-constant-desc-value-desc"></a></dfn>, <a data-link-type="idl-name" href="https://heycam.github.io/webidl/#ArrayBufferView" id="ref-for-ArrayBufferView"><c- n="">ArrayBufferView</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(desc, value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-desc-value-value"><code><c- g="">value</c-></code><a href="#dom-neuralnetworkcontext-constant-desc-value-value"></a></dfn>);

  // Create a single-value tensor from the specified number of the specified type.
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand‚ë¢"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="constant(value, type)|constant(value)" id="dom-neuralnetworkcontext-constant-value-type"><code><c- g="">constant</c-></code><a href="#dom-neuralnetworkcontext-constant-value-type"></a></dfn>(<a data-link-type="idl-name" href="#typedefdef-number" id="ref-for-typedefdef-number"><c- n="">number</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(value, type), NeuralNetworkContext/constant(value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-value-type-value"><code><c- g="">value</c-></code><a href="#dom-neuralnetworkcontext-constant-value-type-value"></a></dfn>, <c- b="">optional</c-> <a data-link-type="idl-name" href="#enumdef-operandtype" id="ref-for-enumdef-operandtype‚ë†"><c- n="">OperandType</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(value, type), NeuralNetworkContext/constant(value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-value-type-type"><code><c- g="">type</c-></code><a href="#dom-neuralnetworkcontext-constant-value-type-type"></a></dfn> = "float32");

  // Create a Model object by identifying output operands.
  <c- b="">Promise</c->&lt;<a data-link-type="idl-name" href="#model" id="ref-for-model"><c- n="">Model</c-></a>&gt; <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="createModel(outputs)" id="dom-neuralnetworkcontext-createmodel"><code><c- g="">createModel</c-></code><a href="#dom-neuralnetworkcontext-createmodel"></a></dfn>(<c- b="">sequence</c->&lt;<a data-link-type="idl-name" href="#dictdef-namedoperand" id="ref-for-dictdef-namedoperand"><c- n="">NamedOperand</c-></a>&gt; <dfn data-dfn-for="NeuralNetworkContext/createModel(outputs)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-createmodel-outputs-outputs"><code><c- g="">outputs</c-></code><a href="#dom-neuralnetworkcontext-createmodel-outputs-outputs"></a></dfn>);
};
</pre>
   <h4 data-level="3.5.1" id="api-neuralnetworkcontext-batchnorm"><span>3.5.1. </span><span>batchNormalization</span><a href="#api-neuralnetworkcontext-batchnorm"></a></h4>
    Normalize the tensor values across dimensions in a batch through a specialized <a data-link-type="biblio" href="#biblio-batchnorm">[BatchNorm]</a> <a href="https://en.wikipedia.org/wiki/Batch_normalization#Batch_Normalizing_Transform">transform</a>. The <em>mean</em> and <em>variance</em> tensors are previously calculated during model training pass. 
<pre><c- b="">partial</c-> <c- b="">interface</c-> <a data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext‚ë°"><c- g="">NeuralNetworkContext</c-></a> {
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand‚ë£"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="batchNormalization(input, mean, variance, scale, bias, axis, epsilon)|batchNormalization(input, mean, variance, scale, bias, axis)|batchNormalization(input, mean, variance, scale, bias)|batchNormalization(input, mean, variance, scale)|batchNormalization(input, mean, variance)" id="dom-neuralnetworkcontext-batchnormalization"><code><c- g="">batchNormalization</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization"></a></dfn>(<a data-link-type="idl-name" href="#operand" id="ref-for-operand‚ë§"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-input"><code><c- g="">input</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-input"></a></dfn>, <a data-link-type="idl-name" href="#operand" id="ref-for-operand‚ë•"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-mean"><code><c- g="">mean</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-mean"></a></dfn>, <a data-link-type="idl-name" href="#operand" id="ref-for-operand‚ë¶"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-variance"><code><c- g="">variance</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-variance"></a></dfn>, 
                             <c- b="">optional</c-> <a data-link-type="idl-name" href="#operand" id="ref-for-operand‚ëß"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-scale"><code><c- g="">scale</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-scale"></a></dfn>, <c- b="">optional</c-> <a data-link-type="idl-name" href="#operand" id="ref-for-operand‚ë®"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-bias"><code><c- g="">bias</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-bias"></a></dfn>, 
                             <c- b="">optional</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long‚ë°"><c- b="">long</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-axis"><code><c- g="">axis</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-axis"></a></dfn> = 1, <c- b="">optional</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float‚ë†"><c- b="">float</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-epsilon"><code><c- g="">epsilon</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-epsilon"></a></dfn> = 1e-5);
};
</pre>
   <div data-algorithm="batchnorm">
     <p><strong>Arguments:</strong></p><ul>
     <li data-md="">
      <p><em>input</em>: an <code><a data-link-type="idl" href="#operand" id="ref-for-operand‚ë†‚ì™">Operand</a></code>. The input N-D tensor.</p>
     </li><li data-md="">
      <p><em>mean</em>: an <code><a data-link-type="idl" href="#operand" id="ref-for-operand‚ë†‚ë†">Operand</a></code>. The 1-D tensor of the batch mean values
whose length is equal to the size of the input dimension denoted by <em>axis</em>.</p>
     </li><li data-md="">
      <p><em>variance</em>: an <code><a data-link-type="idl" href="#operand" id="ref-for-operand‚ë†‚ë°">Operand</a></code>. The 1-D tensor of the batch variance values
whose length is equal to the size of the input ‚Ä¶</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://webmachinelearning.github.io/webnn/">https://webmachinelearning.github.io/webnn/</a></em></p>]]>
            </description>
            <link>https://webmachinelearning.github.io/webnn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649616</guid>
            <pubDate>Thu, 01 Oct 2020 11:18:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Supporting a misbehaving NAND ECC engine in the Linux kernel]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649565">thread link</a>) | @pabs3
<br/>
October 1, 2020 | https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/ | <a href="https://web.archive.org/web/*/https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-13845">
	<!-- .entry-header -->

	
	
	<div>
		<p>Over the years, Bootlin has grown a significant expertise in U-Boot and Linux support for flash memory devices. Thanks to this expertise, we have recently been in charge of rewriting and upstreaming a driver for the <a href="https://www.arasan.com/products/nand-flash/">Arasan NAND controller</a>, which is used in a number of <a href="https://www.xilinx.com/products/silicon-devices/soc.html">Xilinx Zynq SoCs</a>. It turned out that supporting this NAND controller had some interesting challenges to handle its ECC engine peculiarities. In this blog post, we would like to give some background about ECC issues with NAND flash devices, and then dive into the specific issues that we encountered with the Arasan NAND controller, and how we solved them.</p>

<p>NAND flash memories are known to be intrinsically rather unstable: over time, external conditions or repetitive access to a NAND device may result in the data being corrupted. This is particularly true with newer chips, where the number of corruptions usually increases with density, requiring even stronger corrections. To mitigate this, Error Correcting Codes are typically used to detect and correct such corruptions, and since the calculations related to ECC detection and correction are quite intensive, NAND controllers often embed a dedicated engine, the ECC engine, to offload those operations from the CPU.</p>
<p>An ECC engine typically acts as a DMA master, moving, correcting data and calculating syndromes on the fly between the controller FIFO‚Äôs and the user buffer. The engine correction is characterized by two inputs: the size of the data chunks on which the correction applies and the strength of the correction. Old SLC (Single Level Cell) NAND chips typically require a strength of 1 symbol over 4096 (1 bit/512 bytes) while new ones may require much more: 8, 16 or even 24 symbols.</p>
<p>In the write path, the ECC engine reads a user buffer and computes a code for each chunk of data. NAND pages being longer than officially advertised, there is a persistent Out-Of-Band (OOB) area which may be used to store these codes. When reading data, the ECC engine gets fed by the data coming from the NAND bus, including the OOB area. Chunk by chunk, the engine will do some math and correct the data if needed, and then report the number of corrected symbols. If the number of error is higher than the chosen strength, the engine is not capable of any correction and returns an error.</p>

<p>As explained in our introduction, as part of our work on upstreaming the Arasan NAND controller driver, we discovered that this NAND controller IP has a specific behavior in terms of how it reports ECC results: the hardware ECC engine never reports errors. It means the data may be corrected or uncorrectable: the engine behaves the same. From a software point of view, this is a critical flaw and fully relying on such hardware was not an option.</p>
<p>To overcome this limitation, we investigated different solutions, which we detail in the sections below.</p>
<h2>Suppose there will never be any uncorrectable error</h2>
<p>Let‚Äôs be honest, this hypothesis is highly unreliable. Besides that anyway, it would imply that we do not differentiate between written/erased pages and users would receive unclean buffers (with bitflips), which would not work with upper layers such as UBI/UBIFS which expect clean data.</p>
<h2>Keep an history of bitflips of every page</h2>
<p>This way, during a read, it would be possible to compare the evolution of the number of bitflips. If it suddenly drops significantly, the engine is lying and we are facing an error. Unfortunately it is not a reliable solution either because we should either trigger a write operation every time a read happens (slowing down a lot the I/Os and wearing out very quickly the storage device) or loose the tracking after every power cycle which would make this solution very fragile.</p>
<h2>Add a CRC16</h2>
<p>This CRC16 could lay in the OOB area and help to manually verify the data integrity after the engine‚Äôs correction by checking it against the checksum. This could be acceptable, even if not perfect in term of collisions. However, it would not work with existing data while there are many downstreams users of the vendor driver already.</p>
<h2>Use a bitwise XOR between raw and corrected data</h2>
<p>By doing a bitwise XOR between raw and corrected datra, and compare with the number of bitflips reported by the engine, we could detect if the engine is lying on the number of corrected bitflips. This solution has actually been implemented and tested. It involves extra I/Os as the page must be read twice: first with correction and then again without correction. Hence, the NAND bus throughput becomes a limiting factor. In addition, when there are too many bitflips, the engine still tries to correct data and creates bitflips by itself. The result is that, with just a XOR, we cannot discriminate a working correction from a failure. The following figure shows the issue.</p>
<p><a href="https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips.png"><img loading="lazy" src="https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-1024x460.png" alt="Show the engine issue when it creates bitflips when trying to correct uncorrectable data" width="840" height="377" srcset="https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-1024x460.png 1024w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-300x135.png 300w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-768x345.png 768w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-1200x539.png 1200w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips.png 1458w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"></a></p>
<h2>Rely on the hardware only in the write path</h2>
<p>Using the hardware engine in the write path is fine (and possibly the quickest solution). Instead of trying to workaround the flaws of the read path, we can do the math by software to derive the syndrome in the read path and compare it with the one in the OOB section. If it does not match, it means we are facing an uncorrectable error. This is finally the solution that we have chosen. Of course, if we want to compare software and hardware calculated ECC bytes, we must find a way to reproduce the hardware calculations, and this is what we are going to explore in the next sections.</p>

<p>There is already a BCH library in the Linux kernel on which we could rely on to compute BCH codes. What needed to be identified though, were the BCH initial parameters. In particular:</p>
<ul>
<li>The BCH primary polynomial, from which is derived the generator polynomial. The latter is then used for the computation of BCH codes.</li>
<li>The range of data on which the derivation would apply.</li>
</ul>
<p>There are several thousands possible primary polynomials with a form like <code>x^3 + x^2 + 1</code>. In order to represent these polynomials more easily by software, we use integers or binary arrays. In both cases, each bit represents the coefficient for the order of magnitude corresponding to its position. The above example could be represented by <code>b1101</code> or <code>0xD</code>.</p>
<p>For a given desired BCH code (ie. the ECC chunk size and hence its corresponding Gallois Field order), there is a limited range of possible primary polynomials which can be used. Given <code>eccsize</code> being the amount of data to protect, the Gallois Field order is the smallest integer <code>m</code> so that: <code>2^m &gt; eccsize</code>. Knowing <code>m</code>, one can check <a href="https://www.partow.net/programming/polynomials/index.html">these tables</a> to see examples of polynomials which could match (non exhaustive). The Arasan ECC engine supporting two possible ECC chunk sizes of 512 and 1024 bytes, we had to look at the tables for <code>m = 13</code> and <code>m = 14</code>.</p>
<p>Given the required strength <code>t</code>, the number of needed parity bits <code>p</code> is: <code>p = t x m</code>.</p>
<p>The total amount of manipulated data (ECC chunk, parity bits, eventual padding) <code>n</code>, also called BCH codeword in papers, is: <code>n = 2^m - 1</code>.</p>
<p>Given the size of the codeword <code>n</code> and the number of parity bits <code>p</code>, it is then possible to derive the maximum message length <code>k</code> with: <code>k = n - p</code>.</p>
<p>The theory of BCH also shows that if <code>(n, k)</code> is a valid BCH code, then <code>(n - x, k - x)</code> will also be valid. In our situation this is very interesting. Indeed, we want to protect <code>eccsize</code> number of symbols, but we currently cover <code>k</code> within <code>n</code>. In other words we could use the translation factor <code>x</code> being: <code>x = k - eccsize</code>. If the ECC engine was also protecting some part of the OOB area, <code>x</code> should have been extended a little bit to match the extra range.</p>
<p>With all this theory in mind, we used GNU Octave to <a href="https://github.com/miquelraynal/find-bch-prim-poly/blob/master/find_bch_polynomial.m">brute force the BCH polynomials</a> used by the Arasan ECC engine with the following logic:</p>
<ul>
<li>Write a NAND page with a <code>eccsize</code>-long ECC step full of zeros, and another one full of ones: this is our known set of inputs.</li>
<li>Extract each BCH code of <code>p</code> bits produced by the hardware: this is our known set of outputs.</li>
</ul>
<p>For each possible primary polynomial with the Gallois Field order <code>m</code>, we derive a generator polynomial, use it to encode both input buffers thanks to a regular BCH derivation, and compare the output syndromes with the expected output buffers.</p>
<p>Because the GNU Octave program was not tricky to write, we first tried to match with the output of Linux software BCH engine. Linux using by default the primary polynomial which is the first in GNU Octave‚Äôs list for the desired field order, it was quite easy to verify the algorithm worked.</p>
<p>As unfortunate as it sounds, running this test with the hardware data did not gave any match. Looking more in depth, we realized that visually, there was something like a matching pattern between the output of the Arasan engine and the output of Linux software BCH engine. In fact, both syndromes where identical, the bits being swapped at byte level by the hardware. This observation was made possible because the input buffers have the same values no matter the bit ordering. By extension, we also figured that swapping the bits in the input buffer was also necessary.</p>
<p>The primary polynomial for an <code>eccsize</code> of 512 bytes being already found, we ran again the program with <code>eccsize</code> being 1024 bytes:</p>
<p><code>     eccsize =  1024<br>
     eccstrength =  24<br>
     m =  14<br>
     n =  16383<br>
     p =  336<br>
     k =  16047<br>
     x =  7855<br>
     Trying primary polynomial #1: 0x402b<br>
     Trying primary polynomial #2: 0x4039<br>
     Trying primary polynomial #3: 0x4053<br>
     Trying primary polynomial #4: 0x405f<br>
     Trying primary polynomial #5: 0x407b<br>
     [...]<br>
     Trying primary polynomial #44: 0x43c9<br>
     Trying primary polynomial #45: 0x43eb<br>
     Trying primary polynomial #46: 0x43ed<br>
     Trying primary polynomial #47: 0x440b<br>
     Trying primary polynomial #48: 0x4443<br>
     Primary polynomial found! 0x4443</code></p>

<p>With the two possible primary polynomials in hand, we could finish the support for this ECC engine.</p>
<p>At first, we tried a ‚Äúmixed-mode‚Äù solution: read and correct the data with the hardware engine and then re-read the data in raw mode. Calculate the syndrome over the raw data, derive the number ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/">https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/</a></em></p>]]>
            </description>
            <link>https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649565</guid>
            <pubDate>Thu, 01 Oct 2020 11:08:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Deep Learning Toolchain]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649488">thread link</a>) | @rosshemsley
<br/>
October 1, 2020 | https://rosshemsley.co.uk/posts/deep_learning_toolchain/ | <a href="https://web.archive.org/web/*/https://rosshemsley.co.uk/posts/deep_learning_toolchain/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
Successful model development can be surprisingly dependent on good engineering practices. Despite this, many model implementations scattered about Github are difficult to follow and hard to recreate locally.
</p>

<p>
But what should a <em>good model</em> look like? I would propose that the gold standard for a model implemented on Github could be:
</p>
<ol>
<li> The dependencies may be installed automatically, using a single command.</li>
<li> I can build the model in a sandbox without polluting with my dev. environment.</li>
<li> I can easily retrain (and retune!) the model the model exactly as the author did during their development.</li>
<li> I can easily test the inference pass.</li>
<li> I can easily import the model into my own workflow and use it as part of my own code.</li>
</ol>
<p>
It may be that I've never come across a model that met this standard in practical day-to-day development...! But I claim that achieving these things is surprisingly easy given the modern tools available to us.
</p>
<p>
Furthermore, many may simply respond "just ship everything in a Docker container". My response to this is that Docker is a great tool for
<em>deploying</em> a stable, reproducible environment, but Docker images provide a poor basis for sharing code and enabling collaboration.
In this post, we'll focus on designing models that can be <em>installed and imported with a single command, without Docker, on any OS, on any platform,
using the vanilla tools our language provides</em>.
</p>
<p>
So, let's dive in and look at the tools that I use to train models, and how they can be used to meet the gold standard I gave above.
</p>

<h2>Python 3 for model development</h2>
<p><img src="https://rosshemsley.co.uk/posts/deep_learning_toolchain_images/python_logo.png"></p><p>
It may not be controversial these days, but it's worth highlighting that Python 3 is an excellent choice for prototyping and releasing deep learning models. The key feature here is the library support, which is unmatched by other languages.
I tend to target <strong>Python 3.7.5</strong> or later, because I make heavy use of <em><a href="https://docs.python.org/3/library/dataclasses.html">dataclass</a></em>, and it's recent enough to support type annotations. Ubuntu Focal now includes Python 3.8 by default,
so many users will start being able to support this out of the box.
</p>
<h3>Bonus pionts: type annotations</h3>
<p>
If you use type annotations (correctly) in your model, you will get serious points from me.
It's very common that models use native lists, tensors, and numpy arrays almost interchangeably as function
arguments, and so using type hints can make the data flow in your model easier to follow and debug.
</p>
<div><pre><code data-lang="python"><span>from</span> dataclasses <span>import</span> dataclass
<span>from</span> typing <span>import</span> List, Optional

<span>import</span> numpy <span>as</span> np
<span>from</span> PIL <span>import</span> Image

<span>@dataclass</span>
<span>class</span> <span>DataSample</span>:
    img: Image
    bboxes: List[np<span>.</span>ndarray]
    scores: Optional[List[float]]

<span>...</span>

sample <span>=</span> DataSample(Image(), [np<span>.</span>array([<span>1</span>,<span>2</span>,<span>3</span>,<span>4</span>])], scores<span>=</span>None)</code></pre></div>
<p><em><strong>Above:</strong> an example of using modern Python features to write a clear and simple data container
for a training sample in a model. The dataclass decorator adds all of the utility functions we may want (including
a pretty string reprsentation so we can print the object), and the type annotations make it clear what the user 
should expect the fields to contain.</em></p><h2> Use <em>pyenv</em> to manage Python versions</h2>
<p>
For better or worse, many incompatible versions of Python now exist, and it's easy to get
in a tangle with different Python installs, especially when making system-wide changes.
</p>
<p>
My advice here is to do it properly, and do it once: learn to use <em>pyenv</em> to manage all of your Python
installs.
</p>
<p>
Pyenv is a tool that provides a shim around the <em>python</em> command which redirects it to the correct version 
of Python for the current context. For a given project, you can use <em>pyenv local 3.7.5</em> in a directory
to tell pyenv to use Python 3.7.5 from now on when calling Python in that directory.
</p>
<p>
If you don't have the version of Python installed that you need, you can use pyenv to install it.
If the universe is feeling good to you today, <em>pyenv install 3.7.5</em> should be sufficient to fetch and install Python 3.7.5
for you automatically on any platform.
</p>
<p>
<strong>In practice</strong>, things don't always go so smoothly with pyenv, however I really believe
it's really worth the hassle of spending the time and getting it working - most issues you might enouncter are well understood, and documented on stackoverflow.
</p>
<h3>A few common tips for common pyenv issues</h3>
<ul>
<li><strong>It's not working!</strong> - make sure you have activated it (google "pyenv activate"). Typically you need to add this to e.g. your .bashrc</li>
<li><strong><em>pyenv install</em> failed!</strong> - you may be missing system dependencies. Be patient, and trawl stackoverflow. It can be made to work!</li>
</ul>


<h2>Use <em>poetry</em> to manage your project and dependencies</h2> 
<p>
Keeping your Python project sandboxed is crucial aspect of remaining sane when using Python.
We typically use <em>virtualenvs</em>, or virtual environments, to achieve this. These are are essentially directories containing their own
Python install, and a local copy of all the packages your project needs. 
</p>
<p>
A separate but related problem is ensuring you actually <em>have</em> the dependencies your project needs
installed into that virtualenv. 
</p>
<p>
Once upon a time, you may have used `virtualenv` and `requirements.txt` or `anaconda` or `pipenv` to do these things.
</p>
<p>
Well, my advice is <strong>steer clear from all of them</strong> and move straight to <a href="https://python-poetry.org/">poetry</a>.
It's very much the new kid on the block, but from my perspective it's already miles ahead of the competition.
I have managed to deploy a number of complex Python applications in a professional capacity using
poetry, and I have found it both plays very well with other tools and is generally well designed.
</p>
<p>
Poetry uses the modern <a href="https://snarky.ca/what-the-heck-is-pyproject-toml/">pyproject.toml</a> way of defining a package, and this essentially replaces the old setup.py and friends.
It would be out of scope to explain why pyproject.toml is important and worth learning about, so I recommend some googling here!
</p>
<p>
Ok, so let's create a new project! ... don't forget to `pyenv local 3.7.5` first, to ensure you are using the correct version of Python (if you forgot, you can run it later, and then go
back and edit pyproject.toml to make sure it's set correctly.)
</p>

<p>
Yes, it's as easy as that. Go ahead and move in the directory poetry created for you, and you can now
</p>
<p>
and poetry will automatically create a managed virtualenv for you. Let's now install some of the tools of our trade,
</p><div><pre><code data-lang="bash">$ poetry add torch
$ poetry add numpy</code></pre></div>
<p>
Poetry will install them to the virtualenv and add them to the pyproject.toml. It will 
also <strong>pin</strong> the exact versions of the dependencies into a lock file so that <strong>other users installing your package
can reproduce precisely the same environment as you</strong>. This is perhaps the most important step here, and is worth underscoring:
this is how we are able to achieve <em>reproducibility</em>. 
</p>
<h3>The Best Bit About Poetry</h3>
<p>
Poetry was designed to be good at both developing packages and <em>building/sharing/publishing</em> them.
These latter features are sorely missing from other tools (such as pyenv), and they are really the killer
feature of poetry.
</p>
<p>
Let's suppose you pushed your <em>fancynet</em> package to github (don't forget to check in the lock file!).
Now, <strong>anyone using a recent version of pip can install your package with a single command</strong>,
</p><div><pre><code data-lang="bash">$ pip install git+https://github.com/myusername/fancynet</code></pre></div>
<p>
Pip will fetch the code from github, look into the pyproject.toml, see it uses poetry, and then just do
everything for you, including installing poetry, and fetching the correct versions of the pinned dependencies!
<strong>
This is totally magic and not enough people know this trick.</strong> Go forth and spread this knowledge!
</p>
<p>
If your package reaches a level of maturity where you'd like to publish it to a public package repository (e.g. pypi),
you can use poetry to manage this. To bump the version (you can also bump the minor and major versions this way), use
</p><p>
Then to build and publish to pypi, use
</p><div><pre><code data-lang="bash">$ poetry build
$ poetry publish</code></pre></div><p>
The defaults used by poetry are spookily well designed, and I have never had any problems publishing packages in this way.
</p>

<h2>Use <em>click</em> to manage your entrypoint</h2> 
<p>
An oft-overlooked step in building a good python package is organising the files and "entrypoints" (or "executables"). 
I believe it's worth imagining that someone else is going to use your code at somepoint, and so I try to create nicely named
subdirectories for each part of my model: "datasets", "models", "inference", but also <strong>"cli"</strong>.
In this "cli" directory, I usually have several subdirectories "train", "tune", "test". Each of these contains a single
"__main__.py", which contains the (small!) shim code needed to perform those actions.
</p>
<p>
Inside "__main__.py" I then use <a href="https://click.palletsprojects.com/en/7.x/">click</a> to manage arguments and the entrypoint.
I have found it much easier to use than argparse, and I do think it's worth the effort!
</p>
<div><pre><code data-lang="python"><span>import</span> click
<span>from</span> omegaconf <span>import</span> OmegaConf
<span>from</span> pytorch_lightning <span>import</span> Trainer

<span>from</span> mynet.models <span>import</span> MyNet

<span>@click.command</span>()
<span>@click.option</span>(<span>'--dataset-root-dir'</span>, help<span>=</span><span>'directory containing the dataset'</span>)
<span>@click.option</span>(<span>'--config-path'</span>, default<span>=</span><span>"config.yaml"</span>, help<span>=</span><span>'The config file to use.'</span>)
<span>def</span> <span>train</span>(dataset_root_dir: str, config_path: str):
    cfg <span>=</span> OmegaConf<span>.</span>load(config_path)

    model <span>=</span> MyNet(cfg)
    trainer <span>=</span> Trainer(gpus<span>=</span><span>1</span>, profiler<span>=</span>True)
    trainer<span>.</span>fit(model)

<span>if</span> __name__ <span>==</span> <span>'__main__'</span>:
    train()</code></pre></div>
<p>
Now, if we are developing locally, we can run this using
</p><div><pre><code data-lang="bash">$ poetry run python -m mynet.cli.train --dataset-root-dir /foo/bar/baz</code></pre></div><p>
Which is fine and good, but if we want to go 10X, we can also use a neat future of project.toml and add an entrypoint
</p><div><pre><code data-lang="toml">[<span>tool</span>.<span>poetry</span>.<span>scripts</span>]
<span>train</span> = <span>"mynet.cli.train.__main__:train"</span></code></pre></div><p>
Once we do this, users can run training using
</p><div><pre><code data-lang="bash">$ poetry run train --dataset-root-dir /foo/bar/baz</code></pre></div><p>
or if you "activate" the environment, simply
</p><div><pre><code data-lang="bash">$ train --dataset-root-dir /foo/bar/baz</code></pre></div>

<p>
It's possible to add multiple entrypoints to the pyproject.toml, so you can easily create one for training, tuning, testing.
This is helpful for users trying to discover how to train or evaluate your model from scratch!
</p>
<p>
Do note that if a user installs your package into a shared virtualenv, you may wish to choose a more meaningful name than train!
</p>

<h2>Use <em>pytorch</em> to develop your net</h2>
<p></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rosshemsley.co.uk/posts/deep_learning_toolchain/">https://rosshemsley.co.uk/posts/deep_learning_toolchain/</a></em></p>]]>
            </description>
            <link>https://rosshemsley.co.uk/posts/deep_learning_toolchain/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649488</guid>
            <pubDate>Thu, 01 Oct 2020 10:54:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PowerShell Universal v1.4]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649270">thread link</a>) | @l33t_d0nut
<br/>
October 1, 2020 | https://blog.ironmansoftware.com/powershell-universal-1-4/ | <a href="https://web.archive.org/web/*/https://blog.ironmansoftware.com/powershell-universal-1-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main"><div><h2>PowerShell Universal v1.4</h2><h4>September 30, 2020</h4><p>I‚Äôm pleased to announce another feature-packed <a href="https://ironmansoftware.com/powershell-universal">PowerShell Universal</a> release! Today, we‚Äôre releasing version 1.4 of the ultimate platform for building web-based IT tools. This release contains an extensive list of features as well as bug fixes. This blog post will go over them but I encourage you to <a href="https://ironmansoftware.com/downloads">download or upgrade</a> to take full advantage of everything that has been added.</p><h2 id="release-notes">Release Notes</h2><p>Full release notes can be found <a href="https://docs.ironmansoftware.com/changelog">here</a>.</p><h2 id="downloads">Downloads</h2><ul><li><a href="https://imsreleases.blob.core.windows.net/universal/production/1.4.0/PowerShellUniversal.1.4.0.msi">Windows MSI</a></li><li><a href="https://imsreleases.blob.core.windows.net/universal/production/1.4.0/Universal.win-x64.1.4.0.zip">Windows ZIP</a></li><li><a href="https://imsreleases.blob.core.windows.net/universal/production/1.4.0/Universal.linux-x64.1.4.0.zip">Linux ZIP</a></li><li><a href="https://hub.docker.com/r/ironmansoftware/universal">Docker</a></li></ul><h2 id="platform">Platform</h2><h3 id="environments">Environments</h3><p>We‚Äôve extended the concept of PowerShell Versions and replaced it with Environments. Environments allow you to specify the executable, arguments, modules and variables that are defined whenever you execute an API request, run a job or host a dashboard. The execution environment will automatically create a runspace pool with the assets you define so there is no need to import them every time.</p><p>We‚Äôve standardized environments across all features and now you can select which environment is used in each place.</p><p><a href="https://docs.ironmansoftware.com/config/environments">Learn more about Environments</a></p><p><img src="https://blog.ironmansoftware.com/images/environments.png" alt=""></p><h3 id="windows-authentication-with-iis">Windows Authentication with IIS</h3><p>You can now configure Windows Authentication without IIS. IIS can complicate deployments and if it‚Äôs not something you need, you can now avoid it by simply installing Universal as a service and configuring Windows authentication.</p><p><a href="https://docs.ironmansoftware.com/config/security#windows-authentication-outside-of-iis">Learn more about Windows Authentication without IIS</a></p><h2 id="apis">APIs</h2><h3 id="rate-limiting">Rate Limiting</h3><p>We‚Äôve added the ability to configure rate limiting for APIs. This is an important feature for anyone that may be exposing their API publicly or may call a sensitive resource that you do not want to overload. You can configure rate limits based on HTTP method, endpoint (or pattern), and the number of requests over a period of time.</p><p><a href="https://docs.ironmansoftware.com/api/rate-limiting">Learn more about Rate Limiting</a></p><p><img src="https://blog.ironmansoftware.com/images/ratelimit.png" alt=""></p><h3 id="connection-information">Connection Information</h3><p>You‚Äôll have access to more connection information in your endpoints. Variables are now defined for Local IP Address, Remote IP Address, Local Port and Remote Port.</p><h3 id="updated-endpoint-page">Updated Endpoint Page</h3><p>We‚Äôve enhanced the API page to provide a neat in-browser experience for developing your API. This includes the ability to test your APIs directly in the browser.</p><p><img src="https://blog.ironmansoftware.com/images/apis.png" alt=""></p><h2 id="automation">Automation</h2><h3 id="continuous-schedules">Continuous Schedules</h3><p>You can now define continuous schedules that will run a job over and over again with a configurable delay. It won‚Äôt start another job until the previous one has finished.</p><p><a href="https://docs.ironmansoftware.com/automation/schedules#continuous">Learn more about Scheduling</a></p><p><img src="https://blog.ironmansoftware.com/images/continuous-schedule.png" alt=""></p><h3 id="variables">Variables</h3><p>Variables are now global for the entire Universal platform. By default, your existing Environments will import all variables but you can define specific variables or patterns to use in an environment. This change shouldn‚Äôt affect your jobs but be aware that variables are no longer present only present in jobs but present in any one of the features using an Environment.</p><p><a href="https://docs.ironmansoftware.com/automation/variables">Learn more about Variables</a></p><h2 id="dashboard">Dashboard</h2><h3 id="role-based-access">Role-based Access</h3><p>We‚Äôve added the ability to assign roles to dashboards and pages in the v3 framework. If you assign a role to a dashboard, only users of that role will have access to the entire dashboard. When you assign roles to a page in a dashboard, any authenticated user will be able to access the dashboard but only users in the specified role will have access to the pages.</p><p><a href="https://docs.ironmansoftware.com/dashboard/role-based-access">Learn more about Role-Based Access in Dashboards</a></p><h3 id="chartjs">ChartJS</h3><p>We‚Äôve brought back ChartJS support. This was the primary chart library in UDv2. Many users preferred this library over our Nivo charts integration so we have decided to include it. We‚Äôve also simplified the API to make it even easier to build charts.</p><p><a href="https://docs.ironmansoftware.com/dashboard/components/data-visualization/charts#chartjs">Learn more about ChartJS integration</a></p><p><img src="https://blog.ironmansoftware.com/images/chartjs.png" alt=""></p><h3 id="improved-navigation">Improved Navigation</h3><p>We‚Äôve simplified and extended the built in navigation. You can now more easily define your navigation items for a page. We also support a persistent layout that does not require a click of a hamburger menu to open the navigation.</p><p><a href="https://docs.ironmansoftware.com/dashboard/components/pages#navigation">Learn more about Navigation</a></p><p><img src="https://blog.ironmansoftware.com/images/permanent-drawer.png" alt=""></p><h3 id="redesigned-dashboard-page">Redesigned Dashboard Page</h3><p>The dashboard page has been redesigned to make it easier to see an overview of the dashboards running in your environment.</p><p><img src="https://blog.ironmansoftware.com/images/new-dashboards.png" alt=""></p><h2 id="get-started-now">Get Started Now</h2><p>PowerShell Universal is free to try. <a href="https://ironmansoftware.com/downloads">Download now</a> and start building tools with your existing PowerShell scripts. Please feel free to join our <a href="https://forums.universaldashboard.io/">growing community</a>.</p></div></div></div>]]>
            </description>
            <link>https://blog.ironmansoftware.com/powershell-universal-1-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649270</guid>
            <pubDate>Thu, 01 Oct 2020 10:11:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You can drive more traffic and engagement with content amplification]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649266">thread link</a>) | @JamesConverge
<br/>
October 1, 2020 | https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification | <a href="https://web.archive.org/web/*/https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><strong>Content amplification is one of the most underused&nbsp;pieces of the&nbsp;content marketing puzzle.</strong></p>
<p><strong>Hands down.</strong></p>
<p><span>So many businesses create great content, but then they only publish that content on their own website, and maybe share it once or twice on social media.</span></p>
<p><span>Sorry to break it to you, but with millions of other businesses doing the same thing, that isn't going to help you cut through the noise.&nbsp;</span></p>
<p><span>At all.&nbsp;</span></p>
<p><span>And hoping that someone will just stumble across your content isn‚Äôt a good strategy, either.&nbsp;</span></p>
<p><span>In reality, you need to <strong>AMPLIFY YOUR CONTENT</strong></span><span>.</span></p>
<p><span>Without content amplification, your hard work and effort will remain essentially ‚Äúon the shelf collecting dust".</span></p>
<p><span>Creating content is less than half the battle. If you don't have a distribution, or amplification strategy for your content, then you're missing out on more traffic, more awareness, more backlinks, better SEO and a more engaged audience.</span></p>
<p><span>And, of course, all of the above <em>usually</em> lead to additional commercial benefits such as more customers and more sales.</span></p>
<p><span>In this article, we‚Äôre going to break down content amplification, tell you what it is, how it works, and how you can get the most out of it so your content can start to work harder and more effectively for you.&nbsp;</span></p>
<p><span>We‚Äôre going to answer the most common questions we get that relate to content amplification, such as:</span></p>
<ul>
<li><span>What is content amplification?</span></li>
<li><span>Why is content amplification so important?</span></li>
<li><span>How can I build a content amplification strategy?</span></li>
</ul>
<p><span>But enough with the preamble. Let‚Äôs jump in and get right into the good stuff.&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Mark%20Masters.jpg" alt="" width="1600" height="150"></span></p>
<p><em>"The reason we shy away from content distribution or amplification is that it feels far better to be creative and produce, than it is to encourage people to watch/listen/read, as this side takes far more effort. Then again, the reason we are creating is to motivate people and get them to subscribe, enquire, interact and buy.</em></p>
<p><em>What is really important is to have something to say that can be amplified. Distribution channels work really well, once you have something to distribute. So, make sure that your message links to your values and that can strike a chord with others. This is how you find your allies, make sure your work is seen and people want to feel a part of it and prepared to stand with you."&nbsp;</em></p>
<p><strong><em>Mark Masters - <a href="https://www.wearethemedia.co.uk/">We Are The Media</a></em></strong></p>
<p>What is content amplification, and why is it so important?</p>
<p><span>Content amplification is the act of promoting and distributing your content across multiple channels (paid, owned and earned) so you can increase the reach and impact of both your content and your brand.</span></p>
<p><span>However, amplifying your content does more than simply provide your brand with additional exposure. It also allows you to position yourself as a thought leader, and build valuable backlinks, as well as build relationships, and increase both engagement and conversion rates with your target audience.&nbsp;</span></p>
<p><span>There are many different ways to amplify content. Paying to promote your content on Facebook or Twitter, leveraging influencers to promote your content, publishing your content on </span><a href="https://promos.converge.today/join-converge"><span>other platforms with an already captivated audience</span></a><span> - they‚Äôre all different ways to amplify your content, and we‚Äôll get into them in a bit more detail later on.</span></p>
<p><span>Without amplification, it‚Äôll be much more difficult for you to get the results you want from your content.&nbsp;</span></p>
<p><span>Every single day, there are</span><a href="https://www.worldometers.info/blogs/"><span> millions of new blogs published</span></a><span>. Yes, not all of them will be competing with what you‚Äôve created, but that‚Äôs a lot of potential noise getting in the way of your message. And organic reach is getting lower and lower all the time.</span></p>
<p><span>Because organic reach across the board is down, way down, when it comes to creating content - and you may be producing the best stuff out there - the likelihood is that without amplifying your content, it‚Äôs not going to perform well.&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Cathy%20McPhillips.jpg" alt="" width="1600" height="150"></span></p>
<p><em>‚ÄúYou‚Äôve written an amazing article ‚Äì and now what? You can‚Äôt expect the results to happen without some distribution work on your end. This includes content amplification ‚Äì a multi-channel approach to increase your brand‚Äôs reach. It‚Äôs taking your owned media, and combining it with paid and earned media. It‚Äôs really knowing the right places ‚Äì and people ‚Äì to help amplify your message to your audience.</em></p>
<p><em>Through content amplification, you‚Äôre able to extend your reach into new areas you couldn‚Äôt achieve on your own through organic methods. It‚Äôs getting out of your echo chamber of your current customers and brand loyalists and finding new and relevant customers who wouldn‚Äôt have necessarily heard of you otherwise. Amplification done right brings customers to you who didn‚Äôt yet know how much they needed you.</em></p>
<p><strong><em>Cathy McPhillips - <a href="http://contentmarketinginstitute.com/">Content Marketing Institute</a></em></strong></p>
<p>The problem with organic traffic</p>
<p><span>OK, that‚Äôs a little misleading. There is no problem with organic traffic.</span></p>
<p><span>The problem lies with the expectations people have when it comes to organic traffic. And, frankly, the delusion that generating it is both a) easily achievable and, b) that it is the only traffic source worth aiming for.&nbsp;</span></p>
<p><span>Nope.</span></p>
<p><span>Listen, organic traffic is great. It‚Äôs wonderful. If you‚Äôre getting huge organic traffic and your website and blogs are appearing right at the top of search results for your most relevant and valuable keywords and phrases, then brilliant! You‚Äôve smashed it already.&nbsp;</span></p>
<p><span>Chances are, though, that‚Äôs not the case. Because, 1) only a handful of businesses across the entire planet can claim to have achieved the above. And it‚Äôs a constant battle for them to remain at the top. And, 2) organic reach is in decline </span><a href="https://blog.hootsuite.com/organic-reach-declining/"><span>across the board</span></a><span>.</span></p>
<p><span>We‚Äôre not saying achieving a first page ranking on Google for your content is impossible, but it may take both time and resources that you currently don‚Äôt have to get there. So, before you become a high-ranking Google superstar, you must find another way to get eyeballs on your content.</span></p>
<p><span>You need to amplify content so you can generate the consistent traffic and backlinks you need to get it the awareness and engagement it deserves, and to get it started on the long, arduous climb towards the first page of search results.&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Abby%20Sorensen.jpg" alt="" width="1600" height="150"></span></p>
<p><em>‚ÄúImagine this scenario at the most important trade show in your industry - Your sales team picks up their badges and heads for the show floor, eager to make connections and meet potential buyers. Your product/service is the exact right fit for these prospects, and your message has been carefully crafted to resonate with them. But your booth is set up at the empty convention center across town. Maybe you were trying to stretch your budget. Or maybe you thought your product/service was so exciting that buyers would go out of their way to find you. Your sales team heads back to the office empty-handed, a complete waste of time and energy spent setting up your booth where your buyers were not.</em></p>
<p><em>This is exactly what happens when you create content with no plan to distribute it.<strong> Only a select few companies can afford to buy their way to the top of Google‚Äôs search rankings.</strong> The only way to get the most out of your content is to distribute it where your buyers are likely to be. And while your website might be the most strategized, optimized, digitized, mobilized website in your market, your buyers simply are not likely to spend a great deal of time there (especially if you hit them with gates and form-fills).‚Äù</em></p>
<p><strong><em>Abby Sorensen - <a href="https://www.followyourbuyer.com/">Follow Your Buyer</a></em></strong></p>
<p>Creating content is less than half the battle</p>
<p><span>That‚Äôs right. All that time you spent researching, planning, creating and publishing content is less than half of what‚Äôs required to give your content the best chance of generating the return on investment you want from it.&nbsp;</span></p>
<p><span>Depending on who you talk to and the articles you read, you may have heard people saying content creation is anywhere from 20-40% of the job.</span></p>
<p><span>The rest of it? You guessed it; amplification/distribution/promotion - whatever you call it. Whatever it takes to get your content in front of everyone you want to read it.</span></p>
<p><span>But let‚Äôs not get bogged down in specific percentages. The only thing you need to know is that you need to spend more time promoting your hard work than you do creating it. Because the competition for attention is fierce, and you need to cut through the noise and make sure people are actually engaging with your content. Otherwise why spend the time creating it in the first place?&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Alexandra%20Cote.jpg" alt="" width="1600" height="150"></span></p>
<p><em>"Beyond simply creating a really good post, you'll also need really great content amplification methods in place. In fact, everything that happens AFTER you publish a piece of content is much more important than the post itself. This is because sharing content across appropriate channels and talking about your findings and products gets your brand in front of more people.</em></p>
<p><em>This being said, content amplification is the core driver behind reaching your business goals and hitting your KPIs. Whether you want to improve your brand awareness, get more qualified leads, gain new partnerships, or just position yourself as a thought leader in the industry, content amplification can help you hit those targets. Do remember to stay away from vanity metrics though. Just because a lot of people like a post of yours on LinkedIn doesn't mean they read your article and it's a far cry from them actually making a purchase.</em></p>
<p><em>The best advice I have to ensure you're seeing real results from your content amplification techniques is to choose the right networks and websites to promote your content. You'll first need a clear image of your buyer persona. By analyzing potential customers and their behavior, you'll see where they spend most of their time and, above all, what determines them to make a purchase decision. Then, all you have to do is craft the right messaging revolving around the benefits they're looking to get and stay consistent on a couple of networks of choice. Feel free to include the same terms and pain points they use and remember to be responsive so the conversation is bidirectional."</em></p>
<p><strong><em><a href="https://mktodyssey.wordpress.com/">Alexandra Cote</a>, B2B and SaaS Content Writer and SEO Strategist</em></strong></p>
<p>Building a content amplification strategy</p>
<p><span>Of course, it‚Äôs easy ‚Ä¶</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification">https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification</a></em></p>]]>
            </description>
            <link>https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649266</guid>
            <pubDate>Thu, 01 Oct 2020 10:10:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why are secrets in Git such a threat?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649034">thread link</a>) | @oodelally
<br/>
October 1, 2020 | https://www.gitguardian.com/secrets-detection/secret-sprawl | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection/secret-sprawl">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>What are secrets in the software development world?</p><div><p>In the common language, a secret can be any sensitive data that we want to keep private. When discussing secrets in the context of software development, secrets generally refer to digital authentication credentials that grant access to systems or data. These are most commonly API keys, usernames and passwords, or security certificates.</p><p>Secrets exist in the context of applications that are no longer standalone monoliths. Applications nowadays rely on thousands of independent building blocks: cloud infrastructure, databases, SaaS components such as Stripe, Slack, HubSpot‚Ä¶&nbsp;</p><p>Secrets are what tie together these different building blocks of a single application by creating a secure connection between each component.</p></div><p>What is secret sprawl?</p><div><p>Secret sprawl is the unwanted distribution of secrets like API keys and credentials through multiple systems.&nbsp;</p><p>In modern software development, secrets are regularly used by developers and applications. As a result they often get shared through different services like Slack or email and can be stored in multiple locations including different machines, git repositories or inside company wikis. This is a phenomenon we call secret sprawl.</p></div><p>What are some of the best practices to securely manage secrets like API keys?</p><div><p>Storing and managing secrets like API keys and other credentials can be challenging. Even the most careful policies can sometimes be circumvented in exchange for convenience. We have put together a helpful <a href="https://blog.gitguardian.com/secrets-api-management/" target="_blank">cheat sheet</a> and article explaining the <a href="https://blog.gitguardian.com/secrets-api-management/" target="_blank">best practices for managing secrets</a>.</p><p>As a minimum here are some points you should consider:</p></div><div><p>Never store unencrypted secrets in git repositories</p></div><div><p>Avoid git add * commands on git</p></div><div><p>Add sensitive files in .gitignore</p></div><div><p>Don‚Äôt rely on code reviews to discover secrets</p></div><div><p>Use automated secrets scanning on repositories</p></div><div><p>Don‚Äôt share your secrets unencrypted in messaging systems like Slack</p></div><div><p>Store secrets safely (method to be used depends on every use case)</p></div><div><p>Default to minimal permission scope for APIs</p></div><div><p>Whitelist IP addresses where appropriate</p></div><p>What are the threats associated with secret sprawl?</p><div><p>When secrets are sprawled through multiple systems it increases what is referred to as the ‚Äòattack surface‚Äô. This is the amount of points where an unauthorized user could gain access to your systems or data. In the case of secret sprawl, each time a secret enters another system it is another point where an attacker could gain access to your secrets.</p><p>Most internal systems are not an appropriate place to store sensitive information, even if those systems are private. No company wants credit card numbers in plaintext in databases, PII in application logs, bank account credentials in a Google Doc. Secrets benefit from the same kind of protective measures.</p><p>As a general security principle, where feasible, data should remain safe even if it leaves the devices, systems, infrastructure or networks that are under organizations‚Äô control, or if they are compromised. This helps prevent credential stealing, which is a well-known adversary technique described in the MITRE ATT&amp;CK framework:</p></div><p>‚Äú Adversaries may search local file systems and remote file shares for files containing passwords. These can be files created by users to store their own credentials, shared credential stores for a group of individuals, configuration files containing passwords for a system or service, or source code/ binary files containing embedded passwords. ‚Äù<br></p><p>Secrets accessed by malicious threat actors can lead to information leakage and allow lateral movement or privilege escalation, as secrets very often lead to other secrets. Furthermore, once an attacker has the credentials to operate like a valid user, it is extremely difficult to detect the abuse and the threat can become persistent.<br></p><p>What are some of the biggest challenges associated with secret sprawl?</p><div><p>Because secrets tie together each component of an application, developers and ops need access to these secrets to build, connect, test and deploy applications. The result is that secrets need to be both tightly wrapped and also widely distributed. </p><p>Enforcing good security practices at the organization level is hard. Developers today can have large turnovers inside companies, be spread through many different teams and geographies. They have a growing number of technologies they must master and are under hard pressure due to shortened release cycles. This makes secret management very complicated and an ever changing challenge. </p><p>This is further complicated when VCS like git are introduced because secrets can be buried deep inside the history. The actual version of source code might look clean, while the history might present credentials that were added than later removed. Any secret reaching the Version Control System must be considered compromised and the presence of valid secrets in the git history presents a threat!</p></div></div></div>]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection/secret-sprawl</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649034</guid>
            <pubDate>Thu, 01 Oct 2020 09:27:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is it hard to detect API keys in source code?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24649026">thread link</a>) | @oodelally
<br/>
October 1, 2020 | https://www.gitguardian.com/secrets-detection/how-to-detect-secrets-in-source-code | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection/how-to-detect-secrets-in-source-code">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Why is it hard to detect secrets like API keys and other credentials?</p><div><p>Secrets detection is probabilistic‚Äîthat is to say that it is not always possible to determine what is a true secret (or true positive). Because secrets share very few common, distinctive factors, decisions must be taken by aggregating weak signals to make strong predictions. </p><p>One of the most common factors is that almost all secrets are strings that look random. We call these strings high entropy strings. The issue is that this common factor is not very distinctive: 99% of strings that look random in source code aren‚Äôt secrets. They are for example database IDs or other types of false positives. </p><p>Of course, some secrets have fixed patterns: AWS keys often start with AKIA for example. But most secrets do not. The portions of code surrounding them are also very different, depending on what the secrets are used for and how they are used by the developers in the context of specific applications. Usernames and passwords can be used to authenticate in many different ways, and it is really hard to distinguish between real and fake credentials used as placeholders for example. </p><p>All this makes it extremely challenging to accurately capture all true secrets without also capturing false positives. At some point, a line in the sand needs to be drawn that considers the cost of a secret going undetected (a false negative) and compares it to the outcome that too many false positives would create. Different organizations with different people, cultures and workflows will draw different lines!</p></div><p>Why do code reviews fail at finding secrets in source code?</p><p>Code reviews are great overall for detecting logic flaws or maintaining certain good coding practices. But they are not adequate protection for detecting secrets, mostly for two reasons:<br></p><div><p>Reviews generally only consider the net difference between the current and proposed states. Not the entire history of changes. If a commit adds a secret and another one later deletes it, this has a zero net effect that is not of any interest to reviewers. But the vulnerability is there.</p></div><div><p>Reviewers prefer to focus on errors that cannot be automatically detected, like design flaws. As a general principle, security automation should be implemented wherever it can be, so that humans focus on where they bring the most value.</p></div><p>What is a "good" secrets detection algorithm?</p><div><p>Detecting secrets in source code is like finding needles in a haystack: there are a lot more sticks than there are needles, and you don‚Äôt know how many needles might be in the haystack. In the case of secrets detection, you don‚Äôt even know what all the needles look like!</p><p>Ideally, you want your detection system to achieve at the same time:</p></div><div><p>A low number of false alerts raised. We call this high precision. Precision answers the question: ¬´What is the percentage of the secrets that you detect that are actual secrets?¬ª. This question is perfectly legitimate, especially in the context of security teams being overwhelmed with too many alerts.</p></div><div><p>A low number of secrets missed. This is what we call high recall. Considering that a single undetected credential can have a big impact for an organization, some organizations prefer to triage more false alerts but make sure they don‚Äôt miss a secret.</p></div><p>Balancing the equation to ensure that the algorithm captures as many secrets as possible without flagging too many false results is an intricate and extremely difficult challenge. Read more on evaluating <a href="https://blog.gitguardian.com/secrets-detection-accuracy-precision-recall-explained/" target="_blank">secrets detection algorithms</a>.<br></p><p>What is a false positive in secrets detection?</p><div><p>A false positive in secrets detection refers to when a secret candidate is wrongly marked as a true secret when it is in fact a non-sensitive string. </p><p>Typical examples of strings that can be mistaken for true secrets are:</p></div><div><p>UUIDs (Universally Unique Identifiers) that are used for example by databases as unique keys.</p></div><div><p>High entropy URLs or file paths. They often contain random strings that look like keys.</p></div><p>Examples of server-side hooks:<br></p><div><p>Test keys. Service Providers sometimes provide developers with a set of test credentials with a very restricted scope so developers can exercise parts of the API without charging their account</p></div><div><p>Public keys. As surprising as it is, a very small number of keys are really meant to be public (like Firebase keys, see this Stack Overflow <a href="https://stackoverflow.com/questions/37482366/is-it-safe-to-expose-firebase-apikey-to-the-public" target="_blank">conversation</a>).</p></div><p>Are secrets detection algorithms language-dependent?</p><p>Secrets detection is, for the most part, not language specific. Of course, there are some subtleties to take into account, like the way variables are assigned in any programming language. But there is no need to support all the different syntaxes in their greatest details. This means that the same algorithms can be applied to any project, in any programming language, without using things like Abstract Syntax Trees.<br></p></div></div>]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection/how-to-detect-secrets-in-source-code</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649026</guid>
            <pubDate>Thu, 01 Oct 2020 09:26:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why automate secrets scanning throughout your SDLC?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649022">thread link</a>) | @oodelally
<br/>
October 1, 2020 | https://www.gitguardian.com/secrets-detection/secrets-detection-application-security | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection/secrets-detection-application-security">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>My source code is private, so why is hardcoding credentials in git considered a bad practice?</p><div><p>While private repositories offer some level of protection for your code they still do not have adequate protection to store information as sensitive as secrets. </p><p>Imagine if there was a plain text file with all your credit card numbers within it, you hopefully wouldn‚Äôt put this into the companies git repository. Secrets are just as sensitive.</p><p>A few things to consider when storing secrets in private repositories:</p></div><div><p>Source code is made to be duplicated and distributed, therefore lives in multiple places. Source code is a leaky asset and you never know where it is going to end up. It can be cloned to a compromised workstation or server, intentionally or accidentally published in whole or in part, uploaded to your website, released to a customer, pasted in Slack, or end up in your package manager or mobile application...</p></div><div><p>It would just take one compromised developer account to compromise all the secrets they have access to.</p></div><div><p>Hardcoded credentials make it impossible to know what secrets a developer accessed, and very difficult to rotate keys.</p></div><p>Why automate secrets scanning throughout the Software Development Life Cycle (SLDC)?</p><p>While DevOps, Continuous Integration and Continuous Delivery speed up software development, they can also significantly increase security risks.<br></p><p>‚ÄúDevOps is rapid and requires lots of small, iterative changes. But this increases complexity and opens up a new set of security problems. With DevOps, existing security vulnerabilities can be magnified and manifest themselves in new ways. The speed of software creation can mean new vulnerabilities are created unseen by developers. The solution is to build security monitoring into the DevOps process from the start.‚Äù<br></p><p>Greg Day, RSA Conference Organizer (<a href="https://www.securityroundtable.org/the-biggest-cybersecurity-risks-in-2020/" target="_blank">source</a>)<br></p><p>Security now needs to be part of the SDLC from the start, and part of every incremental change. This concept is called Shifting Left, a development principle which states that security should move from the right (or end) of the SDLC to the left (the beginning). A great deal of automation is needed in order to be able to cope with running security checks at each incremental change. &nbsp;Automation helps streamline the detection, alerting and remediation processes and workflows.<br></p><p>How does secrets detection compare with Static Application Security Testing (SAST)?</p><div><p>Secrets detection is often confused with SAST because both scan through static source code. </p><p>SAST is mostly testing control structure, input validation, error handling, etc. Such vulnerabilities like SQL injection vulnerabilities only express themselves the moment the code is deployed. Exposed secrets are unlike these vulnerabilities, because any secret reaching version control system must be considered compromised and requires immediate attention. This is true even if the code is never deployed. </p><p>Implementing secrets detection is not only about scanning the most actual version of your master branch before deployment. It is also about scanning through every single commit of your git history, covering every branch, even development or test ones.</p><p>To conclude, SAST is concerned only with the current version of a project, the version that is going to be deployed, whereas secrets detection is concerned with the entire history of the project.</p></div><p>What are git hooks?</p><div><p>Git hooks are scripts that are triggered by certain actions in the software development process, like committing or pushing. By automatically pointing out issues in code, they allow reviewers not to waste time on mistakes that can be easily diagnosed by a machine. </p><p>There are client-side hooks, that execute locally on the developers‚Äô workstation, and server-side hooks, that execute on the centralized version control system.</p><p>Examples of client-side hooks:</p></div><p>Examples of server-side hooks:<br></p><p>What is a pre-commit hook?</p><div><p>"The pre-commit hook is run first when committing, before you even type in a commit message. It‚Äôs used to inspect the snapshot that‚Äôs about to be committed, to see if you‚Äôve forgotten something, to make sure tests run, or to examine whatever you need to inspect in the code. </p><p>Exiting non-zero from this hook aborts the commit, although you can bypass it with <span>git commit --no-verify</span>. You can do things like check for code style (run lint or something equivalent), check for trailing whitespace, or check for appropriate documentation on new methods."</p></div><p>Source: <a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks" target="_blank">git-scm</a><br></p><p>What is a pre-receive hook?</p><div><p>A pre-receive hook is a script that runs on the server. It performs checks on the content of the push; if it exits non-zero, the push is rejected. You can use this hook to do things like prevent a PR author from merging their own changes, or require commit messages to follow some specific guidelines. </p><p>Be careful when using pre-receive hooks as they are blocking: if the checks don‚Äôt pass, the server is not updated.</p></div><p>What is a post-receive hook?</p><p>"The post-receive hook runs after the entire process of pushing code to the server is completed and can be used to update other services or notify users. Examples include emailing a list, notifying a continuous integration server, or updating a ticket-tracking system ‚Äì you can even parse the commit messages to see if any tickets need to be opened, modified, or closed. This script can‚Äôt stop the push process, but the client doesn‚Äôt disconnect until it has completed, so be careful if you try to do anything that may take a long time."<br></p><p>Source: <a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks" target="_blank">git-scm</a><br></p><p>Unlike the pre-receive hook, post-receive is non-blocking.<br></p><p>Where in the DevOps pipeline to implement automated secrets scanning? Client-side or server-side?</p><div><p>The earlier a security vulnerability is uncovered, the less costly it is to correct. Hardcoded secrets are no exceptions. If the secret is uncovered after the secret reaches centralized version control server-side, it must be considered compromised, which requires rotating (revoking and redistributing) the exposed credential. This operation can be complex and typically involves multiple stakeholders.</p><p>Client-side secrets detection early in the software development process is a nice-to-have as it will prevent secrets entering the VCS earlier. </p><p>Server-side secrets detection is a must have:</p></div><div><p>&nbsp;Server-side is where the ultimate threat lies. From the server, the code can uncontrollably spread in a lot of different places, with the hardcoded secrets in it.</p></div><div><p>Implementing client-side hooks on an organization level is hard. This is something we have heard many application security professionals claim they are not confident to do, due to the difficulty to deploy and update this on every developer‚Äôs workstation.</p></div><div><p>Client-side hooks can and must be easy to bypass (remember secret detection is probabilistic). Usage of client side hooks largely comes down to the individual developers‚Äô responsibility. Hence the need to have visibility over the later stages.</p></div><p>Should secrets detection be blocking or non-blocking in the SDLC?</p><div><p>From our experience, when trying to impose rules that are too constraining, people will bend them, often in an effort to collaborate better and do their job. Security must not be a blocker. It should allow flexibility and enable information to flow, yet enable visibility and control. </p><p>On one hand, security measures will be bypassed, sometimes for the worst. But on the other hand, it is also good sometimes that the developer can take the responsibility to bypass them. </p><p>Because even the best algorithms can fail and need human judgement. Secrets detection is probabilistic: algorithms achieve a tradeoff between not raising false alerts and not missing keys.</p></div></div></div>]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection/secrets-detection-application-security</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649022</guid>
            <pubDate>Thu, 01 Oct 2020 09:25:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paralyzed Dutch man can temporarily move and talk again thanks to sleeping pill]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24648831">thread link</a>) | @jacquesm
<br/>
October 1, 2020 | https://www.world-today-news.com/paralyzed-dutch-man-can-temporarily-move-and-talk-again-thanks-to-sleeping-pill-now/ | <a href="https://web.archive.org/web/*/https://www.world-today-news.com/paralyzed-dutch-man-can-temporarily-move-and-talk-again-thanks-to-sleeping-pill-now/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>A Dutch man who has been unable to move and speak for eight years due to brain damage, can temporarily do so after taking the sleeping drug Zolpidem.  Brain scans show that the sleeping pill removes an obstacle to these actions, scientists from Radboudumc and Amsterdam UMC report Thursday.</p>
<p>In men, the brain activity for moving and talking is drowned out by the brain activity for the transfer of information.</p>
<p>‚ÄúYou could compare the brain, as it were, to a large string orchestra‚Äù, explains fellow researcher Hisse Arnts.  ‚ÄúWith Richard (the man, ed.) The first violins play so loud that they drown out the other members of the string orchestra and people can no longer hear each other. Zolpidem ensures that these first violins play more ‚Äòpianissimo‚Äô, so that everyone back within time. ‚Äú</p>
<p>The fact that the man does not go to sleep because of Zolpidem is probably due to the way his brain has become confused, Arnts thinks.  The problem, however, is that the man gets used to the sleeping aid, so that the effect becomes shorter and shorter.  Yet he still receives it regularly and the discovery is a promising starting point for further research.</p>
<p>The man is not the first to return to a normal situation briefly with such a means;  there are similar reports from Italy and South Africa.  But how that is possible has now been determined for the first time on the basis of scans, according to the medical centers.</p>

<p>The man, in his late twenties at the time, suffered a severe lack of oxygen eight years ago due to choking.  He ended up in a nursing home with the very rare diagnosis of akinetic mutism.  Because Richard‚Äôs situation seemed hopeless, it was decided to give him the remedy.</p>

</div><p>    .</p></div>]]>
            </description>
            <link>https://www.world-today-news.com/paralyzed-dutch-man-can-temporarily-move-and-talk-again-thanks-to-sleeping-pill-now/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648831</guid>
            <pubDate>Thu, 01 Oct 2020 08:48:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asteroids: By the Numbers]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24648639">thread link</a>) | @rbanffy
<br/>
October 1, 2020 | http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1 | <a href="https://web.archive.org/web/*/http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-3855344372715435262"><p>
By 1979, arcade games were rapidly becoming more complex and colorful, and a game like <i>Asteroids </i>might have seemed quaint by comparison to the likes of <i><a href="http://www.retrogamedeconstructionzone.com/2019/09/galaxian-aesthetics-of-simple-patterns.html">Galaxian</a>, <a href="http://www.retrogamedeconstructionzone.com/2019/09/star-fire-weirdness-of-pseudo-3d.html">Star Fire</a></i>, or <i>Radar Scope.&nbsp; </i>But beneath its simple exterior lies a challenging shooter with surprisingly complex physics.&nbsp; The image below shows a sample still from it, including the player's ship (the triangle on the left), three sizes of asteroids, and an alien ship.</p><p><a href="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s1600/Asteroids_sample%2B%25282%2529.png"><img data-original-height="461" data-original-width="598" height="492" src="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s640/Asteroids_sample%2B%25282%2529.png" width="640"></a></p>

<p>
The goal of the game is to maximize your score, destroying as many asteroids and aliens as possible before you run out of ships.&nbsp; When an asteroid is hit by something (usually the player's bullets), large asteroids turn into two medium ones and medium asteroids turn into two small ones, while small asteroids and aliens are destroyed when hit.</p><p><a href="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s1600/Asteroids%2BPlay.gif"><img data-original-height="357" data-original-width="600" height="237" src="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s400/Asteroids%2BPlay.gif" width="400"></a></p>
<p>
For the designers of the game, balancing the relative sizes of the objects would have been important in such a dense field, because it determines how often things run into one another other.&nbsp; The table below outlines the sizes of the objects in <i>Asteroids</i>, expressed relative to the length of the player's ship.</p><table>
<caption>The approximate horizontal lengths of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Length (in player ship lengths)</th>
    </tr>
<tr>
    <td>Screen</td>
    <td>25 x 36</td>
    </tr>
<tr>
    <td>Large Asteroids</td>
    <td>2.4</td>
    </tr>
<tr>
    <td>Medium Asteroid</td>
    <td>1.2</td>
    </tr>
<tr>
    <td>Small Asteroid</td>
    <td>0.6</td>
    </tr>
<tr>
    <td>Alien Ship (large)</td>
    <td>1.5</td>
    </tr>
<tr>
    <td>Alien Ship (small)</td>
    <td>0.75</td>
    </tr>
</tbody>
    </table>
<p>
Notice how the medium asteroid is twice the size of the small one, and the large is twice the size of the medium.&nbsp; If you think about it, this doesn't actually make much physical sense -- you can break a two-dimensional object into four pieces half its size, not two.&nbsp; But the size ratios do make game sense, because what really matters to the player is not how much area an asteroid takes up, but how likely it is to hit them.</p><p><a href="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"><img data-original-height="281" data-original-width="170" src="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"></a></p>

<p>
In the picture above, you can see that while the four small asteroids take up less area on the screen than the big one, they present the same cross section to your ship.&nbsp; This means that breaking up the asteroids doesn't greatly increase the probability that the player will be struck by one.&nbsp; If the asteroids had been broken up into four half-sized pieces at each blow, each large asteroid would result in sixteen small ones (that's four times the cross section!) and the player would be quickly overwhelmed.&nbsp; Note that the small asteroids do move faster than the large ones, and speed increases the chance of getting hit, but I'll return to that in a moment.</p>

<p>
Another big reason that size matters in <i>Asteroids</i>&nbsp;is that it determines how close something has to be before you're likely to be able to hit it.&nbsp; In 1979, vector arcade cabinet screens had an effective resolution of 1024 x 768, and the player's ship was only connected graphically by about 20 points.&nbsp; This meant, in turn, that there were only a limited number of orientations that they could render for the ship, in this case intervals of 5 degrees.&nbsp; To see how this might affect gameplay, imagine your ship is located at the fixed position shown in the picture below.&nbsp; Anything located entirely between the two solid lines will not be accessible by your bullets because your ship can't turn to the appropriate angle to hit it.&nbsp; This restriction isn't a big deal for large asteroids, which are still accessible over most of the screen, but small asteroids can be out of reach of your guns at relatively close range, sometimes as close as 7 ship lengths away!&nbsp; So even if you aim as accurately as possible, chances are you won't be able to hit a small asteroid on the other side of the screen, at least not on your first shot.&nbsp; This is probably one of the reasons that <i>Asteroids</i>&nbsp;allows you to fire up to four bullets in succession: even if you can't hit an object right away, it will eventually move into your line of fire.</p>

<p><a href="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s1600/Asteroids_hittable%2B%25285%2529.png"><img data-original-height="397" data-original-width="1024" height="248" src="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s640/Asteroids_hittable%2B%25285%2529.png" width="640"></a></p>
<p>
And what about speed?&nbsp; There is some variability in the speeds of individual asteroids, but small asteroids can move as much as 63% faster than large ones (see the table below), meaning that even if four small asteroids present the same cross section for hitting your ship as a large one does, their higher speed means they're more likely to hit you.&nbsp; The reasoning for this is simple: the faster something moves, the longer the path it can traverse in a given amount of time, and the larger the likelihood that you'll be in that path.&nbsp; Fortunately, even the fastest asteroids are much slower than your ship, which can traverse the screen in about two seconds; so if you're skilled enough, you should be able to maneuver around the asteroid field without a problem.</p><table>
<caption>The approximate speeds of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Speed (in ship lengths per second)</th>
    </tr>
<tr>
    <td>Your ship</td>
    <td>0 - 17</td>
    </tr>
<tr>
    <td>Asteroids</td>
    <td>4 - 6.5</td>
    </tr>
<tr>
    <td>Alien ships (both sizes)</td>
    <td>4 - 6.5 (depending on your score)</td>
    </tr>
<tr>
    <td>Bullets</td>
    <td>17 (ship at rest)&nbsp;</td></tr>
</tbody></table>
<p>
One other interesting thing about speed: notice in the table above that the speed of a bullet, when fired at rest, is the same as your ship's maximum speed.&nbsp; This means that when you're moving rapidly and fire a bullet in the opposite direction of your motion, the two speeds should cancel for a stationary observer and the bullet should appear roughly stationary.</p>

<p><a href="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s1600/Asteroids_bullet_stationary.gif"><img data-original-height="175" data-original-width="468" height="239" src="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s640/Asteroids_bullet_stationary.gif" width="640"></a></p>


<div><p>
Sure enough, when I fire a bullet while moving quickly in the opposite direction, it just floats near where I fired it, allowing me to place bullets like mines for the asteroids to run into.</p>
<p>
The developers of <i>Asteroids </i>wanted the game to simulate the real laws of physics (<a href="http://www.technologyuk.net/computing/computer-gaming/gaming-landmarks-1960-1985/asteroids.shtml">see here</a>), and I think in many respects they succeeded, at least compared to most other arcade games of the time.&nbsp; It's not entirely realistic, however.&nbsp; In my article on <a href="http://www.retrogamedeconstructionzone.com/2019/10/impossible-motion-in-video-games.html">motion in early arcade games</a>, I discussed how the acceleration of the ship in <i>Asteroids</i> is too rapid for a human-occupied vehicle.&nbsp; We might suppose that the vehicle is automated, but even then, engineering spacecraft to withstand 30+ g's of acceleration is a non-trivial challenge.</p><p><a href="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s1600/Acceleration%2BAsteroids.gif"><img data-original-height="175" data-original-width="634" height="176" src="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s640/Acceleration%2BAsteroids.gif" width="640"></a></p>
<p>
Another issue is the way the asteroids break up.&nbsp; In physics, there's a principle called the conservation of momentum that says that when objects interact with one another or break apart, the total mass times the velocity must remain the same after the interaction as it was before.&nbsp; In layman's terms, this means that things can't suddenly go from moving one direction to moving in another unless there is something else carry its previous momentum.&nbsp; In the example shown below, an asteroid does just that, and the only thing that could have absorbed its previous momentum is the bullet.&nbsp; But the bullet is so tiny that it's difficult to imagine how that would be possible.</p><p><a href="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s1600/Asteroids_momentum.gif"><img data-original-height="248" data-original-width="533" height="185" src="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s400/Asteroids_momentum.gif" width="400"></a></p>

<p>
These are mere quibbles, however, and shouldn't dissuade you from giving the game a try.&nbsp; <i>Asteroids </i>ended up being one of Atari's biggest arcade hits, selling over 70,000 cabinets, and remains one of their most recognizable games to this day.&nbsp; Many gamers who grew up in the '80s, myself included, are more familiar with the Atari 2600 version of the game.&nbsp; Unfortunately, the designers had to make a lot of sacrifices in game physics in order to make it work on a home console, so I think the arcade version is really the way to go.&nbsp; Outside of visiting a vintage arcade, your best bet is probably the <a href="https://www.mamedev.org/">Multiple Arcade Machine Emulator</a> (MAME).&nbsp; Happy hunting!</p></div><div><p><span>NOTE: &nbsp;A previous version of this article stated that the game has limited pixel resolution, but <i>Asteroids </i>uses a vector display that is not composed of pixels. &nbsp;The resolution of the <i>Asteroids </i>vector display is 1024 x 768.</span></p><p><a href="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s1600/Asteroids_loop_transparent.gif"><img data-original-height="151" data-original-width="600" height="160" src="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s640/Asteroids_loop_transparent.gif" width="640"></a></p>
<br></div>
</div>
</div></div>]]>
            </description>
            <link>http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648639</guid>
            <pubDate>Thu, 01 Oct 2020 08:15:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russian opposition leader Alexei Navalny describes his poisoning with Novichok]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24648502">thread link</a>) | @FrojoS
<br/>
October 1, 2020 | https://www.spiegel.de/international/world/alexei-navalny-thanks-germany-and-describes-his-poisoning-with-novichok-a-f1249540-76f7-43ce-aa14-358d71256684 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/alexei-navalny-thanks-germany-and-describes-his-poisoning-with-novichok-a-f1249540-76f7-43ce-aa14-358d71256684">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;83eb2320-0da2-4c9c-971a-560530cea088&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;02c7d434-33a6-4d2b-a553-72392b2db9bd&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/83eb2320-0da2-4c9c-971a-560530cea088_w948_r1.77_fpx28.11_fpy49.98.jpg" srcset="https://cdn.prod.www.spiegel.de/images/83eb2320-0da2-4c9c-971a-560530cea088_w520_r1.77_fpx28.11_fpy49.98.jpg 520w, https://cdn.prod.www.spiegel.de/images/83eb2320-0da2-4c9c-971a-560530cea088_w948_r1.77_fpx28.11_fpy49.98.jpg 948w" width="948" height="536" sizes="948px" title="Alexei Nawalny" alt="Alexei Nawalny">
</span>
</span>
</span>

</p>
<figcaption>
<p>Alexei Nawalny</p>
<span>
Foto:‚ÄÇPeter Rigaud&nbsp;/ DER SPIEGEL
</span>
</figcaption>
</figure>
</div><div>
<p>In his first media interview following his poisoning, Russian opposition leader Alexei Navalny expresses his "tremendous gratitude to all Germans" in an interview with the newsmagazine DER SPIEGEL. In the interview, he says that although he never had close ties to Germany, it was German politicians and Chancellor Angela Merkel who saved his life. He says the doctors at Berlin's Charit√© University Hospital saved his life for a second time and nursed him back to health. "I know it sounds a bit over the top, but Germany has become a special country for me," Navalny says. Describing the personal visit paid to him by Merkel last week, he says: "I was impressed by the detail she knows about <a href="https://www.spiegel.de/thema/russia_en/" data-link-flag="english">Russia</a> and my case."</p>



<section data-area="contentbox">

</section>
<p>Navalny says he is doing "much better than three weeks ago, and things are getting better each day." The doctors say he could get back to 90 percent of his former self, perhaps even 100 percent, although no one knows for sure. "Basically, I‚Äôm a bit of a guinea pig," he says. "There aren‚Äôt many people you can observe who are still alive after being poisoned with a nerve agent." Describing the moment in the airplane when the poison started to take effect, Navalny says: "You feel no pain, but you know you‚Äôre dying. And I mean, right now. Even though nothing hurts you." You just think: This is the end. "Organophosphorus compounds attack your nervous system like a DDos attack attacks the computer - it's an overload that breaks you," he told DER SPIEGEL.</p>

<div>
<p>"I assert that <a href="https://www.spiegel.de/thema/vladimir_putin_en/" data-link-flag="english">Putin</a> was behind the crime, and I have no other explanation for what happened." Despite the attempt on his life, he says he wants to return to Russia. "And my job now is to remain the guy who isn‚Äôt afraid. And I‚Äôm not afraid! When my hands shake, it‚Äôs not from fear ‚Äì it‚Äôs from this stuff. I would not give Putin the gift of not returning to Russia."</p><p>When asked whether he thinks Germany should stop the completion of the Nord Stream 2 Russian gas pipeline project, Navalny didn‚Äôt want to answer. "That‚Äôs Germany‚Äôs business. Decide for yourself!" Any strategy toward Russia must "take into account the level of insanity that Putin has reached."</p>
</div>

<div>
<p><em>The full interview with Navalny will be posted in English later today.</em></p>
<p><span><svg aria-labelledby="title-b3ab4652-e428-41a8-a973-570c15e33654" width="10" height="20" viewBox="0 0 10 20" fill="none" xmlns="http://www.w3.org/2000/svg" role="img"><title id="title-b3ab4652-e428-41a8-a973-570c15e33654">Icon: Der Spiegel</title><g id="l-s-flag-b3ab4652-e428-41a8-a973-570c15e33654"><path id="vector-b3ab4652-e428-41a8-a973-570c15e33654" d="M9.85 16.293v-8H3.212V4.667h3.533v2.24h3.212v-3.2C9.85 2.747 8.993 2 8.03 2H1.713C.749 2 0 2.747 0 3.707v7.253h6.638v4.373H3.105v-2.986H0v3.84c0 .96.75 1.706 1.713 1.706H8.03c.963.107 1.82-.64 1.82-1.6z" fill="#000"></path></g></svg>
</span>
</p></div>

</div>
</section>

</div></div>]]>
            </description>
            <link>https://www.spiegel.de/international/world/alexei-navalny-thanks-germany-and-describes-his-poisoning-with-novichok-a-f1249540-76f7-43ce-aa14-358d71256684</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648502</guid>
            <pubDate>Thu, 01 Oct 2020 07:54:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Baremetal programming on the tinyAVR 0 micro-controllers]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 94 (<a href="https://news.ycombinator.com/item?id=24648397">thread link</a>) | @unwind
<br/>
October 1, 2020 | https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers | <a href="https://web.archive.org/web/*/https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><section><div><h4>All you need is a text editor, a makefile and a USB-serial cable.</h4></div></section><section><div><p><img src="https://www.omzlo.com/uploads/std_attiny-406-macro.jpg" alt=""></p>

<h2 id="introduction">Introduction</h2>

<p>Are you an 8-bit or a 32-bit programmer? </p>

<p>At OMZLO, we have been mainly focussing our development efforts on newer 32-bit Arm-Cortex chips (STM32 and SAMD), which typically offer more RAM, more speed, more peripherals, at a similar or lower price-point than older 8-bit MCUs. But 8-bit MCUs are far from dead. Microchip has notably released a new series of chips, collectively branded as the "tinyAVR 0-series", which offer more modern peripherals than the older AVR chips at a very competitive price point. They seem like the perfect candidate for simple products that don't need all the features and fine-tuning capabilities of the newer 32-bit MCUs. 8-bit MCUs are also substantially simpler to program, which translates into faster development time. </p>

<p>Thanks to the success of the Arduino UNO, there are tons of tutorials online that explain how to program 8-bit Atmega328 microcontrollers and their cousins like the Attiny85 using direct register access, without the Arduino language or any vendor IDE such as Atmel Studio. Just google "atmega328 blinky". All you need is an AVR C-compiler, a text editor, <a href="https://www.nongnu.org/avrdude/">avrdude</a>, and an AVR programmer. Some <a href="https://www.instructables.com/id/Getting-Started-With-the-ATMega328P/">resources</a> even show how to also build the electronics needed to get a basic atmega328 running on a breadboard. However, it's hard to find the same information for these newer "tinyAVR 0" chips.</p>

<p>Of course, Microchip offers all the tools necessary to program these newer "TinyAVR" MCUs with their windows-only IDE. There are also "Arduino cores" for some of these newer "TinyAVR" MCUs that let you program them with the Arduino IDE. But again, if you like to write code for MCUs in "baremetal" style, with your favorite text editor, a makefile, and a c-compiler, there are few resources available online. </p>

<p>In this blog post, we will describe how to program a <a href="https://www.ladyada.net/learn/proj1/blinky.html">blinky</a> firmware on an <strong>Attiny406</strong>, from the ground up, using the simplest tools. Most of the things described here can be easily transposed to other TinyAVR MCUs. Our approach is generally guided toward macOS or Linux users, but should also be applicable in an MS-Windows environment with a few minor changes.</p>

<h2 id="hardware">Hardware</h2>

<p>We decided to play with the <a href="https://www.microchip.com/wwwproducts/en/ATTINY406">Attiny406</a>, with a view of using it in the future to replace the Attiny45 we currently use on the <a href="https://www.omzlo.com/articles/the-piwatcher">PiWatcher</a>, our Raspberry-Pi watchdog. The Attiny406 has 4K of flash space, 256 bytes of RAM, and can run at 20Mhz without an external clock source.</p>

<p>One of the most important differences between the new TinyAVR MCUs and the older classic AVR MCU like the Attiny85 is that the newer chips use a different programming protocol called UPDI, which requires only 3 pins, as opposed to the 6-pin ISP on the classic AVRs.</p>

<p>A little research shows that programming TinyAVRs with UPDI can be achieved with a simple USB-to-serial cable and a resistor, thanks to a python tool called <a href="https://github.com/mraardvark/pyupdi">pyupdi</a>, which suggests the following connection diagram for firmware upload:</p>
<pre>                        Vcc                     Vcc
                        +-+                     +-+
                         |                       |
 +---------------------+ |                       | +--------------------+
 | Serial port         +-+                       +-+  AVR device        |
 |                     |      +----------+         |                    |
 |                  TX +------+   4k7    +---------+ UPDI               |
 |                     |      +----------+    |    |                    |
 |                     |                      |    |                    |
 |                  RX +----------------------+    |                    |
 |                     |                           |                    |
 |                     +--+                     +--+                    |
 +---------------------+  |                     |  +--------------------+
                         +-+                   +-+
                         GND                   GND
</pre>
<h3 id="shematic">shematic</h3>

<p>We created a minimalistic breakout board for the Attiny406. The board can be powered by 5V through USB or a lower 3.3V through dedicated VCC/GND pins. An LED and a button were also fitted on the board. For testing purposes, we decided to embed the 4.7K resistor needed for the UPDI programming directly in the hardware (i.e. resistor <em>R2</em>). 
This gives us the following schematic:</p>

<p><img src="https://www.omzlo.com/uploads/attiny406-schematic.png" alt="schematic"></p>

<h3 id="board">Board</h3>

<p>The resulting breakout board is tiny and fits conveniently on a small breadboard. The design files are <a href="https://aisler.net/p/SIEGFIYL">shared on aisler.net</a>.</p>

<p><img src="https://www.omzlo.com/uploads/std_attiny-406-breadboard.jpg" alt=""></p>

<p>Programming the Attiny406 on the board with a USB-serial cable is done by connecting the headers on the board edge:</p>

<p><img src="https://www.omzlo.com/uploads/attiny406-prog.png" alt=""></p>

<h2 id="software">Software</h2>

<h3 id="pyudpi">pyudpi</h3>

<p>We installed <strong>pyupdi</strong> following the instructions provided on <a href="https://github.com/mraardvark/pyupdi">their webpage</a>. </p>

<p>We connected our USB-Serial cable to the board with the 4 dedicated UPDI pins available on the board. Our USB-Serial converter shows up as the file <code>/dev/tty.usbserial-FTF5HUAV</code> on a MacOS system.</p>

<p>To test that the programmer recognizes the Attiny406, you can issue a command similar to the following, adapting the path for the USB-serial converter to your setup:</p>
<pre>pyupdi -d tiny406 -c /dev/tty.usbserial-FTF5HUAV -i
</pre>
<p>This should result in the following output if all goes well:</p>
<pre>Device info: {'family': 'tinyAVR', 'nvm': 'P:0', 'ocd': 'D:0', 'osc': '3', 'device_id': '1E9225', 'device_rev': '0.1'}
</pre>
<h3 id="the-c-compiler">The C compiler</h3>

<p>The typical <strong>avr-gcc</strong> available on macOS with <a href="https://brew.sh/">homebrew</a> did not seem to recognize the Attiny406 as a compiler target, so we went off to install the avr-gcc compiler provided by Microchip, which is available <a href="https://www.microchip.com/mplab/avr-support/avr-and-arm-toolchains-c-compilers">here</a>. Downloading the compiler requires you to create an account on the Microchip website, which is a bit annoying. </p>

<p><img src="https://www.omzlo.com/uploads/avr-toolchain.png" alt="AVR toolchain link"></p>

<p>Once downloaded, we extracted the provided archive in a dedicated directory. The <code>bin</code> directory in the archive should be added to the <code>PATH</code> variable to make your life easier. Assuming the downloaded compiler is stored in the directory <code>$HOME/Src/avr8-gnu-toolchain-darwin_x86_64</code>, the PATH can be altered by adding the following line to your <code>.bash_profile</code> file:</p>
<pre>export PATH=$PATH:$HOME/Src/avr8-gnu-toolchain-darwin_x86_64/bin/
</pre>
<p>Newer Attiny MCUs are not supported out of the box by the Microchip <strong>avc-gcc</strong> compiler. You need to download a dedicated <em>Attiny Device Pack</em> from <a href="http://packs.download.atmel.com/">their website</a>, as shown below:</p>

<p><img src="https://www.omzlo.com/uploads/microchip-pack-repository.png" alt="AVR toolchain link"></p>

<p>The resulting downloaded <em>Device Pack</em> is named <code>Atmel.ATtiny_DFP.1.6.326.atpack</code> (or similar depending on versioning). Though the extension is <code>.atpack</code>, the file is actually a zip archive. We changed the extension to <code>.zip</code> and extracted the package in the directory <code>$HOME/Src/Atmel.ATtiny_DFP.1.6.326</code> next to the compiler files. </p>

<h3 id="c-program">C program</h3>

<p>We created the following program that blinks the LED on pin PB5 of our Attiny board at a frequency of 1Hz.</p>
<pre><span>#include &lt;avr/io.h&gt;
#include &lt;util/delay.h&gt;
</span>
<span>int</span> <span>main</span><span>()</span> <span>{</span>
    <span>_PROTECTED_WRITE</span><span>(</span><span>CLKCTRL</span><span>.</span><span>MCLKCTRLB</span><span>,</span> <span>0</span><span>);</span> <span>// set to 20Mhz (assuming fuse 0x02 is set to 2)</span>

    <span>PORTB</span><span>.</span><span>DIRSET</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
    <span>for</span> <span>(;;)</span> <span>{</span>
        <span>PORTB</span><span>.</span><span>OUTSET</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
        <span>_delay_ms</span><span>(</span><span>500</span><span>);</span>
        <span>PORTB</span><span>.</span><span>OUTCLR</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
        <span>_delay_ms</span><span>(</span><span>500</span><span>);</span>
    <span>}</span>
<span>}</span>
</pre>
<p>The code looks very similar to what you would see on a classic AVR "blinky" program. One visible change is the use of structures to access various registers of the MCU: e.g instead of setting bits in <code>PORTB</code>, you access <code>PORTB.DIRSET</code>.</p>

<p>The other visible change is the clock setup code <code>_PROTECTED_WRITE(CLKCTRL.MCLKCTRLB, 0)</code>. Out of the box, at reset, the Attiny406 runs at 3.33Mhz, which corresponds to a base frequency of 20Mhz with a 6x clock divider applied. To enable the full 20Mhz speed, the register <code>CLKCTRL.MCLKCTRLB</code> is cleared. Because this register needs to be protected against accidental changes, the Attiny406 requires a specific programming sequence to modify it. Fortunately, this is natively offered by the macro <code>_PROTECTED_WRITE</code>. More details are available in the <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/ATtiny406-DataSheet-DS40001976B.pdf">Attiny406 datasheet</a>.</p>

<p>In comparison with an STM32 or a SAMD21, the code is blissfully simple. </p>

<h3 id="makefile">Makefile</h3>

<p>We assume the following directory structure where:</p>

<ul>
<li><code>Src/Atmel.ATtiny_DFP.1.6.326/</code> is the location of the Microchip <em>Device Pack</em></li>
<li><code>Src/attiny406-test/</code> is the directory where the code above is stored in a file called <code>main.c</code></li>
</ul>

<p>Compiling the code can be done by issuing the following command within <code>attiny406-test/</code> directory,:</p>
<pre>avr-gcc -mmcu=attiny406 -B ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/ -O3 -I ../Atmel.ATtiny_DFP.1.6.326/include/ -DF_CPU=20000000L -o attiny406-test.elf main.c
</pre>
<p>An <code>-O</code> optimization flag is required to make the <code>_delay_ms()</code> function calls work successfully, as well as defining the variable F_CPU to reflect the expected chip clock speed. The rest of the parameters provide the location of the Attiny406 device-specific files we previously extracted from the <em>Device Pack</em>.</p>

<p>Uploading the firmware to the MCU requires a conversion to the intel HEX format and a call to the <strong>pyupdi</strong> tool. To address all these steps, we created a simple Makefile.</p>
<pre><span>OBJS</span><span>=</span>main.o
<span>ELF</span><span>=</span><span>$(</span>notdir <span>$(</span>CURDIR<span>))</span>.elf  
<span>HEX</span><span>=</span><span>$(</span>notdir <span>$(</span>CURDIR<span>))</span>.hex
<span>F_CPU</span><span>=</span>20000000L


<span>CFLAGS</span><span>=</span><span>-mmcu</span><span>=</span>attiny406 <span>-B</span> ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/ <span>-O3</span>
CFLAGS+<span>=</span><span>-I</span> ../Atmel.ATtiny_DFP.1.6.326/include/ <span>-DF_CPU</span><span>=</span><span>$(</span>F_CPU<span>)</span>
<span>LDFLAGS</span><span>=</span><span>-mmcu</span><span>=</span>attiny406 <span>-B</span> ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/
<span>CC</span><span>=</span>avr-gcc
<span>LD</span><span>=</span>avr-gcc

all:    <span>$(</span>HEX<span>)</span>  

<span>$(</span>ELF<span>)</span>: <span>$(</span>OBJS<span>)</span>
                <span>$(</span>LD<span>)</span> <span>$(</span>LDFLAGS<span>)</span> <span>-o</span> <span>$@</span> <span>$(</span>OBJS<span>)</span> <span>$(</span>LDLIBS<span>)</span>

<span>$(</span>HEX<span>)</span>: <span>$(</span>ELF<span>)</span>
                avr-objcopy <span>-O</span> ihex <span>-R</span> .eeprom <span>$&lt;</span> <span>$@</span>

flash:  <span>$(</span>HEX<span>)</span>
                pyupdi <span>-d</span> tiny406 <span>-c</span> /dev/tty.usbserial-FTF5HUAV <span>-f</span> attiny406-test.hex

read-fuses:
                pyupdi <span>-d</span> tiny406 <span>-c</span> /dev/tty.usbserial-FTF5HUAV <span>-fr</span>

clean:
                <span>rm</span> <span>-rf</span> <span>$(</span>OBJS<span>)</span> <span>$(</span>ELF<span>)</span> <span>$(</span>HEX<span>)</span>
</pre>
<p>To compile the code, we simply type <code>make</code>. Uploading is done with <code>make flash</code>. This Makefile can be further enhanced as needed.</p>

<h2 id="conclusion">Conclusion</h2>

<p>With the right tools, baremetal programming on the new TinyAVR MCUs is as simple as on its older AVR cousins. </p>

<p>If you have programming tips for the AVRTiny, please share them with us on <a href="https://twitter.com/OmzloElec">on Twitter</a> or in the comments below.</p>
</div></section><section><div><h4>Comments</h4><div><div><p>Hi, </p>

<p>It's great that ‚Ä¶</p></div></div></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers">https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers</a></em></p>]]>
            </description>
            <link>https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648397</guid>
            <pubDate>Thu, 01 Oct 2020 07:37:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start your open-source venture with AsyncAPI at Hacktoberfest]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24648373">thread link</a>) | @derberg
<br/>
October 1, 2020 | https://www.asyncapi.com/blog/hacktoberfest-2020 | <a href="https://web.archive.org/web/*/https://www.asyncapi.com/blog/hacktoberfest-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><img src="https://www.asyncapi.com/img/posts/hacktoberfest.webp" alt="Post cover image"><h2 id="what-is-asyncapi">What is AsyncAPI</h2><p>AsyncAPI is a specification for describing your <a href="https://www.asyncapi.com/docs/getting-started/event-driven-architectures/">event-driven architecture</a>. You are probably using already <a href="https://www.asyncapi.com/docs/getting-started/coming-from-openapi/">OpenAPI/Swagger specification</a> for describing your synchronous RESTful APIs. AsyncAPI is something that supplements OpenAPI. As an example, you should use AsyncAPI when your services do not talk to each other directly but through a message broker.</p><p>In contrast to the OpenAPI Initiative, AsyncAPI Initiative is focused not only on creating and evolving the AsyncAPI specification but also on its tooling. It is a vendor-neutral space for the community to work together on the spec and its tools. We work on tools like specification parsers or docs and code generators.</p><p><iframe src="https://www.youtube.com/embed/pU71J-F7pfI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h2 id="what-is-hacktoberfest-and-why-asyncapi-initiative-joins-it">What Is Hacktoberfest And Why AsyncAPI Initiative Joins It</h2><p><a href="https://hacktoberfest.digitalocean.com/">Hacktoberfest</a> is a well-known event that promotes open source contributions. In short, you have the entire October to submit four pull requests to any project you want, and in exchange, you get a super cool t-shirt. Is that it? Is it just for a t-shirt? Nah, the t-shirt is nice but what you also get is easy access to open source world. Maintainers of many projects open up for contributions, and it is a great chance to make your first step to joining this fantastic world.</p><p>AsyncAPI Initiative joins the Hacktoberfest for two main reasons:</p><ul><li>Promote AsyncAPI Initiative as a place where we don't work on the specification only but also build a lot of great tools</li><li>Make it much easier for the community to make the first contribution to one of the AsyncAPI repositories</li></ul><p>In the past, we were also there where you are now, shy and uncertain if we can impact open source community. We want to give you an easy path to take the first baby steps in the world of open source in a welcoming and friendly environment.</p><blockquote><p>Don't forget to <a href="https://hacktoberfest.digitalocean.com/login">sign up</a> to the Hacktoberfest</p></blockquote><p><iframe src="https://www.youtube.com/embed/_1WRr3Ml9t4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h2 id="how-can-you-help">How Can You Help</h2><p>There is always a lot of work waiting out there. For the sake of this special event, we prepared around 75 GitHub issues that you can pick up. They represent different areas (for example, JavaScript or HTML), different difficulty (for example, 50 issues are easy), and different repositories. No matter if they are trivial or demanding, all of them are important for us. Even with trivial ones where you, for example, need to remove a semicolon, we will still be super happy because this will improve the quality of the project (SonarCloud reports). In other words, every single issue from <a href="https://docs.google.com/spreadsheets/d/1vX4J395apexutfQ0OSqPNltFKDacmemHZwCmOXwHNLo/edit?usp=sharing">this</a> list is important.</p><h3 id="1-pick-the-right-issue">1. Pick The Right Issue</h3><p><a href="https://docs.google.com/spreadsheets/d/1vX4J395apexutfQ0OSqPNltFKDacmemHZwCmOXwHNLo/edit?usp=sharing">Here</a> you can find a list of all the issues that you can work on. Most of the issues are about code contribution, but not all of them. There are also issues about documentation or CI/CD configuration (we use GitHub Actions). Just pick the issues you want to work on, one at a time, and let us know in the comments section that you want to work on it.</p><p><iframe src="https://www.youtube.com/embed/Iqs_2BiNEEo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h3 id="2-setup-your-environment-and-create-a-first-pull-request">2. Setup Your Environment And Create A First Pull Request</h3><p>Once you <a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git">install Git</a> on your machine and get a <a href="https://github.com/join">GitHub account</a>, you need first to decide if you are here just for Hacktoberfest or longer, and make sure if your issue is easy and maybe you can complete it in the GitHub UI. </p><p>In case you are here just for the Hacktoberfest, and you picked easy issues that involve changes only to a single file, there is no need to install Git and complicate your life. GitHub UI enables you to <a href="https://docs.github.com/en/free-pro-team@latest/github/managing-files-in-a-repository/editing-files-in-your-repository">make changes to a single file online</a>.</p><p>In case you:</p><ul><li>want to stay with us longer,</li><li>you picked up an issue where you need to make changes to more than just one file,</li><li>you also need to run the project locally to check if it works</li></ul><p>Then follow <a href="https://github.com/asyncapi/.github/blob/master/git-workflow.md">this</a> short instruction on how to fork the repository and set it up locally.</p><p>Once you are ready with your changes, submit a pull request. Be nice and follow our <a href="https://github.com/asyncapi/.github/blob/master/CODE_OF_CONDUCT.md">code of conduct</a> and make sure your pull request is <a href="https://github.com/asyncapi/.github/blob/master/CONTRIBUTING.md#conventional-commits">described properly</a>.</p><p><iframe src="https://www.youtube.com/embed/BsC5tu4M1rw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h2 id="office-hours">Office Hours</h2><p>Do you feel overwhelmed? No need. You can do it. Just take this blog post seriously. </p><p>Trust me when I write that every pull request is crucial for us.
Trust me when I write that we are a welcoming community.
Don't be afraid that you will waste our time. If we would think about it this way, we would not even join the Hacktoberfest.</p><p>Still not sure if you can make it? Don't worry. We want to host office hours throughout the event, 2x a week, 1h long, and different time zones. You can join whenever you want and ask us anything, or do pair programming with us. We start with the first meeting on <a href="https://calendar.google.com/calendar/u/0?cid=dGJyYmZxNGRlNWJjbmd0OG9rdmV2NGxzdGtAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ">Tuesday 6th, 8AM UTC</a> and then on the following days:</p><ul><li>Tuesday 6th, 8AM UTC</li><li>Thursday 8th, 4PM UTC</li><li>Tuesday 13th, 8AM UTC</li><li>Thursday 15th, 4PM UTC</li><li>Tuesday 20th, 8AM UTC</li><li>Thursday 22nd, 4PM UTC</li><li>Tuesday 27th, 8AM UTC</li><li>Thursday 29th, 4PM UTC</li></ul><p>You can also join us in a more asynchronous discussion on <a href="https://www.asyncapi.com/slack-invite/">Slack</a>. For updates and latest news, the best is to follow our <a href="https://twitter.com/AsyncAPISpec">Twitter account</a>. </p><h2 id="blooper-reel">Blooper Reel</h2><p>Before you jump to your first contribution, have a look at the making of the videos. It was quite fun.</p><p><iframe src="https://www.youtube.com/embed/anjcF2l0lGs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><p>Enjoy the Hacktoberfest!</p></article></div>]]>
            </description>
            <link>https://www.asyncapi.com/blog/hacktoberfest-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648373</guid>
            <pubDate>Thu, 01 Oct 2020 07:34:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MobX 6]]>
            </title>
            <description>
<![CDATA[
Score 139 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24648363">thread link</a>) | @nikivi
<br/>
October 1, 2020 | https://michel.codes/blogs/mobx6 | <a href="https://web.archive.org/web/*/https://michel.codes/blogs/mobx6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" role="group"><div><section><center><br><small>September 24, 2020</small></center><div><h2>Five years of MobX</h2>
<p>Time flies, and it has been 5.5 years since the first commit to MobX was made to build <a href="https://www.mendix.com/">Mendix Studio</a>.
In those years MobX has been adopted by well-known Software companies like Microsoft (Outlook), Netflix, Amazon and, my personal favorite, it runs in the Battlefield games by EA.
<a href="https://www.amazon.co.uk/MobX-Quick-Start-Guide-Supercharge/dp/1789344832/ref=sr_1_1?crid=BRUIHPUQL64D&amp;dchild=1&amp;keywords=mobx&amp;qid=1600809874&amp;s=books&amp;sprefix=mobx%2Caps%2C138&amp;sr=1-1">Books</a> and video courses have been written, and so have implementations in other languages.</p>
<p><span>
    <span></span>
    <img alt="Battlefield &amp; MobX" title="" src="https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/128ae/dice.jpg" srcset="https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/08cbc/dice.jpg 160w,
https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/37ac5/dice.jpg 320w,
https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/128ae/dice.jpg 640w,
https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/52793/dice.jpg 800w" sizes="(max-width: 640px) 100vw, 640px">
  </span></p>
<p>Yet, since that first commit the philosophy of the MobX hasn't changed: <em>Anything that can be derived from the application state, should be derived. Automatically.</em>.
The API hasn't changed too much since those days either,
and you will find the original <a href="https://www.mendix.com/blog/making-react-reactive-pursuit-high-performing-easily-maintainable-react-apps/">introduction of MobX</a> still pretty recognizable.
If <code>React.createClass</code> still rings a bell that is.</p>
<p>In contrast, the JavaScript eco-system has changed significantly over the years.
TypeScript and Babel have become the de-facto standards.
React went from <code>createClass</code> to classes to hook-based function components.
Yet, relevant JavaScript proposals for observables, Object.observe and decorators have never materialized.</p>
<p>MobX 6 is a new major version that doesn't bring many new features, but is rather a consolidation of MobX on the current state of affairs in JavaScript.
That doesn't come without a few plot twists, so if you are an existing MobX user, please read till the end!</p>
<h2>Bye bye decorators</h2>
<p>Let's start with the bad news: Using decorators is no longer the norm in MobX.
This is good news to some of you, but others will hate it.
Rightfully so, because I concur that the declarative syntax of decorators is still the best that can be offered.
When MobX started, it was a TypeScript only project, so decorators were available.
Still experimental, but obviously they were going to be standardized soon.
That was my expectation at least (I did mostly Java and C# before).
However, that moment still hasn't come yet, and two decorators proposals have been cancelled in the mean time.
Although they still can be transpiled.</p>
<p>So why did we stop using decorators by default?</p>
<p>First of all, the current experimental decorator implementations are incompatible with the soon-to-be-standardized class-fields proposal.
The legacy (Babel) and experimental (TypeScript) decorator implementations will no longer be able to <a href="https://github.com/tc39/proposal-class-fields/issues/151">trap class fields initializations</a>.</p>
<p>Secondly, using decorators has always been a serious hurdle in adopting and advocating MobX.
In Babel, it is quite fragile to set up.
<code>create-react-app</code> doesn't support it out of the box, and many developers rightfully don't like to use non-standard features.
Even though decorators have always been optional in MobX, the fact that they were prominent in the docs left many confused.
Or as one MobX fan <a href="https://github.com/mobxjs/mobx/issues/2325#issuecomment-693130586">puts it</a>:</p>
<p><em>I am guessing this choice [to drop decorators] was probably a good call. Maybe now without decorators I am hopeful I will be able to convey to people how amazing Mobx is and at least I won't hear the decorators excuse anymore. I have never seen an "@" sign scare so many people.</em></p>
<p>So, what does MobX after decorators look like?
Simply put, instead of decorating class members during the class definition, instance members need to be annotated in the constructor instead, using the new <code>makeObservable</code> utility:</p>
<div data-language="typescript"><pre><code><span>import</span> <span>{</span>observable<span>,</span> computed<span>,</span> action<span>,</span> makeObservable<span>}</span> <span>from</span> <span>"mobx"</span>


<span>class</span> <span>TodoStore</span> <span>{</span>
    @observable
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    @computed
    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    @action
    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span>


<span>class</span> <span>TodoStore</span> <span>{</span>
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
        <span>makeObservable</span><span>(</span><span>this</span><span>,</span> <span>{</span>
            todos<span>:</span> observable<span>,</span>
            unfinishedTodoCount<span>:</span> computed<span>,</span>
            addTodo<span>:</span> action
        <span>}</span><span>)</span>
    <span>}</span>

    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>Admittedly, this is a slightly worse DX than before, since member and annotation are no longer co-located.
But the good news is that using <code>makeObservable</code> doesn't require any fancy build setup.
It should work everywhere out of the box.</p>
<p>Migrating an entire code-base from decorators to <code>makeObservable</code> might be challenging, so that is why we released a <a href="https://www.npmjs.com/package/mobx-undecorate">code-mod</a> together with MobX 6 to do that automatically!
Just run the command <code>npx mobx-undecorate</code> inside the folder where your source files live, and after that all decorators should have been magically rewritten!
After that, make sure to <a href="https://mobx.js.org/migrating-from-4-or-5.html#getting-started">update your TypeScript / babel config</a>, and you should be good to go!</p>
<h2>Introducing <code>makeAutoObservable</code></h2>
<p>We realize it is easier to make mistakes now that the annotations are no longer adjacent to the fields they are decorating.
Hence a convenience utility has been introduced that automates the annotation process by picking sane defaults: <code>makeAutoObservable</code>.
It will automatically pick the best annotation for every member of a class, thereby simplifying the above listing to:</p>
<div data-language="typescript"><pre><code><span>class</span> <span>TodoStore</span> <span>{</span>
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
        <span>makeAutoObservable</span><span>(</span><span>this</span><span>)</span>
    <span>}</span>

    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>Note that it is possible to pass a map of <em>overrides</em> as second argument, in case you want to use a modifier.
For example: <code>makeAutoObservable(this, { todos: observable.shallow })</code>.
Pass <code>member: false</code> to have MobX ignore that member entirely.
(Technical fineprint: class methods will not be decorated with <code>action</code>, but with the new <code>autoAction</code>, this annotation will make methods suitable to be used both as a state updating action, or as function that derives information from state).</p>
<p>What I personally like about <code>makeAutoObservable</code> is that it plays really nice with factory functions.
Which is great if you prefer to not use classes (factory functions make it is easy to hide members and prevent issues with <code>this</code> and <code>new</code>. And they compose more easily).
The same store expressed as factory function will look as follows. Pick the style that suits you:</p>
<div data-language="typescript"><pre><code><span>function</span> <span>createTodoStore</span><span>(</span><span>)</span> <span>{</span>
    <span>const</span> store <span>=</span> <span>makeAutoObservable</span><span>(</span><span>{</span>
        todos<span>:</span> <span>[</span><span>]</span> <span>as</span> Todo<span>[</span><span>]</span><span>,</span>
        <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
            <span>return</span> store<span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
        <span>}</span><span>,</span>
        <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
            store<span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
        <span>}</span>
    <span>}</span><span>)</span>
    <span>return</span> store
<span>}</span></code></pre></div>
<h2>Fresh docs!</h2>
<p>Since decorators are no longer the norm, <a href="https://twitter.com/faassen">Martijn Faassen</a>, <a href="https://twitter.com/zangornjak">≈Ωan Gornjak</a> and yours truly went over all the documentation.
We updated all examples and significantly restructured the docs that have grown quite organically over the years.
We feel the current docs are shorter, have less repetition, and better discuss common scenarios.
Also, we marked all non-essential knowledge in the docs with a {üöÄ} rocket emoji, to make it clear which knowledge is optional.
Hopefully it is much quicker now to find your way around in MobX!</p>
<p>On a similar note, we've updated all <a href="https://mobx.js.org/react-integration.html">React related documentation</a> to use function components instead of class components. And added documentation on how to use MobX with hooks, context and effects.
This knowledge existed before (little has changed technically), but was scattered all over the place.
As a result, we now recommend <code>mobx-react-lite</code> over <code>mobx-react</code> for (greenfield) projects that don't use class components.
As a result the separate mobx-react.js.org/ website has been deprecated.
All credits go to <a href="https://twitter.com/danielk_cz">Daniel K</a> for maintaining those two projects!</p>
<p>And finally, there is now a <a href="https://gum.co/fSocU">one pager MobX 6 cheat sheet üë®‚Äçüéì</a> covering all the import mobx / mobx-react(-lite) API's.
(It is a great way to one-time sponser the project in an invoicable way).</p>
<h2>Improved browser support</h2>
<p>A probably little surprising improvement in MobX 6 is that it supports <em>more</em> JavaScript engines than MobX 5.
MobX 5 required proxy support, making MobX unsuitable for Internet Explorer or React Native (depending on the engine).
For this reason MobX 4 was still actively maintained.
However, MobX 6 replaces both at once.</p>
<p>By default MobX 6 will still require Proxies, but it is possible to opt-out from Proxy usage in case you need to support older engines.
And, as a result, it is now possible for MobX 6 to warn in development mode when features that would require proxies are used.
See the documentation for more <a href="https://mobx.js.org/configuration.html#proxy-support">details</a>.</p>
<div data-language="typescript"><pre><code><span>import</span> <span>{</span> configure <span>}</span> <span>from</span> <span>"mobx"</span>

<span>configure</span><span>(</span><span>{</span>
    
    
    
    useProxies<span>:</span> <span>"never"</span>
<span>}</span><span>)</span></code></pre></div>
<h2>Decorators are back!</h2>
<p>Ok, time for the plot twist. MobX 6 stills supports decorators!
The decorator implementation in MobX 6 is entirely different from the one in earlier versions, but does work with the current implementations in TypeScript and Babel.
It basically provides an alternative way to construct the annotations map for <code>makeObservable</code>, and allows us to rewrite the first example as:</p>
<div data-language="typescript"><pre><code><span>class</span> <span>TodoStore</span> <span>{</span>
    @observable
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
        <span>makeObservable</span><span>(</span><span>this</span><span>)</span>
    <span>}</span>

    @computed
    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    @action
    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>Note that we still need to add a constructor to the class, but this time we omit the second argument to <code>makeObservable</code>, so that it will rely on the decorators instead.
We don't recommend this set up for greenfield projects, after all decorators are still experimental, but this is a great compromise for
existing code bases.
Generating constructors without removing decorators is supported by <code>mobx-undecorate</code> as well, and can be achieved by running <code>npx mobx-undecorate --keepDecorators</code>.</p>
<p>And here is even more good news: There is a fresh <a href="https://github.com/tc39/proposal-decorators">decorators proposal</a> being championed by the tireless hero <a href="https://twitter.com/littledan">Daniel Ehrenberg</a>.
I've been a bit involved in it, and the MobX use case has inspired the proposal.
So the benefits of the fresh decorator implementation are that it a) solves the compatibility issue with the class fields spec discussed above, and
b) it also paves the way ‚Ä¶</p></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://michel.codes/blogs/mobx6">https://michel.codes/blogs/mobx6</a></em></p>]]>
            </description>
            <link>https://michel.codes/blogs/mobx6</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648363</guid>
            <pubDate>Thu, 01 Oct 2020 07:33:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Worst Decision of My Career]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24648256">thread link</a>) | @fribmendes
<br/>
October 1, 2020 | https://subvisual.com/blog/posts/the-worst-decision-of-my-career/ | <a href="https://web.archive.org/web/*/https://subvisual.com/blog/posts/the-worst-decision-of-my-career/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article><section><div><div><div><div><div><div>
<p>This is a reflection on software development and complexity. Let's start with
some quotes to make me look smart:</p>
<blockquote>
<p>A complex system that works is invariably found to have evolved from a simple
system that worked. A complex system designed from scratch never works and
cannot be patched up to make it work. You have to start over with a working
simple system -- <em>Gall's law</em></p>
</blockquote>
<p>I only came across this quote recently, but I think that it summarizes what
I've learned these past seven years. Another idea that I've found in a few books
is that programming in isolation is problem-solving, but software engineering
is all about managing complexity. This distinction between programming and
software engineering makes sense to me, probably because of my mental models.
I'm sure we can all disagree on this, but that's not the topic of today.
Complexity is.</p>
<h2>Complexity</h2>
<p>Almost everyone I know in the software industry wants to build products that
solve real and challenging problems. Change the world! The last thing you want
is to build another CRUD application. They are fine, but it gets boring after
a while.</p>
<p>Most of us will get bored without novelty. That's why the software industry has
a recycling mechanism to keep things fresh and interesting for us: every once
in a while a new, or different, language/framework will rise and light the path
for a brighter future, overthrowing the existing standard, demanding that we
learn it to be on top of the game.</p>
<p>We change our tools, but we keep building the same things over and over. I've
been doing this long enough to see that we are just going in circles. Let's be
honest, most of us aren't building life-changing products that wouldn't have
been possible ten years ago, so let's not jump straight into another shiny
technology that just came out and is going to solve all of our problems.</p>
<h2>Solutions, solutions, solutions</h2>
<blockquote>
<p>For a while, the solution to every problem I encountered was a Rails app. --
<em>this one is mine</em></p>
</blockquote>
<p>Over the years, I've seen companies rewrite their products to change languages,
frameworks, or architectures because they were told that the change would make
their product better, run faster, and scale. By the way, you're only a true
Ruby developer after you've heard the question "but does it scale?" at least
one hundred times (kidding, but it'll happen).</p>
<p>Think about it, how many times were you sold a new programming language,
technology, or a concept like microservices, serverless, event sourcing, clean
architecture, micro frontends. There are many preachers in the software world.</p>
<p>At Subvisual, we started using Elixir a lot these past years, so I've learned
a bit about the history of Erlang. If you don't know, Erlang uses the Actor
Model, and the interesting part is that the designers of Erlang only learned
about the Actor Model after having designed Erlang. This is important because
the designers of Erlang didn't start with the intent of applying the Actor
Model; it came as a solution to fault-tolerant distributed programming.</p>
<blockquote>
<p>If all you have is a hammer, everything looks like a nail <em>Abraham Maslow</em></p>
</blockquote>
<p>The designers of Erlang picked the right tool for the job and most of us want
to do the same. Unfortunately, there's usually more than one "tool" that would
be "right," but to know which ones, you need to know what "job" you're solving.
All of us <strong>should</strong> know this, but I keep learning about teams that fail to do
it. There are so many companies, with a handful of experienced developers, that
don't know what they are building, don't have a clear business yet, but their
product is already built on complex architectures and technologies such as
microservices, Kubernetes or event-sourcing.</p>
<h2>Improving</h2>
<p>Every project we start from scratch is an opportunity to do it right. We'll
think to ourselves: <em>This time I won't fall into the same traps! I have learned
my lessons, I've studied the books, and I even met some of my gurus that wrote
them! This time I'll follow "industry standards"!</em></p>
<p><em>I am the "architect"; I will design the perfect system! Without me, none of
this will be possible. Those mindless programmers have no idea what they are
doing. I, and only I, am the true heir of Martin Fowler!</em></p>
<p>This was a bit dramatic, but I needed a break from all of that whining. I know
it's easy to fall into these traps. It's even easier when your company raised
money, and everyone is expecting you to deliver the absolute best product ever
because they are paying you for it! This is why your starting team is so
important; they have to withstand the pressure. They must know that to build
the grand vision, they have to go one step at a time.</p>
<h2>The decision</h2>
<p>I've made many bad decisions, and I've been fortunate enough to suffer the
consequences of those decisions. A lot of developers don't get to experience
consequences, so they never learn.</p>
<p>So what was the worst decision of my career? I don't know. But the title of
this blog post is inspired by something an old colleague said. At the time, we
were working for a product company that reached for event-driven architecture
and event-sourcing too soon. They knew little about their market, and the
choices the software team made were crippling their ability to change. Business
rules were almost set in stone. Migrating data was a pain and the source of
many bugs. And unfortunately, because the team didn't have experience with
event-sourcing, the event store, which kept the state of all services, was also
being used as an event-bus to communicate between services. Because of that, it
was possible to couple one service to the internal state of another, which
happened a lot. This almost invisible coupling made everything worse.</p>
<p>What did we do against such an unpredictable system? We took it apart: merging
services that were too coupled; defining clear boundaries between services;
moving some services away from the event-store into a traditional database;
making some communication channels synchronous; writing integration and
end-to-end tests.</p>
<p>When we were finished it was still an unnecessarily complex system, but it was
one that we could change with some confidence. After that, we defined
a long-term plan for the product's architecture and technology, but we didn't
implement it. We waited for the right moment when something was starting to
slow us down to make a small step in that direction. When the business goals
changed, we changed our long-term plan, and once again made small steps in that
direction when we felt the need for it.</p>
<p>Eventually, complexity found its way again into the codebase, but it was fine
because the codebase was evolving slowing, adding and removing complexity when
necessary.</p>
<h2>Making the right call</h2>
<p>Was that the worst decision of his career? I don't think so. The issue with him
going for event-sourcing and event-driven architecture was that it wasn't the
right moment, but my colleague didn't know that. He thought the goals for the
next years were well defined, but unfortunately, they never are.</p>
<p>Should you use microservices or event-sourcing? Maybe, it depends on the
context and the client. The decisions I make are the best that I can with the
information that I have. For instance, when I'm part of the team that's
starting a product, the technology we pick will depend on how we'll hire: if
you want to build an office in Portugal, we have to make sure we have
developers for that technology available. We have to think things through, and
some things you only learn from experience. This applies to the systems we
design as well. I've seen enough people design around what they believe the
product will become in two years to know that those designs always fail to
accommodate the changes that will come. So we design systems for small,
incremental changes. Do the smallest thing that will get us started and
doesn't compromise our ability to change once we know what the business needs.</p></div></div></div></div></div></div></section></article></div></div></div>]]>
            </description>
            <link>https://subvisual.com/blog/posts/the-worst-decision-of-my-career/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648256</guid>
            <pubDate>Thu, 01 Oct 2020 07:18:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Before You Start Coding]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24647918">thread link</a>) | @dinomad
<br/>
September 30, 2020 | https://scorpil.com/post/before-you-start-coding/ | <a href="https://web.archive.org/web/*/https://scorpil.com/post/before-you-start-coding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="container"><div><article itemscope="" itemtype="http://schema.org/BlogPosting"><div itemprop="articleBody"><p>Full disclosure: things discussed in this post are, to be frank, quite obvious. My intent is not so much to teach a reader something new, as to remind him what might have been forgotten. After all, anyone who does a single kind of work daily for years inevitably develops habits and mental-shortcuts that are <em>usually</em> useful but can misfire from time to time. After all, software development is too complex and too technical to be guided by subconscious intuition.</p><p>Pilots use pre-flight checks to combat this kind of problem, so why not developers? Here‚Äôs a check-list of things I find important to consider <strong>before</strong> writing the first line of code.</p><h3 id="set-your-target-straight">Set your target straight</h3><p>Imagine yourself solving these tasks:</p><ul><li>generating a single-use report for an established company</li><li>writing a feature in proof-of-concept MVP for a startup</li><li>extending at enterprise product that has 20 years of codebase support guarantee in its SLAs</li></ul><p>Clearly, it wouldn‚Äôt be smart to blindly apply the same set of software development best-practices for all three cases. You probably don‚Äôt need a perfectly polished code for a single-use report. A startup that operates in the ‚Äúrush to market before we run out of money" mode is much more worried about the feature working than about its performance. Long-support code needs to be first and foremost maintainable. Also, if you‚Äôre working on a pet-project for fun, you might gasp skip writing tests (unless you enjoy writing tests, in which case I envy you a little bit). Some developers take so much pride in their craft that they lose sight of the forest behind the trees. Following all best practices and writing state-of-the-art code <em>feels</em> right, but logically it‚Äôs not the only option. Sometimes you should consciously generate technical debt. Reality constraints are not something that can be ignored.</p><p>As self-evident as this advice is, we‚Äôve all heard stories where things went wrong because of misaligned goals. ‚ÄúPremature optimization‚Äù is a common special case. Refactoring an old codebase that rarely changes, just so it‚Äôs pretty, is another one. And to not leave you with the thought that goal misalignment is always linked to perfectionism: writing an unsupportable code to meet a <em>fictional</em> deadline, either self-imposed or forced on to developers by impatient management, is the same kind of error.</p><p>You need to know where to go before you can start thinking about how to get there. Think of the most important criteria your solution needs to fulfill and align your decision-making with those.</p><h3 id="consider-alternatives">Consider alternatives</h3><p>You‚Äôve got the task in front of you, requirements are pretty clear, and you vaguely remember how you did something similar a few years before. Or maybe you don‚Äôt know how to solve it at first, but after some googling, you get a general idea. Start coding?</p><p>There are always multiple ways to solve a problem. The first viable solution is unlikely to be an optimal one. By focusing on the first approach discovered you rob yourself of choice. Do a thorough research first, and after you have options in front of you, carefully consider the pros and cons of each. There is no magical number of solutions you need. I often set the minimum bound to three for myself.</p><p>Selecting the right tool for a job is an obvious example of a decision that benefits from upfront research, and even then, in a real-world scenario, a tool that‚Äôs familiar often gets selected over the tool that fits. Don‚Äôt think this advice only applies to ‚Äûmacro‚Äú decisions, it can be applied just as well for your everyday code design choices.</p><h3 id="consult-the-docs-yes-upfront">Consult the docs. Yes, upfront</h3><p>It‚Äôs impossible to keep up with the pace modern tech is moving. Doesn‚Äôt matter how many years of experience you have under your belt, when you pick up the project on a modern stack there will be tools and libraries, released recently, that have slipped under your radar. So most developers are in a constant in-flight-learning mode: picking up knowledge as they search answers on immediate questions. It‚Äôs an efficient way to learn, but it creates a risk of missing an easy solution because of the inability to form the right question.</p><p>Skimming the docs upfront, without digging deep into any particular topic, doesn‚Äôt take much time, but it helps create mental anchors, which your brain will fetch when you encounter the problem. You will have a better starting point for finding the right answer quickly.</p><h3 id="design-your-apis">Design your APIs</h3><p>The hardest part of writing code is to imagine in the minutest details how to handle each workflow, each exceptional situation, and each edge case. Many developers first solve a problem, then write a ‚Äûwrapper‚Äú to expose their work to the outside world through some kind of API (i don‚Äôt mean just REST API, function signatures and interfaces are APIs as well). Often this bottom-up design leads to an API that‚Äôs too ‚Äûtechnical‚Äú, i.e. leaking it‚Äôs abstractions to the consumer. It‚Äôs hard to make your brain switch from one level of abstraction to another.</p><p>Before starting the work on implementation, put yourself in the shoes of the API user first (even if that user is you). What would be the user‚Äôs most common usage pattern? What‚Äôs the absolute minimal required set of parameters the API needs to have? Which terminology makes sense for the user? What input format would be most convenient? What defaults to set? It‚Äôs up to you how thorough you want this process to be.</p><h3 id="split-up-the-work">Split up the work</h3><p>Each entity in a system exponentially increases the number of possible interactions. Code that‚Äôs easy to reason about forms a pyramid of abstraction layers, each one hiding its inner workings from the layer above. Each layer can be reasoned about independently, limiting the amount of ‚Äûmoving parts‚Äú you need to keep track of in your brain. If you succeed in splitting the task into multiple loosely coupled entities upfront, you will simplify your code and work process.</p><p>If the task at hand is large enough, it might make sense to form a tree-like task structure, starting from the highest level of abstraction and moving down the layers until the tasks are small enough. The ‚Äûsmall enough‚Äú parameter depends on your particular codebase, mindset, and type of work you do, but after a bit of practice, you‚Äôll find what granularity suits you the best.</p><p>Each task should be fairly self-sufficient and ideally shouldn‚Äôt stay in ‚Äúkinda-finished‚Äù state for long (‚Äúfinished but not deployed‚Äù, ‚Äúfinished but not reviewed‚Äù, ‚Äúfinished but not tested‚Äù or ‚Äúfinished but waiting for authorization from XYZ department‚Äù). Finished is when you don‚Äôt think about it anymore and it doesn‚Äôt drain your mental resources.</p><p><img src="https://scorpil.com/img/tree.png" alt="Example of a task tree"></p><p>Do you have your own tips and tricks for organizing developer‚Äôs work? Please share!</p></div></article></div></div></div></div>]]>
            </description>
            <link>https://scorpil.com/post/before-you-start-coding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647918</guid>
            <pubDate>Thu, 01 Oct 2020 06:20:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You're Allowed to Write Slow Rust Code]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24647910">thread link</a>) | @ingve
<br/>
September 30, 2020 | https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/ | <a href="https://web.archive.org/web/*/https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog-post">
    
    
    <article>
        <p>There's a thing that comes up from time to time in the Rust community: people wanting to optimize their code. Make the code run faster. Make it allocate less memory. These are worthy goals, but maybe not necessary for all projects. Just because your program is written in Rust, it doesn't have to be optimized to the moon and back to do it's job. In a lot of cases, you'll be fine using <code>.clone()</code>.</p>
<p>There's a fantastic quote from a discussion on the <a href="https://users.rust-lang.org/">Rust user forums</a> which I always think of when these discussions emerge:</p>
<blockquote>
<p>Just because Rust allows you to write super cool non-allocating zero-copy algorithms safely, doesn't mean every algorithm you write should be super cool, zero-copy and non-allocating.<br>
-- <a href="https://users.rust-lang.org/t/feeling-rust-is-so-difficult/29962/15">trentj on The Rust Programming Language Forum</a></p>
</blockquote>
<p>Of course there's a time and place for <em>super cool no-allocating zero-copy algorithms</em>, but very often it's not the time, nor the place. You can write fantastically effective code with Rust, but <strong>you don't have to</strong>! A lot of the time it's entirely fine to just write code that works with minimal effort. You don't have to spend 4 days trying to figure out how lifetimes work just to avoid calling <code>.clone()</code> a few times.</p>
<p>Don't spend time trying to make micro optimizations now. Take the easy route. You'll probably come back to that piece of code in a few months time, smile, and change that <code>.clone()</code> to something more efficient.</p>
<p>Happy coding!</p>
<p><small>NB: Watch this <a href="https://youtu.be/rAl-9HwD858">video by Jon Gjengset</a> if you want a good, pragmatic walk through of lifetimes in Rust.</small></p>

    </article>
</div></div>]]>
            </description>
            <link>https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647910</guid>
            <pubDate>Thu, 01 Oct 2020 06:19:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designed IOS14 Icons to to fight the screen time, clutter and visual fatigue]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24647737">thread link</a>) | @hren
<br/>
September 30, 2020 | https://hren.io/products/iso14-home-screen-icons-set/ | <a href="https://web.archive.org/web/*/https://hren.io/products/iso14-home-screen-icons-set/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>As IOS14 allows the customization of the home screen with the Shortcuts app, this icon set tries to fight the screen time, clutter and fatigue by minimizing visuals.</p><p>The goal is to also lover the Screen Time by only limited to one screen.</p><p>More icons will be added. For icon requests DM on<!-- --> <a href="https://twitter.com/@darjanhren" target="_blank">Twitter</a>.</p><p><a href="https://gum.co/wIROw" target="_blank">Get Calm Icon Set</a></p></div></div></div>]]>
            </description>
            <link>https://hren.io/products/iso14-home-screen-icons-set/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647737</guid>
            <pubDate>Thu, 01 Oct 2020 05:44:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running GitHub Actions for Certain Commit Messages]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24647722">thread link</a>) | @kiyanwang
<br/>
September 30, 2020 | https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages | <a href="https://web.archive.org/web/*/https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            
                <section>
        
        <p>A quick look at how you can configure your GitHub Actions workflows to only run when a certain phrase is present in the commit message.</p>
                    <small>Published 4 days ago</small>
                            <span>|</span>
                <small>Updated 4 days ago</small>
                                                <p><span>
    Tooling
</span>
 
                                     <span>
    GitHub Actions
</span>
 
                            </p>
                        <article>
            <p>I'm going to be honest with you all for a second. I write a lot of <code>wip</code> commits. These commits are normally small changes that I want to push up to GitHub so that:</p>
<ol>
<li>I don't lose things if anything goes wrong and my backup hasn't picked it up.</li>
<li>If I can't describe the change I have just made.</li>
<li>If I'm demonstrating something to somebody on a pull-request.</li>
</ol>
<p>The problem is, my actions are setup to run on <code>push</code>, so every single <code>wip</code> commit gets run through the CI process, whether it be running tests, linting or formatting.</p>
<p>After doing some research, I found a way of preventing these from running on every single commit.</p>
<pre><code data-lang="yml"><span>jobs:</span>
  <span>format:</span>
    <span>runs-on:</span> <span>ubuntu-latest</span>
    <span>if:</span> <span>"! contains(github.event.head_commit.message, 'wip')"</span>
</code></pre>
<p>Now, whenever I push a <code>wip</code> commit or any commit that contains the word <code>wip</code>, it will be marked as skipped inside of GitHub actions.</p>
<p>You could also flip the logic and perhaps do something like:</p>
<pre><code data-lang="yml"><span>jobs:</span>
  <span>format:</span>
    <span>runs-on:</span> <span>ubuntu-latest</span>
    <span>if:</span> <span>"contains(github.event.head_commit.message, '[build]')"</span>
</code></pre>
<p>Any commit that contains <code>[build]</code> will now trigger these jobs, everything else will be skipped.</p>
<p>You can thank me later! üòâ</p>

        </article>
    </section>
        </div>
    </div></div>]]>
            </description>
            <link>https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647722</guid>
            <pubDate>Thu, 01 Oct 2020 05:41:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prime and battery usage on Linux laptops: sometimes it's not what it seems to be]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24646504">thread link</a>) | @todsacerdoti
<br/>
September 30, 2020 | https://nwildner.com/posts/2020-10-01-nvidia-reverseprime/ | <a href="https://web.archive.org/web/*/https://nwildner.com/posts/2020-10-01-nvidia-reverseprime/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><a href="https://wiki.archlinux.org/index.php/PRIME">PRIME</a> is a technology used to manage hybrid graphics. It was meant to be a resource saver since you can configure it to use only the Integrated GPU, and render offload to the dedicated GPU whenever is needed. But that is not what happened in my real life situation.</p>

<p>I was not happy with the fact that my laptop was draining a lot of battery. Not only while using render offload by running software with <code>prime-run</code> and delegating gpu stuff to my dGPU(Nvidia MX150), but using the iGPU(i915 Intel) to daily stuff(terminal, browser) was also draining a lot of battery. Overheating was also a problem and then, i started to investigate.</p>
<p>Using <code>powertop -t 3</code> shown that Firefox was draining as much as <code>800 mW</code> per process(tab) on the <code>Power Est.</code> column. Meanwhile, <code>i915</code> module was using about <code>150 mW</code> alone. That got me thinking if, using the dedicated GPU to render stuff would get it better, but it didn‚Äôt. Launching Firefox with <code>prime-run</code> reduced a little the power usage per tab (opening the same websites), but the Intel module was still draining almost the same amount of power(<code>145 mW</code>) while the <code>nvidia</code> module was using <code>35mW</code>.</p>
<p>Other thing that bugged me was that my system always started with a lot of RAM already compromissed(<code>900MB</code>) on a simple <code>i3</code> setup. Could be the case where my iGPU was already allocating a lot of that resource to itself?</p>
<p>After that, i‚Äôve decided to try some 3D, and <a href="https://veloren.net/">Veloren</a> was the game i‚Äôve chosen. Those were the metrics captured with my status bar and <code>powertop</code>:</p>
<ul>
<li>
<p>Using <code>i915</code> driver:</p>
<ul>
<li>Driver drain reached <code>400mW</code>.</li>
<li><code>1,9 GB</code> Ram used</li>
<li>Battery expected duration after full charge was <code>1:28</code>.</li>
</ul>
</li>
<li>
<p>Using <code>nvidia</code> driver with <code>prime-run</code>.</p>
<ul>
<li><code>i915</code> driver was still draining <code>200 mW</code> approximately, spiking to <code>400</code> sometimes.</li>
<li><code>nvidia</code> driver was using about <code>50mW</code>, spiking to <code>80</code> once in a while.</li>
<li><code>1,7 GB</code> RAM used</li>
<li>About <code>140MB</code> of GDDR used</li>
<li>Battery expected duration after full charge was <code>1:12</code>.</li>
<li>nvidia temperature reached <code>73¬∫C</code>.</li>
</ul>
</li>
</ul>
<p>I know that this doesn‚Äôt seems to be a fair test, comparing a dGPU with an iGPU while executing a game. The point I was trying to prove was: Using the render offload didn‚Äôt really help on reducing resource consumption at all. On the oposite, it seems that it somehow helped me to have resources wasted by doubling energy consumption due to this binding created between modules with the <a href="https://wiki.archlinux.org/index.php/PRIME#PRIME_render_offload">render offload</a> feature.</p>

<p>I was decided to try a new approach and use <a href="https://wiki.archlinux.org/index.php/NVIDIA_Optimus#Use_NVIDIA_graphics_only">Nvidia graphics only</a>. Setup was pretty straightforward and after rebooting, I‚Äôve launched Firefox with the same sites and <code>Power Est.</code> was about <code>570mW</code> per process. Good news, lets try Veloren again:</p>
<ul>
<li>Using <code>nvidia</code> driver only
<ul>
<li><code>nvidia</code> driver was using about <code>120mW</code>.</li>
<li>Battery expected duration after full charge was <code>1:47</code>.</li>
<li><code>1,3 GB</code> RAM used</li>
<li>About <code>140MB</code> of GDDR used</li>
<li>nvidia temperature reached <code>67¬∫C</code>.</li>
</ul>
</li>
</ul>
<p>That‚Äôs a lot better. I also noticed that my system was using only <code>500MB</code> RAM after a fresh start(a <code>400MB</code> difference).</p>
<p><strong>Lesson learned.</strong> Try things by yourself when it comes to power management.</p>

<p>Other things changed on my system after spending the weekend optimizing energy stuff:</p>
<ul>
<li>Not using <a href="https://github.com/tobi-wan-kenobi/bumblebee-status"><code>bumblebee-status</code></a> anymore. It‚Äôs a great bar, full of useful modules, but it was creating some weird spikes on power usage. Migrated to <a href="https://github.com/greshake/i3status-rust/"><code>i3status-rust</code></a> and now my bar isn‚Äôt even listed on the top 20 power usage agressors.
<ul>
<li>All previous tests were done using the same bar.</li>
</ul>
</li>
<li><code>telegram-desktop</code> is a mess on power and cpu usage and i‚Äôm seriously thinking on ditching this software and using it‚Äôs web version only. Firefox is a software I already use so, there‚Äôs nothing to lose.</li>
<li>Try to get used with some lightweight browser like <a href="https://qutebrowser.org/">qutebrowser</a> while on battery, and stop using my bookmark sync of choice. Have to test since not having video acceleration could be a caveat.</li>
<li>Find out why while using specific softwares <code>pulseaudio</code> gets crazy and it spikes with <code>4W</code> of Power Estimated usage.</li>
</ul>
  </div></div>]]>
            </description>
            <link>https://nwildner.com/posts/2020-10-01-nvidia-reverseprime/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646504</guid>
            <pubDate>Thu, 01 Oct 2020 02:06:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our Voice Assistant Spoke to Google Duplex. Here‚Äôs What Happened]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24646421">thread link</a>) | @xingyzt
<br/>
September 30, 2020 | https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/ | <a href="https://web.archive.org/web/*/https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				<div>
				
													<p><img src="https://www.polyai.com/wp-content/uploads/2019/08/nikola-1-500x500.jpg"></p><div>
							<h6>Nikola Mrk≈°iƒá</h6>
							<p><span>
								23 Sep 2020								- 5 minutes read							</span>
						</p></div>
						
										
				</div>
			</div><div>
									<p>This summer, Google has been deploying its AI voice assistant called Duplex to call bars and restaurants in order to update their opening hours on Google Maps listings.<br>
Here‚Äôs a call their system had with our virtual assistant for restaurants.</p>
<p><iframe src="https://player.vimeo.com/video/460586741" width="640" height="360" frameborder="0" allowfullscreen="allowfullscreen"><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">Ôªø</span><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">Ôªø</span></iframe></p>
<p>As far as we‚Äôre aware, this is the <strong>first naturally-occurring conversation between AI voice assistants in the wild</strong>. I have never seen anything like this before, and I‚Äôm incredibly proud that PolyAI is sharing this moment in computing history with our friends from Google.</p>
<p>After listening to the call, we‚Äôd say that it went pretty well! Google could have handled the two-part opening hours a bit better, but overall, the interaction was smooth. I want to share a few thoughts on what this means for the future of conversational technologies.</p>
<h3>Human language is a Universal API</h3>
<p>This interaction did not need to be a conversation in the way that we as humans think of it. The caller‚Äôs request was transactional and to the point. An API call or an HTTPS request between two web services would have done the job in 150ms, instead of two minutes of synthesized voice going back and forth across the telephone line. However, such APIs are not always available, or standardised. For instance, there are dozens of reservation APIs for restaurants used in the UK alone, and voice assistants will never integrate with every single one.</p>
<p>This kind of machine-to-machine conversational communication will become more commonplace as AI deployment accelerates. And while it may seem like an overkill from a technical standpoint, there are good reasons for these kinds of interactions to be conversational, rather than API calls.</p>
<p>Imagine you ask your virtual assistant ‚Äî Siri or Alexa, for example ‚Äî to book a hotel room. It can phone multiple hotels to check availability and book without having to integrate into each hotel‚Äôs individual booking API. And logs of the conversation can inform the user of alternative venues for their next trip.</p>
<h3>Welcome to the Uncanny Valley</h3>
<p>Google introduced <a href="https://ai.googleblog.com/2018/05/duplex-ai-system-for-natural-conversation.html">Duplex in May 2018</a> as an ‚ÄòAI system for accomplishing real-world tasks over the phone‚Äô. You may have seen this video of <a href="https://www.youtube.com/watch?v=D5VN56jQMWM">Sundar Pichai at Google I/O</a> using Duplex to make a restaurant reservation.</p>
<p>I‚Äôll be the first to point out how incredible Google‚Äôs TTS (text-to-speech) is in the Duplex/PolyAI call. It sounds like a human, much more so than our assistant does.</p>
<p>According to the <a href="https://en.wikipedia.org/wiki/Uncanny_valley">Uncanny Valley theory</a>, the more human-like a robot is, the more likely people are to feel positive towards it. However, at a certain point of human-likeness, the robot becomes a bit creepy, and people are repulsed by it.</p>
<p><img src="https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley.png" alt="" width="588" height="387" srcset="https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley.png 588w, https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley-300x197.png 300w" sizes="(max-width: 588px) 100vw, 588px"></p>
<p>In the Google/PolyAI call, Duplex really does sound like a human ‚Äì it does mention that it‚Äôs an automated service, but this is not enough. Why? Because crossing the Uncanny Valley means that a person on the call will treat the bot as though they are human.</p>
<p>Around the 1 minute mark, you‚Äôll hear our voice assistant ask the caller when they‚Äôd like to come in, and Duplex speaks over it. In reality, these are machines ‚Äì no-one‚Äôs getting offended. But when you listen to the call, the Duplex bot comes across as pretty rude. Because it sounds so human, it‚Äôs practically impossible to not attribute human qualities to the bot. And no one wants a rude voice assistant representing their company.</p>
<p><strong>Making customers think that your voice assistant is a real human is a sure-fire way to deliver frustrating customer experiences. At PolyAI, we work hard to make sure our voice assistants sit at the peak right before the Uncanny Valley ‚Äì but without crossing it. Warm and friendly enough to put callers at ease, but not real enough to cause cognitive dissonance.</strong></p>
<h3>The Future of Voice</h3>
<p>Companies are wising up to the benefits of conversational AI in customer communications, and we‚Äôll see a growing number of instances of machines communicating in human language. While this type of transactional communication may seem better suited to quick API calls, voice assistants can get the job done even when such APIs are not available.</p>
<p>We are super excited about the future of voice assistants. Two highly sophisticated voice assistants have now met in the wild, in a rerun of the legendary ‚ÄúDr Livingstone, I presume‚Äù moment (though neither assistant realised they were speaking to one of their own). This is a sign of great things to come. Stay tuned ‚Äì and get in touch with us if you want to build a great voice assistant for your brand.</p>
<p><strong>What do you think of the PolyAI vs Google Duplex call? Let us know on Twitter, <a href="https://twitter.com/poly_ai">@poly_ai</a>.</strong></p>
							</div></div>]]>
            </description>
            <link>https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646421</guid>
            <pubDate>Thu, 01 Oct 2020 01:54:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Grand Design (2010)]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24646120">thread link</a>) | @got-any-grapes
<br/>
September 30, 2020 | https://blas.com/the-grand-design/ | <a href="https://web.archive.org/web/*/https://blas.com/the-grand-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<!-- #masthead -->

	<div id="main">

	<div id="primary">
		<div id="content" role="main">

			
				
	<article id="post-5144">
				<!-- .entry-header -->

				<div>
			
<p>Summary</p>



<ol><li>Traditionally these are questions for philosophy, but philosophy is dead. Philosophy has not kept up with modern developments in science, particularly physics. Scientists have become the bearers of the torch of discovery in our quest for knowledge. The purpose of this book is to give the answers that are suggested by recent discoveries and theoretical advances. They lead us to a new picture of the universe and our place in it that is very different from the traditional one, and different even from the picture we might have painted just a decade or two ago.</li></ol>



<p>Key Takeaways</p>



<ol><li>According to the traditional conception of the universe, objects move on well-defined paths and have definite histories. We can specify their precise position at each moment in time. Although that account is successful enough for everyday purposes, it was found in the 1920s that this ‚Äúclassical‚Äù picture could not account for the seemingly bizarre behavior observed on the atomic and subatomic scales of existence. Instead it was necessary to adopt a different framework, called quantum physics. Quantum theories have turned out to be remarkably accurate at predicting events on those scales, while also reproducing the predictions of the old classical theories when applied to the macroscopic world of daily life. But quantum and classical physics are based on very different conceptions of physical reality.</li><li><strong>We will explain Feynman‚Äôs approach in detail, and employ it to explore the idea that the universe itself has no single history, nor even an independent existence. That seems like a radical idea, even to many physicists. Indeed, like many notions in today‚Äôs science, it appears to violate common sense. But common sense is based upon everyday experience, not upon the universe as it is revealed through the marvels of technologies such as those that allow us to gaze deep into the atom or back to the early universe.</strong></li><li><strong>To deal with such paradoxes we shall adopt an approach that we call model-dependent realism. It is based on the idea that our brains interpret the input from our sensory organs by making a model of the world. When such a model is successful at explaining events, we tend to attribute to it, and to the elements and concepts that constitute it, the quality of reality or absolute truth. But there may be different ways in which one could model the same physical situation, with each employing different fundamental elements and concepts. If two such physical theories or models accurately predict the same events, one cannot be said to be more real than the other; rather, we are free to use whichever model is most convenient.</strong><ol><li><em>Model-dependent realism, mental models</em></li></ol></li><li><strong>M-theory is not a theory in the usual sense. It is a whole family of different theories, each of which is a good description of observations only in some range of physical situations. It is a bit like a map. As is well known, one cannot show the whole of the earth‚Äôs surface on a single map. The usual Mercator projection used for maps of the world makes areas appear larger and larger in the far north and south and doesn‚Äôt cover the North and South Poles. To faithfully map the entire earth, one has to use a collection of maps, each of which covers a limited region. The maps overlap each other, and where they do, they show the same landscape. M-theory is similar. The different theories in the M-theory family may look very different, but they can all be regarded as aspects of the same underlying theory. They are versions of the theory that are applicable only in limited ranges‚Äîfor example, when certain quantities such as energy are small. Like the overlapping maps in a Mercator projection, where the ranges of different versions overlap, they predict the same phenomena. But just as there is no flat map that is a good representation of the earth‚Äôs entire surface, there is no single theory that is a good representation of observations in all situations.</strong><ol><li><em>The Mp is Not the Terrain</em></li></ol></li><li>Today most scientists would say a law of nature is a rule that is based upon an observed regularity and provides predictions that go beyond the immediate situations upon which it is based.<ol><li><em>General and broadly applicable</em></li></ol></li><li>Because it is so impractical to use the underlying physical laws to predict human behavior, we adopt what is called an effective theory. In physics, an effective theory is a framework created to model certain observed phenomena without describing in detail all of the underlying processes.</li><li>There is no picture- or theory-independent concept of reality. Instead we will adopt a view that we will call model-dependent realism: the idea that a physical theory or world picture is a model (generally of a mathematical nature) and a set of rules that connect the elements of the model to observations. This provides a framework with which to interpret modern science.</li><li><strong>We make models in science, but we also make them in everyday life. Model-dependent realism applies not only to scientific models but also to the conscious and subconscious mental models we all create in order to interpret and understand the everyday world. There is no way to remove the observer‚Äîus‚Äîfrom our perception of the world, which is created through our sensory processing and through the way we think and reason. Our perception‚Äîand hence the observations upon which our theories are based‚Äîis not direct, but rather is shaped by a kind of lens, the interpretive structure of our human brains.</strong><ol><li><em>Mental Models, Galilean Relativity</em></li></ol></li><li><strong>A model is a good model if it: Is elegant, Contains few arbitrary or adjustable elements, Agrees with and explains all existing observations, Makes detailed predictions about future observations that can disprove or falsify the model if they are not borne out.</strong></li><li>Another of the main tenets of quantum physics is the uncertainty principle, formulated by Werner Heisenberg in 1926. The uncertainty principle tells us that there are limits to our ability to simultaneously measure certain data, such as the position and velocity of a particle. According to the uncertainty principle, for example, if you multiply the uncertainty in the position of a particle by the uncertainty in its momentum (its mass times its velocity) the result can never be smaller than a certain fixed quantity, called Planck‚Äôs constant. That‚Äôs a tongue-twister, but its gist can be stated simply: The more precisely you measure speed, the less precisely you can measure position, and vice versa.</li><li><strong>In other words, nature does not dictate the outcome of any process or experiment, even in the simplest of situations. Rather, it allows a number of different eventualities, each with a certain likelihood of being realized.</strong></li><li>Given the state of a system at some time, the laws of nature determine the probabilities of various futures and pasts rather than determining the future and past with certainty.</li><li><strong>Quantum physics tells us that no matter how thorough our observation of the present, the (unobserved) past, like the future, is indefinite and exists only as a spectrum of possibilities. The universe, according to quantum physics, has no single past, or history. The fact that the past takes no definite form means that observations you make on a system in the present affect its past.</strong></li><li>Electric and magnetic forces are far stronger than gravity, but we don‚Äôt usually notice them in everyday life because a macroscopic body contains almost equal numbers of positive and negative electrical charges. This means that the electric and magnetic forces between two macroscopic bodies nearly cancel each other out, unlike the gravitational forces, which all add up.</li><li>Maxwell‚Äôs equations dictate that electromagnetic waves travel at a speed of about 300,000 kilometers a second, or about 670 million miles per hour. But to quote a speed means nothing unless you specify a frame of reference relative to which the speed is measured. That‚Äôs not something you usually need to think about in everyday life. When a speed limit sign reads 60 miles per hour, it is understood that your speed is measured relative to the road and not the black hole at the center of the Milky Way. But even in everyday life there are occasions in which you have to take into account reference frames. For example, if you carry a cup of tea up the aisle of a jet plane in flight, you might say your speed is 2 miles per hour. Someone on the ground, however, might say you were moving at 572 miles per hour. Lest you think that one or the other of those observers has a better claim to the truth, keep in mind that because the earth orbits the sun, someone watching you from the surface of that heavenly body would disagree with both and say you are moving at about 18 miles per second, not to mention envying your air-conditioning.<ol><li><em>Galilean Relativity</em></li></ol></li><li>Electromagnetic forces are responsible for all of chemistry and biology.</li><li>The histories that contribute to the Feynman sum don‚Äôt have an independent existence, but depend on what is being measured. We create history by our observation, rather than history creating us. The idea that the universe does not have a unique observer-independent history might seem to conflict with certain facts we know. There might be one history in which the moon is made of Roquefort cheese. But we have observed that the moon is not made of cheese, which is bad news for mice. Hence histories in which the moon is made of cheese do not contribute to the present state of our universe, though they might contribute to others. That might sound like science fiction, but it isn‚Äôt.</li><li>What makes this universe interesting is that although the fundamental ‚Äúphysics‚Äù of this universe is simple, the ‚Äúchemistry‚Äù can be complicated. That is, composite objects exist on different scales. At the smallest scale, the fundamental physics tells us that there are just live and dead squares. On a larger scale, there are gliders, blinkers, and still-life blocks. At a still larger scale there are even more complex objects, such as ‚Ä¶</li></ol></div></article></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blas.com/the-grand-design/">https://blas.com/the-grand-design/</a></em></p>]]>
            </description>
            <link>https://blas.com/the-grand-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646120</guid>
            <pubDate>Thu, 01 Oct 2020 01:08:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Computer Dungeon Slash Postmortem]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24646063">thread link</a>) | @panic
<br/>
September 30, 2020 | https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem | <a href="https://web.archive.org/web/*/https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-article_id="496">


    

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image2.png"></p>


        

    


<p>I consider <a href="https://museumofzzt.com/file/c/CDZ20MOZ.ZIP" target="_blank"><i>Computer Dungeon Slash: ZZT 2.0</i></a> my personal best for ZZT games. I've now released two versions, one in September of 2019 and then another with some updates and optimizations in May of 2020. Aside from a couple of smaller errors and special-thanks additions, there's not much more to fix, so this will probably be the final version with any major changes.</p>

<p>Like some of my previous ZZT games, it relies heavily on procedural generation, with apparently such complexity that Dr. Dos called it "basically sorcery" during their <a href="https://museumofzzt.com/article/479/livestream-computer-dungeon-slash-zzt-20">playthrough on Twitch</a>, which I took as a great compliment. He also mentioned that this game, its generators in particular, could use a write-up. So I wrote one!</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image24.png"></p>

<p>In case you're reading this and unfamiliar with this game, it concerns a player finding themselves in the town of Habeas Corpus, where almost everyone and everything has been swallowed by the dungeon.</p>

<p>The player's task is to brave the randomly-generated dungeon, rescuing the town and townspeople from its clutches.</p>

<p>There's not much more plot or lore than the above, since I focused mainly on characterization in my worldbuilding and most of the actual plot isn't revealed until the end.</p>

<p>So what about the workings of this game?</p>

<p>I'll start with "sorcery"--there's something to that, for sure. When I work with procedural generation it feels a bit like alchemy. Scientific, but also a little bit mysterious and magical. I hope this article helps you better understand the scientific side of that coin.</p>

<p>For readers not intimately familiar with ZZT, one reason a veteran ZZTer would call my level generation "sorcery"  is its limitations. ZZT is a 1991 DOS game-creation-system, after all, simple enough for 8-year-old me to use. So if you don't know anything about ZZT coming in, I hope this write-up helps you better understand the absurdity and appeal of working in it and pushing its limits.</p>

<p>Further, if you came into this wanting to know how this stuff works so that you can experiment with it or even improve on it, I want you to be empowered to do so.</p>

<h2>Goals</h2>

<p>With <i>Computer Dungeon Slash: ZZT</i> (called <i>CDZ</i> here for short) I had three goals for generation. I wanted levels to be interesting to look at, fun to play, and fair. What does fair mean?</p>

<p>Most previous ZZT releases with procedural generation would probably not soft-lock players (block them off from finishing the game). In the early 2000s when this fad hit, most ZZTers involved were in high school and "probably not" was enough. But that small chance of soft-locking players with my generators annoyed me even then.</p>

<p>With <i>CDZ</i>, I wanted some certainty that my algorithms absolutely would not soft-lock players.</p>

<p>With these goals in mind, let's look at the tools I had to accomplish them.</p>

<h2>Building Blocks for Procedural Level Generation in ZZT</h2>

<p>ZZT is tile-based, so making it create its own levels is kind of like generating dungeons for classic ASCII roguelikes, except with much more restrictive tools and limits than, for example, C++ or Python. There's no way to easily store level layout data outside of "in the level", and ZZT boasts precious few variables and only ten true-or-false flags. In addition, the entire game is made up of "boards" of only 60x25 tiles! Despite being such a limited system, ZZT lets us do a fair amount.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image4.png">
<img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image7.gif"></p>

<p>Almost any element (terrain or other object) that takes up a space on a board is helpful, but a few basic ones are laid out in a reference image on the left. Fake walls prove pretty invaluable because they don't block objects but help the engine easily keep track of where another terrain type <i>will</i> later appear.</p>

<p>While <i>CDZ</i> uses sliders and boulders to some extent, the classic examples of ZZT level generators using sliders and boulders are probably WiL's <i>Run-On</i> and Benco's <i>Lost</i>.</p>

<p>And of course, one of the elements of play is actually <i>called</i> an object, and can run little scripts in ZZT-OOP, the engine's default "language." ZZT-OOP has a number of helpful commands for procedural generation.</p>

<p>The <code>#change</code> command can change almost any ZZT gameplay element into almost any other, which is invaluable both for structuring and theming levels. <code>#put THING DIRECTION</code> and <code>#become THING</code> allow for level builder objects to modify environments directly, and they have a more complex use we'll go into later.</p>

<p>Procedural level generation in <i>CDZ</i> is random. Appropriately, ZZT-OOP's random directions proved immensely useful in making it happen. A number of situations call for a "four-sided" dice-roll, and ZZT does have an <i>rnd</i> direction (randomly north, south, east, or west), but as the reader may know, <i>rnd</i> is twice as likely to give an east-west result as a north-south. So what to do?</p>

<p>Well, there are also <i>rndne</i> (north or east) and <i>rndp DIRECTION</i> (one of two directions perpendicular to <i>DIRECTION</i>). Because <i>rndne</i> is a valid direction in itself, you can use <i>rndp rndne</i> to get a random cardinal direction with equal probability of each. (I'm ashamed that I didn't realize that one until reading Anna Anthropy's <i>ZZT</i> a few years back.)</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image14.gif"></p>

<p>In ZZT, <code>#if blocked DIRECTION</code> tells an object whether it is blocked in a given direction. And <code>#send OBJECTNAME:LABEL</code> tells another object, <i>OBJECTNAME</i>, to immediately begin executing code starting with <i>:LABEL</i>.</p>

<p>Slime enemies move erratically and leave breakable walls behind, so you can change their color frequently to fill empty spaces with different colors of breakable walls.</p>

<p>One last limitation and one last "coding" trick deserves mention. ZZT has a limit of about 20 kilobytes per board (including code) before the board misbehaves or gets corrupted at runtime. Objects can use the command <code>#bind OBJECTNAME</code> to work from the same exact instance of the same code as the other object <i>OBJECTNAME</i>, saving valuable code space.</p>

<p>Nowadays, one can "pre-bind" objects with external editors, causing them to share identical labels and behaviors but eliminating the need for the 5+ bytes of space that a <code>#bind</code> command needs.</p>

<h2>Two Big Insights</h2>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image18.png">
<img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image20.png"></p>

<p>In addition to the more concrete "tools" above, two big conceptual insights greatly impacted this project. The first is about level connectedness, and it hit me after reading Rabbitboots's musings on house generation in <a href="https://museumofzzt.com/file/d/dood2018.zip" target="_blank"><i>Doodads 2018</i></a>.</p>

<p>Say I have a house with four rooms, and I block off only one doorway in the house, as on the left. Any room in the house can still visit any other.</p>

<p>Rabbitboots goes on to note that if we make a larger house out of smaller ones, the large house remains fully connected.</p>

<p>If House A connects to House B and B connects to House C, then A connects to C.</p>

<p>This was huge for me. It gave me hope that I could avoid soft-locks while also making more interesting, varied levels.</p>

<p>Shortly after the 2019 release, while looking at TriphEd's maze generation in <a href="https://museumofzzt.com/file/b/BACKTRAX.zip" target="_blank"><i>Backtrax</i></a>, I had another "Aha!" moment.</p>


<p>The algorithm is best explained step-by-step, and you can follow along with the following roughly equivalent method if you have a pencil and paper.</p>

<p>(1) Start with a grid of dots. Any size 3 x 3 or up will do.</p>

<p>(2) Connect all the outer dots along the edge so that they make a rectangle.</p>

<p>(3) For each "middle dot" within the square, draw <i>exactly one line</i> from that dot to any dot directly above, below, left, or right of it. Edge dots can receive lines.</p>

<p>If you used a 3 x 3 grid of dots, the end result will resemble the 2 x 2 house above.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/backtrax-levels.gif"></p>

<p>Any edge tile can access any other edge tile in this algorithm. It can leave some squares inaccessible from the edges, but this is acceptable if nothing essential to player progress is placed in those tiles.</p>

<p>In ZZT, you can accomplish this by having objects use <code>#put rndp rndne ELEMENT</code> on a grid, and that's exactly what <i>Backtrax</i> is doing.</p>

<p>A <i>very</i> small set of soft-lock possibilities does exist in <i>Backtrax</i>. Because there's a blocking linewall diagonally southeast of the lower-right-hand wall generator object, the wrong combinations of walls <i>could</i> block the player, but it is <i>incredibly</i> unlikely and easily remedied.</p>

<p>This is the most elegant level generator in ZZT to date--and also, in case it wasn't already elegant enough, it weighs in at only 10.9 kilobytes and re-uses its "grid" after you reach the exit, using a separate trick (that I won't discuss in detail here) to teleport the player back to the start for a new level.</p>

<p>Recognize TriphEd's genius.</p>

<p>After the initial <i>CDZ</i> release, I experimented a lot with this algorithm. Several generators in version 2.0 benefited from its use. We can now move slowly but surely into the actual inner workings of this game.</p>

<h2>Primary Generators</h2>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image6.png"></p>

<p><i>Computer Dungeon Slash</i> level generators have a "primary generator" object that handles a lot of needed dice-rolls and uses <code>#send</code> to communicate its randomization to different groups of objects. It's usually set up as on the left, or similar.</p>

<p>This particular setup involves fake walls placed north, south, east, and west of the primary generator and water (a blocking terrain) in the four corners. To make a four-direction roll, it uses <code>#put rndp rndne gem</code> and then iterates over some variation of:</p>

<code>#if blocked n #send object:option1
#if blocked e #send object:option2
#if blocked s #send object:option3
#if blocked w #send object:option4</code>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image16.png"></p>

<p>The objects referred to in the <code>#send object:option</code> commands  are pre-bound objects with exactly the same code, and positioned so that only one of them will place a wall, generate an important key, etc. at the time they're called. In this example, the pre-bound group of objects has this code:</p><p>

<code>@object
#cycle 1
#end
:option1
#if blocked n become solid
#die
:option2
#if blocked e become solid
#die
:option3
#if blocked s become solid
#die
:option4
#if blocked w become solid
#die</code></p><p>There is a fake wall in the middle of the house, so that only one object becomes a wall, and the rest die. Then the primary generator turns the fake into a solid wall.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image23.gif"></p>

<p>This method also extends to larger houses similar to those in the <i>Doodads 2018</i> example, and can ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem">https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem</a></em></p>]]>
            </description>
            <link>https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646063</guid>
            <pubDate>Thu, 01 Oct 2020 00:59:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ontario doctors sign letter to Premier advising against sweeping lockdowns]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 175 (<a href="https://news.ycombinator.com/item?id=24645821">thread link</a>) | @mrfusion
<br/>
September 30, 2020 | https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html | <a href="https://web.archive.org/web/*/https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>



<div>
    
        <p>Published Sept. 30, 2020 9:40 a.m. ET</p>
        <p>Updated  Sept. 30, 2020 7:26 p.m. ET</p>
    
</div>



  


    
        
        
    
    
    <amp-iframe resizable="" width="16" height="17" layout="responsive" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation" allowfullscreen="" frameborder="0" src="https://ampvideo.ctvnews.ca/content/ctvnews/en/local/ottawa/2020/9/30/1_5126193.vidi.root-responsivegrid-vidicomponent.html?preventDefault=true">
        
        <p>Click to Expand</p>
    </amp-iframe>





    <p>OTTAWA -- 	Twenty-one Ontario doctors have signed a joint letter to Premier Doug Ford, urging him not to issue a new lockdown this fall because of rising COVID-19 case numbers.</p><p>	Daily numbers of new cases have risen dramatically in recent days, with Ontario recording <a href="https://toronto.ctvnews.ca/new-covid-19-cases-in-ontario-reach-highest-mark-ever-1.5122863" target="_blank">700 new cases of COVID-19 on Monday</a> ‚Äì the highest number of new cases recorded in a single day.</p><p>	However, the 21 doctors who signed the letter to the premier say another provincewide lockdown‚Äîsimilar to what was in place in the spring‚Äîwould not be helpful.</p><ul>	<li>		<a href="#Full letter"><i>Read the full letter below</i></a></li></ul><p>	"We are writing this letter in support of the governments‚Äô plan to use a tactical localized approach, rather than sweeping new lockdown measures, to deal with the increasing COVID case numbers in Ontario," the letter says.&nbsp;</p><p>	"Lockdowns have been shown not to eliminate the virus. While they slow the spread of the virus, this only lasts as long as the lockdown lasts. This creates a situation where there is no way to end the lockdown, and society cannot move forward in vitally important ways including in the health sector, the economy and other critically important instrumental goods including education, recreation, and healthy human social interactions."</p><p>	Speaking on Newstalk 580 CFRA's "The Morning Rush with Bill Carroll" in Ottawa, CTV's infectious disease specialist Dr. Neil Rau‚Äîa signatory of the letter‚Äîpointed to two data points to consider when looking at the spread of COVID-19.</p><p>	"We're reacting to increased aggregate case numbers, but the percentage positive is not really as bad as it used to be," he said. "We're testing more people, so we're finding more cases [‚Ä¶] We're driving our numbers up, it's worse than it was in the summer, but it's not what it was last winter and life has to go on."</p><ul>	<li>		<a href="https://www.iheartradio.ca/580-cfra/podcasts/the-morning-rush-dr-neil-rau-interview-why-we-don-t-want-another-lockdown-1.13612912?mode=Article" target="_blank"><strong>LISTEN NOW: "The Morning Rush": Dr. Neil Rau - Why we don't want another lockdown</strong></a></li></ul><p>	Monday's 700 cases in Ontario came from 41,111 total tests, for a positive percentage rate of 1.7 per cent. On April 24, <a href="https://toronto.ctvnews.ca/highest-number-of-new-covid-19-cases-in-a-single-day-reported-by-ontario-health-officials-1.4910216" target="_blank">the previous watermark of 640 new cases in a single day</a>, the result came from 12,295 tests, for a positive percentage rate of 5.2 per cent.</p><p>	Testing capacity was lower in the spring than it is now, and testing criteria has changed over time; however, Dr. Rau and the other signatories of the letter said the increasing case numbers are not leading to unmanageable levels of hospitalizations.</p><p>	"In Ontario and other parts of the world, such as the European Union, increasing case loads are not necessarily translating into unmanageable levels of hospitalizations and ICU admissions," the letter says.</p><p>	The letter also points to other health impacts linked to the lockdown.</p><p>	"Hard data now exist showing the significant negative health effects shutting down society has caused. Overdoses have risen 40% in some jurisdictions. Extensive morbidity has been experienced by those whose surgery has been cancelled, and the ramifications for cancer patients whose diagnostic testing was delayed has yet to be determined," the letter states.</p><p>	"Economic harms are health harms," Dr. Rau told CFRA. "It sounds horrible to say, but it's true. Health is wealth. We all know this."</p><h2>	<strong>LETTER POINTS TO DISAGREEMENT AMONG HEALTH PROFESSIONALS</strong></h2><p>	Other Ontario health professionals have been arguing for increased restrictions as cases rise.</p><p>	Last week, the Ontario Hospital Association released a letter signed by 38 health professionals which <a href="https://ottawa.ctvnews.ca/ontario-hospital-association-calls-for-return-to-restrictions-on-non-essential-businesses-1.5119832" target="_blank">called for immediate restrictions to be re-imposed on non-essential businesses</a>, such as gyms, dine-in restaurants and bars, nightclubs, and theatres. It also calls on restrictions on other places where people can gather, such as places of worship.</p><p>	The letter from the OHA said regions where the speed of transmission was underestimated are ‚Äúnow facing the consequence of increased hospitalization rates, including a rise in intensive care unit (ICU) admissions and more deaths.‚Äù</p><p>	Hospitalizations in Ontario have been increasing, but have not yet reached the same level that was seen in the spring.</p><p>	According to <a href="https://covid-19.ontario.ca/data" target="_blank">data from the Ontario government</a>, there were 128 people in hospital in Ontario with COVID-19 complications on Monday‚Äîthe day 700 new cases were recorded‚Äîup from 65 a week before; however, on April 24‚Äîwhen 640 new cases were recorded‚Äîgovernment data shows that there were 910 people in hospital. The peak for hospitalizations in Ontario came in May, when there were days when more than 1,000 people were hospitalized. That number steadily decreased from May through the summer before it began going up again in September.</p><p>	Speaking on CTV Morning Live Ottawa, infectious disease specialist Dr. Abdu Sharkawy suggested t<a href="https://ottawa.ctvnews.ca/video?clipId=2045684" target="_blank">emporary restrictions on gathering would help curb the spread of COVID-19</a>.&nbsp;</p><p>	"We don't want to see our hospitals overwhelmed," he said. "We're still waiting for flu season and a whole bunch of other respiratory viruses to hit us and our capacity to be challenged. We don't want that to happen. We need everybody to try and simplify their lives and minimize anything that's non-essential."</p><p>	Dr. Sharkawy said regions where cases are rapidly rising may need to impose new restrictions to get the spread of the virus under control.</p><p>	"I think it's abundantly clear that, particularly in hot spots like Ottawa, Toronto and Peel region, the situation is not well controlled," he said. "Sometimes you need blunt instruments, even if they're temporary in nature, to make sure that you curtail the spread of this virus because it gets away from us a lot more quickly than many of us can anticipate sometimes."</p><p>	Dr. Sharkawy suggested hot spots follow the lead of Quebec, which imposed <a href="https://montreal.ctvnews.ca/life-in-the-red-zone-here-s-what-you-can-and-can-t-do-1.5125093" target="_blank">harsh restrictions on three areas in the province</a>, including Montreal and Quebec City, banning private gatherings and closing bars and restaurant dining rooms.</p><p>	"I think we should do it now," Dr. Sharkawy said of Ontario. "I think we all need to adopt an attitude and an approach that recognizes that we have to do what's absolutely necessary to keep everybody safe."</p><h2>	<strong>FULL LETTER FROM ONTARIO DOCTORS TO THE PREMIER</strong></h2><p>	Dear Premier Ford,</p><p>	We are writing this letter in support of the governments‚Äô plan to use a tactical localized approach, rather than sweeping new lockdown measures, to deal with the increasing COVID case numbers in Ontario. Lockdowns have been shown not to eliminate the virus. While they slow the spread of the virus, this only lasts as long as the lockdown lasts. This creates a situation where there is no way to end the lockdown, and society cannot move forward in vitally important ways including in the health sector, the economy and other critically important instrumental goods including education, recreation, and healthy human social interactions.</p><p>	In Ontario the increase in cases at this time are in people under 60 years of age who are unlikely to become very ill. At the peak of the pandemic in Ontario in mid-April, 56% of cases were in ‚â•60 year olds, now in Sept only 14% of cases are in ‚â•60 year olds. In Ontario and other parts of the world, such as the European Union, increasing case loads are not necessarily translating into unmanageable levels of hospitalizations and ICU admissions. This is not a result of a lag in reporting of severe and fatal cases. While we understand the concerns that these cases could spill into vulnerable communities, we also need to balance the actual risk. As the virus circulates at manageable levels within the community, we need to continue the gains we have made in the protection of the vulnerable in long-term care and retirement institutions, and continue to educate other people about their individual risk, so that they can observe appropriate protective measures.</p><p>	Lockdowns have costs that have, to this point, not been included in the consideration of further measures. A full accounting of the implications on health and well-being must be included in the models, and be brought forward for public debate. Hard data now exist showing the significant negative health effects shutting down society has caused. Overdoses have risen 40% in some jurisdictions. Extensive morbidity has been experienced by those whose surgery has been cancelled, and the ramifications for cancer patients whose diagnostic testing was delayed has yet to be determined. A huge concern is the implication of closure of schools, and the ongoing reluctance we have seen in the large urban centers of sending children back to the classroom due to safety concerns. Global data clearly now show that children have an extremely low risk of serious illness, but they are disproportionately harmed by precautions. Children‚Äôs rights to societal care, mental health support and education must be protected. This cannot be achieved with ongoing or rotating lockdown.</p><p>	The invitation and involvement of other health experts to advise the government‚Äôs response beside individuals in Public Health and Infectious Diseases in addition to leaders in the business, securities and arts communities is essential. We also call for increased open debate, in the public forum, that hears voices from outside the medical and public health communities, in order to consider all points of view from society. This is a fundamental principle upon which democratic societies are built. All stakeholders should have an equal right to participation in public discourse when it comes to setting such fundamental and sweeping societal interventions.</p><p>	All have the right to feel their voices have been heard, and moreover to ensure factual credible data is openly debated, in contrast to the personal and political slants that have had apparent significant impacts on the management of the virus to date. Our society has borne enormous pain over the past 6 months. It‚Äôs time to do something different.</p><p>	Sincerely,</p><p>	Jane Batt MD, PhD, FRCPC. Respirologist, Associate Professor, Department of ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html">https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html</a></em></p>]]>
            </description>
            <link>https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24645821</guid>
            <pubDate>Thu, 01 Oct 2020 00:23:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A housing industry of endless one-offs is holding our society back]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 156 (<a href="https://news.ycombinator.com/item?id=24645525">thread link</a>) | @jseliger
<br/>
September 30, 2020 | https://blokable.com/news/the-housing-market-is-building-snowflakes-an-endless-series-of-one-offs/ | <a href="https://web.archive.org/web/*/https://blokable.com/news/the-housing-market-is-building-snowflakes-an-endless-series-of-one-offs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2><strong>By Aaron Holm and Nelson Del Rio,<br>Co-CEOs, Blokable Inc.</strong></h2><h2>The following post breaks down the high cost of building housing as part of a series exploring the root causes of the U.S. housing crisis and how private and public sector collaboration can chart a different course.&nbsp;</h2><figure><img width="1200" height="800" src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjA0OCAxMzY0IiB3aWR0aD0iMjA0OCIgaGVpZ2h0PSIxMzY0IiBkYXRhLXU9IiUyRndwLWNvbnRlbnQlMkZ1cGxvYWRzJTJGMjAyMCUyRjA5JTJGQmxvZy0yLWltYWdlLTIwNDh4MTM2NC5qcGciIGRhdGEtdz0iMjA0OCIgZGF0YS1oPSIxMzY0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==" data-spai="1" alt="" sizes="(max-width: 1200px) 100vw, 1200px"></figure><p>In mid-2018 we met with Washington State Governor Jay Inslee to discuss the insatiable need for affordable housing in the Pacific Northwest. We gave him a tour of Blokable‚Äôs prototype factory in Vancouver, Wash., and shared our R&amp;D work to reimagine how housing is built. Afterward, we drove up to Seattle in a rented Nissan Maxima, wondering aloud what it would cost to build our rental car from scratch in a driveway ‚Äî exactly how nearly all housing is built today.&nbsp;&nbsp;&nbsp;</p><p>We would have to design, engineer, and fabricate all of the car‚Äôs systems and components, specify and source the materials, identify the regulatory requirements and work with different agencies to test our systems and sign off on safety and environmental requirements, create a working set of engineering drawings to track the build, order the equipment necessary to complete the assembly, and hire at least a small team of people to put the car together. A car that retails for just under $35,000 would cost tens of millions of dollars to build, and there would be no guarantees of quality and reliability.&nbsp;</p><p>Every time a new residential real estate project appears on the landscape, it‚Äôs a bespoke process that can directly involve hundreds of people, including a developer and a general contractor, various architects and engineers, and the investors who are funding the project. For each participant in the process, the singular goal is to extract a profit from that specific patch of dirt, and their profits are circumscribed by the value of the land, the applicable building regulations, and the prevailing labor and capital costs.&nbsp;</p><p>The result of this one-off approach is soaring project costs that make housing simply unaffordable to most people in many parts of the U.S.. Conventional housing development is like building a snowflake every time. And if the glut of empty luxury condo towers in downtown San Francisco is any indication, many of these snowflake projects are indeed melting as soon as they touch the ground.&nbsp;</p><p>How did this one-off approach to development take shape? Everything from ovens to stereos were all once clunky prototypes built as one-offs in the same location as their eventual use. Over time with innovation, standardization, and market demand, they evolved into products. In the early days of the automobile and aviation industries, prototypes and projects were built at high cost and yielded low quality results that resembled the current market products in their most basic functionality: they could drive and fly. Early automobile and airplane prototypes were unsafe and expensive. But through investment in product design, engineering, prototyping, and manufacturing, these prototypes eventually evolved into products. Increasingly stable designs and specifications enabled greater standardization, repeatability, and mass production resulting in lower costs, higher quality, and broader distribution.&nbsp;</p><p>Coupled with clear market demand, this standardization led to the formation of entire industries to build roads and airports, manufacture tires, test safety under federal guidelines, and so on. If you visit the automotive and aviation manufacturing hubs around Detroit and Seattle you‚Äôll find vibrant supply chains competing for business and investing in innovation to provide better products and services. Continuously improving engines, seats, windshields, and bathrooms. All of this activity creates ever-improving products and fierce competition for performance, quality, and price.&nbsp;&nbsp;</p><p>If we compare product manufacturing in the automotive and aviation industries to how we build housing ‚Äî whether it is an Accessory Dwelling Unit (ADU), single family home, multi-family apartment building, or a high rise ‚Äî the steps in the process are largely the same. To simplify the housing development process, let‚Äôs assume the land is entitled, there are no environmental mitigation issues, financing is secured, and development will not be opposed by regulatory agencies or local city council. What does it take to build a snowflake?</p><figure><img width="1200" height="800" src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjA0OCAxMzY0IiB3aWR0aD0iMjA0OCIgaGVpZ2h0PSIxMzY0IiBkYXRhLXU9IiUyRndwLWNvbnRlbnQlMkZ1cGxvYWRzJTJGMjAyMCUyRjA5JTJGQmxvZy0yLWJvZHktaW1hZ2UtMjA0OHgxMzY0LmpwZyIgZGF0YS13PSIyMDQ4IiBkYXRhLWg9IjEzNjQiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PC9zdmc+" data-spai="1" alt="Housing creation is an endless series of one-offs" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption><em>Conventional housing development is like building a snowflake every time.</em></figcaption></figure><p>Let‚Äôs look at the absolute bare minimum of steps in the process from the perspective of the developer. Broadly speaking, the developer identifies and ties up the site, conducts preliminary site review and discussions with impacted parties, manages entitlements, financing, and the project approval process for the site, oversees all building and owns the project along with any equity investors they have brought in to finance the deal. With respect to the building process itself, the developer will partner with an architect to work up a site massing and design that will satisfy the intended program ‚Äî the mix of units, floorplans, common spaces, revenue generating and non-revenue generating space ‚Äî as well as the code requirements for the building and the site. Once the basic architecture is in place, the project heads over to engineers, which are typically separate firms with separate contracts, costs, regulatory oversight, and liability, to specify structural engineering, MEP (mechanical, electrical, plumbing), and site and offsite engineering.&nbsp;</p><p>With the initial design and engineering complete, the developer sends a construction set of drawings to a general contractor (GC) for final pricing. The GC will take the specifications and build out a schedule and budget to determine how much work they intend to do themselves (self-perform) vs. how much work they will contract out to sub-contractors (subs). The GC will oversee all of the work necessary to build this custom-designed and engineered project on-site, including civil, foundation, pulling utilities, framing, rough-in and waterproofing, siding and cladding, roofing, windows and doors, MEP, paint and trim, fixtures and finishes, and ultimately certificate of occupancy.&nbsp; It is important to note that at this stage the GC‚Äôs quote is just an estimate. We haven‚Äôt built anything yet.</p><p>With approved drawings, financing, budget, and schedule in hand, the developer can start the snowflake build. Every step listed in the paragraph above must be completed by the corresponding specialists, and getting the work done on schedule is much more of an art than a science. Each contractor and subcontractor has their own contractual obligations, risks, and liability. Getting to the certificate of occupancy means the developer has navigated the process and can now bring in buyers or renters to start paying off the decades of debt that were secured to finance the build.&nbsp; When the developer moves on to the next project, all of the steps must be performed again, without exception. The finished project may be beautiful, energy efficient, or last 100 years, but it will still be a one-off.&nbsp;&nbsp;</p><p>All of this work is done for every project every time, regardless of size. A home or apartment is not more complicated than a car or plane, and while the unique attributes of individual sites and real estate do add challenges to repeatability, it is possible to decouple the building from the dirt.</p><p>We can‚Äôt be surprised that building costs for new housing continue to escalate. We can‚Äôt be surprised that it‚Äôs even more expensive to create affordable housing. Yet we continue to shrug our shoulders and say, ‚ÄúThat‚Äôs just how it is.‚Äù We dig around the edges of the problem, foraging for scraps by looking for cost savings in commodities, underpaying labor, cutting corners on quality and performance, and building on cheaper land further and further from work and community.&nbsp;</p><p>Housing development is antiquated and the only group benefitting is the real estate development and building industry, who in fact have every incentive to restrict the supply. We‚Äôre making Version 1 of the oven, stereo, car, and plane over and over again, in a housing market that is chronically under-served. The failure to build adequate housing has generational effects on health, education, and opportunity.&nbsp;</p><p>There has to be a better way. We have to re-imagine the housing market and build better. More on that to come in our next post.</p></div></div></div>]]>
            </description>
            <link>https://blokable.com/news/the-housing-market-is-building-snowflakes-an-endless-series-of-one-offs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24645525</guid>
            <pubDate>Wed, 30 Sep 2020 23:48:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bay Area approve plan requiring employees to work from home 3 days a week]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24645083">thread link</a>) | @henryw
<br/>
September 30, 2020 | https://usatodaysun.com/bay-area-says-employees-will-be-required-to-work-from-home-three-days-a-week-after-the-pandemic-to-reduce-greenhouse-gas-emissions/ | <a href="https://web.archive.org/web/*/https://usatodaysun.com/bay-area-says-employees-will-be-required-to-work-from-home-three-days-a-week-after-the-pandemic-to-reduce-greenhouse-gas-emissions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<li><strong>The&nbsp;Metropolitan Transportation Commission approved a plan that would require Bay Area residents to work from home three days a week&nbsp;</strong></li>
<li><strong>The proposal, which was voted on Wednesday, would ensure that sizable, office-based companies keep 60 per cent of their workers home</strong></li>
<li><strong>&nbsp;Transportation officials hope it will reduce greenhouse gas emissions and curb climate change in the area</strong></li>
<li><strong>Some residents and workers opposed the plan by noting that working remotely is not ideal for many people</strong></li>
<li><b>Big Tech companies in Bay Area have already transitioned much of their operations online and some have made remote work a permanent feature&nbsp;</b></li>
<li>
<p>A new proposal could require Californians to work remotely three days a week ‚Äì even after the COVID-19 pandemic ‚Äì to reduce greenhouse gas emissions to aid in environmental efforts.</p>
<p>A number of Bay Area residents, including employees at large tech firms, were concerned over a new proposal approved by the Metropolitan Transportation Commission on Wednesday.</p>
 <!-- A generated by theme --> 



 <!-- end A --> 


<p>The controversial proposal would effectively ensure that sizable, office-based companies kept 60 per cent of their workers at home on any given workday to curb</p>
</li>
<li>
<p>‚ÄòGiven the changes in travel patterns during the&nbsp;<a id="mol-ecbfd540-000a-11eb-af1a-6fc9d77b8f42" href="https://www.dailymail.co.uk/news/coronavirus/index.html">coronavirus</a>&nbsp;pandemic, there was strong support for bolder policies on this front in the Final Blueprint, including a mandate for office-based employers,‚Äô the proposal read.</p>
<p>‚ÄòTo ensure this strategy achieves equity goals, a complementary strategy to expand internet access in underserved communities was added to the Economy Element as well.‚Äô</p>
</li>
<li>
<p>This latest proposal underscores a larger shift towards remote work that became commonplace after the COVID-19 pandemic hit the United States in January.</p>
<p>By March, entire office buildings shuttered and industries stumbled as employers struggled to transfer in-person operations to out of the workplace.</p>
<p>But now, six months later, city officials and some employers viewed the forced transition as a unrealized benefit that could reshape office culture and transportation.</p>
<p>‚ÄòThere is an opportunity to do things that could not have been done in the past,‚Äô said&nbsp;Oakland Mayor Libby Schaaf, a commission member and proposal supporter,</p>
</li>
<li><img loading="lazy" src="https://usatodaysun.com/wp-content/uploads/2020/09/b-300x200.jpg" alt="" width="524" height="349" srcset="https://usatodaysun.com/wp-content/uploads/2020/09/b-300x200.jpg 300w, https://usatodaysun.com/wp-content/uploads/2020/09/b.jpg 634w" sizes="(max-width: 524px) 100vw, 524px"></li>
<li>
<p>A May 2020 study from the&nbsp;Nature Climate Change Journal&nbsp;noted that daily carbon dioxide emissions plunged by 17 per cent in the United States during April.</p>
<p>‚ÄòThe estimated decrease in daily fossil CO2&nbsp;emissions from the severe and forced confinement of world populations of ‚Äì17% (‚Äì11 to ‚Äì25%) at its peak are extreme and probably unseen before,‚Äô the study said.</p>
<p>The commission‚Äôs proposal was found inside a larger policy package titled ‚ÄòPlan Bay Area 2050 Final Blueprint,‚Äô in which officials theorized what the Bay Area could look like in 30 years and what could be done about reducing greenhouse gas emissions.</p>
<p>Members voted 11-1 to approve the overall policy package, including the mandate.</p>
<p>Bay Area is home to Silicon Valley, the central hub of Big Tech firms that have taken different approaches to working from home.</p>
<p>Facebook quickly embraced remote working as a longterm plan&nbsp;and advised its 50,000 staffers to work from home to avoid spreading the coronavirus.</p>
<p>CEO Mark Zuckerberg later announced that the company had extended its work-from-home plan until 2021, allowing employees to avoid the Menlo Park office for the next several months.</p>
<p>Similarly, Twitter, which reported 5,100 employees in its most recent earnings report, ordered employees to work from home .</p>
</li>
<li>
<p>It was later revealed by CEO Jack Dorsey that the company will allow most of its employees to work from home permanently.</p>
<p>‚ÄòOpening offices will be our decision. When and if our employees come back, will be theirs,‚Äô a spokesperson for the company said.</p>
<p>But companies like Apple, that have invested loads of money on its campuses and facilities, have been less eager to fully welcome remote work.</p>
<p>Tim Cook revealed in a recent interview at The Atlantic Festival that he hoped employees would be back in the office by next year and pointed out that remote work doesn‚Äôt allow for certain employee interactions.</p>
<p>When word of the plan reached Bay Area residents, many were concerned and logged onto the virtual commission meeting on Wednesday to object.</p>
<p>‚ÄòWe do not want to continue this as a lifestyle,‚Äô said&nbsp;Steven Buss, a Google software engineer who lives in San Francisco, according to NBC News.</p>
<p>‚ÄòWe are all sacrificing now to reduce the spread of the virus, but no one is enjoying working from home.</p>
<p>‚ÄòIt‚Äôs probably fine if you own a big house out in the suburbs and you‚Äôre nearing retirement, but for young workers like me who live in crowded conditions, working from home is terrible.‚Äô</p>
</li>
<li>
<p>Some residents noted that the strategy enforces workplace inequality since some jobs cannot be performed at home, while others worried about the effects it would have on other industries as a result.</p>
<p>Stacey Randecker called into the meeting on Wednesday and questioned why the proposal included all commute alternatives if the main focus was on car emissions.</p>
<p>‚ÄòYes, yes, yes, we want to reduce greenhouse gases, but why aren‚Äôt you considering transit? Walking? Biking?‚Äô she said.</p>
<p>Duston Moskovitz, co-founder of Facebook, shared the sentiments on Twitter.</p>
<p>‚ÄòWe tried nothing, and we‚Äôre all out of ideas,‚Äô he wrote on Tuesday.</p>
</li>
<li>
<p>Commission member Nick Josefowitz said the work-from-home proposal was a late addition into the policy package.</p>
<p>NBC News reports that&nbsp;Josefowitz attempted to amend the proposal to allow transit and walking from home as alternatives, but critics worried that a delay could result in the commission missing emission reduction targets and an important funding deadline.</p>
<p>‚ÄòIf we start amending this plan at this late hour, do you have any rabbits in your hat that‚Äôs going to get us to the finish line,‚Äô asked commission member&nbsp;Jim Spering.</p>
<p>The proposal added that the work-from-home strategy ‚Äòwas not included in the Draft Blueprint and was added based upon public feedback this summer.‚Äô</p>
<p>MTC executive director Therese McMillan said there would be opportunities to later go over the strategy‚Äôs details and include alternative transportation.</p>
<p>The commission will meet against before the end of the year and then it would need to be implemented over time.</p>
</li>
</div></div>]]>
            </description>
            <link>https://usatodaysun.com/bay-area-says-employees-will-be-required-to-work-from-home-three-days-a-week-after-the-pandemic-to-reduce-greenhouse-gas-emissions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24645083</guid>
            <pubDate>Wed, 30 Sep 2020 23:01:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secrets detection learning center: complete handbook for dev, SEC, ops]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24644392">thread link</a>) | @mackenzie-gg
<br/>
September 30, 2020 | https://www.gitguardian.com/secrets-detection | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection</link>
            <guid isPermaLink="false">hacker-news-small-sites-24644392</guid>
            <pubDate>Wed, 30 Sep 2020 21:49:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissecting Lemire‚Äôs nearly divisionless random]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24644370">thread link</a>) | @bbgm
<br/>
September 30, 2020 | https://veryseriousblog.com/posts/dissecting-lemire | <a href="https://web.archive.org/web/*/https://veryseriousblog.com/posts/dissecting-lemire">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-74174200445ef6e30546"><div><p>This blog post is very late. It‚Äôs well over a year since<a href="https://twitter.com/colmmacc/status/1153727018896244736"> I posted a coding challenge on twitter</a>. The idea was simple, I‚Äôve always felt that code readability is undervalued so I figured I‚Äôd put cold hard cash up. I announced a $1,000 pot, divided into $500, $300, and $200 prizes for the most readable implementations of <a href="https://lemire.me/blog/2019/06/06/nearly-divisionless-random-integer-generation-on-various-systems/">Daniel Lemire‚Äôs nearly divisionless algorithm for selecting a random number from an interval.</a> I now have winners to announce and congratulate, and they‚Äôre in this blog post, but there‚Äôs more to this story.</p><p>I didn‚Äôt know it at the time but I‚Äôd end up reviewing the entries with colleagues to see if they could follow what was happening (spoiler: they couldn‚Äôt). When people got stuck, we‚Äôd whiteboard&nbsp;our way through so that we could better understand why and where people were getting stuck. Oh, to be able to whiteboard in person again!  </p><p>I learned a lot about how people think through problems, and that process led to me writing a seperate implementation of Lemire‚Äôs Algorithm, with a twenty-to-one comment to code ratio (that‚Äôs a lot of comments), and finding a sort-of security issue with the algorithm in the process. I say ‚Äúsort of‚Äù because you really have a ridiculously enormous struggle to find a case where it‚Äôs going to be practical to exploit. But it still surprised me, and you probably can‚Äôt use Lemire‚Äôs algorithm in Vegas.</p><h4>Why Lemire‚Äôs Algorithm?</h4><p>I chose Lemire‚Äôs algorithm because it is brilliant. When I read Lemire‚Äôs code I get that kind of brain-tingling and gawk at the sheer ‚ÄúHow on earth did someone think of this‚Äù of it all. Lemire has a mastery of code and how code is executed, and then pairs that with transcendent creativity and concision.  Lemire also writes well, and the papers that accompany his code and algorithms are easily some of the most cogent and approachable you‚Äôll find in academia. They are short and clear and avoid the jargon and obtuseness that plagues the field, while containing just enough formalism to be rigorous.</p><p>Lemire‚Äôs algorithm is a solution to the problem ‚ÄúGive me a random number between 0 and N, not including N itself‚Äù. For simulating a dice, N would be 6 and you‚Äôd get back either 0, 1, 2, 3, 4, or 5 with equal probability. Computers like to start at zero. We can always add one to the result to get the familiar results you‚Äôd get on a real dice. I‚Äôve worked on random number generators and written quite a few. In 20 years of doing that, I‚Äôd never come across a solution as cool as Lemire‚Äôs.</p><p>Before Lemire, the best-known solutions to this problem required one or two divisions per number generated. You probably learned long division when you were quite young. You may remember that it can be get pretty tedious and cumbersome. It‚Äôs the same for computers. Division is actually one of the slowest things we can ask a computer to do. Lemire avoids division by translating numbers into a much larger number ‚Äúspace‚Äù and using binary-friendly powers-of-two operations instead. His technique almost always avoids needing a division.</p><p>The second reason I chose Lemire‚Äôs algorithm is that it is impenetrable upon first reading. There are lucky few people who are so practiced and conversant in number manipulation that they can see inside of algorithms like Neo in the matrix, but I don‚Äôt mean them. To the average reader, myself included, it‚Äôs not clear what‚Äôs going on and why.</p><p>Lemire‚Äôs reference code is fourteen lines long, like a sonnet. Twelve of the lines are simple, and any proficient programmer could tell <em>what</em> they are doing. Two specific lines of the code are pretty hard to decipher.. But the real difficulty is how hard it is to understand <em>why</em> all 14 lines are doing what they are doing, and <em>why</em> it results in a fair and correct algorithm for choosing a random number.</p><div><p>As a case in point, if you read the comments to Lemire‚Äôs blog, you‚Äôll find several misunderstandings of the code. That‚Äôs within an audience of primed Lemire fans and critics who are familiar with the field. <a href="https://arxiv.org/abs/1805.10941">Lemire‚Äôs accompanying paper</a> is great and very readable, but it still takes effort and concentration to follow everything. I work on cryptography and write cryptographic code for a living and I‚Äôm not ashamed to tell you it took me about 3 readings to really get it. The algorithm is based on an interaction between two modular spaces, one of which is sized 2 to power of 64, and the other is ‚ÄúN‚Äù sized, and if I just totally lost you there, I beg forgiveness and if you bear with me I promise there‚Äôs a link to my detailed dissection of how and why everything works. </p><p>All of this makes Lemire‚Äôs algorithm a really good challenge for creating a more readable version. Ideally something that an average coder can read in one pass, understand, and agree that it‚Äôs correct. </p></div><h4>Why does readability matter?</h4><p>Code readability is the most important pillar of code correctness and maintainability. When code is unreadable, it is harder to spot errors. That‚Äôs true when you‚Äôre doing a code review and it‚Äôs even more true when you‚Äôre adding more code to an existing code base. Great testing can compensate for some of the correctness challenges, but it doesn‚Äôt do as much for maintainability. </p><p>In s2n, one of our <a href="https://github.com/awslabs/s2n/blob/main/docs/DEVELOPMENT-GUIDE.md">development principles</a> is to write clear readable code with a light cognitive load. We‚Äôre serious about it, and I wasn‚Äôt going to try and use Lemire‚Äôs algorithm in s2n without a very readable implementation.</p><p>Working in software development I‚Äôve heard the opinion more than once about how programmers and coders should be more familiar with the fundamental mathematics of logic and number theory that underpin their field, and that academic style papers and explanations should be sufficient. I happen to work with teams that are made up of both expert coders and expert mathematicians, and even there I don‚Äôt think this is a good idea.</p><p>Software engineering is engineering, which means translating science into solutions that work in the real world.  To wildly generalize, there are better dividends to be found in focusing on deepening ones understanding of the ‚Äúreal world‚Äù part of that, the users, the customers, the business models, usability, ergonomics, and so on, than on the ‚Äúscience‚Äù part of that. Some science is needed, but there‚Äôs a shallow limit. Just as a civil engineer doesn‚Äôt need too detailed an understanding of the chemistry of concrete. PHs and setting times, but not quantum numbers.</p><p>Code should be self-documenting. The average programmer, including someone straight out of college, should be able to understand and work on a well put-together codebase. This greatly improves the odds of finding problems, and that‚Äôs what matters. </p><h4>The contest</h4><p>One of the reasons I‚Äôve been so tardy about this blog post is that the contest didn‚Äôt go as I‚Äôd expected. </p><p>Let‚Äôs start with the great thing that happened. I got several submissions, more than enough to pick winners from. Many of these submissions are good and do improve upon Lemire‚Äôs code. The most common improvement was to use more descriptive names for the variables. Lemire uses variable names such as ‚Äús‚Äù, ‚Äút‚Äù, ‚Äúl‚Äù which seemingly don‚Äôt correspond to much. In such a short piece of code, this actually isn‚Äôt too big an offense. I kept these terms in my own implementation, because I want to be consistent with the paper, but it‚Äôs absolutely a valid improvement. Another great improvement is to write and include tests, which is really an essential part of software development. </p><p>The first place <a href="https://github.com/ziglang/zig/blob/98183e47436699f6e5eab200061c46eec342806e/std/rand.zig#L74-L118">winner</a> did both of these, and also cleared up some of the confusing lines of code by making an implicit truncation explicit. According to GitHub the winner had 5 contributors, but twitter user <a href="https://twitter.com/komu_wairagu/status/1161643573223317504">komu_wairagu</a> submitted it, so that‚Äôs who I‚Äôll be contacting to Venmo $500.</p><p>The second place <a href="https://github.com/nimia/Lemire_RNG">winner</a> comes from <a href="https://twitter.com/NimrodAviram">Nimrod Aviram</a>, who I know professionally as the discoverer of the DROWN vulnerability and fun person to hang out with at RealWorldCrypto. Nimrod‚Äôs implementation includes some great testing too.</p><p>The third place winner wants to stay anonymous, and cheated their way to some bonus points by writing a great implementation in LISP. How can you not love that? If they change their minds about anonymity I‚Äôll update this post with a link. The sha256 checksum of their implementation is ae008644b2f0b10eddbbce3a0508b103b19925e4e0c9354c569ff0816acb760c. </p><p>Now on to the not as great, and one of the reasons I‚Äôve taken this long to write. It doesn‚Äôt feel right to criticize any of these efforts, made in spare time and as part of a fun challenge I put out there, but none of them actually explained Lemire‚Äôs algorithm or broke down how and why it worked. I asked several colleagues to look through these implementations and tell me if they understood what was going on, and the response was a uniform zero. Noone could fully understand even one of the implementations, or Lemire‚Äôs original.  When I asked people to also read the paper, things got a bit better, but everyone still seemed to trip on some issues.  These are smart people who absolutely know what they are doing. I‚Äôm sure given more time they could fully understand everything, but that wasn‚Äôt the goal. The goal was to have understanding after one or two, or at most just a few, readings.</p><h4>What did people find hard to follow?</h4><p>Talking through things with people I found some common problems. Some directly in the code, and others in the paper. The first line of code that threw people was:</p><pre><code>uint64_t l = ( uint64_t ) m;</code></pre><p>This line of code does an unusual operation called truncation. It takes a 128-bit value ‚Äúm‚Äù and truncates that to its least significant 64-bits. All of this is implicit in the code, rather than explicit. Reading the code, you have to recall that m is 128-bits. Then there‚Äôs also the question of why are we doing this truncation? I‚Äôll leave that for a minute. </p><p>The next problematic line of code was:</p><pre><code>uint64_t t = -s % s;</code></pre><p>This line of code is using an unusual combination of unary negation, on an unsigned int, and the modulus operator.  Nobody remembers what unary negation does to an unsigned int - and why should they ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://veryseriousblog.com/posts/dissecting-lemire">https://veryseriousblog.com/posts/dissecting-lemire</a></em></p>]]>
            </description>
            <link>https://veryseriousblog.com/posts/dissecting-lemire</link>
            <guid isPermaLink="false">hacker-news-small-sites-24644370</guid>
            <pubDate>Wed, 30 Sep 2020 21:48:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Netflix 4K UHD Streaming requires Apple's T2 chip]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24644228">thread link</a>) | @aunali1
<br/>
September 30, 2020 | https://www.iphoneincanada.ca/news/how-to-stream-netflix-in-4k-on-mac/ | <a href="https://web.archive.org/web/*/https://www.iphoneincanada.ca/news/how-to-stream-netflix-in-4k-on-mac/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>


<!-- .entry-social-links -->
<div>
	
	
	
		
		
	
<!-- .entry-social-links -->	
		
		
	<div>
	<p>Netflix has finally made its 4K Ultra HD content available to stream on Mac, albeit not everyone will be able to benefit from that. As mentioned on the&nbsp;<a href="https://help.netflix.com/fr-ca/node/55764">Netflix Ultra HD support page</a>, 4K streaming only works on&nbsp;select 2018 or later Mac computers with an Apple T2 Security chip (via <em><a href="https://www.macg.co/mac/2020/09/netflix-en-4k-sur-mac-uniquement-pour-les-machines-avec-puce-t2-116775">MacGeneration</a></em>).</p>
<p><img title="netflix log.png" src="https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/netflix-log.png" alt="Netflix log" width="640" height="272"></p>	
	
	
	
<p>In addition to a T2 chip Mac, you also need the latest version of Safari running on macOS Big Sur, a screen capable of displaying a 4K 60Hz image (compliant with the HDCP 2.2 standard in the case of an external screen), and a subscription plan that supports Ultra HD streaming.</p>
<p>Here‚Äôs an interesting take on the T2 chip requirement from a <a href="https://www.reddit.com/r/apple/comments/j2cik9/youll_need_a_mac_with_a_t2_chip_to_be_able_to/">Reddit</a> user:</p>
<blockquote>
<p><em>‚ÄúThis makes zero sense to me. The only Macs, that could really benefit from 4k streaming, without an external monitor, are the 4k and 5k iMacs yet only 2 models (the Pro and the new 2020 27‚Ä≥) will be able to stream it. Windows machines don‚Äôt have any kind of T2 alternative and are still able to stream 4k via Edge or via the native app, their only requirement is a 7th gen intel cpu or a dedicated graphics card.‚Äù</em></p>
</blockquote>
<p>Below is the&nbsp;list of Macs compatible with 4K Netflix streaming:</p>
<ul>
<li>iMac Pro (late 2017)</li>
<li>Mac mini (late 2018)</li>
<li>MacBook Air ( 2018 and up)</li>
<li>MacBook Pro (2018 and up)</li>
<li>Mac Pro (2019)</li>
<li>iMac (2020)</li>
</ul>
<p>What do you guys think of the T2 chip requirement for streaming Netflix in Ultra HD?</p>

	</div>

</div><!-- .entry-inner -->
</article></div>]]>
            </description>
            <link>https://www.iphoneincanada.ca/news/how-to-stream-netflix-in-4k-on-mac/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24644228</guid>
            <pubDate>Wed, 30 Sep 2020 21:36:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DigitalOcean's Hacktoberfest Is Hurting Open Source]]>
            </title>
            <description>
<![CDATA[
Score 790 | Comments 378 (<a href="https://news.ycombinator.com/item?id=24643894">thread link</a>) | @domenicd
<br/>
September 30, 2020 | https://blog.domenic.me/hacktoberfest/ | <a href="https://web.archive.org/web/*/https://blog.domenic.me/hacktoberfest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>For the last couple of years, <a href="https://www.digitalocean.com/">DigitalOcean</a> has run
<a href="https://hacktoberfest.digitalocean.com/">Hacktoberfest</a>, which purports to ‚Äúsupport open source‚Äù by giving free
t-shirts to people who send pull requests to open source repositories.</p>

<p>In reality, <strong>Hacktoberfest is a corporate-sponsored distributed denial of service attack against the open source
maintainer community</strong>.</p>

<p>So far today, on <a href="https://github.com/whatwg/html/pulls?q=is%3Apr+is%3Aclosed+label%3Aspam">a single repository</a>, myself
and fellow maintainers have closed 11 spam pull requests. Each of these generates notifications, often email, to the 485
watchers of the repository. And each of them requires maintainer time to visit the pull request page, evaluate its
spamminess, close it, tag it as spam, lock the thread to prevent further spam comments, and then report the spammer to
GitHub in the hopes of stopping their time-wasting rampage.</p>

<p>The rate of spam pull requests is, at this time, around four per hour. <em>And it‚Äôs not even October yet in my timezone.</em></p>

<p><img src="https://blog.domenic.me/images/hacktoberfest-spam-listing.png" alt="A screenshot showing a spam query for the whatwg/html repository, which is at this time up to 14 spam PRs"></p>

<p>Myself and other maintainers of the whatwg/html repository are not alone in suffering this deluge.
<a href="https://twitter.com/gravitystorm/status/1311386082982924289">My tweet</a> got commiseration from
<a href="https://mobile.twitter.com/gravitystorm/status/1311386082982924289">OpenStreetMap, phpMyAdmin</a>,
<a href="https://mobile.twitter.com/ulmerleben/status/1311378655231332355">PubCSS</a>,
<a href="https://mobile.twitter.com/JakeDChampion/status/1311389420638138370">GitHub, the Financial Times</a>,
<a href="https://twitter.com/slicknet/status/1311377444188770312">ESLint</a>, a
<a href="https://mobile.twitter.com/zekjur/status/1311411780162326531">computer club website</a>, and
<a href="https://mobile.twitter.com/juliusvolz/status/1311412919196844038">a conference website</a>, just within the first couple
of hours. Since then a dedicated account ‚Äú<a href="https://twitter.com/shitoberfest">@shitoberfest</a>‚Äù has arisen to document the
barrage. Some <a href="https://github.com/search?q=is%3Apr+%22improve+docs%22+created%3A%3E2020-09-29&amp;type=Issues">cursory</a>
<a href="https://github.com/search?q=is%3Apr+label%3Ainvalid+created%3A%3E2020-09-29&amp;type=Issues">searches</a> show thousands of
spam pull requests, and rising.</p>

<p>DigitalOcean seems to be aware that they have a spam problem. Their solution, per their
<a href="https://hacktoberfest.digitalocean.com/faq">FAQ</a>, is to put the burden solely on the shoulders of maintainers. If we go
out of our way to tag a contribution as spam, then‚Ä¶ we slightly decrease the chance of the spammer getting their free
t-shirt. In reality, the spammer will just keep going, submitting more pull requests to more repositories, until they
finally find a repository where the maintainer doesn‚Äôt bother to tag the PR as spam, or where the maintainer isn‚Äôt
available during the seven-day window DigitalOcean uses for spam-tracking.</p>

<p>To be clear, myself and my fellow maintainers did not ask for this. This is not an opt-in situation. If your open source
project is public on GitHub, DigitalOcean will incentivize people to spam you. There is no consent involved. Either we
contribute to DigitalOcean‚Äôs marketing project, or,
<a href="https://twitter.com/SudoFox/status/1311431141702819840">they suggest, we should quit open source</a>.</p>

<p>Hacktoberfest does not support open source. Instead, it drives open source maintainers even closer to
<a href="https://www.google.com/search?q=open+source+burnout">burnout</a>.</p>

<p><img src="https://blog.domenic.me/images/hacktoberfest-spam-pr.png" alt="A screenshot of a spam PR which adds the heading &quot;Great Work&quot; to the HTML Standard README"></p>

<h2 id="what-can-we-do">What can we do?</h2>

<p>My most fervent hope is that DigitalOcean will see the harm they are doing to the open source community, and put an end
to Hacktoberfest. I hope they can do it as soon as possible, before October becomes another lowpoint in the hell-year
that is 2020. In 2021, they could consider relaunching it as an opt-in project, where maintainers consent on a
per-repository basis to deal with such t-shirt‚Äìincentivized contributors.</p>

<p>To protect ourselves, maintainers have a few options. First, you can take the feeble step of ensuring that any spam
against your repositories doesn‚Äôt contribute to the spammer‚Äôs ‚Äút-shirt points‚Äù, by tagging pull requests with a ‚Äúspam‚Äù
label, and <a href="https://twitter.com/MattIPv4/status/1311390498888781824">emailing hacktoberfest@digitalocean.com</a>.
DigitalOcean themselves, however, admit that
<a href="https://twitter.com/MattIPv4/status/1311390054334554113">this won‚Äôt stop the problem they‚Äôve unleashed on us</a>. But
maybe it will contribute to the <a href="https://github.com/MattIPv4/hacktoberfest-data">metrics</a> they collect, which last year
showed that ‚Äúonly‚Äù 3,712 pull requests were labeled as spam by project maintainers.</p>

<p>If you‚Äôre comfortable cutting off genuine contributions from new users, you can try enabling GitHub‚Äôs
<a href="https://docs.github.com/en/free-pro-team@latest/github/building-a-strong-community/limiting-interactions-in-your-repository">interaction limits</a>.
However, <del>you have to do this every 24 hours, and</del> it has the drawback of also disabling issue creation and
comments. <ins>Update: GitHub has made the limit configurable, and has
<a href="https://twitter.com/github/status/1311772722234560517">a nice cheeky announcement tweet</a> zooming in on the ‚Äú1 month‚Äù
option.</ins></p>

<p>Another promising route would be if GitHub would cut off DigitalOcean‚Äôs API access, as
<a href="https://twitter.com/__agwa/status/1311399074814472194">Andrew Ayer has suggested</a>. It‚Äôs not clear whether DigitalOcean
is committing a terms of service violation that would support such measures. But they‚Äôre certainly making GitHub a
less-pleasant place to be, and I hope GitHub can think seriously about how to discourage such corporate-sponsored
attacks on the open source community.</p>

<p>Finally, and most importantly, we can remember that this is how DigitalOcean treats the open source maintainer
community, and stay away from their products going forward. Although we‚Äôve enjoyed using them for hosting the
<a href="https://whatwg.org/">WHATWG</a> standards organization, this kind of behavior is not something we want to support, so
we‚Äôre starting to investigate alternatives.</p>

  </div>

</article></div>]]>
            </description>
            <link>https://blog.domenic.me/hacktoberfest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643894</guid>
            <pubDate>Wed, 30 Sep 2020 21:10:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create and watch any 100m race with AI based Fantasy100m]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24643622">thread link</a>) | @SeanWingad
<br/>
September 30, 2020 | https://www.joinfudge.com/fantasy100m | <a href="https://web.archive.org/web/*/https://www.joinfudge.com/fantasy100m">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.joinfudge.com/fantasy100m</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643622</guid>
            <pubDate>Wed, 30 Sep 2020 20:46:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Definition of News Has Been Legally Changed]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24643481">thread link</a>) | @recroad
<br/>
September 30, 2020 | https://zararsiddiqi.com/definition-of-news-legally-changed/ | <a href="https://web.archive.org/web/*/https://zararsiddiqi.com/definition-of-news-legally-changed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A tipping point has been reached in what is legally considered news. Critiquing a news source by  questioning the facts presented, the manner in which they were communicated, the source's validity, the broadcaster's motivations or any inherent biases that may exist, is no longer a fruitful activity.</p>
<p>That line of critique has been swept aside by legally muddying what news is. The presenter is no longer required to convey any truths and the onus of verification has entirely shifted from the news source to the audience.</p>
<p>There are two ways on how this has been achieved.</p>
<p><em>Burden of Verification</em>: A "reasonable" viewer is expected to "arrive with an appropriate amount of skepticism" based on the material presented by the news outlet. Any lies that the news broadcast may convey are not actionable because the viewer is expected to filter out lies from the truth. Even if the news source is spewing lies they're given a pass because the viewer should have known better to believe it in the first place to believe it. That is, any "reasonable" viewer. Adding this word into any court's ruling opens up the door to say anything.</p>
<p><em>False Presupposition</em>: The presenter can state an assumption which is very likely to be false (or known to be false) and then base future arguments on the suspect assumption. As long as what follows traces back to the false assumption, all is good and anything can be said. For example if a host says "We‚Äôre going to start by stipulating that everything Michael Cohen has told the feds is absolutely true", then the presenter has wide latitude on what conclusions they can draw, without ever worrying about whether Cohen was lying.</p>
<p>There are two compounding factors which make this especially harmful.</p>
<p><em>Inability for Skepticism</em>:  The constant bombarding of rhetoric in news shows overwhelms its audience and amplifies the echo in the chamber that the viewer already lives in. There is no pause (or desire to pause) to reflect on whether the information presented should be met with skepticism. The expectation that the consumer has the ability to be skeptical is wrong. The medium has become powerful enough that it overrides a human being's ability to be skeptical, especially one who <em>wants to believe</em> in the lie.</p>
<p><em>Repackaging</em>: Having talk shows disguise as news programs is a laughably easy way of repackaging lies without risking the penalty of being called out. Twenty-four hour news channels can have talk shows with millions of viewers who tune in to get some semblance of valid information. I provide the "some semblance" qualifier only because the audience have been conditioned enough and are polarized enough that they no longer can think on their own, and only tune in to reinforce whatever they already believe. As there is no material differentiation between talk shows and news programs for the audience, the convenient repackaging gives the broadcaster an out to say anything and hide behind the argument, "it's not news, it's a talk show".</p>
<p><img src="https://zararsiddiqi.com/images/news-court-ruling.png" alt="&quot;US District Court, Southern District of New York: Case 1:19-cv-11161-MKV   Document 39   Filed 09/24/20   Page 12 of 19&quot;">
US District Court, Southern District of New York: Case 1:19-cv-11161-MKV   Document 39   Filed 09/24/20  Page 12 of 19</p>
<p>--</p>
<ul>
<li><a href="https://law.justia.com/cases/federal/district-courts/new-york/nysdce/1:2019cv11161/527808/39/">https://law.justia.com/cases/federal/district-courts/new-york/nysdce/1:2019cv11161/527808/39/</a></li>
</ul></div></div>]]>
            </description>
            <link>https://zararsiddiqi.com/definition-of-news-legally-changed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643481</guid>
            <pubDate>Wed, 30 Sep 2020 20:34:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CloudBee's CodeShip Critical Security Notification]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24643253">thread link</a>) | @seneca
<br/>
September 30, 2020 | https://www.codeshipstatus.com/incidents/91bvlfw9xlm9 | <a href="https://web.archive.org/web/*/https://www.codeshipstatus.com/incidents/91bvlfw9xlm9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
              Dear CodeShip users,</p><p>We are reaching out to inform you of additional information we have uncovered as a result of our continuing investigation of the recent GitHub breach. To provide maximum transparency, we are reporting on the results of our investigation, the impact on users, actions you must take to protect yourself/your organization, and actions we will take to strengthen our security processes going forward.</p><p>On Wednesday, September 16, 2020, CloudBees was notified by GitHub of suspicious activities targeting CodeShip business accounts connected to GitHub via the CodeShip GitHub app and now deprecated CodeShip OAuth tokens. CloudBees immediately initiated an investigation conducted by our security and engineering teams, and on September 27, we identified additional evidence of malicious activity against a failover CodeShip database. On September 29, we uncovered evidence to indicate that a malicious actor had access to this failover instance during the period of June 2019 to June 2020. At this time and to the best of our knowledge, we have no evidence of malicious activity or attempts within CodeShip systems since June 2020. </p><p>*What type of data was affected?*</p><p>The impacted accounts are those of CodeShip users. No other products or accounts were affected and CodeShip is in no way integrated with other CloudBees products or systems.</p><p>*For all CodeShip users:*</p><p>CodeShip users hashed account passwords, one-time password (OTP) recovery codes, and the OTP secret keys used to seed two-factor authentication all may have been exposed.</p><p>Business contact information for invoicing purposes such as company contact name, company name, VAT number, postal address, phone number also may have been exposed. No payment information, such as bank account numbers or credit card numbers, was exposed. No other CloudBees product other than CodeShip was impacted. Also, the logging system was not accessed for any customers.</p><p>*For CodeShip Basic users:*</p><p>Any information contained in CodeShip users‚Äô pipelines may have been exposed. This includes scripts, environment variables, access tokens and other similar data.</p><p>*For CodeShip Pro users:*</p><p>AES encryption keys may have been exposed.</p><p>*Steps you should take*</p><p>Although at this time we have no evidence that the data potentially exfiltrated has been used, all CodeShip users may have been affected (including free, Basic and Pro accounts) and should take the following steps:</p><p>- Immediately rotate any keys or other secrets for cloud providers, third-party tools, or anything else that you used in your CodeShip pipelines.</p><p>- If using CodeShip Pro, rotate your AES key and re-encrypt your secrets.</p><p>- Immediately identify any other sensitive information that is stored in your pipelines and replace them within your pipelines and on any external systems.</p><p>- Determine whether any of your systems accessible from CodeShip have experienced unauthorized access, by contacting your provider or carefully review your access records.</p><p>- Verify that the source code held in repositories that are linked to your CodeShip account have retained their full integrity.</p><p>- Reset your CodeShip 2FA: <a target="_blank" href="https://documentation.codeship.com/general/about/2fa/">https://documentation.codeship.com/general/about/2fa/</a></p><p>At this time and to the best of our knowledge, we have no evidence of malicious activity or attempts within CodeShip systems since June 2020. We are continuing to monitor the situation.</p><p>*Steps we are taking*</p><p>As soon as we were notified by GitHub on September 16, we proceeded to rotate all our applications' internal secrets and rebuilt all our AWS AMIs. We are continuing to scrutinize our AWS security logs to monitor for suspicious activity, such as outbound connections to known malicious IPs. To date, we have not found any such activity.</p><p>We want you to be assured that we are taking steps to increase the security strength of the CodeShip product, including but not limited to:</p><p>- Validation that our product threat modeling and large-scope security reviews are systematically implemented.</p><p>- Validation that the application of production security standards to all operational processes and artifacts is systematically implemented.</p><p>- Enhancement of strict restrictions on access to production data and strict segregation of sensitive data.</p><p>- Improvement of existing SIRT processes to ensure faster and better forensic investigation.</p><p>*Who to contact *</p><p> We will update here with any new developments. </p><p>If you still have questions, please contact <a target="_blank" href="mailto:security@codeship.com">security@codeship.com</a>.</p><p>Last but not least, I‚Äôd like to apologize for the impact this is having on you. In the decade that CloudBees has been operating SaaS applications, we have always taken full responsibility for our products and we do so today. Please be assured that we will do everything we can to prevent this from happening again. </p><p>- Sacha Labourey, CEO, CloudBees
            </p></div></div>]]>
            </description>
            <link>https://www.codeshipstatus.com/incidents/91bvlfw9xlm9</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643253</guid>
            <pubDate>Wed, 30 Sep 2020 20:12:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Defer Reference Implementation for C]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24643034">thread link</a>) | @cyber1
<br/>
September 30, 2020 | https://gustedt.gitlabpages.inria.fr/defer/ | <a href="https://web.archive.org/web/*/https://gustedt.gitlabpages.inria.fr/defer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-1-1">
<p>
In the following code snippet we
have one <i>guarded block</i> and three <i>deferred statements</i>.
</p>

<div>
<pre>guard {
  <span>void</span> * <span>const</span> <span>p</span> = malloc(25);
  <span>if</span> (<span>!</span>p) <span>break</span>;
  <span>defer</span> <span>free</span>(p);

  <span>void</span> * <span>const</span> <span>q</span> = malloc(25);
  <span>if</span> (<span>!</span>q) <span>break</span>;
  <span>defer</span> <span>free</span>(q);

  <span>if</span> (mtx_lock(&amp;mut)==thrd_error) <span>break</span>;
  <span>defer</span> <span>mtx_unlock</span>(&amp;mut);

  <span>// </span><span>all resources acquired</span>
}

</pre>
</div>

<p>
The idea is that we indicate with a <b><code>defer</code></b> keyword that the
statement, e.g a call to <b><code>free</code></b>, is only to be executed at the end of
the guarded block, and, that we want this action to happen
unconditionally in which way ever the guarded block is left.  For the
three deferred statements together it says that they should be
executed in the inverse order than they were encountered. So the
control flow for this code example can be visualized as follows:
</p>



<p><img src="https://gustedt.gitlabpages.inria.fr/defer/defer-image.png" alt="defer-image.png">
</p>

<p>
Here, the dashed lines represent circumstancial control flow that
might arise when some resources are not available or when the
execution is interrupted by a signal.
</p>

<p>
This new technique has at least two advantages to commonly used <code>C</code> or
<code>C++</code> techniques:
</p>

<dl>
<dt>proximity</dt><dd>The cleanup code (<code>free</code> or <code>mtx_unlock</code>) is coded
close to the place where its need arises.</dd>

<dt>visibility</dt><dd>The cleanup code is not hidden in some previously
defined function (such as for <code>atexit</code> handlers) or
constructor/destructor pairs (<code>C++</code>)</dd>
</dl>


<p>
For normal control flow (without intermediate <b><code>return</code></b>, <code>exit</code>, ‚Ä¶)
code with similar properties can be coded with existing tools. The
above is equivalent to something like the following
</p>

<div>
<pre>{
   <span>void</span> * <span>const</span> <span>p</span> = malloc(25);
   <span>if</span> (<span>!</span>p) <span>goto</span> <span>DEFER0</span>;
   <span>if</span> (<span>false</span>) {
     <span>DEFER1</span>:
       free(p);
       <span>goto</span> <span>DEFER0</span>;
   }

   <span>void</span> * <span>const</span> <span>q</span> = malloc(25);
   <span>if</span> (<span>!</span>q) <span>goto</span> <span>DEFER1</span>;

   <span>if</span> (<span>false</span>) {
     <span>DEFER2</span>:
       free(q);
       <span>goto</span> <span>DEFER1</span>;
   }

   <span>if</span> (mtx_lock(&amp;mut)==thrd_error) <span>goto</span> <span>DEFER2</span>;

   <span>if</span> (<span>false</span>) {
     <span>DEFER3</span>:
       mtx_unlock(&amp;mut);
       <span>goto</span> <span>DEFER2</span>;
   }

   <span>// </span><span>all resources acquired</span>

   <span>goto</span> <span>DEFER3</span>;
   <span>DEFER0</span>:;
}

</pre>
</div>

<p>
Here, the <b><code>if(false)</code></b> clauses guarantee that the deferred statements
are jumped over when they are first met, and the labels and <b><code>goto</code></b>
statements implement the hops from back to front to execute the
deferred statements eventually.
</p>

<p>
Obviously, most <code>C</code> programmers would not code like this but they
would prefer to write down a <i>linearization</i> of the above, which is a
quite common idiom for cleanup handling in <code>C</code>:
</p>

<div>
<pre>{
   <span>void</span> * <span>const</span> <span>p</span> = malloc(25);
   <span>if</span> (<span>!</span>p) <span>goto</span> <span>DEFER0</span>;

   <span>void</span>*<span>const</span> <span>q</span> = malloc(25);
   <span>if</span> (<span>!</span>q) <span>goto</span> <span>DEFER1</span>;

   <span>if</span> (mtx_lock(&amp;mut)==thrd_error) <span>goto</span> <span>DEFER2</span>;

   <span>// </span><span>all resources acquired</span>

   mtx_unlock(&amp;mut);

 <span>DEFER2</span>:
   free(q);
 <span>DEFER1</span>:
   free(p);
 <span>DEFER0</span>:;
}

</pre>
</div>

<p>
This has the advantage of only making the circumstantial control flow
explicit (with three *=goto=) but it does that for the price of
proximity; the cleanup code is far from the place where its need
arises.
</p>

<p>
Nevertheless, even this linearization needs some form of naming
convention for the labels. For more complicated code the maintenance
of these jumps can be tricky and prone to errors.  This shows another
advantage of the <a href="#org63e5a5c"><code>defer</code></a> approach:
</p>

<dl>
<dt>maintainability</dt><dd>The cleanup specification is not dependent on
arbitrary naming such as labels (<code>C</code>) or RAII classes
(<code>C++</code>) and does not change when <a href="#org63e5a5c"><code>defer</code></a> or <b><code>break</code></b>
statements are added or removed.</dd>
</dl>

<p>
Another important property that is much more difficult to implement in
<code>C</code> (and that needs <b><code>try/catch</code></b> blocks in <code>C++</code>) is that <b>all</b> exits
from the guarded block are detected and acted upon: <b><code>break</code></b>, <b><code>return</code></b>,
<a href="#org18b8cc4"><code>thrd_exit</code></a>, <a href="#org9db677d"><code>exit</code></a>, <a href="#org7f6c106"><code>panic</code></a>, or
an interruption by a signal. That is, unless there are nasal deamons
flying around, we have a forth important property
</p>


<dl>
<dt>robustness</dt><dd>Any deferred statement is guaranteed to be executed
eventually.</dd>
</dl>

<p>
This is different from <code>C++</code>'s handling of destructors, which are only
guaranteed to be executed if there is a <b><code>try/catch</code></b> block underneath.
</p>

<p>
This principle of deferred execution extends to nested
guarded blocks in a natural way, even if they are stacked in
different function calls.
</p>
</div></div>]]>
            </description>
            <link>https://gustedt.gitlabpages.inria.fr/defer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643034</guid>
            <pubDate>Wed, 30 Sep 2020 19:55:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Qiskit release comprehensive textbook for all to learn basic quantum computing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24643006">thread link</a>) | @mindcrime
<br/>
September 30, 2020 | https://quantumzeitgeist.com/qiskit-releases-comprehensive-textbook-for-all-to-learn-basic-quantum-computing | <a href="https://web.archive.org/web/*/https://quantumzeitgeist.com/qiskit-releases-comprehensive-textbook-for-all-to-learn-basic-quantum-computing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
<p>Qiskit hosted a course this past summer, which saw over 4000 students from more than 100 countries registering to attend the same quantum computing courses taught to IBM Quantum interns. Now, Qiskit is planning to offer the same course to anyone who wants to get their feet wet in the world of quantum computing and quantum hardware.</p>



<p>One of the core beliefs the Qiskit team holds to is that anyone trained right can program a quantum computer. Because of this belief, the team wrote an open-source textbook that teaches readers how to use Qiskit in quantum computing. The training is both effective and thorough. A survey revealed that 92 percent of QGSS participants felt that the Qiskit Global Summer School exceeded or was equivalent to other quantum computing courses available.</p>



<figure><img loading="lazy" width="1024" height="668" src="https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=1024%2C668&amp;ssl=1" alt="" srcset="https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=1024%2C668&amp;ssl=1 1024w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=300%2C196&amp;ssl=1 300w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=768%2C501&amp;ssl=1 768w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=750%2C490&amp;ssl=1 750w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?w=1050&amp;ssl=1 1050w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=1024%2C668&amp;ssl=1 1024w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=300%2C196&amp;ssl=1 300w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=768%2C501&amp;ssl=1 768w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=750%2C490&amp;ssl=1 750w, https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?w=1050&amp;ssl=1 1050w" data-lazy-src="https://i2.wp.com/quantumzeitgeist.com/wp-content/uploads/1_Mnqa-aMTqT08pM2vokXM_g.png?resize=1024%2C668&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>The various lectures that will be available for all</figcaption></figure>



<p>The team will be releasing 27 lectures with notes and labs, around a semester‚Äôs load of content. The lectures will teach students the basics of programming a quantum computer, introduce famous algorithms such as Shor‚Äôs and Grover‚Äôs algorithm, and give an overview of how they built quantum bits and use them to represent data. There will even be an introduction to quantum chemistry included. Two prerequisites are a basic understanding of the Python language and linear algebra.</p>



<p>Qiskit believes that quantum computing should be accessible by all, and access to this knowledge should not be limited. They hope that students can teach themselves how to code with quantum computers as well as help and teach others. By doing so, the largest and easiest quantum community will come to fruition.</p>



<p><strong>About<a href="https://qiskit.org/" data-wpel-link="external" rel="external noopener noreferrer"> Qiskit</a></strong></p>



<p>Qiskit is an open-source software development kit that is used to program quantum computers, work with quantum experiments, and write quantum applications. It can be installed by anyone with a working computer and is easily available. The Qiskit community is very tight-knit and often very helpful in sharing information and teaching.</p>
															</div></div>]]>
            </description>
            <link>https://quantumzeitgeist.com/qiskit-releases-comprehensive-textbook-for-all-to-learn-basic-quantum-computing</link>
            <guid isPermaLink="false">hacker-news-small-sites-24643006</guid>
            <pubDate>Wed, 30 Sep 2020 19:53:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Signals and Threads: Compiler Optimization, with Greta Yorsh]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642987">thread link</a>) | @yminsky
<br/>
September 30, 2020 | https://signalsandthreads.com/compiler-optimization/ | <a href="https://web.archive.org/web/*/https://signalsandthreads.com/compiler-optimization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<!--
## 0:00
# Name
Text with [link](url).  <br><br>New paragraph.
-->

<h2 id="000004">00:00:04</h2>

<p>Welcome to Signals &amp; Threads, in-depth conversations about every layer of the tech stack from Jane Street. I‚Äôm Ron Minsky. So, it‚Äôs my pleasure today to have a conversation with Greta Yorsh. Greta is a compiler engineer in our compilers team in the London office, and she also has a rich and interesting background in compilers and programming languages and program analysis and verification, and we‚Äôre going to talk about all that. She‚Äôs also had a lot of experience in both industry and academia, and since 2018, Great has worked with us working on the OCaml compiler. So, Greta, to start with, can you talk about how you got interested in compiler optimization?</p>

<h2 id="000044">00:00:44</h2>

<div><p>I studied in Israel. I did my undergraduate studies in computer science and economics. I found that I don‚Äôt cope well with uncertainty, so the interesting mathematical bits of economics were not the right choice for me. So, I decided to do a PhD in computer science in the area of software verification where a lot of the concerns are about ensuring things, so that fits well with my approach to certain things. And after my PhD, I worked for a few years at IBM Watson Research Center in New York working on program analysis and verification problems.
</p><p> After that, I moved to Cambridge in England, and I joined an amazing company, ARM, that makes processors, and I worked there in the compilers team working on the GCC compiler backend for ARM, and after that, I worked at Queen Mary University of London as an assistant professor, or lecturer it‚Äôs called in England, where I did research in teaching in the area of compilers, and then recently, a year and a half ago, I joined Jane Street. At Jane Street, I work on the compilers team on the OCaml compiler.</p></div>

<h2 id="000209">00:02:09</h2>

<p>Tell us a little bit more about how that fits into the arc of your research.</p>

<h2 id="000214">00:02:14</h2>

<div><p>I started my research working on the problem of software verification or certain aspects of this problem, proving that software satisfies certain good properties, correctness properties that users expect from it, and that research involved a lot of reasoning about the source code of the program rather than executing it and then using certain formal methods and logical reasoning techniques, decision procedures, in order to prove properties of the program.
</p><p> I worked on that for a while, and there‚Äôs this ultimate goal of proving that the software behaves just the way it should be so that real-world executions of their program don‚Äôt cause terrible failures, and I was very excited about it for a while, but it is an undecidable problem, a problem that is very hard to solve in general, and that becomes a bit frustrating after a while, and I was interested in what is it that real programmers and users of software want to prove about their programs, and how I can help them using the techniques that I know and the logic that I know.
</p><p> So I worked on that, and in the process of that, I‚Äôve discovered that it‚Äôs really fun to work with real users and have people who care about certain things. I don‚Äôt know what they care about, but if I talk to them, maybe I‚Äôll find out, and maybe one of the tools I have in my toolbox will help me to give users a tool, and I found it very exciting. I think the first time it happened, it was at IBM, and I was really excited about it, but what I also realized is that not everyone really cares about correctness, that sometimes it‚Äôs okay to have bugs in their programs.
</p><p> There are other important aspects of software, like performance. That made a big change to my understanding, because I could now put these very formal techniques together with something practical and try to combine the two. And then when I had the chance to work at ARM on the GCC compiler backend for ARM, I‚Äôve discovered how important it is, the performance and how exciting it is to work on this micro-optimization, CPU-specific, machine-specific optimization, how much difference they make to the behavior of the program, to the performance behavior from these characteristics of the program, and at the same time, working on the compiler, you just can‚Äôt have bugs. An important property of the compiler is that so much else in our system is built on top of it. That was a tool that combines correctness and performance. It‚Äôs an optimization function that is very clear and measurable, as opposed to what properties do users want to have for their programs, and that‚Äôs how I came to work in compilers.</p></div>

<h2 id="000458">00:04:58</h2>

<div><p>Yeah, it‚Äôs interesting, you‚Äôre starting off by focusing on verification, because I think verification is this very shiny and attractive goal, because there‚Äôs this basic fact about programming, which is that we‚Äôre all terrible at it. Humans are bad at writing programs. Program languages are things that, at their best, do, infuriatingly, only the very specific things you ask them to do and not what you intended, and so trying to close that gap between the thing you tried to do and the terrible thing that you actually wrote down is an attractive goal.
</p><p> You were talking about one of the problems of verification, and just to be clear, by verification, formal methods (lots of terms here), we basically mean coming up with the moral equivalent of a proof that a program matches some specification. So you write in some precise, higher-level way what the program is supposed to do, and then there‚Äôs the actual program that you‚Äôve written, and some kind of proof of the program does what it‚Äôs intended to do. You mentioned undecidability ‚Äì an undecidable problem is one where you can show that there is no general technique that solves it all the time, and you mention that as a sign of how difficult the problem is. But, it‚Äôs a funny thing, in some sense almost everything that we do is undecidable, right? You can‚Äôt answer almost any interesting question about a program in full generality, the classic result being the halting program: You can‚Äôt even tell whether a given problem is going to ever finish executing in a general way. But that normally doesn‚Äôt stop us. The way we deal with this is we tend to provide people not with fully automated systems that solve all of their problems, but instead, tools that they can use while they write programs. They can maybe do some extra work along the side to help ensure the correctness of those programs, and those tools might be in the form of testing systems, and they might be in the forms of something that looks more like formal methods, things that, essentially, along with the program, develop some aspect of the proof of correctness of the program. So, I‚Äôm curious what you think about the kind of practicality and ergonomics of formal methods as a thing that can be layered into the programming process to make it easier for people to write programs that do the right thing.</p></div>

<h2 id="000702">00:07:02</h2>

<div><p>The kind of verification, proving properties of programs, that I think of when I say software verification (traditional methods) involve writing a program in one language and then providing specification of its behavior, telling what properties should hold about the program in a different language, in logic of some kind that describes it, and then proving that the specification and the implementation are conformed. That is very different from the type system approach that OCaml takes where the types are the specification of the program, and that is something I‚Äôm learning as I become better at programming in OCaml. But the kind of verification I‚Äôm talking about, the idea of specifying these properties on the side somewhere or even in the program, but in a different syntax, I think is a big problem for adopting this kind of technology. It‚Äôs possible to specify something about the library, but keeping it up to date as the code evolves is very hard. Same problem with documentation, but as you try to reason about it, and you have a tool that runs together with the specification and the code and checks them against each other as you do the development, there is some hope to keep the code and the spec aligned, but still, the programmer needs to write both of them. So, there is opportunity for automation to save some work for the programmer and keep the two aligned.
</p><p> I also wanted to mention, when you were talking about verification, so different people think of verification as different things. To me, it is what you said. It‚Äôs the more formal proof about the source code of the program and its properties, but for most of the development process, it is testing. It‚Äôs running the program on some inputs and checking that the outputs behave as we expect. So, after working a bit and trying to find the right logics that are expressive enough to describe the properties we want and at the same time, allow us to prove automatically that the program conforms to these properties, you find, ‚Äúoh, this is very restrictive.‚Äù Then you look, but testing is so much better. ‚ÄúI‚Äôve been working on this for two years, but I could‚Äôve found this bug with a simple test.‚Äù So how do we find tests that are good tests, or do we have good tests? So, this problem has been worked on by many people, and what I find exciting is that taking the testing approach, finding test cases, and the formal proof approach, and combining them helps us build better tools. So, there are many ways in which each side can help the other, and I worked on exploring some of these ways, and I found it very interesting. And I think this shows up in the verification, but there are also similar combinations of static and dynamic information or execution time and compile time information that are useful for compilers during compilations.</p></div>

<h2 id="000949">00:09:49</h2>

<p>It‚Äôs interesting for you to say this thing about the way in which tests and formal proofs mix together. I feel like this is a thing that I‚Äôve noticed informally on my own in programming, which is the OCaml type system, and in general type systems, are a kind of lightweight formal method. Types only capture some fairly limited properties of ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://signalsandthreads.com/compiler-optimization/">https://signalsandthreads.com/compiler-optimization/</a></em></p>]]>
            </description>
            <link>https://signalsandthreads.com/compiler-optimization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642987</guid>
            <pubDate>Wed, 30 Sep 2020 19:51:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Artificial Intelligence in Health Care]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642719">thread link</a>) | @Sanksshep
<br/>
September 30, 2020 | https://www.aiplusinfo.com/blog/ai-in-healthcare | <a href="https://web.archive.org/web/*/https://www.aiplusinfo.com/blog/ai-in-healthcare">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-3857ad1892c7d8adea01"><p><h2>Artificial intelligence has the potential to transform many aspects of patient care and administrative processes in healthcare. I think the role of artificial intelligence will be an asset to all healthcare professionals. The following article contains examples of artificial intelligence in healthcare and companies doing a great job at it.</h2></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1600557578492_4166"><div><h3>Introduction</h3><p>Artificial intelligence (AI), Machine learning, NLP, Robotics, and Automation are increasingly prevalent in all aspects and are being applied to healthcare as well. These technologies have the potential to transform all aspects of health care from patient care to the development and production of new experimental drugs that can have a faster roll-out date than traditional methods.&nbsp;</p><p>There are numerous research studies suggesting that AI can outperform humans at key healthcare tasks, such as diagnosing ailments. Here is a great example, <a href="https://www.bbc.com/news/health-50857759#:~:text=Artificial%20intelligence%20is%20more%20accurate,images%20from%20nearly%2029%2C000%20women." target="_blank">AI ‚Äòoutperforms‚Äô doctors diagnosing breast cancer¬π.</a></p><p>Artificial intelligence is a collection of technologies that come together form artificial intelligence. AI‚Äôs diverse range of technologies impacts a wide spectrum of healthcare.&nbsp;</p><p>Tech firms and startups are also working assiduously on the same issues. Google, for example, is collaborating with health delivery networks to build prediction models from big data to warn clinicians of high-risk conditions, such as sepsis and heart failure. Google, Enlitic, and a variety of other startups are developing AI-derived image interpretation algorithms. Jvion offers a ‚Äòclinical success machine‚Äô that identifies the patients most at risk as well as those most likely to respond to treatment protocols. Each of these could provide decision support to clinicians seeking to find the best diagnosis and treatment for patients.</p><p>You will find below some technologies that improve a specific area in healthcare with examples sourced from the internet with citations.&nbsp;</p><h3>Machine learning</h3><p>Machine learning is an application of artificial intelligence (AI)<em> </em>that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it to learn for themselves¬≤.</p><p>There are majorly three types of Machine learning‚Ää‚Äî‚Ää</p><ul data-rte-list="default"><li><p>Supervised Learning</p></li><li><p>Unsupervised Learning</p></li><li><p>Reinforcement Learning&nbsp;</p></li></ul><p>In healthcare, the most common application of machine learning is predictive medicine ‚Ää‚Äî‚Ää predicting what treatment alternatives are likely to work best on a patient based on various patient traits, history, the treatment situation, and protocols. The supervised learning model for predictive medicine applications requires a training dataset, like all supervised learning models. the difference here is that there may be a lot of variables.&nbsp;</p><p>Using neural networks it is now possible to also predict whether a patient will acquire a particular ailment or not based on a set of variables and conditions that can be fed into algorithms in the form of data.</p><p>One common application of deep learning and neural networks is the ability to detect ailments/issues in the radiology images. I think deep learning should be increasingly applied wherever clinically possible. This will allow doctors and radiologists to just supervise results and focus on other important aspects of their job. This combination promises better accuracy of finding ailments with limited human intervention or supervision.&nbsp;</p><p>Here are some organizations that are doing groundbreaking work in this area.</p><blockquote><p><strong>Organization:</strong> <a href="https://www.pathai.com/">PathAI</a><br><strong>Location: </strong>Cambridge, Massachusetts<br><strong>How it‚Äôs using AI in healthcare:</strong> PathAI is developing machine learning technology to assist pathologists in making more accurate diagnoses. The company‚Äôs current goals include reducing errors in cancer diagnosis and developing methods for individualized medical treatment¬≥.</p><p><strong>Organization:</strong> <a href="https://www.enlitic.com/">Enlitic</a><span><br></span><strong>Location: </strong>San Francisco, California<br><strong>How it‚Äôs using AI in healthcare: </strong>Enlitic develops deep learning medical tools to streamline radiology diagnoses. The company‚Äôs deep learning platform analyzes unstructured medical data (radiology images, blood tests, EKGs, genomics, patient medical history) to give doctors better insight into a patient‚Äôs real-time needs¬≥.</p></blockquote><h3>Natural language processing</h3><p>In healthcare, most applications of NLP involve the creation, understanding, parsing, and classification of clinical documentation and published research. NLP can also be used to analyze clinical notes, prescriptions, help prepare reports, and possibly conversational AI. Few good examples of how NLP is currently being used.&nbsp;</p><ul data-rte-list="default"><li><p>Parsing data realtime from coronavirus research that is being published globally. You can find more information about this in my article <a href="https://medium.com/@sanksshep/how-can-ai-help-with-the-covid-19-vaccine-search-a68d40fc0cb0" target="_blank">here</a>.&nbsp;</p></li><li><p>Project Meena by Google. More information can be found <a href="https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html" target="_blank">here</a>.</p></li></ul><h3>Decision Tree&nbsp;</h3><p>Decision trees require doctors and engineers to come up with an if-then-else decision flow chart that can help train machines to make decisions by building complex algorithms based on the finalized decision tree. This is critical and processes heavy software design, this enables the machines to take accurate decisions with human intervention. This will help save a ton of time for doctors and patients alike. This will enhance the capabilities of doctors to predict, analyze, and come up with a treatment plan for patient care.&nbsp;</p><p>This can also be used extensively in vaccine and treatment research provided the known variable is the ailment we are making the vaccine for and its pre-set conditions and protocols. This is an effective mechanism for pre-morbidity patients as well.&nbsp;</p><h3>Robotics</h3><p>Robots are becoming more intelligent, as other AI capabilities are being embedded in their OS. Other areas of improvements in AI have exponentially improved the capabilities of the robots and their ability to perform complex operations.</p><p>One such area of operation is robotic surgery. This enables surgeons to perform complex procedures with much greater precision and create precise, minimized, invasive incisions, and stitches. This is a game-changer in performing surgery, as long as human supervision exists. &nbsp;</p><p>Here are some examples of organizations using AI and Robotics&nbsp;</p><blockquote><p><strong>Organization: </strong><a href="https://www.vicarioussurgical.com/" target="_blank">Vicarious Surgical</a><br><strong>Location: </strong>Charlestown, Massachusetts<br><strong>How it‚Äôs using AI in healthcare: </strong>Vicarious Surgical combines virtual reality with AI-enabled robots so surgeons can perform minimally invasive operations. Using the company‚Äôs technology, surgeons can virtually shrink and explore the inside of a patient‚Äôs body in much more detail¬≥.</p><p><strong>Organization:</strong> <a href="https://www.aurishealth.com/" target="_blank">Auris Health</a><br><strong>Location: </strong>Redwood City, California<br><strong>How it‚Äôs using AI in healthcare: </strong>Auris Health develops a variety of robots designed to improve endoscopies by employing the latest in micro-instrumentation, endoscope design, data science and AI. Consequently, doctors get a clearer view of a patient‚Äôs illness from both physical and data perspective¬≥.</p><p><strong>Organization:</strong> ‚Ää<a href="https://www.accuray.com/" target="_blank">Accuray</a>  <br><strong>Location: </strong>Sunnyvale, California<br><strong>How it‚Äôs using AI in healthcare: </strong>The Accuray CyberKnife System uses robotic arms to precisely treat cancerous tumors all over the body. Using the robot‚Äôs real-time tumor tracking capabilities, doctors and surgeons are able to treat only affected areas rather than the whole body. The Accuray CyberKnife robot uses 6D motion-sensing technology to aggressively track and attack cancerous tumors while saving healthy tissue¬≥.</p><p><strong>Organization:</strong> <a href="https://www.intuitive.com/" target="_blank">Intuitive</a><br><strong>Location:</strong> San Francisco, California<br><strong>How it‚Äôs using AI in healthcare:</strong> Intuitive‚Äôs da Vinci platforms have pioneered the robotic surgery industry. Being the first robotic surgery assistant approved by the FDA over 18 years ago, the surgical machines feature cameras, robotic arms, and surgical tools to aide in minimally invasive procedures.<br>The da Vinci platform is constantly taking in information and providing analytics to surgeons to improve future surgeries. So far, da Vinci has assisted in over five million operations¬≥.</p><p><strong>University: </strong><a href="https://www.cmu.edu/" target="_blank">Carnegie Mellon University</a> <br><strong>Location:</strong> Pittsburgh, Pennsylvania<br><strong>How it‚Äôs using AI in healthcare:</strong> The robotics department at Carnegie Mellon University developed Heartlander, a miniature mobile robot designed to facilitate therapy on the heart. Under a physician‚Äôs control, the tiny robot enters the chest through a small incision, navigates to certain locations of the heart by itself, adheres to the surface of the heart, and administers therapy¬≥.</p><p><strong>Organization:</strong> <a href="http://microsure.nl/" target="_blank">MicroSure</a><br><strong>Location:</strong> Eindhoven, The Netherlands<br><strong>How it‚Äôs using AI in healthcare:</strong> MicroSure robots help surgeons overcome their human physical limitations. The company‚Äôs motion stabilizer system reportedly improves performance and precision during surgical procedures. Currently, eight of MicroSure‚Äôs micro-surgical operations are approved for lymphatic system procedures¬≥.</p><p><strong>Organization:</strong> <a href="https://www.mazorrobotics.com/index.php/en-us/" target="_blank">Mazor Robotics</a><br><strong>Location:</strong> Caesarea, Israel<br><strong>How it‚Äôs using AI in healthcare:</strong> Surgeons use the Mazor Robotics‚Äô 3D tools to visualize their surgical plans, read images with AI that recognizes anatomical features and perform a more stable and precise spinal operation¬≥.</p></blockquote><h3>Robotic process automation</h3><p>Robotic process automation performs structured digital tasks for administrative purposes, ie those involving information systems, as if they were a human user following a script or rules. It relies on a combination of workflow, business rules, and ‚Äòpresentation layer‚Äô integration with information systems to act like a semi-intelligent user of the systems. In healthcare, they are used for repetitive tasks like prior authorization, updating patient records, or billing. When combined with other technologies like image recognition, they can be used to extract data from, for example, faxed images in order to input it into transactional systems.</p><h3>Mass personalization</h3><p>Artificial Intelligence can help in mass personalization of patient care, treatments, procedures, vaccine research, and production. This along with human interaction can reduce costs and improve coverage across the board for healthcare.&nbsp;</p><p>AI can help with various aspects of patient care, like, charting the ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.aiplusinfo.com/blog/ai-in-healthcare">https://www.aiplusinfo.com/blog/ai-in-healthcare</a></em></p>]]>
            </description>
            <link>https://www.aiplusinfo.com/blog/ai-in-healthcare</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642719</guid>
            <pubDate>Wed, 30 Sep 2020 19:29:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Buy vs. Building Software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642596">thread link</a>) | @neinasaservice
<br/>
September 30, 2020 | https://21-lessons.com/2020/09/30/buy-vs-build/ | <a href="https://web.archive.org/web/*/https://21-lessons.com/2020/09/30/buy-vs-build/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><div id="content">
		<div>

		

<header id="masthead" role="banner">
	<div>

		<p><a href="https://21-lessons.com/" rel="home" itemprop="url"><img width="400" height="400" src="https://i2.wp.com/21-lessons.com/wp-content/uploads/2020/06/original-scaled.png?fit=400%2C400&amp;ssl=1&amp;is-pending-load=1" alt="" loading="lazy" data-size="patch-site-logo" itemprop="logo" data-attachment-id="694" data-permalink="https://21-lessons.com/original-scaled/" data-orig-file="https://i2.wp.com/21-lessons.com/wp-content/uploads/2020/06/original-scaled.png?fit=400%2C400&amp;ssl=1" data-orig-size="400,400" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Original ‚Äì Scaled" data-image-description="" data-medium-file="https://i2.wp.com/21-lessons.com/wp-content/uploads/2020/06/original-scaled.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/21-lessons.com/wp-content/uploads/2020/06/original-scaled.png?fit=400%2C400&amp;ssl=1" data-lazy-src="https://i2.wp.com/21-lessons.com/wp-content/uploads/2020/06/original-scaled.png?fit=400%2C400&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p><div>
		<p><a href="https://21-lessons.com/" rel="home">
			21 Lessons		</a>

		</p></div>
			<p><span>Learn 21st Century Skills</span>
			</p>

		
	</div><!-- .site-branding -->

	<nav id="site-navigation" role="navigation">

		<ul id="menu-main-menu"><li id="menu-item-343"><a href="https://21lessonscom.wordpress.com/">Home</a></li>
<li id="menu-item-1094"><a title="About Jan" href="https://work-with-jan.com/">About</a></li>
</ul>
	</nav><!-- #site-navigation -->

</header><!-- #masthead -->


	<div id="primary">
		<main id="main" role="main">

			
<article id="post-1145">

    <div>

        
        <header>
            <div>

                <p><span><a href="https://21-lessons.com/category/business/" rel="category tag">Business</a>, <a href="https://21-lessons.com/category/programming/" rel="category tag">programming</a></span></p><div>

                    <p><span> by <span><a href="https://21-lessons.com/author/jan21lessonscom/">Jan</a></span></span><span><a href="https://21-lessons.com/2020/09/30/buy-vs-build/" rel="bookmark"><time datetime="2020-09-30T14:54:00-04:00">September 30, 2020<span>2:54 pm</span></time></a></span>
                </p></div>

            </div><!-- .entry-meta -->

            
        </header><!-- .entry-header -->

        
    </div>

	<div>

		
<figure><img data-attachment-id="1146" data-permalink="https://21-lessons.com/2020/09/30/buy-vs-build/buy_vs_build/" data-orig-file="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?fit=2048%2C2048&amp;ssl=1" data-orig-size="2048,2048" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Buy_Vs_Build" data-image-description="" data-medium-file="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?fit=300%2C300&amp;ssl=1" data-large-file="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?fit=980%2C980&amp;ssl=1" loading="lazy" width="980" height="980" src="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=980%2C980&amp;ssl=1" alt="Buy vs Build Sketchnote, explaining the cost of not using a paid tool for CI/CD" srcset="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?w=2048&amp;ssl=1 2048w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=300%2C300&amp;ssl=1 300w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=150%2C150&amp;ssl=1 150w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=768%2C768&amp;ssl=1 768w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=1536%2C1536&amp;ssl=1 1536w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=1200%2C1200&amp;ssl=1 1200w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=800%2C800&amp;ssl=1 800w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=400%2C400&amp;ssl=1 400w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=200%2C200&amp;ssl=1 200w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=640%2C640&amp;ssl=1 640w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=500%2C500&amp;ssl=1 500w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=928%2C928&amp;ssl=1 928w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=600%2C600&amp;ssl=1 600w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=100%2C100&amp;ssl=1 100w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?w=1960&amp;ssl=1 1960w" sizes="(max-width: 980px) 100vw, 980px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?w=2048&amp;ssl=1 2048w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=300%2C300&amp;ssl=1 300w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=1024%2C1024&amp;ssl=1 1024w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=150%2C150&amp;ssl=1 150w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=768%2C768&amp;ssl=1 768w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=1536%2C1536&amp;ssl=1 1536w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=1200%2C1200&amp;ssl=1 1200w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=800%2C800&amp;ssl=1 800w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=400%2C400&amp;ssl=1 400w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=200%2C200&amp;ssl=1 200w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=640%2C640&amp;ssl=1 640w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=500%2C500&amp;ssl=1 500w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=928%2C928&amp;ssl=1 928w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=600%2C600&amp;ssl=1 600w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=100%2C100&amp;ssl=1 100w, https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?w=1960&amp;ssl=1 1960w" data-lazy-src="https://i1.wp.com/21-lessons.com/wp-content/uploads/2020/09/Buy_Vs_Build.jpg?resize=980%2C980&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>

<p id="jp-relatedposts">
	<h3><em>Also checkout these posts</em></h3>
</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->



		</main><!-- #main -->
	</div><!-- #primary -->


<div id="secondary" role="complementary">

	
</div><!-- #secondary -->		</div><!-- .container -->
	</div><!-- #content -->

	<!-- #colophon -->
	<div>
		<div>
			<form role="search" method="get" action="https://21-lessons.com/">
				<label>
					<span>Search for:</span>
					
				</label>
				
			</form>			<p>Begin typing your search above and press return to search. Press Esc to cancel.</p>
		</div>
		</div>
</div></div>]]>
            </description>
            <link>https://21-lessons.com/2020/09/30/buy-vs-build/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642596</guid>
            <pubDate>Wed, 30 Sep 2020 19:19:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Progress in Biology Is Slow ‚Äì Here's How We Can Speed It Up]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24642489">thread link</a>) | @ashwal
<br/>
September 30, 2020 | https://adamashwal.com/irreducible | <a href="https://web.archive.org/web/*/https://adamashwal.com/irreducible">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			<p>Living is great and I'd prefer to do more of it. Unfortunately, progress towards immortality has been rather slow ‚Äî for all of our technological progress in the last century we've only picked up a few extra years of life. An incorrect framing of the problem has led to slow progress, but with a little bit of mind shift we can choose much better strategies for learning about and manipulating biology.</p>
<h3 id="what-s-the-status-quo-">What's the status quo?</h3>
<p>There's been a subset of humans over the last 100 years who also would like to live longer and healthier lives and have invested considerable time and energy into this problem. They've mostly failed as is evidence by the fact if you make it out of childhood, keep a good BMI, stop smoking, and exercise, you'll make it, at best, <a href="https://ourworldindata.org/life-expectancy">a decade longer than someone in the 1700s</a> (provided you escaped the trough of death that was childhood). In that same 100 years we took our first flight on Earth and then landed on the moon. In that same 100 years we went from 0 transistors per chip to 50,000,000,000. In that same 100 years we invented the Cool Ranch Dorito. So why did we succeed in so many other places but have failed in the most important? Why don't we live extremely long, healthy, and happy lives?</p>
<h3 id="why-has-this-approach-worked-in-other-areas-">Why has this approach worked in other areas?</h3>
<p>Some problems are, in retrospect, clearly easier than others. But if you had surveyed the leading minds in 1900 which would be easier: splitting the atom, sending a probe outside the solar system, or living to 90, it's hard to imagine it would be the last option they would have chosen. Yet here we are.</p>
<p>There are problems that on the face of it seem of similar difficulty to an outsider but are magnitudes (and magnitudes and magnitudes) harder to solve. What leads to this difference can be summarized as <em>computational reducibility</em>. As way of example, take the planet. Think of every atom on Earth- the rocks, the trees, that one ex who still drifts in and out of memory. If I want to know where this sphere will be in the universe tomorrow or 1,000 years from now and I don't have a notion of basic physics I may think this intractable. There's so much going on! How could one possibly think to describe how all these atoms would move through space and time? But it turns out to be fairly trivial - all those atoms can be reduced to a single point, a center of mass, and then calculations of momentum can be easily computed and trajectory projected forward. There are many systems that allow for these "shortcuts" where the dimensionality can be collapsed and the useful information is still present. A bridge builder doesn't need to think of each atom in a brick, or even really the brick; it's enough to think of the collection of bricks and how they are arranged.</p>
<h3 id="engineering-takes-place-in-reducible-places">Engineering takes place in reducible places</h3>
<p>Engineering, generally, is the practice of working on problems that are tractable. Given constraints on energy and time, only hard problems that have been sufficiently reduced are tractable and as such are the ones that are worked on. Oftentimes science leads us to new ways of reducing the complexity of problems (think Newton and his equations in the previous example). This isn't a law, just a result of how resources are allocated. </p>
<h3 id="is-biology-reducible-">Is Biology Reducible?</h3>
<p>We haven't seen progress in biology because it is stubborn to attempts to reduce it. Darwin was one of the last great reducers - able to collapse the high dimensional problem of evolution into a few axioms. But even with natural selection in hand, the resolution of claims is not particularly specific. Hypotheses are hard to prove or disprove given the near impossibility of running a counterfactual and it mostly serves as a post-hoc description (large proboscis <a href="https://en.wikipedia.org/wiki/Xanthopan">moths</a> notwithstanding). Perhaps if we were luckier we could  have lived in a universe that allowed us to use natural selection to know the structure of cells and animals without having to go look (this is a little true - something I'll explore in a future post), similar to knowing the position of the planets a millennia in advance.</p>
<p>What is it about biology that makes it irreducible but splitting the atom was something we accomplished 80 years ago? Spitting in the face of entropy is hard and the number of problems that need to be solved by a biological system are vast. The components of that system are not elegant fundamental laws of the universe but artisanal components created by random search through a loosely constrained fitness space. Even highly conserved pathways still exist in a unique context of the whole organism. </p>
<h3 id="biology-s-drunken-walk">Biology's Drunken Walk</h3>
<p>Biology is constantly transitioning from current state to a future state where some future branch of the evolutionary tree has higher fitness but the potential branch space is massive and the "choice" of which branch is picked is a random process. For example, in a scenario where the environment is slowly acidifying, any given bacteria has many solutions to survive. While aesthetically they could be vastly different (off the top of my head: changes to cell membranes, additional transmembrane proton pumps, neutralizing organelles, heat shock proteins, etc), which one ends up being dominant for a given bacteria is a random mutation. Given enough bacteria "searching" the solution space, you'll likely see many solutions.</p>
<p>Crucially, because in any scenario there is a one-to-many relationship between a problem and solutions, you can't extrapolate which solutions an organism possesses based on reasoning. You can‚Äôt postdict, you have to go look.</p>
<h3 id="so-what-do-we-do-">So, what do we do?</h3>
<p>So biology suffers from low reducibility - we aren‚Äôt able to summarize systems allowing us to make inferences cheaply. In the instance of disease this prevents both easy understanding of the disease state, i.e. what is going wrong, and prevents easy drug design, i.e. which node in the system do I push on in order to reverse the disease state. Right now, drug discovery is a lot of serendipity and a lot of pretending we know enough to pick targets. Unsurprisingly, this mostly fails.</p>
<p>There is another way. Currently, we brute force biology via Grad student search and it‚Äôs remarkably slow. A small number of underpowered, poorly done experiments makes up the bulk of what is produced. A model organism is chosen, an intervention is proposed, a measurement is done, and a paper is written: repeat ad nauseam. </p>
<p>But if an infinite number of monkeys can write Shakespeare, an infinite number of mice can allow us a way forward.</p>
<p>If we care about blood pressure, for example, why have we not given every drug, at every dosage, every regiment, and in every combination to a mouse and actually seen what happens?
We <em>do</em> have high throughput screening, mostly in individual cells or enzymes, but this is mostly garbage owing to the information decay from cell to whole organism (something I will expound on in a future post). Is my proposed solution expensive? Yes! Combinatorial explosions are the opposite of computational reducibility. But my point is that we can't just hope to have cheaper solutions in the future ‚Äì that is the ostrich approach to progress. And we spent $288,100,000,000 to get to the moon.</p>
<p>The problem is also not as intractable as it may first seem. How do we test a large number of drugs on a large number of mice? Drive the cost down on any marginal mouse. Recent advances in machine learning allow automation of those pesky variable costs. Image recognition and classification are now good enough to track a mouse and its movements automatically - there is no need to babysit mice and manually classify behavior. With the state of every mouse known, simple robotics, e.g. food/medication administration and outcome measurements, become possible. The simplest experiments are possible today, and with a concerted effort, the realm of possible can grow. </p>
<p>There will always be innovations in new measurement techniques, new ways of peering into the system. Biologists generally fail in scaling these new techniques at a detriment to our ability to control biology. By adding scalability as an important aspect of innovation we can unlock so much more with what we already have today. </p>
<p>Importantly, this isn't just limited to a causal inference between a drug and a disease. We're getting very good at measuring the state of systems, just pick your favorite "‚Äìome". It's not hard to squint and see that large numbers of interventions, on large numbers of model organisms, with large readouts of state will approach full 4D models of organic systems.  </p>
<p>There are not going to be any shortcuts with biology. The sooner we recognize this, the sooner we can start building systems that operate at the scale needed to bring useful inference, drug discovery, and network topology into the 21st century. </p>
<p>Thank you to Aubree for her feedback on commas, words, and ideas.</p>


			
			
		

			
			




		</div></div>]]>
            </description>
            <link>https://adamashwal.com/irreducible</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642489</guid>
            <pubDate>Wed, 30 Sep 2020 19:10:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Beeminder?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24642136">thread link</a>) | @maxwelljoslyn
<br/>
September 30, 2020 | https://www.maxwelljoslyn.com/beeminder | <a href="https://web.archive.org/web/*/https://www.maxwelljoslyn.com/beeminder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article-body">
        <p><strong>I vigorously encourage you</strong> to <a href="https://beeminder.com/">use Beeminder</a> for tracking, maintaining, and modifying habits.</p>
<p>Several people have recently asked me to explain why I like this service so much. This page is my evolving answer.</p>
<p>So, <strong>why Beeminder?</strong></p>
<h2 id="design">Design</h2>
<p>The core feature of Beeminder is the ‚Äúbee sting.‚Äù The service charges you money if you fail to meet a certain rate of progress toward a goal.</p>
<p>For instance, if I declare to Beeminder that I will meditate 5 minutes per day, and I fail to perform meditation at that rate, Beeminder will ‚Äúderail‚Äù me, charge me a small amount of money, and ‚Äì after a weeklong grace period ‚Äì rearm the sting.</p>
<p><strong>Why Beeminder?</strong> It assigns meaningful consequences for not living up to your stated goals.</p>
<p>The good news about the bee sting is that Beeminder is totally self-driven. You<a href="#fn1" id="fnref1"><sup>1</sup></a> do the data reporting, you set the starting and maximum penalties for the bee sting, and you choose how fast you want to make progress on each goal. You are even responsible for confirming with the Beeminder team whether or not a derailment was legitimate.</p>
<p><strong>Why Beeminder?</strong> It trains you to build honesty with yourself (and the support team!) when you succeed or fail. This calibrates a better understanding of your strengths and weaknesses, while giving you the information you need to ramp up or ease off on a goal.</p>
<h2 id="philosophy">Philosophy</h2>
<p>A Beeminder user must break down his or her goals into atomic, numerically-measurable steps toward a large goal. Goals like ‚Äúchinups performed,‚Äù being both numeric and precise, are a perfect fit for Beeminder. To perform 100 chinups, set your target rate to 1 chinup per hour/day/week; set your target number to 100; and do chinups whenever you can. That‚Äôs it: as long as you keep your average rate above 1 chinup per chosen time unit, Beeminder will never charge you, and you‚Äôll be making steady progress.</p>
<p><strong>Why Beeminder?</strong> It trains you to reframe your life goals, especially ones that seem monumental, as nothing more than piles of little goals, steadily achieved.</p>
<p>While goals that are easily quantified are the best fit for Beeminder, even nebulous goals can be tracked and nudged in the system. One of my goals is called ‚Äúselfserve‚Äù, and its target number is 100 ‚Äì where ‚Äú100‚Äù means ‚Äúhas ported 100% of this website to self-administered web servers and infrastructure.‚Äù</p>
<p>Few methods of calculating exact progress on this goal would be worth the time they took to administer. However, since I know the scope of the task and its subtasks, after completing each subtask I can add a few percent here and a few percent there into Beeminder‚Äôs tracker.</p>
<p><strong>Why Beeminder?</strong> Whether your goal is concrete or abstract, Beeminder puts you on a schedule which will achieve it.</p>
<p>What‚Äôs more, merely declaring ‚ÄúI will be 100% done with this hairy task by such-and-such date‚Äù was enough to spur me into action. My original target date was 100% completion by mid-December, but as of today, before even reaching October, my ‚Äúselfserve‚Äù goal sits at 60%! I‚Äôm months ahead of my original pessimistic estimate, and <em>it never once felt difficult</em> to get there ‚Äì but if I hadn‚Äôt <em>promised myself</em>, via Beeminder, that I would do so, I‚Äôd probably still be sitting around griping about my crappy old website infrastructure.</p>
<p><strong>Why Beeminder?</strong> It builds the self-confidence and self-trust that can only come from diligently working toward success.</p>
<p>Finally, I realized recently that Beeminder has <em>instilled in me a new and creative instinct</em>: the impulse to judge any new opportunity by determining how I might realize its potential in steps of Beemindable size.</p>
<p>It is one thing for the latest self-help book or productivity guru to tell you that anything is achievable in small steps. It is quite another for that mantra to develop into a deep-seated instinct which influences your worldview. Thus Beeminder is empowering in the truest sense of the word: it grants new abilities.</p>
<p><strong>Why Beeminder?</strong> Extended use installs the powerful meta-habit of noticing opportunities to achieve goals by ‚Äúmere‚Äù effort ‚Äì and as a Beeminder user, you‚Äôll be ready to exploit such opportunities <em>because you‚Äôve practiced doing so.</em></p>
<h2 id="proof-by-existence">Proof by Existence</h2>
<p>The Beeminder founders, Danny and Bethany, use Beeminder to supercharge the development of Beeminder itself. <a href="https://www.beeminder.com/meta">They‚Äôve set up the Beeminder user ‚Äúmeta‚Äù</a> to publicly display business metrics, which they‚Äôve committed to Beeminding just as you or I might Beemind pushups or calories.</p>
<p>The ‚Äúmeta‚Äù goals include typical metrics like revenue and monthly active users. That Beeminder openly publishes these figures makes them is noble, but I want to draw attention to a non-financial indicator: <a href="https://www.beeminder.com/meta/uvi">a very, very important number called ‚ÄúUVIs.‚Äù</a></p>
<p>UVI stands for ‚ÄúUser-Visible Improvement,‚Äù and they are the gold-standard, AAA, totally-unfakeable indicator that Beeminder works. One point on the UVI goal means the Beeminder team has directly improved your experience using Beeminder, and at time of writing, the Beeminder team has added <em>one new UVI every day for ten years</em>.</p>
<p><strong>Why Beeminder?</strong> <em>Its own existence is a massive proof</em> of its ability to motivate you to fantastic heights ‚Äì like, say, creating a program which has helped tens of thousands of people achieve their goals.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I‚Äôve said my piece, so don‚Äôt delay: <a href="https://beeminder.com/">go try Beeminder for yourself</a>. <strong>Set your goals set to the minimum charge until you figure out what works for you</strong>, and if you want help getting started, email the ever-helpful support team, or check out the forums.</p>
<p>I‚Äôm just a happy customer with a blog, and Beeminder didn‚Äôt ask me to write this post. That said, Danny and other staff members encouraged me to write on this topic after I mentioned it over email.</p>
<p>If you liked this, leave a response! In a future post, I‚Äôll investigate my own Beeminder successes and failures as case studies for others to learn from. Thanks for reading, and never ever hesitate to .</p>


        





        
    </div></div>]]>
            </description>
            <link>https://www.maxwelljoslyn.com/beeminder</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642136</guid>
            <pubDate>Wed, 30 Sep 2020 18:43:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Energy Efficiency across Programming Languages [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 190 | Comments 153 (<a href="https://news.ycombinator.com/item?id=24642134">thread link</a>) | @Malfunction92
<br/>
September 30, 2020 | https://greenlab.di.uminho.pt/wp-content/uploads/2017/10/sleFinal.pdf | <a href="https://web.archive.org/web/*/https://greenlab.di.uminho.pt/wp-content/uploads/2017/10/sleFinal.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://greenlab.di.uminho.pt/wp-content/uploads/2017/10/sleFinal.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24642134</guid>
            <pubDate>Wed, 30 Sep 2020 18:43:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is Snowflake so Valuable?]]>
            </title>
            <description>
<![CDATA[
Score 240 | Comments 158 (<a href="https://news.ycombinator.com/item?id=24641481">thread link</a>) | @malisper
<br/>
September 30, 2020 | https://www.freshpaint.io/blog/why-is-snowflake-so-valuable | <a href="https://web.archive.org/web/*/https://www.freshpaint.io/blog/why-is-snowflake-so-valuable">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Two weeks ago, Snowflake had the largest IPO ever for a software company. On the first day of trading, the stock price doubled, giving Snowflake a market cap of over $60 billion. Snowflake became all that everyone was talking about. There was so much hype, my mom, who doesn't even know what Snowflake is, decided to invest in Snowflake.</p><p>At first glance, the valuation of $60 billion seems absurd. Not only is Snowflake not profitable, having a net loss of $349 million in 2019, but their revenue is also small relative to their valuation. Their revenue over the last 12 months was $403 million. Based on that, their market cap is around 150x their revenue. So why exactly is their market cap so high? Besides revenue and profitability, there are a number of other metrics that investors look at. Compared to similar software businesses, Snowflake has god-like metrics. In this post, I'm going to go through a number of metrics from Snowflake's S-1, explain what the metrics mean, and give context on just how exceptional Snowflake's metrics are.</p><p>The first metric that stands out is Snowflakes 121% year over year growth. To give you a sense of how fantastic it is, you can compare it to the growth rates of other companies at IPO. <a href="https://techcrunch.com/2013/08/24/how-fast-should-you-be-growing/">Institutional Venture Partners looked at how quickly Internet and software companies were growing at IPO</a>.</p><figure><p><img src="https://uploads-ssl.webflow.com/5dad2b1e508f04886d0245c3/5f74c44d240d4de932d463c4_growth1.jpeg" alt="growth1"></p></figure><p>Based on their numbers, only 25% of companies that are between $75M-$500M in annual revenue are growing at just over 60% year over year. Snowflake's growth rate is nearly twice that! Snowflake's revenue was also $403M for the last 12 months, which would put them at the high end of that range. Not only are they growing significantly faster than other companies, but they are already significantly larger!</p><p>For companies that sell software to businesses an important number to look at is their retention rate. For Snowflake, their net retention rate is 158%. You may be asking, how do they have a retention rate over 100%? That's because companies that use Snowflake pay more for Snowflake over time. For every $1 of revenue Snowflake received from their customers a year ago, that same pool of customers are now paying $1.58. That means Snowflake could acquire no new customers, and they would still be doubling revenue every 18 months.</p><p>To compare that to other companies, <a href="https://www.lennyrachitsky.com/p/what-is-good-retention-issue-29">Lenny Rachitsky surveyed a number of industry experts on what they thought good and great net retention would be</a>. On average, for enterprise subscription software, the category Snowflake would fall under, the experts surveyed said 110% net retention would be good and 130% net retention would be great. He also pulled the net retention rates for a number of public companies:</p><ul role="list"><li><strong>Alteryx</strong>: 135% (<a href="https://docs.google.com/spreadsheets/d/1ogELPtct2s6jj9wRBpOgqGUE5k4cO73XXcvqmEZE89M/edit#gid=0">source</a>)</li><li><strong>Fastly</strong>: 130% (<a href="https://www.saastr.com/5-interesting-learnings-from-fastly-as-it-gets-ready-to-ipo/">source</a>)</li><li><strong>Okta</strong>: 124% (<a href="https://docs.google.com/spreadsheets/d/1ogELPtct2s6jj9wRBpOgqGUE5k4cO73XXcvqmEZE89M/edit#gid=0">source</a>)</li><li><strong>Anaplan</strong>: 124% (<a href="https://www.key.com/kco/images/Public_SaaS_Company_Retention_Metrics_2019.pdf">source</a>)</li><li><strong>Workday</strong>: 100%+ (<a href="https://www.workday.com/content/dam/web/en-us/documents/investor/workday-financial-analyst-day-2018.pdf">source</a>)</li><li><strong>ServiceNow</strong>: 97% (<a href="https://www.publiccomps.com/tickers/NOW">source</a>)</li></ul><p>You will notice that Snowflake's net retention rate of 158% is significantly higher than all of these!</p><p>Net promoter score (NPS) is a way of measuring customer satisfaction. It's convenient because it's easy to calculate and boils down customer satisfaction to a single number, making it easy to compare NPS between different companies. To compute NPS, a company performs a survey of their customers. The company asks "On a scale of 0 to 10, how likely are you to recommend this company‚Äôs product or service to a friend or a colleague?". Anyone that answers 9 or 10 is deemed a "promoter" of the product, while anyone that answers 6 or less is considered to be a "detractor". To compute the NPS, you take the percentage of users that are promoters and subtract the percentage of users that are detractors. This results in a number between -100 and 100 which is the NPS.</p><p>To give some examples, an NPS of 0 means your company has just as many promoters as detractors, whereas an NPS of 100 means everyone loves your product. Here are the NPS's for a few well known companies according to <a href="https://www.satmetrix.com/infographic/2020-us-consumer-benchmarks/">satmetrix</a>:</p><ul role="list"><li>Apple - 62</li><li>AirBnB - 43</li><li>AT&amp;T - 20</li></ul><p>What is Snowflake's NPS score? It's 71. According to NPS, Snowflake's customers like Snowflake more than Apple's customers like Apple.</p><p>The average Snowflake customer pays Snowflake $165k a year. Average contract value (ACV) is a useful metric to look at because it gives you a rough sense of how efficient a sales team is. To elaborate, there's a similar amount of work needed for a sales person to sell a $50k deal as there is for a sales person to sell a $100k deal. This is because most of the work a sales person does such as giving a demo, dealing with the paper process, and negotiating, have to happen regardless of how much the contract actually winds up being. Closing a $100k deal brings in twice as much revenue as a $50k deal does, but it's not usually twice as much work.</p><p>For this reason, higher average contract values are usually better. According to <a href="https://dskok-wpengine.netdna-ssl.com/wp-content/uploads/2020/08/2020-KBCM-SaaS-Survey.pdf">KBCM Technology Group</a>, 29% of software businesses have an ACV between $50k-$250k, and only 9% have an ACV greater than $250k. That gives Snowflake a relatively healthy ACV.</p><p>Not only does Snowflake have a high ACV, but their high end contract values are also really high. Snowflake has 56 customers that pay them over $1M a year. They also have Capital One, their largest customer, account for 11% of their 2019 revenue with approximately $29M.</p><p>Snowflake's net loss of $349M during 2019 does not sound good, but it does not tell the full story. There are two issues with using profit as a metric when looking at a subscription software business:</p><ul role="list"><li>Due to the generally accepted accounting principles (GAAP), a customer can give Snowflake money, but Snowflake can't count that money as revenue until a later date, even though that money is in Snowflake's bank account.</li><li>A net loss doesn't tell you where the money is coming in and where the money is going to.</li></ul><p>Addressing each of these points:</p><h3>Revenue under GAAP</h3><p>Under GAAP, Snowflake doesn't count revenue when a customer pays them, but instead when a customer uses the Snowflake product. To be more specific when a company pays Snowflake, they are purchasing a number of "Snowflake credits". When you are using the Snowflake product you exchange your credits for Snowflake compute time.</p><p>As an example, let's say a customer purchases one year of Snowflake credits for $100k. That money winds up in Snowflake's bank account, but Snowflake cannot count that $100k as revenue until Snowflake delivers the service, which is when the customer uses their credits for compute time. If the customer uses a quarter of the Snowflake credits within three months after purchases them, under GAAP, Snowflake would count that as $25k in revenue over those three months.</p><p>You can see the impact this has by looking at the $688M Snowflake has in "remaining performance obligations". This $688M is money that Snowflake's customers have either already given to Snowflake or have contractually committed to giving to Snowflake, but it won't show up as revenue until the customers use the credits they purchased.</p><h3>Where's the money going?</h3><p>The other thing to look at is what they are spending the money on. Snowflake is making money on every sale. They have a gross profit of 62% so they have no problem running the product. The thing is they are spending A LOT on sales and marketing. Their total net loss for the last six months was $171M while during the same time period they spent $191M on sales and marketing. If they wanted to, they could stop investing in growth, lay off their entire sales and marketing team, and they would become profitable. In other words, Snowflake could be profitable if they wanted to, but they are intentionally choosing not to, and are instead focusing on growing the customer base.</p><p>Not that they should. If we assume the $191M they spent in sales and marketing over the last six months was responsible for the $81M increase in revenue in the last six months compared to the prior six months, every $1 Snowflake invests in sales and marketing results in $.42 of revenue. With Snowflake's 158% net retention rate, that customer will pay back the initial investment in sales and marketing after around two years and then return many times the investment in the years following that.</p><p>In practice, Snowflake probably sees a return on investment much sooner. A company pays for Snowflake well before Snowflake is able to count that money as revenue.</p><p>So does it make sense for Snowflake's market cap to be 150x their revenue. I definitely think it's high, but I it's certainly plausible. They're growing faster, have higher customer satisfaction, and just have phenomenal metrics across the board when compared to similar businesses.</p><p>‚Äç</p></div></div>]]>
            </description>
            <link>https://www.freshpaint.io/blog/why-is-snowflake-so-valuable</link>
            <guid isPermaLink="false">hacker-news-small-sites-24641481</guid>
            <pubDate>Wed, 30 Sep 2020 17:50:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Save Millions with QSBS and Section 1045 Rollovers]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24641348">thread link</a>) | @ankit77
<br/>
September 30, 2020 | https://goyalpost.com/2020/09/29/how-to-save-millions-with-qsbs-and-section-1045-rollovers/ | <a href="https://web.archive.org/web/*/https://goyalpost.com/2020/09/29/how-to-save-millions-with-qsbs-and-section-1045-rollovers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Qualified Small Business Stock (QSBS) is some of the most tax-advantaged stock you can hold, yet few people know about it. If you‚Äôre a founder, early employee, or investor, you can potentially save millions of dollars by understanding the implications of QSBS.</p>



<p>In this article I will discuss the following:</p>



<ol><li>History of QSBS</li><li>QSBS Tax Savings</li><li>Requirements for QSBS</li><li>Section 1045 Rollover (applicable if you don‚Äôt meet the five year holding period, explained below)</li></ol>



<p>I recently sold shares in a company I co-founded and spoke to more than two dozen accountants in the process. I‚Äôm summarizing my findings and experiences in the article below. As such, the information in this article is not formal tax advice. I recommend you speak with your accountant prior to making any decisions.&nbsp;</p>



<h2>History of QSBS</h2>



<p>Section 1202 is the section of the tax code that outlines the QSBS tax exclusion. It was added to the tax code in 1993 to encourage individuals to invest in new ventures, far before the creation of Silicon Valley as we know it today. The act, however, failed to provide the intended incentive of spurring investments in new ventures.</p>



<p>Over the past three decades, a number of tailwinds have propelled QSBS back into the limelight. Congress reduced the tax on long-term capital gains in 1997, increased the tax savings of QSBS incrementally until 2010, and finally reduced corporate taxes from 35% to a flat 21% in 2017. These three forces have made QSBS far more relevant today than in the past.</p>



<h2>QSBS Tax Savings</h2>



<p><strong>Under Section 1202, your gains from selling QSBS may be eligible for up to 100% exclusion from federal and state taxes. This exclusion is limited to the </strong><strong><em>greater</em></strong><strong> of $10 million or 10 times your cost basis during a liquidity event.</strong></p>



<p>For instance, the excludable amount for a founder may be on $10 million of gain, while the exclusion for a VC may be much greater. If, for instance, a VC invests $20 million, the VC may obtain an exclusion for $200 million of gain. See the ‚ÄúScenario Table‚Äù in the Appendix for more examples. Please also note that if you end up selling your shares in multiple tranches over multiple years, the excludable amount might vary. Reference<a href="https://www.thetaxadviser.com/issues/2018/nov/qualified-small-business-stock-more-attractive.html"> this</a> article for further details.</p>



<p><strong>If you qualify for a QSBS tax exclusion, you are 100% exempt from federal taxes. The current federal tax rate is 23.8% (20% federal + 3.8% medicare). This means you can save 23.8% in long-term capital gains that you would have been subject to otherwise. Depending on which state you live in (</strong><strong><em>not</em></strong><strong> which state the company is incorporated), you may qualify for state-level exclusion as well.</strong> States typically fall into one of four buckets:</p>



<ol><li>States with no individual income tax or no capital gains tax. These states are QSBS compliant by default.</li><li>States that follow the federal tax code and waive state taxes if an individual meets the federal-level QSBS requirements. These states are also QSBS compliant.&nbsp;</li><li>States that have their own QSBS exclusion statues.</li><li>States that do not recognize QSBS in any way, shape, or form (California notably falls in this bucket).&nbsp;</li></ol>



<p>I‚Äôve provided a chart of applicable QSBS treatment in each of the 50 states and District of Columbia in the Appendix.</p>



<h2>Requirements for QSBS</h2>



<p><strong>For your stock to qualify as QSBS, you must meet certain requirements at the time of your stock issuance, and others during your entire holding period of the stock. If you sell QSBS, you must report the entire gain as a long-term gain on your Schedule D, and enter the allowable exclusion as a loss below the entry for the gain.</strong></p>



<h3>Requirements that must be met on the date of issuance:</h3>



<ul><li>Corporation issuing the stock must be a domestic C-Corp (and the stock must be issued after August 9, 1993)</li><li>You must acquire your stock directly from the company for money, property, or services. The only exception is if you acquire the stock by gift or inheritance. In this case, you are treated as having acquired the stock in the same manner as the original owner.<ul><li>Note: do not contribute the stock to a family LLC, limited partnership/trust, or to an LLC organized to manage the sale of your stock. This will disqualify the stock as QSBS.</li></ul></li><li><strong>Corporation must have assets of $50M or less at the time you receive your shares (or exercise your options).</strong><ul><li>Note: this is a continuous requirement and if at any point the assets of a corporation exceed $50M, the corporation can never again issue QSBS (even if the assets are below $50M on the date of the subsequent issuance).</li><li>Note: the assets of the corporation must not exceed $50M even after taking into account amounts the corporation received in the current issuance. If, for instance, a company has $40M in the bank and is raising a $20M Series B, none of the newly issued Series B stock will be QSBS.</li></ul></li><li>You must determine your stock issuance date. This is critical for three reasons:<ul><li><strong>Starts the clock for purposes of the five-year holding period requirement. In order to be eligible for the tax exemption outlined above, you must have held on to your stock for a minimum of five years.</strong> If you do not meet this minimum requirement, you can employ a Section 1045 rollover (described below) to extend your holding period.<ul><li><strong>Note: this requirement is yet another reason why you should early exercise your options and file an 83(b). Early exercise allows you to 1) start the one year holding period for long-term capital gains treatment, and 2) start the five year holding period for Section 1202. If you don‚Äôt file an 83(b) election, the clock on long-term capital gain only begins when your shares vest ‚Äì so if there are multiple vesting dates, you will have multiple clocks to monitor for long-term capital gain ‚Äì and, if eligible, QSBS. An unexercised option or warrant is not considered QSBS, even if the underlying stock would meet the definition of QSBS.</strong></li><li><strong>Note: for stock acquired through the exercise of an option, the company must pass the ‚Äú$50M asset test‚Äù on the date of your exercise, not on the date of your grant.</strong> Similarly, for stock acquired through the vesting of RSUs, the company must pass the ‚Äú$50M asset test‚Äù on vesting, and your five year holding period begins on vesting, not on grant.</li><li>Note: if the stock was received as a gift, inheritance, or as a distribution from a partnership, the acquisition date is the date on which the transferor acquired the stock.</li></ul></li><li>Determines whether gain from the sale of the QSB stock is eligible for a 50%, 75%, or 100% federal tax exclusion.<ul><li>50% federal tax exclusion for stock issued before February 18, 2009</li><li>75% federal tax exclusion for stock issued between February 18, 2009 and September 27, 2010</li><li>100% federal tax exclusion for stock issued after September 27, 2010</li></ul></li><li>Marks the date on which the company must have $50M or less in assets.&nbsp;</li></ul></li></ul>



<h3>Requirements that must be met during the shareholder‚Äôs holding period:</h3>



<ul><li>Corporation must be a C-corp for the entire holding period.</li><li><strong>The corporation must be an ‚Äúactive business‚Äù during the entire period you held your stock. This means that at least 80% (by value) of the assets in your corporation must be used to pursue business in industries </strong><strong><em>other</em></strong><strong> than the industries below. Note that if your business provides a service, then it most likely does not qualify as a qualified small business.&nbsp;</strong><ul><li>Health, law, non-software engineering (civil, electrical, etc), architecture, accounting, actuarial science, performing arts, consulting, athletics, financial services, or brokerage.</li><li>Banking, insurance, financing, leasing, investing, or similar business.</li><li>Farming.</li><li>Mining or natural resource production or extraction.</li><li>Operating a hotel, restaurant, or similar business.</li></ul></li><li>Cash held for burn requirements generally qualify under this ‚Äúactive business‚Äù requirement. However, after two years, technically no more than 50% of the corporation‚Äôs assets can qualify under this exemption. While startups usually satisfy this requirement, it isn‚Äôt always clear how to apply the rule, especially if the startup retains significant cash following an investment (in other words, overfunded startups sitting on cash). If you‚Äôre like most startups and you‚Äôre burning cash to fund business operations you will most likely pass this check.</li><li>If the corporation bought back 5% or more of its stock in the year before or after your stock issuance, your stock will not qualify as QSBS.&nbsp;</li></ul>



<h2>Section 1045 Rollover</h2>



<p><strong>In order to be eligible for preferential tax treatment under Section 1202, you must satisfy the requirements above and have held onto your stock for at least five years. If you have not met the five year minimum, however, you can employ a Section 1045 rollover to extend your holding period.</strong></p>



<p><strong>If you have held onto your QSBS for at least six months, you can sell your QSBS and roll the proceeds of the sale into another QSBS issuer without recognizing a gain under Section 1045.</strong> This is a similar concept to a Section 1031 exchange in real estate. <strong>Per Section 1045, you have 60 days from the date of the sale of your original QSBS to roll the sale proceeds into new QSBS.</strong> In general, you should roll all of the proceeds from your sale of original QSBS into the new QSBS. If you take any cash off the table after the initial sale, that amount would be subject to capital gains tax. <strong>The cost basis of the new QSBS is the same as the cost basis of the original QSBS, and the holding period from the original QSBS is counted towards the holding period of the new QSBS.</strong></p>



<p>Consider the following scenario: you acquire 5M shares of QSBS from ‚ÄúCompany A‚Äù on January 1st, 2010 for $0.00001 per share. Your original cost basis is $50 (5M * $0.00001). Assume you then sell these shares in Company A for $4M on January 1st, 2012, and then reinvest this $4M to purchase 2,000 shares of QSBS in ‚ÄúCompany B‚Äù. Your holding period will pick up from where it left off and the cost basis for your new shares in Company B will be the same as the original cost basis for your shares in Company A ($50). If you then sell your QSBS in Company B at any point after January 1, ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://goyalpost.com/2020/09/29/how-to-save-millions-with-qsbs-and-section-1045-rollovers/">https://goyalpost.com/2020/09/29/how-to-save-millions-with-qsbs-and-section-1045-rollovers/</a></em></p>]]>
            </description>
            <link>https://goyalpost.com/2020/09/29/how-to-save-millions-with-qsbs-and-section-1045-rollovers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24641348</guid>
            <pubDate>Wed, 30 Sep 2020 17:39:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Telegram bot to get new HN stories by keywords]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24640924">thread link</a>) | @solus_factor
<br/>
September 30, 2020 | https://solus.life/hnbuzz/ | <a href="https://web.archive.org/web/*/https://solus.life/hnbuzz/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://solus.life/hnbuzz/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640924</guid>
            <pubDate>Wed, 30 Sep 2020 17:00:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ray 1.0]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24640775">thread link</a>) | @robertnishihara
<br/>
September 30, 2020 | https://www.anyscale.com/blog/announcing-ray-1-0 | <a href="https://web.archive.org/web/*/https://www.anyscale.com/blog/announcing-ray-1-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h3>Announcing Ray&nbsp;1.0</h3><p>Today, we‚Äôre happy to announce the release of <a href="https://github.com/ray-project/ray">Ray 1.0</a>. Ray 1.0 brings a <a href="https://docs.ray.io/en/master/package-ref.html">stable API</a> and new <a href="https://ray2020.sched.com/event/dhCy/ray-a-general-purpose-serverless-substrate-eric-liang-anyscale">general purpose serverless</a> features, both important steps towards the goal of providing a universal API for distributed computing. This past release has seen 67 contributors and 458 commits, making it the among the <a href="https://github.com/ray-project/ray/releases">largest yet</a> for Ray. In addition, 1.0 brings many new community <a href="https://docs.ray.io/en/master/ray-libraries.html">library integrations</a> to the growing Ray ecosystem.</p><h3>New Features</h3><p>Ray 1.0 makes it easier than ever to build and compose highly scalable libraries, applications, and services. Here are the highlights:</p><p><b>Resources, Not Machines: </b>Building distributed applications that run portably across different machine types, clusters, and clouds is a challenging task. Ray 1.0 makes this easy with an <a href="https://docs.ray.io/en/master/cluster/autoscaling.html">autoscaler</a> that intelligently selects the best <a href="https://docs.ray.io/en/master/cluster/autoscaling.html#multiple-node-type-autoscaling">node types</a> for an application‚Äôs <a href="https://docs.ray.io/en/master/advanced.html#accelerator-types">resource requests</a>. In addition, Ray 1.0 introduces <a href="https://docs.ray.io/en/master/placement-group.html">a placement group API</a> for fine-grained control over scheduling.</p><p><b>Production Serving: </b>A general purpose serverless framework hosts both offline batch and online serving workloads. Ray 1.0 ships with <a href="https://docs.ray.io/en/master/serve/">Ray Serve</a>, a production microservice and ML serving library. For custom serving applications, Ray 1.0 also introduces <a href="https://docs.ray.io/en/master/actors.html?highlight=lifetime#actor-lifetimes">detached</a> actor lifetimes, <a href="https://docs.ray.io/en/master/async_api.html">AsyncIO</a> actors, and application-level metrics via <a href="https://docs.ray.io/en/master/ray-metrics.html?highlight=prometheus">Prometheus</a>. Ray serving applications can be deployed in various <a href="https://docs.ray.io/en/master/cluster/cloud.html">cloud providers</a> and on <a href="https://docs.ray.io/en/master/cluster/kubernetes.html">Kubernetes</a>.</p><p><b>Automatic Memory Management</b>: Users of Ray 1.0 can say goodbye to ‚Äúobject evicted‚Äù errors, thanks to fully automated <a href="https://docs.ray.io/en/master/memory-management.html">memory management</a>. Application performance and memory usage can be debugged in the <a href="https://docs.ray.io/en/master/ray-dashboard.html">Ray dashboard</a>. To learn more about how Ray implements distributed reference counting with high-performance, reliability, and fault tolerance, check out the new <a href="https://docs.ray.io/en/master/whitepaper.html">Ray 1.0 whitepaper</a>.</p><p><b>Java and Windows Support: </b>Ray 1.0 brings native support for the Java and Windows platforms. This means that you can now use Ray to build <a href="https://docs.ray.io/en/master/cross-language.html">cross-language</a> and <a href="https://medium.com/distributed-computing-with-ray/build-distributed-java-applications-with-ray-90b381eff564">distributed Java</a> applications, and <a href="https://docs.ray.io/en/master/installation.html#windows-support">install Ray on Windows</a>.</p><h3>Community Update</h3><p><b>Community Integrations</b>: There are a growing number of <a href="https://docs.ray.io/en/master/ray-libraries.html">community libraries</a> that integrate with Ray 1.0 for distributed execution: <a href="https://classyvision.ai/tutorials/ray_aws">ClassyVision</a>, <a href="https://docs.ray.io/en/master/dask-on-ray.html">Dask</a>, <a href="https://github.com/asappresearch/flambe">Flambe</a>, <a href="https://horovod.readthedocs.io/en/stable/ray_include.html">Horovod</a>, <a href="https://huggingface.co/transformers/master/main_classes/trainer.html#transformers.Trainer.hyperparameter_search">HuggingFace</a>, <a href="https://analytics-zoo.github.io/master/#ProgrammingGuide/rayonspark/">Intel Analytics Zoo</a>, <a href="https://docs.ray.io/en/master/mars-on-ray.html">MARS</a>, <a href="https://github.com/modin-project/modin">Modin</a>, <a href="https://github.com/Intel-bigdata/oap-raydp">RayDP</a>, <a href="https://github.com/SeldonIO/alibi">Seldon Alibi</a>, and <a href="https://pypi.org/project/spacy-ray/">SpaCy</a>. This means users of these libraries can now scale their applications with Ray, and Ray users can easily leverage these libraries in their distributed applications.</p><p><b>Open Source</b>: At Anyscale, we‚Äôre proud to develop Ray along with the open source community. Many key Ray contributions are driven by the community‚Ää‚Äî‚Ääfor example, ongoing projects around high availability, multi-tenancy, and placement groups are led by <a href="https://www.antgroup.com/en">Ant Group</a>, and improved autoscaler support for different Clouds has come from <a href="https://aws.amazon.com/">Amazon</a> and <a href="https://azure.microsoft.com/en-us/">Microsoft</a>.</p><h3>More Information</h3><p>To learn more about Ray, join us at <a href="https://events.linuxfoundation.org/ray-summit/">Ray Summit</a>, which runs from September 30 to October 1. You can also find out more about Ray 1.0 through the <a href="https://forms.gle/9TSdDYUgxYs8SA9e8">Ray Slack</a> or the <a href="https://docs.ray.io/en/master/index.html">Documentation</a>.</p></div></div></div>]]>
            </description>
            <link>https://www.anyscale.com/blog/announcing-ray-1-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640775</guid>
            <pubDate>Wed, 30 Sep 2020 16:49:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Easy Ubuntu Hardening for Web Developers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24640736">thread link</a>) | @mariuz
<br/>
September 30, 2020 | https://blog.openbloc.com/automated-hardening-for-ubuntu/ | <a href="https://web.archive.org/web/*/https://blog.openbloc.com/automated-hardening-for-ubuntu/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-40-37.png 300w,
                            https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-40-37.png 600w,
                            https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-40-37.png 1000w,
                            https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-40-37.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-40-37.png" alt="Easy Ubuntu Hardening for Web Developers">
            </figure>

            <section>
                <div>
                    <p>You may have good reasons to focus on developing your disrupting app. And you may well be a very talented developer. But like me, even after years of experience as a web engineer, comes a point where we have to admit we don't know that much about security.</p><p>Unless you only use fully managed solutions to host your web applications, your startup probably has a bunch of servers you have to monitor and maintain. And unless your company has the scale to pay for real DevOps, security engineers, audits or pentests, then quite frankly, we'll mainly focus on finishing the current sprint hoping to get some traction ;)</p><p>Today I got my first Ubuntu VPS from <a href="https://blog.openbloc.com/p/3f54a7d4-a161-4bf0-a9ee-8ea9c6daf259/www.ovh.com">OVH</a>, a fresh new image ready to host the next version of my website. And it's got me thinking: I do remember it's best practice to disable SSH login by password, what else should I do ? Do I need a firewall ? Surely I don't have time to fully audit this default Ubuntu image by myself...</p><p>In this article I'll show you how to harden a default Ubuntu Server 20.04 image using existing open-source tools:</p><ol><li><a href="https://www.inspec.io/">Inspec</a> to identify security issues and misconfiguration</li><li><a href="https://www.ansible.com/">Ansible</a> to automatically harden your server</li><li><a href="https://dev-sec.io/">The DevSec Hardening Framework</a> which provides:<br>- <a href="https://github.com/dev-sec/linux-baseline">An Inspec profile</a><br>- <a href="https://github.com/dev-sec">Ansible / Chef / Puppet recipes</a> to enforce above Inspec profile</li></ol><!--kg-card-begin: markdown--><h2 id="quicksshsetup">Quick SSH setup</h2>
<p>Make sure your server is defined in <code>~/.ssh/config</code></p>
<pre><code>Host servername
	HostName &lt;your server ip address&gt;
	User username
	Port 22
</code></pre>
<p>To ssh into the server with your ssh key without typing the password just run:</p>
<p><code>$ ssh-copy-id -i ~/.ssh/id_rsa.pub servername</code></p>
<h2 id="usinginspecwithlinuxbaselineprofile">Using Inspec with linux-baseline profile</h2>
<p>On the server:</p>
<pre><code># download and install Inspec
$ wget https://packages.chef.io/files/stable/inspec/4.20.2/ubuntu/20.04/inspec_4.20.2-1_amd64.deb
$ sudo dpkg -i inspec_4.20.2-1_amd64.deb

# clone the linux-baseline profile
$ git clone https://github.com/dev-sec/linux-baseline

# run the Inspec profile
$ inspec exec linux-baseline
</code></pre>
<p><a href="https://www.inspec.io/docs/reference/install/">Inspec installation instructions</a></p>
<p>You should see a similar output:<br>
<img src="https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-01-40.png" alt="Capture-d--cran-de-2020-06-17-13-01-40"></p>
<p>Next thing will be to automatically apply better OS settings using Ansible and the recipes provided by the DevSec framework.</p>
<h2 id="usingansibletohardentheserver">Using Ansible to harden the server</h2>
<p>On your local machine:</p>
<pre><code># install Ansible
$ sudo apt update
$ sudo apt install software-properties-common
$ sudo apt-add-repository --yes --update ppa:ansible/ansible
$ sudo apt install ansible

# install the os and ssh hardening roles
$ ansible-galaxy install dev-sec.os-hardening
$ ansible-galaxy install dev-sec.ssh-hardening
</code></pre>
<p><a href="https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html">Ansible installation instructions</a></p>
<p>We then need to write a playbook for each ansible role:</p>
<pre><code># ansible-os-hardening.yaml
- hosts: your-server
  become: true
  roles:
    - dev-sec.os-hardening
    
# ansible-ssh-hardening.yaml 
- hosts: your-server
  become: true
  roles:
    - dev-sec.ssh-hardening
</code></pre>
<p>Finally run these playbooks with the following commands:</p>
<pre><code>$ ansible-playbook -K ansible-os-hardening.yaml
$ ansible-playbook -K ansible-ssh-hardening.yaml
</code></pre>
<p>Then, re-running <code>inspec exec linux-baseline</code> on the server should give a similar output:<br>
<img src="https://cdn.openbloc.fr/2020/06/Capture-d--cran-de-2020-06-17-13-00-59.png" alt="Capture-d--cran-de-2020-06-17-13-00-59"></p>
<p>Which is much better!</p>
<h2 id="finalthoughts">Final thoughts</h2>
<p>Though I can't say I have audited the DevSec framework per-se, I hope you now have a better understanding on how you can automate your servers security to stay up-to-date whith industry best practices.</p>
<p>Depending on what you then run on your server, you may have to allow some ports on the Ubuntu firewall, <a href="https://help.ubuntu.com/community/UFW">ufw</a>. Personally while testing <a href="https://caprover.com/">CapRover</a> I just had to run:</p>
<p><code>$ ufw allow 80,443,3000,996,7946,4789,2377/tcp; ufw allow 7946,4789,2377/udp;</code></p>
<h3 id="thanksforreadingandtakecare">Thanks for reading and take care !</h3>
<!--kg-card-end: markdown-->
                </div>
            </section>

                <section>
    <h3>Subscribe to Openbloc</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.openbloc.com/automated-hardening-for-ubuntu/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640736</guid>
            <pubDate>Wed, 30 Sep 2020 16:46:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Love Is the Only Antidote to Fear: A Lecture by John O'Donohue]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24640573">thread link</a>) | @sbuccini
<br/>
September 30, 2020 | https://www.stevenbuccini.com/love-is-the-only-antidote-to-fear | <a href="https://web.archive.org/web/*/https://www.stevenbuccini.com/love-is-the-only-antidote-to-fear">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <blockquote>
  <p>‚ÄúIt‚Äôs an old-fashioned thing to say, but I think that occasions of fear are invitations for freedom and for courage.‚Äù<br>
<em>‚ÄîJohn O‚ÄôDonohue</em></p>
</blockquote>

<p>It was just before Thanksgiving in 2017 and I was scared. The enormity of the decision I had just made ‚Äì to leave behind 5 years worth of memories, friendships, and professional networks on the opposite side of the country to move home and run for office ‚Äì was finally hitting home. I was lonely and afraid. So I decided to drive down to Durham to meet up with a close high school friend I hadn‚Äôt seen in a long, long time. After a couple of beers, I confessed my anxiousness. She recommended <a href="https://drive.google.com/open?id=1RpKTUDIhXlfXdoZXqt3gBlY0Zvy4_EZY">a lecture by an Irish thinker named John O‚ÄôDonohue, specifically ‚ÄúLove is the Only Antidote to Fear‚Äù</a>. The words hit me like a thunderbolt. Ever since then, whenever I am weighing the pros and cons of a big decision, I make sure to re-listen to this talk.</p>

<p>These are confusing, chaotic, and uncertain times. It is natural to be afraid. I hope this lecture provides some level of comfort to you, just as it has for me throughout the years.</p>

<p>NB: I highly, highly recommend <em>listening</em> to this talk. <a href="https://drive.google.com/open?id=1RpKTUDIhXlfXdoZXqt3gBlY0Zvy4_EZY">You can find the link here</a>. O‚ÄôDonohue is a noted lecturer for a reason, and it‚Äôs clear when you hear his highly conversational style in a Celtic lilt that those skills were honed at a lecturn during his years as a parish priest. However, if you prefer to read the text, I have transcribed it below.</p>

<hr>



<p><em>This text has been lightly edited to improve the flow while reading. I fed the recording through Descript to generate the original transcript, and then attempted to manually clean it up as I best I could. Transcription errors may remain. If you have suggestions or corrections, please email me.</em></p>

<p>Something that everyone has in common is the experience of fear, and the power of the presence of fear. There is no one that could say that they‚Äôre not afraid of something. Fear is present in every heart, and science and cultural studies show us that we‚Äôre right to be afraid to a level of about 10% in our experience that that corresponds with what‚Äôs actually the situation, but that 90% of the fear that we have is unreal. And that‚Äôs the haunting loneliness and incredible wastage of what fear does to the human heart.</p>

<p>Fear is the greatest trickster of all. It makes what is real seem unreal and it makes the unreal, real. I always think from nature that the most telling image to correspond to fear is fog. If you‚Äôve ever been out in the mountains and you‚Äôve got caught in fog, you‚Äôll know what I‚Äôm talking about. Several years ago, in the mountains at home in the west of Ireland that I know very well, I brought a friend from Manchester for a day on the mountains. And about two hours up in the mountains, the fog came down. I know these mountains really well and we kept going because I told her that I knew where I was going. And about four hours later, we found ourselves exactly back in the place where we were on the fog came down, not knowing where we were. Eventually we got down off the mountains because I was able to hear the ocean and we went in that direction. But that‚Äôs what fear does. And your normal experience is that it inflates things and makes something that‚Äôs fairly small very, very huge.</p>

<p>Some years ago, I was talking to a friend of mine who is into psychology and psychotherapy about fear. He said that something that he found very helpful when he was afraid was to hold on to one question and stick with it. And the question is to ask yourself, ‚ÄúWhat is it, exactly, that I‚Äôm afraid of?‚Äù If you hold to this question, gradually what seems huge and amorphous and beyond your control begins to shrink right down to one moment, one thing that you can actually deal with and handle.</p>

<p>Part of the reason that fear has such power over us is we are vulnerable, and fear draws great strength from time. If you wake up one Monday morning and you realize that on the next Friday that you have something horrible waiting for you, the chances are that your days on Monday, Tuesday, Wednesday, and Thursday will be totally shadowed by the threat of Friday, and you waste four lovely days because the fear of what‚Äôs waiting for you robs you of the beauty of the days that you have.
Something that I try to do myself when I‚Äôm afraid is to sit myself down, and on an empty chair opposite me I‚Äôd imagine the thing (or person or situation or whatever) that I was afraid of. Then I‚Äôd say to myself, ‚ÄúLet‚Äôs do it now. Instead of being miserable about it, let‚Äôs have a blast at it.‚Äù And then I would imagine, I‚Äôd say to myself, ‚ÄúWhat‚Äôs the worst thing that could happen in this situation?‚Äù And I‚Äôd think about it until I realize what the worst thing was and then I would force myself to imagine all the elements of the worst aspect of it. And then by the time the situation actually arrives, it isn‚Äôt too bad at all. You‚Äôll be incredibly relieved cause it‚Äôs never as bad as you thought!</p>

<p>One of the questions that‚Äôs always haunted me is what is the origin of fear? Why are humans afraid? One of the reasons is that the place we live in the world is in this clay tent of the human body. And it‚Äôs a very vulnerable old tent. Because once you‚Äôre in a body, you‚Äôre always somewhere. You can never successfully hide and you can always be gotten to. You know, like in some of these mafia films, when they go off for a while but somebody always turns up nearly and gets to them? It‚Äôs the same thing, but in a human life.</p>

<p>The other thing is that the way that we interpret the world is an incredibly painful and broken and tender way through birth, which was separation. And I always think that humans are really able for anything after successfully coming through the trauma of being born. Because it was loss, separation, alienation. I mean, I often think that‚Äôs an image I often use for myself in relation to death. Maybe we have death all wrong because we always think of it as an ending, as closure. A quenching.
But say you turn it the other way around. Say you conducted an interview with the baby in the womb before it was born. And say was a real ‚Äúwith it‚Äù baby, the kind that wanted to know what‚Äôs going down and you said:</p>

<p>‚ÄúOkay, baby, you asked for it. You‚Äôre going to get it. Here‚Äôs the story. In a half an hour you will be expelled from the shelter of the womb where you have emerged and been formed. Secondly, you will come out along a passage (and we all did this) where you will feel that every moment you‚Äôre being smothered. Thirdly, you will arrive out into a huge vacancy, probably with merciless light in it. Fourthly, the cord that connects you to the mother heart will be cut. Fifthly, regardless of how close you ever come to anyone in your life afterwards, you will always be on your own. Sixthly, you‚Äôre going on a journey for which there is no map. And seventhly, you can‚Äôt turn back and eighth, anything can happen to you on the journey.‚Äù
Now, if the baby was still breathing at that stage, it would have to conclude, ‚ÄúJesus, things were really nice and good here and now it looks like I‚Äôm going to die,‚Äù when in actual fact what‚Äôs happening is that has been born. And my suspicion in relation to death is that we only see all the destructive side of it, and that possibly, (I‚Äôll address this bit tomorrow and my talk on beauty), that what‚Äôs happening actually in death is that we‚Äôre being born again. This time, in a way that the loneliness of space and time no longer has a hold over us.</p>

<p>But I think that if you were to ask, ‚ÄúWhat is the root of all fear?‚Äù the root of all fear is in the fear of death. And I have an old suspicion that if you sort out your fear of death as the worst thing ‚Äì not something that just might happen to you but that IS going to happen to you ‚Äì then you remove the soil and the nutrient that nourishes your normal fears.</p>

<p>I used to be very afraid of dying for a long time in my life. And then I became a Roman Catholic priest. And in my years as a priest, one of the immense privileges was to help people to die. And early on in my priesthood there was this woman that I knew. She was a lovely woman, 27 years old. She was a traveler, one of the gypsy people, and she had two children and she was pregnant with a third child when she got leukemia. She was being treated for it though, and it seemed to be working. I was visiting her once a week, and one evening I went in to see her and I was going to give her a hug and she said, ‚ÄúDon‚Äôt hug me, I‚Äôm bleeding.‚Äù And it turned out that the treatment wasn‚Äôt working. About four nights later, in the middle of the night, there was a knock at the door of my house. Her family was there and they said, ‚ÄúWe‚Äôve got news from the hospital that she‚Äôs really bad and we need to go in.‚Äù So I talked to the father and mother, and then they all came with their vans and we all went into the hospital. And as soon as I came in the hospital door, I saw the young woman on all these machines and tubes and everything. And she looked up at me, the poor pet, and she said, ‚ÄúAm I going to die?‚Äù And I said, ‚ÄúI don‚Äôt know whether you‚Äôre going to die or not. But when I do, I will tell you.‚Äù She said, ‚ÄúOkay.‚Äù So then everybody arrived and all the rest of it, and about 4:15 in the morning, she said to me, ‚ÄúWill you open the window?‚Äù And something told me that she was going to die. So I went out and I met the house doctor who was on duty and I said, ‚ÄúWhat‚Äôs the story here?‚Äù He said, ‚ÄúAt 7:30, we are going to bring our downstairs and try one more procedure. But, in actual fact, we expect her to be dead by 10.‚Äù So I went back into the room and I said that I wanted some time on my own with her. All the family left and I sat down. I took her hand.</p>

<p>‚ÄúYou‚Äôre going to die,‚Äù is one of the most awful sentences any human being can ever hear, no matter how sick you are. Sometimes we think when people are sick that they know what‚Äôs coming, but they don‚Äôt. Because language is an incredible presence. There are some words that are said that are like ‚Ä¶</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.stevenbuccini.com/love-is-the-only-antidote-to-fear">https://www.stevenbuccini.com/love-is-the-only-antidote-to-fear</a></em></p>]]>
            </description>
            <link>https://www.stevenbuccini.com/love-is-the-only-antidote-to-fear</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640573</guid>
            <pubDate>Wed, 30 Sep 2020 16:33:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief History of Neural Nets and Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24640259">thread link</a>) | @andreyk
<br/>
September 30, 2020 | https://www.skynettoday.com/overviews/neural-net-history | <a href="https://web.archive.org/web/*/https://www.skynettoday.com/overviews/neural-net-history">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2 id="prologue-the-deep-learning-tsunami">Prologue: The Deep Learning Tsunami</h2>

<blockquote>
  <p>‚ÄúDeep Learning waves have lapped at the shores of computational linguistics for several years now, but 2015 seems like the year when the full force of the tsunami hit the major Natural Language Processing (NLP) conferences.‚Äù -<a href="http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00239">Dr. Christopher D. Manning, Dec 2015</a> <sup id="fnref:part1_1" role="doc-noteref"><a href="#fn:part1_1">1</a></sup></p>
</blockquote>

<p>This may sound hyperbolic - to say the established methods of an entire field of research are quickly being superseded by a new discovery, as if hit by a research ‚Äòtsunami‚Äô. But, this catastrophic language is appropriate for describing the meteoric rise of Deep Learning over the last several years - a rise characterized by drastic improvements over reigning approaches towards the hardest problems in AI, massive investments from industry giants such as Google, and exponential growth in research publications (and Machine Learning graduate students). Having taken several classes on Machine Learning, and even used it in undergraduate research, I could not help but wonder if this new ‚ÄòDeep Learning‚Äô was anything fancy or just a scaled up version of the ‚Äòartificial neural nets‚Äô that were already developed by the late 80s. And let me tell you, the answer is quite a story - the story of not just neural nets, not just of a sequence of research breakthroughs that make Deep Learning somewhat more interesting than ‚Äòbig neural nets‚Äô  (that I will attempt to explain in a way that just about anyone can understand), but most of all of how several unyielding researchers made it through dark decades of banishment to finally redeem neural nets and achieve the dream of Deep Learning.</p>


<blockquote><p id="sources">
I am certainly not a foremost expert on this topic. In depth technical overviews with long lists of references written by those who actually made the field what it is include Yoshua Bengio's <a href="http://www.iro.umontreal.ca/~lisa/pointeurs/TR1312.pdf">"Learning Deep Architectures for AI"</a>, J√ºrgen Schmidhuber's <a href="http://arxiv.org/pdf/1404.7828v4.pdf">"Deep Learning in Neural Networks: An Overview"</a> and LeCun et al.s' <a href="http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf">"Deep learning"</a>. In particular, this is mostly a history of research in the US/Canada AI community, and even there will not mention many researchers; a particularly in depth history of the field that covers these omissions is J√ºrgen Schmidhuber's <a href="http://people.idsia.ch/~juergen/deep-learning-overview.html">"Deep Learning in Neural Networks: An Overview"</a>. I am also most certainly not a professional writer, and will cop to there being shorter and much less technical overviews written by professional writers such as Paul Voosen's <a href="http://chronicle.com/article/The-Believers/190147">"The Believers"</a>, John Markoff's <a href="http://www.nytimes.com/2012/11/24/science/scientists-see-advances-in-deep-learning-a-part-of-artificial-intelligence.html">"Scientists See Promise in Deep-Learning Programs"</a> and Gary Marcus's <a href="http://www.newyorker.com/news/news-desk/is-deep-learning-a-revolution-in-artificial-intelligence">"Is ‚ÄúDeep Learning‚Äù a Revolution in Artificial Intelligence?"</a>. I also will stay away from getting too technical here, but there is a plethora of tutorials on the internet on all the major topics covered in brief by me.
<br>
Any corrections would be appreciated, though I will note some ommisions are intentional since I want to try and keep this 'brief' and a good mix of simple technical explanations and storytelling. 
<br>
This piece is an updated and expanded version of blog posts originally released in 2015 on www.andreykurenkov.com. 
</p></blockquote>

<ul id="markdown-toc">
  <li><a href="#prologue-the-deep-learning-tsunami" id="markdown-toc-prologue-the-deep-learning-tsunami">Prologue: The Deep Learning Tsunami</a></li>
  <li><a href="#part-1-the-beginnings-1950s-1980s" id="markdown-toc-part-1-the-beginnings-1950s-1980s">Part 1: The Beginnings (1950s-1980s)</a>    <ul>
      <li><a href="#the-centuries-old-machine-learning-algorithm" id="markdown-toc-the-centuries-old-machine-learning-algorithm">The Centuries Old Machine Learning Algorithm</a></li>
      <li><a href="#the-folly-of-false-promises" id="markdown-toc-the-folly-of-false-promises">The Folly of False Promises</a></li>
      <li><a href="#the-thaw-of-the-ai-winter" id="markdown-toc-the-thaw-of-the-ai-winter">The Thaw of the AI Winter</a></li>
    </ul>
  </li>
  <li><a href="#part-2-neural-nets-blossom-1980s-2000s" id="markdown-toc-part-2-neural-nets-blossom-1980s-2000s">Part 2: Neural Nets Blossom (1980s-2000s)</a>    <ul>
      <li><a href="#neural-nets-gain-vision" id="markdown-toc-neural-nets-gain-vision">Neural Nets Gain Vision</a></li>
      <li><a href="#neural-nets-go-unsupervised" id="markdown-toc-neural-nets-go-unsupervised">Neural Nets Go Unsupervised</a></li>
      <li><a href="#neural-nets-gain-beliefs" id="markdown-toc-neural-nets-gain-beliefs">Neural Nets Gain Beliefs</a></li>
      <li><a href="#neural-nets-make-decisions" id="markdown-toc-neural-nets-make-decisions">Neural Nets Make Decisions</a></li>
      <li><a href="#neural-nets-get-loopy" id="markdown-toc-neural-nets-get-loopy">Neural Nets Get Loopy</a></li>
      <li><a href="#neural-nets-start-to-speak" id="markdown-toc-neural-nets-start-to-speak">Neural Nets Start to Speak</a></li>
      <li><a href="#a-new-winter-dawns" id="markdown-toc-a-new-winter-dawns">A New Winter Dawns</a></li>
    </ul>
  </li>
  <li><a href="#part-3-deep-learning-2000s-2010s" id="markdown-toc-part-3-deep-learning-2000s-2010s">Part 3: Deep Learning (2000s-2010s)</a>    <ul>
      <li><a href="#the-funding-of-more-layers" id="markdown-toc-the-funding-of-more-layers">The Funding of More Layers</a></li>
      <li><a href="#the-development-of-big-data" id="markdown-toc-the-development-of-big-data">The Development of Big Data</a></li>
      <li><a href="#the-importance-of-brute-force" id="markdown-toc-the-importance-of-brute-force">The Importance of Brute Force</a></li>
      <li><a href="#the-deep-learning-equation" id="markdown-toc-the-deep-learning-equation">The Deep Learning Equation</a></li>
    </ul>
  </li>
  <li><a href="#epilogue-the-decade-of-deep-learning" id="markdown-toc-epilogue-the-decade-of-deep-learning">Epilogue: The Decade of Deep Learning</a></li>
</ul>


<p>The beginning of a story spanning half a century, about how we learned to make computers learn. In this part, we shall cover the birth of neural nets with the Perceptron in 1958, the AI Winter of the 70s, and neural nets‚Äô return to popularity with backpropagation in 1986.</p>

<h2 id="the-centuries-old-machine-learning-algorithm">The Centuries Old Machine Learning Algorithm</h2>
<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/Linear_regression.svg" alt="Linear Regression">     
    <figcaption>Linear regression <a href="https://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_regression.svg">(Source)</a></figcaption>
</figure>

<p>Let‚Äôs start with a brief primer on what Machine Learning is. Take some points on a 2D graph, and draw a line that fits them as well as possible. What you have just done is generalized from a few example of pairs of input values (x) and output values (y) to a general function that can map any input value to an output value. This is known as linear regression, and it is a wonderful little <a href="https://en.wikipedia.org/wiki/Linear_regression#cite_note-4">200 year old</a> technique for extrapolating a general function from some set of input-output pairs. And here‚Äôs why having such a technique is wonderful: there is an incalculable number of functions that are hard to develop equations for directly, but are easy to collect examples of input and output pairs for in the real world - for instance, the function mapping an input of recorded audio of a spoken word to an output of what that spoken word is.</p>

<p>Linear regression is a bit too wimpy a technique to solve the problem of speech recognition, but what it does is essentially what <strong>supervised Machine Learning</strong> is all about: ‚Äòlearning‚Äô a function given a <strong>training set</strong> of <strong>examples</strong>, where each example is a pair of an input and output from the function (we shall touch on the unsupervised flavor in a little while). In particular, machine learning methods should derive a function that can generalize well to inputs not in the training set, since then we can actually apply it to inputs for which we do not have an output. For instance, Google‚Äôs current speech recognition technology is powered by Machine Learning with a massive training set, but not nearly as big a training set as all the possible speech inputs you might task your phone with understanding.</p>

<p>This generalization principle is so important that there is almost always a <strong>test set</strong> of data (more examples of inputs and outputs) that is not part of the training set. The separate set can be used to evaluate the effectiveness of the machine learning technique by seeing how many of the examples the method correctly computes outputs for given the inputs. The nemesis of generalization is <strong>overfitting</strong> - learning a function that works really well for the training set but badly on the test set. Since machine learning researchers needed means to compare the effectiveness of their methods, over time there appeared standard <strong>datasets</strong> of training and testing sets that could be used to evaluate machine learning algorithms.</p>

<p>Okay okay, enough definitions. Point is - our line drawing exercise is a very simple example of supervised machine learning: the points are the training set (X is input and Y is output), the line is the approximated function, and we can use the line to find Y values for X values that don‚Äôt match any of the points we started with. Don‚Äôt worry, the rest of this history will not be nearly so dry as all this. Here we go.</p>

<h2 id="the-folly-of-false-promises">The Folly of False Promises</h2>

<p>Why have all this prologue with linear regression, since the topic here is ostensibly neural nets? Well, in fact linear regression bears some resemblance to the first idea conceived specifically as a method to make machines learn: <a href="http://psycnet.apa.org/index.cfm?fa=buy.optionToBuy&amp;id=1959-09865-001">Frank Rosenblatt‚Äôs <strong>Perceptron</strong></a><sup id="fnref:part1_2" role="doc-noteref"><a href="#fn:part1_2">2</a></sup>.</p>
<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/34998.jpg" alt="Perceptron">
    <figcaption>A diagram showing how the Perceptron works. <a href="http://cse-wiki.unl.edu/wiki/images/0/0f/Perceptron.jpg">(Source)</a></figcaption>    
</figure>

<p>A psychologist, Rosenblatt conceived of the Percetron as a simplified mathematical model of how the neurons in our brains operate: it takes a set of binary inputs (nearby neurons), multiplies each input by a continuous valued weight (the synapse strength to each nearby neuron), and thresholds the sum of these weighted inputs to output a 1 if the sum is big enough and otherwise a 0 (in the same way neurons either fire or do not). Most of the inputs to a Perceptron are either some data or the output of another Perceptron, but an extra detail is that Perceptrons also have one special ‚Äòbias‚Äô input, which just has a value of 1 and basically ensures that more functions are computable with the same input by being able to offset the summed value. This model of the neuron built on the work of Warren McCulloch and Walter Pitts <a href="http://www.minicomplexity.org/pubs/1943-mcculloch-pitts-bmb.pdf">Mcculoch-Pitts</a><sup id="fnref:part1_3" role="doc-noteref"><a href="#fn:part1_3">3</a></sup>, who showed that a neuron model that sums binary inputs and outputs a 1 if the sum exceeds a certain threshold value, and otherwise outputs a 0, can model the basic OR/AND/NOT functions. This, in the early days of AI, was a big deal - the predominant thought at the time was that making computers able to perform formal logical reasoning would essentially solve AI.</p>

<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/34832.jpg" alt="Perceptron 2"> 
    <figcaption>Another diagram, showing the biological inspiration. The <b>activation function</b> is what people now call the non-linear function applied to the weighted input sum to produce the output of the artificial neuron - in the case of Rosenblatt's Perceptron, the function just a thresholding operation.  <a href="http://cs231n.github.io/neural-networks-1/">(Source)</a> </figcaption>    
</figure>

<p>However, the Mcculoch-Pitts model lacked a mechanism for learning, which was crucial for it to be usable for AI. This is where the Perceptron excelled - Rosenblatt came up with a way to make such artificial neurons learn, inspired by the <a href="http://onlinelibrary.wiley.com/doi/10.1002/cne.900930310/abstract">foundational work</a><sup id="fnref:part1_4" role="doc-noteref"><a href="#fn:part1_4">4</a></sup> of Donald Hebb. Hebb put forth the unexpected and hugely influential idea that knowledge and learning occurs in the brain primarily through the formation and change of synapses between neurons - concisely stated as Hebb‚Äôs Rule:</p>

<blockquote>
  <p>‚ÄúWhen an axon of cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that A‚Äôs efficiency, as one of the cells firing B, is increased.‚Äù</p>
</blockquote>

<p>The Perceptron did not follow this idea exactly, but having weights on the inputs allowed for a very simple and intuitive learning scheme: given a <strong>training set</strong> of input-output examples the Perceptron should ‚Äòlearn‚Äô a function from, for each example increase the weights if the Perceptron output for that example‚Äôs input is too low compared to the example, and otherwise decrease the weights if the output is too high. Stated ever so slightly more formally, the algorithm is as follows:</p>

<ol>
  <li>Start off with a Perceptron having random weights and a training set</li>
  <li>For the inputs of an example in the ‚Ä¶</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.skynettoday.com/overviews/neural-net-history">https://www.skynettoday.com/overviews/neural-net-history</a></em></p>]]>
            </description>
            <link>https://www.skynettoday.com/overviews/neural-net-history</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640259</guid>
            <pubDate>Wed, 30 Sep 2020 16:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the pervasive presence of military language elements in computer security]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24640198">thread link</a>) | @dijit
<br/>
September 30, 2020 | https://dustri.org/b/on-the-pervasive-presence-of-military-language-elements-in-computer-security.html | <a href="https://web.archive.org/web/*/https://dustri.org/b/on-the-pervasive-presence-of-military-language-elements-in-computer-security.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section id="content">
  <article>
    <header>
      
    </header>

    <div>
      <p>As I was writing an article for the first edition of <a href="https://pagedout.institute/">Paged Out</a>,
I had an interesting (albeit too short) conversation regarding
its <a href="https://pagedout.institute/download/PagedOut_001_wallpaper_30.png">cover</a>
with <a href="https://gynvael.coldwind.pl/?id=50">Gynvael Coldwind</a>.
Drawn by <a href="https://www.deviantart.com/refiend">ReFiend</a>, it
features two people on the foreground, wielding what looks like guns.
This lead to a discussion on the omnipresence of military jargon, and thus violence,
in the world of computer security. I told him that I'll publish a blogpost 
to correctly articulate my thoughts on the topic, instead of the incoherent
rambling that I served him.</p>
<p>At every single security conference, there is someone with a direct quote of
the <a href="https://en.wikipedia.org/wiki/The_Art_of_War">Art of War</a> on their slide
deck, and there is a metric fuckton of assorted military-inspired bullshit
terms for almost everything: <a href="http://www.sans.org/reading-room/whitepapers/analyst/killing-advanced-threats-tracks-intelligent-approach-attack">cyber
kill-chain</a>/<a href="https://www.langner.com/2010/12/the-short-path-from-cyber-missiles-to-dirty-digital-bombs/">cyber
missiles</a>/<a href="https://www.techopedia.com/definition/29052/cyber-pearl-harbor">cyber
pearl
harbor</a>/<a href="https://www.arcyber.army.mil/">cyber
soldier</a>/<a href="https://www.langner.com/2010/12/the-short-path-from-cyber-missiles-to-dirty-digital-bombs/">cyber
strikes</a>/<a href="https://www.wired.com/2010/03/schmidt-cyberwar/">cyber</a>
<a href="https://www.theverge.com/2014/11/21/7259833/cyberwar-is-bullshit">war</a>/<a href="https://www.bloomberg.com/news/articles/2011-07-20/cyber-weapons-the-new-arms-race">cyber
weapons</a>/<a href="https://www.academic-conferences.org/conferences/iccws/">cyber</a>
<a href="https://en.wikipedia.org/wiki/cyberwarfare">warfare</a>/<a href="http://www.nsci-va.org/cyberreferencelib/2010-11-joint%20terminology%20for%20cyberspace%20operations.pdf">defensive counter
cyber</a>/<a href="https://nvd.nist.gov/800-53/rev4/control/sc-44">detonation
chamber capability</a>/<a href="https://www.cyberriskopportunities.com/notpetya-the-exploit-that-would-lead-to-many-attacks-part-3/">digital
munitions</a>/<a href="https://www.howtogeek.com/445096/what-does-military-grade-encryption-mean/">military-grade
encryption</a>/<a href="https://www.jstor.org/stable/26502756">next-generation
defensive cyber operations</a>/<a href="https://en.wikipedia.org/wiki/proactive_cyber_defence">proactive
cyber defence</a>/‚Ä¶</p>
<p>I understand that it's tempting to compare computer security to war: It takes our daily toil and
raises the stakes, makes us feel that victory is glorious; a battle of the
minds, that our work really matters and is important; and we are united against a common enemy.</p>
<p>But when you think about it, it's absurd: War is something terrible that should be avoided at
almost any cost, a <em>solution</em> of last resort. The worse outcome of
computer-related drama/problems probably doesn't imply entire populations
dying, being tortured, millions of refugees, camps, ‚Ä¶ Odds are that you won't
save actual lives by deploying a firewall: don't call it a "cyber bulletproof vest deployment".</p>
<p>War justifies terrible behaviours: who cares about you being screamed at when
you're <em>at war</em>? Who cares about your family life, your dinners plans, your hollidays, ‚Ä¶ when you're <em>at war</em>? What
are broken principles and despicable means, when you're <em>at war</em> ? ‚Ä¶
which is a disastrous way to govern and organise a workspace.</p>
<p>Moreover, war maps poorly over computer security. What is a "<a href="https://en.wikipedia.org/wiki/Penetration_test">penetration
test</a>"
combat-wise? How do you map "<a href="https://en.wikipedia.org/wiki/Full_disclosure_">full disclosure</a>" to war? What is a
"prisoner's camp" or "<a href="https://en.wikipedia.org/wiki/Carpet_bombing">carpet bombing</a>" with a computer (apparently <a href="https://www.zdnet.com/article/proof-of-concept-carpet-bombing-exploit-released-in-the-wild/">zdnet</a> <a href="https://www.zdnet.com/article/carpet-bombing-ddos-attack-takes-down-south-african-isp-for-an-entire-day/">can</a> )? Rigidly mapping
one onto the other can and will create huge distortions.</p>
<p>Of course, nobody says that computer security stuff actually <em>is</em> war, but
as said in <a href="https://en.wikipedia.org/wiki/Metaphors_We_Live_By">Metaphors We Live By </a> by <a href="https://en.wikipedia.org/wiki/George_Lakoff">George Lakoff</a> and <a href="https://en.wikipedia.org/wiki/Mark_Johnson_(professor)">Mark
Johnson</a>, "Conceptual metaphors shape not just our communication, but also shape
the way we think and act.". Leading to nonsensical bullshit posts like <a href="https://twoscenarios.typepad.com/maneuver_marketing_commun/2005/05/military_metaph.html">this one</a>, <a href="https://www.forbes.com/sites/forbeslifestyle/2012/05/07/plea-for-a-cease-fire-in-business-as-warfare-advice/#f77cce37aa79">entire laughingly stupid books</a>,
and to despicable and hostile work climate.</p>
<p>An other perverse effect is that since military and violent imagery are traditionally, culturally and stereotypically associated with <a href="https://en.wikipedia.org/wiki/Toxic_masculinity">toxic masculinity</a>,
this doesn't help with increasing the <a href="https://www.isc2.org/research/women-in-cybersecurity">dramatically low</a> diversity in the computer security sector.</p>
<p>When we think about it, we have way better metaphors:</p>
<ul>
<li>Computer security as gardening: defending against bugs, growing programs,
     harvesting money, ‚Ä¶</li>
<li>Computer security as building a house: everyone wants cosy stuff, yet you
    still need a solid door, maybe a couple of windows as well, definitely solid
    walls, ‚Ä¶</li>
<li>Computer security as playing cards: there are adversaries, winning moves,
    gambles, influences, ‚Ä¶</li>
<li>Computer security as guarding a museum: priceless artefacts, sneaky attackers
    √† la Ars√®ne Lupin, ‚Ä¶</li>
<li>‚Ä¶</li>
</ul>
<p>The goal of computer security is to make safer systems, not about waging wars,
and thus shouldn't be envisioned as such. </p>
<p>Of course, if you're working in the military and in infosec, there are overlaps,
but I would argue that this is more about military than it is about computer security.</p>
<p>As <a href="https://www.linkedin.com/in/roybahat">Rob Bahat</a> said in 2016 in his <a href="https://shift.newco.co/2016/11/15/business-is-not-war-lets-stop-talking-like-it-is/">Business Is Not War. Let‚Äôs Stop Talking Like It Is.</a> article:</p>
<blockquote>
<p>Business, at its best, is creation‚Ää‚Äî‚Ääand war,
always, is destruction. They are opposites, and if we want industry to be a
positive force in our personal lives, environment, society, and future, we
should divorce our language about business from the tragic (if sometimes
necessary) conflicts that bring devastation. There are so many good businesses;
but it is hard to find a good war.</p>
</blockquote>
    </div>
  </article>
</section>
    </div></div>]]>
            </description>
            <link>https://dustri.org/b/on-the-pervasive-presence-of-military-language-elements-in-computer-security.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640198</guid>
            <pubDate>Wed, 30 Sep 2020 16:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Failed Promise of Web Components]]>
            </title>
            <description>
<![CDATA[
Score 360 | Comments 223 (<a href="https://news.ycombinator.com/item?id=24640151">thread link</a>) | @lemonberry
<br/>
September 30, 2020 | https://lea.verou.me/2020/09/the-failed-promise-of-web-components/ | <a href="https://web.archive.org/web/*/https://lea.verou.me/2020/09/the-failed-promise-of-web-components/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Web Components had so much potential to empower HTML to do more, and make web development more accessible to non-programmers and easier for programmers. Remember how exciting it was every time we got new shiny HTML elements that actually <em>do stuff</em>? Remember how exciting it was to be able to do sliders, color pickers, dialogs, disclosure widgets straight in the HTML, without having to include any widget libraries?</p>



<p>The promise of Web Components was that we‚Äôd get this convenience, but for a much wider range of HTML elements, developed much faster, as nobody needs to wait for the full spec + implementation process. We‚Äôd just include a script, and boom, we have more elements at our disposal!</p>



<p>Or, that was the idea. Somewhere along the way, the space got flooded by JS frameworks aficionados, who revel in complex APIs, overengineered build processes and dependency graphs that look like the roots of a banyan tree.</p>



<figure><img src="https://live.staticflickr.com/2025/32441377780_e3acf6de12_b.jpg" alt=""><figcaption>This is what the roots of a Banyan tree look like. <a href="https://www.flickr.com/photos/79721788@N00/32441377780/">Photo by David Stanley on Flickr (CC-BY)</a>. </figcaption></figure>



<p>Perusing the components on <a href="https://www.webcomponents.org/">webcomponents.org</a> fills me with anxiety, and I‚Äôm perfectly comfortable writing JS ‚Äî I write JS for a living! What hope do those who can‚Äôt write JS have? Using a custom element from the directory often needs to be preceded by a ritual of npm flugelhorn, import clownshoes, build quux, all completely unapologetically because ‚Äúhere is my truckload of dependencies, yeah, what‚Äù. Many steps are even omitted, likely because they are ‚Äúobvious‚Äù. Often, you wade through the maze only to find the component doesn‚Äôt work anymore, or is not fit for your purpose.</p>



<p>Besides setup, the main problem is that HTML is not treated with the appropriate respect in the design of these components. They are not designed as closely as possible to standard HTML elements, but <em>expect</em> JS to be written for them to do anything. HTML is simply treated as a shorthand, or worse, as merely a marker to indicate where the element goes in the DOM, with all parameters passed in via JS. I recall <a href="https://adactio.com/articles/12839#webcomponents">a wonderful talk by Jeremy Keith</a> a few years ago about this very phenomenon, where he discussed <a href="https://shop.polymer-project.org/">this e-shop Web components demo by Google</a>, which is the poster child of this practice. These are the entire contents of its <code>&lt;body&gt;</code> element:</p>



<pre><code>&lt;body&gt;
	&lt;shop-app unresolved=""&gt;SHOP&lt;/shop-app&gt;
	&lt;script src="node_assets/@webcomponents/webcomponentsjs/webcomponents-loader.js"&gt;&lt;/script&gt;
	&lt;script type="module" src="src/shop-app.js"&gt;&lt;/script&gt;
	&lt;script&gt;window.performance&amp;&amp;performance.mark&amp;&amp;performance.mark("index.html");&lt;/script&gt;
&lt;/body&gt;</code></pre>



<p>If this is how Google is leading the way, how can we hope for contributors to design components that follow established HTML conventions?</p>



<p>Jeremy criticized this practice from the aspect of backwards compatibility: when JS is broken or not enabled, or the browser doesn‚Äôt support Web Components, the entire website is blank. While this is indeed a serious concern, my primary concern is one of <strong>usability</strong>: <strong>HTML is a lower barrier to entry language</strong>. Far more people can write HTML than JS. Even for those who do eventually write JS, it often comes after spending years writing HTML &amp; CSS.</p>



<p>If components are designed in a way that requires  JS, this excludes thousands of people from using them. And even for those who <em>can</em> write JS, HTML is often easier: you don‚Äôt see many people rolling their own sliders or using JS-based ones once <code>&lt;input type="range"&gt;</code> became widely supported, right?</p>



<p>Even when JS is unavoidable, it‚Äôs not black and white. A well designed HTML element can reduce the amount and complexity of JS needed to a minimum. Think of the <code><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/dialog">&lt;dialog&gt;</a></code> element: it usually does require *some* JS, but it‚Äôs usually rather simple JS. Similarly, the <code>&lt;video&gt;</code> element is perfectly usable just by writing HTML, and has a comprehensive JS API for anyone who wants to do fancy custom things.</p>



<p>The other day I was looking for a simple, dependency free, tabs component. You know, the canonical example of something that is easy to do with Web Components, the example 50% of tutorials mention. I didn‚Äôt even care what it looked like, it was for a testing interface. I just wanted something that is small and works like a normal HTML element. Yet, it proved so hard I ended up writing my own!</p>



<h3>Can we fix this?</h3>



<p>I‚Äôm not sure if this is a design issue, or a documentation issue. Perhaps for many of these web components, there are easier ways to use them. Perhaps there are vanilla web components out there that I just can‚Äôt find. Perhaps I‚Äôm looking in the wrong place and there is another directory somewhere with different goals and a different target audience. </p>



<p>But if not, and if I‚Äôm not alone in feeling this way, we need a directory of web components with strict inclusion criteria:</p>



<ul><li><strong>Plug and play.</strong> No dependencies, no setup beyond including one <code>&lt;script&gt;</code> tag. If a dependency is absolutely <em>needed</em> (e.g. in a map component it doesn‚Äôt make sense to draw your own maps), the component loads it automatically if it‚Äôs not already loaded.</li><li>Syntax and API follows <a href="https://www.smashingmagazine.com/2017/02/designing-html-apis/"><strong>conventions established by built-in HTML elements</strong></a> and anything that <em>can</em> be done without the component user writing JS, <em>is</em> doable without JS, per <a href="https://www.w3.org/2001/tag/doc/leastPower.html">the W3C principle of least power</a>.</li><li><strong>Accessible by default</strong> via sensible ARIA defaults, just like normal HTML elements.</li><li><strong>Themable</strong> via <code><a href="https://developer.mozilla.org/en-US/docs/Web/CSS/::part">::part()</a></code>, selective inheritance and custom properties. Very minimal style by default. Normal CSS properties should just ‚Äúwork‚Äù to the the extent possible.</li><li><strong>Only one component of a given type</strong> in the directory, that is <strong>flexible</strong> and <strong>extensible</strong> and continuously iterated on and improved by the community. Not 30 different sliders and 15 different tabs that users have to wade through. No branding, no silos of ‚Äúcomponent libraries‚Äù. Only elements that are designed as closely as possible to what a browser would implement in every way the current technology allows.</li></ul>



<p>I would be up for working on this if others feel the same way, since that is not a project for one person to tackle. <em>Who‚Äôs with me?</em></p>



<p><strong>UPDATE:</strong> Wow this post blew up! Thank you all for your interest in participating in a potential future effort. I‚Äôm currently talking to stakeholders of some of the existing efforts to see if there are any potential collaborations before I go off and create a new one. <a href="https://twitter.com/leaverou">Follow me on Twitter to hear about the outcome</a>!</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://lea.verou.me/2020/09/the-failed-promise-of-web-components/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24640151</guid>
            <pubDate>Wed, 30 Sep 2020 15:59:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Garry Tan on Posterous, Palantir, YC, Initialized and Influencer Investing]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24639871">thread link</a>) | @rayshan
<br/>
September 30, 2020 | https://www.acquired.fm/episodes/how-yc-rewrote-the-seed-playbook-with-garry-tan-hn | <a href="https://web.archive.org/web/*/https://www.acquired.fm/episodes/how-yc-rewrote-the-seed-playbook-with-garry-tan-hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><strong>Transcript:</strong> <em>(disclaimer: may contain unintentionally confusing, inaccurate and/or amusing transcription errors)</em><strong><br></strong></p><div><p>David: Hello, Acquired LPs. We are coming at you today with a very special episode with Garry Tan of Initialized Fame and before that‚ÄîY Combinator, Posterous, and has a long and very illustrious career here in Silicon Valley. We are going to talk about the evolution of early-stage investing.</p><p>Garry has seen it all. I think he started back in the early days when early-stage investing meant a $2 million Series A at a $5 million poster. Maybe that was even high. </p><p>Garry: Yeah, it‚Äôs a while.</p><p>David: Goodness, things have changed. I'm so excited to have you here. Thanks for joining us and we can't wait to dive in.</p><p>Garry: Yeah, thank you for having me. Big fan of the show and it means a lot to me that you'd have me.</p><p>David: Likewise that you would come on. Let's just dive right in. We're going to weave in the story of Initialized along the way, but we thought maybe we'd start way back in those prehistoric days of what life is like?</p><p>Garry: So, Arthur Rock.</p><p>David: We've already done that on the Sequoia episodes. Not that far back but when was it that you started Posterous? Was it in 2005?</p><p>Garry: It was 2008, actually. </p><p>David: It was 2008. It‚Äôs later than I thought.</p><p>Garry: 2005 I was still at Palantir, so I had just designed the logo for Palantir and built one of the major product teams. Before that, I was Stanford Computer Engineering, and the crazy story for me is that friends of mine were starting a company. And I was the lowest of the low PM at Microsoft.</p><p>Ben: What that‚Äôs like?</p><p>Garry: Great place to start, great reach. Friends of mine were starting a company with Peter Thiel. They flew me down to San Francisco to have dinner with Peter right when he wrote the $500,000 check to Facebook. He said, ‚ÄúGarry, what are you doing at Microsoft? You're wasting your time.‚Äù I said, ‚ÄúI wanted to work at a startup, but they weren't startups in 2003, 2004.‚Äù</p><p>He said, ‚ÄúI'm so sure this is the right thing. You need to quit your job.‚Äù He asked me how much a year I made. I told him it was $70,000. He said, ‚ÄúWell, how about this? I'll write you a personal check from my bank account to yours. This is your risk opportunity. Quit your job.‚Äù I said, ‚ÄúThank you very much, Mr. Thiel, but I might make it to level 60 next year,‚Äù and I got on a plane and went back to Seattle. That company turned into Palantir. </p><p>David: Oh my gosh.</p><p>Garry: I ended up joining a year later, they had hired away some of my closest friends who were way smarter than me. Bob McGrew, who now runs stuff over at OpenAI. Just so many smart people you get to meet in Silicon Valley over time. Once they hired away people smarter than, I was like, I need to quit my job at Microsoft. At the moment, when your friends are starting a business and you don't know anything about startups, tech, or how these things are funded. You say, well, I have a real job, and you say no.</p><p>David: We're talking about this with Kevin and Julia Hartz on the Eventbrite episode. I imagine you're right out of college. Your parents were probably (if you even told them about this) like, no way would they let you do this.</p><p>Garry: They‚Äôre like don‚Äôt do it. That seems unsafe. Yeah. The immigrant mentality for sure.</p><p>Ben: Garry, that's an amazing story, and it is absolutely one of survivorship bias because I want to share my story. I had a friend who was starting a YC Company. I had just moved to Seattle, and I was about to start my job at Microsoft. This friend lobbied and lobbied and lobbied. They‚Äôd come and get me to co-found the company with them.</p><p>For years, it looked like a huge mistake that I said, are you kidding me? I'd have to give back my signing bonus. I just moved here. This person told me something very similar that they would help definitely pay back the signing bonus. [...] your risk thing, they‚Äôd pay for my move. But as years have gone by, that company sold for exactly the preference. It would have been completely awash.</p><p>Garry: Yeah. That's tough.</p><p>Ben: For a while I was like, wow, that's one of several examples in my life where I really blew it on joining something early. Sometimes, not that my choice was the right choice, but unless it's Peter Thiel calling, the story doesn't always end the way you‚Äôre‚Äî</p><p>Garry: Yeah. These things are crazy risky. I often think about, wow, he was willing to pay that much upfront for an engineer. The rest of my career‚Äîeven as an investor today‚Äîis now actually the inversion of that. Which is now I realize actually, it's the software engineers, designers, product people, and the builders who create the future. That's why we're able to do early-stage at all is that we look a lot more like them at that stage and so they'll pick us.</p><p>On the flip side, because I can still code a little bit and I still do design. I'm probably better at marketing now than I was 10 years ago.</p><p>David: You've diversified your skillset.</p><p>Garry: Yeah. That's right. We look more like them. Then that's the cool thing. I think that fits with the overall series. It's like we're talking about the traitorous eight‚Äîsending real typewritten letters across the country to financiers who were totally different from them. Now, what we're talking about‚Äîwhat you guys do and what we're doing‚Äîis we're no different. I think that time was for venture capitalists to say we're set apart, we're different.</p><p>David: We're in this ivory tower.</p><p>Garry: Yeah. The ivory tower is different. There's actually a ritualistic aspect that I was talking with Geoff Lewis at Bedrock. He has this theory that is really interesting. There is something to be said for I'm walking up the steps of Sequoia, this is what legends before me did, and I can be a part of that.</p><p>Now it's Zoom. If anything, now it's flipped. Now it's about the one on one conversation that you can have right here. That's why you have the rise of influencer investing. I know, we'll talk about it later, but that's part of the reason why I think YouTube is so important, for me anyway. I'm investing very deeply into it because I think it's a very interesting innovation in the course of how ventures are created.</p><p>David: VCs historically take a long time to catch on. YouTube was founded right around this time that we're talking about, and here we are in 2020 and people only just were starting to catch on.</p><p>Garry: 2005, yeah.</p><p>Ben: Garry, you talked about your time as a builder, and we're going to put a pin in this influencer investing and definitely come back to it because I think it'll be a nice way to round out the full story. Take us through founding Posterous, leaving Palantir, how you raised money for that, and how you went about getting enough proof that there's a there, there to invest more of your time.</p><p>Garry: There's nothing quite like seeing a super early-stage startup for your own eyes. Actually, I've always been really thankful for my time working with Stephen Cohen, Joe Lonsdale, and Alex Karp‚Äîjust the founders of Palantir. Being able to build software from scratch. The more subtle interesting thing that I feel like I learned was how important it is to basically continue to hire people way smarter than you actually.</p><p>The cult making and the mythmaking of the startup very early are really underplayed. I don't feel like people talk about it enough, and Palantir, I think remains very good at it. The only cult that was stronger than our cult was the Facebook cult (I think). But it's interesting to see. Years later, that's an order of magnitude bigger as a company, which is fascinating to me. I think that actually is directly proportional. How strong your cult will result in how big your company ends up being.</p><p>Assuming you're in the right market and 10 other things that you need to survive. You need to be one of those survivors. A lot of things have to break your way.</p><p>Ben: What's an example of something that was done at Palantir to help build that cult brand?</p><p>Garry: Honestly, I think the simplest thing was even just trying to get the smartest, most capable, and hardworking people, which sounds really stupid simple. It seems like everyone should do that, but honestly, people just don't. When you think about hiring, the mistake that a lot of founders make‚Äîand honestly, I made this mistake at some level too when I worked on Posterous‚Äîwas who can I get? And that's the wrong question.</p><p>You should start with who is the smartest person I know, and it doesn't matter where they're at. Because if I get them, then our self-fulfilling prophecy becomes destiny. If I don't, then it doesn't. I'm not doing myself or them a favor by not going after them. We would just go. </p><p>People would pass out yellow legal pads, and we would force everyone to step away from their computers, and it'd be like, write down the names of 20 people who were the smartest people you've ever met in any walk of life. It didn't have to be engineering, design, or whatever. It was just, who are the smartest people you know in your life. We take it into a backroom and cross-reference it and then those are like our hit list. It's like let's go get those people. We're going to take them to dinner, we're going to take them to lunch, we're going to meet them, we're going to chop down the tree, and we're going to go get them.</p><p>David: That mindset leads to doing things like what Peter offered to you. I can't believe I've never thought of that before. Yeah, you were ungettable. You were at Microsoft, but what if you just offered to personally cover the gap in your salary? It didn't work for you then, but a certain number of people, that's going to work with. And if you're not in that mindset of okay, I don't even go to try to get this person. Well then, you don't know, but once you're like, no, I'm going to try and get them. Well, what can I do?</p><p>Garry: Yeah. It just compounds from there because smart people want to work with smart people. I think that is testament and credit to what they've been able to build over the years. That becomes a self-fulfilling ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.acquired.fm/episodes/how-yc-rewrote-the-seed-playbook-with-garry-tan-hn">https://www.acquired.fm/episodes/how-yc-rewrote-the-seed-playbook-with-garry-tan-hn</a></em></p>]]>
            </description>
            <link>https://www.acquired.fm/episodes/how-yc-rewrote-the-seed-playbook-with-garry-tan-hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24639871</guid>
            <pubDate>Wed, 30 Sep 2020 15:37:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ideas from My Development Setup: Always Tmux]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24639599">thread link</a>) | @ceda_ei
<br/>
September 30, 2020 | https://cedaei.com/posts/ideas-from-my-dev-setup-always-tmux/ | <a href="https://web.archive.org/web/*/https://cedaei.com/posts/ideas-from-my-dev-setup-always-tmux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>Back when I first learnt tmux, I realized it was a really valuable tool. Soon
afterwards, I found myself in need of wanting to make a split only to find out
I wasn‚Äôt in tmux. This would lead to:</p>
<ul>
<li>Killing the running process.</li>
<li>Starting tmux.</li>
<li>Restarting the previous process.</li>
</ul>
<p>In pursuit of an ideal solution, I added a tiny script in my scripts directory
which was called by my bashrc.</p>
<h2 id="current-workflow">Current Workflow<a href="#current-workflow" arialabel="Anchor">‚åó</a> </h2>
<p>My current workflow simply starts by opening the terminal. Instead of the bash
prompt, I am greeted by this.</p>
<pre><code>Choose the terminal to attach:
1 - 12: 3 windows (created Wed Sep 30 14:26:37 2020) (attached)
2 - tana: 3 windows (created Wed Sep 30 18:17:24 2020) (attached)
3 - userbot: 1 windows (created Tue Sep 29 18:37:19 2020)
4 - ytc: 1 windows (created Tue Sep 29 18:37:19 2020)

Create a new session by entering a name for it
</code></pre><p>At this point, I either</p>
<ul>
<li>enter a number (in this case from 1 to 4) to connect to an existing session.</li>
<li>enter a name to create a named tmux session.</li>
<li>hit enter (or C-D) to create an unnamed session (tmux will name it
sequentially).</li>
<li>type nil and hit enter to drop to shell without starting tmux</li>
</ul>
<h2 id="implementation">Implementation<a href="#implementation" arialabel="Anchor">‚åó</a> </h2>
<p>In my <code>.bashrc</code>, live these lines.</p>
<div><pre><code data-lang="bash"><span>if</span> <span>[[</span> ! -v TMUX <span>&amp;&amp;</span> $TERM_PROGRAM !<span>=</span> <span>"vscode"</span> <span>]]</span>; <span>then</span>
	tmux_chooser <span>&amp;&amp;</span> exit
<span>fi</span>
</code></pre></div><p>Although I use vim as my sole editor, I needed to demo something in VSCode and
for that case I have added an exception so that the script does not run the
<code>tmux_chooser</code> in VSCode‚Äôs integrated terminal.</p>
<p>Here is the source of <code>tmux_chooser</code> called above.</p>
<div><pre><code data-lang="bash"><span>#!/usr/bin/bash
</span><span></span><span># shellcheck disable=SC2207</span>

<span># Doesn't let you press Ctrl-C</span>
<span>function</span> ctrl_c<span>()</span> <span>{</span>
	echo -e <span>"\renter nil to drop to normal prompt"</span>
<span>}</span>

trap ctrl_c SIGINT

no_of_terminals<span>=</span><span>$(</span>tmux list-sessions | wc -l<span>)</span>
IFS<span>=</span><span>$'\n'</span>
output<span>=(</span><span>$(</span>tmux list-sessions<span>)</span><span>)</span>
output_names<span>=(</span><span>$(</span>tmux list-sessions -F<span>\#</span>S<span>)</span><span>)</span>
k<span>=</span><span>1</span>
echo <span>"Choose the terminal to attach: "</span>
<span>for</span> i in <span>"</span><span>${</span>output[@]<span>}</span><span>"</span>; <span>do</span>
	echo <span>"</span>$k<span> - </span>$i<span>"</span>
	<span>((</span>k++<span>))</span>
<span>done</span>
echo
echo <span>"Create a new session by entering a name for it"</span>
read -r input
<span>if</span> <span>[[</span> $input <span>==</span> <span>""</span> <span>]]</span>; <span>then</span>
	tmux new-session
<span>elif</span> <span>[[</span> $input <span>==</span> <span>'nil'</span> <span>]]</span>; <span>then</span>
	exit <span>1</span>
<span>elif</span> <span>[[</span> $input <span>=</span>~ ^<span>[</span>0-9<span>]</span>+$ <span>]]</span> <span>&amp;&amp;</span> <span>[[</span> $input -le $no_of_terminals <span>]]</span>; <span>then</span>
	terminal_name<span>=</span><span>"</span><span>${</span>output_names[input - 1]<span>}</span><span>"</span>
	tmux attach -t <span>"</span>$terminal_name<span>"</span>
<span>else</span>
	tmux new-session -s <span>"</span>$input<span>"</span>
<span>fi</span>
exit <span>0</span>
</code></pre></div>
      </div></div></div>]]>
            </description>
            <link>https://cedaei.com/posts/ideas-from-my-dev-setup-always-tmux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24639599</guid>
            <pubDate>Wed, 30 Sep 2020 15:16:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Beginner's Guide to Arguing Constructively]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24639504">thread link</a>) | @liamrosen
<br/>
September 30, 2020 | http://liamrosen.com/arguments.html | <a href="https://web.archive.org/web/*/http://liamrosen.com/arguments.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<div><p><span>First published September 2020</span></p><p>

<em>Questions? Suggestions? E-mail me:</em>&nbsp;<img alt="" height="22" src="http://liamrosen.com/liamrosen.png" title="" width="164"></p></div>

<h2>CONTENTS</h2>

<p><a href="#intro">PART I: INTRO</a><br>
<a href="#mindset">PART II: MINDSET</a><br>
<a href="#prework">PART III: PRE-WORK</a><br>
<a href="#debatebreakdown">PART IV: BREAKING DOWN A DEBATE</a><br>
<a href="#strategies">PART V: STRATEGIES</a><br>
<a href="#tips">PART VI: TIPS</a><br>
<a href="#thanks">PART VII: CONCLUSION</a></p>

<h2><a id="intro" name="intro">INTRO</a></h2>

<p>The vast majority of people on earth argue in a <em>destructive </em>fashion. Debates, especially in online spaces, are viewed as a battle of the wits in which egos are put on display and there can be only one "winner".</p>

<p>Instead, we should be arguing in a <em>constructive </em>fashion: treating arguments as an opportunity to expand knowledge, finding points of disagreement, and collaborating towards a common truth.</p>

<p>I have a confession to make: I used to be a destructive arguer. When I was younger, my goal in any argument was not to learn something new, but rather to assure my superiority over what I felt to be the clear stupidity of the other side. I even used to save screenshots of debates I had on various forums and social media platforms, returning periodically to reminisce about past skirmishes in which I "<a href="https://knowyourmeme.com/memes/trigger-the-libs">owned the conservatives</a>".</p>

<p>Luckily, several years spent abroad gave me a different perspective. I realized that in the small-sided debates I used to engage in back home, my positions lacked the nuance and context of the greater world. For the first time, I began to do deep research on how to think ‚Äî and argue ‚Äî &nbsp;more clearly, drawing from concepts from philosophy, psychology, and behavioral economics.</p>

<p>This widened outlook led me to see arguments as a chance to build value, rather than destroy it. Instead of going through the mental anguish of battle, I now follow a collaborative approach to debate that I'd like to share in this guide in hopes that it will inspire others to argue more constructively.</p>

<p>Note that the content in this guide will focus on arguments about public issues, like politics and religion, as opposed to personal issues, like "you need to communicate more" or "you haven't done the dishes in weeks". Though there is overlap between the two, interpersonal arguments are much more complex and require more nuance than this guide can provide, plus there are already a ton of great resources out there that explore these topics more thoroughly.</p>

<h2><a id="mindset" name="mindset">MINDSET</a></h2>

<blockquote>
<p><strong><span><em>&nbsp;"An argument should be a collaboration between two people to find the truth."</em></span></strong></p>
</blockquote>

<p>If I had to distill this guide down to one sentence, it would be the above. Even if you forget the individual tenets and strategies this guide has to offer, as long as you are treating any given argument as a collaboration in search of truth, you can't go wrong.</p>

<p>Arguing more effectively requires detaching yourself from the idea of "winning" in the traditional sense. Instead, you should declare victory when you have argued in good faith and kept an open mind.</p>

<p>True collaboration requires that both parties open an investigation into why they may be wrong and consider changing their beliefs. Which brings us to the three core tenets of a constructive debate mindset:</p>

<h3>Acknowledge You May Be Wrong, and Be Willing to Change Your Mind <a href="#Acknowledge You May Be Wrong, and Be Willing to Change Your Mind" id="Acknowledge You May Be Wrong, and Be Willing to Change Your Mind" name="Acknowledge You May Be Wrong, and Be Willing to Change Your Mind"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>Was there ever a time in which you had a deeply-held belief about something, but slowly came to realize that you were wrong? Maybe you thought a past partner was "the one", or you were devoted to a religious faith. Or perhaps something as simple as believing in Santa Claus.</p>

<p>What's to say that couldn't happen with the rest of your deeply-held beliefs, given enough evidence?</p>

<p>Go into every debate with the mindset that you may not know everything about the topic at hand, and in fact <em>may be wrong</em>.</p>

<p>If you successfully acknowledge that you may be wrong, it follows that you must then be willing to change your mind. Having the humility to admit that your mind has been changed is one of the most honorable positions in a good faith debate.</p>

<h3>Arguments Are Not Soldiers <a href="#Arguments Are Not Soldiers" id="Arguments Are Not Soldiers" name="Arguments Are Not Soldiers"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>In a war, all soldiers take an oath to fight for their own side, no matter what amount they agree with its principles. <a href="https://www.lesswrong.com/posts/9weLK2AJ9JEt2Tt8f/politics-is-the-mind-killer">Eliezer Yudkowsky once observed</a> that in political debates, arguments were treated like soldiers: "<em>Once you know which side you're on, you must support all arguments of that side, and attack all arguments that appear to favor the enemy side; otherwise it's like stabbing your soldiers in the back.</em>"</p>

<p>Because most people go into debate with a war-like mentality, they feel they must fly the flag for all points that <em>their</em><em> side</em> supports, regardless of how much they actually agree with them.</p>

<p>The red state gun-owner must be pro-religion, anti-abortion, anti-drugs, anti-tax, and skeptical of gender issues.</p>

<p>The blue state Subaru-owner must be anti-religion, pro-abortion, pro-drugs, pro-tax(ing-the-rich), and concerned about gender issues.</p>

<p>Most annoying is that given the societal expectations for this divide, being for or against one issue immediately assigns you to a "side" in the views of everyone involved. Breaking out of this Arguments as Soldiers mindset involves two steps:</p>

<p>1. Do not be afraid to agree with the arguments of the other side when they strike you as reasonable, and critique the arguments of your own side when they strike you as unreasonable (better yet, try not to have a side).</p>

<p>2. On the flip side, avoid stereotyping your debate partner based on one opinion. If you are engaging with someone in debate for the first time, assume that they agree with you on every other position than the one they are defending, until proven otherwise.</p>

<h3>There's Always Someone Who Thinks the Jedi Are Evil <a href="#There's Always Someone Who Thinks the Jedi Are Evil" id="There's Always Someone Who Thinks the Jedi Are Evil" name="There's Always Someone Who Thinks the Jedi Are Evil"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p><em>Brace yourself, Star Wars references incoming:</em></p>

<p>In a given debate, almost everyone thinks they are a member of the Jedi order, fighting for all that is virtuous and good in the universe. Yet for every Jedi, there's a Sith out there <a href="http://www.youtube.com/watch?v=llLKar19XhA">who thinks that the Jedi are evil</a> and wrong and that <em>they</em> are actually the ones fighting for virtue and good. Remember that this person might even be <em>you</em>.</p>

<p>Of course, you are not a full agent of good, and your debate partner is not an agent of evil, or vice versa. You are simply citizens of the galaxy who happen to be operating with different sets of information. Look at the situation from a different perspective: if you were raised with Sith beliefs from childhood, don't you think you might believe the exact same things a Sith would?</p>

<p>In debate, your goal should not be to <a href="https://www.youtube.com/watch?v=rMNKwZTv1d0">strike down the side of evil with all your hatred</a>, but rather work together with them to uncover the true facts about the universe, and in doing so perhaps change both your perspectives.</p>

<h2><a id="mindset" name="prework">PRE-WORK</a></h2>

<p>It would be great if choosing to pursue the path of arguing constructively was just a matter of changing your mindset overnight, but as Carl Sagan once said: <a href="https://youtu.be/BkHCO8f2TWs?t=9">"If you wish to bake an apple pie from scratch, you must first invent the universe."</a></p>

<p>In the same vein, if you wish to improve the constructiveness of the debates you engage in, you must first spend time re-inventing your entire mind.</p>

<p>This is because our mind is constantly working against us, plagued by ancient errors from the times in which we lived in caves and hunted woolly mammoths. These errors work against us in the form of cognitive biases and logical fallacies, which hinder our ability to clearly see reality and engage in sound debate.</p>

<h3>Recognize and Avoid Cognitive Biases <a href="#Recognize and Avoid Cognitive Biases" id="Recognize and Avoid Cognitive Biases" name="Recognize and Avoid Cognitive Biases"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>Cognitive biases are limits and mistakes in human judgement that prevent someone from acting rationally. They are present in every aspect of human life, and in tense situations like arguments, they tend to appear more often as emotions are heightened and the brain gets overloaded.</p>

<p>Common examples that relate to debates are <em>confirmation bias</em>, or the tendency of humans to seek out information that confirms existing beliefs, and <em>ingroup bias</em>, or the tendency to agree more strongly with people that appear to be part of our "tribe", but there are over 100 identified biases, and it's worth reading through the Wikipedia article on the <a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases">most common cognitive biases</a> so you can recognize when they might be clouding your thinking.</p>

<h3>Recognize and Avoid Logical Fallacies <a href="#Recognize and Avoid Logical Fallacies" id="Recognize and Avoid Logical Fallacies" name="Recognize and Avoid Logical Fallacies"><img alt="" src="http://liamrosen.com/anchor.png"></a></h3>

<p>In part caused by cognitive biases, logical fallacies are errors in argument that give off an air of decisiveness, despite making points that don't hold up to logical scrutiny. While these are often used unintentionally, due to bias, carelessness, or ignorance, unfortunately, they can also be wielded intentionally by a shrewd debate partner.</p>

<p>Common examples in debate include the <em>false dilemma fallacy</em>: "you're either with us or against us", and the <em>slippery slope fallacy</em>: "if we allow the gays to marry, what's next: plants?" Just like cognitive biases, there are a large number of identified logical fallacies, and it's worth it to review the <a href="https://en.wikipedia.org/wiki/List_of_fallacies">entire list</a>, so you can spot them in your own arguments and in those of others.</p>

<h2><a id="debatebreakdown" name="debatebreakdown">BREAKING DOWN A DEBATE</a></h2>

<p>To the untrained eye, a debate might look like two or more parties trading argumentative points back and forth. But interestingly, these points can almost perfectly be classified into a few categories. Understanding these categories, and why some types of arguments are better than others, is crucial for learning how we and those whom we engage with in debate might shape their points. In a brilliant post called <em><a href="https://slatestarcodex.com/2018/05/08/varieties-of-argumentative-experience/">Varieties of Argumentative Experience</a></em>, Scott Alexander does just this, illuminating and labeling practically every part of a debate. The post itself is basically required reading, but is long-ish<em>,</em> so I will summarize here.</p>

<p>Think of a debate as a pyramid: <a href="#debatepyramid" id="debatepyramid" name="debatepyramid"><img alt="" src="http://liamrosen.com/anchor.png"></a></p>

<p><img alt="" height="548" src="http://liamrosen.com/Pyramid%20of%20Argumentative%20Experience.svg" width="978"></p>

<p>In general, the lower on the pyramid you are, the worse debate you're having. The goal should be to start as high as possible and continue to work your way towards the top.</p>

<p>Debates on twitter and other forms of social media are almost guaranteed to never rise above the lower dotted line, as these platform don't allow for more nuanced debate. Everything above the higher dotted line is our gold standard: two intelligent, charitable, and versed debaters can successfully maintain a debate at this level until some form of resolution.</p>

<p>The blue side represents the discussion ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://liamrosen.com/arguments.html">http://liamrosen.com/arguments.html</a></em></p>]]>
            </description>
            <link>http://liamrosen.com/arguments.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24639504</guid>
            <pubDate>Wed, 30 Sep 2020 15:08:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Skill Stacking]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24639304">thread link</a>) | @mcrittenden
<br/>
September 30, 2020 | https://critter.blog/2020/09/30/skill-stacking/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/09/30/skill-stacking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-825">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Scott Adams, the creator of Dilbert, <a href="https://dilbertblog.typepad.com/the_dilbert_blog/2007/07/career-advice.html">wrote</a> about how to reach the top:</p>



<blockquote><p>If you want something extraordinary, you have two paths:</p><p>1. Become the best at one specific thing.<br>2. Become good (top 25%) at two or more things.</p><cite>Scott Adams (<a href="https://dilbertblog.typepad.com/the_dilbert_blog/2007/07/career-advice.html">source</a>)</cite></blockquote>



<p>Number one, he says, is as good as impossible but number two is easy. </p>



<p>It‚Äôs called <strong>Skill Stacking</strong>. I went down the rabbit hole and found <a href="https://forge.medium.com/how-to-become-the-best-in-the-world-at-something-f1b658f93428">this excellent post</a> with this image:</p>



<figure><img data-attachment-id="1710" data-permalink="https://critter.blog/stackiing/" data-orig-file="https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png" data-orig-size="1400,787" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="stackiing" data-image-description="" data-medium-file="https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=300" data-large-file="https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=580" src="https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=1024" alt="" srcset="https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=1024 1024w, https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=150 150w, https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=300 300w, https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png?w=768 768w, https://mikecrittendenhome.files.wordpress.com/2020/09/stackiing.png 1400w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>See that little fella in the middle there? That‚Äôs the sweet spot. </p>



<p>I will never be the best in the world at running or programming or writing or agile process. But I can be in the top 25% of each. If I can find a way to combine two or more of them, then I can be the best at that combination. </p>



<p>I could build an audiobook reader app specifically for runners. I could create a niche blog for programmers who run. I could apply for Strava‚Äôs engineering team. I could write a book on how to apply agile principles to running. </p>



<p>Here‚Äôs another example, plucked from a random Hacker News comment:</p>



<blockquote><p>I learned this lesson from Clifford Stoll. He said that astronomers figure he must be an exceptional programmer, since he‚Äôs clearly a mediocre astronomer. While programmers figure he must be an exceptional astronomer, since his programming is strictly middle-of-the-road!</p><cite><a href="https://news.ycombinator.com/item?id=24263882">samatman on HN</a></cite></blockquote>



<p>Of course, there are different types of skills. You‚Äôll have trouble combining some skills, but others are universal. Public speaking, writing, marketing, programming, charisma; these can stack with almost anything. Scott Adams says this about public speaking:</p>



<blockquote><p>I always advise young people to become good public speakers (top 25%). Anyone can do it with practice. If you add that talent to any other, suddenly you‚Äôre the boss of the people who have only one skill.</p><cite>Scott Adams</cite></blockquote>



<p>It‚Äôs a fun thought experiment. List the things you‚Äôre pretty good at, and brainstorm ways to combine 2 or more of them. What do you come up with?</p>



		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/09/30/skill-stacking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24639304</guid>
            <pubDate>Wed, 30 Sep 2020 14:52:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Coinbase post was 100% right. Here's what you can do about it]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24638995">thread link</a>) | @ihm
<br/>
September 30, 2020 | https://parametricity.com/posts/2020-power/ | <a href="https://web.archive.org/web/*/https://parametricity.com/posts/2020-power/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>Recently there was a minor controversy over a blogpost from Coinbase‚Äôs <a href="https://blog.coinbase.com/coinbase-is-a-mission-focused-company-af882df8804">CEO</a>
discouraging employees from thinking about politics, and encouraging them to focus on profit-making.
I really appreciated this post, because I think it can be very clarifying for those employees who think their
company can be a pure force for good. The Coinbase blogpost gives the honest truth that in the final calculus,
corporations whose primary goal is profit-maximization can only incidentally and in small ways advance any other
aim.</p>
<p>At the same time, there is a lot of promise for good in the actual technology underlying the crypto industry. This post will argue</p>
<ol>
<li><strong>If work is organized through for-profit corporations, there will be strong pressure from management and capital to
distort positive aspects of the technology in favor of profit-making</strong></li>
<li>The <strong>naive utopianism</strong> which has sustained the industry so far and helped produce some good technology <strong>is no match for this pressure</strong></li>
<li><strong>The only realistic way to combat this</strong> distorting pressure and focus on the socially-beneficial aspects of the technology <strong>is for workers</strong>
(the other human factor of production apart from management and capitalists) <strong>to use their collective power to push back</strong>.</li>
</ol>
<p>This argument is not surprisingly somewhat controversial among executives and VCs, but happily that same group loves
free speech and hates cancel-culture, so I assume I will not be attacked for expressing it.</p>
<h2 id="what-is-the-web-and-what-should-it-be">What is the web and what should it be?</h2>
<p>What should the web be? It should be a medium for personal communication, organization for people in projects, art and creative expression, etc. that is oriented around the goals of individual and collective flourishing. That would be ideal.</p>
<p>In reality, it is not operated that way. It ‚Äì like almost everything in our society ‚Äì is operated as a profit-extraction machine in the service of a small group of people.
This machine started off performing the above functions (of course, already distorted by its origins as a technology for the military and academia).
Soon, an industry of for-profit companies sprung up around developing the internet. Many of these companies became large enough to have a decisive influence on what the web would be.</p>
<p>As the years went by, the parts of it that did not contribute much to profit generation (like weird personal websites) were scrapped under the influence of these companies,
and new pieces which enhanced profit generation were added. It happened this way because there is enormous pressure from management and investors to focus on profit-generation
to the exclusion of all else.</p>
<p>Of course, because these modifications were made primarily in pursuit of profit with other reasons being secondary, this resulted in a bunch of unintended (or un-‚Äúcared about‚Äù) negative consequences like</p>
<ul>
<li>creepy data-collection and surveillance which is used to manipulate us into buying things</li>
<li>right-wing radicalization which has resulted in widespread political violence</li>
<li>distribution of misinformation</li>
<li>an enormous carbon footprint</li>
<li>collective billions in wasted minutes spent scrolling because we were tricked by the algorithm to stay on just a bit longer</li>
</ul>
<p>All of these things are natural results of a system that cannot ‚Äúsee‚Äù the concept of social good and can only see profits.
These problems just do not matter to the system, and only could in the event that they interfered with profit-generation.</p>
<h2 id="how-to-push-back">How to push back</h2>
<p>Let‚Äôs say you are a worker at a crypto company who sees this history and want to make sure that in crypto, socially useful aspects of
the technology are prioritized rather than those that make the most profit. What should you do?</p>
<p>First, I think it is necessary to deal with the most popular response, which is a utopian faith that the decentralized
nature of some crypto technology will inherently stop bad things from happening.</p>
<h3 id="crypto-utopianism">Crypto-utopianism</h3>
<p>There‚Äôs a lot of utopianism in crypto. This ranges from the lowest Bitcoin-booster all the way up to people like Vitalik.</p>
<p>This quote is somewhat <a href="https://www.coindesk.com/this-political-conversation-with-vitalik-buterin-shows-how-ethereum-could-change-the-world">examplary</a>:</p>
<blockquote>
<p>These three white men talked about the protests erupting across the United States. To his credit, the Russian-Canadian Buterin spoke broadly instead of attempting to comment on inequality in American politics. He said the current generation is facing a global ‚Äúcrisis of legitimacy,‚Äù concerning both corporations and ‚Äúmany types of governments.‚Äù</p>
</blockquote>
<blockquote>
<p>‚ÄúThe challenge here is can we create systems that allow some groups of people to cooperate without that downside of a centralized or trusted actor having to be in the middle,‚Äù Buterin said.</p>
</blockquote>
<p>Crypto-utopianism usually includes a suggestion that crypto will replace existing systems (which are bad because they‚Äôre ‚Äúcentralized‚Äù or some other vague reason) and be better because they are ‚Äúdecentralized‚Äù (whatever that might mean).</p>
<p>These analyses give crypto projects a sense of grandeur and importance which is motivating to developers and investors alike. Unfortunately, if your goal is to push back against the existing profit-maximizing power structures, you need to have a better analysis than ‚Äúcentralized bad, decentralized good‚Äù. It sounds good, but it doesn‚Äôt actually constitute a plan to defeat the Facebooks of the world or even to resist pressure from investors.</p>
<p>The crypto-utopian prescription for all that ails the web is some new technology.
Technology is great and a necessary part of the puzzle, but unless Glenn Weyl has a way of forcing Facebook to use quadratic voting for corporate governance, it‚Äôs not useful yet.
<strong>The existing power structure can always pick-and-choose the new technology that best advances its goals.</strong>
If you have goals which are distinct from theirs, you need to build power that is capable of a serious challenge.</p>
<h3 id="what-kind-of-power-do-they-have">What kind of power do they have?</h3>
<p>What kind of power does the existing ‚Äúpower structure‚Äù consisting of senior management and capitalists have?
It has</p>
<ul>
<li><a href="https://www.theverge.com/2019/11/25/20983053/google-fires-four-employees-memo-rebecca-rivers-laurence-berland-union-busting-accusation-walkout">the ability to fire people</a> that won‚Äôt comply with its goals</li>
<li>the ability to withhold funding from companies that won‚Äôt comply with its goals (this is kind of another version of the previous)</li>
<li><a href="https://parametricity.com/posts/2020-power/news.ycombinator.com">public platforms</a> to spread <a href="https://blog.coinbase.com/coinbase-is-a-mission-focused-company-af882df8804">messaging that argues in favor of its goals</a></li>
<li>control of platforms which allows them to <a href="https://itsgoingdown.org/on-facebook-banning-anarchist-and-antifascist-pages-the-digital-censorship-to-come/">censor unfavorable currents in the culture at large</a></li>
<li>endless legal resources to neutralize those that won‚Äôt comply with its goals</li>
<li>in some cases, relationships with law enforcement that can be used against those that won‚Äôt comply with its goals
and surely much more.</li>
</ul>
<p>Profit-maximization is the ‚Äúprime directive‚Äù of the existing power structure and as a result challenging it inevitably provokes a fight.
This fight is usually waged (on their end) by making use of all the above tools and more.</p>
<h3 id="what-kind-of-power-do-you-have">What kind of power do you have?</h3>
<p>What kind of power do you, a worker at a crypto company, have to resist all of the above? On your own, basically none. If you
make too much trouble, you will simply be fired and then you‚Äôre out of luck. Some small number of people can try starting a company (which I have done)
but you‚Äôre still subject to some of the same kinds of retaliation as funding can be withheld, which either ‚Äúfires‚Äù the company or redirects
it toward whatever profit-maximization opportunity is available. And even if you have an independent revenue stream, you will be competing
against firms that are willing to do whatever it takes to maximize profits.</p>
<p>As a group however, workers have an enormous amount of power. It is sometimes considered controversial to say so, but VCs and senior
management cannot actually do anything without workers. As such, if workers organize together into a strong company or industry-wide union,
they can make demands of the existing power structure and refuse to participate in the production process (i.e., strike) if those demands are not met.
This power can be augmented with legal resources, platforms of their own, etc.</p>
<p>If you are interested in building power with your fellow workers to advance your own goals rather than those of the profit-maximizers,
both within your company and across your industry, I recommend reaching out to <a href="https://techworkerscoalition.org/">Tech Workers Coalition</a>
who can provide further guidance. You can also get in touch with or <a href="https://act.dsausa.org/donate/membership2020">join your local DSA</a> to
build your analysis, help push more broadly for a world beyond profit maximization, and get support.</p>

		</div></div>]]>
            </description>
            <link>https://parametricity.com/posts/2020-power/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24638995</guid>
            <pubDate>Wed, 30 Sep 2020 14:22:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: We just cracked the problem with sneaker drops and sold out]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24638290">thread link</a>) | @skorski
<br/>
September 30, 2020 | https://gothelist.com/initial-product-offering | <a href="https://web.archive.org/web/*/https://gothelist.com/initial-product-offering">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>
<p><img src="https://gothelist.com/media/wysiwyg/products.gif" alt="No Waitlist"></p><h2>No Waitlist.</h2>
<h4>Introducing Initial Product Offering</h4>
<p>Get immediate access and shop highly demanded, limited and hard-to-get products without VIP status, waiting list or queue via IPOs in THE LIST App.</p>

</div>
</div>
<div>
<div>
<p><img src="https://gothelist.com/media/wysiwyg/listed.png" alt="LISTED.">
</p>
<div>
<h2>LISTED.</h2>
<p>We skip the waitlist for you. <br>Highly covetable items, collections &amp; <br>rare, unique products are listed <br>daily at 9:30 AM EST NYC.</p>
</div>
</div>
</div>
<div>
<div>
<p><img src="https://gothelist.com/media/wysiwyg/includes.gif" alt="MUST-HAVES INCLUDED.">
</p>
<div>
<h2>MUST-HAVES <br>INCLUDED.</h2>
<p>THE LIST App offers you over 1,200 brands, <br>from established luxury brands <br>to the coolest, emerging designer labels.</p>
</div>
</div>
</div>
<div>
<div>
<h2>HOW DOES IT WORK<span>?</span></h2>
<div>
<h2>HOW DOES IT WORK<span>?</span></h2>
<h2>SHOP.</h2>
<p>Purchase a product during an IPO <br>for a limited time period <br>at dynamic market price <br>depending on how demanded <br>a product is. Better be fast!</p>
</div>
<p><img src="https://gothelist.com/media/wysiwyg/how-does-it-works.png" alt="HOW DOES IT WORK?">
</p>
</div>
</div>
<div>
<div>
<p><img src="https://gothelist.com/media/wysiwyg/pay1.png" alt="PAY.">
</p>
<div>
<h2>PAY.</h2>
<p>Secure your piece fast <br>within the price lockdown. <br>Only pay a deposit when placing the order, <br>and the remaining balance, <br>once the item is ready to ship.</p>
</div>
</div>
</div>
<div>
<div>
<div>
<h2>GET.</h2>
<p>Your order will be directly delivered <br>from the authorized retailer to you <br>via express shipping.</p>
</div>
<p><img src="https://gothelist.com/media/wysiwyg/get1.png" alt="GET.">
</p>
</div>
</div>
<div>
<div>
<h2>What are you waiting for<span>?</span></h2>

</div>
</div>
</div></div>]]>
            </description>
            <link>https://gothelist.com/initial-product-offering</link>
            <guid isPermaLink="false">hacker-news-small-sites-24638290</guid>
            <pubDate>Wed, 30 Sep 2020 13:01:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Revisiting a 'Smaller Rust']]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24638129">thread link</a>) | @gbrown_
<br/>
September 30, 2020 | https://without.boats/blog/revisiting-a-smaller-rust/ | <a href="https://web.archive.org/web/*/https://without.boats/blog/revisiting-a-smaller-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
			<p>A bit over a year ago, I wrote some <a href="https://without.boats/blog/notes-on-a-smaller-rust">notes on a ‚Äúsmaller Rust‚Äù</a> - a higher level language
that would take inspiration from some of Rust‚Äôs type system innovations, but would be simpler by
virtue of targeting a domain with less stringent requirements for user control and performance.
During my time of unemployment this year, I worked on sketching out what a language like that would
look like in a bit more detail. I wanted to write a bit about what new conclusions I‚Äôve come to
during that time.</p>
<h2 id="the-purpose-for-our-language">The purpose for our language</h2>
<p>Re-reading my previous post, I‚Äôm struck by how vague my statement of purpose for this language is.
My entire blog post is really focused on differentiating the language from <em>Rust</em>, and I frame the
discussion in terms of what I would remove from Rust, and how the language would not support certain
use cases of Rust. This isn‚Äôt really surprising: I was working on Rust, and I never had taken the
time to think of this hypothetical language in itself the way I have now.</p>
<p>The goal of this design was to create a language that could compete as an ‚Äúapplication programming
language.‚Äù The design goals of this language were:</p>
<ol>
<li>It should try not to be notably hard to learn. To the extent possible, it should be familiar to
most programmers. Since I‚Äôm comitting by the exercise to trying to apply ownership and borrowing
to the application domain, it will necessarily contain some features most programmers find
pretty novel (like Rust ‚Äúlifetimes‚Äù). But in general, we will try to reduce the onboarding ramp
and simplify things.</li>
<li>It should typecheck and compile quickly. It should not have bad batch compilation performance,
and it should be designed with incremental recompilation in mind, to enable a good experience for
users who integrate their compiler into their development environment (with a full IDE or even
just with a plugin for a text editor). I didn‚Äôt even mention this concern in the previous post.
As others have discussed elsewhere; Rust‚Äôs poor compile times are not the result of its advanced
type system, but of a combination of other factors. Some are essential, like the runtime
guarantees it makes (e.g. monomorphization) whereas others are accidental, like some aspects of
its module system. None of these factors would be essential for our language, so we would
carefully avoid these pitfalls.</li>
<li>It should have a runtime which suits it well to the major use cases for application programming
languages today. This means mainly being well suited to the developing for the web, both
front-end and back-end. (Being well-suited to the mobile platforms is unrealistic for a language
not sponsored by those platform developers, unfortunately.) Being well-suited to CLIs would also
be beneficial.</li>
</ol>
<p>I want to focus the rest of this post on my thoughts for evolving Rust‚Äôs ownership and borrowing
system, but before I do that I want to briefly touch on other design decisions that fell out of this
thought process:</p>
<ul>
<li>I would target WASM, and only WASM, for this language. WASM with reference types is suitable as
an environment for application programming (with shims for future extensions like properly
integrated garbage collection). This way the language designers can piggy back on the work being
done at many companies to establish WASM as a good shared VM platform, instead of being
responsible for things like platform compatibility or using the very slow LLVM. Targeting WASM
would also mean easier FFI integration into other languages that run on the same VM as WASM; that
is, other languages targeting WASM (like Rust) and JavaScript.</li>
<li>I would explore control-flow-capturing closures as a core language abstraction, similar to Kotlin.
As I wrote in <a href="https://without.boats/blog/the-problem-of-effects">an earlier blog post</a> inspired by the design on this hypothetical
language, I think these are a great way to integrate effects well with higher order function
abstractions.</li>
<li>I would provide syntactic sugar for <code>Result</code> and <code>Option</code> as the way to handle null and errors,
similar to Swift.</li>
<li>As I wrote in a previous blog post, I would provide green threads as the sole concurrency model,
with language or standard library provided channels and cells (discussed later) as the way of
sharing data between threads. How these green threads are mapped to CPUs is a matter for the
runtime you choose to run the compiled WASM in.</li>
<li>I didn‚Äôt get to the point of designing a polymorphism system; I would probably start with a
strenuous comparison of Rust‚Äôs traits and Go‚Äôs interfaces, and (knowing the other features of the
language) try to figure out what from Rust‚Äôs traits is unimportant.</li>
<li>I would be hope the language could avoid macros, which (in the case of pattern based macros) add a
second meta language to the language that advanced users need to understand, and in all cases
substantially complicate compilation.</li>
</ul>

<p>But now onto the meat of this post: the ownership and borrowing model. In my previous post I made
some points that I largely agree with still, but would probably reframe. Here‚Äôs what I wrote:</p>
<blockquote>
<p>Rust works because it enables users to write in an imperative programming style, which is the
mainstream style of programming that most users are familiar with, while avoiding to an impressive
degree the kinds of bugs that imperative programming is notorious for. As I said once, pure
functional programming is an ingenious trick to show you can code without mutation, but Rust is an
even cleverer trick to show you can just have mutation.</p>
<p>‚Ä¶</p>
<p><strong>Resource acquisition is initialization:</strong> Objects should manage conceptual resources like file
descriptors and sockets, and have destructors which clean up resource state when the object goes
out of scope. It should be trivial to be confident the destructor will run when the object goes
out of scope. This necesitates most of ownership, moving, and borrowing.</p>
<p><strong>Aliasable XOR mutable:</strong> The default should be that values can be mutated only if they are not
aliased, and there should be no way to introduce unsynchronized aliased mutation. However, the
language should support mutating values. The only way to get this is the rest of ownership and
borrowing, the distinction between borrows and mutable borrows and the aliasing rules between
them.</p>
<p>In other words, the core, commonly identified ‚Äúhard part‚Äù of Rust - ownership and borrowing - is
essentially applicable for any attempt to make checking the correctness of an imperative program
tractable. So trying to get rid of it would be missing the real insight of Rust, and not building
on the foundations Rust has laid out.</p>
</blockquote>
<p>I still think this is Rust‚Äôs ‚Äúsecret sauce‚Äù and it does mean what I said: the language would have to
have ownership and borrowing. But what I‚Äôve realized since is that there‚Äôs a very important
distinction between the cases in which users <em>want</em> these semantics and the cases where they largely
get in the way. This distinction is between types which represent <em>resources</em> and types which
represent <em>data</em>.</p>
<p>In this mental model, resources are types which represent ‚Äúa thing‚Äù - something with an identity and
a state which can change with time as the program executes. In Rust, almost everything is a
resource: a String is a resource a HashMap is a resource, most user types are resources. In
contrast, data types are just ‚Äúinformation‚Äù - a fact, which has no meaningful identity, contains no
state that evolves over time, etc. In Rust, types like integers, <code>&amp;str</code>, and so on - which all
implement <code>Copy</code> - are data types. (However, a mutable reference to those types is a resource: more
on this later.)</p>
<p>In Rust, only types which can be cloned by a mempcy can implement <code>Copy</code>. This is because Rust is
designed to encourage treating all heap memory as a <em>resource</em>, the management of which the end
user can control by selecting when the type representing that memory is dropped. This is very
valuable in the domains which Rust is intended to target. However, for higher level applications
that most programmers write, control over heap memory is not <em>usually</em> important. This is what users
mean when they want to ‚Äúturn off the borrow checker‚Äù - they want to let a garbage collector figure
it out for them when this bit of data is freed, because to them it is ‚Äújust data‚Äù and not a
resource.</p>
<p>This hypothetical language would lean into that distinction. Using persistent data structures (like
those from Clojure) and garbage collection, the set of types which could be treated as data types
would not be restricted in this language. The string type would be a data type, rather than
a resource; a dynamically sized array of data types would be a data type as well, as would a map
with keys and values that are data types.</p>
<p>Meanwhile, types representing IO objects would always be resource types. Collections containing
resource types would also be resource types. Composite types (like structs and enums) which contain
a resource type would also have to be a resource type. There would be an easy way to convert data
types to fully owned resource types as well; in the case of persistent data structures, converting
a data type to a resource type would be the point at which the ‚Äúcopy on write‚Äù operation occurs.
As a result users can use ownership semantics for things which impact global and external state
(like IO) and for cases where they know it will be an important performance optimization.</p>
<p>And the difference in how the language treats data and resources would be identical to the
difference between how Rust treats Copy and non-Copy types. Only resources would have affine
‚Äúownership‚Äù semantics - in which moving them invalidates the previous binding. Data types would have
the standard non-linear semantics users are familiar with from most languages. This means that
writing algorithms using data types would be functionally the same as writing algorithms in other
imperative languages, easing the onboarding of users to the language and limiting their errors
related to linear types to areas where they are certain to care.</p>
<h2 id="borrowing-and-the-two-reference-types">Borrowing and the two reference types</h2>
<p>The previous discussion covers the ground of ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://without.boats/blog/revisiting-a-smaller-rust/">https://without.boats/blog/revisiting-a-smaller-rust/</a></em></p>]]>
            </description>
            <link>https://without.boats/blog/revisiting-a-smaller-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24638129</guid>
            <pubDate>Wed, 30 Sep 2020 12:38:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Hidden Costs from a DevOps Perspective]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24637836">thread link</a>) | @gimmecoffee
<br/>
September 30, 2020 | https://pushbuildtestdeploy.com/on-hidden-costs-and-the-value-of-devops/ | <a href="https://web.archive.org/web/*/https://pushbuildtestdeploy.com/on-hidden-costs-and-the-value-of-devops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p><img src="https://pushbuildtestdeploy.com/images/hidden-cost-devops.png" alt=""></p>

<p>When you think about cost in the DevOps world, the first thing that will come to mind is your AWS bill, or maybe that Datadog subscription. However, the cost is not always as straightforward as receiving an invoice, and in the DevOps world, the hidden cost is about doing it wrong.</p>

<p>I believe that being aware of hidden costs is a ‚Äúmental model‚Äù you can use when making decisions. Without taking it to account, you are making bets with only half of the information.</p>

<p>Hidden cost takes on many forms in DevOps:</p>

<ul>
<li>Idle developers are waiting for builds to finish.</li>
<li>Over architected Jira workflows that take forever to go through - Jireaucracy (not my term).</li>
<li>Automating things that don‚Äôt need to scale - we are all lazy engineers who would rather spend a full day scripting something than doing 5 minutes of manual work.</li>
<li>Trying to save cost where there is no real benefit.</li>
<li>Higher Churn Rate.</li>
<li>Technical debt.</li>
</ul>

<p>Let‚Äôs try to take a close look at some of these examples.</p>

<h3 id="not-accounting-for-the-human-element">Not accounting for the human element</h3>

<p>In these complicated days, companies are franticly working to reduce their cloud costs. However, there‚Äôs a trap that you need to be mindful of when going through such a process.</p>

<p>Let‚Äôs look at this oversimplified equation.</p>

<blockquote>
<p><strong>$100</strong> <em>(hourly cost of a developer)</em> <strong>x</strong> <strong>10</strong> <em>(developers)</em> <strong>x</strong> <strong>2</strong> <em>(idle hours a day)</em> <strong>x</strong> <strong>21</strong> <em>(work days in a month)</em> <strong>=</strong> <strong>$42,000</strong></p>
</blockquote>

<p>If, on average, a developer at a company waits on builds or deployment for two hours per day and there are 10 developers on the team, that‚Äôs <strong>$2,000/</strong> per day going down the drain. Multiply by 21 workdays per month, and you get <strong>$42,000</strong> of wasted developer time.</p>

<p>Now, suppose that you can cut the idle time by half by adding two new build workers, where each one costs $3000/month. Is it worth it?
It seems trivial when you present it this way but harder to consider when cutting costs across the board.</p>

<p>The problem is that employees are a ‚Äúfixed cost‚Äù, a different budget, and you don‚Äôt think of them in the context of wasted resources.</p>

<p>Now think about that developer idling for two hours a day. An idle engineer is a bored engineer, which leads me to the next point -  chasing away competent engineers, or making it more challenging to attract new ones.</p>

<p>You spend significant resources to keep your top engineers, but then they will be the first to jump ship when work is just not fun.</p>

<p>Team leaders spend much of their time in the recruiting process when the company is growing. Time that could be used for onboarding new employees, or mentoring the team, or doing actual development work.</p>

<p>If it takes weeks for engineers to see their work in production or they spend their time chasing the DevOps team to get a simple thing running, they will not stay for long. And worse, you will start getting a bad reputation, resulting in fewer hiring options.</p>

<p>Add burnout to the mix, and now your top developers are producing less, which trickles down to more jr. engineers. You are now stuck with a disgruntled team and no new hires on the horizon.</p>

<h3 id="trying-to-automate-and-scale-at-all-cost">Trying to automate and scale at all cost</h3>

<p>Here is another example that I see all the time - A belief that everything has to be automated and scalable.</p>

<p>‚ÄúWrite this script to automate task XYZ, and don‚Äôt forget to document everything and make sure it‚Äôs IaC and write a confluence page and‚Ä¶‚Äù
But do you really need to automate it? How much time does this task take, and how many times are you planning to perform it?</p>

<p>If it‚Äôs an annoying task that takes an hour to perform, and you expect to repeat it three times in the future, does it justify a full week of an engineer to automate?</p>

<p>What about a deployment that is pretty much a one-off? Do you really need to automate it fully? Is it worth your time? Isn‚Äôt there something else that is more meaningful for you to do?</p>

<p>I mean, yes, we have standards and workflows and beliefs, but we don‚Äôt have to follow them blindly when it doesn‚Äôt make sense.</p>

<h3 id="technical-debt">Technical Debt</h3>

<p>Managers who brush off the importance of technical debt are a bit like people who never back up their system. They never saw how technical debt could cripple a company.</p>

<p>If you don‚Äôt account for the effects of technical debt, it‚Äôs hard to see the cost, but by looking closely, you will soon see how much it affects your velocity, churn, and pretty much every aspect of the value you deliver:</p>

<ol>
<li>It slows down your developers.</li>
<li>Each feature takes twice as much time to complete.</li>
<li>The system keeps crashing.</li>
<li>It burns out your team members.</li>
<li>It makes some business decisions impossible.</li>
</ol>

<p>Think about credit card debt. At one point, the interest rates will make you go bankrupt.
Yes, fixing some of the issues takes time and resources, but can you afford to continue rolling the snowball?</p>

<h2 id="opportunity-cost">Opportunity cost</h2>

<p>In a previous example, I referred to the cost ‚Äúas is,‚Äù using the developer‚Äôs direct hourly cost.  But unless you are a service business, a developer hour is worth much more than the cost.</p>

<p>This is why software companies are worth so much - The Developer‚Äôs time is a force multiplier. Developers are adding value to the company that is much higher than their yearly cost. The value they add takes the the form of IP and products that you can sell over and over without scaling inventory and distribution.</p>

<p>If we go back to the previous example, if you instead have the developers work on a new product or initiative with those hours, it‚Äôs not $42k per month that you are losing, but giving up a much higher future revenue.</p>

<p>And of course, opportunity cost can take on other forms that may not be as intuitive:</p>

<h3 id="milestone-investing">Milestone Investing</h3>

<p>Suppose that you are an early startup that has raised capital with set milestones (<a href="https://avc.com/2009/08/milestone-based-investing/">Milestone Investing</a>). By hitting the next milestone, you will increase your valuation and get a hefty cash infusion.
Now imagine your runway running out, and you have yet to meet the milestone.</p>

<p>Wouldn‚Äôt it be great if you had more time to reach your goals?</p>

<p>Suppose that your developers worked much more efficiently. Instead of idling for two hours, automating and simplifying your developers‚Äô workflow added an hour a day of ‚Äúworking in the zone‚Äù for each developer.</p>

<p>How much more could you accomplish by having three more hours a day per developer?</p>

<p>Could you meet that arbitrary board goal with an impossible deadline they set for you?</p>

<p>Is it going to help you meet the milestone the investors set for receiving the next cash infusion?</p>

<p>That‚Äôs where we, the DevOps engineers (or whatever you call this function at your company), can help move the needle. We can facilitate growth and improve the productivity of our engineering teams.
It‚Äôs not just about throwing new technology at the solution and implementing the latest fad.</p>

<h2 id="so-how-can-we-produce-value-as-devops-engineers">So how can we produce Value as DevOps engineers?</h2>

<p>DevOps has always been tied to business value, but it‚Äôs rare to see this idea fully implemented in corporate culture.
Even when it does, it‚Äôs usually wrapped around a vague user story with a soggy and generic statement that doesn‚Äôt make any sense.</p>

<blockquote>
<p><em>‚ÄúThis feature will increase user happiness and deliver more value by making the top navigation bar a bit more blueish.‚Äù</em></p>
</blockquote>

<p>One way to create value is by addressing the cost - by reversing it, we can generate value. All you need is to look at it from a different perspective.</p>

<p>I mentioned Churn before as a metric that the business is actively working to reduce, but for engineers, it‚Äôs just ‚Äúdowntime.‚Äù Engineers are seldomly exposed to the idea that lowering Churn increases customer lifetime value and affects customer acquisition cost.</p>

<p>So put your DevOps cap on for a minute. Can you think of ways to reduce the churn rate?</p>

<ul>
<li>Reduce downtime.</li>
<li>Reduce latency and load speed.</li>
<li>Optimize report generation time.</li>
<li>Increase email deliverability.</li>
<li>Enable toggle features to allow your product team to test their new features on users.</li>
</ul>

<p>The list goes on, and it‚Äôs just for reducing Churn.
And yes, these are obvious priorities for operations, but now you have a clear business value tied to it.</p>

<p>Almost every hidden cost I mentioned earlier could turn into a value proposition for a DevOps related project.</p>

<h2 id="make-sure-you-have-all-the-data">Make sure you have all the data</h2>

<p>All of this ‚ÄúCost‚Äù and ‚ÄúValue‚Äù talk is almost meaningless or non-actionable if you don‚Äôt have metrics in place.</p>

<ul>
<li>You need to have a cloud provider cost breakdown to know how much you‚Äôre spending on a project or a server.</li>
<li>Build time statistics.</li>
<li>Build and deployment success rate over time.<br></li>
<li>How long it takes to onboard a new developer to the team.</li>
</ul>

<p>You need the metrics for three reasons:</p>

<ol>
<li>Visibility - You need to be aware of the cost in the first place.</li>
<li>When making a decision, you have to have a benchmark.</li>
<li>To see the impact of your actions when working to reduce the cost.</li>
</ol>

<p>You can‚Äôt make informed decisions without having all the data; otherwise, it‚Äôs just guessing.</p>



<p>Ask yourself the following questions:</p>

<ol>
<li>Do we really need to scale this?</li>
<li>How much time will it take to reduce a cost? What can your developers do instead?</li>
<li>How can you improve the development workflow? How much time can you save?</li>
<li>Do we have a culture that allows open discussion? Do engineers have a voice when it comes to new projects and features?</li>
<li>How can we share knowledge across the organization, so engineers are aware of the product, sales, and marketing struggles?</li>
</ol>

    </div></div>]]>
            </description>
            <link>https://pushbuildtestdeploy.com/on-hidden-costs-and-the-value-of-devops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637836</guid>
            <pubDate>Wed, 30 Sep 2020 12:02:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ruby One-Liners Cookbook]]>
            </title>
            <description>
<![CDATA[
Score 188 | Comments 32 (<a href="https://news.ycombinator.com/item?id=24637797">thread link</a>) | @asicsp
<br/>
September 30, 2020 | https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html | <a href="https://web.archive.org/web/*/https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        <!-- Provide site root to javascript -->
        

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            
            
        </nav>

        <div id="page-wrapper">

            <div class="page">
                
                
                

                
                
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        
<p>This chapter will give an overview of <code>ruby</code> syntax for command line usage and some examples to show what kind of problems are typically suited for one-liners.</p>
<h2><a href="#why-use-ruby-for-one-liners" id="why-use-ruby-for-one-liners">Why use Ruby for one-liners?</a></h2>
<p>I assume you are already familiar with use cases where command line is more productive compared to GUI. See also this series of articles titled <a href="https://sanctum.geek.nz/arabesque/series/unix-as-ide/">Unix as IDE</a>.</p>
<p>A shell utility like <code>bash</code> provides built-in commands and scripting features to make it easier to solve and automate various tasks. External *nix commands like <code>grep</code>, <code>sed</code>, <code>awk</code>, <code>sort</code>, <code>find</code>, <code>parallel</code> etc can be combined to work with each other. Depending upon your familiarity with those tools, you can either use <code>ruby</code> as a single replacement or complement them for specific use cases.</p>
<p>Here's some one-liners (options will be explained later):</p>
<ul>
<li><code>ruby -e 'puts readlines.uniq' *.txt</code> ‚Äî retain only one copy if lines are duplicated from the given list of input file(s)</li>
<li><code>ruby -e 'puts readlines.uniq {|s| s.split[1]}' *.txt</code> ‚Äî retain only first copy of duplicate lines using second field as duplicate criteria</li>
<li><code>ruby -rcommonregex -ne 'puts CommonRegex.get_links($_)' *.md</code> ‚Äî extract only the URLs, using a third-party <a href="https://github.com/talyssonoc/CommonRegexRuby">CommonRegexRuby</a> library</li>
<li><a href="https://stackoverflow.com/questions/63954081/bash-remove-duplicate-of-key-values-with-preserving-order">stackoverflow: merge duplicate key values while preserving order</a> ‚Äî a recent Q&amp;A that I answered with a simpler <code>ruby</code> solution compared to <code>awk</code></li>
</ul>
<p>The main advantage of <code>ruby</code> over tools like <code>grep</code>, <code>sed</code> and <code>awk</code> includes feature rich regular expression engine, standard library and third-party libraries. If you don't already know the syntax and idioms for <code>sed</code> and <code>awk</code>, learning command line options for <code>ruby</code> would be the easier option. The main disadvantage is that <code>ruby</code> is likely to be slower compared to those tools.</p>
<h2><a href="#command-line-options" id="command-line-options">Command line options</a></h2>
<table><thead><tr><th><strong>Option</strong></th><th><strong>Description</strong></th></tr></thead><tbody>
<tr><td><code>-0[octal]</code></td><td>specify record separator (<code>\0</code>, if no argument)</td></tr>
<tr><td><code>-a</code></td><td>autosplit mode with <code>-n</code> or <code>-p</code> (splits <code>$_</code> into <code>$F</code>)</td></tr>
<tr><td><code>-c</code></td><td>check syntax only</td></tr>
<tr><td><code>-Cdirectory</code></td><td>cd to directory before executing your script</td></tr>
<tr><td><code>-d</code></td><td>set debugging flags (set <code>$DEBUG</code> to true)</td></tr>
<tr><td><code>-e 'command'</code></td><td>one line of script. Several <code>-e</code>'s allowed. Omit [programfile]</td></tr>
<tr><td><code>-Eex[:in]</code></td><td>specify the default external and internal character encodings</td></tr>
<tr><td><code>-Fpattern</code></td><td><code>split()</code> pattern for autosplit (<code>-a</code>)</td></tr>
<tr><td><code>-i[extension]</code></td><td>edit <code>ARGV</code> files in place (make backup if extension supplied)</td></tr>
<tr><td><code>-Idirectory</code></td><td>specify <code>$LOAD_PATH</code> directory (may be used more than once)</td></tr>
<tr><td><code>-l</code></td><td>enable line ending processing</td></tr>
<tr><td><code>-n</code></td><td>assume <code>'while gets(); ... end'</code> loop around your script</td></tr>
<tr><td><code>-p</code></td><td>assume loop like <code>-n</code> but print line also like <code>sed</code></td></tr>
<tr><td><code>-rlibrary</code></td><td>require the library before executing your script</td></tr>
<tr><td><code>-s</code></td><td>enable some switch parsing for switches after script name</td></tr>
<tr><td><code>-S</code></td><td>look for the script using PATH environment variable</td></tr>
<tr><td><code>-v</code></td><td>print the version number, then turn on verbose mode</td></tr>
<tr><td><code>-w</code></td><td>turn warnings on for your script</td></tr>
<tr><td><code>-W[level=2|:category]</code></td><td>set warning level; 0=silence, 1=medium, 2=verbose</td></tr>
<tr><td><code>-x[directory]</code></td><td>strip off text before #!ruby line and perhaps cd to directory</td></tr>
<tr><td><code>--jit</code></td><td>enable JIT with default options (experimental)</td></tr>
<tr><td><code>--jit-[option]</code></td><td>enable JIT with an option (experimental)</td></tr>
<tr><td><code>-h</code></td><td>show this message, <code>--help</code> for more info</td></tr>
</tbody></table>
<p>This chapter will show examples with <code>-e</code>, <code>-n</code>, <code>-p</code> and <code>-a</code> options. Some more options will be covered in later chapters, but not all of them are discussed in this book.</p>
<h2><a href="#executing-ruby-code" id="executing-ruby-code">Executing Ruby code</a></h2>
<p>If you want to execute a <code>ruby</code> program file, one way is to pass the filename as argument to the <code>ruby</code> command.</p>
<pre><code>$ echo 'puts "Hello Ruby"' &gt; hello.rb
$ ruby hello.rb
Hello Ruby
</code></pre>
<p>For short programs, you can also directly pass the code as an argument to the <code>-e</code> option.</p>
<pre><code>$ ruby -e 'puts "Hello Ruby"'
Hello Ruby

$ # multiple statements can be issued separated by ;
$ ruby -e 'x=25; y=12; puts x**y'
59604644775390625
$ # or use -e option multiple times
$ ruby -e 'x=25' -e 'y=12' -e 'puts x**y'
59604644775390625
</code></pre>
<h2><a href="#filtering" id="filtering">Filtering</a></h2>
<p><code>ruby</code> one-liners can be used for filtering lines matched by a regexp, similar to <code>grep</code>, <code>sed</code> and <code>awk</code>. And similar to many command line utilities, <code>ruby</code> can accept input from both <code>stdin</code> and file arguments.</p>
<pre><code>$ # sample stdin data
$ printf 'gate\napple\nwhat\nkite\n'
gate
apple
what
kite

$ # print all lines containing 'at'
$ # same as: grep 'at' and sed -n '/at/p' and awk '/at/'
$ printf 'gate\napple\nwhat\nkite\n' | ruby -ne 'print if /at/'
gate
what

$ # print all lines NOT containing 'e'
$ # same as: grep -v 'e' and sed -n '/e/!p' and awk '!/e/'
$ printf 'gate\napple\nwhat\nkite\n' | ruby -ne 'print if !/e/'
what
</code></pre>
<p>By default, <code>grep</code>, <code>sed</code> and <code>awk</code> will automatically loop over input content line by line (with <code>\n</code> as the line distinguishing character). The <code>-n</code> or <code>-p</code> option will enable this feature for <code>ruby</code>. As seen before, the <code>-e</code> option accepts code as command line argument. Many shortcuts are available to reduce the amount of typing needed.</p>
<p>In the above examples, a regular expression (defined by the pattern between a pair of forward slashes) has been used to filter the input. When the input string isn't specified in a conditional context (for example: <code>if</code>), the test is performed against global variable <code>$_</code>, which has the contents of the input line (the correct term would be input <strong>record</strong>, see <a href="https://learnbyexample.github.io/learn_ruby_oneliners/record-separators.html#record-separators">Record separators</a> chapter). To summarize, in a conditional context:</p>
<ul>
<li><code>/regexp/</code> is a shortcut for <code>$_ =~ /regexp/</code></li>
<li><code>!/regexp/</code> is a shortcut for <code>$_ !~ /regexp/</code></li>
</ul>
<p><code>$_</code> is also the default argument for <code>print</code> method, which is why it is generally preferred in one-liners over <code>puts</code> method. More such defaults that apply to the <code>print</code> method will be discussed later.</p>
<blockquote>
<p><img src="https://learnbyexample.github.io/learn_ruby_oneliners/images/info.svg" alt="info"> See <a href="https://ruby-doc.org/core-2.7.1/doc/globals_rdoc.html">ruby-doc: Pre-defined global variables</a> for documentation on <code>$_</code>, <code>$&amp;</code>, etc.</p>
</blockquote>
<p>Here's an example with file input instead of <code>stdin</code>.</p>
<pre><code>$ cat table.txt
brown bread mat hair 42
blue cake mug shirt -7
yellow banana window shoes 3.14

$ # same as: grep -oE '[0-9]+$' table.txt
$ ruby -ne 'puts $&amp; if /\d+$/' table.txt
42
7
14
</code></pre>
<blockquote>
<p><img src="https://learnbyexample.github.io/learn_ruby_oneliners/images/info.svg" alt="info"> The <a href="https://github.com/learnbyexample/learn_ruby_oneliners/tree/master/example_files">learn_ruby_oneliners repo</a> has all the files used in examples.</p>
</blockquote>
<h2><a href="#substitution" id="substitution">Substitution</a></h2>
<p>Use <code>sub</code> and <code>gsub</code> methods for search and replace requirements. By default, these methods operate on <code>$_</code> when the input string isn't provided. For these examples, <code>-p</code> option is used instead of <code>-n</code> option, so that the value of <code>$_</code> is automatically printed after processing each input line.</p>
<pre><code>$ # for each input line, change only first ':' to '-'
$ # same as: sed 's/:/-/' and awk '{sub(/:/, "-")} 1'
$ printf '1:2:3:4\na:b:c:d\n' | ruby -pe 'sub(/:/, "-")'
1-2:3:4
a-b:c:d

$ # for each input line, change all ':' to '-'
$ # same as: sed 's/:/-/g' and awk '{gsub(/:/, "-")} 1'
$ printf '1:2:3:4\na:b:c:d\n' | ruby -pe 'gsub(/:/, "-")'
1-2-3-4
a-b-c-d
</code></pre>
<p>You might wonder how <code>$_</code> is modified without the use of <code>!</code> methods. The reason is that these methods are part of Kernel (see <a href="https://ruby-doc.org/core-2.7.1/Kernel.html">ruby-doc: Kernel</a> for details) and are available only when <code>-n</code> or <code>-p</code> options are used.</p>
<ul>
<li><code>sub(/regexp/, repl)</code> is a shortcut for <code>$_.sub(/regexp/, repl)</code> and <code>$_</code> will be updated if substitution succeeds</li>
<li><code>gsub(/regexp/, repl)</code> is a shortcut for <code>$_.gsub(/regexp/, repl)</code> and <code>$_</code> gets updated if substitution succeeds</li>
</ul>
<blockquote>
<p><img src="https://learnbyexample.github.io/learn_ruby_oneliners/images/info.svg" alt="info"> This book assumes you are already familiar with regular expressions. If not, you can check out my free <a href="https://learnbyexample.github.io/Ruby_Regexp/">Ruby Regexp</a> book.</p>
</blockquote>
<h2><a href="#field-processing" id="field-processing">Field processing</a></h2>
<p>Consider the sample input file shown below with fields separated by a single space character.</p>
<pre><code>$ cat table.txt
brown bread mat hair 42
blue cake mug shirt -7
yellow banana window shoes 3.14
</code></pre>
<p>Here's some examples that is based on specific field rather than the entire line. The <code>-a</code> option will cause the input line to be split based on whitespaces and the field contents can be accessed using <code>$F</code> global variable. Leading and trailing whitespaces will be suppressed and won't result in empty fields. More details is discussed in <a href="https://learnbyexample.github.io/learn_ruby_oneliners/field-separators.html#default-field-separation">Default field separation</a> section.</p>
<pre><code>$ # print the second field of each input line
$ # same as: awk '{print $2}' table.txt
$ ruby -ane 'puts $F[1]' table.txt
bread
cake
banana

$ # print lines only if last field is a negative number
$ # same as: awk '$NF&lt;0' table.txt
$ ruby -ane 'print if $F[-1].to_f &lt; 0' table.txt
blue cake mug shirt -7

$ # change 'b' to 'B' only for the first field
$ # same as: awk '{gsub(/b/, "B", $1)} 1' table.txt
$ ruby -ane '$F[0].gsub!(/b/, "B"); puts $F * " "' table.txt
Brown bread mat hair 42
Blue cake mug shirt -7
yellow banana window shoes 3.14
</code></pre>
<h2><a href="#begin-and-end" id="begin-and-end">BEGIN and END</a></h2>
<p>You can use a <code>BEGIN{}</code> block when you need to execute something before input is read and a <code>END{}</code> block to execute something after all of the input has been processed.</p>
<pre><code>$ # same as: awk 'BEGIN{print "---"} 1; END{print "%%%"}'
$ # note the use of ; after BEGIN block
$ seq 4 | ruby -pe 'BEGIN{puts "---"}; END{puts "%%%"}'
---
1
2
3
4
%%%
</code></pre>
<h2><a href="#env-hash" id="env-hash">ENV hash</a></h2>
<p>When it comes to automation and scripting, you'd often need to construct commands that can accept input from user, file, output of a shell command, etc. As mentioned before, this book assumes <code>bash</code> as the shell being used. To access environment variables of the shell, you can call the special hash variable <code>ENV</code> with the name of the environment variable as a string key.</p>
<pre><code>$ # existing environment variable
$ # output shown here is for my machine, would differ for you
$ ruby -e 'puts ENV["HOME"]'
/home/learnbyexample
$ ruby -e 'puts ENV["SHELL"]'
/bin/bash

$ # defined along with ruby command
$ # note that the variable is placed before the shell command
$ word='hello' ruby -e 'puts ENV["word"]'
hello
$ # the input characters are preserved as is
$ ip='hi\nbye' ruby -e 'puts ENV["ip"]'
hi\nbye
</code></pre>
<p>Here's another example when a regexp is passed as an environment variable content.</p>
<pre><code>$ cat word_anchors.txt
sub par
spar
apparent effort
two spare computers
cart part tart mart

$ # assume 'r' is a shell variable that has to be passed to the ruby command
$ r='\Bpar\B'
$ rgx="$r" ruby -ne 'print if /#{ENV["rgx"]}/' word_anchors.txt
apparent effort
two spare computers
</code></pre>
<blockquote>
<p><img src="https://learnbyexample.github.io/learn_ruby_oneliners/images/info.svg" alt="info"> As an example, see my repo <a href="https://github.com/learnbyexample/command_help/blob/master/ch">ch: command help</a> for a practical shell script, where commands are constructed ‚Ä¶</p></blockquote></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html">https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html</a></em></p>]]>
            </description>
            <link>https://learnbyexample.github.io/learn_ruby_oneliners/one-liner-introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637797</guid>
            <pubDate>Wed, 30 Sep 2020 11:57:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making the Monte Hall problem weirder but obvious]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24637787">thread link</a>) | @dyno-might
<br/>
September 30, 2020 | https://dyno-might.github.io/2020/09/17/making-the-monty-hall-problem-weirder-but-obvious/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/09/17/making-the-monty-hall-problem-weirder-but-obvious/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        

<div>
    <div>
        <div>
            <p><strong>Sep 17, 2020</strong></p>
            



<p>The <a href="https://en.wikipedia.org/wiki/Monty_Hall_problem">Monty Hall problem</a> is famously unintuitive. This post starts with an extreme version where the solution is blindingly obvious. We then go through a series of small changes. It will be clear that these don‚Äôt affect the solution. At the end, we arrive at the classic Monte Hall problem.</p>

<p>For reference, the <a href="https://en.wikipedia.org/wiki/Monty_Hall_problem">classic formulation</a> goes:</p>

<blockquote>
  <p>Suppose you‚Äôre on a game show, and you‚Äôre given the choice of three doors: Behind one door is a car; behind the others, goats. You pick a door, say No. 1, and the host, who knows what‚Äôs behind the doors, opens another door, say No. 3, which has a goat. He then says to you, ‚ÄúDo you want to pick door No. 2?‚Äù Is it to your advantage to switch your choice?</p>
</blockquote>

<p>Intuitively, many people guess it doesn‚Äôt matter if you switch. But it does. You get the car 2/3 of the time if you switch, and 1/3 of the time if you don‚Äôt. Why?</p>



<p>Here‚Äôs our first game.</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind all of the other 9 doors.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game1.png">
</p>

<p>There‚Äôs nothing mysterious here. You should choose option B. There‚Äôs only a 10% chance you picked the right door, so there‚Äôs a 90% chance the car is behind one of the others.</p>



<p>Now, we slightly update the game (new part in bold).</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li><strong>Monty says ‚ÄúHey! I promise you that there is a goat behind at least 8 of the other 9 doors!‚Äù</strong></li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind all of the other 9 doors.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game2.png">
</p>

<p>Monty‚Äôs statement changes nothing. You don‚Äôt need to rely on his <a href="https://en.wikipedia.org/wiki/Monty_Hall#/media/File:Monty_hall_abc_tv.JPG">trustworthy looks</a>. You already <em>knew</em> there were at least 8 goats! Option B still gets you the car 90% of the time.</p>



<p>Let‚Äôs update the game again (new part in bold).</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li><strong>Monty looks behind the other 9 doors. He chooses 8 with goats behind them, and opens them.</strong></li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind all of the other 9 doors.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game3.png">
</p>

<p>The key insight is this: When Monty shows you that 8 of the 9 other doors contain goats, you haven‚Äôt learned anything relevant to your decision. You <em>already knew there were at least 8 goats behind the other doors</em>! So this is just like game 2. Option B still gets you the car 90% of the time.</p>

<p>Want more intuition? Suppose you picked door 3. Imagne Monty walking past the doors, opening doors 1, 2, 4, 5, 6, <strong>skipping 7</strong>, then opening 8, 9, and 10. Doesn‚Äôt door 7 seem special?</p>



<p>Let‚Äôs make another change. Finally, we arrive at a game very similar to Monty Hall.</p>

<ol>
  <li>There are 10 doors. A car is randomly placed behind one, and goats behind the other 9.</li>
  <li>You pick one door.</li>
  <li>Monty looks behind the other 9 doors. He chooses 8 of them with goats behind them, and opens them.</li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind <strong>the other closed door</strong>.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game4.png">
</p>

<p>The only difference with Game 3 is that option B doesn‚Äôt get you the 8 visible goats. Since you don‚Äôt care about goats, this makes no difference. This is still just like the game 3. You get the car 90% of the time by switching.</p>



<p>Here is the last game. We just change the number of doors from 10 to 3.</p>

<ol>
  <li>There are <strong>3</strong> doors. A car is randomly placed behind one, and goats behind the other <strong>2</strong>.</li>
  <li>You pick one door.</li>
  <li>Monty looks behind the other <strong>2</strong> doors. He chooses one <strong>1</strong> of them with a goat behind it, and opens it.**</li>
  <li>You get two options:
    <ul>
      <li>Option A: You get whatever is behind the door you picked.</li>
      <li>Option B: You get whatever is behind the other closed door.</li>
    </ul>
  </li>
</ol>

<p><img src="https://dyno-might.github.io/img/monty-hall/game5.png">
</p>

<p>Of course, you still want to choose option B. The chance of success is now 2/3 instead of 9/10. This game is exactly Monty Hall, so we‚Äôre done.</p>



<ul>
  <li>
    <p>It‚Äôs important that Monty looked behind the doors before choosing which to open. This is where people‚Äôs intuition usually fails. If he had chosen a door at random ‚Äî <em>in a way that he risked possibly exposing a car</em>, then the situation would be different. (In that case, there‚Äôs no advantage or harm in switching.) But he doesn‚Äôt choose the door at random. He deliberately chooses to show you goats. Since this is always possible, it tells you nothing. I think this is the crux of what makes this problem unintuitive. Many people intuitively think it doen‚Äôt matter if you switch. And that <em>would be correct</em> if the door had been opened at random!</p>
  </li>
  <li>
    <p>It might be helpful to draw a diagram of the relationship of the different games, starting with classic Monty Hall and ending with the extreme version.</p>
  </li>
</ul>

<blockquote>
  <p>Game 5 (Classic Monty Hall)<br>
‚ÄÉ‚Üì<br>
‚ÄÉ‚Üì (Use 10 doors instead of 3)<br>
‚ÄÉ‚Üì <br>
Game 4<br>
‚ÄÉ‚Üì<br>
‚ÄÉ‚Üì (If you switch, get the contents of <em>all</em> other doors, not just the other closed door.)<br>
‚ÄÉ‚Üì<br>
Game 3<br>
‚ÄÉ‚Üì<br>
‚ÄÉ‚Üì (Monty promises 8 goats behind the other doors instead of showing you.)<br>
‚ÄÉ‚Üì<br>
Game 2<br>
‚ÄÉ‚Üì<br>
‚ÄÉ‚Üì (Monty doesn‚Äôt bother promsising.)<br>
‚ÄÉ‚Üì<br>
Game 1 (Dyno Might¬© Monty Hall)</p>
</blockquote>

<ul>
  <li>
    <p>There are <a href="https://marginalrevolution.com/marginalrevolution/2019/09/the-intuitive-monty-hall-problem.html">some</a> <a href="https://twitter.com/jben0/status/1174180200072011776">other</a> <a href="https://statmodeling.stat.columbia.edu/2019/09/19/alternative-more-intuitive-formulation-of-monte-hall-problem/">attempts</a> at <a href="https://math.stackexchange.com/questions/96826/the-monty-hall-problem/3360686#3360686">variants</a> of the Monte Hall problem, also intended to be more intuitive. These involve switching the doors for ‚Äúboxers‚Äù.</p>
  </li>
  <li>
    <p>Monty Hall was actually named ‚ÄúMonte‚Äù at birth! Given that <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo simulations</a> are often used for exploring the Monty Hall problem, that‚Äôs either a tragedy for puns or a miracle for confused students.</p>
  </li>
</ul>

        </div>

        

        
        
    </div>
</div>


    </div>
</section></div>]]>
            </description>
            <link>https://dyno-might.github.io/2020/09/17/making-the-monty-hall-problem-weirder-but-obvious/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637787</guid>
            <pubDate>Wed, 30 Sep 2020 11:56:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spotify‚Äôs Failed Squad Goals]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24637656">thread link</a>) | @cocoflunchy
<br/>
September 30, 2020 | https://www.jeremiahlee.com/posts/failed-squad-goals/?repost | <a href="https://web.archive.org/web/*/https://www.jeremiahlee.com/posts/failed-squad-goals/?repost">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<!-- Spread 1 -->
<section>
<section>
<video autoplay="true" muted="true" loop="true">
<source srcset="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.png" media="(prefers-reduced-motion: reduce)">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.webm" type="video/webm">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.m4v" type="video/mp4">
<img src="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.png" alt="Taylor Swift and her squad walking away from an explosion in front of the Spotify office at Birger Jarlsgatan.">
</video>
</section>
<section>
<div>

<p><b>Spotify</b> doesn‚Äôt use <em>‚Äúthe Spotify model‚Äù</em><br>and neither should you.</p>
<p>By Jeremiah Lee</p>
<p>Sunday, April 19, 2020 ‚Ä¢ <a href="https://anchor.fm/jeremiah-oral-lee/episodes/Spotifys-Failed-SquadGoals-edia0p">Listen</a> ‚Ä¢&nbsp;<a href="https://oyomy.fr/2020/04/l-echec-du-modele-spotify/" hreflang="fr">En fran√ßais</a> ‚Ä¢&nbsp;<a href="https://jp.quora.com/q/agile/Spotify%E3%81%AF-Spotify%E3%83%A2%E3%83%87%E3%83%AB-%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%84%E3%81%AA%E3%81%84" hreflang="ja">Êó•Êú¨Ë™û„Åß</a> ‚Ä¢ <a href="https://flavioclesio.com/2020/05/18/o-modelo-de-squadgoals-do-spotify-falhou/" hreflang="pt-br">Portugu√™s (Brasil)</a></p>
</div>
</section>
</section>
<!-- Spread 2 -->
<section>
<section>
<div>
<p>Of all the allures of startup culture, few are more desireable than the speed and nimbleness of a small team. Maintaining that feeling as a company grows is a challenge. In 2012, Spotify shared its way of working and suggested it had figured it out.<sup><a href="#1">1</a></sup></p>
<p>I was excited to see <em>the Spotify model</em> in action when I interviewed for a product management role at its Stockholm headquarters in 2017. However, the recruiter surprised me before the first interview. She cautioned me to not expect Spotify to be an <a href="https://en.wikipedia.org/wiki/Agile_software_development">Agile</a> utopia.</p>
<p>I joined the company after it had tripled in size to 3,000 people over 18 months. I learned the famed squad model was only ever aspirational and never fully implemented. I witnessed organizational chaos as the company‚Äôs leaders incrementally transitioned to more traditional management structures.</p>
<p>When I asked my coworkers why the content was not removed or updated to reflect reality, I never got a good answer. Many people ironically thought the posts were great for recruiting. I no longer work at Spotify, so I am sharing my experience to set the record straight. The Spotify squad model failed Spotify and it will fail your company too.</p>
</div>
</section>
<section>
<div>
<h3>But you don‚Äôt have to take my word for it.</h3>
<p>The co-author of the Spotify model<sup><a href="#2">2</a></sup> and multiple agile coaches who worked at Spotify have been telling people to not copy it for years. Unfortunately, truth doesn‚Äôt spread as quickly or as widely as an idea people want to believe in.</p>
<blockquote>
<p>‚ÄúEven at the time we wrote it, we weren‚Äôt doing it. It was part ambition, part approximation. People have really struggled to copy something that didn‚Äôt really exist.‚Äù</p>
</blockquote>
<p>‚ÄîJoakim Sund√©n, agile coach at Spotify&nbsp;2011‚Äì2017<sup><a href="#4">4</a></sup></p>
<blockquote>
<p><em>‚ÄúIt worries me when people look at what we do and think it‚Äôs a framework they can just copy and implement.</em> ‚Ä¶ We are really trying hard now to emphasize we have problems as well. It‚Äôs not all ‚Äòshiny and everything works well and all our squads are super amazing‚Äô.‚Äù</p>
</blockquote>
<p>‚ÄîAnders Ivarsson, co-author of the Spotify&nbsp;whitepaper<sup><a href="#3">3</a></sup></p>
</div>
</section>
</section>
<!-- Spread 3 -->
<section>
<section>
<div>
<h2>Recap</h2>
<p>You can read and watch the <a href="#1">original content</a> in less than 30 minutes or <a href="#spread-4">skip to the next section</a> if you are familiar. Here is a brief summary.</p>
<p>Spotify had teams it called <em>squads</em> because it sounded cooler (not joking). A group of teams were organized into a department called a <em>tribe</em>. Each team was intended to be an autonomous mini-startup, with a product manager acting as mini-CEO for a feature area. The teams had designers and software engineers with a range of specializations. The intent was that a team should have every skill necessary without needing to rely on another team for success.</p>
<p>Product managers had a traditional management structure. A product manager for a team reported to their department‚Äôs product director (<em>‚Äútribe lead‚Äù</em>). Same for designers. Software engineers, however, were managed outside of the team structure.</p>
</div>
</section>
<section>
<div>
<p><em>‚ÄúChapter leads‚Äù</em> managed software engineers specializing in a specific type of software development across the department. For example, all of the software engineers working on backend APIs across all the teams within the department would have one manager and all of the Android mobile engineers in the department would have a different manager. The intent was to allow engineers to be moved between teams within the department to best meet business requirements without them having to change managers.</p>
<figure>
<video autoplay="true" muted="true" loop="true">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/scaling-spotify-squads.webm" type="video/webm">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/scaling-spotify-squads.m4v" type="video/mp4">
<img src="https://www.jeremiahlee.com/posts/failed-squad-goals/scaling-spotify-squads.png" alt="Spotify matrix organization diagram. A department is called a tribe and has multiple squads, another name for a team. Each squad has a product owner, another name for a product manager. Software engineers of the same discipline across multiple teams are called a chapter and managed by a chapter lead, another name for an engineering manager.">
</video>
<figcaption>Spotify tried a long-lived matrix team structure with unusual word choices.<sup><a href="#1">1</a></sup> It did not work well.</figcaption>
</figure>
</div>
</section>
</section>
<!-- Spread 4 -->
<section id="spread-4">
<section>

</section>
<section id="matrix-management-sucks">
<div>
<h3>Matrix management solved the wrong problem</h3>
<p>The ‚Äúfull stack‚Äù agile team worked well, but the matrix management of software engineers introduced more problems than it solved.</p>
<ul>
<li><p>Teams at Spotify were rather long-lived. The benefit of not having to change manager when moving to another team was limited.</p></li>
<li><p>Engineering managers in this model had little responsibility beyond the career development of the people they managed. Even then, their ability to help with interpersonal people skills development was limited. An engineering manager would not manage enough of the other people on the team or be involved enough in the daily context to independently assess conflict within the team.</p></li>
</ul>
</div>
</section>
</section>
<!-- Spread 5 -->
<section>
<section>
<div>
<ul>
<li><p>Without a single engineering manager responsible for the engineers on a team, the product manager lacked an equivalent peer‚Äîthe mini-CTO to their mini-CEO role. There was no single person accountable for the engineering team‚Äôs delivery or who could negotiate prioritization of work at an equivalent level of responsibility.</p><p>When disagreements within the engineering team arose, the product manager needed to negotiate with all of the engineers on the team. If the engineers could not reach a consensus, the product manager needed to escalate to as many engineering managers as there were engineering specializations within the team. A team with backend, Web app, and mobile app engineers would have at least 3 engineering managers who might need to get involved. If those engineering managers could not reach a consensus, a single team‚Äôs issue would have to escalate to the department‚Äôs engineering director.</p></li>
</ul>
</div></section>
<section id="matrix-management-sucks">
<div>
<blockquote>
<p>‚ÄúChapter leads are servant-leaders who help you grow as an individual. They don‚Äôt really work with any team. They have direct reports on all the teams. They don‚Äôt have really any accountability for the delivery. They aren‚Äôt taking that responsibility. It‚Äôs easy to see the product owner as the manager for the team.‚Äù</p>
</blockquote>
<p>‚ÄîJoakim Sund√©n, agile coach at Spotify<sup><a href="#4">4</a></sup></p>
<p><strong>Learn from Spotify‚Äôs mistakes:</strong></p>
<ul>
<li>A product‚Äîdesign‚Äîengineering team typically contains more engineers than designers or product managers. Having a single engineering manager for the engineers on the team creates an accountable escalation path for conflict within the team.</li>
<li>Product managers should have an equivalent peer for engineering. Product managers should be accountable for the prioritization of work. Engineering managers should be accountable for the engineers‚Äô execution, which includes being able to negotiate speed and quality tradeoffs with the product manager.</li>
</ul>
</div>
</section>
</section>
<!-- Spread 6 -->
<section>
<section id="too-much-autonomy">
<div>
<h3>Spotify fixated on team autonomy</h3>
<p>When a company is small, teams have to do a wide range of work to deliver and have to shift initiatives frequently. As a company grows from startup to scale-up, duplicated functions across teams move to new teams dedicated to increasing organization efficiency by reducing duplication. With more teams, the need for a team to shift initiative decreases in frequency. Both of these changes allow for teams to think more deeply and long term about the problems they are scoped to solve. Faster iteration, however, is not guaranteed. Every responsibility a team cedes to increase its focus becomes a new cross-team dependency.</p>
<p>Spotify did not define a common process for cross-team collaboration. Allowing every team to have a unique way of working meant each team needed a unique way of engagement when collaborating. Overall organization productivity suffered.</p>
<p>The Spotify model was documented when Spotify was a much smaller company. It was supposed to be a multiple part series, according to Anders Ivarsson. Autonomy made the first cut, but the parts on alignment and accountability were never completed.</p>
</div>
</section>
<section>
<div>
<p><strong>Learn from Spotify‚Äôs mistakes:</strong></p>
<ul>
<li>Autonomy requires alignment. Company priorities must be defined by leadership. Autonomy does not mean teams get to do whatever they want.</li>
<li>Processes for cross-team collaboration must be defined. Autonomy does not mean leaving teams to self-organize every problem.</li>
<li>How success is measured must be defined by leadership so people can effectively negotiate cross-team dependency prioritization.</li>
<li>Autonomy requires accountability. Product management is accountable for value. The team is accountable for delivering ‚Äòdone‚Äô increments. Mature teams can justify their independence with their ability to articulate business value, risk, learning, and the next optimal move.<sup><a href="#6">6</a></sup></li>
</ul>
</div>
</section>
</section>
<!-- Spread 7 -->
<section>
<section id="too-much-autonomy">
<div>
<blockquote>
<p>‚ÄúIf I were to do one thing differently, I would say we should not be focusing so much on autonomy.</p>
<p>‚ÄúEvery time you have a new team, they have to reinvent the wheel in how they should be working. Maybe, just maybe, we should have a ‚Äòminimum viable agility‚Äô. You start with that. You are free to opt out, but people shouldn‚Äôt have to opt-in all the time.</p>
<p>‚ÄúAt what point do you start inserting this process? Probably when it‚Äôs too late.‚Äù</p>
</blockquote>
<p>‚ÄîJoakim Sund√©n, agile coach at Spotify<sup><a href="#4">4</a></sup></p>
</div>
</section>
<section>
<div>
<blockquote>
<p>‚ÄúHenrik Kniberg talked about how we're not that good at large initiatives and we‚Äôre still not that good at large initiatives.</p>
<p>‚ÄúIf you have inconsistent ways of working, it‚Äôs more difficult for people to move. If it‚Äôs more difficult for people to move, it‚Äôs more likely you have inconsistent ways of working. It will just reinforce until all of a sudden, you‚Äôre not really working for the same company anymore. You‚Äôre working for these kind of weird subcultures.‚Äù</p>
</blockquote>
<p>‚ÄîJason Yip, agile coach at Spotify<br>2015‚Äìtime of writing<sup><a href="#5">5</a></sup></p>
</div>
</section>
</section>
<!-- Spread 8 -->
<section>
<section id="collaboration-is-a-competency">
<div>
<h3>Collaboration was an assumed competency</h3>
<p>While Spotify gave teams control over their way of working, many people did not have a basic understanding of Agile practices. This resulted in teams iterating through process tweaks in blind hope of finding the combination that would help them improve their delivery. People lacked a common language to effectively discuss the process problems, the education to solve them, and the experience to evaluate performance. It was not really <em>agile</em>. It was just <em>not-waterfall</em>.</p>
<p><em>‚ÄúAgile coaches‚Äù</em> were internal consultants Spotify provided teams to teach and suggest process improvements. While well-intentioned, there were not enough coaches to help every team. A coach‚Äôs engagement with a team was rarely long enough to span a project‚Äôs completion to help a team evaluate performance. More so, they were not accountable for anything.</p>
</div>
</section>
<section>
<div>
<blockquote>
<p>‚ÄúControl without competence is chaos.‚Äù</p>
</blockquote>
<p>‚ÄîL. David Marquet, <a href="https://www.indiebound.org/book/9781591846406"><cite>Turn the Ship Around!</cite></a></p>
<p><strong>Learn from Spotify‚Äôs ‚Ä¶</strong></p></div></section></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jeremiahlee.com/posts/failed-squad-goals/?repost">https://www.jeremiahlee.com/posts/failed-squad-goals/?repost</a></em></p>]]>
            </description>
            <link>https://www.jeremiahlee.com/posts/failed-squad-goals/?repost</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637656</guid>
            <pubDate>Wed, 30 Sep 2020 11:35:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Six Figures in 6 days]]>
            </title>
            <description>
<![CDATA[
Score 622 | Comments 283 (<a href="https://news.ycombinator.com/item?id=24637405">thread link</a>) | @brunojppb
<br/>
September 30, 2020 | https://tr.af/6 | <a href="https://web.archive.org/web/*/https://tr.af/6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-lax-preset="fadeIn">
        <p>This title is a little misleading.</p>

<p>Sure, it took me 6 days to amass 3,626 sales for a total of $101,528, but like any overnight success, it was years in the making. In my case, about 7 years.</p>

<p>In 2013, the jailbreaking days of iOS were in full effect. Inspired, I created and sold an icon set titled 'Greyish HD' on the Cydia store for $0.99. It was the first few dollars I ever made on the internet. I think I made a total of $17, and it was magical.</p>

<p>It wasn't about the $17, obviously; it was how I earned it. I spent time creating something that I thought was cool, then hit publish. After a few days, random strangers I've never met before decided to spend their hard-earned cents on my icon set, oftentimes while I was working on something else entirely. Without realizing it, I just discovered digital content leverage: <strong>create something once with sufficient effort, then sell it repeatedly with minimal effort.</strong></p>

<p>Fast forward 7 years later, minus 6 days. I saw some people sharing screenshots of their iPhones after discovering that iOS 14 now allows you to add custom icons to your home screen using the Siri Shortcuts app. This was the first time you can really customize iOS, and it was catching on. </p>

<p>This is something people have been doing for years on jailbroken iOS and Android devices, except this time, you can do it natively on iOS.</p>

<p>As soon as I noticed the hype, I put together some <a href="https://icons.tr.af/">icons</a> in my own style, downloaded some widgets, and tried it all out. I thought it looked cool, so I shared a screenshot of it on Twitter. Right away, people started asking about the icons in the screenshot. So I quickly packaged them, uploaded them to <a href="https://gumroad.com/">Gumroad</a>, and embedded them on a <a href="https://notion.so/">Notion</a> site using <a href="https://super.so/">Super</a>. All of this took about two hours.</p>

<p>The next day, the tweet had hundreds of retweets, thousands of likes, and over 100k impressions. The day after that, almost a million. The next thing I knew, it was everywhere. My icons got published on notable tech sites like <a href="https://www.cultofmac.com/723490/ios-14-iphone-home-screen-customization/">Cult of Mac</a>, <a href="https://www.imore.com/people-are-making-real-money-selling-icon-sets-ios-14-home-screens">iMore</a>, <a href="https://allthingst3ch.com/ios14homescreen">AllThingsTech</a>, and <a href="https://gridfiti.com/aesthetic-ios-home-screen-ideas">Gridfiti</a>. I think at this time I was around the $6k mark in sales.</p>

<p>Then, MKBHD happened. He shared a <a href="https://youtu.be/cH66LWWluVE">video</a> about all of this‚Äîusing my icons for his setup, and linked them in the description. The next thing I knew, I was making $28 what felt like every 28 seconds. My phone turned into the ultimate dopamine dispenser (if it wasn't already). I had to disable notifications.</p>

<p>The day after, sales jumped from $6k to about $40k, and during the time of this writing, sales are at $116,147 from 4,188 customers.</p>

<p>All from one. Single. <a href="https://twitter.com/traf/status/1307707156788060160">Tweet</a>.</p>

<p>The right content, posted at the right time, can create unimaginable results. Although there's likely plenty of other variables that went into making this work, there are a few key insights that I think increased my odds.</p>

<h3>Publish often</h3>

<p>Continually putting things out into the world creates proof of work. The difference between where you are and where you want to be could be as little as sharing what you build, or even what you know.</p>

<p>There's only so much we can control once pushing something out into the world, but publishing often will increase your odds at finding something that sticks. They say that fortune favors the bold. In the internet age, the bold are those that aren't afraid to publish their work for the world to see. The internet is a never-ending stream of content, the idea of being annoying or over-sharing is only an idea that you invent to stop you from sharing. </p>

<h3>Act immediately</h3>

<p>I could have easily ignored the requests for the icons, or directed people to icon sets that already existed, but that would be a missed opportunity. Since I've done similar icon sets so many times already in the past, I was ready for it. Acting quickly is crucial if you plan on riding the wave. </p>

<h3>Be transparent</h3>

<p>I shared <a href="https://twitter.com/traf/status/1308158718975111175">this tweet</a> the day after posting my home screen with details of all the hype, and it created even more hype. It brought another 540,000 impressions and added fuel to an already growing fire. <strong>Share what works, and share what doesn't.</strong> Transparency is visibility.</p>

<h3>Have a clear schedule</h3>

<p>A lot of this was happening on a Monday morning. If I were working a more traditional job, or had time commitments that I had previously scheduled, I wouldn't have been able to act on my ideas as quickly as I did. I get that not everyone has the privilege of a flexible schedule, but almost anyone can start to move towards it if they want it badly enough. Freedom of a clear schedule allowed me to take action as soon as the inspiration hit, which was incredibly important to maximize exposure. Inspiration is a productivity-multiplier, but it's perishable‚Äîso act quickly.</p>

<h3>Charge more</h3>

<p>If I would have asked anyone what to price these at, most would have said $2, or maybe $5. One thing I knew for sure was that the people most likely to buy these were not the same people who were jailbreaking their iOS devices in the past. These are first time iOS customizers, so there's no notion of what an iOS icon set should be priced at.</p>

<h3>Do it for the art</h3>

<p>If I would have done this exclusively for the goal of making money, I'm convinced it wouldn't have worked nearly as well as it did. I see copycats showing up everywhere. They see success, and try to replicate exactly how it happened, but it won't work. At least not nearly as well. The reasons for this post is not to teach you how to sit on the edge of your seat, foaming at the mouth at the chance to exploit the next big internet trend, but it's to push you to keep working at the things you enjoy, share them with the world, and letting the internet do the rest.</p>

<h3>Aftermath</h3>

<p>So what came of all this? I suspect this is why most of you are here reading this, so here's a recap of everything that came from last week in numbers, from the time of this writing:</p>

<h4>Short-term metrics:</h4>

<ul><li>4,188 total icon sales</li><li>$116,147 in revenue</li><li>97% profit margins</li><li>6.2m impression</li><li>216,800 visitors</li></ul>

<h4>Long-term metrics:</h4>

<ul><li>5,216 email subscribers</li><li>4,620 Twitter followers</li><li>180 <a href="https://super.so/">Super</a> customers</li></ul>

<h3>What's next?</h3>

<p>In the same way that creating icon sets 7 years ago prepared me for last week, this whole experiment has likely prepared me for what's to come years from now.</p>

<p>The best part about this is the freedom its bought me, to keep building things that'll create even more freedom. <strong>Spending time on things that will buy you time is always a good use of it.</strong> When people buy into what ever it is you're selling, they're not only giving you money, but they're contributing to your future freedom.</p>

<p>The market will decide a huge part of what comes after sharing something, so continually increase your odds by building, publishing, then repeating. Try many things once to figure out what you want to do twice. Figure out what you've got stored in your brain that can be of value to others, then share it with the world. You might be surprised of what comes of it.</p>

<p>Thanks for reading.</p>

<p>PS. For proof that I did this in 2013, here's my <a href="https://deviantart.com/jtraf">DeviantArt profile</a>.<br>PPS. For details about the Notion/Super/Gumroad combo: <a href="https://www.makerpad.co/deep-dives/the-community-creator-how-to-run-a-low-cost-membership-community-or-creator-business-with-circle-memberspace-gumroad-notion-super-so">Makerpad deep-dive</a>.</p>

<p>‚Äî <a href="https://twitter.com/traf">@traf</a></p>
      </div></div>]]>
            </description>
            <link>https://tr.af/6</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637405</guid>
            <pubDate>Wed, 30 Sep 2020 10:59:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gitlab CI/CD for cross-platform Unreal Engine 4 projects]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24637248">thread link</a>) | @me2too
<br/>
September 30, 2020 | https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/ | <a href="https://web.archive.org/web/*/https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>Continuous Integration (CI) is an essential step in the development pipeline of well-designed software infrastructure. The goal of CI is to <strong>automatize the boring stuff</strong> by letting the developers focusing on the code and, at the same time, helping them in producing good quality software.</p>
<p>Often, we read together two acronyms (and this article makes no exception) CI &amp; CD. While CI always stands for Continuous Integration, CD has two different meanings:</p>
<ol>
<li><strong>Continuous Delivery</strong> where a developer‚Äôs change is automatically bug-tested and uploaded to a repository, or</li>
<li><strong>Continuous Deployment</strong> where a developer‚Äôs change is automatically released to the production environment, where the customer can use this brand-new version.</li>
</ol>
<p>In this article, I‚Äôm going to show you how to configure and use the CI/CD tool provided by GitLab to correctly manage the CI/CD pipeline of an <strong>Unreal Engine 4 (UE4) project</strong> that needs to work (and thus, to be tested) on 3 different platforms:</p>
<ul>
<li>Windows</li>
<li>macOS</li>
<li>Linux</li>
</ul>
<p>In the following, ‚ÄúCD‚Äù will stand for Continuous Delivery - so I won‚Äôt cover the Deployment part.</p>

<p><a href="https://about.gitlab.com/">GitLab</a> is a complete DevOps platform: it offers us a complete CI/CD toolchain, an amazing issue tracking suite, and exposes in a user-friendly-way almost every Git‚Äôs feature.</p>
<p><img src="https://pgaleone.eu/images/ciue4/cicd_pipeline_infograph.png" alt="GitLab Continuous Integration pipeline"></p>
<p>The CI/CD toolchain is composed of 3 main parts:</p>
<ul>
<li>The <code>gitlab-ci.yml</code> file that contains the configuration of the CI/CD pipeline. Using this YAML file we can configure the CI/CD behavior: what should happen on every commit or merge request, what should happen at scheduled times, and <a href="https://docs.gitlab.com/ee/ci/yaml/">many many more</a>. This file contains the commands to execute (a batch of commands is called ‚Äújob‚Äù) on the specified runner.</li>
<li><a href="https://docs.gitlab.com/runner/">GitLab Runners</a>. A runner is a software able to receive from GitLab a job, execute it, and send back the result to GitLab. Several runners can (and should) run in parallel, allowing the whole infrastructure to scale. The execution of the job is delegated to an ‚Äúexecutor‚Äù.</li>
<li><strong>The executor</strong>. During the configuration of the runner, we can specify what type of executor to use. In particular, it‚Äôs possible to use the machine where the runner is installed to run directly in its shell the commands (that‚Äôs the shell executor), or use Docker to execute the commands into a container, or even use a virtual machine or a Kubernetes cluster (for a complete reference see: https://docs.gitlab.com/runner/executors/).</li>
</ul>
<p>The amazing thing is that GitLab Runner is a software written in Go: this means that it can run perfectly on our three target platforms: Windows, macOS, and Linux.</p>
<p>Moreover, installing it is trivial as explained in <a href="https://docs.gitlab.com/runner/#install-gitlab-runner">the documentation</a>.</p>
<h2 id="executors-for-ue4-projects">Executors for UE4 projects</h2>
<p><a href="https://www.unrealengine.com/en-US/">Unreal Engine</a> is a cross-platform game engine, quoting the official website:</p>
<blockquote>
<p>Unreal Engine is the world‚Äôs most open and advanced real-time 3D creation tool. Continuously evolving to serve not only its original purpose as a state-of-the-art game engine, today it gives creators across industries the freedom and control to deliver cutting-edge content, interactive experiences, and immersive virtual worlds.</p>
</blockquote>
<p>UE4 is really an amazing project, but this amazingness comes at a cost: it‚Äôs <strong>heavy</strong>. The engine itself, <a href="https://docs.unrealengine.com/en-US/GettingStarted/DownloadingUnrealEngine/index.html">available on GitHub</a>, weights ~132GB on Linux:</p>
<div><div><pre><code><span>du</span> <span>-hs</span> /opt/unreal-engine/
132G    /opt/unreal-engine/
</code></pre></div></div>
<p>Since our goal is to create an environment that contains the compiled engine (for our three target platforms) and use it inside our CI. Using a <strong>Docker executor</strong> it is perhaps the best possible solution.</p>
<h3 id="docker-executor">Docker executor</h3>
<p>As previously stated, one of the costs of using UE4 is its size: when we have enough resources this isn‚Äôt a problem (you need a good amount of storage and a lot of memory and CPU power to compile and use the engine), and it‚Äôs not a problem even when using Docker on Linux. However, building a Docker image containing UE4 on Windows is somehow a difficult and long process, because there is a well-know and <em>unresolved</em> issue about the creation of <a href="https://github.com/moby/moby/issues/37581">filesystem layers lager than 8 GiB</a>.</p>
<p>Although there are well-known issues (only on Windows), using a Docker executor have a lot of advantages like:</p>
<ul>
<li>Spawning a container is a cheap operation.</li>
<li>Every container is isolated.</li>
<li>It is possible to scale the solution easily (easy to parallelize).</li>
<li>Customizing/Creating a Dockerfile is easy.</li>
</ul>
<p>Creating docker containers with unreal-engine inside is a challenge that <a href="https://adamrehn.com/">Adam Rehn</a> with his <a href="https://unrealcontainers.com/">Unreal Containers</a> <strong>amazingly faced</strong>.</p>
<p><img src="https://pgaleone.eu/images/ciue4/ue-plus-docker.svg" alt="UnrealContainer logo"></p>
<p>The project, and Python package, <a href="https://docs.adamrehn.com/ue4-docker/read-these-first/introduction-to-ue4-docker">ue4-docker</a> contains all we need to create a docker image that we will later on use in our <code>.gitlab-ci.yml</code> file.</p>
<p>Using <code>ue4-docker</code> creating an image is so easy as:</p>
<div><div><pre><code><span>REPO_URL</span><span>=</span><span>"&lt;set url here&gt;"</span>
<span>BRANCH</span><span>=</span><span>"&lt;set branch here&gt;"</span>
ue4-docker build custom:4.25.3 <span>-repo</span><span>=</span><span>"</span><span>$REPO_URL</span><span>"</span> <span>-branch</span><span>=</span><span>"</span><span>$BRANCH</span><span>"</span> <span>\</span>
           <span>--exclude</span> debug <span>\ </span><span># exclude debug symbols to reduce the image and workaround the windows issue</span>
           <span>--exclude</span> templates <span>\ </span><span># exclude the templates since we don't need them in our CI</span>
           <span>--exclude</span> ddc <span># exclude DDC to speed up the image creation </span>
</code></pre></div></div>
<p>The same command can be executed in a Linux and in a Windows machine. Personally, I prefer having a Linux machine that executes a docker container, instead of using a Windows machine to execute a docker container containing a Linux image (for performance reasons and to save time during the creation of the images too).</p>
<p>At the end of the execution of the <code>ue4-docker</code> command, we end up with a set of images ready to use like:</p>
<div><div><pre><code>docker images | grep ue4

adamrehn/ue4-full                           4.25.3                        01562ee9c264        9 days ago          15.6GB
adamrehn/ue4-full                           4.25.3-opengl                 01562ee9c264        9 days ago          15.6GB
adamrehn/ue4-minimal                        4.25.3                        561beaae1f0f        9 days ago          14GB
adamrehn/ue4-minimal                        4.25.3-opengl                 561beaae1f0f        9 days ago          14GB
adamrehn/ue4-engine                         4.25.3                        717a019f5917        9 days ago          85.6GB
adamrehn/ue4-engine                         4.25.3-opengl                 717a019f5917        9 days ago          85.6GB
adamrehn/ue4-source                         4.25.3                        dce5e2cdbc65        9 days ago          54.7GB
adamrehn/ue4-source                         4.25.3-opengl                 dce5e2cdbc65        9 days ago          54.7GB
adamrehn/ue4-build-prerequisites            opengl                        ec75c0a656c0        7 months ago        584MB
</code></pre></div></div>
<p>A complete description of what is inside every image is available in the <a href="https://docs.adamrehn.com/ue4-docker/building-images/available-container-images">List of available container images</a> page.</p>
<p>Using Docker we can cover the CI for the Linux and Windows platforms. macOS, instead, can‚Äôt run inside a container :( hence we have to use another executor.</p>
<h3 id="shell-executor">Shell executor</h3>
<p>The shell executor is just ‚Äúthe current machine‚Äù. Thus, we can install <a href="https://docs.gitlab.com/runner/install/osx.html">GitLab Runner on macOS</a> and manually install all the dependencies that are, in our case, only unreal engine and the Xcode toolchain.</p>
<p>Differently from the Docker executor, the Shell executor has several disadvantages:</p>
<ul>
<li>No isolation at all.</li>
<li>No native support for parallel and isolated executions.</li>
<li>It doesn‚Äôt scale well.</li>
<li>We have to clean up the dirt left by the operations we do in the CI (e.g. temporary files).</li>
</ul>
<p>The only advantage we have is the simplicity of installation: we just have to install UE4 on our machine and we are ready to go.</p>
<p>Supposing to have Unreal Engine already installed (the setup on Mac, Linux, Windows is straightforward; it‚Äôs just a matter of following the <a href="https://docs.unrealengine.com/en-US/GettingStarted/Installation/index.html">guide</a>), the only thing we need to do is to install another Python tool created by Adam Rehn: <a href="https://docs.adamrehn.com/ue4cli/overview/introduction-to-ue4cli">ue4cli</a>.</p>
<p>This Python package implements a command-line tool called <code>ue4</code>: this tool simplifies the invocation/usage of the UE4 toolchain and, perhaps more importantly, it unifies the interface we have to use on different platforms.</p>
<p>The tool is installed into the <code>ue4-full</code> images and that‚Äôs the reason we‚Äôre going to use these images in our <code>gitlab-ci.yml</code> file.</p>
<h2 id="the-cicd-pipeline">The CI/CD pipeline</h2>
<p>As introduced at the beginning of the article, after setting up the runners and the executor, we are ready to describe the CI/CD pipeline in the <code>.gitlab-ci.yml</code> file.</p>
<h3 id="continuous-integration">Continuous Integration</h3>
<p>Let‚Äôs start with the automatization of the boring stuff, we need to find a way to automatically answer these questions:</p>
<ol>
<li>Is the code following the code style / required formatting?</li>
<li>Does the code I want to merge compile correctly on every platform?</li>
<li>Am I introducing regressions?</li>
</ol>
<p>To answer all these questions, and be ready for the continuous delivery stuff, we need to define the variables and the stages (of the pipeline) we plan to execute.</p>
<div><div><pre><code><span>variables</span><span>:</span>
    <span>GIT_SUBMODULE_STRATEGY</span><span>:</span> <span>"</span><span>recursive"</span>
    <span>GIT_STRATEGY</span><span>:</span> <span>"</span><span>fetch"</span>
    <span>GIT_CHECKOUT</span><span>:</span> <span>"</span><span>true"</span>
    <span>GIT_SSL_NO_VERIFY</span><span>:</span> <span>"</span><span>1"</span>
    <span>GET_SOURCES_ATTEMPTS</span><span>:</span> <span>"</span><span>10"</span>

<span>stages</span><span>:</span>
    <span>-</span> <span>static-analysis</span>
    <span>-</span> <span>build</span>
    <span>-</span> <span>tests</span>
    <span>-</span> <span>package</span>
</code></pre></div></div>
<ul>
<li>The <strong>static-analysis</strong> stage will contain the jobs related to the source code analysis. The checks for the source code formatting (the only one presented in this article) and other checks related to the analysis of the source code itself.</li>
<li>The <strong>build</strong> stage will contain the jobs that answer question 2.</li>
<li>The <strong>test</strong> stage contains the execution of the test cases (because every unreal project uses the unreal test suite - isn‚Äôt it?)</li>
<li>The <strong>package</strong> stage contains the continuous delivery part of the pipeline.</li>
</ul>
<h5 id="static-analysis">Static Analysis</h5>
<p>Every C++ project should follow a code style. This CI job uses <code>clang-format</code> and <code>dos2unix</code> to check if every committed file has the correct encoding (we need UTF-8 encoded files to be sure that every compiler on every platform can read them well) and follows the style rules present in the <code>.clang-format</code> file that should be present into every project :)</p>
<div><div><pre><code><span>clang-format</span><span>:</span>
    <span>image</span><span>:</span> <span>alpine</span>
    <span>stage</span><span>:</span> <span>static-analysis</span>
    <span>variables</span><span>:</span>
        <span>GIT_LFS_SKIP_SMUDGE</span><span>:</span> <span>"</span><span>1"</span>
    <span># empty dependencies = do not need artifacts from previous stages</span>
    <span>dependencies</span><span>:</span> <span>[]</span>
    <span>script</span><span>:</span>
        <span>-</span> <span>apk update &amp;&amp; apk add clang git bash dos2unix</span>
        <span>-</span> <span>exclude=$(for d in $(git ‚Ä¶</span></code></pre></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/">https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/</a></em></p>]]>
            </description>
            <link>https://pgaleone.eu/cicd/unreal-engine/2020/09/30/continuous-integration-with-unreal-engine-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637248</guid>
            <pubDate>Wed, 30 Sep 2020 10:33:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Book: Epic Alignment ‚Äì How the best Product Managers work with feature documents]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24637233">thread link</a>) | @njanse
<br/>
September 30, 2020 | https://www.delibr.com/ebook | <a href="https://web.archive.org/web/*/https://www.delibr.com/ebook">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h3>What's inside</h3>
<p>How can you drive the thinking on what to develop, why and how to
do it ‚Äî leveraging the insights from both team and stakeholders ‚Äî all the way from idea to
deploy?</p>
<p>This book tries to answer the above question. As part of our own
product development at Delibr, we interviewed over 300 Product Managers to understand how they work
and collaborate around feature development, what problems they face, and the many approaches to
solving those problems. </p>
<p>"Epic alignment" describes four broad approaches that we saw help
Product Managers excel.</p>
<h3>What you'll learn</h3>
<ul>
<li>How to drive product development towards impact based on research</li>
<li>How to use user stories as a shared language to align your entire team</li>
<li>How to write feature documents that drive joint understanding and act as a single source of
truth
</li>
<li>How to tackle the massive amounts of decisions needed for every epic</li>
</ul>
</div></div>]]>
            </description>
            <link>https://www.delibr.com/ebook</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637233</guid>
            <pubDate>Wed, 30 Sep 2020 10:29:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Most popular GraphgQL server implementations]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24637210">thread link</a>) | @oczek
<br/>
September 30, 2020 | https://blog.graphqleditor.com/graphql-servers/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/graphql-servers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>GraphQL is a query language for APIs that describes how to ask &amp; fetch the data from the server to the client which of course requires setting up a server. Below you will find a list of the most popular GraphgQL server implementations. There‚Äôs quite a few of them so we‚Äôre not going to get through the lot of them in one go.</p>
<h2>Express GraphQL</h2>
<p>It is said that <a href="https://github.com/graphql/express-graphql">Express GraphQL</a> is the simplest way to run a GraphQL API server. Express is a popular web application framework for Node.js allowing you to create a GraphQL server with any HTTP web framework supporting connect styled middleware including <a href="https://expressjs.com/">Express</a>, <a href="http://restify.com/">Restify</a> and, of course, <a href="https://github.com/senchalabs/connect">Connect</a>. Getting started is as easy as installing some additional dependencies in form of <code>npm install express express-graphql graphql --save</code></p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/21b4d/express.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Express GraphQL" title="Express GraphQL" src="https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/fcda8/express.png" srcset="https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/12f09/express.png 148w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/e4a3f/express.png 295w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/fcda8/express.png 590w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/efc66/express.png 885w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/c83ae/express.png 1180w,
https://blog.graphqleditor.com/static/d8c5b170d7059b55a31da3c1de450fb5/21b4d/express.png 1280w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://graphql.org/graphql-js/running-an-express-graphql-server/">graphql.org</a></h5>
<h2>Apollo GraphQL Server</h2>
<p><a href="https://github.com/apollographql/apollo-server">Apollo GraphQL Server</a> is an open-source GraphQL server compatible with any GraphQL client and it‚Äôs an easy way to build a production-ready, self-documenting GraphQL API that can use data from any source. Apollo Server can be used as a stand-alone GraphQL server, a plugin to your application‚Äôs Node.js middleware, or as a gateway for a federated data graph. Apollo GraphQL Server offers:</p>
<ul>
<li><strong>easy setup</strong> - client-side can start fetching data instantly,</li>
<li><strong>incremental adoption</strong> - elastic approach to adding new features, you can add them easily later on when you decide they‚Äôre needed,</li>
<li><strong>universality</strong> - compatibility with any data source, multiple
build tools and GraphQL clients,</li>
<li><strong>production-ready</strong> - tested across various enterprise-grade projects.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/23266/apollo.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Apollo GraphQL Server" title="Apollo GraphQL Server" src="https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/fcda8/apollo.png" srcset="https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/12f09/apollo.png 148w,
https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/e4a3f/apollo.png 295w,
https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/fcda8/apollo.png 590w,
https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/efc66/apollo.png 885w,
https://blog.graphqleditor.com/static/b7f98cac82ca2ea3fce952f1f25867a3/23266/apollo.png 923w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://github.com/apollographql/apollo-server">apollographql.com</a></h5>
<h2>Hot Chocolate</h2>
<p><a href="https://hotchocolate.io/">Hot Chocolate</a> is a GraphQL server you can use to create GraphQL endpoints,  merge schemas, etc. Hot Chocolate is a part of a .NET based <a href="https://github.com/ChilliCream/hotchocolate">ChilliCream GraphQL Platform</a> that can help you build a GraphQL layer over your existing and new infrastructure. It provides pre-built templates that let you start in seconds, supporting both ASP.Net Core as well as ASP.Net Framework out of the box.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/23266/hotchoc.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Hot Chocolate is a part of ChilliCream GraphQL Platform" title="Hot Chocolate is a part of ChilliCream GraphQL Platform" src="https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/fcda8/hotchoc.png" srcset="https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/12f09/hotchoc.png 148w,
https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/e4a3f/hotchoc.png 295w,
https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/fcda8/hotchoc.png 590w,
https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/efc66/hotchoc.png 885w,
https://blog.graphqleditor.com/static/0e8f4aada898797c50c04bb75e6a98ec/23266/hotchoc.png 923w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://github.com/ChilliCream/hotchocolate">github.com/ChilliCream/hotchocolate</a></h5>
<h2>Hasura GraphQL Engine</h2>
<p><a href="https://github.com/hasura/graphql-engine">Hasura GraphQL Engine</a> is a GraphQL server that gives you realtime GraphQL APIs over Postgres, making easy building your new Postgress-backed GraphQL app or adding a GraphQL layer for your existing Postgres bases app.  Hasura GraphQL Engine offers built-in filtering, pagination, merging remote schemas along with many other useful features. All that keeping high-performance &amp; footprint at the lowest possible rate.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/d9199/hasura.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Hasura GraphQL Engine" title="Hasura GraphQL Engine" src="https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/fcda8/hasura.png" srcset="https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/12f09/hasura.png 148w,
https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/e4a3f/hasura.png 295w,
https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/fcda8/hasura.png 590w,
https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/efc66/hasura.png 885w,
https://blog.graphqleditor.com/static/522960eb8b0af0ea8789fac5f6c91c9b/d9199/hasura.png 960w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://github.com/hasura/graphql-engine">github.com/hasura</a></h5>
<h2>API PLATFORM</h2>
<p><a href="https://github.com/api-platform/api-platform">API Platform</a> is a set of tools that combined build a modern framework for building REST and GraphQL APIs including GraphQL Server. The server solution is located in the API Platform Core Library which is built on top of Symfony 4 (PHP) microframework and the Doctrine ORM. API Platform Core Library is a highly flexible solution allowing you to build fully-featured GraphQL API in minutes.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/2cefc/apiplatform.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="API PLATFORM" title="API PLATFORM" src="https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/fcda8/apiplatform.png" srcset="https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/12f09/apiplatform.png 148w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/e4a3f/apiplatform.png 295w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/fcda8/apiplatform.png 590w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/efc66/apiplatform.png 885w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/c83ae/apiplatform.png 1180w,
https://blog.graphqleditor.com/static/06c54d11146913c58117559a32674596/2cefc/apiplatform.png 1400w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://api-platform.com/">api-platform.com</a></h5>
<h2>Parse Server GraphQL API</h2>
<p>In addition to the traditional REST API, Parse Server automatically generates a GraphQL API basing on a given schema. <a href="https://docs.parseplatform.org/graphql/guide/">Parse Server GraphQL API</a> follows Relay specification along with the latest industry standards which makes it a perfect choice for modern projects requiring the highest-scalability.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/00d43/parse.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Parse Server GraphQL API " title="Parse Server GraphQL API " src="https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/fcda8/parse.png" srcset="https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/12f09/parse.png 148w,
https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/e4a3f/parse.png 295w,
https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/fcda8/parse.png 590w,
https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/efc66/parse.png 885w,
https://blog.graphqleditor.com/static/48c5fb34b2f1914c334930add2472828/00d43/parse.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h5>Source: <a href="https://docs.parseplatform.org/graphql/guide/">docs.parseplatform.org/graphql/guide</a></h5>
<p>That‚Äôs it for the first look at GraphQL servers. So if I missed your favorite one, just mention it in the comments and stay tuned for the next parts!</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/graphql-servers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637210</guid>
            <pubDate>Wed, 30 Sep 2020 10:26:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Commodore 64 Program Discovered on 35-Year Old Vinyl Album (2019)]]>
            </title>
            <description>
<![CDATA[
Score 204 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24637146">thread link</a>) | @clockworksoul
<br/>
September 30, 2020 | https://popcultureretrorama.com/2019/11/25/35-years-later-a-commodore-64-program-was-found-on-this-1984-album/ | <a href="https://web.archive.org/web/*/https://popcultureretrorama.com/2019/11/25/35-years-later-a-commodore-64-program-was-found-on-this-1984-album/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1304">
	
	<div>
		
<p>Friends, this should give you a little boost at the end of your day ‚Äì because 8-Bit Show and Tell has located a Commodore 64 program hidden within Prodigal‚Äôs 1984 album entitled Electric Eye. I was just goofing around on YouTube when I came across this video ‚Äì which was originally uploaded back on October 19th of this year. Since I have been known to talk about my love of the Commdore 64 computer of my youth ‚Äì the title of the video caught my attention pretty quickly. And seriously, how absolutely amazing is it that in this day and age we can still be surprised by little Easter eggs from 35 years ago? As Robin will demonstrate on the video itself the program was hidden in the runout groove on the B side of <em>Electric Eye</em>  ‚Äì which you can plainly see in this article image header has a ‚ÄúC-64‚Äù scratched into said groove. Probably one of the reasons that not a lot of people know about the program is because it needed to be played on your turntable where you could record the hidden program on a cassette tape to upload it on your C64‚Ä¶ that is a little bit of work. As the video will show ‚Äì sometimes using older technology takes a couple of tries ‚Äì or even totally different equipment in some cases.</p>







<p>I will have to in the near future share an article about the Mattel Electronics Aquarius computer that we obtained at the arcade ‚Äì in fact I talked just a bit about it in the <em><a href="https://popcultureretrorama.com/2019/11/24/diary-of-an-arcade-employee-podcast-1up-night-stalker/">Night Stalker</a></em> podcast earlier today. Robin was able to make contact with one of the surviving members of <strong>Prodigal</strong> by the way ‚Äì which was a Christian rock group, active from 1975 until 1986 ‚Äì to ask how and why this 35 year-old computer program was included on the <em>Electric Eye</em> album. </p>



<div><figure><img data-attachment-id="1306" data-permalink="https://popcultureretrorama.com/2019/11/25/35-years-later-a-commodore-64-program-was-found-on-this-1984-album/35-years-later-a-commodore-64-program-electric-eye/" data-orig-file="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?fit=700%2C394&amp;ssl=1" data-orig-size="700,394" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="35-Years-Later-A-Commodore-64-Program-Electric-Eye" data-image-description="" data-medium-file="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?fit=640%2C360&amp;ssl=1" loading="lazy" width="640" height="360" src="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=640%2C360&amp;ssl=1" alt="" srcset="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?w=700&amp;ssl=1 700w, https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=150%2C84&amp;ssl=1 150w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?w=700&amp;ssl=1 700w, https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=150%2C84&amp;ssl=1 150w" data-lazy-src="https://i0.wp.com/popcultureretrorama.com/wp-content/uploads/2019/11/35-Years-Later-A-Commodore-64-Program-Electric-Eye.jpg?resize=640%2C360&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>The discovery of what amounts to a simple message from <strong>Prodigal</strong> 35 years later might not be the most groundbreaking thing you‚Äôll see today‚Ä¶ but I thought it was special enough that I had to share it. Watching this particular 8-Bit Show and Tell video will in addition show you how to hack your turntable to disable the auto return if you need to!</p>



<figure><p><span><iframe width="640" height="360" src="https://www.youtube.com/embed/6_CZpFqvDQo?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

			<div>
	
	<p>
		An avid devotee to pretty much all things pop culture and retro related - I love to share my memories and passion for films, comics, gaming, podcasting... and curiously enough my overwhelming desire to never stop eating beef jerky.		<a href="https://popcultureretrorama.com/author/vicsagepopculture/" rel="author">
			View more posts		</a>
	</p><!-- .author-description -->
</div><!-- .author-bio -->
	
</article></div>]]>
            </description>
            <link>https://popcultureretrorama.com/2019/11/25/35-years-later-a-commodore-64-program-was-found-on-this-1984-album/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637146</guid>
            <pubDate>Wed, 30 Sep 2020 10:13:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief Guide to OTP in Elixir]]>
            </title>
            <description>
<![CDATA[
Score 229 | Comments 89 (<a href="https://news.ycombinator.com/item?id=24637121">thread link</a>) | @NaeosPsy
<br/>
September 30, 2020 | https://serokell.io/blog/elixir-otp-guide | <a href="https://web.archive.org/web/*/https://serokell.io/blog/elixir-otp-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One of the main advantages of Elixir is that it is awesome for server-side systems. Forget using a million different technologies for things like data persistence, background jobs, and service crash recovery, OTP can supply you with everything.</p><p><em>So what exactly is this magical thing?</em></p><p>In this article, I will introduce you to OTP, look at basic process loops, the GenServer and Supervisor behaviours, and see how they can be used to implement an elementary process that stores funds.</p><p>(This article assumes that you are already familiar with the basics of Elixir. If you‚Äôre not, you can check out the <a href="https://elixir-lang.org/getting-started/introduction.html">Getting Started guide</a> on Elixir‚Äôs website or use one of the other resources listed in our <a href="https://serokell.io/blog/learn-elixir">Elixir guide</a>.)</p><h2 id="what-is-otp%3F">What is OTP?</h2><p>OTP is an awesome set of tools and libraries that Elixir inherits from Erlang, <a href="https://serokell.io/blog/history-of-erlang-and-elixir">a programming language on whose VM it runs</a>.</p><p>OTP contains a lot of stuff, such as the Erlang compiler, databases, test framework, profiler, debugging tools. But, when we talk about OTP in the context of Elixir, we usually mean the Erlang actor model that is based on lightweight processes and is the basis of what makes Elixir so efficient.</p><h2 id="processes">Processes</h2><p><img src="https://serokell.io/files/dg/dg0wowcg.processes_(1).jpg" alt="Processes divider"></p><p>At the foundation of OTP, there are tiny things called processes.</p><p>Unlike OS processes, they are really, really lightweight. Creating them takes microseconds, and a single machine can easily run multiple thousands of them, simultaneously.</p><p>Processes loosely follow the <a href="https://en.wikipedia.org/wiki/Actor_model">actor model</a>. Every process is <em>basically</em> a mailbox that can receive messages, and in response to those messages it can:</p><ul>
<li>Create new processes.</li>
<li>Send messages to other processes.</li>
<li>Modify its private state.</li>
</ul><p><img src="https://serokell.io/files/j1/j1smm7kp.process.jpg" alt="Process graph"></p><h3 id="spawning-processes">Spawning processes</h3><p>The most basic way to spawn a process is with the spawn command. Let‚Äôs open IEx and launch one.</p><pre><code>iex(<span>1</span>)&gt; process = spawn(<span>fn</span> -&gt; IO.puts(<span>"hey there!"</span>) <span>end</span>)
</code></pre><p>The above function will return:</p><pre><code>hey there!

</code></pre><p>First is the result of the function, second is the output of spawn ‚Äì PID, a unique process identification number.</p><p>Meanwhile, we have a problem with our process. While it did the task we asked it to do, it seems like it is now‚Ä¶ dead? üò±</p><p>Let‚Äôs use its PID (stored in the variable <code>process</code>) to query for life signs.</p><pre><code>iex(<span>2</span>)&gt; Process.alive?(process)
<span>false</span>
</code></pre><p>If you think about it, it makes sense. The process did what we asked it to do, fulfilled its reason for existence, and closed itself. But there is a way to extend the life of the process to make it more worthwhile for us.</p><h3 id="receive-do-loop">Receive-do loop</h3><p>Turns out, we can extend the process function to a loop that can hold state and modify it.</p><p>For example, let‚Äôs imagine that we need to create a process that mimics the funds in a palace treasury. We‚Äôll create a simple process to which you can store or withdraw funds, and ask for the current balance.</p><p>We‚Äôll do that by creating a loop function that responds to certain messages while keeping the state in its argument.</p><pre><code><span><span>defmodule</span> <span>Palace</span></span>.SimpleTreasury <span>do</span>

  <span><span>def</span> <span>loop</span></span>(balance) <span>do</span>
      receive <span>do</span>
        {<span>:store</span>, amount} -&gt;
          loop(balance + amount)
        {<span>:withdraw</span>, amount} -&gt;
          loop(balance - amount)
        {<span>:balance</span>, pid} -&gt;
          send(pid, balance)
          loop(balance)
      <span>end</span>
    <span>end</span>
<span>end</span>
</code></pre><p>In the body of the function, we put the receive statement and pattern match all the messages we want our process to respond to. Every time the loop runs, it will check from the bottom of the mailbox (in order they were received) for messages that match what we need and process them.</p><p>If the process sees any messages with atoms <code>store</code>, <code>withdraw</code>, <code>balance</code>, those will trigger certain actions.</p><p>To make it a bit nicer, we can add an <code>open</code> function and also dump all the messages we don‚Äôt need to not pollute the mailbox.</p><pre><code><span><span>defmodule</span> <span>Palace</span></span>.SimpleTreasury <span>do</span>

  <span><span>def</span> <span>open</span></span>() <span>do</span>
    loop(<span>0</span>)
  <span>end</span>

  <span><span>def</span> <span>loop</span></span>(balance) <span>do</span>
    receive <span>do</span>
      {<span>:store</span>, amount} -&gt;
        loop(balance + amount)
      {<span>:withdraw</span>, amount} -&gt;
        loop(balance - amount)
      {<span>:balance</span>, pid} -&gt;
        send(pid, balance)
        loop(balance)
      <span>_</span> -&gt;
        loop(balance)
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre><p>While this seems quite concise, there‚Äôs already some boilerplate lurking, and we haven‚Äôt even covered corner cases, tracing, and reporting that would be necessary for production-level code.</p><p>In real life, we don‚Äôt need to write code with receive do loops. Instead, we use one of the behaviours created by people much smarter than us.</p><h2 id="behaviours">Behaviours</h2><p>Many processes follow certain similar  patterns. To abstract over these patterns, we use behaviours. Behaviours have two parts: abstract code that we don‚Äôt have to implement and a callback module that is implementation-specific.</p><p>In this article, I will introduce you to <a href="https://hexdocs.pm/elixir/GenServer.html">GenServer</a>, short for <em>generic server</em>, and <a href="https://hexdocs.pm/elixir/Supervisor.html">Supervisor</a>. Those are not the only behaviours out there, but they certainly are one of the most common ones.</p><h3 id="genserver">GenServer</h3><p><img src="https://serokell.io/files/za/za1kwa33.genserver.jpg" alt="GenServer divider"></p><p>To start off, let‚Äôs create a module called <code>Treasury</code>, and add the GenServer behaviour to it.</p><pre><code><span><span>defmodule</span> <span>Palace</span></span>.Treasury <span>do</span>
  <span>use</span> GenServer
<span>end</span>
</code></pre><p>This will pull in the necessary boilerplate for the behaviour. After that, we need to implement the callbacks for our specific use case.</p><p>Here‚Äôs what we will use for our basic implementation.</p><table>
  <tbody><tr>
   <td>Callback
   </td>
   <td>What it does
   </td>
   <td>What it <em>usually</em> returns
   </td>
  </tr>
  <tr>
   <td><code>init(state)</code>
   </td>
   <td>Initializes the server.
   </td>
   <td><code>{:ok, state}</code>
   </td>
  </tr>
  <tr>
   <td><code>handle_cast(pid, message)</code>
   </td>
   <td>An async call that doesn‚Äôt demand an answer from the server.
   </td>
   <td><code>{:noreply, state}</code>
   </td>
  </tr>
  <tr>
   <td><code>handle_call(pid, from, message)</code>
   </td>
   <td>A synchronous call that demands an answer from the server.
   </td>
   <td><code>{:reply, reply, state}</code>
   </td>
  </tr>
</tbody></table><p>Let‚Äôs start with the easy one ‚Äì <code>init</code>. It takes a state and starts a process with that state.</p><pre><code> <span><span>def</span> <span>init</span></span>(balance) <span>do</span>
   {<span>:ok</span>, balance}
 <span>end</span> 
</code></pre><p>Now, if you look at the simple code we wrote with <code>receive</code>, there are two types of triggers. The first one (<code>store</code> and <code>withdraw</code>)  just asks for the treasury to update its state asynchronously, while the second one (<code>get_balance</code>) waits for an answer. <code>handle_cast</code> can handle the async ones, while <code>handle_call</code>can handle the synchronous one.</p><p>To handle adding and subtracting, we will need two casts. These take a message with the command and the transaction amount and update the state.</p><pre><code><span><span>def</span> <span>handle_cast</span></span>({<span>:store</span>, amount}, balance) <span>do</span>
  {<span>:noreply</span>, balance + amount}
<span>end</span>

<span><span>def</span> <span>handle_cast</span></span>({<span>:withdraw</span>, amount}, balance) <span>do</span>
  {<span>:noreply</span>, balance - amount}
<span>end</span>
</code></pre><p>Finally, <code>handle_call</code>takes the balance call, the caller, and state, and uses all that to reply to the caller and return the same state.</p><pre><code><span><span>def</span> <span>handle_call</span></span>(<span>:balance</span>, _from, balance) <span>do</span>
  {<span>:reply</span>, balance, balance}
<span>end</span>
</code></pre><p>These are all the callbacks we have:</p><pre><code><span><span>defmodule</span> <span>Palace</span></span>.Treasury <span>do</span>
  <span>use</span> GenServer

  <span><span>def</span> <span>init</span></span>(balance) <span>do</span>
    {<span>:ok</span>, balance}
  <span>end</span>

  <span><span>def</span> <span>handle_cast</span></span>({<span>:store</span>, amount}, balance) <span>do</span>
    {<span>:noreply</span>, balance + amount}
  <span>end</span>

  <span><span>def</span> <span>handle_cast</span></span>({<span>:withdraw</span>, amount}, balance) <span>do</span>
    {<span>:noreply</span>, balance - amount}
  <span>end</span>

  <span><span>def</span> <span>handle_call</span></span>(<span>:balance</span>, _from, balance) <span>do</span>
    {<span>:reply</span>, balance, balance}
  <span>end</span>
<span>end</span>
</code></pre><p>To hide the implementation details, we can add client commands in the same module. Since this will be the only treasury of the palace, let‚Äôs also give a name to the process equal to its module name when spawning it with <code>start_link.</code>This will make it easier to refer to it.</p><pre><code><span><span>defmodule</span> <span>Palace</span></span>.Treasury <span>do</span>
  <span>use</span> GenServer

  

  <span><span>def</span> <span>open</span></span>() <span>do</span>
    GenServer.start_link(__MODULE_<span>_</span>, <span>0</span>, <span>name:</span> __MODULE_<span>_</span>)
  <span>end</span>

  <span><span>def</span> <span>store</span></span>(amount) <span>do</span>
    GenServer.cast(__MODULE_<span>_</span>, {<span>:store</span>, amount})
  <span>end</span>

  <span><span>def</span> <span>withdraw</span></span>(amount) <span>do</span>
    GenServer.cast(__MODULE_<span>_</span>, {<span>:withdraw</span>, amount})
  <span>end</span>

  <span><span>def</span> <span>get_balance</span></span>() <span>do</span>
    GenServer.call(__MODULE_<span>_</span>, <span>:balance</span>)
  <span>end</span>

  

  <span><span>def</span> <span>init</span></span>(balance) <span>do</span>
    {<span>:ok</span>, balance}
  <span>end</span>

  <span><span>def</span> <span>handle_cast</span></span>({<span>:store</span>, amount}, balance) <span>do</span>
    {<span>:noreply</span>, balance + amount}
  <span>end</span>

  <span><span>def</span> <span>handle_cast</span></span>({<span>:withdraw</span>, amount}, balance) <span>do</span>
    {<span>:noreply</span>, balance - amount}
  <span>end</span>

  <span><span>def</span> <span>handle_call</span></span>(<span>:balance</span>, _from, balance) <span>do</span>
    {<span>:reply</span>, balance, balance}
  <span>end</span>
<span>end</span>
</code></pre><p>Let‚Äôs try it out:</p><pre><code><span><span>iex</span><span>(<span>1</span>)</span></span>&gt; Palace<span>.Treasury</span><span>.open</span>()
{:ok, #PID&lt;<span>0.138</span>.<span>0</span>&gt;}
<span><span>iex</span><span>(<span>2</span>)</span></span>&gt; Palace<span>.Treasury</span><span>.store</span>(<span>400</span>)
:ok
<span><span>iex</span><span>(<span>3</span>)</span></span>&gt; Palace<span>.Treasury</span><span>.withdraw</span>(<span>100</span>)
:ok
<span><span>iex</span><span>(<span>4</span>)</span></span>&gt; Palace<span>.Treasury</span><span>.get_balance</span>()
<span>300</span>
</code></pre><p>It works. ü•≥</p><p>Here‚Äôs <a href="https://elixir-lang.org/cheatsheets/gen-server.pdf">a cheatsheet on GenServer</a> to help you remember where to put what.</p><h3 id="supervisor">Supervisor</h3><p><img src="https://serokell.io/files/7j/7jpa2q4j.supervisor_(1).jpg" alt="Supervisor divider"></p><p>However, just letting a treasury run without supervision is a bit irresponsible, and a good way to lose your funds or your head. üòÖ</p><p>Thankfully, OTP provides us with the <a href="https://hexdocs.pm/elixir/Supervisor.html">supervisor behaviour</a>. Supervisors can:</p><ul>
<li>start and shutdown applications,</li>
<li>provide fault tolerance by restarting crashed processes,</li>
<li>be used to make a hierarchical supervision structure, called a <em>supervision tree</em>.</li>
</ul><p>Let‚Äôs equip our treasury with a simple supervisor.</p><pre><code><span><span>defmodule</span> <span>Palace</span></span>.Treasury.Supervisor <span>do</span>
  <span>use</span> Supervisor

  <span><span>def</span> <span>start_link</span></span>(init_arg) <span>do</span>
    Supervisor.start_link(__MODULE_<span>_</span>, init_arg,  <span>name:</span> __MODULE_<span>_</span>)
  <span>end</span>

  <span><span>def</span> <span>init</span></span>(_init_arg) <span>do</span>
    children = [
      %{
       <span>id:</span> Palace.Treasury,
       <span>start:</span> {Palace.Treasury, <span>:open</span>, []}
      }
    ]   


    Supervisor.init(children, <span>strategy:</span> <span>:one_for_one</span>)
  <span>end</span>
<span>end</span>
</code></pre><p>In its most basic, a supervisor has two functions: <code>start_link()</code>, which runs the supervisor as a process, and <code>init</code>, which provides the arguments necessary for the supervisor to initialize.</p><p>Things we need to pay attention to are:</p><ul>
<li><strong>The list of children.</strong> Here, we list all the processes that we want the supervisor to start, together with their init functions and starting arguments. Each of the processes is a map, with at least the <code>id</code>and <code>start</code> keys in it.</li>
<li><strong>Supervisor‚Äôs <code>init</code> function.</strong> To it, we supply the list of children processes and a supervision strategy. Here, we use <code>:one_for_one</code>‚Äì if a child process will crash, only that process will be restarted. There are <a href="https://hexdocs.pm/elixir/Supervisor.html#module-strategies">a few more</a>.</li>
</ul><p>Running the <code>Palace.Treasury.Supervisor.start_link()</code> function will open a treasury, which will be supervised by the process. If the treasury crashes, it will get restarted with the initial state ‚Äì 0.</p><p>If we wanted, we could add several other processes to this supervisor that are relevant to the treasury function, such as a process that can exchange looted items for their monetary value.</p><p>Additionally, we could also duplicate or persist the state of the treasury ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serokell.io/blog/elixir-otp-guide">https://serokell.io/blog/elixir-otp-guide</a></em></p>]]>
            </description>
            <link>https://serokell.io/blog/elixir-otp-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24637121</guid>
            <pubDate>Wed, 30 Sep 2020 10:08:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It Is Never a Compiler Bug Until It Is]]>
            </title>
            <description>
<![CDATA[
Score 244 | Comments 130 (<a href="https://news.ycombinator.com/item?id=24636326">thread link</a>) | @nullc
<br/>
September 30, 2020 | http://r6.ca/blog/20200929T023701Z.html | <a href="https://web.archive.org/web/*/http://r6.ca/blog/20200929T023701Z.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Last week I was trying to add some <a href="https://github.com/bitcoin-core/secp256k1/pull/822/commits/aa833603a6b4c947c21da04aeac40d80444ebcc1#diff-b04459e37839cd223176618536295715R425">testing code to libsecp256k1</a> and I was pulling out my hair trying to get it to work.
No amount of <code>printf</code> was working to illuminate what I was doing wrong.
Finally, out of desperation, I thought I would do a quick check to see if there are any compiler bugs related to <code>memcmp</code>, and lo and behold, I found <a href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=95189">GCC bug #95189: memcmp being wrongly stripped like strcmp</a>.</p><p>Honestly this was a pretty horrifying bug to read about.
Under some circumstances GCC 9 and 10 will cause <code>memcmp</code> to return an incorrect value when one of the inputs is statically known array that contains <code>NULL</code> bytes.
As I rushed to <a href="https://gist.githubusercontent.com/roconnor/2b8e22e829ed80088ed6690cc3c7f3a8/raw/455571a6d9053c597c1585debe6f9dbd6af85071/gistfile1.txt">recompile my computer system using GCC 8</a>, I contemplated the vast consequences of such a bug could be, and pondered how it was possible that computers could function at all.</p><p>However over the week, with the help of my colleagues, we managed to get a better understanding of the scope of the bug.
The bug can only convert non-zero values to zero values.
The static array needs to have a <code>NULL</code> byte within the first 4 bytes.
Most importantly, the <code>memcmp</code> result must not immediately be compared to <code>0</code> for equality or inequality, or any equivalent test.
A different code path is taken in the compiler in that case.
That explained why computers were still functioning.
I expect the vast majority of the uses of <code>memcmp</code> does an immediate test for equality with <code>0</code>.</p><p>I still wondered though, how much code was being affected. My colleague Tim suggested that it would be possible to instrument GCC to emit a message when it was about to miscompile a program.
Together we came up with <a href="https://gcc.gnu.org/bugzilla/attachment.cgi?id=49276&amp;action=diff">a patch</a> to GCC 9 and 10 that would print a debugging message.
Once again, I recompiled my entire system, to see what GCC was miscompiling.
This is what I found:</p><ul>
<li><a href="https://github.com/unicode-org/icu/blob/4fb47b12a70737ee12326220e71c2d73c5ec658f/icu4c/source/common/uniset_props.cpp#L709">https://github.com/unicode-org/icu/blob/4fb47b12a70737ee12326220e71c2d73c5ec658f/icu4c/source/common/uniset_props.cpp#L709</a></li>
<li><a href="https://github.com/xiph/flac/blob/ce6dd6b5732e319ef60716d9cc9af6a836a4011a/src/flac/decode.c#L1310">https://github.com/xiph/flac/blob/ce6dd6b5732e319ef60716d9cc9af6a836a4011a/src/flac/decode.c#L1310</a></li>
<li><a href="https://github.com/torvalds/linux/blob/fb0155a09b0224a7147cb07a4ce6034c8d29667f/drivers/atm/zatm.c#L1172">https://github.com/torvalds/linux/blob/fb0155a09b0224a7147cb07a4ce6034c8d29667f/drivers/atm/zatm.c#L1172</a></li>
<li><a href="https://github.com/nss-dev/nss/blob/1f3746f5107535a47bb4e3969f561e1bd1314bab/gtests/pk11_gtest/pk11_chacha20poly1305_unittest.cc#L425">https://github.com/nss-dev/nss/blob/1f3746f5107535a47bb4e3969f561e1bd1314bab/gtests/pk11_gtest/pk11_chacha20poly1305_unittest.cc#L425</a></li>
<li><a href="https://github.com/GNOME/glib/blob/010569b3734f864fcf584f771915b78bd391eb5f/glib/tests/refstring.c#L70">https://github.com/GNOME/glib/blob/010569b3734f864fcf584f771915b78bd391eb5f/glib/tests/refstring.c#L70</a></li>
<li><a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L390">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L390</a>, <a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L661">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L661</a>, <a href="https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L1279">https://github.com/heimdal/heimdal/blob/7ae2dfd853c87f9cbecb6f399de4dad09bad4606/lib/gssapi/krb5/arcfour.c#L1279</a></li>
<li><a href="https://github.com/zeromq/libzmq/blob/22d218a182855f28038e865cb75bf5897ff0c786/tests/test_mock_pub_sub.cpp#L203">https://github.com/zeromq/libzmq/blob/22d218a182855f28038e865cb75bf5897ff0c786/tests/test_mock_pub_sub.cpp#L203</a></li>
<li><a href="https://github.com/pigoz/mplayer-svn/blob/8d651873a9eb193f5155ffb51ece206f187cf00f/sub/sub_cc.c#L391-L412">https://github.com/pigoz/mplayer-svn/blob/8d651873a9eb193f5155ffb51ece206f187cf00f/sub/sub_cc.c#L391-L412</a></li>
</ul>
<p>On my entire system I only found 10 lines of code that were miscompiled.
Three lines are tests.
All of the lines could be rewritten as a comparison to 0.
None of the lines looked that serious.
I am not sure which one is the worse: the reduced message integrity code(?) from some ARCFOUR implementation or the something something from an ATM driver?</p><p>The mplayer miscompilation is the most mysterious.
The code surrounding that function all appears to be immediately compare <code>memcmp</code> with <code>0</code>.
And given that my debug message refused to point to exactly what line is being miscompiled in that function, I fear some set of optimizations has happened to allow this code to be miscompiled in some way.</p><p>With more hardware I could do <a href="https://hydra.nixos.org/jobset/nixpkgs/trunk#tabs-jobs">a more thorough investigation</a> of the consequences of this GCC bug.
Until then I am going to stick with GCC 8 until GCC 9 and 10 have a new point releases.

</p></div></div>]]>
            </description>
            <link>http://r6.ca/blog/20200929T023701Z.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636326</guid>
            <pubDate>Wed, 30 Sep 2020 07:01:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding How UUIDs Are Generated]]>
            </title>
            <description>
<![CDATA[
Score 160 | Comments 58 (<a href="https://news.ycombinator.com/item?id=24636204">thread link</a>) | @aryamansharda
<br/>
September 29, 2020 | https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/ | <a href="https://web.archive.org/web/*/https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="mainEntityOfPage">
<h2><strong>Introduction</strong></h2>
<p>You‚Äôve likely used UUIDs in projects before and assumed them to be unique. Today, we‚Äôll take a look at the main aspects of the implementation and understand why UUIDs are <em>practically </em>unique, though an incredibly small potential for duplication exists.&nbsp;</p>
<p>The modern day implementation of UUIDs can be tied back to <a href="https://tools.ietf.org/html/rfc4122" target="_blank" rel="noreferrer noopener">RFC 4122 </a>which introduced 5 different approaches for generating these identifiers. We‚Äôll take a look at each one and we‚Äôll step through the implementation details of Version 1 &amp; Version 4 in a moment.&nbsp;</p>
<h2><strong>Background</strong></h2>
<p>UUIDs, or universally unique IDentifiers, are simply a 128 bit number used to uniquely identify items in software development. Their canonical textual representation is as a series of 32 hexadecimal characters which are separated into five groups by hyphens in the form 8-4-4-4-12.&nbsp;</p>
<p>For example,&nbsp;</p>
<p><code>3422b448-2460-4fd2-9183-8000de6f8343</code></p>
<p>Embedded inside this seemingly random series of hexadecimal characters is information about the UUID implementation.&nbsp;</p>
<p><code>xxxxxxxx-xxxx-<strong>M</strong>xxx-<strong>N</strong>xxx-xxxxxxxxxxxx</code></p>
<p>The values in the M and N locations uniquely identify the UUID version and variant respectively.</p>
<h4><strong>Version</strong></h4>
<p>The version number is identified by looking at the most significant 4 bits of the value in the M position.&nbsp;</p>
<p>The following table lists the currently defined versions:</p>
<div><figure><img src="https://lh3.googleusercontent.com/1ePxhp-OP2JdmdHVLd3rbfDc9dcNP5J9QQncT0bYPdJ5W3_2pAHfGZ9a7Q7m3mav6VA1syO22nTIavepVicTMW9YxqiuGcSePUOanJeyz67K_bZwDbd_KO25oLgPirr53qj1wZq9" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<h4><strong>&nbsp;Variant</strong></h4>
<p>The variant field determines the layout of the information embedded in the UUID. The interpretation of all other bits in the UUID depends on the value of the variant.&nbsp;</p>
<p>We identify the variant by considering the first 1-3 most significant bits of N.&nbsp;</p>
<div><figure><img src="https://lh3.googleusercontent.com/FeXxFJcHdVVJA7IorpHtQx67F3eiSkMJVAr2Q5E4t3IierXggi-DR1uthMBOgRBXRP4JzcdRMuHbVqMMkCWZ47fo7sUO8sDBQcwgALwr45qLdpC9bSUBoXKQF9Bhdnnc9kN-g8p9" alt="" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<p>The most common implementation nowadays is Variant 1 where the MSB0&nbsp; is fixed as 1 and MSB1 is fixed as 0. This means that considering our wildcard values ‚Äì the bits marked with an <code>x</code> above ‚Äì the only possible values are 8, 9, A, or B.</p>
<blockquote><p><strong>Quick Reminder:&nbsp;</strong></p><p>1 0 0 0 = 8&nbsp;</p><p>1 0 0 1 = 9</p><p>1 0 1 0 = A</p><p>1 0 1 1 = B</p></blockquote>
<p>So, if you ever see a UUID with these values in the N position, you‚Äôll know it‚Äôs the common Variant 1 type.&nbsp;</p>
<h4><strong>Version 1 (Time Based + Unique or Random Host Identifier)&nbsp;</strong></h4>
<p>In this version, the UUID is generated by taking the current timestamp and some identifying property of the device generating the UUID ‚Äì most commonly, the MAC address (also called the node ID).&nbsp;</p>
<p>This UUID is generated by concatenating the 48 bit MAC address, a 60 bit-timestamp, and a 14 bit ‚Äúuniquifying‚Äù clock sequence, along with the 6 reserved bits for version and variant to generate a unique UUID.&nbsp;</p>
<blockquote><p>The clock sequence is simply a value incremented every time the clock is modified.&nbsp;</p></blockquote>
<p>The timestamp used in this version is the number of 100 nanosecond time intervals since October 15, 1582 ‚Äì the date of Gregorian reform to the Christian calendar.&nbsp;</p>
<blockquote><p>You may be familiar with Unix systems and time since epoch. This is simply just a different Day 0. There are several algorithms online that allow you to convert one time representation to the other, so we won‚Äôt go over this here.</p></blockquote>
<p>Though this implementation seems fairly straightforward and robust, because it reveals the MAC address of the machine it was generated on, this approach is not suitable for all use cases.&nbsp; Especially, when security is a major concern. Instead, some implementations will use 6 random bytes sourced from a cryptographically secure random number generator as a replacement for the node ID.&nbsp;</p>
<p>&nbsp;To assemble a Version 1 UUID, we‚Äôll do the following steps:&nbsp;</p>
<ol><li>Take the low 32 bits of the current UTC timestamp. This will be the first 4 bytes / 8 hex characters of our UUID [TimeLow]</li><li>Take the middle 16 bits of the current UTC timestamp. These will be the following 2 bytes / 4 hex characters. [TimeMid]</li><li>The next 2 bytes / 4 hex characters will concat the 4 bit UUID version with the remaining high 12 bits of the current UTC timestamp (which is 60 bits in total). [TimeHighAndVersion]</li><li>Now, the next 1-3 bits will specify the variant of the UUID version. The remaining bits will contain the clock sequence which is meant to contribute some small amount of randomness to this implementation. In doing so, it helps avoid collisions in the event multiple UUID generators are running on the same system, a system clock for a UUID generator is set backwards, or the system clock doesn‚Äôt advance fast enough. [ClockSequenceHiAndRes &amp;&amp; ClockSequenceLow]</li><li>The final 6 bytes / 12 hex characters / 48 bits are the ‚Äúnode id‚Äù which is most commonly the MAC address of the issuing device. [NodeID]</li></ol>
<p>Putting everything together, our Version 1 UUID is generated by concatenating:</p>
<p><code>TimeLow + TimeMid + TimeHighAndVersion + (ClockSequenceHiAndRes &amp;&amp; ClockSequenceLow) + NodeID&nbsp;</code></p>
<p>Due to this implementation‚Äôs reliance on the clock, there are some edge cases we‚Äôll need to handle. Firstly, to minimize correlation across systems, the clock sequence is defaulted to a random number ‚Äì this will only happen once in the lifetime of a system. This has the added benefit of allowing us to support node identifiers that may move from system to system as the initial value of the clock sequence is completely agnostic of the node identifier.&nbsp;</p>
<p>Remember that the main purpose of the clock sequence is to introduce some amount of randomness into the equation. The bits allocated for the clock sequence help us extend the timestamp and account for situations where multiple UUIDs are generated before the processor clock advances. This helps us avoid the potential creation of duplicates when the clock is set backwards in time (device is powered off) or the node ID changes. If the clock is set backwards, or might have been set backwards (e.g., while the system was powered off), and the UUID generator can not be sure that no UUIDs were generated with timestamps larger than the value to which the clock was set, then the clock sequence has to be changed. If the previous value of the clock sequence is known, it can just be incremented; otherwise it should be set to a random or high-quality pseudo-random value.</p>
<h4><strong>Version 2 (Distributed Computing Environment Security)</strong></h4>
<p>The main difference between this version and Version 1 is that this implementation uses some identifier specific to the system in place of the ‚Äúrandomness‚Äù generated by using the least significant bits of the clock sequence. This value is often just the current user‚Äôs ID. This version is less common and only a small deviation from Version 1, so we won‚Äôt explore it any further.&nbsp;</p>
<h4><strong>Version 3 (Name-based + MD5 Hash)</strong></h4>
<p>In the event that you want to have unique identifiers for information within a namespace or for ‚Äúnameable‚Äù information more generally, UUID version 3 and version 5 are your preferred options.&nbsp;</p>
<p>They‚Äôll encode any ‚Äúnameable‚Äù entity (website, DNS information, plain text, etc) into the UUID value. The main takeaway here is that for the same namespace and text, the generated UUID will be the same.&nbsp;</p>
<p>Take note that the namespace itself is a UUID.</p>
<pre><code>let namespace = ‚Äúdigitalbunker.dev‚Äù
let namespaceUUID = UUID3(.DNS, namespace)

// Ex: 
UUID3(namespaceUUID, ‚Äú/category/things-you-should-know-1/‚Äù) 
4896c91b-9e61-3129-87b6-8aa299028058

UUID3(namespaceUUID, ‚Äú/category/things-you-should-know-2/‚Äù) 
29be0ee3-fe77-331e-a1bf-9494ec18c0ba

UUID3(namespaceUUID, ‚Äú/category/things-you-should-know-3/‚Äù) 
33b06619-1ee7-3db5-827d-0dc85df1f759
</code></pre>
<p>In this implementation, the UUID of the namespace is transformed to a string of bytes, concatenated with the input name, then hashed with MD5, yielding the 128 bits for the UUID. Then, we‚Äôll overwrite some of those bits to accurately reflect the version and variant information leaving the rest unchanged.&nbsp;</p>
<p>It‚Äôs also important to understand that neither the namespace nor the inputted name can be generated from the UUID. This is a one-way operation. The only exception here would be through a brute force approach if one of the values (namespace or text) were known by the attacker.</p>
<p>For Version 3 and Version 5, as long as you use the same inputs, the generated UUID will be deterministic.&nbsp;</p>
<h4><strong>Version 4 (PRNG)</strong></h4>
<p>This is probably the simplest implementation of the bunch.</p>
<p>As we‚Äôve now seen, 6 bits are reserved for the version and variant information leaving us 122 bits free to decide. This version simply generates all 128 random bits and then fills in the values for the version and variant information as a secondary step.&nbsp;</p>
<p>UUIDs of this variety rely heavily on the quality of the PRNG in use (pseudo-random number generator). If the PRNG is lacking a sophisticated algorithm or the correct seed and initialization values, the likelihood of a duplicate can increase. To better understand how computers generate random numbers, <a href="https://digitalbunker.dev/2020/09/08/how-do-computers-generate-random-numbers/" target="_blank" rel="noreferrer noopener">check out my previous article.</a>&nbsp;</p>
<p>Version 4 is what you‚Äôll find most commonly implemented in modern programming languages.</p>
<p>It‚Äôs implementation is reasonably simple.&nbsp;</p>
<ol><li>Generate 128 random bits</li><li>Now, we‚Äôll need to overwrite some of these bits with the correct version and variant information&nbsp;<ol><li>Take the 7th byte and perform an AND operation with <code>0x0F</code> to clear out the high nibble. Then, OR it with <code>0x40</code> to set the version number to 4.&nbsp;</li><li>Next, take the 9th byte and perform an AND operation with <code>0x3F</code> and then OR it with <code>0x80</code>.&nbsp;</li></ol></li><li>Convert the 128 bits to hexadecimal representation and insert the hyphens to achieve the canonical text representation.&nbsp;</li></ol>
<h4><strong>Version 5 (Name-based + SHA-1 Hash)</strong></h4>
<p>This version is no different than Version 3 with the exception that the <code>SHA-1</code> hashing algorithm is used here in place of <code>MD5</code>. This version is preferred to Version 3 (SHA-1 &gt; MD5).&nbsp;</p>
<h2><strong>In Practice</strong></h2>
<p>One of the notable benefits of UUIDs is that their uniqueness does not depend on a central authority or coordination between different systems. Anyone can create UUIDs with reasonable assurance that a duplicate value does not exist and will conceivably not be made in the future.&nbsp;</p>
<p>This has the added benefit of allowing UUIDs generated by independent parties to be combined into a single database or moved across databases with a trivial probability of duplication / collision.&nbsp;</p>
<p>Due to this uniqueness, you can use UUIDs as primary keys in databases, unique filenames for uploaded files, unique names for any web resource, or ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/">https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/</a></em></p>]]>
            </description>
            <link>https://digitalbunker.dev/2020/09/30/understanding-how-uuids-are-generated/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636204</guid>
            <pubDate>Wed, 30 Sep 2020 06:31:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A categorized list of all Java and JVM features since JDK 8 to 15]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24636197">thread link</a>) | @pjmlp
<br/>
September 29, 2020 | https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/ | <a href="https://web.archive.org/web/*/https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><strong>Last updated</strong> on 2020/09/29 to include changes up to <a href="https://openjdk.java.net/projects/jdk/15/">JDK 15</a>.</p> <p>Since the release of version 8, up to version 15, Java is shaped by 163 <a href="http://openjdk.java.net/jeps/0">JDK Enhancement Proposals</a> (JEPs), each of which brings some improvement to the platform. This page is a <strong>categorized</strong> and <strong>curated</strong> list of the most important improvements.</p> <p><img alt="JDK timeline" integrity="sha256-LaVVHICMYi3voV98aHwg0mrUzl6D7m+MpNnEXwTXOWk=" crossorigin="anonymous" src="https://advancedweb.hu/assets/posts/post_java_8/jdktimeline-v3-2da5551c808c622defa15f7c687c20d26ad4ce5e83ee6f8ca4d9c45f04d73969.jpg"></p> <p><strong>Contents of this page:</strong></p> <ul> <li><a href="#new-language-features">New Language Features</a></li> <li><a href="#new-apis">New APIs</a></li> <li><a href="#performance-improvements">Performance Improvements</a></li> <li><a href="#security-improvements">Security Improvements</a></li> <li><a href="#bytecode">Bytecode Changes</a></li> <li><a href="#launching">Launching</a></li> <li><a href="#packaging">Packaging</a></li> <li><a href="#javadoc">Javadoc</a></li> <li><a href="#new-supported-platforms">New Platforms</a></li> <li><a href="#deprecation-and-removal">Deprecation and Removal</a></li> <li><a href="#new-version-scheme">New Version Scheme</a></li> </ul> <p>The full list of JEPs can be found on the OpenJDK website under the <a href="https://openjdk.java.net/projects/jdk/">jdk</a> and <a href="https://openjdk.java.net/projects/jdk9/">jdk9</a> projects.</p> <p>All features are generally available and enabled by default, except if they are labelled with one of the following:</p> <ul> <li> <strong>Preview</strong> üîç features are fully specified and implemented, but not yet considered to be final. They are considered to be almost complete, waiting for an additional round of real-world feedback. They have to be <a href="https://openjdk.java.net/jeps/12">explicitly enabled</a>.</li> <li> <strong>Experimental</strong> üí• features are less stable, and more likely to change. They also have to be explicitly enabled.</li> <li> <strong>Incubator</strong> ü•ö modules are non-final tools and API‚Äôs, and are <a href="https://openjdk.java.net/jeps/11">distributed in separate modules</a>.</li> </ul> <h2 id="new-language-features">New Language Features</h2> <p>When Java 8 introduced lambdas it was a pretty huge change. While recent versions did not add such impactful features, lots of smaller improvements were made to the language.</p> <p>Here‚Äôs a quick recap on what happened in the last years. For a more in-depth guide, see <a href="https://advancedweb.hu/new-language-features-since-java-8-to-14/">New language features since Java 8</a>.</p><div> <p> Related </p> <div> <p><a href="https://advancedweb.hu/new-language-features-since-java-8-to-14/"> <img integrity="sha256-Ko5UWYfecL05QXbtkFEINWvtXxZRNvydy8FQEPm7Vsw=" crossorigin="anonymous" src="https://advancedweb.hu/assets/53487f-15f99cf9213eacf6f30f40e8d76a4dea7f587df024e1fe2ffa4cf085fa462d21.jpg"> </a> </p> <div>  <p> Enhancements to the Java language you should know </p> </div> </div> </div> <ul> <li>Text Blocks<br> <a href="https://openjdk.java.net/jeps/378">JDK 15</a> (Preview in <a href="https://openjdk.java.net/jeps/368">JDK 14</a> <a href="https://openjdk.java.net/jeps/355">JDK 13</a>) <div> <div><pre><code><span>String</span> <span>html</span> <span>=</span> <span>"""
            &lt;html&gt;
                &lt;body&gt;
                    &lt;p&gt;Hello, world&lt;/p&gt;
                &lt;/body&gt;
            &lt;/html&gt;
            """</span><span>;</span>
</code></pre></div> </div> </li> <li>Sealed Classes can restrict which other classes may extend them (<strong>Preview</strong> üîç)<br> <a href="https://openjdk.java.net/jeps/360">JDK 15</a> <div> <div><pre><code><span>public</span> <span>abstract</span> <span>sealed</span> <span>class</span> <span>Shape</span>
    <span>permits</span> <span>Circle</span><span>,</span> <span>Rectangle</span> <span>{...}</span>

<span>public</span> <span>class</span> <span>Circle</span> <span>extends</span> <span>Shape</span> <span>{...}</span> <span>// OK</span>
<span>public</span> <span>class</span> <span>Rectangle</span> <span>extends</span> <span>Shape</span> <span>{...}</span> <span>// OK</span>
<span>public</span> <span>class</span> <span>Triangle</span> <span>extends</span> <span>Shape</span> <span>{...}</span> <span>// Compile error</span>

<span>// No need for default case if all permitted types are covered</span>
<span>double</span> <span>area</span> <span>=</span> <span>switch</span> <span>(</span><span>shape</span><span>)</span> <span>{</span>
    <span>case</span> <span>Circle</span> <span>c</span>    <span>-&gt;</span> <span>Math</span><span>.</span><span>pow</span><span>(</span><span>c</span><span>.</span><span>radius</span><span>(),</span> <span>2</span><span>)</span> <span>*</span> <span>Math</span><span>.</span><span>PI</span>
    <span>case</span> <span>Rectangle</span> <span>r</span> <span>-&gt;</span> <span>r</span><span>.</span><span>a</span><span>()</span> <span>*</span> <span>r</span><span>.</span><span>b</span><span>()</span>
<span>};</span>
</code></pre></div> </div> </li> <li>Records (<strong>Preview</strong> üîç)<br> <a href="https://openjdk.java.net/jeps/384">JDK 15</a> <a href="https://openjdk.java.net/jeps/359">JDK 14</a> <div> <div><pre><code><span>record</span> <span>Point</span><span>(</span><span>int</span> <span>x</span><span>,</span> <span>int</span> <span>y</span><span>)</span> <span>{</span> <span>}</span>
</code></pre></div> </div> </li> <li>Pattern Matching for instanceof (<strong>Preview</strong> üîç)<br> <a href="https://openjdk.java.net/jeps/375">JDK 15</a> <a href="https://openjdk.java.net/jeps/305">JDK 14</a> <div> <div><pre><code><span>if</span> <span>(</span><span>obj</span> <span>instanceof</span> <span>String</span> <span>s</span><span>)</span> <span>{</span>
    <span>System</span><span>.</span><span>out</span><span>.</span><span>println</span><span>(</span><span>"obj is a String and it' length is "</span> <span>+</span> <span>s</span><span>.</span><span>length</span><span>());</span>
<span>}</span>
</code></pre></div> </div> </li> <li>Switch Expressions<br> <a href="https://openjdk.java.net/jeps/361">JDK 14</a> (Preview in <a href="https://openjdk.java.net/jeps/325">JDK 12</a> <a href="https://openjdk.java.net/jeps/354">JDK 13</a>) <div> <div><pre><code><span>int</span> <span>numLetters</span> <span>=</span> <span>switch</span> <span>(</span><span>day</span><span>)</span> <span>{</span>
    <span>case</span> <span>MONDAY</span><span>,</span> <span>FRIDAY</span><span>,</span> <span>SUNDAY</span> <span>-&gt;</span> <span>6</span><span>;</span>
    <span>case</span> <span>TUESDAY</span>                <span>-&gt;</span> <span>7</span><span>;</span>
    <span>default</span>      <span>-&gt;</span> <span>{</span>
      <span>String</span> <span>s</span> <span>=</span> <span>day</span><span>.</span><span>toString</span><span>();</span>
      <span>int</span> <span>result</span> <span>=</span> <span>s</span><span>.</span><span>length</span><span>();</span>
      <span>yield</span> <span>result</span><span>;</span>
    <span>}</span>
<span>};</span>
</code></pre></div> </div> </li> <li>Helpful NullPointerExceptions describing precisely which variable was null<br> <a href="https://bugs.openjdk.java.net/browse/JDK-8233014">JDK 15</a> (Enabled with <code>-XX:+ShowCodeDetailsInExceptionMessages</code> in <a href="https://openjdk.java.net/jeps/358">JDK 14</a>) <div> <div><pre><code><span>a</span><span>.</span><span>b</span><span>.</span><span>c</span><span>.</span><span>i</span> <span>=</span> <span>99</span><span>;</span>
<span>---</span>
<span>Exception</span> <span>in</span> <span>thread</span> <span>"main"</span> <span>java</span><span>.</span><span>lang</span><span>.</span><span>NullPointerException</span><span>:</span>
      <span>Cannot</span> <span>read</span> <span>field</span> <span>"c"</span> <span>because</span> <span>"a.b"</span> <span>is</span> <span>null</span>
</code></pre></div> </div> </li> <li>Introduction of <code>var</code> to make local variable declarations less ceremonious<br> <a href="https://openjdk.java.net/jeps/323">JDK 11</a> (Without lambda support in <a href="https://openjdk.java.net/jeps/286">JDK 10</a>) <div> <div><pre><code><span>var</span> <span>greeting</span> <span>=</span> <span>"Hello World!"</span><span>;</span>
</code></pre></div> </div> </li> <li>Opt-in and backwards-compatible Module System to avoid <code>ClassDefNotFoundErrors</code> at runtime and create internal APIs<br> <a href="https://openjdk.java.net/jeps/261">JDK 9</a> (Project Jigsaw) <div> <div><pre><code><span>module</span> <span>hu</span><span>.</span><span>advancedweb</span><span>.</span><span>helloworld</span> <span>{</span>
    <span>requires</span> <span>hu</span><span>.</span><span>advancedweb</span><span>.</span><span>somedependency</span><span>;</span>
    <span>exports</span> <span>hu</span><span>.</span><span>advancedweb</span><span>.</span><span>hello</span>
<span>}</span>
</code></pre></div> </div> </li> <li> <p>Private methods in interfaces<br> <a href="https://openjdk.java.net/jeps/213">JDK 9</a> (Milling Project Coin)</p> </li> <li> <p>Diamond operator for anonymous inner classes<br> <a href="https://openjdk.java.net/jeps/213">JDK 9</a> (Milling Project Coin)</p> </li> <li> <p>Try-with-resources allows effectively final variables<br> <a href="https://openjdk.java.net/jeps/213">JDK 9</a> (Milling Project Coin)</p> </li> <li> <p><code>@SafeVargs</code> on private instance methods<br> <a href="https://openjdk.java.net/jeps/213">JDK 9</a> (Milling Project Coin)</p> </li> <li>No deprecation warnings on <code>import</code> statements<br> <a href="https://openjdk.java.net/jeps/211">JDK 9</a> </li> </ul> <p> We write articles like this regularly. <a href="#bottom-promo">Join our mailing list</a> and let's keep in touch. </p> <h2 id="new-apis">New APIs</h2> <p>Let‚Äôs continue with the Java Standard Library, focusing on the new features that we can use in day-to-day coding.</p> <p>If you are curious about all the API level differences between Java 8 and 14, check the <a href="https://github.com/AdoptOpenJDK/jdk-api-diff">AdoptOpenJDK/jdk-api-diff on GitHub</a>.</p> <h3 id="general">General</h3> <ul> <li> <p>Support Non-Volatile Mapped Byte Buffers in the FileChannel API<br> <a href="https://openjdk.java.net/jeps/352">JDK 14</a></p> </li> <li> <p><code>Files.mismatch</code>: find the first mismatched byte in the content of two files<br> <a href="https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/nio/file/Files.html">JDK 12</a></p> </li> <li> <p><code>Collectors.teeing</code> to create a Collector that is a composite of two downstream collectors<br> <a href="https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/util/stream/Collectors.html#teeing(java.util.stream.Collector,java.util.stream.Collector,java.util.function.BiFunction)">JDK 12</a></p> </li> <li> <p>String enhancements: <code>indent</code> and <code>transform</code><br> <a href="https://docs.oracle.com/en/java/javase/12/docs/api/java.base/java/lang/String.html">JDK 12</a></p> </li> <li>Standard HTTP Client featuring HTTP/2, WebSocket support and non-blocking API<br> <a href="https://openjdk.java.net/jeps/321">JDK 11</a> (<strong>Incubator</strong> ü•ö in <a href="https://openjdk.java.net/jeps/110">JDK 9</a>) <div> <div><pre><code><span>HttpClient</span> <span>httpClient</span> <span>=</span> <span>HttpClient</span><span>.</span><span>newBuilder</span><span>().</span><span>build</span><span>();</span>

<span>HttpRequest</span> <span>request</span> <span>=</span>
  <span>HttpRequest</span><span>.</span><span>newBuilder</span><span>()</span>
    <span>.</span><span>uri</span><span>(</span><span>URI</span><span>.</span><span>create</span><span>(</span><span>"https://advancedweb.hu/"</span><span>))</span>
    <span>.</span><span>GET</span><span>()</span>
    <span>.</span><span>build</span><span>();</span>

<span>HttpResponse</span><span>&lt;</span><span>String</span><span>&gt;</span> <span>response</span> <span>=</span>
  <span>httpClient</span><span>.</span><span>send</span><span>(</span><span>request</span><span>,</span> <span>BodyHandlers</span><span>.</span><span>ofString</span><span>());</span>
</code></pre></div> </div> </li> <li> <p>String enhancements, like <code>isBlank</code>, <code>lines</code>, <code>repeat</code> and <code>strip</code><br> <a href="https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/String.html">JDK 11</a></p> </li> <li>Convenience Factory Methods for Collections to ease the pain of not having collection literals<br> <a href="https://openjdk.java.net/jeps/269">JDK 9</a> <div> <div><pre><code><span>Set</span><span>&lt;</span><span>Integer</span><span>&gt;</span> <span>mySet</span> <span>=</span> <span>Set</span><span>.</span><span>of</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>);</span>
<span>List</span><span>&lt;</span><span>Integer</span><span>&gt;</span> <span>myList</span> <span>=</span> <span>List</span><span>.</span><span>of</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>);</span>
<span>Map</span><span>&lt;</span><span>String</span><span>,</span> <span>Integer</span><span>&gt;</span> <span>myMap</span> <span>=</span> <span>Map</span><span>.</span><span>of</span><span>(</span><span>"one"</span><span>,</span> <span>1</span><span>,</span> <span>"two"</span><span>,</span> <span>2</span><span>);</span>
</code></pre></div> </div> </li> <li> <p>Reactive Streams publish-subscribe framework for asynchronous stream processing with non-blocking backpressure<br> <a href="https://openjdk.java.net/jeps/266">JDK 9</a></p> </li> <li> <p>Time-based enhancements to <code>CompletableFuture</code> (timeout, delay)<br> <a href="https://openjdk.java.net/jeps/266">JDK 9</a></p> </li> <li> <p>More options to transform (<code>dropWhile</code>, <code>takeWhile</code>) and generate (<code>iterate</code>, <code>ofNullable</code>) streams; readonly collectors (<code>toUnmodifiableList</code>); optionals can be transformed to streams<br> <a href="https://docs.oracle.com/javase/9/docs/api/java/util/stream/Stream.html#iterate-T-java.util.function.UnaryOperator-">JDK 9</a></p> </li> <li> <p><code>Arrays.mismatch</code>: find the first mismatching element between two arrays<br> <a href="https://docs.oracle.com/javase/9/docs/api/java/util/Arrays.html#mismatch-java.lang.Object:A-java.lang.Object:A-">JDK 9</a></p> </li> <li> <p>Stack-Walking API that allows laziness and stack-frame filtering<br> <a href="https://openjdk.java.net/jeps/259">JDK 9</a></p> </li> <li> <p>Process API provides more info and control (e.g. process ID, arguments, CPU time, parent/child processes), enhance <code>ProcessBuilder</code> to aid the creation of process pipelines<br> <a href="https://openjdk.java.net/jeps/102">JDK 9</a></p> </li> <li> <p><code>VarHandle</code> API to replace the field and array related operations of <code>java.util.concurrent.atomic</code> and <code>sun.misc.Unsafe</code> in order to and provide low-level access mechamisms, e.g. atomic write.<br> <a href="https://openjdk.java.net/jeps/193">JDK 9</a></p> </li> <li> <p>New combinators and lookup methods for <code>MethodHandle</code><br> <a href="https://openjdk.java.net/jeps/274">JDK 9</a></p> </li> <li> <p>Enhanced Deprecation policy. <code>@Deprecated</code> can be marked with <code>forRemoval</code>, which emits a new warning.<br> <a href="https://openjdk.java.net/jeps/277">JDK 9</a></p> </li> <li> <p>OASIS Standard XML Catalog API to manage external resources in XMLs in a secure and performant manner<br> <a href="https://openjdk.java.net/jeps/268">JDK 9</a></p> </li> <li> <p>Update JDK‚Äôs XML parser, Xerces, to version 2.11.0<br> <a href="https://openjdk.java.net/jeps/255">JDK 9</a></p> </li> <li>TIFF Support for Image I/O Framework<br> <a href="https://openjdk.java.net/jeps/262">JDK 9</a> </li> </ul> <h3 id="internationalization">Internationalization</h3> <ul> <li> <p>Unicode 10.0, adding roughly 27.000 characters, 10 blocks, and more than 30 scripts<br> <a href="https://openjdk.java.net/jeps/327">JDK 11</a> (Unicode 8.0 support in <a href="https://openjdk.java.net/jeps/267">JDK 9</a>)</p> </li> <li> <p><code>java.util.Locale</code> and related APIs support currency type, time zone and more<br> <a href="https://openjdk.java.net/jeps/314">JDK 10</a></p> </li> <li> <p><code>ResourceBundle</code> loads properties files in UTF-8 instead of ISO-8859-1<br> <a href="https://openjdk.java.net/jeps/226">JDK 9</a></p> </li> <li> <p>CLDR Locale Data Enabled by Default<br> <a href="https://openjdk.java.net/jeps/252">JDK 9</a></p> </li> </ul> <h3 id="graphics-and-desktop-applications">Graphics and Desktop Applications</h3> <ul> <li> <p>Desktop features for all platforms like login/logout/lock event listener and task bar interactions<br> <a href="https://openjdk.java.net/jeps/272">JDK 9</a></p> </li> <li> <p><code>MultiResolutionImage</code> that makes easy to retrieve a resolution-specific image for a DPI<br> <a href="https://openjdk.java.net/jeps/251">JDK 9</a></p> </li> <li> <p>HiDPI Graphics on Windows and Linux<br> <a href="https://openjdk.java.net/jeps/263">JDK 9</a></p> </li> <li> <p>Enable GTK 3 on Linux for JavaFX, Swing, and AWT<br> <a href="https://openjdk.java.net/jeps/283">JDK 9</a></p> </li> <li> <p>Replace <code>@beaninfo</code> Javadoc tags with <code>@BeanInfo</code> annotations for Swing<br> <a href="https://openjdk.java.net/jeps/256">JDK 9</a></p> </li> <li> <p>Update GStreamer included in JavaFX/Media to version 1.4.4<br> <a href="https://openjdk.java.net/jeps/257">JDK 9</a></p> </li> <li> <p>Replace the existing ICU OpenType font-layout engine with HarfBuzz<br> <a href="https://openjdk.java.net/jeps/258">JDK 9</a></p> </li> </ul> <h2 id="performance-improvements">Performance Improvements</h2> <h3 id="general-1">General</h3> <ul> <li> <p>Foreign-Memory Access API to safely and efficiently use off-heap memory (<strong>Incubator</strong> ü•ö)<br> <a href="https://openjdk.java.net/jeps/383">JDK 15</a> <a href="https://openjdk.java.net/jeps/370">JDK 14</a></p> </li> <li> <p>Enable dynamic archiving of classes at the end of Java application execution<br> <a href="https://openjdk.java.net/jeps/350">JDK 13</a></p> </li> <li> <p>Application Class-Data Sharing to improve startup time and reduce footprint by sharing class metadata between Java processes.<br> <a href="https://openjdk.java.net/jeps/310">JDK 10</a></p> </li> <li> <p>Class-Data Sharing archive of the default class list is enabled by default to improve out-of-the-box startup time<br> <a href="https://openjdk.java.net/jeps/341">JDK 12</a></p> </li> <li> <p>Space-efficient, Compact Strings that stores Latin-1 only Strings more efficiently<br> <a href="https://openjdk.java.net/jeps/254">JDK 9</a></p> </li> <li> <p>Code caches of profiled and non-profiled compiled code is separated, resulting in improved performance and memory footprint<br> <a href="https://openjdk.java.net/jeps/197">JDK 9</a></p> </li> <li> <p>Store Interned Strings in Class-Data Sharing archives to reduce memory consumption<br> <a href="https://openjdk.java.net/jeps/250">JDK 9</a></p> </li> </ul> <h3 id="library">Library</h3> <ul> <li> <p>Improved intrinsics for <code>java.lang.Math</code> <code>sin</code>, <code>cos</code> and <code>log</code> functions on AArch64 processors<br> <a href="https://openjdk.java.net/jeps/315">JDK 11</a></p> </li> <li> <p>Security Manager performance improvements<br> <a href="https://openjdk.java.net/jeps/232">JDK 9</a></p> </li> <li> <p>Spin-Wait Hint (<code>Thread#onSpinWait</code>) to optimize busy-waiting style loops<br> <a href="https://openjdk.java.net/jeps/285">JDK 9</a></p> </li> <li> <p>Use Marlin Renderer in Java 2D as the default graphics rasterizer instead of Pisces<br> <a href="https://openjdk.java.net/jeps/265">JDK 9</a></p> </li> <li> <p>Improved GHASH and RSA performance by leveraging recently-introduced SPARC and Intel x64 CPU instructions<br> <a href="https://openjdk.java.net/jeps/246">JDK 9</a></p> </li> </ul> <h3 id="concurrency">Concurrency</h3> <ul> <li> <p>Thread-Local Handshakes to stop individual threads<br> <a href="https://openjdk.java.net/jeps/312">JDK 10</a></p> </li> <li> <p>Improved performance of contended object monitors<br> <a href="https://openjdk.java.net/jeps/143">JDK 9</a></p> </li> <li> <p>Extra space on thread stack for critical sections, mitigating the risk of a deadlock in <code>java.util.concurrent</code> locks in case of a stack overflow<br> <a href="https://openjdk.java.net/jeps/270">JDK 9</a></p> </li> </ul> <h3 id="compiler">Compiler</h3> <ul> <li> <p>Ahead-of-Time Compilation capability for Linux (<strong>Experimental</strong> üí•)<br> <a href="https://openjdk.java.net/jeps/246">JDK 10</a> (Graal as an experimental JIT Compiler) <a href="https://openjdk.java.net/jeps/243">JDK 9</a> (JVM Compiler Interface) <a href="https://openjdk.java.net/jeps/295">JDK 9</a> (Graal as an AoT Compiler)</p> </li> <li> <p>Performance improvement in javac: new strategy for type checking poly expressions<br> <a href="https://openjdk.java.net/jeps/215">JDK 9</a></p> </li> </ul> <h3 id="g1-garbage-collector-default">G1 Garbage Collector (default)</h3> <ul> <li> <p>NUMA-Aware Memory Allocation<br> <a href="https://openjdk.java.net/jeps/345">JDK 14</a></p> </li> <li> <p>Abortable mixed collections to meet user-supplied pause goals<br> <a href="https://openjdk.java.net/jeps/344">JDK 12</a></p> </li> <li> <p>Automatically return heap memory to the operating system when idle<br> <a href="https://openjdk.java.net/jeps/346">JDK 12</a></p> </li> <li> <p>Parallel Full GC to improve worst-case latencies<br> <a href="https://openjdk.java.net/jeps/307">JDK 10</a></p> </li> <li> <p>G1 Garbage Collector is now the default instead of Parallel GC<br> <a href="https://openjdk.java.net/jeps/248">JDK 9</a></p> </li> </ul> <h3 id="other-garbage-collectors">Other Garbage Collectors</h3> <ul> <li> <p>Z Garbage Collector, offering very low pause times on large heaps<br> <a href="https://openjdk.java.net/jeps/379">JDK 15</a> (<strong>Experimental</strong> üí• in <a href="https://openjdk.java.net/jeps/365">JDK 14</a> (Windows) <a href="https://openjdk.java.net/jeps/364">JDK 14</a> (OS X) <a href="https://openjdk.java.net/jeps/333">JDK 11</a> (Linux) )</p> </li> <li> <p>Shenandoah Garbage Collector, offering similar benefits as ZGC but based on a different algorithm<br> <a href="https://openjdk.java.net/jeps/377">JDK 15</a> (<strong>Experimental</strong> üí• in <a href="https://openjdk.java.net/jeps/189">JDK 12</a> )</p> </li> <li> <p>Epsilon Garbage Collector, which does not implement actual memory reclamation, striving for the lowest overhead possible<br> <a href="https://openjdk.java.net/jeps/318">JDK 11</a></p> </li> <li> <p><code>XX:AllocateHeapAt=&lt;path&gt;</code> to support Alternative Memory Devices<br> <a href="https://openjdk.java.net/jeps/316">JDK 10</a></p> </li> </ul> <h3 id="diagnostic-and-tools">Diagnostic and Tools</h3> <ul> <li> <p>Flight Recorder Event Streaming: profiling data is available via an <a href="https://cr.openjdk.java.net/~egahlin/jep-349/javadocs/api/jdk.jfr/jdk/jfr/consumer/package-summary.html">API</a>, making ‚Ä¶</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/">https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/</a></em></p>]]>
            </description>
            <link>https://advancedweb.hu/a-categorized-list-of-all-java-and-jvm-features-since-jdk-8-to-15/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636197</guid>
            <pubDate>Wed, 30 Sep 2020 06:29:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple‚Äôs T2 security chip jailbreak]]>
            </title>
            <description>
<![CDATA[
Score 726 | Comments 374 (<a href="https://news.ycombinator.com/item?id=24636166">thread link</a>) | @Yeri
<br/>
September 29, 2020 | https://reportcybercrime.com/hackers-jailbreak-apples-t2-security-chip-powered-by-bridgeos/ | <a href="https://web.archive.org/web/*/https://reportcybercrime.com/hackers-jailbreak-apples-t2-security-chip-powered-by-bridgeos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The Apple T2 security chip has finally been jailbroken! Here‚Äôs all you need to know about it.&nbsp; &nbsp; &nbsp;</p>
<h2><span id="The_Apple_T2_Security_chip_now_has_a_jailbreak"><strong>The Apple T2 Security chip now has a jailbreak</strong><span></span></span></h2>
<p>The <a href="https://yalujailbreak.net/checkra1n-jailbreak-ios-14/">latest update of checkra1n</a> adds support for bridgeOS ‚Äì the operating system that powers the Apple T2 security chip.</p>
<p>For what it‚Äôs worth, the T2 chip is not A10 per se but it is derived from the Apple A10 Fusion architecture.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p><strong>bridgeOS</strong> is a proprietary operating system created by Apple for its hardware. It is responsible for operating the Touch Bar and managing secure data.&nbsp;&nbsp;&nbsp;</p>
<p>Here‚Äôs what hacker Jamie Bishop had to say about this development.&nbsp;&nbsp;</p>
<blockquote data-width="550" data-dnt="true">
<p lang="en" dir="ltr">With <a href="https://twitter.com/checkra1n?ref_src=twsrc%5Etfw" target="_blank" rel="nofollow noopener noreferrer">@checkra1n</a> 0.11.0, you can now jailbreak the T2 chip in your Mac. An incredible amount of work went into this and it required changes at multiple levels.</p>
<p>There‚Äôs too many people to tag, but shoutout to everyone who worked on getting this incredible feature shipped.</p>
<p>‚Äî Jamie Bishop (@jamiebishop123) <a href="https://twitter.com/jamiebishop123/status/1308355178307948545?ref_src=twsrc%5Etfw" target="_blank" rel="nofollow noopener noreferrer">September 22, 2020</a></p>
</blockquote>
<p>Since checkra1n is still in beta, there are a few issues you need to be aware of. Firstly, you might have to reconnect your device after jailbreaking for bootstrap upload.</p>
<p>Secondly, macOS takes over the USB connection and blocks communication after bootup.&nbsp;</p>
<p>If you are interested in jailbreaking the T2 chip, download checkra1n jailbreak v0.11 from this <a href="https://yalujailbreak.net/checkra1n-jailbreak-ios-14/">link</a>.&nbsp;</p>
<h2><span id="What_can_a_bridgeOS_jailbreak_be_used_for"><strong>What can a bridgeOS jailbreak be used for?&nbsp;</strong><span></span></span></h2>
<p>The T2 security processor and the Touch Bar can run while the operating system is shutdown.</p>
<p>Apparently, jailbreak tweak developers could develop tweaks for the Touch Bar if it gets Substrate support in the future.</p>
<p>At present, there are no publicly dumped headers available for bridgeOS. It lacks a MobileSubstrate port too. However, that could change in the future because it shares some of the components of watchOS and iOS frameworks.</p>
<p>Once we get Substrate working, <strong>tweaking and theming could become possible.</strong></p>

<p>The ability to exploit the T2 processor could also allow you to bypass the anti-repair mechanism built into the Touch Bar. Further, it may allow hackers to get rid of the password or unlock MDM-locked systems.&nbsp;</p>
<p>As far as the OS goes, we could also add secure boot certificates like Microsoft‚Äôs secure boot signing or a self-signed Linux certificate.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
<p>It will definitely be interesting to see what the future holds for the <em>T2 security chip</em> following the release of checkra1n.&nbsp; &nbsp; &nbsp;</p>
<p>Don‚Äôt forget to follow us on Twitter and Facebook for the latest jailbreak news and updates.&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</p>
</div></div>]]>
            </description>
            <link>https://reportcybercrime.com/hackers-jailbreak-apples-t2-security-chip-powered-by-bridgeos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24636166</guid>
            <pubDate>Wed, 30 Sep 2020 06:19:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elements of Programmnig]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24635947">thread link</a>) | @todsacerdoti
<br/>
September 29, 2020 | http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html | <a href="https://web.archive.org/web/*/http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>

<p>The C++ STL may be the most impressive achievement in language standard libraries. Where most programmers are stuck complaining that their language‚Äôs default strings aren‚Äôt performant enough, about every standard C++ function for strings actually runs on arbitrary character sequences. Design your own container? <span>std::find_if</span> works just as well as for the built-ins. And it does this while often being more performant than the code you‚Äôd write yourself.</p>

<p>Alex Stepanov is the man who made this happen, and Elements of Programming (EOP) is his 200-page paean to his method for writing generic code. He‚Äôs a believer that programming can be turned from an art to a rigorous discipline based on mathematics, and I‚Äôve long admired him for his deep knowledge and impact. Indeed, he‚Äôs spent years at  #1 on my list of people I‚Äôd like to have lunch with. (Hey readers ‚Äî can anyone help?)</p>

<p>And now, I‚Äôm about to ruin all that by writing a negative review.</p>

<p>EOP has a strong beginning and a strong finish. The first chapter explains core programming language concepts such as types and state ‚Äî using non-standard terminology, but probably intentionally, judging by the explanation‚Äôs lucidity. This culminates in his big idea of being able to write programs on any type that offers a bundle of operations and properties called a concept, explained in this book over a decade before they entered the C++ standard. The afterword is a few pages of reflection on the power of this approach.</p>

<p>Between them is 11 chapters where he plays the same game: define a new abstraction and then show a bunch of functions that can be written using it. And unfortunately, these functions and abstractions are largely not very interesting.</p>

<p>There‚Äôs a famous site called Project Euler, where users write code to solve mathy problems such as ‚ÄúIn a modified version of the board game Monopoly, on what three squares is a player most likely to land?‚Äù My former programming-contest coach advocated against using it to practice, because ‚ÄúIt‚Äôs not really programming, and it‚Äôs not really math.‚Äù</p>

<p>I think this is an apt description of EOP, particularly the first half. This starts from Chapter 2, which is about cool algorithms that involve applying some function to itself repeatedly (iteration). One of my <a href="https://www.cs.cmu.edu/~cdm/pdf/lect-05.pdf">favorite lectures</a> in undergrad was on this topic, and yet I still couldn‚Äôt enjoy this chapter, as I know no application of these algorithms outside of niche mathematical topics. This gets taken up another notch in Chapter 5, where, in about 5 pages, he goes from explaining commutativity to defining the algebraic structures of monoids, groups, and rings, all the way up to algebraic modules (no relation to software modules). I cannot fathom these explanations being useful to someone who does not already know these concepts, and certainly not to someone who already does. And while I do know many uses of groups in software engineering ‚Äî as an abstraction of the idea of an invertible operation ‚Äî he actually spends the remainder of this chapter considering generalizations of the greatest common divisor function.</p>

<p>I slogged through these chapters, excited for the second half of the book, which focused largely on iterators and containers, things more relevant to typical software engineering. Yet after encountering endless listings of variations of list-copy functions, I found myself no more fulfilled, and soon regressed to skimming through the pages.</p>

<p>Aside from my long-term goal to find all the good writing on software design, I had a short-term goal when reading this book: a student wanted me to teach a lesson based on it. But, halfway through the book, my deadline was fast approaching, and I hadn‚Äôt found any material useful enough for a software design lesson for experienced engineers.</p>

<p>I then noticed all the chapters were generated by the deeper principle of coming up with a good abstraction to write generic functions against. I got the idea that maybe I could use EOP as a problem book, telling them to look at the descriptions of generic functions, and then come up with both the code and the abstractions they can be written against. Alas, the topic selection is not suitable for this purpose. One section of the book, for example, deals with computing integer sequences by matrix exponentiation. Asking students to come up with this themselves would be too familiar for many who have taken a linear algebra course, and impossible for those who haven‚Äôt. I did design a lesson where students come up with their own abstractions for generic programming problems, but I used examples completely unrelated to the book.</p>

<p>I asked the friend who recommended EOP what he got out of the book, and his first answer was a technique for elegantly expressing state machines using goto‚Äôs. I similarly loved that part, but, alas, that was the only concrete thing I got out of this book. I‚Äôll explain it at the end of this review and spare you the other 200 pages.</p>

<p>I have an undergraduate degree in mathematics and have authored several papers on generic programming, so I knew I was reading it for others‚Äô benefit. Still, I don‚Äôt think my opinion would be changed were this not the case, and I‚Äôd really like help understanding the viewpoint of the many readers who did thoroughly enjoy it. Instead, I find myself agreeing with this Amazon reviewer, although I have too much admiration for Stepanov to contemplate a 1-star rating:</p>

<blockquote>If you've ever written a generic function, you already know that the type parameters must obey a set of preconditions. This book lays out a big pile of definitions for types, numbers, algebraic structures, iterators, and such, so as to bamboozle people easily impressed by mathematical notation. It does so sloppily and writes some trivial generic algorithms in C++. To whatever extent one might accomplish something interesting with this topic, this book doesn't. Avoid.</blockquote>

<p>As I read other material by Stepanov, I mourn for the book that could have been. Stepanov clearly cares about these abstractions and algorithms, to the point where he wrote a <a href="https://www.amazon.com/Mathematics-Generic-Programming-Alexander-Stepanov/dp/0321942043">second book</a> on largely the same material, with a chattier exposition and chapters more explicitly focusing on pure math. How different would it be had he managed to transmit this appreciation to me? The day after finishing, I watched <a href="https://www.youtube.com/watch?v=W2tWOdzgXHA&amp;t=1344s">this talk</a> by a close colleague of Stepanov. ‚ÄúIn this menu, you can select a bunch of rows and drag them somewhere else,‚Äù he explained over animated slides. ‚ÄúHow many of you could implement this in one line?‚Äù It made me want to open section 10.4 on ‚Äúrotation algorithms‚Äù again.</p>

<p>I‚Äôve started watching <a href="https://www.youtube.com/playlist?list=PLHxtyCq_WDLXryyw91lahwdtpZsmo4BGD">a seminar</a> he gave at Amazon. I‚Äôm only a few lectures in, but I‚Äôm already enthralled by his high teaching ability. I feel like I‚Äôm there with him working through problems. I feel like I‚Äôve learned a great secret as he tells the story of how he invented ‚Äúregular types,‚Äù something used throughout EOP but never motivated. To be honest, I still don‚Äôt know what this lecture series is about, but nonetheless expect to recommend it when I‚Äôm done.</p>

<p>In short, Stepanov has given many gifts to the world of programming, and EOP is not one of them.</p>

<p><b>Overall rating</b>: <span>Not recommended</span></p>

<p>With a smattering of exceptions, EOP neither teaches abstractions useful in everyday programming, nor teaches you the skills to invent your own.</p>

<h2><b>Addendum</b>: State machines by goto‚Äôs</h2>

<blockquote>‚ÄúThe fastest way to go from one place in code to another is goto.‚Äù</blockquote><p>

‚Äî <a href="https://www.youtube.com/watch?v=sp_IBYVqMeQ&amp;list=PLHxtyCq_WDLXryyw91lahwdtpZsmo4BGD">Alexander Stepanov</a></p><p>Many iterative algorithms can be described as state machines: first it looks for an X, then it does Y with it, then it looks for another X, and so on. Rather than trying to massage the cycles in the state machine into structured loops, Stepanov advocates a style using goto‚Äôs, with one goto-label per machine state.</p>

<p>In searching for an example to best illustrate this, I wanted something where the code was under 40 lines (which ruled out Stepanov‚Äôs examples), understandable with little context or knowledge of C++, and which was not equivalent to a regular expression. And so:</p>

<p>In my defunctionalization talk, I showed that many state machines are derived from recursive functions, being turned into iterative traversals by creating a state for each point in the program between recursive calls. For that talk, I demonstrated this in full for the example of printing a binary tree. It turns out that adding parentheses makes this derivation substantially harder, as an arbitrary number of close-parentheses may need to be printed after processing a node. And that difficulty comes from trying to massage a state machine into a loop.</p>

<p>In this case, seeing as I came up with this example by starring with a recursive function, the recursive version is quite simple:</p>

<div><pre><span>void</span> <span>print_tree_rec</span><span>(tree</span> <span>*</span><span>t)</span> <span>{</span>
  <span>if</span> <span>(t</span> <span>!=</span> <span>NULL)</span> <span>{</span>
    <span>printf(</span><span>"("</span><span>);</span>
    <span>print_tree_rec(t</span><span>-&gt;</span><span>left);</span>
    <span>printf(</span><span>" %d "</span><span>,</span> <span>t</span><span>-&gt;</span><span>element);</span>
    <span>print_tree_rec(t</span><span>-&gt;</span><span>right);</span>
    <span>printf(</span><span>")"</span><span>);</span>
  <span>}</span>
<span>}</span>
</pre></div>


<p>But, for other state machines, the recursive version is not so easy. For example, Dijkstra created the ‚Äúshunting yard‚Äù algorithm for parsing an arithmetic expression all the way back in 1961, yet I‚Äôm not aware of the recursive equivalent being discovered <a href="https://www.brics.dk/RS/07/7/BRICS-RS-07-7.pdf">until 2007</a>, using the technique of refunctionalization.</p>

<p>Here‚Äôs the state machine:</p><p><span id="docs-internal-guid-068c5e82-7fff-aeae-61d2-74453ca23aeb"><span><span><img height="566" src="https://lh4.googleusercontent.com/bfYT7CeU0eo8KAoMt8gB5Y4FDgD7Y1UlUJYSNI3ndYZ6jQpZv5Nwpyqyqoqffi_tgSRBYslU93EZy_nCil9ub6FZraaRGOBoABGPk0i9DoNbgr1fWAnkQzXMxPvLvEYFSDRWZ1RL" width="572"></span></span></span></p>

<p>A confession: the first time I thought about how to make this recursive function function iterative, I didn‚Äôt get it, and had to look it up. The solution is to merge the ‚ÄúNext from stack‚Äù state in the diagram with its successors, resulting in a solution with two nested while-loops, at the cost of some duplicated code.</p>

<p>However, the version based on goto‚Äôs reads off this diagram rather nicely. One C++-ism in this code to note: while the stack s is initialized to NULL, the  <span>push()</span> and  <span>pop()</span> calls can actually change it.</p>

<!--HTML generated using hilite.me--><div><pre><span>void</span> <span>print_tree</span><span>(tree</span> <span>*</span><span>t)</span> <span>{</span>
  <span>tree</span> <span>*</span><span>cur</span> <span>=</span> <span>t;</span>
  <span>stack</span> <span>*</span><span>s</span> <span>=</span> <span>NULL;</span>
  
<span>begin_print_node:</span>
  <span>if</span> <span>(cur</span> <span>==</span> <span>NULL)</span> <span>{</span>
    <span>goto</span> <span>dispatch_stack_frame;</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>printf(</span><span>"("</span><span>);</span>
    <span>push(LEFT_CHILD,</span> <span>cur,</span> <span>s);</span>
    <span>cur</span> <span>=</span> <span>cur</span><span>-&gt;</span><span>left;</span>
    <span>goto</span> <span>begin_print_n‚Ä¶</span></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html">http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html</a></em></p>]]>
            </description>
            <link>http://www.pathsensitive.com/2020/09/book-review-elements-of-programmnig.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635947</guid>
            <pubDate>Wed, 30 Sep 2020 05:28:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From zero to main(): How to write a bootloader from scratch]]>
            </title>
            <description>
<![CDATA[
Score 330 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24635383">thread link</a>) | @tigerlily
<br/>
September 29, 2020 | https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch | <a href="https://web.archive.org/web/*/https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <p>This is the third post in our <a href="https://interrupt.memfault.com/blog/tag/zero-to-main">Zero to main() series</a>,
where we bootstrap a working firmware from zero code on a
cortex-M series microcontroller.</p>

<p>Previously, <a href="https://interrupt.memfault.com/blog/zero-to-main-1">we wrote a startup file to bootstrap our C environment</a>, and <a href="https://interrupt.memfault.com/blog/how-to-write-linker-scripts-for-firmware">a linker
script to get the right data at the right addresses</a>. These two will allow us to
write a monolithic firmware which we can load and run on our microcontrollers.</p>

<p>In practice, this is not how most firmware is structured. Digging through vendor
SDKs, you‚Äôll notice that they all recommend using a <em>bootloader</em> to load your
applications. A bootloader is a small program which is responsible for loading
and starting your application.</p>

<!-- excerpt start -->
<p>In this post, we will explain why you may want a
bootloader, how to implement one, and cover a few advanced techniques you may
use to make your bootloader more useful.
<!-- excerpt end --></p>

<p>Like Interrupt? <a href="http://eepurl.com/gpRedv" target="_blank">Subscribe</a> to get our latest posts straight to your mailbox.</p>



<h2 id="why-you-may-need-a-bootloader">Why you may need a bootloader</h2>

<p>Bootloaders serve many purposes, ranging from security to software architecture.</p>

<p>Most commonly, you may need a bootloader to load your software. Some
microcontrollers like Dialog‚Äôs
<a href="https://www.dialog-semiconductor.com/products/connectivity/bluetooth-low-energy/smartbond-da14580-and-da14583">DA14580</a>
have little to no onboard flash and instead rely on an external device to store
firmware code. In that case, it is the bootloader‚Äôs job to copy code from
non-executable storage, such as a SPI flash, to an area of memory that can be
executed from, such as RAM.</p>

<p>Bootloaders also allow you to decouple parts of the program that are mission
critical, or that have security implications, from application code which
changes regularly.  For example, your bootloader may contain firmware update
logic so your device can recover no matter how bad a bug ships in your
application firmware.</p>

<p>Last but certainly not least, bootloaders are an essential component of a
trusted boot architecture.  Your bootloader can, for example, verify a
cryptographic signature to make sure the application has not been replaced or
tampered with.</p>

<h2 id="a-minimal-bootloader">A minimal bootloader</h2>
<p>Let‚Äôs build a simple bootloader together. To start, our bootloader must do two
things:</p>

<ol>
  <li>Execute on MCU boot</li>
  <li>Jump to our application code</li>
</ol>

<p>We‚Äôll need to decide on a memory map, write some bootloader code, and update our
application to make it bootload-able.</p>

<h3 id="setting-the-stage">Setting the stage</h3>

<p>For this example, we‚Äôll be using the same setup as we did in our previous Zero
to Main posts:</p>
<ul>
  <li>Adafruit‚Äôs <a href="https://www.adafruit.com/product/3505">Metro M0 Express</a> as our
development board,</li>
  <li>a simple <a href="https://www.adafruit.com/product/2764">CMSIS-DAP Adapter</a></li>
  <li>OpenOCD (the <a href="https://github.com/arduino/OpenOCD">Arduino fork</a>) for
programming</li>
</ul>

<h3 id="deciding-on-a-memory-map">Deciding on a memory map</h3>

<p>We must first decide on how much space we want to dedicate to our bootloader.
Code space is precious - your application may come to need more of it - and you
will not be able to change this without updating your bootloader, so make
this as small as you possibly can.</p>

<p>Another important factor is your flash sector size: you want to make sure you
can erase app sectors without erasing bootloader data, or vice versa.
Consequently, your bootloader region must end on a flash sector boundary
(typically 4kB).</p>

<p>I decided to go with a 16kB region, leading to the following memory map:</p>

<div><div><pre><code>        0x0 +---------------------+
            |                     |
            |     Bootloader      |
            |                     |
     0x4000 +---------------------+
            |                     |
            |                     |
            |     Application     |
            |                     |
            |                     |
    0x30000 +---------------------+
</code></pre></div></div>

<p>We can transcribe that memory into a linker script:</p>

<div><div><pre><code>/* memory_map.ld */
MEMORY
{
  bootrom  (rx)  : ORIGIN = 0x00000000, LENGTH = 0x00004000
  approm   (rx)  : ORIGIN = 0x00004000, LENGTH = 0x0003C000
  ram      (rwx) : ORIGIN = 0x20000000, LENGTH = 0x00008000
}

__bootrom_start__ = ORIGIN(bootrom);
__bootrom_size__ = LENGTH(bootrom);
__approm_start__ = ORIGIN(approm);
__approm_size__ = LENGTH(approm);
</code></pre></div></div>

<p>Since linker scripts are composable, we will be able to <code>include</code> that memory
map into the linker scripts we write for our bootloader and our application.</p>

<p>You‚Äôll notice that the linker script above declares some variables. We‚Äôll need
those for our bootloader to know where to find the application. To make them
accessible in C code, we declare them in a header file:</p>

<div><div><pre><code><span>/* memory_map.h */</span>
<span>#pragma once
</span>
<span>extern</span> <span>int</span> <span>__bootrom_start__</span><span>;</span>
<span>extern</span> <span>int</span> <span>__bootrom_size__</span><span>;</span>
<span>extern</span> <span>int</span> <span>__approm_start__</span><span>;</span>
<span>extern</span> <span>int</span> <span>__approm_size__</span><span>;</span>
</code></pre></div></div>

<h3 id="implementing-the-bootloader-itself">Implementing the bootloader itself</h3>
<p>Next up, let‚Äôs write some bootloader code. Our bootloader needs to start
executing on boot and then jump to our app.</p>

<p>We know how to do the first part from our previous post: we need a valid stack
pointer at address <code>0x0</code> , and a valid <code>Reset_Handler</code>  function setting up our
environment at address <code>0x4</code>. We can reuse our previous startup file and linker
script, with one change: we use  <code>memory_map.ld</code> rather than define our own
<code>MEMORY</code> section.</p>

<p>We also need to put our code in the <code>bootrom</code> region from our memory rather than
the <code>rom</code> region in our previous post.</p>

<p>Our linker script therefore looks like this:</p>

<div><div><pre><code>/* bootloader.ld */
INCLUDE memory_map.ld

/* Section Definitions */
SECTIONS
{
    .text :
    {
        KEEP(*(.vectors .vectors.*))
        *(.text*)
        *(.rodata*)
        _etext = .;
    } &gt; bootrom
  ...
}
</code></pre></div></div>

<p>To jump into our application, we need to know where the <code>Reset_Handler</code> of the
app is, and what stack pointer to load.  Again, we know from our previous post
that those should be the first two 32-bit words in our binary, so we just need
to dereference those addresses using the <code>__approm_start__</code> variable from our
memory map.</p>

<div><div><pre><code><span>/* bootloader.c */</span>
<span>#include &lt;inttypes.h&gt;
#include "memory_map.h"
</span>
<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
  <span>uint32_t</span> <span>*</span><span>app_code</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span><span>__approm_start__</span><span>;</span>
  <span>uint32_t</span> <span>app_sp</span> <span>=</span> <span>app_code</span><span>[</span><span>0</span><span>];</span>
  <span>uint32_t</span> <span>app_start</span> <span>=</span> <span>app_code</span><span>[</span><span>1</span><span>];</span>
  <span>/* TODO: Start app */</span>
  <span>/* Not Reached */</span>
  <span>while</span> <span>(</span><span>1</span><span>)</span> <span>{}</span>
<span>}</span>
</code></pre></div></div>

<p>Next we must load that stack pointer and jump to the code. This will require a
bit of assembly code.</p>

<p>ARM MCUs use the <a href="http://www.keil.com/support/man/docs/armasm/armasm_dom1361289882044.htm"><code>msr</code> instruction
</a> to
load immediate or register data into system registers, in this case the MSP
register or ‚ÄúMain Stack Pointer‚Äù.</p>

<p>Jumping to an address is done with a branch, in our case with a <a href="http://www.keil.com/support/man/docs/armasm/armasm_dom1361289866466.htm"><code>bx</code>
instruction</a>.</p>

<p>We wrap those two into a <code>start_app</code> function which accepts our <code>pc</code> and <code>sp</code> as
arguments, and get our minimal bootloader:</p>

<div><div><pre><code><span>/* app.c */</span>
<span>#include &lt;inttypes.h&gt;
#include "memory_map.h"
</span>
<span>static</span> <span>void</span> <span>start_app</span><span>(</span><span>uint32_t</span> <span>pc</span><span>,</span> <span>uint32_t</span> <span>sp</span><span>)</span> <span>__attribute__</span><span>((</span><span>naked</span><span>))</span> <span>{</span>
    <span>__asm</span><span>(</span><span>"           </span><span>\n</span><span>\
          msr msp, r1 /* load r1 into MSP */</span><span>\n</span><span>\
          bx r0       /* branch to the address at r0 */</span><span>\n</span><span>\
    "</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
  <span>uint32_t</span> <span>*</span><span>app_code</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span><span>__approm_start__</span><span>;</span>
  <span>uint32_t</span> <span>app_sp</span> <span>=</span> <span>app_code</span><span>[</span><span>0</span><span>];</span>
  <span>uint32_t</span> <span>app_start</span> <span>=</span> <span>app_code</span><span>[</span><span>1</span><span>];</span>
  <span>start_app</span><span>(</span><span>app_start</span><span>,</span> <span>app_sp</span><span>);</span>
  <span>/* Not Reached */</span>
  <span>while</span> <span>(</span><span>1</span><span>)</span> <span>{}</span>
<span>}</span>
</code></pre></div></div>

<blockquote>
  <p>Note: hardware resources initialized in the bootloader must be de-initialized
before control is transferred to the app. Otherwise, you risk breaking
assumptions the app code is making about the state of the system</p>
</blockquote>

<h3 id="making-our-app-bootloadable">Making our app bootloadable</h3>

<p>We must update our app to take advantage of our new memory map. This is again
done by updating our linker script to include <code>memory_map.ld</code> and changing our
sections to go to the <code>approm</code> region rather than <code>rom</code>.</p>

<div><div><pre><code>/* app.ld */
INCLUDE memory_map.ld

/* Section Definitions */
SECTIONS
{
    .text :
    {
        KEEP(*(.vectors .vectors.*))
        *(.text*)
        *(.rodata*)
        _etext = .;
    } &gt; approm
  ...
}
</code></pre></div></div>

<p>We also need to update the <a href="https://developer.arm.com/docs/dui0552/latest/the-cortex-m3-processor/exception-model/vector-table"><em>vector
table</em></a>
used by the microcontroller. The vector table contains the address of every
exception and interrupt handler in our system. When an interrupt signal comes
in, the ARM core will call the address at the corresponding offset in the vector
table.</p>

<p>For example, the offset for the Hard fault handler is <code>0xc</code>, so when a hard
fault is hit, the ARM core will jump to the address contained in the table at
that offset.</p>

<p>By default, the vector table is at address <code>0x0</code>, which means that when our chip
powers up, only the bootloader can handle exceptions or interrupts! Fortunately, ARM
provides the <a href="https://developer.arm.com/docs/dui0552/latest/cortex-m3-peripherals/system-control-block/vector-table-offset-register">Vector Table Offset
Register</a>
to dynamically change the address of the vector table. The register is at
address <code>0xE000ED08</code> and has a simple layout:</p>

<div><div><pre><code>31                                  7              0
+-----------------------------------+--------------+
|                                   |              |
|              TBLOFF               |   Reserved   |
|                                   |              |
+-----------------------------------+--------------+
</code></pre></div></div>

<p>Where <code>TBLOFF</code> is the address of the vector table. In our case, that‚Äôs the start
of our text section, or <code>_stext</code>. To set it in our app, we add the following to
our <code>Reset_Handler</code>:</p>

<div><div><pre><code><span>/* startup_samd21.c */</span>
<span>/* Set the vector table base address */</span>
<span>uint32_t</span> <span>*</span><span>vector_table</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span> <span>&amp;</span><span>_stext</span><span>;</span>
<span>uint32_t</span> <span>*</span><span>vtor</span> <span>=</span> <span>(</span><span>uint32_t</span> <span>*</span><span>)</span><span>0xE000ED08</span><span>;</span>
<span>*</span><span>vtor</span> <span>=</span> <span>((</span><span>uint32_t</span><span>)</span> <span>vector_table</span> <span>&amp;</span> <span>0xFFFFFFF8</span><span>);</span>
</code></pre></div></div>

<p>One quirk of the ARMv7-m architecture is the alignment requirement for the
vector table, as specified in section B1.5.3 of the <a href="https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf">reference
manual</a>:</p>

<blockquote>
  <p>The Vector table must be naturally aligned to a power of two whose alignment value is greater than or equal
to (Number of Exceptions supported x 4), with a minimum alignment of 128 bytes.The entry at offset 0 is
used to initialize the value for SP_main, see The SP registers on page B1-8. All other entries must have bit
[0] set, as the bit is used to define the EPSR T-bit on exception entry (see Reset behavior on page B1-20 and
Exception entry behavior on page B1-21 for details).</p>
</blockquote>

<p>Our SAMD21 MCU has 28 interrupts on top of the 16 system reserved exceptions,
for a total of 44 entries in the table. Multiply that by 4 and you get 176. The
next power of 2 is 256, so our vector table must be 256-byte aligned.</p>

<h3 id="putting-it-all-together">Putting it all together</h3>

<p>Because it is hard to witness the bootloader execute, we add a print line to
each of our programs:</p>

<div><div><pre><code><span>/* boootloader.c */</span>
<span>#include &lt;inttypes.h&gt;
#include "memory_map.h"
</span>
<span>static</span> <span>void</span> <span>s‚Ä¶</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch">https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch</a></em></p>]]>
            </description>
            <link>https://interrupt.memfault.com/blog/how-to-write-a-bootloader-from-scratch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635383</guid>
            <pubDate>Wed, 30 Sep 2020 03:19:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The UX of Banking]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24635364">thread link</a>) | @Garbage
<br/>
September 29, 2020 | https://builtformars.co.uk/banks/ | <a href="https://web.archive.org/web/*/https://builtformars.co.uk/banks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-page" data-elementor-id="3032" data-elementor-settings="[]">
<div>
<div>
<section data-id="2898fc6" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">

<div>
<div>
<div data-id="4964a44" data-element_type="column">
<div>
<div>

<div data-id="0a3485f" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;none&quot;}" data-widget_type="heading.default">
<p>
<h3>What the challenger banks did differently: a study into the UX of banking.</h3> </p>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="535cf2f" data-element_type="section">

</section>
<section data-id="9be0ee4" data-element_type="section">
<div>
<div>
<div data-id="bf5c18d" data-element_type="column">
<div>
<div>

<div data-id="b431a25" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;none&quot;}" data-widget_type="heading.default">
<p>
<h4>Billion dollar experiences</h4> </p>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="b910384" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
<div>
<div>
<div data-id="96fe065" data-element_type="column">
<div>
<div>
<div data-id="3c618a0" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Monzo, Revolut and Starling‚Äîoften called the challenger banks‚Äîhave built billion-dollar businesses around the belief that they offer the best overall banking experience.</p>
</div>
</div>
<div data-id="941ff44" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But are they actually any better, or is it all clever marketing? To answer that question I opened 12 real bank accounts, and logged <em>everything</em>.</p>
</div>
</div>
<div data-id="8bb4b6b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Each chapter provides a forensic analysis of a particular feature or user journey.</p>
</div>
</div>
<div data-id="78b3d97" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>But more importantly, I‚Äôve highlighted what can we all learn from the challenger banks, and used real examples to teach you how to craft better experiences in the future.</p>
</div>
</div>
</div>
</div>
</div>
<div data-id="560e042" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
<div>
<div>
<div data-id="9643ce0" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p><strong>Subscribe to get more content like this!</strong></p>
</div>
</div>

</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="546fd67" data-element_type="section">
<div>
<div>
<div data-id="4cd7bfe" data-element_type="column">
<div>
<div>
<div data-id="bdaeb8e" data-element_type="widget" data-widget_type="image.default">
<div>
<p><a href="https://builtformars.com/banks/opening/">
<img width="562" height="343" src="https://builtformars.com/wp-content/uploads/2020/06/AllCardsFixed.jpg" alt="" loading="lazy" srcset="https://builtformars.com/wp-content/uploads/2020/06/AllCardsFixed.jpg 562w, https://builtformars.com/wp-content/uploads/2020/06/AllCardsFixed-300x183.jpg 300w, https://builtformars.com/wp-content/uploads/2020/06/AllCardsFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px"> </a>
</p>
</div>
</div>


<div data-id="29b9a8f" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>It took <strong>18x longer</strong> to open an account with HSBC that it did with Monzo.</p>
</div>
</div>

</div>
</div>
</div>
<div data-id="4a8ea32" data-element_type="column">
<div>
<div>
<div data-id="c26ace2" data-element_type="widget" data-widget_type="image.default">
<div>
<p><a href="https://builtformars.com/banks/first-payment">
<img width="562" height="343" src="https://builtformars.com/wp-content/uploads/2020/06/FirstPaymentFixed-1.jpg" alt="" loading="lazy" srcset="https://builtformars.com/wp-content/uploads/2020/06/FirstPaymentFixed-1.jpg 562w, https://builtformars.com/wp-content/uploads/2020/06/FirstPaymentFixed-1-300x183.jpg 300w, https://builtformars.com/wp-content/uploads/2020/06/FirstPaymentFixed-1-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px"> </a>
</p>
</div>
</div>


<div data-id="410d84b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Payment notifications were <strong>at least 2x faster</strong> with the challenger banks, and in some cases <strong>100x faster</strong>.</p>
</div>
</div>

<div data-id="5892a2c" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>‚ö°Ô∏è Includes <strong>12</strong><strong>&nbsp;case studies</strong></p>
</div>
</div>
</div>
</div>
</div>
<div data-id="671df6e" data-element_type="column">
<div>
<div>
<div data-id="2d3db91" data-element_type="widget" data-widget_type="image.default">
<div>
<p><a href="https://builtformars.com/banks/freezing/">
<img width="562" height="343" src="https://builtformars.com/wp-content/uploads/2020/06/FrozenCardsFixed.jpg" alt="" loading="lazy" srcset="https://builtformars.com/wp-content/uploads/2020/06/FrozenCardsFixed.jpg 562w, https://builtformars.com/wp-content/uploads/2020/06/FrozenCardsFixed-300x183.jpg 300w, https://builtformars.com/wp-content/uploads/2020/06/FrozenCardsFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px"> </a>
</p>
</div>
</div>


<div data-id="caa9ed8" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>There were the <strong>only 3</strong> banks to send notifications when someone attempted to use a frozen card.</p>
</div>
</div>

<div data-id="f06833c" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>‚ö°Ô∏è Includes <strong>10</strong><strong>&nbsp;case studies</strong></p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="894506f" data-element_type="section">
<div>
<div>
<div data-id="df064b1" data-element_type="column">
<div>
<div>
<div data-id="28c4ea8" data-element_type="widget" data-widget_type="image.default">
<div>
<p><a href="https://builtformars.com/banks/international/">
<img width="562" height="343" src="https://builtformars.com/wp-content/uploads/2020/06/InternationalFixed.jpg" alt="" loading="lazy" srcset="https://builtformars.com/wp-content/uploads/2020/06/InternationalFixed.jpg 562w, https://builtformars.com/wp-content/uploads/2020/06/InternationalFixed-300x183.jpg 300w, https://builtformars.com/wp-content/uploads/2020/06/InternationalFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px"> </a>
</p>
</div>
</div>


<div data-id="b437d79" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>It cost <strong>at least ¬£20</strong> to send ¬£1 (GBP) to a US bank (USD) with three banks.</p>
</div>
</div>

<div data-id="f6c6bbc" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>‚ö°Ô∏è Includes <strong>12</strong><strong>&nbsp;case studies</strong></p>
</div>
</div>
</div>
</div>
</div>
<div data-id="8e4c759" data-element_type="column">
<div>
<div>
<div data-id="c4df7a5" data-element_type="widget" data-widget_type="image.default">
<div>
<p><a href="https://builtformars.com/banks/open-banking/">
<img width="562" height="343" src="https://builtformars.com/wp-content/uploads/2020/06/OpenBankingFixed.jpg" alt="" loading="lazy" srcset="https://builtformars.com/wp-content/uploads/2020/06/OpenBankingFixed.jpg 562w, https://builtformars.com/wp-content/uploads/2020/06/OpenBankingFixed-300x183.jpg 300w, https://builtformars.com/wp-content/uploads/2020/06/OpenBankingFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px"> </a>
</p>
</div>
</div>


<div data-id="977ae52" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>It took nearly <strong>4x longer</strong>&nbsp;to authorise an Open Banking payment with Lloyds than it did with Starling.</p>
</div>
</div>

<div data-id="4b3bec9" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>‚ö°Ô∏è Includes <strong>10</strong><strong>&nbsp;case studies</strong></p>
</div>
</div>
</div>
</div>
</div>
<div data-id="4ff6bfc" data-element_type="column">
<div>
<div>
<div data-id="3fac4a8" data-element_type="widget" data-widget_type="image.default">
<div>
<p><a href="https://builtformars.com/banks/support/">
<img width="562" height="343" src="https://builtformars.com/wp-content/uploads/2020/07/CustomerServiceFixed.jpg" alt="" loading="lazy" srcset="https://builtformars.com/wp-content/uploads/2020/07/CustomerServiceFixed.jpg 562w, https://builtformars.com/wp-content/uploads/2020/07/CustomerServiceFixed-300x183.jpg 300w, https://builtformars.com/wp-content/uploads/2020/07/CustomerServiceFixed-100x61.jpg 100w" sizes="(max-width: 562px) 100vw, 562px"> </a>
</p>
</div>
</div>


<div data-id="56418e4" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<p>Revolut only ever replied to <strong>20%</strong> of my live chat support messages, and don‚Äôt have a phone line.</p>
</div>
</div>

</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="178d96c" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">

</section>
<section data-id="d2d652f" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
<div>
<div>
<div data-id="39958a6" data-element_type="column">
<div>
<div>

<div data-id="bd6b341" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;none&quot;}" data-widget_type="heading.default">
<p>
<h4>Thank you for all your support</h4> </p>
</div>
</div>
</div>
</div>

</div>
</div>
</section>
<section data-id="832fa78" data-element_type="section">
<div>
<div>
<div data-id="4d4f429" data-element_type="column">
<div>
<div>
<div data-id="0df1ab9" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="2136" height="839" src="https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller.png" alt="" loading="lazy" srcset="https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller.png 2136w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-300x118.png 300w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-1024x402.png 1024w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-768x302.png 768w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-1536x603.png 1536w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-2048x804.png 2048w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-100x39.png 100w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-700x275.png 700w, https://builtformars.com/wp-content/uploads/2020/04/ATM-light-smaller-1600x628.png 1600w" sizes="(max-width: 2136px) 100vw, 2136px"> </p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="c7e323d" data-element_type="section">
<div>
<div>

<div data-id="75df2de" data-element_type="column">
<div>
<div>
 <div data-id="f2bc236" data-element_type="widget" data-widget_type="html.default">
<div>
<blockquote><p lang="en" dir="ltr">No research could be crisper in explaining the sense of "Frictionless experience" and Frictionless IT that I kept talking about for years. Must-read and must-subscribe. &gt; "What the challenger banks did differently" by <a href="https://twitter.com/PeteRamsey?ref_src=twsrc%5Etfw">@PeteRamsey</a> <a href="https://t.co/zWmxpYG0LT">https://t.co/zWmxpYG0LT</a></p>‚Äî Alessandro Perilli ‚ú™ AIÔø®AutomationÔø®Cybersecurity (@giano) <a href="https://twitter.com/giano/status/1263436408745844741?ref_src=twsrc%5Etfw">May 21, 2020</a></blockquote>  </div>
</div>




</div>
</div>
</div>
<div data-id="9072e4a" data-element_type="column">
<div>
<div>
<div data-id="c9ef61c" data-element_type="widget" data-widget_type="html.default">
<div>
<blockquote data-conversation="none"><p lang="en" dir="ltr">This should be required reading by every exec at traditional banks. Fantastic work</p>‚Äî Alex Barkley (@alexfintec) <a href="https://twitter.com/alexfintec/status/1264827065725059072?ref_src=twsrc%5Etfw">May 25, 2020</a></blockquote>  </div>
</div>




</div>
</div>
</div>

</div>
</div>
</section>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://builtformars.co.uk/banks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635364</guid>
            <pubDate>Wed, 30 Sep 2020 03:15:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nobody seems to give a crap about Google‚Äôs monopoly on search, not even Google]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24635322">thread link</a>) | @pcr910303
<br/>
September 29, 2020 | https://thejollyteapot.com/2020/09/29/nobody-seems-to-give-a-crap-about-google-s-monopoly-on-search-not-even-google | <a href="https://web.archive.org/web/*/https://thejollyteapot.com/2020/09/29/nobody-seems-to-give-a-crap-about-google-s-monopoly-on-search-not-even-google">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><a href="https://thejollyteapot.com/2020/09/29/nobody-seems-to-give-a-crap-about-google-s-monopoly-on-search-not-even-google">29 September 2020</a></p>
<p>Quick summary of the situation, from the <a href="https://www.android.com/choicescreen/">Choice Screen webpage on the Android website</a>:</p>
<blockquote>
<p>On August 2, 2019, following the European Commission‚Äôs July 2018 Android decision, Google announced that it would implement a choice screen for general search providers on all new Android phones and tablets shipped into the European Economic Area (<span>EEA</span>) where the Google Search app is pre-installed. This updated Help Center article describes a modified choice screen design that was developed in consultation with the European Commission.</p>
<p>The choice screen will appear during initial device setup and will feature multiple search providers, including Google. An illustrative version of the choice screen follows. Providers may vary by country. [‚Ä¶]</p>
<p>Eligible search providers will need to fill out an application form and can bid for inclusion based on an auction. The auction process is explained in greater detail below.</p>
</blockquote>
<p>Considering how much this farce has been <a href="https://www.neowin.net/news/duckduckgo-blasts-googles-android-choice-screen-says-it-incentivizes-ads">covered</a> <a href="https://techcrunch.com/2020/07/30/googles-no-choice-screen-on-android-isnt-working-says-ecosia-querying-the-eus-approach-to-antitrust-enforcement/">already</a>, I will not repeat what <a href="https://www.businessinsider.com/google-android-choice-screen-eu-duckduckgo-2020-9?IR=T">everybody knows</a>. Instead I will just point out how Google announced the result of the auctions <a href="https://www.android.com/choicescreen-winners/">on the Android website</a>: four sentences, two footnotes, a table listing the<span></span> <span>‚Äú</span>winners‚Äù per country, a title that reads do-not-give-a-shit, and that‚Äôs it.</p>
<p>Also, I don‚Äôt think I have ever heard of ‚Äî <em>check notes</em> ‚Äî PrivacyWall and info.com.<span></span> <span>‚Äô</span>What are they?‚Äô, you may ask: they are search engines apparently, and they are the only two search engine options offered to Android users in France that are not Google or Bing. And yes, in case you‚Äôre wondering, <a href="https://www.youtube.com/watch?v=nfHuZ5qrYX4">Bing is still around</a>. Ecosia, DuckDuckGo, barely appear on the list.</p>
<p>If anything, this whole thing will reinforce Google‚Äôs monopoly on search. Users will see this<span></span> <span>‚Äô</span>choice screen‚Äô and think:<span></span> <span>‚Äú</span><span>OK</span>, so two shady things I don‚Äôt know, Bing (laughs), and yep, Google. Why would they even ask me to choose?‚Äù</p>
<p>It‚Äôs like asking kids who have only ever watched the movie <em>Ratatouille</em> if they want to watch Ratatouille again, or another movie from this list: <a href="https://www.imdb.com/title/tt2120120/?ref_=fn_al_tt_1"><em>Pixels</em></a> (even the kids would know it sucks), <em><a href="https://www.imdb.com/title/tt0257778/?ref_=ttls_li_tt">The Hunchback of Notre Dame <span>II</span>: The Secret of the Bell</a></em> (you‚Äôre lucky if the kids even know about the first one), and <em><a href="https://www.imdb.com/title/tt0083630/?ref_=nv_sr_srsg_0">The Beastmaster</a></em>.</p>

          
          <p>
            <a href="https://thejollyteapot.com/tagged/technology">Technology</a>
          </p>

          
          


      

          <a href="https://thejollyteapot.com/2020/08/18/samsung-commits-to-deliver-three-years-of-android-updates-for-its-phones">
            <h5>Previous post</h5>
            <span>Samsung commits to deliver three years of Android updates for its phones</span>
            
          </a>

          <a href="https://thejollyteapot.com/2020/10/1/looking-back-at-my-short-list-of-apple-wishes-from-april">
            <h5>Next post</h5>
            <span>Looking back at my short list of Apple wishes from April</span>
          </a>

        </div></div>]]>
            </description>
            <link>https://thejollyteapot.com/2020/09/29/nobody-seems-to-give-a-crap-about-google-s-monopoly-on-search-not-even-google</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635322</guid>
            <pubDate>Wed, 30 Sep 2020 03:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Live dashboard of every email Trump and Biden are sending]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24635143">thread link</a>) | @greggblanchard
<br/>
September 29, 2020 | https://sendview.io/trump-v-biden | <a href="https://web.archive.org/web/*/https://sendview.io/trump-v-biden">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <!--
            <h2 style="margin-bottom: 25px;">
              <em class="fa fa-calendar"></em>
              Live Campaign Timeline
              <span>Last 50, Newest to Oldest</span>
            </h2>-->
            <div>
              <p>
                <h2>
                  <em></em>
                  Live Campaign Timeline
                  <span>Camapaigns Listed Newest to Oldest</span>
                </h2>
              </p>
              
              
            </div>
              
                                        <p><a href="https://sendview.io/s/a_9fNLqxPj6VmkFu7g" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                URGENT: √∞≈∏‚Äú≈Ω Video message from President Trump <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  55mins ago</span>
              </a></p><p>
                FRIDAY, OCT 2, 2020              </p>
                            <p><a href="https://sendview.io/s/a_KqnCSMGkw07LHFQZ" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                I'd like to give you a call <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  8:31pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_fSAgmyN2U7MGpI8H" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Lyin√¢‚Ç¨‚Ñ¢ Obama <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  5:26pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_hcWgLrIAMy5zpSFK" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                re: your RSVP for my event today <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  3:57pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_7iE9KWVLCjR3kozY" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Your Matching Check <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  3:15pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_CXtLcqnNoMbSPAz6" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                You√¢‚Ç¨‚Ñ¢re going to love this <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  2:12pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_XbEVhKT8d6nFH2oR" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                President Obama and Kamala are counting on you <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  1:37pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_1UjPHg54QoMSaYsu" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Your flight to Houston <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  7:15am</span>
              </a>
                                        <a href="https://sendview.io/s/a_IkizDcuOT8ylBC4H" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Update on our goal <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  5:13am</span>
              </a></p><p>
                THURSDAY, OCT 1, 2020              </p>
                            <p><a href="https://sendview.io/s/a_Rlb26OAG8p9JSZjq" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                You + Me in LA <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  11:10pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_T0cKaYwRMfSVeX5G" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Are you free tomorrow? <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  11:00pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_8wfpsh7CGvimO3nQ" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Become a Trump MVP <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:15pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_Ok52vWoDCfpXqJcA" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Your chance, Donald <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  8:13pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_nTg8lvFtqHN7rh2I" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                You, me, and President Obama tomorrow <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  7:36pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_C49HAINZvdL7qfYF" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                We√¢‚Ç¨‚Ñ¢ve got some just for you <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  7:10pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_F9iYc1rtlGE0ex8p" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                √∞≈∏≈í≈æ Sunny LA √∞≈∏≈í≈æ <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  6:13pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_FeVqHJo9mNEpId6j" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                We are in the fight of our life <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  5:10pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_986tWrmfPQL7d3TA" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Time is running out <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  3:24pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_BaW56ywqAEbDr7iP" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                President Obama and Kamala Harris want to know if you're free tomorrow <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  1:32pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_eBGadSwkztgQc6xF" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Congratulations! <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  1:28pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_1sBaJHTnCL6QMkhG" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                September 31st <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  11:46am</span>
              </a>
                                        <a href="https://sendview.io/s/a_P2Kcmzw5H38fXiB9" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Thank you for your support <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  10:36am</span>
              </a>
                                        <a href="https://sendview.io/s/a_u7YIdQZaELOiHhWm" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Let√¢‚Ç¨‚Ñ¢s meet up <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:07am</span>
              </a>
                                        <a href="https://sendview.io/s/a_fSjtBVY9CzRmWT35" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                It√¢‚Ç¨‚Ñ¢s not too late <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  7:13am</span>
              </a>
                                        <a href="https://sendview.io/s/a_MYU9n5oZziDfXmy6" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Take the Official Presidential Debate Approval Poll NOW <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  3:08am</span>
              </a>
                                        <a href="https://sendview.io/s/a_okW9C2DTvq8bdcwE" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                √∞≈∏≈°¬® End-of-Quarter ALERT √∞≈∏≈°¬® <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  1:07am</span>
              </a>
                                        <a href="https://sendview.io/s/a_4psIDmQouE7Oyg3G" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Your 850%-MATCHING check <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  12:07am</span>
              </a></p><p>
                WEDNESDAY, SEP 30, 2020              </p>
                            <p><a href="https://sendview.io/s/a_8PVaoth0nDJNEykg" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Will you be one of our final September donors? <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  11:23pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_RpcftUMWwi8JkxG3" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Deadline: MIDNIGHT <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  11:08pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_35UwrGOA0ezop4l8" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                We have to do this FIRST <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  10:07pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_sOn9lPbojwGCEKMu" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                FINAL THREE HOURS <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:07pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_g2hXH6RLT8MpJejP" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Election Day is ALMOST here <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  8:23pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_aT8wySMDbYRtKlQn" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Joe, Kamala, Barack, Hillary, and more all emailed you <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  8:00pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_mbgOeCs2aNpLfH3w" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                We need to CRUSH our goal <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  7:38pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_uW3BVxv78zT9oUjh" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                It√¢‚Ç¨‚Ñ¢s now or never <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  6:52pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_cuLdqJb0gS6zPXCQ" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                ONLY 6 hours to step up <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  6:08pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_e8MqBiXOY4bt2Fzm" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                I'm worried we might fall short <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  5:42pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_g6weXC74azqjEROk" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                FINAL NOTICE <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  5:21pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_ZGMDk7Jf520IUnHE" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                We need to keep going <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  4:06pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_gGD6aAfpl1SZ2W7i" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                BIDEN WILL PACK THE COURTS <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  2:10pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_EAJO4ailPtzcrvj2" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                I'm asking personally <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  12:45pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_YRjK5yF0L6euZxVi" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                √¢ÔøΩ¬∞√¢ÔøΩ¬∞ 12-hour deadline alert √¢ÔøΩ¬∞√¢ÔøΩ¬∞ <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  12:00pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_UC0hbDl6nYpSAFq9" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                Please <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  10:40am</span>
              </a>
                                        <a href="https://sendview.io/s/a_i8Wxynv2m4AYKISe" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                √¢≈ì‚Äù√Ø¬∏ÔøΩ First Presidential Debate <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:09am</span>
              </a>
                                        <a href="https://sendview.io/s/a_PqzUhvEjTtuSNp3A" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                What did you think of the debate? <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  7:09am</span>
              </a>
                                        <a href="https://sendview.io/s/a_8yrCmnIS4P7ZwaMc" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Special 800%-MATCH <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  5:08am</span>
              </a>
                                        <a href="https://sendview.io/s/a_T3yfNaQluA6vPtpX" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Did you watch the debate? <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  3:05am</span>
              </a>
                                        <a href="https://sendview.io/s/a_GT7vWI6naMJZkmXc" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                I√¢‚Ç¨‚Ñ¢m upping the stakes <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  2:09am</span>
              </a>
                                        <a href="https://sendview.io/s/a_lnjKFNfErRepQAGg" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                800%-MATCH <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  1:09am</span>
              </a>
                                        <a href="https://sendview.io/s/a_N4Fuym97MhcG6RAx" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/biden-shot-e1601143284384.jpg" alt="Joe Biden" title="Joe Biden">
                I hope I made you proud <em></em>
                <span>Biden &nbsp; / &nbsp;  
                  12:30am</span>
              </a>
                                        <a href="https://sendview.io/s/a_s1EUWeLk89dGDzp2" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                √∞≈∏≈°¬® 850%-MATCH √∞≈∏≈°¬® <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  12:09am</span>
              </a></p><p>
                TUESDAY, SEP 29, 2020              </p>
                            <p><a href="https://sendview.io/s/a_h8VmH9snxRl7GyJ3" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                I just stepped off stage <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  11:05pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_Yd1aZVuA8hbsSweX" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                My father is debating Joe Biden <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  10:40pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_4uZ0b1Ne9jEkwOgV" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Make it the BEST quarter EVER <em></em>
                <span>Trump &nbsp; / &nbsp;  
                  9:28pm</span>
              </a>
                                        <a href="https://sendview.io/s/a_HXN4R8D5sVU6hcfy" target="_blank">
                <img src="https://sendview.io/wp-content/uploads/2020/09/trump-shot-e1601143360836.jpg" alt="Donald Trump" title="Donald Trump">
                Are you watching my father debate? <em></em>
                <span>Trump &nbsp; / &nbsp;  
            ‚Ä¶</span></a></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sendview.io/trump-v-biden">https://sendview.io/trump-v-biden</a></em></p>]]>
            </description>
            <link>https://sendview.io/trump-v-biden</link>
            <guid isPermaLink="false">hacker-news-small-sites-24635143</guid>
            <pubDate>Wed, 30 Sep 2020 02:25:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I tracked and analyzed 13,159 Hacker News posts. Here's what I learned]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24634991">thread link</a>) | @mellosouls
<br/>
September 29, 2020 | https://www.ankle.io/posts/hacker-news-analysis | <a href="https://web.archive.org/web/*/https://www.ankle.io/posts/hacker-news-analysis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="motivation"><a href="#motivation" aria-label="motivation permalink"></a>Motivation</h2>
<p>Hitting the front page of Hacker News is an incredible source of short-term traffic to your website or article.</p>
<p>According to this <a href="https://thehftguy.com/2017/09/26/hitting-hacker-news-front-page-how-much-traffic-do-you-get" rel="nofollow">article</a>, in 2017, being on the front page brings a sudden influx of between 10k and 30k visitors to your website/article, something many content marketers, product people, and entrepreneurs undoubtedly salivate over, including me.</p>
<p>I occasionally post to Hacker News (with random things and personal stuff) but have never reached the front page before. Therefore, I decided to dig a little deeper into the mechanics of Hacker News and the best approach to take if the sole goal is to hit the front page.</p>
<p>Obviously, a critical part of hitting the front page is submitting an interesting article which resonates with the HN audience. But beyond this, there are other factors at play‚Äîtiming, title, upvotes, etc.</p>
<h2 id="methodology-a-unique-approach"><a href="#methodology-a-unique-approach" aria-label="methodology a unique approach permalink"></a>Methodology: A unique approach</h2>
<p>I am not the only person to want to know the best approach to hitting the front page. A few people have analyzed data from <a href="https://console.cloud.google.com/marketplace/details/y-combinator/hacker-news" target="_blank" rel="nofollow noopener noreferrer">Google‚Äôs Hacker News Dataset</a> on BigQuery to find the best time to submit to Hacker News.</p>
<p>The problem with this approach is that BigQuery doesn‚Äôt know how long a post spent on the front page, nor how long it was there for or what position it reached. It can only provide the total number of upvotes.</p>
<p>With this in mind, I wrote a small NodeJS script to poll Hacker News every 2 minutes. Using a Postgres database, I stored every post, user, and upvote over two weeks.</p>
<p>With this information, I compiled a list of useful information and insights below.</p>
<p>Note: To filter out posts that are either flagged or transiently featured, I set an arbitrary duration of 60+ minutes as a time requirement in the top for a post to be considered a ‚Äúfront page post.‚Äù</p>
<h2 id="limitations"><a href="#limitations" aria-label="limitations permalink"></a>Limitations</h2>
<p>Obviously, the lack of data (13,159 posts) and time spent collecting data (2 weeks) is the most significant limitation of my results. Nonetheless, I believe the results are still relatively useful, at least for the next few weeks or months.</p>
<h2 id="results"><a href="#results" aria-label="results permalink"></a>Results</h2>
<h3 id="basic-stats"><a href="#basic-stats" aria-label="basic stats permalink"></a>Basic stats</h3>
<ul>
<li>I tracked a total of 13,159 posts over two weeks.</li>
<li>Of these, 1,073 made the front page for more than 60 minutes.</li>
<li>That‚Äôs a hit rate of 8.15%</li>
<li>Frontpage posts stayed at the top for an average of 483.3 minutes (8 hours)</li>
<li>30% of posts reaching the front page were posted by users who posted more than once over the two weeks.</li>
</ul>
<p><strong>Takeaway:</strong> In my opinion, more posts reach the front page than expected and for longer than expected.</p>
<h3 id="types-of-posts-breakdown"><a href="#types-of-posts-breakdown" aria-label="types of posts breakdown permalink"></a>Types of posts breakdown</h3>

<h3 id="hit-rate--of-different-post-types-making-the-front-page"><a href="#hit-rate--of-different-post-types-making-the-front-page" aria-label="hit rate  of different post types making the front page permalink"></a>Hit rate % of different post types making the front page</h3>

<p><strong>Takeaway:</strong> Interestingly, ‚ÄúShow HN‚Äù posts make the front page by proportion very slightly less than ‚ÄúLinks,‚Äù which goes against previous thought that ‚ÄúShow HN‚Äù posts perform better due to an algorithm bias. That being said, there may well be an algorithm bias, just many ‚ÄúShow HN‚Äù posts are simply not worth upvoting.</p>
<h3 id="when-is-the-best-day-to-post-to-hacker-news-in-2020"><a href="#when-is-the-best-day-to-post-to-hacker-news-in-2020" aria-label="when is the best day to post to hacker news in 2020 permalink"></a>When is the best day to post to Hacker News in 2020?</h3>

<p>The chart above shows that you should post on the weekend to stand the best chance of reaching the front page of Hacker News. The difference from the worst to the best day is only 3.2%, so there‚Äôs not a lot in it.</p>
<p>The weekend likely gives you a higher chance to reach the front page because fewer posts are submitted, probably due to lower traffic.</p>
<p><strong>Takeaway</strong>: If your goal is to reach the front page regardless of traffic, posting on the weekend is your best bet. However, because the difference in chance is relatively low throughout the week, posting on a more popular day might be a better risk-reward ratio based on the considerable difference in the traffic you‚Äôd likely receive.</p>
<h3 id="when-is-the-best-time-to-post-to-hacker-news-in-2020"><a href="#when-is-the-best-time-to-post-to-hacker-news-in-2020" aria-label="when is the best time to post to hacker news in 2020 permalink"></a>When is the best time to post to Hacker News in 2020?</h3>

<p>Taking a more granular look at the combined hours of all the posts submitted, the chart above highlights a much more significant difference (10.9%) between the chance of reaching the front page of Hacker News.</p>
<p>The best time to post to Hacker News is between 6 am‚Äî12 pm UTC (11 pm‚Äî5 am PDT). Again, the reason is likely because this is when the website traffic is at it‚Äôs lowest, and therefore the competition is relatively low.</p>
<p>I imagine the US is responsible for most of Hacker News‚Äôs web traffic, which lines up with the results above. Therefore, if you are posting a link for a US-specific audience to HN, it‚Äôs probably best to pick a different time like 4 pm UTC (9 am PDT), or midnight UTC (5 pm PDT).</p>
<p><strong>Takeaway:</strong> If your link requires a US-specific audience, post at 4 pm UTC (9 am PDT / 12 pm EDT), or midnight UTC (5 pm PDT). Otherwise, post between 6 am‚Äî12 pm UTC (11 pm‚Äî5 am PDT) for the best chance of reaching the front page of Hacker News.</p>
<h3 id="when-in-the-best-day-and-time-to-post-to-hacker-news-in-2020"><a href="#when-in-the-best-day-and-time-to-post-to-hacker-news-in-2020" aria-label="when in the best day and time to post to hacker news in 2020 permalink"></a>When in the best day and time to post to Hacker News in 2020?</h3>
<p>Combining both days and hours into a total weekly picture is even more evident when it is best to post. However, please note, the lack of data makes this chart vulnerable to skewed results.</p>

<p>The chart above illustrates wild fluctuations between the different hours of the week. The lowest chance of reaching the front page is 1-2%, and the highest is 18%-27%. That‚Äôs a massive difference.</p>
<p>Looking at the chart, below are generally the best days &amp; times to post to Hacker News:</p>
<ul>
<li><strong>Monday:</strong> 1 am‚Äî4 pm UTC (6 pm‚Äî9 am PDT)</li>
<li><strong>Tuesday, Wednesday &amp; Thursday:</strong> 12 am‚Äî6 am &amp; 9 am‚Äî12 pm UTC (5 pm‚Äî11 pm &amp; 2 am‚Äî5 am PDT)</li>
<li><strong>Friday:</strong> 5 am‚Äî12 pm UTC (10 pm‚Äî5 am PDT)</li>
<li><strong>Saturday:</strong> 4 am‚Äî9 am UTC (9 pm‚Äî2 am PDT)</li>
<li><strong>Sunday:</strong> 3 am‚Äî8 am &amp; 10 am‚Äî6 pm UTC (8 pm‚Äî1 am &amp; 3 am‚Äî11 am PDT)</li>
</ul>
<p>And here are the best times specifically (bear in mind these may not be the case week-in-week-out because the amount of data limits the results):</p>
<ul>
<li><strong>Monday:</strong> 12 pm UTC (5 am PDT)</li>
<li><strong>Tuesday:</strong> 9 am UTC (2 am PDT)</li>
<li><strong>Wednesday:</strong> 10 am UTC (3 am PDT)</li>
<li><strong>Thursday:</strong> 12 pm UTC (5 pm PDT)</li>
<li><strong>Friday:</strong> 8 am UTC (1 am PDT)</li>
<li><strong>Saturday:</strong> 9 am UTC (2 am PDT)</li>
<li><strong>Sunday:</strong> 5 am OR 1 pm (10 pm OR 6 am PDT)</li>
</ul>
<p><strong>Takeaway:</strong> It‚Äôs pretty clear that the best times to post on Hacker News to reach the front page are usually around 6 am UTC (11 pm PDT), 9 am UTC (2 am PDT), or 12 pm UTC (5 am PDT), when the US is asleep.</p>
<p>However, given that 8 hours is the average time spent on the front page, it‚Äôs probably best to post at 12 pm UTC on Monday, Thursday, Saturday or Sunday to maximize traffic for when the US wakes up.</p>
<h3 id="how-many-votes-does-a-post-need-to-reach-the-front-page-of-hacker-news-in-2020"><a href="#how-many-votes-does-a-post-need-to-reach-the-front-page-of-hacker-news-in-2020" aria-label="how many votes does a post need to reach the front page of hacker news in 2020 permalink"></a>How many votes does a post need to reach the front page of Hacker News in 2020?</h3>
<p>5.22 is the average number of votes a post needed within an average time of 27.1 minutes to reach the front page for the first time.</p>
<p>Below is a chart of box plots to illustrate the variation of votes required over 24 hours.</p>

<p>Interestingly, this graph clearly shows every post, regardless of time, required at least three upvotes, and for 75% of posts, they never needed more than eight votes to reach the front page of Hacker News.</p>
<p>Expectedly, the range of upvotes required is lower for the first half of the day than the second half, roughly matching up to the timings above.</p>
<p>In some cases, posts required a lot more votes to reach the front page. Presumably, because either the time it took to get these votes was over more time, or there was a lot of competition.</p>
<p><strong>Takeaway:</strong> The votes required to be seen on the front page is relatively small. For the best chance of getting on the front page, you‚Äôll need between 4-6 votes in about 30 minutes, posting in the first half of the day (12 am‚Äî12pm UTC).</p>
<h3 id="how-much-karma-do-you-need-to-reach-the-front-page-of-hacker-news-in-2020"><a href="#how-much-karma-do-you-need-to-reach-the-front-page-of-hacker-news-in-2020" aria-label="how much karma do you need to reach the front page of hacker news in 2020 permalink"></a>How much karma do you need to reach the front page of Hacker News in 2020?</h3>
<p>Finally, I thought it would be interesting to see the relationship between karma and reaching the front page of Hacker News.</p>
<p>This first pie chart demonstrates the proportion of posts being posted by users with varying levels of karma.</p>

<p>Surprisingly, over 50% of posts are submitted by users with over 1,000 karma points. However, the largest single segment is by users with little to no karma.</p>

<p>The chart above shows that newer users (0-50 karma) make the front page proportionally less than more experienced users. Interestingly, really experienced users (over 10,000 karma) reached the front page significantly more than experienced users.</p>
<p><strong>Takeaway:</strong> It‚Äôs hard to say whether karma has anything to do with rankings. Likely, users with more karma are just better at posting content that resonates with the Hacker News audience.</p></div></div>]]>
            </description>
            <link>https://www.ankle.io/posts/hacker-news-analysis</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634991</guid>
            <pubDate>Wed, 30 Sep 2020 01:43:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guima Cloud ‚Äì TLA+ Online Simple REPL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24634705">thread link</a>) | @pfeodrippe
<br/>
September 29, 2020 | https://guima.cloud/editor?state=ezpibG9jay9ibG9ja3MgW3s6YmxvY2sucmVwbC9jb2RlICIoKiA8LS0gQmVnaW5uaW5nIG9mIGEgY29tbWVudGFyeS5cbiAgICBcbiAgSGksIHRoaXMgaXMgeW91ciBvbmxpbmUgVExBKyBSRVBMIChub24tb2ZpY2lhbCksXG4gIHdlbGNvbWUgby9cbiAgIFxuICBVc2UgQ1RSTCtFTlRFUiB0byBldmFsIHRoZSBSRVBMIGNvZGUsXG4gIEFMVCtFTlRFUiB0byBjcmVhdGUgYSBuZXcgUkVQTCBibG9jay4uLiBhbmQgdGhhdCBpcyBhbGwuXG4gICAgXG4gIFNlZSByZXN1bHQgYXQgdGhlIHJpZ2h0IG9mIHRoZSBibG9jay5cbiAgICBcbiAgU2hhcmUgd2l0aCB5b3VyIGZyaW5kIHVzaW5nIHRoZSBcIlNoYXJlXCIgYnV0dG9uIGF0IHRoZSB0b3AgKHRoZSB1cmxcbiAgaXMgY29wcGllZCB0byB5b3VyIGNsaXBib2FyZCkuXG4gICAgXG4gIFRoaXMgaXMgYSB2ZXJ5IHJvdWdoIGV4cGVyaW1lbnQsIGhhdmUgZnVuLCBzaGFyZSBrbm93bGVkZ2UuXG4gICAgXG4gIFdlIGxldmVyYWdlIFwiaHR0cHM6Ly9naXRodWIuY29tL3RsYXBsdXMvUGx1c1B5XCIgdG8gcnVuIHRoZSBjb2RlLCBcbiAgYXdlc29tZSBwcm9qZWN0ISEgXG4gIFxuICBTZWUgXCJodHRwczovL2xlYXJudGxhLmNvbVwiIHRvIGxlYXJuIFRMQSsgc3ludGF4LlxuICAgIFxuICBIZWF2aWx5IGluc3BpcmVkICh5b3UgY291bGQgc2F5IGNvcGllZCkgYnkgXCJodHRwczovL3d3dy5tYXJpYS5jbG91ZC9cIiA9RFxuICBcbiAgRW5kIG9mIGEgY29tbWVudGFyeS4gLS0+ICopIn0gezpibG9jay5yZXBsL2NvZGUgIigqIEEgc3VtICopXG4xICsgNCJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDcmVhdGVzIGEgc2V0IHNxdWFyaW5nIGEgbnVtYmVyLCB3aGVyZSB0aGlzIG51bWJlciBpc1xuICAgYSBlbGVtZW50IG9mIHRoZSBzZXQgezEsIDJ9ICopXG57eCAqIHggOiB4IFxcaW4gezEsIDJ9fSJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDb25jYXQgbGlzdCAqKVxuPDwgMSA+PiBcXG8gPDwgMiwgMyA+PiJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBUaGlzIHdpbGwgcmFpc2UgYW4gZXJyb3IsIHNlZSBzb2x1dGlvbiBhdCB0aGUgbmV4dCBibG9jayAqKVxuU29tZXRoaW5nID09IDJcbjEgKyBTb21ldGhpbmcifSB7OmJsb2NrLnJlcGwvY29kZSAiKCogRm9yIG11bHRpbGluZSBibG9ja3MsIHVzZSA0IC0gLSAtIC0gKilcblNvbWV0aGluZyA9PSAyXG4tLS0tXG4xICsgU29tZXRoaW5nIn1dfQ== | <a href="https://web.archive.org/web/*/https://guima.cloud/editor?state=ezpibG9jay9ibG9ja3MgW3s6YmxvY2sucmVwbC9jb2RlICIoKiA8LS0gQmVnaW5uaW5nIG9mIGEgY29tbWVudGFyeS5cbiAgICBcbiAgSGksIHRoaXMgaXMgeW91ciBvbmxpbmUgVExBKyBSRVBMIChub24tb2ZpY2lhbCksXG4gIHdlbGNvbWUgby9cbiAgIFxuICBVc2UgQ1RSTCtFTlRFUiB0byBldmFsIHRoZSBSRVBMIGNvZGUsXG4gIEFMVCtFTlRFUiB0byBjcmVhdGUgYSBuZXcgUkVQTCBibG9jay4uLiBhbmQgdGhhdCBpcyBhbGwuXG4gICAgXG4gIFNlZSByZXN1bHQgYXQgdGhlIHJpZ2h0IG9mIHRoZSBibG9jay5cbiAgICBcbiAgU2hhcmUgd2l0aCB5b3VyIGZyaW5kIHVzaW5nIHRoZSBcIlNoYXJlXCIgYnV0dG9uIGF0IHRoZSB0b3AgKHRoZSB1cmxcbiAgaXMgY29wcGllZCB0byB5b3VyIGNsaXBib2FyZCkuXG4gICAgXG4gIFRoaXMgaXMgYSB2ZXJ5IHJvdWdoIGV4cGVyaW1lbnQsIGhhdmUgZnVuLCBzaGFyZSBrbm93bGVkZ2UuXG4gICAgXG4gIFdlIGxldmVyYWdlIFwiaHR0cHM6Ly9naXRodWIuY29tL3RsYXBsdXMvUGx1c1B5XCIgdG8gcnVuIHRoZSBjb2RlLCBcbiAgYXdlc29tZSBwcm9qZWN0ISEgXG4gIFxuICBTZWUgXCJodHRwczovL2xlYXJudGxhLmNvbVwiIHRvIGxlYXJuIFRMQSsgc3ludGF4LlxuICAgIFxuICBIZWF2aWx5IGluc3BpcmVkICh5b3UgY291bGQgc2F5IGNvcGllZCkgYnkgXCJodHRwczovL3d3dy5tYXJpYS5jbG91ZC9cIiA9RFxuICBcbiAgRW5kIG9mIGEgY29tbWVudGFyeS4gLS0+ICopIn0gezpibG9jay5yZXBsL2NvZGUgIigqIEEgc3VtICopXG4xICsgNCJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDcmVhdGVzIGEgc2V0IHNxdWFyaW5nIGEgbnVtYmVyLCB3aGVyZSB0aGlzIG51bWJlciBpc1xuICAgYSBlbGVtZW50IG9mIHRoZSBzZXQgezEsIDJ9ICopXG57eCAqIHggOiB4IFxcaW4gezEsIDJ9fSJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDb25jYXQgbGlzdCAqKVxuPDwgMSA+PiBcXG8gPDwgMiwgMyA+PiJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBUaGlzIHdpbGwgcmFpc2UgYW4gZXJyb3IsIHNlZSBzb2x1dGlvbiBhdCB0aGUgbmV4dCBibG9jayAqKVxuU29tZXRoaW5nID09IDJcbjEgKyBTb21ldGhpbmcifSB7OmJsb2NrLnJlcGwvY29kZSAiKCogRm9yIG11bHRpbGluZSBibG9ja3MsIHVzZSA0IC0gLSAtIC0gKilcblNvbWV0aGluZyA9PSAyXG4tLS0tXG4xICsgU29tZXRoaW5nIn1dfQ==">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://guima.cloud/editor?state=ezpibG9jay9ibG9ja3MgW3s6YmxvY2sucmVwbC9jb2RlICIoKiA8LS0gQmVnaW5uaW5nIG9mIGEgY29tbWVudGFyeS5cbiAgICBcbiAgSGksIHRoaXMgaXMgeW91ciBvbmxpbmUgVExBKyBSRVBMIChub24tb2ZpY2lhbCksXG4gIHdlbGNvbWUgby9cbiAgIFxuICBVc2UgQ1RSTCtFTlRFUiB0byBldmFsIHRoZSBSRVBMIGNvZGUsXG4gIEFMVCtFTlRFUiB0byBjcmVhdGUgYSBuZXcgUkVQTCBibG9jay4uLiBhbmQgdGhhdCBpcyBhbGwuXG4gICAgXG4gIFNlZSByZXN1bHQgYXQgdGhlIHJpZ2h0IG9mIHRoZSBibG9jay5cbiAgICBcbiAgU2hhcmUgd2l0aCB5b3VyIGZyaW5kIHVzaW5nIHRoZSBcIlNoYXJlXCIgYnV0dG9uIGF0IHRoZSB0b3AgKHRoZSB1cmxcbiAgaXMgY29wcGllZCB0byB5b3VyIGNsaXBib2FyZCkuXG4gICAgXG4gIFRoaXMgaXMgYSB2ZXJ5IHJvdWdoIGV4cGVyaW1lbnQsIGhhdmUgZnVuLCBzaGFyZSBrbm93bGVkZ2UuXG4gICAgXG4gIFdlIGxldmVyYWdlIFwiaHR0cHM6Ly9naXRodWIuY29tL3RsYXBsdXMvUGx1c1B5XCIgdG8gcnVuIHRoZSBjb2RlLCBcbiAgYXdlc29tZSBwcm9qZWN0ISEgXG4gIFxuICBTZWUgXCJodHRwczovL2xlYXJudGxhLmNvbVwiIHRvIGxlYXJuIFRMQSsgc3ludGF4LlxuICAgIFxuICBIZWF2aWx5IGluc3BpcmVkICh5b3UgY291bGQgc2F5IGNvcGllZCkgYnkgXCJodHRwczovL3d3dy5tYXJpYS5jbG91ZC9cIiA9RFxuICBcbiAgRW5kIG9mIGEgY29tbWVudGFyeS4gLS0+ICopIn0gezpibG9jay5yZXBsL2NvZGUgIigqIEEgc3VtICopXG4xICsgNCJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDcmVhdGVzIGEgc2V0IHNxdWFyaW5nIGEgbnVtYmVyLCB3aGVyZSB0aGlzIG51bWJlciBpc1xuICAgYSBlbGVtZW50IG9mIHRoZSBzZXQgezEsIDJ9ICopXG57eCAqIHggOiB4IFxcaW4gezEsIDJ9fSJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBDb25jYXQgbGlzdCAqKVxuPDwgMSA+PiBcXG8gPDwgMiwgMyA+PiJ9IHs6YmxvY2sucmVwbC9jb2RlICIoKiBUaGlzIHdpbGwgcmFpc2UgYW4gZXJyb3IsIHNlZSBzb2x1dGlvbiBhdCB0aGUgbmV4dCBibG9jayAqKVxuU29tZXRoaW5nID09IDJcbjEgKyBTb21ldGhpbmcifSB7OmJsb2NrLnJlcGwvY29kZSAiKCogRm9yIG11bHRpbGluZSBibG9ja3MsIHVzZSA0IC0gLSAtIC0gKilcblNvbWV0aGluZyA9PSAyXG4tLS0tXG4xICsgU29tZXRoaW5nIn1dfQ==</link>
            <guid isPermaLink="false">hacker-news-small-sites-24634705</guid>
            <pubDate>Wed, 30 Sep 2020 00:42:13 GMT</pubDate>
        </item>
    </channel>
</rss>
