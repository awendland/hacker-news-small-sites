<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 03 Aug 2020 08:19:41 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 03 Aug 2020 08:19:41 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Projecting Bitcoin’s Price with Popularity (Google Trends)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24019023">thread link</a>) | @hackernewsreadr
<br/>
August 1, 2020 | https://blogofjake.com/2020/07/31/projecting-bitcoins-price-with-popularity-google-trends/ | <a href="https://web.archive.org/web/*/https://blogofjake.com/2020/07/31/projecting-bitcoins-price-with-popularity-google-trends/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><strong><span>A Tale of Two Charts</span></strong></p>



<p>The chart below shows the monthly average <a href="https://www.coindesk.com/price/bitcoin">price of bitcoin</a> since October 2013.</p>



<figure><img data-attachment-id="1238" data-permalink="https://blogofjake.com/image-26/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-26.png" data-orig-size="782,307" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-26" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=782" src="https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=782" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-26.png 782w, https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=768 768w" sizes="(max-width: 782px) 100vw, 782px"></figure>



<p>This second chart shows the <a href="https://trends.google.com/trends/explore?date=all&amp;q=bitcoin">Google Trends Score</a> by month for the search term “bitcoin”, also since October 2013.</p>



<figure><img data-attachment-id="1239" data-permalink="https://blogofjake.com/image-27/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-27.png" data-orig-size="783,307" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-27" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-27.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>When I first saw the second chart, I thought it looked remarkably similar to the first. Sure enough, it does. Below are the two charts together. The darker line shows the price according to the left-side axis and the lighter line shows the Google Trends Score according to the right-side axis.</p>



<figure><img data-attachment-id="1240" data-permalink="https://blogofjake.com/image-28/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-28.png" data-orig-size="783,306" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-28" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-28.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>It turns out that bitcoin’s price and its Google Trends Score are quite correlated.</p>



<p>Specifically, they have had a 72% positive correlation since October 2013. This compares favorably to bitcoin’s <a href="https://cointelegraph.com/news/bitcoins-correlation-with-gold-is-weakening-says-new-kraken-report">26% correlation with the stock market and 24% correlation with gold</a> over the last year.</p>



<p>I should note that the correlation between bitcoin’s price and its Google Trends Score was much stronger up until both price and score peaked in December 2017 (98%) than it has been since (59%).</p>



<p>Nonetheless, the purpose of this analysis is not to argue about the level of correlation nor to assert causation one way or another (though it seems logical that the price and popularity feed off of each other). Rather, the purpose of this analysis is to make a speculative projection regarding what bitcoin’s price could be if and when its popularity (as measured by its Google Trends Score) returns to and surpasses its previous all-time high.</p>



<p>In order to make this projection, we first must consider the historical ratio between bitcoin’s average price and its Google Trends Score on a monthly basis. Let us refer to this as the <em><strong>price:score ratio</strong></em><strong> </strong>for short.</p>



<p><strong><span>Bitcoin’s Price:Score Ratio</span></strong></p>



<p>The chart below shows how bitcoin’s price:score ratio has increased over the last several years.</p>



<figure><img data-attachment-id="1241" data-permalink="https://blogofjake.com/image-29/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-29.png" data-orig-size="783,307" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-29" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-29.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>For a ratio that has been relatively volatile historically, it has remained unusually consistent for the last two months (June &amp; July) at 729, just 4% short of its all-time high of 758 in November 2019.</p>



<p>Bitcoin’s price:score ratio has been above 645 for 9 of the last 12 months after having only reached such a level once before, and barely (646 in October 2018).</p>



<p>The 3 months in the last year during which the ratio was lower than 645 can be fairly easily explained. They took place this past March, April, and May as hype grew in anticipation of bitcoin’s once every four years halving event on May 11, 2020. Additionally, people perhaps were searching more than usual for information about alternative assets (including bitcoin) when the stock market crashed ~30% in the early days of the lockdown resulting from the pandemic. Those two factors together seem sufficient to explain the uptick in bitcoin’s Google Trends Score over that period. On the other side of the price:score ratio, bitcoin’s price fell along with the market, and so with the price going down and the score going up, the decreased price:score ratio over those few months makes sense.</p>



<p>Since the stock market substantially recovered and the halving event came and went without materially moving bitcoin’s price, the Google Trends Score has returned to the pre-pandemic, pre-halving-hype range. For the last two months (June &amp; July), bitcoin’s monthly Google Trends Score has stayed steady at 13, which is equal to its average from April 2018 (after the peak) through February 2020 (before the halving hype and market crash).</p>



<p>For some additional context, it should be noted that bitcoin’s Google Trends Score has only been equal to or greater than 21 in 7 months since bitcoin’s inception and they all took place consecutively surrounding bitcoin’s last major surge from September 2017 through March 2018 (with scores chronologically of 21, 22, 44, 100, 55, 39, and 23).</p>



<p><strong><span>Flying Under The Radar</span></strong></p>



<p>Sufficed to say, bitcoin’s average score of 13 since the last surge, excluding the three aforementioned months from earlier this year (14 if we include them), shows objectively that bitcoin is flying under the radar (in terms of its popularity as a search term at least). Of course, it may not seem this way to people who follow crypto closely and daily but the algorithmic and mass-data collecting Google Trends Score should be trusted over any single person’s speculative and subjective observation about the current level of hype and attention.</p>



<p>If you, like me, believe that bitcoin is and has been flying under the radar for more than two years now, the natural question to ask is this. What do we expect to happen when that is no longer the case? In other words, what happens to bitcoin’s price if and when it reaches the pinnacle of its next hype cycle? How high might bitcoin fly the next time we see a situation similar to that of December 2017?</p>



<p><strong><span>Projecting Bitcoin’s Price</span></strong></p>



<p>I believe a reasonable response to this question can be made by applying bitcoin’s average price:score ratio over the last twelve months (643) to a Google Trends Score of 100 to estimate what bitcoin’s price would be if the price:score ratio stays about constant and bitcoin’s popularity in terms of search returns to its all-time high. The price implied by this projection is about $65,000 as is demonstrated by the maximum value in the top right corner of the chart below. Basically, if one believes that bitcoin will at least at some point return to the level of popularity it attained in December 2017, this methodology would lead that person to expect bitcoin to attain a price of at least $60,000 at that time.</p>



<figure><img data-attachment-id="1242" data-permalink="https://blogofjake.com/image-30/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-30.png" data-orig-size="783,308" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-30" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-30.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>This estimate can be made less conservative in two ways. The first is to assume that the price:score ratio will continue to increase as it has all along (6% month-over-month), rather than calculating the price using the LTM average of the ratio. The second is to assume that bitcoin’s popularity as a search term will well surpass its previous all-time high set in December 2017 just as that all-time was more than twice as great as any high before it and more than 8 times greater than the all-time high before May 2017 (which was set in December 2013, perhaps not coincidentally exactly 4 years or one halving period prior to the latest all-time high). I hesitate to call either of these two less conservative assumptions aggressive because they are not only reasonable but actually probable if one is to simply assume that the historical trends will continue in terms of the score and the ratio.</p>



<p>As such, I will close by presenting a chart which one can use to approximate the price implied by their own inputs for the Google Trends Score and the price:score ratio. In this chart, I show the ratio for the last 12 months, 2 years, 3 years, and so on, and use the average year-over-year growth rate between those figures (16%) to project the next twelve months (“NTM”), next two years (“N2Y”), and next three years (“N3Y”) ratios.</p>



<p>The highest price projected on the chart is right around $300,000 based on a Google Trends Score of 3 times the previous all-time high (300) and a projected N3Y price:score ratio of 996 (the LTM average of 643 increased 16% 3 times for 3 years). Of course, this maximum price projection is limited only arbitrarily by the maximums I have decided to present on this chart for both the score and the ratio.</p>



<figure><img data-attachment-id="1243" data-permalink="https://blogofjake.com/image-31/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-31.png" data-orig-size="783,306" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-31" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-31.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p><strong><span>To Be Continued…</span></strong></p>



<p>Many people have employed many methodologies in attempting to accurately project bitcoin’s price. For example, <a href="https://medium.com/@100trillionUSD">PlanB</a>‘s stock to flow ratio looks at scarcity to make one of the more convincing price projections I’ve seen. My price:score ratio looks at popularity in endeavoring to do the same. This analysis was not intended to be totally comprehensive. My intention was merely to introduce this methodology for others to critique. As such, my hope is that this becomes widely enough read so that I may receive ample critical feedback for further consideration and refinement of the methodology.</p>



<p><em>As always, I welcome all outreach to jake@blogofjake.com and any comments on Twitter <a href="https://twitter.com/blogofjake">@blogofjake</a></em></p>
	</div></div>]]>
            </description>
            <link>https://blogofjake.com/2020/07/31/projecting-bitcoins-price-with-popularity-google-trends/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24019023</guid>
            <pubDate>Sat, 01 Aug 2020 09:21:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to correctly ask a customer how much they are willing to pay]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24018272">thread link</a>) | @alfahad
<br/>
July 31, 2020 | https://theunconventional.blog/how-to-survey-product-pricing/ | <a href="https://web.archive.org/web/*/https://theunconventional.blog/how-to-survey-product-pricing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://theunconventional.blog/content/images/size/w300/2020/07/pricing1.jpg 300w,
                            https://theunconventional.blog/content/images/size/w600/2020/07/pricing1.jpg 600w,
                            https://theunconventional.blog/content/images/size/w1000/2020/07/pricing1.jpg 1000w,
                            https://theunconventional.blog/content/images/size/w2000/2020/07/pricing1.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://theunconventional.blog/content/images/size/w2000/2020/07/pricing1.jpg" alt="How to correctly ask a customer how much they are willing to pay">
            </figure>

            <section>
                <div>
                    <p><strong><em>We can take advantage of the way humans think about value.</em></strong></p><p>We know that the computer you are using is <strong>worth more</strong> than the water bottle that is on the table. That is just something we inherently know. <strong>Why?</strong> Because we probably purchased water in the past, we recognize the price of a computer. We understand that we get more value out of the computer than the bottle of water. Every human has a built-in value meter in which we value products (or services!) comparatively.</p><p>Now, assume I put you in the middle of the desert and don't give you water for two days. Suddenly the value of the water bottle climbs to the top of your value meter.</p><hr><p>When you ask a person directly what they are willing to pay for a bottle of water, they refer to their value meter. They give you an answer based on expectation and comparison rather than on how much they may potentially value it. This happening makes it hard for a person to admit the real value of your product.</p><p>This phenomenon occurs when your product is an innovation, without valid comparisons, or if the value your product provides is much higher than any substitutes available on the market. The customer suddenly does not have an accurate thermometer to measure your product against, and will often give you a much lower price point when asked directly.</p><p>Economists and psychologists have studied this phenomenon for a long time. There are many techniques to gather information on the world-famous question for any startup: <strong>How much should I price my product?</strong></p><p>We can take advantage of this phenomenon by asking the customer indirect questions on a range.</p><hr><p>One of my favorite techniques, which I believe works very well, is the <strong><a href="https://en.wikipedia.org/wiki/Van_Westendorp%27s_Price_Sensitivity_Meter">Van Westerndorp method</a></strong>, also known as the Price Sensitivity Meter technique. Its a series of 4 simple questions you can ask your customers to determine a price range at which your product pricing matches your offering's real value. </p><p>What better way then to put those questions on a survey and ask enough people. If you survey, say, 150 potential customers, you will discover a pretty accurate price range determined by consumer value. Simple enough? Let's get started.</p><p>The first step is to <strong>make sure that customers understand your product</strong>. Consider giving customers a demo, sharing a video, or showing them detailed pictures of your product. You could include this at the top of your survey. For our purposes, let us take a picture of this yummy Gyro. Since a picture is worth a thousand words, I think it would do quite well to price this Gyro.</p><figure><img src="https://theunconventional.blog/content/images/2020/07/gyro.jpg" alt="" srcset="https://theunconventional.blog/content/images/size/w600/2020/07/gyro.jpg 600w, https://theunconventional.blog/content/images/2020/07/gyro.jpg 700w"><figcaption>Let's price this Gyro.</figcaption></figure><!--kg-card-begin: markdown--><blockquote>
<ol>
<li>The first question you would ask is, at what particular price point is this Gyro way <strong>too expensive</strong> that you would never consider purchasing it?</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li>Then you would ask at what specific price point is this Gyro <strong>getting expensive, but you would still consider</strong> buying it?</li>
</ol>
</blockquote>
<blockquote>
<ol start="3">
<li>At what price point is this Gyro a really <strong>good deal</strong>?</li>
</ol>
</blockquote>
<blockquote>
<ol start="4">
<li>And, At what point is this Gyro <strong>too cheap</strong> that you'd question its quality?</li>
</ol>
</blockquote>
<!--kg-card-end: markdown--><p>Notice the answers would give us a range of prices rather than one fixed price. By answering in ranges, people tend to let go of their value spectrum and instead determine the boundaries of how valuable the product is to them. This technique is, by far, one of the most accurate ways of determining your products true value-based price through a survey.</p><p>Looking at the data for 30+ users, we would get a cumulative graph as shown below.</p><figure><img src="https://theunconventional.blog/content/images/2020/07/PSM-graph-ready.png" alt="" srcset="https://theunconventional.blog/content/images/size/w600/2020/07/PSM-graph-ready.png 600w, https://theunconventional.blog/content/images/2020/07/PSM-graph-ready.png 933w" sizes="(min-width: 720px) 720px"><figcaption>Gyro Survey Results</figcaption></figure><p>From the results of the survey above, (about 30 entries at the time of this article.) We notice that the optimal value-based price range is between $2.5 and $3.5. At $2.5, the Gyro has approximately 15% of people who think its both expensive and too cheap. The optimal price would be the intersection of "too expensive" and "too cheap" at $3. Of course, this is just an indication of pricing and based purely on the people you have surveyed!</p><p>For anyone interested, I have created the Gyro survey <a href="https://forms.gle/EML2DwbiaEgFQWoe8">here</a> &nbsp;(feel free to take it!). I have set up a live updating-pricing <a href="https://bit.ly/2X0wQoZ">worksheet</a> to go along with it.</p><p><strong>Feel free to make a copy for your own product pricing journey, and good luck with your product pricing adventures.</strong></p>
                </div>
            </section>

                <section>
    <h3>Subscribe to The Unconventional Blog</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://theunconventional.blog/how-to-survey-product-pricing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24018272</guid>
            <pubDate>Sat, 01 Aug 2020 06:50:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gimp is working on its own version of “smart objects”]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24018269">thread link</a>) | @pmoriarty
<br/>
July 31, 2020 | https://daviesmediadesign.com/gimp-is-quietly-working-on-its-own-version-of-smart-objects-and-its-just-as-good-as-photoshops/ | <a href="https://web.archive.org/web/*/https://daviesmediadesign.com/gimp-is-quietly-working-on-its-own-version-of-smart-objects-and-its-just-as-good-as-photoshops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>The GIMP team recently informed me that the next upcoming version of GIMP will be GIMP 2.10.22 (no GIMP 3.0 just yet – womp). Though there has been no official announcements of specific features to come in this next version, there has been one feature announcement in particular that has caught my eye – the “<strong>linked layers</strong>” feature.</p>



<h2>Linked Layers – GIMP’s Answer to Photoshop’s Smart Objects?</h2>



<p><a href="https://twitter.com/zemarmot/status/1286952087558004738?s=20" target="_blank" rel="noreferrer noopener">GIMP quietly announced (via a retweet)</a> that the <a href="https://patreon.com/zemarmot?utm_medium=social&amp;utm_source=twitter&amp;utm_campaign=creatorshare" target="_blank" rel="noreferrer noopener">ZeMarmot team</a> was working on a new feature they are calling the “Linked Layers” feature (note: this has nothing to do with the “transform link” feature already found in GIMP).</p>



<p>In fact, work for this feature actually began in July 2019 (about a year ago) but, due to limited developers working on GIMP, this feature was shelved until recently.&nbsp;</p>



<p>Jehan from ZeMarmot, who recently revisited development on this feature, described the application of Linked Layers in this way: “What if you wanted to use the same background in several images? Instead of duplicating it, you could just link it from all images using it. And if you edit a bit your common background, it would automatically update the render of all images.”</p>



<p>Sound familiar?&nbsp;</p>



<p>To me, this sounds like GIMP’s version of “Smart Objects” – the popular Photoshop feature that allows you to “link” a different file to your composition, then have that file live update in your current composition any time you make changes to it. This has many applications – especially in the world of creating universal templates that can be updated with your own design (by simply replacing the “linked image” with your own design, then re-saving that image). <strong>This is huge.&nbsp;</strong></p>



<figure><img data-attachment-id="13511" data-permalink="https://daviesmediadesign.com/gimp-is-quietly-working-on-its-own-version-of-smart-objects-and-its-just-as-good-as-photoshops/linked-layers-test-gimp-smart-objects-2/" data-orig-file="https://i0.wp.com/daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-2.jpg?fit=820%2C511&amp;ssl=1" data-orig-size="820,511" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Linked-Layers-Test-GIMP-Smart-Objects-2" data-image-description="" data-medium-file="https://i0.wp.com/daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-2.jpg?fit=300%2C187&amp;ssl=1" data-large-file="https://i0.wp.com/daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-2.jpg?fit=820%2C511&amp;ssl=1" src="https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-2.jpg" alt="" srcset="https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-2.jpg 820w, https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-2-480x299.jpg 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) 820px, 100vw" data-recalc-dims="1" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-2.jpg" data-srcset="https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-2.jpg 820w, https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-2-480x299.jpg 480w"><figcaption><em>How linked layers would work (image from <a href="https://youtu.be/N5oyqbD7zyQ">ZeMarmot test video</a>)</em></figcaption></figure>



<p>It would work like this in GIMP: you would create a new layer, and under “Fill With” you choose “Image Link” (red arrow in the image above). Choosing this option would bring up an option to select an image to link the layer to on your computer (blue arrow). You then select your image, and click “OK” to create your new layer. The layer is now linked to the image on your computer. If you were to then open that image in GIMP and make edits to it, the edits would automatically update in the linked layer inside your other composition.</p>



<h2>Why GIMP’s Linked Layers Will Be Just As Good As Photoshop’s Smart Objects</h2>



<figure><img data-attachment-id="13510" data-permalink="https://daviesmediadesign.com/gimp-is-quietly-working-on-its-own-version-of-smart-objects-and-its-just-as-good-as-photoshops/linked-layers-test-gimp-smart-objects/" data-orig-file="https://i2.wp.com/daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects.jpg?fit=850%2C346&amp;ssl=1" data-orig-size="850,346" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Linked-Layers-Test-GIMP-Smart-Objects" data-image-description="" data-medium-file="https://i2.wp.com/daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects.jpg?fit=300%2C122&amp;ssl=1" data-large-file="https://i2.wp.com/daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects.jpg?fit=850%2C346&amp;ssl=1" src="https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects.jpg" alt="" srcset="https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects.jpg 850w, https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-480x195.jpg 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) 850px, 100vw" data-recalc-dims="1" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects.jpg" data-srcset="https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects.jpg 850w, https://daviesmediadesign.com/wp-content/uploads/2020/07/Linked-Layers-Test-GIMP-Smart-Objects-480x195.jpg 480w"><figcaption><em>In this photo, which is from <a href="https://youtu.be/N5oyqbD7zyQ">ZeMarmot’s video demo-ing the linked layers feature</a>, you can see a new layer thumbnail/icon (red arrow) indicating that the layer is linked to another image.</em></figcaption></figure>



<p>Some of you are wondering how this feature would keep pace with Photoshop’s well-established “Smart Objects” feature. In Photoshop, not only can you link a layer from one composition to a layer or image from another composition, but you can also link vector objects from Adobe Illustrator as a layer in Photoshop, and edit that vector object essentially in real-time in either program and have the quality of the vector object remain intact.</p>



<p>Well, GIMP’s “linked layers” will do the exact same thing – using Open Source alternatives, of course. This feature will be integrated with Inkscape so that, for example, you can link a vector composition to a GIMP layer, and have the GIMP layer scale up without quality loss the way any vector object would in Inskcape. <strong>This is mind-blowing.</strong> You could also make updates to the vector file in Inkscape, and those changes would then refresh inside of the linked layer in GIMP. It would essentially create a dynamic link between the two programs.</p>



<p>Here is a <a href="https://youtu.be/N5oyqbD7zyQ">video ZeMarmot released showing this new “linked layers” feature in action.</a> This isn’t just a pipe-dream or concept yet to be implemented – it’s a feature they’ve demonstrated to work in a test-version of GIMP. </p>



<p>If GIMP can successfully get linked layers to work in a stable release version of GIMP, the internet, myself included, will lose its mind. And, once again, GIMP will have successfully taken a bite out of Adobe’s photo editing software lead (still without charging its users a dime).</p>



<p>In my opinion, some form of “smart object” functionality is one of the top 3 features missing in GIMP (and one of the top 3 things I get comments about on my videos – especially when doing PS vs. GIMP comparisons). Stay tuned – I will provide more information on this feature as it comes out (hopefully via a video tutorial if they get the feature implemented in one of the new release-versions of GIMP).</p>



<p>If you want to help speed up the development of this and other cool new features in GIMP, I recommend supporting the <a href="https://patreon.com/zemarmot?utm_medium=social&amp;utm_source=twitter&amp;utm_campaign=creatorshare">ZeMarmot team on Patreon</a> so they can spend more time on GIMP development and less time on other jobs to pay their bills.</p>




</div></div>]]>
            </description>
            <link>https://daviesmediadesign.com/gimp-is-quietly-working-on-its-own-version-of-smart-objects-and-its-just-as-good-as-photoshops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24018269</guid>
            <pubDate>Sat, 01 Aug 2020 06:49:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I learned from doing over 60 technical interviews in 30 days]]>
            </title>
            <description>
<![CDATA[
Score 181 | Comments 111 (<a href="https://news.ycombinator.com/item?id=24017555">thread link</a>) | @bolajiayodeji
<br/>
July 31, 2020 | https://meekg33k.dev/what-i-learned-from-doing-60-technical-interviews-in-30-days-ckda9sn7s00iftss13b0wd0ky | <a href="https://web.archive.org/web/*/https://meekg33k.dev/what-i-learned-from-doing-60-technical-interviews-in-30-days-ckda9sn7s00iftss13b0wd0ky">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>In this article, I’ll share my motivation for doing 60+ technical interviews in 30 days. More importantly, I’ll share 13 lessons I learned from my failures and my successes.</p>
<p>I’ve grouped the lessons into three categories to match the phases of a typical recruitment process.</p>
<p>While most of the lessons apply directly to software engineers and technical professionals, the principles behind these lessons can be applied to all careers. I hope you find something useful that you can apply to your professional lives.</p>
<h2 id="how-did-i-get-started-">How did I get started?</h2>
<blockquote>
<p> “If you’re going to fail, do it fast.” — Unknown</p>
</blockquote>
<p>Like any other software engineer, I’ve had different types of technical interviews - from the dreaded whiteboard coding interview to the unreal 45-minute coding challenge on platforms like HackerRank. While some of my experiences in these interviews were great, others were bad. Really bad.</p>
<p>But I wanted to get really good at interviewing. I wanted to learn to overcome the interviewing phobia and exude confidence at interviews. Like a skilled surfer, I wanted to learn to ride the high pressure waves that came with interviews. I was also looking to change jobs at the time.</p>
<p>So from January through early March 2020, I applied to and was contacted by companies based in the US and Europe. From early-stage startups like Coda to later stage startups like Crunchbase, from mid-size companies like Affirm, to bigger companies like Amazon and even remote companies like Webflow.</p>
<p>109+ applications later, I landed myself more than 60 interviews. These comprised more than 60 introductory phone interviews, 50+ technical phone screen interviews, 18 take-home coding projects, 11 coding challenges and 8 on-site interviews including 3 virtual ones.</p>
<h2 id="what-did-i-learn-">What did I learn?</h2>
<p>For better appreciation, I have grouped the lessons into three categories to match the different phases of a typical recruitment process.</p>
<h3 id="pre-interview-phase">Pre-Interview Phase</h3>
<p>This covers everything from the initial contact with a company to the point where the first interview happens.</p>
<h4 id="1-what-i-learned-about-applications">1. What I learned about applications</h4>
<p>When I started applying to companies, I imagined that the more applications I submitted, the higher my chances of getting an interview would be. Seems logical, huh? So I set a target of 5 applications a day, aiming for 1 interview for every 5 applications.</p>
<p>But my strategy didn’t work as I hoped it would. The number of interview requests I got often fell short of my target. It was almost a 1:12 ratio - 1 interview for every 12 applications.</p>
<p>I was faced with the question: do I need to increase my daily target to, say, 10 companies? Or was there something else I needed to change?</p>
<p>With every unsuccessful application, I saw that something needed to change.</p>
<p>That change came when I took a break from meeting my daily numbers and began to think of my applications differently. I began to see each application as a sales pitch to the hiring manager or whoever was going to be reading my application, but here the product being sold was me.</p>
<p>If a company needed to fill a talent gap and I say I had the skills, I needed to find a way to convince them that I did.</p>
<p>My new task then became to find a way to effectively pitch my unique skills, experience and personality in a way that convinced the hiring manager that I was the right fit for the job.</p>
<p>Here is an example of one of such <em>pitches</em> I came up with:</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1596030331456/A8nDIn-ih.png?auto=format&amp;q=60" alt="body image.png"></p>
<p>Backed with my resume, this cover letter had a 95% success rate. The one time this didn’t work, the hiring manager still replied to let me know that the position was no longer available but he would like to connect in the future.</p>
<p>The lesson here is, be very intentional about the application you put forward – quality over quantity. Better still do both. Know your unique competencies and experience and present them in a way that matches the company’s needs without sacrificing your personality.</p>
<p>It is also important to understand the peculiarity of the company you are applying to and its specific needs. A startup or a smaller-sized company may have different needs from a bigger company, thus requiring a different skill-set.</p>
<p>Sell yourself and be sure to back your sales pitch during the interview.</p>
<h4 id="2-what-i-learned-about-recruiter-in-mails">2. What I learned about recruiter in-mails</h4>
<p>During this period, I received a number of in-mails from recruiters (mostly unsolicited) for open roles, the majority of which were roles I wasn’t interested in.</p>
<p>Granted, it was sometimes a lot given my busy schedule but I learned to be empathetic, understanding that these recruiters were only trying to do their jobs.</p>
<p>I stopped seeing these in-mails as noise in my inbox and started making the effort to reply to all recruiter in-mails, even for positions I was not interested in. By doing this, I succeeded in building a network of recruiters that have become a rich resource if I have to switch roles in the future.</p>
<p>Now I don’t expect you may want to start replying to every in-mail you receive. But it might interest you to know that some of the interview requests I got were from recruiters I had replied to before for roles I wasn’t interested in. It never hurts to reply.</p>
<h3 id="the-interview-phase">The Interview Phase</h3>
<p>This covers everything about the interview itself, cutting across the different interview types.</p>
<h4 id="3-how-to-handle-introductory-phone-calls">3. How to handle introductory phone calls</h4>
<p>Yes I get it, you’re busy and many things are competing for your time. But hey, you are also an excellent professional, and that means you never get on a phone call without knowing at least these two things:</p>
<ul>
<li>the first name of your interviewer, and</li>
<li>at least one tangible thing about the company — what they do, where they are located, any recent news, something, anything!</li>
</ul>
<p>I noticed that for interviews where I put in the effort to make these findings, I always came across as being genuinely interested in the company. That’s something recruiters typically look for in these kinds of interviews.</p>
<h4 id="4-how-to-handle-technical-phone-screens">4. How to handle technical phone screens</h4>
<p>The one thing that can almost single-handedly decide how well you do in a technical phone screen interview is your ability to communicate your thoughts clearly.</p>
<p>You may have heard stuff like this before:
“<em>The interviewers care about your thought process. Yes they can see your code but importantly, they want to know why you are doing what you’re doing</em>.”</p>
<p>The interviewer isn’t there with you and so does not have the luxury of seeing other non-verbal cues like your hand gestures or nuances. All the interviewer has is your voice as a means of understanding your thought process.</p>
<p>Now you know how you should lead this conversation, the next question is how do you become good at this? Because the truth is, while expressing your thoughts may come naturally to some people, it doesn’t to others – including me.</p>
<p>So – Practice! Practice!! Practice!!!</p>
<p>Practice doing a lot of mock interviews. Doing these mock interviews with friends made me better and more confident in explaining my thought process. But more interestingly, it helped me develop a new mindset about interviews.</p>
<p>I began to see interviews as a conversation with a friend or a team member. I visualized the interviewer on the other end as one of my friends (I sometimes gave the interviewer a name in my head). So what would have been a high-pressure interview I now saw as a friendly ‘chat’ about a technical problem.</p>
<p>This new mindset, aided by the many practice interviews, helped me grow in confidence so much so that I started enjoying interviews, sorry, technical chats.
How to get started on a problem</p>
<p>Never start solving a problem without fully understanding the problem statement. You are almost never wrong if you start by asking clarifying questions. It’s also a good sign to your interviewer when you ask those questions rather than run with your assumptions.</p>
<h4 id="5-how-to-solve-the-problem">5. How to solve the problem</h4>
<p>Good candidates know how to solve a problem (e.g. a sorting problem), but the best candidates know multiple solutions to a problem and understand the trade-offs of one solution versus the other.</p>
<p>The interviews where I performed the best (Cruise comes to mind) are the ones where I didn’t just solve the algorithmic challenge – I was also able to provide alternative solutions and discuss the trade-offs.</p>
<p>Aim to provide multiple solutions to a problem, be willing to discuss the trade-offs, and be able to implement at least one of them.</p>
<p>For technical interviews, write clean code. Most interviewers care about your code quality as well as the correctness of your solution. Aim for modular code, separate reusable logic into utility functions, name variables and methods properly, and just be a boss!</p>
<h4 id="6-what-to-do-when-you-re-stuck-on-a-problem">6. What to do when you’re stuck on a problem</h4>
<p>There will be times when you’re stuck. And this could be caused by a number of reasons: you don’t have the requisite knowledge, incorrect assumptions, missing details, and so on.</p>
<p>I used to think that at such times I was being judged by how fast I could come up with a solution. So I would be quiet, thinking, not communicating with the interviewer, just thinking.</p>
<p>And this is where a lot of us get it wrong. I get it, you need some alone time to think. But sorry to burst your bubble, that alone time is not when you’re being interviewed by a person.</p>
<p>Yes, your interviewer wants to see that you can come up with a solution, but one thing you must not forget is that they also want to see that <strong>you can collaborate with other team-mates to come up with a solution</strong>. While companies want rock-stars, they also want team-players.</p>
<p>Since your interviewer is a friend, a buddy, a team member who’s on your side and means well for you (Refer to 4), talk to them while you're figuring it out.</p>
<p>Share your thought process up till the point you got stuck and do it confidently, not like some cry for help. By doing so you just may uncover the solution, as was the case during my interview with Coda.</p>
<h4 id="7-how-to-handle-coding-challenges">7. How to handle coding challenges</h4>
<p>The lessons here apply to interviews that take the form of coding challenges on platforms like Hackerrank, Codility, and so on. Typically these are timed challenges, say 45 minutes or …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://meekg33k.dev/what-i-learned-from-doing-60-technical-interviews-in-30-days-ckda9sn7s00iftss13b0wd0ky">https://meekg33k.dev/what-i-learned-from-doing-60-technical-interviews-in-30-days-ckda9sn7s00iftss13b0wd0ky</a></em></p>]]>
            </description>
            <link>https://meekg33k.dev/what-i-learned-from-doing-60-technical-interviews-in-30-days-ckda9sn7s00iftss13b0wd0ky</link>
            <guid isPermaLink="false">hacker-news-small-sites-24017555</guid>
            <pubDate>Sat, 01 Aug 2020 04:19:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple iCloud – please stop bugging me]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24017071">thread link</a>) | @cjlovett
<br/>
July 31, 2020 | https://lovettchris.github.io/posts/apple_upsell/ | <a href="https://web.archive.org/web/*/https://lovettchris.github.io/posts/apple_upsell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<article>
			<div>
				<div>
					<div>
						

<p>Anyone else tired of these annoying popups?</p>

<p><img src="https://lovettchris.github.io/posts/apple_upsell/icloud_installer.png" alt=""></p>

<p>I’m getting pretty tired of all this… I actually tried to find customer support for the PC
installer popup, but no luck. Anyone know who owns this ugly little Windows app? I find it
particularly devious that Apple uses language here that sounds like something is broken until I
“Install” their fix. This is not a fix, this is an upsell to get iCloud on my PC.</p>

<p>The iPhone backup message is also annoying. I tried to tell my iPhone to stop backing up my photos,
and yet I still get this backup failed warning every day. Perhaps Apple should find a more creative
way to upsell my on iCloud because this is driving me nuts, and making it much less likely I’ll
ever checkout the benefits of paying Apple for cloud storage on stuff I’ve backed up my self lots
of other ways.</p>

<p>Apple is world class on user experiences of everything else, so why are they so bad at this
experience? I’m guessing the part of the company that expertly squeezes every dime out of consumers
is not so connected to the user experience gods at Apple… Here’s hoping I can wake up some of
those gods to go slap the accountants on the wrist for this naughty behavior.</p>

<p>-Chris.</p>

					</div>
				</div>
			</div>
		</article>
	</div></div>]]>
            </description>
            <link>https://lovettchris.github.io/posts/apple_upsell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24017071</guid>
            <pubDate>Sat, 01 Aug 2020 03:14:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking the Pleroma: Elixir, Phoenix and a Bit of ActivityPub]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24017031">thread link</a>) | @todsacerdoti
<br/>
July 31, 2020 | https://wimvanderbauwhede.github.io/articles/hacking-pleroma/ | <a href="https://web.archive.org/web/*/https://wimvanderbauwhede.github.io/articles/hacking-pleroma/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" itemprop="articleBody">
				<p><a href="https://pleroma.social/">Pleroma</a> "is a microblogging server software that can federate (= exchange messages with) other servers that support the same federation standards (OStatus and ActivityPub). What that means is that you can host a server for yourself or your friends and stay in control of your online identity, but still exchange messages with people on larger servers. Pleroma will federate with all servers that implement either OStatus or ActivityPub, like GNU Social, Friendica, Hubzilla and Mastodon." <a href="https://blog.soykaf.com/post/what-is-pleroma/">(stolen from Lain's blog post)</a>.</p>

<p>Recently I modified my Pleroma instance to support bot services: parse a posted message, take an action, post the result. To get there I had to learn <a href="https://elixir-lang.org/">Elixir</a>, the language in which Pleroma is written, as well as <a href="https://hexdocs.pm/phoenix/overview.html">Phoenix</a>, the web framework Elixir uses, and a little bit about ActivityPub, the protocol for exchanging messages. What I want to explain here in particular is the architecture of Pleroma, so that you can hack it more easily, for fun or if you want to participate in the development.</p>

<h2>Elixir</h2>

<p>As Pleroma is written in <a href="https://elixir-lang.org/">Elixir</a> you'll need to learn that language to some extent. If you are familiar with Ruby (or Perl, for that matter) and with the idea of functional programming (everything is a function), then it is quite easy to learn and understand. The <a href="https://hexdocs.pm/elixir/">documentation</a> and <a href="https://elixir-lang.org/getting-started/introduction.html">guides</a> are very good. </p>

<p>If you've never hear of functional programming, the main difference with e.g. Ruby or Java is that Elixir does not use an object-oriented programming model. Instead, there are functions that manipulate data structures and other functions. A particular consequence of the functional model is that there are no for- or while-loops. Instead, there are what is called higher-order functions which e.g. apply another function to a list. Elixir programs also make a lot more use of recursion. </p>

<p>Another point about Elixir as a web programming language is that it is built on a system where processes communicate by passing messages to one another, and it is  built in such a way that if a process dies it will normally be restarted automatically. This approach makes it very easy to offload work to separate worker processes etc. </p>

<p>All this comes courtesy of <a href="https://www.erlang.org/">Erlang</a>, the language on which Elixir is built, with its powerfull OTP framework for building applications and its BEAM virtual machine, which manages the processes. </p>

<h2>Phoenix</h2>

<p>A lot of the groundwork of Pleroma is done by <a href="https://hexdocs.pm/phoenix/overview.html">Phoenix</a>, a very easy-to-use web server framework. Essentially, what happens is that the end user accesses the application using a specific url, typically via a web browser, and based on this url the application performs a number of actions, which in the end result in a change in the state of the application and usually in what is shown in the browser window.</p>

<p>In Phoenix, there are five stages or components  between the connection and the resulting action by the application:</p>

<h3>Endpoint</h3>

<p>The <a href="https://hexdocs.pm/phoenix/Phoenix.Endpoint.html">endpoint</a> is the boundary where all requests to your web application start. It is also the interface your application provides to the underlying web servers.</p>

<p>Pleroma's endpoint is <a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/endpoint.ex"><code>web/endpoint.ex</code></a>. If you look at the source you see several occurrences of <code>plug(Plug...)</code>. <a href="https://hexdocs.pm/phoenix/plug.html">Plug</a> is a specification for composable modules in between web applications, and it is very heavily used in Pleroma.  For example, to serve only specific static files/folders from <code>priv/static</code>:</p>
<div><pre><code data-lang="elixir"><span></span><span>plug</span><span>(</span>
  <span>Plug.Static</span><span>,</span>
  <span>at</span><span>:</span> <span>"/"</span><span>,</span>
  <span>from</span><span>:</span> <span>:pleroma</span><span>,</span>
  <span>only</span><span>:</span> <span>~w(index.html static finmoji emoji packs sounds images instance sw.js)</span>
<span>)</span>
</code></pre></div>
<p>Another very nice feature of Phoenis is that you can edit your code while your server is running. It gets automatically recompiled and the affected processes are automatically restarted, courtesy of the <a href="https://hexdocs.pm/phoenix/Phoenix.CodeReloader.html">Phoenix.CodeReloader</a>:</p>
<div><pre><code data-lang="elixir"><span></span>  <span># Code reloading can be explicitly enabled under the</span>
  <span># :code_reloader configuration of your endpoint.</span>
  <span>if</span> <span>code_reloading?</span> <span>do</span>
    <span>plug</span><span>(</span><span>Phoenix.CodeReloader</span><span>)</span>
  <span>end</span>
</code></pre></div>
<h3>Router</h3>

<p><a href="https://hexdocs.pm/phoenix/Phoenix.Router.html">Routers</a> are the main hubs of Phoenix applications. They match HTTP requests to controller actions, wire up real-time channel handlers, and define a series of pipeline transformations for scoping middleware to sets of routes.</p>

<p>Pleroma's router is <a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/router.ex"><code>web/router.ex</code></a>. The key function in the router is the <code>pipeline</code> which lets you create pipelines of plugs. Other functions are <code>scope</code>, <code>get</code>, <code>post</code>, <code>pipe_through</code>, all of these let you match on the url and whether you are dealing with a get or post request, and define appropriate pipelines of actions. For example, federated ActivityPub requests handled as follows:</p>
<div><pre><code data-lang="elixir"><span></span><span>scope</span> <span>"/"</span><span>,</span> <span>Pleroma.Web.ActivityPub</span> <span>do</span>
  <span>pipe_through</span><span>(</span><span>:activitypub</span><span>)</span>
  <span>post</span><span>(</span><span>"/users/:nickname/inbox"</span><span>,</span> <span>ActivityPubController</span><span>,</span> <span>:inbox</span><span>)</span>
  <span>post</span><span>(</span><span>"/inbox"</span><span>,</span> <span>ActivityPubController</span><span>,</span> <span>:inbox</span><span>)</span>
<span>end</span>
</code></pre></div>
<p>where the <code>pipe_through(:activitypub)</code> call is used to insert a custom pipeline:</p>
<div><pre><code data-lang="elixir"><span></span><span>pipeline</span> <span>:activitypub</span> <span>do</span>
  <span>plug</span><span>(</span><span>:accepts</span><span>,</span> <span>[</span><span>"activity+json"</span><span>])</span>
  <span>plug</span><span>(</span><span>Pleroma.Web.Plugs.HTTPSignaturePlug</span><span>)</span>
<span>end</span>
</code></pre></div>
<h3>Controllers</h3>

<p><a href="https://hexdocs.pm/phoenix/Phoenix.Controller.htm">Controllers</a> are used to group common functionality in the same (pluggable) module.  </p>

<p>Pleroma makes heavy use of controllers: almost every request is handled by a specific controller for any given protocol, e.g. <code>MastodonAPIController</code> or <code>ActivityPubController</code>. This makes it easy to identify the files to work on if you need to make a change to the code for a given protocol. For example, the ActivityPub post requests in the Router are handled by <code>inbox</code> function in the <a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/activity_pub/activity_pub_controller.ex">ActivityPubController</a>:</p>
<div><pre><code data-lang="elixir"><span></span><span>def</span> <span>inbox</span><span>(%{</span><span>assigns</span><span>:</span> <span>%{</span><span>valid_signature</span><span>:</span> <span>true</span><span>}}</span> <span>=</span> <span>conn</span><span>,</span> <span>params</span><span>)</span> <span>do</span>
  <span>Federator</span><span>.</span><span>enqueue</span><span>(</span><span>:incoming_ap_doc</span><span>,</span> <span>params</span><span>)</span>
  <span>json</span><span>(</span><span>conn</span><span>,</span> <span>"ok"</span><span>)</span>
<span>end</span>
</code></pre></div>
<h3>Views</h3>

<p><a href="https://hexdocs.pm/phoenix/Phoenix.View.html">Views</a> are used to control the rendering of templates. You create a view module, a template and a set of assigns, which are basically key-value pairs.</p>

<p>Pleroma uses views for "rendering" JSON objects. For example in <a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/activity_pub/activity_pub_controller.ex"><code>web/activity_pub/activity_pub_controller.ex</code></a> there are lines like</p>
<div><pre><code data-lang="elixir"><span></span><span>json</span><span>(</span><span>UserView</span><span>.</span><span>render</span><span>(</span><span>"user.json"</span><span>,</span> <span>%{</span><span>user</span><span>:</span> <span>user</span><span>}))</span>
</code></pre></div>
<p>Here, <code>UserView.render</code> is defined in <a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/activity_pub/views/user_view.ex"><code>web/activity_pub/views/user_view.ex</code></a> for a number of different "*.json" strings. These are not really templates, they are simply used to pattern match on the function definitions.</p>

<p>The more conventional usage to create HTML is also used, e.g. the template <a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/templates/mastodon_api/mastodon/index.html.eex"><code>web/templates/mastodon_api/mastodon/index.html.eex</code></a>
is used in <a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/mastodon_api/mastodon_api_controller.ex"><code>web/mastodon_api/mastodon_api_controller.ex</code></a> via the view
<a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/mastodon_api/views/mastodon_view.ex"><code>web/mastodon_api/views/mastodon_view.ex</code></a>:</p>
<div><pre><code data-lang="elixir"><span></span><span>render</span><span>(</span><span>MastodonView</span><span>,</span> <span>"index.html"</span><span>,</span> <span>%{</span><span>initial_state</span><span>:</span> <span>initial_state</span><span>})</span>
</code></pre></div>
<h3>Templates</h3>

<p><a href="https://hexdocs.pm/phoenix/Phoenix.Template.html">Templates</a> are text files (typically html pages) with Elixir code to generate the specific values based on the assigns, included in <code>&lt;%= ... %&gt;</code>.</p>

<p>For example, in Pleroma, the Mastodon front-end uses a template for the <code>index.html</code> file which has the code</p>
<div><pre><code data-lang="elixir"><span></span><span>&lt;</span><span>%</span><span>=</span> <span>Application</span><span>.</span><span>get_env</span><span>(</span><span>:pleroma</span><span>,</span> <span>:instance</span><span>)[</span><span>:name</span><span>]</span> <span>%</span><span>&gt;</span>
</code></pre></div>
<p>to show the name of the instance.</p>

<h2>Ecto</h2>

<p><a href="https://hexdocs.pm/ecto/Ecto.html">Ecto</a> is not a part of Phoenix, but it is an integral part of most web applications: Ecto is Elixir's main library for working with databases. It provides the tools to interact with databases under a common API.</p>

<p>Ecto is split into 4 main components:</p>

<p>Ecto.Repo - repositories are wrappers around the data store. Via the repository, we can create, update, destroy and query existing entries. A repository needs an adapter and credentials to communicate to the database</p>

<p>Pleroma uses the PostgresQL database.</p>

<p>Ecto.Schema - schemas are used mainly to map tables into Elixir data (there are other use cases too).</p>

<p>Ecto.Changeset - changesets provide a way for developers to filter and cast external parameters, as well as a mechanism to track and validate changes before they are applied to your data</p>

<p>Ecto.Query - written in Elixir syntax, queries are used to retrieve information from the database.</p>

<h2>GenServer</h2>

<p>Because Elixir, like Erlang, uses a processes-with-message-passing paradigm, client-server relationships are so common that they have been abstracted as a <em>behaviour</em>, which in Elixir is a specification for composable modules which have to implement specified public functions (a bit like an interface in Java or typeclass in Haskell).</p>

<p>If we look at the <code>Federator.enqueue</code> function, its implementation actually reduces to a single line:</p>
<div><pre><code data-lang="elixir"><span></span><span>GenServer</span><span>.</span><span>cast</span><span>(</span><span>__MODULE__</span><span>,</span> <span>{</span><span>:enqueue</span><span>,</span> <span>type</span><span>,</span> <span>payload</span><span>,</span> <span>priority</span><span>})</span>
</code></pre></div>
<p><a href="https://hexdocs.pm/elixir/GenServer.html">GenServer</a> is an Elixir behaviour module for implementing the server of a client-server relation. The <code>cast</code> call sends an asynchronous request to the server (synchronous requests use <code>call</code>). The server behaviour is implemented using the <code>handle_cast</code> callback, which handles <code>cast</code> calls. </p>

<p>In <a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/federator/federator.ex"><code>Pleroma.Federator</code></a>, these are implemented in the same module as the <code>enqueue</code> function, hence the use of <code>__MODULE__</code> rather than the hardcoded module name.</p>

<h2>Applications, Workers and Supervisors</h2>

<p>Elixir borrows the concept of a "supervision tree" from Erlang/OTP. AN application consists of a tree of processes than can either be <em>supervisors</em> or <em>workers</em>. The task of a supervisors is to ensure that the worker processes do their work, including distributing the work and restarting the worker processes when they die. Supervisors can supervise either worker or other supervisors, so you can build a <em>supervision tree</em>.</p>

<p>Elixir provides an <a href="http://elixir-lang.org/docs/stable/elixir/Application.html">Application</a> behaviour module and a <a href="https://hexdocs.pm/elixir/Supervisor.html">Supervisor</a> module to make this easy. The Application module requires a <code>start()</code> function as entry point. Typical code to create a supervision tree is</p>
<div><pre><code data-lang="elixir"><span></span><span>Supervisor</span><span>.</span><span>start_link</span><span>(</span><span>children</span><span>,</span> <span>opts</span><span>)</span>
</code></pre></div>
<p>where <code>start_link()</code> spawns the top process of the tree, and it spawns all the child processes in the list <code>children</code>. </p>

<p>Pleroma uses a convenient but deprecated module called <a href="https://hexdocs.pm/elixir/Supervisor.Spec.html">Supervisor.Spec</a> which provides <code>worker()</code> and <code>supervisor()</code> functions, for example:</p>
<div><pre><code data-lang="elixir"><span></span><span>children</span> <span>=</span> <span>[</span>
  <span>supervisor</span><span>(</span><span>Pleroma.Repo</span><span>,</span> <span>[]),</span>
  <span>supervisor</span><span>(</span><span>Pleroma.Web.Endpoint</span><span>,</span> <span>[]),</span>
  <span># ...</span>
  <span>worker</span><span>(</span><span>Pleroma.Web.Federator</span><span>,</span> <span>[]),</span>
  <span># ...</span>
<span>]</span>  
</code></pre></div>
<p>Every worker has this own <code>start_link</code> function,  e.g.  in <a href="https://git.pleroma.social/pleroma/pleroma/blob/develop/lib/pleroma/web/federator/federator.ex"><code>web/federator/federator.ex</code></a> we find: </p>
<div><pre><code data-lang="elixir"><span></span><span>def</span> <span>start_link</span> <span>do</span>
  <span># ...</span>
  <span>GenServer</span><span>.</span><span>start_link</span><span>(</span><span>__MODULE__</span><span>,</span> <span>...</span><span>)</span>
<span>end</span>
</code></pre></div>
<p>This means that the Federator module borrows the <code>start_link</code> from the GenServer module. This is a very common way to create a worker.</p>

<h2>Mix</h2>

<p><a href="https://hexdocs.pm/mix/Mix.html">Mix</a> is the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wimvanderbauwhede.github.io/articles/hacking-pleroma/">https://wimvanderbauwhede.github.io/articles/hacking-pleroma/</a></em></p>]]>
            </description>
            <link>https://wimvanderbauwhede.github.io/articles/hacking-pleroma/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24017031</guid>
            <pubDate>Sat, 01 Aug 2020 03:08:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Sizle.io – React Presentation Builder]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24016998">thread link</a>) | @sizleio
<br/>
July 31, 2020 | https://sizle.io/presentations/ | <a href="https://web.archive.org/web/*/https://sizle.io/presentations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="home" data-column-margin="default" data-midnight="dark" data-top-percent="6%" data-bottom-percent="7%" data-bg-mobile-hidden="true" data-using-ctc="true"><div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="right" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div id="fws_5f27c8a4bf7da" data-midnight="" data-column-margin="default"><div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div><p><h3>Make your content shine on all devices with presentations and proposals that convert more leads</h3></p></div></div></div></div></div></div></div></div></div></div></div><div id="fws_5f27c8a4c4360" data-column-margin="default" data-midnight="dark" data-top-percent="5%" data-bottom-percent="5%"><div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div data-max-width="100%" data-max-width-mobile="default" data-border-radius="none" data-shadow="none" data-animation="none"><div><div data-hover-animation="none"><p><img data-delay="0" height="775" width="933" data-animation="none" src="https://sizle.io/wp-content/uploads/2020/04/Mobile-friendly-online-presentations-min-2.png" alt="Mobile friendly online presentations" srcset="https://sizle.io/wp-content/uploads/2020/04/Mobile-friendly-online-presentations-min-2.png 933w, https://sizle.io/wp-content/uploads/2020/04/Mobile-friendly-online-presentations-min-2-300x249.png 300w, https://sizle.io/wp-content/uploads/2020/04/Mobile-friendly-online-presentations-min-2-768x638.png 768w" sizes="(min-width: 1450px) 75vw, (min-width: 1000px) 85vw, 100vw"></p></div></div></div></div></div></div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><h2>Mobile friendly</h2><div><p>Give your viewer the best experience no matter what device they’re using.</p></div><h2>Distraction-free</h2><div><p>Display your presentations in a minimal interface that makes your content shine.</p></div><h2>Viewer analytics</h2><div><p>Measure the performance of your presentations across multiple devices.</p></div></div></div></div></div></div><div id="fws_5f27c8a4cb725" data-column-margin="default" data-midnight="dark" data-top-percent="5%" data-bottom-percent="4%" data-using-ctc="true"><div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div><p>Ensure that your presentations remain commercial in confidence. Share securely with password protection.</p></div></div></div></div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div data-max-width="100%" data-max-width-mobile="default" data-border-radius="none" data-shadow="none" data-animation="none"><div><div data-hover-animation="none"><p><img data-delay="0" height="964" width="1634" data-animation="none" src="https://sizle.io/wp-content/uploads/2020/02/Sizle-Presentation-Password-Protection.svg" alt="Sizle Presentation Password Protection"></p></div></div></div></div></div></div></div></div><div id="howitworks" data-column-margin="default" data-midnight="dark" data-top-percent="3%" data-bottom-percent="3%" data-using-ctc="true"><div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="left" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div><p><h2>Viewer insights<br> and alerts</h2></p></div><div><p>See how people engage with your<br> presentation slide-by-slide.</p></div></div></div></div></div></div><div id="fws_5f27c8a4d474b" data-column-margin="default" data-midnight="dark" data-top-percent="8%" data-bottom-percent="8%" data-using-ctc="true"><div><div data-t-w-inherits="default" data-bg-cover="" data-padding-pos="all" data-has-bg-color="false" data-bg-color="" data-bg-opacity="1" data-hover-bg="" data-hover-bg-opacity="1" data-animation="" data-delay="0"><div><div><div><p>Create a or upload a presentation to explore a suite of dynamic features.</p></div></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://sizle.io/presentations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24016998</guid>
            <pubDate>Sat, 01 Aug 2020 03:02:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alacritty Version 0.5.0 Release]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 55 (<a href="https://news.ycombinator.com/item?id=24016977">thread link</a>) | @sbt567
<br/>
July 31, 2020 | https://blog.christianduerr.com/alacritty_0_5_0_announcement.html | <a href="https://web.archive.org/web/*/https://blog.christianduerr.com/alacritty_0_5_0_announcement.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <p>
        
        <h4>July 31, 2020</h4>
    </p>

    <h2>Table of Contents</h2>

    <ul>
      <li><a href="#about">About</a></li>
      <li><a href="#added">Added</a></li>
      <li><a href="#changed">Changed</a></li>
      <li><a href="#fixed">Fixed</a></li>
      <li><a href="#removed">Removed</a></li>
      <li><a href="#additional-information">Additional Information</a></li>
    </ul>

    <h2><a name="about" href="#about">About</a></h2>

    <p>
      <a href="https://github.com/alacritty/alacritty" target="_blank">Alacritty</a>
      is a terminal emulator with a strong focus on simplicity and performance.
      With such a strong focus on performance, included features are carefully
      considered and you can always expect Alacritty to be blazingly fast. By
      making sane choices for defaults, Alacritty requires no additional setup.
      However, it does allow configuration of many aspects of the terminal.
    </p>

    <h2>
      <a name="added" href="#added">Added</a>
    </h2>
    <ul>
      <li>Default Command+N keybinding for SpawnNewInstance on macOS</li>
      <li>Vi mode for regex search, copying text, and opening links</li>
        
        
      <li><code>CopySelection</code> action which copies into selection buffer on Linux/BSD</li>
      <li>Option <code>cursor.thickness</code> to set terminal cursor thickness</li>
        <p><img src="https://blog.christianduerr.com/img/cursor_thickness.png">
        </p>
      <li>Font fallback on Windows</li>
      <li>Support for Fontconfig embolden and matrix options</li>
      <li>Opt-out compilation flag <code>winpty</code> to disable WinPTY support</li>
      <li>Scrolling during selection when mouse is at top/bottom of window</li>
        
      <li>Expanding existing selections using single, double and triple click with the right mouse button</li>
        
      <li>Support for <code>gopher</code> and <code>gemini</code> URLs</li>
      <li>Unicode 13 support</li>
      <li>Option to run command on bell which can be set in <code>bell.command</code></li>
      <li>Fallback to program specified in <code>$SHELL</code> variable on Linux/BSD if it is present</li>
    </ul>

    <h2>
      <a name="changed" href="#changed">Changed</a>
    </h2>
    <ul>
      <li>Block cursor is no longer inverted at the start/end of a selection</li>
      <li>Preserve selection on non-LMB or mouse mode clicks</li>
      <li>Wayland client side decorations are now based on config colorscheme</li>
      <li>Low resolution window decoration icon on Windows</li>
      <li>Mouse bindings for additional buttons need to be specified as a number not a string</li>
      <li>Don't hide cursor on modifier press with <code>mouse.hide_when_typing</code> enabled</li>
      <li><code>Shift + Backspace</code> now sends <code>^?</code> instead of <code>^H</code></li>
      <li>Default color scheme is now <code>Tomorrow Night</code> with the bright colors of <code>Tomorrow Night Bright</code></li>
        <p><img src="https://blog.christianduerr.com/img/new_colorscheme.png">
        </p>
      <li>Set IUTF8 termios flag for improved UTF8 input support</li>
      <li>Dragging files into terminal now adds a space after each path</li>
      <li>Default binding replacement conditions</li>
      <li>Adjusted selection clearing granularity to more accurately match content</li>
      <li>To use the cell's text color for selection with a modified background, the <code>color.selection.text</code>
      variable must now be set to <code>CellForeground</code> instead of omitting it</li>
      <li>URLs are no longer highlighted without a clearly delimited scheme</li>
      <li>Renamed config option <code>visual_bell</code> to <code>bell</code></li>
      <li>Moved config option <code>dynamic_title</code> to <code>window.dynamic_title</code></li>
    </ul>

    <h2>
      <a name="fixed" href="#fixed">Fixed</a>
    </h2>
    <ul>
      <li>Selection not cleared when switching between main and alt grid</li>
      <li>Freeze when application is invisible on Wayland</li>
      <li>Paste from some apps on Wayland</li>
      <li>Slow startup with Nvidia binary drivers on some X11 systems</li>
      <li>Display not scrolling when printing new lines while scrolled in history</li>
      <li>Regression in font rendering on macOS</li>
      <li>Scroll down escape (<code>CSI Ps T</code>) incorrectly pulling lines from history</li>
      <li>Dim escape (<code>CSI 2 m</code>) support for truecolor text</li>
      <li>Incorrectly deleted lines when increasing width with a prompt wrapped using spaces</li>
      <li>Documentation for class in <code>--help</code> missing information on setting general class</li>
      <li>Linewrap tracking when switching between primary and alternate screen buffer</li>
      <li>Preservation of the alternate screen's saved cursor when swapping to primary screen and back</li>
      <li>Reflow of cursor during resize</li>
      <li>Cursor color escape ignored when its color is set to inverted in the config</li>
      <li>Fontconfig's <code>autohint</code> and <code>hinting</code> options being ignored</li>
      <li>Ingoring of default FreeType properties</li>
      <li>Alacritty crashing at startup when the configured font does not exist</li>
      <li>Font size rounding error</li>
    </ul>

    <h2>
      <a name="removed" href="#removed">Removed</a>
    </h2>
    <ul>
      <li>Environment variable <code>RUST_LOG</code> for selecting the log level</li>
      <li>Deprecated <code>window.start_maximized</code> config field</li>
      <li>Deprecated <code>render_timer</code> config field</li>
      <li>Deprecated <code>persistent_logging</code> config field</li>
    </ul>

    <h2><a name="additional-information" href="#additional-information">Additional Information</a></h2>

    <p>
      Detailed installation instructions can be found in
      <a href="https://github.com/alacritty/alacritty#installation">
        Alacritty's GitHub README.
      </a>
    </p>

    <p>
      The full changelog including all previous versions can be found
      <a href="https://github.com/alacritty/alacritty/blob/v0.5.0/CHANGELOG.md">here</a>.
    </p>
  

</div>]]>
            </description>
            <link>https://blog.christianduerr.com/alacritty_0_5_0_announcement.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24016977</guid>
            <pubDate>Sat, 01 Aug 2020 02:59:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing a Physics Engine]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24016718">thread link</a>) | @todsacerdoti
<br/>
July 31, 2020 | https://blog.winter.dev/2020/designing-a-physics-engine/ | <a href="https://web.archive.org/web/*/https://blog.winter.dev/2020/designing-a-physics-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>By coincidence, right when <a href="https://www.youtube.com/c/TheChernoProject/videos" target="_blank" rel="noreferrer noopener">The Cherno</a> announced his game engine series I was just starting to get going on my own engine. I couldn’t wait to finally have a professional opinion on how to make one. With self-taught programming it’s hard to not doubt yourself constantly, wondering if you are doing things right or just think you are.</p>



<p>Recently, he has been posting videos about huge aspects of his engine like physics and entity systems, which were what I really wanted to learn about by making myself, but he ended up using libraries instead of going through the internals! I am not against using libraries, but to use them for the fun stuff? I felt like it defeated the point of making a <em>custom</em> engine series.</p>



<p>There is an argument to be made about saving time, but this was the first C++ project that I was making and the goal from the start was to go through all the major pillars of an engine: input, graphics, physics, entities, and audio. I wanted to learn how those things worked along with C++ and code design in general.</p>



<p>I bet that some other people are interested in the details of how these systems work, and I want to learn how to explain code better, so I am going to try and make some videos going over the internals of these systems. They end up being much simpler than at first glance.</p>



<p><strong>Let’s start with the physics engine…</strong></p>



<p>Physics engines are responsible for figuring out where each object in a scene is over time. Objects can collide with one another, then choose to respond in several ways. It’s a generic problem that the user can configure at several different levels. Do they want a collider? Do they want to respond to collisions? Do they want to simulate dynamics? They could want dynamics, but not gravity. It’s a problem that calls for good planning and robust design.</p>



<p>I looked at how <a href="https://github.com/bulletphysics/bullet3" target="_blank" rel="noreferrer noopener">bullet</a> and <a href="https://github.com/erincatto/box2d" target="_blank" rel="noreferrer noopener">box2d</a> went about sorting their engines and concluded that the way bullet went about it was solid. I boiled it down to just what was needed, and based my design around that. There are already some <a href="https://www.toptal.com/game/video-game-physics-part-i-an-introduction-to-rigid-body-dynamics" target="_blank" rel="noreferrer noopener">great articles</a> going over the hard math involved, so I am going to focus on the design aspect instead because I haven’t seen anyone do that, and it’s also a real headache.</p>



<p>At the current moment, this physics engine is not fully featured, but in future articles I plan to build it out further. This article will not cover rotation, multiple contact point collisions, or constrained simulation. I think it will work out for the best as it’s easy to get overwhelmed, and I want to ease into those topics. With that out of the way, let’s dive into the different parts of a physics engine.</p>



<p>The problem can be split into 2 or 3 pieces, dynamics, collision detection, and collision response. I’ll start with dynamics because it is by far the simplest.</p>



<p><strong>Dynamics</strong></p>



<p>Dynamics is all about calculating where the new positions of objects are based on their velocity and acceleration. In high school you learn about the four kinematic equations along with Newton's three laws which describe the motion of objects. We’ll only be using the first and third kinematic equations, the others are more useful for analysis of situations, not simulation. That leaves us with:</p>



<p><span data-katex-display="true">v = v_0+at</span>



<span data-katex-display="true">\Delta x = v_0t + \frac{1}{2}at^2</span></p><p>We can give ourselves more control by using Newtons 2<sup>nd</sup> law, subbing out acceleration giving us:</p>



<p><span data-katex-display="true">v = v_0+\frac{F}{m}t</span>



<span data-katex-display="true">x = x_0+vt</span></p><p>Each object needs to store these three properties: velocity, mass, and net force. Here we find the first decision we can make towards the design, net force could either be a list or a single vector. In school you make force diagrams and sum up the forces, implying that we should store a list. This would make it so you could set a force, but you would need to remove it later which could get annoying for the user. If we think about it further, net force is really the total force applied in a <em>single</em> frame, so we can use a vector and clear it at the end of each update. This allows the user to apply a force by adding it, but removing it is automatic. This shortens our code and gives a performance bump because there is no summation of forces, it’s a running total.</p>



<p>We’ll use this struct to store the object info for now.</p>



<pre><span>struct</span>&nbsp;<span>Object</span>&nbsp;<span>{</span>
	<span>vector3</span>&nbsp;<span>Position</span><span>;</span>&nbsp;<span>//&nbsp;struct&nbsp;with&nbsp;3&nbsp;floats&nbsp;for&nbsp;x,&nbsp;y,&nbsp;z&nbsp;or&nbsp;i&nbsp;+&nbsp;j&nbsp;+&nbsp;k</span>
	<span>vector3</span>&nbsp;<span>Velocity</span><span>;</span>
	<span>vector3</span>&nbsp;<span>Force</span><span>;</span>
	<span>float</span>&nbsp;<span>Mass</span><span>;</span>
<span>};</span>
</pre>



<p>We need a way to keep track of the objects we want to update. A classic approach is to have a <em>physics world</em> that has list of objects and a <em>step</em> function that loops over each one. Let’s see how that might look; I’ll omit header/cpp files for brevity.</p>



<pre><span>class</span>&nbsp;<span>PhysicsWorld</span>&nbsp;<span>{</span>
<span>private</span><span>:</span>
	<span>std</span><span>::</span><span>vector</span><span>&lt;</span><span>Object</span><span>*&gt;</span>&nbsp;<span>m_objects</span><span>;</span>
	<span>vector3</span>&nbsp;<span>m_gravity</span>&nbsp;<span>=</span>&nbsp;<span>vector3</span><span>(</span><span>0</span><span>,</span>&nbsp;<span>-</span><span>9.81f</span><span>,</span>&nbsp;<span>0</span><span>);</span>
 
<span>public</span><span>:</span>
	<span>void</span>&nbsp;<span>AddObject</span>&nbsp;&nbsp;&nbsp;<span>(</span><span>Object</span><span>*</span>&nbsp;<span>object</span><span>)</span>&nbsp;<span>{</span>&nbsp;<span>/*&nbsp;...&nbsp;*/</span>&nbsp;<span>}</span>
	<span>void</span>&nbsp;<span>RemoveObject</span><span>(</span><span>Object</span><span>*</span>&nbsp;<span>object</span><span>)</span>&nbsp;<span>{</span>&nbsp;<span>/*&nbsp;...&nbsp;*/</span>&nbsp;<span>}</span>
 
	<span>void</span>&nbsp;<span>Step</span><span>(</span>
		<span>float</span>&nbsp;<span>dt</span><span>)</span>
	<span>{</span>
		<span>for</span>&nbsp;<span>(</span><span>Object</span><span>*</span>&nbsp;<span>obj</span>&nbsp;<span>:</span>&nbsp;<span>m_objects</span><span>)</span>&nbsp;<span>{</span>
			<span>obj</span><span>-&gt;</span><span>Force</span>&nbsp;<span>+=</span>&nbsp;<span>obj</span><span>-&gt;</span><span>Mass</span>&nbsp;<span>*</span>&nbsp;<span>m_gravity</span><span>;</span>&nbsp;<span>//&nbsp;apply&nbsp;a&nbsp;force</span>
 
			<span>obj</span><span>-&gt;</span><span>Velocity</span>&nbsp;<span>+=</span>&nbsp;<span>obj</span><span>-&gt;</span><span>Force</span>&nbsp;<span>/</span>&nbsp;<span>obj</span><span>-&gt;</span><span>Mass</span>&nbsp;<span>*</span>&nbsp;<span>dt</span><span>;</span>
			<span>obj</span><span>-&gt;</span><span>Position</span>&nbsp;<span>+=</span>&nbsp;<span>obj</span><span>-&gt;</span><span>Velocity</span>&nbsp;<span>*</span>&nbsp;<span>dt</span><span>;</span>
 
			<span>obj</span><span>-&gt;</span><span>Force</span>&nbsp;<span>=</span>&nbsp;<span>vector3</span><span>(</span><span>0</span><span>,</span>&nbsp;<span>0</span><span>,</span>&nbsp;<span>0</span><span>);</span>&nbsp;<span>//&nbsp;reset&nbsp;net&nbsp;force&nbsp;at&nbsp;the&nbsp;end</span>
		<span>}</span>
	<span>}</span>
<span>};</span>
</pre>



<p>Note the use of pointers, this forces other systems to take care of the actual storing of objects, leaving the physics engine to worry about physics, not memory allocation.</p>



<p>With this you can simulate all sorts of stuff from objects flying through the sky to solar systems.</p>



<iframe src="https://www.youtube.com/embed/crKrkn-RIOU?rel=0" allowfullscreen=""></iframe>



<iframe src="https://www.youtube.com/embed/sHZEs-oQTI4?rel=0" allowfullscreen=""></iframe>



<p>You can do a lot with this, but it’s the easy part to be honest, and that’s not what you came for…</p>



<p><strong>Collision detection</strong></p>



<p>Collision detection is more involved, but we can lighten the load by using some clever tricks. Let’s think about what needs to be found first. If we look at some examples of objects colliding, we notice that in most cases there is a point on each shape that is furthest inside the other.</p>



<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 364.19 219.82"><defs></defs><g id="Layer_2" data-name="Layer 2"><g id="Layer_1-2" data-name="Layer 1"><path id="a7vJywMoip" d="M250.74,108.59A108.34,108.34,0,1,1,142.4.25,108.39,108.39,0,0,1,250.74,108.59Z"></path><path id="aojGvlR1o" d="M364.19,149.47H0"></path><path id="b13RQfe45N" d="M145,216.93a2.64,2.64,0,1,1-2.64-2.64A2.64,2.64,0,0,1,145,216.93Z"></path><path id="a3jwpJe9bd" d="M145,149.47a2.64,2.64,0,1,1-2.64-2.64A2.64,2.64,0,0,1,145,149.47Z"></path><g id="epQfmNKBq"><text transform="translate(147.06 211.83)">A</text></g><g id="g3JoLaPokP"><text transform="translate(147.06 143.56)">B</text></g><path id="bnhzn14P" d="M145,157.62l-2.64-3.82-2.64,3.82h1.68v54.21h1.93V157.62Z"></path><g id="a5EIiwgkw"><g id="aeJzDwQJn"><text transform="translate(269.3 140.4)">Plane B</text></g></g><g id="lWR9tvULn"><g id="giK7zCiBZ"><text transform="translate(209.6 209.41)">Sphere A</text></g></g></g></g></svg>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 319.48 293.52"><defs></defs><g id="Layer_2" data-name="Layer 2"><g id="Layer_1-2" data-name="Layer 1"><path id="circleB" d="M216.92,108.58A108.34,108.34,0,1,1,108.58.25,108.38,108.38,0,0,1,216.92,108.58Z"></path><path id="pointA" d="M201.59,169.27a2.64,2.64,0,1,1-2.64-2.64A2.64,2.64,0,0,1,201.59,169.27Z"></path><path id="bvujLY3Pv" d="M319.23,184.93A108.34,108.34,0,1,1,210.89,76.59,108.4,108.4,0,0,1,319.23,184.93Z"></path><path id="b2sM6mmV3Y" d="M138.53,105.94a2.64,2.64,0,1,1-2.64-2.64A2.64,2.64,0,0,1,138.53,105.94Z"></path><g id="g7IjQmpjFM"><g id="a5ffFLN0Lk"><text transform="translate(206.96 169.27)">A</text></g></g><g id="f5t39XVL9"><g id="a3HVPWIRk6"><text transform="translate(125.66 100.13)">B</text></g></g><path id="a6B9Ro3d2Q" d="M145.73,112.32l-5.51-1.77,1.78,5.5,1.18-1.18,51.76,51.76,1.37-1.37L144.55,113.5Z"></path><g id="b34R6jrlf6"><g id="azoQGzEb0"><text transform="translate(254.28 162.37)">Sphere B</text></g></g><g id="c1Pseh1RfC"><g id="j1Q686eol"><text transform="translate(10.62 84.31)">Sphere A</text></g></g></g></g></svg>



<p>This turns out to be all we need to respond to a collision. From those two points we can find the normal, and how deep the objects are inside one another. This is huge because it means that we can abstract the idea of different shapes away, and only worry about the points in the response.</p>



<p>Let’s jump into the code, we’ll need some helper structs that I’ll note first.</p>



<pre><span>struct</span>&nbsp;<span>CollisionPoints</span>&nbsp;<span>{</span>
	<span>vector3</span>&nbsp;<span>A</span><span>;</span>&nbsp;<span>//&nbsp;Furthest&nbsp;point&nbsp;of&nbsp;A&nbsp;into&nbsp;B</span>
	<span>vector3</span>&nbsp;<span>B</span><span>;</span>&nbsp;<span>//&nbsp;Furthest&nbsp;point&nbsp;of&nbsp;B&nbsp;into&nbsp;A</span>
	<span>vector3</span>&nbsp;<span>Normal</span><span>;</span>&nbsp;<span>//&nbsp;B&nbsp;–&nbsp;A&nbsp;normalized</span>
	<span>float</span>&nbsp;<span>Depth</span><span>;</span>&nbsp;&nbsp;&nbsp;&nbsp;<span>//&nbsp;Length&nbsp;of&nbsp;B&nbsp;–&nbsp;A</span>
	<span>bool</span>&nbsp;<span>HasCollision</span><span>;</span>
<span>};</span>
 
<span>struct</span>&nbsp;<span>Transform</span>&nbsp;<span>{</span>&nbsp;<span>//&nbsp;Describes&nbsp;an&nbsp;objects&nbsp;location</span>
	<span>vector3</span>&nbsp;<span>Position</span><span>;</span>
	<span>vector3</span>&nbsp;<span>Scale</span><span>;</span>
	<span>quaternion</span>&nbsp;<span>Rotation</span><span>;</span>
<span>};</span>
</pre>



<p>Each shape will have a different type of collider to hold its properties and a base to allow them to be stored. Any type of collider should be able to test for a collision with any other type, so we’ll add functions in the base for each one. These functions will take <em>Transforms</em>, so the colliders can use relative coordinates. I’ll only demonstrate spheres and planes, but the code is repeatable for any number of colliders.</p>



<pre><span>struct</span>&nbsp;<span>Collider</span>&nbsp;<span>{</span>
	<span>virtual</span>&nbsp;<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>Collider</span><span>*</span>&nbsp;<span>collider</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>colliderTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>=</span>&nbsp;<span>0</span><span>;</span>
 
	<span>virtual</span>&nbsp;<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>SphereCollider</span><span>*</span>&nbsp;<span>sphere</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>sphereTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>=</span>&nbsp;<span>0</span><span>;</span>
 
	<span>virtual</span>&nbsp;<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>PlaneCollider</span><span>*</span>&nbsp;<span>plane</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>planeTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>=</span>&nbsp;<span>0</span><span>;</span>
<span>};</span>
</pre>



<p>Let’s make both types of colliders at the same time too see how they interact. A sphere is defined as a point and a radius, and a plane is defined as a vector and a distance. We’ll override the functions from <em>Collider</em>, but won’t worry about the work for now.</p>



<p>We can choose per collider which other colliders it will detect by filling, or not filling, in these functions. In this case, we don’t want Plane v Plane collisions, so we return an empty <em>CollisionPoints</em>.</p>



<pre><span>struct</span>&nbsp;<span>SphereCollider</span>
	<span>:</span>&nbsp;<span>Collider</span>
<span>{</span>
	<span>vector3</span>&nbsp;<span>Center</span><span>;</span>
	<span>float</span>&nbsp;<span>Radius</span><span>;</span>
 
	<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>Collider</span><span>*</span>&nbsp;<span>collider</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>colliderTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>override</span>
	<span>{</span>
		<span>return</span>&nbsp;<span>collider</span><span>-&gt;</span><span>TestCollision</span><span>(</span><span>colliderTransform</span><span>,</span>&nbsp;<span>this</span><span>,</span>&nbsp;<span>transform</span><span>);</span>
	<span>}</span>
 
	<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>SphereCollider</span><span>*</span>&nbsp;<span>sphere</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>sphereTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>override</span>
	<span>{</span>
		<span>return</span>&nbsp;<span>algo</span><span>::</span><span>FindSphereSphereCollisionPoints</span><span>(</span>
			<span>this</span><span>,</span>&nbsp;<span>transform</span><span>,</span>&nbsp;<span>sphere</span><span>,</span>&nbsp;<span>sphereTransform</span><span>);</span>
	<span>}</span>
 
	<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>PlaneCollider</span><span>*</span>&nbsp;<span>plane</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>planeTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>override</span>
	<span>{</span>
		<span>return</span>&nbsp;<span>algo</span><span>::</span><span>FindSpherePlaneCollisionPoints</span><span>(</span>
			<span>this</span><span>,</span>&nbsp;<span>transform</span><span>,</span>&nbsp;<span>plane</span><span>,</span>&nbsp;<span>planeTransform</span><span>);</span>
	<span>}</span>
<span>};</span></pre>



<p>We can add a function for testing the base and use a technique called <a href="https://en.wikipedia.org/wiki/Double_dispatch" target="_blank" rel="noreferrer noopener">double dispatch</a>. This takes advantage of the type system to determine both types of colliders for us by swapping the arguments, determining the first, then the second type through two calls of TestCollision. This saves us needing to know what type of colliders we are checking, which means we’ve fully abstracted away the notion of different shapes outside the collision detection.</p>



<pre><span>struct</span>&nbsp;<span>PlaneCollider</span>
	<span>:</span>&nbsp;<span>Collider</span>
<span>{</span>
	<span>vector3</span>&nbsp;<span>Plane</span><span>;</span>
	<span>float</span>&nbsp;<span>Distance</span><span>;</span>
 
	<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>Collider</span><span>*</span>&nbsp;<span>collider</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>colliderTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>override</span>
	<span>{</span>
		<span>return</span>&nbsp;<span>collider</span><span>-&gt;</span><span>TestCollision</span><span>(</span><span>colliderTransform</span><span>,</span>&nbsp;<span>this</span><span>,</span>&nbsp;<span>transform</span><span>);</span>
	<span>}</span>
 
	<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>SphereCollider</span><span>*</span>&nbsp;<span>sphere</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>sphereTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>override</span>
	<span>{</span>
		<span>//&nbsp;reuse&nbsp;sphere&nbsp;code</span>
		<span>return</span>&nbsp;<span>sphere</span><span>-&gt;</span><span>TestCollision</span><span>(</span><span>sphereTransform</span><span>,</span>&nbsp;<span>this</span><span>,</span>&nbsp;<span>transform</span><span>);</span>
	<span>}</span>
 
	<span>CollisionPoints</span>&nbsp;<span>TestCollision</span><span>(</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>transform</span><span>,</span>
		<span>const</span>&nbsp;<span>PlaneCollider</span><span>*</span>&nbsp;<span>plane</span><span>,</span>
		<span>const</span>&nbsp;<span>Transform</span><span>*</span>&nbsp;<span>planeTransform</span><span>)</span>&nbsp;<span>const</span>&nbsp;<span>override</span>
	<span>{</span>
		<span>return</span>&nbsp;<span>{};</span>&nbsp;<span>//&nbsp;No&nbsp;plane&nbsp;v&nbsp;plane</span>
	<span>}</span>
<span>};</span>
</pre>



<p>In cases like this, where there are many classes with a web of similar functions, it can be confusing as to where the actual code is located. <em>Sphere</em> v …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.winter.dev/2020/designing-a-physics-engine/">https://blog.winter.dev/2020/designing-a-physics-engine/</a></em></p>]]>
            </description>
            <link>https://blog.winter.dev/2020/designing-a-physics-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24016718</guid>
            <pubDate>Sat, 01 Aug 2020 02:07:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Retail millennials are now in charge]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24016249">thread link</a>) | @shdc
<br/>
July 31, 2020 | https://shyal.com/blog/retail-millennials-are-now-in-charge | <a href="https://web.archive.org/web/*/https://shyal.com/blog/retail-millennials-are-now-in-charge">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    
     

    
    â†�
    <a href="https://shyal.com/">ðŸ�&nbsp;</a>
     
    <!-- if has_fences -->
    <!-- <div><a href='/black'><img src='/Attachments/black.svg'/></a></div> -->
    <!--  end  -->
    <p>2020 has flipped the investment scene upside down: retail investors are now in charge. It first struck me when i picked the <a href="https://shyal.com/blog/tesla-stock-bottom-date">tesla stock bottom date</a> while professional financial advisors, professional investors, and economics professors missed the entire 800% move.</p>
<h2 id="millenials-hold-the-reins">Millenials hold the reins</h2>
<p>Don't want to take my word for it? Then in the words of billionaire investor Chamath Paliphpitiya:</p>
<blockquote>
<blockquote>
<p>"Retail investors now have access to so much information that it's almost on parity with people that work in traditional investment organisations" -- Chamath Palihapitiya</p>
</blockquote>
</blockquote>
<p><img alt="Pasted image 48.png" src="https://shyal.com/Attachments/Pasted%20image%2048.png"></p>
<h2 id="the-importance-of-retail-flows">The importance of retail flows</h2>
<p><a href="https://www.biancoresearch.com/about-us/">Jim Bianco</a>, a macro strategist who recently featured on <a href="https://realvision.com/">RealVision</a> also agrees: </p>
<blockquote>
<blockquote>
<p>"Well, that seems to be what's going on with a lot of this money, even though a traditional AAII account might have half a million dollars in it, and a Robinhood account might have 10,000 just to use a number, that 10,000 will turn over every day or two, that half a million might do three trades a year. That Robinhood account will have a bigger influence on the flow of money in and out of the markets than those other accounts. Citadel says that about 25% of all trading in the markets, they said this to Bloomberg a few weeks ago, is retail investors on peak days, 20% on normal days. Now the third group" -- Jim Bianco @ RealVision</p>
</blockquote>
</blockquote>
<p>This means:</p>
<ul>
<li>on peak days, people trading on their apps are actually driving the price action.</li>
<li>the rest of the time (non peak days) they still dictate about a third of the price action.</li>
</ul>
<p>The average Robinhood investor is <a href="https://techcrunch.com/2020/02/20/robinhood-profiles-morgan-stanley-etrade">30 years old</a>. </p>
<p><img alt="Pasted image 51.png" src="https://shyal.com/Attachments/Pasted%20image%2051.png"></p>
<h2 id="listen-to-the-millennials-who-have-savings">Listen to the Millennials (who have savings)</h2>
<p><a href="https://www.youtube.com/watch?v=GGberGnxiJk">Thomas Lee</a> also agrees, and has been warning us that Millennials are now entering into their peak income years. It turns out Millennials love <a href="https://www.investopedia.com/terms/g/growthstock.asp">"growth stocks"</a> (companies which re-invest in themselves and focus on exponential growth).</p>
<p>If TSLA teaches us anything, it is that big disruptive growth stock companies have become too complex for traditional finance to analyze under their existing lense. They'll often blend AI, SAAS, economies of scale, etc. and require a more technologically versed group of analysts to properly price.</p>
<p>Maybe this is something Millenials can do, natively, especially when not pressured by their boomer CEOs while working in the traditional fin jobs? After all, Millenials grew up programming their parents' VCRs.</p>
<p>Another thesis is that <strong>it doesn't matter whether millennials are right or wrong</strong>. They are now calling the shots. If they say it's right, then it's right.</p>
<p><img alt="Pasted image 50.png" src="https://shyal.com/Attachments/Pasted%20image%2050.png"></p>
<h2 id="ditch-your-hedge-fund">Ditch your hedge fund</h2>
<p>We now know that hedge funds are basically a money-making myth:</p>
<blockquote>
<blockquote>
<p>"Hedge funds lost 3.8% of assets globally in 2019, the most since 2009" --<a href="https://www.marketwatch.com/story/clients-withdrew-nearly-1-of-all-hedge-fund-assets-in-december-2020-02-18">market watch</a></p>
</blockquote>
</blockquote>
<p>You can also ditch your financial advisor if they missed all the important trends of 2020. They'll tell you that you cannot live without them; they'll enter self-preservation mode, but remember they make money from you; and the data is showing they should start paying you for advice, not vice versa.</p>
<h2 id="to-sum-up">To sum up</h2>
<ul>
<li>Do your own research, you have access to as much information as investment firms.</li>
<li>Listen to 30 year olds. What companies do they like? <strong>30 year olds dictate the trends</strong>.</li>
<li>Research <strong>good</strong> investment apps: apps that let you directly buy:<ul>
<li>Stocks</li>
<li>Commodities</li>
<li>Bitcoin</li>
</ul>
</li>
<li>Start <strong>small</strong>, while you learn.</li>
</ul>
<p>You are now in charge.</p>
    </div></div>]]>
            </description>
            <link>https://shyal.com/blog/retail-millennials-are-now-in-charge</link>
            <guid isPermaLink="false">hacker-news-small-sites-24016249</guid>
            <pubDate>Sat, 01 Aug 2020 00:56:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[National Defense Authorization Act: Implications for Design Engineers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24016173">thread link</a>) | @stn8188
<br/>
July 31, 2020 | https://shielddigitaldesign.com/posts/2020_001_ndaa/ndaa/ | <a href="https://web.archive.org/web/*/https://shielddigitaldesign.com/posts/2020_001_ndaa/ndaa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://shielddigitaldesign.com/posts/2020_001_ndaa/ndaa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24016173</guid>
            <pubDate>Sat, 01 Aug 2020 00:43:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TODO Zero: Write more robust code by treating TODOs like sticky notes]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24015723">thread link</a>) | @countermeasure
<br/>
July 31, 2020 | https://redandblack.io/blog/2020/todo-zero/ | <a href="https://web.archive.org/web/*/https://redandblack.io/blog/2020/todo-zero/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <p>When used well, TODOs can help you write more robust code and minimise
unhandled edge cases. When used badly, they disappear into your codebase and
are forgotten, marking problems which will never be fixed.</p>
<p>Here’s what I think of as a best-practice system for using TODOs. It treats
them like sticky notes and is made up of two rules and four actions. I call it
“TODO Zero”.</p>
<h2 id="the-two-rules">The two rules</h2>
<p>There are only two rules, and everything flows from them.</p>
<p>They are:</p>
<ol>
<li>
<p>Capture every useful thought in a TODO.</p>
</li>
<li>
<p>Leave no TODOs in shipped code.</p>
</li>
</ol>
<h2 id="the-four-actions">The four actions</h2>
<p>Something must be done with a TODO which was created because of Rule 1 before
it is deleted because of Rule 2, so the rules give rise to the four actions.</p>
<p>They are:</p>
<ol>
<li>
<p>Disregard it.</p>
</li>
<li>
<p>Do it.</p>
</li>
<li>
<p>Create an issue (or ticket) from it.</p>
</li>
<li>
<p>Convert it to a note.</p>
</li>
</ol>
<h2 id="the-system">The system</h2>
<p>These rules and actions combine to create a simple system which works like
this.</p>
<p>When you’re writing code and you have a useful idea or thought which isn’t
directly relevant to the code you’re writing at that instant, record it as a
TODO. Then as soon as you’ve done that forget about it and go back to the
code you were writing.</p>
<p>Treat a TODO as a temporary reminder, like a sticky note. It serves two
purposes. The first is to make sure that ideas and insights which you can’t act
on straight away aren’t forgotten. The second is to clear your mind of thoughts
that aren’t relevant to what you’re doing right at that instant.</p>
<p>Over your work session, review the TODOs you’ve written. Your aim for each one
is to use one of the four actions to deal with it, and then delete it. Just
like sticky notes, TODOs are thrown out as soon as they’ve served their purpose
as a reminder, and just like sticky notes, they don’t make it into the final
product.</p>
<p>Before your code reaches the branch from which you ship (i.e. release or
deploy), all the TODOs you’ve created should be deleted. No TODOs should
survive in your finished code, which is where the name <em>TODO Zero</em> comes from.</p>
<h2 id="lets-dive-in">Let’s dive in</h2>
<p>That was the high-level summary, now stay with me as I explain how it works,
why it works and how to best make it work for you.</p>
<p>First, let’s start with a look at the most common problem <em>TODO Zero</em> saves you
from – The Forgotten TODO.</p>
<h2 id="the-forgotten-todo">The Forgotten TODO</h2>
<p>A TODO usually marks something that the person who left it didn’t have the
time, energy or knowledge to take care of.</p>
<p>Let’s say you’re coding productively and you don’t want to slow down to handle
an unlikely edge case, so you quickly throw in a comment like this and move on:</p>
<div><pre><code data-lang="python"><span># TODO: Handle an empty list.</span></code></pre></div>
<p>Or you’re racing the clock on a deadline. The function you’ve just finished is
unpleasantly complicated <em>but it works</em>, and so you add a note like this above
it:</p>
<div><pre><code data-lang="python"><span># TODO: Clean this function up.</span></code></pre></div>
<p>Or maybe an aspect of what you’re doing is a bit beyond your current
capabilities, so you leave a comment like this behind hoping that someone with
the right skills will see it one day and sort it out:</p>
<div><pre><code data-lang="python"><span># TODO: Optimise for large querysets.</span></code></pre></div>
<p>It’s easy to write a TODO and tell ourselves someone will get to it sometime.
But is that what really happens once we finish working with that code? Does
someone get to it, ever? In my experience, the answer is usually “no”.</p>
<p>How often have you stumbled across a TODO in some rarely visited code, only to
ignore it and move on because it’s not relevant to the task at hand? How many
people before you have ignored that same comment, just as you did? And so there
it stays through the ages, forgotten.</p>
<p><em>TODO Zero</em> stops TODOs being forgotten because it requires us to do something
with them rather than letting them sneak into shipped code.</p>
<p>Let’s see how to put it into practice!</p>
<h2 id="rule-1-capture-every-useful-thought-in-a-todo">Rule 1: Capture every useful thought in a TODO</h2>
<p>If you’re anything like me, you’ll have thoughts and realisations about the
code you’re working on faster than you can implement them.</p>
<p>Many of these will be useful, and easily forgotten. If you try to remember
them, you’ll find that they get in the way of you focusing properly on the code
you’re writing, <em>and you’ll still forget some</em>. The less you try to remember,
the lower your <a href="https://en.wikipedia.org/wiki/Cognitive_load" target="_blank">cognitive load</a> and the more clearly you can think.</p>
<p>It’s much better to capture them in TODOs as they come to you, as if you were
jotting them down quickly on sticky notes. Do this and you can come back and
take care of each one when you have time and can give it your full attention.</p>
<p>Let’s say you’ve just finishing writing the signature of the <code>display_errors</code>
function when two edge cases it will need to handle come to mind. You can
capture them like this:</p>
<div><pre><code data-lang="python"><span>def</span> <span>display_errors</span>(error_list):
    <span># TODO: Handle a really long list. Truncate and add count of hidden items?</span>
    <span># TODO: Handle error messages with &gt;100 characters.</span></code></pre></div>
<p>It’s better to get the main path through the function fleshed out before
shifting focus to handle those edge cases, so you make them into TODOs and
forget about them for now.</p>
<p>Then let’s say you’re only two lines into <code>display_errors</code> when you have a
realisation about the thread-safety of the <code>build_pdf</code> function you wrote an
hour ago. Again, capture it in a TODO. It doesn’t matter where. You can put it
right where you’re working for the time being and move it later:</p>
<div><pre><code data-lang="python"><span>def</span> <span>display_errors</span>(error_list):
    <span>for</span> error <span>in</span> error_list:
        <span>print</span>(error)
    <span># TODO: Ensure that build_pdf function is thread-safe.</span>
    <span># TODO: Handle a really long list. Truncate and add hidden item count?</span>
    <span># TODO: Handle error messages with &gt;100 characters.</span></code></pre></div>
<p>When you use TODOs in this way, you ensure that every realisation and edge case
which occurs to you is recorded and will be dealt with. Once recorded they
can’t fall through the cracks, so your code will be more robust.</p>
<p>Because a TODO is now just a note to yourself, don’t take time making it
detailed or perfect. You’re the only one who will read it. As long as you can
understand it, that’s all that matters. Just like a sticky note.</p>
<p>Anyone familiar with <a href="https://en.wikipedia.org/wiki/David_Allen_%28author%29" target="_blank">David Allen's</a>
<a href="https://en.wikipedia.org/wiki/Getting_Things_Done" target="_blank">Getting Things Done (GTD) methodology</a> will recognise what I’ve just
described as what he calls “ubiquitous capture”. Which is really just another
way of saying that if you have a good idea, record it somewhere so you don’t
forget it.</p>
<h2 id="rule-2-leave-no-todos-in-shipped-code">Rule 2: Leave no TODOs in shipped code</h2>
<p>The TODOs you create represent tasks you need to do, problems you need to solve
or ideas you need to consider as part of the work you’re doing.</p>
<p>Every single one should be addressed and then removed before the code reaches
the branch you ship from.</p>
<p>By addressing them all, you gain the confidence of knowing that every potential
problem or issue which occurred to you has been dealt with, so your code is as
thorough as you can make it.</p>
<p>Addressing a TODO requires you to <em>do something with it</em> so that it is no
longer needed. That means applying one of the four actions – disregard it, do
it, create an issue from it or convert it to a note. I’ll explain each of them
in more detail shortly.</p>
<p>As you progress through the work you’re doing, take some time now and then to
look over the TODOs you’ve made. When the time is right for each one, do
something with it and then delete it.</p>
<p>I use this <a href="https://www.gnu.org/software/make/manual/make.html#Introduction" target="_blank">Makefile</a> target which lists all TODOs to help with that:</p>
<div><pre><code data-lang="make"><span>todos</span>:
    @grep -r -v <span>"| grep TODO"</span> . | grep TODO
</code></pre></div>
<p>You should find that as you get closer to finishing there are fewer and fewer
remaining. When you finish, ensure that there are none left at all. Your code
is not complete until they have all been addressed and removed.</p>
<p>Again, think of a TODO like a sticky note. It’s a scrappy short-term reminder
that doesn’t belong in a finished product and is disposed of when it has served
its purpose.</p>
<p>Now let’s look at each of the four actions.</p>
<h2 id="action-1-disregard-it">Action 1: Disregard it</h2>
<p><em>Sometimes you’re wrong.</em></p>
<p>When you record all the thoughts and ideas that cross your mind, once you come
back later to give them your full attention, it’s inevitable that some will
turn out to be junk, or mistakes, or just not worth doing.</p>
<p>Maybe you thought you saw an edge case where there wasn’t one. Maybe what
seemed like a good idea turns out to be a bad idea. Maybe you saw an
opportunity for an optimisation which would actually be too time-consuming to
be worth doing.</p>
<p>Not to worry. When you come across a TODO like this, disregard it, delete it,
and move on.</p>
<h2 id="action-2-do-it">Action 2: Do it</h2>
<p><em>Sometimes you’re right.</em></p>
<p>Often a TODO contains a good idea that’s worth doing, and worth doing now.</p>
<p>Maybe it’s an easy optimisation. Maybe it’s dealing with an edge case.</p>
<p>If it’s necessary to complete your work, or if it’s not but you think it’s
worth doing now anyway, do it. Then once you’ve done it, delete that TODO.</p>
<h2 id="action-3-create-an-issue-or-ticket-from-it">Action 3: Create an issue (or ticket) from it.</h2>
<p><em>Sometimes it can wait for later.</em></p>
<p>There will be some TODOs which describe something which will need to be done
eventually, but which can wait until after your code is shipped.</p>
<p>For each of these, create an issue from it in the project’s issue tracker, then
delete the TODO.</p>
<p>Although some people argue that in cases like this leaving TODOs in shipped
code is an effective way to track tasks that need to be done, I disagree. I’m a
believer in the benefits of having a single source of truth for work to be
done. When an issue tracker isn’t tracking <em>all</em> the work for a project, you
undermine its effectiveness, and I say that because my experience is that
what’s not in the issue tracker doesn’t get done.</p>
<h2 id="action-4-convert-it-to-a-note">Action 4: Convert it to a note.</h2>
<p><em>Sometimes it’s just not going to happen.</em></p>
<p>Some TODOs fall into the category of “in a perfect world we’d address that, but
it’s never likely to be important enough to worry about”.</p>
<p>In my experience, these are often the ones which flag edge cases which are
either very unlikely to arise, or won’t have worrying consequences when they
do, or both.</p>
<p>It’s not appropriate to create issues about these in your issue tracker,
because you don’t actually intend to do anything about them.</p>
<p>But it is helpful to convert them into NOTEs which point out the shortcomings
of the code for the benefit of people who will work with it in the future.</p>
<p>As an example, you …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://redandblack.io/blog/2020/todo-zero/">https://redandblack.io/blog/2020/todo-zero/</a></em></p>]]>
            </description>
            <link>https://redandblack.io/blog/2020/todo-zero/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24015723</guid>
            <pubDate>Fri, 31 Jul 2020 23:45:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zero-Cost References with Regions]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24015581">thread link</a>) | @verdagon
<br/>
July 31, 2020 | https://vale.dev/blog/zero-cost-refs-regions | <a href="https://web.archive.org/web/*/https://vale.dev/blog/zero-cost-refs-regions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://vale.dev/blog/zero-cost-refs-regions</link>
            <guid isPermaLink="false">hacker-news-small-sites-24015581</guid>
            <pubDate>Fri, 31 Jul 2020 23:30:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introverts are excluded unfairly in an extraverts’ world]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24015012">thread link</a>) | @__ka
<br/>
July 31, 2020 | https://psyche.co/ideas/introverts-are-excluded-unfairly-in-an-extraverts-world | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/introverts-are-excluded-unfairly-in-an-extraverts-world">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>Life as an introvert</strong> is rarely easy. Ever since I graduated, Iâ€™ve been compelled to work in open-plan offices. Itâ€™s exhausting. Imagine being engaged in a task that requires high concentration, such as looking for a lost earing in the middle of a tennis court. Now imagine that an automatic ball launcher keeps shooting balls directly at you. Wouldnâ€™t you get tired quickly, and be much less efficient in your search? This is how I feel during my work, when sudden and repeating distractions are â€˜shotâ€™ at or near my desk.</p><p>The struggle of an introvert doesnâ€™t end in the office. Networking at conferences, some with thousands of attendees, is a central part of an academic career. Picture yourself entering a huge hall, with bright neon lights, hundreds of people in each aisle, and a background din that forces you to yell to be heard. In a typical two-hour poster session, youâ€™re expected to acquire the information you need while also efficiently introducing your own work to colleagues. As an introvert, the experience is equal to riding a terrifying rollercoaster while having to maintain a big smile on your face.</p><p>I wish I could say these types of challenge are limited to the work environment, but thatâ€™s not the case. For my most recent birthday, a friend bought me a dinner at EatWith â€“ a meal-sharing platform. Youâ€™re invited to dine in the house of strangers who cook for you and other participating guests. I would enjoy the food and cultural experience if I didnâ€™t have to go through the excruciating labour of small talk with random people. â€˜Sounds like fun,â€™ I said politely to my friend, but privately my immediate sense was that this was yet another ill-designed platform for introverts.</p><p>Today, as a psychologist, I know that introversion is a <a href="https://www.pewresearch.org/science/2015/12/11/personality-and-interest-in-science-health-topics/" target="_blank">common</a> trait. Unlike shyness, which is more about a fear of being judged negatively, introversion is defined as a preference for quiet, less stimulating environments. The Swiss psychoanalyst Carl Jung was the first to propose differentiating individuals along an introvert-extravert axis. Writing in the 1920s, he <a href="http://www.cyjack.com/cognition/(ebook%20pdf)%20jung,%20carl%20-%20the%20psychological%20types.pdf" target="_blank">described</a> introverts as preferring to direct their attention inward, to their own feelings and thoughts, and how they lose energy during social interactions. Extraverts, by contrast, direct their attention outward, gain energy from social interactions, and lose energy during periods of solitude.</p><p>Beginning in the 1950s, the German-born psychologist Hans Eysenck proposed a physiological explanation for the difference between introverts and extraverts. Extraverts, he <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8295.1964.tb00912.x" target="_blank">said</a>, have a lower baseline level of cortical arousal relative to introverts, leading them to search for external stimulation to increase their motivation, attention and alertness. Introvertsâ€™ higher baseline arousal levels, in contrast, lead them to withdraw. Contemporary psychology still considers the introversion-extraversion distinction a core aspect of personality (it is one of the <a href="https://psycnet.apa.org/record/1991-09869-001" target="_blank">so-called</a> â€˜Big Fiveâ€™ traits), although it is seen as a continuous spectrum along which we are all positioned, rather than a dichotomous state.</p><p>Although thereâ€™s no definitive way of identifying the proportion of introverts in the population, Susan Cain, an influential thinker in the field, has made a reasonable <a href="https://www.penguin.co.uk/books/296/296443/quiet-power/9780241977910.html" target="_blank">estimate</a> that at least a third of people are at one end of this spectrum. The third on the other end are extraverts, and the final third fall somewhere in between â€“ some <a href="https://www.tandfonline.com/doi/abs/10.1207/s15327752jpa4305_14" target="_blank">call</a> these people â€˜ambivertsâ€™. Knowing that introverts comprise an approximately equal share of the population as extraverts, I keep wondering about the missing 33 per cent â€“ where are all the introverts in the ocean of extraverts that surround me in my daily life?</p><p>Many of the decisions relating to the daily life of introverts are in the hands of extraverts</p><p><strong>While I have introverted</strong> friends, they seem to be vastly outnumbered by my extraverted friends and acquaintances. I have to remind myself that this apparent absence from my daily landscape is not surprising: we introverts are much harder to notice. Introverts probably wonâ€™t be the ones sharing a joke with the entire office, waiting by the coffee machine for a chance to chat, or appearing on television screens as rising reality-show stars. On the contrary, theyâ€™re more likely to enjoy some quiet time by themselves or with a few selected friends, to process their thoughts silently before saying them out loud, and to retreat to their quiet-place to recharge after social interactions.</p><p>While the higher visibility of extraverts is self-explanatory, it is far from trivial. Not only does it mean introversion is perceived as less common than it really is, but also introverts are less likely to be evenly represented in influential social groups, including in politics. We risk missing the immense contribution of a large percentage of our employees, students, trainees and friends.</p><p>For <a href="https://journals.sagepub.com/doi/10.1177/0894439312462802" target="_blank">example</a>, extraverts are more likely to take part in political engagements, such as disseminating political messages and signing petitions, both on the internet and offline. Negative political messages, which seem so common nowadays, <a href="https://jspp.psychopen.eu/article/view/280" target="_blank">deter</a> introverts from participating in politics, while having the opposite influence on extraverts, including increasing their likelihood of voting, rallying or volunteering for a political campaign. Extraverts are more <a href="https://www.sciencedirect.com/science/article/pii/S0747563209001472" target="_blank">active</a> on social media. They also have easier access to higher corporate ranks, due to the high attention they draw to themselves and to social <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/fire.12173" target="_blank">stereotypes</a> that associate extravert characteristics with leadership. This state of affairs leaves many of the decisions relating to the daily life of introverts in the hands of the extraverts.</p><p>Unfortunately, the greater representation of extraverts in social and political life is self-perpetuating. Working conditions chosen by extraverts to suit extraverts increase the burden on introverts. For instance, group meetings, in which each participant contributes thoughts in a disorganised, dominance-based manner, can put introverts at a disadvantage. The overabundance of extraverts in managing and recruitment roles also decreases the likelihood of introverts winning promotion due to whatâ€™s <a href="https://psycnet.apa.org/record/2016-02267-014" target="_blank">called</a> the â€˜similarity biasâ€™ â€“ our tendency to prefer people who are similar to ourselves. This is not only unfair to introverts, itâ€™s to the detriment of organisations.</p><p>Leadership is commonly associated with extraversion, but history teaches us that introverts can serve as powerful leaders. Rosa Parks, a leading activist in the American civil rights movement, was quiet and reserved. Her brave actions, more than her words, led to a crucial turning-point in the struggle. Similarly, while serving as US president, Barack Obama eagerly protected his solitude in the evenings, spending the time reading and concentrating on work decisions. His preference for small group outings rather than big social events didnâ€™t deprive him of extraordinary communication skills and the ability to make bold decisions. In <a href="https://www.tandfonline.com/doi/abs/10.1080/10904018.2016.1202770" target="_blank">contrast</a> to the mistaken perception of introverts as snobbish, misanthropic or depressed, we can be highly empathic, with strong communicative skills.</p><p>But itâ€™s not a case of establishing whether introverts or extraverts make better leaders, rather each brings something different, and diversity is often key to effective leadership. For <a href="https://link.springer.com/article/10.1007/s11365-014-0334-3" target="_blank">instance</a>, entrepreneurial teams perform better when leadership is shared between individuals, but only if they have diverse personality traits. Moreover, teams dominated by extraverted members <a href="https://psycnet.apa.org/record/2011-15936-006" target="_blank">actually</a> perform better under introverted leaders, possibly due to their greater responsiveness to their employeesâ€™ ideas.</p><p>Introversion is not something to be fixed â€“ but a blessed source of human diversity</p><p>The main cultural problem is that introverts are widely seen as not adapted to the environment, instead of it being acknowledged that the environment is designed to profit extraverts. Societyâ€™s praise and acceptance of extraversion as the norm has led many introverts, along with many ambiverts, to suppress different aspects of their personality, or to see them as flaws. This state of affairs is bad not only for introverts, but for society as a whole.</p><p><strong>The bias begins already</strong> in the first grade of school. Learning in a big classroom environment might be cost-efficient, but is by no means the best model for everyone. Some kids, especially the introverts, will struggle in the continuous company of a large number of others and the constant requirement to engage in group work. The same misconception â€“ placing the onus on introverts to change â€“ is also reflected in the recent <a href="https://psycnet.apa.org/record/2011-18181-001" target="_blank">proposal</a> that introverts would be happier if only they â€˜acted more extravertedâ€™, even if acting this way counteracts their natural tendencies.</p><p>Simple changes across society could be made to mitigate the inequities faced by introverts. In the educational system, for example, designated private spaces in schools could enable periodic shelter for those introverted kids and others who need a place to recharge. Introverts could also profit from greater access to online learning and sharing platforms, with asynchronous communication <a href="https://link.springer.com/chapter/10.1007/978-1-4471-0625-8_15" target="_blank">enabling</a> them to think and research an area without the pressure to respond immediately. Creating equal opportunities for participation in class, such as giving students time to think, the autonomy to decide to work alone or to write their ideas instead of presenting them verbally, could also help rebalance the traditional inequity.</p><p>In business and academic settings, workers should have more autonomy in choosing their working conditions. In meetings, stating the topics to be discussed in advance could allow more time for introverts to prepare and process the information. Allocating time for each attendee to speak could also give introverts the chance to express their thoughts. There should be more questioning of whether group meetings are necessarily the best platform for disseminating knowledge, brainstorming …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/introverts-are-excluded-unfairly-in-an-extraverts-world">https://psyche.co/ideas/introverts-are-excluded-unfairly-in-an-extraverts-world</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/introverts-are-excluded-unfairly-in-an-extraverts-world</link>
            <guid isPermaLink="false">hacker-news-small-sites-24015012</guid>
            <pubDate>Fri, 31 Jul 2020 22:34:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Anatomy of Open Data Projects]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24014777">thread link</a>) | @oscar-batori
<br/>
July 31, 2020 | https://www.dolthub.com/blog/2020-07-30-anatomy-of-open-data-projects/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-07-30-anatomy-of-open-data-projects/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text"><p>A core motivation for building DoltHub was to empower organizations to collaboratively create and maintain high quality data assets that they could collectively depend on. This is very much analogous to GitHub. Analogies are powerful ways to articulate an idea when an appropriate one is already widely understood. In our case a large community of developers, and technology adjacent businesses more broadly, understand GitHub, and how it enabled a revolution in open source software. It's therefore straightforward for us to explain our product in terms of an analogy.</p>
<p>The balance of this article is about the, relatively nascent, open data ecosystem, and the similarities and differences with the the open source software ecosystem.</p>
<h2>Open Source Software</h2>
<p>Collaborative public development of software is not necessary for it to be considered "open source", this is a characteristic of the distribution licensing, but when one uses the term "open source" that is normally what is implicitly understood. Indeed at various points in my career assessing whether to adopt a tool often involved gauging how "vibrant" the "community" around that tool was. What does this mean in specifically?</p>
<ul>
<li>gauging the level of mailing list activity, JIRA board back and forth, or GitHub issues to see a healthy interest in the tool, that is a user base</li>
<li>checking Git commit logs to see if there is a healthy base of contributors</li>
</ul>
<p>The fundamental thing this kind of analysis seeks to establish is a qualitative sense of whether a <em>healthy</em> dynamic exists around the project. At a fundamental level marginal users must see value in the project, and some fraction of them must be willing to convert to contributors in order to sustain the project. If significant investment is attracted, then the user base can grow as the project in creases in scope and quality, thus becoming a solution to more and more problems. This is the "flywheel" that sustains open source projects that allow companies to drop in pieces of software infrastructure that they might otherwise have to buy or maintain. The existence of the open source alternative allows these companies to compare the cost of buying or building to having a stake in a free to use tool, usually outside their core competency.</p>
<p>This is not a scientific, or exhaustive, theory of open source software project dynamics, but it seems a reasonable first approximation of the dynamic that drives companies to seek to employ open source contributors to projects that constitute a critical part of their infrastructure.</p>
<h2>Open Data</h2>
<p>To start to gauge the relevance of this analogy at the level of "project dynamics", I performed a quick Google search:
<a href="https://www.dolthub.com/blog/images/open-data-project-google-search.png">Open Data Projects Google Search</a></p>
<p>The first, non-paid, article is a blog by a SaaS business focused on "spatial data science", and so while data sources may be interesting, they are picked because they compliment Carto's business thesis of the value of geo spatial data. Furthermore, most of the identified "projects" are the work of an individual or organization publishing, rather than the kind of distributed collaboration we identified as the core of the open source software development model.</p>
<p>The next two links are initiatives by the government to make data publicly available. While government data can be great, the existence of single publisher is the essence of its value. We then have Kaggle, a well known platform for machine learning competitions. Since a necessary prerequisite for a machine learning competition is a dataset, Kaggle hosts a lot of free datasets. However, they tend to be tailored toward the competition, and most are not updated, nor is there any concept of collaboration on a single dataset. We then reach some summary articles, probably what we were really looking for, that identify interesting and compelling "open data." However, again these data sources are mostly organizations and governments, or quasi government, entities <em>publishing</em>.</p>
<p>It seems pretty clear that the term "open data" often just means "available data", a one directional relationship where individuals and organizations can consume a data source passively. But how are organizations that have a shared interest in a dataset that is necessary but not a core competitive advantage supposed to collaborate?</p>
<p>Let's dig into an example.</p>
<h2>Open Elections</h2>
<p>One interesting open data project that looks bit like open source software is Open Elections. We have <a href="https://www.dolthub.com/blog/2020-07-01-open-elections/">blogged about</a> the project in the past. Recapping, the goal of the project is simple:</p>
<blockquote>
<p>Our goal is to create the first free, comprehensive, standardized, linked set of election data for the United States, including federal and statewide offices.</p>
</blockquote>
<p>Interest in voting data is broad, and is driven by both professional and personal motivations. Furthermore, many organizations have an interest in voting data, but lack the financial resources to buy it. Many commercial grade solutions, such as the associated press, are tailored to large media organizations with big budgets and low latency tolerance. This is not a good trade off for researchers or campaigns. Open Elections seeks to democratize access to this data by making high quality precinct level results available.</p>
<p>Perhaps because of wide interest in the data there is a sizable base of contributors. It's not hard to imagine that a researcher or enthusiast sees the Open Elections <a href="http://openelections.net/">homepage</a>, and realizes that with a small outlay of effort they can extend the dataset to meet their needs. They <em>convert from a user to a contributor</em>. This looks much more like open source software than random quasi-governmental agencies pushing out collections of CSVs whenever they see fit. To be clear, this is not to be scoffed at, but it's an entirely different model of data distribution.</p>
<p>Open Elections is managed via GitHub, which makes sense as that's the most notable platform around for administering a project with this dynamic. It's also free to use, widely understood, and the product is mature and well executed. However, one shortcoming of using data in a format such as CSV is that the format itself is "loose", it is after all a file format. Databases are a file format in a sense, but differ hugely in they require a program to edit the format. In essence that program, the query engine, "gates" interactions with the format, which in turn enables much stronger "guarantees" to be presented. These guarantees are described by a schema, and enable the use of a query language. Dolt uses SQL. Datasets store in a database are much more work to build than collections of data files separated by commas, but when data arrives in a database the time to value is radically compressed. We published a subset of the Open Elections data as a <a href="https://www.dolthub.com/repositories/open-elections/voting-data">Dolt repository</a>, which does a nice job of illustrating the power of the distribution model.</p>
<p>This is the core value proposition of Dolt to the open data community, it offers mechanism for building high quality production grade resources, and delivering a uniquely seamless consumption experience to users of the data.</p>
<h2>Moving Forward</h2>
<p>Putting data in relational databases is hard. The analogy to open source software would be unit tests. While the existence of such a "forcing function" to quality makes the life of the contributor harder by raising the barrier to creating a successful contribution, it also greatly elevates the experience of the marginal user.</p>
<p>That forcing function, using a database with Git-like features for managing open data project, is essential to our vision for Dolt and DoltHub in the open data world. We see Dolt the database, and the collaboration features built on top of it for DoltHub, as having the potential to elevate the quality of the data assets that come out of open data projects such that businesses are more willing to rely on them, and therefore invest in the projects themselves.</p>
<h2>Conclusion</h2>
<p>To recap, we have used the analogy of open source code, and Git and GitHub, to articulate the goals of Dolt and DoltHub in many places, including this blog. While the analogy is a powerful communication tool, it does tend to gloss over the key differences between the dynamics at play in collaborative process design, open source software, and collaborative fact assembly, open data.</p>
<p>One reason that we believe open data projects have not taken off is lack of tools that make it easy for contributors to publish high quality data assets that clear the threshold of quality such that commercial enterprises see them as viable alternatives to proprietary and paid solutions. Dolt and DoltHub represent our attempt to facilitate collaboration that creates high quality data assets that can become reliable dependencies.</p></div></div>]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-07-30-anatomy-of-open-data-projects/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24014777</guid>
            <pubDate>Fri, 31 Jul 2020 22:06:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pebkac: I Spent 2 Days Fixing a Bug That Didn't Exist]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24014565">thread link</a>) | @figbert
<br/>
July 31, 2020 | https://figbert.com/posts/pebkac-txtodo/ | <a href="https://web.archive.org/web/*/https://figbert.com/posts/pebkac-txtodo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><a href="https://figbert.com/posts/pebkac-txtodo" rel="me">FIGBERT</a> <section> <p>Published by  on <time datetime="2020-07-28">7/28/2020</time></p> </section> <p>Post-<a href="https://developer.apple.com/wwdc20/" rel="noopener noreferrer" target="_blank">WWDC2020</a>, I decided to rewrite the backend of txtodo in SwiftUI using the new <a href="https://developer.apple.com/videos/play/wwdc2020/10037/" rel="noopener noreferrer" target="_blank">App and Scene structure</a>. Rebuilding the app from scratch may have not been the best choice, but during that process I have massively simplified the app's data structure, despaghettified some messy UI code, and spent two full days trying to solve a problem that didn't exist. This is the story of that last bit.</p>  <section><p>Post-<a href="https://developer.apple.com/wwdc20/" rel="noopener noreferrer" target="_blank">WWDC2020</a>, I decided to rewrite the backend of txtodo in SwiftUI using the new <a href="https://developer.apple.com/videos/play/wwdc2020/10037/" rel="noopener noreferrer" target="_blank">App and Scene structure</a>. Rebuilding the app from scratch may have not been the best choice, but during that process I have massively simplified the app's data structure, despaghettified some messy UI code, and spent two full days trying to solve a problem that didn't exist. This is the story of that last bit.</p> <h2 id="-structural-changes">## Structural Changes</h2> <p>The new app, so far, was mostly the same as the old version but without the <code>AppDelegate.swift</code> or <code>SceneDelegate.swift</code> files (using the new XCode 12 multiplatform app template). I also combined the Core Data <code>FloatingTask</code> and <code>DailyTask</code> entities into one <code>Task</code> entity. By this point, everything was running well enough so I started to migrate more code into the new codebase starting with the fetch request:</p> <pre><code>@FetchRequest(
    entity: Task.entity(),
    sortDescriptors: [
        NSSortDescriptor(keyPath: \Task.completed, ascending: true),
        NSSortDescriptor(keyPath: \Task.priority, ascending: false),
        NSSortDescriptor(keyPath: \Task.name, ascending: true)
    ]
) var tasks: FetchedResults&lt;Task&gt;</code></pre> <h2 id="-breaking-taskview">## Breaking TaskView</h2> <p>Tasks are displayed as <code>TaskView</code>s in a <code>ForEach</code> loop on the homescreen, which is simple enough. The <code>TaskView</code> struct, however, is relatively complicated. The purpose of <code>TaskView</code> is to represent and manipulate a single <code>Task</code>. In the previous version of the app (I'm going to call the original version 2.0 and the rewrite 3.0 from now on), this involved passing a number of attributes individually to be manipulated as the view's <code>@State</code>. When migrating the view, I reduced this to a single <code>@ObservedObject</code>. I also removed some of the text styling, which I planned to port over after I got the UI functional.</p> <p>I ran the app on my device, and this happened:</p> <p><video controls="" src="https://figbert.com/content/posts/pebkac-txtodo-rewrite/ascending-checkmarks-error.webm"><a href="https://figbert.com/content/posts/pebkac-txtodo-rewrite/ascending-checkmarks-error.webm">As you check off any task in the vertical stack, instead of checking off the task that you selected, tasks are checked off starting from the bottom and moving upwards in an ascending order.</a></video></p> <p>Well that was unexpected. Instead of checking off the tasks I selected, tasks were checked off starting from the bottom and ascending – obviously not the intended behavior! My first thought was that it was caused by the use of <code>@ObservedObject</code> to declare the view's task property –&nbsp;I haven't seen it used to manipulate a Core Data entity before, but it's worked fine so far in txtodo – so I rewrote the variables to match version 2.0.</p> <p><img alt="The variables declared before the UI of version 3.0 and version 2.0. Version 3.0 has two variables, task and config, but version 2.0 has nine: task, completed, name, priority, deleted, editingText, editingPriority, viewingNotes, and confirmingDelete." src="https://figbert.com/content/posts/pebkac-txtodo-rewrite/variable-comparison.webp"></p> <p>Still no change. It was getting pretty late at this point, but I decided to stick it out for just a bit longer. I rewrote the <code>TaskView</code> struct from scratch <em>two more times</em> to no avail. Something was wrong, but I had no idea where it was and there was no way I was going to figure it out at two in the morning by coding it again the exact same way.</p> <h2 id="-fantastic-bugs-and-where-to-find-them">## Fantastic Bugs and Where to Find Them</h2> <p>The next morning, I took a look at the code again. If the problem wasn't in <code>TaskView</code>, where was it? The only other thing in the UI was the button to make a new task, which looked something like this:</p> <pre><code>Button(action: {
    let newTask = Task(context: self.managedObjectContext)
    newTask.name = "test"
    newTask.priority = 3
    newTask.notes = [String]() as NSObject
    newTask.id = UUID()
    newTask.date = Date.init()
    newTask.daily = true
    do {
        try self.managedObjectContext.save()
    } catch {
        print(error.localizedDescription)
    }
}) {
    Text("Add")
}</code></pre> <p>Some of you may have figured it out by this point. At the time, I was still confused – this was the exact method I was using in my previous app, but with preset values – how could it be broken? I modified the generation slightly so I could tell the difference between tasks, and hopefully get to the bottom of the issue:</p> <pre><code>let newTask = Task(context: self.managedObjectContext)
newTask.name = String(UUID().uuidString.prefix(Int.random(in: 5..&lt;9)))
newTask.priority = Int16.random(in: 1..&lt;4)
newTask.notes = [String]() as NSObject
newTask.id = UUID()
newTask.date = Date.init()
newTask.daily = Bool.random()</code></pre> <p>I ran the app again and saw this:</p> <p><video controls="" src="https://figbert.com/content/posts/pebkac-txtodo-rewrite/randomized-test-values.webm"><a href="https://figbert.com/content/posts/pebkac-txtodo-rewrite/randomized-test-values.webm">The tasks were not being marked off in ascending order – rather, they were being moved to the bottom when completed, which I couldn't tell before because they were all identical.</a></video></p> <h2 id="-intentional-behavior">## Intentional Behavior</h2> <p>The tasks weren't being marked off in ascending order. They were being moved to the bottom automatically when marked as complete, which I couldn't see because a) all the tasks were identical and b) there were no animations to indicate that was happening. They were sorted by the <code>FetchRequest</code> with a <code>NSSortDescriptor</code>, to make sure that the unfinished tasks are the first thing the user sees. The "glitch" I had spent two days chasing down was entirely by design, and I had just forgotten.</p> <p>There were two main things I learned from this experience. First, it's incredibly important to be able to take breaks. The difference between spending two days trying to fix a non-existent glitch and realizing it's a feature you implemented could be as simple as a nap – it was for me. Secondly, your test and placeholder data is more significant than you might think: <a href="https://en.wikipedia.org/wiki/Garbage_in%2C_garbage_out" rel="noopener noreferrer" target="_blank">garbage in, garbage out</a> definitely applies here. If all your test data is the same, your tests are not good tests.</p> <h2 id="-wrap-up">## Wrap-up</h2> <p>To make the sorting more clear, I randomized the tasks' priority, name, and category (as seen above) and added an animation with <code>.animation(.easeIn(duration: 0.25))</code>. The current prototype looks something like this:</p> <p><video controls="" src="https://figbert.com/content/posts/pebkac-txtodo-rewrite/update-preview.webm"><a href="https://figbert.com/content/posts/pebkac-txtodo-rewrite/update-preview.webm">Animated, randomized tasks being checked off, deleted, and delayed.</a></video></p> <p>This has been a really fun blog post to write! A got a big laugh out of this bug chase, and I hope you've enjoyed reading it.</p> <p>Till next time, FIGBERT</p> </section></article></div>]]>
            </description>
            <link>https://figbert.com/posts/pebkac-txtodo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24014565</guid>
            <pubDate>Fri, 31 Jul 2020 21:46:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to play audio from Docker containers over the web]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24013764">thread link</a>) | @amasad
<br/>
July 31, 2020 | https://blog.repl.it/audio | <a href="https://web.archive.org/web/*/https://blog.repl.it/audio">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Audio brings games and projects to life! Web developers have it easy, they can publish their apps on the web and play audio using the browser API no problem. However, what about those of us that are command-line and graphics apps in other languages? Repl.it is a special place on the web where you can publish any app in any language, but so far it’s been missing audio capabilities because code executes in a container on the backend. This summer, for my internship I set out to solve this problem and make it possible to play audio in any repl in any language. In this post I’ll show you how to play audio in your repl and then I will chronicle the journey that got us here. </p>
<p><img src="https://repl.art/music-01.png" alt="music art"></p>
<h2 id="how-you-play-audio">How you play audio</h2>
<p>Before we get to the technical parts, let's talk about how you can use audio in your app or game.</p>
<p>As of this writing we support two libraries: Python and JavaScript. The Python library is built right in so you shouldn't need to install it. However, the JavaScript library you'll have to install and you can do that by simple importing (<code>@replit/audio</code>).</p>
<p>You can learn more on our <a href="https://docs.repl.it/repls/audio">docs for audio</a>.</p>
<p>Let’s take a look at a quick demo before I tell how it all works:</p>


<h2 id="how-it-works">How it works</h2>
<p>It started out with an idea, I wanted to add audio to Repl.it because I wanted to use it and many users were asking for it, so it seemed like a good project to take on.  To be honest, I thought it was going to be a lot easier than it turned out to be. I thought I’d just throw in a Pulseaudio stream over TCP, play it in the browser, and be done with it. I was wrong. But who would’ve thought that real-time audio streaming from an isolated Docker container using fake audio devices without the use of an always-on daemon would be difficult? I sure didn’t.</p>
<p>At first, my goal was to get something simple that worked. My first attempt was to use a combination of portaudio and loopback devices native to the host machine but isolated to each container but that didn’t end up working because the infrastructure was far too complicated to be maintainable and we’d have to install C libraries for each language so they could play audio. Moving on.</p>
<p>My second attempt was to prototype something so I could see how I could build the client. I wanted to make sure that I had at least one part of the setup correct.  For this attempt, I just searched for files named “PlayMeAudio.wav (or .aiff)” which would be decoded and sent to the client in a buffer when the client opened the repl. Although this worked, it was only a prototype and we didn’t ship it.</p>
<p>For my third attempt, I figured I’d decode the audio and relay that to the client via a pipe file. Although this worked, it was using a ridiculous amount of CPU in Python and just simply not fast enough. I had concerns it might be an issue in other languages as well.</p>
<p>For my final and fourth attempt, I made a request based system. Instead of decoding the audio files in userland and putting a strain on resources, I’d have the user language tell me which files to play, and we’d do the heavy lifting in Go, which is the language that we write the container service in, which we call PID1.  Although the code was a mess, it worked and ended up being the first version of audio we released to explorers, despite its many shortcomings.</p>
<p>Although it worked, this attempt had three issues: 
All files had to be at a sample rate of <code>44,000</code> hertz
All files had to have a bit depth of <code>32</code>
Only <code>.aiff</code> and <code>.wav</code> files were supported.</p>
<p>The reason for the first issue was that I couldn't find a good polyphase filter (for sample rate conversion) and I needed a C library to cross compile. This proved to be challenging, as we needed to static link it and it had libm as a dependency, which means we’d have to static link all of libc -- more on that later.  I ended up having to dynamically build it. Including its source wasn't an option because it had very large generated files, so I had to build it before we built PID1, more on this later on.</p>
<p>For the second issue, I really didn’t have an excuse other than not really understanding bit depth, but once I did I was able to quickly fix it.</p>
<p>For the third one, it wasn't so much that those files were the only ones supported - it was more so that we didn’t support <code>.mp3</code> files- for this, I ended up needing to use C again. I used minimp3 library and its Go bindings.</p>
<p>I also had plans to include <code>.opus</code> file support, so I was going to need another C library… Well to clarify, I needed both opus and opusfile. Opusfile requires opus, which requires OpenSSL, so I had to build OpenSSL the build opus and opusfile, without root. Well needless to say, this was starting to get a bit ridiculous to do more than once. I made a <a href="https://github.com/repl-it-discord/audio/">github repo</a> which would serve as a repo to house all the C libraries we needed along with the Go bindings, and I included a file I found from a source that would let me static link libm without all of libc. </p>
<p>After all of this, we have the dependencies resolved, and everything sounds good - except for one thing: Changes in audio take <code>~.74</code> -  <code>~1.48</code> seconds to take effect. Why? Well we were sending audio in chunks, instead of streaming. Every <code>~.74</code> seconds, we prepare audio and send exactly <code>32,768</code> samples (<code>2^15</code>, no particular reason for this magic number other than the buffer rarely runs out and the latency isn't unbearable) but this wasn't enough.  </p>
<p>The client was designed to append audio samples at the end of what it had scheduled, so what I did was send audio initially and then immediately send it again, so we’d give the client  <code>65,536</code> samples at the start, and send an additional <code>32,768</code> samples every <code>~.74</code> seconds. Where did I get <code>.74</code> seconds from? As we are playing the audio at <code>44,100</code> hertz, we play <code>44,100</code> samples per second - so <code>32,768/44,100</code>. </p>
<p>This setup was great for smooth audio, but I felt that the latency makes your repl experience feel rather shoddy. I mean, imagine you’re playing a game, you open the chest and go through a door. Once you go through the door, the sound from the chests plays because you as a user have that <code>.74</code> - <code>1.48</code> second buffer, which just makes using audio for games useless for anything other than background music.</p>
<p>So we had to rewrite this and unfortunately to solve the timing issue we had to complicate the solution. We made the server send overlapping buffers of samples and the client used a timing system along with a sample index the server sent to calculate and compensate for latency and try to make it “real-time” streaming.</p>
<p>Now I know this is hard to understand, in fact I was told it was also hard to code review, so I’ll do my best to illustrate it. </p>
<p>Normally, this is how our makeshift stream would look:</p>
<pre><code>Message 1: 1 2 3 4 5
Message 2:         5 6 7 8 9 
Message 3:                 9 10 11 12 13
...</code></pre><p>This keeps us from audio cutting out due to (network) latency (to an extent), allowing us for smaller buffer sizes without as much (audio) latency</p>
<p>That alone isn't very special, what's really the star of the show is for the server to be able to send:</p>
<pre><code>Message 1: 1 2 3 4 5  
Message 2:   2 3 4 5 6
Message 3:           6 7 8 9 10</code></pre><p>The client is where the difficult processing for this takes place, when we receive new samples we immediately stop playing and start playing those samples… well… mostly. </p>
<p>You see, there's still the one thing that we can’t control. Networking.  Maybe there's a <code>.1</code> second delay for one of the messages, well now look - we’re playing audio we already played!</p>
<p>So now the client has to calculate LATENCY too, which is even MORE difficult. At this point, we’re on multiple devices, and we need less than a <code>1/44,100</code> second difference in time in order to figure this out! That seemed too hard. Instead, what I did was give each message in the protocol the sample index of the first sample, i.e. the first message would have sample index <code>0</code>.  The client then determines how many samples the player has played in total and if that's greater than the sample index it will compensate for that by skipping samples. </p>
<p>Now too get back to the request system I mentioned earlier -- how does one use that? As I mentioned, there’s two libraries above for Python and JavaScript, however this should work for any language, and you’re free to implement your own libraries.</p>
<h2 id="how-do-libraries-work">How do libraries work?</h2>
<p>As mentioned above, users can determine what is played via requests to a named pipe which PID1 reads.  I opted for a simple approach for encoding - json. While making libraries is fun and all, I can’t update libraries for many languages every time I change the requests, so I figured I’d make the request system pretty simple.</p>
<p>The user’s script must only write json data to <code>/tmp/audio</code> (a named pipe) and the go script will then parse the data and fulfill the request.  However, this might error - for example the file isn't found or has invalid encoding. Since we’re sending requests through a named pipe, we can't get errors very easily.
This means that the library the client uses must determine when there’s an issue with a source being created - the setup I made for the libraries which I used would wait up to a set amount of time then if the source wasn’t created in time it times out - while this isn’t always perfect, it's better than nothing.</p>
<p>A typical request to play a tone might look like this:</p>
<pre><code>{
  <span>"Paused"</span>: <span>false</span>,
  <span>"Name"</span>: <span>"My tone"</span>,
  <span>"Type"</span>: <span>"tone"</span>,
  <span>"Volume"</span>: <span>1</span>,
  <span>"DoesLoop"</span>: <span>false</span>,
  <span>"LoopCount"</span>: <span>0</span>,
  <span>"Args"</span>: {
    <span>"Pitch"</span>: <span>400</span>,
    <span>"Seconds"</span>: <span>5</span>,
    <span>"Type"</span>: <span>1</span>,
    <span>"Path"</span>: <span>""</span>
  }
}</code></pre>
<p>A quick explanation of the above fields: </p>
<ul>
<li><code>Paused</code> - Whether the source is paused or not - this can only be set when updating the source.</li>
<li><code>Name</code> - the name of the source - this can be used to identify the source when it's being created - if it's not set the name will be set by pid1.</li>
<li><code>Type</code> - the type of the source, supported types when I wrote this are:<ul>
<li><code>wav</code> - A <code>.wav</code> file</li>
<li><code>aiff</code> - A <code>.aiff</code> file </li>
<li><code>mp3</code> - A <code>.mp3</code> file</li>
<li><code>tone</code> - A generated tone.</li>
</ul>
</li>
<li><code>Volume</code> - The volume of the source as a floating point number - <code>1</code> would be <code>100</code>%</li>
<li><code>DoesLoop</code> - Whether the source should loop or not …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.repl.it/audio">https://blog.repl.it/audio</a></em></p>]]>
            </description>
            <link>https://blog.repl.it/audio</link>
            <guid isPermaLink="false">hacker-news-small-sites-24013764</guid>
            <pubDate>Fri, 31 Jul 2020 20:42:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Automate Tasks Estimation in Jira]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24013045">thread link</a>) | @Gen1us
<br/>
July 31, 2020 | https://blog.maddevs.io/how-to-automate-tasks-estimation-in-jira-720bacf6d75d?source=friends_link&sk=f57cc9a52560108f1a045e4a60e63281 | <a href="https://web.archive.org/web/*/https://blog.maddevs.io/how-to-automate-tasks-estimation-in-jira-720bacf6d75d?source=friends_link&sk=f57cc9a52560108f1a045e4a60e63281">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><h2 id="46e5">Project Management</h2><div><div><div><div><p><a href="https://blog.maddevs.io/@earthur_?source=post_page-----720bacf6d75d----------------------" rel="noopener"><img alt="Arthur Elizavetenkov" src="https://miro.medium.com/fit/c/96/96/2*4kZIGfRKTvxdq8xsJazHPw.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Mad Devs Time Tracking with Jira Software." src="https://miro.medium.com/max/8000/1*9EXM3IcfihDTOBG2284wKw.jpeg" width="4000" height="2172" srcset="https://miro.medium.com/max/552/1*9EXM3IcfihDTOBG2284wKw.jpeg 276w, https://miro.medium.com/max/1104/1*9EXM3IcfihDTOBG2284wKw.jpeg 552w, https://miro.medium.com/max/1280/1*9EXM3IcfihDTOBG2284wKw.jpeg 640w, https://miro.medium.com/max/1400/1*9EXM3IcfihDTOBG2284wKw.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*9EXM3IcfihDTOBG2284wKw.jpeg?q=20"></p></div></div></div></figure><h2 id="473c"><strong>Planning means more than just “staying organized”</strong></h2><p id="f337">IT project management is hard to imagine without planning. Planning orchestrates the work of different project departments (<a href="https://maddevs.io/services?utm_source=blog&amp;utm_medium=task-estimation" target="_blank" rel="noopener">software development</a>, marketing, sales, etc.). Having a plan enables business decision-makers to stay focused on where they go and see the vector of product development clearly. Planning cannot work without estimating the time of execution for each of your tasks. Developing a habit of splitting your tasks into subtasks while defining the estimated time of execution for all of them is not easy. This sin can be common not only with Junior developers but more experienced professionals can also avoid estimates.</p><p id="2cc2">In this article, I’ll explain how we encourage our developers to estimate tasks using simple &amp; smart Jira configuration.</p><h2 id="5b9a"><strong>Where the problem originates from?</strong></h2><p id="e435">To quickly start a new project in JIRA, our PMs often use the default settings for workflow, fields, screens, etc. These settings are a good fit for a broad variety of projects, which is excellent! However, if you have a more specific task to complete, you’ll need to go deeper into configurations, like in our example. You will have to learn something new, too.</p><figure><div><div><div><p><img alt="The Default Workflow and the Advanced Workflow Configured in Jira for One of Mad Devs Projects." src="https://miro.medium.com/max/3000/1*xZ3XrvuYRQ0muY--dmqAxw.png" width="1500" height="844" srcset="https://miro.medium.com/max/552/1*xZ3XrvuYRQ0muY--dmqAxw.png 276w, https://miro.medium.com/max/1104/1*xZ3XrvuYRQ0muY--dmqAxw.png 552w, https://miro.medium.com/max/1280/1*xZ3XrvuYRQ0muY--dmqAxw.png 640w, https://miro.medium.com/max/1400/1*xZ3XrvuYRQ0muY--dmqAxw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*xZ3XrvuYRQ0muY--dmqAxw.png?q=20"></p></div></div></div><figcaption>The default workflow and the advanced workflow configured for one of our projects.</figcaption></figure><p id="0015">At the sprint planning stage, our PMs ask developers to fracture and estimate their tasks. This enables us not to overload the sprint and stay committed to what we can deliver on time. However, at times a developer may drill into an unestimated task which may let the entire team down. This person may be unaware of the full scope of work that he or she needs to do. This is the reason behind such actions.</p><blockquote><p id="ada6">The developer’s estimate is their personal commitment to complete the task on time.</p></blockquote><p id="38d3">The manager can surely control estimates manually by checking out every ticket, but this is not what we really want. We need to save time. A project manager can automate their routine tasks by picking the existing tool or even creating one from scratch. This principle is driving the entire IT industry forward.</p><p id="2a30">Now let’s have a look at the simple and elegant solution to the problem with the tasks estimating.</p><h2 id="728e"><strong>JIRA can do more than you think</strong></h2><p id="b59e">To solve the problem, I needed to make developers fill the <strong>Original Estimate</strong> field before they start working on a task (this is important). I’ve been working with JIRA for over a year now. Thanks to the <a href="https://www.atlassian.com/university" target="_blank" rel="noopener">Atlassian University</a> courses I took, I came up with a solution fast. I assigned a task in JIRA to myself and started as follows:</p><p id="11c7"><strong>Prevent developers from moving an issue to the <em>In Progress</em> status until the issue has Original Estimate field filled</strong></p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3998/1*-d1B6G45hH3hYYwHlqVAIQ.png" width="1999" height="1137" srcset="https://miro.medium.com/max/552/1*-d1B6G45hH3hYYwHlqVAIQ.png 276w, https://miro.medium.com/max/1104/1*-d1B6G45hH3hYYwHlqVAIQ.png 552w, https://miro.medium.com/max/1280/1*-d1B6G45hH3hYYwHlqVAIQ.png 640w, https://miro.medium.com/max/1400/1*-d1B6G45hH3hYYwHlqVAIQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*-d1B6G45hH3hYYwHlqVAIQ.png?q=20"></p></div></div></div></figure><p id="339c">By default, JIRA allows you to start working on a task freely, without providing an estimate. So let’s fix this!</p><p id="438c"><strong>Step one. </strong>Go to the workflow of your project and find the <em>transition</em> from <strong>To Do</strong> to the <strong>In Progress</strong> status.</p><figure><div><div><div><p><img alt="The transition from To Do to the In Progress Status in Jira Software." src="https://miro.medium.com/max/3388/1*osq5d4VeVCsXfAwhn5Y8_g.png" width="1694" height="930" srcset="https://miro.medium.com/max/552/1*osq5d4VeVCsXfAwhn5Y8_g.png 276w, https://miro.medium.com/max/1104/1*osq5d4VeVCsXfAwhn5Y8_g.png 552w, https://miro.medium.com/max/1280/1*osq5d4VeVCsXfAwhn5Y8_g.png 640w, https://miro.medium.com/max/1400/1*osq5d4VeVCsXfAwhn5Y8_g.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*osq5d4VeVCsXfAwhn5Y8_g.png?q=20"></p></div></div></div><figcaption>The transition from <strong>To Do</strong> to the <strong>In Progress</strong> status in Jira Software</figcaption></figure><p id="bffc"><strong>Step two. </strong>Add validation to the <strong>Original Estimate</strong> in the <strong>Field Required Validator</strong>. Add the error text explaining why a developer cannot proceed with the task. Apply the changes to your workflow.</p><figure><div><div><div><p><img alt="How to Add Validation to the Original Estimate in the Field Required Validator in Jira Software." src="https://miro.medium.com/max/1600/1*XdGepnVqCapzKH4p8yfqWA.gif" width="800" height="460" srcset="https://miro.medium.com/max/552/1*XdGepnVqCapzKH4p8yfqWA.gif 276w, https://miro.medium.com/max/1104/1*XdGepnVqCapzKH4p8yfqWA.gif 552w, https://miro.medium.com/max/1280/1*XdGepnVqCapzKH4p8yfqWA.gif 640w, https://miro.medium.com/max/1400/1*XdGepnVqCapzKH4p8yfqWA.gif 700w" sizes="700px" data-old-src="https://miro.medium.com/freeze/max/60/1*XdGepnVqCapzKH4p8yfqWA.gif?q=20"></p></div></div></div><figcaption>Add Validation <strong>Original Estimate</strong> in the <strong>Field Required Validator</strong></figcaption></figure><p id="9e5a"><strong>Step Three. </strong>Testing. Let’s try to move the task to the <strong>In Progress</strong> status with and without an estimate.</p><figure><div><div><div><p><img alt="Moving the Task to the In Progress Status With and Without an Estimate in Jira Software." src="https://miro.medium.com/max/1600/1*KHsybQD2CJHsO0xHyT5ZMg.gif" width="800" height="472" srcset="https://miro.medium.com/max/552/1*KHsybQD2CJHsO0xHyT5ZMg.gif 276w, https://miro.medium.com/max/1104/1*KHsybQD2CJHsO0xHyT5ZMg.gif 552w, https://miro.medium.com/max/1280/1*KHsybQD2CJHsO0xHyT5ZMg.gif 640w, https://miro.medium.com/max/1400/1*KHsybQD2CJHsO0xHyT5ZMg.gif 700w" sizes="700px" data-old-src="https://miro.medium.com/freeze/max/60/1*KHsybQD2CJHsO0xHyT5ZMg.gif?q=20"></p></div></div></div><figcaption>Moving the task to the <strong>In Progress</strong> status with and without an estimate</figcaption></figure><p id="927f">Perfect! Now no one on your team is able to start working on a task that hasn’t been estimated. (Bear in mind that this configuration applies to<em> all</em> tasks going through the transition <strong>To Do</strong><em> →</em><strong><em> </em>In Progress</strong>. If you need to set up the estimation required for certain <em>issuetypes</em>, you will need to set additional steps in <strong>Conditions</strong>).</p><h2 id="8361"><strong>Conclusion</strong></h2><p id="9989">This simple &amp; smart configuration will help you as a manager to always see how long all tasks take to be completed. Such a condition makes your developers think about the number of tasks taken into work. The estimation process is automated with zero micromanagement!</p><p id="666c">Do you want to know about Project Management more?</p></div></div></section></div>]]>
            </description>
            <link>https://blog.maddevs.io/how-to-automate-tasks-estimation-in-jira-720bacf6d75d?source=friends_link&amp;sk=f57cc9a52560108f1a045e4a60e63281</link>
            <guid isPermaLink="false">hacker-news-small-sites-24013045</guid>
            <pubDate>Fri, 31 Jul 2020 19:43:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: We're a bootstrapped B2B SaaS company that made and shipped “hardware”]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24012790">thread link</a>) | @cowllin
<br/>
July 31, 2020 | https://www.watercoolertrivia.com/blog/trophies | <a href="https://web.archive.org/web/*/https://www.watercoolertrivia.com/blog/trophies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>‍<strong>Here’s the one(ish)-sentence summary: </strong>we took a goofy idea with some crummy designs made in Google Slides and ended up contract manufacturing custom bobblehead trophies. We send these trophies to every team that subscribes to Water Cooler Trivia. <br></p><h2><strong>How it all began</strong><br></h2><p>In January 2019, our team met to talk goals for the upcoming year. We had laid the foundations for a product that brings work teams closer together and builds office culture, and we wanted to keep improving the product and bringing it to more teams.<br></p><p>One of our goals: <strong>Delight users through new customer-centric innovations. </strong>We’re a platform for customizable weekly trivia quizzes. The quizzes and results are sent via email or Slack. Naturally, most of our “customer-centric innovations” are software based, like redesigning our <a href="https://app.watercoolertrivia.com/demo/results">quiz results</a> or building a<a href="https://www.watercoolertrivia.com/blog/features-slack-app"> Slack app</a>.<br></p><p>However, with only a single-person engineering department, we couldn’t bite off much more than one big feature each quarter.&nbsp;So we started thinking about a customer-centric feature that didn’t require a single line of code: <strong>a Water Cooler Trivia bobblehead trophy.&nbsp;</strong></p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f23668c73efdd4882767e82_IMG_0918.jpg" alt=""></p><figcaption>Yes, those are the trophies posed in my kitchen.</figcaption></figure><h2><strong>From idea to design</strong></h2><p>Back in 2019, there was a little old institution known as the office. This is where coworkers would spend much of their waking week, working in non-socially-distant proximity.&nbsp;<br></p><p>This is also where teams would discuss the weekly Water Cooler Trivia results. The winner is celebrated in the results email each week, but that fleeting sense of accomplishment, well, fleets.&nbsp;<br></p><p>We wanted to create a new way to celebrate the winner. Stealing the idea of a roaming championship totem like the <a href="https://www.google.com/search?q=stanley+cup+filled+with+skittles&amp;rlz=1C5CHFA_enUS879US879&amp;sxsrf=ALeKk01N4_N6R1iLOS5J_sNWKjo3ynVPPA:1596144974172&amp;source=lnms&amp;tbm=isch&amp;sa=X&amp;ved=2ahUKEwjTy8ex9_XqAhXKQc0KHdcjBx0Q_AUoAXoECA4QAw&amp;biw=1440&amp;bih=749">Stanley Cup</a> or a WWE belt, we wanted to send a trophy to each team. <strong>The winner would proudly display the trophy on their desk for the duration of their reign</strong> -- typically one week but longer if they had back-to-back victories.&nbsp;<br></p><p>Rather than imitation-chrome over a faceless figurine like the soccer participation trophies of our past, we wanted <strong>a trophy that reflected the quirky, fun tone of Water Cooler Trivia</strong>. After all, the goal here is team-building fun, so the trophy might as well be fun.&nbsp;</p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f23602980e22bd77a756d05_Group%2050%20(2).png" alt=""></p><figcaption>There's enough of these faux-metallic-finished trophies in the world.</figcaption></figure><p>What’s more fun than a trophy? A bobblehead. What’s more fun than a faceless gold figurine? Our “blue brain” mascot.</p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f23609fc91bd60af1a7d087_collage%201.png" alt=""></p><figcaption>We love the brains.</figcaption></figure><p>I had a clear vision in my head of what these trophies would look like, but no design skills or manufacturing experience. <strong>My design toolkit? Google Slides.</strong> It’s free, super easy to share, and it has a crop button.<br></p><p>I searched for a few inspiration images: <strong>blue brains</strong>, <strong>water cooler renderings</strong>, and <strong>brain trophies</strong>. The results were pretty much exactly what you would expect.&nbsp;<br></p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f3f49ec631774ca9422_hl75CU-kzTBo4_7r8jgUb2N8qc0Qw5isQu2pzmqlcHxo3zsOE7ge9pZJZ8GPuOOSho4quQe03VPjzZU8NMiNZxjrByIc5GMmJqLP99lFup3xD7WJ1pyreymPrxgyUYH4isDsRLbO.png" alt=""></p><figcaption>Design building blocks via Google Images.</figcaption></figure><p>Next up, I played with a few iterations of what this trophy might look like by overlaying text blocks and smashing two images together. <strong>These looked bad.&nbsp;</strong><br></p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f3fa79a46074dcddffa_Gu4Z_2uchCr5yiSgMknGu-nYorXoS3MiytTGaoHUpEoE1cnIwZhNa7fKO_beOtjIa6kVTBx4Fllbdp_SVW9YNRVpkx7HY9ve5UmbZzDd7qqbae7FjngA2yYyXaMGakAalD5ALlLA.png" alt=""></p><figcaption>First attempts at a trophy design.</figcaption></figure><p>So I iterated a few more times. I noodled with the concept of putting the brain in a water cooler (basically a 3D version of our boringly 2D logo).&nbsp;I toggled the transparency and saturation, hoping that I would magically stumble upon a not-totally-horrible-looking combination. <br></p><p><strong>It turned out fine.</strong><br></p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f245e1f6d93f82c6667f72d_Screen%20Shot%202020-07-31%20at%2012.08.20%20PM.png" alt=""></p><figcaption>My final Google Slides design of the trophy.</figcaption></figure><h2><strong>From design to manufacturing partner</strong></h2><p>Quick aside: a friend of a friend owns a business that sells Bitcoin socks. You read that right: socks, not stocks. Black foot-and-lower-leg coverings dotted with yellow BTC logos. I was amazed that the design, manufacturing, and shipping were all through <a href="https://en.wikipedia.org/wiki/Alibaba">Alibaba</a>, the Chinese conglomerate often compared to Amazon. </p><p>Critically, he clued me in to the fact that Alibaba has a super-accessible RFP (request for proposal) feature.</p><p><strong>You enter a description, an image, a quantity, and a price point. Within hours you are flooded with offers from manufacturers. </strong>This was extremely convenient. <br></p><p><strong>Five vendors reached out within 48 hours</strong> in various mixes of Chinese and English. I wasn’t quite sure how to decide, so I went with the vendor that was most responsive to my questions and had the most robust English.</p><p>Our contract manufacturer? <a href="https://xfdbobble.en.alibaba.com/">Xiamen Xinfade Trade Co</a> with Jonas from their team as our touchpoint throughout the process.<br></p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f245fb1dd15c16aa68b3ffc_Screen%20Shot%202020-07-31%20at%2012.15.02%20PM.png" alt=""></p><figcaption>Dog Custom bobblehead was the closest category.</figcaption></figure><h2><strong>From manufacturing partner to bobblehead trophies</strong></h2><p>The email back-and-forth with Jonas began in earnest when I sent my “designs” (Google Slides screenshots) in March 2019.<br></p><p>We discussed project timing, and in less than two weeks he sent pictures of the mold.</p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f4041f47b7113ec4f25_HT8B54ZCk_wm8pWpAzzq5DaBl9ViC-JS4Y2cCE9xGvXP1pPbvsDqLgjaZe4QREMBi2A_OxtqCVx9F4uLdG-HUe0MoA_CQapNoGtoTHAWrzMKJCatr-u1Y2SUpAM7BDLOa9Dp_XGr.gif" alt=""></p><figcaption>The mold of the trophy from different angles.</figcaption></figure><p>At this point, we'd agreed to 300 trophies for $3.50 each, but we hadn't signed a contract or paid a single cent. So when Jonas sent through the mold images I was floored: <strong>this was actually happening.</strong><br></p><p>The molds looked good enough that we locked in the deal with a signed and paid invoice.&nbsp;<br></p><p>By April 11, Jonas sent me painted versions of the molds so we could get a sense of the colors. He asked about box details, colors, stickers, size, and more fine tuning.</p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f3f680645a36ea7f2ec_P7_uon-XtgJW6KHv4xzCgkMbcCvyQNsq4XhoDOVf-xOd5E-LQ3V_B1-wLxrfB-mGO8lNkupe5fl1CFZr57yhkRLx82KDDNDWlJdD6jW0vkF5Fieny-8CSTC9sP665J_gUOYBfAdP.png" alt=""></p><figcaption>Painted versions of the mold. Still just a sticker version of the logo.</figcaption></figure><p>We asked for a lighter resin to make the cooler more transparent. Jonas made it happen. By mid-May, Jonas sent the picture of hundreds of bobbleheads coming off the assembly line. <strong>We were ecstatic.</strong></p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f41e63c203678cfd7f0_lhd5l-_H4iikMusOv844lY3tWLENxFn5CyPE6mh8nrARa2XutbHet_-H356eKmkpMx9dd-lOQ9dz75iKCIalsrH4LX0QZkHak0WPmJqF9_BoYL95F6R_rHNFuFw8TJ9Kiqi5i9SQ.png" alt=""></p><figcaption>Fresh off the assembly line.</figcaption></figure><h2><strong>From China to Brooklyn</strong></h2><p>Turns out shipping across an ocean with a small quantity of low-cost items is… expensive.<br></p><p>Jonas asked who our freight-forwarder was. We had no idea what he was talking about. He asked about our customs and import licenses. We were still clueless.&nbsp;<br></p><p><strong>We solved those boring logistics, but the cost was quickly escalating.</strong></p><ul role="list"><li>That initial quote of $3.50 per bobblehead trophy had risen to $4.00</li><li>There was $400 in setup fees</li><li>Another $150 surcharge because of our small order size</li><li>Freight was almost $750 to get them sent halfway around the world&nbsp;<br></li></ul><p><strong>Total price: $2,492 ($8.31 per trophy) </strong>to turn my crummy design into boxes and boxes of bobbleheads.<br></p><p>One small issue: that price only got the trophies to us. We would still need to mail out each one individually to each customer, adding another $3-6 per trophy.</p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f24616d27b61804384eaefd_Group%2059.png" alt=""></p><figcaption>Money fleeing our pockets.</figcaption></figure><h2><strong>Tearing them down to build them up again</strong></h2><p>After an early July vacation, I returned to my fourth-floor walkup Brooklyn apartment with quite the surprise: 12 large, heavy boxes stacked neatly in the atrium. I didn't know how long the boxes had been there (I’d been out of town for over a week), but I was sure it'd confused my neighbors.<br></p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f40a79a463e49cddffb_jYbXUPrTvTKK3a8IJHNei2HidUvHJYD_Z60f33c0gfdzwNaSWQ7sg8yyO1Y0pXsjpVbSzZDzJHZh4nir8Kx2NtFKH8wGiS8e9bo70otXHOihTjPcrxdxQyQPk1rpzglmSXwLCQFj.jpeg" alt=""></p><figcaption>Much of the atrium was taken up with trivia trophy boxes.</figcaption></figure><p>With the help of two roommates, we carried the boxes up to our apartment. <strong>We unboxed the trophies, excited to see the outcome of the quixotic quest.</strong> They looked great! The brain was on a spring-loaded cylinder so it did indeed bobble, the transparency on the cooler allowed for easy observation of the richly-colored blue brain. It worked out better than I could have expected.&nbsp;</p><p>Except... </p><p>When I bobbled the bobblehead for a second time, the cooler separated from its circular base, sliding right off, and thusly <strong>decapitating the trophy.&nbsp;</strong></p><p>The glue that attached the open cooler cylinder to the circular cardboard base was shoddy. As bobbleheads, we fully expected them to receive regular rattling.</p><p>I hoped I’d pulled a bad apple out of the barrel, but <strong>quality control checks on the next five trophies confirmed the problem was widespread.</strong> It was simply a weak point in the construction.&nbsp;</p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f3f0544bd5651c0cbd0_C25G_MkoXsmSSgJagtb83H09Y1nECSOFa20tDsF49FGMSo4PgeGyRKj9TCt3A5W5jtooAoiRwpUK2369TgnCLTH_qo9fQpX2GxbZhoVjxC5eTFo0upGfua3XHAYPNUWsoc-29wAI.png" alt=""></p><figcaption>Actually there were two weak points.</figcaption></figure><p><strong>The glue did not hold the resin and the cardboard together nearly enough for a trophy meant to bobble.</strong> After confirming the worst, we acknowledged that it was going to take serious elbow grease and human power to get the trophies in customer-ready shape.<br></p><p>Before undertaking the crafty project, we fixed a handful and took them on a quick photoshoot around New York City.<br></p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f423227a4684e5a1aa4_mAPl9kF4d7Y-7A8c00uxYUVjSlReiPVk0u-bPp1KLFY7XHcnUlD0EWfq-KYey7NfXRQYFkaJQQAbCXWTMkaFCy34NBTVmuNTe-nHiYnB5ijfyPIcN3kV3XBC7OfITeuT7RPMsEIH.png" alt=""></p><figcaption>We call it the "poor man's photoshoot."</figcaption></figure><p>The process of precisely breaking 300 bobbleheads and re-gluing them in two different places with Gorilla Glue is not a quick one. Especially when you add in the time of unboxing and re-boxing each individual trophy. My partner, my roommate, even my sister visiting New York all generously chipped in their time. <strong>In total, we spent about 30 hours fixing up the trophies.</strong><br></p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f40be075e716de512c6_szmo0tDw4evHQO38Am7oYvL3LxscMU9jQJYxsR3iH0PSxUxdYFfxnqOB5OSRUfaUmG6jU3W2vjAYdFoV8VW6J6mHZd99b9nwEVcT0vduh7slhZWiSMcCImIFMWlr41Hn5WJ6SDab.jpeg" alt=""></p></figure><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f413227a489155a1aa3_4UNLDXSbdfeSvaO1Mn39bH51Stoov0wdxX-Ct3cyE2klQfOo_4ZsGFy6fwrEE_Fwa-F1JtRSdFT_igsbtnI5DJMQDiaALP418hApTCDbAO0Lz5Lt0MCsZyyQCgEax98ASz-o0AXJ.jpeg" alt=""></p></figure><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f40e762e79eb6d96dfe_iv7bHadxbLn_BnrWBepDqLbbEorOsEjSgBH4FPX2c1hmxpq4WtjK5GfKQ1gbcbnr4Eion6apmH4heWraFTJBqSFd9-O2xmT4jTC_tSE-jphn_I0KBG1_amel7hP9hoUUnuf_aMP8.jpeg" alt=""></p><figcaption>The real MVP.</figcaption></figure><p>Not exactly scintillating work, but we didn’t want to make it to the finish line only to send our customers a knowingly-busted object.</p><h2><strong>Lessons learned?</strong></h2><p><strong>Customers seem to genuinely like and appreciate the trophies.</strong> It gives our whimsical, fun-loving brand a more physical presence for hundreds of teams around the world.</p><figure><p><img src="https://uploads-ssl.webflow.com/5eb9c1e4771ba53de5f5dbee/5f235f41d45976e1588c8c02_P37-ZeibsPwed0EDZpx_tgN41PuVZmSTffCrehHhU1u_eDKlYKaYjpH5xaXYasWMCypFZO5lJ4D7EnD8q5VbzEXFOeMMMAgHbr0r_MamQY3_Hoc3oFTYfsb44qYMw9BJuT_jn_cp.png" alt=""></p><figcaption>Happy customers after a weekly trivia win.</figcaption></figure><p>We’re a pragmatic team here at Water Cooler Trivia HQ. We don’t think these trophies are going to make-or-break our success as a team, product, and company. But it was one hell of a fun project. And we’re going to keep producing more to send to all of our customers (the first batch is nearly gone!)<br></p><p><strong>Paul Graham would be proud, we did something that </strong><a href="http://paulgraham.com/ds.html"><strong>doesn't scale</strong></a><strong>. </strong>We shipped “hardware” to each customer.<br></p><p>Plus, I learned. I learned that obscenely rudimentary design skills plus the power of Alibaba’s RFP system can get anything built. It was a cool learning that I’ve since re-applied exactly zero times (...yet).<br></p><p>Want one of these limited-edition Water Cooler Trivia bobblehead trophies? We’ll send you one for free when your office <a href="http://app.watercoolertrivia.com/signup">signs up</a> for a Water Cooler Trivia subscription :)<br></p></div></div>]]>
            </description>
            <link>https://www.watercoolertrivia.com/blog/trophies</link>
            <guid isPermaLink="false">hacker-news-small-sites-24012790</guid>
            <pubDate>Fri, 31 Jul 2020 19:22:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Glucosamine Supplementation Reduces All-Cause Mortality: Study]]>
            </title>
            <description>
<![CDATA[
Score 254 | Comments 134 (<a href="https://news.ycombinator.com/item?id=24012587">thread link</a>) | @mrfusion
<br/>
July 31, 2020 | https://www.lifespan.io/news/glucosamine-supplementation-reduces-all-cause-mortality/ | <a href="https://web.archive.org/web/*/https://www.lifespan.io/news/glucosamine-supplementation-reduces-all-cause-mortality/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																
								
								
<p>It is one of the most commonly used supplements frequently taken to address joint pain, but there might be more to this dietary supplement than first meets the eye.</p>
<p>Glucosamine was originally discovered during the 1960s in Italy by pharmacologist Professor Luigi Rovati. Glucosamine is one of the most commonly used dietary supplements and is typically taken to help with the joint pain and inflammation associated with aging.</p>
<p>Glucosamine is a polysaccharide that is found naturally in cartilaginous joint tissues, bones, skin, ligaments, and nails, and it is involved in protein and lipid synthesis. In the context of joints, synovial fluid contains glucosamine and occupies the space between joints, helping to reduce the friction of joint surfaces.</p>
<p>Despite it being frequently taken for arthritis, the evidence for its effectiveness is limited, although, there is data for it being anti-inflammatory, as suggested by the results of a randomized clinical trial in 2015 [1].</p>
<p>However, glucosamine supplementation seems to correlate with lower all-cause mortality and other mortality risks, such as cardiovascular disease (CVD), cancer, respiratory and digestive diseases. A recent <a href="https://ard.bmj.com/content/79/6/829" target="_blank" rel="noopener noreferrer">analysis</a> published in the journal BMJ showed that glucosamine supplementation conveys around a 15% reduction of all-cause mortality [2]. This is a considerable amount when compared to other lifestyle interventions as well as other supplements. The data gathered is from a large number of people, and the trend of reduced mortality is unmistakable.</p>


<blockquote>
<p>This population-based prospective cohort study included 495 077 women and men (mean (SD) age, 56.6 (8.1) years) from the UK Biobank study. Participants were recruited from 2006 to 2010 and were followed up through 2018. We evaluated all-cause mortality and mortality due to cardiovascular disease (CVD), cancer, respiratory and digestive disease. HRs and 95% CIs for all-cause and cause-specific mortality were calculated using Cox proportional hazards models with adjustment for potential confounding variables.</p>
<p>Regular glucosamine supplementation was associated with lower mortality due to all causes, cancer, CVD, respiratory and digestive diseases.</p>
</blockquote>
<p><strong>Conclusion</strong></p>
<p>The exact reasons for this correlation with the reduction of various mortality risks is as yet unknown, but given the large patient group in this and in other analyses along with the popularity of this supplement, it is impossible to deny that there is a definite trend here.</p>
<p>We are not suggesting that you take this supplement, but given that it is cheap and freely available with an excellent safety profile, it may be worth your consideration and further research to evaluate if you wish to take it or not.</p>
			
		
<p><strong>Literature</strong></p>
<p>[1] Navarro, S. L., White, E., Kantor, E. D., Zhang, Y., Rho, J., Song, X., … &amp; Lampe, J. W. (2015). Randomized trial of glucosamine and chondroitin supplementation on inflammation and oxidative stress biomarkers and plasma proteomics profiles in healthy humans. PloS one, 10(2), e0117534.</p>
<p>[2] Li, Z. H., Gao, X., Chung, V. C., Zhong, W. F., Fu, Q., Lv, Y. B., … &amp; Li, F. R. (2020). Associations of regular glucosamine use with all-cause and cause-specific mortality: a large prospective cohort study. Annals of the Rheumatic Diseases, 79(6), 829-836.</p>
																	
															</div></div>]]>
            </description>
            <link>https://www.lifespan.io/news/glucosamine-supplementation-reduces-all-cause-mortality/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24012587</guid>
            <pubDate>Fri, 31 Jul 2020 19:07:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Slack Is Fumbling Developers]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24012496">thread link</a>) | @gregdoesit
<br/>
July 31, 2020 | https://www.swyx.io/writing/slack-fumble/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/writing/slack-fumble/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="sapper"> <div>  <main> <div>  <h2 id="postSubtitle">and the Rise of Developer Discords</h2> <p>A few days ago <a href="https://twitter.com/swyx/status/1260929975454056449">I had a sudden realization</a>: I hadn't been active in Slack in the 2 months since <a href="https://www.swyx.io/writing/farewell-netlify/">I left Netlify</a>. Those of you who live and work in Slack know how big this is - I personally went from opening Slack practically <em>every day</em> from 2015 - 2020, to zero meaningful usage whatsoever.</p> <p>In its place, I am now active in a ton of Developer Discord channels. I feel like this is a <em>meaningful</em> shift this year, and based on responses, <a href="https://twitter.com/jkup/status/1260936175172419590?s=20">I'm</a> <a href="https://twitter.com/1Marc/status/1261960701666623488?s=20">not</a> <a href="https://twitter.com/stolinski/status/1260943494635352066?s=20">alone</a>.</p> <section> <h2 id="but-they-didnt-want-developers">But They Didn't Want Developers?</h2> <p>The obvious proximate cause of course, is that I am professionally and personally highly attuned to developer communities, and Slack has actively pushed away developer communities. <a href="https://twitter.com/harry_hedger/status/1261967137989513216?s=20">Quote Harry Hedger</a>:</p> <blockquote> <p>Slack lost <a href="https://www.reactiflux.com/">Reactiflux</a> bc they wanted $70k/month to support them.</p> </blockquote> <p>Sure, I get that this was a deliberate decision. Storage costs money. But <em>how much</em> are we talking? Further, every company understands the logic of running "loss leaders" in order to seed stickiness and future growth. <strong>While literally every other company on Earth is throwing all sorts of free benefits to attract developers</strong>, Slack found developer communities growing like a weed on it, and flicked them away like so much dandruff. Stewart Butterfield is like the anti-<a href="https://www.youtube.com/watch?v=VM-2OVNt-eQ">Ballmer</a>.</p> <p>I'm not here to argue that Slack lost developers because it didn't want developers. That's a tautology. I'm here to argue that <strong>this is a strategic fumble</strong> that opened up the field to whatever will eventually replace Slack for startups (Microsoft Teams' success is difficult to assess so I will ignore it here).</p> </section> <section> <h2 id="slack-losing-its-way">Slack Losing Its Way</h2> <p><strong>Developers are your canary in the coalmine</strong> for user experience - because they create the damn things!</p> <p>Slack's original appeal was that it had a much better user experience than prior work chat/email/collaboration tools including the now-dead HipChat and Campfire. Reams of VC pitch decks were made about the "Consumerization of the Workplace" thanks to Slack's approachable design (as <a href="https://medium.com/@awilkinson/slack-s-2-8-billion-dollar-secret-sauce-5c5ec7117908">MetaLab never fails to remind you</a>) and early touches like emoji reactions and bots. The theory was that we demand the UX polish that we see in our personal lives, in our professional lives as well.</p> <p>Fast forward to today: "I’ve been using Discord a ton lately. Slack for work and Discord for hobbies." That's from <a href="https://twitter.com/1Marc/status/1261960701666623488">Marc Grabanski</a>, who knows a thing or two about developer trends.</p> <p>I'll raise you another point: In 2016, Slack was originally backronym'ed into the <a href="https://www.businessinsider.com/where-did-slack-get-its-name-2016-9">Searchable Log of All Conversation and Knowledge</a>.</p> <p>Fast forward to today and advice from the curiously high amount of "how to work from home" content you've undoubtedly been receiving is overwhelmingly <a href="https://about.gitlab.com/blog/2015/04/08/the-remote-manifesto/#2-communicate-asynchronously">Communicate Asynchronously</a> and <a href="https://knowyourteam.com/m/lessons/161-managing-remote-teams/topics/1331-process-and-tools-how-to-collaborate-effectively-when-your-team-is-remote#but-are-there-tools-you-just-cant-live-without">Use Anything But Slack for Long Lived Knowledge</a>.</p> </section> <section> <h2 id="the-game-is-changing">The Game is Changing</h2> <p>Meanwhile the UX bar has risen in the past 5 years:</p> <ul> <li>Slack makes you create a email and password anew every time you join a new Slack. Clicking a Discord invite immediately lands you in the channel as long as you're logged in.</li> <li>Slack walks you through the full onboarding experience every time you join a new Slack. I've joined probably 80 Slacks, I'm tired of the "👋 Hi, Slackbot here!" welcome messages on how to use Slack, or the downright <em>buggy</em> step through guide that prompts me to put in my profile picture even though Slack clearly figured out that I use the same damn picture every time and is already displaying it. Discord does exactly none of this.</li> <li>You need to repeat the whole email and signup song and dance when you move to your phone. Discord is cross-platform-first - sign in on desktop and you're also signed in on mobile.</li> <li>(Developer specific) The new WYSIWYG editor rolled out last year <a href="https://www.vice.com/en_us/article/pa7nbn/slacks-new-rich-text-editor-shows-why-markdown-still-scares-people">made it annoying</a> for developers accustomed to What We Type Is What We Get Thank You Very Much. Not only does Discord not get in the way of your typing, it offers <strong>SYNTAX HIGHLIGHTING</strong> if you add <a href="https://help.github.com/en/github/writing-on-github/creating-and-highlighting-code-blocks#syntax-highlighting">language identifiers</a> to your code fenced blocks!</li> </ul> <p>The past year or so in Office Productivity has been a free-for-all as other companies moved into Slack's open flanks. Notion has torn it up as the Searchable Knowledge Base to beat today. Zoom has overwhelmingly captured video chat, despite Slack also offering it natively. Even a bootstrapped startup like <a href="http://tuple.app/">Tuple</a> has become successful despite Slack buying the literal <a href="https://techcrunch.com/2015/01/28/slack-buys-screenhero-to-add-screen-sharing-and-voice-chat-to-its-work-messaging-platform/">category maker</a> in the space. And of course Discord and even Telegram have made inroads in real time chat.</p> <p>My intuition is that <a href="https://stratechery.com/2017/the-great-unbundling/">the Great Unbundling</a> has come for Slack. Whether or not it survives will probably depend on this: Is text chat really <a href="https://jtbd.info/feature-vs-product-42bf2dad2764">a feature or a product</a>? Either way, having to answer that question is an undesirable strategic position for Slack to be in. There is no victory in this fight.</p> <blockquote> <p>Note: if you feel lost right about here, I released the <a href="https://www.swyx.io/writing/dev-guide-to-tech-strategy/">Developer's Guide to Tech Strategy</a> chapter of <a href="https://twitter.com/coding_career">my upcoming book</a> recently, feel free to pause and check it out.</p> </blockquote> </section> <section> <h2 id="not-over-yet">Not Over Yet</h2> <p>Slack has fumbled a ball, but it still has a strong lead. Two features still make Slack a strong fit for realtime workplace communication: <a href="https://www.theverge.com/2017/1/18/14305528/slack-threads-threaded-messages">threaded messages</a>, which Discord refuses to build, and <a href="https://slackhq.com/shared-channels-growth-innovation">Shared Channels</a>, which <a href="https://twitter.com/swyx/status/1096347638696267778?s=20">I've gone on record</a> as saying will add years' worth and billions of dollars of revenue. Both were introduced in 2017, probably the peak year of innovation for Slack before creating <a href="https://www.google.com/search?q=slack+fund&amp;oq=slack+fund&amp;aqs=chrome..69i57l2j69i59l2j69i65l2j69i61j69i60.843j0j7&amp;sourceid=chrome&amp;ie=UTF-8">the Slack fund</a> in 2018 and then its 2019 IPO.</p> <p>From my limited anecdata, the no-code <a href="https://venturebeat.com/2019/04/24/slack-launches-workflow-builder-for-businesses-to-make-apps-without-code/">Workflow Builder</a> hasn't yet had significant adoption, but I would be happy to see this change over time. All great platforms eventually add low/no-code automation.</p> <p>Slack has also made heavy investments for Enterprise Adoption, with things like <a href="https://slackhq.com/introducing-slack-enterprise-grid">Enterprise Grid</a> (also in 2017! hmm...). I of course don't have any insight into Slack's growth in the Enterprise. I'm fully aware of the economic incentives of going upmarket and forsaking low end customers.</p> </section> <section> <h2 id="communities-over-teams">Communities Over Teams</h2> <p>The net result of all this is that Slack is now very much not <a href="https://www.bloomberg.com/features/2016-design/a/stewart-butterfield/">the operating system for your team</a> that it set out to be. However its entire user experience is tied to teams.</p> <p>More specifically - having one single home team, interacting with that team on one device, and the assumption that you don't join or change teams very often. Perhaps this is the disconnect we are sensing.</p> <p> Slack's focus on teams may be becoming outdated in this new world we live in, where Deep Work and organized knowledge bases come at a premium, and our professional work crosses professional and personal boundaries, and spans across multiple devices, modalities and even multiple communities we both lead and participate in. Discord's focus on communities may win hearts and eventually wallets. Here's <a href="https://twitter.com/kurtkemple/status/1260947289436303367?s=20">Kurt Kemple on Discord's community features</a>, for thought: </p> <blockquote> <p>Discord is more community friendly IMO. Things like moderation, roles, boosting, group A/V, all make it a great place for a more democratized and scaleable platform.</p> </blockquote> <p>By focusing on communities instead of siloed teams, Discord becomes a friend of community leaders. In other words, <strong>Discord aggregates aggregators</strong>. In a world of <a href="https://stratechery.com/aggregation-theory/">Aggregation Theory</a>, this is a very good thing.</p> <p>I thought it was Paul Graham or Benedict Evans who said this, but am unable to find the source: "What hackers do for fun today, we will do at work tomorrow".</p> <p><strong>Hackers are deserting Slack in droves</strong>. Slack should be on high alert.</p> <hr> <p>Recommended reads:</p> <ul> <li>Mule's Dark Horse Discord: How a gaming chat platform is secretly connecting the internet, and defining the future of work: <a href="https://mule.substack.com/p/dark-horse-discord">https://mule.substack.com/p/dark-horse-discord</a></li> <li>Kevin Kwok's The Arc of Collaboration: <a href="https://kwokchain.com/2019/08/16/the-arc-of-collaboration/">https://kwokchain.com/2019/08/16/the-arc-of-collaboration/</a></li> </ul> </section> <hr>  </div> </main>  </div></div></div>]]>
            </description>
            <link>https://www.swyx.io/writing/slack-fumble/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24012496</guid>
            <pubDate>Fri, 31 Jul 2020 19:01:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Releasing on Product Hunt vs. Hacker News]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24011607">thread link</a>) | @shahahmed
<br/>
July 31, 2020 | https://failflow.com/blog/my-first-product-hunt | <a href="https://web.archive.org/web/*/https://failflow.com/blog/my-first-product-hunt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://failflow.com/blog/my-first-product-hunt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24011607</guid>
            <pubDate>Fri, 31 Jul 2020 18:06:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Does Having an Anime Profile Picture Make You a Better Programmer?]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 48 (<a href="https://news.ycombinator.com/item?id=24011583">thread link</a>) | @wh313
<br/>
July 31, 2020 | https://h313.info/blog/github/anime/google-cloud/2020/07/31/does-having-an-anime-profile-picture-make-you-a-better-programmer.html | <a href="https://web.archive.org/web/*/https://h313.info/blog/github/anime/google-cloud/2020/07/31/does-having-an-anime-profile-picture-make-you-a-better-programmer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
<div>
<article itemscope="" itemtype="http://schema.org/BlogPosting">

<div itemprop="articleBody">
<p>In her 2001 book <em>Anime from Akira to Princess Mononoke</em>, Professor Napier showed that many fans of
anime work in computer science and its related fields. The survey also happened to show that “over
70 percent had a grade point average of 3.0 or higher, which is especially impressive when one
considers the academic rigor of scientific fields.”</p>
<p>Anime has a pretty well-known reputation for creating <a href="https://youtu.be/755BDwzxv5c?t=3">men of culture</a>. That’s a clear
indication that anime fans can be profoundly affected by the medium. In addition, many prolific
open source contributors have anime characters as their profile picture. So that got me to thinking,
does being a fan of anime also make you a more intelligent person?</p>
<p><img src="https://raw.githubusercontent.com/laynH/Anime-Girls-Holding-Programming-Books/master/C%2B%2B/Sakura_Nene_CPP.jpg" alt="sakura nene cpp"></p>
<p>Of course, a question like that is nearly impossible to answer directly. After all, there’s
countless ways to measure intelligence, and anime fandom is so broad that no one definition can fit
all cases. For example, should we consider someone who has only watched <em>Spirited Away</em>, and liked
it very much, but has no exposure to other forms of anime, to be an anime fan? What about people who
only read manga? Or those who exclusively watch <a href="https://en.wikipedia.org/wiki/The_Leader_(web_series)">whatever this is supposed to be</a>?</p>
<p>A smaller question that’s easily answerable would be to see if having an anime profile picture
correlates with you being a better programmer. After all, if someone takes the effort to set their
profile picture to a waifu, they clearly have some fondness for anime. As for being a “better
programmer,” we’ll just equate being better with having more activity on GitHub. And being good at
programming does require an amount of critical reasoning at logic skill, which should equate to a
higher intelligence. Of course, this metric could be easily abused by having a <code>cron</code> job making a
ton of commits, but it’s a measure of programming activity that should be Good Enough™.</p>
<p>Luckily, Google provides their <a href="https://cloud.google.com/vision/">image labelling API</a> for very cheap (or free, if you
have GCP credit). As an example, putting in an image of best girl Mai Sakurajima from <em>Rascal Does
Not Dream of Bunny Girl Senpai</em> into the demo provided, I’ll get this list of labels back from it:</p>
<p><img src="https://h313.info/blog/assets/img/mai_google_vision.png" alt="mai"></p>
<p>Notice how one of the labels is “Anime”? That’s a surprise tool that will help us later :) Google
also provides a Python API, which makes it even easier to check images, since all you have to do now
is check if “Anime” is one of the tags:</p>
<div><div><pre><code><span>anime_or_not</span><span>(</span><span>image</span><span>):</span>
    <span>response</span> <span>=</span> <span>client</span><span>.</span><span>label_detection</span><span>(</span><span>image</span><span>=</span><span>image</span><span>)</span>
    <span>labels</span> <span>=</span> <span>response</span><span>.</span><span>label_annotations</span>

    <span>for</span> <span>item</span> <span>in</span> <span>labels</span><span>:</span>
        <span>if</span> <span>item</span><span>.</span><span>description</span> <span>==</span> <span>"Anime"</span><span>:</span>
            <span>return</span> <span>True</span>
</code></pre></div></div>
<p>As for GitHub commits, we can use the <a href="https://docs.github.com/v3/activity/event_types/">events API</a> that’s roughly analogous to the
contribution history graph of a user. We’ll be measuring user activity just by the number of events
for each user, so each event (opening a PR, creating a repo, etc.) is given equal weight. That’s
roughly analogous to how green a user’s contribution heatmap is.</p>
<p><img src="https://h313.info/blog/assets/img/github_contribution_graph.png" alt="contribution map"></p>
<p><a href="https://pygithub.readthedocs.io/en/latest/">PyGitHub</a> wraps the GitHub API into an easy to use library, so getting the number of
events for a user, as well as their profile picture’s URL, is pretty simple:</p>
<div><div><pre><code><span>users</span> <span>=</span> <span>g</span><span>.</span><span>get_users</span><span>()</span>

<span>for</span> <span>user</span> <span>in</span> <span>users</span><span>:</span>
    <span>event_count</span> <span>=</span> <span>0</span>
    <span>for</span> <span>event</span> <span>in</span> <span>user</span><span>.</span><span>get_events</span><span>():</span>
        <span>event_count</span> <span>+=</span> <span>1</span>

    <span>is_anime_image</span> <span>=</span> <span>check_if_weeb</span><span>(</span><span>user</span><span>.</span><span>avatar_url</span><span>)</span>
</code></pre></div></div>
<p>GitHub does rate limit the API to 5000 requests per hour for authenticated users. That’s enough to
run about 2000 requests per hour. To get around that, we can take advantage of how GitHub profile
IDs are numbered sequentially and process profiles in batches of 1000:</p>
<div><div><pre><code><span>for</span> <span>github_id</span> <span>in</span> <span>range</span><span>(</span><span>1200000</span><span>,</span> <span>1201000</span><span>):</span>
    <span>try</span><span>:</span>
        <span>user</span> <span>=</span> <span>g</span><span>.</span><span>get_user</span><span>(</span><span>github_id</span><span>)</span>
    <span>except</span> <span>Exception</span><span>:</span>
        <span>continue</span>

    <span># do user stuff here
</span></code></pre></div></div>
<p>I’ve modified the <code>get_user</code> function here to use the undocumented <code>/user/:id</code> endpoint. This hasn’t
been implemented in PyGitHub yet, but <a href="https://github.com/PyGithub/PyGithub/issues/1615">this issue</a> seems to be tracking it.</p>
<p>All that’s left is to link these APIs up and save the data. It’s trivial to just loop through all
users using the <code>/users</code> GitHub API endpoint, send their image over to the Google Vision API, note
down whether they had an anime profile picture and the number of events for that user, and finally
log it into a CSV for analysis later. That’s exactly what I did, and you can see my code
<a href="https://github.com/h313/anime-face">here</a>. It’s very research quality, so don’t expect much.</p>
<p>So now I’ve got a table of 3497 GitHub profiles, of which only 23 have anime profile pictures.
Here’s a box plot that displays the distribution of user activity by profile picture type:</p>
<p><img src="https://h313.info/blog/assets/img/github_boxplot.png" alt="box plot"></p>
<p>Hmm, the users with an anime profile picture do seem to have a higher average number of
activities. But we can’t stop here. Keep in mind that there’s way more samples of users without
anime profile pictures compared to those with, as well as the comparatively high amount of
outliers in both groups. To be sure that the difference here is statistically significant,
we’ll need to do a T-test:</p>
<div><div><pre><code><span>from</span> <span>scipy.stats</span> <span>import</span> <span>ttest_ind</span>

<span>cat1</span> <span>=</span> <span>df</span><span>[</span><span>df</span><span>[</span><span>'is_anime_face'</span><span>]</span> <span>==</span> <span>True</span><span>]</span>
<span>cat2</span> <span>=</span> <span>df</span><span>[</span><span>df</span><span>[</span><span>'is_anime_face'</span><span>]</span> <span>==</span> <span>False</span><span>]</span>

<span>ttest_ind</span><span>(</span><span>cat1</span><span>[</span><span>'contribs'</span><span>],</span> <span>cat2</span><span>[</span><span>'contribs'</span><span>])</span>
</code></pre></div></div>
<p>That provides a p-value of <code>0.2371</code>. We now have to conclude that the higher average we got isn’t
statistically significant, since our p-value of 23.7% doesn’t meet the traditional 5% cutoff.
Therefore, we must once again acquiesce to <a href="https://en.wikipedia.org/wiki/Betteridge's_law_of_headlines">Betteridge’s law</a>, and adopt our null
hypothesis, that having an anime profile picture does not necessarily correlate with your abilities
as a programmer.</p>
<p>Further work into this topic can be done, however. Since this project only looked at a small
number of users, who were among the first to register, it is not a representative slice of the
GitHub user population. In addition, it may also be enlightening to include the inactive users
skipped in this experiment.</p>
</div>

</article>
</div>
</div></div>]]>
            </description>
            <link>https://h313.info/blog/github/anime/google-cloud/2020/07/31/does-having-an-anime-profile-picture-make-you-a-better-programmer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24011583</guid>
            <pubDate>Fri, 31 Jul 2020 18:04:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Niklaus Wirth was right and that is a problem]]>
            </title>
            <description>
<![CDATA[
Score 185 | Comments 169 (<a href="https://news.ycombinator.com/item?id=24011573">thread link</a>) | @bowero
<br/>
July 31, 2020 | https://bowero.nl/blog/2020/07/31/niklaus-wirth-was-right-and-that-is-a-problem/ | <a href="https://web.archive.org/web/*/https://bowero.nl/blog/2020/07/31/niklaus-wirth-was-right-and-that-is-a-problem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-226">
	

	<div>
		
<p>Wirth’s law is not really a law. Actually, none of them ever are laws. They are adages:</p>



<blockquote><p><em>a proverb or short statement expressing a general truth.</em></p><cite><a href="https://www.lexico.com/en/definition/adage">https://www.lexico.com/en/definition/adage</a></cite></blockquote>



<p>Here is another law that is not a real law:&nbsp;<em>Moore’s law is the observation that the number of transistors in a dense integrated circuit (IC) doubles about every two years.</em></p>



<p>This means that we can expect the speed and capability of computers to increase while lowering the costs. Sadly, this is where Wirth’s law comes in:</p>



<blockquote><p><em>Wirth’s law is an adage on computer performance which states that software is getting slower more rapidly than hardware is becoming faster.</em></p><cite><a href="https://en.wikipedia.org/wiki/Wirth%27s_law">https://en.wikipedia.org/wiki/Wirth%27s_law</a></cite></blockquote>



<p>And while Moore’s law has proven to be true since 1975, Wirth’s law seems to be true as well. Niklaus Wirth, the designer of Pascal, wrote an article in 1995:</p>



<blockquote><p>About 25 years ago, an interactive text editor could be designed with as little as 8,000 bytes of storage. (Modern program editors request 100 times that much!) An operating system had to manage with 8,000 bytes, and a compiler had to fit into 32 Kbytes, whereas their modern descendants require megabytes. Has all this inflated software become any faster? On the contrary. Were it not for a thousand times faster hardware, modern software would be utterly unusable.</p><cite>Niklaus Wirth – A Plea for Lean Software</cite></blockquote>



<p>The problem of modern software development is manyfold. Wirth points out one crucial aspect: time.</p>



<blockquote><p>Time pressure is probably the foremost reason behind the emergence of bulky software.</p><cite>Niklaus Wirth – A Plea for Lean Software</cite></blockquote>



<p>And while that was true back in 1995, that is no longer the most important factor. We now have to deal with a much bigger problem: abstraction. Developers never built things from scratch, and that has never been a problem, but now they have also become lazy.</p>



<p>It was Edsger W. Dijkstra who tried to improve the quality of code and coined the concept of <em>structured programming</em>. He tried to get programming out of the state of crisis it was in, and he found support in programmers like Harlan D. Mills, Richard C. Linger and Bernard I. Witt. For a short period of time, programming was seen as a real craftmanship. Programmers cared about the quality of their programs, and that included clarity and efficiency.</p>



<p>Those times have passed. With the introduction of higher-level languages such as Java, Ruby, PHP and Javascript all in 1995, the same year in which Wirth wrote his article, programming became more abstract. </p>



<p>Languages like these made programming a lot easier and took many things out of the programmer’s hands. They were object-oriented and came with things as an IDE and garbage collection.</p>



<p>This meant that programmers had fewer things to worry about, which is of course great. Sadly, everything comes with a price. Having fewer things to worry about, also means having fewer things to think about. 1995 was the year in which programmers stopped thinking about the quality of their programs.</p>



<p>It also marked the beginning of the widespread use of libraries, probably one of the bigger problems. Don’t get me wrong, I love libraries. They are the only reason I am able to get things done. However, a library never comes with the exact things that you need.</p>



<p>Because a library is not made for one specific project, it probably has a bit more functionalities than you really needed. No problem, you would say. However, things pile up pretty quickly. Even the people who like libraries, don’t want to reinvent the wheel. This results in what we call dependency hell. <a href="https://blog.appsignal.com/2020/04/09/ride-down-the-javascript-dependency-hell.html">Nikola Duza wrote a post about that issue in Javascript</a>.</p>



<p>The problem does not seem that big, but try to grasp what is happening here. In another tutorial that Nikola wrote, he built a simple todo-list. It works in your browser with HTML and Javascript. How many dependencies did he use? <a href="https://blog.appsignal.com/2020/05/14/javascript-growing-pains-from-0-to-13000-dependencies.html">13,000.</a></p>



<p>These numbers are insane, but this problem will only keep increasing. As new, very useful libraries keep being built, the number of dependencies per project will keep growing as well.</p>



<p>That means that the problem Niklaus was warning us about in 1995, only gets bigger over time. </p>



<p>And no, you don’t have to learn assembly and start writing your web application in that. A good way to start would be to split up libraries. Instead of creating one big library that does everything you could ever possibly need, just create many libraries. Your god-like library could still exist, but solely as a wrapper. </p>



<p>This way a programmer only has to select the libraries he really requires, while ignoring the functionalities he is not going to use in his application. Not only are his dependencies smaller, but they will also use less of their dependencies because the dependencies of the unused functionalities do not have to be installed.</p>



<blockquote><p><strong>Note: </strong>The proposed solution obviously is not <em>the</em> solution. It would for example require a good way of versioning software to avoid a new dependency hell.</p></blockquote>
	</div>

	
</article></div>]]>
            </description>
            <link>https://bowero.nl/blog/2020/07/31/niklaus-wirth-was-right-and-that-is-a-problem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24011573</guid>
            <pubDate>Fri, 31 Jul 2020 18:03:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Projecting Bitcoin's Price with Popularity (Google Trends)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24010763">thread link</a>) | @webcerfer2020
<br/>
July 31, 2020 | https://blogofjake.com/2020/07/31/projecting-bitcoins-price-with-popularity-google-trends/ | <a href="https://web.archive.org/web/*/https://blogofjake.com/2020/07/31/projecting-bitcoins-price-with-popularity-google-trends/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><strong><span>A Tale of Two Charts</span></strong></p>



<p>The chart below shows the monthly average <a href="https://www.coindesk.com/price/bitcoin">price of bitcoin</a> since October 2013.</p>



<figure><img data-attachment-id="1238" data-permalink="https://blogofjake.com/image-26/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-26.png" data-orig-size="782,307" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-26" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=782" src="https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=782" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-26.png 782w, https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-26.png?w=768 768w" sizes="(max-width: 782px) 100vw, 782px"></figure>



<p>This second chart shows the <a href="https://trends.google.com/trends/explore?date=all&amp;q=bitcoin">Google Trends Score</a> by month for the search term “bitcoin”, also since October 2013.</p>



<figure><img data-attachment-id="1239" data-permalink="https://blogofjake.com/image-27/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-27.png" data-orig-size="783,307" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-27" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-27.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-27.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>When I first saw the second chart, I thought it looked remarkably similar to the first. Sure enough, it does. Below are the two charts together. The darker line shows the price according to the left-side axis and the lighter line shows the Google Trends Score according to the right-side axis.</p>



<figure><img data-attachment-id="1240" data-permalink="https://blogofjake.com/image-28/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-28.png" data-orig-size="783,306" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-28" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-28.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-28.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>It turns out that bitcoin’s price and its Google Trends Score are quite correlated.</p>



<p>Specifically, they have had a 72% positive correlation since October 2013. This compares favorably to bitcoin’s <a href="https://cointelegraph.com/news/bitcoins-correlation-with-gold-is-weakening-says-new-kraken-report">26% correlation with the stock market and 24% correlation with gold</a> over the last year.</p>



<p>I should note that the correlation between bitcoin’s price and its Google Trends Score was much stronger up until both price and score peaked in December 2017 (98%) than it has been since (59%).</p>



<p>Nonetheless, the purpose of this analysis is not to argue about the level of correlation nor to assert causation one way or another (though it seems logical that the price and popularity feed off of each other). Rather, the purpose of this analysis is to make a speculative projection regarding what bitcoin’s price could be if and when its popularity (as measured by its Google Trends Score) returns to and surpasses its previous all-time high.</p>



<p>In order to make this projection, we first must consider the historical ratio between bitcoin’s average price and its Google Trends Score on a monthly basis. Let us refer to this as the <em><strong>price:score ratio</strong></em><strong> </strong>for short.</p>



<p><strong><span>Bitcoin’s Price:Score Ratio</span></strong></p>



<p>The chart below shows how bitcoin’s price:score ratio has increased over the last several years.</p>



<figure><img data-attachment-id="1241" data-permalink="https://blogofjake.com/image-29/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-29.png" data-orig-size="783,307" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-29" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-29.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-29.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>For a ratio that has been relatively volatile historically, it has remained unusually consistent for the last two months (June &amp; July) at 729, just 4% short of its all-time high of 758 in November 2019.</p>



<p>Bitcoin’s price:score ratio has been above 645 for 9 of the last 12 months after having only reached such a level once before, and barely (646 in October 2018).</p>



<p>The 3 months in the last year during which the ratio was lower than 645 can be fairly easily explained. They took place this past March, April, and May as hype grew in anticipation of bitcoin’s once every four years halving event on May 11, 2020. Additionally, people perhaps were searching more than usual for information about alternative assets (including bitcoin) when the stock market crashed ~30% in the early days of the lockdown resulting from the pandemic. Those two factors together seem sufficient to explain the uptick in bitcoin’s Google Trends Score over that period. On the other side of the price:score ratio, bitcoin’s price fell along with the market, and so with the price going down and the score going up, the decreased price:score ratio over those few months makes sense.</p>



<p>Since the stock market substantially recovered and the halving event came and went without materially moving bitcoin’s price, the Google Trends Score has returned to the pre-pandemic, pre-halving-hype range. For the last two months (June &amp; July), bitcoin’s monthly Google Trends Score has stayed steady at 13, which is equal to its average from April 2018 (after the peak) through February 2020 (before the halving hype and market crash).</p>



<p>For some additional context, it should be noted that bitcoin’s Google Trends Score has only been equal to or greater than 21 in 7 months since bitcoin’s inception and they all took place consecutively surrounding bitcoin’s last major surge from September 2017 through March 2018 (with scores chronologically of 21, 22, 44, 100, 55, 39, and 23).</p>



<p><strong><span>Flying Under The Radar</span></strong></p>



<p>Sufficed to say, bitcoin’s average score of 13 since the last surge, excluding the three aforementioned months from earlier this year (14 if we include them), shows objectively that bitcoin is flying under the radar (in terms of its popularity as a search term at least). Of course, it may not seem this way to people who follow crypto closely and daily but the algorithmic and mass-data collecting Google Trends Score should be trusted over any single person’s speculative and subjective observation about the current level of hype and attention.</p>



<p>If you, like me, believe that bitcoin is and has been flying under the radar for more than two years now, the natural question to ask is this. What do we expect to happen when that is no longer the case? In other words, what happens to bitcoin’s price if and when it reaches the pinnacle of its next hype cycle? How high might bitcoin fly the next time we see a situation similar to that of December 2017?</p>



<p><strong><span>Projecting Bitcoin’s Price</span></strong></p>



<p>I believe a reasonable response to this question can be made by applying bitcoin’s average price:score ratio over the last twelve months (643) to a Google Trends Score of 100 to estimate what bitcoin’s price would be if the price:score ratio stays about constant and bitcoin’s popularity in terms of search returns to its all-time high. The price implied by this projection is about $65,000 as is demonstrated by the maximum value in the top right corner of the chart below. Basically, if one believes that bitcoin will at least at some point return to the level of popularity it attained in December 2017, this methodology would lead that person to expect bitcoin to attain a price of at least $60,000 at that time.</p>



<figure><img data-attachment-id="1242" data-permalink="https://blogofjake.com/image-30/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-30.png" data-orig-size="783,308" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-30" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-30.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-30.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p>This estimate can be made less conservative in two ways. The first is to assume that the price:score ratio will continue to increase as it has all along (6% month-over-month), rather than calculating the price using the LTM average of the ratio. The second is to assume that bitcoin’s popularity as a search term will well surpass its previous all-time high set in December 2017 just as that all-time was more than twice as great as any high before it and more than 8 times greater than the all-time high before May 2017 (which was set in December 2013, perhaps not coincidentally exactly 4 years or one halving period prior to the latest all-time high). I hesitate to call either of these two less conservative assumptions aggressive because they are not only reasonable but actually probable if one is to simply assume that the historical trends will continue in terms of the score and the ratio.</p>



<p>As such, I will close by presenting a chart which one can use to approximate the price implied by their own inputs for the Google Trends Score and the price:score ratio. In this chart, I show the ratio for the last 12 months, 2 years, 3 years, and so on, and use the average year-over-year growth rate between those figures (16%) to project the next twelve months (“NTM”), next two years (“N2Y”), and next three years (“N3Y”) ratios.</p>



<p>The highest price projected on the chart is right around $300,000 based on a Google Trends Score of 3 times the previous all-time high (300) and a projected N3Y price:score ratio of 996 (the LTM average of 643 increased 16% 3 times for 3 years). Of course, this maximum price projection is limited only arbitrarily by the maximums I have decided to present on this chart for both the score and the ratio.</p>



<figure><img data-attachment-id="1243" data-permalink="https://blogofjake.com/image-31/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/07/image-31.png" data-orig-size="783,306" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-31" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=783" src="https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=783" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/07/image-31.png 783w, https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=300 300w, https://theblogofjake.files.wordpress.com/2020/07/image-31.png?w=768 768w" sizes="(max-width: 783px) 100vw, 783px"></figure>



<p><strong><span>To Be Continued…</span></strong></p>



<p>Many people have employed many methodologies in attempting to accurately project bitcoin’s price. For example, <a href="https://medium.com/@100trillionUSD">PlanB</a>‘s stock to flow ratio looks at scarcity to make one of the more convincing price projections I’ve seen. My price:score ratio looks at popularity in endeavoring to do the same. This analysis was not intended to be totally comprehensive. My intention was merely to introduce this methodology for others to critique. As such, my hope is that this becomes widely enough read so that I may receive ample critical feedback for further consideration and refinement of the methodology.</p>



<p><em>As always, I welcome all outreach to jake@blogofjake.com and any comments on Twitter <a href="https://twitter.com/blogofjake">@blogofjake</a></em></p>
	</div></div>]]>
            </description>
            <link>https://blogofjake.com/2020/07/31/projecting-bitcoins-price-with-popularity-google-trends/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24010763</guid>
            <pubDate>Fri, 31 Jul 2020 17:05:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cracking the Developer Code: Flow]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24010663">thread link</a>) | @discodave
<br/>
July 31, 2020 | https://blog.drgriffin.com.au/posts/2020-07-31-cracking-the-developer-code:-flow.html | <a href="https://web.archive.org/web/*/https://blog.drgriffin.com.au/posts/2020-07-31-cracking-the-developer-code:-flow.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>I’ve been thinking a lot lately about what motivates software developers. If
you believe that <a href="https://thenewkingmakers.com/">Developers are the new
Kingmakers</a>, then this is an important subject!</p>
<p>It's certainly true that developers can be opinionated, but I’m not sure I
agree with statements like the following;</p>
<blockquote>
<p>“[a developer] typically just wants to use the best
tool for the job”<sup>1</sup>.</p>
</blockquote>
<p>Throughout my career I’ve seen it over and over that developers want to
reinvent the wheel instead of talking to another team, or using a pre-existing
solution. Sometimes it seems like the primary goal of developers is to find
excuses to write a lot of code. There are
<a href="https://en.wikipedia.org/wiki/Boondoggle">so</a>
<a href="https://en.wikipedia.org/wiki/Not_invented_here">many</a>
<a href="https://kubernetes.io/">examples</a> of developers picking things that let them
muck around with code, instead of making the best choice for the business.</p>
<p>Code, rather than results has this mythical status in the industry. Candidates
for highly-paid developer jobs, like the one I used to hold, are tested on
their coding ability first, and other skills second. These skills, like
communication, and listening are often derisively referred to as soft skills.
I've seen interview debriefs where interviewers act like being able to code
trumps all other skills.  The reality is that those "soft" skills are the most
important skills, and they only get more important as you progress in your
career. The technical leaders that I admire the most, like <a href="https://www.youtube.com/watch?v=BOYdKht1YwE">James
Hamilton</a>, or <a href="https://www.youtube.com/watch?v=Pqc6X3sj6q8">Heidi
Howard</a> are great communicators
above all. Those are the people who change industries, and upend the
<a href="https://fortune.com/2015/10/21/hp-public-cloud/">status</a>
<a href="https://www.forbes.com/sites/benkepes/2013/10/29/ibm-capitulates-amazon-gains-cia-contract/#60d44d204bbf">quo</a>.</p>
<p>So why is it code and coding that holds this mythical status? Why are all the
hopeful university and bootcamp graduates studying <a href="http://www.crackingthecodinginterview.com/">Cracking the Coding
Interview</a> in the hopes of landing
a six-figure salary at a tech company?</p>
<p>Two things finally made it click for me. Firstly, I listened to a podcast
about achieving <a href="https://anchor.fm/curiousclimberpodcast/episodes/Cameron-Norsworthy---The-Path-to-Flow-eboqkc">flow state, and how it applies to
climbing</a>.
Secondly, I finally watched the 1995 cult-classic Hackers. In that movie, the
main character Dade is basically addicted to his computer. He stays up all
night, much to his mother’s distress.</p>
<blockquote>
<p>In positive psychology, a flow state, also known colloquially as being in the
zone, is the mental state in which a person performing an activity is fully
immersed in a feeling of energized focus, full involvement, and enjoyment in
the process of the activity. In essence, flow is characterized by the complete
absorption in what one does, and a resulting transformation in one's sense of
time. (<a href="https://en.wikipedia.org/wiki/Flow_(psychology)">Wikipedia</a>)</p>
</blockquote>
<p><img alt="Hacking movie collage" src="https://blog.drgriffin.com.au/hacking-collage-v2.jpeg">
A selection of scenes involving coding, or 'hacking', from War Games, Hackers,
The Matrix , Swordfish , The Girl With The Dragon Tattoo, and Halt and Catch
Fire.</p>
<p>People like me love to deride ‘hacking’ scenes in hollywood movies as being
unrealistic.  But after watching Hackers I realised... I have behaved like
Dade, many times; and not just recently during this
<a href="https://www.goodreads.com/quotes/6344-time-is-an-illusion-lunchtime-doubly-so">pandemic</a>.</p>
<p><img alt="Me playing my GameBoy" src="https://blog.drgriffin.com.au/gameboy.jpeg">
That's me engrossed in a GameBoy sometime in the 90s.</p>
<p>When I think about it, that search for flow has had a huge impact on my life
and career. It was while I had some spare time<sup>2</sup> as a ski-bum that I
did Zed Shaw's <a href="https://shop.learncodethehardway.org/">Learn Python the Hard
Way</a>.  That, along with my Electrical
Engineering degree is what lead me down the path towards Amazon, and Seattle.
You could argue that I spent two (Australian) summers as a ski-bum, and learned
a new programming language in search of that flow state.  Some other examples
of things I've done over the years perhaps in search of flow are sailing,
hiking, climbing, and weightlifting. In that context, those hollywood scenes of
caffeinated hackers staying up all night don't seem so far off the mark.</p>
<p>This got me thinking about a stereotypical software developer, what were they
like as a child? Did they love LEGO? Did they play computer games? Did they
read lots of books? Are they into comic books? Did they excel at math? The list
goes on.</p>
<p><img alt="My first lego set?" src="https://blog.drgriffin.com.au/bob-lego-and-me.jpeg">
How many engineers began their journey with a set of LEGO?</p>
<p>It turns out that the people who defined and researched flow, like Mihaly
Csikszentmihályi, and Jeanne Nakamura outlined some specific conditions that
need to be met to achieve the flow state, again from
<a href="https://en.wikipedia.org/wiki/Flow_(psychology)">Wikipedia</a>: </p>
<blockquote>
<ol>
<li>
<p>One must be involved in an activity with a clear set of goals and
   progress.  This adds direction and structure to the task. </p>
</li>
<li>
<p>The task at hand must have clear and immediate feedback. This helps the
   person negotiate any changing demands and allows them to adjust their
   performance to maintain the flow state.</p>
</li>
<li>
<p>One must have a good balance between the perceived challenges of the task
   at hand and their own perceived skills. One must have confidence in one's
   ability to complete the task at hand.</p>
</li>
</ol>
</blockquote>
<p>These principles have been used pretty heavily by games, and the techniques of
game designers are now common in <a href="https://en.wikipedia.org/wiki/Gamification">everyday
life</a>, sometimes with <a href="https://www.washingtonpost.com/news/monkey-cage/wp/2018/08/06/its-no-accident-that-facebook-is-so-addictive/">questionable
outcomes</a>.
But bringing it back to developers, many things you can see in the software
industry look like attempts to find flow.</p>
<p>Firstly, a clear set of goals and progress?  Hello <em>tasks</em>. From Agile,
to Scrum, to Kanban, most software development methodologies are built around
the <em>task</em>.  <em>Tasks</em> are created precisely to set goals and measure progress.</p>
<p>Secondly, feedback. One of the key things that attracted me to software, over
the other branches of electrical engineering was the immediate, almost
addictive feedback loops you can get while coding.</p>
<p>And thirdly, endless ink has been spilled over the years about aligning
challenges with skills. Every discussion you’ve ever seen about organizational
structure has some element of trying to align the challenges of the
organization with the skills of it's people. All the work I've done around
mentoring and growth, from when I was a 14 year old Patrol Leader in Scouts, to
Amazon, was about finding the right level of challenge for people.</p>
<h2>Maybe they weren't crazy after all</h2>
<p>So now when I think back to my first job, the way I ended up owning a bespoke
"distributed lock service" built on top of NFS<sup>3</sup> makes much more
sense to me. It makes sense why my predecessor chose to build this instead of
using some simpler, or off-the-shelf solution. When Csikszentmihályi describes
flow state as the “optimal experience”, he's giving us a clue. People probably
aren’t optimizing for making money, or increased feature velocity, or more
reliable software, or better customer experiences, and your employees are
especially not optimizing for shareholder value. People are optimizing for
their <em>own</em> happiness, which often involves finding ways to reach a flow state.
Of course, often we pop out of that state to align our work with the customer,
with making money, or other external factors. Just like whales, we must come up
for air. But people certainly enjoy it more when they get to spend as much time
as possible approaching flow.</p>
<p>Hopefully by now you’re convinced that the flow state, or optimal experience is
a real thing, and that many developers are searching for this state through
coding. Being in a state of flow has the potential to make people both happier,
and more productive. If you’re an employer, it can be a win-win.</p>


<p>But I'm not (currently) an employer. Although I am building some things aimed
at developers.</p>
<h2>Can we design for flow?</h2>
<p>I think the answer is yes. A slightly bolder claim would be that developers
only truly <em>love</em> products that help them reach a state of flow.</p>
<p>There are two extremes from which developers will critizise most products. Some
lucky products manage to get both criticisms at the same time.</p>
<p>The first is if the product is incomplete, too low-level, or difficult to use.
This often results in large amounts of <a href="https://en.wiktionary.org/wiki/Talk:yak_shaving">yak
shaving</a> to get anything
useful done. You can't get into a flow state if you're staring into the
abyss of errors, or constantly having to
<a href="https://en.wikipedia.org/wiki/RTFM">RTFM</a>. Here are some examples of things
that fit into this category, from my personal experience:</p>
<ul>
<li>Configuration languages like CloudFormation, or TerraForm.</li>
<li>Compiling from source (think Linux WiFi and graphics drivers<sup>4</sup>).</li>
<li>Deciding which of the 200+ AWS services are right for my use case.</li>
<li>Programming in assembly (Motorola HC11) at university many years ago.</li>
<li>A certain internal Amazon <a href="https://aws.amazon.com/cdk/">tool</a>, that I can't
  name for fear of breaking my NDA (and also causing PTSD in current and former
  Amazon engineers reading this).</li>
</ul>
<p>The other extreme from which developers will critizise products is being too
high-level, restrictive, or not having enough options. You can't get into that
flow state if you don't get to engage your brain! As an example, the Wikipedia
page for <a href="https://en.wikipedia.org/wiki/Software_framework#Rationale">software
frameworks</a> has
some hilarious "<em>[citation needed]</em>" back-and-forth about the pros-and cons of
frameworks. The interesting thing is that <em>both sides</em> of this debate want to
write lots of code and be productive. They're just looking at it differently.
The <a href="https://www.youtube.com/watch?v=Gzj723LkRJY">OG framework demo</a> was all
about how quickly you could start writing code. Meanwhile opponents of
frameworks say that they spend more time learning how to use the framework than
coding. </p>
<p>Another area where I wonder if the products are too high-level, or restrictive
is the so-called <em>NoCode</em> space.  There are a bevy of well-funded startups,
like AirTable, ReTool, and Webflow that claim to eliminate the need for coding
to build websites. The thing is, I have tried a couple of them, and the UIs
aren't as intuitive as you might hope. I also can't imagine myself achieving a
state of flow with them. I've spent many, many hours in my life writing things
like this blog post, or programming in Java and Python. To me, graphical UIs
don't get you that feeling of <em>building</em> that you get from typing at a command
line, or even typing up a document.</p>
<p>I can imagine people reaching a flow state if they're really proficient users
of, say, Photoshop. But I'm not sure that these NoCode tools encourage the high
level of mastery that a professional photographer, or editor might have. As
such, while they're interesting tools, I struggle to see them catching on in a
way that justifies the kind of valuations that VCs are looking for.  But it's
still early in this space, the jury is still out.  Maybe I'll …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.drgriffin.com.au/posts/2020-07-31-cracking-the-developer-code:-flow.html">https://blog.drgriffin.com.au/posts/2020-07-31-cracking-the-developer-code:-flow.html</a></em></p>]]>
            </description>
            <link>https://blog.drgriffin.com.au/posts/2020-07-31-cracking-the-developer-code:-flow.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24010663</guid>
            <pubDate>Fri, 31 Jul 2020 16:56:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Records and Tuples for React]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24010282">thread link</a>) | @slorber
<br/>
July 31, 2020 | https://sebastienlorber.com/records-and-tuples-for-react | <a href="https://web.archive.org/web/*/https://sebastienlorber.com/records-and-tuples-for-react">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p><strong>Records &amp; Tuples</strong>, a very interesting <a href="https://github.com/tc39/proposal-record-tuple" target="_blank" rel="noreferrer">proposal</a> for the JavaScript language, has just reached <strong><a href="https://twitter.com/robpalmer2/status/1286040041089904640" target="_blank" rel="noreferrer">stage 2</a></strong> at <strong>TC39</strong>.</p><p>A whole category of <strong>React bugs</strong> are related to <strong>unstable object identities</strong>:</p><ul><li><strong>Performance</strong>: can trigger re-renders that could be avoided</li><li><strong>Behavior</strong>: can trigger useless effect re-executions, and lead to infinite loops</li><li><strong>API surface</strong>: we don’t have a way to express when a stable object identity matters</li></ul><p>I will explain the basics of <strong>Records &amp; Tuples</strong>, and how they can solve <strong>real world React issues</strong>.</p><hr><h2 id="records--tuples-101">Records &amp; Tuples 101</h2><p>This article is about Records &amp; Tuples <strong><u>for React</u></strong>. I’ll only cover the basics here.</p><p>They look like regular <strong>Objects and Arrays</strong>, with a <strong>#</strong> prefix.</p><div><pre><p><span>1</span><span>const</span><span> record </span><span>=</span><span> #</span><span>{</span><span>a</span><span>:</span><span> </span><span>1</span><span>,</span><span> b</span><span>:</span><span> </span><span>2</span><span>}</span><span>;</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>const</span><span> updatedRecord </span><span>=</span><span> #</span><span>{</span><span>...</span><span>record</span><span>,</span><span> b</span><span>:</span><span> </span><span>3</span><span>}</span><span>;</span><span></span></p><p><span>4</span><span></span><span></span></p><p><span>5</span><span></span></p><p><span>6</span><span></span><span>const</span><span> tuple </span><span>=</span><span> #</span><span>[</span><span>1</span><span>,</span><span> </span><span>2</span><span>,</span><span> </span><span>3</span><span>,</span><span> </span><span>4</span><span>]</span><span>;</span><span></span></p><p><span>7</span><span></span></p><p><span>8</span><span></span><span>const</span><span> filteredTuple </span><span>=</span><span> tuple</span><span>.</span><span>filter</span><span>(</span><span>num</span><span> </span><span>=&gt;</span><span> num </span><span>&gt;</span><span> </span><span>2</span><span>)</span><span></span></p><p><span>9</span><span></span></p></pre></div><p>They are <strong>deeply immutable</strong> by default.</p><div><pre><p><span>1</span><span>const</span><span> record </span><span>=</span><span> #</span><span>{</span><span>a</span><span>:</span><span> </span><span>1</span><span>,</span><span> b</span><span>:</span><span> </span><span>2</span><span>}</span><span>;</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span>record</span><span>.</span><span>b </span><span>=</span><span> </span><span>3</span><span>;</span><span></span></p><p><span>4</span><span></span></p></pre></div><p>They can be seen as <strong>“compound primitives”</strong>, and can be compared by value.</p><p><strong>VERY IMPORTANT</strong>: two deeply equal records will <strong>ALWAYS</strong> return <code>true</code> with <code>===</code>.</p><div><pre><p><span>1</span><span>{</span><span>a</span><span>:</span><span> </span><span>1</span><span>,</span><span> b</span><span>:</span><span> </span><span>[</span><span>3</span><span>,</span><span> </span><span>4</span><span>]</span><span>}</span><span> </span><span>===</span><span> </span><span>{</span><span>a</span><span>:</span><span> </span><span>1</span><span>,</span><span> b</span><span>:</span><span> </span><span>[</span><span>3</span><span>,</span><span> </span><span>4</span><span>]</span><span>}</span><span></span></p><p><span>2</span><span></span><span></span></p><p><span>3</span><span></span></p><p><span>4</span><span>#</span><span>{</span><span>a</span><span>:</span><span> </span><span>1</span><span>,</span><span> b</span><span>:</span><span> #</span><span>[</span><span>3</span><span>,</span><span> </span><span>4</span><span>]</span><span>}</span><span> </span><span>===</span><span> #</span><span>{</span><span>a</span><span>:</span><span> </span><span>1</span><span>,</span><span> b</span><span>:</span><span> #</span><span>[</span><span>3</span><span>,</span><span> </span><span>4</span><span>]</span><span>}</span><span></span></p><p><span>5</span><span></span></p></pre></div><p>They are interoperable with JSON:</p><div><pre><p><span>1</span><span>const</span><span> record </span><span>=</span><span> </span><span>JSON</span><span>.</span><span>parseImmutable</span><span>(</span><span>'{a: 1, b: [2, 3]}'</span><span>)</span><span>;</span><span></span></p><p><span>2</span><span></span><span></span></p><p><span>3</span><span></span></p><p><span>4</span><span></span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>record</span><span>)</span><span>;</span><span></span></p><p><span>5</span><span></span></p></pre></div><p>They can only contain other records and tuples, or primitive values.</p><div><pre><p><span>1</span><span>const</span><span> record </span><span>=</span><span> #</span><span>{</span><span></span></p><p><span>2</span><span>  a</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>3</span><span>    regular</span><span>:</span><span> </span><span>'object'</span><span>,</span><span></span></p><p><span>4</span><span>  </span><span>}</span><span>,</span><span></span></p><p><span>5</span><span>  b</span><span>:</span><span> </span><span>new</span><span> </span><span>Date</span><span>(</span><span>)</span><span>,</span><span></span></p><p><span>6</span><span>  c</span><span>:</span><span> </span><span>new</span><span> </span><span>MyClass</span><span>(</span><span>)</span><span>,</span><span></span></p><p><span>7</span><span>  </span><span>d</span><span>:</span><span> </span><span>function</span><span> </span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>8</span><span>    </span><span>alert</span><span>(</span><span>'forbidden'</span><span>)</span><span>;</span><span></span></p><p><span>9</span><span>  </span><span>}</span><span>,</span><span></span></p><p><span>10</span><span></span><span>}</span><span>;</span><span></span></p><p><span>11</span><span></span></p></pre></div><p><strong>Note</strong>: you could somehow add such mutable values to a Record by using Symbols as WeakMap keys (<a href="https://github.com/tc39/proposal-symbols-as-weakmap-keys" target="_blank" rel="noreferrer">separate proposal</a>), and <a href="https://github.com/tc39/proposal-record-tuple#could-i-box-a-pointer-to-an-object-and-put-that-in-a-record-or-tuple" target="_blank" rel="noreferrer">reference</a> the symbols in records.</p><p>Want more? Read the <a href="https://github.com/tc39/proposal-record-tuple" target="_blank" rel="noreferrer">proposal</a> directly, or this <a href="https://2ality.com/2020/05/records-tuples-first-look.html" target="_blank" rel="noreferrer">article</a> from Axel Rauschmayer.</p><hr><h2 id="records--tuples-for-react">Records &amp; Tuples for React</h2><p>React developers are now used to <strong>immutability</strong>.</p><p>Every time you update some piece of state in an immutable way, you create <strong>new object identities</strong>.</p><p>Unfortunately, this immutability model has introduced a whole new class of bugs, and performance issues in React applications.
Sometimes, a component works correctly and in a performant way, <strong>only under the assumption that props preserve identities</strong> as most as they can over time.</p><p>I like to think about Records &amp; Tuples as a convenient way to <strong>make object identities more “stable”</strong>.</p><p>Let’s see how this proposal will <strong>impact your React code</strong> with practical use cases.</p><p><strong>Note</strong>: there is a <a href="https://rickbutton.github.io/record-tuple-playground/#eyJjb250ZW50IjoiaW1wb3J0IFJlYWN0IGZyb20gXCJodHRwczovL2Nkbi5za3lwYWNrLmRldi9yZWFjdFwiO1xuaW1wb3J0IFJlYWN0RE9NIGZyb20gXCJodHRwczovL2Nkbi5za3lwYWNrLmRldi9yZWFjdC1kb21cIjtcblxuXG5jb25zdCBIZWxsbyA9ICh7dXNlcn0pID0+IHtcbiAgcmV0dXJuIDxwPkhlbGxvIHt1c2VyLm5hbWV9PC9wPlxufTtcblxuY29uc3QgdXNlciA9ICN7bmFtZTogXCJTZWJhc3RpZW5cIn1cblxuUmVhY3RET00ucmVuZGVyKFxuICAgIDxIZWxsbyB1c2VyPXt1c2VyfS8+LFxuICAgIGRvY3VtZW50LmJvZHksXG4pO1xuXG4iLCJzeW50YXgiOiJoYXNoIiwiZG9tTW9kZSI6dHJ1ZX0=" target="_blank" rel="noreferrer">Records &amp; Tuples playground</a>, that can run React.</p><h3 id="immutability">Immutability</h3><p>Enforcing immutability can be achieved with recursive <code>Object.freeze()</code> calls.</p><p>But in practice, we often use the immutability model without enforcing it too strictly, as it’s not convenient to apply <code>Object.freeze()</code> after each update. Yet, mutating the React state directly is a common mistake for new React developers.</p><p>The Records &amp; Tuples proposal will <strong>enforce immutability</strong>, and prevent common state mutation mistakes:</p><div><pre><p><span>1</span><span>const</span><span> </span><span>Hello</span><span> </span><span>=</span><span> </span><span>(</span><span>{</span><span> profile </span><span>}</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span></span></p><p><span>3</span><span>  profile</span><span>.</span><span>name </span><span>=</span><span> </span><span>'Sebastien updated'</span><span>;</span><span></span></p><p><span>4</span><span></span></p><p><span>5</span><span>  </span><span>return</span><span> </span><span>&lt;</span><span>p</span><span>&gt;</span><span>Hello </span><span>{</span><span>profile</span><span>.</span><span>name</span><span>}</span><span>&lt;/</span><span>p</span><span>&gt;</span><span>;</span><span></span></p><p><span>6</span><span></span><span>}</span><span>;</span><span></span></p><p><span>7</span><span></span></p><p><span>8</span><span></span><span>function</span><span> </span><span>App</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>9</span><span>  </span><span>const</span><span> </span><span>[</span><span>profile</span><span>,</span><span> setProfile</span><span>]</span><span> </span><span>=</span><span> React</span><span>.</span><span>useState</span><span>(</span><span>#</span><span>{</span><span></span></p><p><span>10</span><span>    name</span><span>:</span><span> </span><span>'Sebastien'</span><span>,</span><span></span></p><p><span>11</span><span>  </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>12</span><span></span></p><p><span>13</span><span>  </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>14</span><span>    </span><span></span></p><p><span>15</span><span>    profile</span><span>.</span><span>name </span><span>=</span><span> </span><span>'Sebastien updated'</span><span>;</span><span></span></p><p><span>16</span><span>  </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>17</span><span></span></p><p><span>18</span><span>  </span><span>return</span><span> </span><span>&lt;</span><span>Hello</span><span> </span><span>profile</span><span>=</span><span>{</span><span>profile</span><span>}</span><span> </span><span>/&gt;</span><span>;</span><span></span></p><p><span>19</span><span></span><span>}</span></p></pre></div><h3 id="immutable-updates">Immutable updates</h3><p>There are <a href="https://dev.to/sebastienlorber/insight-3-use-immerjs-over-lodash-set-immutablejs-or-plain-js-36bl" target="_blank" rel="noreferrer">many ways</a> to perform immutable state updates in React: vanilla JS, Lodash set, ImmerJS, ImmutableJS…</p><p>Records &amp; Tuples support the same immutable update patterns that you use with Objects and Arrays:</p><div><pre><p><span>1</span><span>const</span><span> initialState </span><span>=</span><span> #</span><span>{</span><span></span></p><p><span>2</span><span>  user</span><span>:</span><span> #</span><span>{</span><span></span></p><p><span>3</span><span>    firstName</span><span>:</span><span> </span><span>"Sebastien"</span><span>,</span><span></span></p><p><span>4</span><span>    lastName</span><span>:</span><span> </span><span>"Lorber"</span><span></span></p><p><span>5</span><span>  </span><span>}</span><span></span></p><p><span>6</span><span>  company</span><span>:</span><span> #</span><span>{</span><span></span></p><p><span>7</span><span>    name</span><span>:</span><span> </span><span>"Lambda Scale"</span><span>,</span><span></span></p><p><span>8</span><span>  </span><span>}</span><span></span></p><p><span>9</span><span></span><span>}</span><span>;</span><span></span></p><p><span>10</span><span></span></p><p><span>11</span><span></span></p><p><span>12</span><span></span><span>const</span><span> updatedState </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>13</span><span>  </span><span>...</span><span>initialState</span><span>,</span><span></span></p><p><span>14</span><span>  company</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>15</span><span>    </span><span>...</span><span>initialState</span><span>.</span><span>company</span><span>,</span><span></span></p><p><span>16</span><span>    name</span><span>:</span><span> </span><span>'Freelance'</span><span>,</span><span></span></p><p><span>17</span><span>  </span><span>}</span><span>,</span><span></span></p><p><span>18</span><span></span><span>}</span><span>;</span></p></pre></div><p>So far, <a href="https://github.com/immerjs/immer" target="_blank" rel="noreferrer">ImmerJS</a> has won this battle, due to its simplicity to handle nested attributes, and interoperability with regular JS code.</p><p>It is not clear how Immer could work with Records &amp; Tuples yet, but it’s something the proposal authors are exploring.</p><p>Michael Weststrate himself has <a href="https://twitter.com/mweststrate/status/1263482177934819329" target="_blank" rel="noreferrer">highlighted</a> that a <a href="https://github.com/tc39/proposal-deep-path-properties-for-record" target="_blank" rel="noreferrer">separate but related proposal</a> could <strong>make ImmerJS unnecessary for Records &amp; Tuples</strong>:</p><div><pre><p><span>1</span><span>const</span><span> initialState </span><span>=</span><span> #</span><span>{</span><span></span></p><p><span>2</span><span>  counters</span><span>:</span><span> #</span><span>[</span><span></span></p><p><span>3</span><span>    #</span><span>{</span><span> name</span><span>:</span><span> </span><span>"Counter 1"</span><span>,</span><span> value</span><span>:</span><span> </span><span>1</span><span> </span><span>}</span><span>,</span><span></span></p><p><span>4</span><span>    #</span><span>{</span><span> name</span><span>:</span><span> </span><span>"Counter 2"</span><span>,</span><span> value</span><span>:</span><span> </span><span>0</span><span> </span><span>}</span><span>,</span><span></span></p><p><span>5</span><span>    #</span><span>{</span><span> name</span><span>:</span><span> </span><span>"Counter 3"</span><span>,</span><span> value</span><span>:</span><span> </span><span>123</span><span> </span><span>}</span><span>,</span><span></span></p><p><span>6</span><span>  </span><span>]</span><span>,</span><span></span></p><p><span>7</span><span>  metadata</span><span>:</span><span> #</span><span>{</span><span></span></p><p><span>8</span><span>    lastUpdate</span><span>:</span><span> </span><span>1584382969000</span><span>,</span><span></span></p><p><span>9</span><span>  </span><span>}</span><span>,</span><span></span></p><p><span>10</span><span></span><span>}</span><span>;</span><span></span></p><p><span>11</span><span></span></p><p><span>12</span><span></span></p><p><span>13</span><span></span><span></span></p><p><span>14</span><span></span><span></span></p><p><span>15</span><span></span><span>const</span><span> updatedStateNative </span><span>=</span><span> #</span><span>{</span><span></span></p><p><span>16</span><span>  </span><span>...</span><span>initialState</span><span>,</span><span></span></p><p><span>17</span><span>  counters</span><span>[</span><span>0</span><span>]</span><span>.</span><span>value</span><span>:</span><span> </span><span>2</span><span>,</span><span></span></p><p><span>18</span><span>  counters</span><span>[</span><span>1</span><span>]</span><span>.</span><span>value</span><span>:</span><span> </span><span>1</span><span>,</span><span></span></p><p><span>19</span><span>  metadata</span><span>.</span><span>lastUpdate</span><span>:</span><span> </span><span>1584383011300</span><span>,</span><span></span></p><p><span>20</span><span></span><span>}</span><span>;</span></p></pre></div><h3 id="usememo">useMemo</h3><p>In addition to memoizing expensive computations, <code>useMemo()</code> is also useful to <strong>avoid creating new object identities</strong>, that might <strong>trigger useless computations, re-renders, or effects executions deeper in the tree</strong>.</p><p>Let’s consider the following use-case: you have an UI with multiple filters, and want to fetch some data from the backend.</p><p>Existing React code-bases might contain code such as:</p><div><pre><p><span>1</span><span></span></p><p><span>2</span><span></span><span></span></p><p><span>3</span><span></span><span></span></p><p><span>4</span><span></span><span></span></p><p><span>5</span><span></span><span>const</span><span> apiFilters </span><span>=</span><span> </span><span>useMemo</span><span>(</span><span></span></p><p><span>6</span><span>  </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>(</span><span>{</span><span> userFilter</span><span>,</span><span> companyFilter </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span>7</span><span>  </span><span>[</span><span>userFilter</span><span>,</span><span> companyFilter</span><span>]</span><span>,</span><span></span></p><p><span>8</span><span></span><span>)</span><span>;</span><span></span></p><p><span>9</span><span></span></p><p><span>10</span><span></span><span>const</span><span> </span><span>{</span><span> apiData</span><span>,</span><span> loading </span><span>}</span><span> </span><span>=</span><span> </span><span>useApiData</span><span>(</span><span>apiFilters</span><span>)</span><span>;</span></p></pre></div><p>With Records &amp; Tuples, this simply becomes:</p><div><pre><p><span>1</span><span>const</span><span> </span><span>{</span><span>apiData</span><span>,</span><span>loading</span><span>}</span><span> </span><span>=</span><span> </span><span>useApiData</span><span>(</span><span>#</span><span>{</span><span> userFilter</span><span>,</span><span> companyFilter </span><span>}</span><span>)</span></p></pre></div><h3 id="useeffect">useEffect</h3><p>Let’s continue with our api filters use-case:</p><div><pre><p><span>1</span><span>const</span><span> apiFilters </span><span>=</span><span> </span><span>{</span><span> userFilter</span><span>,</span><span> companyFilter </span><span>}</span><span>;</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>  </span><span>fetchApiData</span><span>(</span><span>apiFilters</span><span>)</span><span>.</span><span>then</span><span>(</span><span>setApiDataInState</span><span>)</span><span>;</span><span></span></p><p><span>5</span><span></span><span>}</span><span>,</span><span> </span><span>[</span><span>apiFilters</span><span>]</span><span>)</span><span>;</span></p></pre></div><p>Unfortunately, the fetch effect gets <strong>re-executed</strong>, because the identity of the <code>apiFilters</code> object changes every time this component re-renders. <code>setApiDataInState</code> will trigger a re-render, and you will end up with an infinite fetch/render loop.</p><p>This mistake is so common across React developers that there are thousand of Google search results for <strong><a href="https://www.google.com/search?q=useEffect+%2B+%22infinite+loop%22" target="_blank" rel="noreferrer">useEffect + “infinite loop”</a></strong>.
Kent C Dodds even created <a href="https://github.com/kentcdodds/stop-runaway-react-effects" target="_blank" rel="noreferrer">a tool</a> to break such infinite loops in development.</p><p>Very common solution: create <code>apiFilters</code> directly in the effect’s callback:</p><div><pre><p><span>1</span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>const</span><span> apiFilters </span><span>=</span><span> </span><span>{</span><span> userFilter</span><span>,</span><span> companyFilter </span><span>}</span><span>;</span><span></span></p><p><span>3</span><span>  </span><span>fetchApiData</span><span>(</span><span>apiFilters</span><span>)</span><span>.</span><span>then</span><span>(</span><span>setApiDataInState</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span></span><span>}</span><span>,</span><span> </span><span>[</span><span>userFilter</span><span>,</span><span> companyFilter</span><span>]</span><span>)</span><span>;</span></p></pre></div><p>Another creative solution (not very performant, found on <a href="https://twitter.com/acutmore/status/1256533631914426369" target="_blank" rel="noreferrer">Twitter</a>):</p><div><pre><p><span>1</span><span>const</span><span> apiFiltersString </span><span>=</span><span> </span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span></span></p><p><span>2</span><span>  userFilter</span><span>,</span><span></span></p><p><span>3</span><span>  companyFilter</span><span>,</span><span></span></p><p><span>4</span><span></span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>5</span><span></span></p><p><span>6</span><span></span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>7</span><span>  </span><span>fetchApiData</span><span>(</span><span>JSON</span><span>.</span><span>parse</span><span>(</span><span>apiFiltersString</span><span>)</span><span>)</span><span>.</span><span>then</span><span>(</span><span></span></p><p><span>8</span><span>    setApiDataInState</span><span>,</span><span></span></p><p><span>9</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>10</span><span></span><span>}</span><span>,</span><span> </span><span>[</span><span>apiFiltersString</span><span>]</span><span>)</span><span>;</span></p></pre></div><p>The one I like the most:</p><div><pre><p><span>1</span><span></span></p><p><span>2</span><span></span><span>const</span><span> apiFilters </span><span>=</span><span> </span><span>useMemo</span><span>(</span><span></span></p><p><span>3</span><span>  </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>(</span><span>{</span><span> userFilter</span><span>,</span><span> companyFilter </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span>4</span><span>  </span><span>[</span><span>userFilter</span><span>,</span><span> companyFilter</span><span>]</span><span>,</span><span></span></p><p><span>5</span><span></span><span>)</span><span>;</span><span></span></p><p><span>6</span><span></span></p><p><span>7</span><span></span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>8</span><span>  </span><span>fetchApiData</span><span>(</span><span>apiFilters</span><span>)</span><span>.</span><span>then</span><span>(</span><span>setApiDataInState</span><span>)</span><span>;</span><span></span></p><p><span>9</span><span></span><span>}</span><span>,</span><span> </span><span>[</span><span>apiFilters</span><span>]</span><span>)</span><span>;</span></p></pre></div><p>There are many fancy ways to solve this problem, but they all tend to <strong>become annoying</strong>, as the number of filters increase.</p><p>They are much <strong>more verbose and less idiomatic</strong> than their Records &amp; Tuples counterpart:</p><div><pre><p><span>1</span><span>const</span><span> apiFilters </span><span>=</span><span> #</span><span>{</span><span> userFilter</span><span>,</span><span> companyFilter </span><span>}</span><span>;</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>  </span><span>fetchApiData</span><span>(</span><span>apiFilters</span><span>)</span><span>.</span><span>then</span><span>(</span><span>setApiDataInState</span><span>)</span><span>;</span><span></span></p><p><span>5</span><span></span><span>}</span><span>,</span><span> </span><span>[</span><span>apiFilters</span><span>]</span><span>)</span><span>;</span></p></pre></div><h3 id="props-and-reactmemo">Props and React.memo</h3><p>Preserving object identities in props is also very useful for React performances.</p><p>Another very common performance mistake: create new objects identities in render.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>Parent</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>useRerenderEverySeconds</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>3</span><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>4</span><span>    </span><span>&lt;</span><span>ExpensiveChild</span></p><p><span>5</span><span>      </span><span></span></p><p><span>6</span><span>      someData</span><span>=</span><span>{</span><span>{</span><span> attr1</span><span>:</span><span> </span><span>'abc'</span><span>,</span><span> attr2</span><span>:</span><span> </span><span>'def'</span><span> </span><span>}</span><span>}</span><span></span></p><p><span>7</span><span>    </span><span>/</span><span>&gt;</span><span></span></p><p><span>8</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>9</span><span></span><span>}</span><span>;</span><span></span></p><p><span>10</span><span></span></p><p><span>11</span><span></span><span>const</span><span> ExpensiveChild </span><span>=</span><span> React</span><span>.</span><span>memo</span><span>(</span><span>(</span><span>{</span><span> someData </span><span>}</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>12</span><span>  </span><span>return</span><span> </span><span>&lt;</span><span>div</span><span>&gt;</span><span>{</span><span>expensiveRender</span><span>(</span><span>someData</span><span>)</span><span>}</span><span>&lt;/</span><span>div</span><span>&gt;</span><span>;</span><span></span></p><p><span>13</span><span></span><span>}</span><span>)</span><span>;</span></p></pre></div><p>Most of the time, this is not a problem, and React is fast enough.</p><p>But sometimes you are looking to optimize your app, and this new object creation makes the <code>React.memo()</code> useless. Worst, it actually <strong>makes your application a little bit slower</strong> (as it now has to run an additional shallow equality check, always returning false).</p><p>Another pattern I often see in client code-bases:</p><div><pre><p><span>1</span><span>const</span><span> currentUser </span><span>=</span><span> </span><span>{</span><span> name</span><span>:</span><span> </span><span>'Sebastien'</span><span> </span><span>}</span><span>;</span><span></span></p><p><span>2</span><span></span><span>const</span><span> currentCompany </span><span>=</span><span> </span><span>{</span><span> name</span><span>:</span><span> </span><span>'Lambda Scale'</span><span> </span><span>}</span><span>;</span><span></span></p><p><span>3</span><span></span></p><p><span>4</span><span></span><span>const</span><span> </span><span>AppProvider</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>5</span><span>  </span><span>useRerenderEverySeconds</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>6</span><span></span></p><p><span>7</span><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>8</span><span>    </span><span>&lt;</span><span>MyAppContext.Provider</span><span></span></p><p><span>9</span><span>      </span><span>value</span><span>=</span><span>{</span><span>{</span><span> currentUser</span><span>,</span><span> currentCompany </span><span>}</span><span>}</span><span></span></p><p><span>10</span><span>    </span><span>/&gt;</span><span></span></p><p><span>11</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>12</span><span></span><span>}</span><span>;</span></p></pre></div><p>Despite the fact that <code>currentUser</code> or <code>currentCompany</code> <strong>never gets updated</strong>, your context value changes every time this provider re-renders, which trigger re-renders of all context subscribers.</p><p>All these issues can be solved with memoization:</p><div><pre><p><span>1</span><span>const</span><span> someData </span><span>=</span><span> </span><span>useMemo</span><span>(</span><span></span></p><p><span>2</span><span>  </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>(</span><span>{</span><span> attr1</span><span>:</span><span> </span><span>'abc'</span><span>,</span><span> attr2</span><span>:</span><span> </span><span>'def'</span><span> </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span>3</span><span>  </span><span>[</span><span>]</span><span>,</span><span></span></p><p><span>4</span><span></span><span>)</span><span>;</span><span></span></p><p><span>5</span><span></span></p><p><span>6</span><span></span><span>&lt;</span><span>ExpensiveChild</span><span> </span><span>someData</span><span>=</span><span>{</span><span>someData</span><span>}</span><span> </span><span>/&gt;</span><span>;</span></p></pre></div><div><pre><p><span>1</span><span>const</span><span> contextValue </span><span>=</span><span> </span><span>useMemo</span><span>(</span><span></span></p><p><span>2</span><span>  </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>(</span><span>{</span><span> currentUser</span><span>,</span><span> currentCompany </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span>3</span><span>  </span><span>[</span><span>currentUser</span><span>,</span><span> currentCompany</span><span>]</span><span>,</span><span></span></p><p><span>4</span><span></span><span>)</span><span>;</span><span></span></p><p><span>5</span><span></span></p><p><span>6</span><span></span><span>&lt;</span><span>MyAppContext.Provider</span><span> </span><span>value</span><span>=</span><span>{</span><span>contextValue</span><span>}</span><span> </span><span>/&gt;</span><span>;</span></p></pre></div><p>With Records &amp; Tuples, it is <strong>idiomatic to write performant code</strong>:</p><div><pre><p><span>1</span><span>&lt;</span><span>ExpensiveChild</span><span> </span><span>someData</span><span>=</span><span>{</span><span>#</span><span>{</span><span> attr1</span><span>:</span><span> </span><span>'abc'</span><span>,</span><span> attr2</span><span>:</span><span> </span><span>'def'</span><span> </span><span>}</span><span>}</span><span> </span><span>/&gt;</span><span>;</span></p></pre></div><div><pre><p><span>1</span><span>&lt;</span><span>MyAppContext.Provider</span><span> </span><span>value</span><span>=</span><span>{</span><span>#</span><span>{</span><span> currentUser</span><span>,</span><span> currentCompany </span><span>}</span><span>}</span><span> </span><span>/&gt;</span><span>;</span></p></pre></div><h3 id="fetching-and-re-fetching">Fetching and re-fetching</h3><p>There are many ways to fetch data in React: <code>useEffect</code>, HOC, Render props, Redux, SWR, React-Query, Apollo, Relay, Urql, …</p><p>Most often, we hit the backend with a request, and get some JSON data back.</p><p>To illustrate this section, I will use <a href="https://github.com/slorber/react-async-hook" target="_blank" rel="noreferrer">react-async-hook</a>, my own very simple fetching library, but this applies to other libraries as well.</p><p>Let’s consider a classic async function to get some API data:</p><div><pre><p><span>1</span><span>const</span><span> </span><span>fetchUserAndCompany</span><span> </span><span>=</span><span> </span><span>async</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>const</span><span> response </span><span>=</span><span> </span><span>await</span><span> </span><span>fetch</span><span>(</span><span></span></p><p><span>3</span><span>    </span><span>`https://myBackend.com/userAndCompany`</span><span>,</span><span></span></p><p><span>4</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>5</span><span>  </span><span>return</span><span> response</span><span>.</span><span>json</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>6</span><span></span><span>}</span><span>;</span></p></pre></div><p>This app fetches the data, and ensure this data stays “fresh” (non-stale) over time:</p><div><pre><p><span>1</span><span>const</span><span> </span><span>App</span><span> </span><span>=</span><span> </span><span>(</span><span>{</span><span> id </span><span>}</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>const</span><span> </span><span>{</span><span> result</span><span>,</span><span> refetch </span><span>}</span><span> </span><span>=</span><span> </span><span>useAsync</span><span>(</span><span></span></p><p><span>3</span><span>    fetchUserAndCompany</span><span>,</span><span></span></p><p><span>4</span><span>    </span><span>[</span><span>]</span><span>,</span><span></span></p><p><span>5</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>6</span><span></span></p><p><span>7</span><span>  </span><span></span></p><p><span>8</span><span>  </span><span>useInterval</span><span>(</span><span>refetch</span><span>,</span><span> </span><span>10000</span><span>)</span><span>;</span><span></span></p><p><span>9</span><span>  </span><span>useOnReconnect</span><span>(</span><span>refetch</span><span>)</span><span>;</span><span></span></p><p><span>10</span><span>  </span><span>useOnNavigate</span><span>(</span><span>refetch</span><span>)</span><span>;</span><span></span></p><p><span>11</span><span></span></p><p><span>12</span><span>  </span><span>if</span><span> </span><span>(</span><span>!</span><span>result</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>13</span><span>    </span><span>return</span><span> </span><span>null</span><span>;</span><span></span></p><p><span>14</span><span>  </span><span>}</span><span></span></p><p><span>15</span><span></span></p><p><span>16</span><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>17</span><span>    </span><span>&lt;</span><span>div</span><span>&gt;</span><span></span></p><p><span>18</span><span>      </span><span>&lt;</span><span>User</span><span> </span><span>user</span><span>=</span><span>{</span><span>result</span><span>.</span><span>user</span><span>}</span><span> </span><span>/&gt;</span><span></span></p><p><span>19</span><span>      </span><span>&lt;</span><span>Company</span><span> </span><span>company</span><span>=</span><span>{</span><span>result</span><span>.</span><span>company</span><span>}</span><span> </span><span>/&gt;</span><span></span></p><p><span>20</span><span>    </span><span>&lt;/</span><span>div</span><span>&gt;</span><span></span></p><p><span>21</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>22</span><span></span><span>}</span><span>;</span><span></span></p><p><span>23</span><span></span></p><p><span>24</span><span></span><span>const</span><span> User </span><span>=</span><span> React</span><span>.</span><span>memo</span><span>(</span><span>(</span><span>{</span><span> user </span><span>}</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>25</span><span>  </span><span>return</span><span> </span><span>&lt;</span><span>div</span><span>&gt;</span><span>{</span><span>user</span><span>.</span><span>name</span><span>}</span><span>&lt;/</span><span>div</span><span>&gt;</span><span>;</span><span></span></p><p><span>26</span><span></span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>27</span><span></span></p><p><span>28</span><span></span><span>const</span><span> Company </span><span>=</span><span> React</span><span>.</span><span>memo</span><span>(</span><span>(</span><span>{</span><span> company </span><span>}</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>29</span><span>  </span><span>return</span><span> </span><span>&lt;</span><span>div</span><span>&gt;</span><span>{</span><span>company</span><span>.</span><span>name</span><span>}</span><span>&lt;/</span><span>div</span><span>&gt;</span><span>;</span><span></span></p><p><span>30</span><span></span><span>}</span><span>)</span><span>;</span></p></pre></div><p>Problem: you have used <code>React.memo</code> for performance reasons, but every time the re-fetch happens, you end up with a new JS object, with a <strong>new identity</strong>, and <strong>everything re-renders</strong>, despite the fetched data being the <strong>same as before</strong> (deeply equal payloads).</p><p>Let’s imagine this scenario:</p><ul><li>you use …</li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sebastienlorber.com/records-and-tuples-for-react">https://sebastienlorber.com/records-and-tuples-for-react</a></em></p>]]>
            </description>
            <link>https://sebastienlorber.com/records-and-tuples-for-react</link>
            <guid isPermaLink="false">hacker-news-small-sites-24010282</guid>
            <pubDate>Fri, 31 Jul 2020 16:23:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Should web apps use PAKEs?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24009979">thread link</a>) | @arkadiyt
<br/>
July 31, 2020 | https://emilymstark.com/2020/07/30/should-web-apps-use-pakes.html | <a href="https://web.archive.org/web/*/https://emilymstark.com/2020/07/30/should-web-apps-use-pakes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>My colleague
<a href="https://twitter.com/jyasskin/status/1288308864786419713">Jeffrey Yasskin</a>
asked an interesting question on Twitter:</p>

<figure>
  <img src="https://emilymstark.com/assets/jyasskin_pake_tweet.png" alt="Tweet asking why we advise developers to use password hashing functions instead of PAKEs to check the password without sending it">
  <figcaption><i></i></figcaption>
</figure>

<p>Jeffrey is referring to Password Authenticated Key Exchange (PAKE) protocols.
PAKEs allow two parties to negotiate a cryptographic key based on a password,
which might be known by one or both of the parties. When people talk about using
PAKEs in the web setting, however, they usually aren’t directly interested in
negotiating a cryptographic key. Instead, they’re interested in using a PAKE to
authenticate a user, and they’re specifically interested in PAKEs because some
PAKEs allow a client to prove to a server that the client knows the correct
password without revealing the password to the server. In contrast, when using
traditional password-based authentication, the client sends the password to the
server, and the server compares it with a value stored in its database
(hopefully hashed with a strong password hashing function).</p>

<p>Not sending the password to a server is appealing for two reasons:</p>
<ul>
  <li>The server can’t leak the password if it never sees the password. In
traditional password-based authentication, we partially mitigate this risk by
hashing the password when it’s stored in a database, so that a database breach
won’t leak the password. Some developers worry about leaking passwords before
they reach the database – for example, passwords might get accidentally
written to frontend log files that get leaked – and using a PAKE could
mitigate this risk.</li>
  <li>A malicious server can’t steal the password if it never sees the password.
However, this goal is irrelevant to Jeffrey’s question about web apps
implementing PAKEs. The web server provides the JavaScript code that
implements the PAKE, so a malicious server could just steal the password
directly on the client. (However, it is interesting to think about how the
browser itself might intervene to stop malicious servers from obtaining the
password; see <a href="#browser-mediated-pakes">Browser-mediated PAKEs</a> below.)</li>
</ul>

<p>If web apps were to use PAKEs, the security gain would be via the first
property: the server can’t leak the password. My position is that PAKEs provide
a very marginal security gain in the web app setting (funnily enough, many years
ago I was to <a href="https://twitter.com/estark37/status/1288319710744834049">blame</a>
for exorcising one of the few PAKE implementations on the web), but to argue
that position coherently, I first need to discuss why web developers care about
leaking passwords in the first place.</p>



<p>I’m not talking about <em>how</em> we hash passwords – e.g., which password hashing
function to use, how many rounds, etc. I’m talking about a much more basic
question: why do we bother hashing passwords rather than just sticking them in
the database like other data? (Sidenote: I think this would make a great warm-up
interview question for a security engineer… of course now that I’m blogging
about, I won’t be able to use it.)</p>

<p>At first glance, it might seem obvious that websites hash passwords so that a
database breach doesn’t yield long-term access to all the site’s users’
accounts. But, if an attacker gains read access to a website’s database, the
attacker can likely leak session cookies or other bearer tokens as well as all
the other sensitive user data that the website handles. The main reason we hash
passwords is to mitigate users’ tendency to reuse passwords across different
services (in other words, to protect against
<a href="https://en.wikipedia.org/wiki/Credential_stuffing">credential stuffing attacks</a>
in which a leaked password at one service is reused at another). If a website’s
database gets breached, it is a catastrophic security incident for that website
regardless of whether the attacker leaks plaintext passwords or other data. But
if the attacker leaks plaintext passwords, the breach is also a catastrophic
security incident for other websites. The value of hashing passwords is to
prevent a security incident at one service from spreading laterally across huge
swaths of the web.</p>



<p>That’s why my answer to Jeffrey’s question was that, in the web setting, PAKEs
don’t buy you much that client-side password hashing doesn’t also buy you (and
client-side password hashing is much simpler). Both protect against credential
stuffing attacks in the event of any server data leak, which, as I argued above,
is the main threat that password protections aim to mitigate. A PAKE is stronger
in that it prevents a server data leak from yielding long-term access to users’
accounts. In contrast, leaked client-side-hashed passwords do give the attacker
access to users’ accounts on that service, because the hashed password
effectively is the password. But I just don’t find that very compelling in light
of all the other interesting data (session cookies, sensitive user data, etc.)
that an attacker would be able to access with a server data leak.</p>

<p>This is not to say that I recommend client-side password hashing – just that
any web developer considering implementing a PAKE should take a close look at
their threat model and consider if client-side hashing is a much simpler way to
get what they want. Personally I’d recommend that web developers focus their
cycles on moving users towards stronger auth in the form of
<a href="https://webauthn.io/">WebAuthn</a>, rather than investing in either a PAKE or
client-side password hashing.</p>



<p>Reasonable people can disagree on the answer to Jeffrey’s question, and another
reasonable answer might be “historical accident.” PAKEs were patent-encumbered
for some period of time, and some had <a href="https://blog.cryptographyengineering.com/should-you-use-srp/">less than ideal security
properties</a>.
Furthermore, until the
<a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Crypto_API">WebCrypto</a> API
came along and offered native implementations of cryptographic algorithms to
JavaScript, implementing a PAKE would have involved hand-rolling cryptographic
primitives in a slow language that isn’t particularly well-suited to it. So it
could be that the advice to use a strong password hashing function took root in
the web developer community and wasn’t easy to overturn once
<a href="https://eprint.iacr.org/2018/163.pdf">stronger PAKEs</a> and native crypto
implementations came along.</p>



<p>PAKEs don’t provide protection against malicious servers in the web setting,
because a malicious server could serve evil JavaScript that reads the plaintext
password off the page as the user is typing it. This problem invites an
alternative design to implementing a PAKE in JavaScript. What if the PAKE was
implemented in the browser itself and exposed via JavaScript API, with
trustworthy browser UI collecting the password from the user so that malicious
JavaScript can’t steal it?</p>

<p>At first glance, a browser-mediated PAKE appears to be a powerful anti-phishing
tool as well as a protection against server data leaks. But there are some
problems with this idea:</p>

<ul>
  <li>It poses a usable security and ecosystem challenge. The vast majority of
websites would have to migrate to the browser-mediated PAKE in order for users
to get out of the habit of typing passwords directly into webpages. Otherwise,
users wouldn’t notice anything amiss as they type their password directly into
a phishing webpage, even if the victim website used the browser-mediated PAKE.
Even if all websites magically migrated away from plaintext passwords to a
browser-mediated PAKE, a phishing website could likely convincingly spoof the
browser password entry UI to trick the user into typing the password into the
page, where it is accessible to JavaScript.</li>
  <li>Historically, browser-mediated authentication hasn’t seen widespread adoption
on the consumer web. Browser developers tend to view
<a href="https://en.wikipedia.org/wiki/Basic_access_authentication">HTTP Basic Auth</a>
as legacy cruft that we’re stuck with due to entrenchment in enterprises. The
<a href="https://developer.mozilla.org/en-US/docs/Web/API/Credential_Management_API">Credential Management API</a>
was a more recent attempt, and not many websites use it. I’m not sure why this
is<sup id="fnref:1"><a href="#fn:1">1</a></sup>, but one hypothesis is that web developers don’t like to have the
browser mediate user authentication and prefer to integrate it into the look
and feel of their website. <a href="https://github.com/WICG/WebID">WebID</a> is a
brand-new attempt aimed at moving federated login into the browser to prevent
cross-site tracking, so it will be interesting to see if and how that gains
adoption.</li>
  <li>If we could solve these usable security challenges, particularly the challenge
of training users to not type passwords directly into webpages, then browsers
could defend against phishing with much simpler means, e.g. by getting users
to log in to websites exclusively using a password manager that refuses to
fill credentials on the wrong sites. The marginal value of adopting PAKEs then
reduces to the same question I discussed above: is the complexity of a PAKE
worth the benefits in the event of a server data leak when you consider all
the other sensitive data that could be leaked?</li>
</ul>

<p>One final approach I’ll mention: TLS includes
<a href="https://tools.ietf.org/html/draft-barnes-tls-pake-04">PAKE ciphersuites</a>.
One could imagine browsers using this feature as a way of implementing a
browser-mediated PAKE. I think this is unlikely to achieve widespread adoption
in browsers and web servers, or solve any of the security problems I’ve
discussed. It suffers from all the usability and adoption challenges I just
mentioned, plus it’s implemented at the wrong layer for web applications:
TLS-terminating frontends don’t typically know about application authentication
state. Similarly, TLS client certificates aren’t widely used outside of
enterprises (though client certs suffer from other problems that further inhibit
their adoption). I think TLS PAKE ciphersuites are probably designed for
non-browser use cases.</p>

<p>Overall, one can construct various theories as to why web apps don’t implement
PAKEs, but my personal theory is that the marginal security gain is just not
worth the effort and complexity, and I predict that we won’t see widespread PAKE
adoption on the web.</p>

<p><small><em>Many thanks to Zakir Durumeric, Chris Palmer, and Mike West for their
feedback on this post.</em></small></p>



  </div></div>]]>
            </description>
            <link>https://emilymstark.com/2020/07/30/should-web-apps-use-pakes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24009979</guid>
            <pubDate>Fri, 31 Jul 2020 15:57:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remotely working: All remote or all office. Hybrids are problematic]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24009592">thread link</a>) | @snird
<br/>
July 31, 2020 | https://snir.dev/blog/remotely/all-remote-or-all-office/ | <a href="https://web.archive.org/web/*/https://snir.dev/blog/remotely/all-remote-or-all-office/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Remote work isn't harder than working in the office, It’s actually easier. The transition is difficult. Changing all the patterns you are used to from the office as an employee/manager is never easy. </p> <p>When I moved a startup to be completely remote as its CTO in 2015 I discovered the hard way that I had to change how I personally communicate and how the team communicates. I had to adopt new ways of team bonding, conveying company culture, etc. </p> <p>For remote work to be effective every aspect had to be fundamentally different. One example is the need for <a href="https://snir.dev/blog/remote-async-communication">written async communication</a> which I wrote an extensive essay about. </p>  <p>When I tell people remote will work much better if everyone is remote, I get called dogmatic. “It’s not all black and white”. I’m sure some companies will be able to roll out hybrid models, but they need to know what they lose. </p> <p>Remote work practices are so fundamentally different from the office, that using a hybrid model of some people remote some are in the office will eventually lead to 2 separate companies within the company. </p> <p>The remote company communicates through written communication, so their work is transparent and easily accessible to everyone. The office company relies on meetings and in-person talk, so their work is inaccessible and making the remote employees left out. </p> <p>The remote company relies on online activities to get to know and trust each other, which the office people can take a part of too. The office people in the meantime sit down for a beer only with other office people. </p> <p>Those who claim remote work will stifle your progress as an employee, usually refer to this kind of hybrid company. And rightfully so, you will usually be at a political disadvantage to those working in the office. </p> <p>In a remote company that takes remote seriously, and manage remote as an important part of the company, this is not an issue.</p>  <p>If a company wants the benefits of remote work it has to truly commit it. Don’t leave anyone behind. One way around it that seems to work well enough though, is logical separation by departments. </p> <p>For example - having all the R&amp;D working remotely, and all the sales in office. This still works as it does not stifle the progress of someone within his department and unify the communication methods within each department. </p> <hr> <p>There’s a lot more to be said on the topic and the implementation details. But I think this clears out most of the recent criticism for remote work I saw that is actually criticizing the hybrid model. </p> <form action="https://snir.substack.com/api/v1/free?nojs=true" method="post" min-width="400 500 600 700 800"> <div data-style="minimal">  <ul data-element="errors" data-group="alert"></ul>  <p>I wont send you spam. Unsubscribe at any time.</p></div></form></article></div>]]>
            </description>
            <link>https://snir.dev/blog/remotely/all-remote-or-all-office/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24009592</guid>
            <pubDate>Fri, 31 Jul 2020 15:28:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Public-Key Cryptosystems and Digital Signatures]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24009587">thread link</a>) | @keyboardman
<br/>
July 31, 2020 | https://leimao.github.io/blog/Public-Key-Cryptosystem-and-Digital-Signature/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Public-Key-Cryptosystem-and-Digital-Signature/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Sometimes I would get some interesting questions from my friends about internet security, such as whether it is possible to leak the bank account password when logging to the online bank via an untrusted network, whether it is possible that the message you received from someone via an untrusted network got modified maliciously, and whether it is possible that someone pretends to be you and send messages in your name. My answers to those questions are as long as your computer and cell phone are uncontaminated they are almost impossible thanks to our modern public-key crytosystems and digital signatures.</p>



<p>There are a couple of introductions to the public-key crystosystems and digital signature available online. However, I think most of them are incomplete or hard to understand. In this blog post, I am going to describe the public-key crystosystems and digital signatures using extremely simple math, so that there would be no ambiguity at all.</p>

<h3 id="usages">Usages</h3>

<p>The modern cryptosystems are public-key encryption systems in which everyone has a public-key for encryption and a private key for decryption. The public-key is seen by everyone, but the private is only accessible by the owner. The public-key encryption systems could also generate digital signatures which could be used to verify whether the message you received is unmodified and truly sent from the sender.</p>



<p>RSA (Rivest–Shamir–Adleman) is a typical algorithm for the public-key cryptosystems used by modern computers to encrypt and decrypt messages. However, we are not going to introduce the RSA algorithm in this blog post. Instead, we would describe the public-key cryptosystems and digital signatures at a high level.</p>

<h3 id="essential-features">Essential Features</h3>

<p>Each user has their own encryption and decryption functions, $E$ and $D$, using public-key and private key respectively. We use $M$ to represent the message to be encrypted and sent. There are four features that are essential to a public-key cryptosystem.</p>

<ul>
  <li>Decrypting an encrypted message gives you the original message (Of course!). Specifically,</li>
</ul>



<ul>
  <li>Encrypting a decrypted message gives you the original message (Hmm…). Specifically,</li>
</ul>



<ul>
  <li>
    <p>$E$ and $D$ are easy to compute. This means the encryption and decryption process should be fast.</p>
  </li>
  <li>
    <p>The publicity of $E$ does not compromise the secrecy of $D$. This means you could hardly find a way to decrypt the encrypted message, even if you know how to encrypt the message.</p>
  </li>
</ul>

<p>We would ignore how to satisfy the four features in this blog post.</p>

<h3 id="message-encryption-and-decryption">Message Encryption and Decryption</h3>

<p>Suppose we have two people, Alice and Bob. Both of them are using the same public-key cryptosystems. This means Alice and Bob both have their private keys stored secretly and have their public key published to some authorities. From the authorities, we could find the public keys of Alice and Bob unambiguously. We denote encrypting the message using Alice and Bob’s public keys to be $E_A$ and $E_B$ respectively, and decrypting the message using Alice and Bob’s private keys to be $D_A$ and $D_B$ respectively.</p>



<p>One day, Alice wanted to send a private message $M$ to Bob. Alice found the public key of Bob, encrypted the message $M$ using Bob’s public key. The encrypted message for Bob is denoted as $C$.</p>



<p>Once Bob received the encrypted message $C$, he could decrypt $C$ using his private key.</p>



<p>Even if the network was compromised and someone intercepted $C$, it is still almost impossible to decrypt $C$ because of that $D_B$ is unknown and the feature “the publicity of $E$ does not compromise the secrecy of $D$” for public-key cryptosystems.</p>



<p>The message content is safe because of the public-key encryption systems. However, it does not provide any assurance about the sender. For example, James could send Bob a message $M^\prime$ which specifically says the message is from Alice, encrypt it using $E_B$, and send it to Bob. If there is no author verification procedure and Bob is not careful enough, Bob might actually think the message is sent from Alice. In some other scenarios, James might have intercepted the encrypted message $C$ sent out from Alice to Bob, prevented the message transmission to Bob, replaced the original message to $M^\prime$ which specifically says the message is from Alice, encrypt it using $E_B$, and send it to Bob. Bob might also be convinced that the message content $M^\prime$ was actually the original message Alice has sent. Specifically,</p>



<p>Digital signatures, derived from the public-key cryptosystems, are designed to solve these authentication problems.</p>

<h3 id="digital-signatures">Digital Signatures</h3>

<p>In addition to the encrypted message $C$ that Alice sent to Bob, Alice would also have to send her digital signature $S$ to Bob. Namely,</p>



<p>Alice could find $E_B$ using Bob’s public key and $D_A$ using her private key.</p>



<p>Once Bob received both $S$ and $C$, he could decrypt both $S$ and $C$ using his private key and Alice’s public key. Specially,</p>



<p>We found actually the two decrypted messages from $S$ and $C$ are exactly the same. This is expected if the message was sent from Alice and the content of the message was not modified. Let’s further see what will happen if someone pretends to be Alice to send a message to Bob, or the content of the message has been modified.</p>



<p>James, again, wanted to send Bob a message $M^\prime$ which specifically says the message is from Alice, or had intercepted an encrypted message $C$ from Alice, blocked it and created a message $M^\prime$ which specifically says the message is from Alice. To make the message readable by Bob, James encrypted $M^\prime$ using $E_B$, send the encrypted message $C^\prime$ to Bob.</p>



<p>Because Bob does not accept any message without a signature, James had to make up a signature. However, because James knew nothing about Alice’s private key, he used a decryption function $D_J$ which is different from Alice’s secrete $D_A$. The signature James generated would be</p>



<p>Once Bob received both $S^\prime$ and $C^\prime$, he could decrypt both $S$ and $C$ using his private key and Alice’s public key as usual. Specially,</p>



<p>In this case, Bob would see the two decrypted messages are not the same. Bob would then realize that there is something unusual happened and he should not trust anything about the message.</p>

<h3 id="hacking-the-public-key-cryptosystems">Hacking the Public-Key Cryptosystems</h3>

<p>As long as the four features of the public-key cryptosystems hold, cracking it is almost impossible. If somedayy, when the almighty quantum computer is available, the feature “the publicity of $E$ does not compromise the secrecy of $D$” would be compromised, therefore the modern public-key cryptosystems would no longer be reliable. I may talk about this topic in the future.</p>



<p>There is another way to send fake messages to Bob in name of Alice, without using a quantum computer. If James could somehow crack the account name and password of Alice on the web application, replace the Alice’s public encryption function from $E_A$ to $E_J$, when Bob tried to retrieve Alice’s encryption function, he would get $E_J$ instead of $E_A$. The decryption of signature $S^\prime$ would become $M^\prime$ instead of $M^{\prime\prime}$ then. Concretely,</p>



<p>In this case the two decrypted messages match. Bob would be convinced that the message is from Alice and it has not been modified.</p>



<p>It should be noted that James was replacing Alice’s public encryption function from $E_A$ to $E_J$, instead of replacing his private decryption function from $D_J$ to $D_A$. In principle, $D_A$ would only be kept on Alice local computer and not anywhere else. Even if James has Alice’s account name and password on the web application, he would not get a copy of $D_A$ unless he specifically hacked Alice’s physical computer.</p>



<p>This reminds us that actually keeping our password safe is the most important.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://sites.math.washington.edu/~morrow/336_09/papers/Yevgeny.pdf">The RSA Algorithm</a></li>
  <li><a href="https://www.youtube.com/watch?v=JR4_RBb8A9Q">What are Digital Signatures and How Do They Work?</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/Public-Key-Cryptosystem-and-Digital-Signature/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24009587</guid>
            <pubDate>Fri, 31 Jul 2020 15:28:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Think About Chess]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24009477">thread link</a>) | @FailMore
<br/>
July 31, 2020 | https://taaalk.co/t/how-to-think-about-chess#r | <a href="https://web.archive.org/web/*/https://taaalk.co/t/how-to-think-about-chess#r">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
  <div id="tlk-section-read">
    



<div>

    <div>
      <div>
        <div>
          
          <div>
            <div>
              <div>
                <div>
  <p>I'm a keen, but not very accomplished, chess player. I'm looking to understand the basics of good chess strategy.</p>
</div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div>
      <div>
        <div>
          
          <div>
            <div>
              <div>
                <div>
  <p>I started playing chess when I was 6, and played seriously until the age of 18. My career highlights include 30th in the European U18s, captaining/vice-captaining England at most age groups, playing for Oxford in 3 Varsity matches and achieving rankings of 195 ECF and 2200 FIDE. I'm a software engineer at <a href="https://stripe.com/">Stripe</a> and blog at <a href="https://robertheaton.com/">robertheaton.com</a>.</p>
</div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    

</div>

  </div>







  <div>

      <div id="1">
        <div>
          
          <p>Admin</p>
          <p>13:27, 06 May 20 (edit: 13:28, 13 May 20)</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>This Taaalk was written on the first version of Taaalk in 2016.</p></div><div><p>The archive.org version is available <a href="https://web.archive.org/web/20160427012637/http://taaalk.co/taaalk/chess/robert-heaton-josh-summers">here</a>.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="2">
        <div>
          
          <p>Joshua Summers</p>
          <p>18:08, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>A lot of people write about chess as having an opening game, a middle game and an endgame. When you're playing is that what's going through your head?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="3">
        <div>
          
          <p>Robert Heaton</p>
          <p>18:08, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Everyone has an opening repertoire. Many people just have one answer for each question they might reasonably expect their opponents to ask, which means they get very good at playing those answers, but equally become very predictable. There are some openings that are razor sharp and precise, and require knowing many 15-20 move variations in order to not get destroyed without the game even starting. I personally prefer openings that are more conceptual, which tend to be slightly more flexible, require much less knowledge, but arguably lead to somewhat more boring positions because of this.</p></div><div><p>So when the middlegame comes around, it's probably the kind of position I've played many times before. My strategy is usually to throw lots of pieces at their king and hope they die or I can win some material. Since I'm hoping to win at this point, I probably don't start thinking explicitly about the endgame until little suggestions of things that might become relevant start cropping up. So if pawns become isolated or doubled, or we end up with opposite colored bishops, or with a bishop on the same color square as most of our pawns, etc. If I can take one of these small positional advantages then I will, and then effectively "bank" it until the endgame actually comes around. Having one or more of these might make me more likely to head towards an endgame too.</p></div><div><p>Endgames are really hard and require a lot of technique that I don't really have. Fortunately most other people don't either, because you just don't get to play that many of them.</p></div><div><p>It probably is fair to say that I'm pretty aware of the opening/middlegame/endgame distinction. The opening is where I'm playing pretty much from memory, the middlegame is where I try and win, and the endgame is what I might head towards if I think I have a tangible advantage but try and avoid otherwise.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="4">
        <div>
          
          <p>Joshua Summers</p>
          <p>18:08, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>So when you say that the endgame is what you might head towards - is the endgame not just the 'end of the game'? In which case won't most games have one? I know in the extremely amateur world of chess that I play in that most games come to a end where one side is actively checkmated. Is the endgame more unusual the higher up you go because a party will often resign when one side is in a dominant position?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="5">
        <div>
          
          <p>Robert Heaton</p>
          <p>18:10, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>I guess this is a question for statistics to answer properly, but my gut says that there possibly are fewer endgames in higher level play. If you lose a bishop or a knight without any obvious compensation, you will almost definitely resign on the spot. That said, it's probably also true that fewer boneheaded mistakes mean that neither side may have had much of a chance to win before the endgame. Overall I'm not sure!</p></div><div><p>But when I say "might head towards the endgame", I mean that I might deliberately choose to swap off pieces and accelerate progress towards the end of the game. If I'm a pawn up then trading off pieces is likely a huge win for me, because whilst a queen + 2 rooks + 1 bishop + 2 knights + 7 pawns v the same but 6 pawns is not a huge advantage, a bishop + 5 pawns v a bishop + 4 pawns probably is. Small material advantages are a much bigger deal in the endgame and leave less room for your opponent to generate compensation, so if you are slightly ahead then deliberately swapping off pieces is very important. Games can naturally meander towards an endgame where neither side is too psyched about their chances, or they can be forced.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="6">
        <div>
          
          <p>Joshua Summers</p>
          <p>18:10, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>OK - that makes a lot of sense. You mentioned that you like to keep your openings of a 'conceptual' nature. What kind of concepts are you basing your openings on?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="7">
        <div>
          
          <p>Robert Heaton</p>
          <p>18:10, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Honestly I like openings that allow you to put your pieces on nice squares without thinking too hard, and then throw them all at your opponent's king. This is not a very sophisticated strategy, but it can be very hard to deal with if you aren't prepared (this is a good example). If you can get off the beaten track without doing anything too insane then you become much more familiar with the kinds of positions that result than your opponents, and develop a big box of patterns that have worked in the past.</p></div><div><p>This becomes somewhat less effective the higher level and more famous you get, as you start to become notorious for particular openings, and opponents can start preparing counters to them. This is where a degree of flexibility and unpredictability becomes invaluable, so that your opponents can't just put all their time into preparing for your Stonewall Dutch or Trompowsky, and also have to keep in mind that you might throw in a Benko Gambit or English Opening. It can be worthwhile playing these alternatives in high profile tournaments that will get their games into databases that your future opponents will see and get confused and upset by.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="8">
        <div>
          
          <p>Joshua Summers</p>
          <p>18:11, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>The part on variation makes a lot of sense. So what are nice squares and what makes them nice?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="9">
        <div>
          
          <p>Robert Heaton</p>
          <p>18:11, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>"Nice" squares is obviously a super-vague concept, but in this situation I mostly just mean:</p></div><div><p>Knights in the middle of the board</p></div><div><p>Bishops pointing towards the king</p></div><div><p>Rooks on open files or behind pawns that are marching towards their king</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="10">
        <div>
          
          <p>Joshua Summers</p>
          <p>18:11, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>OK - now we're warming up!! A few things to deal with:</p></div><div><p>1) Why is it good to have knights in the middle of the board?</p></div><div><p>2) Why is it good to have bishops pointing at the king?</p></div><div><p>3) And i) what is an open file? and ii) why do I want my rook on it?</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="11">
        <div>
          
          <p>Robert Heaton</p>
          <p>18:12, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>1) Knights on the edge of the board don't attack many squares, knights in the centre of the board do. Because of their uniquely short range, they are the one piece that really benefits from being in the centre. A rook or bishop in the corner can still rake across the entire board, but a knight in the same spot looks pretty dumb.</p></div><div><p>2) If you want to attack the king (I do), you need to have your pieces attacking him and the squares around him! Even if you aren't planning on immediately checkmating anytime soon, you may be able to use threats against him to force smaller concessions or weaknesses.</p></div><div><p>3) An open file is one that isn't blocked by any of your pawns or pieces, and so if you put a rook at one end of it you'll be probing into some part of their position (hopefully a weak part!). This is the most direct way for your rooks to influence the game. As mentioned above, you don't necessarily need to be destroying or capturing anything in order for your pieces to be making your opponents' life awkward, so principles like "rooks on open files" will almost always be good things to at least look out for.</p></div>
</div>

            </div>
          </div>
        </div>
      </div>
      <div id="12">
        <div>
          
          <p>Joshua Summers</p>
          <p>18:14, 07 May 20</p>
        </div>
        <div>
          <div target="spkr-color-">
            <div><div>
  <div><p>Right. Would you say you're setting yourself up in the strongest position possible to deal with the largest number of variations down your opponents end (defensive) or setting yourself up to maximise your attacking options? Or a balance of the two?</p></div><div><p>When I'm playing with friends sometimes it feels like there is an unspoken agreement to let the other player 'set up' so to speak. To get their pieces into the strongest structural position before the WAR takes place. When you're playing is this something that happens? Or are you looking to start WAR while you set up your …</p></div></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://taaalk.co/t/how-to-think-about-chess#r">https://taaalk.co/t/how-to-think-about-chess#r</a></em></p>]]>
            </description>
            <link>https://taaalk.co/t/how-to-think-about-chess#r</link>
            <guid isPermaLink="false">hacker-news-small-sites-24009477</guid>
            <pubDate>Fri, 31 Jul 2020 15:19:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choosing Between ActiveMQ and Kafka based on messaging semantics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24009298">thread link</a>) | @bibryam
<br/>
July 31, 2020 | http://www.ofbizian.com/2020/07/choosing-between-activemq-and-kafka-for.html | <a href="https://web.archive.org/web/*/http://www.ofbizian.com/2020/07/choosing-between-activemq-and-kafka-for.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The term asynchronous means “not occurring at the same time” and in the context of distributed systems and messaging it implies that the processing of a request occurs at an arbitrary point in time. There are many advantages of asynchronous interactions over synchronous ones but also new challenges introduced by it. In this post, we will focus on a few specific considerations for choosing a suitable asynchronous messaging infrastructure for implementing <a href="https://developers.redhat.com/topics/event-driven/" target="_blank">event-driven</a> systems. Let’s see a few of the subtle differences between asynchronous interaction styles.<br></p><h2>Message Business Value</h2><p>Not all messages are created equal. Some are valid and valuable only for a short period of time and obsolete later. Some are valuable until they are consumed regardless of the time passed. And some messages are valid and useful for repeated consumption. Considering the validity and the value of messages relative to time and consumption rate, we can qualify interaction styles between services into the following categories:</p><div><p><a href="https://1.bp.blogspot.com/-p9AE1uCT-lY/XyQrM2kw2LI/AAAAAAAAOi8/9VSsF63jc_0u3NSab9nn5nYwCtS4fce_QCLcBGAsYHQ/s2576/business_value.png"><img alt="Message types by business value" height="136" src="https://1.bp.blogspot.com/-p9AE1uCT-lY/XyQrM2kw2LI/AAAAAAAAOi8/9VSsF63jc_0u3NSab9nn5nYwCtS4fce_QCLcBGAsYHQ/d/business_value.png" title="Message types by business value" width="400"></a><br><i>Message types by business value</i></p><h4>Volatile</h4><p>These are ephemeral messages where the value is time-bound. Valuable now, but not in the short future. There is no point in storing events that are useless in the future and using messaging systems with such characteristics gives the best performance with the lowest latency possible as the disk is skipped. In such a scenario, the system is aware of the connected consumers and the event disseminated to all consumers online at the time of publication. If a consumer is disconnected, the messaging system forgets about these consumers. What is important in such a system is the ability to handle a large number of dynamic clients with low latency interaction needs such as IoT devices.</p><h4>Durable</h4><p>However, in some situations you want the messaging system to be aware of the consumers and store the messages while the consumer is not available. That is a traditional message broker which will hold on to the messages for the consumers that he knows about and allow the consumers to re-connect and consume the events that were produced in his absence. Once an event is consumed by all the interested parties, it will discard the messages. Here the broker knows about registered consumers and messages are stored durably until read by all registered consumers. Here the goal is to do reliable messaging among services with strong ordering and delivery guarantees.</p><h4>Replayable</h4><p>Here, the messaging system is not aware of the consumers that are interested in the event. It simply stores the events published to a stream for some time or until capacity is reached. Then a consumer can come along at any time, connect and consume the events and perhaps replay the stream from the beginning. Consumers can move back and forth in the stream as required and replay the messages repeatedly. Here, the driving force is extreme scalability combined with the ability to replay messages for existing or new consumers.</p><h2>Message Semantics</h2><p>Apart from the technical characteristics of the messages, it is important to distinguish the language we use, the semantic aspects, and the intent of the interactions. Some messages are targeted for a specific consumer and demand concrete actions. Some are querying the latest state of a system without requiring a state change. And some notify the world about a change that has happened in the source system. From a messaging semantic perspective, there are the following types of messages:</p><p><a href="https://1.bp.blogspot.com/-RMxJzN21Bbk/XyQrihOt9FI/AAAAAAAAOjE/3jg_mU4oqN0WB1G8OOqQ43FC2JNmt5yMACLcBGAsYHQ/s2568/Screenshot%2B2020-07-28%2Bat%2B07.39.01.png"><img alt="Message types by semantics" height="135" src="https://1.bp.blogspot.com/-RMxJzN21Bbk/XyQrihOt9FI/AAAAAAAAOjE/3jg_mU4oqN0WB1G8OOqQ43FC2JNmt5yMACLcBGAsYHQ/d/Screenshot%2B2020-07-28%2Bat%2B07.39.01.png" title="Message types by semantics" width="400"></a><i><br></i></p></div><p><i>Message types by semantics</i></p><div><h4>Command</h4><p>A command is a request for action that usually leads to a state change on a known target system. Typically there is a response indicating that action was completed and even there might be a result associated with it. When a response is expected, commands are typically implemented over synchronous protocols such as HTTP, but it is possible to implement request/response or fire and forget style commands over asynchronous messaging systems. With a command based asynchronous messages, there is some coupling between the source and the target systems in the form of command semantics.</p><h4>Query</h4><p>A query is like a command, but it is a read-only interaction that does not lead to a state change. By its very nature, a query expects a response, and it is common to see synchronous implementations here. But asynchronous and non-blocking implementations over messaging systems and even fire and forget style interactions for long-running operations where a response is written to a different location are common too.</p><h4>Event</h4><p>An event is a notification that something has changed. A system sends event notifications to notify other systems for a change in its domain. An event is different from a command in that often the event emitting system doesn’t expect an answer at all. In addition to being asynchronous, event messages are not targeted to a specific recipient and thus, they enable even further decoupling. Similar to other asynchronous interactions, events are implemented as messages on queues, which are often called streams. Martin Fowler covers in-depth the different types of events in <a href="https://www.youtube.com/watch?v=STKCRSUsyP0" target="_blank">this</a> talk.</p><h2>Summary</h2></div><div><p>One approach you can take is to follow the <a href="https://en.wikipedia.org/wiki/Law_of_the_instrument" target="_blank">Law of the Instrument</a> approach defined by Maslow as “If the only tool you have is a hammer, treat everything as if it were a nail." You could certainly use a classic message broker such as Apache ActiveMQ to implement the different interaction styles. It would be a familiar technology to many and easier to start with, but hard to implement some use cases such as replayable messaging. Or you could take the other extreme and try to use Apache Kafka for everything. It would require a larger amount of hardware resources and human effort to manage it, but it would cover the replayable messaging and extreme scalability needs. While both of the above approaches are fine to start with, when you have a large number of services with different messaging needs, using the right tool for the right job is a better option. We can map the above-described messaging patterns to see what messaging infrastructure is best suited for each.</p><p><a href="https://1.bp.blogspot.com/-MTuOiuBjh48/XyQr8TVfwuI/AAAAAAAAOjQ/JwY1yhgOkGY8l-upOVl2vqR9kvYdXh9tQCLcBGAsYHQ/s2768/Screenshot%2B2020-07-28%2Bat%2B07.39.17.png"><img alt="Mapping messaging subtleties to different messaging infrastructures" height="135" src="https://1.bp.blogspot.com/-MTuOiuBjh48/XyQr8TVfwuI/AAAAAAAAOjQ/JwY1yhgOkGY8l-upOVl2vqR9kvYdXh9tQCLcBGAsYHQ/d/Screenshot%2B2020-07-28%2Bat%2B07.39.17.png" title="Mapping messaging subtleties to different messaging infrastructures" width="400"></a><br><i>Mapping messaging subtleties to different messaging infrastructures</i></p><p>We at Red Hat love any open source technology. That is why we included Apache Qpid, Apache ActiveMQ Artemis, and Apache Kafka in our <a href="https://www.redhat.com/en/technologies/jboss-middleware/amq" target="_blank">Red Hat AMQ</a> product and let the customer choose the right tool for the right job. There are many other aspects to consider when choosing the right tool, I hope this post will help you get there one step closer.</p></div><p><i>This post was originally published on Red Hat Developers. To read the original post, check <a href="https://developers.redhat.com/blog/2020/07/31/choosing-the-right-asynchronous-messaging-infrastructure-for-the-job/" target="_blank">here</a>.</i></p>



</div></div>]]>
            </description>
            <link>http://www.ofbizian.com/2020/07/choosing-between-activemq-and-kafka-for.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24009298</guid>
            <pubDate>Fri, 31 Jul 2020 15:03:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compile Time, Binary Size Reductions and C++’s future for sol3]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24009272">thread link</a>) | @flipchart
<br/>
July 31, 2020 | https://thephd.github.io/sol3-compile-times-binary-sizes | <a href="https://web.archive.org/web/*/https://thephd.github.io/sol3-compile-times-binary-sizes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
      <p>This is going to be a practical overview of how I reduced the compilation time and binary sizes of Release Mode (-O3 or /Ox) C++ software. The goal of this will be to review some of the things that help with the goal, and some of the things that C++ as a language is fundamentally incapable of producing satisfactory answers to. Let’s<!--more--> dig in!</p>



<p>We were able to save some things for a project with 2.5K class bindings:</p>

<table>
  <tbody>
    <tr>
      <td>Version</td>
      <td>sol2</td>
      <td>sol3 (patron-only alpha)</td>
      <td>sol3 (now)</td>
    </tr>
    <tr>
      <td>Build Time</td>
      <td>2 hours, 3 minutes</td>
      <td>2 hours, 11 minutes</td>
      <td>1 hour, 53 minutes</td>
    </tr>
    <tr>
      <td>Binary Size</td>
      <td>119.0 MB</td>
      <td>138.0 MB</td>
      <td>103.0 MB</td>
    </tr>
  </tbody>
</table>



<p>I added 3 new core template types that all abstractions get milled through. I also committed some of the sins below in improving the functionality and streamlining the code. To be honest, I’m actually surprised it only cost me 7 more minutes over sol2! But, let’s talk about the things I did in order to get to where we are now, and what I needed to identify as problem points…</p>



<p>This was a combination of intuition and empirical evidence. I had suspicions about what increased my compile time, but I did not want to go off on a wild hunt trying to figure out what was going on. Much as Templight and other tracers exist (and are <a href="http://aras-p.info/blog/2019/01/16/time-trace-timeline-flame-chart-profiler-for-Clang/">currently being worked on</a>) I kept my assumptions in the back of my mind but checked them by asking a few companies and individual users of sol2 to send me their largest object files VIA Discord and other means:</p>

<p><img src="https://thephd.github.io/assets/img/2019-01-19/biggest-you-have.png" alt="Mmmn, girthy."></p>

<p>In doing so, I could confirm my suspicions by seeing what was serialized into the object file. Note that while this does not perfectly translate to the final code (especially in release builds), it is a good proxy for (1) link times, due to having to resolve all of the (possibly non-unique) definitions from a single object file with all the others in the project; and (2) compile times, because the compiler has to vomit all of this stuff into these object files to begin with.</p>

<p>One of the object files I studied was 14 megabytes big from a Visual Studio 2017 Release build. the fun started when I expanded the <code>.7z</code> file:</p>

<p><img src="https://thephd.github.io/assets/img/2019-01-19/file-sizes.png" alt="Goodness...!"></p>

<p>Mama mia that’s a spicy 16.4x file size increase!</p>

<p>This is a screaming red flag that we have a LOT of redundancy (because it compresses so obscenely well under default settings). Duplicate symbols are rife in any TU that heavily uses templates, and sol3 <em>is</em> a template-heavy, header-only library. But, this probably doesn’t explain the absolute ballooning in size when going from the packed 7zip I was sent to the big thing in the actual binary.</p>

<p>To help me dig in, I <a href="https://twitter.com/chieltbest">relied on someone else</a> who did all the hard work for benchmarking what were the more expensive operations one could perform in relation to templates. I also use this brilliant person’s Rule of Chiel:</p>

<p><img src="https://thephd.github.io/assets/img/2019-01-19/rule-of-chiel.png" alt="The Rule of Chiel"></p>

<p>Armed with this knowledge and a bunch of object files, I set off to find the worst offenders in my code. I targeted what was either SFINAE + types, or SFINAE + function templates, since those were my typical things that destroyed my code. sol2 uses a lot of struct specialization SFINAE, which is probably the most damaging to compile-times right now. Coupled with some very gnarly function template SFINAE and other things, I figured that this and other things were probably the root of the cause.</p>

<p>Just where I found that bloat – asides from the obvious places where I used exactly those techniques – was even more of a surprise…</p>



<p>Lambdas are ultra convenient and – in some cases – even more powerful than structs you declare locally (for example, you can’t template function-local structs but you can do it with a lambda and <code>auto</code>/Concept function argument types!) But, I needed to tear them down in several places where I had capturing lambdas inside of templated code. I only did this in a handful of places – 6 or 7 total in the whole library, up from 1 or 2 in sol2 – and it did a fair amount of to save me the mental overhead when programming. They’re just Immediately Invoked Function Expressions, right? How costly can they be?</p>

<p>It turns out capturing Lambdas – even entirely local ones – don’t optimize out cleanly in terms of <em>code size</em> for C++ and a lot of it gets dumped into the object file and the resulting executable. I used <code>dumpbin</code> to get me all the symbols in a text file (an 11 megabyte text file) and then proceeded to just goof around and scroll through it. Some things there was nothing I could do about, like all the string spam for my Compile-Time Type Strings work I was doing. But, for this 1 object file where only 1 class was being bound using an alpha of sol3, I ran a count for the times <code>lambda</code> showed up:</p>

<p><img src="https://thephd.github.io/assets/img/2019-01-19/lambda-count.png" alt="Goodness Gracious..."></p>

<p>Sheesh… a few more pointed searches for certain identifiers with the lambda revealed that most of those belonged to my detail namespaces and inner workings. Remember, this is just for binding one class! All this symbol spam from the template-capturing lambdas revealed one thing, though: <em>each lambda, when inlined, results in a fat slab of code that is different per-instantiation</em> (I mean, duh, that’s the point of a template, right?). The compiler marks all of this code inline and dumps it into the resulting function instantiation, which is expected. The problem is that capturing all the variables in a templated function means that any time you have enough variable initializations and function declarations that depend on said templates, it is impossible for the optimizer to combine these bits of code together, even if its fundamentally the same code for all invocations!</p>

<p>The solution here was to roll up my sleeves and get out the dough, because it was time for…!</p>

<p><img src="https://thephd.github.io/assets/img/pexels/baked-baking-chef.jpg" alt="Only the best ingredients for your code base."></p>

<p>
🥖🥖 A R T I S A N A L 🥖 H A N D - C R A F T E D 🥖 L A M B D A S 🥖🥖
</p>


<p>Since the 1990s, like your mothers and their mother’s mothers, and your fathers and their father’s fathers, I took to the oven to bake only the freshest lambda to trump them all, taking advantage of the fact that all of the routines were identical and that I could use some of Grandma’s <code>void*</code> and Great Aunt Mary’s function pointers. To top that off, Lua is a runtime ingredient so all the compile-time shenanigans weren’t exactly necessary at the point of my lambda. I lowered down my <code>if constexpr</code> spices into regular <code>if</code> statement herbs, powered by runtime booleans initialized with constant expressions. The result was a creamy yet spicy French struct with so many delicious members. Ultimately a reduction but the culinary blend saved me quite a bit of symbol spam in the object file and lambda-based template spew by quite a bit, making for some <em>chef kiss</em> nice improvements:</p>

<p><img src="https://thephd.github.io/assets/img/2019-01-19/artisanal-lambda.png" alt="Artisanal hand-crafted lambdas"></p>

<p>Food silliness aside, this helped a lot. To recap the point in a more clear way, though, here are some snippets illustrating the various degrees of (non-)trouble you can get yourself into.</p>

<p>Good:</p>

<div><div><pre><code><span>void</span> <span>func</span> <span>()</span> <span>{</span>
	<span>auto</span> <span>iife</span> <span>=</span> <span>[]()</span> <span>{</span>
		<span>/* work */</span>
	<span>};</span>
	<span>iife</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>Also good:</p>

<div><div><pre><code><span>void</span> <span>func</span> <span>(</span><span>int</span> <span>arg</span><span>,</span> <span>my_class</span><span>&amp;</span> <span>foo</span><span>)</span> <span>{</span>
	<span>auto</span> <span>iife</span> <span>=</span> <span>[</span><span>&amp;</span><span>]()</span> <span>{</span>
		<span>/* work */</span>
	<span>};</span>
	<span>iife</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>Okay, but be careful…:</p>

<div><div><pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>&gt;</span>
<span>void</span> <span>func</span> <span>(</span><span>T</span> <span>arg</span><span>,</span> <span>my_class</span><span>&amp;</span> <span>foo</span><span>)</span> <span>{</span>
	<span>auto</span> <span>iife</span> <span>=</span> <span>[</span><span>&amp;</span><span>]()</span> <span>{</span>
		<span>/* work */</span>
	<span>};</span>
	<span>iife</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>Worse:</p>

<div><div><pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>,</span> <span>typename</span><span>...</span> <span>Args</span><span>&gt;</span>
<span>void</span> <span>func</span> <span>(</span> <span>my_class</span><span>&amp;</span> <span>foo</span><span>,</span> <span>Args</span><span>&amp;&amp;</span><span>...</span> <span>args</span><span>)</span> <span>{</span>
	<span>auto</span> <span>iife</span> <span>=</span> <span>[</span><span>&amp;</span><span>]()</span> <span>{</span>
		<span>/* work */</span>
	<span>};</span>
	<span>iife</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p><em>Screaming in the distance:</em></p>

<div><div><pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>Binding</span><span>&gt;</span>
<span>struct</span> <span>binding</span> <span>{</span>
	<span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>,</span> <span>typename</span><span>...</span> <span>Args</span><span>&gt;</span>
	<span>void</span> <span>func</span> <span>(</span><span>my_class</span><span>&amp;</span> <span>foo</span><span>,</span> <span>Args</span><span>&amp;&amp;</span><span>...</span> <span>args</span><span>)</span> <span>{</span>
		<span>auto</span> <span>iife</span> <span>=</span> <span>[</span><span>&amp;</span><span>]()</span> <span>{</span>
			<span>/* work */</span>
		<span>};</span>
		<span>iife</span><span>();</span>
	<span>}</span>
<span>};</span>
</code></pre></div></div>

<p>Of course, this is easy to see in these examples. But when working with complex template functions, it’s very easy to just make a fully-capturing lambda that gets you all the local variables and arguments you need with very little fuss. Just be careful if it’s a common use point in your API, and especially if there is a forwarding capture reference and you are expected to have string literals come into your API. String literals are actually the worst offenders for the bloat, because <code>"set"</code> is not the same type as <code>"super_set"</code> (they’re both different-sized C-style arrays).</p>

<p>Having a (imaginary) <code>std::c_string_view</code> or some <code>std::string_literal</code> <code>constexpr</code> type be the default here might help that out but I doubt the C++ Committee will ever bite on a <code>std::string_literal</code>-by-default type anytime soon. (After all, backwards compatibility etc. etc. – someone is bound to be broken if we change the fundamental type of <code>"blah"</code> in C++!) But, what may happen is a <code>std::string_literal</code> type that can <em>only</em> be created magically by the compiler. This will give us some interesting information to work with (read-only, string is interned, etc.), and from there we could probably at least fix some of C++’s strange warts, even if we still get <code>const char[N]</code> and <code>const char*</code> from template deduction and <code>auto</code>-deduction.</p>

<p>The point being, if you expect <code>my_template_f("blah")</code> to be a thing your users write, be careful!</p>



<p>Is anyone really surprised this shows up?</p>

<p>Parsing stuff in C++ is its own particularly special nightmare. I provided a <code>sol_forward.hpp</code> to ease on this parsing adventure. But I didn’t really put enough stuff in there. So I added some more forward declarations in there for sol3, and now the single header generates a proper <code>sol/sol.hpp</code> and a <code>sol/forward.hpp</code> for users to include. The result was pretty good gains:</p>

<p><img src="https://thephd.github.io/assets/img/2019-01-19/forward-declarations.png" alt="forward.hpp bringing huge benefits."></p>

<p>Forward declarations are good. Honestly, we should probably be providing very small Modules for the standard library, and also be providing incredibly fine-tuned headers too. <code>&lt;functional&gt;</code> alone is absolutely enormous, and it would be nice if we just had <code>&lt;functional_fwd&gt;</code> when we really don’t need the whole thing. I have some ideas in this space, but it’s going to take some time before I can let it manifest. (I have a lot to do over the next 3 years…!)</p>



<p>Tag dispatching – while a good technique – results in the compiler having to pick between overloads, even if its only 2. The worst part about any overload set is that the compiler cannot short circuit what it finds: it needs to walk over all of the possible function entities in an overload set before selecting the right one.</p>

<p>My tag dispatching code was …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thephd.github.io/sol3-compile-times-binary-sizes">https://thephd.github.io/sol3-compile-times-binary-sizes</a></em></p>]]>
            </description>
            <link>https://thephd.github.io/sol3-compile-times-binary-sizes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24009272</guid>
            <pubDate>Fri, 31 Jul 2020 15:01:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Creating a Board Game Is Like Writing Software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24009223">thread link</a>) | @ddorosz93
<br/>
July 31, 2020 | https://nerdstack.io/creating-board-game-is-like-writing-software/ | <a href="https://web.archive.org/web/*/https://nerdstack.io/creating-board-game-is-like-writing-software/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-94" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>For the past month or two, my brother, a friend of ours, and I have been working on creating a new board game. All three of us are extremely into board games and have always wanted to create one. It’s been really fun, but definitely not easy.&nbsp;</p>



<p>When making a board game, there are a ton of edge cases and variables you have to consider. You have to run tests, fix issues and iterate on things that may need some improvement. This entire process made me realize that making a board game is a lot like writing software. It’s so similar in fact, that I believe creating a board game should be an activity done in schools to teach younger (and older) students the benefits of planning, thinking about edge cases, extensibility, iteration and probably more that isn’t popping into my head right now.&nbsp;</p>



<p>The first step in board game creation was thinking of an idea and refining it into a general set of rules. This is very similar to software where once you think of an idea, you have to define a set of features and acceptance criteria. There are many things that we originally wanted to include but felt didn’t offer enough benefit, maybe even added confusion, so we left them out. We also had to think about whether the board game was fun at each step of the process, similar to thinking about if your software is adding value.</p>



<p>Once we had our general idea, we started thinking about edge cases. What happens if a player does this, what happens if they do that. In software you have to do the same thing. The difference is that in software (at least nowadays) you usually have the opportunity to go back and fix some of the edge cases after releasing it. With the board game, our goal is to fund it and release it. Once you release a board game, you can’t just patch it whenever you like. Any edge cases you may have missed are now there for people to run into (or exploit).&nbsp;</p>



<p>Ok, so you finished writing your software… I mean… finished creating your first board game prototype. Now what? Well you have to test it. There’s no such thing as automated testing for board games, so you have to play test it. This is the most lengthy process of the creation process (At least so far. This is the stage we’re at now.). As you test, you’ll notice certain mechanics that don’t work, and have to patch them. This is similar to fixing bugs or improving on certain features in software.</p>



<p>Once you’ve finished play testing it and feel confident in your board game, that’s when you can start releasing it to the public. This requires you to write the rules in a way that is understandable to your target audience. Similar to software, documentation is very important. In software, documentation can take many different forms; API docs, instruction manuals, etc. Each of these documents has a different target audience and should be written with that target audience in mind. When writing the rule book for your board game, know your target audience.&nbsp;</p>



<p>There is one other aspect of board game creation that might not apply to all board games but is a good thing to keep in mind. Expansions. A lot of board games come with expansion packs. The only way you can create an expansion pack is if you created your board game in a way that allows for this sort of extensibility. This is very similar to how in software you don’t want to write spaghetti code and should always keep extensibility in mind.&nbsp;</p>



<p>Creating a board game has been super fun and rewarding. It made me realize that I can put my software engineering skills to use in other areas seemingly unrelated. I believe that creating a board game, and maybe even converting it to code should be an activity done in schools in software courses.&nbsp;Especially for younger students who may not be interested in software yet.</p>



<p>This is my insight into board game creation and how it relates to software. Feel free to email me at <a href="mailto:ddorosz@katsudo.io">ddorosz@katsudo.io</a> if you have any questions, want to chat, or are interested in finding out more about the board game and when we plan on releasing it.&nbsp;</p>

		
		
			</div><!-- .entry-content .clear -->
</div>

	
</article></div>]]>
            </description>
            <link>https://nerdstack.io/creating-board-game-is-like-writing-software/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24009223</guid>
            <pubDate>Fri, 31 Jul 2020 14:56:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Collections: Bread, How Did They Make It? Part II: Big Farms]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24009134">thread link</a>) | @jrott
<br/>
July 31, 2020 | https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This is the second part of our look at the basic structure of food production (particularly grains to make bread) in the pre-modern world.  <a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">Last week</a>, we began by looking at the great majority of our rural population, the little farmers.  Now I know everyone is eager to get to the mechanics of planting, harvesting, threshing, milling, baking and so on, but we have one more group of people in the countryside to talk about: the much smaller group of larger landholders, or as they are often generally referred to, the ‘big men.’</p>



<p>Now I should begin by noting that not all of our ‘big men’ are, in fact, men – though most were.  Exactly how many large rural landholders are women varies from one pre-modern society to the next (though it is almost always a minority), but it was generally not zero, save in a relative handful of societies which specifically <em>completely </em>barred women from independent landholdings by law (some Greek <em>poleis</em> did this, for instance); even in sharply patriarchal societies like Rome, there would always be a handful of great estates run by women, particularly widows.  Nevertheless ‘big man’ (or ‘big person’) is a fairly common way to refer to these fellows across languages (for instance, magnates from Latin <em>magnati</em>, literally ‘big men,’ mirrored by the Greek μεγιστᾶνες (‘big men’) which has the same meaning; ‘grandees’ has the same sense, coming from Portuguese).  I don’t want to use many of the language-specific terms because they often come with additional meaning – we could call these fellows ‘nobles’ or ‘aristocrats’ or ‘the gentry’ in various times and places, but these terms often imply rigid social classes which don’t apply cross-culturally (and in many cases might have no real equivalent in societies which still have recognizable rural ‘big men’).  Almost all of these traditional terms for the ‘big men’ (who again, are not all men) are loaded with some sort of meaning which won’t do for our very general look at the basic structures of pre-modern cereal agriculture.</p>



<p><strong>So instead, I am going to go with the somewhat clinical and bland “large landholders”</strong> most of whom are men (but some of whom are women), but <strong>all of whom hold lots of land</strong>.  But what I want to stress is that these fellows were understood as being ‘big’ in the sense that they held a lot of agricultural <em>capital</em> but <em>also</em> generally ‘big’ in the sense that they dominated, socially and politically, their societies (notice though how the words used to describe them above often <em>also</em> imply ‘bigness’ of ability or character – like ‘noble’ – they certainly <em>believed this about themselves</em> and they write most of our sources; one assumes the  peasantry viewed the matter quite differently, though they only infrequently get a chance to say it to us).  Now I know that capital is a scary word in some quarters, worry not.  We are going to use it in a fairly simple, direct way just to mean all of the things – land, animals, equipment, infrastructure – which make farming productive.  While these large landholders <em>almost always</em> represent a legally or socially privileged class,<strong> what matters for us is how their large landholdings and capital reshaped farming in the countryside</strong>.  I am not going to get too deep into the landholders themselves beyond these effects – they already get <em>quite enough</em> attention in their role as military, political and cultural elites as it is (<a href="https://acoup.blog/2020/05/22/collections-the-battle-of-helms-deep-part-iv-men-of-rohan/">even </a><a href="https://acoup.blog/2019/12/12/collections-a-trip-through-cicero-natural-law/">elsewhere </a><a href="https://acoup.blog/2019/12/05/collections-a-trip-through-thucydides-fear-honor-and-interest/">on </a><a href="https://acoup.blog/2020/04/16/collections-a-trip-through-bertran-de-born-martial-values-in-the-12th-century-occitan-nobility/">this </a><a href="https://acoup.blog/2020/03/27/a-trip-through-dhuoda-of-uzes-carolingian-values/">blog</a>).</p>



<p><strong>So how do these large landholders function in a countryside mostly composed of small subsistence farmers?</strong>  Let’s walk out of the village and up to the manor and find out.</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<p>(Also as a reminder, the selected bibliography for all of this is back <a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">in the first post</a>.)</p>



<figure><img data-attachment-id="3985" data-permalink="https://acoup.blog/104852001/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/07/104852001.jpg" data-orig-size="2500,1931" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="104852001" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/07/104852001.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/07/104852001.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/07/104852001.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/07/104852001.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/07/104852001.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2020/07/104852001.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/07/104852001.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/07/104852001.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Via the British Museum (<a href="https://www.britishmuseum.org/collection/object/P_1858-0626-227">inv. 1858,0626.227</a>), a c. 1720 drawing of Italian farmers working their fields outside of the ruins of the Baths of Caracalla at Rome.</figcaption></figure>



<h2>Farming Capital</h2>



<p>What generally defines our large landholders is their greater access to <em>capital</em>.  Now we don’t want to think of capital in the sort of money-denominated, fungible sense of modern finance, but in a very concrete sense: land, infrastructure, animals, and equipment.  As we’ll see, it isn’t just that the big men hold more of this capital, but that they hold fundamentally different <em>sorts</em> of capital and often use it very differently.</p>



<p>Of course this begins with <strong>land</strong>.  The thing to keep in mind is that prior to the modern period (really, later still – we might equally say prior to the industrial revolution; c. 1760 instead of c. 1500) the vast majority of economic activity was the production of the land.  That meant that land was both the primary form of holding wealth but also the main income-producing asset.  <strong>Consequently, larger land holdings are the assets that <em>enable</em> the accumulation of all of the other kinds of capital we’re discussing</strong>.  By having more land – typically <em>much</em> more land – than is required to feed a single household, these larger farmers can (as we’ll discuss in a bit) produce for markets and trade, enabling them to afford to acquire labor, animals, equipment and so on.  Our subsistence farmers of the last post, focused on producing for survival, would be hard-pressed to acquire much further in the way of substantial capital.</p>



<p>The next most important category is generally <strong>animals</strong>, particularly a <strong>plow team</strong> (typically two oxen, but sometimes draft horses and sometimes four instead of two).  I realize I didn’t spell this out explicitly in the previous piece, <strong>but while our small subsistence farmers may keep chickens or pigs on some small part of the pasture they have access to, they probably <em>do not</em> have a complete plow-team for their own farm</strong> (but I should note there is a <em>lot</em> of variability in this; my impression is that moving forward chronologically, you tend to see more plow-teams in the middle ages compared to the ancient world, and more in the early modern compared to the middle ages, occasionally held in common by villages).  Oxen and horses are <em>hideously</em> expensive, both to acquire but also to feed and for a family barely surviving one year to the next, they simply cannot afford them.  They also do not have herds of animals (because their small farms absolutely cannot support acres of pasturage) and they probably have limited access to <em>herdsmen</em> generally (that is, <a href="https://acoup.blog/2019/07/12/collections-the-lonely-city-part-i-the-ideal-city/">transhumant pastoralists</a> moving around the countryside) because those fellows will tend to want to interact with the community <em>leaders</em> who are, as noted above, the large landholders.  All of which is to say that while the small farmers may keep a few animals, they do not have access to significantly large numbers of animals (or humans), which matters, as we’ll see.</p>



<figure><img data-attachment-id="3981" data-permalink="https://acoup.blog/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/07/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje.jpg" data-orig-size="1280,834" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/07/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/07/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/07/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/07/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/07/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/07/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/07/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2020/07/1280px-deir_el-medina-20-grab_1-sennedjem-pflueger-saeerin-1982-gje.jpg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>From the ‘Tomb of Sennedjem” in Deir el-Medina, Egypt, a mural showing a farmer plowing his field with a pair of oxen as a plow-team, with his wife sowing behind him, dating to c. 1200 BC (New Kingdom). Apologies for poor quality of the image, getting a decent picture that is of the painting itself and not a reproduction is difficult; this one is from <a href="https://commons.wikimedia.org/wiki/Category:Tomb_of_Sennedjem#/media/File:Deir_el-Medina-20-Grab_1-Sennedjem-Pflueger-Saeerin-1982-gje.jpg">wikipedia</a>.</figcaption></figure>



<p>The first impact of having a plow-team is fairly obvious: <strong>a plow drawn by a couple of oxen is more effective than a plow pushed by a single human</strong>.  That means that a plow-team lets the same amount of farming <em>labor</em> sow a larger area of land (and if your thought is, “ok, but what about the <em>harvest</em>” – good, keep a pin in that, we’ll come back to it). <strong> It also allows for a larger, deeper plow, which in turn plows at a greater depth, which<a href="https://pubmed.ncbi.nlm.nih.gov/19093521/"> can improve yields </a></strong>(we’ll get into why and how plowing works next week).  You can easily see why, for a landholder with a large farm, having a plow-team is so useful: whereas the subsistence farmer struggles by having too much labor (and too many mouths to feed) and too little land, the big landholder has a lot of land they are trying to get farmed with as little labor as possible.  And of course, more to the point, the large landholder has the wealth and acreage necessary to buy and then pasture the animals in the plow-team.</p>



<p>The second major impact is <strong>manure</strong>.  Remember that our farmers live before the time of artificial fertilizer.  Crops, especially bulk cereal crops, wear out the nutrients in the soil quite rapidly after repeated harvests, which leaves the farmer two options.  The first, standard option, is that the farmer can fallow the field (which also has the advantage of disrupting certain pest life-cycles); depending on the farming method, fallowing may mean planting specific plants to renew the soil’s nutrients when those plants are uprooted and left to return to the soil in the field or it may mean simply turning the field over to wild plants with a similar effect.  The second option is using fertilizer, which in this case means manure.  Quite a lot of it.  Aggressive manuring, particularly on rich soils which have good access to moisture (because cropping also dries out the soil; fallowing can restore that moisture) allows the field to be fallowed less frequently and thus farmed more intensively.  In some cases it allowed rich farmland to be <em>continuously</em> cropped, with fairly dramatic increases in returns-to-acreage as a result.  And by increasing the nutrients in the soil, it also produces higher yields in a given season.</p>



<p>Now the humans in a farming household aren’t going to generate enough manure on their own to make a meaningful contribution to soil fertility.  But the larger landholders generally have two advantages in this sense.  <strong>First, because their landholdings are large, they can afford to turn over marginal farming ground to pasture for horses, cattle, sheep and so on</strong>; these …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/">https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24009134</guid>
            <pubDate>Fri, 31 Jul 2020 14:51:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Rogue Wave of Enterprise SaaS]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008717">thread link</a>) | @gmays
<br/>
July 31, 2020 | https://staysaasy.com/scaling/2020/07/29/the-rogue-wave-of-enterprise-saas.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/scaling/2020/07/29/the-rogue-wave-of-enterprise-saas.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://staysaasy.com/assets/rogue-wave/freakwave.jpg" alt="Freak wave"></p>

<p>During the pandemic, I’ve done my civic duty and spent lockdown reading a ton of random stuff on the internet. In the midst of a Wikipedia binge, I went down a rabbit hole on <a href="https://en.wikipedia.org/wiki/Rogue_wave">rogue waves</a>: massive waves that occur in the middle of the ocean, endangering ships and generating <a href="https://www.youtube.com/watch?v=pu4ogCy5d4k">kickass Youtube content</a>.</p>

<p>The concept of a rogue wave reminded me of a particularly challenging stage in the life of many venture-backed enterprise SaaS startups. Similar to how a rogue wave forms, during this phase many Small Problems coincide and create a Big Problem. Also like rogue waves, this moment in the life of a high-growth enterprise SaaS business is uncommon – it seems to occur around $5-20 million ARR, which relatively few companies reach, and can seem almost mythical. And finally, the effects of both rogue waves and this challenging startup stage are predictable: if you spend long enough on the high seas, they’re waiting for you.</p>

<p>I’ve seen this phenomenon both in-person as an operator and as an observer of other companies, and I do believe it’s real. I’m writing this essay in order to:</p>

<ul>
  <li>Share what I’ve seen</li>
  <li>Provide some opinions on what you can do about it</li>
</ul>

<p>Hopefully I can be the crusty old mariner bringing back tales that others find useful.</p>

<h2 id="hitting-the-wall">Hitting the Wall</h2>

<p><img src="https://staysaasy.com/assets/rogue-wave/boat.jpg" alt="Big boat, bigger wave">
Startups can be stressful</p>

<p>The rogue wave typically seems to hit between $5M and $20M in ARR. If you’re operating with a common venture-backed SaaS model of <a href="https://www.saastr.com/how-to-figure-out-your-competitors-revenues-in-about-70-seconds/">$1-200k ARR per employee</a>, this is around where you’ll hit the <a href="https://www.bbc.com/future/article/20191001-dunbars-number-why-we-can-only-maintain-150-relationships">Dunbar number</a> of ~150 people: the point where you can no longer operate as a large family, and need to start acting like a corporation. <em>(Note that the post linked is from 2012 – SaaS has since exploded, and more companies are raising huge rounds and hiring more on less revenue)</em></p>

<p>Crossing the 150-person barrier is both operationally and emotionally difficult:</p>

<ul>
  <li>Operational: We have so many teams, we need regular status reports!</li>
  <li>Emotional: Why do I need to send <em>you</em> a status report all of a sudden, I thought we were all friends here?!</li>
</ul>

<p>This transition point is also when many leaders who excelled in scrappy startup mode <a href="https://staysaasy.com/scaling/2020/06/27/hardest-part-of-startup-scale-yourself.html">struggle to level up</a> in a larger organization. Some successfully scale themselves (slow, painful) and others will leave the company (fast, but often even more painful).</p>

<p>Many of the first contracts that you closed post-traction come up for renewal around this point (in the enterprise – SMB SaaS has less predictable growth profiles). If you’re following a <a href="https://www.battery.com/powered/helping-entrepreneurs-triple-triple-double-double-double-to-a-billion-dollar-company/">triple-triple-double-double-double</a> growth path, you’ll be at roughly your second triple. There will be too many customers for the founding team to personally visit and retain everyone.</p>

<p>At this point you’ll need to renew “real” customers, not just friends who took a flyer on your infant product. These aren’t the earliest adopters who will be with you through thick and thin and are really closer to partners. These are real live paying customers who will leave if your product is screwed up. As these renewals approach, a mature post-sales motion becomes essential.</p>

<p>The expectations around your revenue also become more real at this stage. Under about $10M ARR, your revenue projections can be a mild shitshow. But the expectation that you’ll have at least some semblance of predictability steadily increases.</p>

<p>And through it all you need to continue to scale the product. Your code is no longer a series of never-ending green fields rolling off into the distance, and non-trivial parts of your product will need to be meaningfully restructured. You’re burdened by decisions made years ago, often by people who are no longer on the team.</p>

<p>This is especially true for enterprise SaaS. Enterprise products are much more unwieldy than jewel-box consumer products, as they have to support many more users and workflows. Consumer products are like Chipotle: a small, carefully curated set of menu items, built for elegance and efficiency. Enterprise products are like the Cheesecake Factory: you can get steak, pasta, a milkshake and 4 kinds of margarita in the same meal. You need to level up how your team builds products.</p>

<h2 id="cresting-the-wave">Cresting the Wave</h2>

<p>I’m writing about this phenomenon because if you haven’t seen or heard about it, there isn’t really a good way to realize that it might be coming. Even if it isn’t preventable, it’s better to know what’s on the horizon. After all, being able to see around corners is why many companies hire experienced operators.</p>

<p>I won’t claim to be an expert on how to react, but I can share a few things that I think work well and a few that don’t, and what I would do if I had to go through this phase again.</p>

<h3 id="the-crew">The Crew</h3>

<p>First, I would do my best to get the right team in place in advance. In particular, I would make sure that I had very strong functional heads for the functions that will be strained the most: Product, Engineering, Marketing, Sales, Support, and Customer Success. You don’t need every role covered, but it saves headaches to know that some parts of the team are bulletproof. This isn’t the time for unforced errors.</p>

<p><img src="https://staysaasy.com/assets/rogue-wave/pirate-crew.jpg" alt="Pirates of the Caribbean crew">
You want a senior crew. You can tell that Sharkman here has experience and won’t freak out when the database goes down or a large account churns.</p>

<p>I also recommend hiring senior team members who can help see around corners and anticipate issues. This is a taxing time period because it’s so damn busy, and raw, well-directed horsepower tends to carry the day in those situations. More importantly, seasoned operators have typically seen challenging times before, and have the composure to handle them calmly because they know that things are always on fire.</p>

<p>It’s tempting during these busy times to make very junior hires such as new college graduates or coding bootcamp grads just to put butts in seats. These folks can be excellent hires in calmer times, but the chaos caused by too many inexperienced employees is very difficult while you’re cresting the wave.</p>

<h3 id="steering-the-ship">Steering the Ship</h3>

<p>Startups are generally fairly stressful, and that’s heightened in this time period. When operational problems strike in stressful times, it’s common to blame the people involved rather than processes – in reality, bad processes or incentives are usually the root cause.</p>

<p>Generally speaking, the faster you’re growing, the more lightweight your processes should be. When you’re in rapid scaling mode your operational tempo is constantly changing, so there’s no point boiling the ocean to create a perfect process when next month so much will have changed.</p>

<p>For example: when confronting a startup rogue wave, I would not choose to reinvent a completely new system for launching new features. Instead, use 20% of the time to set up a simple, predictable process that gives you 80% of the value. Example: set up a recurring check-in meeting where upcoming releases are discussed by PMs and Tech Leads + a Slack thread where all new releases are announced when they go-live. It won’t be perfect, but you can get this up and running in 15 minutes.</p>

<h3 id="commit">Commit</h3>

<p>This is not the time to hedge your decisions or waffle on strategy.</p>

<p>For example: in general, I prefer to give people a generous window of time to grow into stretch roles. Promoting from within builds continuity, leads to a more invested team, and motivates others by demonstrating that you’re creating strong career paths. But in this phase it’s especially important that you commit to keeping or replacing leaders fast, as there’s just too much going on.</p>

<p>If you’re 30% of the way up a 100 foot wall of water and decide to adjust course, you’re going to get slammed.</p>

<h3 id="keeping-calm">Keeping Calm</h3>

<p>Whatever you do, <em>don’t freak out</em>. When it feels like shit is hitting the fan everywhere, it’s easy to want to react and search for magic solutions. Hire a new Head of X! Spend less! No wait, spend <em>more</em>! Pause development and focus on tech debt! Actually our largest customer needs more features, cancel all tech debt projects!</p>

<p>In reality, to take a line from The Sopranos, <a href="https://www.youtube.com/watch?v=_po7So0MKq4">it won’t be cinematic</a>. Life isn’t a movie. There are no magic fixes – this challenging phase gets resolved by showing up and executing in an unflashy way for months. Magic fixes never really exist, and that’s especially true since this crucible stems from several medium-sized problems amplifying one another.</p>

<p>Searching for a unified solution to your troubles risks distraction. The road is reasonably straightforward and the challenges are tractable: there are just a lot of them. Just like an actual rogue wave, you can’t flee or dodge the factors that make crossing these rogue waves so difficult. You succeed by pointing your boat right at the problem and hitting the gas. Keeping calm doesn’t mean being stubborn or refusing to change, but it does mean that you can’t second guess your decisions – especially when it feels like you’re climbing a wall of water.</p>

<h2 id="takeaways">Takeaways</h2>

<p>Not everyone makes it over the wave – of the roughly 10 cases that I’ve observed, roughly half had their growth stunted for at least several years after hitting this stage. In my opinion this SaaS rogue wave should be taken seriously.</p>

<p>But the good news is that once you’ve crossed the wave, you can speed up again. As you’re rising up the wall everything goes into slow motion; but once you’ve crested the top, your acceleration can increase again as you’ve set yourself up with a more stable operating model and a hardened team.</p>

<p>This is a wonderful time, as there’s so much opportunity. Your team is still in place. The market opportunity is there, and people are buying. And once you’re over the top, the water is much calmer towards the horizon.</p>

<p>In conclusion:</p>

<ul>
  <li>Many challenging situations tend to arise simultaneously when high growth enterprise SaaS companies hit roughly $5-20 million ARR.</li>
  <li>The good news is that after this phase things get easier – the bad news is that it’s not easily avoidable.</li>
  <li>The best way to move forward is to focus on executing – and don’t be overly reactive.</li>
</ul>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/scaling/2020/07/29/the-rogue-wave-of-enterprise-saas.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008717</guid>
            <pubDate>Fri, 31 Jul 2020 14:09:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Types in Ruby 3, RBS, and Sorbet]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008520">thread link</a>) | @bradleybuda
<br/>
July 31, 2020 | https://sorbet.org/blog/2020/07/30/ruby-3-rbs-sorbet | <a href="https://web.archive.org/web/*/https://sorbet.org/blog/2020/07/30/ruby-3-rbs-sorbet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>Yesterday Square <a href="https://developer.squareup.com/blog/the-state-of-ruby-3-typing/">posted an article</a> to their blog introducing
<a href="https://github.com/ruby/rbs">RBS</a> (Ruby Signature), a type syntax format for Ruby 3.</p>
<p>We’d like to take a second to speak to how RBS relates to Sorbet. The short
version: Sorbet will happily incorporate RBS as a way to specify type
annotations, in addition to the existing syntax Sorbet supports. Stripe still
has a very strong commitment to Sorbet’s continued progress and success. While
the Ruby core team has been working on syntax, we’ve been working on features
that build on top of that syntax.</p>
<p>With that in mind, I’d love to start a discussion of some of the finer points of
what this announcement means for Ruby, and for Sorbet.</p>
<!--truncate-->
<h2>RBI? RBS?</h2>
<p>As <a href="https://youtu.be/2g9R7PUCEXo?t=2076">Matz announced at RubyConf 2019</a>, Ruby 3 plans to ship type
annotations for the standard library in a particular format. We’ve been meeting
with Matz and the Ruby core team to provide input on our experience and learn
from them how they’re thinking about types so that Sorbet wil be ready. We’re
<a href="https://sorbet.org/docs/faq#when-ruby-3-gets-types-what-will-the-migration-plan-look-like">committed</a> to supporting Ruby 3’s type syntax.</p>
<p>In the mean time, we’ve kept busy. While the Ruby core team has been working on
the RBS syntax over the past year, the Sorbet team has delivered tons of other
features. A sampling of features that didn’t exist a year ago:</p>
<ul>
<li>Go to Definition (Aug 2019)</li>
<li><a href="https://sorbet.org/docs/exhaustiveness">Exhaustiveness checking</a> (Aug 2019)</li>
<li><a href="https://sorbet.org/docs/tenum">Typed enums</a> (Nov 2019)</li>
<li>Autocompletion (Nov 2019)</li>
<li>Step-function improvements in IDE speed (Feb 2020, June 2020)</li>
</ul>
<p>These features make Sorbet users more productive, empowering them to do more
with Sorbet. We’ll happily incorporate any other syntax the Ruby core team wants
to build.</p>
<h2>Wait, a wholly separate file?</h2>
<p>RBS type signatures are placed in a separate file. While Sorbet also offers
inline syntax (more later), we believe that supporting type signatures in a
separate file is necessary. Consider: most of the Ruby standard library is
implemented in C for performance (e.g., all <code>Array</code> and <code>Hash</code> functions, and
many others). There must be a way to ascribe types to these internally defined
classes and methods.</p>
<p>Providing types for the standard library is incredibly important! In completely
untyped, unannotated Ruby codebases, people who try out Sorbet for the first
time find that about 25% of call sites already have static type coverage. Why?
Everyday Ruby code uses the standard library abundantly, and Sorbet includes
type definitions for the standard library out of the box!</p>
<p>Additionally, there will always be libraries that prefer not using type
annotations. To integrate an untyped library into a typed Ruby codebase, there
must be a place for these types to live outside of that project. In fact, we
already have the <a href="https://github.com/sorbet/sorbet-typed">sorbet-typed</a> repo for this purpose.</p>
<p>Thus, both Sorbet and Ruby 3 support type annotations in separate files (via RBI
files and RBS files, respectively).</p>
<h2>What about inline type annotations?</h2>
<p>There are people using Ruby who still prefer type annotations to live in the
code itself. We’ve built Sorbet to cater to both groups: those who <strong>like and
don’t like</strong> type annotations benefit from Sorbet.</p>
<p>How? Sorbet implements a <a href="https://sorbet.org/docs/gradual">gradual type system</a>. Without any type annotations,
Sorbet will do its best to understand and offer feedback on your code. With type
annotations exclusively in separate files, Sorbet will understand more and offer
better feedback. With inline type annotations, people can tell Sorbet every
little detail about their code so Sorbet can offer incredible feedback. For
these people, reading the types is as valuable as reading the code itself.</p>
<p>Sorbet has always provided syntax for inline type annotations. Annotations
aren’t required by Sorbet—they’re there for the people who want to empower
Sorbet to help them even more. Whether you love type annotations or not, Sorbet
still provides value.</p>
<h2>Why are inline type annotations useful?</h2>
<p>As we mentioned above, for those teams and projects who really want static
typing, inline type annotations become essential. Types carry intent, and there
are frequently places where inferring the intent could be ambiguous. Consider
this snippet:</p>
<pre><code>xs = [<span>1</span>, <span>2</span>, <span>3</span>]
xs &lt;&lt; <span>nil</span>


</code></pre>
<p><a href="https://sorbet.run/#%23%20typed%3A%20true%0A%0Axs%20%3D%20%5B1%2C%202%2C%203%5D%0Axs%20%3C%3C%20nil">→ View on sorbet.run</a></p>
<p>A type checker could infer one of two types here:</p>
<ol>
<li>either the programmer meant for <code>xs</code> to be an array of <code>Integer</code>'s and
<code>nil</code>'s (i.e., <code>T::Array[T.nilable(Integer)]</code> in Sorbet’s syntax), or</li>
<li>the programmer made a mistake, and didn’t intend to allow <code>nil</code>'s in <code>xs</code>
(i.e., it was intended to be a <code>T::Array[Integer]</code>, and this code should
report a static error).</li>
</ol>
<p>Any static checker must assume one of these outcomes, but there are times when
either might make sense. Explicit annotations resolve these ambiguities. In this
case, Sorbet assumes (2) by default, but other type systems do other things. For
example, Flow <a href="https://flow.org/try/#0MYewdgzgLgBAHhGBeGBtAjAGhgJmwZgF0BuAKAQDoAHAVwgAsAKMGgG1YEpig">assumes (1) by default</a>.</p>
<p>Here’s how to use an inline annotation in Sorbet to explicitly declare that (1)
is intended:</p>
<pre><code>xs = T.let([<span>1</span>, <span>2</span>, <span>3</span>], T::Array[T.nilable(Integer)])
xs &lt;&lt; <span>nil</span>


</code></pre>
<p><a href="https://sorbet.run/#%23%20typed%3A%20true%0A%0Axs%20%3D%20T.let(%5B1%2C%202%2C%203%5D%2C%20T%3A%3AArray%5BT.nilable(Integer)%5D)%0Axs%20%3C%3C%20nil">→
View on sorbet.run</a></p>
<h2>Inline type annotations must be Ruby syntax</h2>
<p>For the time being, Matz and the Ruby core team want to experiment with type
annotations without changing Ruby syntax, because that would require everyone to
upgrade to a specific Ruby version to benefit. Because Sorbet values inline type
annotations, we embedded a type annotation language in Ruby with no syntax
changes needed:</p>
<pre><code>extend T::Sig

sig {params(<span>strings:</span> T::Array[String]).returns(Integer)}
<span><span>def</span> <span>count_letters</span><span>(strings)</span></span>
  strings.map(&amp;<span>:length</span>).sum
<span>end</span>
</code></pre>
<p><a href="https://sorbet.run/#%23%20typed%3A%20true%0A%0Aextend%20T%3A%3ASig%0A%0Asig%20%7Bparams(strings%3A%20T%3A%3AArray%5BString%5D).returns(Integer)%7D%0Adef%20count_letters(strings)%0A%20%20strings.map(%26%3Alength).sum%0Aend">→
View on sorbet.run</a></p>
<p>Sorbet’s syntax is 100% valid Ruby, which has tons of benefits!</p>
<ul>
<li>Syntax highlighting for type annotations already works in 100% of Ruby
editors.</li>
<li>There’s no transpiler step required—Ruby code with Sorbet type annotations
runs directly.</li>
<li>Every RuboCop rule ever written works with Sorbet type annotations.</li>
<li>Any Ruby IDE with Go to Definition already has Go to Definition on type
annotations.</li>
<li>Sorbet’s RBI files are just Ruby code with empty method bodies, reusing the
inline syntax.</li>
<li>It’s backwards compatible with all supported versions of Ruby.</li>
</ul>
<p>The obvious downside is that there are prettier inline type annotation syntaxes
that are not valid Ruby. The Ruby grammar is not so complicated that it couldn’t
be changed to support type annotations. But again, this syntax does so well
<strong>because</strong> it doesn’t fracture the Ruby community with incompatible syntax
changes.</p>
<h2>Sorbet is committed to improving</h2>
<p>At the end of the day, it’s not a choice between Ruby 3 or Sorbet—you can have
both at the same time. We love that the Ruby core team is bringing types to
Ruby, and we’re happy to incorporate their work into Sorbet. We plan to give
back too: it’s likely that the initial release of RBS files for the Ruby
standard library will be created by converting Sorbet’s already extensive
standard library annotations into the RBS format.</p>
<p>At the same time, we’re hard at work improving Sorbet. Stripe has millions of
lines of Ruby code and that number is only growing. We’re nearing our <a href="https://en.wikipedia.org/wiki/High_availability#Percentage_calculation">second
nine</a> of percentage of files at <code># typed: true</code> or above—which is to say, those
millions of lines of Ruby use a lot of types. We have hundreds of engineers
writing Ruby and using our Sorbet-powered IDE every day.</p>
<p>Sorbet type checks these millions of lines of Ruby code in seconds, helps
prevent countless production incidents, and helps new Stripe engineers spin up
fast. And it does all this today! If you want to try it out, check out the docs:</p>
<p><a href="https://sorbet.org/docs/adopting">→ Adopting Sorbet in an Existing Codebase</a></p>
<p>or play around with small Sorbet examples online:</p>
<p><a href="https://sorbet.run/">→ Sorbet playground</a></p>
<p>Sorbet already has extensive type annotations for the Ruby standard library,
thanks in large part to the nearly 200 contributors to Sorbet that you can find
<a href="https://github.com/sorbet/sorbet/graphs/contributors">on GitHub</a>, the vast majority of whom come to Sorbet from outside
of Stripe and the Sorbet team.</p>
<p>We’re happy that the Ruby core team is focused on continually improving Ruby,
because we are too. ❤️</p>
<p>— Jake “jez” Zimmerman, on behalf of the Sorbet team</p>
<p><em>Thanks to Dmitry Petrashko, James Iry, Trevor Elliott, and Soutaro Matsumoto
for reading early drafts of this post.</em></p>
</span></p></div></div></div>]]>
            </description>
            <link>https://sorbet.org/blog/2020/07/30/ruby-3-rbs-sorbet</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008520</guid>
            <pubDate>Fri, 31 Jul 2020 13:48:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Your Parent’s Internet – Solving the Misinformation Problem]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008470">thread link</a>) | @lanecwagner
<br/>
July 31, 2020 | https://qvault.io/2020/07/31/fake-news-misinformation-fix/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/07/31/fake-news-misinformation-fix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>The age of information is not what we all hoped it would be. We successfully digitized the majority of human knowledge, and we even made it freely accessible to most. Now the problem is different, we have <em>too much</em> information. Answers to most questions can be found in thousands of distinct places online, and the new problem is <em>“whos information can we trust?”</em></p>



<h2>What Platforms Think They Should Do About Fake News</h2>



<p>Twitter and Facebook have recently been under scrutiny for their censorship of coronavirus related misinformation. For example, a <a aria-label="undefined (opens in a new tab)" href="https://www.bbc.com/news/53559938" target="_blank" rel="noreferrer noopener">video claiming Hydroxychloroquine is a Corona cure</a> recently went viral on Facebook, and the video keeps getting taken down. The video contains some wild assertions, made by Stella Immanuel, who also believes that gynecological problems are the result of <a aria-label="undefined (opens in a new tab)" href="https://www.youtube.com/watch?v=9yCXCP3evAg" target="_blank" rel="noreferrer noopener">spiritual relationships</a>.</p>



<p>By removing content they believe to be dubious, Twitter and Facebook have made themselves arbiters of truth. Anecdotally, all the posts I’ve seen them remove HAVE contained misinformation, but the fact remains… these platforms have become self-appointed authorities on the veracity of our information.</p>



<p><strong>This is a problem.</strong></p>



<h2>So We Can’t Censor?</h2>



<p>We certainly can, and we certainly should in some cases. Let’s get some obvious ones out of the way:</p>



<ul><li>Child Pornography</li><li>Death Threats</li><li>Doxing</li></ul>



<p>There may be some other clear examples where censoring is unquestionably the right choice, though I doubt there are many. Let’s look at some more controversial examples:</p>



<ul><li>Hate Speech</li><li>Misinformation</li></ul>



<p>I would posit that here the answer is contingent on <em>who </em>is doing the censoring. While hate speech and misinformation are disgusting, I don’t want a government deciding <em>what </em>is hate speech, or deciding <em>what </em>is truth.</p>



<div><figure><img src="https://qvault.io/wp-content/uploads/2020/07/war-is-peace-300x225.jpg" alt="war is peace 1984 orwell" srcset="https://qvault.io/wp-content/uploads/2020/07/war-is-peace-300x225.jpg 300w, https://qvault.io/wp-content/uploads/2020/07/war-is-peace-768x576.jpg 768w, https://qvault.io/wp-content/uploads/2020/07/war-is-peace.jpg 877w" sizes="(max-width: 300px) 100vw, 300px" data-srcset="https://qvault.io/wp-content/uploads/2020/07/war-is-peace-300x225.jpg 300w, https://qvault.io/wp-content/uploads/2020/07/war-is-peace-768x576.jpg 768w, https://qvault.io/wp-content/uploads/2020/07/war-is-peace.jpg 877w" data-src="https://qvault.io/wp-content/uploads/2020/07/war-is-peace-300x225.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>George Orwell, 1984</figcaption></figure></div>



<p>That said, I certainly want an online system where hate speech and misinformation are effectively filtered out of the conversation. Ideally, every online participant is a virtuous, educated, and concerned conversationalist. If this were the case, posts of an undesirable nature would effectively be ignored due to not receiving the likes, shares, upvotes, and comments they need to spread.</p>



<p>In reality, we can’t have such a pacifistic approach. We need to <a href="https://www.lesswrong.com/posts/tscc3e5eujrsEeFN4/well-kept-gardens-die-by-pacifism" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">protect our gardens</a>.</p>



<h2>Misinformation – What Should Platforms Do?</h2>



<p>It starts here. All online platforms are responsible for the tools they provide for moderation, if not for the moderation itself.</p>



<p>Platforms <strong>should</strong>:</p>



<ul><li>Remove dangerous content such as doxing, threats, child trafficking, etc</li><li>Provide tools for users to mark content as harmful or misleading</li><li>Mark content as dubious</li></ul>



<p>Platforms <strong>should not:</strong></p>



<ul><li><em>Remove </em>misleading content</li></ul>



<p>By removing misleading content, platforms run the risk of fueling an <a aria-label="undefined (opens in a new tab)" href="https://rationalwiki.org/wiki/Argumentum_ad_martyrdom" target="_blank" rel="noreferrer noopener">argumentum ad martyrdom</a> mentality. Removing information can have an adverse effect, causing people to suspect we have a nefarious reason for removing it.</p>



<blockquote><p>But the fact that some geniuses were laughed at does not imply that all who are laughed at are geniuses. They laughed at&nbsp;Columbus, they laughed at Fulton, they laughed at the Wright brothers. But they also laughed at Bozo the Clown.</p><cite>– Carl Sagan, Probably</cite></blockquote>



<h2>What Should Users Do About Misinformation and Fake News?</h2>



<p>Users <strong>should</strong>:</p>



<ul><li>Read entire articles before liking, sharing, or commenting</li><li>Deploy extra skepticism to information with a clear political or monetary agenda</li><li>Be self-aware about their preconceived notions and confirmation biases</li><li>Look for the primary source of information</li><li>Ensure information is up-to-date</li></ul>



<p>Users <strong>should not:</strong></p>



<ul><li>Reward clickbait titles with engagement</li><li>Exclusively follow, subscribe, or search for content that aligns with their current beliefs</li><li>Assume your position is valid because people are trying to remove your content</li><li>Trust articles and posts coming from sites that appear <a aria-label="undefined (opens in a new tab)" href="https://www.sitelock.com/blog/is-this-website-safe/" target="_blank" rel="noreferrer noopener nofollow">unsafe</a></li></ul>



<div><div>
<h2>Thanks For Reading!</h2>



<p>Follow us on Twitter <a href="https://twitter.com/q_vault">@q_vault</a> if you have any questions or comments</p>



<p>Take game-like coding courses on <a href="https://classroom.qvault.io/#/">Qvault Classroom</a></p>



<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe">Subscribe</a> to our Newsletter for more educational articles</p>
</div></div>

		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/07/31/fake-news-misinformation-fix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008470</guid>
            <pubDate>Fri, 31 Jul 2020 13:43:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What every developer should know about consistency]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008416">thread link</a>) | @MindGods
<br/>
July 31, 2020 | https://robertovitillo.com/what-every-developer-should-know-about-consistency/ | <a href="https://web.archive.org/web/*/https://robertovitillo.com/what-every-developer-should-know-about-consistency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>July 31, 2020</p></header><p>If you make a request to a database to update some data, the change won’t necessarily be visible to other clients right away, even if your request has completed successfully. Whether it becomes visible sooner rather than later depends on the consistency guarantees offered by the database.</p><p>“But wait, aren’t databases supposed to take care of consistency issues for me?” I hear you ask. Some databases come with counter-intuitive consistency guarantees to provide high availability and performance. Others have knobs that allow you to chose whether you want better performance or stronger consistency guarantees, like <a href="https://docs.microsoft.com/en-us/azure/cosmos-db/consistency-levels">Azure’s Cosmos DB</a>. Because of that, you need to know what the trade-offs are, and whether there are knobs you can use to tune your database to your specific use-case.</p><p>Let’s take a look at what happens when you send a request to a database. In an ideal world, your request executes instantaneously:</p><p><span>
      <a href="https://robertovitillo.com/static/37663397db28ea1852607ed34f7575d1/807a0/ideal.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="ideal" title="ideal" src="https://robertovitillo.com/static/37663397db28ea1852607ed34f7575d1/fcda8/ideal.png" srcset="https://robertovitillo.com/static/37663397db28ea1852607ed34f7575d1/12f09/ideal.png 148w,https://robertovitillo.com/static/37663397db28ea1852607ed34f7575d1/e4a3f/ideal.png 295w,https://robertovitillo.com/static/37663397db28ea1852607ed34f7575d1/fcda8/ideal.png 590w,https://robertovitillo.com/static/37663397db28ea1852607ed34f7575d1/efc66/ideal.png 885w,https://robertovitillo.com/static/37663397db28ea1852607ed34f7575d1/c83ae/ideal.png 1180w,https://robertovitillo.com/static/37663397db28ea1852607ed34f7575d1/807a0/ideal.png 1652w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><p>But we don’t live an ideal world - your request needs to reach the data store, which then needs to process the request and finally send back a response to you. All these actions take time and are not instantaneous:</p><p><span>
      <a href="https://robertovitillo.com/static/0b7b29c09562260ae62841025b9b79fa/807a0/cones.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="cones" title="cones" src="https://robertovitillo.com/static/0b7b29c09562260ae62841025b9b79fa/fcda8/cones.png" srcset="https://robertovitillo.com/static/0b7b29c09562260ae62841025b9b79fa/12f09/cones.png 148w,https://robertovitillo.com/static/0b7b29c09562260ae62841025b9b79fa/e4a3f/cones.png 295w,https://robertovitillo.com/static/0b7b29c09562260ae62841025b9b79fa/fcda8/cones.png 590w,https://robertovitillo.com/static/0b7b29c09562260ae62841025b9b79fa/efc66/cones.png 885w,https://robertovitillo.com/static/0b7b29c09562260ae62841025b9b79fa/c83ae/cones.png 1180w,https://robertovitillo.com/static/0b7b29c09562260ae62841025b9b79fa/807a0/cones.png 1652w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><p>The best guarantee a database can provide is that the request executes somewhere between its invocation and completion time. You might think that this doesn’t look like a big deal - after all, it’s what you are used to when writing single-threaded applications - if you assign 1 to x and read its value right after, you expect to find 1 in there, assuming there is no other thread writing to the same variable. But, once you start dealing with data stores that replicate their state on multiple machines for high availability and scalability, all bets are off. To understand why that’s the case, we will explore the trade-offs a system designer has to make to implement reads in a simplified model of a distributed database.</p><p>Suppose we have a distributed key-value store, which is composed of a set of replicas. The replicas elect a leader among themselves, which is the only node that can accept writes. When the leader receives a write request, it broadcasts it asynchronously to the other replicas. Although all replicas receive the same updates in the same order, they do so at different times. </p><p>You are tasked to come up with a strategy to handle read requests - how would you go about it? Well, a read can potentially be served by the leader or a replica. If all reads were to go through the leader, the throughput would be limited by what a single node can handle. Alternatively, any replica could serve any read request - that would definitely scale, but then two clients, or observers, could have a different view of the system’s state, as replicas can lag behind the leader and between them.</p><p>Intuitively, there is a trade-off between how consistent the observers’ views of the system are, and the system’s performance and availability. To understand this relationship, we need to define precisely what we mean by consistency. We will do so with the help of <a href="https://jepsen.io/consistency">consistency models</a>, which formally define the possible views of the system’s state observers can experience. </p><h2 id="strong-consistency"><a href="#strong-consistency" aria-label="strong consistency permalink"></a>Strong Consistency</h2><p>If clients send writes and reads exclusively to the leader, then every request appears to take place atomically at a very specific point in time as if there was a single copy of the data. No matter how many replicas there are or how far behind they are lagging, as long as the clients always query the leader directly, from their point of view there is a single copy of data.</p><p>Because a request is not served instantaneously, and there is a single node serving it, the request executes somewhere between its invocation and completion time. Another way to think about it is that once a request completes, it’s side-effects are visible to all observers:</p><p><span>
      <a href="https://robertovitillo.com/static/feea00679261f20e62755aecf682c527/95fa1/linearizability.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="linearizability" title="linearizability" src="https://robertovitillo.com/static/feea00679261f20e62755aecf682c527/fcda8/linearizability.png" srcset="https://robertovitillo.com/static/feea00679261f20e62755aecf682c527/12f09/linearizability.png 148w,https://robertovitillo.com/static/feea00679261f20e62755aecf682c527/e4a3f/linearizability.png 295w,https://robertovitillo.com/static/feea00679261f20e62755aecf682c527/fcda8/linearizability.png 590w,https://robertovitillo.com/static/feea00679261f20e62755aecf682c527/efc66/linearizability.png 885w,https://robertovitillo.com/static/feea00679261f20e62755aecf682c527/c83ae/linearizability.png 1180w,https://robertovitillo.com/static/feea00679261f20e62755aecf682c527/95fa1/linearizability.png 1816w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><p>Since a request becomes visible to all other participants between its invocation and completion time, there is a real-time guarantee that must be enforced - this guarantee is formalized by a consistency model called <a href="https://jepsen.io/consistency/models/linearizable">linearizability</a>, or strong consistency. Linearizability is the strongest consistency guarantee a system can provide for single-object requests. </p><p>What if the client sends a read request to the leader, but by the time the request gets there, the server that received the request thinks it’s still the leader, but it actually was deposed? If the ex-leader was to process the request, the system would no longer be strongly consistent. To guard against this case, the presumed leader first needs to contact a majority of the replicas to confirm whether it still is the leader. Only then is it allowed to execute the request and send back the response to the client. This considerably increases the time required to serve a read.</p><h3 id="sequential-consistency"><a href="#sequential-consistency" aria-label="sequential consistency permalink"></a>Sequential Consistency</h3><p>So far, we have discussed serializing all reads through the leader. But doing so creates a single chokepoint, which limits the system’s throughput. On top of that, the leader needs to contact a majority of replicas to handle a read. To increase the read performance, we could allow the replicas to handle requests as well.</p><p>Even though a replica can lag behind the leader, it will always receive new updates in the same order as the leader. If a client A only ever queries replica 1, and client B only ever queries replica 2, the two clients will see the state evolving at different times, as replicas are not entirely in sync:</p><p><span>
      <a href="https://robertovitillo.com/static/222569085b17d0f9796c0c07c93f10cb/555cf/sequential.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="sequential" title="sequential" src="https://robertovitillo.com/static/222569085b17d0f9796c0c07c93f10cb/fcda8/sequential.png" srcset="https://robertovitillo.com/static/222569085b17d0f9796c0c07c93f10cb/12f09/sequential.png 148w,https://robertovitillo.com/static/222569085b17d0f9796c0c07c93f10cb/e4a3f/sequential.png 295w,https://robertovitillo.com/static/222569085b17d0f9796c0c07c93f10cb/fcda8/sequential.png 590w,https://robertovitillo.com/static/222569085b17d0f9796c0c07c93f10cb/efc66/sequential.png 885w,https://robertovitillo.com/static/222569085b17d0f9796c0c07c93f10cb/c83ae/sequential.png 1180w,https://robertovitillo.com/static/222569085b17d0f9796c0c07c93f10cb/555cf/sequential.png 1960w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><p>The consistency model in which operations occur in the same order for all observers, but doesn’t provide any real-time guarantee about when an operation’s side-effect becomes visible to the observers, is called <a href="https://jepsen.io/consistency/models/sequential">sequential consistency</a>. The lack of real-time guarantees is what differentiates sequential consistency with linearizability. </p><p>A simple application of this model is a producer/consumer system synchronized with a queue - a producer node writes items to the queue, which a consumer reads. The producer and the consumer see the items in the same order, but the consumer lags behind the producer.</p><h3 id="eventual-consistency"><a href="#eventual-consistency" aria-label="eventual consistency permalink"></a>Eventual Consistency</h3><p>Although we managed to increase the read throughput, we had to pin clients to replicas - what if a replica goes down? We could increase the availability of the store by allowing a client to query any replica. But, this comes at a steep price in terms of consistency. Say there are two replicas 1 and 2, where replica 2 lags behind replica 1. If a client queries replica 1 and right after replica 2, it will see a state from the past, which can be very confusing. The only guarantee a client has is that eventually, all replicas will converge to the final state if the writes to the system stop. This consistency model is called eventual consistency. </p><p>It’s challenging to build applications on top of an eventually consistent data store because the behavior is different from the one you are used to when writing single-threaded applications. Subtle bugs can creep up that are hard to debug and to reproduce. Yet, in eventual consistency’s defense, not all applications require linearizability. You need to make the conscious choice whether the guarantees offered by your data store, or lack thereof, satisfy your application’s requirements. An eventually consistent store is perfectly fine if you want to keep track of the number of users visiting your website, as it doesn’t really matter if a read returns a number that is slightly out of date. But for a payment processor, you definitely want strong consistency.</p><p>There are more <a href="https://jepsen.io/consistency">consistency models</a> than the ones presented in this post. Still, the main intuition behind them is the same: the stronger the consistency guarantees are, the higher the latency of individual operations is, and the less available the store becomes when failures happen. This relationship is formalized by the <a href="https://en.wikipedia.org/wiki/PACELC_theorem">PACELC theorem</a>. It states that in case of network partitioning (P) in a distributed computer system, one has to choose between availability (A) and consistency (C), but else (E), even when the system is running normally in the absence of partitions, one has to choose between latency (L) and consistency (C). </p><p>In my <a href="https://systemdesignmanual.com/">system design book</a>, I explore other tunable trade-offs data stores make to guarantee high availability and performance, like the isolation guarantees that prevent a group of operations within a transaction from interfering with other concurrently running transactions. </p><hr></article></div>]]>
            </description>
            <link>https://robertovitillo.com/what-every-developer-should-know-about-consistency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008416</guid>
            <pubDate>Fri, 31 Jul 2020 13:37:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zuckerberg expects 50% of employees to go “remote long term, within 5-10 years”]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008242">thread link</a>) | @RayMan1
<br/>
July 31, 2020 | http://alugy.com/tech/zuckerberg-expects-that-50-of-employees-will-stay-remote-long-term-within-5-10-years/ | <a href="https://web.archive.org/web/*/http://alugy.com/tech/zuckerberg-expects-that-50-of-employees-will-stay-remote-long-term-within-5-10-years/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><p><a href="http://alugy.com/wp-content/uploads/2020/04/startup-849804_640.jpg" data-caption=""><img width="640" height="457" src="http://alugy.com/wp-content/uploads/2020/04/startup-849804_640.jpg" srcset="http://alugy.com/wp-content/uploads/2020/04/startup-849804_640.jpg 640w, http://alugy.com/wp-content/uploads/2020/04/startup-849804_640-300x214.jpg 300w, http://alugy.com/wp-content/uploads/2020/04/startup-849804_640-588x420.jpg 588w, http://alugy.com/wp-content/uploads/2020/04/startup-849804_640-100x70.jpg 100w" sizes="(max-width: 640px) 100vw, 640px" alt="" title="startup-849804_640"></a></p>
            <!-- content -->
<p>The shares of Alphabet , Amazon (AMZN) , Apple (AAPL) and Facebook (FB) responded to the announcement of unexpectedly good quarterly figures for the four tech companies in pre-market trading session on Friday. As a result, the shares were close to their respective record highs (Amazon and Alphabet) or even higher (Apple and Facebook).</p>



<p>And during the FB earnings conference call from Thursday, July 30, CEO of Facebook Inc talked, among other things, about the future of remote work within the Company. He said that even before COVID Facebook had a long-term goal of enabling more remote work since the ability to feel present even when you’re remote is a core aspect of their own product work on video presence, workplace and virtual and augmented reality. </p>



<blockquote><p>“the reason why we’re shifting to more remote work is that we think that culturally, it will allow us to attract more talented people. We’re not doing this primarily as a cost-saving measure.”-Mark ZuckeRberg</p></blockquote>



<p>He added that Facebook is:”using this moment to accelerate these plans. And I expect that up to 50% of our employees will be remote long term within the next 5 to 10 years. This will enable us to attract and retain broader pools of talent regardless of where they live.”</p>



<p>David Wehner, Facebook CFO also touched this topic and said:”We had our <strong>strongest hiring quarter ever in Q2</strong>, adding over 4,200 net new hires, primarily in technical functions. We ended the quarter with over 52,500 full-time employees, up 32% year-over-year.” and continued on remote work “The main thing we’re trying to do is access a greater talent pool, which ultimately might give us more opportunity to grow head count. So I think there’s an effect there that’s, I think, in addition to cost in the sense that we would have a greater pool of people that we could recruit from.”.</p>



<p>Facebook, Inc. Common Stock (NASDAQ: FB) price went up 7% in the pre-amrket session on Friday which is more than $16.00 higher then Thursday afternoon.</p>



<p>At the same time, the number of users continued to rise rapidly: in the past quarter, FB added more than 100 million monthly active user – and now there are a total of 2.6 billion. At nearly $ 5.2 billion, the profit was about twice as high as in the same quarter of the previous year.</p>

 <!-- A generated by theme --> 



 <!-- end A --> 

        </div></div>]]>
            </description>
            <link>http://alugy.com/tech/zuckerberg-expects-that-50-of-employees-will-stay-remote-long-term-within-5-10-years/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008242</guid>
            <pubDate>Fri, 31 Jul 2020 13:12:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best open-source IoT frameworks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008129">thread link</a>) | @DanaStartupNews
<br/>
July 31, 2020 | https://www.byteant.com/blog/5-best-open-source-iot-frameworks/ | <a href="https://web.archive.org/web/*/https://www.byteant.com/blog/5-best-open-source-iot-frameworks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <ol>
            <li>
                    <a href="https://www.byteant.com/">Home</a>
            </li>
            <li>
                    <a href="https://www.byteant.com/blog/">Blog</a>
            </li>
            <li>5 Best Open Source IoT Frameworks</li>
        </ol>
    </div>

    <section>
        <div>
            <div>
                

                <div>
                            
    

    <div>
        <div>
    <div>
        <div>
            <div>
                <div>
                    
    
    <figure>
        <img src="https://www.byteant.com/media/1417/5-best-open-source-iot-frameworks.jpg" alt="">
    </figure>


                    
    
<h2>Overview</h2>
<p>The <a rel="noopener" href="https://www.byteant.com/internet-of-things-development-services" target="_blank">Internet of Things, or IoT for short</a>, is a promising branch of technology that together withÂ&nbsp;<a rel="noopener" href="https://www.byteant.com/blog/7-ways-how-big-data-can-supercharge-your-business/" target="_blank">Big Data</a> is conquering the digital world now. The idea of smart interrelated gadgets and consumer electronics able to work independently has been evolving since the end of the 20th century. This technology has successfully resulted in a highly-developed far-reaching system of middleware between the devices and user applications. The universal popularity of the IoT strategy is easily explained by the fact that there are billions of devices worldwide in all aspects of human life: medicine, industry, commerce, farming, lifestyle, to name just a few.</p>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
                        <div>
                <div>
                    
    
    <figure>
        <img src="https://www.byteant.com/media/1320/the-internet-of-things-2025.png" alt="">
    </figure>


                </div>
            </div>                    </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<p>Â&nbsp;</p>
<p>You should bear in mind, though, that open source solutions are not totally equal to free software. The terms may mean the same and are used interchangeably sometimes. However, open source software (OSS) goes both ways: it can come to you at no cost as well as offer you quite expensive price tags. The difference lies in its open nature of the software development approach as it allows side code enthusiasts to easily join the programming process.</p>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <p>Needless to say, the majority of businesses treat <a rel="noopener" href="https://www.byteant.com/blog/top-10-technology-trends-2019/" target="_blank">emerging tech trends</a> as an invaluable asset with an eye on their subsequent monetization. Quite obviously, some organizations opt for having the competitive IoT-backed solutions integrated with their processes, like these actionable use cases for <a href="https://www.byteant.com/blog/case-study-iot-and-saas-solutions-for-auto-repair-startup/">Automobile</a> and <a rel="noopener" href="https://www.byteant.com/blog/case-study-how-iot-and-bigdata-transform-sports-industry/" target="_blank">Sports </a>industries. Some decide to double down on buying out or creating their own open source platforms to maximize revenues. Either way, it leads us to the exponential increase of software development initiatives driven by IoT. Hereâ€™s a list of some facts that just add fuel to the fire of IoT-based potential. Â&nbsp;Â&nbsp;</p>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<ul>
<li><a rel="noopener" href="https://www.gartner.com/en/newsroom/press-releases/2018-11-07-gartner-identifies-top-10-strategic-iot-technologies-and-trends" target="_blank">Gartner forecasts</a> the rapid growth of connected things from 14.2 billion in 2019 and 20.4 billion in 2020 up to 25 billion by 2021.</li>
<li>Many advanced technologies, like AI, ML, clouds, IoT, blockchains, are developed within open software platforms. In 2018 <a rel="noopener" href="https://www.redhat.com/en/about/press-releases/ibm-acquire-red-hat-completely-changing-cloud-landscape-and-becoming-worlds-1-hybrid-cloud-provider" target="_blank">IBM buys Red Hat</a> and <a rel="noopener" href="https://news.microsoft.com/2018/06/04/microsoft-to-acquire-github-for-7-5-billion/" target="_blank">Microsoft buys GitHub</a> â€“ the homes of contemporary software innovations for all branches of business.</li>
<li>According to <a rel="noopener" href="https://www.redhat.com/en/enterprise-open-source-report/2019" target="_blank">the Red Hat report</a>, 77% of surveyed IT leaders plan to expand the usage of open source solutions in the next 12 months. 75% of respondents consider it very or extremely important.</li>
<li>Open source-based business solutions are among the most discussed<a rel="noopener" href="https://jaxenter.com/2019-open-source-battles-cloud-war-154174.html" target="_blank">Â&nbsp;technological topics of 2019</a> alongside with cryptocurrency and self-driving cars.</li>
</ul>
<p>Here is an in-depth guide on how open-source software is used by major organizations like Google.</p>


                    
    

<p>
	<iframe width="640" height="360" src="https://www.youtube.com/embed/SpeDK1TPbew?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>


                    
    
<h2>Open source IoT frameworks to consider</h2>
<p>Many companies look for the out-of-the-box open source platforms, while trying to find the best IoT tools that can provide robust analytics and interoperability between their connected devices. Letâ€™s get a brief overview of the 5 most deployed open source IoT frameworks to see if they meet your business needs.</p>
<ol>
<li>
<h3><a rel="noopener" href="https://devicehive.com/" target="_blank">DeviceHive</a></h3>
</li>
</ol>


                    
    
    <figure>
        <img src="https://www.byteant.com/media/achnmp4o/devicehive_.jpg" alt="">
    </figure>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<p><br>Price: by request</p>
<p>Documentation: <a rel="noopener" href="https://docs.devicehive.com/docs" target="_blank">https://docs.devicehive.com/docs</a></p>
<p>DeviceHive is an open-source IoT cloud service management platform, licensed under the Apache License Version 2.0, with a particular focus on big data analytics. This function-rich technology can:</p>
<ul>
<li>support Python, Node.js, Java and other client libraries</li>
<li>provide scalable public, private or hybrid cloud resources</li>
<li>support Docker and Kubernetes deployment options</li>
<li>handle single and multiple production volumes at scale</li>
<li>deprive of minor technical peculiarities</li>
<li>connect any devices with REST API, WebSockets or MQTT protocols</li>
<li>leverage the benefits of Apache Kafka, Spark and Cassandra solutions for big data analytics</li>
</ul>
<div><p>What is more prominent about DeviceHive is that it is mostly free to use and change, though also having fixed price services. Both professional developers and consultants support the platformâ€™s implementation.</p><p>DeviceHive offers robust tools to set up communication between smart IoT devices. It fills the gap between cloud development, embedded, and mobile app development.Â&nbsp;Â&nbsp;</p></div>
<ol start="2">
<li>
<h3><a rel="noopener" href="https://thingspeak.com/" target="_blank">ThingSpeak</a></h3>
</li>
</ol>


                    
    
    <figure>
        <img src="https://www.byteant.com/media/d4pdlnh0/thingspeak.png" alt="">
    </figure>


                    
    
<p><a rel="noopener" href="https://www.byteant.com/portfolio/automotive-iot-and-multitenant-saas-solution/?utm_source=Blog&amp;utm_medium=IoT%20Frameworks&amp;utm_campaign=IoT" target="_blank"><img src="https://www.byteant.com/media/531bxanz/iot-automotive-solution.png" alt="IoT Automotive Solution"></a></p>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<p><br>Price: from $ 650 /unit</p>
<p>Documentation: <a rel="noopener" href="https://www.mathworks.com/help/thingspeak/" target="_blank">https://www.mathworks.com/help/thingspeak/</a></p>
<p>ThingSpeak is a relatively young IoT platform that tightly collaborates with MathWorks. This gives the possibility to leverage from timely MATLAB data analysis from numberless sensors. The platform comprises:</p>
<ul>
<li>live data streams aggregation and analytics;</li>
<li>data recording from public channels to be further used in newly created private channels;</li>
<li>assignment ofÂ&nbsp; public channels to share data;</li>
<li>visualization of collected data;</li>
<li>updates of channel feed via the REST and MQTT APIs;</li>
<li>MATLABÂ® online analytical tools for exploring patterns and relationships;</li>
<li>TimeControl function that enables event-triggered alerts.</li>
</ul>
<p>To sum up, this frameworkâ€™s biggest advantage is that it really makes things communicate with you.</p>
<ol start="3">
<li>
<h3><a href="https://www.mainflux.com/">Mainflux</a></h3>
</li>
</ol>
<h3><img src="https://www.byteant.com/media/irplzuhy/mainfluxiotframework.png?width=734&amp;height=354&amp;mode=max" alt="" width="734" height="354" data-udi="umb://media/d0ac5f42abf84466ab8c380ae8ecc4c6"></h3>
<p>Price: from $500 /month</p>
<p>Documentation: <a href="https://mainflux.readthedocs.io/en/latest/">https://mainflux.readthedocs.io/en/latest/</a></p>
<p>Mainflux is an open-source and patent-free IoT platform that has a rich number of advantageous tools for data collection and management, core analytics, and event scheduling. No matter the industry, Mainflux provides:</p>
<ul>
<li>connectivity of things and users via HTTP, MQTT, WebSocket, CoAP protocols;</li>
<li>device management and provisioning;</li>
<li>container-based deployment by Docker;</li>
<li>container orchestration by Kubernetes;</li>
<li>enhanced data security with customizable API keys and scoped JWT;</li>
<li>low OPEX (operating expense) benefits;</li>
<li>Both protocol and device agnostic.</li>
</ul>
<p>This platform is written in Golang and can be deployed as an on-premises, hybrid or cloud-based model. Prices may vary, starting from absolutely free-of-charge installation modes and support plans to fully-managed business and custom variants.</p>
<ol start="4">
<li>
<h3><a rel="noopener" href="https://thinger.io/" target="_blank">Thinger.io</a></h3>
</li>
</ol>
<h3><img src="https://www.byteant.com/media/cnpdbuue/thingerio.png?width=731&amp;height=212&amp;mode=max" alt="" width="731" height="212" data-udi="umb://media/d2205f1565844a08900f2b7b2dd221f3"></h3>
<p>Price: from â‚¬ 3.95 / month</p>
<p>Documentation: <a rel="noopener" href="http://docs.thinger.io/" target="_blank">http://docs.thinger.io/</a></p>
<p>Thinger.io is an open source ready-to-go platform for cloud IoT projects. This software enables deployment through Docker containerization methods. Among its beneficial features there are:</p>
<ul>
<li>smooth multi-hardware integration;</li>
<li>hardware support of Arduino IDE, Linux, Sigfox andARM Mbed boards;</li>
<li>easy-to-use cloud admin console;</li>
<li>live data streaming to websockets;</li>
<li>device data visualization in the cloud via real-time dashboards;</li>
<li>support of both iOS and Android mobile apps;</li>
<li>IFTTT event-triggered settings for multiple IoT devices</li>
</ul>
<p>This OSS tool is highly sensible, easy-to-use, scalable and secure. Both free and paid subscription plans are available.</p>
<ol start="5">
<li>
<h3><a rel="noopener" href="http://www.zettajs.com/" target="_blank">Zetta</a></h3>
</li>
</ol>
<h3><img src="https://www.byteant.com/media/53edcxyy/zettaiotframework.png?width=734&amp;height=408&amp;mode=max" alt="" width="734" height="408" data-udi="umb://media/5f2149f9091841699da13956160fffe0"></h3>
<p>Price: Free</p>
<p>Documentation: <a rel="noopener" href="https://github.com/zettajs/zetta/wiki" target="_blank">https://github.com/zettajs/zetta/wiki</a></p>
<p>Zetta is the first API-oriented open source IoT framework that basically serves for non-stop streaming loads of data. This technology is deprived of vivid data visualization but its main advantage remains â€œreactive programmingâ€�. The feature list consists of both commonplace and unique characteristics:Â&nbsp;</p>
<ul>
<li>smooth integration with customerâ€™s business logic</li>
<li>based on Node.js;</li>
<li>harnesses Reactive Hypermedia patterns for data streaming;</li>
<li>uses Siren Format to build a solid API for IoT devices;</li>
<li>network protocol agnostic ;</li>
<li>secured connection between peering servers;</li>
<li>consistent data transition over websockets;</li>
<li>ability to send data to other analytical platforms;</li>
<li>A SQL syntax for queries and notifications.</li>
</ul>
<p>No matter the Zetta community is comparatively small, this IoT dashboard open source counts a great number of devoted followers.</p>


                </div>
            </div>        </div>
    </div>
    <div>
        <div>
            <div>
                <div>
                    
    
<h2>Utilizing OSS: Some benefits and drawbacks explained</h2>
<p>At first glance, the IoT tools mentioned above may seem quite similar and enlist homogeneous features but these platforms can come in handy going far beyond. Alternatively to proprietary software, open source technologies are completely customizable and scalable â€“ as the code is open it can be adjusted and modified to the businesses needs. OSS allows developers and enterprises to move between different frameworks without complications â€“ the necessary toolkit provided.</p>
<p>With a great number of automated protocols and functions, open source frameworks save much time of IoT engineers and tech-professionals. This IoT solution is better for handling deployment flexibility issues and reducing expenses. Being of the major priority, data privacy and security is the main standpoint of any business, so you may choose from diverse open source framework vendors worldwide.</p>
<p>There are still some challenges you can face on this far-reaching way:</p>
<ul>
<li>Open means free access, i.e. contributors are not always specialists.</li>
<li>Secure maintenance is always vulnerable.</li>
<li>Data privacy gains a growing legal interest.</li>
<li>A number of best open source platforms may cost a fortune.</li>
<li>Bugs happen.</li>
<li>The set of available standard features doesnâ€™t fit all your business needs.</li>
<li>Open source IoT platforms are not for a mediocre user.</li>
</ul>
<p><em><strong>Whateve…</strong></em></p></div></div></div></div></div></div></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.byteant.com/blog/5-best-open-source-iot-frameworks/">https://www.byteant.com/blog/5-best-open-source-iot-frameworks/</a></em></p>]]>
            </description>
            <link>https://www.byteant.com/blog/5-best-open-source-iot-frameworks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008129</guid>
            <pubDate>Fri, 31 Jul 2020 12:55:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Built a Serverless Search for My Blog]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24008083">thread link</a>) | @kiyanwang
<br/>
July 31, 2020 | https://www.morling.dev/blog/how-i-built-a-serverless-search-for-my-blog/ | <a href="https://web.archive.org/web/*/https://www.morling.dev/blog/how-i-built-a-serverless-search-for-my-blog/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
			

			<div>
				<p><em>I have built a custom search functionality for this blog,
based on Java and the Apache Lucene full-text search library,
compiled into a native binary using the Quarkus framework and GraalVM.
It is deployed as a Serverless application running on AWS Lambda,
providing search results without any significant cold start delay.
If you thought Java wouldn’t be the right language for this job, keep reading;
in this post I’m going to give an overview over the implementation of this feature and my learnings along the way.</em></p>
<p>Having a search functionality for my blog has been on my mind for quite some time;
I’d like to give users the opportunity to find specific contents on this blog right here on this site, without having to use an external search engine.
That’s not only nice in terms of user experience, but also having insight into the kind of information readers look for on this blog should help me to identify interesting things to write about in the future.</p>
<p>Now this blog is a static site — generated using <a href="https://gohugo.io/">Hugo</a>, hosted on <a href="https://pages.github.com/">GitHub Pages</a> — which makes this an interesting challenge.
I didn’t want to rely on an external search service
(see "Why No External Search Service" below for the reasoning),
and also a purely client-side solution as described in this <a href="https://endler.dev/2019/tinysearch/">excellent blog post</a> didn’t seem ideal.
While technically fascinating, I didn’t like the fact that it requires shipping the entire search index to the client for executing search queries.
Also things like result highlighting, customized result scoring, word stemming, fuzzy search and more seemed a bit more than I’d be willing to implement on the client.</p>
<p>All these issues have largely been solved on the server-side by libraries such as <a href="https://lucene.apache.org/">Apache Lucene</a> for quite some time.
Using a library like Lucene means implementing a custom server-side process, though.
How to deploy such service?
Operating a VM 24/7 with my search backend for what’s likely going to be not more than a few dozen queries per month seemed a bit like overkill.</p>
<p>So after some consideration I decided to implement my own search functionality,
based on the highly popular Apache Lucene library,
deployed as a Serverless application,
which is started on-demand if a user runs a query on my website.
In the remainder of this post I’m going to describe the solution I came up with and how it works.</p>
<p>If you like, you can try it out right now, this post is about this little search input control at the top right of this page!</p>
<div>
<table>
<tbody><tr>
<td>
<i title="Note"></i>
</td>
<td>
<p>Why No External Search Service?</p>
<p>When <a href="https://twitter.com/gunnarmorling/status/1284925378868518913">tweeting</a> about my serverless search experiment, one of the questions was "What’s wrong with <a href="https://www.algolia.com/">Algolia</a>?".
To be very clear, there’s nothing wrong with it at all.
External search services like Algolia, <a href="https://developers.google.com/custom-search">Google Custom Search</a>, or an Elasticsearch provider such as <a href="https://bonsai.io/">Bonsai</a> promise an easy-to-use, turn-key search functionality which can be a great choice for your specific use case.</p>
<p>However, I felt that none of these options would provide me the degree of control and customizability I was after.
I also ruled out any "free" options, as they’d either mean having ads or paying for the service with the data of myself or that of my readers.
And to be honest, I also just fancied the prospect of solving the problem by myself, instead of relying on an off-the-shelf solution.</p>
</td>
</tr>
</tbody></table>
</div>
<div>
<h2 id="_why_serverless">Why Serverless?</h2>
<div>
<p>First of all, let’s discuss why I opted for a Serverless solution.
It boils down to three reasons:</p>
<div>
<ul>
<li>
<p><em>Security:</em> While it’d only cost a few EUR per month to set up a VM with a cloud provider like Digital Ocean or Hetzner, having to manage a full operating system installation would require too much of my attention; I don’t want someone to mine bitcoins or doing other nasty things on a box I run, just because I failed to apply some security patch</p>
</li>
<li>
<p><em>Cost:</em> Serverless does not only promise to scale-out (and let’s be honest, there likely won’t be millions of search queries on my blog every month), but also scale-to-zero.
As Serverless is pay-per-use and there are free tiers in place e.g. for AWS Lambda,
this service ideally should cost me just a few cents per month</p>
</li>
<li>
<p><em>Learning Opportunity:</em> Last but not least, this also should be a nice occasion for me to dive into the world of Serverless, by means of designing, developing and running a solution for a real-world problem, exploring how Java as my preferred programming language can be used for this task</p>
</li>
</ul>
</div>
</div>
</div>
<div>
<h2 id="_solution_overview">Solution Overview</h2>
<div>
<p>The overall idea is quite simple: there’s a simple HTTP service which takes a query string,
runs the query against a Lucene index with my blog’s contents and returns the search results to the caller.
This service gets invoked via JavaScript from my static blog pages,
where results are shown to the user.</p>
<p>The Lucene search index is read-only and gets rebuilt whenever I update the blog.
It’s baked into the search service deployment package,
which that way becomes fully immutable.
This reduces complexities and the attack surface at runtime.
Surely that’s not an approach that’s viable for more dynamic use cases,
but for a blog that’s updated every few weeks, it’s perfect.
Here’s a visualization of the overall flow:</p>
<div>
<p><img src="https://www.morling.dev/images/serverless_search_overview.png" alt="Serverless Search Solution Overview">
</p>
</div>
<p>The search service is deployed as a Serverless function on <a href="https://aws.amazon.com/lambda/">AWS Lambda</a>.
One important design goal for me is to avoid lock-in to any specific cloud provider:
the solution should be portable and also be usable with container-based Serverless approaches like <a href="https://knative.dev/">Knative</a>.</p>
<p>Relying on a Serverless architecture means its start-up time must be a matter of milli-seconds rather than seconds,
so to not have a user wait for a noticeable amount of time in case of a cold start.
While <a href="https://www.morling.dev/blog/building-class-data-sharing-archives-with-apache-maven/">substantial improvements</a> have been made in recent Java versions to improve start-up times,
it’s still not ideal for this kind of use case.
Therefore, the application is compiled into a native binary via <a href="https://quarkus.io/">Quarkus</a> and <a href="https://www.graalvm.org/">GraalVM</a>,
which results in a start-up time of ~30 ms on my laptop, and ~180 ms when deployed to AWS Lambda.
With that we’re in a range where a cold start won’t impact the user experience in any significant way.</p>
<p>The Lambda function is exposed to callers via the <a href="https://aws.amazon.com/api-gateway/">AWS API Gateway</a>,
which takes incoming HTTP requests, maps them to calls of the function and converts its response into an HTTP response which is sent back to the caller.</p>
<p>Now let’s dive down a bit more into the specific parts of the solution.
Overall, there are four steps involved:</p>
<div>
<ul>
<li>
<p><em><a href="#_data_extraction">Data extraction:</a></em> The blog contents to be indexed must be extracted and converted into an easy-to-process data format</p>
</li>
<li>
<p><em><a href="#_search_backend_implementation">Search backend implementation:</a></em> A small HTTP service is needed which exposes the search functionality of Apache Lucene, which in particular requires some steps to enable Lucene being used in a native GraalVM binary</p>
</li>
<li>
<p><em><a href="#_wiring_things_up">Integration with the website:</a></em> The search service must be integrated into the static site on GitHub Pages</p>
</li>
<li>
<p><em><a href="#_deployment_to_aws_lambda">Deployment:</a></em> Finally, the search service needs to be deployed to AWS API Gateway and Lambda</p>
</li>
</ul>
</div>
</div>
</div>
<div>

<div>
<p>The first step was to obtain the contents of my blog in an easily processable format.
Instead of requiring something like a real search engine’s crawler,
I essentially only needed to have a single file in a structured format which then can be passed on to the Lucene indexer.</p>
<p>This task proved rather easy with Hugo;
by means of a <a href="https://gohugo.io/templates/output-formats/#output-formats-for-pages">custom output format</a> it’s straight-forward to produce a JSON file which contains the text of all my blog pages.
In my <em>config.toml</em> I declared the new output format and activate it for the homepage
(largely inspired by this <a href="https://xdeb.org/post/2017/06/11/make-hugo-generate-a-json-search-index-and-json-feed/">write-up</a>):</p>
<div>
<div>
<pre><code data-lang="toml"><span>[outputFormats.SearchIndex]</span>
<span>mediaType</span> <span>=</span> <span>"application/json"</span>
<span>baseName</span> <span>=</span> <span>"searchindex"</span>
<span>isPlainText</span> <span>=</span> <span>true</span>
<span>notAlternative</span> <span>=</span> <span>true</span>

<span>[outputs]</span>
<span>home</span> <span>=</span> <span>[</span><span>"HTML"</span><span>,</span><span>"RSS"</span><span>,</span> <span>"SearchIndex"</span><span>]</span></code></pre>
</div>
</div>
<p>The template in <em>layouts/_default/list.searchindex.json</em> isn’t too complex either:</p>
<div>
<div>
<pre><code>{{- $.Scratch.Add "searchindex" slice -}}
{{- range $index, $element := .Site.Pages -}}
  {{- $.Scratch.Add "searchindex" (dict "id" $index "title" $element.Title "uri" $element.Permalink "tags" $element.Params.tags "section" $element.Section "content" $element.Plain "summary" $element.Summary "publicationdate" ($element.Date.Format "Jan 2, 2006")) -}}
{{- end -}}
{{- $.Scratch.Get "searchindex" | jsonify -}}</code></pre>
</div>
</div>

<div>
<div>
<pre><code data-lang="json"><span>[</span><span>
  </span><span>...</span><span>
  </span><span>{</span><span>
    </span><span>"content"</span><span>:</span><span> </span><span>"The JDK Flight Recorder (JFR) is an invaluable tool..."</span><span>,</span><span>
    </span><span>"id"</span><span>:</span><span> </span><span>12</span><span>,</span><span>
    </span><span>"publicationdate"</span><span>:</span><span> </span><span>"Jan 29, 2020"</span><span>,</span><span>
    </span><span>"section"</span><span>:</span><span> </span><span>"blog"</span><span>,</span><span>
    </span><span>"summary"</span><span>:</span><span> </span><span>"</span><span>\u</span><span>003cdiv class=</span><span>\"</span><span>paragraph</span><span>\"\u</span><span>003e</span><span>\n\u</span><span>003cp</span><span>\u</span><span>003eThe </span><span>\u</span><span>003ca href=</span><span>\"</span><span>https://openjdk.java.net/jeps/328</span><span>\"\u</span><span>003eJDK Flight Recorder</span><span>\u</span><span>003c/a</span><span>\u</span><span>003e (JFR) is an invaluable tool..."</span><span>,</span><span>
    </span><span>"tags"</span><span>:</span><span> </span><span>[</span><span>
      </span><span>"java"</span><span>,</span><span>
      </span><span>"monitoring"</span><span>,</span><span>
      </span><span>"microprofile"</span><span>,</span><span>
      </span><span>"jakartaee"</span><span>,</span><span>
      </span><span>"quarkus"</span><span>
    </span><span>],</span><span>
    </span><span>"title"</span><span>:</span><span> </span><span>"Monitoring REST APIs with Custom JDK Flight Recorder Events"</span><span>,</span><span>
    </span><span>"uri"</span><span>:</span><span> </span><span>"https://www.morling.dev/blog/rest-api-monitoring-with-custom-jdk-flight-recorder-events/"</span><span>
  </span><span>},</span><span>
  </span><span>...</span><span>
</span><span>]</span></code></pre>
</div>
</div>
<p>This file gets automatically updated whenever I republish the blog.</p>
</div>
</div>
<div>
<h2 id="_search_backend_implementation">Search Backend Implementation</h2>
<div>
<p>My stack of choice for this kind of application is Quarkus.
As a <a href="https://quarkus.io/guides/kafka-streams-guide">contributor</a>, I am of course biased, but Quarkus is ideal for the task at hand:
built and optimized from the ground up for implementing fast-starting and memory-efficient cloud-native and Serverless applications,
it makes building HTTP services, e.g. based on JAX-RS, running on GraalVM a trivial effort.</p>
<p>Now typically a Java library such as Lucene will not run in a GraalVM native binary out-of-the-box.
Things like reflection or JNI usage require specific configuration,
while other Java features like method handles are only supported partly or not at all.</p>
<div>
<h3 id="_apache_lucene_in_a_graalvm_native_binary">Apache Lucene in a GraalVM Native Binary</h3>
<p>Quarkus enables a wide range of popular Java libraries to be used with GraalVM,
but at this point there’s no extension yet which would take care of Lucene.
So I set out to implement a small Quarkus extension for Lucene.
Depending on the implementation details of the library in question, this can be a more or less complex and time-consuming endeavor.
The workflow is like so:</p>
<div>
<ul>
<li>
<p>compile down an application using the library into a native image</p>
</li>
<li>
<p>run into some sort of …</p></li></ul></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.morling.dev/blog/how-i-built-a-serverless-search-for-my-blog/">https://www.morling.dev/blog/how-i-built-a-serverless-search-for-my-blog/</a></em></p>]]>
            </description>
            <link>https://www.morling.dev/blog/how-i-built-a-serverless-search-for-my-blog/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008083</guid>
            <pubDate>Fri, 31 Jul 2020 12:47:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Everything” Is Done]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24008049">thread link</a>) | @AlchemistCamp
<br/>
July 31, 2020 | https://questinglog.com/everything-is-done/ | <a href="https://web.archive.org/web/*/https://questinglog.com/everything-is-done/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>It's not unusual to see people on entreprenurial subreddits or message boards make a claim along the lines of, "Your tech (software) choices don't matter. It's all about the sales and marketing." Many of the same people will say things like, "software is easy... the hard part is marketing".</p> <p>It's generally easy to dismiss these claims. Not only is it clear that organizations such as governments and banks often spend great deal of money <em>completely</em> fail to make decent web apps, but the other half of the statement fails as well. Rand Fishin's excellent book <a href="https://sparktoro.com/book" target="_blank" rel="noopener noreferrer">Lost &amp; Founder</a> goes into detail about just how difficult it can be for even a world-class marketer to compete with more technical rivals.</p> <p>A truer claim would be, "the hard part" is whatever isn't in the founder's skill set.</p> <h2 id="tech-is-done"><a href="#tech-is-done">#</a> Tech is done</h2> <p>One reason why many people see less value in technical talent or a "good tech stack", whatever that may mean, is the belief that tech is "done". Many people are building the same kinds of B2B SaaS web apps or consumer-focused content sites in 2020 that were being built in 2007. There absolutely are deeper technology challenges being tackled, but that's a topic for another day.</p> <p>There really <em>isn't</em> much challenging in building a Reddit clone or a Zendesk clone in 2020. Using a productive framework like Rails, Laravel or Phoenix, a mid-level full-stack dev could crank out an MVP in a day. Even without a such a framework, shipping it over a weekend wouldn't be uncommon.</p> <p>A week ago, I saw an interesting <a href="https://news.ycombinator.com/item?id=23923104" target="_blank" rel="noopener noreferrer">comment</a> from an startup-employee and entrepreneur that took the idea a step further:</p> <blockquote><p>I work in early stage product startups.</p> <p>What R&amp;D do you need? CRUD is solved, hosting is solved, UX is solved, scaling is solved, marketing is solved ...</p> <p>Everything to do with web and mobile is very solved at this point. Most problems come from tripping over ourselves and cobbling things together to fit new domains.</p> <p>All real hard R&amp;D happens inside faang these days. At least for web/mobile consumer stuff.</p></blockquote> <h2 id="marketing-is-done"><a href="#marketing-is-done">#</a> Marketing is done</h2> <p>Not only are there frameworks and playbooks for <em>building</em> a polished CRUD web app and/or mobile app, but there frameworks and playbooks for marketing them and selling them, too!</p> <p>Knowledge of how to effectively design an email funnel or run Facebook ads may have been relatively scarce a decade ago, but it sure isn't now! "Everybody" knows how important it is to build an email list, test landing pages, talk to early customers, etc, etc, etc.</p> <p>The secret isn't locked up in a few expensive members-only communities or Silicon Valley-based startups. It's out. It's gone global. There are even fantastic books about getting <a href="https://medium.com/@yegg/78-takeaways-from-traction-book-1b44d2a03dda" target="_blank" rel="noopener noreferrer">Traction</a></p> <h2 id="financing-is-done"><a href="#financing-is-done">#</a> Financing is done</h2> <p>It used to be expensive to build a web app. There weren't many investors willing to put up the money it took. The few that were tended to be highly credentialist.</p> <p>Now it's so cheap that founders are building on the side and keeping their jobs until reaching a replacement salary. Fundraising options have also exploded—traditional investors have multiplied, crowd funding is a force, blockchain-based models are popping up and there are even <a href="https://earnestcapital.com/" target="_blank" rel="noopener noreferrer">some investors</a> who fund bootstrappers with no intention of <em>ever</em> building a gigantic business.</p> <p>It still doesn't hurt to have gone to Stanford, Harvard or similarly elite institution but it's far less of an uphill struggle for those who haven't in 2020 than it was in the past.</p> <h2 id="the-remaining-question"><a href="#the-remaining-question">#</a> The remaining question</h2> <p>If the skills that were an unfair advantage in the aughts are now widespread, then what <em>is</em> the edge in 2020?</p>  <h2 id=""><a href="#">#</a> <br></h2> <p><a href="http://news.ycombinator.com/submitlink?t=%22Everything%22%20is%20done.%20&amp;u=https://questinglog.com/everything-is-done" target="_blank" rel="noopener noreferrer">Comment on HN</a></p></div></div>]]>
            </description>
            <link>https://questinglog.com/everything-is-done/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24008049</guid>
            <pubDate>Fri, 31 Jul 2020 12:42:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Learning's Most Important Ideas]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24007965">thread link</a>) | @Anon84
<br/>
July 31, 2020 | https://dennybritz.com/blog/deep-learning-most-important-ideas/ | <a href="https://web.archive.org/web/*/https://dennybritz.com/blog/deep-learning-most-important-ideas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The goal of this post is to review well-adopted ideas that have stood the test of time. I will present a small set of techniques that cover a lot of basic knowledge necessary to understand modern Deep Learning research. If you're new to the field, these are a great starting point.</p><div id="post-content"><p>Deep Learning is an extremely fast-moving field and the huge number of research papers and ideas can be overwhelming. Even seasoned researchers have a hard time telling company PR from real breakthroughs. The goal of this post is to review those ideas that have <strong>stood the test of time</strong>, which is perhaps the only significance test one should rely on. These ideas, or improvements of them, have been used over and over again. They're known to work.</p> <p>If you were to start in Deep Learning today, understanding and implementing each of these techniques would give you an excellent foundation for understanding recent research and working on your own projects. It's what I believe the best way to get started. Working through papers in historical order is also a useful exercise to understand where the current techniques come from and why they were invented in the first place. <strong><strong>Put another way, I will try to present a <em>minimal set</em> of ideas that most of the basic knowledge necessary to understand modern Deep Learning research.</strong></strong></p> <p>A rather unique thing about Deep Learning is that its application domains (Vision, Natural Language, Speech, RL, etc) share the majority of techniques. For example, someone who has worked in Deep Learning for Computer Vision his whole career could quickly be productive in NLP research. The specific network architectures may differ, but the concepts, approaches and code are mostly the same. I will try to present ideas from various fields, but there are a few caveats about this list:</p> <ul> <li>My goal is not to give in-depth explanations or code examples for these techniques. It's not easily possible to summarize long complex papers into a single paragraph. Instead, I will give a brief overview of each technique, its historical context, and links to papers and implementations. If you want to learn something, I <em>highly recommend</em> trying to re-produce some of these paper results from scratch in raw <a href="https://pytorch.org/">PyTorch</a> without using existing code bases or high-level libraries.</li> <li>The list is biased towards my own knowledge and the fields I am familiar with. There are many exciting subfields that I don't have experience with. I will stick to what most people would consider the popular mainstream domains of Vision, Natural Language, Speech, and Reinforcement Learning / Games.</li> <li>I will only discuss research that has official or semi-official open source implementations that are known to work well. Some research isn't easily reproducible because it involves huge engineering challenges, for example <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">DeepMind's AlphaGo</a> or <a href="https://openai.com/projects/five/">OpenAI's Dota 2 AI</a>, so I won't highlight it here.</li> <li>Some choices are arbitrary. Often, rather similar techniques are published at around the same time. The goal of this post is not be a comprehensive review, but to to expose someone new to the field to a cross-section of ideas that cover a lot of ground. For example, there may be hundreds of GAN variations, but to understand the general concept of GANs, it really doesn't matter which one you study.</li> </ul>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">ImageNet Classification with Deep Convolutional Neural Networks (2012)</a> <span data-cites="krizhevsky_imagenet_2012">Krizhevsky, Sutskever, and Hinton (2012)</span></li> <li><a href="https://arxiv.org/abs/1207.0580">Improving neural networks by preventing co-adaptation of feature detectors (2012)</a> <span data-cites="hinton_improving_2012">Hinton et al. (2012)</span></li> <li><a href="https://arxiv.org/abs/1404.5997">One weird trick for parallelizing convolutional neural networks (2014)</a> <span data-cites="krizhevsky_one_2014">Krizhevsky (2014)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://pytorch.org/hub/pytorch_vision_alexnet">AlexNet in PyTorch</a></li> <li><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/alexnet.py">AlexNet in TensorFlow</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/alexnet-full.png" alt=""><figcaption>Source: <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks</a></figcaption> </figure> <p>AlexNet is often considered the algorithm responsible for the recent boom in Deep Learning and Artificial Intelligence research. It is a Deep Convolutional Neural Network based on the earlier LeNet developed by Yann LeCun. AlexNet beat previous methods at classifying images from the <a href="http://image-net.org/index">ImageNet dataset</a> by a significant margin through a combination of GPU power and algorithmic advances. It demonstrated that neural networks actually work! AlexNet was also one of the first times Dropout <span data-cites="hinton_improving_2012">Hinton et al. (2012)</span> was used, which has since become a crucial component for improving the generalization ability of all kinds of Deep Learning models.</p> <p>The architecture used by AlexNet, a sequence of Convolutional layers, ReLU nonlinearity, and max-pooling, became the accepted standard that future Computer Vision architectures would extend and built upon. These days, software libraries such as PyTorch are so powerful, and compared to more recent architectures AlexNet is so simple, that it can be implemented in only a few lines of code. Note that many implementations of AlexNet, such as those linked above, use the slight variation of the network described in <a href="https://arxiv.org/abs/1404.5997">One weird trick for parallelizing convolutional neural networks</a> <span data-cites="krizhevsky_one_2014">Krizhevsky (2014)</span>.</p>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://arxiv.org/abs/1312.5602">Playing Atari with Deep Reinforcement Learning (2013)</a> <span data-cites="mnih_playing_2013">Mnih et al. (2013)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html">DQN in PyTorch</a></li> <li><a href="https://www.tensorflow.org/agents/tutorials/1_dqn_tutorial">DQN in TensorFlow</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/deep-q-learning-value.png" alt=""><figcaption>Source: <a href="https://deepmind.com/research/publications/human-level-control-through-deep-reinforcement-learning">https://deepmind.com/research/publications/human-level-control-through-deep-reinforcement-learning</a></figcaption> </figure> <p>Building on top of the recent breakthroughs in image recognition and GPUs, a team at DeepMind managed to train a network to <a href="https://www.youtube.com/watch?v=V1eYniJ0Rnk">play Atari Games</a> from raw pixel inputs. What's more, the <em>same</em> neural network architecture learned to play seven different games without being told any game-specific rules, demonstrating the generality of the approach.</p> <p>Reinforcement Learning differs from Supervised Learning, such as image classification, in that an agent must learn maximize to the sum of rewards over multiple time steps, such as winning a game, instead of just predicting a label. Because the agent interacts directly with the environment and each action affects the next, the training data is not independent and identically distributed (iid), which makes the training of many Machine Learning models quite unstable. This was solved by using techniques such as experience replay <span data-cites="lin_self-improving_1992">Lin (1992)</span>.</p> <p>While there was no obvious algorithmic innovation that made this work, the research cleverly combined existing techniques, convolutional neural networks trained on GPUs and experience replay, with a few data processing tricks to achieve impressive results that most people would not have expected. This gave people confidence in extending Deep Reinforcement Learning techniques to tackle even more complex tasks such as <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">Go</a>, <a href="https://openai.com/projects/five/">Dota 2</a>, <a href="https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii">Starcraft 2</a>, and others.</p> <p>Atari Games <span data-cites="bellemare_arcade_2013">Bellemare et al. (2013)</span> have since become a standard benchmark in Reinforcement Learning research. The initial approach only solved (beat human baselines on) seven games, but over the coming years advances built on top of these ideas would start beating humans on an ever increasing number of games. One particular game, Montezuma’s Revenge, was famous for requiring long-term planning and was considered to be among the most difficult to solve. It was only recently <span data-cites="badia_agent57_2020">Badia et al. (2020)</span> <span data-cites="ecoffet_first_2020">Ecoffet et al. (2020)</span> that techniques managed to beat human baselines on all 57 games.</p>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural Networks</a> <span data-cites="sutskever_sequence_2014">Sutskever, Vinyals, and Le (2014)</span></li> <li><a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a> <span data-cites="bahdanau_neural_2016">Bahdanau, Cho, and Bengio (2016)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#">Seq2Seq with Attention in PyTorch</a></li> <li><a href="https://www.tensorflow.org/addons/tutorials/networks_seq2seq_nmt">Seq2Seq with Attention in TensorFlow</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/seq2seq-cn.gif" alt=""><figcaption>Source: <a href="https://ai.googleblog.com/2017/04/introducing-tf-seq2seq-open-source.html">https://ai.googleblog.com/2017/04/introducing-tf-seq2seq-open-source.html</a></figcaption> </figure> <p>Deep Learning's most impressive results had largely been on vision-related tasks and was driven by Convolutional Neural Networks. While the NLP community had success with <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">Language Modeling</a> and Translation using LSTM networks <span data-cites="hochreiter_long_1997">Hochreiter and Schmidhuber (1997)</span> and Encoder-Decoder architectures <span data-cites="sutskever_sequence_2014">Sutskever, Vinyals, and Le (2014)</span>, it was not until the invention of the <strong>attention</strong> mechanism <span data-cites="bahdanau_neural_2016">Bahdanau, Cho, and Bengio (2016)</span> that things started to work spectacularly well.</p> <p>When processing language, each token, which could be a character, a word, or something in between, is fed into a recurrent network, such as an LSTM, which maintains a kind of memory of previously processed inputs. In other words, a sentence is very similar to a time series with each token being a time step. These recurrent models often had difficulty dealing with dependencies over long time horizons. When they process a sequence, they would easily "forget" earlier inputs because their gradients needed to propagate through many time steps. Optimizing these models with gradient descent was hard.</p> <p>The new attention mechanism helped alleviate the problem. It gave the network an option to adaptively "look back" at earlier time steps by introducing shortcut connections. These connections allowed the network to decide which inputs are important when producing a specific output. The canonical example is translation: When producing an output word, it typically maps to one or more specific input words.</p>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://arxiv.org/abs/1412.6980">Adam: A Method for Stochastic Optimization</a> <span data-cites="kingma_adam_2017">Kingma and Ba (2017)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://d2l.ai/chapter_optimization/adam.html">Implementing Adam in Python</a></li> <li><a href="https://pytorch.org/docs/master/_modules/torch/optim/adam.html">PyTorch Adam implementation</a></li> <li><a href="https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/optimizer_v2/adam.py#L32-L281">TensorFlow Adam implementation</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/optimizer-benchmark.png" alt=""><figcaption>Source: <a href="http://arxiv.org/abs/1910.11758">http://arxiv.org/abs/1910.11758</a></figcaption> </figure> <p>Neural networks are trained by minimizing a loss function, such as the average classification error, using an optimizer. The optimizer is responsible for figuring out how to adjust the parameters of the network to make it learn the objective. Most optimizers are <a href="https://ruder.io/optimizing-gradient-descent/">based on variations of Stochastic Gradient Descent (SGD)</a>. However, many of these optimizers contain tunable parameters such as a learning rate themselves. Finding the right settings for a specific problem not only reduces training time, but can also lead to better results due to finding a better local minimum of the loss function.</p> <p>Big resarch labs often ran expensive hyperparameter searches that came up with complex learning rate schedules to get the best out of simple but hyperparameter-sensitive optimizers such as SGD. When they …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dennybritz.com/blog/deep-learning-most-important-ideas/">https://dennybritz.com/blog/deep-learning-most-important-ideas/</a></em></p>]]>
            </description>
            <link>https://dennybritz.com/blog/deep-learning-most-important-ideas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24007965</guid>
            <pubDate>Fri, 31 Jul 2020 12:25:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Starting a Business Around GPT-3 Is a Bad Idea]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24007929">thread link</a>) | @paraschopra
<br/>
July 31, 2020 | https://www.allencheng.com/starting-a-business-around-gpt-3-is-a-bad-idea/ | <a href="https://web.archive.org/web/*/https://www.allencheng.com/starting-a-business-around-gpt-3-is-a-bad-idea/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>GPT-3 is an amazing technology. Within a few weeks after beta API access opened, a <a href="https://twitter.com/xuenay/status/1283312640199196673" target="_blank">host of jaw-dropping demos</a> popped up, from <a href="https://twitter.com/sharifshameem/status/1282676454690451457" target="_blank">automatic code generation</a> to <a href="https://twitter.com/nicklovescode/status/1283326066338062337" target="_blank">automated therapy bots</a> to <a href="https://www.gwern.net/GPT-3" target="_blank">writing original poetry and Navy SEAL copypasta memes</a>. It does things that would have been science fiction 10 years ago.&nbsp;GPT-3 and its successor algorithms are going to change entire industries.</p><p>Naturally, tech founders and VC investors are salivating at the possibilities of turning GPT-3 applications into businesses.</p><p>But a good technology doesn’t necessarily make for a good business. <strong>The fact that GPT-3 works so well out of the box should be terrifying to founders.</strong> Here’s why:</p><ul><li>If it’s easy to make a good-enough app out of the box, the barriers to entry are mercilessly low. Dozens of competitors for your idea will spring up literally overnight, as they already have in these Twitter demos.</li><li>It’s not just about new entrants. If GPT-3 is so easy to adopt and build products with, incumbents will do it too. Thus, in Clayton Christensen’s framework, GPT-3 looks more like a <strong>sustaining innovation</strong> than a disruptive innovation. This will strengthen existing winners more than it creates openings for new startups.</li><li>If the baseline GPT-3 performance cannot be substantially improved to create a substantial (10x) proprietary edge, the competition will shift away from technology to other dimensions of competition—particularly in marketing and distribution. This is where incumbents beat startups.</li><li>Meanwhile, the profits will accrue to the true beneficiaries: 1) the algorithm owners,&nbsp; OpenAI (and, by extension, Azure), 2) to marketing platforms, particularly Google and Facebook. Both can raise pricing to the point where companies built on each are barely profitable.</li></ul><p>Let’s dive more into these ideas.</p><h2><span id="Low_Barrier_to_Entry_Fierce_Competition"><strong>Low Barrier to Entry = Fierce Competition</strong></span></h2><div><figure><img src="https://i1.wp.com/www.allencheng.com/wp-content/uploads/2020/07/image.png?w=750&amp;ssl=1" alt="" srcset="https://i1.wp.com/www.allencheng.com/wp-content/uploads/2020/07/image.png?w=471&amp;ssl=1 471w, https://i1.wp.com/www.allencheng.com/wp-content/uploads/2020/07/image.png?resize=300%2C174&amp;ssl=1 300w" sizes="(max-width: 471px) 100vw, 471px" data-recalc-dims="1"></figure></div><p><a href="https://a16z.com/2020/05/28/moats-before-gross-margins/" target="_blank">Moats provide an enduring competitive advantage</a>. The wider and deeper the moat, the higher the barrier to entry to compete with your business, and the less capably a hotshot teenager can start a new company to compete.</p><p>If a moat is shallow, hundreds of competitors can pop up overnight and provide a good-enough competing product. If you can’t build a meaningful product advantage, then the grounds of competition shift to other dimensions of competition—namely, marketing and distribution.</p><h3><strong>The Parable of Online Mattresses</strong></h3><p>The online mattress industry had shallow moats and played out predictably. A few years ago, if you wanted to start a new mattress company, you only needed to cobble together a few components:</p><ul><li>A manufacturer</li><li>A website</li><li>A marketing campaign</li></ul><p>At the peak of the industry, there were <a href="https://www.cnbc.com/2019/08/18/there-are-now-175-online-mattress-companiesand-you-cant-tell-them-apart.html" target="_blank">175 online mattress companies</a>. None had a meaningful product advantage—many used the same mattress manufacturers. (And having personally tried several of these mattresses in stores, they really did feel about the same.)</p><p>The grounds of competition thus shifted to marketing and branding, which is why a year ago you heard so many podcast ads for Casper, Purple, and the like. When product 17 and product 130 are identical, then the only way to win is to get buyers more familiar with product 17. But <strong>when competition meets a narrow dimension of competition, profits evaporate</strong>—companies bid up marketing prices to the highest that they can endure. It became a game of chicken—how much are <em>you </em>willing to spend to acquire a customer? The best-funded startups “won” this branding battle.</p><p>But this was a short-lived victory. <strong>The ultimate result: perpetually unprofitable businesses</strong>, with <a href="https://www.marketwatch.com/investing/stock/cspr/financials" target="_blank">companies spending most of their revenue on COGS and user acquisition</a>. Casper now has a market value of just $350 million, down from its peak private valuation of $1.1 billion.&nbsp;</p><p>Meanwhile, the real beneficiaries of all this funding are:&nbsp;</p><p>1) the companies selling shovels in the gold rush, including mattress manufacturers and marketing platforms (particularly Google and Facebook)</p><p>2) customers, who enjoyed rock-bottom mattress prices subsidized by venture capital.</p><p>This situation played out in meal kit companies too, and one could argue the same is true of Uber vs Lyft and the food delivery war going on now.</p><h2><span id="Can_You_Differentiate_Yourself_with_GPT-3"><strong>Can You Differentiate Yourself with GPT-3?</strong></span></h2><p>Because GPT-3 works so well out of the box, I see this playing out a similar way. To start a new AI company, you need only cobble together a few components:</p><ul><li>A product built on GPT-3’s (very easy to use) API</li><li>A website</li><li>A marketing campaign</li></ul><p>As we see with Twitter demos, the products you can make off the shelf will frankly be pretty good.</p><p>Unfortunately, most of the products built on GPT-3 will be identical to each other, and few will have a meaningful edge. We’ll dive more into this next.</p><h3><strong>Differentiated Technology</strong></h3><p><strong>To win a market with technology, your product needs to be <em>obviously</em> better to the user.</strong> When Google first came out, it delivered such better search results than other engines—possibly by a subjective factor of 10 or more—that there was little reason to use any competitor. When Dropbox first came out, its syncing and ease of use was unbeatable. Right now SpaceX has a rocket that can do what no other company’s can, at an unbeatable price. These companies have real technology moats.</p><p>In contrast, if an industry has products that are are more or less identical—like online mattresses—the grounds of competition shift elsewhere other than product (like marketing and distribution), and there is no technology moat.</p><p>So imagine: If 100 companies build an AI therapy bot with GPT-3, how different will their user experiences be? How far ahead will company #1 be above company #2, and then over company #10? <strong>Will there be a 10x difference? Or more like a 5% difference?</strong></p><p>I argue: <strong>The better GPT-3 works out of the box, the harder it will be for any single company to build meaningful differentiation.</strong> Frankly, <a href="https://twitter.com/nicklovescode/status/1283326066338062337" target="_blank">early demos already look very good</a>.</p><figure><div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>I thought you made a good point so I did another run being as depressive as I could. I sampled most “John” lines only once, I think I ran one twice. I’m really impressed</p><p>The prefix makes a difference but that could be automatically prepended by an end-user therapy app <a href="https://t.co/YZmQL9EXqW" target="_blank">pic.twitter.com/YZmQL9EXqW</a></p></div>— Nick Cammarata (@nicklovescode) <a href="https://twitter.com/nicklovescode/status/1283326066338062337?ref_src=twsrc%5Etfw" target="_blank">July 15, 2020</a></blockquote> </div></figure><p>Imagine how much better it can get with just a <em>little</em> more work—a modicum of fine tuning on therapy conversations and user safeguards. This is the new baseline, the “table stakes” for any new entrant, which is going to be relatively easy to achieve.</p><p>And then from this baseline, how much better could any one company get?</p><p>Here’s one way to think about it. The pinnacle of AI therapy would be a bot that rivals the <em>best</em> human therapist. Call this the 100% experience. The <em>average</em> human therapist might be somewhere at the 85% bar. And then a human user might be willing to tolerate a “good enough” AI performing at 70%—it’s clearly worse than a human therapist, but usable enough that it can keep up a coherent conversation and remembers that you were bullied in 5th grade.</p><figure><img src="https://lh6.googleusercontent.com/d-9mr1Bo8EgQaIlWnKd4EQuSrjjJuoBmjOkpcbPwJ0h9xnyIGz832tT133eTopDQZQWr2pXAJ-lS9mhaP9KBInUCnGtSqJKAtdZV-acn55hQ25c-p7bwdHgjyl-zFJ54I9Hg4aVX" alt=""></figure><p><strong>Before GPT-3, building anything </strong><strong><em>close</em></strong><strong> to the Good Enough AI was really hard.</strong> A company would have needed to invest many millions into its own algorithms and data cleanup to get anywhere close to the human user bar.&nbsp;</p><p>In this environment, the leading company had a few advantages:</p><ul><li>The barrier to entry was high, so it faced less competition.</li><li>The spread between the #1 and #3 companies was high, meaning the leading company had a sizable moat.</li><li>It still had a lot of room to grow to get to 85%+ level—this is room in which it could carve out a meaningful edge over competition.</li><li>It owned its own technology, so it could iterate to continuously improve its experience.</li></ul><p>Here’s how the landscape might have looked:</p><figure><img src="https://lh3.googleusercontent.com/Fz675xiZWljHeS4HWUGNcrO8qbaLtjJ9zfqJNCa2HhthN84Nt7JCQpMMhC4SzO9dWfSkGpWxOwIkaz745S-XJijAd91g0JDS2A7nDXrv6ku2fckVbW5kCl-UEyZci3tRgrb4aNwl" alt=""></figure><p>(In practice, I don’t know of any <a href="https://www.healthline.com/health/mental-health/chatbots-reviews#7" target="_blank">pre-GPT-3 AI therapy bot</a> that comes anywhere close to a human therapist. So competitive lead notwithstanding, I don’t think there have been any good AI therapy businesses to date.)</p><p>Then comes GPT-3. <strong>Now <em>anyone</em> can produce a “good enough AI therapy bot,”</strong> with a modicum of fine-tuning and UX design. This outcome wouldn’t be shocking—people were producing <a href="https://twitter.com/nicklovescode/status/1283326066338062337" target="_blank">plausible demos</a> within days of accessing the private beta. Imagine what can be done with just a few weeks of work and $500,000 of investment.</p><p>The result: the range of competition narrows:</p><figure><img src="https://lh6.googleusercontent.com/BiYRcsL4EKmlGKyc5gFDCCkQ_79ijr-jBknzfVb2MVuPj-Rp-D56fLeNhVnV9F46I3tWmUgzJLfV_hh5Q-oOZuR531DWJwI11JKQWgRfFt0fDDDGybrQX7yuTvAGp0TDWmem8_K5" alt=""></figure><p>Compared to the previous situation:</p><ul><li>There are many more competitors who can offer a “good enough” product.</li><li>The range of competition is compressed into a narrower band. It becomes much harder for any single product to stand out from the median product, which is already quite good.</li><li>Because the companies don’t own the core technology behind GPT-3, their ability to improve beyond the baseline performance is limited. Yes, they can fine-tune GPT-3 with their proprietary data, but how much is this going to improve on the core algorithm, which <a href="https://venturebeat.com/2020/06/11/openai-launches-an-api-to-commercialize-its-research/" target="_blank">cost $12 million to train</a> on 40GB of Internet text? <strong>And won’t everyone else be fine-tuning like this too?</strong></li></ul><p>Again, this really gives credit to OpenAI for how well GPT-3 works—out of the gate, you can produce a pretty usable product. But for startups, this merely <em>raises the table stakes</em> instead of offering a competitive advantage, and it <strong>neutralizes the technology edge</strong> any single company can have over another. Great for OpenAI, not great for new startups.</p><p><strong>Then imagine how much worse this will get when GPT-4 comes out. And again with GPT-5. </strong>The minimum bar of quality will keep inching up inexorably, and the range of competition will be compressed further and further.</p><p>Plus, it’s likely that <strong>any proprietary progress you make on GPT-3 will be totally wiped out by GPT-4</strong>; the same way your tweaks on GPT-2 would have been wiped out by GPT-3.</p><p>We’ve talked about AI therapy here, but this argument extends easily to automated code generation, creative writing tools, chatbots, Q&amp;A services, games, and so on.</p><h3><strong>Other Avenues of Differentiation</strong></h3><p>Yes, the algorithm isn’t everything. Products can still differentiate with their user experience, product design, customer support, adding on human services, and so on.&nbsp;</p><p>But as far as AI companies typically go, this is not really the <em>hard</em> …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.allencheng.com/starting-a-business-around-gpt-3-is-a-bad-idea/">https://www.allencheng.com/starting-a-business-around-gpt-3-is-a-bad-idea/</a></em></p>]]>
            </description>
            <link>https://www.allencheng.com/starting-a-business-around-gpt-3-is-a-bad-idea/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24007929</guid>
            <pubDate>Fri, 31 Jul 2020 12:19:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Git as a Logbook to Improve Efficiency]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24007802">thread link</a>) | @svdo
<br/>
July 31, 2020 | https://unfolded.dev/posts/2020-07-21-using-git-more-effectively/ | <a href="https://web.archive.org/web/*/https://unfolded.dev/posts/2020-07-21-using-git-more-effectively/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <h2>Contents</h2>
    <ol><li><a href="#a-creative-pursuit">A Creative Pursuit</a></li><li><a href="#not-a-unique-problem">Not A Unique Problem</a></li><li><a href="#a-logbook-on-steroids">A Logbook On Steroids</a></li><ol><li><a href="#target-audience">Target Audience</a></li><li><a href="#tell-a-story">Tell A Story</a></li><li><a href="#record-frequently">Record Frequently</a></li><li><a href="#rewrite">Rewrite</a></li><li><a href="#record-failures">Record Failures</a></li></ol><li><a href="#when-to-use-it">When To Use It</a></li><li><a href="#comments"></a><a href="https://github.com/svdo/unfolded.dev/issues/1">Comments</a></li></ol>
    
    <p><em>In my daily work, I have the good fortune to work with many very talented
people. Some are professional software developers, like myself. Others are for
example researchers, scientist, project leaders, and so on. Is that you? Do you
also write software, but not as your main activity? Do you have some experience
but maybe no formal training? In <a href="https://unfolded.dev/pages/software-development-easy-to-learn-hard-to-master/">this series of blog
posts</a> I will explain
the best practices that I use, so that you may be able to benefit from them. So
that writing software hopefully takes you less effort and gives you more
pleasure.</em></p><h2 id="a-creative-pursuit">A Creative Pursuit</h2><p>A decade or so ago, I had the good fortune to work with a group of extremely
smart scientists. Without going into details, their job was to conceive
algorithms for image processing, and improve them. They had huge volumes of
data, and the ability to create more. The algorithms had to be robust in the
face of all kinds of variations in that data. Much like software development,
their work was <a href="https://iism.org/article/why-are-ceos-failing-software-engineers-56">a creative pursuit</a>.</p><p>They would have regular meetings to discuss progress, results and challenges. In
those meetings, I remember being surprised now and then. For example, you might
hear a conversation like this<sup id="fnref-1"><a href="#fn-1">1</a></sup>:</p><blockquote><p><strong>Betty</strong>: Say, John, didn't you have some progress on «some algorithm
feature» a few weeks ago? I'm running into some issues and I think your
findings may help me here.</p><p><strong>John</strong>: Yeah, that's right, I remember having some results when I was
working on «something else». I'm not sure which algorithm variant
I used exactly though, or which test data for that matter. If it's important
to you, we can sit together and see if we can reproduce that.</p></blockquote><p>While this was commendable in terms of team spirit, I always felt it wasteful
that apparently things had not been tracked and documented in such a way that it
was easy to recover what people had tried and done.</p><p>🤔</p><h2 id="not-a-unique-problem">Not A Unique Problem</h2><p>It turns out that software development is not that different from research in
the sense that they are both creative pursuits. Also software development
requires a good amount of trial-and-error, backtracking, rethinking, trying
again, going back to something that wasn't so stupid after all. The difference
is that we, software developers, are lazy to the point that we try to automate
just about anything that we can. So we use tools. And yes, nowadays probably
everybody understands that I'm going to say "git" (or "mercurial" or something
similar)<sup id="fnref-2"><a href="#fn-2">2</a></sup>. So I'm not going to explain what git is here. Plenty of
good resources out there on that topic. No, I'm going to tell you a bit about
how I use it.</p><p>🛠</p><h2 id="a-logbook-on-steroids">A Logbook On Steroids</h2><p>My version control system (e.g. git) is like a logbook. I use it to record
relevant things about my work that are not part of the code itself. For example,
in a commit message I type the reason why I'm doing things a certain way. Or I
might record that I tried something but it failed. Let's go into some details to
better explain.</p><h3 id="target-audience">Target Audience</h3><p>For any kind of writing, an important question is: who is your target audience?
Whether it's a blog post like this one, a scientific paper, a conference talk,
you always ask yourself: for whom am I writing this? For version control, the
answer is:</p><ol><li>My future self. Much like the researchers in the example above, I cannot hold
everything in my head. I forget details, I forget why I tried certain things,
I forget why other things failed. By documenting them, I can remind myself
when I need to in the near or not-so-near future.</li><li>My team. Even though I very much like pair programming, and I hope one day to
be part of a team that wants to do <a href="https://040code.github.io/2019/03/15/mob-programming">mob programming</a>, in
reality I cannot share all relevant details with the rest of my team all the
time. By documenting them, I allow my team mates to step into my shoes and
follow my reasoning.</li><li>Successors or other people who may have to work on the code when I'm not
around. Even though the average "best before" date of software is a fair
bit closer than people prefer to believe, it still happens that I write code
that others need to continue working on when I'm not available, for example
because I'm in a different department or working for a different employer.
Again, by documenting things I try to enable them to decide what pieces are
important to them and which are not.</li></ol><h3 id="tell-a-story">Tell A Story</h3><p>Well, maybe that's a bit overdoing it. My kids are going to be bored out of
their socks by these stories. But still, I do try to commit in such a way that
the sequence of all commit messages can be understood by others. They say more
than the individual commits in isolation, because the succession of commits
allows you to distill my reasoning, from where to where I'm going.</p><h3 id="record-frequently">Record Frequently</h3><p>This requires to commit frequently. "Oh but I do! I commit at least every day
before I leave the office! And sometimes even more!", you say? Well, we're
thinking of a different order of magnitude then. When I'm "<a href="https://en.wikipedia.org/wiki/Flow_(psychology)">in flow</a>" I
commit <em>many times every hour</em>. Every few minutes when I'm really on a roll. No,
of course not always. When I'm grinding on a hard problem I may have nothing to
commit for a few hours. That's ok, but it should be exceptional, not the norm.</p><p>Committing frequently also means that I make separate commits when reasonably
possible. For example, as I'm writing this blog post, I'm making a few changes
to the CSS style sheet. I could commit those as part of the blog post, or as a
separate commit. Instead, I chose to create
<a href="https://github.com/svdo/unfolded.dev/commit/3fec2de430168ad50cbdee7144b5f5f827321be4">three</a> <a href="https://github.com/svdo/unfolded.dev/commit/63c1a75a857b8c6075c9d8302535309b1857ec37">separate</a> <a href="https://github.com/svdo/unfolded.dev/commit/9fb7189a19b5d1b0f53113996d9a95259395b193">commits</a> because each
makes sense on its own, without the other two. This way I can later revert any
of the three changes by simply reverting the corresponding commit. Of course
some people find this rather extreme<sup id="fnref-3"><a href="#fn-3">3</a></sup>, and that's fine. YMMV.</p><h3 id="rewrite">Rewrite</h3><p>And like any good story, this one also needs to be polished and rewritten to be
as good as it can be. I do that all the time. When I'm working on a feature, I
may for example have ten commits that form a logical whole. Then I notice
that there was a change that should have been part of one of those commits, but
I overlooked it at that time. So I make a new commit with that single thing that
I forgot, I move that new "fixup" commit to the commit where it belongs, and I
combine the two. I look at the commit messages and edit them if needed.
I reorder commits. And then, when I'm satisfied, only then I push my commits to
the remote, so that others will only see the polished version of my story.
Obviously having a great git client tremendously helps with this. I can't
recommend anything specific on Linux or Windows, but on macOS <a href="https://gitup.co/">GitUp</a> is
extraordinary in this regard: hitting "d" moves a commit down, hitting "f" does
a fixup (combine it with the commit before it), "e" edits the commit message. I
don't know of another git client that can do this so easily.</p><h3 id="record-failures">Record Failures</h3><p>One final thing to note here: don't hesitate to also record failures. Most of
the time there is more to be learned from failures than from successes. So when
rewriting my commits before pushing, I may either delete a few commits that were
failures, but sometimes I actually decide to leave them there and explain (in
the commit messages) why. Same for "reverse commit". I try something that
doesn't work but is already committed. I may then delete that last commit before
pushing, but I can also "reverse commit" it. Again, so that it may be clear that
I tried something and that it failed, so that others don't have to try
themselves as well.</p><p>📔</p><h2 id="when-to-use-it">When To Use It</h2><p>In closing, I want to say a few words about <em>when</em> I use a version control
system. The answer may surprise you, because it is: "almost always". Yesterday
and today, I was trying out a few different crypto libraries for some finite
field arithmetic that I needed to do. So I created a few small projects to
quickly try a few libraries. And for each of those, I created a git repo. Just
on my own computer, mind you. Unless I end up creating a spike that I think has
value to others, I won't create a remote for these repos. But just typing <code>git init</code> after creating a new project doesn't cost me anything. When I don't need
it anymore, I remove the project, and the embedded <code>.git</code> folder with the
history is automatically deleted as well. So why not?</p><p>Like Woody Zuill says it: "turn up the good!" If using a version control system
like git is good, turn it up. Use it more than you used to, and then more still,
and see what happens. If committing to git is good, turn it up. Commit more
frequently, and then more frequently still. Maybe you'll be surprised. I hope it
will bring you the satisfaction it has given me!</p><p>🤠</p><p>Since this is a privacy-friendly static web site, I'm not including the ability
to post comments directly here. I do love feedback though, so I created a ticket
on GitHub that you can use to leave your comments. Tell me if it's bad, tell me
if it's good, but please don't forget to tell me <em>why</em>. So please head over
there and <a href="https://github.com/svdo/unfolded.dev/issues/1">leave your comments</a>!</p>
</div></div>]]>
            </description>
            <link>https://unfolded.dev/posts/2020-07-21-using-git-more-effectively/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24007802</guid>
            <pubDate>Fri, 31 Jul 2020 11:58:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meat consumption is causing damage]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24007355">thread link</a>) | @lcnmrn
<br/>
July 31, 2020 | https://subreply.com/trohs/ik9 | <a href="https://web.archive.org/web/*/https://subreply.com/trohs/ik9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://subreply.com/trohs/ik9</link>
            <guid isPermaLink="false">hacker-news-small-sites-24007355</guid>
            <pubDate>Fri, 31 Jul 2020 10:36:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google removes all Danish music from YouTube]]>
            </title>
            <description>
<![CDATA[
Score 169 | Comments 174 (<a href="https://news.ycombinator.com/item?id=24006932">thread link</a>) | @erk__
<br/>
July 31, 2020 | https://www.koda.dk/about-us/press-release-google-removes-all-danish-music-from-youtube | <a href="https://web.archive.org/web/*/https://www.koda.dk/about-us/press-release-google-removes-all-danish-music-from-youtube">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div>   
    <p>Press Release<br>July 30, 2020</p>

<h3><strong>Google removes all Danish music from YouTube </strong></h3>
<h5>While the negotiations on a new joint Nordic agreement are in full swing, Google have chosen to leverage their total dominance in the market in the strongest way possible. On the evening of Thursday 30 July, Google announced that they will soon remove all Danish music content on YouTube.</h5>

<p>Under the auspices of the Nordic alliance of collecting societies, Polaris, negotiations on a joint Nordic agreement on the use of music on YouTube are currently in full swing. The agreement will replace the local agreements of the Norwegian, Finnish and Danish composers and songwriters’ societies, combining them in a single, joint agreement with Google. In the case of Koda, the national agreement for Denmark expired in April, after which it was temporarily extended – as is standard practice in the industry while negotiating a new agreement.</p>
<p>Now, however, Google have issued a new demand: if the agreement is to be temporarily extended, Koda must agree to reduce the payment provided to composers and songwriters for YouTube’s use of music by almost 70% – despite the fact that YouTube’s use of music has increased significantly since Koda entered into its last agreement with Google.</p>
<p>Of course, Koda cannot accept these terms, and Google have now unilaterally decided that Koda’s members cannot have their content shown on YouTube and that their fans and users on YouTube will be unable to listen to Koda members’ music until a new agreement is in place.</p>
<p>Although the parties involved in the negotiations on the new joint agreement are by no means in concord yet, progress has been made in recent weeks, and Koda is puzzled by the extremely aggressive approach taken by Google in the negotiations this time.</p>
<h5><strong>Koda’s media director, Kaare Struve, says:</strong></h5>
<p>‘Google have always taken an “our way or the highway” approach, but even for Google, this is a low point. Of course, Google know that they can create enormous frustration among our members by denying them access to YouTube – and among the many Danes who use YouTube every day. We can only suppose that by doing so, YouTube hope to be able to push through an agreement, one where they alone dictate all terms’.</p>
<p>Ever since the first agreement was signed in 2013, the level of payments received from YouTube has been significantly lower than the level of payment agreed to by subscription-based services.</p>
<h5><strong>Koda’s CEO, Gorm Arildsen, says:</strong></h5>
<p>‘It is no secret that our members have been very dissatisfied with the level of payment received for the use of their music on YouTube for many years now. And it’s no secret that we at Koda have actively advocated putting an end to the tech giants’ free-ride approach and underpayment for artistic content in connection with the EU’s new Copyright Directive. The fact that Google now demands that the payments due from them should be reduced by almost 70% in connection with a temporary contract extension seems quite bizarre’.</p>
<p><strong>Media contact</strong>&nbsp;<br>Head of Communications Eva Hein /<span>&nbsp;</span><a href="mailto:eh@koda.dk">eh@koda.dk</a><span>&nbsp;</span>/ (+45) 61893233</p>
</div>
 </div></div>]]>
            </description>
            <link>https://www.koda.dk/about-us/press-release-google-removes-all-danish-music-from-youtube</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006932</guid>
            <pubDate>Fri, 31 Jul 2020 08:59:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[High Output Founder's Library]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24006686">thread link</a>) | @sandGorgon
<br/>
July 31, 2020 | https://www.notion.so/High-Output-Founders-Library-48742928f9f149b8a777e11a1409ce0a | <a href="https://web.archive.org/web/*/https://www.notion.so/High-Output-Founders-Library-48742928f9f149b8a777e11a1409ce0a">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/High-Output-Founders-Library-48742928f9f149b8a777e11a1409ce0a</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006686</guid>
            <pubDate>Fri, 31 Jul 2020 08:04:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Signs of a Bad Outsource Contractor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24006632">thread link</a>) | @ProArea
<br/>
July 31, 2020 | https://proarea.co/blog/6-signs-of-a-bad-outsource-contractor/ | <a href="https://web.archive.org/web/*/https://proarea.co/blog/6-signs-of-a-bad-outsource-contractor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><span><span>H</span>ow to differ a bad contractor from a good partner?</span> There can be many advantages of working by the outsourced model, but also a lot of risks. Finding a good partner is difficult, but it is an ambitious and necessary task. We wrote this article to <span>differ</span> it from a bad and irresponsible contractor. What kind of mistakes do contractors make, so it`s not worth working with them?</p>
<h3><b>SIGN #1 WORK OF THE TEAM IS NOT VISIBLE</b></h3>
<p><span>The manager assured that the team was working and would show the result “in the nearest future”, and after weeks of work, it wasn`t clear what the result of the project is and whether work is underway.</span></p>
<p><span>How it is needed:</span></p>
<p><span>Use the Scrum project management methodology:</span></p>
<p><span>✓ Carry out daily calls where show the status of the tasks</span></p>
<p><span>✓ Make the result demonstration each sprint (2 weeks)</span></p>
<p><span>✓ Analyze the results of each sprint</span></p>
<p><span>What is the benefit for you:</span></p>
<p><span>✓ You see not only the final result but also understand the progress along with the sprint</span></p>
<p><span>✓ You see delays and problems on time and keep your finger on the pulse</span></p>
<h3><b>SIGN </b><b>#2 DOUBTFUL CODE QUALITY</b></h3>
<p><span>In a rush, programmers write low-quality code that cannot be supported. Because of this, in the future, it will be necessary to rewrite the system from scratch or it will not perform the necessary tasks and functions at all. </span><span>The system may run slowly due to poor-quality and unstructured code, so it will be extremely difficult and expensive to finalize a new module.</span></p>
<p><span>How it is needed:</span></p>
<p><span>✓ Make and show a code quality assessment using special programs – professional tools for analysis</span></p>
<p><span>✓ Work on git-flow, where some programmers check others to avoid mistakes</span></p>
<p><span>What is the benefit for you:</span></p>
<p><span>✓ You don’t need to overpay for alterations</span></p>
<p><span>✓ You get a working system that is easy to refine and scale</span></p>
<p><span>✓ Other programmers and teams can easily work with the code</span></p>
<h3><img src="https://proarea.co/blog/wp-content/uploads/2020/06/2.png" alt="Подрядчик в IT" width="800" height="552" srcset="https://proarea.co/blog/wp-content/uploads/2020/06/2.png 800w, https://proarea.co/blog/wp-content/uploads/2020/06/2-300x207.png 300w, https://proarea.co/blog/wp-content/uploads/2020/06/2-768x530.png 768w" sizes="(max-width: 800px) 100vw, 800px"></h3>
<h3><b>SING #3 NO DEEP UNDERSTANDING OF THE PROJECT</b></h3>
<p><span>The contractor simply performs the task pool, not wanting to delve into the subtleties of the project and study it. </span><span>Developers just write the code the way they understand the task.</span></p>
<p><span>How it is needed:</span></p>
<p><span>✓ Make a competitor analysis and study successful counterparts in the market to understand trends and delve deeply into the project</span></p>
<p><span>✓ Fix errors and improve the system along the way, playing the role of business analysts</span></p>
<p><span>✓ Developers write code, taking into account business requirements, think about creating a product that will be interesting and convenient for the user</span></p>
<p><span>What is the benefit for you:</span></p>
<p><span>✓ The contractor isn’t just “hands” that build, but also a “head” that will find and come up with the best solution</span></p>
<h3><b>SING #4 JUST THE VISIBILITY OF WORK, MANY EXTRA MOVEMENTS</b></h3>
<p><span>The team creates the appearance of work – constantly there are new documents with a description, new work files. </span><span>The code is simply written just for fact and over time it turns out that the functions aren’t logical, inconvenient, or impossible to use. </span><span>Business doesn’t get results – a system that can be used.</span></p>
<p><span>How it is needed:</span></p>
<p><span>✓ Iteratively create a finished product that can be used after the first sprints</span></p>
<p><span>✓ Instead of 20 sheets of documentation, make one prototype and clearly show how the new module will work</span></p>
<p><span>✓ Don’t just write code but offer a solution for business – work functions that are needed</span></p>
<p><span>What is the benefit for you:</span></p>
<p><span>✓ You get the result – a system that you can use&nbsp;</span></p>
<p><span>✓ Save time and money</span></p>
<h3><b>SING</b><b> #5 DON`T CARE ABOUT DESIGN</b></h3>
<p><span>Bad contractors focus only on functionality and don’t consider design as an important stage in product development and as a tool to achieve project goals. </span><span>Don’t reuse logic/components from already developed system modules. </span><span>Don’t use a design system – a unified style and approach to project design.</span></p>
<p><span>How it is needed:</span></p>
<p><span>✓ Follow the best solutions of modern UI/UX design with care for the user</span></p>
<p><span>✓ Don’t just develop functionality to the level of “everything works fine”, but make a big emphasis on the visual part to the level of “comfortable and beautiful”</span></p>
<p><span>✓ Use ready-made solutions and components from already completed system modules</span></p>
<p><span>✓ Use the design system and templates in the design to speed up the work and improve its quality</span></p>
<p><span>What is the benefit for you:</span></p>
<p><span>✓ Time for design and engineering is allocated as efficiently as possible</span></p>
<p><span>✓ Users get a product that looks like they want to use it all the time – all because it has a responsive, understandable, convenient, inspirational design!</span></p>
<h3><img src="https://proarea.co/blog/wp-content/uploads/2020/06/1.png" alt="IT аутсорс подрядчик" width="800" height="552" srcset="https://proarea.co/blog/wp-content/uploads/2020/06/1.png 800w, https://proarea.co/blog/wp-content/uploads/2020/06/1-300x207.png 300w, https://proarea.co/blog/wp-content/uploads/2020/06/1-768x530.png 768w" sizes="(max-width: 800px) 100vw, 800px"><b></b></h3>
<h3><b>SING</b><b> #6 GO TO NEW FUNCTIONS WITHOUT COMPLETING PREVIOUS</b></h3>
<p><span>For your product, you have conceived many functions that are described in the specifications for the contractor. He began developing all the functions at once but didn’t complete any of them properly. Six months later, all the modules are “almost ready” but none can be used.</span></p>
<p><span>How it is needed:</span></p>
<p><span>✓ Give the revised functions – correctly working modules that take into account all the scenarios. Screens are correctly displayed on all devices and all operating systems. Pages correctly show information, even if there is no data, there is no Internet or the user entered an incorrect value</span></p>
<p><span>✓ Develop all functions in stages, bringing them to the desired result – a modified functional that you can use</span></p>
<p><span>✓ Pass to the new task only after the previous one is fully completed</span></p>
<p><span>What is the benefit for you:</span></p>
<p><span>✓ You see how your product is formed – gradually, but with visible results</span></p>
<p><span>✓ You get working functions after the end of the current sprints, and not at the very end of the project when it turns out that something remains unfinished</span></p>
<p>We think you have found at least a couple of matches with the work of your current or ex contractor. Their mistakes and lack of professionalism can cost you the success of the entire project, so we advise you to carefully choose the company to which you are ready to entrust your business. We try to follow the principles described in the paragraphs “how it is needed”, taking care of you and the end-users of your product. Speaking of the importance of outsourcing, <span><a href="https://www.forbes.com/sites/forbesbusinesscouncil/2020/07/08/why-its-important-to-outsource-right-now/#a0dbea670e9a">Forbes wrote an excellent article</a>.</span></p>
<p>The next step after choosing a contractor will be writing a statement of work (SOW or specifications). In our article <span><a href="https://proarea.co/blog/how-to-make-correct-requirement-specifications/">“How to make correct requirement specifications”</a></span>, we have written everything you need to consider. Good luck with implementing your ambitious ideas!</p>

        
    </div></div>]]>
            </description>
            <link>https://proarea.co/blog/6-signs-of-a-bad-outsource-contractor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006632</guid>
            <pubDate>Fri, 31 Jul 2020 07:51:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to make correct Requirement Specifications]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24006519">thread link</a>) | @ProArea
<br/>
July 31, 2020 | https://proarea.co/blog/how-to-make-correct-requirement-specifications/ | <a href="https://web.archive.org/web/*/https://proarea.co/blog/how-to-make-correct-requirement-specifications/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><span><span>R</span>equirement specifications are the main project document, describing all its technical and non-technical issues. Any of your ideas are just ideas until specifications developed. In this article, we will explain why this document is so important, when it`s correct to begin development and what exactly it should contain.</span></p>
<h3><b>WHY YOU NEED REQUIREMENT SPECIFICATIONS</b></h3>
<p><span>If you don’t describe the expected result, don`t formulate a clear task and project requirements, you will:&nbsp;</span></p>
<ul>
<li><span>overpay for work and edits;&nbsp;</span></li>
<li><span>waste time;</span></li>
<li><span>get not at all what you want and again overpay for edits;</span></li>
<li><span>close the project due to the fact that there are no more resources for corrections.</span></li>
</ul>
<p><span>And in order to prevent this, it is important to write requirement specifications. In order for the team to understand specific tasks and be able to implement them so that the expectation and the final product result coincide.</span></p>
<h3><strong>THE SPECIFICATIONS` ROLE IN DIFFERENT PROJECT STAGES</strong></h3>
<ol>
<li><span><b> Formation of business requirements</b></span></li>
</ol>
<p><span>This is the foundation for project implementation. At this stage goals and budgets are set. Here the requirement development begins because it determines the future product success. All further work on specifications should be based on business requirements.</span></p>
<ol start="2">
<li><span><b> MVP development</b></span></li>
</ol>
<p><span>It’s almost impossible to build the perfect product on the first try. In any case, it will change based on the feedback of the market and users. Therefore, it is logical to start with MVP – the minimum viable product. For the development of MVP, </span><span>specifications</span><span> are as important as for the development of the main product. At this stage, the </span><span>specifications</span><span> task defines:</span></p>
<ul>
<li><span>basic functions and user interface needed to test a hypothesis;</span></li>
<li><span>criteria necessary for understanding the success of the implementation and launch of the first product version on the market.</span></li>
</ul>
<p><span>So, </span><span>specifications</span><span> at the MVP development stage describe which functions are needed and how it is necessary (minimal and sufficient) to implement in order to test the hypothesis.</span></p>
<p><img src="https://proarea.co/blog/wp-content/uploads/2020/06/rlprkv.png" alt="requirement specifications" width="800" height="552" srcset="https://proarea.co/blog/wp-content/uploads/2020/06/rlprkv.png 800w, https://proarea.co/blog/wp-content/uploads/2020/06/rlprkv-300x207.png 300w, https://proarea.co/blog/wp-content/uploads/2020/06/rlprkv-768x530.png 768w" sizes="(max-width: 800px) 100vw, 800px"></p>
<ol start="3">
<li><span><b> Main product development</b></span></li>
</ol>
<p><span>After the successful launch of MVP, </span><span>requirements</span><span> for the main product are finalized based on the results: a positive market reaction, as confirmation that the business model is working. That is necessary to take into account and describe in </span><span>specifications</span><span>, we wrote in detail in the 3rd section of this document. At this stage, </span><span>requirements </span><span>play a crucial role:</span></p>
<ul>
<li><span>take into account market features (business opportunities, necessary budgets, target audience);</span></li>
<li><span>define the project objectives;</span></li>
<li><span>demonstrate use cases;</span></li>
<li><span>captures functional, non-functional, and technical requirements so that the product is properly designed.&nbsp;</span></li>
</ul>
<p><span>At this stage, </span><span>specifications</span><span> are a complete guide to action, completely describing all important points, starting from a business analysis of the market and target audience, ending with colors, fonts, and other details.</span></p>
<ol start="4">
<li><span><b> Marketing promotion</b></span></li>
</ol>
<p><span>In good </span><span>specifications,</span><span> there is a place for market research, competitors, communication channels with potential users, and resources for promotion. Marketing promotion is the logical and necessary project support at the start and after it. If you don’t initially plan marketing activity, you probably won’t take into account the resources (in particular, the money) needed for a confident release. You run the risk of being left completely without promotion since the main resources will go to development. So, without the described marketing, you can confront a lot of problems:</span></p>
<ul>
<li><span>lack of promotion resources;</span></li>
<li><span>lack of understanding of the market and its users;</span></li>
<li><span>failure to provide your product benefits to the audience;</span></li>
<li><span>and as a result – market failure.</span></li>
</ul>
<p><span>At this stage, </span><span>specifications</span><span> are the answer to the question “what to do after the release?”</span></p>
<p><img src="https://proarea.co/blog/wp-content/uploads/2020/02/fke2.png" alt="requirement specifications" width="800" height="552" srcset="https://proarea.co/blog/wp-content/uploads/2020/02/fke2.png 800w, https://proarea.co/blog/wp-content/uploads/2020/02/fke2-300x207.png 300w, https://proarea.co/blog/wp-content/uploads/2020/02/fke2-768x530.png 768w" sizes="(max-width: 800px) 100vw, 800px"></p>
<h3><strong>WHAT IS IMPORTANT TO ACCOUNT AND DESCRIBE IN SPECIFICATIONS</strong></h3>
<ol>
<li><span><b> Describe a problem</b></span></li>
</ol>
<ul>
<li><span>Why does the market need a product?</span></li>
<li><span>Whose and what problem does it solve?</span></li>
<li><span>What tasks should the product solve?</span></li>
</ul>
<ol start="2">
<li><span><b> Determine personal goals</b></span></li>
</ol>
<ul>
<li><span>Why do I need this in the long term?</span></li>
<li><span>Why do I need this in the short term?</span></li>
</ul>
<ol start="3">
<li><span><b> Describe a business model</b></span></li>
</ol>
<ul>
<li><span>Who is our target audience?</span></li>
<li><span>What is a client portrait?</span></li>
<li><span>Where to find a target audience, through which sales channels?</span></li>
<li><span>What are the communication channels with the client?</span></li>
<li><span>Who are the key competitors? What are their advantages and USP?</span></li>
<li><span>What are our value propositions?</span></li>
<li><span>What is our USP?</span></li>
<li><span>What are the product advantages?</span></li>
<li><span>What key actions do we need to perform?</span></li>
<li><span>What key resources do we need?</span></li>
<li><span>Who are our key partners?</span></li>
<li><span>What are the risks?</span></li>
</ul>
<ol start="4">
<li><span><b> Form a financial model</b></span></li>
</ol>
<ul>
<li><span>What will be the main costs?</span></li>
<li><span>What will be the main sources of income?</span></li>
<li><span>Calculate the breakeven point (optimistic, real, and pessimistic forecast).</span></li>
</ul>
<ol start="5">
<li><span><b> Describe use cases</b></span></li>
</ol>
<ul>
<li><span>Describe users by groups. For example, administrator, manager, financier, operator, driver, etc.</span></li>
<li><span>What is the use case for each group?</span></li>
<li><span>What are the features and limitations of each of these roles?</span></li>
</ul>
<ol start="6">
<li><b><span> Describe Functional / Technical requirements</span></b></li>
</ol>
<ul>
<li><span>What key target action should the user make?</span></li>
<li><span>What features need to be implemented?</span></li>
<li><span>Do you need integration with third-party services?</span></li>
<li><span>How many and what languages are needed?</span></li>
<li><span>What operating systems, browsers and their versions need to be supported?</span></li>
<li><span>What are the technology preferences for development?</span></li>
<li><span>Are there any additional requirements for safety or personal data security?</span></li>
<li><span>What legislative framework should be taken into account? For example, RGPR.</span></li>
</ul>
<ol start="7">
<li><span><b> Describe Non-Functional requirements</b></span></li>
</ol>
<ul>
<li><span>How should the product look like?</span></li>
<li><span>What screens are needed in the product, what is displayed on each of them?</span></li>
<li><span>How does each screen change in different states (there is the Internet, there is data to display, there is no data to display, an error has occurred on the server, etc.)?</span></li>
</ul>
<p><img src="https://proarea.co/blog/wp-content/uploads/2020/06/art1.png" alt="Project wireframes and flow" width="800" height="552" srcset="https://proarea.co/blog/wp-content/uploads/2020/06/art1.png 800w, https://proarea.co/blog/wp-content/uploads/2020/06/art1-300x207.png 300w, https://proarea.co/blog/wp-content/uploads/2020/06/art1-768x530.png 768w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p><span>The ideal picture is described above, which is not always needed and feasible. Depending on your goals, project size, and product complexity, some points may be skipped. <span>The main thing is to answer all the questions that are important for the project and document it at the requirement specifications. Then, you will be sure that you are moving in the right direction at all stages of development.</span></span></p>
<p><span>If you don’t have specifications or you are not sure about the current ones, we can develop it for you, just contact us using the button below. We also recommend <span><a href="https://proarea.co/blog/make-pop-ups-which-don-t-enragethe-whole-world-is-in-our-smartphones-modern-types-of-mobile-apps/">our article about application types</a></span> and <span><a href="https://proarea.co/blog/when-does-business-need-a-mobile-app/">when and why a business may need a mobile application</a></span>.</span></p>

        
    </div></div>]]>
            </description>
            <link>https://proarea.co/blog/how-to-make-correct-requirement-specifications/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006519</guid>
            <pubDate>Fri, 31 Jul 2020 07:30:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS: Refactor a distributed monolith to microservices with Event Bridge and BASE]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24006410">thread link</a>) | @rehanvdm
<br/>
July 31, 2020 | https://www.rehanvdm.com/serverless/refactoring-a-distributed-monolith-to-microservices/index.html | <a href="https://web.archive.org/web/*/https://www.rehanvdm.com/serverless/refactoring-a-distributed-monolith-to-microservices/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<ul><li><a data-class="popup" data-network="facebook" href="https://www.facebook.com/sharer.php?u=http%3A%2F%2Fwww.rehanvdm.com%2Fserverless%2Frefactoring-a-distributed-monolith-to-microservices%2Findex.html" target="_blank" rel="nofollow"><i></i> </a></li><li><a data-class="popup" data-network="twitter" href="https://twitter.com/intent/tweet?text=Refactoring%20a%20distributed%20monolith%20to%20microservices&amp;url=http%3A%2F%2Fwww.rehanvdm.com%2Fserverless%2Frefactoring-a-distributed-monolith-to-microservices%2Findex.html&amp;via=der_rehan" target="_blank" rel="nofollow"><i></i> </a></li><li><a data-class="popup" data-network="linkedin" href="https://linkedin.com/shareArticle?mini=true&amp;url=http%3A%2F%2Fwww.rehanvdm.com%2Fserverless%2Frefactoring-a-distributed-monolith-to-microservices%2Findex.html&amp;title=Refactoring+a+distributed+monolith+to+microservices" target="_blank" rel="nofollow"><i></i> </a></li></ul>




<p>This article documents the thought process and steps involved in refactoring a distributed monolith to microservices. We are going to remove API GW, use Amazon Event Bridge and implement BASE consistency in the system to truly decouple our microservices.</p>



<p><em>This blog is also available as a presentation. Reach out
if you would like me to present it at an event. </em></p>



<p>I will use the codebase from the previous installment to the series that can be found <a rel="noreferrer noopener" aria-label="here (opens in a new tab)" href="https://www.rehanvdm.com/general/aws-serverless-you-might-not-need-third-party-monitoring/index.html" target="_blank">here</a>. The first part focuses on creating the codebase and implementing AWS native observability, monitoring and alerting services. As always you can find the code that we used in the respective GitHub repositories over here: <a rel="noreferrer noopener" href="https://github.com/rehanvdm/MicroService" target="_blank">https://github.com/rehanvdm/MicroService</a>.</p>



<h2>Original System</h2>



<p>The <a rel="noreferrer noopener" aria-label="original system (opens in a new tab)" href="https://www.rehanvdm.com/general/aws-serverless-you-might-not-need-third-party-monitoring/index.html" target="_blank">original system</a> is a distributed monolith that consists of three microservices. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_01_SystemArchitecture.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_01_SystemArchitecture-1024x715.png" alt="" width="1024" height="715" srcset="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_01_SystemArchitecture-1024x715.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_01_SystemArchitecture-300x210.png 300w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_01_SystemArchitecture-768x536.png 768w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_01_SystemArchitecture.png 1111w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>Original system (Click to enlarge)</figcaption></figure>



<p>Within each project you can find an <strong>OpenAPI </strong>(<a rel="noreferrer noopener" href="https://github.com/rehanvdm/MicroServicePerson/blob/master/part1/src/lambda/api/api-definition.yaml" target="_blank">part2/src/lambda/api/api-definition.yaml</a>) file that defines the API definition for each service.<strong> AWS CDK</strong> is used and they all follow the similar stock standard CDK project layout: Typescript for the CDK and <strong>ES6 JS</strong> for the application code. NPM commands have been written to do deployments and it also contains<strong> end-to-end tests </strong>using Mocha and Chai. In addition, each service contains a detailed README inside the /part2 path. Note that I only have a single Lambda for the API endpoint and do internal routing. Yes, I believe in a <strong>Lambalith for the API</strong> 😊 and also prefer JSON POST over REST (more about this later). </p>



<p>A <strong>problem </strong>arises as soon as these microservices start to call one another. We will focus on the creation of a new person to demonstrate how this <strong>tight coupling</strong> is working. </p>



<p>The client service stores clients and has basic <em>create-client</em> and <em>find-client</em> functionalities as well as an endpoint to increment the person count for a specific client. The person service also has basic <em>create-person</em> and <em>find-person</em> endpoints. When a person is created, it calls the common service which notifies me by email about the new person that was added using an SNS subscription. The common service first needs to do a lookup on the client service so that it can enrich the email. It also increments the counter on the client. Click on the image below to see the step-by-step path for creating a person:</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_02_SystemArchitecturePathFocus.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_02_SystemArchitecturePathFocus-1024x553.png" alt="" width="1024" height="553" srcset="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_02_SystemArchitecturePathFocus-1024x553.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_02_SystemArchitecturePathFocus-300x162.png 300w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_02_SystemArchitecturePathFocus-768x415.png 768w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_02_SystemArchitecturePathFocus.png 1442w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption> <br>Original system – full create person flow (Click to enlarge) </figcaption></figure>



<p>The <em>create-person</em> call is highly dependent on the common service and does not even know that the common service is dependent on the client service. As a result, the person service is also dragged down if either the common or the client service is down. Not to mention that it now has to wait for the completion of every step in the synchronous chain. This wastes money and increases the probability of hitting the API Gateway timeout of 29 seconds.</p>



<h2>Decoupling with Amazon Event Bridge</h2>



<p>Amazon Event Bridge is a serverless event bus that makes it easy to work with <strong>event-driven architectures</strong>. It works on a basic <strong>publish and subscribe</strong> model. We use it to emit certain events like: <em>person-created </em>and <em>client-created.</em> Other services can then listen to only the events that they want and act on it. The new system is refactored to incorporate this and remove the direct HTTP API calls between services. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_03_EVentBridge.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_03_EVentBridge-1024x522.png" alt="" width="1024" height="522" srcset="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_03_EVentBridge-1024x522.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_03_EVentBridge-300x153.png 300w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_03_EVentBridge-768x391.png 768w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_03_EVentBridge.png 1531w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption> <br>New system (Click to enlarge)  </figcaption></figure>



<p>The <strong>client service</strong> has not changed much. It is still
fronted with API Gateway (GW). It now emits an event onto the bus whenever a
client is created. A new Lambda function is added that listens to the <em>create-person</em> events. This increments the person counter for that specific client.
This feature was previously on the common service but has now moved to the
client service.</p>



<p>The <strong>person service</strong> is working exactly as before. Just
like the client service, it also emits an event onto the event bus,
specifically the <em>create-person</em> event.</p>



<p>The <strong>common service</strong> no longer needs to be fronted by
API GW. Instead it listens to both the <em>create-client</em> and <em>create-person</em>
events. The common service stores the client data in its own DynamoDB table. It
uses this to look the client up within itself (locally), rather than calling an
HTTP API to get the data for a specific client. The common service still sends
an email when a new person is added. </p>



<p>From an <strong>external integration point of view</strong>, all API endpoints stayed exactly the same. The diagrams below clearly illustrate that each service is only concerned with its own data and responsibilities. The event that is emitted onto the bus is also added for convenience.</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_04_PartialPerson.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_04_PartialPerson-1024x711.png" alt="" width="1024" height="711" srcset="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_04_PartialPerson-1024x711.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_04_PartialPerson-300x208.png 300w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_04_PartialPerson-768x533.png 768w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_04_PartialPerson.png 1539w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption> <br>New system – partial create person flow (Click to enlarge) </figcaption></figure>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_05_PartialClient.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_05_PartialClient-1024x715.png" alt="" width="1024" height="715" srcset="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_05_PartialClient-1024x715.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_05_PartialClient-300x209.png 300w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_05_PartialClient-768x536.png 768w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_05_PartialClient.png 1522w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption> <br>New system – partial client person flow (Click to enlarge)  </figcaption></figure>



<p><strong>Internally</strong> the common service has an Event Bridge Rule with the Lambda function as target. It listens to the <em>create-client</em> events and then stores only the client-id and client name fields within its own DynamoDB table. This <strong>removes the need for it to do an HTTP API call</strong> to the client service as it can now just do the lookup locally against its own data store.</p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_06_FullClient.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_06_FullClient-1024x529.png" alt="" width="1024" height="529" srcset="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_06_FullClient-1024x529.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_06_FullClient-300x155.png 300w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_06_FullClient-768x397.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption> <br>New system – full create client flow (Click to enlarge)  </figcaption></figure>



<p>The common service also listens to the <em>create-person</em> event. It <strong>looks up the client information in its own DynamoDB table</strong> and then sends the SNS message. <strong>At the same time</strong>, the client service also listens to the <em>create-person</em> events. It uses the client-id that comes with the event to increment the person counter for that specific client in the client service DynamoDB table. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_07_FullPerson.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_07_FullPerson-1024x522.png" alt="" width="1024" height="522" srcset="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_07_FullPerson-1024x522.png 1024w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_07_FullPerson-300x153.png 300w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_07_FullPerson-768x391.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption> <br>New system – full create person flow (Click to enlarge)   </figcaption></figure>



<h2>What has changed?</h2>



<p>We used Event Bridge to<strong> remove direct HTTP API calls</strong> between microservices. It also allowed us to <strong>move some logic</strong> to where it belongs. The common service should not be responsible to increment the specific client’s person counter in the first place. That functionality is now contained within the client service, where it belongs. </p>



<p>We basically borrowed two principles from the <strong>SOLID OOP principles</strong>: </p>



<ul><li>Single Responsibility – Each service is only concerned with its own core functionality.</li><li>Open Closed – Each service is now open for extension, but the core functionality is closed for modification.</li></ul>







<p>Then we introduced <strong>BASE consistency</strong> into the system: </p>



<ul><li><strong>B</strong>asic <strong>A</strong>vailability – Even if the client service is down the common service can still operate as it has a copy of the data. Thus the data layer/plane is still operational.</li><li><strong>S</strong>oft State – Stores don’t have to be write-consistent or mutually consistent all the time.</li><li><strong>E</strong>ventual Consistency – The system will become consistent over time, given that the system doesn’t receive input during that time.</li></ul>







<p>A BASE system is almost always going to be an <strong>AP system</strong> if you look at the CAP theorem. Meaning it favors <strong>A</strong>vailability and <strong>P</strong>artitioning over <strong>C</strong>onsistency. </p>



<figure><a href="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_08_CAP.png" target="_blank" rel="noreferrer noopener"><img src="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_08_CAP.png" alt="" width="966" height="683" srcset="https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_08_CAP.png 966w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_08_CAP-300x212.png 300w, https://www.rehanvdm.com/contents/data/2020/07/refactor_dist_mon_08_CAP-768x543.png 768w" sizes="(max-width: 966px) 100vw, 966px"></a><figcaption>CAP theorem applied to Databases (Click to enlarge)</figcaption></figure>



<p><strong>DynamoDB </strong>is an example of an <strong>AP system</strong> as well. Your data is stored on multiple 10GB partition drives spread over multiple Availability Zones. That replication takes a few milliseconds, up to a second or two. Obviously, there are cases where you need to read the data back directly after writing. That is why you can specify a Strongly Consistent read, which just goes back to the writer node and queries the data there instead of waiting for the data to have propagated to all nodes. </p>



<p><strong>S3 </strong>has <strong>read-after-write consistency for the PUT item</strong> command but all <strong>other commands are subject to eventual consistency.</strong> This means that after updating an item, the old content may still be returned for a short amount of time until the content of that file has propagated to all the storage nodes. There are more examples such as these all over the AWS ecosystem.</p>



<p>Event-driven architectures come with their own <strong>pros and cons</strong>. Firstly, you need to <strong>approach the problem with a different distributed mindset</strong> that needs to be present within the company/team as well. Event <strong>versioning and communication</strong> between teams that own microservices are also crucial. It is a good idea to have a service that keeps a <strong>ledger of all events that happen</strong> in the system. Worst case, this history of events can be replayed to fix any processing errors in the downstream processing. </p>



<p>Event bridge, like SNS and SQS, guarantees delivery of a message at least once. This means your <strong>system needs to be idempotent</strong>. An example of an idempotent flow is when the client is created and the common service does a PUT command into the DynamoDB table. If that event gets delivered more than once, it just overwrites the current client with the exact same data.</p>



<p>An example of a non-idempotent flow is when the person is
created. If the client service gets more than one message, it increments the
client-person counter more than once. There are ways to make this call
idempotent, but we’ll leave that for a different blog. </p>



<p>Another thing to consider is that not all systems can accept the delay that eventual consistency introduces into a system. It is perfectly acceptable in our system as a person will probably not be created immediately within one second after a client has been created. Thus, whenever the common service does the client lookup locally, it can be assured that the client data is always populated. </p>



<h2>Resilience to Failure</h2>



<p>One of the benefits that we have achieved by refactoring to a microservice system is that we are now r<strong>esilient to complete services failure</strong>. The client service can still operate if the person and common service is down. Similarly, the person service can operate on its own and is not dependent on the other services.</p>



<p>We also <strong>removed any timeout problems that was introduced</strong> by the previous architecture that synchronously chained API calls. If an Event Bridge target service (like Lambda, in our case) is down, it will retry sending the message with exponential bakeoff for up to 24 hours. </p>



<p>All Lambda functions that process the asynchronous events from Event Bridge have <strong>Dead Letter Queues</strong> (DLQ) …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.rehanvdm.com/serverless/refactoring-a-distributed-monolith-to-microservices/index.html">https://www.rehanvdm.com/serverless/refactoring-a-distributed-monolith-to-microservices/index.html</a></em></p>]]>
            </description>
            <link>https://www.rehanvdm.com/serverless/refactoring-a-distributed-monolith-to-microservices/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006410</guid>
            <pubDate>Fri, 31 Jul 2020 07:07:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anachro-PC – The Anachronistic Personal Computer]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24006236">thread link</a>) | @MindGods
<br/>
July 30, 2020 | https://jamesmunns.com/blog/anachro-pc-001/ | <a href="https://web.archive.org/web/*/https://jamesmunns.com/blog/anachro-pc-001/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
  
  <p><span>2020-07-30</span></p><hr>
  <blockquote>
<p>TL;DR - These are my notes for a potential computer hobbyist personal computer architecture. Someone called it "Minix for motherboards".</p>
</blockquote>
<p>This roughly describes an architecture of off the shelf microcontroller components that can be used to create a basic standalone PC, somewhere in the neighborhood of performance of an old 286/386 DOS style PC.</p>
<p>If I build this, it will almost certainly be done in Rust. I do hope to specify the protocol/operational semantics well enough that you could create a component that was written in Micro/Circuit Python, C/C++, Ada, or maybe even as an embedded linux PC.</p>
<p>I currently am working on other projects, but I feel like this would be a fun project to stream, or maybe even write a book about learning embedded systems, or learning Rust with embedded systems?</p>
<p><strong>If you'd be interested in taking a class building/using a system like this, or would be interested in seeing this happen, <a href="mailto:james.munns@ferrous-systems.com">send me a message</a>.</strong></p>

<h2 id="project-goals">Project Goals</h2>
<p>The goal of this project is to design a PC-ish architecture that makes it easy for people learning embedded systems to build a single component. This includes:</p>
<ol>
<li>Making the system resistant to failure of a single component</li>
<li>Use only protocols/components that can be easily purchased</li>
<li>Be adaptive to allow for variety of components used</li>
<li>Value simplicity over performance</li>
<li>Make the steps to initial success very short</li>
<li>Make this fun for me and other collaborators to work on</li>
</ol>
<h2 id="project-anti-goals">Project Anti-Goals</h2>
<ol>
<li>Designing something that is wholly useful in commercial deployments</li>
</ol>
<h2 id="interesting-ideas">Interesting Ideas</h2>
<p>These are ideas that I think will help make the project successful.</p>
<h3 id="every-component-is-a-microcontroller-any-microcontroller">Every Component is a Microcontroller - Any Microcontroller.</h3>
<p>The idea is to have every part (or <strong>Component</strong>) of the system be its own standalone microcontroller system. Honestly, this is how most computers work today anyway, but the idea is to be able to use almost any microcontroller, from 8051, to Arm Cortex-M, to RISC-V parts, for any piece of the PC. At some point, I can see people even making parts of the PC out of FPGAs as well.</p>
<p>This includes all of the following PC parts:</p>
<ul>
<li>The Main CPU/Processor</li>
<li>An input controller (Keyboard/Mouse/Touch)</li>
<li>A network interface (Ethernet/Wi-Fi/LPWAN)</li>
<li>A storage controller (SSD/SD/HDD/RAMFS/USB)</li>
<li>A Sound Card</li>
<li>A graphics card (framebuffer, shaders)</li>
</ul>
<p>The system should use a protocol that almost every device has support for, and is forgiving. For that reason, I plan to use SPI for system communication.</p>
<h3 id="the-bus-protocol-spi-but-weird">The Bus Protocol - SPI, but weird.</h3>
<p>So, SPI is a simple, fast, and reliable protocol, but the trick is that it is WAY easier to write a SPI Controller, rather than a SPI peripheral. Since I want things to be simplest for the people writing the Components, they should be the SPI Controllers. But this leaves us with a problem, how do we make a PC with N SPI Controllers work with a single SPI peripheral? Here is where it gets weird.</p>
<ol>
<li>Every Component is a SPI Controller, with SCK, COPI, and CIPO pins wired to a central <strong>Arbitrator</strong>.</li>
<li>Every Component also has two GPIOs:
<ul>
<li>An output that is a "Request" line. This signals to the Arbitrator that the Component would like to talk</li>
<li>An input that is a "Go-Ahead" line. This signals to the Component to begin talking to the Arbitrator</li>
</ul>
</li>
</ol>
<p>In this system, the Arbitrator will either support being a SPI Peripheral for a lot of lines, or will handle MUXing the SCK/COPI/CIPO pins as necessary.
The Arbitrator will decide which component it wants to talk to, and for how long.
When a Component pulls its Request line low, the arbitrator will eventually acknowledge this by pulling the Component's Go-Ahead line low.
The Component can begin clocking SPI data at whatever speed it feels like, up to the maximum speed supported by the Arbitrator.
When the Component is done sending/receiving data, it checks whether the Go-Ahead line is still low.
If so, then the message was "accepted" by the arbitrator.
If the Go-Ahead line is released high before the Component releases the Request line, this means that the arbitrator has "hung up" on the Component, meaning either an error or timeout has occurred.</p>
<h3 id="the-arbitrator-basically-a-northbridge-chip">The Arbitrator - Basically a Northbridge chip</h3>
<p>The Arbitrator has two primary tasks:</p>
<ol>
<li>Arbitrating the Bus Protocol as described above, servicing and discovering components that have been connected</li>
<li>Managing memory allocations used to communicate between devices</li>
</ol>
<p>I've already described the lowest level of the protocol above - we'll use an awkward SPI communication. However I haven't described how the higher protocol layers work.</p>
<p>All devices will communicate through a mailbox system.
The arbitrator will take data from the Components, and place them in an in-memory object store.
Each created item will be assigned a UUID, which will be returned to the Component on creation.
This UUID can then be placed in a mailbox to another component, sending access to the data to that component.
Each item is read-only.</p>
<p>Example (psuedocode):</p>
<pre><span>// A binary RPC messages are sent from Component to the Arbitrator
// The format will probably be binary, but maybe with an alternative
// command to use the following REPL format?
//
// Components are also assigned a UUID on boot. This Component has
// the own-address of 9ea8b6a7-2967-4db8-98b8-d4577548ed04.

// Data can be stored to the Arbitrator memory space. Data can then be
// referenced as inter-device storage using UUIDs as a reference. Data
// is allocated on a FIFO basis, with oldest memory items becoming
// dropped.
//
// The arbitrator may choose to limit the rate, maximum size or other
// parameters of creating memory items based on configuration.
CREATE(
    // number of bytes to write, can be set to zero for dynamic
    // length using something like COBS or when the Request
    // line is de-asserted
    13,

    // The payload of the data
    "Hello, world!",

    // No UUID provided to send to another component, just return
    // the newly created UUID. If provided, this would place
    // the created UUID into the mailbox of another component
    None,
)
// The following UUID is returned to the Component on success
-&gt; Result&lt;3b2fd5d1-ae16-46af-afc1-f60241d0a5b6, CreateError&gt;

// You can send data by reference to another component you know's
// mailbox. Mailboxes are provided as a Component's address. Mailboxes
// are a FIFO queue of UUIDs that can be loaded by that Component
SEND_MAILBOX(
    // The data reference to send
    3b2fd5d1-ae16-46af-afc1-f60241d0a5b6,

    // The destination address
    56c3dbda-c762-4107-be58-855dc8e5aa92,
)

// The other device can receive messages on a FIFO basis, and can view
// the item at the top of the stack without removing it
PEEK_MAILBOX(
    // You can provide Some(usize) as a max message size, or None for
    // anymessage size. Messages larger than the usize value will
    // instead return an Error
    Some(32),
)
-&gt; Result&lt;(13, "Hello, world!"), GetError&gt;

// The other device can receive messages on a FIFO basis, and can view
// and remove the item at the top of the stack. If the Controller
// ends the message before all bytes are received, the item is still
// removed from the FIFO. Thiscan be used to simply drop the item on
// the top of the FIFO.
POP_MAILBOX(
    // You can provide Some(usize) as a max message size, or None for
    // any message size. Messages larger than the usize value will
    // instead return an Error
    Some(32),
)
-&gt; Result&lt;(13, "Hello, world!"), GetError&gt;

// TODO: How to have a "clone and modify" operation that isn't hard
// because of re-allocs? Insertions would suck unless I used some kind
//  of rope structure, which might be too complex to implement
</span></pre>
<p>You can also use the SPI interface for certain communications directly to the arbitrator</p>
<pre><span>// Register ourself using an enumerated type ID
//
// TODO: What to do when calling this more than once?
REGISTER_TYPE(
    IO_CONTROLLER,
) -&gt; Result&lt;9ea8b6a7-2967-4db8-98b8-d4577548ed04, GetError&gt;

// Get the ID of ourself. Matches ID given on registration
GET_OWN_ID()
-&gt; Result&lt;9ea8b6a7-2967-4db8-98b8-d4577548ed04, GetError&gt;

// Get limits of the arbitrator interface
GET_ARBITRATOR_LIMITS()
-&gt; {
    min_speed_hz: 125_000,     // What is the minimum SPI clock rate?
    max_speed_hz: 8_000_000,   // What is the maximum SPI clock rate?
    exp_polls_per_sec: 100,    // What is the expected poll frequency?
    request_line_shared: false,// Is the request line open drain?
    total_memory: 524288,      // 512KiB
    max_files: 512,            // Max number of records alive at once
}

// Get limits for message creation
GET_CREATE_LIMITS()
-&gt; {
    max_bytes: 512,             // Largest message can be 512 bytes
    max_bytes_per_second: 4096, // Running resource limits
    messages_per_second: 10,    // Running resource limits
}
</span></pre>
<blockquote>
<p>TODO: How to register multiple addresses/logical addressing? e.g. for keyboard that has a mouse and touchpad?
Could add a "from" field to every message, but then I'm adding a routing layer?</p>
</blockquote>
<h3 id="an-easy-bootloader">An easy bootloader</h3>
<p>Write a simple bootloader that can enumerate on the bus, take an image, and reboot? PXII boot style? Would need to enumerate type
and maybe even serial number or something to load the right firmware to the right place.</p>
<h2 id="the-first-implementation">The First Implementation</h2>
<p>These are ideas for possible first implementation of the PC architecture described above</p>
<h3 id="a-simulator-with-real-world-hooks">A Simulator with real-world hooks</h3>
<p>I could create a simulated environment for these components, using no_std libraries and using TCP over localhost to emulate the SPI target environment, basically providing an I/O library or a "HAL" for simulating each component inside of a system. Maybe even port RTIC to the simulated environment, or even just use QEMU, using Semihosting for simulated SPI/GPIOs?</p>
<p>With a little work, I could also probably have an arbitrator or even just a simple SPI controller sit outside of the PC, bridging one or more simulated components to a shared network with physical components.</p>
<p>This would allow me to bring up multiple devices quickly, both from a Component software …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jamesmunns.com/blog/anachro-pc-001/">https://jamesmunns.com/blog/anachro-pc-001/</a></em></p>]]>
            </description>
            <link>https://jamesmunns.com/blog/anachro-pc-001/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006236</guid>
            <pubDate>Fri, 31 Jul 2020 06:30:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Gentle Introduction to HVMI (Hypervisor Memory Introspection)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24006120">thread link</a>) | @__rompy
<br/>
July 30, 2020 | https://hvmi.github.io/blog/introspection/2020/07/30/introduction.html | <a href="https://web.archive.org/web/*/https://hvmi.github.io/blog/introspection/2020/07/30/introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <h2 id="introduction">Introduction</h2>

<p>Hypervisor memory introspection (HVMI) has been around for quite some time now, and there are several open-source projects utilizing virtual-machine introspection (VMI), one way or another. Generally, existing projects focus on debugging or tracing the execution of a guest VM. In this blog post, we introduce a slightly different approach to memory introspection; live protection of guest VMs. We cover the motivation behind our HVMI engine, how it was conceived, how it evolved over time, and finally, why we made it available for everyone.</p>

<p>Throughout this blog, we assume the reader has some basic knowledge about virtualization technologies (Intel VT-x specifically) and about OS internals (both Windows and Linux), although we try to cover as much ground as possible when it comes to technical details.</p>

<h2 id="what-hvmi-is">What HVMI Is</h2>

<p>Memory introspection is the technique of analyzing the contents of a guest VM from outside. The most common way to achieve this is using a hypervisor – running guest VMs are analyzed or introspected by the hypervisor. The CPU context can be viewed, the contents of the physical memory can be observed, and so on. In addition to simply analyzing the state of the VM, the introspection logic, or HVMI (how we refer to it from here on) also leverages the virtualization features provided by the CPU to provide security.</p>

<p>For example, by using the Extended Page Table (EPT) feature provided by Intel CPUs, HVMI overrides the guest OS memory protection policies. HVMI could, for example, enforce a no-execute policy for certain memory areas, and an exploit would fail even if it compromised the OS kernel. In addition to using the EPT to enforce memory access restrictions, HVMI can also use other virtualization capabilities to offer security. It can prevent modification of certain critical resources, such as control registers or model specific registers. Rootkits or exploits that rely on modifying these will fail because HVMI blocks the modifications.</p>

<p>HVMI is not about just advantages; it does have some drawbacks. One of the most important disadvantages of HVMI is the semantic gap – from outside the VM, we see only raw physical memory, with no apparent meaning. To do something useful, we must infer what those memory pages contain. Is it a process structure, is it a stack page, etc. In addition to the semantic gap, providing protection for certain system resources may prove challenging, from a performance point of view. Many legitimate accesses made inside a page that contains a protected structure may induce a severe performance overhead; this makes choosing what structures to protect a very difficult task. Finally, implementing HVMI is often very complex since it often requires reverse-engineering chunks of OS kernel, advanced knowledge about virtualization and, of course, software engineering.</p>

<h2 id="hvmi-history">HVMI History</h2>

<p>HVMI began as a research idea almost 10 years ago (late 2011). The team initially consisted of only one researcher (yours truly), who developed the initial PoC (simple driver-object protection via EPT, to block the TDL rootkit). Once the blessing from the powers that be was received, more time and effort was invested into this research, and the team began to grow. What was initially very straightforward code capable of protecting a handful of non-paged kernel memory pages on Windows 7 grew to become a beast capable of protecting all Windows versions starting with Windows 7, several Linux distros, and, on each of these, even user-mode processes, from various types of attacks.</p>

<p>HVMI was available as a commercial product in 2017, as part of the SVE package – Security for Virtualized Environments. During this time, it was polished, performance was improved, and several new features were developed. In late 2019, we decided to open-source the technology to make it available for everyone to see, use, play with, and extend with new features and capabilities.</p>

<h2 id="how-hvmi-works">How HVMI Works</h2>

<p>In essence, HVMI requires a hypervisor that provides the required API to provide protection. The required API can be explored in the official documentation TODO ref. Once such an API is provided, HVMI places several types of hooks inside the guest. For example, it can intercept control register 3 (CR3 - the register containing the address of the page-tables used for translating linear addresses to physical addresses) – this way, HVMI intercepts context switches inside the guest. By intercepting, for example, SYSCALL MSR writes, HVMI intercepts and blocks attempts to manipulate the SYSCALL entry point address. Most importantly, it uses the EPT to alter physical memory access permissions, thus overriding and restricting access to certain areas of the guest memory.</p>

<h3 id="general-architecture">General Architecture</h3>

<p>The HVMI engine is a standalone library, self-contained (it has no explicit external dependencies), and can be run in user-mode, kernel-mode, or even VMX root-mode. It is written entirely in C, with small bits and pieces written in assembly. The HVMI engine expects an interface containing several API functions to be exposed to it by whatever integrates with it. In this context, the integrator is a tool that binds the HVMI library to a particular hypervisor which provides a uniform API.</p>

<p>Supported hypervisors include our internally built Napoca hypervisor TODO ref, and the well-known open-source hypervisors Xen and KVM. Using the Napoca hypervisor, the HVMI engine runs directly inside VMX root, alongside the HV. In Xen and KVM, the HVMI engine runs as a regular user-mode process inside a special VM (or domain), or even dom0. The general architecture of HVMI is illustrated in the following image:</p>

<p><img src="https://hvmi.github.io/blog/assets/architecture.png" alt="General HVMI architecture on Xen/KVM"></p>

<p>From a functional perspective, HVMI is an event-driven library. When introspection is enabled for a guest VM, HVMI starts by identifying the guest operating system type, version, to find various important structures inside its memory. This process is asynchronous, meaning that once the initialization function returns, there’s no guarantee that HVMI has finished initialization; some parts of the guest introspection process occur when various events take place (for example, when CR3 is written). Once introspection is enabled, HVMI kicks-in when interesting events take-place within the guest; when a process is created or terminated, when a new memory region is allocated inside a protected process, or when memory accesses take place inside a protected region.</p>

<h2 id="making-use-of-hvmi">Making Use of HVMI</h2>

<p>Although we won’t go into very deep details (yet!) regarding the internals of the HVMI engine, here’s a list of the most important features HVMI exposes:</p>

<ul>
  <li>The list of loaded kernel mode drivers, with load/unload events;</li>
  <li>The list of user-mode processes, with create/terminate events;</li>
  <li>For processes that are protected, the list of loaded user-mode DLLs with load/unload events, and the list of Virtual Address Descriptors for that process with alloc/free events;</li>
  <li>On Windows, access to the Page Frame Number (PFN) Database;</li>
  <li>On Windows, the ability to parse the object tree (this is currently used to search for driver-objects inside guest memory, but it can easily be extended to handle any kind of object);</li>
</ul>

<p>As for OS agnostic features HVMI provides:</p>

<ul>
  <li>Guest hardware registers state query;</li>
  <li>Guest physical memory access;</li>
  <li>Ability to place read/write/execute hooks on physical memory;</li>
  <li>Ability to place read/write/execute hooks on virtual memory;</li>
  <li>Ability to place access hooks on control registers;</li>
  <li>Ability to place access hooks on model specific registers;</li>
  <li>Ability to place access hooks on descriptor table registers;</li>
  <li>Ability to intercept exceptions that take place inside the guest (for example, #PF, #BP, etc.);</li>
  <li>Ability inject exceptions inside the guest;</li>
  <li>Access to swapped out guest memory (by injecting #PF inside the guest);</li>
  <li>Ability to hide certain guest memory contents (reads issued inside the guest will be fed with custom values);</li>
  <li>Advanced instruction decoding and handling (the disassembler used by HVMI provides extended information about the decoded instructions, making information extraction and emulation very simple)</li>
</ul>

<h3 id="protection-features">Protection features</h3>

<p>The primary purpose of the HVMI engine is to, above all, provide protection. The following list contains the main types of threats HVMI was built to mitigate:</p>

<ul>
  <li>Binary exploits inside protected processes;</li>
  <li>Code and data injection techniques inside protected processes;</li>
  <li>Function hooks inside protected processes, on designated system DLLs;</li>
  <li>Rootkits (various techniques are blocked, such as inline hooks inside the kernel or other drivers, SSDT hooks, Driver-object hooks, system register modifications, etc.);</li>
  <li>Kernel exploits;</li>
  <li>Privilege escalation;</li>
  <li>Credentials theft;</li>
  <li>Deep process introspection (prevents process creation if the parent process has been compromised);</li>
  <li>Fileless malware (powershell command line scanning).</li>
</ul>

<h2 id="start-contributing">Start Contributing</h2>

<p>We see great potential for the HVMI project, which is why we decided to open-source it and make it available to everyone. Researchers are welcome to clone the project, run it, experiment, and add new features. We also accept pull-requests – if you think your feature is cool enough, be sure to make it available on the main HVMI repo!</p>

<p>Intel is continuously developing new virtualization technologies which make HVMI better and faster. Some of these have already been released, such as the Virtualization Exception (#VE), VM Functions (VMFUNC) and Sub Page Permissions (SPP), and HVMI makes use of them. Others, such as Hypervisor Linear Address Translations (HLAT) have recently been announced, and will make it into silicon in the upcoming years. We are sure that other technologies are yet to come, showing that both hardware vendors and software developers want to invest time and effort to create new virtualization features!</p>



<ul>
  <li>The HVMI project is located at <a href="https://github.com/hvmi">https://github.com/hvmi</a>;</li>
  <li>The documentation is available at <a href="https://hvmi.readthedocs.io/">https://hvmi.readthedocs.io</a> - it contains both a high-level documentation and the low-level source code documentation, in Doxygen format;</li>
  <li>For any …</li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hvmi.github.io/blog/introspection/2020/07/30/introduction.html">https://hvmi.github.io/blog/introspection/2020/07/30/introduction.html</a></em></p>]]>
            </description>
            <link>https://hvmi.github.io/blog/introspection/2020/07/30/introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24006120</guid>
            <pubDate>Fri, 31 Jul 2020 06:00:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You don't need no Service Mesh]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24005953">thread link</a>) | @SerCe
<br/>
July 30, 2020 | https://serce.me/posts/23-07-2020-you-dont-need-no-service-mesh/ | <a href="https://web.archive.org/web/*/https://serce.me/posts/23-07-2020-you-dont-need-no-service-mesh/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Hi!</p>
<p>Service meshes have attracted an enormous amount of hype around them. With at least a few talks about service meshes during each tech conference, one can easily be convinced that having a service mesh in their infrastructure is a must. However, hype isn’t a good indicator of whether the new shiny tech is the right solution for your problems. So below, I’ll try to express an anti-hype opinion on service meshes to hopefully make it less confusing when you want to decide whether you may or may not need one.</p>
<p><span><img src="https://serce.me/img/servicemesh/rick.png" alt="rick"></span></p>
<div>
<blockquote>
<p>There’s a lesson here, and I’m not going to be the one to figure it out.</p>
</blockquote>
<p>
— Rick Sanchez
</p>
</div>
<div>
<h3 id="_the_invention">The invention</h3>
<p>Let’s take a step back in history and take a look at one of the <a href="https://eng.lyft.com/envoy-7-months-later-41986c2fd443">early articles</a> about introducing Envoy at Lyft.</p>
<div>
<blockquote>
<p>As it turns out, almost every company with a moderately-sized service oriented architecture is having the same problems that Lyft did prior to the development and deployment of Envoy:</p>
<div>
<ul>
<li>
<p>An architecture composed of a variety of languages, each containing a half-baked RPC library, including partial (or zero) implementations of rate limiting, circuit breaking, timeouts, retries, etc.</p>
</li>
<li>
<p>Differing or partial implementations of stats, logging, and ….</p>
</li>
</ul>
</div>
</blockquote>
</div>
<p>While Envoy is not a service mesh by itself, the outlined problems describe the exact reason why service meshes were invented. They add “rate limiting, circuit breaking, …” and other reliability, observability, and security features to the services by enforcing the communication to go through the service mesh proxies, a data plane. Additionally, they require a separate component, a control plane, to control the configuration.</p>
<p>However, at this point, a lot of people miss the context in which service meshes were introduced. Service meshes are able to solve the problem not because it’s impossible to solve them in any other way. There are many battle-proof RPC libraries that take on the challenges of a separate data plane layer, <a href="https://github.com/twitter/finagle">Finagle</a>, <a href="https://github.com/grpc">gRPC</a>, <a href="https://github.com/line/armeria">Armeria</a>, <a href="https://github.com/apple/servicetalk">Servicetalk</a>, to name a few. After all, the very first service mesh - Linkerd 1.0 <a href="https://github.com/linkerd/linkerd">is powered by Finagle</a>. The RPC libraries will need a component which provides service discovery and configuration management to make it a true mesh. For instance, Zookeeper, or Consul, a component that service meshes call a control plane.</p>
<p>Why introduce a new concept to solve the problems that have been solved before? The service mesh concept wasn’t introduced to address problems that hadn’t been addressed before but rather address them in a way that doesn’t require any modifications to the application code, which is incredibly convenient when it’s hard to introduce an RPC layer into an existing heterogeneous microservice environment.</p>
<p>When you hear service mesh, Istio with Envoy might be the first thing that comes to mind, but it wasn’t the first service mesh to enter the market. Linkerd authors who pioneered the space, described exactly this situation in the <a href="https://linkerd.io/2017/04/25/whats-a-service-mesh-and-why-do-i-need-one/#why-is-the-service-mesh-necessary">"why is the service mesh necessary"</a>. Interestingly, in many hype-y articles on the Internet this context is often forgotten, or omitted.</p>
<p>Solving a problem well, even if it’s a problem that a lot of people have, doesn’t magically provide the tech with a lot of hype. There is always a sponsor behind it. I don’t know who the sponsor was here, and I’m going to speculate, but it’s hard to sell an RPC library in the world where open source is a fundamental requirement. There is no clear business model there, that’s why most of the mature RPC libraries were open-sourced by large tech companies for which it’s not a part of the core business model. A library is just code, not a piece of infrastructure. Service meshes are a different story. It’s an isolated non-trivial piece of infrastructure. As a vendor, not only can you provide consultancy around the configuration and deployment, but you can also sell complete hosted solutions around it.</p>
</div>
<div>
<h3 id="_disillusionments">Disillusionments</h3>
<p>Now that we’ve established the problems, the solution, and most importantly, the context in which the solution was made, let’s take a look at the alternatives. The most obvious one, in the spirit of KISS, is to use an RPC library for your preferred language. Here is where the context is crucial: if you have a large fleet of services, each written in its own language/ecosystem, and the only language that they share is HTTP then having a single shared RPC library is going to be hard. Perhaps, you’ve got a fabric of deployed and running services, but everyone is afraid of touching them, no one knows how they work, and each redeploy is an adventure. A service mesh is here to help you, because at least you’ll be able to roll out new infrastructure features to the mesh regularly.</p>
<p>On the other hand, if you have a fleet of healthy services written in a single application stack, then it’s a good idea to think twice before introducing a service mesh. By simply introducing or evolving a shared RPC library, you’ll get the exact same benefits and avoid dealing with the downsides of maintaining service meshes. By studying the service mesh limitations thoroughly, you can avoid finding yourself in the trough of disillusionment.</p>
<p><span><img src="https://serce.me/img/servicemesh/curve.png" alt="Hype Cycle"></span></p>
<div>
<h4 id="_different_ecosystem">Different ecosystem</h4>
<p>The ecosystem of the service mesh of your choice will likely be different from the ecosystem of your services. Beautiful websites always make you believe that the solution is plug’n’play, always works and never goes down. In reality, sooner or later problems, bugs, quirks in behaviour will reveal themselves, as they always do. At that point, you’ll need to have engineers who work on the service-mesh’s ecosystem which when it’s different from the main app, effectively limits the set of people who can introduce changes or fix problems. This is likely to reintroduce silos, which is against the whole DevOps spirit. Yes, having a DevOps team of engineers who are doing DevOps-y things <a href="https://continuousdelivery.com/2012/10/theres-no-such-thing-as-a-devops-team/">is against DevOps</a>.</p>
</div>
<div>
<h4 id="_unnecessary_overhead">Unnecessary overhead</h4>
<p>Not only having a proxy in front of each service adds overhead (often significant, talking about <a href="https://istio.io/latest/docs/ops/deployment/performance-and-scalability/">90pt</a> rather than 99pt in the performance summary <a href="https://www.infoq.com/presentations/latency-response-time/">doesn’t make software run faster</a>) and consumes resources, but you also requires time (or rather a team of people) to manage them. Yes, it can help to make some of the tasks potentially easier - yay, you can now add canary deployments with a few lines of YAML to simple applications now. However, you still need to manage canary deployments of the proxies themselves which don’t have a proxy in front of them. The problems just get pushed up the stack.</p>
</div>
<div>
<h4 id="_limiting_your_architecture_to_what_the_proxy_supports">Limiting your architecture to what The Proxy supports.</h4>
<p>As you’re reading this paragraph, HTTP/3 is slowly being rolled out to the Internet. It uses UDP as transport. Why use UDP rather than create a completely new protocol you ask? That’s because anything but TCP and UDP is simply “blocked” by the boxes, various proxies on the internet - routers, gateways, etc. This phenomenon got named <a href="https://http3-explained.haxx.se/en/why-quic/why-ossification">ossification</a>. So, only TCP or UDP are left is the practical chose, and even UDP is partially blocked by various corporate proxies which slows down the adoption.</p>
<p>Even though your microservice environment is probably much smaller compared to the Internet, you can draw parallels with service meshes. Proxies can ossify your application architecture by limiting how your services talk to each other, and there is not much benefit in having proxies if you can bypass them. Suppose you want to build a reactive application which is using RSocket over pure tcp? Or perhaps a message-driven application using an actor model? Or maybe push the performance boundaries with Aeron? Not going to happen until the box in the middle becomes aware of the protocol.</p>
</div>
</div>
<div>
<h3 id="_do_i_need_one">Do I need one?</h3>
<p>What does it all mean for you as an engineer? The answer to whether you need to adopt the service mesh approach comes down to the state of the microservice environment you’re trying to improve. As we have established, compared to an RPC framework, service meshes allow you to:</p>
<div>
<ol>
<li>
<p>Deploy the infra changes more often than deploying your services.</p>
</li>
<li>
<p>Introduce infra changes without touching the service code.</p>
</li>
</ol>
</div>
<p>The point 1. is important when for whatever reason you can’t redeploy your services very often, e.g. maybe no one remembers how it’s done anymore, or maybe there are other restrictions. The point 2. is important when your stack is heterogeneous, e.g. some services are built in Go, some in Java, some in Haskell, etc. Where are you on the interval from a huge set of heterogeneous services with unknown deployment schedules to a set of homogenous regularly deployed services defines whether a service mesh is the best solution for you.</p>
</div>
<div>
<h3 id="_conclusion">Conclusion</h3>
<p>Service meshes have a lot of hype around them, and way too much in my opinion. However, before committing to a piece of technology, it’s crucial to understand the problems it solves, and the context in which the solution was made. A service mesh is not an ultimate “good practice” but simply one of the patterns to solve a set of issues, and it’s quite a heavy one.</p>
<p>Rather than jumping on board, look carefully - the last thing you want is to find out that you have invested in a solution for a problem that you don’t have. Service meshes are an amazing piece of tech solving a whole lot of problems. Not in every case, it is the best solution.</p>
</div>
<div>
<h3 id="_thank_you_to">Thank you to</h3>
<div>
<ul>
<li>
<p>You for reading this article.</p>
</li>
<li>
<p><a href="https://twitter.com/ptuls">Paul Tune</a> for reviewing the article.</p>
</li>
</ul>
</div>
</div>
<div>

<hr>
<blockquote><p lang="en" dir="ltr">"You don't need no Service Mesh". Just published a new blog post with an anti-hype opinion on the over-hyped topic. <a href="https://t.co/SVXS3nWKzj">https://t.co/SVXS3nWKzj</a></p>— Sergey Tselovalnikov (@SerCeMan) <a href="https://twitter.com/SerCeMan/status/1286242507664191488?ref_src=twsrc%5Etfw">July 23, 2020</a></blockquote> 
</div>

</div></div>]]>
            </description>
            <link>https://serce.me/posts/23-07-2020-you-dont-need-no-service-mesh/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24005953</guid>
            <pubDate>Fri, 31 Jul 2020 05:26:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Context should go away for Go 2 (2017)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24005733">thread link</a>) | @atombender
<br/>
July 30, 2020 | https://faiface.github.io/post/context-should-go-away-go2/ | <a href="https://web.archive.org/web/*/https://faiface.github.io/post/context-should-go-away-go2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        

<p>As usual, when a new blog post comes out on <a href="https://blog.golang.org/">blog.golang.org</a>, I’m all
eager to read it as soon as possible. The most recent one, <a href="https://blog.golang.org/contributors-summit">Contributors
Summit</a>, is a nice write-up on the issues that the Go
contributors have been talking about. While reading it, I stumbled upon a sentence that made me
write this post. Here is is:</p>

<blockquote>
<p>For instance, it would be nice if io.Reader accepted a context so that blocking read operations
could be canceled.</p>
</blockquote>

<p>This gave me chills. This is what <code>io.Reader</code> would look like with a context.</p>

<pre><code>type Reader interface {
        Read(ctx context.Context, p []byte) (n int, err error)
}
</code></pre>

<p>I did some research and found that some people already <a href="https://github.com/golang/go/issues/20280">proposed this
change</a> for Go 2. Thankfully it received a decent amount
of thumbs down, so it’s likely not making it.</p>

<p>This post is about all of the things that are wrong with the <code>"context"</code> package, why it is useful
 despite that, and that Go 2 should do something about it. So, grab some popcorn and let’s get
 started!</p>

<h2 id="go-is-a-general-purpose-language">Go is a general purpose language</h2>

<p>First things first, let’s establish some ground. Go is a <em>good</em> language for writing servers, but Go
is not a <em>language for writing servers</em>. Go is a <em>general purpose programming language</em>, just like
C, C++, Java or Python. For example, I’ve been using Go for about 2 years and I’ve never written a
single server in it.</p>

<p>For this reason, when designing the Go language and it’s standard library, we need to approach it
from a general purpose language perspective. Now, I’m not trying to say that context is only useful
for server people. But mostly, it is.</p>

<h2 id="context-is-like-a-virus">Context is like a virus</h2>

<p>This is the first and most important problem with context: it spreads! As mentioned in <a href="https://blog.golang.org/context">this blog
post about the context package</a>:</p>

<blockquote>
<p>At Google, we require that Go programmers pass a Context parameter as the first argument to every
function on the call path between incoming and outgoing requests.</p>
</blockquote>

<p>Every such function also needs to propagate the context down it’s call path, or else it wouldn’t be
fully cancelable. This means that all the potentially slow functions from other libraries that are
being called from a function accepting a context should also accept a context.</p>

<p>In short, if you’re writing a library that has function which can take some significant amount of
time and your library is <em>potentially</em> going to be used by a server application, you have to accept
a context in those functions.</p>

<p>That’s how context spreads like a virus. What’s bad about that? Let’s recap:</p>

<ol>
<li>Go is a general purpose language.</li>
<li>If a library is <em>potentially</em> going to be used by a server, it should accept a context.</li>
<li>Now, everyone has to deal with the context, even the ones who don’t need it.</li>
</ol>

<p>Of course, I can just pass <code>context.TODO()</code> everywhere, but that’s just gross, it hurts readability,
makes my code look ugly and simply removes a part of fun I have with Go.</p>

<p>If the Go language ever comes to the point where I’d have to write this</p>

<pre><code>n, err := r.Read(context.TODO(), p)
</code></pre>

<p>put a bullet in my head, please.</p>

<p>You might argue: <em>A library can provide two version of each function, one with a context and one
without a context.</em> Sure, just take a look at the
<a href="https://golang.org/pkg/database/sql/"><code>"database/sql"</code></a> package. Although it does solve the problem
partially, it smells quite bad.</p>

<p>Also, imagine teaching Go to a student. You start explaining the context-equipped <code>io.Reader</code>
interface (or anything else which occasionally requires a context) to them and they ask: <em>What is
that <code>ctx context.Context</code> thingy there?</em> And the answer would probably just be: <em>Don’t worry about
that, just pass <code>context.TODO()</code> there for now.</em> Sounds a lot like <code>public static void</code> to me.</p>

<p>The message is: Context spreads like a virus and I (alongside almost everyone who doesn’t write
servers in Go) don’t want to deal with it when I don’t have to.</p>

<h2 id="the-context-package-itself-is-not-that-good">The <code>"context"</code> package itself is not that good</h2>

<p>The first thing is a personal opinion, but for me, the <code>context.Context</code> interface has too many
methods. Now, the more serious problems.</p>

<h3 id="if-you-use-ctx-value-in-my-non-existent-company-you-re-fired">If you use <code>ctx.Value</code> in my (non-existent) company, you’re fired</h3>

<p>I’m not sure who came up with this idea that context should carry a map of meaningless objects to
meaningless objects. There are just so many things that are wrong with it. Let’s list a few:</p>

<ol>
<li>An obvious one, it’s not statically typed at all.</li>
<li>It requires documenting which values (keys and their types) a certain function supports and uses.
As we all know, documentation is mostly a code that never runs.</li>
<li>It’s very similar to thread-local storage. We know how bad of an idea thread-local storage is.
Non-flexible, complicates usage, composition, testing.</li>
<li>This probably doesn’t happen often, but it’s prone to name collisions.</li>
<li>It’s just magic. An error-prone magic.</li>
</ol>

<p>I know that <code>ctx.Value</code> makes some things easier. But, I believe that designing your APIs without
<code>ctx.Value</code> in mind at all makes it always possible to come up with alternatives.</p>

<h3 id="context-is-mostly-an-inefficient-linked-list">Context is mostly an inefficient linked list</h3>

<p>The way <code>WithCancel</code>, <code>WithDeadline</code>, etc. constructors from the <code>"context"</code> package work is they
create a linked list. Among other things, this sometimes requires creating a
<a href="https://golang.org/src/context/context.go#L261">goroutine</a> for <code>WithCancel</code>, which propagates
cancelation signals from the previous context to the new one. Of course, if the context is never
canceled, this goroutine is leaked.</p>

<p>The <code>WithValue</code> constructor takes a context and returns a context which propagates the previous
context but also contains a value under the specified key. This is, obviously, achieved by creating
another node in the linked list, the purpose of which is to return the correct value for that key
and propagate the previous context otherwise. So, <code>ctx.Value</code> is not only a map of meaningless
objects to meaningless objects, it’s also a terribly slow map of meaningless objects to meaningless
objects.</p>

<h3 id="and-lastly">And lastly</h3>

<pre><code>ctx context.Context
</code></pre>

<p>is a lot like</p>

<pre><code>Foo foo = new Foo();
</code></pre>

<p>One of the things Go was <a href="https://www.youtube.com/watch?v=rKnDgT73v8s">created to avoid</a>.</p>

<h2 id="what-does-the-context-package-actually-solve">What does the <code>"context"</code> package actually solve?</h2>

<p>Despite all of the bad things described above, the <code>"context"</code> package is genuinely useful, because
it solves one thing that is kinda hard to do in Go: <strong>cancelation</strong>. That’s the only problem the
<code>"context"</code> package really solves (or attempts to solve).</p>

<p>Let’s face it, cancelation in Go is hard. There is a whole talk called <a href="https://www.youtube.com/watch?v=QDDwwePbDtw">‘Advanced Go Concurrency
Patterns’</a>, which discusses this problem in depth. This
talk happened before the <code>"context"</code> package was introduced into the Go standard library and thus it
discusses solutions to the cancelation problem which only involve simple channels.</p>

<p>There are number of reasons why solutions proposed in the talk don’t scale very well. Here are a few
of them:</p>

<ol>
<li>The cancelation channels are usually not accepted by other libraries and functions and thus
cancelation is only possible ‘in-between’ the slow operations.</li>
<li>Considering a ‘tree of goroutines’ (where children goroutines are the ones spawned by the parent
goroutines), it’s easy to cancel the whole tree (just close the cancelation channel), but it’s
harder to cancel a sub-tree (you need to introduce another channel for that, or some other
solution).</li>
</ol>

<p>The <code>"context"</code> package does solve these problems. Inefficiently and with numerous problems, but
solves them better than anything else out there. <strong>In Go, we need to be able to solve the
cancelation problem</strong>. Solving it is usually necessary anytime a decent usage of goroutines is
involved.</p>

<h2 id="go-2-should-explicitly-address-the-cancelation-problem">Go 2 should explicitly address the cancelation problem</h2>

<p>I think it’s a weakness of the Go programming language that we needed to introduce a package like
<code>"context"</code>. Go makes it very easy to create goroutines and communicate between them. However, the
<code>"context"</code> package is a proof that Go makes it hard enough to <em>arrange goroutines to finish</em>. I
believe this problem should be solved directly in the language. The language should provide a
solution, which is:</p>

<ol>
<li>Simple and elegant.</li>
<li>Optional, non-intrusive and non-infectious.</li>
<li>Robust and efficient.</li>
<li>Only solves the cancelation problem. Values can be omitted. Timeouts can also be implemented on
top of a very simple cancelation.</li>
</ol>

<p>You might argue: <em>I like context, it’s an elegant solution to the problem without changing or
complicating the language</em>. I disagree. For all the reasons described above it’s not an elegant
solution and although it’s not an integral part of the language, it is and is becoming more and more
an integral part of the libraries. In the end, it makes the language harder to use.</p>

<p>I have a few solutions in mind, but I’ll leave them for another post or a proposal, or I’ll leave
them for myself if someone comes up with a better solution. The purpose of this post is just to
point out the problem.</p>

<h2 id="conclusion">Conclusion</h2>

<p>This post was trying to point out a problem in the Go language. In short, cancelation is a problem
in Go and the <code>"context"</code> package does not solve this problem very well. I can’t think of any other
solution that would solve this problem good except for a language change. That is up for Go 2.</p>

<p>Thanks for reading and I’m looking forward to your feedback and <del>hate comments</del> objections ;).</p>

<p>Michal Štrba</p>


        


<a href="https://disqus.com/">comments powered by </a>
      </article></div>]]>
            </description>
            <link>https://faiface.github.io/post/context-should-go-away-go2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24005733</guid>
            <pubDate>Fri, 31 Jul 2020 04:42:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Beginner’s Guide to Note-Taking (For Your Life)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24005659">thread link</a>) | @hiivan
<br/>
July 30, 2020 | https://www.ivan-ang.com/a-beginners-guide-to-note-taking-for-your-life/ | <a href="https://web.archive.org/web/*/https://www.ivan-ang.com/a-beginners-guide-to-note-taking-for-your-life/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>  <time datetime="2020-07-29T00:00:00+00:00">July 29th, 2020 in <a href="https://www.ivan-ang.com/categories/#Posts%F0%9F%93%8C">Posts📌</a> </time> <word> 1842 words, 10 min read </word> <p>Note-taking has become a huge part of my life. It has helped me retain information better, and ensures that I am constantly learning everyday.</p> <p>Twitter user <a href="https://twitter.com/visakanv">@visakanv</a> beautifully describes journaling (though also highly applicable to note-taking in general) in this twitter thread:</p> <blockquote data-conversation="none" data-theme="light"><p lang="en" dir="ltr">So in a way journaling for yourself is a radical act! It’s an act of self-ownership, self-education. It’s about setting your own curriculum, defining your own worldview, deciding for yourself what is important. I don’t think this should be outsourced to others, but that’s my POV</p>— youtube.com/visakanv (❤️ if you subscribe!) (@visakanv) <a href="https://twitter.com/visakanv/status/1087436197410959361?ref_src=twsrc%5Etfw">January 21, 2019</a></blockquote>  <h2 id="why-i-take-notes">Why I Take Notes.</h2> <p>Oftentimes, when people think of taking notes, they associate it to <em>studying for an exam</em>.</p> <p>But the fact is, we are constantly learning new things everyday. So if you are all about living life to the fullest and improving yourself as a person, then why would you not transfer this concept of note-taking to your own personal life?</p> <p>One of the best thing <em>writing</em> things down can do for you is to <strong>sharpen your thinking</strong>. Sitting down and putting the work to synthesizing your thoughts can help to produce better quality ideas. If I find myself having an abstract thought in my head that it is hard to express in words, penning them down can help to solidify and refine the idea.</p> <p>In the rest of the article, I will be going through my note-taking journey, and the various techniques &amp; concepts I use to make my note-taking more effective.</p> <h2 id="active-recall-and-spaced-repetition">Active Recall and Spaced Repetition</h2> <p>When I was a student in junior college studying for ‘A’ Levels, the content we were learning were becoming more and more complex. So I started searching up study techniques to optimize my learning.</p> <p>I came across <a href="https://youtu.be/ukLnPbIffxE">Ali Abdaal’s YouTube videos</a> on <em>Active Recall</em> and <em>Spaced Repetition</em>, and these techniques stuck with me till this day. These were legitimate, scientifically backed<sup id="fnref:1"><a href="#fn:1">1</a></sup> advice, in contrast to the plethora of “<em>Top 101 Study Tips</em>” listicles online that sounds good but doesn’t work.</p> <p>(Spoiler alert: Active Recall trumps other study techniques like rereading, highlighting and blindly writing notes, in terms of examination performance.)</p> <p> <strong>Active Recall</strong><sup id="fnref:2"><a href="#fn:2">2</a></sup>: <em>This involves retrieving information from your brain after learning something, typically through testing yourself. The act of recalling strengthens your ability to retain your information and solidifies the connections in our brain between different concepts.</em> <br><strong>Spaced Repetition</strong><sup id="fnref:3"><a href="#fn:3">3</a></sup>: <em>The act of reviewing materials at spaced intervals. This is effective in memory retention and countering the forgetting curve.</em> </p> <p>If you ever want to learn something effectively, it is key to utilize both techniques to maximize your retention rate.</p> <h2 id="second-brain">Second Brain</h2> <p>On the never-ending quest for maximum productivity, I chanced upon an <a href="https://fortelabs.co/blog/basboverview/">article by Forte Labs</a> that explained this conundrum I had in my head:</p> <blockquote> <p>How many brilliant ideas have you had and forgotten? How many insights have you failed to take action on? How much useful advice have you slowly forgotten as the years have passed?</p> <p>We feel a constant pressure to be learning, improving ourselves, and making progress. We spend countless hours every year reading, listening, and watching informational content. And yet, where has all that valuable knowledge gone? Where is it when we need it? Our brain can only store a few thoughts at any one time. Our brain is for <em>having</em> ideas, not storing them.</p> </blockquote> <blockquote> <p>Without a little extra care to preserve these valuable resources, our precious knowledge remains siloed and scattered across dozens of different locations.</p> </blockquote> <p>Mind = Blown 🤯. This perpetual problem that has always bothered my mind (but could never find the words for it) was perfectly articulated by this excerpt.</p> <p>The article then introduced a solution: <a href="https://www.buildingasecondbrain.com/">Building A Second Brain</a>. BASB is a methodology for “preserving your ideas, and turning them into reality”. The article explains it like this:</p> <blockquote> <p>We are constantly generating ideas. Yet, without a little extra care to preserve these valuable resources, our precious knowledge remains siloed and scattered across dozens of different locations.</p> <p>By offloading our thinking onto a “second brain,” we free our biological brain to imagine, create, and simply be present.</p> </blockquote> <p>Information overload is a plague of today’s society. Building a digital system where you can deposit all your thoughts and learnings there is quintessential for knowledge workers in this day and age.</p> <p>Another similar concept is the <a href="https://en.wikipedia.org/wiki/Personal_knowledge_management">Personal Knowledge System</a>. PKM involves the bottom-up approach of <em>collecting information that a person uses to gather, classify, store, search, retrieve and share knowledge in their daily activities.</em><sup id="fnref:4"><a href="#fn:4">4</a></sup></p> <h2 id="note-taking-app-roam-research">Note-Taking App: Roam Research</h2> <p><i>(This segment talks about my favourite note-taking app, Roam Research. If you wish to skip to the next segment of the article, click <a href="#how_i_take_notes">here.</a>)</i></p> <p>In search for an appropriate medium for BASB, I discovered <a href="https://roamresearch.com/">Roam Research</a>. I have been using it ever since and have never looked back.</p> <picture> <img src="https://www.ivan-ang.com/assets/roam-showcase.png" height="100%" width="100%"> <figure> <figcaption><b>Source:</b> <a href="https://roamresearch.com/">Roam Research</a>'s official site.</figcaption> </figure> </picture> <h3 id="what-makes-roam-different-from-the-other-note-taking-apps">What makes Roam different from the other note-taking apps?</h3> <p>Note-taking apps typically function <strong>hierarchically</strong>.</p> <p>You create categories, and within each categories are sub-categories and within them contain notes. The problem with this is that we face the issue of deciding where to put these notes under, since they can belong to multiple categories.</p> <p>Roam Research is a note-taking application for <strong>networked thought</strong>.</p> <p>It seeks to make note-taking function more like how a brain processes information. Whenever you have an idea, your brain will create multiple associations to it. Thinking of linked concepts will help you recall that idea.</p> <p>Likewise, Roam seeks to associate notes with other notes via <em>bi-directional linking</em>, making it easier to connect your ideas. It becomes your second brain. Your notes do not just sit there idly like other note apps. Roam encourages serendipity and <em>Spaced Repetition</em> by letting you to continuously revisit past notes.</p> <p>For those tinkerers out there, you can even create your own custom CSS and JavaScript themes! (Shameless plug: check out my theme <a href="https://github.com/hiivan/CyanoRoam">CyanoRoam</a> on Github).</p> <h3 id="pricing">Pricing</h3> <p>The bummer is that after their 31-days free trial, they start with a whopping $15/month and $7.50/month for students afterwards. If you are not willing to spend that much money on it, I recommend looking into other <a href="https://nesslabs.com/roam-research-alternatives">Roam alternatives</a> like <a href="https://obsidian.md/">Obsidian</a> and <a href="https://giffmex.org/experiments/stroll.experiment.html">TiddlyStroll</a>.</p> <p>(I was lucky enough to have been part of their beta program so my graph is free indefinitely 😁.)</p> <p>If you are interested to know more about how Roam Research works, you can also check out <a href="https://www.youtube.com/watch?v=bpikCLhpIRY">Ali Abdaal’s video on Roam</a>.</p>  <h2 id="how-i-take-notes">How I Take Notes.</h2> <p>Personal Knowledge System/Building A Second Brain or whatever you want to call it, below are the multiple facets of how I take my notes. See and pick what works for you.</p> <h3 id="quick-capture">📸Quick Capture</h3> <p>Our brains are constantly coming up with new ideas. Sometimes, this can get very distracting and take away from what we are currently focusing on.</p> <p>A way I have come up to curb this problem is that whenever I come up with a new idea or inspiration, I will immediately <strong>capture them</strong> down on Roam.</p> <p>I keep quotes, reading highlights, podcast insights and everything you can think of. I find this very liberating as it helps to take the load off my brain so I can focus what is important presently.</p> <p>Then, at the end of the day, I can go back to review whatever I have written the entire day, and decide whether I will add them to the list of stuff to work on.</p> <h3 id="bookpodcastarticle-notes">📚Book/Podcast/Article Notes</h3> <p>This is the most obvious kind of note-taking: writing notes on stuff you read.</p> <p>Whenever I read, or other content I consume online e.g. podcasts, articles, I try my best to paraphrase and summarize every book. Especially when coming across a foreign concept that I wish to learn more on, I find it best to actively engage with the material for better learning.</p> <p>Take note <em>(pun intended)</em>: When taking notes, paraphrase and try not to refer back to the material at hand. This is the essence behind <em>Active Recall</em>.</p> <h3 id="️quantifying-my-productivity">⚖️Quantifying My Productivity</h3> <p>I subscribe to the notion of the <strong>1% Rule</strong>: if you improve yourself by 1% everyday for one year, you will end up 3800% better than where you started off a year ago. I first read this from James Clear, the author of the best-selling book, <a href="https://www.goodreads.com/book/show/40121378-atomic-habits">Atomic Habits</a>.</p> <picture> <img src="https://www.ivan-ang.com/assets/marginal-gains.jpg" height="85%" width="85%"> <figure> <figcaption><b>Source:</b> <a href="https://jamesclear.com/marginal-gains">Marginal Gains</a> by James Clear. <br><i>"Habits are the compound interest of self-improvement."</i></figcaption> </figure> </picture> <p>Of course, in reality, the metric to quantify your productivity is slightly more unclear, and you might not exactly be 38x better. But the 1% Rule proves how powerful compound interest can be and how it can do wonders to your life.</p> <p>I follow a simple system of quantifying my output to track my productivity. I have a section called <span>⏳Timeline of My Life</span>. In there, I record down the notable things that I have learnt or accomplished that day, or when I have reached a certain milestone in my life.</p> <p>This is especially useful if you wish to do <strong>weekly reviews</strong> on your personal development.</p> <p>Looking at all your past notes can give you a birds-eye view of what you have accomplished the entire week. By reviewing, you are applying <em>Spaced Repetition</em> to your learning. Occasionally looking back at the mini-achievements you have done can also do wonders to your motivation and self-esteem :P.</p> <p>I am considering using a software tool like <a href="https://airtable.com/">Airtable</a> in the future to relegate this mini-project to. Maybe one day, I will reach the level of <a href="https://julian.digital/2020/02/23/my-quantified-self-setup/">julian.digital</a>.</p> <h3 id="journaling">📝Journaling</h3> <p>As mentioned in my article on journaling, I also use Roam as a tool for writing down my thoughts and reflections. You can read the article <a href="https://www.ivan-ang.com/journaling-as-a-tool-for-self-help/">here</a>, where I talk more about how I use it to manage my emotional and mental health.</p> <h2 id="conclusion">Conclusion</h2> <p>So this is a brief overview of the theories behind how I do my note-taking. I hope you have gained some insights after reading this post, and perhaps even incorporate some of these concepts into your own life.</p> <picture> <img src="https://www.ivan-ang.com/assets/my-roam-graph.png" height="95%" width="95%"> <figure> <figcaption><b>My Roam Graph:</b> An overview of how all my notes are …</figcaption></figure></picture></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ivan-ang.com/a-beginners-guide-to-note-taking-for-your-life/">https://www.ivan-ang.com/a-beginners-guide-to-note-taking-for-your-life/</a></em></p>]]>
            </description>
            <link>https://www.ivan-ang.com/a-beginners-guide-to-note-taking-for-your-life/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24005659</guid>
            <pubDate>Fri, 31 Jul 2020 04:28:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A Free Gatsby.js/Tailwind Theme for Business Websites]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24005615">thread link</a>) | @taphangum
<br/>
July 30, 2020 | https://planflow.dev/free-themes | <a href="https://web.archive.org/web/*/https://planflow.dev/free-themes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://planflow.dev/free-themes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24005615</guid>
            <pubDate>Fri, 31 Jul 2020 04:21:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zero-Cost References with Regions in Vale]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24005370">thread link</a>) | @verdagon
<br/>
July 30, 2020 | https://vale.dev/blog/zero-cost-refs-regions | <a href="https://web.archive.org/web/*/https://vale.dev/blog/zero-cost-refs-regions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://vale.dev/blog/zero-cost-refs-regions</link>
            <guid isPermaLink="false">hacker-news-small-sites-24005370</guid>
            <pubDate>Fri, 31 Jul 2020 03:31:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Learning's Most Important Ideas – A Brief Historical Review]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24004790">thread link</a>) | @jonbaer
<br/>
July 30, 2020 | https://dennybritz.com/blog/deep-learning-most-important-ideas/ | <a href="https://web.archive.org/web/*/https://dennybritz.com/blog/deep-learning-most-important-ideas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The goal of this post is to review well-adopted ideas that have stood the test of time. I will present a small set of techniques that cover a lot of basic knowledge necessary to understand modern Deep Learning research. If you're new to the field, these are a great starting point.</p><div id="post-content"><p>Deep Learning is an extremely fast-moving field and the huge number of research papers and ideas can be overwhelming. Even seasoned researchers have a hard time telling company PR from real breakthroughs. The goal of this post is to review those ideas that have <strong>stood the test of time</strong>, which is perhaps the only significance test one should rely on. These ideas, or improvements of them, have been used over and over again. They're known to work.</p> <p>If you were to start in Deep Learning today, understanding and implementing each of these techniques would give you an excellent foundation for understanding recent research and working on your own projects. It's what I believe the best way to get started. Working through papers in historical order is also a useful exercise to understand where the current techniques come from and why they were invented in the first place. <strong><strong>Put another way, I will try to present a <em>minimal set</em> of ideas that most of the basic knowledge necessary to understand modern Deep Learning research.</strong></strong></p> <p>A rather unique thing about Deep Learning is that its application domains (Vision, Natural Language, Speech, RL, etc) share the majority of techniques. For example, someone who has worked in Deep Learning for Computer Vision his whole career could quickly be productive in NLP research. The specific network architectures may differ, but the concepts, approaches and code are mostly the same. I will try to present ideas from various fields, but there are a few caveats about this list:</p> <ul> <li>My goal is not to give in-depth explanations or code examples for these techniques. It's not easily possible to summarize long complex papers into a single paragraph. Instead, I will give a brief overview of each technique, its historical context, and links to papers and implementations. If you want to learn something, I <em>highly recommend</em> trying to re-produce some of these paper results from scratch in raw <a href="https://pytorch.org/">PyTorch</a> without using existing code bases or high-level libraries.</li> <li>The list is biased towards my own knowledge and the fields I am familiar with. There are many exciting subfields that I don't have experience with. I will stick to what most people would consider the popular mainstream domains of Vision, Natural Language, Speech, and Reinforcement Learning / Games.</li> <li>I will only discuss research that has official or semi-official open source implementations that are known to work well. Some research isn't easily reproducible because it involves huge engineering challenges, for example <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">DeepMind's AlphaGo</a> or <a href="https://openai.com/projects/five/">OpenAI's Dota 2 AI</a>, so I won't highlight it here.</li> <li>Some choices are arbitrary. Often, rather similar techniques are published at around the same time. The goal of this post is not be a comprehensive review, but to to expose someone new to the field to a cross-section of ideas that cover a lot of ground. For example, there may be hundreds of GAN variations, but to understand the general concept of GANs, it really doesn't matter which one you study.</li> </ul>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">ImageNet Classification with Deep Convolutional Neural Networks (2012)</a> <span data-cites="krizhevsky_imagenet_2012">Krizhevsky, Sutskever, and Hinton (2012)</span></li> <li><a href="https://arxiv.org/abs/1207.0580">Improving neural networks by preventing co-adaptation of feature detectors (2012)</a> <span data-cites="hinton_improving_2012">Hinton et al. (2012)</span></li> <li><a href="https://arxiv.org/abs/1404.5997">One weird trick for parallelizing convolutional neural networks (2014)</a> <span data-cites="krizhevsky_one_2014">Krizhevsky (2014)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://pytorch.org/hub/pytorch_vision_alexnet">AlexNet in PyTorch</a></li> <li><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/alexnet.py">AlexNet in TensorFlow</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/alexnet-full.png" alt=""><figcaption>Source: <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks</a></figcaption> </figure> <p>AlexNet is often considered the algorithm responsible for the recent boom in Deep Learning and Artificial Intelligence research. It is a Deep Convolutional Neural Network based on the earlier LeNet developed by Yann LeCun. AlexNet beat previous methods at classifying images from the <a href="http://image-net.org/index">ImageNet dataset</a> by a significant margin through a combination of GPU power and algorithmic advances. It demonstrated that neural networks actually work! AlexNet was also one of the first times Dropout <span data-cites="hinton_improving_2012">Hinton et al. (2012)</span> was used, which has since become a crucial component for improving the generalization ability of all kinds of Deep Learning models.</p> <p>The architecture used by AlexNet, a sequence of Convolutional layers, ReLU nonlinearity, and max-pooling, became the accepted standard that future Computer Vision architectures would extend and built upon. These days, software libraries such as PyTorch are so powerful, and compared to more recent architectures AlexNet is so simple, that it can be implemented in only a few lines of code. Note that many implementations of AlexNet, such as those linked above, use the slight variation of the network described in <a href="https://arxiv.org/abs/1404.5997">One weird trick for parallelizing convolutional neural networks</a> <span data-cites="krizhevsky_one_2014">Krizhevsky (2014)</span>.</p>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://arxiv.org/abs/1312.5602">Playing Atari with Deep Reinforcement Learning (2013)</a> <span data-cites="mnih_playing_2013">Mnih et al. (2013)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html">DQN in PyTorch</a></li> <li><a href="https://www.tensorflow.org/agents/tutorials/1_dqn_tutorial">DQN in TensorFlow</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/deep-q-learning-value.png" alt=""><figcaption>Source: <a href="https://deepmind.com/research/publications/human-level-control-through-deep-reinforcement-learning">https://deepmind.com/research/publications/human-level-control-through-deep-reinforcement-learning</a></figcaption> </figure> <p>Building on top of the recent breakthroughs in image recognition and GPUs, a team at DeepMind managed to train a network to <a href="https://www.youtube.com/watch?v=V1eYniJ0Rnk">play Atari Games</a> from raw pixel inputs. What's more, the <em>same</em> neural network architecture learned to play seven different games without being told any game-specific rules, demonstrating the generality of the approach.</p> <p>Reinforcement Learning differs from Supervised Learning, such as image classification, in that an agent must learn maximize to the sum of rewards over multiple time steps, such as winning a game, instead of just predicting a label. Because the agent interacts directly with the environment and each action affects the next, the training data is not independent and identically distributed (iid), which makes the training of many Machine Learning models quite unstable. This was solved by using techniques such as experience replay <span data-cites="lin_self-improving_1992">Lin (1992)</span>.</p> <p>While there was no obvious algorithmic innovation that made this work, the research cleverly combined existing techniques, convolutional neural networks trained on GPUs and experience replay, with a few data processing tricks to achieve impressive results that most people would not have expected. This gave people confidence in extending Deep Reinforcement Learning techniques to tackle even more complex tasks such as <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">Go</a>, <a href="https://openai.com/projects/five/">Dota 2</a>, <a href="https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii">Starcraft 2</a>, and others.</p> <p>Atari Games <span data-cites="bellemare_arcade_2013">Bellemare et al. (2013)</span> have since become a standard benchmark in Reinforcement Learning research. The initial approach only solved (beat human baselines on) seven games, but over the coming years advances built on top of these ideas would start beating humans on an ever increasing number of games. One particular game, Montezuma’s Revenge, was famous for requiring long-term planning and was considered to be among the most difficult to solve. It was only recently <span data-cites="badia_agent57_2020">Badia et al. (2020)</span> <span data-cites="ecoffet_first_2020">Ecoffet et al. (2020)</span> that techniques managed to beat human baselines on all 57 games.</p>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://arxiv.org/abs/1409.3215">Sequence to Sequence Learning with Neural Networks</a> <span data-cites="sutskever_sequence_2014">Sutskever, Vinyals, and Le (2014)</span></li> <li><a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a> <span data-cites="bahdanau_neural_2016">Bahdanau, Cho, and Bengio (2016)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#">Seq2Seq with Attention in PyTorch</a></li> <li><a href="https://www.tensorflow.org/addons/tutorials/networks_seq2seq_nmt">Seq2Seq with Attention in TensorFlow</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/seq2seq-cn.gif" alt=""><figcaption>Source: <a href="https://ai.googleblog.com/2017/04/introducing-tf-seq2seq-open-source.html">https://ai.googleblog.com/2017/04/introducing-tf-seq2seq-open-source.html</a></figcaption> </figure> <p>Deep Learning's most impressive results had largely been on vision-related tasks and was driven by Convolutional Neural Networks. While the NLP community had success with <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">Language Modeling</a> and Translation using LSTM networks <span data-cites="hochreiter_long_1997">Hochreiter and Schmidhuber (1997)</span> and Encoder-Decoder architectures <span data-cites="sutskever_sequence_2014">Sutskever, Vinyals, and Le (2014)</span>, it was not until the invention of the <strong>attention</strong> mechanism <span data-cites="bahdanau_neural_2016">Bahdanau, Cho, and Bengio (2016)</span> that things started to work spectacularly well.</p> <p>When processing language, each token, which could be a character, a word, or something in between, is fed into a recurrent network, such as an LSTM, which maintains a kind of memory of previously processed inputs. In other words, a sentence is very similar to a time series with each token being a time step. These recurrent models often had difficulty dealing with dependencies over long time horizons. When they process a sequence, they would easily "forget" earlier inputs because their gradients needed to propagate through many time steps. Optimizing these models with gradient descent was hard.</p> <p>The new attention mechanism helped alleviate the problem. It gave the network an option to adaptively "look back" at earlier time steps by introducing shortcut connections. These connections allowed the network to decide which inputs are important when producing a specific output. The canonical example is translation: When producing an output word, it typically maps to one or more specific input words.</p>  <p><strong><strong>Papers</strong></strong></p> <ul> <li><a href="https://arxiv.org/abs/1412.6980">Adam: A Method for Stochastic Optimization</a> <span data-cites="kingma_adam_2017">Kingma and Ba (2017)</span></li> </ul> <p><strong><strong>Implementations</strong></strong></p> <ul> <li><a href="https://d2l.ai/chapter_optimization/adam.html">Implementing Adam in Python</a></li> <li><a href="https://pytorch.org/docs/master/_modules/torch/optim/adam.html">PyTorch Adam implementation</a></li> <li><a href="https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/optimizer_v2/adam.py#L32-L281">TensorFlow Adam implementation</a></li> </ul> <figure> <img src="https://dennybritz.com/assets/deep-learning-most-important-ideas/optimizer-benchmark.png" alt=""><figcaption>Source: <a href="http://arxiv.org/abs/1910.11758">http://arxiv.org/abs/1910.11758</a></figcaption> </figure> <p>Neural networks are trained by minimizing a loss function, such as the average classification error, using an optimizer. The optimizer is responsible for figuring out how to adjust the parameters of the network to make it learn the objective. Most optimizers are <a href="https://ruder.io/optimizing-gradient-descent/">based on variations of Stochastic Gradient Descent (SGD)</a>. However, many of these optimizers contain tunable parameters such as a learning rate themselves. Finding the right settings for a specific problem not only reduces training time, but can also lead to better results due to finding a better local minimum of the loss function.</p> <p>Big resarch labs often ran expensive hyperparameter searches that came up with complex learning rate schedules to get the best out of simple but hyperparameter-sensitive optimizers such as SGD. When they …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dennybritz.com/blog/deep-learning-most-important-ideas/">https://dennybritz.com/blog/deep-learning-most-important-ideas/</a></em></p>]]>
            </description>
            <link>https://dennybritz.com/blog/deep-learning-most-important-ideas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24004790</guid>
            <pubDate>Fri, 31 Jul 2020 01:39:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse Engineering the PLA Chip in the Commodore 128]]>
            </title>
            <description>
<![CDATA[
Score 167 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24004640">thread link</a>) | @segfaultbuserr
<br/>
July 30, 2020 | https://c128.se/posts/silicon-adventures/ | <a href="https://web.archive.org/web/*/https://c128.se/posts/silicon-adventures/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <h2 id="backstory-and-first-attempts">Backstory and first attempts</h2>
<p>As I mentioned in my last post I’ve been working on reverse engineering the PLA chip in the C128.
I’m now mostly done with this process so I think it’s time to share some of the findings.</p>
<p>This has been a very interesting project as I did not really know much about semiconductor design
and manufacturing. My existing knowledge extended to having seen some die shots and admiring the pretty
looking pictures.</p>
<p>It all started with me buying a cheap microscope to help with soldering surface mount components.</p>

<p><a href="https://c128.se/posts/silicon-adventures/cheapo-microscope.jpg" data-mediabox="gallery" data-title="Cheap microscope">
    <img src="https://c128.se/posts/silicon-adventures/cheapo-microscope.jpg" alt="Cheap microscope">
</a>
</p>
<p>Some time later I ended up watching a video on youtube showing a simpler way of getting silicon dies out
of the packaging.</p>


<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/ZQeHHYJYWXo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>This looked simple enough to try at home as I already had all the equipment needed. Decapping an IC usually involves heated sulphuric acid or
other similar nasty chemicals which I do not really want to play with at home. So I dug out a couple of broken MOS chips I had lying around
(never throw things away, could come in handy). After fiddling around a bit I ended up with two 8521R0 dies and one 8721 PLA.
The first real photo was the one show in the last post.</p>

<p><a href="https://c128.se/posts/now-available/pla-die.png" data-mediabox="gallery" data-title="Full 8721 PLA die photo">
    <img src="https://c128.se/posts/now-available/pla-die.png" alt="Full 8721 PLA die photo">
</a>
</p>
<h2 id="better-microscope">Better microscope</h2>
<p>While this was a success I quickly realised that this microscope did not have enough resolution for me to be able to capture images of high
enough quality. The maximum magnification is 90x, when using a 2x barlow lens. Additionally it does not have a stage so I had to place the die
on a table and then move the whole microscope, which is very unstable and makes it hard to capture the bits you want to see.</p>
<p>As such a better microscope was sourced and purchased, still within reasonable money.</p>

<p><a href="https://c128.se/posts/silicon-adventures/amscope-me580t.jpg" data-mediabox="gallery" data-title="AmScope ME580-T microscope">
    <img src="https://c128.se/posts/silicon-adventures/amscope-me580t.jpg" alt="AmScope ME580-T microscope">
</a>
</p>
<p>This proved to be much better at taking pictures of decent quality, I was however not happy with the camera I bought with it. It’s a cheap camera with no capability for me to manage it remotely except using the AmScope application. Around this time, the Raspberry Pi foundation
released the new High Quality camera for the Raspberry Pi. This camera has a C-mount on it which matches the microscope so I quickly bought
one and put in on the microscope. This camera is fantastic for this job, full control of the whole process from the comfort of linux.</p>

<p><a href="https://c128.se/posts/silicon-adventures/8521r0-detail.jpg" data-mediabox="gallery" data-title="Silicon die detail from 8521R0">
    <img src="https://c128.se/posts/silicon-adventures/8521r0-detail.jpg" alt="Silicon die detail from 8521R0">
</a>
</p>
<p>All in all a vast improvement to the previous setup. With the higher resolution I started needing to stitch the photos together to make
larger pictures. This sounded simple at the start and ended up being (as you can probably guess) not very easy at all. I’m still struggling
with the stitching, but slowly improving. One of the key things for a successful panorama stitch is to have consistent photos when it comes
to panning, focus, white balance etc. etc. The more even the photos, the easier and better the stitching becomes.</p>
<h2 id="motorizing">Motorizing</h2>
<p>This led me to start working on motorizing the table. It was getting really tiresome having to manually move the table around and the photos
ended up being moved in multiple axis etc.</p>
<p>Lots of design work, 3D printing and research into CNC firmwares later I ended up with the following setup:</p>

<p><a href="https://c128.se/posts/silicon-adventures/modded-me580t.jpg" data-mediabox="gallery" data-title="Modified AmScope ME580-T microscope">
    <img src="https://c128.se/posts/silicon-adventures/modded-me580t.jpg" alt="Modified AmScope ME580-T microscope">
</a>
</p>
<p>Going from the top we have a Raspberry 7” display, with a Raspberry Pi4 mounted on the back. Not see is also the RPi HiQ camera mounted on
the microscope. The RPi takes photos, displays previews on the display and also runs the python code that controls the CNC board.</p>
<p>The stage and the levelling table is motorized with 28BYJ-48 steppers controlled using a small board with an ESP32 running <a href="https://github.com/bdring/Grbl_Esp32">Grbl_Esp32</a> and four AD4498 stepper motor controllers.</p>
<p>This whole setup has some issues both in software and hardware but it works well enough for now to enable me to do some work.</p>

<p>With the logistics now sorted out I returned to the work of reverse engineering the chip itself. My initial focus was on the PLA chip
as this should be one of the simpler ones to figure out. PLA stands for <a href="https://en.wikipedia.org/wiki/Programmable_logic_array">Programmable Logic Array</a> and is a very common structure in designs from this era.</p>
<p>Looking at the schematic diagram from wikipedia we should expect to see two main arrays, AND and OR. Inputs are connected to AND and
outputs from the OR array.</p>
<p>Going back to the previous die shot with can improve it with some annotations for the pins and the general areas of the chip. Once we
have established the pins we can see that all the inputs are connected to one array and all the outputs to the other array, just as
expected. This also helps us establish which array is which.</p>

<p><a href="https://c128.se/posts/silicon-adventures/pla-annotated.png" data-mediabox="gallery" data-title="Annotated die shot of 8721 PLA">
    <img src="https://c128.se/posts/silicon-adventures/pla-annotated.png" alt="Annotated die shot of 8721 PLA">
</a>
</p>
<p>Here we see the I/O pins marked up with how they are connected to the lead frame and the pins on the DIP itself. We can also see the two main
areas that make up a PLA structure, the AND array and the OR array. Additionally there is some extra logic at the bottom marked with a question
mark. The function of this was unknown to me but as all the output pins are passing through it I was guessing that it was an output stage of
some kind.</p>
<h2 id="and-array">AND array</h2>
<p>So, if we take a closer look at the AND matrix to start with we will see the following. The colours are a bit off as this was still done
using the AmScope camera and I didn’t figure out how to set the white balance on it.</p>

<p><a href="https://c128.se/posts/silicon-adventures/and-matrix-metal.jpg" data-mediabox="gallery" data-title="AND matrix with metal layer">
    <img src="https://c128.se/posts/silicon-adventures/and-matrix-metal.jpg" alt="AND matrix with metal layer">
</a>
</p>
<p>This was not very helpful to understand what was going on as all the interesting bits are covered up by the top-most metal layer. This was
early on when I was still learning a lot so to remove the metal I took a very brute force approach. I use heavy mechanical scrubbing to
remove the metal which I also learned once I put it back in the microscope had removed everything but the substrate itself. Oops.</p>
<p>Fortunately, the details that I needed were in the diffusion embedded into the substrate:</p>

<p><a href="https://c128.se/posts/silicon-adventures/and-matrix-delayer.jpg" data-mediabox="gallery" data-title="AND matrix substrate">
    <img src="https://c128.se/posts/silicon-adventures/and-matrix-delayer.jpg" alt="AND matrix substrate">
</a>
</p>
<p>Looking closely at this image we can see little squiggly lines where a transistor is located to create a connection within the matrix.</p>
<h2 id="or-array">OR array</h2>
<p>Moving on to the OR array we see the exact same pattern. Hard to tell with the metal layer in place, though easier compared to the AND
matrix. Much easier with just the substrate and diffusion left.</p>


<h2 id="full-matrix-decode">Full matrix decode</h2>
<p>Armed with this knowledge we can now proceed with extracting the full PLA logic matrix from the images.</p>
<p>I marked all transistors in each matrix with a dot and got the following picture:</p>

<p><a href="https://c128.se/posts/silicon-adventures/decoded-matrix.jpg" data-mediabox="gallery" data-title="AND matrix with metal layer">
    <img src="https://c128.se/posts/silicon-adventures/decoded-matrix.jpg" alt="AND matrix with metal layer">
</a>
</p>
<p>All inputs are horizontal in the AND matrix, with each line having a normal and an inverted signal being fed in.
All outputs are horizontal in the OR matrix and they are connected with vertical lines called product terms.</p>
<p>By looking at the dots, we can decode the product terms by doing logic and for all vertical lines in the AND matrix, for example</p>
<pre><code>    p0 = CHAREN &amp; HIRAM &amp; BA &amp; !MS3 &amp; GAME &amp; RW &amp; AEC &amp; A12 &amp; !A13 &amp; A14 &amp; A15
</code></pre><p>For the outputs we instead look horizontal for each output and combine with or, for example</p>
<pre><code>    SDEN = p42 | p43 | p66 | p69
</code></pre><p>So now we have the entire set of logic equations. Hooray!</p>
<h2 id="output-stage">Output stage</h2>
<p>Going back to the full die picture, we now have everything but the box marked with a question mark in the output path.</p>
<p>Looking at higher resolution photos of this we can see similar structures for each output. In all cases except two the structure
is bypassed and the output from the OR matrix goes directly to the output pin. This is however not the case for the two pins <code>DWE</code> and <code>CASENB</code>.</p>
<p><code>DWE</code> is the Write Enable signal going to the main system DRAM chips, CASENB is gating the CAS signal towards the RAM. These two signals are
processed in some form using these output gate structures, so I had to reverse engineer this block.</p>


<p>After quite some time reading up on silicon chip design and manufacturing and a lot of attempts I managed to come up with a schematic
for this that makes sense. I’m not going to go into the whole process here but I will document and post it later. Here I would also like
to thank <a href="https://www.patreon.com/androSID">Frank Wolf</a> for his help, please support his project if you can!</p>

<p><a href="https://c128.se/posts/silicon-adventures/output-schematic.png" data-mediabox="gallery" data-title="Output block schematic">
    <img src="https://c128.se/posts/silicon-adventures/output-schematic.png" alt="Output block schematic">
</a>
</p>
<p>Going a bit further, the way this is used in the <code>DWE</code> and <code>CASENB</code> outputs makes it a normal D-latch. The latch enable for this also comes
for the PLA matrix in a pair of lines in the OR matrix.</p>
<h2 id="result">Result</h2>
<p>So as a final result we can now write down the full HDL code for the C128 PLA chip. I’m using verilog for this. Mind you this is the first
verilog I’ve ever written so it’s probably suboptimal. Using a D-latch for the output in verilog is normally seen as a bad thing, however
in this case I am doing it to replicate the logic and function of the existing chip.</p>
<p>I have validated this to the best of my knowledge, but if I’ve missed anything please let me know!</p>
<p>In difference to the C64 PLA the C128 PLA can not be replaced with just an EPROM or similar due to the presence of the output latches.</p>
<div><pre><code data-lang="verilog"><span>module</span> pla_8721(
    <span>input</span> rom_256,
    <span>input</span> va14,
    <span>input</span> charen,
    <span>input</span> hiram,
    <span>input</span> loram,
    <span>input</span> ba,
    <span>input</span> vma5,
    <span>input</span> vma4,
    <span>input</span> ms0,
    <span>input</span> ms1,
    <span>input</span> ms2,
    <span>input</span> ms3,
    <span>input</span> z80io,
    <span>input</span> z80en,
    <span>input</span> exrom,
    <span>input</span> game,
    <span>input</span> rw,
    <span>input</span> aec,
    <span>input</span> dmaack,
    <span>input</span> vicfix,
    <span>input</span> a10,
    <span>input</span> a11,
    <span>input</span> a12,
    <span>input</span> a13,
    <span>input</span> a14,
    <span>input</span> a15,
    <span>input</span> clk,

    <span>output</span> sden,
    <span>output</span> roml,
    <span>output</span> romh,
    <span>output</span> clrbnk,
    <span>output</span> from,
    <span>output</span> rom4,
    <span>output</span> rom3,
    <span>output</span> rom2,
    <span>output</span> rom1,
    <span>output</span> iocs,
    <span>output</span> dir,
    <span>output</span> <span>reg</span> dwe,
    <span>output</span> <span>reg</span> casenb,
    <span>output</span> vic,
    <span>output</span> ioacc,
    <span>output</span> gwe,
    <span>output</span> colram,
    <span>output</span> charom);

<span>wire</span> p0;
<span>wire</span> p1;
<span>wire</span> p2;
<span>wire</span> p3;
<span>wire</span> p4;
<span>wire</span> p5;
<span>wire</span> p6;
<span>wire</span> p7;
<span>wire</span> p8;
<span>wire</span> p9;
<span>wire</span> p10;
<span>wire</span> p11;
<span>wire</span> p12;
<span>wire</span> p13;
<span>wire</span> p14;
<span>wire</span> p15;
<span>wire</span> p16;
<span>wire</span> p17;
<span>wire</span> p18;
<span>wire</span> p19;
<span>wire</span> p20;
<span>wire</span> p21;
<span>wire</span> p22;
<span>wire</span> p23;
<span>wire</span> p24;
<span>wire</span> p25;
<span>wire</span> p26;
<span>wire</span> p27;
<span>wire</span> p28;
<span>wire</span> p29;
<span>wire</span> p30;
<span>wire</span> p31;
<span>wire</span> p32;
<span>wire</span> p33;
<span>wire</span> p34;
<span>wire</span> p35;
<span>wire</span> p36;
<span>wire</span> p37;
<span>wire</span> p38;
<span>wire</span> p39;
<span>wire</span> p40;
<span>wire</span> p41;
<span>wire</span> p42;
<span>wire</span> p43;
<span>wire</span> p44;
<span>wire</span> p45;
<span>wire</span> p46;
<span>wire</span> p47;
<span>wire</span> p48;
<span>wire</span> p49;
<span>wire</span> p50;
<span>wire</span> p51;
<span>wire</span> p52;
<span>wire</span> p53;
<span>wire</span> p54;
<span>wire</span> p55;
<span>wire</span> p56;
<span>wire</span> p57;
<span>wire</span> p58;
<span>wire</span> p59;
<span>wire</span> p60;
<span>wire</span> p61;
<span>wire</span> p62;
<span>wire</span> p63;</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://c128.se/posts/silicon-adventures/">https://c128.se/posts/silicon-adventures/</a></em></p>]]>
            </description>
            <link>https://c128.se/posts/silicon-adventures/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24004640</guid>
            <pubDate>Fri, 31 Jul 2020 01:11:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple’s bulls**t narrative on the App Store]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24004538">thread link</a>) | @invig
<br/>
July 30, 2020 | https://scrambleuphill.com/2020/07/31/apples-bullst-narrative-on-the-app-store/ | <a href="https://web.archive.org/web/*/https://scrambleuphill.com/2020/07/31/apples-bullst-narrative-on-the-app-store/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-77">
			<!-- .entry-header -->		<!-- .entry-meta -->
	
	<div>
		
<figure><blockquote><p>“The only apps that are subject to a commission are those where the developer acquires a customer on an Apple device and where the features or services would be experienced and consumed on an Apple device,” Cook states. </p><p>Cook references <a href="https://www.zdnet.com/article/apple-releases-study-to-justify-app-store-business-model/">a study it commissioned and released last week</a> that compared Apple App Store’s commissions with cuts taken by Google Play Store, Amazon App Store, Samsung Galaxy Store, and Microsoft Store, as well as marketplaces from Airbnb, Uber, and Epic Games.  </p><p>The study concluded that Apple’s guidelines for in-app purchases are necessary to prevent users and developers from ‘free-riding’ on the App Store and that all digital marketplaces “routinely forbid behaviors aimed at avoiding fees”. </p><cite><a rel="noreferrer noopener" href="https://www.zdnet.com/article/tim-cook-defends-app-store-if-apple-is-a-gatekeeper-we-just-opened-the-gate-wider/" target="_blank">ZDNet</a>  – July 29 2020</cite></blockquote></figure>



<p>Apple makes the argument that developers should have to pay for the running of the App Store, but it’s not the largest developers using by  far the most App Store resources who are paying.</p>



<p>Apps by Facebook surely account for some huge percentage of all downloads on the entire App Store. Facebook pays just $99 per year for this service.</p>



<p>Google – $99 per year. Amazon – $99 per year + a special deal for video that no one else gets.  Netflix – $99 per year.</p>



<p>Funny how small developers have to pay 30/15%, and have no way to work around it, but there’s exceptions everywhere for other monopolies and mega-corporations.</p>



<p>“The only apps that are subject to a commission are those where the developer acquires a customer on an Apple device and where the features or services would be experienced and consumed on an Apple device” says Tim Cook. </p>



<p>Tim, how is it possible given todays rules for a small developer to write an app where the developer could prove that they did not “acquire the customer on an Apple device” but instead acquired them via advertising the developer had to pay for (e.g. ads on Google, or via their own website) and therefor should not pay 30%? I’d like to see the steps on how to do that.</p>



<p><em>Note to non-technical audience members: Apple is not providing some kind of amazing technical service here. If you build and distribute an app via the App Store that sells a t-shirt instead of a digital photo you don’t have to use Apple payments and you don’t pay 30%. They have just drawn a line in the sand where they want it to be.</em></p>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	
</article></div>]]>
            </description>
            <link>https://scrambleuphill.com/2020/07/31/apples-bullst-narrative-on-the-app-store/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24004538</guid>
            <pubDate>Fri, 31 Jul 2020 00:53:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Today's B2B startups turned their users into paying customers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24004496">thread link</a>) | @abouelatta
<br/>
July 30, 2020 | https://www.lennyrachitsky.com/p/how-todays-fastest-growing-b2b-startups | <a href="https://web.archive.org/web/*/https://www.lennyrachitsky.com/p/how-todays-fastest-growing-b2b-startups">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>Part two in our series on B2B growth strategy</h3></div><div><p><em>Hello and welcome to a<strong>&nbsp;🔒 subscriber-only edition 🔒&nbsp;</strong>of my weekly newsletter. I’m&nbsp;<a href="https://www.lennyrachitsky.com/subscribe">Lenny</a>, and each week I humbly tackle reader questions about product, growth, working with humans, and anything else that’s stressing you out at the office.&nbsp;<a href="https://www.lennyrachitsky.com/subscribe">Send me your questions</a>&nbsp;and in return, I’ll offer actionable real-talk advice<strong>.</strong></em></p><p>If you find this newsletter valuable, co…</p></div></div>]]>
            </description>
            <link>https://www.lennyrachitsky.com/p/how-todays-fastest-growing-b2b-startups</link>
            <guid isPermaLink="false">hacker-news-small-sites-24004496</guid>
            <pubDate>Fri, 31 Jul 2020 00:46:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Convert Numeric Words into Numbers Using Python]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24004404">thread link</a>) | @aogl
<br/>
July 30, 2020 | https://ao.gl/how-to-convert-numeric-words-into-numbers-using-python/ | <a href="https://web.archive.org/web/*/https://ao.gl/how-to-convert-numeric-words-into-numbers-using-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<h2>Challenge</h2>
<p>Using Python, we want to convert words to numbers. In this challenge, we will explore how to convert a string into an integer.</p>
<p>The strings simply represent the numbers in words.</p>
<h3>Examples:</h3>
<ul><li>“one” =&gt; 1</li><li>“twenty” =&gt; 20</li><li>“two hundred forty-six” =&gt; 246</li><li>“seven hundred eighty-three thousand nine hundred and nineteen” =&gt; 783919</li></ul>
<h3>Additional Notes:</h3>
<ul><li>The minimum number is “zero” (inclusively)</li><li>The maximum number, which must be supported is 1 million (inclusively)</li><li>The “and” in e.g. “one hundred and twenty-four” is optional, in some cases it’s present and in others, it’s not</li><li>All tested numbers are valid, you don’t need to validate them</li></ul>
<h2>Test cases</h2>
<pre title="">Test.assert_equals(parse_int('one'), 1)
Test.assert_equals(parse_int('twenty'), 20)
Test.assert_equals(parse_int('two hundred forty-six'), 246)
</pre>
<h2>The solution in Python</h2>
<pre title="">def parse_int(textnum, numwords={}):
    # create our default word-lists
    if not numwords:

      # singles
      units = [
        "zero", "one", "two", "three", "four", "five", "six", "seven", "eight",
        "nine", "ten", "eleven", "twelve", "thirteen", "fourteen", "fifteen",
        "sixteen", "seventeen", "eighteen", "nineteen",
      ]

      # tens
      tens = ["", "", "twenty", "thirty", "forty", "fifty", "sixty", "seventy", "eighty", "ninety"]

      # larger scales
      scales = ["hundred", "thousand", "million", "billion", "trillion"]

      # divisors
      numwords["and"] = (1, 0)

      # perform our loops and start the swap
      for idx, word in enumerate(units):    numwords[word] = (1, idx)
      for idx, word in enumerate(tens):     numwords[word] = (1, idx * 10)
      for idx, word in enumerate(scales):   numwords[word] = (10 ** (idx * 3 or 2), 0)

    # primary loop
    current = result = 0
    # loop while splitting to break into individual words
    for word in textnum.replace("-"," ").split():
        # if problem then fail-safe
        if word not in numwords:
          raise Exception("Illegal word: " + word)

        # use the index by the multiplier
        scale, increment = numwords[word]
        current = current * scale + increment
        
        # if larger than 100 then push for a round 2
        if scale &gt; 100:
            result += current
            current = 0

    # return the result plus the current
    return result + current
</pre>



</div></div>]]>
            </description>
            <link>https://ao.gl/how-to-convert-numeric-words-into-numbers-using-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24004404</guid>
            <pubDate>Fri, 31 Jul 2020 00:31:31 GMT</pubDate>
        </item>
    </channel>
</rss>
