<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 05 Jul 2020 08:16:35 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 05 Jul 2020 08:16:35 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Type-Safe Single Page Apps: Is F# Ready for Prime Time?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23722496">thread link</a>) | @asp_net
<br/>
July 3, 2020 | https://thomasbandt.com/type-safe-spa-fable-fsharp-vs-typescript | <a href="https://web.archive.org/web/*/https://thomasbandt.com/type-safe-spa-fable-fsharp-vs-typescript">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
    
    <p>While there are many UI libraries available today to build modern web apps, the number of programming languages that compile to JavaScript has also increased in recent years. Here is a quick take on F# and TypeScript.</p>
    
    <h2>Preface</h2>
<p>Although I did focus on mobile apps in the last years, I've spent the first decade or so of my career concatenating strings, also known as web development. So I think I might know a thing or two about how things work there.</p>
<p>However, as I watched the latest hype cycles in the JavaScript universe from the sidelines, I do not have many preferences when choosing "the right" technology stack. Except for one thing. I know for sure that I do not want to build serious software with JavaScript again, except when it acts as a compilation target for a more capable programming language.</p>
<p>So I did take a look at a couple of potential candidates: <a href="https://elm-lang.org/">Elm</a>, <a href="https://reasonml.org/">Reason</a>, <a href="https://www.typescriptlang.org/">TypeScript</a>, and <a href="https://fsharp.org/">F#</a>.</p>
<h2>Shortlist</h2>
<p>While I respect Elm and Reason, the overall experience seemed very close to web development with F#. Which can also be used for server-side tasks (even code-sharing between client and server is possible). So out of those four, F# and TypeScript are the most serious candidates for me. Sorry Elm. Sorry Reason.</p>
<h3>F#</h3>
<p>Since finally <a href="https://thomasbandt.com/who-cares-about-functional-programming">crossing the chasm</a> in 2017, I am a big fan of the language. As a long-time C# developer, it brought back the joy in programming to me. Making a case for using it in production at a larger scale project would intrigue me.</p>
<p>Interestingly, F# today is considered a language targeting two platforms: .NET and JavaScript. That is made possible through <a href="https://fable.io/">Fable</a>, "a compiler powered by Babel designed to make F# a first-class citizen of the JavaScript ecosystem" √¢‚Ç¨‚Äú which sounds promising, doesn't it.</p>
<h3>TypeScript</h3>
<p>When Microsoft announced <a href="https://www.typescriptlang.org/">TypeScript</a> back in 2012, tooling was poor and excitement limited. It needed a significant player in the JavaScript world, Angular, to pick it up, to gain momentum. Today it is so widely used that I consider it the de facto standard for modern web development.</p>
<p>Its success is driven by a powerful type system plus the fact that it is similar enough to JavaScript to keep the learning curve relatively flat. Besides support for immutable data structures, I do not miss much of what I would expect from a modern programming language.</p>
<h2>A Small Case Study</h2>
<p>Now, how to make an informed decision that is not solely based on gut feelings? Good question. I decided to <a href="https://github.com/aspnetde/typesafe-spa">conduct a small case study</a>, which I designed to explore three different options to build a type-safe single page application:</p>
<ol>
<li><a href="https://github.com/aspnetde/typesafe-spa#elmish--feliz">F# + Elmish + Feliz</a></li>
<li><a href="https://github.com/aspnetde/typesafe-spa#react-function-components--feliz">F# + React Function Components + Feliz</a></li>
<li><a href="https://github.com/aspnetde/typesafe-spa#react-function-components--feliz">TypeScript + React</a></li>
</ol>
<p>In particular, I wanted to find answers to the following questions:</p>
<ol>
<li>How are parent-child relationships handled?</li>
<li>How much boilerplate code needs to be written?</li>
<li>How much guidance and support provides the compiler?</li>
<li>How maintainable, aka scalable, does the approach appear to be?</li>
</ol>
<p>The answers to those questions have already been covered in a <a href="https://thomasbandt.com/scaling-model-view-update">separate post</a>. Summary: Going with React components, either with F# or TypeScript, will make you write less code. Whereas choosing MVU (with F# + Elmish) may provide more safeguards through an architecture that is easy to understand and harder to produce errors in.</p>
<p>The bottom line is: Technically, all three approaches are valid, each of them has different strengths and weaknesses. So I cannot recommend one over the other. But I can introduce some more things to consider when making that choice.</p>
<h2>More Things To Consider</h2>
<h3>Language Qualities</h3>
<p>Code written in F# for me more often than not is concise, easy to write, and even more comfortable to read, containing only very few noisy elements. I sometimes sit in front of my computer and just look at F# code, enjoying its beauty. Seriously, that's probably what sets it apart from most other languages I've had the chance to work with. And it brings literally back the joy in programming to me. That's a factor that cannot be stressed enough, in my opinion. I firmly believe that many bored or almost burned out, but very seasoned developers could quickly be sold on it and "flipped."</p>
<p>Whereas TypeScript certainly has different qualities. I like how it integrates with the JavaScript world, offering its type system's help where wanted. But allowing at the same time developers to keep writing their code in the JS style they are used to. It seems to walk the line perfectly fine between the strengths of a statically-typed language and some flexibility and freedom, e.g., through supporting duck-typing. So while I personally am not a big fan of curly braces and semicolons anymore, TypeScript surely provides an enjoyable developer experience as well.</p>
<h3>Vendor Support</h3>
<p>TypeScript receives a lot of attention, not only from Microsoft but industry-wide. I don't see a sign that its development might slow down in the foreseeable future.</p>
<p>Similarily, F# has always been supported by Microsoft since its inception, and a (small) team is actively working on it. So there is no reason to worry about the future of the language itself.</p>
<p>However, while TypeScript is the whole package of compiler plus language, F#'s web story is a bit different. It relies on Fable as the F# to JavaScript compiler. And Fable is a complex operation which, right now, depends on only a few people's willingness to continue to work on it in their spare time (also see "bus factor" below).</p>
<h3>Tooling</h3>
<p>The tooling support for TypeScript is just great. For example, it integrates well in Visual Studio Code and is supported by many other editors and IDEs. Several of them are commercially supported.</p>
<p>The same is actually true for F#. Visual Studio (on Windows and macOS), <a href="https://www.jetbrains.com/rider/">Jetbrains Rider</a> (on Windows, macOS, and Linux) and <a href="https://ionide.io/">Ionide</a> (on all three platforms as well) support it.</p>
<h3>Ecosystem</h3>
<p>For TypeScript, a large amount of JavaScript packages are supported by the community. At the time of writing, there are 6,892 packages supported alone through the <a href="https://github.com/DefinitelyTyped/DefinitelyTyped">DefinitelyTyped</a> project.</p>
<p>Whereas the situation for Fable and F# is not that bright at the moment. There is support for a few essential players, e.g., React and Electron. But if you want to use a small random library, you most likely have to create (and maintain!) those bindings by yourself. Which is not a really complicated task √¢‚Ç¨‚Äú but one that steals time, which could otherwise be spent working on your own project. And if some of the maintainers of the existing bindings lose interest in them, there is a big chance you will inherit them sooner or later (again, see bus factor).</p>
<h3>Bus Factor</h3>
<p>The sheer number of stakeholders makes TypeScript a safe bet for most things, e.g., tooling or library support. It's not only backed and actively developed by Microsoft, but also used by major web frameworks like Angular (Google) and Vue, or at least officially supported (React, Facebook). But it's not only the impressive number of large players. The community also consists of a large number of individual contributors.</p>
<p>Fable, on the other hand, has a small but active community of contributors and a few companies that are backing it (e.g., through <a href="https://safe-stack.github.io/">SAFE Stack</a>). However, the key drivers of the whole ecosystem are only a dozen or so people who move the entire platform forward in their spare time.</p>
<p>I personally see the chance of reaching the tipping point where the ecosystem might be able to grow faster √¢‚Ç¨‚Äú but that's totally subjective and possibly more wishful thinking than reality.</p>
<h3>The Pit Of Success</h3>
<p>As <a href="https://blog.codinghorror.com/falling-into-the-pit-of-success/">described by Jeff Atwood</a>:</p>
<blockquote>
<p>The Pit of Success: in stark contrast to a summit, a peak, or a journey across a desert to find victory through many trials and surprises, we want our customers to simply fall into winning practices by using our platform and frameworks. To the extent that we make it easy to get into trouble we fail.</p>
</blockquote>
<p>While TypeScript is a tool that integrates smoothly in the JS ecosystem, F# and Fable run on top of it. When using Elmish, JS is the eventual compilation target, and React is the execution layer on which the actual F# application is running without many external dependencies. Given this and the high robustness of the F# compiler plus the reliable guidance by the MVU architecture, it makes Fable and F# a poster child of the idea of the pit of success.</p>
<p>Whereas with TypeScript, every component might look different, depending on its author's taste and level of experience.</p>
<h3>Talent Pool</h3>
<p>There is no doubt that TypeScript is one of the <a href="https://insights.stackoverflow.com/survey/2020#most-loved-dreaded-and-wanted">most loved programming languages</a> on earth at the time of writing. So it should not be complicated to find TypeScript developers or train any developer on using it.</p>
<p>While not at all being that popular, I think the story for F# might be more rewarding. There is a large pool of .NET developers who mainly use C# today. A language that adopted and continues to borrow more and more features from F# and that is getting more and more bloated on the way. As already mentioned: I believe that many talented and seasoned C# developers can be trained to use F#. This will make programming more enjoyable to them again and allow you to leverage their experience on the .NET platform.</p>
<h2>Conclusion</h2>
<p>As you can see, there are valid arguments for both TypeScript and F#. While I can and will not pick a winner at this point, I hope some information in this post can help you to make an informed decision yourself. I am sure it will be the right one! ;-)</p>

    
</article>




        </div></div>]]>
            </description>
            <link>https://thomasbandt.com/type-safe-spa-fable-fsharp-vs-typescript</link>
            <guid isPermaLink="false">hacker-news-small-sites-23722496</guid>
            <pubDate>Fri, 03 Jul 2020 09:33:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DuckDuckGo's privacy abuses ‚Äì current, historic, and by proxy]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 14 (<a href="https://news.ycombinator.com/item?id=23722063">thread link</a>) | @mercer
<br/>
July 3, 2020 | https://dev.lemmy.ml/post/31321 | <a href="https://web.archive.org/web/*/https://dev.lemmy.ml/post/31321">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dev.lemmy.ml/post/31321</link>
            <guid isPermaLink="false">hacker-news-small-sites-23722063</guid>
            <pubDate>Fri, 03 Jul 2020 08:11:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automating UX design process using Pixelic]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23721524">thread link</a>) | @_chrischae
<br/>
July 2, 2020 | https://blog.pixelic.io/automating-ux-design-process/ | <a href="https://web.archive.org/web/*/https://blog.pixelic.io/automating-ux-design-process/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.pixelic.io/content/images/size/w300/2020/07/ux_design_process.png 300w,
                            https://blog.pixelic.io/content/images/size/w600/2020/07/ux_design_process.png 600w,
                            https://blog.pixelic.io/content/images/size/w1000/2020/07/ux_design_process.png 1000w,
                            https://blog.pixelic.io/content/images/size/w2000/2020/07/ux_design_process.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.pixelic.io/content/images/size/w2000/2020/07/ux_design_process.png" alt="Automating UX design process using Pixelic">
            </figure>

            <section>
                <div>
                    <p>A few weeks ago, our team adopted a tool called <a href="https://www.pixelic.io/">Pixelic</a>, a UX collaboration tool that integrates with Figma and Slack to make design feedback, task management, and documentation more accessible.</p><figure><img src="https://blog.pixelic.io/content/images/2020/07/Screenshot-2020-07-01-14.57.58.png" alt="" srcset="https://blog.pixelic.io/content/images/size/w600/2020/07/Screenshot-2020-07-01-14.57.58.png 600w, https://blog.pixelic.io/content/images/size/w1000/2020/07/Screenshot-2020-07-01-14.57.58.png 1000w, https://blog.pixelic.io/content/images/size/w1600/2020/07/Screenshot-2020-07-01-14.57.58.png 1600w, https://blog.pixelic.io/content/images/size/w2400/2020/07/Screenshot-2020-07-01-14.57.58.png 2400w" sizes="(min-width: 1200px) 1200px"><figcaption>Pixelic's Figma frames screen.</figcaption></figure><p>I observed our team go through multiple design iterations using the tool and thought it‚Äôd be helpful for other designers and teams to get a perspective on how Pixelic makes the UX design process much easier.</p><p>Here are three topics that I‚Äôll be sharing:</p><ol><li>When do you use Pixelic? A use case for teams</li><li>Tracking history and product backlog through Pixelic</li><li>Creating a shared understanding via Pixelic and its efficacy</li></ol><h2 id="when-do-you-use-pixelic">When do you use Pixelic?</h2><figure><img src="https://blog.pixelic.io/content/images/2020/06/106546009_877858009376814_471483989897433073_n.png" alt="" srcset="https://blog.pixelic.io/content/images/size/w600/2020/06/106546009_877858009376814_471483989897433073_n.png 600w, https://blog.pixelic.io/content/images/size/w1000/2020/06/106546009_877858009376814_471483989897433073_n.png 1000w, https://blog.pixelic.io/content/images/2020/06/106546009_877858009376814_471483989897433073_n.png 1566w" sizes="(min-width: 720px) 720px"><figcaption>This process chart describes our team‚Äôs current UX design process from ideation to retrospectives.</figcaption></figure><p>Rows colored in yellow (from rough sketch, discussion/UX policies, to design QA) were design phases where Pixelic made our collaboration easier.</p><h2 id="improvement-points">Improvement Points</h2><p>Pixelic launched its first open beta in May 2020, so there were areas for improvement and a few features still in development.</p><p>We needed a wiki-like feature where we could take notes, store UX specifications, and share them with product and engineering teams. Notion and Zeplin were our go-to-tools for this during the ‚ÄúUnderstanding‚Äù phase in our design process.</p><p>It was pretty difficult to switch from Notion/Zeplin right away, but we hope to see more improvements in Pixelic‚Äôs documentation features.</p><h2 id="where-pixelic-came-in-handy-for-our-team">Where Pixelic came in handy for our team</h2><p>We realized that Pixelic could be a source of truth for the communication log as it integrates with Figma and Slack. This came in handy during our Design QA phase.</p><p>Before Pixelic, we had to manually create QA documents in Notion and share it with our engineering and product partners. We would copy and paste several links, upload screenshots, write thorough descriptions on the acceptance criteria.</p><figure><img src="https://blog.pixelic.io/content/images/2020/06/Screen-Shot-2020-06-30-at-17.09.35.png" alt="" srcset="https://blog.pixelic.io/content/images/size/w600/2020/06/Screen-Shot-2020-06-30-at-17.09.35.png 600w, https://blog.pixelic.io/content/images/size/w1000/2020/06/Screen-Shot-2020-06-30-at-17.09.35.png 1000w, https://blog.pixelic.io/content/images/size/w1600/2020/06/Screen-Shot-2020-06-30-at-17.09.35.png 1600w, https://blog.pixelic.io/content/images/2020/06/Screen-Shot-2020-06-30-at-17.09.35.png 1942w" sizes="(min-width: 720px) 720px"><figcaption>Sample Notion screen. There was so much to fill out in Notion to make our design QA work.</figcaption></figure><p>With Pixelic, we‚Äôre now able to just import Figma frames into the tool and write acceptance criteria using Pixelic‚Äôs annotation feature. There‚Äôs no need for us to take screenshots, copy/paste Zeplin links, and communicate with our engineering partners to create QA tasks. Pixelic did them all automatically.</p><h3 id="1-tracking-design-task-backlog-history">1) Tracking design task backlog history</h3><p>Not having an optimal product development and design process often made our workflow less productive. It looked something like this:</p><ol><li>Designer ‚ÄúA‚Äù and Developer ‚ÄúB‚Äù review design and exchange feedback in Slack</li><li>They then add the outcome (often design tasks) of the meeting to a Jira project Kanban board under the backlog</li><li>Product manager ‚ÄúC‚Äù notices the new task, but doesn‚Äôt have any context as to why it was created. So ‚ÄúC‚Äù requests designers ‚ÄúA‚Äù &amp; ‚ÄúB‚Äù to explain.</li><li>Teammates ‚ÄúA‚Äù &amp; ‚ÄúB‚Äù stop what they were doing, and loop C in so ‚ÄúC‚Äù could understand the context</li></ol><p>If only we had a place where the product manager (‚ÄúC‚Äù) can read/understand the context behind a task or decision without asking the designers ‚ÄúA‚Äù and ‚ÄúB,‚Äù they would have kept their focus on doing more important tasks. We became less productive as a team due to redundant meetings and discussion. (Meetings are seldom productive!)</p><p>We found that Pixelic was a perfect tool for this pain point. Here are a few ways Pixelic helped us:</p><h3 id="2-pixelic-automates-task-creation-process">2) Pixelic automates task creation process</h3><p>It‚Äôs pretty difficult to keeping track of action items during design reviews. Someone has to take charge of translating discussions into actionable tasks and adding them to a project board while others continue discussing.</p><p>But with Pixelic, all you need to do is click the ‚Äútaskify‚Äù button on each comment. Even during meetings, you can convert comments into tasks while viewing the design, so there‚Äôs no ‚Äúcontext-switching cost‚Äù incurred. Pixelic lets you convert comments into tasks without diverging from the discussion.</p><figure><img src="https://blog.pixelic.io/content/images/2020/06/taskify.png" alt="" srcset="https://blog.pixelic.io/content/images/size/w600/2020/06/taskify.png 600w, https://blog.pixelic.io/content/images/size/w1000/2020/06/taskify.png 1000w, https://blog.pixelic.io/content/images/size/w1600/2020/06/taskify.png 1600w, https://blog.pixelic.io/content/images/size/w2400/2020/06/taskify.png 2400w" sizes="(min-width: 1200px) 1200px"><figcaption>"Taskify" button on each comment on Pixelic converts respective comments into tasks</figcaption></figure><p>Traditionally, teams switch between communication apps (e.g., Slack) and task management apps (e.g., Jira, Notion, etc.) to go back and forth, discussing and adding tasks. Pixelic converges them together so that you can instantly flip the switch to ‚Äútaskify‚Äù a comment.</p><figure><img src="https://blog.pixelic.io/content/images/2020/06/1_q8SiG2je4mdAT3AOo5qeCA--1-.png" alt="" srcset="https://blog.pixelic.io/content/images/size/w600/2020/06/1_q8SiG2je4mdAT3AOo5qeCA--1-.png 600w, https://blog.pixelic.io/content/images/size/w1000/2020/06/1_q8SiG2je4mdAT3AOo5qeCA--1-.png 1000w, https://blog.pixelic.io/content/images/2020/06/1_q8SiG2je4mdAT3AOo5qeCA--1-.png 1400w" sizes="(min-width: 1200px) 1200px"><figcaption>Switching back and forth Slack and Notion to manage feedback and tasks at the same time is cumbersome.</figcaption></figure><p>Pixelic also has built-in version control for each Figma frame. With this feature, you can track all comments by each version.</p><figure><img src="https://blog.pixelic.io/content/images/2020/07/Screen-Shot-2020-07-01-at-14.33.16.png" alt="" srcset="https://blog.pixelic.io/content/images/size/w600/2020/07/Screen-Shot-2020-07-01-at-14.33.16.png 600w, https://blog.pixelic.io/content/images/size/w1000/2020/07/Screen-Shot-2020-07-01-at-14.33.16.png 1000w, https://blog.pixelic.io/content/images/size/w1600/2020/07/Screen-Shot-2020-07-01-at-14.33.16.png 1600w, https://blog.pixelic.io/content/images/size/w2400/2020/07/Screen-Shot-2020-07-01-at-14.33.16.png 2400w" sizes="(min-width: 720px) 720px"></figure><h3 id="3-pixelic-tasks-connect-with-figma-frames-and-their-comments-2-ways-">3) Pixelic tasks connect with Figma frames and their comments ‚Äú2-ways‚Äù</h3><p>Pixelic‚Äôs unique task management feature allows designers to access Figma frames directly from the tasks. This is different from what you see in Notion or Jira, Pixelic‚Äôs Figma integration imports actual Figma frames into the tool for you.</p><figure><img src="https://blog.pixelic.io/content/images/2020/07/task-comments.png" alt="" srcset="https://blog.pixelic.io/content/images/size/w600/2020/07/task-comments.png 600w, https://blog.pixelic.io/content/images/size/w1000/2020/07/task-comments.png 1000w, https://blog.pixelic.io/content/images/size/w1600/2020/07/task-comments.png 1600w, https://blog.pixelic.io/content/images/size/w2400/2020/07/task-comments.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Figma frame comments are always connected with tasks bi-directionally.</figcaption></figure><p>This has two key benefits: (1) anyone can understand the context behind the task without asking others, and (2) view relevant Figma frames, or user flows without logging into Figma.</p><p>Engineers and product managers can access relevant UIs connected to each task and quickly understand the task.</p><p>Adding links, screenshots, and descriptions to each task on Jira or Asana is cumbersome if you have to do them every time. In Pixelic, since Figma frames are connected to each task, there‚Äôs no need to copy/paste links or screenshots.</p><blockquote>‚ÄúWhat if we allow our users to sign up directly from the <strong>home screen</strong>?‚Äù</blockquote><p>Let‚Äôs say your colleague suggested above during a product meeting. How many of your team would think of the same screen? Was it the landing page? Sign up page? Main application page?</p><p>Without a shared understanding of the product, it‚Äôs challenging to communicate, and often people would have to elaborate with more details.</p><p>It‚Äôs too hard for people to see the forest through the trees, so to speak. Without the interface, people will think of different representations of the product. It‚Äôs just not an effective way to collaborate.</p><blockquote>‚ÄúThis wasn‚Äôt what I thought of.‚Äù<br>‚Äì said every stakeholder üôÑ</blockquote><p>Driving shared understanding is crucial to make your workflow productive. Too often, teams revert back to ideation because they failed to align on the same page.</p><p>From my experience working at various startups as a product designer, what worked was communicating visually.</p><p>Visual communication saves not only the presenter‚Äôs time but also the audience because they can see what you‚Äôre seeing. Experts say a human brain processes images 60,000 times faster than texts.</p><h3 id="pixelic-is-the-ultimate-visual-communication-software">Pixelic is the ultimate visual communication software</h3><figure><img src="https://blog.pixelic.io/content/images/2020/07/1_byhPFhrNBgI_cTJWJq1bMw.png" alt="" srcset="https://blog.pixelic.io/content/images/size/w600/2020/07/1_byhPFhrNBgI_cTJWJq1bMw.png 600w, https://blog.pixelic.io/content/images/size/w1000/2020/07/1_byhPFhrNBgI_cTJWJq1bMw.png 1000w, https://blog.pixelic.io/content/images/2020/07/1_byhPFhrNBgI_cTJWJq1bMw.png 1400w" sizes="(min-width: 1200px) 1200px"><figcaption>I took a screenshot of our team discussion on Pixelic (in Korean).</figcaption></figure><p>In offline meetings, you can point out where you are talking about with your fingertips, but in remote settings, it‚Äôs not that simple. And remote collaboration via video conferencing now became the norm since COVID-19.</p><p>Pixelic helped us see the visuals (interface) as well as comments next to them while video conferencing. In Pixelic, you can click &amp; drag specific areas of the image and comment on them. This helped us to store everything so we could always go back to them later.</p><h2 id="in-conclusion">In Conclusion</h2><p>Yes, adding a tool to your already tool stack isn‚Äôt the most exciting thing for your team. But if the new tool replaces or complements your current stack to enhance team productivity, it‚Äôs a no brainer to adopt it.</p><p>Pixelic was a no brainer for us. Through Pixelic, we were able to enhance our team productivity. It helped us build a clear, shared understanding of our product across the team. And managing design projects were super easy and convenient thanks to its seamless integration with Figma.</p><p>There are some features that Pixelic still needs to add to replace our entire design collaboration tool stack, but ever since we started using Pixelic, its founders moved fast to add new fixes and updates every week.</p><p>The founders have been super supportive of any questions or requests we had. We‚Äôre excited to partner with the Pixelic team to build an optimal tool for software teams.</p><hr><p><em>Jieun is a product designer based in Seoul, South Korea. She worked as a product designer in companies including</em> <a href="https://www.mathflat.com/"><em>Mathflat</em></a> <em>and</em> <a href="https://wable.io/"><em>Wable</em></a><em>. She‚Äôs an avid writer! Check out her posts on</em> <a href="https://medium.com/@ohjieun8018"><em>Medium</em></a><em>. You can also reach out to Jieun via her email address: ohjieun8018@gmail.com.</em></p><p><a href="https://www.pixelic.io/"><em>Pixelic</em></a> <em>is a UX-first collaboration platform for designers and product teams. It works with Figma frames, and designers can create tasks, feedback loops, and UX specs using the imported Figma frames.</em></p>
                </div>
            </section>

                <section>
    <h3>Subscribe to Pixelic Blog</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>
          


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.pixelic.io/automating-ux-design-process/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23721524</guid>
            <pubDate>Fri, 03 Jul 2020 06:23:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HTTPS Requests to Any URL Using the ESP8266]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23721470">thread link</a>) | @sohkamyung
<br/>
July 2, 2020 | https://maakbaas.com/esp8266-iot-framework/logs/https-requests/ | <a href="https://web.archive.org/web/*/https://maakbaas.com/esp8266-iot-framework/logs/https-requests/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Fetching or posting data to the internet is one of the core tasks of an IoT device. Doing so over HTTP is implemented quite well in the default ESP8266 Arduino libraries, but for HTTPS requests things are more difficult. In this post I will discuss the most common approaches used by the community, and develop my own method to do arbitrary HTTPS requests in a secure way. This method will not require any specific certificates or fingerprints to be manually coded in the application.</p><p>HTTPS if a method to do a HTTP request over a TLS (formerly SSL) connection. By doing so, the data that is sent back and forth between your computer and the server is encrypted and protected. The good news is that this protocol can be used with the ESP8266 with the <span>WiFiClientSecure</span> class. The bad news is that the common methods to do so have some big disadvantages.</p><p>First I will show the two most common approaches, and next I will describe a generic solution to their problems.</p><h3>A word about certificates</h3><p>Before diving into the details I will briefly explain the basic principles of secure HTTPS requests in layman's terms.</p><p>Basically, every website has a certificate. This certificate is issued by somebody, who is called a certification authority (CA). Each CA certificate can be issued by another CA which leads to the so called certificate chain. In the picture the chain is 3 certificates long, but in reality the length of the chain can be anything.</p><p>A certificate chain. Image from Wikipedia</p><p>The top level certificate is called a root certificate. This certificate is self-signed, which means that it can be trusted inherently. This is because only a few organisations can issue root certificates, and these are trusted to not offer fake or wrong certificates.</p><p>When you do a HTTPS request to a website from your browser, the browser will look at the certificate for the website, and validating if the certificate is indeed issued by its parent. This can be done because each certificate is signed with the private key of the upstream certificate. An explanation for dummies on public and private keys work can be found <a href="https://medium.com/@vrypan/explaining-public-key-cryptography-to-non-geeks-f0994b3c2d5" target="_blank" rel="noopener noreferrer">here<!-- --> <span><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line></svg></span></a>.</p><p>When it is verified that the certificate is indeed issued by a trusted root CA issuer, it is verified that the domain in the certicate is the same as the actual domain. If that is true, we know that the server is who it claims to be, and a secure connection can be started . </p><p>These trusted root certificates are actually stored as part of your browser to be able to validate all other certificates. Each OS or browser stores a slightly different set of roughly 100-200 root certificates, which it knows can be trusted. This is called a certificate store, and this is exactly what I will apply on the ESP8266 later in this article. But first, let's start with the two most popular other approaches.</p><h3>Fingerprints - secure but annoying</h3><p>The method that is proposed in the official ESP8266 Arduino <a href="https://arduino-esp8266.readthedocs.io/en/latest/esp8266wifi/client-secure-examples.html" target="_blank" rel="noopener noreferrer">documentation<!-- --> <span><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line></svg></span></a> is to extract the fingerprint of a site's certificate and store this in the code. The fingerprint is a hash of the certificate. Because it is very unlikely that a second certificate exists with the same hash, we know the website can be trusted if the hash is the same as the one we store.</p><pre><code>const char<span>*</span> host <span>=</span> <span>"https://api.github.com"</span><span>;</span>
const char<span>*</span> fingerpr <span>=</span> <span>"CF 05 98 89 CA FF 8E D8 5E 5C E0 C2 E4 F7 E6 C3 C7 50 DD 5C"</span><span>;</span>
            
WiFiClientSecure client<span>;</span>
client<span>.</span><span>connect</span><span>(</span>host<span>,</span> httpsPort<span>)</span><span>;</span>

<span>if</span> <span>(</span>client<span>.</span><span>verify</span><span>(</span>fingerpr<span>,</span> host<span>)</span><span>)</span> 
<span>{</span>  
    http<span>.</span><span>begin</span><span>(</span>client<span>,</span> host<span>)</span><span>;</span>

    <span>String</span> payload<span>;</span>
    <span>if</span> <span>(</span>http<span>.</span><span>GET</span><span>(</span><span>)</span> <span>==</span> HTTP_CODE_OK<span>)</span>    
        payload <span>=</span> http<span>.</span><span>getString</span><span>(</span><span>)</span><span>;</span>    
<span>}</span>
<span>else</span> 
<span>{</span>
  <span>Serial</span><span>.</span><span>println</span><span>(</span><span>"certificate doesn't match"</span><span>)</span><span>;</span>
<span>}</span></code></pre><p>This approach is simple because the certificate chain does not need to be validated, but has two main issues for me:</p><ol><li>The fingerprint needs to be extracted and stored manually for each page the ESP8266 needs to connect to.</li><li>An even bigger issue is that these fingerprints change roughly once a year when the certificate expires. This means that your program can break at any time and you manually need to update the fingerprint in your code.</li></ol><h3>client.setInsecure() - easy but unsafe</h3><p>You could argue that secure connections are overkill for your application. I would be the first to admit that I prefer a pragmatic solution where possible. Imagine that all you want to do with your ESP8266 is to fetch the weather from the internet and display it in some form. Personally I would not mind to do this in an insecure way, since there are no real dangers.</p><p>But imagine the ESP8266 is controlling the lock on your door or a 3D printer which can heat up and catch on fire. Or think of the case where you are transfering personal information to or from some site or API. In these cases it is better to be safe than sorry, and the method in this section should not be used. Nevertheless, I will show it here:</p><pre><code>const char<span>*</span> host <span>=</span> <span>"https://api.github.com"</span><span>;</span>
            
WiFiClientSecure client<span>;</span>
client<span>.</span><span>setInsecure</span><span>(</span><span>)</span><span>;</span> <span>//the magic line, use with caution</span>
client<span>.</span><span>connect</span><span>(</span>host<span>,</span> httpsPort<span>)</span><span>;</span>
  
http<span>.</span><span>begin</span><span>(</span>client<span>,</span> host<span>)</span><span>;</span>

<span>String</span> payload<span>;</span>
<span>if</span> <span>(</span>http<span>.</span><span>GET</span><span>(</span><span>)</span> <span>==</span> HTTP_CODE_OK<span>)</span>    
    payload <span>=</span> http<span>.</span><span>getString</span><span>(</span><span>)</span><span>;</span>    
</code></pre><p>So basically all you need to do is to add <span>client.setInsecure()</span> to your code and it will start the connection without validating the certificate. </p><h3>HTTPS requests with the IoT framework</h3><p>With that out of the way, we finally get to the implementation I have chosen instead for my ESP8266 IoT Framework, which is placed in the <span>fetch</span> class.</p><pre><code>const char<span>*</span> host <span>=</span> <span>"https://api.github.com"</span><span>;</span>            

<span>String</span> payload<span>;</span>
<span>if</span> <span>(</span>fetch<span>.</span><span>GET</span><span>(</span>host<span>)</span> <span>==</span> HTTP_CODE_OK<span>)</span>    
    payload <span>=</span> http<span>.</span><span>getString</span><span>(</span><span>)</span><span>;</span>    

fetch<span>.</span><span>clean</span><span>(</span><span>)</span><span>;</span>
</code></pre><p>Looks easy enough doesn't it ? So what happens behind the scenes? </p><p>Basically the same thing as in a typical Browser. The ESP8266 contains a full store of all the trusted root certificates in <abbr title="PROGMEM is part of the flash memory where read-only variables can be stored to reduce RAM usage.">PROGMEM</abbr> memory. This takes roughly ~170 kB of flash memory at the moment, which in my case can easily be missed. This certificate store is generated automatically on building the sofware, no manual steps required. This also means that you can do secure HTTPS requests to any URL (so you could even configure or change a URL after the build).</p><p>You might think, but hey! These certificates will expire too. And this is true. The only difference with the fingerprints is that the validity of root certificates is much longer, and can be over 20 years. Whereas the fingerprint for some services can change every few months.</p><p>As a starting point I found a great but hidden example in the ESP8266 Arduino <a href="https://github.com/esp8266/Arduino/tree/master/libraries/ESP8266WiFi/examples/BearSSL_CertStore" target="_blank" rel="noopener noreferrer">repo<!-- --> <span><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line></svg></span></a>. This example contains a Python script that gets all the certificates from the Mozilla root certificate store and stores them as files. These files will then be uploaded to the <abbr title="SPIFFS is an abbreviation for 'Serial Peripheral Interface Flash File System', which is a way to store files on embedded systems.">SPIFFS</abbr> and used during HTTPS requests. I adapted this example to be able to store the certificates in <abbr title="PROGMEM is part of the flash memory where read-only variables can be stored to reduce RAM usage.">PROGMEM</abbr> instead.</p><h3>Generating a certificate store</h3><p>When a request is started, the <span>certStore</span> class will compare the hash of the certificate issuer with all the hashes of the stored root certificates. If there is a match, the correctness of the domain and other properties will be checked and the connection will be initialized.</p><p>In the default Arduino example these hashes for the stored certificates are generated in the <span>certStore</span> class. It seems more logical to me to do this directly in the Python script to save computing time on the ESP8266, so thats where I moved it. Furthermore I adapted the <span>certStore</span> class (<a href="https://github.com/maakbaas/esp8266-iot-framework/blob/master/src/certStore.cpp" target="_blank" rel="noopener noreferrer">GitHub<!-- --> <span><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line></svg></span></a>) to read the information from my <abbr title="PROGMEM is part of the flash memory where read-only variables can be stored to reduce RAM usage.">PROGMEM</abbr> variables rather than the file system. </p><p>The final Python script to generate the certificate store is shown below.</p><pre><code><span>from</span> __future__ <span>import</span> print_function
<span>import</span> csv
<span>import</span> os
<span>import</span> sys
<span>from</span> asn1crypto<span>.</span>x509 <span>import</span> Certificate
<span>import</span> hashlib

<span>from</span> subprocess <span>import</span> Popen<span>,</span> PIPE<span>,</span> call<span>,</span> check_output
<span>try</span><span>:</span>
    <span>from</span> urllib<span>.</span>request <span>import</span> urlopen
<span>except</span><span>:</span>
    <span>from</span> urllib2 <span>import</span> urlopen
<span>try</span><span>:</span>
    <span>from</span> StringIO <span>import</span> StringIO
<span>except</span><span>:</span>
    <span>from</span> io <span>import</span> StringIO

<span>#path to openssl</span>
openssl <span>=</span> <span>"C:\msys32\usr\bin\openssl"</span> 

f <span>=</span> <span>open</span><span>(</span><span>"src/generated/certificates.h"</span><span>,</span> <span>"w"</span><span>,</span> encoding<span>=</span><span>"utf8"</span><span>)</span>

f<span>.</span>write<span>(</span><span>"#ifndef CERT_H"</span> <span>+</span> <span>"\n"</span><span>)</span>
f<span>.</span>write<span>(</span><span>"#define CERT_H"</span> <span>+</span> <span>"\n\n"</span><span>)</span>
f<span>.</span>write<span>(</span><span>"#include &lt;Arduino.h&gt;"</span> <span>+</span> <span>"\n\n"</span><span>)</span>

<span># Mozilla's URL for the CSV file with included PEM certs</span>
mozurl <span>=</span> <span>"https://ccadb-public.secure.force.com/"</span>
mozurl <span>+=</span> <span>"mozilla/IncludedCACertificateReportPEMCSV"</span>

<span># Load the names[] and pems[] array from the URL</span>
names <span>=</span> <span>[</span><span>]</span>
pems <span>=</span> <span>[</span><span>]</span>
dates <span>=</span> <span>[</span><span>]</span>
response <span>=</span> urlopen<span>(</span>mozurl<span>)</span>
csvData <span>=</span> response<span>.</span>read<span>(</span><span>)</span>
<span>if</span> sys<span>.</span>version_info<span>[</span><span>0</span><span>]</span> <span>&gt;</span> <span>2</span><span>:</span>
    csvData <span>=</span> csvData<span>.</span>decode<span>(</span><span>'utf-8'</span><span>)</span>
csvFile <span>=</span> StringIO<span>(</span>csvData<span>)</span>
csvReader <span>=</span> csv<span>.</span>reader<span>(</span>csvFile<span>)</span>
<span>for</span> row <span>in</span> csvReader<span>:</span>
    names<span>.</span>append<span>(</span>row<span>[</span><span>0</span><span>]</span><span>+</span><span>":"</span><span>+</span>row<span>[</span><span>1</span><span>]</span><span>+</span><span>":"</span><span>+</span>row<span>[</span><span>2</span><span>]</span><span>)</span>
    pems<span>.</span>append<span>(</span>row<span>[</span><span>30</span><span>]</span><span>)</span>
    dates<span>.</span>append<span>(</span>row<span>[</span><span>8</span><span>]</span><span>)</span>
<span>del</span> names<span>[</span><span>0</span><span>]</span> <span># Remove headers</span>
<span>del</span> pems<span>[</span><span>0</span><span>]</span> <span># Remove headers</span>
<span>del</span> dates<span>[</span><span>0</span><span>]</span> <span># Remove headers</span>

derFiles <span>=</span> <span>[</span><span>]</span>
totalbytes <span>=</span> <span>0</span>
idx <span>=</span> <span>0</span>
<span># Process the text PEM using openssl into DER files</span>
sizes<span>=</span><span>[</span><span>]</span>
<span>for</span> i <span>in</span> <span>range</span><span>(</span><span>0</span><span>,</span> <span>len</span><span>(</span>pems<span>)</span><span>)</span><span>:</span>
    certName <span>=</span> <span>"ca_%03d.der"</span> <span>%</span> <span>(</span>idx<span>)</span><span>;</span>
    thisPem <span>=</span> pems<span>[</span>i<span>]</span><span>.</span>replace<span>(</span><span>"'"</span><span>,</span> <span>""</span><span>)</span>
    <span>print</span><span>(</span>dates<span>[</span>i<span>]</span> <span>+</span> <span>" -&gt; "</span> <span>+</span> certName<span>)</span>
    f<span>.</span>write<span>(</span><span>(</span><span>"//"</span> <span>+</span> dates<span>[</span>i<span>]</span> <span>+</span> <span>" "</span> <span>+</span> names<span>[</span>i<span>]</span> <span>+</span> <span>"\n"</span><span>)</span><span>)</span>
    
    ssl <span>=</span> Popen<span>(</span><span>[</span>openssl<span>,</span><span>'x509'</span><span>,</span><span>'-inform'</span><span>,</span><span>'PEM'</span><span>,</span><span>'-outform'</span><span>,</span><span>'DER'</span><span>,</span><span>'-out'</span><span>,</span> certName<span>]</span><span>,</span> 
                 shell <span>=</span> <span>False</span><span>,</span> stdin <span>=</span> PIPE<span>)</span>
    pipe <span>=</span> ssl<span>.</span>stdin
    pipe<span>.</span>write<span>(</span>thisPem<span>.</span>encode<span>(</span><span>'utf-8'</span><span>)</span><span>)</span>
    pipe<span>.</span>close<span>(</span><span>)</span>
    ssl<span>.</span>wait<span>(</span><span>)</span>
    <span>if</span> os<span>.</span>path<span>.</span>exists<span>(</span>certName<span>)</span><span>:</span>
        derFiles<span>.</span>append<span>(</span>certName<span>)</span>            
        
        der <span>=</span> <span>open</span><span>(</span>certName<span>,</span><span>'rb'</span><span>)</span>

        bytestr <span>=</span> der<span>.</span>read<span>(</span><span>)</span><span>;</span>
        sizes<span>.</span>append<span>(</span><span>len</span><span>(</span>bytestr<span>)</span><span>)</span>
        cert <span>=</span> Certificate<span>.</span>load<span>(</span>bytestr<span>)</span> 
        idxHash <span>=</span> hashlib<span>.</span>sha256<span>(</span>cert<span>.</span>issuer<span>.</span>dump<span>(</span><span>)</span><span>)</span><span>.</span>digest<span>(</span><span>)</span>

        <span># for each certificate store the binary data as a byte array</span>
        f<span>.</span>write<span>(</span><span>"const uint8_t cert_"</span> <span>+</span> <span>str</span><span>(</span>idx<span>)</span> <span>+</span> <span>"[] PROGMEM = {"</span><span>)</span>
        <span>for</span> j <span>in</span> <span>range</span><span>(</span><span>0</span><span>,</span> <span>len</span><span>(</span>bytestr<span>)</span><span>)</span><span>:</span>
            totalbytes<span>+=</span><span>1</span>
            f<span>.</span>write<span>(</span><span>hex</span><span>(</span>bytestr<span>[</span>j<span>]</span><span>)</span><span>)</span>
            <span>if</span> j<span>&lt;</span><span>len</span><span>(</span>bytestr<span>)</span><span>-</span><span>1</span><span>:</span>
                f<span>.</span>write<span>(</span><span>", "</span><span>)</span>
        f<span>.</span>write<span>(</span><span>"};\n"</span><span>)</span>

        <span># for each hashed certificate issuer, store the binary data as a byte array</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://maakbaas.com/esp8266-iot-framework/logs/https-requests/">https://maakbaas.com/esp8266-iot-framework/logs/https-requests/</a></em></p>]]>
            </description>
            <link>https://maakbaas.com/esp8266-iot-framework/logs/https-requests/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23721470</guid>
            <pubDate>Fri, 03 Jul 2020 06:14:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Complete Guide on How to Disable Windows Defender (Windows 10)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23721454">thread link</a>) | @NaijTecho
<br/>
July 2, 2020 | https://www.naijtecho.com.ng/2020/06/how-to-disable-windows-defender.html?m=1 | <a href="https://web.archive.org/web/*/https://www.naijtecho.com.ng/2020/06/how-to-disable-windows-defender.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.naijtecho.com.ng/2020/06/how-to-disable-windows-defender.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-23721454</guid>
            <pubDate>Fri, 03 Jul 2020 06:10:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Step by Step Guide on How to Encrypt Your Flash Drive Using Bitlocker]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23721451">thread link</a>) | @NaijTecho
<br/>
July 2, 2020 | https://www.naijtecho.com.ng/2020/06/how-to-encrypt-your-flash-drive.html?m=1 | <a href="https://web.archive.org/web/*/https://www.naijtecho.com.ng/2020/06/how-to-encrypt-your-flash-drive.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.naijtecho.com.ng/2020/06/how-to-encrypt-your-flash-drive.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-23721451</guid>
            <pubDate>Fri, 03 Jul 2020 06:09:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Killed Smalltalk? (2015)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23720090">thread link</a>) | @betocmn
<br/>
July 2, 2020 | https://pointersgonewild.com/2015/08/20/what-killed-smalltalk/ | <a href="https://web.archive.org/web/*/https://pointersgonewild.com/2015/08/20/what-killed-smalltalk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								<p>I‚Äôve been thinking about designing my own programming language for a long time. I‚Äôve actually been keeping a lot of notes, and even throwing together some code when I can find time. My plan is to build something that takes inspiration from LISP, JavaScript and Smalltalk. I think there‚Äôs a niche to be filled. There are many new programming languages coming out lately, but most of them are statically typed and compiled ahead of time. The <a href="https://en.wikipedia.org/wiki/Dynamic_programming_language">dynamic languages</a> that do come out often don‚Äôt perform very well (see CPython, Ruby) or have poorly thought out&nbsp;semantics.</p>
<p>I‚Äôve written a few&nbsp;blog posts pointing and laughing at perceived failures of JavaScript, but the truth is that programming language design is hard.&nbsp;There‚Äôs no limit to the complexity of the things you can build with programming code. No matter the design choices you make, no matter the language you design, there are bound&nbsp;to be some inconsistencies and weaknesses somewhere.&nbsp;I think that Smalltalk is a very inspiring programming language, revolutionary in many ways, but it‚Äôs also one that has gone extinct. It‚Äôs interesting, in my opinion, to ask ourselves why Python thrives but Smalltalk died.</p>
<p>Like LISP, Smalltalk implemented some interesting features which have influenced other languages (such as Java and JavaScript). Some nifty features of Smalltalk are really cool, but still aren‚Äôt implemented in any other language. For instance, Smalltalk had the ability to suspend running programs into a saved image, and resume execution later at the saved point. As you can imagine, this is extremely powerful and useful. Forget saving documents or saving games, just save the state of an entire program, no implementation effort required.</p>
<p>I found an interesting talk on YouTube titled ‚ÄúWhat Killed Smalltalk could Kill Ruby Too‚Äù:</p>
<p><span><iframe width="560" height="315" src="https://www.youtube.com/embed/YX3iRjKj7C0?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>Robert Martin makes the case that one of the big weaknesses of Smalltalk is&nbsp;that it was just ‚Äútoo easy to make a mess‚Äù. Smalltalk was highly dynamic, and encouraged people to ‚Äúmonkey patch‚Äù things and do quick fixes/hacks.&nbsp;He also makes the point that Smalltalk just ‚Äúdidn‚Äôt play well with others‚Äù. When you think about it, Smalltalk had its own source control, IDE and GUI built into live images, living alongside your program. Smalltalk isn‚Äôt just a language, it‚Äôs an operating system and a way of life. It‚Äôs conflating things that would maybe be best left separate.</p>
<p>It seems to me that in some key areas, the&nbsp;Smalltalk creators placed their own radical ideas above everything else. They chose idealism over pragmatism. Smalltalk was a language created with a grandiose vision. It had some deeply rooted principles which didn‚Äôt necessarily work so well in practice, such as the idea that everything had to be an object, that the object metaphor should be applied everywhere, one size fits all.&nbsp;At the end of the day, programmers want to get things done and be productive. If the language design or implementation gets in the way of getting things done, people will leave. Pragmatism is key for a programming language to succeed.</p>
<p>Smalltalk was also designed with the idea that it should be easy to learn and intuitive. This has led its creators to have a heavy focus on graphical user interfaces.&nbsp;I watched an introduction to <a href="https://www.youtube.com/watch?v=Ox5P7QyL774">Self on YouTube</a>&nbsp;(Self is a direct descendent of Smalltalk) and saw the heavy emphasis on interacting with objects through UIs. The user interfaces showcased in this video are, in my opinion, horribly complex and unintuitive. Pretty much all of the interactions done through the UI would have been simpler and easier to understand if they had been done by writing one or two lines of code instead!</p>
<p>When you sit down and think about it for one second, you have to realize that programming doesn‚Äôt fundamentally have anything to do with graphical user interfaces. Yes, you can use programming code to create GUIs, but there is no reason that programming should have to involve GUIs and be tied to them. The metaphor of writing code has been extremely successful since the very beginning, and it probably makes more sense to the mathematical mind of a skilled programmer. Not everything has to have a visual metaphor. This is again a case of pushing some idealistic principle too far, in my opinion.</p>
<p>I believe that a lack of pragmatism is something that has killed many languages. Not just Smalltalk, but Scheme too. My first experience with Scheme involved trying and failing to install multiple Scheme distributions because I couldn‚Äôt get all the dependencies to work. Then, finally getting a Scheme compiler installed, and struggling to implement simple routines to parse text files, because Scheme doesn‚Äôt include&nbsp;the most basic string routines. The Scheme compiler I‚Äôd selected bragged that the code it produced was highly optimized, but once I finally managed to write my own string routines, I compiled my program, ran it, and it was dog slow.&nbsp;Parsing a one-megabyte CSV spreadsheet took over a minute. I ended up rewriting the code in Python. Why don‚Äôt more people code in Scheme? Because they try to realize their ideas in Scheme, and it just doesn‚Äôt quite work out.</p>
											</div></div>]]>
            </description>
            <link>https://pointersgonewild.com/2015/08/20/what-killed-smalltalk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23720090</guid>
            <pubDate>Fri, 03 Jul 2020 01:20:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Accelerate your deploys with these 5 CircleCI optimizations]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23718994">thread link</a>) | @giacaglia
<br/>
July 2, 2020 | https://transcend.io/blog/accelerate-your-deploys-with-these-5-circleci-optimizations | <a href="https://web.archive.org/web/*/https://transcend.io/blog/accelerate-your-deploys-with-these-5-circleci-optimizations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>At Transcend, we build, test, and deploy all of our application code through CircleCI. In order to maintain a quick developer feedback loop, we recently optimized our pipeline for performance.</p><p><strong>We were able to reduce our build, test, and deploy cycle time from 22 minutes down to just 8 minutes without removing any generative or integration tests.</strong> Further, we were able to drop unit testing times on our pull requests (PRs) from over 4 minutes to a mere one minute.</p><p>This post explains how we achieved these performance gains.</p><h2 id="get-the-baseline">Get the baseline</h2><p>Let‚Äôs start with a representative job that runs JavaScript unit and integration tests using <a target="_blank" rel="noopener noreferrer" href="https://jestjs.io/">Jest</a>. The following configuration defines an <a target="_blank" rel="noopener noreferrer" href="https://circleci.com/docs/2.0/configuration-reference/#executors-requires-version-21">execution environment</a> <code>ci-node</code>, a <em><a target="_blank" rel="noopener noreferrer" href="https://circleci.com/docs/2.0/configuration-reference/#jobs">job</a></em> named <code>jest-unit</code>, and a <em><a target="_blank" rel="noopener noreferrer" href="https://circleci.com/docs/2.0/configuration-reference/#workflows">workflow</a></em> named <code>main_workflow</code>. (CircleCI workflows run one or more jobs).</p><div><pre><p><span>1</span><span>executors</span><span>:</span><span></span></p><p><span>2</span><span>  </span><span>ci-node</span><span>:</span><span></span></p><p><span>3</span><span>    </span><span>docker</span><span>:</span><span></span></p><p><span>4</span><span>      </span><span>-</span><span> </span><span>image</span><span>:</span><span> 123456789.dkr.ecr.eu</span><span>-</span><span>west</span><span>-</span><span>1.amazonaws.com/ci</span><span>-</span><span>node</span><span>:</span><span>our5ha</span></p><p><span>5</span><span></span></p><p><span>6</span><span></span><span>jobs</span><span>:</span><span></span></p><p><span>7</span><span>  </span><span>jest-unit</span><span>:</span><span></span></p><p><span>8</span><span>    </span><span>executor</span><span>:</span><span> ci</span><span>-</span><span>node</span></p><p><span>9</span><span>    </span><span>steps</span><span>:</span><span></span></p><p><span>10</span><span>      </span><span></span></p><p><span>11</span><span>      </span><span>-</span><span> checkout</span></p><p><span>12</span><span>      </span><span></span></p><p><span>13</span><span>      </span><span>-</span><span> </span><span>restore_cache</span><span>:</span><span></span></p><p><span>14</span><span>          </span><span>keys</span><span>:</span><span></span></p><p><span>15</span><span>            </span><span>-</span><span> yarn</span><span>-</span><span>vblog</span><span>-</span><span>{</span><span>{</span><span> arch </span><span>}</span><span>}</span><span>-</span><span>{</span><span>{</span><span> checksum "yarn.lock" </span><span>}</span><span>}</span><span></span></p><p><span>16</span><span>      </span><span></span></p><p><span>17</span><span>      </span><span>-</span><span> </span><span>run</span><span>:</span><span> yarn install</span></p><p><span>18</span><span>      </span><span></span></p><p><span>19</span><span>      </span><span>-</span><span> </span><span>save_cache</span><span>:</span><span></span></p><p><span>20</span><span>          </span><span>paths</span><span>:</span><span></span></p><p><span>21</span><span>            </span><span>-</span><span> node_modules</span></p><p><span>22</span><span>            </span><span>-</span><span> packages/admin</span><span>-</span><span>dashboard/node_modules</span></p><p><span>23</span><span>            </span><span>-</span><span> packages/core/node_modules</span></p><p><span>24</span><span>            </span><span>-</span><span> ‚Ä¶</span></p><p><span>25</span><span>          </span><span>key</span><span>:</span><span> yarn</span><span>-</span><span>vblog</span><span>-</span><span>{</span><span>{</span><span> arch </span><span>}</span><span>}</span><span>-</span><span>{</span><span>{</span><span> checksum "yarn.lock" </span><span>}</span><span>}</span><span></span></p><p><span>26</span><span></span></p><p><span>27</span><span>      </span><span></span></p><p><span>28</span><span>      </span><span>-</span><span> </span><span>run</span><span>:</span><span> yarn test</span><span>:</span><span>jest</span></p><p><span>29</span><span></span></p><p><span>30</span><span></span><span>workflows</span><span>:</span><span></span></p><p><span>31</span><span>  </span><span>main_workflow</span><span>:</span><span></span></p><p><span>32</span><span>    </span><span>jobs</span><span>:</span><span></span></p><p><span>33</span><span>      </span><span>-</span><span> </span><span>jest-unit</span><span>:</span><span></span></p><p><span>34</span><span>          </span><span></span></p><p><span>35</span><span>          </span><span>context</span><span>:</span><span> dev</span><span>-</span><span>ctx</span></p></pre></div><p>In particular, the <code>jest-unit</code> job does something pretty common in continuous integration (CI): it uses our private Docker image to create an execution environment where it then checks out code from our git repository, installs our <code>node_modules</code> dependencies using <code>yarn</code>, and then runs our tests.</p><p>This job typically takes 4 to 6 minutes to complete running. Here‚Äôs a run that took 4:30:</p><div><p><img src="https://images.ctfassets.net/zp9m00phuodm/36Mmhm3hvFEcn2v5k45OJ8/c9120c139df16150910a69a8a5388cbb/1wsSz9yROEXnMvvHSmIt5J83YIAsS90sJaiuidmI.png" alt="CircleCI: without a cache."></p></div><p>Without a cache (such as when the job is first run, or when the list of node modules that make up the cache is changed), it takes around three minutes to install all dependencies from scratch, and another 40 seconds to save those dependencies to the cache:</p><div><p><img src="https://images.ctfassets.net/zp9m00phuodm/7rhLcGIZiqLiOXPWaFowgQ/9c1139085b600e0151a3be12ca8d7588/16mAVWC6xAttEJckvXfz_6LOp7dcYRSMsxw0rZzQ.png" alt="CircleCI: with a cache."></p></div><p>This run time isn‚Äôt terrible, but it could be <strong>much</strong> better.</p><h2 id="accelerate-each-step">Accelerate each step</h2><p>With a little tinkering, almost every step in this job can be sped up. Let‚Äôs dive in:</p><h3 id="1-use-2nd-gen-convenience-images-for-quick-environment-spin-up">1. Use 2nd gen convenience images for quick environment spin up</h3><p>The ‚ÄúSpin Up Environment‚Äù step is responsible for creating the virtual environment in which your job will execute (hence ‚Äúexecutor‚Äù). Pulling in an executor, in this example an entire Docker image, can be slow. Although you can specify a custom Docker image, CircleCI also provides <a target="_blank" rel="noopener noreferrer" href="https://circleci.com/docs/2.0/circleci-images/#next-generation-convenience-images">pre-made convenience images</a> that we have found to be very convenient.</p><p>CircleCI recently released a second-generation version of these convenience images, which promise faster spin-up times. The <a target="_blank" rel="noopener noreferrer" href="https://github.com/CircleCI-Public/cimg-base/blob/master/Dockerfile.template">cimg-base repository</a> documents everything that is installed in the base Docker Image. Because the convenience images are all built off of the same base image, they can cache very well <a target="_blank" rel="noopener noreferrer" href="https://circleci.com/blog/how-to-build-a-docker-image-on-circleci-2-0/">using Docker Layer Caching</a>.</p><p>In our example, the only change we need to make is to point to one of these new images in our <code>executors</code>. In our case, we can also remove our credentials used to access our private image:</p><div><pre><p><span>1</span><span>executors:</span></p><p><span>2</span><span>   ci-node:</span></p><p><span>3</span><span>     docker:</span></p><p><span>4</span><span></span><span>-     - image: 123456789.dkr.ecr.eu-west-1.amazonaws.com/ci-node:our5ha</span><span></span></p><p><span>5</span><span></span><span>+     - image: cimg/node:14.3</span><span></span></p><p><span>6</span><span> </span></p><p><span>7</span><span> workflows:</span></p><p><span>8</span><span>   main_workflow:</span></p><p><span>9</span><span>     jobs:</span></p><p><span>10</span><span></span><span>+      - jest-unit</span><span></span></p><p><span>11</span><span></span><span>-      - jest-unit:</span><span></span></p><p><span>12</span><span></span><span>-         # Give this job AWS credentials to access our private Docker images</span><span></span></p><p><span>13</span><span></span><span>-         context: dev-ctx</span></p></pre></div><p>The results are pretty dramatic when the cache hits:</p><div><p><img src="https://images.ctfassets.net/zp9m00phuodm/4ramSJxcaUSP3OekcYBkRK/9fac31c12fdcd24b12a2a0a66056c72e/1j-4V-pGdkkTL6bRMc4LkeRZqINrhDWebZzn8j9E.png" alt="CircleCI: with cache hits."></p></div><p>Even when the cache doesn‚Äôt hit, there are usually enough layers cached that spinning up the environment now takes less than 15 seconds (down from 30-50 seconds before).</p><p>Even more helpful than this speed, the new convenience images are Debian-based. This allows us to use Unix tools that our developers are familiar with, like the package manager <code>apt</code>, instead of the sometimes-confusing Alpine <code>apk</code> (Alpine does not include common tools like <code>bash</code> or <code>jq</code> by default).</p><h3 id="2-use-shallow-clones-for-swift-code-checkout">2. Use shallow clones for swift code checkout</h3><p>Repositories balloon over time, especially if you use a monorepo as we do. Even if the file size at HEAD is kept relatively small, <a target="_blank" rel="noopener noreferrer" href="https://stackoverflow.com/questions/5613345/how-to-shrink-the-git-folder">past file blobs can stick around in the .git folder</a>. One of the best ways to speed up <code>git clone</code> commands is to use a <a target="_blank" rel="noopener noreferrer" href="https://www.perforce.com/blog/vcs/git-beyond-basics-using-shallow-clones">shallow checkout</a>.</p><p>There are a few open-source <a target="_blank" rel="noopener noreferrer" href="https://circleci.com/docs/2.0/orb-intro/">CircleCI Orbs</a> that make this optimization easy to implement. In particular, <a target="_blank" rel="noopener noreferrer" href="https://circleci.com/orbs/registry/orb/guitarrapc/git-shallow-clone">we like this one</a> because it lets us customize any git settings we‚Äôd like.</p><p>To use this orb, at the top of your config, add:</p><div><pre><p><span>1</span><span>orbs</span><span>:</span><span></span></p><p><span>2</span><span>  </span><span>git-shallow-clone</span><span>:</span><span> guitarrapc/git</span><span>-</span><span>shallow</span><span>-</span><span>clone@2.0.3</span></p></pre></div><p>Then replace <code>- checkout</code> in all your jobs with <code>- git-shallow-clone/checkout</code>.</p><p>When we made this change, our checkout step dropped from 15-25 seconds down to 3-5 seconds just like that!</p><p>It‚Äôs worth noting that there are two reasons why someone might <em>not</em> use shallow checkouts:</p><ol><li><p><strong>Some Git commands are not supported by shallow checkouts.</strong>
These include fetching information from multiple branches or from deep in the Git history.</p></li><li><p><strong>Git providers sometimes rate limit shallow checkouts.</strong>
This only becomes an issue for large workflows or frequent runs.</p></li></ol><p>That said, for the majority of use cases, shallow checkouts are safe to use and can save a significant amount of time.</p><h3 id="3-untar-in-ram-for-rapid-cache-restores">3. Untar in RAM for rapid cache restores</h3><p>Caching <em>can</em> be a wonderful, run-time-saving thing. That said, accessing our large <code>node_modules</code> folder (nearly 300MB) from the CircleCI cache could sometimes take longer than starting from scratch with a fresh <code>yarn install</code>.</p><p>Internally, CircleCI manages caches and workspaces by putting files into a tarball and uploading that compressed tar file into Amazon S3. When you request a cache, CircleCI downloads the tar file from S3, validates that the file is the one that was requested, and then untars it.</p><p>Because <code>node_modules</code> can have thousands of files, even with lightning-fast network speeds, disk IO can slow down the untar process significantly.</p><p>In our example, restoring our cache took 1:07. Only 6 of those seconds were spent downloading and validating, while decompressing the files took over a minute. In the worst-case scenario, this cache restore step could take up to 3 minutes to complete.</p><div><p><img src="https://images.ctfassets.net/zp9m00phuodm/6Jtu3bfEugHoXeUokHzzag/d747dd8b395c2fa20910eb5fb2c69538/1i1ZdxE38xmjY57AFoLK9hvEqWZ_fshqhPd6_gCI.png" alt="CircleCI: Untar in RAM."></p></div><p>Lucky for all of us, as of the <a target="_blank" rel="noopener noreferrer" href="https://circleci.com/changelog#ram-disks">April 7th, 2020 CircleCI release</a>, CircleCI supports <a target="_blank" rel="noopener noreferrer" href="https://circleci.com/docs/2.0/executor-types/#ram-disks">mounted RAM disks</a> on Docker executors.</p><p>Using these RAM disks has dropped the <code>restore_cache</code> run time down to a consistent 10‚Äì20 seconds. These are the changes we made to achieve faster results:</p><div><pre><p><span>1</span><span>executors:</span></p><p><span>2</span><span>   ci-node:</span></p><p><span>3</span><span>     docker:</span></p><p><span>4</span><span>       - image: cimg/node:14.3</span></p><p><span>5</span><span></span><span>+    # Upgrade the resource_class for a bit more RAM for consistent builds</span><span></span></p><p><span>6</span><span></span><span>+    resource_class: medium+</span><span></span></p><p><span>7</span><span></span><span>+    # Updated so we can build using RAM</span><span></span></p><p><span>8</span><span></span><span>+    working_directory: /mnt/ramdisk</span><span></span></p><p><span>9</span><span></span></p><p><span>10</span><span></span></p><p><span>11</span><span> jobs:</span></p><p><span>12</span><span>   jest-unit:</span></p><p><span>13</span><span>     executor: ci-node</span></p><p><span>14</span><span>     steps:</span></p><p><span>15</span><span>       - git-shallow-clone/checkout</span></p><p><span>16</span><span>       - restore_cache:</span></p><p><span>17</span><span>           keys:</span></p><p><span>18</span><span></span><span>-            - yarn-vblog-{{ arch }}-{{ checksum "yarn.lock" }}</span><span></span></p><p><span>19</span><span></span><span>+            # Reset the cache to vblog2 (from vblog) in order to force a refresh</span><span></span></p><p><span>20</span><span></span><span>+            # The old cache would write out the files to our old `working_directory` path</span><span></span></p><p><span>21</span><span></span><span>+            - yarn-vblog2-{{ arch }}-{{ checksum "yarn.lock" }}</span><span></span></p><p><span>22</span><span>       - run: yarn install</span></p><p><span>23</span><span>       - save_cache:</span></p><p><span>24</span><span>           paths:</span></p><p><span>25</span><span>             - node_modules</span></p><p><span>26</span><span>             - packages/admin-dashboard/node_modules</span></p><p><span>27</span><span>             - packages/core/node_modules</span></p><p><span>28</span><span>             - ...</span></p><p><span>29</span><span>           key: yarn-vblog-{{ arch }}-{{ checksum "yarn.lock" }}</span></p><p><span>30</span><span>           key: yarn-vblog2-{{ arch }}-{{ checksum "yarn.lock" }}</span></p><p><span>31</span><span>       - run: yarn test:jest</span></p></pre></div><p>Just like that, our caches are lightning quick:</p><div><p><img src="https://images.ctfassets.net/zp9m00phuodm/4tv6USwP1AHdxmHtKOHcY3/b2096efacd9aedeb24503c305bf649c4/1rnzqPHF3anjlayEyzth3nP9ocAyDBi5c-Zd70SU.png" alt="CircleCI: faster caches."></p></div><p>In order to use this approach, your repo and its dependencies must be able to fit in RAM. While the larger <code>resource_class</code> costs more money, because our jobs now finish in about half the time, the cost difference has been negligible.</p><p>And while your mileage may vary, give larger instance sizes a try and see if they work for your use case.</p><h3 id="4-parallelize-jobs-for-expedited-workflows">4. Parallelize jobs for expedited workflows</h3><p>Improved caching and access to caches is all very well and good, but when dependencies change, caches need to be updated. In these cases, the <code>yarn install</code> step will need to do more work, as well as the <code>Saving Cache</code> step, adding an extra minute or so to our pipelines. To solve this problem, we decided to play around with parallelization.</p><p>First, we tried saving the cache in a single job separate from all of our other jobs. Each subsequent job could then restore the cache from its saved location in the workspace instead of saving the cache as part of all of our jobs, including the jest tests:</p><div>
  <p><img src="https://images.ctfassets.net/zp9m00phuodm/Uraphwbv2Qr5ch8w5Dc3g/cc782477babf02e39560d899b75a97c7/Before.svg" alt="CircleCI: before restore cache."></p></div><p>Became</p><div>
  <p><img src="https://images.ctfassets.net/zp9m00phuodm/3VITdrgxP0QiRVV5yapNVb/716bb3f826759b81173536cead124a2c/After.svg" alt="CircleCI: after restore cache."></p></div><p>We were disappointed by the results of this approach: combined, these jobs took even longer. It could take almost 2 minutes to store our dependencies in the workspace, and that step needed to complete before we started our jest job.</p><p>To get around this problem, we changed the way we split our jobs. We divided them into first-level jobs that can rely on the global cache for dependencies (and don‚Äôt depend on the completion of other jobs) and everything else. Then we added a new first-level job, <code>cache-deps</code>, that cached all dependencies for any job that ran after the first level.</p><p>Our new pipeline runs all first-level jobs immediately, and then anything with a dependency. This division has the added benefit that most of our first-level jobs no longer need to write out to the cache, as <code>cache-deps</code> now takes care of that.</p><p>In our config, this looks like:</p><div><pre><p><span>1</span><span>jobs:</span></p><p><span>2</span><span></span><span>+  cache-deps:</span><span></span></p><p><span>3</span><span></span><span>+    parameters:</span><span></span></p><p><span>4</span><span></span><span>+      key:</span><span></span></p><p><span>5</span><span></span><span>+        type: string</span><span></span></p><p><span>6</span><span></span><span>+    executor: ci-node</span><span></span></p><p><span>7</span><span></span><span>+    steps:</span><span></span></p><p><span>8</span><span></span><span>+      - git-shallow-clone/checkout</span><span></span></p><p><span>9</span><span></span><span>+      - restore_cache:</span><span></span></p><p><span>10</span><span></span><span>+          keys:</span><span></span></p><p><span>11</span><span></span><span>+            - &lt;&lt; parameters.key &gt;&gt;</span><span></span></p><p><span>12</span><span></span><span>+      - run: yarn install</span><span></span></p><p><span>13</span><span></span><span>+      - save_cache:</span><span></span></p><p><span>14</span><span></span><span>+          paths:</span><span></span></p><p><span>15</span><span></span><span>+            - node_modules</span><span></span></p><p><span>16</span><span></span><span>+            - packages/admin-dashboard/node_modules</span><span></span></p><p><span>17</span><span></span><span>+            - packages/core/node_modules</span><span></span></p><p><span>18</span><span></span><span>+            - ...</span><span></span></p><p><span>19</span><span></span><span>+      ‚Ä¶</span></p></pre></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://transcend.io/blog/accelerate-your-deploys-with-these-5-circleci-optimizations">https://transcend.io/blog/accelerate-your-deploys-with-these-5-circleci-optimizations</a></em></p>]]>
            </description>
            <link>https://transcend.io/blog/accelerate-your-deploys-with-these-5-circleci-optimizations</link>
            <guid isPermaLink="false">hacker-news-small-sites-23718994</guid>
            <pubDate>Thu, 02 Jul 2020 22:48:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixing Rust's test suite on RISC-V]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23718634">thread link</a>) | @emptybits
<br/>
July 2, 2020 | https://www.codethink.co.uk/articles/2020/fixing-rusts-test-suite-on-risc-v/ | <a href="https://web.archive.org/web/*/https://www.codethink.co.uk/articles/2020/fixing-rusts-test-suite-on-risc-v/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <div>
          <p><img src="https://www.codethink.co.uk/theme/images/softwarebug.jpg" alt="Binary data">
          </p>
          <p>My
<a href="https://www.codethink.co.uk/articles/2020/improving-risc-v-linux-support-in-rust/">previous blog post</a>
introduced my work to improve <a href="https://www.rust-lang.org/">Rust's</a> support for
<a href="https://riscv.org/">RISC-V</a> Linux systems. Since then I fixed a couple of
interesting compiler bugs. This blog post is more technical - describing these
bugs and explaining some <code>rustc</code> internals along the way. I conclude by
reporting on movement in the broader Rust community regarding RISC-V. I
assumed that the reader is comfortable with programming terminology. This blog
post contains Rust code samples but the reader is not expected to be fluent in
Rust.</p>
<h2>Hanging Tests</h2>
<p>In the last blog post I mentioned an issue where some <code>rustc</code> tests would
hang indefinitely. While I was tracking down the problem, the upstream
Rust project
<a href="https://github.com/rust-lang/rust/pull/67759">upgraded from LLVM 9 to LLVM 10</a>,
which fixed the hanging tests. I did not look into this issue
further.</p>
<h3>What is LLVM anyway?</h3>
<p>Modern compilers do not translate directly from source code into machine code.
Source code is intended to be convenient for humans to read; but it often is not
convenient for a compiler to reason about. Instead, compilers transform source
code through one (or more) intermediate representations on its way to becoming
machine code. <code>rustc</code> compiles Rust source through intermediate
representations into LLVM Intermediate Representation<a href="#first">*</a> (LLVM IR).
LLVM then runs optimisation passes on the LLVM IR and finally generates machine
code for the chosen architecture.</p>
<p>I think of LLVM IR as an elaborated machine-independent<a href="#second">**</a>
typed assembly language with unlimited registers. See this LLVM IR for a function
to add integers:</p>
<p><code>add.rs</code></p>
<div><pre><span></span><span>pub</span><span> </span><span>fn</span> <span>add</span><span>(</span><span>x</span>: <span>i32</span><span>,</span><span> </span><span>y</span>: <span>i32</span><span>)</span><span> </span>-&gt; <span>i32</span> <span>{</span><span></span>
<span>    </span><span>x</span><span> </span><span>+</span><span> </span><span>y</span><span></span>
<span>}</span><span></span>
</pre></div>


<p><code>rustc --crate-type lib -O add.rs --emit llvm-ir</code></p>
<div><pre><span></span>; ModuleID = 'add.3a1fbbbh-cgu.0'
source_filename = "add.3a1fbbbh-cgu.0"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; add::add
; Function Attrs: norecurse nounwind nonlazybind readnone uwtable
define i32 @_ZN3add3add17h7cc3d194e9d7e4cdE(i32 %x, i32 %y) unnamed_addr #0 {
start:
  %0 = add i32 %y, %x
  ret i32 %0
}

attributes #0 = { norecurse nounwind nonlazybind readnone uwtable "probe-stack"="__rust_probestack" "target-cpu"="x86-64" }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 7, !"PIC Level", i32 2}
!1 = !{i32 2, !"RtLibUseGOT", i32 1}
</pre></div>


<p>In LLVM IR, lines starting with <code>;</code> are comments. <code>target datalayout</code> and
<code>target triple</code> tell LLVM what architecture it should generate code for.</p>
<p>Next is the function definition. In Rust, the function name is <code>add::add</code>;
but the compiler mangles the name to <code>_ZN3add3add17h7cc3d194e9d7e4cdE</code>.
Then <code>define i32 @foo(i32 %x, i32 %y)</code> means <em>"define a function called
<code>foo</code> which takes two 32-bit signed integer (<code>i32</code>) arguments and returns an
<code>i32</code>"</em>. Inside the function, a <code>start:</code> label begins the block;
then <code>%0 = add i32 %y, %x</code> performs signed 32-bit addition on <code>x</code> and <code>y</code>
and puts the result in a variable automatically named <code>0</code>. Finally, <code>ret i32 %0</code>
returns the value of <code>0</code> as an <code>i32</code>.</p>
<p>The <code>attributes #0</code> line provides extra annotations for all functions tagged
with <code>#0</code> (such as <code>add::add</code>). The annotations give hints for LLVM optimisation
passes.</p>
<p>In theory, to support a new target architecture <code>rustc</code> only needs to know how to
tell LLVM that it should generate code for that architecture. <code>rustc</code> can then
generate LLVM IR as usual and LLVM will handle everything specific to the
architecture. For example, see the tiny
<a href="https://github.com/rust-lang/rust/pull/66661">PR</a> which initially added the
RISC-V Linux target.</p>
<p>In practice, <code>rustc</code> also needs to know how to conform to the ABI for the target
so that the generated code is interoperable with other programming languages. The
RISC-V ABI was added separately.</p>
<p><a name="first">*</a> <em>As well as LLVM, <code>rustc</code> also has an experimental
<a href="https://github.com/bjorn3/rustc_codegen_cranelift">cranelift backend</a>.</em></p>
<p><a name="second">**</a> <em>LLVM IR can be ABI specific but is not machine specific.</em></p>
<h2>Code generation Test Failure</h2>
<p>Other than fixing the hanging <code>ui</code> tests, LLVM 10 also broke code generation
tests for RISC-V. In LLVM 9 IR, function
arguments weren't always named but
<a href="https://github.com/llvm/llvm-project/commit/a009a60a917bc30940422bcef73f8270566d78db">in LLVM 10 they are</a>
. This change broke <code>rustc</code> code generation tests which look for specific strings
in the LLVM IR output by <code>rustc</code>.</p>
<p>After narrowing this test failure down to the LLVM 10 upgrade, I found the
relevant change by looking at <code>clang</code> (which also uses LLVM) tests for the RISC-V
ABI. The
<a href="https://github.com/rust-lang/rust/commit/c872dcf956e541315985ee5fdc592907c20df8ec">fix</a>
was as simple as copying the clang test changes and adapting them for <code>rustc</code>'s
tests.</p>
<h2>UI Tests</h2>
<p>The <code>ui</code> tests for <code>rustc</code> check all user facing aspects of the compiler. Some of
these tests check that <code>rustc</code> displays the correct error messages when compiling
erroneous source.</p>
<p>There was a bug highlighted by some of these tests on RISC-V: <code>rustc</code> displays
the correct errors but in the wrong order! To debug this I used
<code>-Z treat-err-as-bug=n</code> to cause <code>rustc</code> to panic on the <code>n</code>th error. The panic
backtrace shows where the error is generated from. In this case, the miss-ordered
errors came from
<a href="https://github.com/rust-lang/rust/blob/master/src/librustc_resolve/late.rs#L1287"><code>src/librustc_resolve/late.rs</code></a>:</p>
<div><pre><span></span><span>/// Checks that all of the arms in an or-pattern have exactly the</span>
<span>/// same set of bindings, with the same binding modes for each.</span>
<span>fn</span> <span>check_consistent_bindings</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>,</span><span> </span><span>pats</span>: <span>&amp;</span><span>[</span><span>P</span><span>&lt;</span><span>Pat</span><span>&gt;</span><span>])</span><span> </span>-&gt; <span>Vec</span><span>&lt;</span><span>BindingMap</span><span>&gt;</span><span> </span><span>{</span><span></span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>missing_vars</span><span> </span><span>=</span><span> </span><span>FxHashMap</span>::<span>default</span><span>();</span><span></span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>inconsistent_vars</span><span> </span><span>=</span><span> </span><span>FxHashMap</span>::<span>default</span><span>();</span><span></span>

<span>    </span><span>// 1) Compute the binding maps of all arms.</span>
<span>[...]</span><span></span>

<span>    </span><span>// 2) Record any missing bindings or binding mode inconsistencies.</span>
<span>[...]</span><span></span>

<span>    </span><span>// 3) Report all missing variables we found.</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>missing_vars</span><span> </span><span>=</span><span> </span><span>missing_vars</span><span>.</span><span>iter_mut</span><span>().</span><span>collect</span>::<span>&lt;</span><span>Vec</span><span>&lt;</span><span>_</span><span>&gt;&gt;</span><span>();</span><span></span>
<span>    </span><span>missing_vars</span><span>.</span><span>sort</span><span>();</span><span></span>

<span>    </span><span>for</span><span> </span><span>(</span><span>name</span><span>,</span><span> </span><span>mut</span><span> </span><span>v</span><span>)</span><span> </span><span>in</span><span> </span><span>missing_vars</span><span> </span><span>{</span><span></span>
<span>        </span><span>if</span><span> </span><span>inconsistent_vars</span><span>.</span><span>contains_key</span><span>(</span><span>name</span><span>)</span><span> </span><span>{</span><span></span>
<span>            </span><span>v</span><span>.</span><span>could_be_path</span><span> </span><span>=</span><span> </span><span>false</span><span>;</span><span></span>
<span>        </span><span>}</span><span></span>
<span>        </span><span>self</span><span>.</span><span>r</span><span>.</span><span>report_error</span><span>(</span><span></span>
<span>            </span><span>*</span><span>v</span><span>.</span><span>origin</span><span>.</span><span>iter</span><span>().</span><span>next</span><span>().</span><span>unwrap</span><span>(),</span><span></span>
<span>            </span><span>ResolutionError</span>::<span>VariableNotBoundInPattern</span><span>(</span><span>v</span><span>),</span><span></span>
<span>        </span><span>);</span><span></span>
<span>    </span><span>}</span><span></span>

<span>[...]</span><span></span>
<span>}</span><span></span>
</pre></div>


<p>In part 3, <code>missing_vars</code> is sorted before the errors are reported so how can
the errors be out of order?</p>
<p>At the time of the sort, <code>missing_vars</code> is a <code>Vec</code>tor of tuples, with each tuple
containing a <code>Symbol</code> and a mutable reference to a <code>BindingError</code>. In Rust this
type is written as <code>Vec&lt;(Symbol, &amp;mut BindingError)&gt;</code>. Rust tuples sort first by
the left-most element (in this case, the <code>Symbol</code>). To explain <code>Symbol</code> ordering
following a sort, first we must look at how strings are used within <code>rustc</code>.</p>
<h3>String Interning</h3>
<p>Source code often contains duplicates of the same string token. For example,
in the above listing of <code>check_consistent_bindings</code> the string <code>"FxHashMap"</code>
occurs twice and <code>"missing_vars"</code> occurs five times. Allocating separate strings
for each of these occurrences would waste memory and time. Instead, <code>rustc</code>
allocates each string once and uses indices to refer to the full string each
time it is needed. These indices are 32-bit unsigned integers (in a wrapper
type) and so can be copied and compared efficiently. The process of allocating
a string only once and using references to that string is called "interning".</p>
<p><a href="https://github.com/rust-lang/rust/blob/master/src/librustc_span/symbol.rs#L1041"><code>Symbol</code></a>
is the type representing an interned string:</p>
<div><pre><span></span><span>#[derive(Clone, Copy, PartialEq, ParitialOrd, Hash)]</span><span></span>
<span>pub</span><span> </span><span>struct</span> <span>Symbol</span><span>(</span><span>SymbolIndex</span><span>);</span><span></span>
</pre></div>


<p>Here we can see that the implementation of <code>PartialOrd</code> for <code>Symbol</code> (which
provides the <code>Ord</code>ering of <code>Vec::sort</code> above) derives from the index's <code>Ord</code>ering.
But where does the index come from?</p>
<div><pre><span></span><span>// The `&amp;'static str`s in this type actually point into the arena.</span>
<span>#[derive(Default)]</span><span></span>
<span>pub</span><span> </span><span>struct</span> <span>Interner</span><span> </span><span>{</span><span></span>
<span>    </span><span>arena</span>: <span>DroplessArena</span><span>,</span><span></span>
<span>    </span><span>names</span>: <span>FxHashMap</span><span>&lt;&amp;</span><span>'static</span><span> </span><span>str</span><span>,</span><span> </span><span>Symbol</span><span>&gt;</span><span>,</span><span></span>
<span>    </span><span>strings</span>: <span>Vec</span><span>&lt;&amp;</span><span>'static</span><span> </span><span>str</span><span>&gt;</span><span>,</span><span></span>
<span>}</span><span></span>

<span>impl</span><span> </span><span>Interner</span><span> </span><span>{</span><span></span>
<span>    </span><span>#[inline]</span><span></span>
<span>    </span><span>pub</span><span> </span><span>fn</span> <span>intern</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>,</span><span> </span><span>string</span>: <span>&amp;</span><span>str</span><span>)</span><span> </span>-&gt; <span>Symbol</span><span> </span><span>{</span><span></span>
<span>        </span><span>if</span><span> </span><span>let</span><span> </span><span>Some</span><span>(</span><span>&amp;</span><span>name</span><span>)</span><span> </span><span>=</span><span> </span><span>self</span><span>.</span><span>names</span><span>.</span><span>get</span><span>(</span><span>string</span><span>)</span><span> </span><span>{</span><span></span>
<span>            </span><span>return</span><span> </span><span>name</span><span>;</span><span></span>
<span>        </span><span>}</span><span></span>

<span>        </span><span>let</span><span> </span><span>name</span><span> </span><span>=</span><span> </span><span>Symbol</span>::<span>new</span><span>(</span><span>self</span><span>.</span><span>strings</span><span>.</span><span>len</span><span>()</span><span> </span><span>as</span><span> </span><span>u32</span><span>);</span><span></span>

<span>        </span><span>// `from_utf8_unchecked` is safe since we just allocated a `&amp;str` which is known to be</span>
<span>        </span><span>// UTF-8.</span>
<span>        </span><span>let</span><span> </span><span>string</span>: <span>&amp;</span><span>str</span> <span>=</span><span></span>
<span>            </span><span>unsafe</span><span> </span><span>{</span><span> </span><span>str</span>::<span>from_utf8_unchecked</span><span>(</span><span>self</span><span>.</span><span>arena</span><span>.</span><span>alloc_slice</span><span>(</span><span>string</span><span>.</span><span>as_bytes</span><span>()))</span><span> </span><span>};</span><span></span>
<span>        </span><span>// It is safe to extend the arena allocation to `'static` because we only access</span>
<span>        </span><span>// these while the arena is still alive.</span>
<span>        </span><span>let</span><span> </span><span>string</span>: <span>&amp;</span><span>'static</span><span> </span><span>str</span><span> </span><span>=</span><span> </span><span>unsafe</span><span> </span><span>{</span><span> </span><span>&amp;*</span><span>(</span><span>string</span><span> </span><span>as</span><span> </span><span>*</span><span>const</span><span> </span><span>str</span><span>)</span><span> </span><span>};</span><span></span>
<span>        </span><span>self</span><span>.</span><span>strings</span><span>.</span><span>push</span><span>(</span><span>string</span><span>);</span><span></span>
<span>        </span><span>self</span><span>.</span><span>names</span><span>.</span><span>insert</span><span>(</span><span>string</span><span>,</span><span> </span><span>name</span><span>);</span><span></span>
<span>        </span><span>name</span><span></span>
<span>    </span><span>}</span><span></span>
<span>}</span><span></span>

<span>impl</span><span> </span><span>Symbol</span><span> </span><span>{</span><span></span>
<span>    </span><span>const</span><span> </span><span>fn</span> <span>new</span><span>(</span><span>n</span>: <span>u32</span><span>)</span><span> </span>-&gt; <span>Self</span><span> </span><span>{</span><span></span>
<span>        </span><span>Symbol</span><span>(</span><span>SymbolIndex</span>::<span>from_u32</span><span>(</span><span>n</span><span>))</span><span></span>
<span>    </span><span>}</span><span></span>

<span>    </span><span>/// Maps a string to its interned representation.</span>
<span>    </span><span>pub</span><span> </span><span>fn</span> <span>intern</span><span>(</span><span>string</span>: <span>&amp;</span><span>str</span><span>)</span><span> </span>-&gt; <span>Self</span><span> </span><span>{</span><span></span>
<span>        </span><span>with_interner</span><span>(</span><span>|</span><span>interner</span><span>|</span><span> </span><span>interner</span><span>.</span><span>intern</span><span>(</span><span>string</span><span>))</span><span></span>
<span>    </span><span>}</span><span></span>

<span>    </span><span>/// Access the symbol's chars. This is a slowish operation because it</span>
<span>    </span><span>/// requires locking the symbol interner.</span>
<span>    </span><span>pub</span><span> </span><span>fn</span> <span>with</span><span>&lt;</span><span>F</span>: <span>FnOnce</span><span>(</span><span>&amp;</span><span>str</span><span>)</span><span> </span>-&gt; <span>R</span><span>,</span><span> </span><span>R</span><span>&gt;</span><span>(</span><span>self</span><span>,</span><span> </span><span>f</span>: <span>F</span><span>)</span><span> </span>-&gt; <span>R</span><span> </span><span>{</span><span></span>
<span>        </span><span>with_interner</span><span>(</span><span>|</span><span>interner</span><span>|</span><span> </span><span>f</span><span>(</span><span>interner</span><span>.</span><span>get</span><span>(</span><span>self</span><span>)))</span><span></span>
<span>    </span><span>}</span><span></span>
<span>}</span><span></span>
</pre></div>


<p><code>rustc</code> interns strings using <code>Interner::intern</code>, which
returns a <code>Symbol</code>. References to the interned strings are stored in a
<code>Vec</code>tor and the <code>Symbol</code> contains the index of the string reference in that
<code>Vec</code>tor. Therefore, the Symbol can look up its string by indexing into the
<code>strings</code> vector and following the reference (pointer) to the actual string
(which is allocated in the <code>arena</code>).</p>
<p>For example, if the strings <code>"a"</code>, <code>"b"</code> and <code>"c"</code> are interned, then (ignoring
the referencing), the <code>Interner</code>'s <code>Vec</code> will look like <code>["a", "b", "c"]</code>. If
instead we interned <code>"b"</code>, <code>"a"</code>, <code>"b"</code> and <code>"c"</code>; the <code>Vec</code> will look like
<code>["b", "a", "c"]</code> because the second attempt to intern <code>"b"</code> finds that <code>"b"</code> is
already interned and so just returns the index of the existing copy of <code>"b"</code>.
Carrying on with this second example, imagine the following:</p>
<div><pre><span></span><span>let</span><span> </span><span>mischief</span><span> </span><span>=</span><span> </span><span>Symbol</span>::<span>intern</span><span>(</span><span>"b"</span><span>);</span><span></span>
<span>let</span><span> </span><span>a</span><span> </span><span>=</span><span> </span><span>Symbol</span>::<span>intern</span><span>(</span><span>"a"</span><span>);</span><span></span>
<span>let</span><span> </span><span>b</span><span> </span><span>=</span><span> </span><span>Symbol</span>::<span>intern</span><span>(</span><span>"b"</span><span>);</span><span></span>
<span>let</span><span> </span><span>c</span><span> </span><span>=</span><span> </span><span>Symbol</span>::<span>intern</span><span>(</span><span>"c"</span><span>);</span><span></span>

<span>let</span><span> </span><span>mut</span><span> </span><span>v</span><span> </span><span>=</span><span> </span><span>vec</span><span>!</span><span>[</span><span>c</span><span>,</span><span> </span><span>b</span><span>,</span><span> </span><span>a</span><span>];</span><span></span>
<span>v</span><span>.</span><span>sort</span><span>();</span><span></span>
</pre></div>


<p>While we might expect <code>v</code> to end up equal to <code>[a, b, c]</code>, <code>v</code> is actually sorted
to equal <code>[b, a, c]</code> because <code>Symbol</code>s are sorted by their indices not by the
strings they point to. <code>b</code> received the lowest index because it was interned
first. This semantic can be useful because the index ordering is faster than
looking up the full strings and comparing them; and ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.codethink.co.uk/articles/2020/fixing-rusts-test-suite-on-risc-v/">https://www.codethink.co.uk/articles/2020/fixing-rusts-test-suite-on-risc-v/</a></em></p>]]>
            </description>
            <link>https://www.codethink.co.uk/articles/2020/fixing-rusts-test-suite-on-risc-v/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23718634</guid>
            <pubDate>Thu, 02 Jul 2020 22:04:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The BEAM Book (2017)]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 15 (<a href="https://news.ycombinator.com/item?id=23718278">thread link</a>) | @hazbo
<br/>
July 2, 2020 | https://blog.stenmans.org/theBeamBook/ | <a href="https://web.archive.org/web/*/https://blog.stenmans.org/theBeamBook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Redbug is safe to be used in production, thanks to a self-protecting
mechanism against overload, which kills the tool in case too many
tracing messages are sent, preventing the Erlang node to become
overloaded. Let‚Äôs see it in action:</p><div>
<div>
<pre><code data-lang="erlang"><span>$ </span><span>erl</span>
<span>Erlang</span><span>/</span><span>OTP</span> <span>19</span> <span>[</span><span>erts</span><span>-</span><span>8</span><span>.</span><span>2</span><span>]</span> <span>[...]</span>

<span>Eshell</span> <span>V8</span><span>.</span><span>2</span> <span>(</span><span>abort</span> <span>with</span> <span>^</span><span>G</span><span>)</span>
<span>1</span><span>&gt;</span> <span>l</span><span>(</span><span>redbug</span><span>).</span> <i data-value="1"></i><b>(1)</b>
<span>{</span><span>module</span><span>,</span><span>redbug</span><span>}</span>
<span>2</span><span>&gt;</span> <span>redbug</span><span>:</span><span>start</span><span>(</span><span>"lists:sort/1"</span><span>).</span> <i data-value="2"></i><b>(2)</b>
<span>{</span><span>30</span><span>,</span><span>1</span><span>}</span>
<span>3</span><span>&gt;</span> <span>lists</span><span>:</span><span>sort</span><span>([</span><span>3</span><span>,</span><span>2</span><span>,</span><span>1</span><span>]).</span>
<span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>]</span>

<span>% 15:20:20 &lt;0.31.0&gt;({erlang,apply,2}) <i data-value="3"></i><b>(3)</b>
% lists:sort([3,2,1])
</span><span>redbug</span> <span>done</span><span>,</span> <span>timeout</span> <span>-</span> <span>1</span> <i data-value="4"></i><b>(4)</b></code></pre>
</div>
</div><p>Let‚Äôs now look at the actual message produced by redbug. By default
messages are printed to the standard output, but it‚Äôs also possible to
dump them to file:</p><div>
<div>
<pre><code data-lang="erlang"><span>% 15:20:20 &lt;0.31.0&gt;({erlang,apply,2})
</span><span>%</span> <span>lists</span><span>:</span><span>sort</span><span>([</span><span>3</span><span>,</span><span>2</span><span>,</span><span>1</span><span>])</span></code></pre>
</div>
</div><p>Depending on the version of redbug you are using, you may get a
slightly different message. In this case, the message is split across
two lines. The first line contains a <strong>timestamp</strong>, the <strong>Process Identifier</strong>
(or <em>PID</em>) of the Erlang process which invoked the function and the
<strong>caller</strong> function. The second line contains the function called,
including the input arguments. Both lines are prepended with a <code>%</code>,
which reminds us of the syntax for Erlang comments.</p><p>We can also ask Redbug to produce an extra message for the return
value. This is achieved using the following syntax:</p><div>
<div>
<pre><code data-lang="erlang"><span>4</span><span>&gt;</span> <span>redbug</span><span>:</span><span>start</span><span>(</span><span>"lists:sort/1-&gt;return"</span><span>).</span>
<span>{</span><span>30</span><span>,</span><span>1</span><span>}</span></code></pre>
</div>
</div><p>Let‚Äôs invoke the <code>lists:sort/1</code> function again. This time the output
from redbug is slightly different.</p><div>
<div>
<pre><code data-lang="erlang"><span>5</span><span>&gt;</span> <span>lists</span><span>:</span><span>sort</span><span>([</span><span>3</span><span>,</span><span>2</span><span>,</span><span>1</span><span>]).</span>
<span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>]</span>

<span>% 15:35:52 &lt;0.31.0&gt;({erlang,apply,2})
% lists:sort([3,2,1])
</span>
<span>% 15:35:52 &lt;0.31.0&gt;({erlang,apply,2})
% lists:sort/1 -&gt; [1,2,3]
</span><span>redbug</span> <span>done</span><span>,</span> <span>timeout</span> <span>-</span> <span>1</span></code></pre>
</div>
</div><p>In this case two messages are produced, one when entering the function
and one when leaving the same function.</p><p>When dealing with real code, trace messages can be complex and
therefore hardly readable. Let‚Äôs see what happens if we try to trace
the sorting of a list containing 10.000 elements.</p><div>
<div>
<pre><code data-lang="erlang"><span>6</span><span>&gt;</span> <span>lists</span><span>:</span><span>sort</span><span>(</span><span>lists</span><span>:</span><span>seq</span><span>(</span><span>10000</span><span>,</span> <span>1</span><span>,</span> <span>-</span><span>1</span><span>)).</span>
<span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>,</span><span>4</span><span>,</span><span>5</span><span>,</span><span>6</span><span>,</span><span>7</span><span>,</span><span>8</span><span>,</span><span>9</span><span>,</span><span>10</span><span>,</span><span>11</span><span>,</span><span>12</span><span>,</span><span>13</span><span>,</span><span>14</span><span>,</span><span>15</span><span>,</span><span>16</span><span>,</span><span>17</span><span>,</span><span>18</span><span>,</span><span>19</span><span>,</span><span>20</span><span>,</span><span>21</span><span>,</span><span>22</span><span>,</span>
<span>23</span><span>,</span><span>24</span><span>,</span><span>25</span><span>,</span><span>26</span><span>,</span><span>27</span><span>,</span><span>28</span><span>,</span><span>29</span><span>|...]</span>

<span>% 15:48:42.208 &lt;0.77.0&gt;({erlang,apply,2})
% lists:sort([10000,9999,9998,9997,9996,9995,9994,9993,9992,9991,9990,9989,9988,9987,9986,
% 9985,9984,9983,9982,9981,9980,9979,9978,9977,9976,9975,9974,9973,9972,9971,
% 9970,9969,9968,9967,9966,9965,9964,9963,9962,9961,9960,9959,9958,9957,9956,
% 9955,9954,9953,9952,9951,9950,9949,9948,9947,9946,9945,9944,9943,9942,9941,
% 9940,9939,9938,9937,9936,9935,9934,9933,9932,9931,9930,9929,9928,9927,9926,
% 9925,9924,9923,9922,9921,9920,9919,9918,9917,9916,9915,9914,9913,9912,9911,
% [...]
% 84,83,82,81,80,79,78,77,76,75,74,73,72,71,70,69,68,67,66,65,64,63,62,61,60,
% 59,58,57,56,55,54,53,52,51,50,49,48,47,46,45,44,43,42,41,40,39,38,37,36,35,
% 34,33,32,31,30,29,28,27,26,25,24,23,22,21,20,19,18,17,16,15,14,13,12,11,10,9,
% 8,7,6,5,4,3,2,1])
</span>
<span>% 15:48:42.210 &lt;0.77.0&gt;({erlang,apply,2}) lists:sort/1 -&gt;
% [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,
% 23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,
% 42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,
% 61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,
% 80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,
% 99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,
% [...]
% 9951,9952,9953,9954,9955,9956,9957,9958,9959,9960,9961,
% 9962,9963,9964,9965,9966,9967,9968,9969,9970,9971,9972,
% 9973,9974,9975,9976,9977,9978,9979,9980,9981,9982,9983,
% 9984,9985,9986,9987,9988,9989,9990,9991,9992,9993,9994,
% 9995,9996,9997,9998,9999,10000]
</span><span>redbug</span> <span>done</span><span>,</span> <span>timeout</span> <span>-</span> <span>1</span></code></pre>
</div>
</div><p>Most of the output has been truncated here, but you should get the
idea. To improve things, we can use a couple of redbug options.  The
option <code>{arity, true}</code> instructs redbug to only display the number of
input arguments for the given function, instead of their actual
value. The <code>{print_return, false}</code> option tells Redbug not to display
the return value of the function call, and to display a <code>‚Ä¶‚Äã</code>  symbol,
instead. Let‚Äôs see these options in action.</p><div>
<div>
<pre><code data-lang="erlang"><span>7</span><span>&gt;</span> <span>redbug</span><span>:</span><span>start</span><span>(</span><span>"lists:sort/1-&gt;return"</span><span>,</span> <span>[{</span><span>arity</span><span>,</span> <span>true</span><span>},</span> <span>{</span><span>print_return</span><span>,</span> <span>false</span><span>}]).</span>
<span>{</span><span>30</span><span>,</span><span>1</span><span>}</span>

<span>8</span><span>&gt;</span> <span>lists</span><span>:</span><span>sort</span><span>(</span><span>lists</span><span>:</span><span>seq</span><span>(</span><span>10000</span><span>,</span> <span>1</span><span>,</span> <span>-</span><span>1</span><span>)).</span>
<span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>,</span><span>4</span><span>,</span><span>5</span><span>,</span><span>6</span><span>,</span><span>7</span><span>,</span><span>8</span><span>,</span><span>9</span><span>,</span><span>10</span><span>,</span><span>11</span><span>,</span><span>12</span><span>,</span><span>13</span><span>,</span><span>14</span><span>,</span><span>15</span><span>,</span><span>16</span><span>,</span><span>17</span><span>,</span><span>18</span><span>,</span><span>19</span><span>,</span><span>20</span><span>,</span><span>21</span><span>,</span><span>22</span><span>,</span>
<span>23</span><span>,</span><span>24</span><span>,</span><span>25</span><span>,</span><span>26</span><span>,</span><span>27</span><span>,</span><span>28</span><span>,</span><span>29</span><span>|...]</span>

<span>% 15:55:32 &lt;0.77.0&gt;({erlang,apply,2})
% lists:sort/1
</span>
<span>% 15:55:32 &lt;0.77.0&gt;({erlang,apply,2})
% lists:sort/1 -&gt; '...'
</span><span>redbug</span> <span>done</span><span>,</span> <span>timeout</span> <span>-</span> <span>1</span></code></pre>
</div>
</div><p>By default, redbug stops after 15 seconds or after 10 messages are
received. Those values are a safe default, but they are rarely
enough. You can bump those limits by using the <code>time</code> and <code>msgs</code>
options. <code>time</code> is expressed in milliseconds.</p><div>
<div>
<pre><code data-lang="erlang"><span>9</span><span>&gt;</span> <span>redbug</span><span>:</span><span>start</span><span>(</span><span>"lists:sort/1-&gt;return"</span><span>,</span> <span>[{</span><span>arity</span><span>,</span> <span>true</span><span>},</span> <span>{</span><span>print_return</span><span>,</span> <span>false</span><span>},</span> <span>{</span><span>time</span><span>,</span> <span>60</span> <span>*</span> <span>1000</span><span>},</span> <span>{</span><span>msgs</span><span>,</span> <span>100</span><span>}]).</span>
<span>{</span><span>30</span><span>,</span><span>1</span><span>}</span></code></pre>
</div>
</div><p>We can also activate redbug for several function calls
simultaneously. Let‚Äôs enable tracing for both functions <code>lists:sort/1</code>
and <code>lists:sort_1/3</code> (an internal function used by the former):</p><div>
<div>
<pre><code data-lang="erlang"><span>10</span><span>&gt;</span> <span>redbug</span><span>:</span><span>start</span><span>([</span><span>"lists:sort/1-&gt;return"</span><span>,</span> <span>"lists:sort_1/3-&gt;return"</span><span>]).</span>
<span>{</span><span>30</span><span>,</span><span>2</span><span>}</span>

<span>11</span><span>&gt;</span> <span>lists</span><span>:</span><span>sort</span><span>([</span><span>4</span><span>,</span><span>4</span><span>,</span><span>2</span><span>,</span><span>1</span><span>]).</span>
<span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>4</span><span>,</span><span>4</span><span>]</span>

<span>% 18:39:26 &lt;0.32.0&gt;({erlang,apply,2})
% lists:sort([4,4,2,1])
</span>
<span>% 18:39:26 &lt;0.32.0&gt;({erlang,apply,2})
% lists:sort_1(4, [2,1], [4])
</span>
<span>% 18:39:26 &lt;0.32.0&gt;({erlang,apply,2})
% lists:sort_1/3 -&gt; [1,2,4,4]
</span>
<span>% 18:39:26 &lt;0.32.0&gt;({erlang,apply,2})
% lists:sort/1 -&gt; [1,2,4,4]
</span><span>redbug</span> <span>done</span><span>,</span> <span>timeout</span> <span>-</span> <span>2</span></code></pre>
</div>
</div><p>Last but not least, redbug offers the ability to only display results
for matching input arguments. This is when the syntax looks a bit like
magic.</p><div>
<div>
<pre><code data-lang="erlang"><span>12</span><span>&gt;</span> <span>redbug</span><span>:</span><span>start</span><span>([</span><span>"lists:sort([1,2,5])-&gt;return"</span><span>]).</span>
<span>{</span><span>30</span><span>,</span><span>1</span><span>}</span>

<span>13</span><span>&gt;</span> <span>lists</span><span>:</span><span>sort</span><span>([</span><span>4</span><span>,</span><span>4</span><span>,</span><span>2</span><span>,</span><span>1</span><span>]).</span>
<span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>4</span><span>,</span><span>4</span><span>]</span>

<span>14</span><span>&gt;</span> <span>lists</span><span>:</span><span>sort</span><span>([</span><span>1</span><span>,</span><span>2</span><span>,</span><span>5</span><span>]).</span>
<span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>5</span><span>]</span>

<span>% 18:45:27 &lt;0.32.0&gt;({erlang,apply,2})
% lists:sort([1,2,5])
</span>
<span>% 18:45:27 &lt;0.32.0&gt;({erlang,apply,2})
% lists:sort/1 -&gt; [1,2,5]
</span><span>redbug</span> <span>done</span><span>,</span> <span>timeout</span> <span>-</span> <span>1</span></code></pre>
</div>
</div><p>In the above example, we are telling redbug that we are only
interested in function calls to the <code>lists:sort/1</code> function when the
input arguments is the list <code>[1,2,5]</code>. This allows us to remove a huge
amount of noise in the case our target function is used by many actors
at the same time and we are only interested in a specific use case.
Oh, and don‚Äôt forget that you can use the underscore as a wildcard:</p><div>
<div>
<pre><code data-lang="erlang"><span>15</span><span>&gt;</span> <span>redbug</span><span>:</span><span>start</span><span>([</span><span>"lists:sort([1,_,5])-&gt;return"</span><span>]).</span>  <span>{</span><span>30</span><span>,</span><span>1</span><span>}</span>

<span>16</span><span>&gt;</span> <span>lists</span><span>:</span><span>sort</span><span>([</span><span>1</span><span>,</span><span>2</span><span>,</span><span>5</span><span>]).</span>  <span>[</span><span>1</span><span>,</span><span>2</span><span>,</span><span>5</span><span>]</span>

<span>% 18:49:07 &lt;0.32.0&gt;({erlang,apply,2}) lists:sort([1,2,5])
</span>
<span>% 18:49:07 &lt;0.32.0&gt;({erlang,apply,2}) lists:sort/1 -&gt; [1,2,5]
</span>
<span>17</span><span>&gt;</span> <span>lists</span><span>:</span><span>sort</span><span>([</span><span>1</span><span>,</span><span>4</span><span>,</span><span>5</span><span>]).</span>  <span>[</span><span>1</span><span>,</span><span>4</span><span>,</span><span>5</span><span>]</span>

<span>% 18:49:09 &lt;0.32.0&gt;({erlang,apply,2}) lists:sort([1,4,5])
</span>
<span>% 18:49:09 &lt;0.32.0&gt;({erlang,apply,2}) lists:sort/1 -&gt; [1,4,5] redbug
</span><span>%</span> <span>done</span><span>,</span> <span>timeout</span> <span>-</span> <span>2</span></code></pre>
</div>
</div><p>This section does not pretend to be a comprehensive guide to redbug,
but it should be enough to get you going. To get a full list of the
available options for redbug, you can ask the tool itself:</p></div>]]>
            </description>
            <link>https://blog.stenmans.org/theBeamBook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23718278</guid>
            <pubDate>Thu, 02 Jul 2020 21:30:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My First Month as a Contractor]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23717963">thread link</a>) | @SarfasCodes
<br/>
July 2, 2020 | https://sarfas.codes/blog/from-employee-to-contractor-my-experience | <a href="https://web.archive.org/web/*/https://sarfas.codes/blog/from-employee-to-contractor-my-experience">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div v-pre="">
        <p>I've been offline (blog wise) for nearly 3 months now - <a href="https://sarfas.codes/blog/laravel-route-model-binding/">in fact my last post was on April 12th!</a>.</p>
<p>A lot of that has come down to me moving house, COVID-19 messing with my working schedule, and some other things I've been working out in the background. The main thing that's changed here is; <strong>I'm now self-employed</strong></p>

<p>Having taken on some large projects at my main job, I had to cut back on my side-projects and contracting work in the evenings. This was to keep me from burning out as I was working too much.</p>
<p>Fast forward to Coronavirus days, and I found myself missing the contracting work. I loved working from home, and being able to structure the freelance hours around my own schedule. So I decided I was going to take this on full time, and pack in my dayjob.</p>
<p>I left my last PAYE ("normal job") role 3 weeks ago now, and have been working full time on <a href="https://cleveregg.io/">CleverEgg Digital</a> with a close group of clients.</p>

<p>For me, the main positive is controlling my own hours.</p>
<p>If I want to take a day off - I just do it. Yes, I'm not earning money that day, so I need to catch it up; but the option is there if I need it. There's no HR process, no holiday bookings, nothing. I take a day, when I like.</p>
<p>The hours. I'm most efficient after midday. Due to this, most of my contract work is done between the hours of 11am and 7pm. This gives me the freedom to do whatever I like in the mornings, and still have a late night if I like - I don't have to get up for work early ‚è∞</p>

<p><strong>Time Management</strong></p>
<p>If you're considering doing this, you need to be your own worst critic and be strict on your time. Time is literally money in the contracting world.</p>
<p>You don't have a boss staring down you 24/7. Or checking up on your progress everyday. If you wanna earn some money, do it off your own back.</p>
<p>Once you get a few clients, the thought of invoices being settled will be a good motivator - so that's always a bonus.</p>
<p>I've found that working for yourself means you do need to know a little more than just "your trade". Here's a few I can mention off the top of my head;</p>
<ul>
<li>Basic Accounting,</li>
<li>Fundamentals of understanding Contracts, Terms, and negotiation thereof,</li>
<li>Marketing &amp; pricing</li>
</ul>
<p>I'm a developer by trade, yet I've had to use all of the above 3 in the last 24 hours. Naturally I could pay someone to do all of them; but I'm not in any financial position to do so.</p>

<p>I should have done this sooner! I'm far happier in my work, as well as in a better position with my mental health.</p>
<p>I thought I'd be working longer hours to chase the extra money - given I can do so. However, I actually work less than I did with my "standard job"; and I'm no worse off financially.</p>

<p>Freelance/Contracting isn't for everyone. Clients are very hard to come by, especially in today's economy and situations. I've been extremely lucky in that I've found a handful of clients who are well backed financially, and are unaffected by the pandemic.</p>
<p>I cannot express how much I owe of this to the <a href="https://laravelphp.uk/">LaravelUK</a> community. Both in sourcing/sharing clients, and giving me support and advice for the last 2 years whilst I ponder over this decision.</p>
<p>If you do take the plunge and go into this chaos, here's a few tips;</p>
<ul>
<li>Find a community of like-minded people within your industry</li>
<li>Ensure that you have enough money that you can go without work for a bit
<ul>
<li><em>You won't be getting sick pay, or Annual Leave</em></li>
</ul></li>
<li>Don't under charge. Cheaper clients are cheap for a reason. Those that want your time, respect your trade, and want to look after you will pay for it.</li>
<li>Be confident in your work; but not complacent / arrogant</li>
<li><strong>Enjoy it. Being your own boss is awesome!</strong></li>
</ul>    </div></div>]]>
            </description>
            <link>https://sarfas.codes/blog/from-employee-to-contractor-my-experience</link>
            <guid isPermaLink="false">hacker-news-small-sites-23717963</guid>
            <pubDate>Thu, 02 Jul 2020 20:55:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Write Book Reviews?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23717878">thread link</a>) | @mlerner
<br/>
July 2, 2020 | https://www.micahlerner.com/2020/06/13/thoughts-on-reviewing-books.html | <a href="https://web.archive.org/web/*/https://www.micahlerner.com/2020/06/13/thoughts-on-reviewing-books.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    	
		<blockquote>
  <p>Discussion on <a href="https://news.ycombinator.com/item?id=23717878">Hacker News</a></p>
</blockquote>

<p>With the coronavirus shortening my work commute into a walk down the hall, I‚Äôve been able to read more in the mornings. Now that I‚Äôve been gifted more time in the day, I am finishing about a book a week (I‚Äôm privileged to have at least an hour a day for reading, and that time quickly adds up). It has been amazing to return to my teenage reading habits when my parents feigned exasperation at my perpetual nose-in-book lifestyle - ‚Äúis that kid reading again?‚Äù. In these tumultuous times, books have also been a welcome respite (well-documented positive effects of reading on mental well-being probably don‚Äôt hurt).</p>

<p>Reading more, I couldn‚Äôt help but notice book reviews everywhere. Inspired, I wrote <a href="https://www.micahlerner.com/books/2020-05-30-solaris.html">a</a> <a href="https://www.micahlerner.com/books/2020-05-21-the-man-who-solved-the-market-how-jim-simons-launched-the-quant-revolution.html">few</a>, but found myself asking what I wanted to get out of the creative energy I was channeling into them (after all, I‚Äôm not a professional book-review-writer and my time is limited). In order to think clearly about the topic, I sought inspiration in the work of other writers.</p>

<h2 id="how-do-other-writers-approach-book-reviews">How do other writers approach book reviews?</h2>

<p>With the question ‚Äúhow should I write about what I‚Äôve been reading?‚Äù in mind, I started compiling examples of book reviews and categorizing them by style:</p>

<ul>
  <li><strong>Persuasive reviews</strong>: I bucket reviews <a href="https://www.nytimes.com/2019/09/16/books/review-night-boat-tangier-kevin-barry.html">like those</a> from the NYTimes into this category. Even though the author of the inevitably informs you about the book‚Äôs content, they‚Äôre advocating that their readers purchase the book (or don‚Äôt purchase the book in some case). Frequently the review also gives a background on the book‚Äôs literary lineage.</li>
  <li><strong>Summary reviews</strong>: Products like <a href="https://www.blinkist.com/en/nc/library/">Blinkist</a> or <a href="https://www.nateliason.com/notes/antifragile">Nat Eliason‚Äôs book reviews</a> fall into this category. I think there‚Äôs a place for summarization-style reviews of non-fiction <a href="https://commoncog.com/blog/the-3-kinds-of-non-fiction-book/#branchbooks">‚Äúbranch books‚Äù</a> - if one were to imagine knowledge as a tree, ‚Äúbranch books‚Äù typically cover a single topic on the edge of the tree, rather than attempting to be a wide-reaching, foundational tome of a subject area.</li>
  <li><strong>Thematic reviews</strong>: The New York Review of Books <a href="https://www.nybooks.com/articles/2020/07/02/what-is-college-worth/">often</a> <a href="https://www.nybooks.com/articles/2019/11/07/heritage-of-evil/">combines</a> discussion of several books into a general overview of a topic. This approach is well-suited to academics or subject-matter experts who have the time (and intellectual stamina!) to read a variety of books connected to a common thread.</li>
  <li><strong>Deep-dive reviews:</strong> Slate Star Codex was (while I was writing this, the takedown of the blog happened) an <a href="https://slatestarcodex.com/2020/03/17/book-review-hoover/">example</a> of this category, with <a href="https://slatestarcodex.com/2020/06/01/book-review-origin-of-consciousness-in-the-breakdown-of-the-bicameral-mind/">opinionated book reviews</a> that form connections between the author‚Äôs well-formed thoughts and the subject matter at hand. They‚Äôre often witty and summarize the content as needed while weaving it into a story.</li>
</ul>

<p>With a general overview of possible styles loaded into my memory, I switched to thinking about what I was hoping to get out of the process.</p>

<h2 id="what-do-i-want-to-get-out-of-book-reviews">What do I want to get out of book reviews?</h2>

<p>After consuming diverse, different review styles, I realized that I could reduce my motivation for reviewing books to two goals: retention of what I learned (in the case of non-fiction) books and writing something other people enjoy reading.</p>

<p>Thankfully there is a large body of knowledge about how to accomplish the first goal using <a href="https://www.gwern.net/Spaced-repetition">spaced repetition</a>.</p>

<p>Spaced repetition is also called SRS, and there are many sources about how to use the system to increase retention:</p>
<ul>
  <li><a href="https://robertheaton.com/">Rob Heaton‚Äôs</a> blog post on <a href="https://robertheaton.com/2018/06/25/how-to-read/">How to read</a></li>
  <li><a href="http://augmentingcognition.com/ltm.html">Augmenting long term memory</a> discusses using Anki for deep reviews</li>
  <li>A (sic) Hahvahd Business Review <a href="https://hbr.org/2016/02/how-to-read-a-book-a-week">article</a> about retention and understanding</li>
</ul>

<p>Unfortunately, making book reviews enjoyable for other people is a more difficult problem, and the best path is being inspired by others. If you find a great review <a href="https://www.micahlerner.com/2020/06/13/micah.lerner@hey.com">send it my way</a>!</p>

        <!-- Begin Mailchimp Signup Form -->





<section id="email-form">
  
  
</section>

	</div></div>]]>
            </description>
            <link>https://www.micahlerner.com/2020/06/13/thoughts-on-reviewing-books.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23717878</guid>
            <pubDate>Thu, 02 Jul 2020 20:49:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React Core team's discussion on rewriting React internals in Rust]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23717871">thread link</a>) | @DaniAkash
<br/>
July 2, 2020 | https://www.twitch.tv/videos/667925289?t=00h39m04s | <a href="https://web.archive.org/web/*/https://www.twitch.tv/videos/667925289?t=00h39m04s">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.twitch.tv/videos/667925289?t=00h39m04s</link>
            <guid isPermaLink="false">hacker-news-small-sites-23717871</guid>
            <pubDate>Thu, 02 Jul 2020 20:48:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Illusion of Statelessness]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23717833">thread link</a>) | @nfrankel
<br/>
July 2, 2020 | https://blog.frankel.ch/illusion-statelessness/ | <a href="https://web.archive.org/web/*/https://blog.frankel.ch/illusion-statelessness/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main" role="main"> <div> <article itemscope="" itemtype="http://schema.org/BlogPosting"> <meta itemprop="mainEntityOfPage" content="//illusion-statelessness/"> <meta itemprop="description" content="">  <figure itemscope="" itemprop="image" itemtype="http://schema.org/ImageObject"> <meta itemprop="url" content="https://blog.frankel.ch/assets/resources/illusion-statelessness/water-nature-horizon-sky-air-lake-1327741.jpg"> <meta itemprop="height" content="871"> <meta itemprop="width" content="1280"> </figure> <section> <div itemprop="articleBody"> <p>Some libraries, frameworks, components, and architectures either encourage statelessness, or make it a requirement. While statelessness has a lot of benefits, it‚Äôs unfortunately rarely possible in the real world. In this post, I‚Äôd like to detail this stance of mine a bit.</p> <div> <h2 id="state-in-functional-programming">State in Functional Programming</h2> <div> <p>Functional Programming is based on a set of principles. Among those principles are <em>pure</em> functions:</p> <div> <blockquote> <p>A pure function is a function that has the following properties:</p> <ol><li><span>Its return value is the same for the same arguments</span></li><li><span>Its evaluation has no side effects</span></li></ol> </blockquote>  </div> <p>For example, the following function is <em>pure</em>:</p> <div> <div> <pre><code data-lang="java"><span>int</span> <span>timesTwo</span><span>(</span><span>int</span> <span>value</span><span>)</span> <span>{</span>
    <span>return</span> <span>value</span> <span>*</span> <span>2</span><span>;</span>
<span>}</span></code></pre> </div> </div> <p>A <em>pure</em> function allows <em>referential transparency</em>: the swapping of then function with its return value. With that in mind, the introduction of state may defeat the previous definition. For example, the following breaks <em>referential transparency</em>:</p> <div> <div> <pre><code data-lang="java"><span>class</span> <span>Multiplier</span> <span>{</span>

  <span>private</span> <span>int</span> <span>factor</span> <span>=</span> <span>1</span><span>;</span>

  <span>public</span> <span>int</span> <span>times</span><span>(</span><span>int</span> <span>value</span><span>)</span> <span>{</span>
    <span>return</span> <span>value</span> <span>*</span> <span>factor</span><span>;</span>
  <span>}</span>

  <span>public</span> <span>void</span> <span>setFactor</span><span>(</span><span>int</span> <span>factor</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>factor</span> <span>=</span> <span>factor</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre> </div> </div> <p>Successive calls to <code>times()</code> with the same argument may return different results because the <code>setFactor()</code> method may have changed the <code>factor</code> attribute‚Äôs value between calls. Interestingly enough, a method can conform to the <em>referential transparency</em> property, but still break the no side-effects property. Here‚Äôs an example:</p> <div> <div> <pre><code data-lang="java"><span>class</span> <span>MemoizedMultiplier</span> <span>{</span>

  <span>private</span> <span>final</span> <span>int</span> <span>factor</span><span>;</span>
  <span>private</span> <span>final</span> <span>Map</span><span>&lt;</span><span>Integer</span><span>,</span> <span>Integer</span><span>&gt;</span> <span>results</span> <span>=</span> <span>new</span> <span>HashMap</span><span>&lt;&gt;();</span>

  <span>public</span> <span>MemoizedMultiplier</span><span>(</span><span>int</span> <span>factor</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>factor</span> <span>=</span> <span>factor</span><span>;</span>
  <span>}</span>

  <span>public</span> <span>int</span> <span>times</span><span>(</span><span>int</span> <span>value</span><span>)</span> <span>{</span>
    <span>int</span> <span>cache</span> <span>=</span> <span>results</span><span>.</span><span>get</span><span>(</span><span>value</span><span>);</span>
    <span>if</span> <span>(</span><span>cache</span> <span>==</span> <span>null</span><span>)</span> <span>{</span>
      <span>int</span> <span>result</span> <span>=</span> <span>value</span> <span>*</span> <span>factor</span><span>;</span>
      <span>results</span><span>.</span><span>put</span><span>(</span><span>value</span><span>,</span> <span>result</span><span>);</span>
      <span>return</span> <span>result</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>return</span> <span>cache</span><span>;</span>
    <span>}</span>
  <span>}</span>
<span>}</span></code></pre> </div> </div> <p>The above implementation is <em>immutable</em>: state is set once when the object is created, and cannot be changed afterwards. Successive calls with the same argument will return the same result over and over. Yet, the method has side-effects.</p> <p>To keep most of the system <em>pure</em>, practitioners of <abbr title="Functional Programming">FP</abbr> push non-pure functions to the system boundaries.</p> </div> </div> <div> <h2 id="state-in-web-architectures">State in web architectures</h2> <div> <p>The HTTP protocol is stateless. The benefit is obvious: when a request hits the load-balancer, the latter can forward it to any web server that belongs to the cluster, and that hosts the requested resource. This allows for <a href="https://en.wikipedia.org/wiki/Scalability#Horizontal_or_Scale_Out" target="_blank" rel="noopener">horizontal scaling</a>. When the load increases, it‚Äôs straightforward to add more nodes until the performance becomes acceptable again. It works like a charm, until the requirement goes beyond just displaying static pages.</p> <p>In reality, a lot of use-cases require different HTTP requests to be recognized as originating from the same "session": authentication, e-commerce caddies, etc. <a href="https://en.wikipedia.org/wiki/HTTP_cookie" target="_blank" rel="noopener">Cookies</a> are the browsers' answer to those requirements.</p> <p>Servers do offer a generic storage mechanism, keyed to a session identifier. On the first request, the server adds a cookie with a specific session id to the response. Subsequent requests will use this cookie, so the server associates the request with the same session. Different servers have different cookies: <code>JSESSIONID</code> for Java EE, <code>PHPSESSID</code> for PHP, <code>ASPSESSIONID</code> for ASP, etc.</p> <p>Data stored on a specific cluster node won‚Äôt obviously be accessible to requests forwarded to other nodes, even when they originate from the same session. To avoid that, sessions needs to be "pinned down" on the node that received the first request for that session. In standard web architectures, this is one of the responsibility of the load-balancer: it keeps the association between a session id and the node in memory. This feature is known as <em>sticky sessions</em>.</p> <p>However, nodes will sometimes fail. If session data is on that node, it will be lost. To compensate for that, data needs to be replicated on other nodes. That capability is known as <em>session replication</em>.</p> <p>Sticky sessions, and even more so sessions replication, make architectures stateful.</p> </div> </div> <div> <h2 id="state-in-rest-architectures">State in REST architectures</h2> <div>  <ol><li><span>Client-server architecture</span></li><li><span>Statelessness</span></li><li><span>Cacheability</span></li><li><span>Layered system</span></li><li><span>Uniform interface</span></li></ol> <p>Note that #2 explicitly defines <a href="https://en.wikipedia.org/wiki/Representational_state_transfer#Statelessness" target="_blank" rel="noopener">statelessness</a> as a requirement of the REST architecture. However, the definition of it in this context is not the absence of state, but that state shouldn‚Äôt be stored server-side.</p> <div> <blockquote> <p>The client-server communication is constrained by no client context being stored on the server between requests. Each request from any client contains all the information necessary to service the request, and the session state is held in the client. The session state can be transferred by the server to another service such as a database to maintain a persistent state for a period and allow authentication.</p> </blockquote> </div> <p>The quote above defines two options to store data:</p> <div> <dl> <dt>In a database</dt> <dd> <p>Storing data is the <em>raison d‚Äô√™tre</em> for databases, whether SQL or NoSQL. Hence, it seems like an obvious choice to store state. However, this generally implies <em>disk-based persistence</em>. In turn, this means increased access time to data, 2 or 3 orders of magnitude higher than for in-memory access.</p> </dd> <dt>On the client</dt> <dd> <p>Another option is to store data as cookies. This approach raises some interesting challenges on its own: the first one is about security. If credentials-related data is stored client-side, then how can the server guarantees they are genuine? The currently agreed-upon answer is <a href="https://jwt.io/" target="_blank" rel="noopener">JSON Web Tokens</a>. One just needs to remember it makes the flow more complex, and slower, because validation still needs to occur server-side, prior to any further request handling.</p> <p>The second challenge revolves around data serialization. Simple types <em>e.g.</em> <code>int</code> or <code>String</code> can easily be set in cookie values, but what about more complex types? It would require an serialization/deserialization mechanism: when the request is received, cookies should be deserialized into objects, and when the response is sent, objects should be serialized back into a compatible format <em>e.g.</em> JSON.</p> <p>The complete setup is worth a dedicated post, but here are some points that deserve some attention:</p> <ul><li><span>How to manage serialization limitations?</span></li><li><span>The need to automate the serialization/deserialization flow</span></li><li><span>Configure the entities to be serialized, and decide which JSON library to use</span></li></ul> </dd> </dl> </div> </div> </div> <div> <h2 id="state-in-kubernetes">State in Kubernetes</h2> <div> <p>First, one should remember that Kubernetes was originally focused on stateless workloads. For example, <code>StatefulSet</code> was introduced in version 1.5 as a beta feature. Furthermore, rolling upgrades of the <code>Deployment</code> object handle pods only. If containerized applications use a database, and software require different schema versions, you‚Äôre on your own: while possible, <a href="https://www.youtube.com/watch?v=RvCnrBZ0DPY" target="_blank" rel="noopener">it‚Äôs not trivial</a>.</p> <p>Apart from that, Kubernetes offers some interesting options to manage state:</p> <div> <dl> <dt>Inside the container</dt> <dd> <p>The easiest way to store data is to use the container‚Äôs topmost layer. This is the case when one uses one of the filesystem unmapped directories <em>e.g.</em> <code>/var/log</code>. This option has a big flaw: when the container is stopped, whether abnormally or not, data is lost.</p> </dd> <dt>In an attached volume</dt> <dd> <p><a href="https://kubernetes.io/docs/concepts/storage/volumes/" target="_blank" rel="noopener">Volumes</a> are the nominal way to store data across pod stops. There is a lot whole different kinds of volumes available:</p> <ul><li><span>Volumes can be mounted on the host</span></li><li><span>They can be as well on <abbr title="Network File System">NFS</abbr></span></li><li><span>There is one kind for each common Cloud provider: Google Cloud, Azure, and AWS</span></li><li><span>Empty volumes allow to share data between pods</span></li><li><span>etc.</span></li></ul> </dd> </dl> </div> <p>Note that even with volumes, there‚Äôs no 100% durability guarantee. It depends on the exact kind of volume, and the surrounding context.</p> </div> </div> <div> <h2 id="final-thoughts">Final thoughts</h2> <div> <p>Despite what we would like to believe, state can be avoided only in trivial cases. There are only three available options:</p> <ol><li><span>Store state somewhere. There are multiple locations where to put data: serialized in cookies client-side, serialized in a data store, replicated in-memory, etc.</span></li><li><span>Compute the state every time it‚Äôs required</span></li><li><span>A combination of the above</span></li></ol> <p>Technical experts need to be aware of the above options, as well as to know which tradeoffs each of them implies. Stop fighting state, it‚Äôs a waste of time.</p> </div> </div>   </div> </section>   </article> </div> </div></div>]]>
            </description>
            <link>https://blog.frankel.ch/illusion-statelessness/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23717833</guid>
            <pubDate>Thu, 02 Jul 2020 20:45:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What it took to delete my 'like' history]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23717739">thread link</a>) | @djsumdog
<br/>
July 2, 2020 | https://tom.eastman.nz/2020/06/what-it-took-to-delete-my-like-history/ | <a href="https://web.archive.org/web/*/https://tom.eastman.nz/2020/06/what-it-took-to-delete-my-like-history/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-492">
		<!-- .entry-header -->

	
	<div>
		
<p>A while ago I decided to delete my ‚Äòlike‚Äô history on Twitter.</p>



<p>Since then, I‚Äôve discovered interesting ways in which Twitter‚Äôs engineering makes it impossible to do.</p>



<p>The recent ones are easy, if you have access to the <a href="https://developer.twitter.com/en/docs/basics/getting-started" target="_blank" rel="noreferrer noopener">Twitter API</a>. You can request the list of ‚Äòfavorites‚Äô (they never renamed them to ‚Äòlikes‚Äô on the API layer) and from there you can <a href="https://developer.twitter.com/en/docs/tweets/post-and-engage/api-reference/post-favorites-destroy" target="_blank" rel="noreferrer noopener">delete them</a>, one at a time.</p>



<pre><code lang="python">#!/usr/bin/env python3
import os
import twitter

api = twitter.Api(
    os.environ['CONSUMER_KEY'], os.environ['CONSUMER_SECRET'],
    os.environ['ACCESS_TOKEN_KEY'], os.environ['ACCESS_TOKEN_SECRET'],
    sleep_on_rate_limit=True
)
while True:
    favorites = api.GetFavorites(count=200)
    if not favorites:
        break
    print(f"GetFavorites(): Received {len(favorites)} status objects.")
    for status in favorites:
        print(f"{status.user.screen_name:20}: {status.text}")
        status = api.DestroyFavorite(status_id=status.id)
</code></pre>



<p>From the looks of things, you can delete the most recent 3,000 or so ‚Äòlikes‚Äô you‚Äôve ever made using a script like this.</p>



<p>After that, things get harder.</p>



<hr>



<p>I‚Äôve been thinking about what a ‚Äòlike‚Äô on Twitter and Facebook means.</p>



<p>When you click it, you‚Äôre sending a single piece of information to the person who wrote the tweet. Ostensibly, I guess, that you liked their tweet. Really it‚Äôs just read-receipt for Twitter ‚Äî you‚Äôre just telling someone that you read what they wrote. If you‚Äôre mentioned in a tweet it seems almost <em>fait accompli</em> that you‚Äôre going to hit ‚Äòlike‚Äô. It means ‚Äúyeah yeah, I got your message‚Äù, and not much else.</p>



<p>After that, it just sits there, in your history, and in Twitter‚Äôs database. It becomes part of their algorithm to tune your feed to keep you hooked.</p>



<hr>



<p>Once you‚Äôve deleted all the ‚Äòlikes‚Äô that the API will allow you to see, you‚Äôll find, to your surprise, that there are still thousands to go. They show up on your ‚Äòlikes‚Äô page, and they show up in your exported data archive, but the little red ‚Äòheart‚Äô isn‚Äôt active.</p>



<p>I guess these ‚Äòlikes‚Äô are in some sort of static cold storage. I‚Äôd be fascinated to hear from a Twitter engineer (a) how it works, and (b) why they still work for Twitter.</p>



<p>You can‚Äôt delete them, the platform doesn‚Äôt treat them as ‚Äòliked‚Äô tweets at all.</p>



<p>The only way to get rid of them is to is to click the heart twice: to ‚Äòlike‚Äô it anew and then ‚Äòunlike‚Äô it. This sends the author  and anyone mentioned a fresh notification telling them that you liked their tweet.</p>



<p>If you want to delete your old history of tweets. You‚Äôre going to have to send a new notification to every single person in every single tweet you‚Äôve ever liked. Thousands upon thousands of them. For tweets that can be years old.</p>



<hr>



<p>I like it when people like my tweets. I come up with witty, snarky things to say so that people click ‚Äòlike‚Äô. I want to write more of them. It keeps me coming up with ‚Äòtweetable‚Äô things to say.</p>



<p>At its most cynical, ‚Äúlike‚Äù is the endorphin button: Every time you like someone‚Äôs tweet you‚Äôre sending them a tiny little burst of pleasure that keeps them addicted to Twitter.</p>



<p>The sad thing is, the better you <em>are</em> at twitter ‚Äî the better you are at pithy, wry sarcasm in short form ‚Äî the more effective you are at keeping everyone else addicted to an intentionally-addictive platform.</p>



<p>We all are each other‚Äôs drug pushers.</p>



<hr>



<p>The only way someone won‚Äôt get a notification when you ‚Äúlike‚Äù their tweet is if (a) they don‚Äôt follow you, and (b) you set your account to ‚Äòprivate‚Äô mode first.</p>



<p>To get an exhaustive list of the tweets you‚Äôve liked, you have to download your Twitter ‚Äúdata archive‚Äù, a <code>.zip</code> file of all data Twitter keeps on you (that they want to admit to). In the <code>date/like.js</code> file is the list of all the likes, along with their ID numbers.</p>



<p>This would be enough to use the API to ‚Äòlike‚Äô and ‚Äòunlike‚Äô each tweet, but if you want to reduce the disruption to others you need to take more steps.</p>



<p>I used the Twitter API to retrieve the full details of every Tweet in the list so that I could group them by author and by accounts mentioned in the Tweet. I ended up writing some unreasonable amount of Python and SQLAlchemy code to correlate them all.</p>



<p>My plan was to group the operations so that I could (a) prevent notifications to strangers by being in ‚Äòprivate mode‚Äô whenever I was running my program, and (b) when it came time to disrupt my friends‚Äô by sending them notifications, I‚Äôd try to group them all so it all happened at once instead of spread out over interminable days of hundreds of notifications.</p>



<p>It <em>would</em> be hundreds, after all: your likes are pretty proportional to the tweets you see. The tweets you see most tend to be the friends you‚Äôve followed the longest.</p>



<p>I started working my way through the list. A couple of times a day the routine was:</p>



<ul><li>set my twitter profile to ‚Äòprotected mode‚Äô</li><li>start my script. Watch it chug through ‚Äòliking‚Äô and ‚Äòunliking‚Äô a stream of tweets</li><li>crash when the rate limit was hit</li><li>reset my Twitter profile to ‚Äòpublic‚Äô mode</li><li>wait a couple hours, and repeat</li></ul>



<p>For friends of mine who‚Äôs tweets I‚Äôd liked *hundreds* of times, I either <strong>blocked</strong> them first so they wouldn‚Äôt get notifications (knowing I could unblock them afterwards, and invite them to re-follow me), or I tried to message them first to warn them that I was about to spam them.</p>



<figure><div>
<blockquote data-width="525" data-dnt="true"><div lang="en" dir="ltr"><p>Dear friends, over the next several days you're likely to see every tweet of yours I've ever "liked" get a fresh "like" notification ‚Äî even years-old ones.</p><p>They're all good tweets.</p></div>‚Äî Tom Eastman (@tveastman) <a href="https://twitter.com/tveastman/status/1260676895328198656?ref_src=twsrc%5Etfw">May 13, 2020</a></blockquote>
</div></figure>



<p>For the people who get scores-to-hundreds of notifications, having this tweet pinned on the top of my profile would at least give them some explanation as to what the hell was happening.</p>



<figure><div>
<blockquote data-width="525" data-dnt="true"><p lang="en" dir="ltr">OKAY, THIS MAKES MORE SENSE NOW</p>‚Äî Dr Sophia Frentz üåà (@SophiaFrentz) <a href="https://twitter.com/SophiaFrentz/status/1261194791729020933?ref_src=twsrc%5Etfw">May 15, 2020</a></blockquote>
</div></figure>



<p>It definitely weirded people the hell out though. Some of my friends politely removed me till it was done.</p>



<figure><div>
<blockquote data-width="525" data-dnt="true"><p lang="en" dir="ltr"><a href="https://twitter.com/tveastman?ref_src=twsrc%5Etfw">@tveastman</a> muting u my friend. Dm me when you done.</p>‚Äî Brenda Wallace, the Potato Enthusiast ü•îüö≤üèûÔ∏èüèñÔ∏è (@BR3NDA) <a href="https://twitter.com/BR3NDA/status/1261036566572486656?ref_src=twsrc%5Etfw">May 14, 2020</a></blockquote>
</div></figure>



<p>I also accidentally re-started conversation threads left hanging years previously, thanks to the fresh notification on an old tweet.</p>



<figure><div>
<blockquote data-width="525" data-dnt="true"><p lang="en" dir="ltr">Lol Tom Necro, also HTTP/3 is almost here which doesnt even use TCP</p>‚Äî Beau Butler (@oddynz) <a href="https://twitter.com/oddynz/status/1261228701947068416?ref_src=twsrc%5Etfw">May 15, 2020</a></blockquote>
</div></figure>



<p>But finally, after about two weeks of running the script at least once a day until rate-limited, I had finally deleted all my likes. Finally, I had a clean slate.</p>



<p>Only, I didn‚Äôt.</p>



<figure><img src="https://tom.eastman.nz/wp-content/uploads/2020/06/completionists-gonna.png" alt="" srcset="https://tom.eastman.nz/wp-content/uploads/2020/06/completionists-gonna.png 609w, https://tom.eastman.nz/wp-content/uploads/2020/06/completionists-gonna-340x243.png 340w" sizes="(max-width: 609px) 100vw, 609px"><figcaption>Completionists gonna have a hard time with this</figcaption></figure>



<p>You can‚Äôt delete a like on an old tweet without ‚Äòliking‚Äô the tweet again.</p>



<p>It turns out that there are plenty of tweets old tweets you might have hit ‚Äòlike‚Äô on once, but you can‚Äôt see any more.</p>



<p>Tweets from deleted or suspended accounts <em>remain</em> in the count even if they‚Äôre not visible by the system. Tweets by people who you don‚Äôt follow who have protected their accounts are inaccessible.</p>



<p>Tweets that you liked, by Twitter users who have subsequently blocked you, can never, ever by removed by you.</p>



<p>And so, at the end of the day, I can no longer see my liked tweets, but maybe you can. And some of the tweets will be people who no longer follow me, and some of them ‚Äî there forever ‚Äî will be from people who loath me.</p>



<hr>



<p>What was the point of all this?</p>



<p>When it became obvious that I wasn‚Äôt going to be able to delete my like history without sending thousands of notifications. I decided to press on with the project because I wanted to see exactly what social cost Twitter would exact upon me, just for trying to reclaim my own data.</p>



<p>I didn‚Äôt measure how many people unfollowed me, but I certainly got some bewildered reactions. I had friends reach out to me out-of-band to ask me if my account had been hacked.</p>



<p>And for all that, it turned out to be un-completable. Twitter will not allow you the means to completely wipe your ‚Äúlike‚Äù history short of actually deleting your account.</p>



<p>‚ÄòLikes‚Äô might not seem important. But it‚Äôs critical to the sorts of algorithms social media use to tune their feeds to keep you hooked, and to target you with advertising. They‚Äôre also a paltry, lazy mode of communication. From now on, if I like someone‚Äôs tweet, I‚Äôll conjure the mental effort to at least tell them so, with words.</p>



<figure><img src="https://tom.eastman.nz/wp-content/uploads/2020/06/digital-minimalism-excerpt-e1591594506484-1038x1024.jpeg" alt="" srcset="https://tom.eastman.nz/wp-content/uploads/2020/06/digital-minimalism-excerpt-e1591594506484-1038x1024.jpeg 1038w, https://tom.eastman.nz/wp-content/uploads/2020/06/digital-minimalism-excerpt-e1591594506484-1024x1010.jpeg 1024w, https://tom.eastman.nz/wp-content/uploads/2020/06/digital-minimalism-excerpt-e1591594506484-340x335.jpeg 340w, https://tom.eastman.nz/wp-content/uploads/2020/06/digital-minimalism-excerpt-e1591594506484-768x758.jpeg 768w, https://tom.eastman.nz/wp-content/uploads/2020/06/digital-minimalism-excerpt-e1591594506484-1536x1515.jpeg 1536w, https://tom.eastman.nz/wp-content/uploads/2020/06/digital-minimalism-excerpt-e1591594506484-100x100.jpeg 100w, https://tom.eastman.nz/wp-content/uploads/2020/06/digital-minimalism-excerpt-e1591594506484.jpeg 1930w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"><figcaption>Don‚Äôt click ‚Äúlike‚Äù, Digital Minimalism by Cal Newport (2019)</figcaption></figure>




	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://tom.eastman.nz/2020/06/what-it-took-to-delete-my-like-history/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23717739</guid>
            <pubDate>Thu, 02 Jul 2020 20:37:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Does saying ‚ÄúFuck You AWS‚Äù constitute offensive content?]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 102 (<a href="https://news.ycombinator.com/item?id=23717254">thread link</a>) | @jmdeon
<br/>
July 2, 2020 | http://thoughts.josephdeon.me/2020/07/02/fuck-you-aws.html | <a href="https://web.archive.org/web/*/http://thoughts.josephdeon.me/2020/07/02/fuck-you-aws.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="http://thoughts.josephdeon.me/assets/canary.png"></p>
<p><br>
I actually quite like AWS and its offerings. I‚Äôm making this post because I‚Äôm genuinely curious
how to interpret the <a href="https://aws.amazon.com/aup/">AWS Acceptable Use Policy</a>. The static content for this blog is hosted within an
AWS S3 bucket. Does saying ‚ÄúFuck You AWS‚Äù constitute offensive content?</p>

<p>The section titled ‚ÄòNo Illegal, Harmful, or Offensive Use or Content‚Äô says:</p>

<blockquote>
  <p>You may not use, or encourage, promote, facilitate or instruct others to use, the Services or AWS Site for any illegal, harmful, fraudulent, infringing or offensive use, or to transmit, store, display, distribute or otherwise make available content that is illegal, harmful, fraudulent, infringing or offensive. Prohibited activities or content include:</p>
</blockquote>

<blockquote>
  <p>Offensive Content. Content that is defamatory, obscene, abusive, invasive of privacy, or otherwise objectionable, including content that constitutes child pornography, relates to bestiality, or depicts non-consensual sex acts.</p>
</blockquote>

<p>‚ÄúOtherwise objectionable‚Äù seems to cast a very wide net.
One of my <a href="http://thoughts.josephdeon.me/2020/07/01/hello-weblog.html">three goals</a> for self hosting this blog was ownership. To me part of
ownership is being able to express myself freely. I hoped that meant as
long as I worked within the confines of the law I would be in the clear.</p>

<p>If this post gets removed then I know I have not fully achieved my ownership goal and it
might be time to just host on a pi.</p>

<p><br>
P.S. I posted this to hackernews. It made it to the front page and generated <a href="https://news.ycombinator.com/item?id=23717254">some discussion</a>.</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>http://thoughts.josephdeon.me/2020/07/02/fuck-you-aws.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23717254</guid>
            <pubDate>Thu, 02 Jul 2020 19:49:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostgreSQL beginner guide ‚Äì connecting, remote access, psql CLI and more]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23716003">thread link</a>) | @lukasbar
<br/>
July 2, 2020 | https://knowledgepill.it/posts/postgresql_basics_guide/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/postgresql_basics_guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<p>By default after instalation and creting database cluster PostgreSQL will listner only on localhost. No remote access will be allowed.</p>
<hr>
<p><a href="https://knowledgepill.it/posts/postgresql_installation/">PostgreSQL installation on Linux - with database creation</a></p>
<hr>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ netstat -lptnu | grep post
<span>(</span>Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.<span>)</span>
tcp        <span>0</span>      <span>0</span> 127.0.0.1:5432          0.0.0.0:*               LISTEN      1977/postmaster     
tcp6       <span>0</span>      <span>0</span> ::1:5432                :::*                    LISTEN      1977/postmaster     
</code></pre></div><p>To change listen address we have to configure parameter in <code>postgresql.conf</code></p>
<p>Check <code>PGDATA</code> - after <code>-D</code> parameter:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ ps aux | grep postgres
postgres  <span>1977</span>  0.0  2.5 <span>286388</span> <span>14864</span> ?        Ss   Jun28   0:02 /usr/pgsql-12/bin/postmaster -D /postgresql/data
postgres  <span>1979</span>  0.0  0.2 <span>140768</span>  <span>1360</span> ?        Ss   Jun28   0:00 postgres: logger   
postgres  <span>1981</span>  0.0  0.5 <span>286504</span>  <span>3028</span> ?        Ss   Jun28   0:00 postgres: checkpointer   
postgres  <span>1982</span>  0.0  0.2 <span>286388</span>  <span>1696</span> ?        Ss   Jun28   0:03 postgres: background writer   
postgres  <span>1983</span>  0.0  0.9 <span>286388</span>  <span>5676</span> ?        Ss   Jun28   0:03 postgres: walwriter   
postgres  <span>1984</span>  0.0  0.4 <span>286924</span>  <span>2688</span> ?        Ss   Jun28   0:02 postgres: autovacuum launcher  
</code></pre></div><p>Locate the file:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ cd /postgresql/data/
<span>[</span>postgres@postgres-lab data<span>]</span>$ ls -lah postgresql.conf
-rw-------. <span>1</span> postgres postgres 26K Jun <span>28</span> 21:44 postgresql.conf
</code></pre></div><p>Change in <code>postgresql.conf</code> parameter <code>listen_addresses</code> to your server IP or <code>*</code> to listen on all IP‚Äôs available on server:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ vi postgresql.conf

<span>#------------------------------------------------------------------------------</span>
<span># CONNECTIONS AND AUTHENTICATION</span>
<span>#------------------------------------------------------------------------------</span>

<span># - Connection Settings -</span>

listen_addresses <span>=</span> <span>'*'</span>          <span># what IP address(es) to listen on;</span>
                                        <span># comma-separated list of addresses;</span>
                                        <span># defaults to 'localhost'; use '*' for all</span>
</code></pre></div><p>Restart PostgreSQL to apply changes - you can do that with <code>systemctl</code> from <code>root</code> os user  service or with <code>pg_ctl -D PGDATA restart</code> from <code>postgres</code> os user:</p>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span># systemctl restart postgresql-12.service</span>
</code></pre></div><p>Check whre PostgreSQL is listening now:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ netstat -lptnu | grep post
<span>(</span>Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.<span>)</span>
tcp        <span>0</span>      <span>0</span> 0.0.0.0:5432            0.0.0.0:*               LISTEN      30161/postmaster    
tcp6       <span>0</span>      <span>0</span> :::5432                 :::*                    LISTEN      30161/postmaster  
</code></pre></div>
<p>PostgreSQL instance has got restricted access by <code>pg_hba.conf</code> file(host based authentication file).</p>
<p>We can provide in it information from which <code>ADDRESS</code> to which <code>DATABASE</code> on which <code>USER</code> by what <code>METHOD</code> we allow connecting. Additionaly we have to provide <code>TYPE</code> of connection.</p>
<p>This file resides in same place where <code>postgresql.conf</code>(we can alter this behavior by setting <code>pg_hba</code> parameter in <code>postgresql.conf</code>):</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ cd /postgresql/data/

<span>[</span>postgres@postgres-lab data<span>]</span>$ vi pg_hba.conf
<span># TYPE  DATABASE        USER            ADDRESS                 METHOD</span>

<span># "local" is for Unix domain socket connections only</span>
local   all             all                                     trust
<span># IPv4 local connections:</span>
host    all             all             127.0.0.1/32            trust
<span># IPv6 local connections:</span>
host    all             all             ::1/128                 trust
</code></pre></div><p>Allowed <code>TYPE</code>'s:</p>
<ul>
<li><code>local</code> - socket connection - needed to connect from shell on database server</li>
<li><code>host</code> - standard TCP/IP connection over the network - bnost SSL and no SSL</li>
<li><code>hostssl</code> - TCP/IP connection but only with SSL</li>
<li><code>hostnossl</code> - TCP/IP only without SSL</li>
<li><code>hostgssenc</code> - TCP/IP only GSSAPI</li>
<li><code>hostnogssenc</code> - TCP/IP only without GSSAPI</li>
</ul>
<p>With <code>DATABASE</code> we can specify database name or use special value <code>sameuser</code> if database name should be same as name of user that is connecting.</p>
<p>With <code>USER</code> we can specify user or role - role name should be preceded by <code>+</code> sign.</p>
<p><code>ADDRESS</code> field could be - hostname, IP range in CIDR format or special words:</p>
<ul>
<li><code>samehost</code> - which correspond to all IP adresses of database server</li>
<li><code>samenet</code> - which correspond to all IP in database server subnet</li>
</ul>
<p>With <code>METHOD</code> field we can set one of authentication methods - most important ones are:</p>
<ul>
<li><code>trust</code> - allow connection without password - moslty set for local connections from database server itself</li>
<li><code>reject</code> - reject connections</li>
<li><code>md5</code> - allow connections after getting from user password - encrypted</li>
<li><code>password</code> - allow connection after getting plain password - DO NOT USE in untrusted networks - better -&gt; never use this option</li>
<li><code>ldap</code> - getting account authorization data from LDAP server</li>
</ul>
<p>In <code>DATABASE</code> and <code>USER</code> fields you can specify special word <code>all</code> if you don‚Äôt want to create any restrictions here.</p>
<p>There can be situation when we must use additional field named <code>auth-options</code> for specyfying details for example for <code>hostssl</code> connection type. This topic will be covered in another post.</p>
<h2 id="sample-pg_hba-record---allow-all-users-connect-to-any-db-from-all-ip-addresses---only-with-password">Sample pg_hba record - allow all users connect to any DB from all IP addresses - only with password</h2>
<p>Add in <code>pg_hba.conf</code>:</p>
<div><pre><code data-lang="bash"><span># Network access</span>
host    all             all             0.0.0.0/0               md5
</code></pre></div><p>Reload(online operation) PostgreSQL that it can use <code>pg_hba.conf</code> changes:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ /usr/pgsql-12/bin/pg_ctl -D /postgresql/data reload
server signaled
</code></pre></div>
<h2 id="local-from-server">Local from server</h2>
<p>It will work without password because we have <code>trust</code> in <code>pg_hba.conf</code> for <code>local</code> connections:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql
psql <span>(</span>12.3<span>)</span>
Type <span>"help"</span> <span>for</span> help.
</code></pre></div><h2 id="remote-machine">Remote machine</h2>
<p>Default URI syntax - you can connect like this:<br>
<code>psql postgresql://user:passwd@host:5432/dbame</code><br>
or by more common method:<br>
Connect to remote database from <code>psql</code> with connections details provided in parameters(it will ask for password because of <code>md5</code> method in <code>pg_hba.conf</code> for connections from <code>0.0.0.0/0</code>):</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ psql -h 10.128.0.2 -p <span>5432</span>
Password <span>for</span> user postgres:
psql <span>(</span>12.3<span>)</span>
Type <span>"help"</span> <span>for</span> help.

postgres<span>=</span>#
</code></pre></div><p>We can also use parameter <code>-U</code> to specify username different than OS username we currently are using.</p>
<p>Also all this parameters can be taken from shell variables which names are self descriptive - if we set all of them we can just use plain <code>psql</code> command to connect:</p>
<ul>
<li><code>PGHOST</code></li>
<li><code>PGPORT</code></li>
<li><code>PGDATABASE</code></li>
<li><code>PGUSER</code></li>
<li><code>PGPASSWORD</code></li>
</ul>
<h2 id="check-connected-database">Check connected database</h2>
<div><pre><code data-lang="bash">postgres<span>=</span><span># select current_database();</span>
 current_database
------------------
 postgres
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h2 id="check-current-user">Check current user</h2>
<div><pre><code data-lang="bash">postgres<span>=</span><span># select current_user;</span>
 current_user
--------------
 postgres
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h2 id="check-ip-and-port-used-for-connection">Check IP and port used for connection</h2>
<div><pre><code data-lang="bash">postgres<span>=</span><span># select inet_server_addr(), inet_server_port();</span>
 inet_server_addr | inet_server_port
------------------+------------------
 10.128.0.2       |             <span>5432</span>
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h2 id="check-postgresql-version">Check PostgreSQL version</h2>
<div><pre><code data-lang="bash">postgres<span>=</span><span># select version();</span>
                                                version                                                 
--------------------------------------------------------------------------------------------------------
 PostgreSQL 12.3 on x86_64-pc-linux-gnu, compiled by gcc <span>(</span>GCC<span>)</span> 8.3.1 <span>20191121</span> <span>(</span>Red Hat 8.3.1-5<span>)</span>, 64-bit
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h2 id="check-connection-info">Check connection info</h2>
<div><pre><code data-lang="bash">postgres<span>=</span><span># \conninfo</span>
You are connected to database <span>"postgres"</span> as user <span>"postgres"</span> on host <span>"10.128.0.2"</span> at port <span>"5432"</span>.
</code></pre></div>
<h2 id="execute-single-command-from-shell">Execute single command from shell</h2>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -c <span>"select current_time"</span>
    current_time    
--------------------
 14:09:19.854598+00
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h2 id="exacute-sql-script-from-shell">Exacute sql script from shell</h2>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -f create_user.sql
CREATE ROLE
CREATE ROLE
CREATE ROLE
</code></pre></div><h2 id="combine-single-command-with-sql-script-from-shell">Combine single command with sql script from shell</h2>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -c <span>"select current_time"</span> -f create_user.sql -c <span>"select current_time"</span>
    current_time    
--------------------
 14:14:26.922453+00
<span>(</span><span>1</span> row<span>)</span>

CREATE ROLE
CREATE ROLE
CREATE ROLE
    current_time    
--------------------
 14:14:26.926545+00
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div>

<p>Do it yourself to see all available commands - output trimmed to important ones!</p>
<div><pre><code data-lang="bash">postgres<span>=</span><span># \?</span>
General
  <span>\c</span>opyright             show PostgreSQL usage and distribution terms
  <span>\c</span>rosstabview <span>[</span>COLUMNS<span>]</span> execute query and display results in crosstab
  <span>\e</span>rrverbose            show most recent error message at maximum verbosity
  <span>\g</span> <span>[</span>FILE<span>]</span> or ;         execute query <span>(</span>and send results to file or |pipe<span>)</span>
  <span>\g</span>desc                 describe result of query, without executing it
  <span>\g</span>exec                 execute query, <span>then</span> execute each value in its result
  <span>\g</span>set <span>[</span>PREFIX<span>]</span>         execute query and store results in psql variables
  <span>\g</span>x <span>[</span>FILE<span>]</span>             as <span>\g</span>, but forces expanded output mode
  <span>\q</span>                     quit psql
  <span>\w</span>atch <span>[</span>SEC<span>]</span>           execute query every SEC seconds

  Query Buffer
    <span>\e</span> <span>[</span>FILE<span>]</span> <span>[</span>LINE<span>]</span>       edit the query buffer <span>(</span>or file<span>)</span> with external editor
    <span>\e</span>f <span>[</span>FUNCNAME <span>[</span>LINE<span>]</span><span>]</span>  edit <span>function</span> definition with external editor
    <span>\e</span>v <span>[</span>VIEWNAME <span>[</span>LINE<span>]</span><span>]</span>  edit view definition with external editor
    <span>\p</span>                     show the contents of the query buffer
    <span>\r</span>                     reset <span>(</span>clear<span>)</span> the query buffer
    <span>\s</span> <span>[</span>FILE<span>]</span>              display history or save it to file
    <span>\w</span> FILE                write query buffer to file

</code></pre></div><h2 id="list-objects-in-psql">List objects in psql</h2>
<ul>
<li>\d[S+]          -       list tables, views, and sequences</li>
<li>\d[S+]  NAME     -      describe table, view, sequence, or index</li>
<li>\da[S]  [PATTERN] -     list aggregates</li>
<li>\dA[+]  [PATTERN]  -    list access methods</li>
<li>\db[+]  [PATTERN]   -   list tablespaces</li>
<li>\dc[S+] [PATTERN]    -  list conversions</li>
<li>\dC[+]  [PATTERN]     - list casts</li>
<li>\dd[S]  [PATTERN]     - show object descriptions not displayed elsewhere</li>
<li>\dD[S+] [PATTERN]     - list domains</li>
<li>\ddp    [PATTERN]     - list default privileges</li>
<li>\dE[S+] [PATTERN]     - list foreign tables</li>
<li>\det[+] [PATTERN]     - list foreign tables</li>
<li>\des[+] [PATTERN]     - list foreign servers</li>
<li>\deu[+] [PATTERN]     - list user mappings</li>
<li>\dew[+] [PATTERN]     - list foreign-data wrappers</li>
<li>\df[anptw][S+] [PATRN]- list [only ‚Ä¶</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://knowledgepill.it/posts/postgresql_basics_guide/">https://knowledgepill.it/posts/postgresql_basics_guide/</a></em></p>]]>
            </description>
            <link>https://knowledgepill.it/posts/postgresql_basics_guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23716003</guid>
            <pubDate>Thu, 02 Jul 2020 17:52:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Every Public Engineering Career Ladder]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23715871">thread link</a>) | @lowmemcpu
<br/>
July 2, 2020 | https://www.swyx.io/writing/career-ladders/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/writing/career-ladders/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="sapper"> <div>  <main> <div>  <p>"What will it take to get to the next level?"</p> <p>Of course this is a very open ended question, but it can be nice to set some guide rails around what expectations are in a company. As an individual contributor, career ladders tell me what the company ostensibly values (and, by omission, what it doesn't value).</p> <p>I recently compiled this list of career ladders and figured I would share it here. Some ladders include nontechnical jobs, I will just look at engineering and engineering management.</p> <ul> <li> <p><strong><a href="https://www.joelonsoftware.com/2009/02/13/fog-creek-professional-ladder/">Fog Creek</a></strong>: from 2009, but obviously Joel's thinking has been very influential. Focus is on growing ownership, ability to write production code independently, shipping experience, and at senior levels, design/planning/architecture. Teamwork, self study, mentorship, and impact are all key, as well as the Joel Test.</p> </li> <li> <p><strong><a href="https://dresscode.renttherunway.com/blog/ladder">Rent the Runway</a></strong> (<a href="https://docs.google.com/spreadsheets/d/1k4sO6pyCl_YYnf0PAXSBcX776rNcTjSOqDxZ5SDty-4/edit?usp=sharing">spreadsheet</a>): from 2015. Takes a fun D&amp;D inspired Dex/Str/Wis/Cha stats based evaluation, corresponding to technical skill, productivity, impact, and communication/leadership. Management track is also included, with more focus on architecture, hiring, organizational skills, and leadership/salesmanship.</p> </li> <li> <p><strong><a href="https://artsy.github.io/blog/2015/04/03/artsy-engineering-compensation-framework/">Artsy</a></strong>: inspired by Rent the Runway</p> </li> <li> <p><strong><a href="https://capgemini.gitbooks.io/grade-ladder/content/">CapGemini UK</a></strong>: also inspired by Rent the Runway</p> </li> <li> <p><strong><a href="https://basecamp.com/handbook/appendix-05-titles-for-programmers">Basecamp</a></strong>: pretty simple.</p> </li> <li> <p><strong><a href="https://engineering.thumbtack.com/how-we-built-an-engineering-job-ladder-from-the-ground-up/">Thumbtack</a></strong> (<a href="https://docs.google.com/spreadsheets/d/15ACBs-crUHnqf1wANUQwX9oZIDOi5tvJJXGWpKTcf00/edit#gid=0">spreadsheet</a>): from 2019. Breaks down technical skills into <strong>code quality/testing</strong>, <strong>debugging</strong>, and <strong>scoping/project design</strong>, and nontechnical factors to <strong>collaboration, citizenship, leadership, and impact</strong>. Leadership is interestingly broken down into <strong>Autonomy, Judgement, Initiative, and Consensus Building</strong>.</p> </li> <li> <p><strong><a href="https://circleci.com/blog/why-we-re-designed-our-engineering-career-paths-at-circleci/">CircleCI</a></strong> (<a href="https://docs.google.com/spreadsheets/d/131XZCEb8LoXqy79WWrhCX4sBnGhCM1nAIz4feFZJsEo/edit#gid=0">spreadsheet</a>): one of the most well known ladders, detailed but not overwhelming. NOtably, one of the values assessed is Security.</p> </li> <li> <p><strong><a href="https://github.com/envoy/Engineering/blob/master/engineering_bands.md">Envoy</a></strong>: pretty simple ladder list, by a hot company.</p> </li> <li> <p><strong><a href="https://medium.com/ft-product-technology/improving-our-career-map-for-engineers-4210185c6246">Financial Times</a></strong> (<a href="https://engineering-progression.ft.com/">webapp</a>). Even has an <a href="https://engineering-progression.ft.com/docs/api/">API</a>! lol. Only 4 areas across Technical, Leadership, Delivery, and Communication are assessed. Feels manageable.</p> </li> <li> <p><strong><a href="https://github.com/meetup/engineering-roles/">Meetup</a></strong>: splits roles into Makers and Managers.</p> <ul> <li>Makers focus on Architecture &amp; framework &amp; software development, Best practices &amp; architecture &amp; code reviews, Technical skills evaluation &amp; mentoring, Introduce new engineering tools &amp; mentor adoption, and Recommend process improvements &amp; support adoption.</li> <li>Managers focus on Performance evaluation, Career growth, Recruiting &amp; resourcing, Rollout process improvements &amp; adoption of engineering tools and Organization &amp; administrative.</li> </ul> </li> <li> <p><strong><a href="https://github.com/Socialbakers/engineeringroles">Socialbakers</a></strong>: seems pretty similar to Meetup's ladder</p> </li> <li> <p><strong><a href="https://medium.com/s/engineering-growth-framework/engineering-growth-tracks-b1fad620787e">Medium</a></strong> (<a href="https://gist.github.com/david206/b8dceddd687bb2c60805c9669cc89eaa">gist</a>): has tracks for Mobile, Servers, Foundations, Web client, Project Management, Communication, Craft, Initiative, Org design, Accomplishment, Wellbeing, Career development, Evangelism, Community, Recruiting, and Mentorship! Phew!</p> </li> <li> <p><strong><a href="http://www.starling-software.com/employment/programmer-competency-matrix.html">Starling Software</a></strong>: Uses Big O notation to denote levels, which is a fun shibboleth. Skills are broken out to Computer Science, Software Engineering, Programming, Experience, and Knowledge. This one has a long record on <a href="https://news.ycombinator.com/item?id=4626695">Hacker News</a> but is a good map of things that we can work on.</p> </li> <li> <p><strong><a href="https://gist.github.com/jamtur01/aef437a79fee5a9cefdc">Kickstarter</a></strong>: basically a bunch of job descriptions, including Data careers and CTO.</p> </li> <li> <p><strong><a href="https://docs.google.com/document/d/1PCj7f-91G6dGdIlfDpCHcm68L80hRELk00eO-gZvh1o/edit">Brandwatch</a></strong>: explains levels at a high level, and then breaks it out for <a href="https://docs.google.com/spreadsheets/d/1weNoeSUfHYOHy9sHKad_ax6qrVXNFlP4ieTwaRll70M/edit#gid=0">IC's and Management in this spreadsheet</a>. A total of 15 attributes to work on!</p> </li> <li> <p><strong><a href="https://labs.spotify.com/2016/02/15/spotify-technology-career-steps/">Spotify</a></strong>: famous for its "Squad/Tribe" structure - emphasizes "Steps", with a simple list of five sets of behaviors they want:</p> <ul> <li>Values team success over individual success</li> <li>Continuously improves themselves and team</li> <li>Holds themselves and others accountable</li> <li>Thinks about the business impact of their work</li> <li>Demonstrates mastery of their discipline</li> </ul> </li> <li> <p><strong><a href="https://blog.usejournal.com/the-software-engineering-job-ladder-4bf70b4c24f3">Chuck Groom</a></strong> - this is unusual - personal thoughts on a Job Ladder, though the author is a senior engineering leader at VTS. Good discussions on how having ladders helps, as well as descriptions of Anti-patterns. I love the Principal Engineer antipatterns:</p> <blockquote> <p>Over-emphasis on scaling or high availability far beyond business needs. Spends too much time chasing the newest ‚Äúshiny‚Äù technology. Doesn‚Äôt collaborate or ask questions. Condescending. Has ‚Äúpet‚Äù agenda. Pisses off senior leadership.</p> </blockquote> </li> </ul> <section> <h2 id="further-reading">Further Reading</h2> <ul> <li>More ladders (non engineering) are available at <a href="https://www.progression.fyi/">https://www.progression.fyi/</a></li> <li><a href="http://engineering.khanacademy.org/posts/career-development.htm">http://engineering.khanacademy.org/posts/career-development.htm</a></li> <li><a href="https://progression.monzo.com/engineering/web">https://progression.monzo.com/engineering/web</a></li> <li><a href="https://squeakyvessel.com/2016/07/11/engineering-ladders-links-elsewhere/">https://squeakyvessel.com/2016/07/11/engineering-ladders-links-elsewhere/</a></li> <li><a href="https://patreonhq.com/how-patreon-levels-engineers-a28a3491ae6a">https://patreonhq.com/how-patreon-levels-engineers-a28a3491ae6a</a></li> <li><a href="https://developer.squareup.com/blog/squares-growth-framework-for-engineers-and-engineering-managers/">https://developer.squareup.com/blog/squares-growth-framework-for-engineers-and-engineering-managers/</a></li> <li><a href="http://www.elidedbranches.com/2015/11/truth-and-consequences-of-technical.html">http://www.elidedbranches.com/2015/11/truth-and-consequences-of-technical.html</a></li> <li><a href="https://mcfunley.com/thoughts-on-the-technical-track">https://mcfunley.com/thoughts-on-the-technical-track</a></li> <li><a href="https://github.com/vijayvenkatesh/engineering_ladders">https://github.com/vijayvenkatesh/engineering_ladders</a></li> <li><a href="https://www.cnblogs.com/dhcn/p/10729002.html">https://www.cnblogs.com/dhcn/p/10729002.html</a></li> <li><a href="https://circleci.com/blog/how-to-successfully-work-from-home-strategies-for-remote-work/">https://circleci.com/blog/how-to-successfully-work-from-home-strategies-for-remote-work/</a></li> <li>Management vs Engineering: <a href="https://charity.wtf/2019/01/04/engineering-management-the-pendulum-or-the-ladder/">https://charity.wtf/2019/01/04/engineering-management-the-pendulum-or-the-ladder/</a></li> </ul> </section> <hr>  </div> </main>  </div></div></div>]]>
            </description>
            <link>https://www.swyx.io/writing/career-ladders/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23715871</guid>
            <pubDate>Thu, 02 Jul 2020 17:42:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Principal Component Analysis]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23715662">thread link</a>) | @yousless
<br/>
July 2, 2020 | https://ymohamedahmed.github.io/post/pca/ | <a href="https://web.archive.org/web/*/https://ymohamedahmed.github.io/post/pca/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>In this post, we‚Äôll take a deep dive into PCA, from both a mathematical and implementation perspective.
We‚Äôll derive the equation from the ground up, look at how we can compute it and finally end with what it can be used for. This post is primarily targeted at those with a basic understanding of PCA but want to know the assumptions it relies on, its properties and derive how it can be computed.</p>
<p>If you‚Äôre interested in the repository containing the Jupyter notebook from which this is derived, it‚Äôs 
<a href="https://github.com/ymohamedahmed/blog-posts/tree/master/pca" target="_blank" rel="noopener">here</a>.</p>
<h2 id="the-optimal-coding-perspective">The optimal coding perspective</h2>
<h3 id="finding-a-low-dimensional-representation">Finding a low dimensional representation</h3>
<p>PCA can be thought of as finding a low-dimensional representation of a set of vectors. Given points in an <em>n</em>-dimensional space, we might wish to find some new <em>k</em>-dimensional space (with <em>k</em> &lt; <em>n</em>) which captures as much of the <em>essence</em> of the original space as possible. The exact definition of capturing the ‚Äò<em>essence</em>‚Äô is subject to design, however, we can consider it from multiple perspectives.</p>


<p><img src="https://ymohamedahmed.github.io/post/pca/images/pca.svg"></p><h3 id="the-notion-of-reconstruction-error">The notion of reconstruction error</h3>
<p>If we take our low-dimensional representation and attempt to recover the original <em>n</em>-dimensional vector of each point, we could measure how much each point varies from its reconstruction. The difference between each reconstruction and the original, is one way of measuring the effectiveness of our new <em>k</em>-dimensional space and is the approach taken by PCA.  Naturally, this requires a definition of a <em>similarity</em> between two matrices. If we have a matrix $X$ of our original points and our reconstruction $X'$ then we can define the difference between them as a sum of the square of errors $\sum_{i,j} (X-X‚Äô)_{i,j}^2$.</p>
<p>This quantity is known as the <em>Frobenius</em> norm of the matrix $||X-X'||_F$ and is essentially an extension of the L2 ($||\mathbf{v}||_2^2 =  \sum_i \mathbf{v}_i^2 = \mathbf{v}^\top \mathbf{v}$) norm from vectors to matrices. It is just a fancy name for squaring every element in a matrix and taking their sum. Crucially, however, we can see that the Frobenius norm of a matrix, $A$, is precisely equivalent to $Tr[A^\top A]$ (see the illustration below).</p>


<figure>
    <img src="https://ymohamedahmed.github.io/post/pca/images/output_smaller.gif">
    <figcaption>Showing the relationship between the Frobenius norm and trace operator: $||A||_F^2 = \text{Tr}(A^\top A)$</figcaption>
</figure> 

<p>As a result, our error of interest, can be computed as $Tr[(X-X‚Äô)^\top (X-X‚Äô)]$, this will come in handy since the trace operator comes with a bunch of neat tricks for manipulating the matrices involved.</p>
<h3 id="pca-assumptions">PCA Assumptions</h3>
<p>We‚Äôve defined how we‚Äôre going to evaluate this reconstruction, but not at all the means of performing the coding or its inverse.</p>
<p>PCA chooses to implement both the encoding and decoding as a matrix multiplication. So we can think of PCA as finding a matrix $D$ that will transform our input, $X$ to our coded version $C$ by a matrix multiplication (i.e. $C = XD$).
The matrix, $X$, being our original data of $m$ rows and $n$ columns.</p>
<p>We might choose, however, to use some matrix, $D_k$ which reduces the number of dimensions of our data from $m$ to $k$. To make it easier, we can tag the matrix with the new number of dimensions. If this is the case, then $D_k$ is of size $n \times k$ and so that the resulting coding, $C$, is of size $m \times k$.</p>
<p>One of the most crucial assumptions made by PCA is that the transformation matrix, $D_k$, has <strong>orthonormal</strong> columns. Criticially, this does not, technically, make it an <strong>orthogonal</strong> matrix since it may not be square and the rows may not be orthonormal.</p>
<p>This assumption is useful since it simplifies the reconstruction process, in fact, $X'$ can be computed as $XD_kD_k^\top$, i.e. we can use the transpose of the encoding matrix to perform the decoding.</p>
<p>To understand exactly why the reconstruction can be performed by the transpose of the matrix let‚Äôs consider a code $\mathbf{z}$ which we‚Äôve generated as $\mathbf{z}=\mathbf{D}\mathbf{x}$ and are decoding using $\mathbf{D}^\top$.</p>
<p>The reconstruction error is $(\mathbf{x}-\mathbf{D}^\top\mathbf{z})^\top(\mathbf{x}-\mathbf{D}^\top\mathbf{z}) = \mathbf{x}^\top\mathbf{x} - \mathbf{x}^\top\mathbf{D}^\top\mathbf{z}-\mathbf{z}^\top\mathbf{D}\mathbf{x} + \mathbf{z}^\top\mathbf{D}\mathbf{D}^\top\mathbf{z}$.</p>
<p>We can take the derivative with respect to the code $\mathbf{z}$, $\nabla_\mathbf{z} = -2\mathbf{D}\mathbf{x} + 2\mathbf{D}\mathbf{D}^\top\mathbf{z}$, which given the definition of $\mathbf{z}$ is equal to $-2\mathbf{D}\mathbf{x} + 2\mathbf{D}\mathbf{D}^\top\mathbf{D}\mathbf{x}$.</p>
<p>We defined our matrix to have orthonormal columns so we know that $\mathbf{D}^\top\mathbf{D} = \mathbf{I}$ because the dot product of each column with itself will be one. Hence, our gradient is  $-2\mathbf{D}\mathbf{x} + 2\mathbf{D}\mathbf{I}\mathbf{x} = \mathbf{0}$. This tells us that our encoding/decoding system is at a stationary point in the reconstruction error. Note that this only tells us for an individual point that was encoded with a matrix that has orthonormal columns, decoding with the transpose is a good idea. It doesn‚Äôt tell us anything about how to pick $\mathbf{D}$ or what happens if you use it for multiple points.</p>
<p>Given these assumptions, we can reframe our problem as finding the coding matrix which minimises the reconstruction error.</p>
<p>This means that formally, for some given value $k$, we wish to discover the matrix $D_k^*$.</p>
<p>$$D_k^* = argmin_{D_k} ||X-X'||_F =  argmin_{D_k} ||X-XD_kD_k^\top||_F$$</p>
<h3 id="discovering-the-coding-function">Discovering the coding function</h3>
<p>Given that we wish to minimise the reconstruction error, let us attempt to discover the transformation precisely capable of this.</p>
<p>We‚Äôll need a few tricks to get us there.</p>
<ul>
<li>$(A+B)^\top = A^\top + B^\top$</li>
<li>$(AB)^\top = B^\top A^\top$</li>
<li>$(A^\top)^\top = A$</li>
</ul>
<p>From the visual illustration, recall that we can write the reconstruction error as $\text{Tr}((X-XD_kD_k^\top)^\top(X-XD_kD_k^\top))$.</p>
<p>By using the rules  this can be expanded into $$\text{argmin}_{D_k}\text{Tr}(X^\top X -X^\top XD_kD_k^\top - D_kD_k^\top X^\top X + D_kD_k^\top X^\top XD_kD_k^\top)$$</p>
<p>We are, however, only interested in the effect of the matrix $D_k$ so we‚Äôll axe the first term $$\text{argmin}_{D_k}\text{Tr}(-X^\top XD_kD_k^\top - D_kD_k^\top X^\top X + D_kD_k^\top X^\top XD_kD_k^\top)$$</p>
<p>Crucially, however, the trace operator has two useful properties for us:</p>
<ul>
<li>it‚Äôs insensitive to cyclic permutations (i.e. $\text{Tr}(ABC) = \text{Tr}(CAB) = \text{Tr}(BCA)$)</li>
<li>the trace of a sum of matrices is the sum of their traces (i.e $\text{Tr}(\sum_i \mathbf{A}_i) = \sum_i \text{Tr}(\mathbf{A}_i)$)</li>
</ul>
<p>Given this, we can write the equation of interest as: $$\text{argmin}_{D_k}-2\text{Tr}(-X^\top XD_kD_k^\top)+ \text{Tr}(D_kD_k^\top X^\top XD_kD_k^\top)$$.</p>
<p>Furthermore, since we define the columns of $D_k$ as being orthonormal, $\mathbf{D}_k^\top \mathbf{D}_k = \mathbf{I}$ and so we can rewrite the second term as $\text{Tr}(\mathbf{D}_k^\top \mathbf{X}^\top  \mathbf{X}\mathbf{D}_k)$ which matches the form of the first term (from permuting it) and therefore can be written as the following maximisation.</p>
<p>$$\text{argmax}_{\mathbf{D}_k} \text{Tr}(\mathbf{D}_k^\top \mathbf{X}^\top  \mathbf{X}\mathbf{D}_k)$$</p>
<p>This is sets up exactly the quantity that PCA is attempting to maximise.</p>
<h4 id="relationship-with-eigendecomposition">Relationship with eigendecomposition</h4>
<p>Having happily derived the maximisation problem, I‚Äôll do my best to convince you that this is, in fact, maximised by having the k-columns of $\mathbf{D}_k$ as the k eigenvectors of $\mathbf{X}^\top\mathbf{X}$ with largest eigenvalues. This will roughly take the form of an inductive proof. So let‚Äôs start with considering $k=1$, that is if we had the choice of using a single vector, what would we go with?</p>
<h5 id="base-case">Base case</h5>
<p>We‚Äôll use the lowercase, $\mathbf{d}$, to emphasise that it‚Äôs a vector rather than matrix. So let‚Äôs try and tackle:</p>
<p>$$\text{argmax}_{\mathbf{d}} \text{Tr}(\mathbf{d}^\top \mathbf{X}^\top  \mathbf{X}\mathbf{d})$$</p>
<p>The trace of a scalar, is defined as itself, so we wish to find $$\text{argmax}_{\mathbf{d}} \mathbf{d}^\top \mathbf{X}^\top  \mathbf{X}\mathbf{d}$$</p>
<p>However, recall that we mandated as our first assumption that the columns of $\mathbf{D}$ are orthonormal and hence we know that $\mathbf{d}^\top\mathbf{d} = 1$.</p>
<p>This allows us to reframe this as a constrained optimisation problem and use Lagrange multipliers to discover which vector minimises the quantity of interest whilst satisfying the norm constraint. For convenience, we‚Äôll use $\mathbf{A} = \mathbf{X}^\top  \mathbf{X}$.</p>
<p>Hence we can write this as:
$$L(\mathbf{d}, \mathbf{A}, \lambda) = \mathbf{d}^\top \mathbf{A}\mathbf{d} - \lambda(\mathbf{d}^\top \mathbf{d} - 1)$$</p>
<blockquote>
<p>TL;DR Lagrange multipliers are just a technique for optimising a function over a specific region, in our case we‚Äôre not looking for all vectors but only ones with a norm of 1. We rewrite the function to include the constraint and take the derivative of the new function, known as the <em>Lagrangian</em>.</p>
</blockquote>
<p>By taking the derivative of $L$ we can find the solution.</p>
<p>$$\frac{\partial L}{\partial \mathbf{d}} = 2\mathbf{A}\mathbf{d} - 2\lambda\mathbf{d}$$</p>
<p>The derivative is precisely zero when $\mathbf{A}\mathbf{d} = \lambda\mathbf{d}$, that is when $\mathbf{d}$ is an eigenvector of the matrix $\mathbf{A}$.
Furthermore, we can see that the quantity in fact takes on the associated eigenvalue since $\mathbf{d}^\top \mathbf{A}\mathbf{d} = \mathbf{d}^\top \lambda\mathbf{d} = \lambda $, where $\lambda$ is the associated eigenvalue. This is always possible since we can mandate that the eigenvector has a unit norm.</p>
<p>Hence, we can see here that for the base case, the best vector is the eigenvector with the largest eigenvalue.</p>
<h5 id="inductive-step">Inductive step</h5>
<p>Having showcased our hypothesis for $k=1$, let‚Äôs see what happens for other values of $k$. Precisely, let us show that if our hypothesis is true for some arbitrary $k$ then it is also true for some $k+1$. That is the best encoding matrix with $k+1$ columns, consists of the $k+1$ unit eigenvectors with the largest associated eigenvalues.</p>
<p>We are now interested in the following problem.</p>
<p>$$\text{argmax}_{\mathbf{D}_{k+1}} \text{Tr}(\mathbf{D}_{k+1}^\top ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ymohamedahmed.github.io/post/pca/">https://ymohamedahmed.github.io/post/pca/</a></em></p>]]>
            </description>
            <link>https://ymohamedahmed.github.io/post/pca/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23715662</guid>
            <pubDate>Thu, 02 Jul 2020 17:25:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Indaba grand challenge: curing Leishmaniasis, a neglected disease]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 7 (<a href="https://news.ycombinator.com/item?id=23715643">thread link</a>) | @adsodemelk
<br/>
July 2, 2020 | https://deeplearningindaba.com/grand-challenges/leishmaniasis/ | <a href="https://web.archive.org/web/*/https://deeplearningindaba.com/grand-challenges/leishmaniasis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
			<div id="main">
				<div id="content">
					
					<div>
						<div>
							<div>
								

<blockquote>
<p><strong>Join the live stream for the #IndabaGrandChallenge kickoff meeting on YouTube  on Tuesday 30 June 3pm Accra,Dakar (UTC) | 4pm Abuja,Kinshasa,Yaounde | 5pm Johannesburg,Lilongwe | 6pm Nairobi, Kigali</strong>. </p>
<p><cite><strong><a href="https://www.youtube.com/c/deeplearningindaba/live">https://www.youtube.com/c/deeplearningindaba/live</a></strong></cite></p></blockquote>
<hr>
<p>Leishmaniasis is a <a href="https://www.dndi.org/diseases-projects/leishmaniasis/">neglected disease</a>. As a disease of poverty, it has historically received <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3530408/">limited funding</a> for discovery, development and delivery of new tools. Current treatment is costly, lengthy, painful and sometimes toxic. Like a handful of similar diseases, it is the scourge of whole regions affected by them, because we still miss cheap, safe and effective cures for them.</p>
<p>At the same time, new drug candidates are being developed and old ones are being tested every day. Today, millions of drug activity assays are available at the press of a button. In this Indaba Grand Challenge, we dare to ask you to help identify amongst the already known, tested and (often) approved drugs, potential cures for different forms of leishmaniasis.</p>
<h2>Leishmaniasis</h2>
<figure>
<p>
<iframe title="KILLER DISEASES | How Leishmaniasis Affects the Body" width="1200" height="675" src="https://www.youtube.com/embed/ABgLFFOO1ek?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
</figure>
<p>Humanity has been remarkably successful in curing most of communicable diseases, be it of bacterial or viral origin. However, there remains a whole group of diseases that largely evade successful treatment ‚Äì the ones transmitted by parasites. Large number of them is caused by a group of small, single-celled animals named <em><a href="https://www.dndi.org/wp-content/uploads/2018/12/Rao_Drugdiscoverykinetoplastiddiseases_ACSInfectiousDiseases_2019.pdf">kinetoplastids</a>. </em>They cause such diseases as African sleeping sickness (caused by <em>Trypanosoma brucei</em>), Chagas disease (<em>Trypanosoma cruzii</em>) and&nbsp; Leishmaniasis (different <em>Leishmania</em> species). </p>
<figure><img src="https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis2.jpg" alt="" srcset="https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis2.jpg 959w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis2-300x163.jpg 300w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis2-768x417.jpg 768w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis2-103x56.jpg 103w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis2-285x155.jpg 285w" sizes="(max-width: 959px) 100vw, 959px"><figcaption> Child with post-kala-azar-dermal leishmaniasis in old Fangak  County, South Sudan. The area suffered  severe visceral leishmaniasis  outbreaks from 2009 to 2012. Source: WHO</figcaption></figure>
<p>Leishmaniases (as it is a whole group of diseases), are spread by bites of sandflies and readily communicated between animals (such as dogs). Out of 30 species that attack animals, 21 affect humans. There are more than 350 million people in nearly 90 countries, that live in areas where leishmaniasis is common. Around 90% of its most dangerous variant ‚Äì visceral leishmaniasis ‚Äì&nbsp; is recorded&nbsp; in Bangladesh, Nepal, Sudan and Brazil, but disease is prevalent also in Mexico, South and Central America, Asia (excluding the South-East Asia), Middle East, southern Europe and Africa (in particular North and East Africa) .</p>
<div>
<figure><a href="https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba.png" target="_blank" rel="noreferrer noopener"><img src="https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba-1024x599.png" alt="" srcset="https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba-1024x599.png 1024w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba-300x176.png 300w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba-768x449.png 768w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba-1536x899.png 1536w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba-2048x1198.png 2048w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba-96x56.png 96w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba-265x155.png 265w, https://deeplearningindaba.com/wp-content/uploads/2020/06/leishmaniasis-map-indaba.png 6460w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>
</div>
<p>Every year approximately 12 million people are afflicted with the disease, with over 2 million new cases each year, most of which is a cutaneous (skin) leishmaniasis (nearly 1.5 million), but nearly 25% comprises the most lethal, visceral variant. Parasite suppresses the host‚Äôs immune system to avoid eradication, which often leads to frequently lethal secondary respiratory infections.&nbsp; Yearly, approximately 50 thousand people die worldwide because of <em>Leishmania </em>caused diseases.  </p>
<p>Visceral leishmaniasis causes swelling, malaise, wasting, damages spleen and liver, as well as leads to characteristic graying of skin (hence the name <em>black fever</em>). The fever caused by the disease lasts for more than two weeks and does not abate with antimalarial drugs. The cutaneous type makes for wide-spread sores that can take over a year to heal, and lead to necrosis (dying of tissue). It leads to scars on the face, neck, arms and legs. The third, mucocutaneous type causes both skin and mucosal ulcers, leading to the damage of soft tissues and cartilage, predominantly of nose and mouth area. All types tend to co-occur with AIDS (approximately 1 in 60 AIDS patients in south of France suffers from leishmaniasis).</p>
<figure><img src="https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-1024x683.jpg" alt="" srcset="https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-1024x683.jpg 1024w, https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-300x200.jpg 300w, https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-768x512.jpg 768w, https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-1536x1024.jpg 1536w, https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-2048x1365.jpg 2048w, https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-84x56.jpg 84w, https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-233x155.jpg 233w, https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-600x400.jpg 600w, https://deeplearningindaba.com/wp-content/uploads/2020/06/Viscerial_Leishmaniasis_hr-scaled.jpg 2560w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption> Patient with post-kala-azar-dermal leishmaniasis. Was earlier  treated and cured for visceral leishmaniasis. Libo Kemkem district,  Ethiopia.  Source: WHO<br></figcaption></figure>
<p> The treatment for visceral leishmaniasis is problematic and relies mostly on antibiotics, which have a variable success rate. The most commonly used non-antibiotic drugs, containing pentavalent antimony (such as sodium stibogluconate or meglumine antimonate) are toxic to the heart, kidneys, pancreas and bone marrow of the patient, leading to headaches, abdominal issues, vomiting and low levels of blood platelets. They also require a month-long treatment through injections, as medication does not work well if taken by mouth. There is no safe treatment for cutaneous leishmaniasis, that would work dependably, with fluconazole (an antifungal medication) and pentamidine (an antimicrobial used for other kinetoplastid diseases) being the most promising support medications. Miltefosine, the first promising oral treatment for visceral leishmaniasis, tends to be effective for cutaneous form, but has limited use, as it is known to cause birth defects. </p>
<p>In the recent years a massive drug discovery campaign has led to discovery of a new drug (codenamed GNF6702) and its analog (a new, improved version, named NITD689), which affect parasites ability to degrade unnecessary and damaged proteins. While these drugs seem to work against a wide range of pathogens (including these causing African sleeping sickness, Chagas disease and visceral leishmaniasis), they are not effective against the other leishmaniases. Additionally, there is an emerging mutation among the parasites, that already now renders the drug ineffective. Therefore, even though it is currently successful in the clinical trials, it will most likely not lead to the eradication of the disease.&nbsp;  </p>
<p>There is a dire need for a new, safe therapy for kinetoplastis, one that can be administered earlier, with lesser likelihood of bothersome side effects, one that could eradicate these diseases once and for all. Finding this therapy is the goal of this Indaba Grand Challenge, and literally lives are at stake. The approach to identify potential cure candidates is drug repurposing. </p>
<h2>What is Drug Repurposing?</h2>
<figure><img src="https://deeplearningindaba.com/wp-content/uploads/2020/05/drug-repurposing.jpg" alt="" srcset="https://deeplearningindaba.com/wp-content/uploads/2020/05/drug-repurposing.jpg 910w, https://deeplearningindaba.com/wp-content/uploads/2020/05/drug-repurposing-300x198.jpg 300w, https://deeplearningindaba.com/wp-content/uploads/2020/05/drug-repurposing-768x508.jpg 768w, https://deeplearningindaba.com/wp-content/uploads/2020/05/drug-repurposing-85x56.jpg 85w, https://deeplearningindaba.com/wp-content/uploads/2020/05/drug-repurposing-234x155.jpg 234w" sizes="(max-width: 910px) 100vw, 910px"><figcaption>Photo Credit: pixabay.com</figcaption></figure>
<p>Drug repurposing is the act of researching if an existing drug can be used for new therapeutic purposes. It‚Äôs something that has been done for centuries. A large amount of medications on the market right now are used for multiple purposes: for instance, aspirin is a pain reliever and also a blood thinner, ibuprofen is also used for pain relief, and for reducing inflammations.</p>
<p>The high cost of research and development involved in finding new drugs means that most of these will be targeted to ‚ÄúFirst World‚Äù countries to generate returns.</p>
<p>For ‚Äúneglected diseases‚Äù or ‚Äútropical diseases‚Äù, drug repurposing is used as a sort of universal strategy: it lowers the costs of research and production and the time needed for clinic trials, which is why you‚Äôll find that many of these diseases use medication that was originally used for other illnesses.</p>
<h2>The Challenge </h2>
<p>Drug discovery methods and pipelines are well described and modular. Each can be decomposed into smaller pieces, which can be rearranged and modified. All of these pipelines rely heavily on knowledge representation, pattern detection and building of statistical models.</p>
<p>The goal of this Indaba Grand Challenge is to, through the use of standard techniques and publicly available data on drugs, drug targets and kinetoplastids (parasites causing amongst other leishmaniasis), identify either:</p>
<ul>
<li>Compounds among known, approved drugs which can target known drug targets in <em>Leishmania </em>(especially one of the 15 species known to cause the cutaneous type of disease)<em> </em>in addition to their official use.</li>
<li>Compounds among known, approved drugs with sufficiently similar targets in the goal organisms to the targets in kinetoplastids.</li>
</ul>
<p>Importantly, the verification of a drug-target interaction is possible and routinely done <em>in silico</em>. However, not all drug-target combinations can be verified, due to sheer combinatorial expansion and limited computational resources. In addition, the identification of similarities and analogies between known experimental data is far from trivial and, despite the existence of numerous approaches, cannot be solved by one statistical technique alone.</p>
<p>By launching this Grand Challenge, and true to the core values of Deep Learning Indaba, we aim to build a <strong>collaborative effort</strong>, joining experts and enthusiasts in machine learning and software engineering, with doctors, epidemiologists, medicinal chemists and policy experts, to create a <strong>synergistic effect at scale</strong>. Our vision, if it becomes true, is one where interesting discoveries of the community are taken up by the experts, and conclusions of the experts are fed back to the community to iteratively improve on its findings and make breakthroughs possible. <strong>No single person can do it perfectly, but through a joint effort, together we can. </strong></p>
<h2> Challenge Specs </h2>
<p><strong>Goal:</strong> Propose a new treatment, comprising an <em>Leishmania </em>protein (either from a defined species, or a protein present in the proteome of one or more of the <em>Leishmania </em>species) and a small molecule (or set of small molecules). Submission can be specified as:</p>
<ul>
<li>Small molecule (SMILES/SMARTS string or SDF file) and a protein name</li>
<li>PDB file with a structure of a target and a bound small molecule</li>
</ul>
<p><strong>Available resources: </strong>We have put together a list of available resources and additional material <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://deeplearningindaba.com/grand-challenges/leishmaniasis/resources/" target="_blank">here</a>.</p>

<h2>Who can apply?</h2>

<p>We invite you to join this initiative and help put an end to Leishmaniasis. We need your involvement, especially if, you are: </p>
<ul>
<li><strong>Data science</strong> or <strong>Machine Learning</strong> expert or enthusiast: we have the data, tools, benchmarks and everything you need to know to attack this problem. Our community needs your data wrangling skills. If you feel up for a challenge, apply here!</li>
<li><strong>Bioinformatics</strong> and <strong>Cheminformatics</strong> people: in addition to the resources, data and standardized protocols, we have a community, which can help you go the final mile from a great protocol to a great candidate. We need your expertise in translating life into bytes. If you can help, please apply here!</li>
<li><strong>Kinetoplastid</strong> <strong>researchers</strong>, <strong>practitioners</strong> and <strong>clinicians</strong>. We need you dearly. We will be generating loads of hypotheses and we need you to help make sense of them. We ‚Ä¶</li></ul></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://deeplearningindaba.com/grand-challenges/leishmaniasis/">https://deeplearningindaba.com/grand-challenges/leishmaniasis/</a></em></p>]]>
            </description>
            <link>https://deeplearningindaba.com/grand-challenges/leishmaniasis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23715643</guid>
            <pubDate>Thu, 02 Jul 2020 17:24:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Your MVP Is Too Bloated]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23715546">thread link</a>) | @arvando
<br/>
July 2, 2020 | http://www.cakewalklabs.com/blog/2020/7/2/top-mistake-of-designing-a-minimal-viable-product | <a href="https://web.archive.org/web/*/http://www.cakewalklabs.com/blog/2020/7/2/top-mistake-of-designing-a-minimal-viable-product">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1593710282011" id="item-5efe13df97ca774c2dd6975d"><div><div><div data-block-type="2" id="block-3a3c4c5bce691fe52f6a"><div><p>This bothers me a lot as a UX Designer, I see it from Fortune 500 companies, to venture funded Silicon Valley startups, to some-guy-in-a-basement startups. The issue has to do with how new features and new products are defined. Regardless of the client‚Äôs experience building digital products, SaaS, mobile apps, web apps, the majority generally tend to screw this up. As a Product Design Consultant, I haven‚Äôt worked on one feature where I didn‚Äôt have to provide clarity to strip down and simplify the scope. The real issue is that the client tends to give little thought to the product scope (amount and complexity of features) for the first version and how it feeds into the second version, through user feedback and analytics data, and how that feeds into the third version. Whatever you think your Minimal Viable Product is, can be stripped much further down.</p><p>I have a few theories as to why clients make this mistake.&nbsp;</p><ul data-rte-list="default"><li><p>They‚Äôre too passionate and excited about the new feature or product, so there is a lot of attachment to the final product vision, which makes for emotional decision making</p></li><li><p>They have a really grand vision and they *think they‚Äôve stripped down the scope to the core, when they haven‚Äôt</p></li><li><p>They think they have to build everything because of a bureaucratic reason</p></li><li><p>They think the user won‚Äôt like the feature or product, because the real value is in the combination of all of those features being in one place</p></li></ul><p>This mistake is important because building too much, too fast, will create a larger time frame between their starting point and their point of receiving positive feedback from users (qualitative feedback, product market fit, user analytics data or some KPI). This larger gap will lead to them running out of resources faster, whether it‚Äôs funding, or psychological motivation to continue.</p><p>I will use a couple of examples based on real clients I‚Äôve worked with to explain my theory and how to go about the thinking.&nbsp;</p><p>1- The client was building a SaaS analytics dashboard for an enterprise use case. As with any data visualization dashboard, giving the user the ability to see an overview snapshot of data to answer their underlying business question is the primary goal, and the secondary goal is for them to dig deeper into specific data points to further uncover information that will guide their business decisions. The first step is to build the primary overview dashboard with the snapshot 30,000 ft view of the data and optimize that in the first version, then focusing on iterations. The second step is to build the deep dive views. If there is no interaction with the overview of the data because it‚Äôs deemed not interesting enough, because it‚Äôs answering the wrong business questions that the user doesn‚Äôt actually care about, then the deep dive views don‚Äôt matter, the user won‚Äôt try to dive deep into something irrelevant. The way to measure the interaction with the snapshot view of the data without having built the deep dive views was to allow click actions into that overview data, but just provide static deep dives, rather than fancy interactive deep dives that lead to more deep dives. In short, the secondary view, which in this case was the analytics deep dives, had to be stripped down a lot.</p><p>2- The client was building a social application. ‚ÄúWe need the ability for users to comment, and for other users to respond to these comments via text, voice, and video.‚Äù If the initial user doesn‚Äôt comment, the corresponding feature of text, voice and video is utterly useless and literally unusable in the UI. So we built the initial comments section, measured the interaction using an analytics tool, or sometimes manually tracked what percentage of users left the initial comment. The idea was that if that percentage is high enough, we would continue with the rest of the product hypothesis, if it‚Äôs low, rethink the initial comment.</p><p>In short, design the core, core-core, like the actual core. Then strip it down further, and build it. And measure it, optimize it. And once it reaches a certain level, then you can start to build the rest, otherwise ‚Äúthe rest‚Äù will never be used, and won‚Äôt be given a fair chance to be measured.</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>http://www.cakewalklabs.com/blog/2020/7/2/top-mistake-of-designing-a-minimal-viable-product</link>
            <guid isPermaLink="false">hacker-news-small-sites-23715546</guid>
            <pubDate>Thu, 02 Jul 2020 17:19:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Honest status reporting and AWS service status ‚Äútruth‚Äù in a post-truth world]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23715218">thread link</a>) | @Alupis
<br/>
July 2, 2020 | https://www.ably.io/blog/honest-status-reporting-aws-service | <a href="https://web.archive.org/web/*/https://www.ably.io/blog/honest-status-reporting-aws-service">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<section>
<div>
<p><strong><em>TL;DR: Don‚Äôt trust AWS status reports, they‚Äôre misleading</em></strong></p>
<p>This morning at 1:00am the reporting systems for <a href="https://ww.ably.io/platform" rel="noopener">our Ably realtime platform</a> notified us of a whole range of service failures for one of our customers in a dedicated realtime cluster in AWS‚Äô Northern California datacenter (us-west-1).</p>
<p>We investigated and discovered network partitioning along with other severe network failures. We checked the AWS status dashboard for information‚Ää‚Äî‚Äänothing, all green. 30 minutes later AWS finally posted a status update with this:</p>
<figure><img src="https://ik.imagekit.io/ably/ghost/medium/max/1600/1*ClSgAjRsUnhaPSpoKBPPPg.png?tr=w-1520" srcset="
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*ClSgAjRsUnhaPSpoKBPPPg.png?tr=w-345 345w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*ClSgAjRsUnhaPSpoKBPPPg.png?tr=w-470 470w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*ClSgAjRsUnhaPSpoKBPPPg.png?tr=w-760 760w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*ClSgAjRsUnhaPSpoKBPPPg.png?tr=w-1520 1520w
    " sizes="
      (max-width: 760px) 100vw,
      (max-width: 1520px) 760px,
      1520px
    "></figure><p>Looking at the notice here is what it said:</p>
<figure><img src="https://ik.imagekit.io/ably/ghost/medium/max/1600/1*xmFKeF3tdEKdwNh6FOHK_A.png?tr=w-1520" srcset="
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*xmFKeF3tdEKdwNh6FOHK_A.png?tr=w-345 345w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*xmFKeF3tdEKdwNh6FOHK_A.png?tr=w-470 470w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*xmFKeF3tdEKdwNh6FOHK_A.png?tr=w-760 760w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*xmFKeF3tdEKdwNh6FOHK_A.png?tr=w-1520 1520w
    " sizes="
      (max-width: 760px) 100vw,
      (max-width: 1520px) 760px,
      1520px
    "></figure><p>Ok, that doesn‚Äôt sound too bad, let‚Äôs revisit the legend from the <a href="https://status.aws.amazon.com/" rel="noopener">AWS status dashboard</a>:</p>
<figure><img src="https://ik.imagekit.io/ably/ghost/medium/max/1600/1*annsHTb8OJDOwaL3C7V7nQ.png?tr=w-1520" srcset="
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*annsHTb8OJDOwaL3C7V7nQ.png?tr=w-345 345w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*annsHTb8OJDOwaL3C7V7nQ.png?tr=w-470 470w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*annsHTb8OJDOwaL3C7V7nQ.png?tr=w-760 760w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*annsHTb8OJDOwaL3C7V7nQ.png?tr=w-1520 1520w
    " sizes="
      (max-width: 760px) 100vw,
      (max-width: 1520px) 760px,
      1520px
    "></figure><p>Great, so Amazon is telling us that everything is operating normally and there is a minor notice stating there are Network Connectivity issues. Here is what the cluster looked like:</p>
<figure><img src="https://ik.imagekit.io/ably/ghost/medium/max/1600/1*zc_RSHffo7hWTJ8lVkH-xQ.png?tr=w-1520" srcset="
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*zc_RSHffo7hWTJ8lVkH-xQ.png?tr=w-345 345w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*zc_RSHffo7hWTJ8lVkH-xQ.png?tr=w-470 470w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*zc_RSHffo7hWTJ8lVkH-xQ.png?tr=w-760 760w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*zc_RSHffo7hWTJ8lVkH-xQ.png?tr=w-1520 1520w
    " sizes="
      (max-width: 760px) 100vw,
      (max-width: 1520px) 760px,
      1520px
    "><figcaption>Network graphs at the time in that effected datacenter</figcaption></figure><p>And here is the net effect for that customer‚Äôs dedicated datacenter:</p>
<figure><img src="https://ik.imagekit.io/ably/ghost/medium/max/1600/1*Uxq0g7k-avP45qRAV-pTOg.png?tr=w-1520" srcset="
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*Uxq0g7k-avP45qRAV-pTOg.png?tr=w-345 345w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*Uxq0g7k-avP45qRAV-pTOg.png?tr=w-470 470w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*Uxq0g7k-avP45qRAV-pTOg.png?tr=w-760 760w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*Uxq0g7k-avP45qRAV-pTOg.png?tr=w-1520 1520w
    " sizes="
      (max-width: 760px) 100vw,
      (max-width: 1520px) 760px,
      1520px
    "><figcaption>Router error&nbsp;rates</figcaption></figure><p>So we contacted our customer about the issue and discussed the options (we ended up setting up a new cluster for them in another region). However he visits the AWS status page and doubts our ‚Äútruth‚Äù because quite rightly, he says everything is green. Here is what the status page looked like:</p>
<figure><img src="https://ik.imagekit.io/ably/ghost/medium/max/1600/1*LV8mLFRrcqOPDdHFGPGJ-Q.png?tr=w-1520" srcset="
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*LV8mLFRrcqOPDdHFGPGJ-Q.png?tr=w-345 345w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*LV8mLFRrcqOPDdHFGPGJ-Q.png?tr=w-470 470w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*LV8mLFRrcqOPDdHFGPGJ-Q.png?tr=w-760 760w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*LV8mLFRrcqOPDdHFGPGJ-Q.png?tr=w-1520 1520w
    " sizes="
      (max-width: 760px) 100vw,
      (max-width: 1520px) 760px,
      1520px
    "><figcaption>AWS Status site dashboard</figcaption></figure><p>Right, so we doubted ourselves and considered that maybe this is just us. Looking at <a href="http://downdetector.com/status/aws-amazon-web-services" rel="noopener">downdetector.com</a> though that was clearly not the case:</p>
<figure><img src="https://ik.imagekit.io/ably/ghost/medium/max/1600/1*noXSgm8uwWerVBTDDafIhQ.png?tr=w-1520" srcset="
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*noXSgm8uwWerVBTDDafIhQ.png?tr=w-345 345w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*noXSgm8uwWerVBTDDafIhQ.png?tr=w-470 470w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*noXSgm8uwWerVBTDDafIhQ.png?tr=w-760 760w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*noXSgm8uwWerVBTDDafIhQ.png?tr=w-1520 1520w
    " sizes="
      (max-width: 760px) 100vw,
      (max-width: 1520px) 760px,
      1520px
    "></figure><p>Ok, so at this point we now knew that:</p>
<ul>
<li>
<strong>Amazon AWS flat out lies</strong>‚Ää‚Äî‚Ääconsidering a cloud based network accessible service to be ‚Äúoperating normally‚Äù when the network is not working is insane</li>
<li>
<strong>We cannot trust Amazon AWS status updates </strong>because the information provided to us about the severity of the issue or how quickly it will really be resolved</li>
</ul>
<p>We suspect if we had reached out to AWS in this post-truth world, this is what we would have got:</p>
<figure><img src="https://ik.imagekit.io/ably/ghost/medium/max/1600/1*BmlyqPNJ4wd4rUi1cTiQxQ.png?tr=w-1520" srcset="
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*BmlyqPNJ4wd4rUi1cTiQxQ.png?tr=w-345 345w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*BmlyqPNJ4wd4rUi1cTiQxQ.png?tr=w-470 470w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*BmlyqPNJ4wd4rUi1cTiQxQ.png?tr=w-760 760w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*BmlyqPNJ4wd4rUi1cTiQxQ.png?tr=w-1520 1520w
    " sizes="
      (max-width: 760px) 100vw,
      (max-width: 1520px) 760px,
      1520px
    "></figure><h3 id="so-what-should-have-happened">So what should have happened</h3>
<p>Fortunately that‚Äôs pretty simple‚Ää‚Äî‚Ääwhat we require is honesty and we expect AWS to err on the side of caution.</p>
<p>Here‚Äôs what we did at <a href="https://www.ably.io/" rel="noopener">Ably</a> for our customers to notify them about what happened when we detected the fault:</p>
<ul>
<li>We had monitoring systems to tell us immediately there was a fault, which in turn created an incident automatically in <a href="https://status.ably.io/" rel="noopener">our status site</a> within minutes of the problems in us-west-1.</li>
<li>We then manually <a href="https://status.ably.io/incidents/377" rel="noopener">updated the incident on our status site</a> with our commentary and emailed everyone signed up for status updates with the issue and what we were doing about it (which was to route traffic away from the faulty datacenter).</li>
<li>We took an honest approach and weren‚Äôt worried to show a bit of orange on our status site. Because if something is not operating as expected, then we are pretty sure that is not classified as ‚Äúoperating normally‚Äù and at best should be classified as ‚Äúperformance issues‚Äù. See our status dashboard below:</li>
</ul>
<figure><img src="https://ik.imagekit.io/ably/ghost/medium/max/1600/1*V7yUO1VhlebTdPCbxRma9A.png?tr=w-1520" srcset="
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*V7yUO1VhlebTdPCbxRma9A.png?tr=w-345 345w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*V7yUO1VhlebTdPCbxRma9A.png?tr=w-470 470w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*V7yUO1VhlebTdPCbxRma9A.png?tr=w-760 760w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*V7yUO1VhlebTdPCbxRma9A.png?tr=w-1520 1520w
    " sizes="
      (max-width: 760px) 100vw,
      (max-width: 1520px) 760px,
      1520px
    "><figcaption><a href="https://status.ably.io/" data-href="https://status.ably.io" rel="noopener" target="_blank">Ably status dashboard at status.ably.io</a></figcaption></figure><ul>
<li>We updated our customers once this issue was resolved via email and on our status site.</li>
<li>We kept a record of what happened for customers to review in <a href="https://status.ably.io/incidents" rel="noopener">our incidents section</a>.</li>
</ul>
<h3 id="amazon-aws-you-can-and-should-do-better">Amazon AWS‚Ää‚Äî‚Ääyou can and ‚Äúshould‚Äù do better</h3>
<p>Our plea to Amazon AWS is please don‚Äôt fall into this post-truth trap and aim to have false green in your status dashboard. Looking at your AWS status dashboard today, in spite of the fact that an entire datacenter was unusable for a few hours this morning, is completely green. See the screenshots: (<a href="https://dl.dropboxusercontent.com/u/1575409/Ably/blog/status-aws-amazon-today-1.png" rel="noopener">page 1</a>), (<a href="https://dl.dropboxusercontent.com/u/1575409/Ably/blog/status-aws-amazon-today-2.png" rel="noopener">page 2</a>)‚Ää‚Äî‚Ääthere is so much green on the status page that we were unable to fit the screenshot in one image (max height of 30,000 pixel). Amazon, your AWS status page today has 38,000 vertical pixels of green!</p>
<p>We rely on AWS infrastructure to deliver our realtime data delivery platform. Amazon needs to take their downtime and issues more seriously, be more upfront about what‚Äôs going on, and not wait half an hour to report that a datacenter being offline is ‚Äúoperating normally‚Äù. It‚Äôs not like they don‚Äôt have resources that outstrip any other infrastructure provider, <a href="https://www.google.co.uk/search?%7Bgoogle:acceptedSuggestion%7Doq=amazon+hires+100%2C000+in+a+month&amp;sourceid=chrome&amp;ie=UTF-8&amp;q=amazon+hires+100%2C000+in+a+month&amp;gws_rd=ssl" rel="noopener">they‚Äôre hiring 100k employees in the next 18 months</a>.</p>
<p>Amazon AWS, we expect more of you. Please be honest.</p>
<hr>
<figure><img src="https://ik.imagekit.io/ably/ghost/medium/max/1600/1*DBw-F0dHtsKD7JnniwdWmw.png?tr=w-1520" srcset="
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*DBw-F0dHtsKD7JnniwdWmw.png?tr=w-345 345w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*DBw-F0dHtsKD7JnniwdWmw.png?tr=w-470 470w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*DBw-F0dHtsKD7JnniwdWmw.png?tr=w-760 760w,
      https://ik.imagekit.io/ably/ghost/medium/max/1600/1*DBw-F0dHtsKD7JnniwdWmw.png?tr=w-1520 1520w
    " sizes="
      (max-width: 760px) 100vw,
      (max-width: 1520px) 760px,
      1520px
    "><figcaption>Matthew O‚ÄôRiordan, CEO,&nbsp;<a href="https://www.ably.io/" data-href="https://www.ably.io" rel="noopener" target="_blank">Ably</a></figcaption></figure>
</div>


</section>

</article>
</div>
</div></div>]]>
            </description>
            <link>https://www.ably.io/blog/honest-status-reporting-aws-service</link>
            <guid isPermaLink="false">hacker-news-small-sites-23715218</guid>
            <pubDate>Thu, 02 Jul 2020 16:52:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I struggled to build a Nextcloud server (and won)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23715201">thread link</a>) | @acolannino
<br/>
July 2, 2020 | https://acolannino.io/blog/how-i-struggled-to-build-a-nextcloud-server-and-won/ | <a href="https://web.archive.org/web/*/https://acolannino.io/blog/how-i-struggled-to-build-a-nextcloud-server-and-won/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h3 id="why-am-i-doing-this-to-myself">Why am I doing this to myself?</h3>
<p>I really like taking notes. Notes are an extension of my stupid brain, which can‚Äôt remember a <em>damn</em> thing on its own. All these notes were being stored on Google‚Äôs servers, which <a href="https://en.wikipedia.org/wiki/PRISM_%28surveillance_program%29" target="_blank" rel="noreferrer noopener">didn‚Äôt</a> <a href="https://www.gnu.org/proprietary/malware-google.en.html" target="_blank" rel="noreferrer noopener">seem like</a> <a href="https://www.washingtonpost.com/technology/2019/06/21/google-chrome-has-become-surveillance-software-its-time-switch/" target="_blank" rel="noreferrer noopener">the best</a> <a href="https://www.eff.org/deeplinks/2020/03/google-says-it-doesnt-sell-your-data-heres-how-company-shares-monetizes-and" target="_blank" rel="noreferrer noopener">idea</a>. And it wasn‚Äôt just notes. Pictures, videos, miscellaneous files, I was giving it all to Google for free.</p>
<p>Since my notes contain <em>my bad ideas, and they are <strong>my</strong> bad ideas alone</em>, I wanted to take back control of my data. After researching ways to do such a thing (through the Google search engine of course), my best option seemed to be a <a href="https://nextcloud.com/" target="_blank" rel="noreferrer noopener">Nextcloud server</a>.</p>
<p>Nextcloud has all the niceties of a Google Drive or Dropbox, but you host it yourself on your own hardware, and no one‚Äôs allowed to snoop. This sounded great! This‚Äôll be so easy! I‚Äôll get this running in just a couple minutes!</p>
<p>Maybe you guessed it from the length of this article, but‚Ä¶ this was not the case. Building and setting up this server was a nightmare hellhole, and I‚Äôm here today to share my hell with you, the reader, for free!</p>
<p>This isn‚Äôt so much a guide or tutorial - more just me explaining (and venting about) the massive effort it took to set this damn thing up. I hope somebody someday learns something from my suffering, or is maybe just entertained.</p>
<h3 id="the-hardware">The hardware</h3>
<p>I had been interested in doing <em>something, anything at all</em>, with a <a href="https://www.raspberrypi.org/" target="_blank" rel="noreferrer noopener">Raspberry Pi</a> for a while, so this was my excuse. Beyond that, I just followed <a href="https://magpi.raspberrypi.org/articles/build-a-raspberry-pi-nas" target="_blank" rel="noreferrer noopener">this great article from a Pi magazine</a> for my hardware choices. If you‚Äôre wondering what hardware I used, look there. I copied it exactly. Plus, c‚Äômon, look how cute everything looks stacked up like that! A literal ‚Äústack‚Äù! Ha!</p>
<p><img src="https://acolannino.io/blog/how-i-struggled-to-build-a-nextcloud-server-and-won/nextbox.png" alt="nextbox"></p>
<p>One part the guide doesn‚Äôt explain very well was the ‚ÄúUSB powered hub‚Äù - both why you need one, and what that actually is. Is it a hub powered by USB? A USB powered by a ‚Äúhub‚Äù? What is a ‚Äúhub‚Äù? Maybe it seems obvious to you, and maybe I was just sleep deprived at the time, but I was having trouble wrapping my smooth brain around this concept.</p>
<p>Turns out, the USB hub is simply needed to provide power to the two hard drives, rather than the power going to the Pi <em>and</em> the drives. I have no idea if this was really necessary, but it makes me feel 10% more confident my drives won‚Äôt crap out at any moment, and that helps me go to sleep at night.</p>
<h3 id="raid-1-or-whatever-that-means">RAID 1, or whatever that means</h3>
<p>Here I was, all ready to go in fulfilling my long-held dream of running my own little server. Then my stupid coworker comes in, and asks ‚Äúhey, what if your drive fails? what will you do then?‚Äù and ruins all of my fun.</p>
<p>He tells me I should do ‚ÄúRAID‚Äù, which is apparently all the rage. RAID stands for ‚ÄúRedundant, Awesome‚Ä¶ I dunno‚Äù, and was invented on a whim by <a href="https://en.wikipedia.org/wiki/RAID#History" target="_blank" rel="noreferrer noopener">some random nerds in the 80‚Äôs</a>. To attempt to give an actual explanation: Using a RAID 1 setup means you get data redundancy, as it will constantly mirror the drives. If one drive craps out, the other drive will still have all the same data, so you just replace the broken one and go about your day as normal. The downside of RAID 1 is you‚Äôre getting half the storage capacity that you paid for, but I figured 1 terabyte was large enough to store plenty of memes.</p>
<p>Setting up the RAID array was by far the most pain-free part of the process. Actually, it was the <em>only</em> pain-free part, the rest was pure suffering. I recommend doing this for fun if you‚Äôre bored on a Friday evening. It‚Äôs cathartic, and the only part of this whole thing that <a href="https://www.youtube.com/watch?v=nVqcxarP9J4" target="_blank" rel="noreferrer noopener">just worked</a>.</p>
<p>All I had to do was run some cute little commands from the guide, and I was golden. I didn‚Äôt fully understand the intricacies of everything I was doing, and the command-line interfaces for some of these programs were absolutely wild (press ‚Äòn‚Äô for a new partition, and ‚Äòp‚Äô for a ‚Äúprimary partition‚Äù? Really <code>fdisk</code>? Does this make you happy?), but other than that, it was all smooth sailing.</p>
<p>I should note - no one on the internet really cared to explain how a RAID setup should work with Nextcloud. Eventually I figured this out - the RAID array is seen by the OS as one device, so just politely ask Nextcloud to use that instead of the SD card. I ended up having to <a href="https://docs.nextcloud.com/server/latest/admin_manual/issues/general_troubleshooting.html#troubleshooting-data-directory" target="_blank" rel="noreferrer noopener">create a symlink from Nextcloud‚Äôs data directory to a directory on my RAID device</a>, but this wasn‚Äôt the worst thing I had to suffer through.</p>
<h3 id="big-pixel-energy-destroys-my-wifi">Big Pixel Energy destroys my WiFi</h3>
<p>So here I am, all proud and happy of my brand new Raspberry Pi running a fresh <del>Raspbian</del> Raspberry Pi OS. As I was setting up the RAID array, downloading lots of cute <a href="https://en.wikipedia.org/wiki/Unix_philosophy" target="_blank" rel="noreferrer noopener">UNIX-style utilities</a>, the WiFi starts to cut in-and-out. This has been a problem on my other main machines ever since I switched them to Linux, so I figured it was the <em>mysterious Intel WiFi+bluetooth death bug</em> plaguing me on yet another machine.</p>
<p>I did some more digging, and found what I believe to be the truth (or, as close as <em>I‚Äôll</em> ever get to the truth). There appears to be a <a href="https://www.raspberrypi.org/forums/viewtopic.php?t=247982" target="_blank" rel="noreferrer noopener">widely reported problem with the Pi 4</a> where the signals coming out from the HDMI (which are shaped like squares?) are the same frequency(?) as the WiFi. So, if your display resolution is pumped up high enough, and that HDMI is cranking out lots of square signals, <a href="https://www.raspberrypi.org/forums/viewtopic.php?p=1514642&amp;sid=b811be4b798c7ab50d7626c691b5cc26#p1514642" target="_blank" rel="noreferrer noopener">the WiFi gets totally borked</a>. Neat.</p>
<p>This is clearly absurd, and I hate it. Hardware is bad, and everyone saying ‚Äúprogrammers gotta learn hardware too!!!‚Äù should get off my lawn. At first I started following the internet‚Äôs advice to simply ‚Äúlower your screen resolution so the WiFi goes fast‚Äù, but this became tiring on the eyes (especially with the added problem of <a href="https://www.raspberrypi.org/forums/viewtopic.php?t=250534" target="_blank" rel="noreferrer noopener">not being able to use redshift on the Pi</a>).</p>
<p>Even though I was reluctant to at first, eventually I started controlling my Pi via an SSH terminal from another machine to avoid this problem entirely. Boy oh boy, was this a joyful discovery. Not only was I freed from whatever stupid resolution the WiFi demanded, but I could also use my beloved blue-light filter to prevent my retinas from burning up. Sure, I had no GUI, but learning to do everything through the terminal came easily enough, and once I got there, I felt like some kind of computer wiz-kid.</p>
<h3 id="the-installation">The installation</h3>
<p>After the RAID was set up and I got SSH going, it was time to install Nextcloud. This proved to be shockingly difficult. There can‚Äôt just be a little <code>sudo apt install nextcloud</code> action, no no no no no. You need to install each little bit yourself, by hand, and glue every piece together (<code>nextcloud</code> isn‚Äôt even in the apt repository, of course you have to download / unpack something called a ‚Äútarball‚Äù yourself).</p>
<h4 id="attempt-1-snap">Attempt 1: Snap!</h4>
<p><a href="https://snapcraft.io/" target="_blank" rel="noreferrer noopener">Snap</a> is Canonical‚Äôs (maker of Ubuntu) locked-down little sandbox for Linux apps. The word ‚Äúcontainer‚Äù is thrown around when describing it, and I have no idea if that‚Äôs correct, but I sure as heck wouldn‚Äôt recommend the <a href="https://snapcraft.io/nextcloud" target="_blank" rel="noreferrer noopener">official Nextcloud snap</a>.</p>
<p>The major selling point of snap is that it bundles together an application‚Äôs dependencies, so it will <em>just work</em> on any Linux distribution. This sounds great! Sign me up! I‚Äôm lazy and hate installing my own dependencies! Who the heck wants to do that? Shell scripts, that‚Äôs who.</p>
<p>Problem is, this doesn‚Äôt <em>really</em> work on every distro, and in fact, it doesn‚Äôt work on the latest Raspberry Pi OS. Do I know why? No. The Nextcloud snap <a href="https://en.wikipedia.org/wiki/Fail-silent_system" target="_blank" rel="noreferrer noopener">failed silently</a> before starting up, and it was too shy to tell me why. Cool.</p>
<h4 id="attempt-2-some-shell-scripts-i-found">Attempt 2: Some shell scripts I found</h4>
<p>At this stage, I was still committed to being a lazy jerk. There‚Äôs no way in heck I would manually install <a href="https://docs.nextcloud.com/server/latest/admin_manual/installation/source_installation.html#prerequisites-for-manual-installation" target="_blank" rel="noreferrer noopener">30-something php modules</a> by hand. So, I found a <a href="https://ownyourbits.com/nextcloudpi/" target="_blank" rel="noreferrer noopener">flashy looking site that claimed to have the scripts for me</a>. It didn‚Äôt work. The script took multiple runs to actually complete itself, and after the 5th or so attempt, it seemed happy. I went to the web GUI, told it to ‚Äúinitialize‚Äù, and it kinda hung out there for a while. I went to take a walk, and when I came back and it was still pretending to initialize.</p>
<p>I found another <a href="https://github.com/nextcloud/vm" target="_blank" rel="noreferrer noopener">official-sounding shell script</a>, in a last-ditch attempt at being lazy. At least this script had the courage to fail immediately, as it‚Äôs <a href="https://github.com/nextcloud/vm/blob/master/nextcloud_install_production.sh/#L83" target="_blank" rel="noreferrer noopener">hardcoded to only work specifically on Ubuntu 20.04</a>. Would have been real nice if it had told me that up-front, but hey, I‚Äôm not the one going through the trouble of writing all these (failing) shell scripts.</p>
<h4 id="attempt-3-the-hard-way">Attempt 3: The hard way</h4>
<p>Being lazy clearly wasn‚Äôt going so well. By now several days had passed, and all I had to show for myself was a whole terabyte of nothing. Worse yet, the shell scripts I ran had spread their little tentacles all over my pure OS install, so I knew I‚Äôd have trouble in the future if I left all that cruft in-place. I decided to re-image my OS, and that I would repeat the RAID setup once I got Nextcloud going.</p>
<p>As previously mentioned, the <a href="https://docs.nextcloud.com/server/latest/admin_manual/installation/source_installation.html" target="_blank" rel="noreferrer noopener">recommended installation</a> wants you to install and hook each bit up together yourself. This approach made some sense as I learned (sort of, vaguely) more about how Nextcloud works - It‚Äôs running on a webserver directly on your machine, handling all the networking and whatnot, with a full-on SQL database and lots of PHP magic happening too. So, it‚Äôs understandable that Nextcloud has to spread it‚Äôs mischievous claws in each and every crevice of your OS.</p>
<p>I followed the <a href="https://docs.nextcloud.com/server/latest/admin_manual/index.html" target="_blank" rel="noreferrer noopener">Nextcloud documentation</a>, which sure does exist. In their defense, all of their software is <a href="https://en.wikipedia.org/wiki/Free_and_open-source_software" target="_blank" rel="noreferrer noopener">free and open</a>, including the docs, so I could have submitted any number of changes, and yet here I am selfishly writing this blog. The worst part of this process was the aforementioned php modules, which had to be installed one-by-one, and had mismatched names compared to the Debian repository. I had these all installed after about an hour, and I remember listening to a podcast in the background while suffering through it.</p>
<p>After <code>apt install</code>ing every module (seriously, why doesn‚Äôt php have it‚Äôs own package manager?!), then gliding through the initialization of Nextcloud with <code>occ</code>, my server was working. The <em>Nextcloud Hub</em> web interface greeted me with the most pleasant design and animations I had seen in quite some time. <strong>It was over. I had won.</strong></p>
<h3 id="conclusion">Conclusion</h3>
<p>All in all, I sure did have a time. The admin page still won‚Äôt stop whining about a ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acolannino.io/blog/how-i-struggled-to-build-a-nextcloud-server-and-won/">https://acolannino.io/blog/how-i-struggled-to-build-a-nextcloud-server-and-won/</a></em></p>]]>
            </description>
            <link>https://acolannino.io/blog/how-i-struggled-to-build-a-nextcloud-server-and-won/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23715201</guid>
            <pubDate>Thu, 02 Jul 2020 16:49:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Approaching Rails Legacy Systems Chapter 2: Become a Git Historian]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23715128">thread link</a>) | @magmalabs
<br/>
July 2, 2020 | http://blog.magmalabs.io/2020/07/02/approaching-rails-legacy-systems-chapter-2-become-a-git-historian.html | <a href="https://web.archive.org/web/*/http://blog.magmalabs.io/2020/07/02/approaching-rails-legacy-systems-chapter-2-become-a-git-historian.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
			<div>
				
				<div id="post-6097">

										
					<section>

								<!-- END .ss-inline-share-wrapper -->
		<span><span>Reading Time: </span> <span>4</span> <span>minutes</span></span>
<h4>To keep track of how a project has been changing through time is key to provide a big picture of what things have been changing and why. After all, the business logic or the domain required those changes to be recorded. Read this to know why it is important to keep an eye on a project‚Äôs history.</h4>

<h2>Become a Git Historian</h2>
<p>This is chapter 2 of a series of blog posts about some pieces of advice, tools, and tips you can consider when you arrive at a Rails project considered as Legacy.</p>
<p>In the <a href="http://blog.magmalabs.io/2020/04/24/approaching-rails-legacy-systems-chapter-1-project-anatomy.html">previous chapter</a>, we reviewed our project‚Äôs anatomy.</p>
<p>In this chapter, we are using <a href="https://git-scm.com/">Git</a> and other tools related to it to find out more about our Rails Legacy System. But this time, it‚Äôs our project‚Äôs history turn.</p>
<p>First, I want us to understand ‚Äò<strong>history</strong>‚Äò as:</p>
<blockquote><p>
  ‚ÄúThe whole series of past events connected with someone or something‚Äù.
</p></blockquote>
<p>When speaking about history in a Rails project, it‚Äôs really important to check <em>how</em> our project has changed through time to get an idea of why things have been modified. Some of those adjustments were maybe done based on business logic, or maybe the domain required those changes.</p>
<p>Maybe, other changes happened because someone followed a particular path ‚Äîwhich is a normal thing if you consider that every project is different and that there are infinite factors that can affect it in a positive or in a negative way.</p>
<span><span><a href="https://twitter.com/intent/tweet?url&amp;text=In%20Software%20Development%2C%20a%20legacy%20system%20is%20outdated%20computing%20software%20that%20is%20still%20in%20use.&amp;via=weareMagmaLabs&amp;related=weareMagmaLabs" target="_blank" rel="noopener noreferrer">In Software Development, a legacy system is outdated computing software that is still in use. </a></span><a href="https://twitter.com/intent/tweet?url&amp;text=In%20Software%20Development%2C%20a%20legacy%20system%20is%20outdated%20computing%20software%20that%20is%20still%20in%20use.&amp;via=weareMagmaLabs&amp;related=weareMagmaLabs" target="_blank" rel="noopener noreferrer">Click To Tweet</a></span>
<p>In Software Development, a legacy system is outdated computing software that is still in use. That system still meets the needs it was originally designed for but doesn‚Äôt allow growth. What a legacy system does now for the project is all it will ever do. A legacy system‚Äôs older technology won‚Äôt allow it to interact with newer systems.</p>
<h2>Git extras</h2>
<p>To get a general summary of things about the project, like repo age, the number of commits, and who the people involved are we could use <a href="https://github.com/tj/git-extras"><code>git-extras</code></a>.</p>
<pre><code>$ brew install git-extras
</code></pre>
<pre><code>$ git summary

 project  : big_rails_jump
 repo age : 7 years
 active   : 1167 days
 commits  : 23794
 files    : 4084
 authors  :
  3392  Aaron Patterson             14.3%
  2596  David Heinemeier Hansson    10.9%
  2389  Yukihiro Matsumoto          10.0%
  2091  Lenny Kravitz               8.8%
  1017  Pedro Infante               4.3%
  1011  Tania Mu√±oz                 4.2%
   986  Edwin Cruz                  4.1%
   870  Juan Carlos Ruiz            3.7%
   857  Omar Vazquez                3.6%
   773  Jonathan Tapia              3.2%
   695  Alejandro Espinoza          2.9%
   667  Heriberto Perez             2.8%
   590  Jose David                  2.5%
   548  Samantha Bello              2.3%
   430  Juan Escutia                1.8%
   417  J Balvin                    1.8%
   309  Myles Kennedy               1.3%
   296  Federico Crespo             1.2%
   266  Dr Simi                     1.1%
   257  Tigger                      1.1%
   246  Emmanuel Delgado            1.0%
   234  Victor Velazquez            1.0%

</code></pre>
<p>Here is another interesting feature from git-extras, let‚Äôs try <code>git effort</code>:</p>
<pre><code>$ git effort --above 15 {src,lib}/*
</code></pre>
<blockquote><p>Displays ‚Äúeffort‚Äù statistics. Currently, it shows just the number of commits per file, highlighting the parts with the most activity. The ‚Äúactive days‚Äù column is the total number of days when contributed modifications to this file were made.</p></blockquote>
<p><a href="https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/08/1__bash_and_Edit_Post_%E2%80%B9_MagmaLabs_Technical_Blog_%E2%80%94_WordPress.jpg"><img data-attachment-id="5686" data-permalink="http://blog.magmalabs.io/2020/04/24/approaching-rails-legacy-systems-chapter-1-project-anatomy.html/1__bash_and_edit_post__magmalabs_technical_blog_-_wordpress" data-orig-file="https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/08/1__bash_and_Edit_Post_‚Äπ_MagmaLabs_Technical_Blog_‚Äî_WordPress.jpg?fit=1874%2C954" data-orig-size="1874,954" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1__bash_and_Edit_Post_‚Äπ_MagmaLabs_Technical_Blog_‚Äî_WordPress" data-image-description="" data-medium-file="https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/08/1__bash_and_Edit_Post_‚Äπ_MagmaLabs_Technical_Blog_‚Äî_WordPress.jpg?fit=300%2C153" data-large-file="https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/08/1__bash_and_Edit_Post_‚Äπ_MagmaLabs_Technical_Blog_‚Äî_WordPress.jpg?fit=1024%2C521" src="https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/08/1__bash_and_Edit_Post_%E2%80%B9_MagmaLabs_Technical_Blog_%E2%80%94_WordPress.jpg?resize=1306%2C665" alt="" width="1306" height="665" srcset="https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/08/1__bash_and_Edit_Post_%E2%80%B9_MagmaLabs_Technical_Blog_%E2%80%94_WordPress.jpg?resize=300%2C153 300w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/08/1__bash_and_Edit_Post_%E2%80%B9_MagmaLabs_Technical_Blog_%E2%80%94_WordPress.jpg?resize=200%2C102 200w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/08/1__bash_and_Edit_Post_%E2%80%B9_MagmaLabs_Technical_Blog_%E2%80%94_WordPress.jpg?resize=768%2C391 768w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/08/1__bash_and_Edit_Post_%E2%80%B9_MagmaLabs_Technical_Blog_%E2%80%94_WordPress.jpg?resize=1024%2C521 1024w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/08/1__bash_and_Edit_Post_%E2%80%B9_MagmaLabs_Technical_Blog_%E2%80%94_WordPress.jpg?resize=1200%2C611 1200w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/08/1__bash_and_Edit_Post_%E2%80%B9_MagmaLabs_Technical_Blog_%E2%80%94_WordPress.jpg?resize=860%2C438 860w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/08/1__bash_and_Edit_Post_%E2%80%B9_MagmaLabs_Technical_Blog_%E2%80%94_WordPress.jpg?resize=680%2C346 680w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/08/1__bash_and_Edit_Post_%E2%80%B9_MagmaLabs_Technical_Blog_%E2%80%94_WordPress.jpg?resize=400%2C204 400w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/08/1__bash_and_Edit_Post_%E2%80%B9_MagmaLabs_Technical_Blog_%E2%80%94_WordPress.jpg?resize=50%2C25 50w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></a></p>
<p><a href="https://github.com/tj/git-extras"><code>git-extras</code></a> has many interesting features that you can explore and use to get a better understanding of your project.</p>
<h3>Git log</h3>
<p>Ok, now let‚Äôs understand how <em>change</em> on single objects works with <code>git log</code>.</p>
<pre><code>$ git log --patch --stat Gemfile

commit f6043a0c731de894f05328da79f04b9456931074
Author: Ozmar Ugarte &lt;ozmmarr.ugarte@magmalabs.io&gt;
Date:   Mon May 9 15:08:33 2016 -0400

    NPS delighted survey scheduling

    This commit was made only for testing purposes.
---
 Gemfile | 3 +++
 1 file changed, 3 insertions(+)

diff --git a/Gemfile b/Gemfile
index bbecfdf79..9b1fa9332 100644
--- a/Gemfile
+++ b/Gemfile
@@ -142,6 +142,9 @@ gem 'has_scope', '~&gt; 0.6.0.rc'
 gem 'cocoon'
 gem 'sailthru-client', '~&gt; 4.0.1'

+#Delighted nps
+gem 'delighted'
+
 # form object
 gem 'virtus', '~&gt; 1.0.3'
</code></pre>
<p>As you can see, it will show why a specific update was made. Or, maybe it will just trigger more questions. But, at least you will be closer to your main goal, which is ‚Äúunderstand what was the purpose of those changes‚Äù.</p>
<h3>Git History</h3>
<p>Also, if you prefer the fancy way and see the timeline of a particular file, you can try <code>git-history</code>.</p>
<p>Now, let‚Äôs use <a href="https://github.com/pomber/git-history">git-history</a>, which is like a visual time machine where you can visually review any change on a specific file and understand its timeline.</p>
<p><a href="https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/Git_History_-_admin_html_slim.jpg"><img data-attachment-id="5429" data-permalink="http://blog.magmalabs.io/2020/04/24/approaching-rails-legacy-systems-chapter-1-project-anatomy.html/git_history_-_admin_html_slim" data-orig-file="https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/Git_History_-_admin_html_slim.jpg?fit=2084%2C1350" data-orig-size="2084,1350" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Git_History_-_admin_html_slim" data-image-description="" data-medium-file="https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/Git_History_-_admin_html_slim.jpg?fit=300%2C194" data-large-file="https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/Git_History_-_admin_html_slim.jpg?fit=1024%2C663" src="https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/Git_History_-_admin_html_slim.jpg?resize=1027%2C665" alt="" width="1027" height="665" srcset="https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/Git_History_-_admin_html_slim.jpg?resize=300%2C194 300w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/Git_History_-_admin_html_slim.jpg?resize=200%2C130 200w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/Git_History_-_admin_html_slim.jpg?resize=768%2C498 768w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/Git_History_-_admin_html_slim.jpg?resize=1024%2C663 1024w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/Git_History_-_admin_html_slim.jpg?resize=1200%2C777 1200w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/Git_History_-_admin_html_slim.jpg?resize=860%2C557 860w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/Git_History_-_admin_html_slim.jpg?resize=680%2C440 680w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/Git_History_-_admin_html_slim.jpg?resize=400%2C259 400w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/Git_History_-_admin_html_slim.jpg?resize=50%2C32 50w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/Git_History_-_admin_html_slim.jpg?w=2000 2000w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></a></p>
<p>Check this <a href="https://githistory.xyz/webdevtalks/www/blob/master/Gemfile">example</a> out.</p>
<h3>Look for Documentation (we‚Äôre using Git as well)</h3>
<p>As we look for documentation keep in mind and ask yourself the following:</p>
<ul>
<li>Is there any documentation at all?</li>
<li>Is there good commentary on the code?</li>
<li>Do the names of things make sense?</li>
<li>Are the System Use Cases documented?</li>
<li>Is there someone in the team that understands the system?</li>
</ul>
<p>We can use <code>git whatchange doc</code> to see logs and differences in our documentation, check the example above:</p>
<pre><code>$ git whatchanged doc
commit e43e0fecfb5914ec0e72eadff73e90c0e14c7026
Author: Daniel Contreras &lt;daniel.country.club@magmalabs.io&gt;
Date:   Thu Jan 28 19:32:35 2016 -0500

    Render diagram inline. Use AsciiDoc for the table of contents.

:100644 100644 13fa6c9d4 ff7935d08 R055 doc/client-system/README.md     doc/client-system/README.adoc
</code></pre>
<p>It seems that we have a doc folder. üéâüéâüéâ It also seems like the last time a document was modified was in 2016, so it‚Äôs time to start documenting your new progress. That would help you in the future, and any other developer that joins the team.</p>
<h3>Extra: The README</h3>
<p>There is a README?  Well, yes. But it is so poor‚Ä¶</p>
<p><a href="https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/README_Template.jpg"><img data-attachment-id="5432" data-permalink="http://blog.magmalabs.io/2020/04/24/approaching-rails-legacy-systems-chapter-1-project-anatomy.html/readme_template" data-orig-file="https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/README_Template.jpg?fit=2032%2C490" data-orig-size="2032,490" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="README_Template" data-image-description="" data-medium-file="https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/README_Template.jpg?fit=300%2C72" data-large-file="https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/README_Template.jpg?fit=1024%2C247" src="https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/README_Template.jpg?resize=1424%2C343" alt="" width="1424" height="343" srcset="https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/README_Template.jpg?resize=300%2C72 300w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/README_Template.jpg?resize=200%2C48 200w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/README_Template.jpg?resize=768%2C185 768w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/README_Template.jpg?resize=1024%2C247 1024w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/README_Template.jpg?resize=1200%2C289 1200w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/README_Template.jpg?resize=860%2C207 860w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/README_Template.jpg?resize=680%2C164 680w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/README_Template.jpg?resize=400%2C96 400w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/README_Template.jpg?resize=50%2C12 50w, https://i1.wp.com/blog.magmalabs.io/wp-content/uploads/2019/05/README_Template.jpg?w=2000 2000w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></a></p>
<p>Hey, but don‚Äôt worry, there are many templates you can use; like this <a href="https://github.com/dbader/readme-template" rel="noopener" target="_blank">example</a>.</p>
<h2>Wrap up</h2>
<p>Here are more things to keep in mind:</p>
<ul>
<li>Document everything you learn.</li>
<li>Keep documentation close to the code, simple is better.</li>
<li>You must understand the design/architecture.</li>
<li>Once you understand something, refine its documentation.</li>
</ul>
<p>I hope you find this blogpost compelling. In the following chapter, we are going to cover some nice toolings for static analysis of your code.</p>

						
						
						
	
					</section>

					
	<section>
		<div>
			
			<hr>
			<p>Passionate about Code, Music, Startups, Dance. Director of Engineering at MagmaLabs, Web Dev Talks Core.</p>
			
		</div>
	</section>
					
	


					



				</div>

				
	
	
			</div>
		</section></div>]]>
            </description>
            <link>http://blog.magmalabs.io/2020/07/02/approaching-rails-legacy-systems-chapter-2-become-a-git-historian.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23715128</guid>
            <pubDate>Thu, 02 Jul 2020 16:43:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RISC-V, China, Nightingales]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23714766">thread link</a>) | @ceohockey60
<br/>
July 2, 2020 | https://interconnected.blog/riscv-china-nightingales/ | <a href="https://web.archive.org/web/*/https://interconnected.blog/riscv-china-nightingales/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>„ÄêÊÉ≥Áúã‰∏≠ÊñáÁöÑ<a href="https://interconnected.blog/riscv-china-nightingales/#chinese-version-below">ËØªËÄÖËØ∑ÁÇπÂáªËøôÈáå</a>ÊàñÊªöÂä®Âà∞Êú¨È°µ‰∏ãÊñπ„Äë</p><p>Last weekend, I read <a href="https://www.huxiu.com/article/360061.html">a long, epic piece of techlore</a> that chronicled the fierce and bitter rivalry between TSMC and Samsung in their fight to become the world‚Äôs number 1 chip foundry, which stretched back three decades and continues today.</p><p>Among the many dramatic details was the ‚ÄúNightingale program‚Äù that TSMC started in the mid-2010s to jumpstart its R&amp;D, because it was falling behind Samsung and losing Apple‚Äôs A9 chip orders to the Korean conglomerate. TSMC conceived of a three-shift, 24-hour non-stop R&amp;D operation, taking a page out of their fellow Taiwanese manufacturing behemoth Foxconn‚Äôs assembly operation. The ‚ÄúNightingales‚Äù were engineers and researchers, who were willing to work the ‚Äúgraveyard shift‚Äù for a 30% increase in base salary and 50% increase in dividend payout. Due to this program, <strong>the total working hours clocked in Taiwan in 2014 was 2135</strong>, apparently the most of any economy in the world that year.</p><p>TSMC, and arguably Taiwan‚Äôs entire economy, was confronting an existential struggle at that time. SMIC (the largest chip foundry in China), and arguably China‚Äôs technological and economic future, is confronting a similarly existential struggle on a larger scale.</p><p>There are many interconnected elements that, when put together, could determine how China will come out on the other end of this struggle -- <strong>RISC-V, foundry technology, the ‚ÄúNew Infrastructure‚Äù stimulus program, open source, and a few key TSMC personnels</strong>, who are now at the helm of China‚Äôs semiconductor industry.</p><p>Let‚Äôs take a look at each of them, sequentially and interconnectedly.</p><h2 id="risc-v-strengths-and-weaknesses">RISC-V: Strengths and Weaknesses</h2><p>The conversation around China‚Äôs journey towards technological self-reliance often involves <strong>RISC-V</strong> -- an open standard Instruction Set Architecture (ISA) for hardware that‚Äôs under open source licenses, thus any one can run, change, copy, and distribute it, in accordance with<a href="https://www.gnu.org/philosophy/free-sw.en.html"> the four freedoms</a> of open source.</p><figure><img src="https://lh6.googleusercontent.com/sVMZ8L3CA61u_kc0hdRdB9AItYEuK65vUJ70os7CAaFpogycLyqhYL_BbwMndKktijiEAF8Bi9WLyKCmW5ztmGE3Zhw2dQrRP0VwWcxWIsUqTFVFfYXIS4K5wp_SDExCRiug0cE1" alt=""><figcaption>RISC-V Ecosystem, courtesy of SiFive.</figcaption></figure><p>However, RISC-V is still young. Its<a href="https://riscv.org/specifications/"> user-space ISA</a> and<a href="https://riscv.org/specifications/privileged-isa/"> privileged ISA</a> wasn‚Äôt frozen, and thus ready for large-scale software and hardware development, until June 2019. The technology and community ecosystem is maturing, and support from large Chinese organizations has a lot to do with it. Of <a href="https://riscv.org/members-at-a-glance/">the six Premier Members</a> of the official RISC-V foundation, RISC-V International, &nbsp;four are Chinese organizations -- Alibaba, Huawei, RIOS Lab, and the Institute of Computing Technology of the Chinese Academy of Sciences.</p><p>But in the near future (say the next five years), what can RISC-V, the technology, realistically enable China to accomplish?</p><p><strong>What is it good for?</strong> &nbsp;RISC-V is a very good foundation for rapidly prototyping and building <strong>special purpose</strong> chips. The development cycle and experience feels closer to software than hardware. This speed in development is partly because it‚Äôs open-sourced -- no hassle in getting a commercial license, as oppose to its proprietary counterparts like ARM -- and also partly because the ISA itself is simplified and ‚Äúreduced‚Äù (i.e. the R in RISC), as opposed to CISC (the C means ‚Äúcomplex‚Äù) which underpins more powerful, proprietary ISAs like Intel‚Äôs x86. This reduced architecture enables and optimizes simple computation instructions well, literally elementary school math: addition, subtraction, multiplication, division, etc. It‚Äôs less capable of supporting complex mathematical operations, like matrix multiplication and partial derivative (used widely in Deep Learning AI).</p><p>Thus, in reality, chips designed using RISC-V have been used most commonly in <strong>IoT and embedded systems</strong> scenarios. Because of its simplicity and malleability, RISC-V chips also <strong>tend to have low power consumption</strong>, which is a good attribute when battery life is an issue, e.g. wearable devices. This reduced simplicity also means that the compiler (the software layer that translates code, like C, into machine instructions for a chip to execute) does not need to be purposefully designed to optimize performance on RISC-V. Using some common compilers <a href="https://riscv.org/software-status/#c-compilers-and-libraries">like GCC, which RISC-V </a>supports, will do.</p><p><strong>What does it lack? </strong>As you might‚Äôve guessed, RISC-V‚Äôs reduced simplicity is also the source of its limitations. While many people like to pit RISC-V against a general purpose ISAs, like Intel‚Äôs, <strong>they are more compliments than competitors. </strong>In fact, special purpose RISC-V chips that accelerate certain computations for AI workloads do run side-by-side along general purpose Intel chips in the cloud. It‚Äôll be a long time (more than five years, in my opinion) before RISC-V can enable the design of a <strong>general purpose</strong> chip that powers our iPhones, laptops, or cloud computing servers in a data center, with enough developers incentivized to both extend the ISA and the compiler and other infrastructure software on top of it.</p><p><strong>Can RISC-V become general purpose some day?</strong> Of course. <strong>But that‚Äôs not an inevitability</strong>. It‚Äôs <strong>a strategic choice</strong> that the RISC-V community can make and work towards, with all the complexity in upstream coordination, developer community building, and open governance, not to mention the work of building the technology itself, that must be executed collectively. That possible future is perhaps the most interesting question when we think about China‚Äôs self-reliance, which I‚Äôll discuss in more detail below <strong>in the context of fostering open source</strong>.</p><h2 id="-new-infrastructure-">‚ÄúNew Infrastructure‚Äù</h2><p>With the strengths and weaknesses of RISC-V in mind, let‚Äôs see where RISC-V chips could get deployed in China‚Äôs economy and infrastructure in the foreseeable future.</p><p>It‚Äôs no secret that central government industrial policy matters a lot in China, even though its market-driven economy is what materializes much of that vision. The most relevant piece of policy is <a href="http://www.china.org.cn/business/2020-04/22/content_75961988.htm">the ‚ÄúNew Infrastructure‚Äù spending plan </a>that came out of the National Development and Reform Commission, as a response to the COVID-19 pandemic to boost the economy. This infrastructure stimulus plan sits in a larger context of two other long-term strategic plans: Made in China 2025 and China Standards 2035.</p><p>The details of this ‚ÄúNew Infrastructure‚Äù plan have emerged in the last couple months, with major emphasis in IT and digital infrastructure, not just traditional infrastructure like highways and railroads. As it often happens in China, the signals sent from the top have already shifted private investment dollars. Nascent chip startups, all of a sudden, are <a href="https://uk.reuters.com/article/uk-china-semiconductors-analysis/sino-u-s-tech-race-turbo-charges-china-chip-investment-triggering-bubble-fear-idUKKBN23V3CO">enjoying investor attention and bubbly valuations</a>.</p><p>With that said, here are some of the ‚ÄúNew Infrastructure‚Äù sectors that I think RISC-V could play an immediate role in, given its strengths:</p><ul><li>IoT</li><li>Smart transportation</li><li>New energy vehicle chargers</li><li>Limited AI (specific workloads that need customized acceleration)</li><li>Autonomous vehicles (limited to certain types of sensors and data collection)</li></ul><p>And as for sectors that I don‚Äôt see RISC-V making much of a dent, given its current limitations:</p><ul><li>Cloud computing</li><li>5G (both base station construction and consumer devices)</li><li>Blockchain</li><li>Data centers</li><li>Big data</li><li>Large-scale AI training and production deployment</li></ul><p>As you can see, RISC-V impact would be limited,<strong> but not insignificant</strong>. The logical next step would be for China to help evolve RISC-V <strong>into a more general purpose ISA</strong>, and reduce its reliance on proprietary solutions from ARM or Intel that could always be subjected to more sanctions.</p><p>The path to that end would have to be fostering open source <strong>and doing it the right way.</strong></p><h2 id="fostering-open-source-the-right-way">Fostering Open Source, the Right Way</h2><p>Open source has been popping up in <a href="https://mp.weixin.qq.com/s/Qcze4R-7zL2wjMh_DNVCIQ">a lot of discussions</a> in various Chinese technical and R&amp;D communities, triggered in particular by MATLAB being now off-limit to Chinese universities that are on the U.S. export control entity list. The discussion inevitably leads to open source: are there open source alternatives to MATLAB? What about CAD softwares, like EDA tools, which every chip foundry needs? Will there be an open source EDA option?</p><p>Implicit in these discussions is a predominant ‚Äútakers‚Äù mentality towards open source. In China, open source solutions are mostly seen as ‚Äúfree stuff‚Äù that you can take and use, without any expectation or incentive to give back (or in open source parlance: ‚Äúcontribute upstream‚Äù).</p><p>It‚Äôs already happening in RISC-V. Alibaba <a href="https://www.techspot.com/news/81177-china-alibaba-making-16-core-25-ghz-risc.html">sports the fastest RISC-V based processor to date</a>, but there‚Äôs no intention to my knowledge for the design to also be open-sourced or at least publicly shared for the benefit of the ecosystem. Many small startups in China, now showered with new investments, are doing the same -- using RISC-V to make special purpose chips that are effectively proprietary.</p><p><em>(This is not to generalize that all Chinese organizations are bad open source players; some are contributing a lot and have open source in their DNA. I‚Äôve profiled many of the big tech firms and some startups from the lens in Part II of my ‚Äú</em><a href="https://interconnected.blog/open-source-in-china-the-game/"><em>Open Source in China</em></a><em>‚Äù series.)</em></p><p><strong>If</strong> China hopes to evolve RISC-V into a more powerful, general-purpose building block to achieve semiconductor self-reliance, Chinese organizations, both individually and collectively, would have to shift from a zero-sum ‚Äútakers‚Äù mentality to a positive-sum ‚Äústakeholders‚Äù mentality. What that means in reality is absorbing and practicing the open source way of doing things -- not just contributing code upstream and being more willing to share, but also behaviors like transparent governance, open discussions with other stakeholders and developers, and clear due process for decision-making, big and small. <strong>These are both technical and human complexities.</strong></p><p>With an existential struggle at hand, there‚Äôs reason to believe that Chinese companies may behave differently for the sake of achieving a national imperative and be less concerned about the tit-for-tat, zero-sum nature of market competition, which is quite cutthroat in China. And<strong> if done right</strong>, RISC-V could unleash massive technological innovation broadly and help China deal with its existential struggle specifically.</p><h2 id="foundries-smic-hsmc">Foundries: SMIC, HSMC</h2><p>Let‚Äô‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://interconnected.blog/riscv-china-nightingales/">https://interconnected.blog/riscv-china-nightingales/</a></em></p>]]>
            </description>
            <link>https://interconnected.blog/riscv-china-nightingales/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23714766</guid>
            <pubDate>Thu, 02 Jul 2020 16:06:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Agile HR Department]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23714508">thread link</a>) | @Gpetrium
<br/>
July 2, 2020 | https://gpetrium.com/the-agile-hr-department/ | <a href="https://web.archive.org/web/*/https://gpetrium.com/the-agile-hr-department/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-post" data-elementor-id="3006" data-elementor-settings="[]"><div><div><section data-id="76403fc7" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;shape_divider_bottom&quot;:&quot;opacity-tilt&quot;}"><div><div><div data-id="10b2a46" data-element_type="column"><div><div><div data-id="6e050ef1" data-element_type="widget" data-widget_type="image.default"><div><p><img width="720" height="1200" src="https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/07/irfan-simsar-wxWulfjN-G0-unsplash.jpg?fit=720%2C1200&amp;ssl=1" data-src="https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/07/irfan-simsar-wxWulfjN-G0-unsplash.jpg?fit=720%2C1200&amp;ssl=1" alt="" data-srcset="https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/07/irfan-simsar-wxWulfjN-G0-unsplash.jpg?w=720&amp;ssl=1 720w, https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/07/irfan-simsar-wxWulfjN-G0-unsplash.jpg?resize=180%2C300&amp;ssl=1 180w, https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/07/irfan-simsar-wxWulfjN-G0-unsplash.jpg?resize=614%2C1024&amp;ssl=1 614w, https://i2.wp.com/gpetrium.com/wp-content/uploads/2020/07/irfan-simsar-wxWulfjN-G0-unsplash.jpg?resize=600%2C1000&amp;ssl=1 600w" data-sizes="(max-width: 720px) 100vw, 720px"></p></div></div></div></div></div></div></div></section><section data-id="6a068b86" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"></section><section data-id="7990ca62" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"></section><section data-id="11d788ff" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="6dde1260" data-element_type="column"><div><div><div data-id="6b7861e0" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>Long gone are the days in which companies worried that only new technologies were able to disrupt their operations and industries. Nowadays, political, social, and technological environments are evolving rapidly. Such changes create further risks and opportunities that may severely influence the way a company operates. For instance, as North American and European countries entered in lock down to combat the spread of the COVID-19 pandemic, several organizations were forced to make the move to remote working, despite not being prepared for it.&nbsp;</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; These massive disruptions have led some organizations to go under, while others fundamentally reinvented their operations to meet their strategic goals. In face of recent challenges, several companies have discovered that they need to be resilient, adaptive, and responsive. All such qualities serve as founding pillars to the Agile methodology, which has become increasingly attractive to companies by promoting faster deployment times and resilient workforces that are flexible and adaptive in the face of challenges and changes.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Arguably, a department that is in need of change in many organizations given recent and prior events is human resources (HR). HR is a key pillar in balancing organizational needs with employee‚Äôs priorities, helping to build, operate and foster incentive mechanisms and culture. Conversely, decisions made in areas such as prospecting, training, salary, and career development can heavily impact employee motivation and productivity. This incredibly delicate package can directly translate into a company‚Äôs ability to meet its strategic goals such as profitability, market share, productivity and sustainability.&nbsp;</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Traditionally, the HR department was governed by stiff protocols that were meant to instil policy alignment, control, and facilitate vertical structures. This style, often criticized as an obstacle to innovative thinking and resilient teams, has been under scrutiny by the business community in recent years. To bring human resources into the digital age, Agile has been identified by some as an ideal solution to create the right incentives necessary to ensure company success, even if partially implemented ‚Äì Agile Lite (<a href="https://hbr.org/2018/03/the-new-rules-of-talent-management#hr-goes-agile">HR Goes Agile</a>, HBR).</p></div></div></div><div data-id="48430811" data-element_type="widget" data-widget_type="heading.default"><p><h2>Agile Driven Trends in HR</h2></p></div><div data-id="169f41f3" data-element_type="widget" data-widget_type="text-editor.default"><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Unbeknownst to them, some companies have already started to implement Agile practices across their organization, while others have knowingly deployed Agile teams to test the waters. Nevertheless, in many well managed environments, such experiments have proven to be fruitful and have given way to innovative thinking and behaviour.</p></div></div><div data-id="62a25b3e" data-element_type="widget" data-widget_type="heading.default"><p><h3>External Talent Acquisition: Reactive vs. Proactive</h3></p></div><div data-id="5fb1805d" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Traditionally, the modus operandi for bringing new talent was, and still is in most enterprises, reactionary: as positions were made available, a formal search process started, from which a pool of applicants was formed. Once the ideal candidate was identified from the pool of applicants, an incentive package was negotiated and, finally, necessary organizational training was given. This talent acquisition style has its benefits as it ensures that the organization follows controls and policies, however, it can be very time consuming and not necessarily attract or select the best candidate for the position.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Agility driven talent acquisition practices understand the power that a company‚Äôs culture has to attract the right personnel. An agile talent acquisition staff becomes less reactive and more proactive in its operational handling. This means that the person is more in tune with the needs of their organization to appropriately forecast personnel needs ‚Äì this can be done by maintaining a relationship with managers, understanding the turnover ratios on each department, and being attuned to the company‚Äôs demographics and needs (ex: what employees are expected to retire soon?).&nbsp;</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; By understanding the organization‚Äôs internal environment, talent acquisition members are then able to cultivate relationships across multiple channels (ex: LinkedIn and Universities) and expedite the hiring process should a position become available. It is important to note that this practice does not enforce or condone direct hiring. In fact, it is still advised that talent acquisition staff invite desired candidates to participate in formal hiring processes and, if all boxes are checked, then make an offer to the most qualified individual.</p></div></div></div><div data-id="2166be74" data-element_type="widget" data-widget_type="heading.default"><p><h3>Internal Talent Acquisition: Gigs and Projects</h3></p></div><div data-id="400b0a9" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Inevitably, as organizations‚Äô needs and challenges change, new projects with differing or novel set of skills may appear. Depending on the complexity of the task, consultants or new talent may be brought in. However, for small and short-term projects, the procurement process for new talent or an agency may become too costly, or even risky. In some cases, the skills necessary to fulfill the project may be found in-house. Some forward looking, agility driven organizations have increased their workforce productivity by assigning short-term projects to employees with downtime. For example, should one department require assistance with the automation of a report, they may post the assignment in a board so other members of the company can apply to fulfill the request.</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Such practice has been implemented by the <a href="https://www.cppinvestments.com/">CPP Investment Board</a> and they call it <a href="https://cdn3.cppinvestments.com/wp-content/uploads/2020/05/cpp-investments-annual-report-2020-en.pdf">Gigs</a> (optional short-term assignments). Similar internal talent utilization may prove to be beneficial on several levels:</p><ul><li>It can further collaboration and a sense of community within the organization, which further strengthens corporate culture.</li><li>It can serve as a new challenge for employees who may find themselves underwhelmed by their current routine and wish to spice things up.</li><li>It may assist employees to acquire professional experience of skills that they previously viewed as hobbies (ex: graphical design or photography).</li><li>It may serve to further augment and sediment skills acquired through internal or external courses.</li><li>It can support an employee‚Äôs transition into a new career.</li></ul></div></div></div><div data-id="2578c15a" data-element_type="widget" data-widget_type="heading.default"><p><h3>Talent Management: Workforce Upskilling</h3></p></div><div data-id="1b44a92c" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Conventional talent management practices are typically owned by HR and focus on assigning static training for individuals who are preparing for new roles, are underperforming, or need to achieve a specific performance level in a desired practice (<a href="https://tech.gsa.gov/guides/applying_agile_practices_HR/#:~:text=According%20to%20the%20HR%20Trend,workforce%20fluctuations%20to%20demand%2C%20and">GSA</a>). This practice alone may not encourage innovative and proactive behaviour among the workforce and can even hurt engagement levels.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Recently, with technological advances in the are of online learning, Agility driven talent management practices are openly facilitated by HR to any employee who wishes to learn or hone a new skill. As such, internal learning portals are available (or the company has the choice to partner with institutions who offer such service) for employees to choose from a vast selection of topics which can be suggested to them according to identified best practices, or can be selected by them independent of their job. Agility driven HR has also found itself with a lot of untapped data that can be harnessed to drive personalized training. Technology is evolving at a rapid pace, causing organizations to consider workforce upskilling as a major driver in the digital age. HR departments that fail to transition at pace, or faster than its competitors may find itself scrambling compete.</p></div></div></div><div data-id="5131c56b" data-element_type="widget" data-widget_type="heading.default"><p><h2>Agile Framework Adapted to HR</h2></p></div><div data-id="2825630a" data-element_type="widget" data-widget_type="text-editor.default"><div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Initially, Agile was a work methodology destined for software development. However, as time passed, other teams and departments started to retrofit its framework to their operations in the hopes of achieving similar results such as higher productivity, engagement, and efficiency. As explained in our previous article from the Agile series, <a href="https://gpetrium.com/agile-sales-department/">The Agile Sales Department</a>, Agile teams have 4 distinct roles: the team lead (in Scrum, also known as Scrum Master), team member, product owner, and stakeholder. Additionally, Agile practices are surrounded by ceremonies that instill team collaboration, autonomy and ownership to reach mutual objectives. Below, let us discuss how roles and ceremonies can both be adapted to further the HR department‚Äôs goals and objectives.</p></div></div><div data-id="460bba18" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <u>The HR Manager</u></strong> is usually tasked with many of the product owner activities. It can range from setting the vision for the team (alongside stakeholders such as Senior HR Manager and Managing Directors), setting priorities, anticipating stakeholder‚Äôs needs, overseeing progress, creating key strategic decisions and team targets. At the end of the cycle (or sprint), the HR manager will review the team‚Äôs progress and provide relevant guidance for future cycles. Although priorities may differ depending on the company and team, one of the key objectives in this role should be to provide targets and guidance for their HR team depending on their priorities ‚Äì be it for the compensation team, benefits team, talent management and more.</p><p><strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <u>The Team Facilitator/ Coordinator</u></strong> serves as an intermediator who encourages the team to be the best they can be (balancing time, cost, and quality), while facilitating meetings, managing stakeholders, reinforcing objective oriented actions, and supporting team introspection. The team facilitator is also tasked with shielding the team from internal and external challenges that are not relevant to the current cycle‚Äôs objectives. This role is incredibly powerful even more so in organization who are testing the implementation of agile teams by introducing a few teams per department or project.</p><p><strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <u>Team Members</u></strong> are a group of 3-8 individuals, excluding the hr manager and the team facilitator. Their aim is to carry out the goals and objectives of the current cycle to the best of their ability in the allocated time and to take steps in preparation for future sprints.</p><p><strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <u>Stakeholders</u></strong> are other individuals with an interest, concern, or who are affected by the activities of ‚Ä¶</p></div></div></div></div></div></div></div></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gpetrium.com/the-agile-hr-department/">https://gpetrium.com/the-agile-hr-department/</a></em></p>]]>
            </description>
            <link>https://gpetrium.com/the-agile-hr-department/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23714508</guid>
            <pubDate>Thu, 02 Jul 2020 15:42:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Visual breakdown of S&P 500 companies]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23714435">thread link</a>) | @Omie6541
<br/>
July 2, 2020 | https://tijorifinance.com/us/company/AMZN | <a href="https://web.archive.org/web/*/https://tijorifinance.com/us/company/AMZN">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://tijorifinance.com/us/company/AMZN</link>
            <guid isPermaLink="false">hacker-news-small-sites-23714435</guid>
            <pubDate>Thu, 02 Jul 2020 15:36:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Think About JavaScript Security]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23714317">thread link</a>) | @marcinhoppe
<br/>
July 2, 2020 | https://marcinhoppe.com/how-to-think-about-javascript-security/ | <a href="https://web.archive.org/web/*/https://marcinhoppe.com/how-to-think-about-javascript-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>JavaScript has no security model. The runtime environments do. This post is a primer on how to think about JavaScript code security in Web browsers and Node.js.</p><p>JavaScript was created to add interactivity to HTML pages. Web browsers were the first runtime environment for JavaScript code.</p><p>When the user visits a Web page, the browser downloads the HTML code of that page and parses it to create the Document Object Model (DOM). The HTML contains information about other assets that need to be downloaded to render the page to the user. This includes stylesheets (CSS), images, other documents to display in frames, and many more.</p><p>The type of asset we are most interested in here is JavaScript code. It is also downloaded by the browser from locations referenced in the HTML.</p><h2 id="same-origin-policy">Same-Origin Policy</h2><p>Users can simultaneously visit many pages in tabs or separate browser windows. JavaScript code downloaded from multiple different sites is executed in the same browser.</p><p>One of those sites could be infected or operated by an attacker. Is this a risk? Could malicious code compromise the machine or steal data from other sites the user is browsing?</p><p>Browsers protect against this. Each Web site executes JavaScript code in a sandbox. Code downloaded from one Web site cannot read or write data from another site. It also cannot call functions or methods across different sites.</p><p>This is called the <a href="https://web.dev/same-origin-policy/">Same-origin policy</a> (SOP) and it is one of the most fundamental security policies on the Web.</p><h2 id="protecting-code-integrity">Protecting Code Integrity</h2><p>Attackers could breach the SOP through the injection of malicious code at the network level, making the injected code appear as coming from the legitimate site. Browsers use the <a href="https://web.dev/why-https-matters/">secure HTTPS protocol</a> to ensure JavaScript code is downloaded from the legitimate server and that the code is not tampered with in transit.</p><p>JavaScript is often distributed using Content Delivery Networks (CDN). Attackers capable of injecting content into the CDN could also compromise the SOP. <a href="https://developer.mozilla.org/en-US/docs/Web/Security/Subresource_Integrity">Subresource Integrity</a> (SRI) provides an additional level of protection that allows HTML code to be cryptographically bound to JavaScript code to prevent this.</p><p>Sandboxing is difficult to implement. Browsers use isolation mechanisms provided by the hardware and the operating system. JavaScript code from different sites is executed in separate processes.</p><p>The code in a sandbox is restricted in what it can do. It cannot directly access devices such as webcams or microphones. The filesystem and the local network are also not directly available.</p><p>JavaScript can use those resources only through very limited APIs. This reduces the attack surface. It also allows the browser to always ask the user for explicit permission before uploading files, capturing the webcam, or listening to the user‚Äôs microphone.</p><p>Node.js is a runtime environment for JavaScript based on the V8 engine built for the Google Chrome browser. It allows JavaScript code to be executed outside of the browser, typically on servers.</p><p>Node.js does not use the browser sandbox to run JavaScript. Security properties of both execution environments are different:</p><ul><li><strong>Origin</strong>. Browsers download the code and Node.js loads the code from local files like other popular programming languages.</li><li><strong>Trust</strong>. Browsers treat the code as untrusted and Node.js treats the code with full trust.</li><li><strong>Permissions</strong>. Browsers restrict capabilities the code has access to and Node.js grants all the privileges of the operating system account. This includes access to devices, files, and the local network.<br>Impact on Security</li></ul><p>The same JavaScript script or module can be executed in the browser or Node.js. Potential attacks may be different in both environments. The impact of successful exploits may be drastically different. It is very hard to reason about the security of JavaScript code without a specific execution environment in mind.</p><h2 id="browsers">Browsers</h2><p>A successful attack on JavaScript code running in the browser impacts a single user. The impact is limited to what the sandbox, browser APIs, and the user‚Äôs explicit consent allow for.</p><p>Compromised JavaScript script or module runs within the context of an authenticated session of the victim and it can perform actions on behalf of the user. In this scenario, the vulnerable code becomes an attack vector against Web applications the victim has legitimate access to.</p><h2 id="node-js">Node.js</h2><p>A successful attack on Node.js programs may impact the entire server the program runs on. The attacker may get access to all the resources the operating system account has access to, potentially leading to a full compromise of the server.</p><p>The next post in this series will demonstrate how the dynamic type system may lead to subtle security bugs.</p><!--kg-card-begin: html-->
      <!--kg-card-end: html-->
        </div></div>]]>
            </description>
            <link>https://marcinhoppe.com/how-to-think-about-javascript-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23714317</guid>
            <pubDate>Thu, 02 Jul 2020 15:26:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Foreign data wrappers: PostgreSQL's secret weapon?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23713994">thread link</a>) | @mildbyte
<br/>
July 2, 2020 | https://www.splitgraph.com/blog/foreign-data-wrappers | <a href="https://web.archive.org/web/*/https://www.splitgraph.com/blog/foreign-data-wrappers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><div><nav><ol><li><a href="#introduction" as="#introduction">Introduction</a></li><li><a href="#using-a-custom-fdw-with-splitgraph" as="#using-a-custom-fdw-with-splitgraph">Using a custom FDW with Splitgraph</a><ol><li><a href="#clone-the-repository" as="#clone-the-repository">Clone the repository</a></li><li><a href="#start-up-the-stack" as="#start-up-the-stack">Start up the stack</a></li><li><a href="#mount-the-data-and-run-some-queries" as="#mount-the-data-and-run-some-queries">Mount the data and run some queries</a></li></ol></li><li><a href="#what-are-foreign-data-wrappers" as="#what-are-foreign-data-wrappers">What are foreign data wrappers?</a></li><li><a href="#why-should-i-use-fdws" as="#why-should-i-use-fdws">Why should I use FDWs?</a></li><li><a href="#why-use-fdws-with-splitgraph" as="#why-use-fdws-with-splitgraph">Why use FDWs with Splitgraph?</a></li><li><a href="#conclusion" as="#conclusion">Conclusion</a></li></ol></nav><section><h2 id="introduction">Introduction</h2><p><a href="https://www.postgresql.org/docs/12/ddl-foreign-data.html" as="https://www.postgresql.org/docs/12/ddl-foreign-data.html">Foreign data wrappers</a> are an advanced <a href="https://postgresql.org/" as="http://postgresql.org/">PostgreSQL</a> feature. They allow you to link a remote database to PostgreSQL and represent it as a set of foreign tables that behave like normal ones.</p><p>Imagine being able to run SQL on a MongoDB collection or querying MySQL data from your PostgreSQL instance. Or, imagine running a <code>JOIN</code> between an SQLite file and an Oracle cluster without having to write and maintain an ETL job.</p><p>In this article, we'll discuss PostgreSQL foreign data wrappers and how <a href="https://www.splitgraph.com/" as="https://www.splitgraph.com/">Splitgraph</a> makes it much easier for anyone to use them.</p></section><section><h2 id="using-a-custom-fdw-with-splitgraph">Using a custom FDW with Splitgraph</h2><p>This example (<a href="https://github.com/splitgraph/splitgraph/tree/master/examples/custom_fdw" as="https://github.com/splitgraph/splitgraph/tree/master/examples/custom_fdw">source code on GitHub</a>) will show you how to write a custom <a href="https://www.splitgraph.com/docs/ingesting-data/foreign-data-wrappers/introduction" as="https://www.splitgraph.com/docs/ingesting-data/foreign-data-wrappers/introduction">foreign data wrapper</a> using Multicorn. <a href="https://github.com/Segfault-Inc/Multicorn" as="https://github.com/Segfault-Inc/Multicorn">Multicorn</a> is a PostgreSQL extension that makes it possible to write foreign data wrappers in Python.</p><p>We will then integrate it with Splitgraph's <a href="https://www.splitgraph.com/docs/sgr/data-import-export/mount" as="https://www.splitgraph.com/docs/sgr/data-import-export/mount"><code>sgr mount</code></a> command. This will make it queryable from the Splitgraph engine and allow Splitgraph to use it in <a href="https://www.splitgraph.com/docs/concepts/splitfiles" as="https://www.splitgraph.com/docs/concepts/splitfiles">Splitfiles</a>.</p><p>In particular, we will be running a foreign data wrapper that queries the <a href="https://github.com/HackerNews/API" as="https://github.com/HackerNews/API">Firebase Hacker News API</a>. This will let us run SQL queries on the top, best and new stories from Hacker News, as well as Show HNs and Ask HNs.</p><p>This foreign data wrapper returns a list of rows from the remote database without performing any filtering. However, Multicorn also passes qualifiers and sort keys to the Python extension. This allows filtering to happen on the remote database as well, if it supports it.</p><p>To run this demo, you will need to have <a href="https://www.docker.com/get-started" as="https://www.docker.com/get-started">Docker</a> and <a href="https://docs.docker.com/compose/install/" as="https://docs.docker.com/compose/install/">Docker Compose</a>.</p><section><h3 id="clone-the-repository">Clone the repository</h3><p>Clone Splitgraph and go to the <a href="https://github.com/splitgraph/splitgraph/tree/master/examples/custom_fdw" as="https://github.com/splitgraph/splitgraph/tree/master/examples/custom_fdw">example project</a>:</p><pre><code metastring=""><span><span>$</span> <span><span>git</span> clone https://github.com/splitgraph/splitgraph.git</span></span>
<span><span>$</span> <span><span>cd</span> splitgraph/examples/custom_fdw</span></span>
</code></pre><p>The Compose stack consists of:</p><ul><li>a custom version of the <a href="https://www.splitgraph.com/docs/architecture/splitgraph-engine" as="https://www.splitgraph.com/docs/architecture/splitgraph-engine">Splitgraph engine</a> (with the FDW installed);</li><li>a small Python container with the <a href="https://www.splitgraph.com/docs/architecture/sgr-client" as="https://www.splitgraph.com/docs/architecture/sgr-client"><code>sgr</code> client</a>.</li></ul><p>The source code for the foreign data wrapper is in <a href="https://github.com/splitgraph/splitgraph/blob/master/examples/custom_fdw/src/hn_fdw/fdw.py" as="https://github.com/splitgraph/splitgraph/blob/master/examples/custom_fdw/src/hn_fdw/fdw.py">src/hn_fdw/fdw.py</a>. The mount handler that exposes it to Splitgraph is in <a href="https://github.com/splitgraph/splitgraph/blob/master/examples/custom_fdw/src/hn_fdw/mount.py" as="https://github.com/splitgraph/splitgraph/blob/master/examples/custom_fdw/src/hn_fdw/mount.py">src/hn_fdw/mount.py</a>.</p></section><section><h3 id="start-up-the-stack">Start up the stack</h3><p>Start the shell and initialize the engine. This will also build and start the engine container:</p><pre><code metastring=""><span><span>$</span> <span>docker-compose run --rm sgr</span></span>

<span><span>$</span> <span>sgr init</span></span>
<span>Initializing engine PostgresEngine LOCAL (sgr@engine:5432/splitgraph)...
Database splitgraph already exists, skipping
Ensuring the metadata schema at splitgraph_meta exists...
Running splitgraph_meta--0.0.1.sql
Running splitgraph_meta--0.0.1--0.0.2.sql
Running splitgraph_meta--0.0.2--0.0.3.sql
Installing Splitgraph API functions...
Installing CStore management functions...
Installing the audit trigger...
Engine PostgresEngine LOCAL (sgr@engine:5432/splitgraph) initialized.
</span></code></pre><p>Check the help for the HN mount handler:</p><pre><code metastring=""><span><span>$</span> <span>sgr <span>mount</span> hackernews --help</span></span>
<span>Usage: sgr mount hackernews [OPTIONS] SCHEMA

      Mount a Hacker News story dataset using the Firebase API.

Options:
  -c, --connection TEXT       Connection string in the form
                              username:password@server:port

  -o, --handler-options TEXT  JSON-encoded dictionary of handler options:

                              endpoints: List of Firebase endpoints to mount,
                              mounted into the same tables as     the endpoint
                              name. Supported endpoints:
                              {top,new,best,ask,show,job}stories.

  --help                      Show this message and exit.
</span></code></pre></section><section><h3 id="mount-the-data-and-run-some-queries">Mount the data and run some queries</h3><p>Now, actually "mount" the dataset. This will create a series of foreign tables. When a PostgreSQL client queries these tables, the foreign data wrapper will forward the queries to the Firebase API:</p><pre><code metastring=""><span><span>$</span> <span>sgr <span>mount</span> hackernews hackernews</span></span>
<span>Mounting topstories...
Mounting newstories...
Mounting beststories...
Mounting askstories...
Mounting showstories...
Mounting jobstories...
</span></code></pre><p>You can now run ordinary SQL queries against these tables:</p><pre><code metastring=""><span><span>$</span> <span>sgr sql -s hackernews <span>"SELECT id, title, url, score FROM topstories LIMIT 10"</span></span></span>

<span>23648942  Amazon to pay </span><span><span>$</span><span>1B+ <span>for</span> Zoox                                             https://www.axios.com/report-amazon-to-pay-1-billion-for-self-driving-tech-firm-zoox-719d293b-3799-4315-a573-a226a58bb004.html                              <span>55</span></span></span>
<span>23646158  When you type realty.com into Safari it takes you to realtor.com        https://www.facebook.com/story.php?story_fbid=10157161487396994&amp;id=501751993                                                                               653
23648864  Turn recipe websites into plain text                                    https://plainoldrecipe.com/                                                                                                                                 30
23644253  Olympus quits camera business after 84 years                            https://www.bbc.com/news/technology-53165293                                                                                                               548
23648217  Boston bans use of facial recognition technology                        https://www.wbur.org/news/2020/06/23/boston-facial-recognition-ban                                                                                          51
23646953  Curl Wttr.in                                                            https://github.com/chubin/wttr.in                                                                                                                          190
23646164  Quora goes permanently remote-first                                     https://twitter.com/adamdangelo/status/1276210618786168833                                                                                                 267
23646395  Dwarf Fortress Creator Explains Its Complexity and Origins [video]      https://www.youtube.com/watch?v=VAhHkJQ3KgY                                                                                                                152
23645305  Blackballed by PayPal, Sci-Hub switches to Bitcoin                      https://www.coindesk.com/blackballed-by-paypal-scientific-paper-pirate-takes-bitcoin-donations                                                             479
23646028  The Acorn Archimedes was the first desktop to use the ARM architecture  https://spectrum.ieee.org/tech-talk/consumer-electronics/gadgets/why-wait-for-apple-try-out-the-original-arm-desktop-experience-today-with-a-raspberry-pi  111
</span></code></pre><p>PostgreSQL handles the actual query planning and filtering. The foreign data wrapper's job is to fetch records from the API. This setup supports any SQL syntax:</p><pre><code metastring=""><span><span>$</span> <span>sgr sql -s hackernews <span>"SELECT id, title, url, score FROM showstories ORDER BY score DESC LIMIT 5"</span></span></span>
<span>23643096  Show HN: Aviary.sh ‚Äì A tiny Bash alternative to Ansible                           https://github.com/team-video/aviary.sh  235
23626167  Show HN: HN Deck ‚Äì An alternative way to browse Hacker News                       https://hndeck.sagunshrestha.com/        110
23640069  Show HN: Sourceful ‚Äì Crowdsourcing the best public Google docs                    https://sourceful.co.uk                  102
23627066  Show HN: Splitgraph - Build and share data with Postgres, inspired by Docker/Git  http://www.splitgraph.com                 79
23629125  Show HN: Deta ‚Äì A cloud platform for building and deploying apps                  https://www.deta.sh/                      78
</span></code></pre></section></section><section><h2 id="what-are-foreign-data-wrappers">What are foreign data wrappers?</h2><p>The easiest way to describe foreign data wrappers is by considering UNIX files. A UNIX file isn't always pointing to a local file on your disk. It could be a file stored on NFS, in a remote S3 bucket or even a shim that lets you manipulate a device on your machine.</p><p>In UNIX, a file is a pretty strong abstraction that doesn't get broken. An IDE doesn't need to know that the file it's editing is on a remote filesystem. It can work with it by issuing the same ordinary read and write calls. Someone who writes a new filesystem doesn't need to make sure that it's compatible with all existing tools. Instead, they can write a driver that mounts the filesystem to a mountpoint.</p><p>PostgreSQL FDWs resemble mounting in that respect. Foreign tables mostly behave like normal tables and can receive the same <code>SELECT/INSERT/UPDATE/DELETE</code> queries. Behind the scenes, the wrapper's only job is to emit tuples.</p></section><section><h2 id="why-should-i-use-fdws">Why should I use FDWs?</h2><p>Foreign data wrappers are a great alternative to ETL. Instead of loading data into your warehouse that you might never use, you can mount the remote database and query it on demand.</p><p>Because they integrate with the PostgreSQL query planner, FDWs have a decent performance. The FDW can push down qualifiers and even aggregations to the remote database. FDWs can report the rough costs of starting a scan and fetching a tuple back to the query planner. This lets the query planner choose, for example, whether running multiple small single scans or one big one is a better strategy for satisfying a JOIN.</p><p>It's straightforward to write your own FDW and the <a href="https://www.postgresql.org/docs/12/fdwhandler.html" as="https://www.postgresql.org/docs/12/fdwhandler.html">PostgreSQL documentation</a> covers it extensively. The <a href="https://github.com/wikrsh/hello_fdw/" as="https://github.com/wikrsh/hello_fdw/">hello-world FDW</a> that returns "Hello, World" in a table is only a couple hundred lines of C code. If you prefer to focus on development simplicity, you can use Multicorn instead of raw C.</p><p>There are plenty of open-source foreign data wrappers available. They let you query other RDBMSs, NoSQL databases, CSV files or column stores. The <a href="https://wiki.postgresql.org/wiki/Foreign_data_wrappers" as="https://wiki.postgresql.org/wiki/Foreign_data_wrappers">PostgreSQL wiki</a> lists some of them.</p><p>Using a foreign data wrapper for your database or data source gives you access to a huge ecosystem of software that works with PostgreSQL. We can almost call this a network effect. A new data source that is accessible via an FDW enhances everything that works with PostgreSQL.</p></section><section><h2 id="why-use-fdws-with-splitgraph">Why use FDWs with Splitgraph?</h2><p><a href="https://www.splitgraph.com/docs/ingesting-data/foreign-data-wrappers/introduction" as="https://www.splitgraph.com/docs/ingesting-data/foreign-data-wrappers/introduction">Foreign data wrappers</a> are one of the ways that Splitgraph aims to make data engineers' and data scientists' work easier.</p><p>Splitgraph's <a href="https://www.splitgraph.com/docs/sgr/data-import-export/mount" as="https://www.splitgraph.com/docs/sgr/data-import-export/mount"><code>sgr mount</code></a> command handles the boilerplate around FDW initialization. This command creates a schema on your ‚Ä¶</p></section></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.splitgraph.com/blog/foreign-data-wrappers">https://www.splitgraph.com/blog/foreign-data-wrappers</a></em></p>]]>
            </description>
            <link>https://www.splitgraph.com/blog/foreign-data-wrappers</link>
            <guid isPermaLink="false">hacker-news-small-sites-23713994</guid>
            <pubDate>Thu, 02 Jul 2020 15:05:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python pattern matching: Guards and or-patterns might just not compose well]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23713795">thread link</a>) | @_ZeD_
<br/>
July 2, 2020 | https://ncik-roberts.github.io/posts/pep622.html | <a href="https://web.archive.org/web/*/https://ncik-roberts.github.io/posts/pep622.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      

<p><a href="https://www.python.org/dev/peps/pep-0622/">PEP 622</a> proposes adding a pattern matching construct to Python. Pattern matching allows the programmer to destructure data with a syntax that mirrors the construction syntax. The proposal brings Python in-line with many other modern programming languages, like Haskell, OCaml, and Rust. However, two features included in the proposal (or-patterns and guards) interact in a perhaps surprising way‚Äîsee <a href="https://hal.inria.fr/hal-01413241/document">this paper</a> for an explanation of this interaction as it relates to OCaml, another language with both or-patterns and guards.</p>

<p>You can try out an in-progress implementation of this PEP at this fork of cpython: <a href="https://github.com/brandtbucher/cpython/tree/patma">https://github.com/brandtbucher/cpython/tree/patma</a>.</p>

<p>In the rest of this post, I‚Äôll briefly summarize pattern matching, define or-patterns and guards, and show the surprising behavior in the context of Python.</p>

<h2 id="example-of-pattern-matching">Example of pattern matching</h2>

<p>Before the proposal, here‚Äôs how you might write a function that classifies a pair of animals according to their kind</p>

<div><div><pre><code><span>class</span> <span>Dog</span><span>:</span>
  <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>name</span><span>):</span>
    <span>self</span><span>.</span><span>name</span> <span>=</span> <span>name</span>

<span>class</span> <span>Cat</span><span>:</span>
  <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>age</span><span>):</span>
    <span>self</span><span>.</span><span>age</span> <span>=</span> <span>age</span>

<span>def</span> <span>classify</span><span>(</span><span>pet</span><span>):</span>
  <span>if</span> <span>isinstance</span><span>(</span><span>pet</span><span>,</span> <span>Cat</span><span>):</span>
    <span>print</span><span>(</span><span>"A cat that's {} years old"</span><span>.</span><span>format</span><span>(</span><span>pet</span><span>.</span><span>age</span><span>))</span>
  <span>elif</span> <span>isinstance</span><span>(</span><span>pet</span><span>,</span> <span>Dog</span><span>):</span>
    <span>print</span><span>(</span><span>"A dog named {}"</span><span>.</span><span>format</span><span>(</span><span>pet</span><span>.</span><span>name</span><span>))</span>

<span>classify</span><span>(</span><span>Dog</span><span>(</span><span>"Fido"</span><span>))</span>
<span># prints: A dog named Fido
</span>
<span>classify</span><span>(</span><span>Cat</span><span>(</span><span>3</span><span>))</span>
<span># prints: A cat that's 3 years old
</span></code></pre></div></div>

<p>Under the proposal, this is how you could write <code>classify</code>:</p>

<div><div><pre><code><span>def</span> <span>classify</span><span>(</span><span>pet</span><span>):</span>
  <span>match</span> <span>pet</span><span>:</span>
    <span>case</span> <span>Cat</span><span>(</span><span>age</span><span>=</span><span>age</span><span>):</span>
      <span>print</span><span>(</span><span>"A cat that's {} years old"</span><span>.</span><span>format</span><span>(</span><span>age</span><span>))</span>
    <span>case</span> <span>Dog</span><span>(</span><span>name</span><span>=</span><span>name</span><span>):</span>
      <span>print</span><span>(</span><span>"A dog named {}"</span><span>.</span><span>format</span><span>(</span><span>name</span><span>))</span>
</code></pre></div></div>

<p>In other words, pattern matching allows you to inspect a piece of data and simultaneously match its shape and bind the value of its fields to variables. In the above code, <code>Cat(age=age)</code> is a <em>pattern</em> that <em>matches</em> <code>Cat</code> values, and <em>binds</em> to the variable named <code>age</code>.</p>

<p>The proposal gives an informal description of the semantics of this construct, but the informal description doesn‚Äôt explain the interaction between two of the introduced features: or-patterns, and pattern guards. As it turns out, as currently implemented, the interaction between these features is somewhat surprising, and will probably yield at least one high-scoring Stack Overflow question if this PEP ends up being accepted.</p>

<h2 id="or-patterns">Or-patterns</h2>

<p>Here is an example of an or-pattern: <code>Cat(age=3) | Dog(name="Fido")</code>. This pattern matches either three-year-old cats or dogs named Fido. In practice:</p>

<div><div><pre><code><span># I have a three-year-old cat and a dog named Fido.
# This function returns true if the pet could be mine.
</span><span>def</span> <span>couldBeMyPet</span><span>(</span><span>pet</span><span>):</span>
  <span>match</span> <span>pet</span><span>:</span>
    <span>case</span> <span>Cat</span><span>(</span><span>age</span><span>=</span><span>3</span><span>)</span> <span>|</span> <span>Dog</span><span>(</span><span>name</span><span>=</span><span>"Fido"</span><span>):</span>
      <span>return</span> <span>True</span>
    <span>case</span> <span>_</span><span>:</span>
      <span>return</span> <span>False</span>

<span>print</span><span>(</span><span>couldBeMyPet</span><span>(</span><span>Cat</span><span>(</span><span>3</span><span>)))</span>
<span># prints True
</span>
<span>print</span><span>(</span><span>couldBeMyPet</span><span>(</span><span>Dog</span><span>(</span><span>"Rover"</span><span>)))</span>
<span># prints False
</span></code></pre></div></div>

<h2 id="pattern-guards">Pattern guards</h2>

<p>Pattern guards are boolean expressions that can be included in a <code>case</code> branch; the case branch is only taken if the pattern guard evaluates to true.</p>

<div><div><pre><code><span>def</span> <span>classify</span><span>(</span><span>pet</span><span>):</span>
  <span>match</span> <span>pet</span><span>:</span>
    <span>case</span> <span>Cat</span><span>(</span><span>age</span><span>=</span><span>age</span><span>)</span> <span>if</span> <span>age</span> <span>%</span> <span>2</span> <span>==</span> <span>0</span><span>:</span>
      <span>print</span><span>(</span><span>"This cat has an even age!"</span><span>)</span>
    <span>case</span> <span>Dog</span><span>(</span><span>name</span><span>=</span><span>name</span><span>)</span> <span>if</span> <span>sorted</span><span>(</span><span>name</span><span>)</span> <span>==</span> <span>list</span><span>(</span><span>name</span><span>):</span>
      <span>print</span><span>(</span><span>"This dog's name is in alphabetical order!"</span><span>)</span>
    <span>case</span> <span>_</span><span>:</span>
      <span>print</span><span>(</span><span>"I have nothing interesting to say about this pet."</span><span>)</span>

<span>classify</span><span>(</span><span>Cat</span><span>(</span><span>4</span><span>))</span>
<span># prints "This cat has an even age!"
</span>
<span>classify</span><span>(</span><span>Dog</span><span>(</span><span>"abe"</span><span>))</span>
<span># prints "This dog's name is in alphabetical order!"
</span>
<span>classify</span><span>(</span><span>Dog</span><span>(</span><span>"fido"</span><span>))</span>
<span># prints "I have nothing interesting to say about this pet."
</span></code></pre></div></div>

<p>In the above example, <code>if age % 2 == 0</code> and <code>if sorted(name) == list(name)</code> are pattern guards that allow that case to be taken only if that boolean expression evaluates to True.</p>

<h2 id="the-surprising-interaction">The surprising interaction</h2>

<p>What do you think this function does?</p>

<div><div><pre><code><span>def</span> <span>doesEitherCatHaveAnEvenAge</span><span>(</span><span>pet1</span><span>,</span> <span>pet2</span><span>):</span>
  <span>match</span> <span>(</span><span>pet1</span><span>,</span> <span>pet2</span><span>):</span>
    <span>case</span> <span>(</span><span>Cat</span><span>(</span><span>age</span><span>=</span><span>age</span><span>),</span> <span>_</span><span>)</span> <span>|</span> <span>(</span><span>_</span><span>,</span> <span>Cat</span><span>(</span><span>age</span><span>=</span><span>age</span><span>))</span> <span>if</span> <span>age</span> <span>%</span> <span>2</span> <span>==</span> <span>0</span><span>:</span>
      <span>return</span> <span>True</span>
    <span>case</span> <span>_</span><span>:</span>
      <span>return</span> <span>False</span>

<span>print</span><span>(</span><span>doesEitherCatHaveAnEvenAge</span><span>(</span><span>Cat</span><span>(</span><span>2</span><span>),</span> <span>Cat</span><span>(</span><span>4</span><span>)))</span>
<span># prints True
</span>
<span>print</span><span>(</span><span>doesEitherCatHaveAnEvenAge</span><span>(</span><span>Cat</span><span>(</span><span>2</span><span>),</span> <span>Cat</span><span>(</span><span>5</span><span>)))</span>
<span># prints True
</span>
<span>print</span><span>(</span><span>doesEitherCatHaveAnEvenAge</span><span>(</span><span>Cat</span><span>(</span><span>5</span><span>),</span> <span>Cat</span><span>(</span><span>4</span><span>)))</span>
<span># prints False (?????)
</span></code></pre></div></div>

<p>The last one (<code>doesEitherCatHaveAnEvenAge(Cat(5), Cat(4))</code>) may seem like it should evaluate to True. After all, the one of the patterns in the or-pattern seems like it matches the second cat, which is a cat with an even age.</p>

<p>Does <code>(Cat(5), Cat(4))</code> match against <code>(Cat(age=age), _) | (_, Cat(age=age)) if age % 2 == 0</code>? To answer this question, the semantics in your head might look something like this:</p>

<ol>
  <li>Well, <code>(Cat(5), Cat(4))</code> does match agains the first pattern of the or-pattern, <code>(Cat(age=age), _)</code>. This match binds the value 5 to the variable <code>age</code>.</li>
  <li>Now we check the guard <code>if age % 2 == 0</code>. Because <code>5 % 2 == 0</code> evaluates to False, this check fails.</li>
  <li>Go back to the or-pattern and see if there‚Äôs any other way to match it. In this case, <code>(Cat(5), Cat(4))</code> also matches the second pattern of the or-pattern, <code>(_, Cat(age=age)</code>. This binds the value 4 to the variable <code>age</code>.</li>
  <li>Now the guard <code>if age % 2 == 0</code> succeeds, because <code>4 % 2 == 0</code> evaluates to <code>True</code>.</li>
  <li>Because this case matches the value, we return True.</li>
</ol>

<p>This is perfectly sensible, but this is not what the implementation does. The implementation‚Äôs semantics are more like this:</p>

<ol>
  <li>Same as step 1 from above.</li>
  <li>Same as step 2 from above.</li>
  <li>Because the guard failed, the case isn‚Äôt taken! Instead, the next case is tried. This case (<code>case _:</code>) always succeeds, so we return False.</li>
</ol>

<p>In other words, pattern matching does‚Äôt have backtracking semantics, even if a value can match an or-pattern in multiple different ways.</p>

<p>I love pattern matching, and I‚Äôm excited to see that it might be adopted by such a popular language as Python. But this particular interaction of features might confuse novices. Let‚Äôs compare the approaches of other languages.</p>

<p>OCaml has the same semantics as Python here, but the OCaml compiler can emit a warning (because the compiler has enough type information to figure out whether the constituent patterns of an or-pattern can possibly match the same value in different ways).</p>

<div><div><pre><code><span>let</span> <span>()</span> <span>=</span>
  <span>match</span> <span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span> <span>with</span>
  <span>|</span> <span>(</span><span>x</span><span>,</span> <span>_</span><span>)</span> <span>|</span> <span>(</span><span>_</span><span>,</span> <span>x</span><span>)</span> <span>when</span> <span>x</span> <span>=</span> <span>2</span> <span>-&gt;</span> <span>print_endline</span> <span>":)"</span>
  <span>|</span> <span>_</span> <span>-&gt;</span> <span>print_endline</span> <span>":("</span>
<span>;;</span>
</code></pre></div></div>

<p>This prints <code>:(</code>, but also emits the warning:</p>

<div><div><pre><code>Warning 57: Ambiguous or-pattern variables under guard;
variable x may match different arguments. (See manual section 9.5)
</code></pre></div></div>

<p>Rust has pattern matching and guards, and has an experimental <code>or_patterns</code> feature. It implements backtracking semantics, unlike Python. This is weird in its own right, especially in the presence of side effects. Take a look at this program:</p>

<div><div><pre><code><span>#![feature(or_patterns)]</span>

<span>// Prompt the user whether they want to accept the match</span>
<span>pub</span> <span>fn</span> <span>check</span><span>(</span><span>x</span><span>:</span> <span>i32</span><span>)</span> <span>-&gt;</span> <span>bool</span> <span>{</span>
    <span>use</span> <span>std</span><span>::</span><span>io</span><span>::{</span><span>stdin</span><span>};</span>
    <span>println!</span><span>(</span><span>"Checking this match: {}. Should we accept it? y/n"</span><span>,</span> <span>x</span><span>);</span>
    <span>let</span> <span>mut</span> <span>s</span> <span>=</span> <span>String</span><span>::</span><span>new</span><span>();</span>
    <span>stdin</span><span>()</span><span>.read_line</span><span>(</span><span>&amp;</span><span>mut</span> <span>s</span><span>)</span><span>.expect</span><span>(</span><span>"Did not enter a correct string"</span><span>);</span>
    <span>return</span> <span>s</span><span>.trim</span><span>()</span> <span>==</span> <span>"y"</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>match</span> <span>(</span><span>1</span><span>,</span> <span>2</span><span>)</span> <span>{</span>
        <span>(</span><span>x</span><span>,</span> <span>_</span><span>)</span> <span>|</span> <span>(</span><span>_</span><span>,</span> <span>x</span><span>)</span> <span>if</span> <span>check</span><span>(</span><span>x</span><span>)</span> <span>=&gt;</span> <span>{</span>
            <span>println!</span><span>(</span><span>":)"</span><span>)</span>
        <span>}</span>
        <span>_</span> <span>=&gt;</span> <span>{</span>
            <span>println!</span><span>(</span><span>":("</span><span>)</span>
        <span>}</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>In particular, the guard can now run multiple times:</p>

<div><div><pre><code>$ cargo +nightly run
Checking this match: 1. Should we accept it? y/n
n
Checking this match: 2. Should we accept it? y/n
y
:)
</code></pre></div></div>

<p>I‚Äôm not sure what the right decision is for Python. Or-patterns and guards may just not compose well.</p>


      
    </div></div>]]>
            </description>
            <link>https://ncik-roberts.github.io/posts/pep622.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23713795</guid>
            <pubDate>Thu, 02 Jul 2020 14:48:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An interview with Alan Kay (March 2020)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23712945">thread link</a>) | @profchaos69
<br/>
July 2, 2020 | https://www.juxt.pro/blog/alan-kay | <a href="https://web.archive.org/web/*/https://www.juxt.pro/blog/alan-kay">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="preamble">
<div>
<p>This summer we were due to hold our XT20 conference, which was going to focus on
how we could bring some of the approaches of the past to tackle the challenges
of the present and the future. Unfortunately, one of these future challenges
arrived, and we had to make the difficult decision to cancel the event.</p>
<p>Alan Kay was one of the leading researchers at the legendary labs of ARPA and
Xerox PARC in the 1960s and 1970s. We wanted to understand from Alan how Xerox
PARC came to be, and how could possibly reproduce what happened there, to make
similar leaps for our industry in the future.</p>
<p>When we held our XT16 conference, we made short videos with all of our speakers
to introduce their talks, and we wanted to continue this tradition with XT20. So
prior to the cancellation, we recorded a short piece with Alan to introduce the
content of his talk.</p>
<p>Alan stresses that we‚Äôre only just at the start of our industry and
that we‚Äôve a long way to go. As he puts it, many of great ideas from
the 1960s and 1970s are still landing, before we consider the new
ground-breaking ideas that are yet to be found. To find those ideas,
we need to seek out the brightest among us, and then we have to figure
out how to fund and manage them properly.</p>
<div>
<p>
<iframe width="300" height="300" src="https://www.youtube.com/embed/Q6Ly4gSfAoo?rel=0" frameborder="0" allowfullscreen=""></iframe>
</p>
</div>
<div>
<blockquote>
<p>I got asked to give a talk at XT20 because I was one of the researchers and a
leader of a research group in the ARPA and Xerox combined research community in
the sixties and the seventies that invented many of the technologies that are in
use today including the ones that we‚Äôre using right now, these include: Personal
Computing; The Graphic User Interface; Ethernet; The Internet; Laser Printing;
Client/Server computing, and a host of other ones.</p>
<p>And so this was not just a series of inventions but was actually the creation of
several really large industries that have, according to the Wall St. Journal,
have returned about 45 trillion (US dollars) to the world, and the four largest
capital net-worth companies in America all used, are based on, these
technologies, so besides being good ideas, besides being something that can
boost human intellect and can deal with much more complicated situations, it
also has been a tremendous commercial success far beyond normal R&amp;D efforts.</p>
<p>One point of interest, I think, to people is that despite this, <strong>no country or
company or Univerisity is willing to fund such an effort!</strong>. The key is: can you
get the right people, and can you set up something that allows the researchers
and the right researchers to do the kind of stuff that normally was only done
when countries felt that they were in the middle of a war.</p>
<p>That‚Äôs the second point, there have been many such efforts, successful efforts,
such as ARPA and Xerox PARC in the past, especially in the US, and the Cold War,
and then back in WWII, and the particular way of going about it actually traces
back to the combined joint work of the UK and the US in developing Radar for
WWII. There‚Äôs a direct link in the methodologies used back then, and to an
extent in projects that are not so directly involved such as Bletchley Park (in
the UK) and Los Alamos and the Atomic Bomb effort (in the US).</p>
<p>So I think what will be of interest to the people who go to this conference will
likely be the idea first that it really can be done, and <em>has</em> been done (more
than once).</p>
<p>Most normal regular people are quite against taking what seems to be a huge risk
but in fact, the pay-off from these risks, which is actually only been a few
hundred million (GB) pounds or so, has been in the trillions!</p>
<p>So if you count up all the zeros the return on investment is not 15% but more like 20,000%,
so it actually would make good business sense for people to take these kinds of
risks, but that isn‚Äôt the way business people think. And so this is, I think, a
really interesting area to explore and that‚Äôs what I will at least open the
door to in my talk.</p>
</blockquote>
<p>
‚Äî Alan Kay
</p>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://www.juxt.pro/blog/alan-kay</link>
            <guid isPermaLink="false">hacker-news-small-sites-23712945</guid>
            <pubDate>Thu, 02 Jul 2020 13:38:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lite: An Implementation Overview]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23712897">thread link</a>) | @bpierre
<br/>
July 2, 2020 | https://rxi.github.io/lite_an_implementation_overview.html | <a href="https://web.archive.org/web/*/https://rxi.github.io/lite_an_implementation_overview.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a href="https://rxi.github.io/index.html"></a>
    
<p>2020.06.04</p>
<p>updated: 2020.06.06</p>



<p>
  This write-up outlines some of the implementation details of the
  <a href="http://github.com/rxi/lite">lite</a> text editor. At the time of writing
  this lite is version <a href="https://github.com/rxi/lite/releases/tag/v1.06">1.06</a>.
</p>


<p>
  Lite is written mainly in Lua (5.2) with the lowest level parts written in C.
  It is written with the intent of being lightweight, easy on the eyes,
  responsive and trivial to modify and extend. To achieve this the core
  implementation aims to be <em>as simple as possible</em>: complexity is only
  brought in when it's proven the simplest method isn't practical.
</p>



<p>
  The core of lite implements documents, syntax highlighting, a
  cooperative-threading system, basic logging and the general ui layout system.
  Overall the core is in charge of handling user input, running per-frame tasks,
  and rendering the resultant frame early enough to meet the frames-per-second
  specified in <code>config.fps</code>.
</p>



<p>
  Lite implements a cooperative-threading system where by background tasks ‚Äî
  such as full-document syntax highlighting and updating the internal list of
  project files ‚Äî can be performed incrementally. Cooperative threads in lite are
  implemented using lua's coroutines and are referred internally as simply
  <code>threads</code>.
</p>
<p>
  A thread can be started by using the <code>core.add_thread()</code> function, this
  function takes a function, and an optional object which is used as a weak
  reference to that thread, eg. if a doc is passed as the weak reference, when
  that doc is garbage collected the coinciding thread will also cease to exist.
</p>
<p>
  As threads in lite are cooperative they're expected to regularly call
  <code>couroutine.yield()</code>. Typically this yielding is done every <code>n</code>
  lines for line-based tasks (eg. full-project search, syntax highlighting).
  When a thread yields the core will continue to render the frame, or ‚Äî if there is
  still enough time left in the current frame ‚Äî pass control to another thread.
  Threads can also pass a numerical argument to <code>coroutine.yield()</code> to wait
  for the number of seconds specified:
</p>
<pre>core.add_thread(function()
  -- print "hello world" every 10 seconds
  while true do
    print("hello world")
    coroutine.yield(10)
  end
end
</pre>
<p>
  Practical usage examples of lite's threading can be seen in the core's project
  file scanning (<code>data/core/init.lua</code>) and the incremental syntax highlighting
  (<code>data/core/doc/highlighter.lua</code>).
</p>


<p>
  All loaded text files in lite are stored in <code>Docs</code>. A doc keeps a table
  of a text file's lines (<code>Doc.lines</code>), undo and redo
  state, the current syntax (<code>Doc.syntax</code>), syntax highlighting state
  (<code>Doc.highlighter</code>) and caret/selection state. Docs are opened using the
  <code>core.open_doc()</code> function; if the function is called and a doc of that
  filename is already open then the existing doc is returned such that
  more-than-one doc representing the same file should never be present.
</p>
<p>
  Lite stores all the open docs in the <code>core.docs</code> table; each frame lite
  checks the number of views referencing each doc and releases those with zero
  references ‚Äî this is an instance of lite favoring polling over callbacks or
  event listeners. This approach is done throughout lite; in avoiding event
  listeners we also avoid having to manage unregistering event handlers or worry
  about having those which are never unregistered through error. This leads to
  much simpler, less error-prone code.
</p>

<p>
  Lite implements a simple syntax highlighter based around lua patterns, this is
  split up into 3 parts:
</p>
<ul>
  <li><code>core.syntax</code>: stores language syntax specifications</li>
  <li><code>core.tokenizer</code>: converts text into table of tokens using a given syntax</li>
  <li><code>core.doc.highlighter</code>: stores token state for lines of a doc and handles
         full-document incremental highlighting</li>
</ul>
<p>
  A language syntax is stored as a table of lua patterns mapped to to their
  resultant token type (<code>.patterns</code>) and a table of symbols mapped to their
  token type (<code>.symbols</code>). Patterns in the pattern table can also be a
  range of the following format:
</p>
<pre>{ range_start_pattern, range_end_pattern [, escape_character] }
</pre>
<p>
  Ranges can be used for matching strings:
</p>
<pre>{ '"', '"', '\\' }
</pre>
<p>
  An example of syntax specifications can be seen in any of the
  <code>data/plugins/language_*.lua</code> files.
</p>
<p>
  The highlighter persists range state between lines by storing the pattern
  table index of the current range. As the highlighter works in increments of
  lines, ranges are useful for multi-line comments or strings which a single
  pattern would fail on.
</p>
<p>
  When the <code>tokenizer.tokenize()</code> function is called it iterates the syntax's
  pattern table from top to bottom, such that patterns higher up in the table
  take precedence. When it matches a pattern it pushes the token to the
  resultant table, if the token's content matches any of the keys in the
  <code>.symbols</code> table that value is used instead of the matched token value;
  this acts both as a more convenient way of specifying keywords as well as an
  optimization as the tokenizer can attempt matching fewer patterns, even if
  there are many keywords specified. The function returns a <code>state</code> integer
  which is used to indicate which pattern range it is currently inside if it is
  inside any.
</p>
<p>
  <code>core.doc.highlighter</code> is in charge of providing tokenized lines when
  displaying a document; each doc stores a <code>Highlighter</code> object. The
  highlighter assures highlighting information for any line that is requested
  is <em>always</em> available, even if the full-document incremental highlighter
  has not yet reached that line.
</p>
<p>
  When a request is made to the highlighter for a specific line the highlighter
  first checks its cache for the line; if it does not have the line cached ‚Äî
  or, if the line's text has changed since its cached version ‚Äî it immediately
  tokenizes the line, continuing from the tokenizer state left from the
  previous line. The highlighter's <code>max_wanted_line</code> field is set to
  that line's value if it's greater than the existing <code>max_wanted_line</code>.
</p>
<p>
  A doc's highlighter creates a thread when it's created which it uses to do
  full-document highlighting starting from its <code>first_invalid_line</code> up
  until the <code>max_wanted_line</code>. When a change occurs in a document the
  <code>first_invalid_line</code> is set to the first line of the change if it's
  greater than the current <code>first_invalid_line</code>.
</p>
<p>
  This implementation results in the following characteristics:
</p>
<ul>
  <li>Displayed lines are always syntax highlighted with, at the very
         least, highlighting which is valid to the current screen's content</li>
  <li>Displayed lines are <em>eventually</em> highlighted with
         full-document aware highlighting</li>
  <li>The highlighting is performed per-line, and so ‚Äî with the exception
         of extremely long lines ‚Äî can be done incrementally without a
         negative effect on responsiveness</li>
  <li>Highlighting is only performed up until the point in the document it
         is required, for example, up until the last visible line</li>
</ul>



<p>
  Each part of lite's UI is implemented as a <code>View</code>, that is, a document is
  shown in the UI as a <code>DocView</code>, the status bar at the bottom the
  <code>StatusView</code> etc. Each view exists within the <code>RootView</code>
  (<code>core.root_view</code>) which is in charge of calling the <code>:update()</code> and
  <code>:draw()</code> functions of each view, managing the layout of the
  views, and routing user input to relevant views.
</p>
<p>
  The rootview is implemented as a binary tree of <code>Nodes</code>. Each node is one
  of the following types:
</p>
<ul>
  <li><code>hsplit</code>: Contains two children side-by-side and a divider between them</li>
  <li><code>vsplit</code>: Contains two children one-above-the-other and a divider between them</li>
  <li><code>leaf</code>: Contains one or more views, and, if there is more than one
        view, a tab at the top for each view.</li>
</ul>
<p>
  Each frame the rootview calculates its layout based on the divider position of
  each split and sets the <code>.size</code> field of each node and view accordingly.
</p>
<p>
  The rootview also has a concept of <em>locked nodes</em>; the size of a locked
  node is not determined by the divider position but instead is set from the
  view's <code>.size</code> field. Locked nodes cannot be resized by the user as
  normal nodes would be, they cannot be closed and cannot open additional views.
  The locked-node feature is used for, amongst other things, the status bar at the
  bottom of the screen which we typically want to be always present and
  immutable.
</p>
<p>
  lite takes the approach of effectively redrawing <em>everything</em> whenever
  it needs to redraw <em>anything</em>, this lends itself to simplified UI code.
  There are no event listeners or callbacks to manage. If something changes the
  state of the UI (eg. the caret is moved), the <code>core.redraw</code> boolean is set
  to <code>true</code> to signify that something has changed and the UI is redrawn on
  that frame. For further simplicity any user input events will also set
  <code>core.redraw</code>, such that there's a guarantee any change which resulted from
  user input will result in the screen contents being updated.
</p>
<p>
  Although the idea of redrawing everything each time may appear wasteful, lite
  employs a technique where by only regions of the screen which have changed
  between frames are actually redrawn ‚Äî these regions can be displayed by calling
  <code>renderer.show_debug(true)</code>. This technique is implemented on the C level
  of the code and is invisible to the lua portion which acts as if it's doing
  a full redraw each time.
</p>
<p>
  An overview of how this is achieved is detailed in the
  <a href="https://rxi.github.io/cached_software_rendering.html">Cached Software Rendering</a> write-up.
</p>



<p>
  Lite's plugin system is based around lua's module system; each plugin is
  simply a lua module (that is, a single <code>.lua</code> file, or, a directory
  containing a <code>init.lua</code> file). All modules in the <code>data/plugins</code>
  directory are automatically loaded when lite starts ‚Äî this is done after
  initializing the core and before loading the user and project modules. Thus to
  install a plugin you simply place the file in the plugins directory; to
  uninstall a plugin you delete the file.
</p>
<p>
  A specific order of which plugins are loaded is not guaranteed by lite but,
  as plugins are just regular lua modules, a plugin can simply call <code>require</code>
  on another plugin if it needs to assure that ‚Ä¶</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rxi.github.io/lite_an_implementation_overview.html">https://rxi.github.io/lite_an_implementation_overview.html</a></em></p>]]>
            </description>
            <link>https://rxi.github.io/lite_an_implementation_overview.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23712897</guid>
            <pubDate>Thu, 02 Jul 2020 13:33:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Setting the SSID of a Fios Home Router to an Emoji]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23712697">thread link</a>) | @deadmetheny
<br/>
July 2, 2020 | https://hamptonmoore.com/posts/fios-home-router-emoji/ | <a href="https://web.archive.org/web/*/https://hamptonmoore.com/posts/fios-home-router-emoji/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"> <article>   <p>Setting the name/SSID of your WiFi to an emoji is fairly simple for the Fios Home Router. Simply log into the router, and go the page for setting the SSID.</p> <p>Once you are there open the developer console using <code>Ctrl+Shift+I</code> or by right clicking and clicking the option labeled along the lines of <code>Inspect Element</code> or <code>Inspect</code>. After this simply paste the following code into the console.</p> <div><div><pre><code><span>validSSID</span> <span>=</span> <span>function</span><span>(){</span><span>return</span> <span>true</span><span>}</span>
</code></pre></div></div> <p>This overrides the current validSSID function which is used to make sure that your SSID is made of the Fios required 1-32 alphanumerical ascii characters. This is not an actual technical requirements for SSIDs with the 2012 standard of 802.11 (Section 6.3.11.2.2) stating SSIDs simply have to be a max of 32 bytes. Once this script is ran you should be able to type anything less than 32 bytes. This tends to be at most 32 characters, but depending on the size of the Unicode characters used it can be much less. For instance the fire emoji, <code>üî•</code>, is actually 4 bytes because of how UTF-8 works. This means that only 8 fire emojis could be used. To get the size of a string simply use the site <a href="https://mothereff.in/byte-counter">https://mothereff.in/byte-counter</a>.</p> <p>Have fun setting unusal SSIDs</p> <hr> <p> Hello reader. I do not normally like to put advertisements or promotions on my website, but recently a good friend of my Jaden Ann Scrivener died in a car crash. She was known in the community as the most caring and energetic person around. She was a beam of sunshine and happiness brightening up the day of anyone who interacted with her. If you could <a href="https://www.aplos.com/aws/give/RayofHopeMedicalMissionsInc/Jaden">please donate to her memorial fund</a>. All the proceeds will go to the <a href="https://www.rohmm.org/">Ray of Hope Medical Missions</a> which facilitates life-changing surgeries, reduces infant mortality, and provides mission opportunities locally. </p> </article>  </div></div>]]>
            </description>
            <link>https://hamptonmoore.com/posts/fios-home-router-emoji/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23712697</guid>
            <pubDate>Thu, 02 Jul 2020 13:05:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debugging Abstractions: The Benefits of Mindfulness for Software Engineers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23712407">thread link</a>) | @sciencewolf
<br/>
July 2, 2020 | https://algodaily.com/blog/debugging-abstractions-the-benefits-of-mindfulness-for-software-engineers | <a href="https://web.archive.org/web/*/https://algodaily.com/blog/debugging-abstractions-the-benefits-of-mindfulness-for-software-engineers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>Code Mode</h2>

<p>It's been a wild week. You and your team have been engaged in an all-out war with the codebase for the past two spints. There's this new integration with a partner that's close to being shipped, and it promises bountiful revenue and voluminous web traffic. And you've been working on the part of it that'll seal the deal and let your squad deploy, come Monday morning.</p>

<p>You find yourself on the Friday night before launch, 6pm, absolutely fried at your desk. Everyone else on your team already left to attend the company happy hour, or has gone home seeking sanity from work. For the past several hours, you've been tracking down a nasty, horrendous bug that could prevent the feature from shipping next week.</p>

<p>But you introduced it.</p>

<p>Caught late in the game, with the marketing team eager to deploy, there were no other options. Thankfully, you're close to patching things up. Your thoughts have been a web of abstractions all night, looking something like this:</p>

<ul>
<li>I've looked at <code>SuperClass</code>, but the stack trace is from <code>ChildClass</code>.</li>
<li>Alright, so <code>ChildClass</code> imports the function from <code>HelperModule</code>...</li>
<li><code>HelperModule</code> uses a bunch of functions from <code>CrazyLibrary</code>. Let's do a search. Great, <code>CrazyLibrary</code> has no documentation.</li>
<li>Wait, did I check out the latest <code>master</code> yet?</li>
<li>Oh wait, the error wasn't actually on the server. Let's look at the client.</li>
<li><code>HugeReactComponent</code> is making the call. Maybe the <code>type</code> is wrong?</li>
<li>Oh man, it uses <code>DatabaseModernClientApi</code>... I don't know <code>DatabaseModernClientApi</code>.</li>
<li>Wait no, it's in <code>MiddlewareClientServer</code>...</li>
</ul>

<p><img src="https://miro.medium.com/max/2560/0*UxR4_Op7AExQz-Oo.png"></p>

<p>At 7:30pm, you're sure you've nailed it. It was a silly conditional that got in the way. Boom, problem solved. After merging a PR that switched the broken ternary statement around, off to the happy hour you go.</p>

<p>Beaming with pride from merging the bug fix, you walk in, and notice your team chatting with folks from a sister team. You recognize some members of the sister team, but not everyone. You go and try to introduce yourself.</p>

<blockquote>
<p>"Hey y'all, what's happening?!"</p>
</blockquote>

<p>Both your team and the sister team sheepishly smile at you. "Hey man", one of them says, "long day?" You look around, and suddenly notice that some people have startled looks on their faces. Then you realize they had been having a low-key conversation, and that you'd jumped into the conversation at quite the high decibel.</p>

<blockquote>
<p>"Yeah, haha", you play it off, "Oh boy, working on the <code>PartnerIntegrationProject</code> this week was awful! Whoever wrote <code>SuperClass</code> created a complete mess. Must've taken 10 hours away from my life."</p>
</blockquote>

<p>Everyone in the circle stops smiling. Eric, who wrote that class, nervously chuckles. "Yeah, I guess it could be better, huh?" Oops. Bad move. You feel the energy drain out of the conversation they were having.</p>

<p>You stay silent for the next half hour or so, and everyone keeps chatting, but it <em>feels</em> weird. You keep noticing people's expressions and body language. There's some more forced conversation before a few folks excuse themselves. Then everyone disperses.</p>

<p>And for the rest of the evening, you can't shake off the feeling that everyone's thinking something about you. That you did something wrong. You get a sense that the energy was off, and blame yourself.</p>

<p>But you're not to blame! Everything was probably fine, and no one was judging you. You were just in <strong>code mode</strong>.</p>

<h2>What Happens In Your Brain When You Program?</h2>

<p>Ask any developer, and "code mode" is a real thing. We seem to be so drawn into our innermost thoughts of <code>classes</code>, <code>modules</code>, <code>syntax</code>, and <code>systems</code>-- that we lose track of how to mentally function the rest of the time. Some call it "monkey mind" or restlessness, but we all recognize it. It's the brain on hyperdrive, going 200 miles per hour when the speed limit's about 50.</p>

<p>It's the thinking, or rather, <em>the overthinking</em>, that is almost always unnecessary. And for reasons unbeknownst, this always tends to happen when we need to deal with other people.</p>

<p><img src="https://i.imgur.com/95NZpPy.png"></p>

<p>Now, that doesn't seem problematic, right? Being stuck in code mode is harmless. So you overthink the occasional small talk session, and can't really pay attention to long films, but is it really harmful?</p>

<p>No, not really. But understanding why it happens helps us understand how to make the gear switch a little bit smoother, which is behind my upcoming pitch for meditation. If you're able to leave the programmatic thought patterns behind anytime you'd like, you have greater control over your life.</p>

<p>Of course, we want to be sure of our assumptions. After all, the argument for meditation requires a somewhat well-formed paradigm of what's happening when we read and write code. It's important to take into account exactly which thought patterns we "execute" <strong>while</strong> in code mode.</p>

<h2>What's Going On Up There?</h2>

<p>There was a push in recent years to allow programming to replace the study of a foreign language. Around that time, <a href="https://par.nsf.gov/servlets/purl/10085745%20conducted%20a%20study%20that%20observed%2017%20participants%20in%20an%20fMRI%20scanner" rel="nofollow" target="_blank">Norman Peitek, Janet Siegmund, and a team of researchers</a> while they were comprehending short source-code snippets. Their key finding was that despite the stereotype of math and logic being the major concern in programming, the brains of the participants showed greater activation of its language centers than expected.</p>

<p>Now, this may be confusing to you, as it seemingly contradicts <em>the idea of code mode</em>. After all, if the language centers are activated, shouldn't we, as social beings who communicate through the use of language, not be affected by these lingering cognitive thought patterns?</p>

<p>This could be so. But if we dig deeper into the results of the sudy, we actually find that the programmer mind is activated more traditionally than the above finding would suggest:</p>

<blockquote>
<p>In essence, we found five relevant activation clusters, all in the left hemisphere.</p>
</blockquote>

<p>The function of the left hemisphere is thought to be for control of the right side of the body, and "is the more academic and logical side of the brain". The right hemisphere is associated with creativity, visual/spatial perception, and emotional management and expression.</p>

<p>Because this <a href="https://now.northropgrumman.com/the-left-brain-right-brain-myth-is-it-true/" rel="nofollow" target="_blank">has been disputed recently</a>, I took a look at what naysayers of the "left-brain, right-brain myth" were saying. It turns out, most of the rejection of this "myth" stems from the fact that <em>people are not usually left-brain or right-brain dominant</em>. However, the fact of the matter is, the left hemisphere is <strong>still associated</strong> with logical operations and analytical functions, and the right with more "emotional" or "creative" activities.</p>

<blockquote>
<p>In fact, a 2013 University of Utah study on brain lateralization examined the brains of more than 1,000 people and found no evidence for people having a dominant side of the brain. <em>Even though each side of the brain does more work for certain functions</em>, such as language being localized on the left and attention on the right, this doesn‚Äôt vary by person. All of the study participants, whether they were engineers or musicians, used their entire brain equally, debunking the left-brain right-brain myth.</p>
</blockquote>

<p>In addition to programming being left hemisphere dominant, there's also a lot going on. The earlier study referenced found that the activated regions while coding found were:</p>

<ol>
<li>Middle frontal gyrus (division of attention, silent word reading, verbal/numeric problem solving)</li>
<li>Middle temporal gyrus (categorization)</li>
<li>Inferior parietal lobule (verbal/numeric problem solving)</li>
<li>Inferior frontal gyrus (verbal/numeric)</li>
<li>Inferior frontal gyrus (silent word reading, problem solving)</li>
</ol>

<p>If this sounds like a surprisingly high amount of brain activity merely for <em>understanding source code</em>, I would agree. And if it sounds like you'd be surprised if all this happened when trying to sleep or talking to a friend, you'd probably be right. Thus, I'd argue that one should choose to believe that quite a bit is going in mentally when we program, and mostly in the left hemisphere.</p>

<h2>But Isn't It Fun?</h2>

<p>An interesting note to add is that this kind of intensive brain activity sounds painful in a challenging way, but is actually desirable. Many call it the "flow" state. Courtland Allen and Vincent Woo <a href="https://www.indiehackers.com/podcast/041-vincent-woo-of-coderpad" rel="nofollow" target="_blank">talked about it in their interview on IndieHackers</a>:</p>

<p>Courtland says:</p>

<blockquote>
<p>That's funny because it reminds me of the first two years after I moved to San Francisco. I started a startup and I basically just coded for sixteen hours a day, every day for two years, and the problem is that if you're in flow for that long and you don't vary your activities... you don't make new memories, everything just blurs together, so I have a two year block of time in my life where there were zero memories, and I swore that I would never do that again.</p>
</blockquote>

<p>To which Vincent replies:</p>

<blockquote>
<p>That's kind of what I suspected happened to that sixty year old plus guy at Amazon, I think he just sat down to code one day and then he woke up, and he was sixty. I don't know, I think flow is both really seductive and also kind of boring in it's own way.</p>
</blockquote>

<p>A fascinating take-away of the above conversation is the conflation of two different ideas: <code>flow</code> state and <code>code mode</code>. From our good friend, <a href="https://en.wikipedia.org/wiki/Flow_(psychology)" rel="nofollow" target="_blank">Wikipedia</a>:</p>

<blockquote>
<p>In positive psychology, a flow state, also known colloquially as being in the zone, is the mental state in which a person performing an activity is fully immersed in a feeling of energized focus, full involvement, and enjoyment in the process of the activity.</p>
</blockquote>

<p>Here, I argue this point, and I want to be succint: <code>flow</code> and <code>code mode</code> appear to be two sides of the same coin. That specific coin is neurotransmitter-fueled activity, causing us to hone in one problem (or consecutive problems) for an indefinite period of time. However, we generally use the term <code>flow</code> to refer to the good parts of it, and I'm using <code>code mode</code> as the detrimental aspect.</p>

<p>I think we'd all agree that <a href="https://algodaily.com/lessons/solving-the-health-problems-of-software-engineers" rel="nofollow" target="_blank">16 hours spent on something is not good for your health</a>, mentally or physically. Especially <a href="https://www.amazon.com/gp/product/0321751043/ref=as_li_qf_asin_il_tl?ie=UTF8&amp;tag=algodaily03-20&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0321751043&amp;linkId=6fb078bf069b7f8eb648902d5923ab87" rel="nofollow" target="_blank">the art of programming</a>-- your back aches, your eyes burn, and you leave the coding session feeling unsatisfied. This is what we want to avoid, and the mental fatigue this imparts on you will carry over to other parts of life.</p>

<p>In ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://algodaily.com/blog/debugging-abstractions-the-benefits-of-mindfulness-for-software-engineers">https://algodaily.com/blog/debugging-abstractions-the-benefits-of-mindfulness-for-software-engineers</a></em></p>]]>
            </description>
            <link>https://algodaily.com/blog/debugging-abstractions-the-benefits-of-mindfulness-for-software-engineers</link>
            <guid isPermaLink="false">hacker-news-small-sites-23712407</guid>
            <pubDate>Thu, 02 Jul 2020 12:30:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubernetes Operators Explained]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23712344">thread link</a>) | @pperzyna
<br/>
July 2, 2020 | https://pperzyna.com/blog/kubernetes-operators-explained/ | <a href="https://web.archive.org/web/*/https://pperzyna.com/blog/kubernetes-operators-explained/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Have you ever wondered how effective Site Reliability Engineering (SRE) teams manage complex applications successfully? In the Kubernetes ecosystem, there is only one answer: Kubernetes Operators! In this article, we will examine both what they are and how they work.</p><div><p>The Kubernetes Operator concept was developed by engineers at CoreOS in 2016 as an advanced and native way of building and driving every application on the Kubernetes cluster, which needs domain-specific knowledge. It provides a consistent approach to handle all application operational processes automatically, without any human reaction via close cooperation with the Kubernetes API. In other words, an operator is a way of packaging, running, and managing Kubernetes applications.</p><p>The Kubernetes Operator pattern acts in accordance with one of the core Kubernetes principles: <a href="https://en.wikipedia.org/wiki/Control_theory">the control theory</a>. In robotics and automation, it is a mechanism that continuously operates dynamical systems. It relies on an ability to quickly tailor the workload demand to the available resources as accurately as possible. The objective is to develop a control model with the necessary logic to help an application or system remain stable. In Kubernetes world, that part is handled by controllers.</p><p>A controller is a special software that, in the loop, responds to changes and performs adaptation actions in the cluster. The first Kubernetes controller was a kube-controller-manager. It is regarded as an ancestor for all operators, which were built later.</p><h2 id="what-is-a-controller-loop">What Is a Controller Loop?</h2><p>To put it simply, controller loops are the base of controller actions. Imagine there is a non-terminating process (called a reconciliation loop, in Kubernetes) happening over and over again, as in the following illustration:</p><a href="#kubernetes-operators-reconciliation-loop.png" onclick="LazyLoadImg()"><figure><img src="https://d33wubrfki0l68.cloudfront.net/3d59e9e2da748992dd14e5abc92073ef7cbcbee9/9f266/img/blog/kubernetes-operators-reconciliation-loop_hu9f7037ecd3cc7a82b7d5e74d6b2b9715_20290_564x0_resize_box_2.png" data-src="https://d33wubrfki0l68.cloudfront.net/3d59e9e2da748992dd14e5abc92073ef7cbcbee9/9f266/img/blog/kubernetes-operators-reconciliation-loop_hu9f7037ecd3cc7a82b7d5e74d6b2b9715_20290_564x0_resize_box_2.png" alt="Kubernetes Operator Controller Loop" title="Kubernetes Operator Controller Loop"></figure></a><a href="#_" id="kubernetes-operators-reconciliation-loop.png"><figure><img src="" data-src="https://d33wubrfki0l68.cloudfront.net/4d00a0df53a752d79d89dbdf5f9da2b36f5167b3/b8cdc/img/blog/kubernetes-operators-reconciliation-loop.png" alt="Kubernetes Operator Controller Loop" title="Kubernetes Operator Controller Loop"></figure></a><p>This process observes at least one Kubernetes <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/#kubernetes-objects">object</a>, which contains information about the desired state. Objects such as ‚Ä¶</p><ul><li>Deployments,</li><li>Services,</li><li>Secrets,</li><li>Ingress,</li><li>Config Maps,</li></ul><p>‚Ä¶ are defined by configuration files made up of manifests in JSON or YAML. Then the controller(s) makes a continuous adjustment via Kubernetes API to imitate the desired state until the current state becomes the desired state, according to the built-in logic.</p><p>In that way, Kubernetes deals with the dynamic nature of Cloud Native systems, by handling a constant change. Examples of modifications perform to achieve expected state include:</p><ul><li>Noticing when nodes go down and demanding a new one.</li><li>Checking if pods need to be replicated.</li><li>Creating a new load-balancer, if requested.</li></ul><h2 id="how-does-a-kubernetes-operator-work">How Does a Kubernetes Operator Work?</h2><p>An operator is an application-specific controller. It extends a Kubernetes API to create, configure, and manage complex applications on behalf of humans (operation engineers or site reliability engineers). Let‚Äôs see what Kubernetes documentation says about it.</p><blockquote><p><em>Operators are software extensions to Kubernetes that make use of custom resources to manage applications and their components. Operators follow Kubernetes principles, notably the control loop.</em> - <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/">Kubernetes Documentation</a></p></blockquote><p>So far, you know that operators take advantage of controllers that observe Kubernetes objects. These controllers are a bit different because they are tracing custom objects, often called custom resources (CR). CR is an extension of the Kubernetes API that provides a place where you can store and retrieve structured data‚Äîthe desired state of your application. The whole principle of operation is presented in the diagram below.</p><a href="#kubernetes-operators-controller-loop.png" onclick="LazyLoadImg()"><figure><img src="https://d33wubrfki0l68.cloudfront.net/421570f988ea30fb53902d4533e0b8de6911d7b7/fa9db/img/blog/kubernetes-operators-controller-loop_hu9fe4ce2832296e1fe8a815e4eca60fda_43276_784x0_resize_box_2.png" data-src="https://d33wubrfki0l68.cloudfront.net/421570f988ea30fb53902d4533e0b8de6911d7b7/fa9db/img/blog/kubernetes-operators-controller-loop_hu9fe4ce2832296e1fe8a815e4eca60fda_43276_784x0_resize_box_2.png" alt="Kubernetes Operator Controller Loop" title="Kubernetes Operator Controller Loop"></figure></a><a href="#_" id="kubernetes-operators-controller-loop.png"><figure><img src="" data-src="https://d33wubrfki0l68.cloudfront.net/63c39aec0db28d70ff470c5aec042c5301b8bc3e/93486/img/blog/kubernetes-operators-controller-loop.png" alt="Kubernetes Operator Controller Loop" title="Kubernetes Operator Controller Loop"></figure></a><p>The Operator continuously tracks cluster events relating to a specific type of custom resource. The types of events on these custom resources that can be tracked are:</p><ul><li>Add,</li><li>Update,</li><li>Delete.</li></ul><p>When the operator receives any information, it will take action to adjust the Kubernetes cluster or external system to the desired state as part of its reconciliation loop in the custom controller.</p><h2 id="how-to-add-a-custom-resource">How to add a custom resource?</h2><p>A custom resource extends Kubernetes capabilities by adding new kinds of objects that can be helpful for your application. Kubernetes provides two ways to add custom resources to clusters:</p><ul><li><strong>via API Aggregation</strong>, an advanced method that requires you to build your own API Server, but will give you more control</li><li><strong>via Custom Resource Definitions (CRD)</strong>, a simple way that can be created without any programming knowledge, as an extension to the original Kubernetes API server.</li></ul><p>These two options meet the needs of different users, who can choose between flexibility and ease of use. The Kubernetes community created a <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#choosing-a-method-for-adding-custom-resources">comparison</a> that will help you decide what method is right for you, but the most popular choice is CRD.</p><h3 id="custom-resource-definitions">Custom Resource Definitions</h3><p>Custom Resource Definitions have been around for quite some time now; the first major API specification was released with Kubernetes 1.16.0. The manifest below presents an example:</p><div><pre><code data-lang="yaml"><span>apiVersion</span>: apiextensions.k8s.io/v1beta1
<span>kind</span>: CustomResourceDefinition
<span>metadata</span>:
  <span>name</span>: application.stable.example.com
<span>spec</span>:
  <span>group</span>: stable.example.com
  <span>version</span>: v1
  <span>scope</span>: Namespaced
  <span>names</span>:
    <span>plural</span>: application
    <span>singular</span>: applications
    <span>kind</span>: Application
    <span>shortNames</span>:
      - app
</code></pre></div><p>This CRD will allow you to create a CR called <em>Application</em>. (We are going to use it in the next section.) The first two lines define what <code>apiVersion apiextensions.k8s.io/v1beta1</code> of object kind <code>CustomResourceDefinition</code> you want to create.</p><p>The metadata describes the name of the resource, but the most important place here is the field <em>spec</em>. It lets you specify the group and version and the scope of visibility - namespaced or cluster-wide.</p><p>Afterwards, you define names in multiple formats and create a handy short name, which lets you perform a command <code>kubectl get app</code> to get the existing CR.</p><h3 id="custom-resource">Custom Resource</h3><p>The CRD above allows you to create the following manifest of a custom resource.</p><div><pre><code data-lang="yaml"><span>apiVersion</span>: stable.example.com/v1
<span>kind</span>: Application
<span>metadata</span>:
  <span>name</span>: application-config
<span>spec</span>:
  <span>image</span>: container-registry-image:v1<span>.0.0</span>
  <span>domain</span>: teamx.yoursaas.io
  <span>plan</span>: premium
</code></pre></div><p>As you can see, we can contain here all the necessary information required to run an application for a specific case. This custom resource will be observed by our operator - to be precise, by the operator‚Äôs custom controller. According to the built-in logic in the controller, the necessary actions will imitate the desired state. It can create a Deployment, Service, and necessary ConfigMaps for our application. Run it and expose it via ingress on a specific domain. This is just an example of a use case, but it can do whatever is designed.</p><p>Operators can also be used to provision resources that live outside Kubernetes. You can control the provisioning of external routers or create a database in the cloud without leaving the Kubernetes platform.</p><h2 id="kubernetes-operators-a-case-study">Kubernetes Operators: a Case Study</h2><p>To have a whole clear picture of Kubernetes Operators, let‚Äôs examine a <a href="https://github.com/coreos/prometheus-operator">Prometheus Operator</a>, one of the first and most popular operators. It simplifies the deployment and configuration of Prometheus, Alertmanager, and related monitoring components.</p><p>The core feature of the Prometheus Operator is to monitor the Kubernetes API server for changes to specific objects and ensure that the current Prometheus deployments match these objects. The Operator acts on the following Custom Resource Definitions (CRDs):</p><ul><li><strong>Prometheus</strong>, which defines a desired Prometheus deployment.</li><li><strong>Alertmanager</strong>, which defines a desired Alertmanager deployment.</li><li><strong>ServiceMonitor</strong>, which declaratively specifies how groups of Kubernetes services should be monitored. The Operator automatically generates Prometheus scrape configuration based on the current state of the objects in the API server.</li><li><strong>PodMonitor</strong>, which declaratively specifies how a group of pods should be monitored. The Operator automatically generates Prometheus scrape configuration based on the current state of the objects in the API server.</li><li><strong>PrometheusRule</strong>, which defines a desired set of Prometheus alerting and/or recording rules. The Operator generates a rule file, which can be used by Prometheus instances.</li></ul><p>The Prometheus Operator automatically detects changes in the Kubernetes API server to any of the above objects, and ensures that matching deployments and configurations are kept in sync.</p><h2 id="need-more">Need more?</h2><p>If you would like to hear more about how to extend Kubernetes, take a look at this talk from one of my Container Solutions colleagues, Adam Otto, from <a href="https://cloudnativewarsaw.com/">Cloud Native Warsaw Conference</a>.</p><p><iframe width="560" height="315" src="https://www.youtube.com/embed/8QoCL1NCVv4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><hr><p>The article has been originally published on the <a href="https://blog.container-solutions.com/kubernetes-operators-explained">Container Solutions</a> blog.</p></div></div>]]>
            </description>
            <link>https://pperzyna.com/blog/kubernetes-operators-explained/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23712344</guid>
            <pubDate>Thu, 02 Jul 2020 12:22:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RCE on Telia Routers]]>
            </title>
            <description>
<![CDATA[
Score 191 | Comments 48 (<a href="https://news.ycombinator.com/item?id=23712143">thread link</a>) | @theshrike79
<br/>
July 2, 2020 | https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-backdoor.html | <a href="https://web.archive.org/web/*/https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-backdoor.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>Multiple vulnerabilities could allow running arbitrary code on an intranet server and gain root access on all the customers' routers</p>

<p>Telia is a Swedish multinational telecommunications company. It also operates in Lithuania and provides mobile service, FTTH internet, DSL internet and IPTV. Telia rents and sells custom routers and set-top tv boxes to customers which have limited or almost no administration access left to them.</p>

<p>Every Telia router or tv box has a backdoor or "management interface". It is an <code>SSH</code> server running on VLAN 5 and/or WAN. Usually, it is running on port <code>8022</code>. Older models, like <code>ADB</code>, have password login enabled. The recent newer models, like <code>Technicolor</code>, have password login disabled and only use ssh with public key authentication (spoiler: it is still vulnerable).</p>

<p>Savitarna (in Lithuanian "Self service") - is a web service <a href="https://www.telia.lt/mano/sso">https://www.telia.lt/mano/sso</a> that allows Telia customers to order and manage services, get invoices, pay bills etc. It uses password authentication or external authority logins such as Facebook, Google, banking, digital signature etc. One of the new features: changing your router's wifi password. Sounds interesting, right? An internet web service that is able to change your local router's wifi password.</p>
<p>Login page:</p>
<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-web-login.jpg" alt="Telia Savitarna web login page"></p>
<p>Change wifi settings:</p>
<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-web-wifi-settings.jpg" alt="Telia Savitarna WiFi setting change feature"></p>

<p>How that works. When a user wants to change the password, the web service calls the backend to initiate an SSH connection to the user's associated router. Depending on the router it will be either password authentication or RSA public key. After a successful login a PHP script on the backend will issue some commands in the router's shell, parse the result and output some of the data to the user in the web UI, like wireless network name. <strong>Telia knows your WIFI password in plain text</strong>, keep it in mind and do not reuse this password anywhere. Overall scheme:</p>
<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-backdoor-scheme.jpg" alt="Overall scheme of Telia backdoor"></p>

<p>Let's take a look at how the SSH connection is established. Network capture shows an SSH client banner and the remote IP that initiated the connection:</p>
<p><code>SSH-2.0-libssh2_1.4.2 PHP 10.0.98.251</code></p>
<p>What is important here:</p>
<ul>
<li>Vulnerable <code>libssh2</code> version <code>1.4.2</code> <a href="https://www.libssh2.org/security.html">https://www.libssh2.org/security.html</a></li>
<li>Weak and deprecated key exchange <code>diffie-hellman-group1-sha1</code></li>
<li>The client does not verify <code>remote SSH server public key</code> (see below)</li>
<li><code>PHP</code></li>
</ul>
<p>And, yes, it turns out that Telia's client does not attempt to verify the remote server's public key. We were able to start a custom SSH server on the same port 8022 and Savitarna successfully established a connection without even trying to verify for a man-in-the-middle. This means that we can see the password used and could try to create a malicious SSH server that exploits public vulnerabilities on Telia's side.</p>

<p>That was an easy task. As soon as Telia's client connected to our malicious SSH server we got the universal router credentials:</p>
<pre>User: tadmin
Password: hqMV8Wps
</pre>

<p>Do you still own an ADB router? Just go ahead and login over the web interface with this user. You are now an admin. You can do some restricted stuff now, great! But what about the root shell? We were able to connect with those credentials locally and got a limited shell. That's nice too. This gave us a lot of additional information that was hidden inside the router, many more vulnerabilities. Using one of them we were able to escalate to root and got full access over the device. The newer models like Technicolor require some additional exploits chained to gain full root access, but all are publicly available and so - easily doable.</p>

<p>In order to exploit RCE we needed to build a virtual test environment that fully copies Telia's PHP client. Step by step we have gone through the sequence of Telia's commands sent over the SSH. And finally we got a malicious SSH server and a test libssh2 client running in our test lab. With this server we could fully control the protocol and start fuzzing.</p>
<p>In the first few days of the fuzzing we got some crashes and partially confirmed that RCE may be exploited. Here is a sample GIF video that demonstrates two kinds of the issues the fuzzer found for us. Same php file was executed twice, but the malicious SSH server sent different payloads which caused:</p>
<ul>
<li>Segfault (stack corruption)</li>
<li>Infinite loop with high CPU</li>
</ul>
<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-poc.gif" alt="GIF PoC video"></p>
<p>However, at the time of the report we couldn't find an easy way to exploit the stack corruption. It may require more time, longer and more sophisticated fuzzing and more knowledge about the server. As Lithuanian law prohibits exploit testing on the real server, we could only fingerprint the Windows OS, but nothing more.</p>

<p>The backend seems to run only 5 php processes, so it is fairly easy to perform DoS by keeping stalled ssh connections. When SSH connections stay active for too long filling all the 5 php processes (there seems to be no timeout reading the remote shell), the Savitarna will show a strange "Maintenance" message:</p>
<p>Translation:</p>
<pre>An update is in progress
Too many of you are trying to access the new Telia webpage.
We are expanding the resources and will accept you all soon.
Apologies for any inconvenience
</pre>

<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-web-DoS.jpg" alt="Service unavailbale"></p>

<p>If we now get all together, an attacker could exploit RCE on the intranet server and use that server to move laterally (because <code>10.0.98.251</code> is whitelisted everywhere) across all the customer routers with the same credentials creating the most powerful, persistent and undetectable botnet of Lithuania. Who knows, maybe someone already exploited that? (spoiler: see bonus section)</p>

<p>The report was responsibly disclosed to Telia and a copy sent to <code>CERT LT</code> (<a href="https://www.nksc.lt/">NKSC</a>). What happened next was a little bit of a surprise to the team. There were rumours previously about Telia's poor tech level, but we have experienced this in a real case.</p>
<p>First, Telia did not have a PGP key and did not know how to use it, so instead they asked us to ZIP the report with password and send the password over a separate email (private GMail). I hope Telia's engineers will be reading this article, so I would like to explain why the report should be encrypted. This is to protect you as the affected vendor. If there is a man in the middle who can intercept all the researcher's traffic, it will be very easy to get the ZIP file in the first email and then the password in the second email. Instead, PKI like PGP only allows to decrypt the report by the private key owner, ensuring that nobody else can intercept the report and exploit the vulnerabilities before you fix them all. </p>
<p>Second, Telia tried to threaten the reporter for the vulnerability discovery:</p>
<p>Translation:</p>
<pre>Thank you for the information
Are you sure you did not violate the electronic data protection law?
</pre>

<p>Original:</p>
<pre>Dƒókojame u≈æ informacijƒÖ.
Ar tikrai tyrimƒÖ atlikote ir nevie≈°us elektroninius duomenis rinkote
nepa≈æeid≈æiant galiojanƒçi≈≥ ƒØstatym≈≥?
</pre>

<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-csirt-response-1.jpg" alt="Telia CSIRT email response"></p>
<p>And then they once again mentioned that they will check if this report wasn't a hacking attempt and that they will persecute any reporter that discloses any information about Telia vulnerabilities:</p>
<p>Translation:</p>
<pre>Thank you for the information. We will continue to check whether you made your report
legally without violating any law. And we will ensure that no fake information will be
published that could do any harm to the company's reputation and to the critical part
of Lithuanian network infrastructure.
</pre>

<p>Original:</p>
<pre>Dƒókojame Jums u≈æ pasidalintƒÖ informacijƒÖ, kurios surinkimo teisƒótumo vertinimƒÖ toliau
atliekame ir tikimƒós, kad ƒØ vie≈°umƒÖ nebus paskleista tikrovƒós neatitinkanti ar neteisƒótai
gauta informacija, kuri daryt≈≥ ≈æalƒÖ bendrovƒós reputacijai ir tuo paƒçiu sƒót≈≥ nepasitikƒójimƒÖ
kritine Lietuvos ry≈°i≈≥ infrastrukt≈´ros dalimi.
</pre>

<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-csirt-response-2.jpg" alt="Telia CSIRT email confirmation"></p>
<p>We will not comment on this and let the IT community to judge. At the same time we will no longer provide any reports in any form to Telia company.</p>
<table>
<thead>
<tr>
<th>Vulnerability</th>
<th>Fixed?</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vulnerable libssh2</td>
<td>NO!</td>
<td><a href="https://www.libssh2.org/security.html">SSH-2.0-libssh2_1.8.0 PHP</a></td>
</tr>
<tr>
<td>Weak KEX</td>
<td>partially*</td>
<td>diffie-hellman-group-exchange-sha256</td>
</tr>
<tr>
<td>MITM</td>
<td>NO!</td>
<td>still no pub key check</td>
</tr>
<tr>
<td>Password leaked</td>
<td>NO!</td>
<td>password has not been rotated</td>
</tr>
</tbody>
</table>
<p>* Note: partial fix for KEX means the new KEX is not considered to be weak, however it is now possible to exploit libssh2 vulnerabilities after 1.8.0 with this particular KEX and a publicly known exploit for <a href="https://github.com/Semmle/SecurityExploits/blob/446048470633bf0f8da9570d008d056dbaa28ea9/libssh2/out_of_bounds_read_kex_CVE-2019-13115/server/home/diff.txt">KexAlgorithms diffie-hellman-group-exchange-sha256</a></p>

<p>After getting the root access and analyzing the Telia's routers' firmwares, we found several more users, like <code>ladmin</code> and <code>technician</code>. We will not disclose those passwords (yet), as it is not clear yet how both are used. But we were surprised that Telia's passwords appeared to be leaked many years ago. You can try to search for the tadmin password's hash on the web and you will be surprised - there was an attempt to crack the hash back in 2014!</p>
<pre>echo -n hqMV8Wps | md5sum
ff19d662d7127446d83c935e74430921  -
</pre>

<p><img src="https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-backdoor-leaked-password-2014.jpg" alt="Screenshot of a leaked Telia admin password MD5"></p>
<p><a href="https://webcache.googleusercontent.com/search?q=cache:J9ef6qUfrCcJ:www.md5this.com/list.php%3Fpage%3D108462%26key%3D1%26author%3DToXiC%26country%3DCyprus%26city%3DNicosia+">Webcache</a></p>
<p>And finally, we found that the hash was cracked and was available in the old "weakpass" database. You can search for the "old" weakpass database (sometimes named "First version of weakpass") and grep it - password is there. This means that most probably we are not the first who were able to penetrate Telia.</p>

<pre>2019-10-22 - tried to get in touch with Telia and asked for PGP key
2019-10-23 - password protected ZIP sent to Telia as they asked
2019-10-24 - Telia confirmed that report had been received
2019-11-21 - disclosure reminder sent to Telia
2019-11-23 - Telia tried to threaten the reporter
2019-11-27 - Telia confirmed that everything was safe, vulnerabilities were "always fixed"
2020-06-29 - full disclosure
</pre>

    </article></div>]]>
            </description>
            <link>https://full-disclosure.eu/reports/2019/FDEU-CVE-2019-10222-telia-savitarna-backdoor.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23712143</guid>
            <pubDate>Thu, 02 Jul 2020 11:50:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Writing a VM for a Small Stack-Base Language in Pointless]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23712035">thread link</a>) | @caditinpiscinam
<br/>
July 2, 2020 | https://ptls.dev/tutorials/factorsVM.html | <a href="https://web.archive.org/web/*/https://ptls.dev/tutorials/factorsVM.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <h3>Tutorial: Writing a VM for a Small Stack-Base Language in Pointless</h3>
      <pre>- Avery N. Nortonsmith</pre>

      <hr>

      <p>
        The age of functional programming will soon be over.
      </p>

      <p>
        Object-oriented programming has come and gone. Functional programming -- the wise, quiet observer -- has waited patiently for its turn. But FP, like OOP, will fade away in time as software yields to the inexorable pull of the one <em>True Paradigm</em>: stack-based programming!
      </p>

      <hr>

      <p>
        Joking aside, stack-based programming <em>is</em> pretty cool.
      </p>

      <p>
        This tutorial covers the implementation of a <strong>virtual-machine</strong> for a small, <strong>stack-based</strong> language in Pointless. We'll take an <strong>incremental</strong> approach to building the VM and improving its capabilities until it can run a short <strong>prime-factorization</strong> program.
      </p>

      This project seeks to demonstrate:

      <ul>
        <li>
          How an imperative language can be implemented in a purely functional context
        </li>

        <li>
          How to structure and refactor code that uses persistent data-structures
        </li>

        <li>
          How Pointless can -- even as a young language -- be used to solve non-trivial tasks
        </li>
      </ul>

      <p>
        Before we tackle prime-factorization, let's take a look at a small example of the stack-based code that our VM will evaluate. The following Pointless code defines a <a href="https://ptls.dev/docs.html#lists">list</a> of 'instructions', where <a href="https://ptls.dev/docs.html#tuples">labeled-tuples</a> are used to represent instructions with an argument, and <a href="https://ptls.dev/docs.html#labels">labels</a> are used for those without. A list of instructions like this represents a program in our stack-based language:
      </p>

      <div>
        <pre>program = [
  Const(7),
  Const(2),
  Mod,
  Const(0),
  Eq,
  Print,
  Exit,
]
</pre>
      </div>

      <p>
        Let's take a minute to fancy things up by writing a function to pretty-print these instruction lists -- this will come in handy later when we work with more complex programs. The function <code>showInst</code> below takes an instruction and returns a string showing the instruction's type (left-justified to 5 characters) and argument. The function <code>argOrBlank</code> returns an instruction's argument if there is one, or an empty string otherwise. 
      </p>

      <div>
        <pre>showInst(inst) =
 format("[ {&lt;5} ] {}", [getLabel(inst), argOrBlank(inst)])

argOrBlank(inst) =
  if is(PtlsTuple, inst) then unwrap(inst) else ""
</pre>
      </div>

      <p>
        In the code above, <code><a href="https://ptls.dev/api/prelude/format.html#format">format</a></code>, <code><a href="https://ptls.dev/api/prelude/label.html#getLabel">getLabel</a></code>, <code><a href="https://ptls.dev/api/prelude/types.html#is">is</a></code>, and <code><a href="https://ptls.dev/api/prelude/label.html#unwrap">unwrap</a></code> are defined in the Pointless <a href="https://ptls.dev/api/index.html">prelude</a> (standard-library).
      </p>

      <p>
        To see our new functions in action, we'll define an output variable for our program; in Pointless, a program's output is defined by its output variable. The prelude contains functions like <code><a href="https://ptls.dev/api/prelude/io.html#printLines">printLines</a></code> which generate sequences of IO commands that can be assigned to a program's output variable.
      </p>

      <p>
        The output definition below takes our list of instructions, generates a new list of instruction-strings by calling <code>showInst</code> on each instruction, and produces IO commands to print each string on a separate line. Take a look at the docs for more info on the function <a href="https://ptls.dev/docs.html#pipeOperator">pipe operator</a> <code>|&gt;</code>, and for <a href="https://ptls.dev/docs.html#partialApplication">partial application</a>.
      </p>

      <p><em>
        Note that the name 'main.ptls' is chosen arbitrarily; it doesn't have any special meaning
      </em></p>

      <div>
        <pre>output =
  program
  |&gt; map(showInst)
  |&gt; printLines
</pre>

      <pre>$ ./bin/pointless main.ptls

[ Const ] 7
[ Const ] 2
[ Mod   ] 
[ Const ] 0
[ Eq    ] 
[ Print ] 
[ Exit  ]
</pre>
      </div>

      <p>Seeing is believing. Time to start making our VM.</p>

      <p>
        We'll represent the VM as an <a href="https://ptls.dev/docs.html#objects">object</a> with the following fields:
      </p>

      <ul>
        <li><code>slots</code>: used to store "heap" variables (discussed later on)</li>
        <li><code>insts</code>: an array containing the program's instructions</li>
        <li><code>index</code>: the position in instruction array of the current instruction</li>
        <li><code>stack</code>: a linked-list serving as the stack for the VM</li>
        <li><code>outVal</code>: used to get output from VM as program runs</li>
      </ul>

      <p>
        The function <code>vmFromInsts</code> sets up a new VM object for a given list of instructions. The code also adds the label <code>VM</code> to the VM object (objects and tuples can be labeled in Pointless). Object labels can be used to write code that tells different types of objects apart, or simply for documentation (as we do here).
      </p>

      <div>
        <pre>vmFromInsts(program) = VM {
  slots  = zeroArray(8)
  insts  = toArray(program)
  index  = 0
  stack  = []
  outVal = None
}
</pre>
      </div>

      <p>
        To check that <code>vmFromInsts</code> works, we'll modify our output definition to create and print a new VM object. Note that we've replaced <code>printLines</code> with <code><a href="https://ptls.dev/api/prelude/io.html#println">println</a></code> -- <code>printLines</code> expects a sequence of values (and can print these values on-the-fly as they're computed in the case of lists!), whereas <code>println</code> can handle sequence and non-sequences types.
      </p>

      <div>
        <pre>output =
  program
  |&gt; vmFromInsts
  |&gt; println
</pre>

      <pre>$ ./bin/pointless main.ptls

VM {stack = []; insts = [Const(7) Const(2) Mod Const(0) Eq Print Exit]; slots = [0 0 0 0 0 0 0 0]; index = 0; outVal = None}
</pre>
      </div>

      <p>
        We run the program, and see that <code>println</code> gives us a nice visualization of our initial VM object, fields and all.
      </p>

      <p>
        Back to our list of instructions:
      </p>

      <div>
        <pre>program = [
  Const(7),
  Const(2),
  Mod,
  Const(0),
  Eq,
  Print,
  Exit,
]
</pre>
      </div>

      <p>
        The instructions above do the following -- (once we've implemented them, that is):
      </p>

      <ul>
        <li><code>Const(arg)</code> pushes <code>arg</code> onto the VM stack</li>
        <li><code>Mod</code> pops values <code>v0</code> and <code>v1</code> from the stack, and pushes <code>v1 % v0</code></li>
        <li><code>Eq</code> pops values <code>v0</code> and <code>v1</code> from the stack, and pushes <code>v1 == v0</code></li>
        <li><code>Print</code> pops a value from the stack and prints it</li>
        <li><code>Exit</code> signals the end of the program</li>
      </ul>

      <p>
        Additionally, each of these instructions will advance the VM to the next instruction after performing the behaviors above. Nice and imperative ;)
      </p>

      <p>
        With this in mind, we see that the program above does the following: loads the values <code>7</code> and <code>2</code> onto the stack, computes <code>7 % 2</code>, loads the value <code>0</code>, compares <code>0</code> with the result of <code>7 % 2</code>, prints the result of this comparison, and exits. In other words, this program tells us whether or not <code>7</code> is even.
      </p>

      <p>
        Now that we've defined some instructions, let's start evaluating them.
      </p>

      <div>
        <pre>eval(vm) = cond {
  case is(Const, vm.insts[vm.index])
    vm with $.stack = [unwrap(vm.insts[vm.index])] ++ vm.stack
}
</pre>
      </div>

      <p>
        Our <code>eval</code> function uses a <code><a href="https://ptls.dev/docs.html#cond">cond</a></code> conditional -- eventually this will include cases for all instructions, but we'll start with just <code>Const</code> for now. The code above calls the function <code><a href="https://ptls.dev/api/prelude/types.html#is">is</a></code> to check whether the current instruction has the label <code>Const</code> (where the current instruction is the instruction in the <code>vm.insts</code> array at index <code>vm.index</code>). If <code>is</code> returns true, then conditional evaluates and returns the body of the case expression.
      </p>

      <p>
        Structures in Pointless persistent, and thus immutable. As such, our program will never mutate the state of a VM object; rather, it will produce new VM objects. The code above uses <a href="https://ptls.dev/docs.html#viaWith">with syntax</a> (which can handle both shallow and nested updates -- one of Pointless's little innovations) to create a new VM object with a new stack value: the old stack with the instruction argument pushed to the top. The <code>unwrap</code> function is used to get the argument from the <code>Const</code> instruction.
      </p>

      <p>
        The code above is dense and repetitive! We can improve it by defining a couple of variables. In the new version, <code>inst</code> is the current instruction, and the <code>arg</code> is the argument of that instruction.
      </p>

      <div>
        <pre>eval(vm) = cond {
  case is(Const, inst)
    vm with $.stack = [arg] ++ vm.stack

} where {
  inst = vm.insts[vm.index]
  arg = unwrap(inst)
}
</pre>
      </div>

      <p>
        We modify the program's output definition to call <code>eval</code> on the VM to evaluate the first instruction, <code>Const(7)</code>. Looking at output, we see that the value <code>7</code> has been pushed to the stack.
      </p>

      <p><em>
        <code>insts</code> field abbreviated for readability
      </em></p>

      <div>
        <pre>output =
  program
  |&gt; vmFromInsts
  |&gt; eval
  |&gt; println
</pre>

      <pre>$ ./bin/pointless main.ptls

VM {stack = [7]; insts = ...; slots = [0 0 0 0 0 0 0 0]; index = 0; outVal = None}
</pre>
      </div>

      <p>
        But wait! We need our <code>Const</code> handler to do one more thing -- advance the VM to the next instruction. To do this, we'll make a new helper function <code>advance</code> that takes a VM object and returns a new VM object with the instruction index incremented. We'll also move the code for pushing a value onto the VM stack into the new function <code>pushVal</code>.
      </p>

      <div>
        <pre>advance(vm) = vm with $.index += 1

pushVal(arg, vm) = vm with $.stack = [arg] ++ vm.stack
</pre>
      </div>

      <p>
        Using these two new functions, the code for <code>eval</code> becomes:
      </p>

      <div>
        <pre>eval(vm) = cond {
  case is(Const, inst)
    vm
    |&gt; pushVal(arg)
    |&gt; advance

} where {
  inst = vm.insts[vm.index]
  arg = unwrap(inst)
}
</pre>

      <pre>$ ./bin/pointless main.ptls

VM {stack = [7]; insts = ...; slots = [0 0 0 0 0 0 0 0]; index = 1; outVal = None}
</pre>
      </div>

      <p>
        We call the program again and get the result seen above: the new VM object returned by <code>eval</code> has the value <code>7</code> on its stack and its index incremented.
      </p>

      <p>
        At this point, the entire program looks something like this:
      </p>

      <p><em>
        Note that the comment bars are not necessary, but are helpful for dividing code visually -- it's a habit of mine, like using fake em-dashes. They can also be used to mark API documentation
      </em></p>

      <div>
        <pre>output =
  program
  |&gt; vmFromInsts
  |&gt; eval
  |&gt; println

------------------------------------------------------------------------------

program = [
  Const(7),
  Const(2),
  Mod,
  Const(0),
  Eq,
  Print,
  Exit,
]

------------------------------------------------------------------------------

showInst(inst) =
 format("[ {&lt;5} ] {}", [getLabel(inst), argOrBlank(inst)])

argOrBlank(inst) =
  if is(PtlsTuple, inst) then unwrap(inst) else ""

------------------------------------------------------------------------------

vmFromInsts(program) = VM {
  slots  = ‚Ä¶</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ptls.dev/tutorials/factorsVM.html">https://ptls.dev/tutorials/factorsVM.html</a></em></p>]]>
            </description>
            <link>https://ptls.dev/tutorials/factorsVM.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23712035</guid>
            <pubDate>Thu, 02 Jul 2020 11:24:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git Good ‚Äì The Ultimate Beginner Reference with Diagrams and Code GIFs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23712034">thread link</a>) | @mrathi12
<br/>
July 2, 2020 | https://mukulrathi.co.uk/git-beginner-cheatsheet/ | <a href="https://web.archive.org/web/*/https://mukulrathi.co.uk/git-beginner-cheatsheet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><h3>January 27, 2019</h3><h3>16 min read</h3></p><h3>Last updated: October 16, 2019</h3><hr><h2 id="what-is-git-and-why-should-i-care"><a href="#what-is-git-and-why-should-i-care" aria-label="what is git and why should i care permalink"></a>What is Git and why should I care?</h2><p>Git is a <strong>distributed version-control system</strong> - i.e. it records the changes made to files in a repository of code as a series of snapshots called <strong><em>commits</em></strong>, stored on many servers. Think of this like your standard cloud backup on steroids - not only are you able to restore your code in event of a crash, but you can also <strong>roll back</strong> your code to any of the snapshots if your code breaks. It is also easy for you to <strong>collaborate</strong> with others - again just like how you can work on the same Google Docs file with multiple people, multiple developers can simultaneously edit the same repository and record their individual changes.</p><p>Thanks to these advantages, Git is a <strong>must-know</strong> for anyone looking to enter the world of software development. This post will provide an overview of the most useful commands in Git and when to use them, and also serves as a reference for when you need to brush up on Git.</p><h2 id="the-git-workflow"><a href="#the-git-workflow" aria-label="the git workflow permalink"></a>The Git Workflow</h2><p>There are a lot of Git commands, so it‚Äôs useful to group them by topic / use-case. We‚Äôll first consider Git on a single machine, since most of Git‚Äôs operations are local and we can then build up to multi-user Git usage.</p><p>Git can either be run using the command line, or using a GUI such as GitHub Desktop. Although the command line may be more intimidating for new developers, it also is far more powerful and you will need to learn it since most GUIs offer limited commands.</p><p>Git commands typically take the form of <code>git &lt;command&gt; &lt;args&gt;</code> where <code>&lt;args&gt;</code> might be a file path. Commands may also have <em>options</em> specified denoted by a <code>--&lt;option&gt;</code> or a <code>-&lt;single-letter-option&gt;</code> - think of these as adding extra details as to what the command should do. In this guide, I will present the general syntax and you should replace anything in <code>&lt;&gt;</code> with your corresponding value.</p><p>If you are uncertain about the usage of a command, a really useful command is:
<code>git help &lt;command&gt;</code>
which brings up the manual, or for a refresher <code>git &lt;command&gt; -h</code> or <code>git &lt;command&gt; --help</code> (<code>--help</code> and <code>-h</code> are equivalent).</p><h2 id="setting-up-git"><a href="#setting-up-git" aria-label="setting up git permalink"></a>Setting up Git</h2><h3 id="installing-git"><a href="#installing-git" aria-label="installing git permalink"></a>Installing Git</h3><p><strong>Windows</strong>: Head to <a href="https://git-scm.com/download/win">https://git-scm.com/download/win</a></p><p><strong>MacOS</strong>: Git comes as part of XCode Command Line Tools, so install that. To check if you‚Äôve installed Git already open a Terminal window and type <code>git --version</code> to check which version you have.</p><p><strong>Linux</strong>: Run <code>sudo apt install git-all</code> (Debian-based) in the terminal or <code>sudo dnf install git-all</code> (RPM-based).</p><h3 id="set-up-configuration-file"><a href="#set-up-configuration-file" aria-label="set up configuration file permalink"></a>Set up Configuration File</h3><p>The first thing to do having installed Git is to set up your user name and email address, since these are used to identify you and stored in all snapshots you make. This is stored in a <strong>configuration file</strong> where you store all your preferences.</p><p>You can either edit this <code>.gitconfig</code> file directly using a text editor or <code>git config --global --edit</code> or instead alter specific fields with <code>git config --global &lt;field&gt; &lt;value&gt;</code> - we‚Äôre interested in the fields <code>user.name</code> and <code>user.email</code>.</p><p>We can also configure the text editor we use for commits using the field <code>core.editor</code> - initially this is set to the system default editor (e.g vi for Linux/Mac). <code>commit.template &lt;template_file&gt;</code> lets you specify a template that comes up whenever you commit.</p><p>There are many other fields, however one particular field I find especially useful is <code>alias</code> which maps commands to abbreviations: <code>alias.&lt;ab&gt; &lt;command&gt;</code>.
e.g. <code>git config --global alias.st "status -s"</code> maps <code>git status -s</code> to <code>git st</code>.</p><p><code>git config --list</code> lists all the fields and values from the config file.</p><h3 id="create-a-git-repository"><a href="#create-a-git-repository" aria-label="create a git repository permalink"></a>Create a Git repository</h3><p>To initialise a .git repository you can use <code>git init</code> or, if you want a copy of an existing repository, you can do <code>git clone &lt;repo_url&gt;</code>.</p><p><img src="https://mukulrathi.co.uk/317c63680d60850c4b4035e791ecd896/setup.svg" alt="Setup Terminal"></p><h2 id="git-commit-history"><a href="#git-commit-history" aria-label="git commit history permalink"></a>Git Commit History</h2><p><img src="https://mukulrathi.co.uk/f66fde04be4a0bf374458ed35fff4e77/commit-history.svg" alt="Git Commit History Diagram"></p><p>Git stores data as a series of lightweight ‚Äúsnapshots‚Äù known as <strong>commits</strong> - these store the state of the filesystem at that time as well as a pointer to the previous commit(s). Each commit has a unique <em>checksum</em> - the ID Git uses to refer to it.
To keep track of the history, Git has a <strong>HEAD</strong> pointer that points to the first commit (we follow the pointer chain back to see previous commits).</p><p>So we can refer to a commit either by its checksum, or its relation to HEAD, e.g. <code>HEAD~4</code> refers to the commit 4 commits before the HEAD commit.</p><h2 id="the-git-file-system"><a href="#the-git-file-system" aria-label="the git file system permalink"></a>The Git File System</h2><p><img src="https://mukulrathi.co.uk/4b6c8479c4391d055b65a8d2a2598187/file-system.svg" alt="Git File System  Diagram"></p><p>Git keeps track of files in 3 main sections:</p><ul><li>Working Directory (this is your computer‚Äôs filesystem)</li><li>Staging Area (this stores the contents of your next commit)</li><li>HEAD (the most recent commit in the .git repository)</li></ul><p>All of the main file commands boil down to understanding how Git maintains these three sections. A common misconception is that the staging area only stores changes - a better way to think of these is as <strong>3 separate file systems</strong>, each with their own copies of the files.</p><h3 id="view-changes-in-the-git-file-systems"><a href="#view-changes-in-the-git-file-systems" aria-label="view changes in the git file systems permalink"></a>View changes in the Git File Systems</h3><p><code>git status</code> displays any files that differ between the 3 sections. Files have 4 states:</p><ul><li><em>Untracked</em> - in Working Dir but no version stored in HEAD or Staging Area (Git doesn‚Äôt know about file)</li><li><em>Modified</em> - newer version in Working Dir compared to Staging Area and HEAD. (changes not in next commit)</li><li><em>Staged</em> - newer version in Staging Area and Working Dir compared to HEAD. (ready to be committed)</li><li><em>Unmodified</em> - same version in all 3 sections (i.e. most recent commit has latest version)</li></ul><p>Note: a file can be both modified and staged, if the version in the working directory is newer than that in the staging area, which in turn is newer than the one in the HEAD commit.</p><p>We can use the <code>-s</code> option for <code>git status</code> to get a cleaner (one line per file) output. This displays <strong>??</strong> if a file is not tracked, <strong>red</strong> if modified and <strong>green</strong> if staged.</p><p>To view the actual changes and not just the files that have changed, you can use:</p><ul><li><code>git diff</code> - see the unstaged changes i.e. compare working directory with staging area.</li><li><code>git diff --staged</code> - see the staged changes i.e. compare staging area with HEAD.</li></ul><p>Adding the <code>&lt;file/dir&gt;</code> argument restricts the diff to that those files. e.g. <code>git diff src/</code></p><h3 id="update-the-git-file-systems"><a href="#update-the-git-file-systems" aria-label="update the git file systems permalink"></a>Update the Git File Systems</h3><p><code>git add &lt;file/directory&gt;</code> updates the staging area with the version of the file/directory in the working directory.</p><p><code>git commit</code> updates HEAD with a new commit that snapshots the files in the staging area.</p><p><code>git reset &lt;commit&gt;</code> has three potential steps:</p><ol><li>Point HEAD to <code>&lt;commit&gt;</code> (e.g. if rolling back a commit,staging area and working dir will now have newer version of files than HEAD). Also points branch‚Äôs HEAD to that commit. (see Branching section)</li><li>Update Staging Area with contents of <code>&lt;commit&gt;</code>. (this has the effect of unstaging file changes - only Working dir. has newest version)</li><li>Update Working Dir with contents of Staging Area (has effect of overwriting and destroying changes to data - <strong>dangerous - take care</strong>)</li></ol><p>By default, <code>git reset</code> only runs Step 1 + 2 however, the options <code>--soft</code> (only run Step 1) and <code>--hard</code> (run Step 1, 2, 3) modify its behaviour.</p><p>If we pass a file path, <code>git reset &lt;commit&gt; &lt;file/dir&gt;</code> it limits effect of <code>reset</code> to files in that file path e.g. <code>git reset --soft HEAD~1 src/</code>.</p><p><code>git checkout HEAD &lt;file&gt;</code> also has the same effect as <code>git reset --hard HEAD &lt;file&gt;</code> - it overwrites the version of the file in the staging area and working directory with the version at HEAD (effectively undoing your changes since the last commit).</p><p><code>git checkout &lt;file&gt;</code> on the other hand (note no <code>HEAD</code>) overwrites the version of the file in the working directory with the version in the staging area (effectively undoing your changes since the last staged version).</p><p>Finally, <code>git rm &lt;file&gt;</code> untracks the file and deletes it from working directory, the option <code>--cached</code> will untrack a file but not delete it from the working directory.</p><p><img src="https://mukulrathi.co.uk/3a5894bb13482084888f9dbffc12737c/manipulate-files.svg" alt="Git status demonstration"></p><h3 id="ignoring-files"><a href="#ignoring-files" aria-label="ignoring files permalink"></a>Ignoring files</h3><p>Often we don‚Äôt want Git to track all of our files in our repository. This might include:</p><ul><li>sensitive files (e.g. passwords.txt)</li><li>huge binary files</li><li>build files that get generated every time you recompile your source code.</li><li>OS/IDE specific files, e.g. <code>.DS_Store</code> for MacOS or <code>.iml</code>for IntelliJ IDE - you want your repo to be as system agnostic as possible.</li></ul><p>We can specify <strong>glob patterns</strong> (think simplified regular expressions) to <strong>match</strong> files that we want to ignore in our <code>.gitignore</code> file.</p><ul><li><code>/___</code> avoids recursivity - only matches it to current directory</li><li><code>__/</code> matches all files in that directory</li><li><code>*___</code> matches all files with that ending</li><li><code>!</code> negates a pattern - i.e. don‚Äôt match this</li><li><code>[__]</code> matches a character to any of the characters in the square brackets.</li><li><code>?</code> matches any character</li><li><code>/**/</code> matches nested directories e.g. <code>a/**/d</code> matches <code>a/d</code> <code>a/b/d</code> <code>a/b/c/d</code> etc.</li></ul><p><a href="https://github.com/github/gitignore">Examples of .gitignore files</a></p><p>You can even use <strong>glob patterns</strong> when using <code>&lt;file/dir&gt;</code> in the other Git commands e.g. <code>git add src/*.css</code> would add all <code>.css</code> files in the <code>src</code> folder.</p><h2 id="commits"><a href="#commits" aria-label="commits permalink"></a>Commits</h2><p>Since commits are the backbone of your version history, it is worth going into them in more depth.</p><p><code>git commit</code> opens up your text editor for you to write a commit message in. The <code>commit</code> command also can takea few common arguments</p><ul><li><code>-m</code> Write the message inline e.g. <code>git commit -m "Fix a bug"</code></li><li><code>-a</code> This stages all modified (tracked) files and includes them in the commit (avoiding a <code>git add</code> before you commit)</li><li><code>--amend</code> replaces the last commit with a <em>new</em> amended commit- useful if you mistyped the most recent commit, or subsequently staged files that you wanted to add to the last commit - just run <code>git commit --amend</code>.</li></ul><p>Good practices to adhere to:</p><ul><li><strong>Commit often:</strong> you can‚Äôt roll back a change unless the original state was committed.</li><li><strong>One commit for one change:</strong> don‚Äôt bundle up all your unrelated changes in one commit, commit them separately as it makes it easier to roll back changes.</li><li><strong>Message format</strong>: The title should be in the imperative and less than 50 characters long, if in doubt your message should complete the phrase <code>this commit will _____</code>. The message should explain WHY the commit is made - the commit itself shows WHAT changed. <a href="https://chris.beams.io/posts/git-commit/">This post</a> has all the details of a good commit message.</li><li><strong><em>(Optional)</em> Don‚Äôt commit extremely minor changes:</strong> in a large repository, lots of tiny commits can clog up the history - a good tip is to make minor commits when developing and then <em>squash</em> (see section on squashing) these into one major commit when contributing to ‚Ä¶</li></ul></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mukulrathi.co.uk/git-beginner-cheatsheet/">https://mukulrathi.co.uk/git-beginner-cheatsheet/</a></em></p>]]>
            </description>
            <link>https://mukulrathi.co.uk/git-beginner-cheatsheet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23712034</guid>
            <pubDate>Thu, 02 Jul 2020 11:24:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Startup Investors Look for in Entrepreneurs and Their Teams]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23712018">thread link</a>) | @Rui_Lou
<br/>
July 2, 2020 | https://altar.io/what-startup-investors-look-for-in-entrepreneurs-and-their-teams/ | <a href="https://web.archive.org/web/*/https://altar.io/what-startup-investors-look-for-in-entrepreneurs-and-their-teams/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>
<p><span>When building your startup you can have a great idea and the perfect market conditions and still come up short. For both your startup and investors, execution is key.</span></p>
<p><span>Just look at this slide I found from Alexander Jarvis on Quora:</span></p>
<figure><img src="https://cdn-images-1.medium.com/max/720/0*4ssSy22XC1crcL3k" alt="Mark Suster on what startup investors look for in entrepreneurs: 70% of my investment decision of an early-stage company is the team" width="720" height="432" data-image-id="0*4ssSy22XC1crcL3k" data-width="1085" data-height="651"></figure>
<p><span>You and your startup team, especially at a management level, are a huge factor as to whether you secure investment or if your pitch ends up in an investor‚Äôs trash can.&nbsp;</span></p>
<p><span>And the first person investors look at as they decide whether or not you are deserving of their time and money is you, the founder.</span></p>
<h2><span>What Startup Investors Look For In Entrepreneurs and The Red Flags They Avoid&nbsp;</span></h2>
<p><span>Investors, like most educated gamblers, bet on the jockey ‚Äì not the horse. Making you the most important asset for a successful fundraising round ‚Äì especially if you have a proven track record. </span><a href="https://medium.com/startupsoft/why-vcs-almost-blindly-invest-in-founders-with-previous-exits-23824334a260" target="_blank" rel="noopener noreferrer"><span>Studies show</span></a><span> that:</span></p>
<h3><em><strong><span>‚ÄúSuccessful serial entrepreneurs are more likely to replicate the success of their past companies.‚Äù and ‚ÄúNearly 80% of [startup] unicorns had at least one co-founder who had previously founded a company of some sort.‚Äù&nbsp;</span></strong></em></h3>
<p><span>However, regardless of your previous success investors need to get to know you before they consider investing. They need to trust that you can execute your milestones and that you will provide a valuable ROI. To earn their trust and ultimately win them over you need these essential qualities:&nbsp;</span></p>
<ul>
<li><span>Character</span></li>
<li><span>Confidence</span></li>
<li><span>Coachability&nbsp;</span></li>
</ul>
<h3><b>Character</b></h3>
<p><span>Renowned leadership guru </span><a href="https://www.linkedin.com/in/simonsinek/" target="_blank" rel="noopener noreferrer"><span>Simon Sinek</span></a><span> states that ‚ÄúPeople don‚Äôt buy </span><b>what you do</b><span>; they buy </span><b>why you do it.</b><span>‚Äù</span></p>
<p><iframe title="Start with why -- how great leaders inspire action | Simon Sinek | TEDxPugetSound" width="500" height="375" src="https://www.youtube.com/embed/u4ZoJKF_VuA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

<p><span>If an investor doesn‚Äôt know </span><b>why</b><span> you are creating your startup what incentive do they have to invest in you; as opposed to the thousands of other founders out there. If they can‚Äôt be sure their money is in the hands of an intelligent, capable, trustworthy founder they are unlikely to commit to a deal.</span></p>
<p><span>Moreover, they aren‚Äôt just planning to invest capital in your business but also their valuable time. They are looking to create a long-term business relationship with you and share their expertise and network. If they don‚Äôt like or trust you they simply won‚Äôt do it.</span></p>
<p><span>Your character is a critical factor and potential investors will want to answer the following questions about you:</span></p>
<ul>
<li><span><strong>Competency</strong> ‚Äì ‚ÄúCan you do this?‚Äù Is the question nearly all financial backers will want the answer to. Demonstrating competence is challenging, but can be made easier if you have been part of (or already founded) a successful startup.&nbsp;</span></li>
<li><span><strong>Commitment</strong> ‚Äì Are you totally invested in your startup? Are you still working for someone else or have you taken the leap?&nbsp; How hard do you work?&nbsp;</span></li>
<li><span><strong>Honesty</strong> ‚Äì Do you tell the truth? Any lies you tell will inevitably backfire. </span><a href="https://www.hbs.edu/faculty/Pages/profile.aspx?facId=6560" target="_blank" rel="noopener noreferrer"><span>Howard Stevenson</span></a><span> (Professor Emeritus at Harvard Business School) sums it up perfectly: ‚ÄúThe first time you hear anything dishonest come out of a founder‚Äôs mouth, you should run, not walk‚Äù</span></li>
<li><span><strong>Trustworthiness</strong> ‚Äì More than telling the truth, do you keep your word and deliver on your promises?</span></li>
<li><span><strong>Who you are underneath it all</strong> ‚Äì Aside from the above are you the kind of person they will be happy to introduce to their professional networks? Will they enjoy working with you over the next three to five years?&nbsp;</span></li>
</ul>
<h3><b>Confidence</b></h3>
<p><span>It may seem obvious but you need to be confident that you, your idea and your team can overcome the inevitable challenges of founding a startup. You will need to get used to hearing no from investors, clients, banks and even family and friends. It‚Äôs important to develop a thick skin and generate self-confidence no matter the hurdles that arise.</span></p>
<p><span>However, there is a fine line between confidence and arrogance ‚Äì and it‚Äôs a line you will need to tread carefully. Overconfidence and arrogance will make you look like a ‚Äúknow-it-all‚Äù to investors. If they decide that you won‚Äôt be open to guidance and new ideas it will be a deal-breaking red flag and they will walk away. The best way to ensure that you‚Äôre portraying confidence and not arrogance is to support your claims with facts and figures.&nbsp;</span></p>
<h3><b>Coachability</b></h3>
<p><span>Do you listen well? Can you learn quickly and effectively? These are two factors essential for investors. They want to feel their time (and money) is well spent and that they are investing in a founder who is open to learning and being mentored.&nbsp;</span></p>
<p><span>A good (smart money) investor will want to nurture a mentor-mentee relationship with you. A receptive mind is a vital quality that you will need. </span><a href="https://www.forbes.com/profile/ron-conway/#4900daef67ac" target="_blank" rel="noopener noreferrer"><span>Ron Conway</span></a><span>, an active early-stage investor in Google and Paypal (and Founder of </span><a href="https://www.svangel.com/index" target="_blank" rel="noopener noreferrer"><span>SV Angel</span></a><span>) puts it this way:&nbsp;</span></p>
<h3><strong><span><i>‚ÄúCoachability enables a willingness to be open and make the necessary and often numerous course corrections and morphing that startups require.‚Äù&nbsp;</i></span></strong></h3>
<h3><b>The Red Flags &amp; Dealbreakers for Investors</b></h3>
<p><span>There are seven ‚Äúdeadly sins‚Äù that will leave you investor-less and could potentially harm your reputation. Here they are and how you can avoid them:&nbsp;</span></p>
<h4>1. Dishonesty</h4>
<p><span>As I mentioned before lies inevitably backfire. Lying about any aspect of your business (or yourself) will plant a seed of doubt into the minds of any potential investor. They will do the necessary research into you and your company to verify your claims before they open their wallets ‚Äì so be upfront and honest at all times.&nbsp;</span></p>
<h4>2. Telling Them you Have ‚ÄúNo Competition‚Äù</h4>
<p><span>Even if your product is the most innovative product the world has ever seen you will either be disrupting an existing market or creating a new market that will quickly fill with investors.&nbsp;</span></p>
<h4>3. Saying you ‚ÄúOnly Need 1% of the Market Share‚Äù<span>&nbsp;</span></h4>
<p><span>This is a great way to show investors that you don‚Äôt understand sales or customer CPA (cost-per-acquisition). Instead of talking in market share talk in customers. Specifically how many you need, how much you will spend to get them and how long it will take for you to get to that number.&nbsp;</span></p>
<h4>4. Failing to Fulfil Your Commitments</h4>
<p><span>When asked about what might kill a potential deal for her clients </span><a href="https://www.linkedin.com/in/marciasnelson/" target="_blank" rel="noopener noreferrer"><span>Marcia Nelson</span></a><span> Managing Director of </span><a href="https://www.alberleen.com/" target="_blank" rel="noopener noreferrer"><span>Alberleen Family Office Solutions</span></a><span> said on aspect is when a ‚Äústartup‚Äôs management takes too long to get us requested information ‚Äì while it may not kill a deal, it will certainly make us more cautious.‚Äù Investors want to know that you take your commitments seriously and that you are prepared to fulfil requests in a timely manner.&nbsp;</span></p>
<h4>5. Being Desperate</h4>
<p><span>Desperation can break a business partnership before it begins and shows investors that you are unconfident.&nbsp;</span></p>
<h4>6. Being Arrogant or Defensive<span>&nbsp;</span></h4>
<p><span>As I mentioned above confidence and arrogance are close neighbours and it‚Äôs important not to come off too strong.&nbsp;</span></p>
<h4>7. An Unwillingness to Listen</h4>
<p><span>Own your weaknesses. Investors will be put off if you act like you have all the answers and don‚Äôt need any help. You will need guidance and help on your journey and investors already know that. If you admit your faults and actively seek advice you will be left with a much healthier and more productive business relationship.&nbsp;</span></p>
<p><span>As a founder, it is </span><b>your responsibility</b><span> to make as easy as possible for investors to say yes to both you and your startup. You have to put yourself in the best position to form a great partnership that will be a lucrative deal for all parties involved. And the next step in that process is choosing your founding team,</span></p>
<h2><span>Choosing Your Co-Founders&nbsp;</span></h2>
<p><span>The founder who will lead the company isn‚Äôt necessarily the inventor. It is someone who believes in the startup‚Äôs idea and product. So much so that they are willing to put their future on the line to turn that idea into a successful company.</span></p>
<p><span>You should try and choose professionals that have the skills you lack. Someone who has a skillset to offer in another part of the business. Their skills should complement yours.&nbsp;</span></p>
<p><span>Another important factor is ensuring your values, expectations and business goals are aligned. You and your co-founders will become your startup‚Äôs core management team. It‚Äôs important to be on the same page when it comes to your startup‚Äôs mission, business goals, values and timeline.</span></p>
<p><span>You need to ask yourself if your personalities are compatible. </span><a href="https://techcrunch.com/2017/02/18/co-founder-conflict/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZm9yYmVzLmNvbS9zaXRlcy9reWxld29uZy8yMDE4LzA3LzI2L2hvdy10by1waWNrLXRoZS1yaWdodC1jb2ZvdW5kZXJzLWFuZC13aHktaXQtaW1wcm92ZXMteW91ci1jdXN0b21lci1leHBlcmllbmNlLw&amp;guce_referrer_sig=AQAAAEtIKZoxIkLDJGeNlqJVPCniIv_oDI2VMfIzQ8MoJFst1Y1LpVPlj_dgeGnWBxvuTx9vTEPU8-Lvvf4l34V7ZmlCoi71qW367ATIsBoEnNZ0Pybpbb0jkw9IphJ8mm-GJetR8PtNUn8-Pv5Rvdh2cXfZ_aO-Kk5hLP--l9aOGQXp" target="_blank" rel="noopener noreferrer"><span>Gary Tan</span></a><span>, Managing Partner at Initialized Capital and previously at YCombinator puts it perfectly:</span></p>
<figure><img src="https://cdn-images-1.medium.com/max/720/0*k0NpSqRY3Ufsv_kH" alt="Gary Tan: Co-founder disputes have historically been one of the top reasons startups fail" width="720" height="440" data-image-id="0*k0NpSqRY3Ufsv_kH" data-width="752" data-height="460"></figure>
<p><span>Will you be able to embrace the conflict with this person? Discussing disagreements on a level playing field to improve your business?&nbsp;</span></p>
<p><span>It comes down to one overarching question:</span></p>
<h4><b>Can you work together over a long period of time? </b></h4>
<p><span>After all, what good is it if their hard skills complement yours if you don‚Äôt actually like the person you have chosen as your cofounder?&nbsp;</span></p>
<p><span>Investors will take the dynamics of your relationship into account as they assess if your startup will be the right fit for their portfolio. As well as assessing your co-founder on the same essential qualities they judged you on.&nbsp;</span></p>
<p><span>I recommend that you thoroughly and carefully consider a business partner as you would a life partner. Ask yourself, if in the toughest times will that person remember that you are both on the same team and be by your side? More importantly, will they be an asset to your business.&nbsp;</span></p>
<p><span>Serial entrepreneur, </span><a href="https://twitter.com/amiller" target="_blank" rel="noopener noreferrer"><span>Andy Miller‚Äôs</span></a><span> formula is simple: </span><b>People</b><span> + </span><b>Execution </b><span>= </span><b>Success</b><span>. Your potential investors are counting on you and your startup management team to execute on your business plan, gain traction and, ultimately, bring in revenue no matter the hurdles.&nbsp;</span></p>
<p><span>Your founding team‚Äôs primary responsibility is to plan your journey to market that avoids potential roadblocks. Then, when unexpected roadblocks do inevitably appear, you and your founding team use that plan to navigate them.&nbsp;</span></p>
<p><span>As </span><a href="https://www.linkedin.com/in/seansheppard/" target="_blank" rel="noopener noreferrer"><span>Sean Sheppard</span></a><span> puts it:&nbsp;</span></p>
<h3><strong><span><i>‚ÄúMost companies and innovations fail, and the reasons have to do with markets and the behaviours of the people who are running them, not the products themselves‚Äù.</i></span></strong></h3>
<p><span>You need to be able to trust and count on your co-founders. Choose correctly and you will have a strong foundation on which to move onto the next step: building a startup team.</span></p>
<div>
<h3>Building a Startup?</h3>
<p>From the product and business reasoning to streamlining your MVP to the most important features, our team of product experts and ex-startup founders can help you bring your vision to life.</p>

</div>
<h2><span>How to Build a ‚Ä¶</span></h2></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://altar.io/what-startup-investors-look-for-in-entrepreneurs-and-their-teams/">https://altar.io/what-startup-investors-look-for-in-entrepreneurs-and-their-teams/</a></em></p>]]>
            </description>
            <link>https://altar.io/what-startup-investors-look-for-in-entrepreneurs-and-their-teams/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23712018</guid>
            <pubDate>Thu, 02 Jul 2020 11:22:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to get values from mouse movement and plug them into an animation]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23711822">thread link</a>) | @thereyougo
<br/>
July 2, 2020 | https://www.cassie.codes/posts/making-a-lil-me-part-1/ | <a href="https://web.archive.org/web/*/https://www.cassie.codes/posts/making-a-lil-me-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>I'm so excited to have <em>finally</em> launched my website.</p><p>This was one of my favourite bits to make <strong>by far</strong>. A little animated me that responds to the cursor position.</p><p data-height="580" data-theme-id="dark" data-preview="true" data-default-tab="result" data-user="cassie-codes" data-slug-hash="WNQqZJG" data-pen-title="lil' me."><span>See the Pen <a href="https://codepen.io/cassie-codes/pen/WNQqZJG">lil' me.</a> by Cassie Evans (<a href="https://codepen.io/cassie-codes">@cassie-codes</a>) on <a href="https://codepen.io/">CodePen</a>.</span></p><p>In this post we'll cover how to get values from the mouse movement and plug them into an animation.</p><p>This is my <strong>favourite</strong> thing about SVG animation. Not mouse movement in particular, but interactivity. Exporting animation as an mp4 is cool and all. But you can't <em>play</em> with it.</p><p>Animating on the web opens up so many cool possibilities!</p><p>If you're the kind of person who learns best by digging into the code, then just go ahead and fork that pen, have fun!</p><hr><p>Still here? üòä Cool beans, let's go through it together.</p><p>I use <a href="https://greensock.com/">Greensock</a> for all my SVG animation. There are a few reasons for this. Firstly, it gives you more control and is super fun to use. But more importantly, as browsers implement the SVG spec differently, animating can get a bit messy. The team at Greensock put a lot of effort into harmonizing behavior across browsers.</p><p>Under the hood though, Greensock is just a really performant property manipulator. It will manipulate (pretty much) whatever value you want to change. In this case it's updating the values in a matrix transform. Check this out.</p><p><img src="https://www.cassie.codes/images/cursor.gif" alt="gif of matrix transforms updating with dev tools open" loading="lazy"></p><p>Cool right! Greensock is great at this kind of thing, but there's a lot going on in this pen, so let's break it down into chunks and focus on one bit at a time. First up, the mouse interaction. We'll come back to Greensock in a bit!</p><h2 id="heading-mouse-movement-fun!">Mouse movement fun!<a href="#heading-mouse-movement-fun!"><span role="text"> permalink</span></a></h2><p>So, there's another way we can modify values in CSS with Javascript. <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/Using_CSS_custom_properties">CSS custom properties!</a></p><p data-height="500" data-theme-id="dark" data-default-tab="result" data-user="cassie-codes" data-slug-hash="OJMOLML" data-pen-title="Mouse movement demo"><span>See the Pen <a href="https://codepen.io/cassie-codes/pen/OJMOLML">Mouse movement demo</a> by Cassie Evans (<a href="https://codepen.io/cassie-codes">@cassie-codes</a>) on <a href="https://codepen.io/">CodePen</a>.</span></p><p>Let's walk through the process. The goal is to get the x and y position of the cursor as we move our mouse about, and then we can use those values to update some custom properties.</p><p>In the previous gif Greensock is using matrix transforms, which are more performant. But we're going to use <code>transform: translate(x,y)</code> for this as it's a tad more readable, and we can use percentage values.</p><p>First up, we declare some custom properties for the x and y values and then use those custom properties in place of regular property values in our transform.</p><pre><code><span><span>:root</span> <span>{</span></span><br><span>  <span>--mouse-x</span><span>:</span> 0<span>;</span></span><br><span>  <span>--mouse-y</span><span>:</span> 0<span>;</span></span><br><span><span>}</span></span><br><span></span><br><span><span>.pointer</span> <span>{</span></span><br><span>  <span>transform</span><span>:</span> <span>translate</span><span>(</span><span>var</span><span>(</span>--mouse-x<span>)</span><span>,</span> <span>var</span><span>(</span>--mouse-y<span>)</span><span>)</span><span>;</span></span><br><span><span>}</span></span></code></pre><p>Then we need to get our mouse coordinates. We can do this by listening to the mouse movement and getting the mouse's coordinates with <code>clientX</code> and <code>clientY</code></p><p>We'll assign those values to some global variables so that we can access them in another function later.</p><pre><code><span><span>let</span> xPosition<span>;</span></span><br><span><span>let</span> yPosition<span>;</span></span><br><span></span><br><span></span><br><span><span>function</span> <span>updateMouseCoords</span><span>(</span><span>event</span><span>)</span> <span>{</span></span><br><span>  xPosition <span>=</span> event<span>.</span>clientX<span>;</span></span><br><span>  yPosition <span>=</span> event<span>.</span>clientY<span>;</span></span><br><span><span>}</span></span><br><span>window<span>.</span><span>addEventListener</span><span>(</span><span>'mousemove'</span><span>,</span> updateMouseCoords<span>)</span><span>;</span></span></code></pre><p>Now we've got our coordinates, lets use them to update our custom properties and move our pointer around!</p><p>üòá When animating things on the web it's important to pay attention to performance. We can't know for sure how many times a users mouse event will fire as it's implementation specific. If it fires more than 60 times per second (which is the average refresh rate for most browsers) we'll end up with unnecessary computation. So to avoid burning up everyone's laptop fans and melting their CPU we can use <code>requestAnimationFrame</code></p><p>Request animation frame allows us to make smoother, browser optimized animations. If the user changes tabs, the animation will stop and give the CPU a break. You call the function once to start, and then it recusively calls itself.</p><p>‚ö†Ô∏è This is a great way to crash your browser if you get some code wrong!</p><pre><code><span><span>function</span> <span>movePointer</span><span>(</span><span>)</span> <span>{</span></span><br><span>  </span><br><span>  <span>requestAnimationFrame</span><span>(</span>movePointer<span>)</span><span>;</span></span><br><span><span>}</span></span><br><span><span>requestAnimationFrame</span><span>(</span>movePointer<span>)</span><span>;</span></span></code></pre><p>Right now, the x and y position we're getting back from <code>event.clientX</code> and <code>event.clientY</code> are pixel values, this isn't really useful to us. If we plug them straight into our custom properties we could end up transforming our pointer hundreds of pixels off in one direction.</p><p data-height="500" data-theme-id="dark" data-default-tab="result" data-user="cassie-codes" data-slug-hash="5ed677605b34f86eeb488b4b2a9bfe6a" data-pen-title="Mouse movement demo"><span>See the Pen <a href="https://codepen.io/cassie-codes/pen/5ed677605b34f86eeb488b4b2a9bfe6a">Mouse movement demo</a> by Cassie Evans (<a href="https://codepen.io/cassie-codes">@cassie-codes</a>) on <a href="https://codepen.io/">CodePen</a>.</span></p><p>We need to convert those pixel values into percentages of the window height and width.</p><p>Let's define some global variables for the window width and height and work out the percentage values.</p><pre><code><span><span>let</span> windowHeight <span>=</span> window<span>.</span>innerHeight<span>;</span></span><br><span><span>let</span> windowWidth <span>=</span> window<span>.</span>innerWidth<span>;</span></span><br><span></span><br><span><span>function</span> <span>percentage</span><span>(</span><span>partialValue<span>,</span> totalValue</span><span>)</span> <span>{</span></span><br><span>  <span>return</span> <span>(</span><span>100</span> <span>*</span> partialValue<span>)</span> <span>/</span> totalValue<span>;</span></span><br><span><span>}</span></span><br><span></span><br><span><span>function</span> <span>movePointer</span><span>(</span><span>)</span> <span>{</span></span><br><span>  x <span>=</span> <span>percentage</span><span>(</span>xPosition<span>,</span> windowWidth<span>)</span><span>;</span></span><br><span>  y <span>=</span> <span>percentage</span><span>(</span>yPosition<span>,</span> windowHeight<span>)</span><span>;</span></span><br><span></span><br><span>  window<span>.</span><span>requestAnimationFrame</span><span>(</span>movePointer<span>)</span><span>;</span></span><br><span><span>}</span></span><br><span><span>requestAnimationFrame</span><span>(</span>movePointer<span>)</span><span>;</span></span></code></pre><p>This will give us a range from 0 - 100, which would just move our pointer downwards and to the right, so we can shift the range by subtracting 50.</p><p>Once we've got our nice centralised range, we can plug it into our custom properties using <code>setProperty()</code></p><pre><code><span><span>let</span> windowHeight <span>=</span> window<span>.</span>innerHeight<span>;</span></span><br><span><span>let</span> windowWidth <span>=</span> window<span>.</span>innerWidth<span>;</span></span><br><span></span><br><span><span>function</span> <span>percentage</span><span>(</span><span>partialValue<span>,</span> totalValue</span><span>)</span> <span>{</span></span><br><span>  <span>return</span> <span>(</span><span>100</span> <span>*</span> partialValue<span>)</span> <span>/</span> totalValue<span>;</span></span><br><span><span>}</span></span><br><span></span><br><span><span>function</span> <span>movePointer</span><span>(</span><span>)</span> <span>{</span></span><br><span>  </span><br><span>  </span><br><span>  x <span>=</span> <span>percentage</span><span>(</span>xPosition<span>,</span> windowWidth<span>)</span> <span>-</span> <span>50</span><span>;</span></span><br><span>  y <span>=</span> <span>percentage</span><span>(</span>yPosition<span>,</span> windowHeight<span>)</span> <span>-</span> <span>50</span><span>;</span></span><br><span></span><br><span>  </span><br><span>  document<span>.</span>documentElement<span>.</span>style<span>.</span><span>setProperty</span><span>(</span><span>'--mouse-x'</span><span>,</span> <span><span>`</span><span><span>${</span>x<span>}</span></span><span>%`</span></span><span>)</span><span>;</span></span><br><span>  document<span>.</span>documentElement<span>.</span>style<span>.</span><span>setProperty</span><span>(</span><span>'--mouse-y'</span><span>,</span> <span><span>`</span><span><span>${</span>y<span>}</span></span><span>%`</span></span><span>)</span><span>;</span></span><br><span></span><br><span>  window<span>.</span><span>requestAnimationFrame</span><span>(</span>movePointer<span>)</span><span>;</span></span><br><span><span>}</span></span><br><span><span>requestAnimationFrame</span><span>(</span>movePointer<span>)</span><span>;</span></span></code></pre><p>The user might resize the browser, so it's good to check for that.</p><pre><code><span></span><br><span><span>function</span> <span>updateWindowSize</span><span>(</span><span>)</span> <span>{</span></span><br><span>  windowHeight <span>=</span> window<span>.</span>innerHeight<span>;</span></span><br><span>  windowWidth <span>=</span> window<span>.</span>innerWidth<span>;</span></span><br><span><span>}</span></span><br><span>window<span>.</span><span>addEventListener</span><span>(</span><span>'resize'</span><span>,</span> updateWindowSize<span>)</span><span>;</span></span></code></pre><p>We can also avoid unnecessary calculations when the mouse position hasn't changed by storing past x and y positions and comparing them to the new positions.</p><pre><code><span><span>let</span> xPosition<span>;</span></span><br><span><span>let</span> yPosition<span>;</span></span><br><span></span><br><span><span>let</span> storedXPosition<span>;</span></span><br><span><span>let</span> storedYPosition<span>;</span></span><br><span></span><br><span><span>function</span> <span>movePointer</span><span>(</span><span>)</span> <span>{</span></span><br><span>  window<span>.</span><span>requestAnimationFrame</span><span>(</span>movePointer<span>)</span><span>;</span></span><br><span>  </span><br><span>  <span>if</span> <span>(</span>storedXPosition <span>===</span> xPosition <span>&amp;&amp;</span> storedYPosition <span>===</span> yPosition<span>)</span> <span>return</span><span>;</span></span><br><span></span><br><span>  </span><br><span></span><br><span>  </span><br><span>  storedXPosition <span>=</span> xPosition<span>;</span></span><br><span>  storedYPosition <span>=</span> yPosition<span>;</span></span><br><span><span>}</span></span></code></pre><p>üòá another <em>super important</em> bit is checking whether the user has a preference set in their OS for reduced motion. Some people have vestibular disorders and get mega quesy when looking at animations.</p><p>I pop this check at the start of all my animation functions, and return out if necessary.</p><pre><code><span><span>const</span> safeToAnimate <span>=</span> window<span>.</span><span>matchMedia</span><span>(</span><span>'(prefers-reduced-motion: no-preference)'</span><span>)</span></span><br><span>  <span>.</span>matches<span>;</span></span><br><span></span><br><span><span>if</span> <span>(</span><span>!</span>safeToAnimate<span>)</span> <span>return</span><span>;</span></span></code></pre><p data-height="500" data-theme-id="dark" data-preview="true" data-default-tab="result js" data-user="cassie-codes" data-slug-hash="OJMOLML" data-pen-title="Mouse movement demo"><span>See the Pen <a href="https://codepen.io/cassie-codes/pen/OJMOLML">Mouse movement demo</a> by Cassie Evans (<a href="https://codepen.io/cassie-codes">@cassie-codes</a>) on <a href="https://codepen.io/">CodePen</a>.</span></p><h2 id="heading-what-about-greensock!">What about Greensock?!<a href="#heading-what-about-greensock!"><span role="text"> permalink</span></a></h2><p>Let's see how we can do the same thing using Greensock! First we have to include the core library, if you're on codepen, you can go to your pen settings and search for greensock.</p><p><img src="https://www.cassie.codes/images/gsap-include.png" alt="pen settings on codepen" loading="lazy"></p><p>Now we've got the GSAP library in our pen, we can take advantage of <code>gsap.ticker()</code></p><p>The greensock ticker is like the heartbeat of the GSAP engine - under the hood it uses requestAnimationFrame, just like we were using, but if that isn‚Äôt supported, the ticker automatically falls back to using a regular setTimeout() loop.</p><p>So rather than calling our function with request animation frame, we would do this...</p><pre><code><span><span>function</span> <span>movePointer</span><span>(</span><span>)</span> <span>{</span></span><br><span>  </span><br><span><span>}</span></span><br><span></span><br><span>gsap<span>.</span>ticker<span>.</span><span>add</span><span>(</span>movePointer<span>)</span><span>;</span></span></code></pre><p>Aside from making structuring animation itself more intuitive, Greensock provides a load of super cool utility functions that make your life easier. Remember all that work we did to get a nice usable range? Chuck that all in the bin. Look what we can do now!</p><pre><code><span></span><br><span><span>let</span> mapWidth<span>;</span></span><br><span><span>let</span> mapHeight<span>;</span></span><br><span><span>function</span> <span>setMaps</span><span>(</span><span>)</span> <span>{</span></span><br><span>  mapWidth <span>=</span> gsap<span>.</span>utils<span>.</span><span>mapRange</span><span>(</span><span>0</span><span>,</span> innerWidth<span>,</span> <span>-</span><span>50</span><span>,</span> <span>50</span><span>)</span><span>;</span></span><br><span>  mapHeight <span>=</span> gsap<span>.</span>utils<span>.</span><span>mapRange</span><span>(</span><span>0</span><span>,</span> innerHeight<span>,</span> <span>-</span><span>50</span><span>,</span> <span>50</span><span>)</span><span>;</span></span><br><span><span>}</span></span><br><span>window<span>.</span><span>addEventListener</span><span>(</span><span>'resize'</span><span>,</span> setMaps<span>)</span><span>;</span></span><br><span><span>setMaps</span><span>(</span><span>)</span><span>;</span></span></code></pre><p>Now we can listen to the mouse movement, feed <code>clientX</code> and <code>clientY</code> into mapWidth, and we'll get back a value within the range we've set!</p><pre><code><span><span>let</span> xPosition<span>;</span></span><br><span><span>let</span> yPosition<span>;</span></span><br><span></span><br><span></span><br><span><span>function</span> <span>updateMouseCoords</span><span>(</span><span>event</span><span>)</span> <span>{</span></span><br><span>  xPosition <span>=</span> <span>mapWidth</span><span>(</span>event<span>.</span>clientX<span>)</span><span>;</span></span><br><span>  yPosition <span>=</span> <span>mapWidth</span><span>(</span>event<span>.</span>clientY<span>)</span><span>;</span></span><br><span><span>}</span></span><br><span>window<span>.</span><span>addEventListener</span><span>(</span><span>'mousemove'</span><span>,</span> updateMouseCoords<span>)</span><span>;</span></span></code></pre><p>So tidy and concise!</p><p>Instead of updating CSS custom properties, we're going to use a Greensock tween. A Tween is what does all the animation work, as I said at the start, it's like a high-performance property manipulator.</p><p>A tween takes in two parameters</p><p>The targets, which are the object(s) whose properties you want to animate. Greensock uses <code>document.querySelectorAll()</code> internally so we can use any CSS selector we would use in CSS, or a direct reference to an element.</p><p>And the vars, an object containing all the properties/values you want to animate, along with any special properties like delay, ease, or duration.</p><pre><code><span><span>function</span> <span>movePointer</span><span>(</span><span>)</span> <span>{</span></span><br><span>  gsap<span>.</span><span>to</span><span>(</span>pointer<span>,</span> <span>{</span></span><br><span>    xPercent<span>:</span> xPosition<span>,</span></span><br><span>    yPercent<span>:</span> yPosition<span>,</span></span><br><span>    ease<span>:</span> <span>'none'</span></span><br><span>    </span><br><span>    </span><br><span>  <span>}</span><span>)</span><span>;</span></span><br><span><span>}</span></span><br><span></span><br><span>gsap<span>.</span>ticker<span>.</span><span>add</span><span>(</span>movePointer<span>)</span><span>;</span></span></code></pre><p>I've added a couple more easing equations in here so you can change them out and see what a difference it can make to the movement.</p><p data-height="400" data-theme-id="dark" data-preview="true" data-default-tab="js,result" data-user="cassie-codes" data-slug-hash="rNxYpzO" data-pen-title="Mouse movement demo - GSAP - easing"><span>See the Pen <a href="https://codepen.io/cassie-codes/pen/rNxYpzO">Mouse movement demo - GSAP - easing</a> by Cassie Evans (<a href="https://codepen.io/cassie-codes">@cassie-codes</a>) on <a href="https://codepen.io/">CodePen</a>.</span></p><p>If you want to focus more on performance than easing you can use gsap.quickSetter to update the transforms. Creating a quickSetter function can boost performance around 50% - 250%!</p><pre><code><span></span><br><span></span><br><span><span>const</span> xSet <span>=</span> gsap<span>.</span><span>quickSetter</span><span>(</span>pointer<span>,</span> <span>'x'</span><span>,</span> <span>'%'</span><span>)</span><span>;</span></span><br><span><span>const</span> ySet <span>=</span> gsap<span>.</span><span>quickSetter</span><span>(</span>pointer<span>,</span> <span>'y'</span><span>,</span> <span>'%'</span><span>)</span><span>;</span></span><br><span></span><br><span><span>function</span> <span>movePointer</span><span>(</span><span>)</span> <span>{</span></span><br><span>  <span>xSet</span><span>(</span>xPosition<span>)</span><span>;</span></span><br><span>  <span>ySet</span><span>(</span>yPosition<span>)</span><span>;</span></span><br><span><span>}</span></span><br><span></span><br><span>gsap<span>.</span>ticker<span>.</span><span>add</span><span>(</span>movePointer<span>)</span><span>;</span></span></code></pre><p data-height="400" data-theme-id="dark" data-preview="true" data-default-tab="js,result" data-user="cassie-codes" data-slug-hash="oNboYNy" data-pen-title="Mouse movement demo - GSAP"><span>See the Pen <a href="https://codepen.io/cassie-codes/pen/oNboYNy">Mouse movement demo - GSAP</a> by Cassie Evans (<a href="https://codepen.io/cassie-codes">@cassie-codes</a>) on <a href="https://codepen.io/">CodePen</a>.</span></p><p>Thanks for reading!</p><p>Next up - lets apply this to a SVG and fake some three dimensional movement!</p><p>(check back in for the next article in a couple of days!)</p><p>Got any questions about this article? <a href="https://twitter.com/cassiecodes">Just pop me a message!</a></p></div></article></div>]]>
            </description>
            <link>https://www.cassie.codes/posts/making-a-lil-me-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23711822</guid>
            <pubDate>Thu, 02 Jul 2020 10:37:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sleep Tracking: My Oura Ring Review (After Two Years)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23711528">thread link</a>) | @remouherek
<br/>
July 2, 2020 | https://remo.org/2020/06/25/sleep-tracking-oura-ring-review/ | <a href="https://web.archive.org/web/*/https://remo.org/2020/06/25/sleep-tracking-oura-ring-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I have been using the <a href="https://ouraring.com/">Oura sleep tracking ring</a> for almost two years now. I immediately fell in love with the form factor, as I can‚Äôt stand watches or bracelets.</p>



<div><figure><a href="https://ouraring.com/"><img src="https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring.png?resize=256%2C156&amp;ssl=1" alt="" width="256" height="156" srcset="https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring.png?w=1024&amp;ssl=1 1024w, https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring.png?resize=300%2C183&amp;ssl=1 300w, https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring.png?resize=768%2C469&amp;ssl=1 768w, https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring.png?resize=850%2C519&amp;ssl=1 850w" sizes="(max-width: 256px) 100vw, 256px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring.png?w=1024&amp;ssl=1 1024w, https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring.png?resize=300%2C183&amp;ssl=1 300w, https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring.png?resize=768%2C469&amp;ssl=1 768w, https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring.png?resize=850%2C519&amp;ssl=1 850w" data-lazy-src="https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring.png?resize=256%2C156&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure></div>



<h2>When do I wear it?</h2>



<p>I used to wear it all the time, but then switched to night-only. I‚Äôm not interested in tracking my steps or any of the other activity features. </p>



<p>It also provides an interesting airport security case study: </p>



<p>Turns out that airport security doesn‚Äôt care about the Oura ring. Every time I try to put it off, they say ‚Äúno no, keep the ring on‚Äù, and it never beeped or anything, even though it‚Äôs an electronic device.</p>



<h2>Main use cases?</h2>



<p>I mainly use it to observe my body temperature at night. It‚Äôs a great early warning system for infections.</p>



<p>Also for my ‚Äúreadiness‚Äù. It indicates how restful my night was, informing the intensity of my workouts. I‚Äòve especially found that ‚Äúlow readiness‚Äù combined with an ‚Äúintense workout‚Äù is a really bad combination. Instead I use the earliest signs to ‚Äûlisten to my body‚Äú</p>



<p>Another important factor is seeing if I got enough REM sleep.</p>



<h2>What have I learned so far?</h2>



<p>I‚Äôve learned that <a href="https://remo.org/2020/05/28/bedtime/" data-type="1791">time in bed doesn‚Äôt equal time asleep</a>. Just because you‚Äôve been in bed for 7 hours doesn‚Äôt mean you slept for 7 hours. It‚Äôs more likely that you slept 6. Based on my ring, my own difference is 30 to 60 minutes per night.</p>



<p>I‚Äôve also learned more about my sleep cycle. For the first few hours, my body focuses on deep sleep. Towards the morning, the focus is shifted to REM sleep. To feel fully rested, I both need enough deep as well as REM sleep. Especially the REM sleep seems to be the most important factor for me.</p>



<h2>Sick vs. Healthy</h2>



<p>Here is a comparison between me being sick and healthy. Your sleep quality is always summarized into a ‚Äúreadiness‚Äù score, which makes it easily comparable.</p>



<figure><img src="https://i2.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-sick.jpeg?fit=495%2C1024&amp;ssl=1" alt="" width="371" height="768" srcset="https://i2.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-sick.jpeg?w=990&amp;ssl=1 990w, https://i2.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-sick.jpeg?resize=145%2C300&amp;ssl=1 145w, https://i2.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-sick.jpeg?resize=495%2C1024&amp;ssl=1 495w, https://i2.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-sick.jpeg?resize=768%2C1589&amp;ssl=1 768w, https://i2.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-sick.jpeg?resize=743%2C1536&amp;ssl=1 743w, https://i2.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-sick.jpeg?resize=300%2C621&amp;ssl=1 300w, https://i2.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-sick.jpeg?resize=850%2C1758&amp;ssl=1 850w" sizes="(max-width: 371px) 100vw, 371px" data-lazy-srcset="https://i2.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-sick.jpeg?w=990&amp;ssl=1 990w, https://i2.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-sick.jpeg?resize=145%2C300&amp;ssl=1 145w, https://i2.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-sick.jpeg?resize=495%2C1024&amp;ssl=1 495w, https://i2.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-sick.jpeg?resize=768%2C1589&amp;ssl=1 768w, https://i2.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-sick.jpeg?resize=743%2C1536&amp;ssl=1 743w, https://i2.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-sick.jpeg?resize=300%2C621&amp;ssl=1 300w, https://i2.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-sick.jpeg?resize=850%2C1758&amp;ssl=1 850w" data-lazy-src="https://i2.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-sick.jpeg?fit=495%2C1024&amp;ssl=1&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Here‚Äôs me having the flu.</figcaption></figure>



<figure><img src="https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-healthy.jpeg?fit=498%2C1024&amp;ssl=1" alt="" width="374" height="768" srcset="https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-healthy.jpeg?resize=146%2C300&amp;ssl=1 146w, https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-healthy.jpeg?resize=498%2C1024&amp;ssl=1 498w, https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-healthy.jpeg?resize=300%2C617&amp;ssl=1 300w, https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-healthy.jpeg?zoom=2&amp;resize=374%2C768&amp;ssl=1 748w" sizes="(max-width: 374px) 100vw, 374px" data-lazy-srcset="https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-healthy.jpeg?resize=146%2C300&amp;ssl=1 146w, https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-healthy.jpeg?resize=498%2C1024&amp;ssl=1 498w, https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-healthy.jpeg?resize=300%2C617&amp;ssl=1 300w, https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-healthy.jpeg?zoom=2&amp;resize=374%2C768&amp;ssl=1 748w" data-lazy-src="https://i1.wp.com/remo.org/wp-content/uploads/2020/06/oura-ring-healthy.jpeg?fit=498%2C1024&amp;ssl=1&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>That‚Äôs how a great night‚Äôs sleep looks like</figcaption></figure>







<h2>How accurate is it?</h2>



<p>At the time I bought the ring, author of <a href="https://www.amazon.de/Why-We-Sleep-Science-Dreams/dp/0141983760/ref=sr_1_1?ie=UTF8&amp;qid=1534409176&amp;sr=8-1&amp;keywords=why+we+sleep&amp;tag=remouherek-21">Why We Sleep</a>, Matthew Walker, has said that this ring was probably the most accurate sleep tracking device for retail consumers. As I loved Matthew‚Äôs book, I trust his judgement.</p>



<h2>Hardware</h2>



<p>The battery lasts for 5-7 days, which is fine. The ring does introduce a new charging device to your life‚Äîbut I guess we got used to charging device inflation, right?</p>



<p>I also like that the ring is waterproof, so you can wash your hands with it, or take a shower. </p>



<p>After 9 months, I had to have my ring replaced on warranty, because the battery life dropped to 1-2 days, and the whole process was very smooth. I never had any problems with my second ring.</p>



<h2>Software</h2>



<p>I love the mobile app. The ring connects via bluetooth and the syncing takes about 20 seconds. The ring receives regular firmware updates, which are also performed through the app.</p>



<h2>Conclusion</h2>



<p>If you care about your sleep and health, I highly recommend using the <a href="https://ouraring.com/">Oura ring</a>.</p>



<p>As a last comment, I strongly believe that the company should be acquired by Apple, as I believe that it would fit nicely into the Apple wearables ecosystem and provide a wonderful new form factor.</p>


		
		<p>Tags: <a href="https://remo.org/tag/rem-sleep/" rel="tag">REM sleep</a>, <a href="https://remo.org/tag/review/" rel="tag">Reviews</a>, <a href="https://remo.org/tag/sleep/" rel="tag">Sleep</a>, <a href="https://remo.org/tag/sleep-tracking/" rel="tag">Sleep tracking</a>, <a href="https://remo.org/tag/smart-ring/" rel="tag">Smart ring</a>, <a href="https://remo.org/tag/wearables/" rel="tag">Wearables</a>		<br>Category: <a href="https://remo.org/health/" rel="category tag">Health</a>		</p>
		
	</div></div>]]>
            </description>
            <link>https://remo.org/2020/06/25/sleep-tracking-oura-ring-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23711528</guid>
            <pubDate>Thu, 02 Jul 2020 09:43:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things I wish I had known when I started programming, Part 4 (2019)]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 36 (<a href="https://news.ycombinator.com/item?id=23711463">thread link</a>) | @juanorozcov
<br/>
July 2, 2020 | https://www.brainstobytes.com/advice-for-new-developers-or-things-i-wish-i-had-known-when-i-started-programming-part-4/ | <a href="https://web.archive.org/web/*/https://www.brainstobytes.com/advice-for-new-developers-or-things-i-wish-i-had-known-when-i-started-programming-part-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<!--kg-card-begin: markdown--><p>Yepp, more things I wish I'd known when I started, 4th edition.</p>
<p><em>You can find the first article in the series <a href="https://www.brainstobytes.com/advice-for-new-developers-or-things-i-wish-i-had-known-when-i-started-to-program/">here</a>.</em></p>
<p><em>And the previous article <a href="https://www.brainstobytes.com/advice-for-new-developers-or-things-i-wish-i-had-known-when-i-started-programming-part-3/">here</a></em></p>
<h2 id="lovemaintenanceworkoratleastlearntoappreciateit">Love maintenance work or at least learn to appreciate it</h2>
<p>Very few things are more despised by programmers than doing maintenance work and working with legacy apps.</p>
<p>This can be counterproductive, as most of the work available involves doing exactly that. Companies have running systems, some built a long time ago, and someone needs to maintain that code. This is especially true if you are starting at an entry position, where you'll most likely work on some old application the company has been running for more than a decade.</p>
<p>We love working on new projects for several reasons:</p>
<ul>
<li>We can choose which technology to use.</li>
<li>We can flex our creatives muscles and create something cool.</li>
<li>There's a lot of freedom when designing the solution.</li>
<li>You get to work on The Next Big Thing and all the credit it carries.</li>
</ul>
<p>The huge difference between how we perceive maintenance work and new project development is a sad thing. On one hand, most of the really important job with high impact happens on those legacy systems, whereas The Next Big Thing often goes bust. On the other hand, that cool new app will be legacy as soon as it hits production and you start receiving new requirements.</p>
<p>We should start seeing maintenance work under a more positive light. After all, most of the value provided to end users happens on those systems. We could exercise our creative muscles by refactoring and improving the design, or increasing the test coverage, all proper challenges for developers of any level.</p>
<p>Learn to love maintenance work, it's most likely what you'll spend doing most of the time as a programmer.</p>
<h2 id="makeaccomplishmentsvisible">Make accomplishments visible</h2>
<p>You are an awesome developer, always finishing tasks on time, writing ultra-complete test suites and providing to customers exactly what they want. You do a great job every day and work extra hard to ship those last-minute features. Then, that time of the year when promotions are given arrives and you... you are still in the same position?</p>
<p>I know it can be extremely frustrating, and you might end up resenting management. After all, aren't you always doing an outstanding job? how dare they pass this chance to show me how much they appreciate my hard work!</p>
<p>In reality, managers are just too busy to keep track of your accomplishments. It's your responsibility to make your contribution visible to management.</p>
<p>It doesn't even require too much effort. Keep a list of the most important things you accomplish every week, and send small reports at the end of the week listing what you accomplished. You don't need to generate a fancy document: an email with bullet points will do.</p>
<p>It has two important advantages:</p>
<ul>
<li>Management doesn't need to pester you to get an idea of what you are doing at work.</li>
<li>You keep a registry of your accomplishments, which is useful for negotiating raises and other things.</li>
</ul>
<p>Take a proactive stance on the way management evaluates you, one of the biggest mistakes you can make is to outsource that responsibility to people who are already too busy with other things. Management will appreciate it, and so will you.</p>
<h2 id="fighttheimpostersyndrome">Fight the imposter syndrome</h2>
<p>Congratulations!</p>
<p>You got your first software development job. The idea of being interviewed made you feel very anxious, but you studied hard and aced the whole thing. Finally, you arrive at the office on your first day and...</p>
<p>And it's terrifying. Suddenly, you feel like a Jon Snow who knows nothing, and self-doubt starts to creep in. What if they find out I am not that smart? do I really deserve this job? am I a fraud? how long will it take them before they find out I'm a fraud and the horrible mistake they made by hiring me?</p>
<p>The following weeks don't help that much. Perhaps it's a technology you are not that familiar with, or maybe they ask you to work on some dark corner of their massive legacy application. Solving the tasks take you twice (or more) as long as the estimate, and you grow more and more anxious.</p>
<p>Been there, more than once.</p>
<p>It's all normal, the good old imposter syndrome. It's this feeling that you are fake, and that you don't deserve to be there. It will go away after a couple of weeks and you'll start to feel more confident. Ramp-up takes time, and in truth, no one really expects you to be 100% productive from the start. Your employer knows it will take some months before you know what you are doing, so don't punish yourself that hard.</p>
<p>Keep working hard, in no time you will become an important part of the team and your contributions will start to have an impact. We've all felt it, and I guarantee you it will go away. So keep up the good work!</p>
<h2 id="ohbutialsoknewallthesethings">Oh but I also knew all these things.</h2>
<p>It's ok, maybe in the next article you'll find something you didn't know yet.</p>
<p>Thank you for reading, I hope you learned one or two new things or at least got something new to think about.</p>
<h2 id="whattodonext">What to do next:</h2>
<ul>
<li>Share this article with friends and colleagues. Thank you for helping me reach people who might find this information useful.</li>
<li>Read the <a href="https://www.brainstobytes.com/advice-for-new-developers-or-things-i-wish-i-had-known-when-i-started-programming-part-5/">next article in the series</a>.</li>
<li>Chad Fowler elaborates more on these topics and offers some really good advice in The Passionate Programmer. This and other very helpful books are in the <a href="https://www.brainstobytes.com/recommended-books/">recommended reading list</a>.</li>
<li>Send me an email with questions, comments or suggestions (it's in the <a href="https://www.brainstobytes.com/about">About Me page</a>). Come on, don't be shy!</li>
</ul>
<!--kg-card-end: markdown-->
					</div></div>]]>
            </description>
            <link>https://www.brainstobytes.com/advice-for-new-developers-or-things-i-wish-i-had-known-when-i-started-programming-part-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23711463</guid>
            <pubDate>Thu, 02 Jul 2020 09:29:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Introduction to GraphQL]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23711333">thread link</a>) | @oczek
<br/>
July 2, 2020 | https://blog.graphqleditor.com/introduction-to-graphql/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/introduction-to-graphql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>GraphQL is a new approach</strong> for building an API that aims to get the better of two basic <strong>RESTful APIs limitations</strong> which are data filters &amp; relationships. These two classic REST flaws force REST users to always get the full payload in response &amp; hit multiple data sources separately.</p>
<h2>What is GraphQL</h2>
<p><strong>GraphQL is a data query and manipulation language</strong> for APIs created and open-source by Facebook to solve the problem of unoptimized data flow in their mobile app. In general, GraphQL is a syntax that describing the way of requesting data from the server. The main difference comparing Graph QL to traditional REST API is that the response format is described in the query and defined by the client rather than the server. Another important thing about GraphQL is that it is language agnostic.</p>
<h2>Basic structure</h2>
<p>The core notion of using GraphQL is a <em>schema</em>.  Designing a schema is one of the first steps in the development process, casting a shadow over the rest of the project. A carefully planned Graph QL schema is the core of a well-designed and secure product. GraphQL Schema is a center-piece of any Graph QL project and it strictly defines its structure &amp; regulates how the data can be accessed.</p>
<h5>GraphQL Queries &amp; Mutations</h5>
<p>There are two basic types of GrahQL operations which are GraphQL Queries &amp; GraphQL Mutations:</p>
<ul>
<li><em>GraphQL Queries</em> - query allows you to read or fetch data from the server-side,</li>
<li><em>GraphQL Mutations</em> - mutations are used to write or post values.</li>
</ul>
<p><span>
      <a href="https://blog.graphqleditor.com/static/fdd547ba79c689cf129b63fea7f8192c/00d43/graphql_query_response.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="GraphQL Query &amp; Response" title="GraphQL Query &amp; Response" src="https://blog.graphqleditor.com/static/fdd547ba79c689cf129b63fea7f8192c/fcda8/graphql_query_response.png" srcset="https://blog.graphqleditor.com/static/fdd547ba79c689cf129b63fea7f8192c/12f09/graphql_query_response.png 148w,
https://blog.graphqleditor.com/static/fdd547ba79c689cf129b63fea7f8192c/e4a3f/graphql_query_response.png 295w,
https://blog.graphqleditor.com/static/fdd547ba79c689cf129b63fea7f8192c/fcda8/graphql_query_response.png 590w,
https://blog.graphqleditor.com/static/fdd547ba79c689cf129b63fea7f8192c/efc66/graphql_query_response.png 885w,
https://blog.graphqleditor.com/static/fdd547ba79c689cf129b63fea7f8192c/00d43/graphql_query_response.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>The performed operations have a form of a string that a GraphQL server can parse and respond to with requested data in a specific format i.e JSON.</p>
<h5>GraphQL Resolvers</h5>
<p>In order to understand what we are querying for the GraphQL server needs to have a defined set of functions/rules that our server would use to generate the response. These functions are called GraphQL Resolvers and they are responsible for handling our queries.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/4928db79f81281efbda8c410cf88a0cf/6f278/graphql_resolvers.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Basic GraphQL resolver function" title="Basic GraphQL resolver function" src="https://blog.graphqleditor.com/static/4928db79f81281efbda8c410cf88a0cf/fcda8/graphql_resolvers.png" srcset="https://blog.graphqleditor.com/static/4928db79f81281efbda8c410cf88a0cf/12f09/graphql_resolvers.png 148w,
https://blog.graphqleditor.com/static/4928db79f81281efbda8c410cf88a0cf/e4a3f/graphql_resolvers.png 295w,
https://blog.graphqleditor.com/static/4928db79f81281efbda8c410cf88a0cf/fcda8/graphql_resolvers.png 590w,
https://blog.graphqleditor.com/static/4928db79f81281efbda8c410cf88a0cf/efc66/graphql_resolvers.png 885w,
https://blog.graphqleditor.com/static/4928db79f81281efbda8c410cf88a0cf/c83ae/graphql_resolvers.png 1180w,
https://blog.graphqleditor.com/static/4928db79f81281efbda8c410cf88a0cf/6f278/graphql_resolvers.png 1488w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h2>GraphQL vs REST</h2>
<p>Imagine we want to retrieve posts from a company blog using RESTful API. First, we need to <code>GET api/posts</code>, but posts have other data like authors so we need to call REST API again to get the details of the posts i.e. authors ending up with two server requests instead of one, and as you continue to scale, you may have even more requests to different endpoints in order to fetch all the needed data. </p>
<p>The performance drop, especially on slow cellular connections,  was the main problem Facebook engineers observed, and the urge to find its solution was a substructure for GraphQL. In GraphQL API we have a single endpoint being able to process complex requests. You query the GraphQL server for specific data and it will respond with what was requested, which results in fewer bits transferred over the wire.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/e5c684bc3f2a7b5729d2b9b4ecb36514/00d43/graphql_vs_rest.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="GraphQL vs REST the main difference" title="GraphQL vs REST the main difference" src="https://blog.graphqleditor.com/static/e5c684bc3f2a7b5729d2b9b4ecb36514/fcda8/graphql_vs_rest.png" srcset="https://blog.graphqleditor.com/static/e5c684bc3f2a7b5729d2b9b4ecb36514/12f09/graphql_vs_rest.png 148w,
https://blog.graphqleditor.com/static/e5c684bc3f2a7b5729d2b9b4ecb36514/e4a3f/graphql_vs_rest.png 295w,
https://blog.graphqleditor.com/static/e5c684bc3f2a7b5729d2b9b4ecb36514/fcda8/graphql_vs_rest.png 590w,
https://blog.graphqleditor.com/static/e5c684bc3f2a7b5729d2b9b4ecb36514/efc66/graphql_vs_rest.png 885w,
https://blog.graphqleditor.com/static/e5c684bc3f2a7b5729d2b9b4ecb36514/00d43/graphql_vs_rest.png 1000w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h2>Learn GraphQL</h2>
<p>As you can see GraphQL is a very interesting concept. In the past couple of years, it gained a lot of traction and became a skill much appreciated and often required in job offers. If you are interested in deepening your knowledge of GraphQL there are plenty of neat resources you can learn from. </p>
<h5>Knowlege base</h5>
<ol>
<li><a href="https://graphql.org/learn/">GrapQL Official Documentation</a> is the best place to start your GraphQL learning.</li>
<li><a href="https://graphqlweekly.com/">GraphQL Weekly</a> is a newsletter with GraphQL tutorials, news, and everything related to GraphQL.</li>
<li><a href="https://www.howtographql.com/">How to GraphQL</a> is a website that will explain to you in detail what is GraphQL and
guide your steps from GraphQL newbie to releasing your production GraphQL project.</li>
</ol>
<p><a href="https://graphqleditor.com/"><img src="https://blog.graphqleditor.com/cd11e751a68e1e57ef406525c71032b1/graphql_docs.gif" alt="static GraphQL docs generated by GraphQL Editor"></a></p>
<h3>GraphQL Tools</h3>
<ol>
<li><a href="https://graphcms.com/">GraphCMS</a> a tool that allows you to build a hosted GraphQL backend for your web project along with tools to manage its content.</li>
<li>
<p><a href="https://graphqleditor.com/">GraphQL Editor</a> is a graphic playground for GraphQL allowing you to build &amp; manage your graphql schema faster giving you a set of GraphQL tools to:</p>
<ul>
<li>bulletproof GraphQL IDE (error handling, type validation),</li>
<li>generate static GraphQL docs,</li>
<li>preview GraphQL queries with a Live JAMStack Engine &amp; Mock Backend.</li>
</ul>
</li>
<li><a href="https://launchpad.graphql.com/new">Dgraph</a> is a native GraphQL database to help you build apps faster.</li>
<li><a href="https://hasura.io/">Hasura</a> makes your PostgreSQL database instantly available over GraphQL API.</li>
<li><a href="https://www.apollographql.com/">Apollo</a> a platform that allows you to combine databases, different APIs, and microservices into a single data source that you can query using GraphQL.</li>
</ol></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/introduction-to-graphql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23711333</guid>
            <pubDate>Thu, 02 Jul 2020 09:03:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bringing modern process management to the desktop]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23710974">thread link</a>) | @thereyougo
<br/>
July 2, 2020 | http://blog.davidedmundson.co.uk/blog/modern-process-management-on-the-desktop/ | <a href="https://web.archive.org/web/*/http://blog.davidedmundson.co.uk/blog/modern-process-management-on-the-desktop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-240">
	
	<!-- .entry-header -->

	<div>
		<p>A desktop environment's sole role is to connect users to their applications. This includes everything from launching apps to actually displaying apps but also managing them and making sure they run fairly. Everyone is familiar the concept of a "Task manager" (like ksysguard), but over time they haven't kept up with the way applications are being developed or the latest developments from Linux.</p>

<h2>Managing running processes</h2>
<p>There used to be a time where one PID == one "application". The kwrite process represents Kwrite, the firefox process represents Firefox, easy. but this has changed. To pick an extreme example:<br>
<strong>Discord in a flatpak is 13 processes!</strong></p>
<p>It basically renders our task manager's process view unusable. All the names are random gibberish, trying to kill the application or setting nice levels becomes a guessing game.  Parent trees can help, but they only get you so far.</p>
<p>It's unusable for me, it's probably unusable for any user and gets in the way of feeling in control of your computer.</p>
<p>We need some metadata.</p>
<h2>Fair resource distribution</h2>
<p>As mentioned above discord in a flatpak is 13 processes. Krita is one process.</p>
<ul>
<li>One will be straining the CPU because it is a highly sophisticated application doing highly complicated graphic operations</li>
<li>One will be straining the CPU because it's written in electron</li>
</ul>
<p>To a kernel scheduler all it would see are 14 opaque processes. It has no knowledge that they are grouped as two different things. It won't be able to come up with something that's fair.</p>
<p>We need some metadata.</p>
<p>(caveat: Obviously most proceses are idling, and I've ignored threads for the purposes of making a point, don't write about it)</p>
<h2>It's hard to map things</h2>
<p>Currently the only metadata of the "application" is on a window.  To show a user friendly name and icon in ksysguard (or any other system monitor) we have to fetch a list of all processes, fetch a list of all windows and perform a mashup. Coming up with arbitrary heuristics for handling parent PIDs which is unstable and messy.</p>
<p>To give some different real world examples:</p>
<ul>
<li>In plasma's task manager we show an audio indicator next to the relevant window, we do this by matching PIDs of what's playing audio to the PID of a window. Easy for the simple case... however as soon as we go multi-process we have to track the parent PID, and each "fix" just alternates between one bug and another.</li>
<li>With PID namespaces apps can't correctly report client PIDs anymore.</li>
<li>We lose information on what "app" we've spawned. We have bug reports where people have two different taskmanager entries for "Firefox" and "Firefox (nightly)" however once the process is spawned that information is lost - the application reports itself as one consistent name and our taskbar gets confused.</li>
</ul>
<p>We need some metadata.</p>

<h2>This is a solved problem!</h2>
<p>A modern sysadmin doesn't deal in processes, but cgroups. The cgroup manager (which will be typically systemd) spawns each service as one cgroup. It uses cgroups to know what's running, the kernel can see what things belong together. </p>
<p>On the desktop flatpaks will spawn themselves in cgroups so that they can use the relevant namespace features.</p>
<p>You're probably already using cgroups. As part of a <a href="https://systemd.io/DESKTOP_ENVIRONMENTS">cross-desktop effort</a> we want to bring cgroups to the entire desktop.</p>
<h2>Example</h2>
<p>Before and after of our system monitor<br>
<a href="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/12/old1.png"><img src="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/12/old1.png" alt=""></a></p>
<p><a href="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/12/ksysguardqml_apps.png"><img src="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/12/ksysguardqml_apps-1024x772.png" alt=""></a></p>
<p>Ultimately the same data but way easier to read..</p>

<p>Another key part of cgroup usage is the concept of slices. Cgroups are based on a heirachical structure, with slices as logical places to split resource usage. We don't adjust resources globally, we adjust resources within our slice, which then provides information to the scheduler.</p>
<p><a href="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/12/treepie.png"><img src="http://blog.davidedmundson.co.uk/wp-content/uploads/2020/12/treepie.png" alt=""></a></p>
<p>Conceptually you can imagine that we just adjust resources within our level of a tree. Then the kernel magically takes care of the rest.</p>
<p>More information can be found on slices in this excellent series <a href="https://www.redhat.com/en/blog/world-domination-cgroups-part-2-turning-knobs"> World domination with cgroups</a>.</p>
<h2>Default slices</h2>
<p>This means we can set up some predefined slices. Within the relevant user slice this will consist shared of</p>
<ul>
<li>applications</li>
<li>the system (kwin/mutter, plasmashell)</li>
<li>background services (baloo, tracker)</li>
</ul>
<p>Each of these slices can be given some default prioritisations and OOM settings out of the box.</p>
<h2>Dynamic resource shifting</h2>
<p>Now that we are using slices, and only adjusting our relative weight within the slice, we can shift resource priority to the application owning the focused window.</p>
<p>This only has any effect if your system is running at full steam from mulitple sources at once, but it can provide a slicker response at no drawback.</p>
<h2>Why slice, doesn't nice suffice?</h2>
<p>Nice is a single value, global across the entire system. Because of this user processes can only be lowered, but never raised to avoid messing with the system.  With slices we're only adjusting relative weight compared to services within our slice. So it's safe to give the user full control within their slice. Any adjustments to an application, won't impact system services or other users.</p>
<p>It also doesn't conflict with nice values set by the application explicitly. If we set kdevelop to have greater CPU weight, clang won't suddenly take over the whole computer when compiling.</p>

<h2>CGroup extra features</h2>
<p>CGroup's come with a lot of new features that aren't available on a per-process level. </p>
<p>We can:</p>
<ul>
<li>Set limits so that a CPU can't use more than N% </li>
<li>We can gracefully close processes on logout</li>
<li>We can disable networking</li>
<li>We can set memory limits</li>
<li>We can prevent forkbombs</li>
<li>We can provide hints to the OOM killer not just with a weight but with expected ranges that should be considered normal</li>
<li>We can freeze groups of processes (which will be useful for Plasma mobile)<br>
... </li>
</ul>
<p>All of this is easy to add for a user / system administrator. Using drop in's one can just add a .service file [example file link] to ~/.config/systemd/user.control/app-firefox@.service and manipulate any of these.</p>
<p>[caveat, some of those features works for applications created as new transient services, not the lite version using scopes that's currently merged in KDE/Gnome - maybe worth mentioning]</p>

<p>Plasma 5.19 and recent Gnome now spawn applications into respective cgroups, but we're not yet surfacing the results that we can get from this.</p>
<p>For the KDE devs providing the metadata is easy.</p>
<p>If spawning a new application from an existing application be sure to use either <a href="https://api.kde.org/frameworks/kio/html/classKIO_1_1ApplicationLauncherJob.html"><code>ApplicationLauncherJob</code></a> or <a href="https://api.kde.org/frameworks/kio/html/classKIO_1_1CommandLauncherJob.html"><code>CommandLauncherJob</code></a> and set the respective service. Everything else is then handled automagically. You should be using these classes anyway for spawning new services.</p>
<p>For users, you can spawn an application with either <code><code>kstart5 --application foo.desktop"</code></code></p>
<p>That change to the launching is relatively tiny, but getting to this point in Plasma wasn't easy - there were a lot of edge cases that messed up the grouping correctly.</p>
<ul>
<li>kinit, our zygote process really meddled with keeping things grouped correctly</li>
<li>drkonqi, our crash handler and application restarter</li>
<li>dbus activation has no knowledge of the associated .desktop file if an application is DBus activated (such as spectacle our screenshot tool)</li>
<li>and many many more papercuts throughout of different launches</li>
</ul>
<p>Also to fully capitalise on slices we need to move all our background processes into managed services and slices. This is worthy of another (equally lengthy) blog post.</p>
<h2>How you can help?</h2>
<p>It's been a battle to find these edge cases.<br>
Whilst running your system, please run systemd-cgls and point out any applications (not background services yet) that are not in their appropriate cgroup.</p>

<p>(e.g BSD users)</p>
<p>As we're just adding metadata, everything used now will continue to work exactly as it does now. All existing tools work exactly the same. Within our task manager we still will keep a process view (it's still useful regardless) and we won't put in any code that relies on the cgroup metadata present. We'll keep the existing heuristics for matching windows with external events, cgroup metadata would just be a strongly influence factor in that. Things won't get worse, but we won't be able to capitalise on the new features discussed here, </p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>http://blog.davidedmundson.co.uk/blog/modern-process-management-on-the-desktop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710974</guid>
            <pubDate>Thu, 02 Jul 2020 08:00:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ikey Doherty Is Making a New Distro, Serpent Linux]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23710908">thread link</a>) | @vital
<br/>
July 2, 2020 | https://www.serpentos.com/about/ | <a href="https://web.archive.org/web/*/https://www.serpentos.com/about/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <article>
            <p>Serpent OS is (or at least, will be) a Linux distribution with notably different goals
from the mainstream offering. We‚Äôre in the process of establishing the project, with
development properly starting towards the end of July.</p>
<h4 id="naming">Naming</h4>
<p>Eventually our plan is to rebrand as ‚ÄòSerpent Linux*‚Äô - however we will first need to
complete some early donkey work and apply for a sublicense to use the name. As explained
below, this is <em>not</em> Serpent ‚ÄòGNU/Linux‚Äô as the distribution will not be dependent on
a GNU toolchain or runtime. For those who are curious, we‚Äôre working with an artist to
choose an appropriate logo for the project.</p>
<h4 id="aims">Aims</h4>
<p>The vast majority of Linux distributions have highly similar goals, and can be best
described using these common industry buzzwords:</p>
<pre><code>Modern, lightweight, privacy oriented/respecting, user-friendly desktop
</code></pre>
<p>We‚Äôre focused on building a Linux distribution that serves our own needs.
Chiefly, a Linux distribution for people who want to use Linux, not a ‚ÄúLinux-based-OS‚Äù
focusing on interoptability with macOS* + Windows*.</p>
<p>In a nut shell, this is <strong>not</strong> ‚ÄúLinux for the masses‚Äù. This is a project setting out to
use Linux as Linux should be used. This will in turn help us to build a significantly
advanced Linux distribution that is both modular and optimised for modern machines.</p>
<h4 id="a-truly-modern-linux-distribution">A Truly Modern Linux Distribution</h4>
<p>As we‚Äôre taking a distro-first, compatibility-later approach, our design decisions
will allow us to take some bold steps. We‚Äôll also be able to incorporate all of the
more sensible design improvements in Linux distribution design over the last decade or
so:</p>
<ul>
<li>No more usrbin split</li>
<li>100% clang-built throughout (including kernel)</li>
<li>musl as libc, relying on compiler optimisations instead of inline asm</li>
<li><code>libc++</code> instead of <code>libstdc++</code></li>
<li>LLVM‚Äôs binutils variants (<code>lld</code>, <code>as</code>, etc.)</li>
<li>Mixed source/binary distribution</li>
<li>Moving away from <code>x86_64-generic</code> baseline to newer CPUs, including Intel and AMD specific optimisations</li>
<li>Capability based subscriptions in package manager (Hardware/ user choice / etc)</li>
<li><code>UEFI</code> only. No more legacy boot.</li>
<li>Completely open source, down to the bootstrap / rebuild scripts</li>
<li>Seriously optimised for serious workloads.</li>
<li>Third party applications reliant on containers only. No compat-hacks</li>
<li>Wayland-only. X11 compatibility via containers will be investigated</li>
<li>Fully stateless with management tools and upstreaming of patches</li>
<li>Lots, lots more. We‚Äôll blog about it.</li>
</ul>
<h4 id="opinionated-by-default">Opinionated By Default</h4>
<p>A recurring theme that holds back the development of world-class Linux, is high tolerance
for those holding Linux back. A perfect example is NVIDIA* and their lack of support for
accelerated Wayland support on their GPUs. Consequently, our project won‚Äôt tolerate such
decisions and will instead blacklist the NVIDIA proprietary drivers from the distribution.</p>
<p>There are other examples that will emerge over time, and will become quite clear.</p>
<p>The time for Linux distributions giving in, with thousands of man hours wasted working around
negative actors, had come to an end.</p>

<p>We will only accept community involvement via our IRC channel: <code>#serpentOS</code> on Freenode.
We will not operate a public bug tracker or forums. Once we are past out initial bootstrap
phase we will set up an email address to help reporting security issues to the team, and
we will of course release security notices.</p>
<p>In terms of feature requests, these will be largely at the discretion of core contributors.
When a company has been formed to house this project, we‚Äôre happy to hash out an SLA for
required works.</p>
<h4 id="timescale">Timescale</h4>
<p>It may seem incredibly odd launching a website before there is a distro to show off, however,
it became very apparent that the cat would be out of the bag, so we wanted to be prepared.</p>
<p>Currently, the Founder is in the midst of relocating to the Republic of Ireland. Once complete
we‚Äôll move to stage2 of our bootstrap process and begin working on the tooling needed for the
base development.</p>

            
        </article>
    </div>
</div></div>]]>
            </description>
            <link>https://www.serpentos.com/about/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710908</guid>
            <pubDate>Thu, 02 Jul 2020 07:46:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixing Rust's test suite on RISC-V]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23710907">thread link</a>) | @lukastyrychtr
<br/>
July 2, 2020 | https://www.codethink.co.uk/articles/2020/fixing-rusts-test-suite-on-risc-v/ | <a href="https://web.archive.org/web/*/https://www.codethink.co.uk/articles/2020/fixing-rusts-test-suite-on-risc-v/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <div>
          <p><img src="https://www.codethink.co.uk/theme/images/softwarebug.jpg" alt="Binary data">
          </p>
          <p>My
<a href="https://www.codethink.co.uk/articles/2020/improving-risc-v-linux-support-in-rust/">previous blog post</a>
introduced my work to improve <a href="https://www.rust-lang.org/">Rust's</a> support for
<a href="https://riscv.org/">RISC-V</a> Linux systems. Since then I fixed a couple of
interesting compiler bugs. This blog post is more technical - describing these
bugs and explaining some <code>rustc</code> internals along the way. I conclude by
reporting on movement in the broader Rust community regarding RISC-V. I
assumed that the reader is comfortable with programming terminology. This blog
post contains Rust code samples but the reader is not expected to be fluent in
Rust.</p>
<h2>Hanging Tests</h2>
<p>In the last blog post I mentioned an issue where some <code>rustc</code> tests would
hang indefinitely. While I was tracking down the problem, the upstream
Rust project
<a href="https://github.com/rust-lang/rust/pull/67759">upgraded from LLVM 9 to LLVM 10</a>,
which fixed the hanging tests. I did not look into this issue
further.</p>
<h3>What is LLVM anyway?</h3>
<p>Modern compilers do not translate directly from source code into machine code.
Source code is intended to be convenient for humans to read; but it often is not
convenient for a compiler to reason about. Instead, compilers transform source
code through one (or more) intermediate representations on its way to becoming
machine code. <code>rustc</code> compiles Rust source through intermediate
representations into LLVM Intermediate Representation<a href="#first">*</a> (LLVM IR).
LLVM then runs optimisation passes on the LLVM IR and finally generates machine
code for the chosen architecture.</p>
<p>I think of LLVM IR as an elaborated machine-independent<a href="#second">**</a>
typed assembly language with unlimited registers. See this LLVM IR for a function
to add integers:</p>
<p><code>add.rs</code></p>
<div><pre><span></span><span>pub</span><span> </span><span>fn</span> <span>add</span><span>(</span><span>x</span>: <span>i32</span><span>,</span><span> </span><span>y</span>: <span>i32</span><span>)</span><span> </span>-&gt; <span>i32</span> <span>{</span><span></span>
<span>    </span><span>x</span><span> </span><span>+</span><span> </span><span>y</span><span></span>
<span>}</span><span></span>
</pre></div>


<p><code>rustc --crate-type lib -O add.rs --emit llvm-ir</code></p>
<div><pre><span></span>; ModuleID = 'add.3a1fbbbh-cgu.0'
source_filename = "add.3a1fbbbh-cgu.0"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; add::add
; Function Attrs: norecurse nounwind nonlazybind readnone uwtable
define i32 @_ZN3add3add17h7cc3d194e9d7e4cdE(i32 %x, i32 %y) unnamed_addr #0 {
start:
  %0 = add i32 %y, %x
  ret i32 %0
}

attributes #0 = { norecurse nounwind nonlazybind readnone uwtable "probe-stack"="__rust_probestack" "target-cpu"="x86-64" }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 7, !"PIC Level", i32 2}
!1 = !{i32 2, !"RtLibUseGOT", i32 1}
</pre></div>


<p>In LLVM IR, lines starting with <code>;</code> are comments. <code>target datalayout</code> and
<code>target triple</code> tell LLVM what architecture it should generate code for.</p>
<p>Next is the function definition. In Rust, the function name is <code>add::add</code>;
but the compiler mangles the name to <code>_ZN3add3add17h7cc3d194e9d7e4cdE</code>.
Then <code>define i32 @foo(i32 %x, i32 %y)</code> means <em>"define a function called
<code>foo</code> which takes two 32-bit signed integer (<code>i32</code>) arguments and returns an
<code>i32</code>"</em>. Inside the function, a <code>start:</code> label begins the block;
then <code>%0 = add i32 %y, %x</code> performs signed 32-bit addition on <code>x</code> and <code>y</code>
and puts the result in a variable automatically named <code>0</code>. Finally, <code>ret i32 %0</code>
returns the value of <code>0</code> as an <code>i32</code>.</p>
<p>The <code>attributes #0</code> line provides extra annotations for all functions tagged
with <code>#0</code> (such as <code>add::add</code>). The annotations give hints for LLVM optimisation
passes.</p>
<p>In theory, to support a new target architecture <code>rustc</code> only needs to know how to
tell LLVM that it should generate code for that architecture. <code>rustc</code> can then
generate LLVM IR as usual and LLVM will handle everything specific to the
architecture. For example, see the tiny
<a href="https://github.com/rust-lang/rust/pull/66661">PR</a> which initially added the
RISC-V Linux target.</p>
<p>In practice, <code>rustc</code> also needs to know how to conform to the ABI for the target
so that the generated code is interoperable with other programming languages. The
RISC-V ABI was added separately.</p>
<p><a name="first">*</a> <em>As well as LLVM, <code>rustc</code> also has an experimental
<a href="https://github.com/bjorn3/rustc_codegen_cranelift">cranelift backend</a>.</em></p>
<p><a name="second">**</a> <em>LLVM IR can be ABI specific but is not machine specific.</em></p>
<h2>Code generation Test Failure</h2>
<p>Other than fixing the hanging <code>ui</code> tests, LLVM 10 also broke code generation
tests for RISC-V. In LLVM 9 IR, function
arguments weren't always named but
<a href="https://github.com/llvm/llvm-project/commit/a009a60a917bc30940422bcef73f8270566d78db">in LLVM 10 they are</a>
. This change broke <code>rustc</code> code generation tests which look for specific strings
in the LLVM IR output by <code>rustc</code>.</p>
<p>After narrowing this test failure down to the LLVM 10 upgrade, I found the
relevant change by looking at <code>clang</code> (which also uses LLVM) tests for the RISC-V
ABI. The
<a href="https://github.com/rust-lang/rust/commit/c872dcf956e541315985ee5fdc592907c20df8ec">fix</a>
was as simple as copying the clang test changes and adapting them for <code>rustc</code>'s
tests.</p>
<h2>UI Tests</h2>
<p>The <code>ui</code> tests for <code>rustc</code> check all user facing aspects of the compiler. Some of
these tests check that <code>rustc</code> displays the correct error messages when compiling
erroneous source.</p>
<p>There was a bug highlighted by some of these tests on RISC-V: <code>rustc</code> displays
the correct errors but in the wrong order! To debug this I used
<code>-Z treat-err-as-bug=n</code> to cause <code>rustc</code> to panic on the <code>n</code>th error. The panic
backtrace shows where the error is generated from. In this case, the miss-ordered
errors came from
<a href="https://github.com/rust-lang/rust/blob/master/src/librustc_resolve/late.rs#L1287"><code>src/librustc_resolve/late.rs</code></a>:</p>
<div><pre><span></span><span>/// Checks that all of the arms in an or-pattern have exactly the</span>
<span>/// same set of bindings, with the same binding modes for each.</span>
<span>fn</span> <span>check_consistent_bindings</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>,</span><span> </span><span>pats</span>: <span>&amp;</span><span>[</span><span>P</span><span>&lt;</span><span>Pat</span><span>&gt;</span><span>])</span><span> </span>-&gt; <span>Vec</span><span>&lt;</span><span>BindingMap</span><span>&gt;</span><span> </span><span>{</span><span></span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>missing_vars</span><span> </span><span>=</span><span> </span><span>FxHashMap</span>::<span>default</span><span>();</span><span></span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>inconsistent_vars</span><span> </span><span>=</span><span> </span><span>FxHashMap</span>::<span>default</span><span>();</span><span></span>

<span>    </span><span>// 1) Compute the binding maps of all arms.</span>
<span>[...]</span><span></span>

<span>    </span><span>// 2) Record any missing bindings or binding mode inconsistencies.</span>
<span>[...]</span><span></span>

<span>    </span><span>// 3) Report all missing variables we found.</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>missing_vars</span><span> </span><span>=</span><span> </span><span>missing_vars</span><span>.</span><span>iter_mut</span><span>().</span><span>collect</span>::<span>&lt;</span><span>Vec</span><span>&lt;</span><span>_</span><span>&gt;&gt;</span><span>();</span><span></span>
<span>    </span><span>missing_vars</span><span>.</span><span>sort</span><span>();</span><span></span>

<span>    </span><span>for</span><span> </span><span>(</span><span>name</span><span>,</span><span> </span><span>mut</span><span> </span><span>v</span><span>)</span><span> </span><span>in</span><span> </span><span>missing_vars</span><span> </span><span>{</span><span></span>
<span>        </span><span>if</span><span> </span><span>inconsistent_vars</span><span>.</span><span>contains_key</span><span>(</span><span>name</span><span>)</span><span> </span><span>{</span><span></span>
<span>            </span><span>v</span><span>.</span><span>could_be_path</span><span> </span><span>=</span><span> </span><span>false</span><span>;</span><span></span>
<span>        </span><span>}</span><span></span>
<span>        </span><span>self</span><span>.</span><span>r</span><span>.</span><span>report_error</span><span>(</span><span></span>
<span>            </span><span>*</span><span>v</span><span>.</span><span>origin</span><span>.</span><span>iter</span><span>().</span><span>next</span><span>().</span><span>unwrap</span><span>(),</span><span></span>
<span>            </span><span>ResolutionError</span>::<span>VariableNotBoundInPattern</span><span>(</span><span>v</span><span>),</span><span></span>
<span>        </span><span>);</span><span></span>
<span>    </span><span>}</span><span></span>

<span>[...]</span><span></span>
<span>}</span><span></span>
</pre></div>


<p>In part 3, <code>missing_vars</code> is sorted before the errors are reported so how can
the errors be out of order?</p>
<p>At the time of the sort, <code>missing_vars</code> is a <code>Vec</code>tor of tuples, with each tuple
containing a <code>Symbol</code> and a mutable reference to a <code>BindingError</code>. In Rust this
type is written as <code>Vec&lt;(Symbol, &amp;mut BindingError)&gt;</code>. Rust tuples sort first by
the left-most element (in this case, the <code>Symbol</code>). To explain <code>Symbol</code> ordering
following a sort, first we must look at how strings are used within <code>rustc</code>.</p>
<h3>String Interning</h3>
<p>Source code often contains duplicates of the same string token. For example,
in the above listing of <code>check_consistent_bindings</code> the string <code>"FxHashMap"</code>
occurs twice and <code>"missing_vars"</code> occurs five times. Allocating separate strings
for each of these occurrences would waste memory and time. Instead, <code>rustc</code>
allocates each string once and uses indices to refer to the full string each
time it is needed. These indices are 32-bit unsigned integers (in a wrapper
type) and so can be copied and compared efficiently. The process of allocating
a string only once and using references to that string is called "interning".</p>
<p><a href="https://github.com/rust-lang/rust/blob/master/src/librustc_span/symbol.rs#L1041"><code>Symbol</code></a>
is the type representing an interned string:</p>
<div><pre><span></span><span>#[derive(Clone, Copy, PartialEq, ParitialOrd, Hash)]</span><span></span>
<span>pub</span><span> </span><span>struct</span> <span>Symbol</span><span>(</span><span>SymbolIndex</span><span>);</span><span></span>
</pre></div>


<p>Here we can see that the implementation of <code>PartialOrd</code> for <code>Symbol</code> (which
provides the <code>Ord</code>ering of <code>Vec::sort</code> above) derives from the index's <code>Ord</code>ering.
But where does the index come from?</p>
<div><pre><span></span><span>// The `&amp;'static str`s in this type actually point into the arena.</span>
<span>#[derive(Default)]</span><span></span>
<span>pub</span><span> </span><span>struct</span> <span>Interner</span><span> </span><span>{</span><span></span>
<span>    </span><span>arena</span>: <span>DroplessArena</span><span>,</span><span></span>
<span>    </span><span>names</span>: <span>FxHashMap</span><span>&lt;&amp;</span><span>'static</span><span> </span><span>str</span><span>,</span><span> </span><span>Symbol</span><span>&gt;</span><span>,</span><span></span>
<span>    </span><span>strings</span>: <span>Vec</span><span>&lt;&amp;</span><span>'static</span><span> </span><span>str</span><span>&gt;</span><span>,</span><span></span>
<span>}</span><span></span>

<span>impl</span><span> </span><span>Interner</span><span> </span><span>{</span><span></span>
<span>    </span><span>#[inline]</span><span></span>
<span>    </span><span>pub</span><span> </span><span>fn</span> <span>intern</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>,</span><span> </span><span>string</span>: <span>&amp;</span><span>str</span><span>)</span><span> </span>-&gt; <span>Symbol</span><span> </span><span>{</span><span></span>
<span>        </span><span>if</span><span> </span><span>let</span><span> </span><span>Some</span><span>(</span><span>&amp;</span><span>name</span><span>)</span><span> </span><span>=</span><span> </span><span>self</span><span>.</span><span>names</span><span>.</span><span>get</span><span>(</span><span>string</span><span>)</span><span> </span><span>{</span><span></span>
<span>            </span><span>return</span><span> </span><span>name</span><span>;</span><span></span>
<span>        </span><span>}</span><span></span>

<span>        </span><span>let</span><span> </span><span>name</span><span> </span><span>=</span><span> </span><span>Symbol</span>::<span>new</span><span>(</span><span>self</span><span>.</span><span>strings</span><span>.</span><span>len</span><span>()</span><span> </span><span>as</span><span> </span><span>u32</span><span>);</span><span></span>

<span>        </span><span>// `from_utf8_unchecked` is safe since we just allocated a `&amp;str` which is known to be</span>
<span>        </span><span>// UTF-8.</span>
<span>        </span><span>let</span><span> </span><span>string</span>: <span>&amp;</span><span>str</span> <span>=</span><span></span>
<span>            </span><span>unsafe</span><span> </span><span>{</span><span> </span><span>str</span>::<span>from_utf8_unchecked</span><span>(</span><span>self</span><span>.</span><span>arena</span><span>.</span><span>alloc_slice</span><span>(</span><span>string</span><span>.</span><span>as_bytes</span><span>()))</span><span> </span><span>};</span><span></span>
<span>        </span><span>// It is safe to extend the arena allocation to `'static` because we only access</span>
<span>        </span><span>// these while the arena is still alive.</span>
<span>        </span><span>let</span><span> </span><span>string</span>: <span>&amp;</span><span>'static</span><span> </span><span>str</span><span> </span><span>=</span><span> </span><span>unsafe</span><span> </span><span>{</span><span> </span><span>&amp;*</span><span>(</span><span>string</span><span> </span><span>as</span><span> </span><span>*</span><span>const</span><span> </span><span>str</span><span>)</span><span> </span><span>};</span><span></span>
<span>        </span><span>self</span><span>.</span><span>strings</span><span>.</span><span>push</span><span>(</span><span>string</span><span>);</span><span></span>
<span>        </span><span>self</span><span>.</span><span>names</span><span>.</span><span>insert</span><span>(</span><span>string</span><span>,</span><span> </span><span>name</span><span>);</span><span></span>
<span>        </span><span>name</span><span></span>
<span>    </span><span>}</span><span></span>
<span>}</span><span></span>

<span>impl</span><span> </span><span>Symbol</span><span> </span><span>{</span><span></span>
<span>    </span><span>const</span><span> </span><span>fn</span> <span>new</span><span>(</span><span>n</span>: <span>u32</span><span>)</span><span> </span>-&gt; <span>Self</span><span> </span><span>{</span><span></span>
<span>        </span><span>Symbol</span><span>(</span><span>SymbolIndex</span>::<span>from_u32</span><span>(</span><span>n</span><span>))</span><span></span>
<span>    </span><span>}</span><span></span>

<span>    </span><span>/// Maps a string to its interned representation.</span>
<span>    </span><span>pub</span><span> </span><span>fn</span> <span>intern</span><span>(</span><span>string</span>: <span>&amp;</span><span>str</span><span>)</span><span> </span>-&gt; <span>Self</span><span> </span><span>{</span><span></span>
<span>        </span><span>with_interner</span><span>(</span><span>|</span><span>interner</span><span>|</span><span> </span><span>interner</span><span>.</span><span>intern</span><span>(</span><span>string</span><span>))</span><span></span>
<span>    </span><span>}</span><span></span>

<span>    </span><span>/// Access the symbol's chars. This is a slowish operation because it</span>
<span>    </span><span>/// requires locking the symbol interner.</span>
<span>    </span><span>pub</span><span> </span><span>fn</span> <span>with</span><span>&lt;</span><span>F</span>: <span>FnOnce</span><span>(</span><span>&amp;</span><span>str</span><span>)</span><span> </span>-&gt; <span>R</span><span>,</span><span> </span><span>R</span><span>&gt;</span><span>(</span><span>self</span><span>,</span><span> </span><span>f</span>: <span>F</span><span>)</span><span> </span>-&gt; <span>R</span><span> </span><span>{</span><span></span>
<span>        </span><span>with_interner</span><span>(</span><span>|</span><span>interner</span><span>|</span><span> </span><span>f</span><span>(</span><span>interner</span><span>.</span><span>get</span><span>(</span><span>self</span><span>)))</span><span></span>
<span>    </span><span>}</span><span></span>
<span>}</span><span></span>
</pre></div>


<p><code>rustc</code> interns strings using <code>Interner::intern</code>, which
returns a <code>Symbol</code>. References to the interned strings are stored in a
<code>Vec</code>tor and the <code>Symbol</code> contains the index of the string reference in that
<code>Vec</code>tor. Therefore, the Symbol can look up its string by indexing into the
<code>strings</code> vector and following the reference (pointer) to the actual string
(which is allocated in the <code>arena</code>).</p>
<p>For example, if the strings <code>"a"</code>, <code>"b"</code> and <code>"c"</code> are interned, then (ignoring
the referencing), the <code>Interner</code>'s <code>Vec</code> will look like <code>["a", "b", "c"]</code>. If
instead we interned <code>"b"</code>, <code>"a"</code>, <code>"b"</code> and <code>"c"</code>; the <code>Vec</code> will look like
<code>["b", "a", "c"]</code> because the second attempt to intern <code>"b"</code> finds that <code>"b"</code> is
already interned and so just returns the index of the existing copy of <code>"b"</code>.
Carrying on with this second example, imagine the following:</p>
<div><pre><span></span><span>let</span><span> </span><span>mischief</span><span> </span><span>=</span><span> </span><span>Symbol</span>::<span>intern</span><span>(</span><span>"b"</span><span>);</span><span></span>
<span>let</span><span> </span><span>a</span><span> </span><span>=</span><span> </span><span>Symbol</span>::<span>intern</span><span>(</span><span>"a"</span><span>);</span><span></span>
<span>let</span><span> </span><span>b</span><span> </span><span>=</span><span> </span><span>Symbol</span>::<span>intern</span><span>(</span><span>"b"</span><span>);</span><span></span>
<span>let</span><span> </span><span>c</span><span> </span><span>=</span><span> </span><span>Symbol</span>::<span>intern</span><span>(</span><span>"c"</span><span>);</span><span></span>

<span>let</span><span> </span><span>mut</span><span> </span><span>v</span><span> </span><span>=</span><span> </span><span>vec</span><span>!</span><span>[</span><span>c</span><span>,</span><span> </span><span>b</span><span>,</span><span> </span><span>a</span><span>];</span><span></span>
<span>v</span><span>.</span><span>sort</span><span>();</span><span></span>
</pre></div>


<p>While we might expect <code>v</code> to end up equal to <code>[a, b, c]</code>, <code>v</code> is actually sorted
to equal <code>[b, a, c]</code> because <code>Symbol</code>s are sorted by their indices not by the
strings they point to. <code>b</code> received the lowest index because it was interned
first. This semantic can be useful because the index ordering is faster than
looking up the full strings and comparing them; and ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.codethink.co.uk/articles/2020/fixing-rusts-test-suite-on-risc-v/">https://www.codethink.co.uk/articles/2020/fixing-rusts-test-suite-on-risc-v/</a></em></p>]]>
            </description>
            <link>https://www.codethink.co.uk/articles/2020/fixing-rusts-test-suite-on-risc-v/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710907</guid>
            <pubDate>Thu, 02 Jul 2020 07:46:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Convolutional Neural Networks]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23710799">thread link</a>) | @advanderveer
<br/>
July 2, 2020 | https://poloclub.github.io/cnn-explainer/ | <a href="https://web.archive.org/web/*/https://poloclub.github.io/cnn-explainer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://poloclub.github.io/cnn-explainer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710799</guid>
            <pubDate>Thu, 02 Jul 2020 07:27:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Indian Gov Bans DuckDuckGo]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23710613">thread link</a>) | @chewdatgenie
<br/>
July 1, 2020 | https://crackerscreed.org/indian-government-bans-duckduckgo-how-to-get-it-back/ | <a href="https://web.archive.org/web/*/https://crackerscreed.org/indian-government-bans-duckduckgo-how-to-get-it-back/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1094">

		<!-- .entry-header -->

		
		<div>

			<div>
				
<figure><img data-attachment-id="1095" data-permalink="https://crackerscreed.org/indian-government-bans-duckduckgo-how-to-get-it-back/duckduckgo/" data-orig-file="https://i0.wp.com/crackerscreed.org/wp-content/uploads/2020/07/duckduckgo.jpg?fit=1050%2C741&amp;ssl=1" data-orig-size="1050,741" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="duckduckgo" data-image-description="" data-medium-file="https://i0.wp.com/crackerscreed.org/wp-content/uploads/2020/07/duckduckgo.jpg?fit=300%2C212&amp;ssl=1" data-large-file="https://i0.wp.com/crackerscreed.org/wp-content/uploads/2020/07/duckduckgo.jpg?fit=756%2C534&amp;ssl=1" src="https://i0.wp.com/crackerscreed.org/wp-content/uploads/2020/07/duckduckgo.jpg?fit=756%2C534&amp;ssl=1" alt="" srcset="https://i0.wp.com/crackerscreed.org/wp-content/uploads/2020/07/duckduckgo.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/crackerscreed.org/wp-content/uploads/2020/07/duckduckgo.jpg?resize=300%2C212&amp;ssl=1 300w, https://i0.wp.com/crackerscreed.org/wp-content/uploads/2020/07/duckduckgo.jpg?resize=1024%2C723&amp;ssl=1 1024w, https://i0.wp.com/crackerscreed.org/wp-content/uploads/2020/07/duckduckgo.jpg?resize=768%2C542&amp;ssl=1 768w, https://i0.wp.com/crackerscreed.org/wp-content/uploads/2020/07/duckduckgo.jpg?resize=200%2C141&amp;ssl=1 200w" sizes="(max-width: 756px) 100vw, 756px"></figure>



<h3><span>What is DuckDuckGo?</span></h3>



<hr>
<p><a href="https://duckduckgo.com/">DuckDuckGo</a> is a search engine similar to Google but, with a major difference ‚Äì It does not track you! In the modern era of internet where the knowledge acquired by the entire humankind is available at your fingertips, the rise of corporate and government-funded digital-tracking has become a major threat to people‚Äôs privacy.</p>
<p>Almost all major search engines including Google, Bing and Yahoo track&nbsp; you. Google most of all!</p>



<h3><span>Why and how much do they track?</span></h3>



<hr>
<p>The reason to why they track is simple ‚Äì Money! Most companies that provide their product without a cost to thier users earn on the data they collected about them. The data collected about your search history, websites visited, time spent on a website, etc. is used to profile you and categorize your interests and then sold to advertisement companies to make the profit. This is the same business model that social media companies like facebook, twitter, etc. use to make money off of your data.</p>
<blockquote>
<p><strong><em>In a world with companies offering free services, the consumer becomes their product!</em></strong></p>
</blockquote>
<p>Google not only logs your search history from its search engine but also tracks your activities on various websites you visit by paying them to run their scripts on the site‚Äôs webpages.</p>



<h3><span>Don‚Äôt believe it?</span></h3>



<hr>
<p>I know it might sound like a conspiracy theory but you‚Äôd be amazed to know how easy it is to verify these claims. Simply install a plugin like uBlock Origin (<a href="https://addons.mozilla.org/en-US/firefox/addon/ublock-origin">For Firefox</a> or <a href="https://chrome.google.com/webstore/detail/ublock-origin/cjpalhdlnbpafiamejdnhcphjbkeiagm?hl=en-US">For Chrome</a>) that lets you see the domains that a website is trying to connect to from your computer and you‚Äôll find that Google‚Äôs and Facebook‚Äôs trackers are all over the internet.</p>
<p>When you visit a website, the website‚Äôs content is downloaded to your device including HTML page, CSS styling and Java Scripts. The websites paid by Google and Facebook send you some additional Java Scripts along with their contents that connect to Google‚Äôs and Facebook‚Äôs servers and send your information to them.</p>
<p>This is also the reason why you see ads similar to your search history all over the internet, specially on websites like YouTube, Facebook, Google, Amazon, etc.</p>



<figure><img data-attachment-id="1099" data-permalink="https://crackerscreed.org/indian-government-bans-duckduckgo-how-to-get-it-back/screenshot-278-1/" data-orig-file="https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?fit=1594%2C666&amp;ssl=1" data-orig-size="1594,666" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot-278-1" data-image-description="" data-medium-file="https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?fit=300%2C125&amp;ssl=1" data-large-file="https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?fit=756%2C316&amp;ssl=1" src="https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?w=756&amp;ssl=1" alt="" srcset="https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?w=1594&amp;ssl=1 1594w, https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?resize=300%2C125&amp;ssl=1 300w, https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?resize=1024%2C428&amp;ssl=1 1024w, https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?resize=768%2C321&amp;ssl=1 768w, https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?resize=1536%2C642&amp;ssl=1 1536w, https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?resize=1250%2C522&amp;ssl=1 1250w, https://i2.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-278-1.png?resize=200%2C84&amp;ssl=1 200w" sizes="(max-width: 756px) 100vw, 756px" data-recalc-dims="1"><figcaption>Screenshot displays Google‚Äôs Javascripts running on Standard Chartered‚Äôs Website </figcaption></figure>



<p>The screenshot above is marked with a box that displays that when I visit Standard Chartered‚Äôs website, a total of 5 domains get information about my presence on that website. Of these 5 domains, the requests to sc.com and www.sc.com were partially blocked (Red Arrow marked 1), gioip-js.com and googletagmanager.com were completely blocked (Red Arrow Marked 2) and maps.googleapis.com were not at all blocked (Red Arrow Marked 3) by uBlock Origin‚Äôs default set of filters. If you‚Äôd look a little to the right of that red box, you‚Äôd notice that despite 7 requests being blocked in total (13% of all requests on that page), the website was still completely functional and that it did not break.</p>



<h3><span>What‚Äôs in it for the government?</span></h3>



<hr>
<p>Frankly, to answer this question is difficult. Sometimes, governments ask these companies to share the data to track their citizens for various reasons. Other times, the governments ask companies like Google to help identify the protestors by disclosing their mobile phone‚Äôs GPS location at the time of protests and as a <em>quid pro quo </em>they kill their competition by passing Laws to ban sites like DuckDuckGo. We can never know these answers for sure as these deals are made behind closed doors.</p>



<h3><span>So, what do I do about DuckDuckGo?</span></h3>



<hr>
<p>Well, fortunately the solution to this problem is extremely simple. You can go to the Menu section of Firefox, select Options, go to the ‚ÄúGeneral‚Äù settings tab, scroll all the way to the bottom and click the ‚ÄúSettings‚Äù button under ‚ÄúNetwork Settings‚Äù.</p>



<figure><img data-attachment-id="1101" data-permalink="https://crackerscreed.org/indian-government-bans-duckduckgo-how-to-get-it-back/screenshot-281/" data-orig-file="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?fit=1600%2C792&amp;ssl=1" data-orig-size="1600,792" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot-281" data-image-description="" data-medium-file="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?fit=300%2C149&amp;ssl=1" data-large-file="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?fit=756%2C374&amp;ssl=1" src="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?w=756&amp;ssl=1" alt="" srcset="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?w=1600&amp;ssl=1 1600w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?resize=300%2C149&amp;ssl=1 300w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?resize=1024%2C507&amp;ssl=1 1024w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?resize=768%2C380&amp;ssl=1 768w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?resize=1536%2C760&amp;ssl=1 1536w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?resize=1250%2C619&amp;ssl=1 1250w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-281.png?resize=200%2C99&amp;ssl=1 200w" sizes="(max-width: 756px) 100vw, 756px" data-recalc-dims="1"><figcaption>First 4 Steps in Firefox</figcaption></figure>



<p>On the menu that pops up, scroll to the bottom and select ‚ÄúEnable DNS Over HTTPS‚Äù and from the dropdown, you can select ‚ÄúNextDNS‚Äù as your ‚ÄúUse Provider‚Äù.</p>



<figure><img data-attachment-id="1102" data-permalink="https://crackerscreed.org/indian-government-bans-duckduckgo-how-to-get-it-back/screenshot-282/" data-orig-file="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?fit=1600%2C761&amp;ssl=1" data-orig-size="1600,761" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot-282" data-image-description="" data-medium-file="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?fit=300%2C143&amp;ssl=1" data-large-file="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?fit=756%2C360&amp;ssl=1" src="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?w=756&amp;ssl=1" alt="" srcset="https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?w=1600&amp;ssl=1 1600w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?resize=300%2C143&amp;ssl=1 300w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?resize=1024%2C487&amp;ssl=1 1024w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?resize=768%2C365&amp;ssl=1 768w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?resize=1536%2C731&amp;ssl=1 1536w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?resize=1250%2C595&amp;ssl=1 1250w, https://i1.wp.com/crackerscreed.org/wp-content/uploads/2020/07/Screenshot-282.png?resize=200%2C95&amp;ssl=1 200w" sizes="(max-width: 756px) 100vw, 756px" data-recalc-dims="1"><figcaption>The Final Destination!</figcaption></figure>



<p>Besides the two options provided by Firefox, you can also find a list of other HTTPS-enabled privacy-oriented DNS services on <a href="https://www.privacytools.io/providers/dns/">PrivacyTools.io ‚Äì DNS</a> page.</p>



<h3><span>How Does This Solution Work?</span></h3>



<hr>
<p>To understand how this solution work, we first need to understand how does the DNS work and <a href="https://crackerscreed.org/understanding-ssl-certificates/">how does SSL certificate work</a>. Once you understand that, you‚Äôd notice the if your DNS queries are sent over HTTPS, they can only be read by the DNS server and not by your ISP‚Äôs firewall. Without reading the your DNS query, they cannot tamper or block its intended response and hence cannot block you from getting its IP address.</p>



<h3><span>Is It A Fool-Proof Solution?</span></h3>



<hr>
<p>The unfortunate answer is No! There are other ways that a government can block a website like IP address based filtering, content based filtering, etc. And even if you bypass these filters and access DuckDuckGo, by no mean you become anonymous over the internet but, switching to an actively-maintained open-sourced browser such as Firefox, installing malware/tracking blocker plugin like uBlock Origin and switching to a privacy-oriented search engine can dramatically reduce your digital footprint. It could be your first step towards a long journey of internet anonymity and digital privacy!</p>

							</div><!-- .entry-content -->

			<!-- .entry-footer -->

			
<!-- #comments -->

		</div>

		<!-- .sidebar -->

	</article></div>]]>
            </description>
            <link>https://crackerscreed.org/indian-government-bans-duckduckgo-how-to-get-it-back/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710613</guid>
            <pubDate>Thu, 02 Jul 2020 06:42:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Accessibility Engineering and Low End Disruption]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23710559">thread link</a>) | @ingve
<br/>
July 1, 2020 | http://www.takingnotes.co/blog/2020/07/01/accessibility-engineering/ | <a href="https://web.archive.org/web/*/http://www.takingnotes.co/blog/2020/07/01/accessibility-engineering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>apple doesn‚Äôt succeed at making their platforms accessible because they care more, they don‚Äôt succeed because they are somehow better at programming</h3>

<p>a capable, thoughtful manager, who is correctly assessing risk vs reward, both qualitatively and quantitatively, who is doing their job well, using all of the experience and skill that brought them to where they are, can, and likely will, decide to ship an app that could be accessible, but is not.</p>

<p>this is not a function of callousness (although they may also be quite callous).</p>

<p>this is not a function of engineering aptitude (plenty of our leading lights have let access fall to the wayside<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> by making solid engineering choices that are completely defensible).</p>

<p>the apple accessibility teams are made up of disciplined, brilliant engineers. they all work incredibly hard on a problem with unimaginable scale. but their brilliance and discipline and hard work, while necessary, are not sufficient.</p>

<p>what matters here, what sets apple apart, is that they figured out how to go last and contain the risk enough to avoid a revolt from other teams or executive leadership. it costs them a lot to do so, has significant, measurable downsides, and requires a significant rethink of what it means to build good software.</p>

<h3>bundles</h3>

<p>some of the code that powers accessibility on apple platforms is just disgusting to look at and to work on.</p>

<p>most of the code that makes apple software accessible lives in what‚Äôs called an accessibility bundle. without diving into the minutia of the thing, bundles are a way to load something akin to a plugin into a cocoa app at runtime if an assistive technology is activated. it involves manipulating the app or framework class hierarchy and using objective-c dynamism to read app state and build up a usable accessibility hierarchy. insert a super class here, read an instance variable there, swizzle in a method and store the state for it in associated objects.<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup></p>

<p>bundles are not a good way to build software by any common measure. they don‚Äôt make you efficient, or your code correct. the performance can get bad. they‚Äôre hard to maintain and involve constant patching to keep them alive. huge chunks of bundle code are thrown away and rewritten multiple times during every major os release.</p>

<p>i found the initial adjustment to working on this code sometimes viscerally upsetting. ‚Äúi can‚Äôt do that!!‚Äù, ‚Äúclearly i should be protecting against‚Ä¶‚Äù, ‚Äúif i do it that way it‚Äôll break when they‚Ä¶‚Äù, etc.</p>

<p>the thing is, critically, if a user never activates an assistive technology like voiceover they wouldn‚Äôt know bundles even exist. many of the managers at apple don‚Äôt know much or care much about accessibility. some of them are borderline hostile to it. the bundles make it possible for the accessibility team to allocate their own resources and set their own priorities with only very limited coordination and fallout contained to people who would benefit most from the upside. they allow the accessibility team to fix the bugs they find, when they find them, with pretty limited opportunities for a manager who‚Äôs next promotion is on the line to get cold feet and pull resources or block fixes.</p>

<p>in the model of low end disruption, we can see bundles as a low end entrant, with a product that seems worse, but that solves an important problem in a way that the mature products, by their nature, can‚Äôt realistically address.</p>

<p>if the job to be done is ‚Äúproduce easy to understand, correct, maintainable code that engineers who care about those things will enjoy working on‚Äù then bundles aren‚Äôt even in the competition.</p>

<p>if the job is ‚Äúmanage your team resources responsibly, keep your bug count low, ship your features on time‚Äù then bundles aren‚Äôt the tool you reach for. why would you load a squirrelly plugin into your own app on purpose?</p>

<p>the chaotic morass of runtime hacks and macros for everything and nearly exclusive dependence on runtime validation<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup> make them not just not good, but almost aggressively bad. but if the job they are hired to do is make apps that aren‚Äôt accessible, they‚Äôre incredible. unparalleled. entirely without peer.</p>

<p>almost all the things a good engineer would do to make bundles less gross would make them worse in unacceptable ways. almost anything a high end product might do to accommodate the kind of autonomy bundles demand would make them unacceptable to their current clients.<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup></p>

<p>apple has a team whose only job is to make things accessible and they have infrastructure that lets that team mostly avoid people who have a different job saying no to them. put those together and you have the most successful accessibility software team (imho) on planet earth.</p>

<h3>the gross stuff isn‚Äôt desirable, but is maybe necessary</h3>

<p>anyone who is steeped in universal design that has made it this far has maybe broken out in hives? please just stick with me, it‚Äôll all come out in the wash.</p>

<ul>
<li>well designed apps that take accessibility into consideration from the beginning are better for everyone.</li>
<li>accessible ramps for getting into buildings are better than those terrible lifts they bolt into the sides of stairs in public buildings.</li>
<li>we all benefit from features in society that originate as accessibility affordances, like curb cuts for wheelchairs, that everyone with a stroller can now take for granted.</li>
</ul>


<p>without question these statements are true.</p>

<p>i don‚Äôt worry too much about saying things that might make people think i‚Äôm a bad engineer or have bad ideas about building software. i do care a lot about not giving people the idea that we should all knock out our accessibility code real quick and sloppy at the end as an afterthought.</p>

<p>my thesis here is that where the effect of failing is very much acute, most of us do not adjust our approach accordingly. likely because we regard assistive technology users as one of many available audiences we may or may not wish to court.</p>

<p>if we ship an app that‚Äôs inaccessible, hey we‚Äôll get around to it, we‚Äôve got a roadmap, hasn‚Äôt bubbled up yet, software takes time. there are so many bugs in our support tracker and ‚Äúdoesn‚Äôt work for blind people‚Äù is just a tiny blip.</p>

<p>of course we should be methodical and plan ahead and build our software in a way that is both accessible and maintainable. we should seek to avoid compromising, but should the need to compromise emerge, the balance should unquestionably be tilted towards gross and unmaintainable code where that is the cost of accessibility. if you could fix that missing label but eww i‚Äôd have to wire up a very clumsy chain of delegates or fire a notification that clearly violates layering, without question, you should do it.<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup></p>

<p>we should be willing to find a blend of cultural and political and technical workarounds in our organizations that acknowledge that code can‚Äôt be allowed to go out the door that isn‚Äôt accessible and that a lot of our ideas about technical excellence and what a good engineering manager does wildly miscalculate the cost of our decisions to ‚Äúdo it right‚Äù.</p>


</div></div>]]>
            </description>
            <link>http://www.takingnotes.co/blog/2020/07/01/accessibility-engineering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710559</guid>
            <pubDate>Thu, 02 Jul 2020 06:27:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adventurist.me: Simple ipfw NAT for bhyve virtual machines and vnet jails]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23710548">thread link</a>) | @rodrigo975
<br/>
July 1, 2020 | https://adventurist.me/posts/00304 | <a href="https://web.archive.org/web/*/https://adventurist.me/posts/00304">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
		<p>Most of the time, I want to do some throw away networking temporally to play
with something or to try something out. I really don't like changing all the
config on a machine just to try something. The FreeBSD documentation leans the
other way first showing you what to edit in rc.conf before maybe mentioning
that actual commands to run. </p>
<p>The ipfw documentation has a different problem. The example in the handbook and
online are both very verbose and very complicated. Because ipfw is normally
configured with a shell script the authors go absolutely wild with all the
features they can.</p>
<p>I had a hard time figuring out ipfw in-kernel NAT from these guides. Instead
here I present the simplest set of commands I could find to set up a NAT and a
little explanation to help you debug when it doesn't work.</p>
<p>This is based on a great email from <a href="https://lists.freebsd.org/pipermail/freebsd-virtualization/2014-October/002998.html">Allan Jude</a> on the
freebsd-virtualization list from 2014 that laid out the basics of this setup. </p>
<h2 id="set-up-overview">Set up Overview</h2>
<p>For testing I want to run virtual machines and vnet jails on my laptop and give
them have access to the internet. I want a throw away NAT setup that is ready
to go quickly.</p>
<p>My laptop connects to my home network (and eventually the internet) over wifi.
The wifi network offers me an address in the 192.168.1.0/24 subnet. On my
laptop I want to have multiple guests. To do this we are going to use ipfw NAT
and a bridge interface. It will look something like this:</p>
<pre><code>         TO INTERNET
          ^
          |
          |
          v
          +-------+  192.168.1.x
+-------------| wlan0 |---------------+
|             +-------+               |
|                 ^                   |
|                 |                   |
|              ipfw nat               |
|                 |                   |
|                 V                   |
|            +---------+              |
| 10.0.4.1   | bridge0 |              |
|            +----+----+              |
|                 ^                   |
|                 | 10.0.4.0/24       |
|      ___________+_______________    |
|      |       |        |        |    |
|      v       v        v        v    |
|  +---+--+ +--+---+ +--+---+ +--+---+|
|  | jail | |  vm  | | jail | | ...  ||
|  +------+ +------+ +------+ +------+|
+-------------- laptop ---------------+
</code></pre><p>The interfaces in the jails (the b half of the epair) and the virtual machines
(the vtnet in the V) won't be visible to ipfw, but will exist in their own
world. To work around this we will use a bridge with the epairs and tap
interfaces.</p>
<h2 id="setting-up-ipfw-nat">Setting up ipfw NAT</h2>
<p>We need to load the kernel modules for ipfw and the ipfw in kernel NAT. ipfw
has the frustrating default (and annoyingly different to ipf and pf) of to
dening all traffic. This default has the great property of locking you out of a
machine you are setting up remotely.</p>
<p>This is control by a sysctl that cannot be changed at run time, but we can
change the default behaviour with kenv before we load the module:</p>
<pre><code># kenv net.inet.ip.fw.default_to_accept=1
</code></pre><p>Now we can safely load ipfw and the in-kernel NAT. </p>
<pre><code># kldload ipfw ipfw_nat
</code></pre><p>ipfw should load enabled, if you are having trouble later on double check that
the firewall is actually enabled.</p>
<pre><code># sysctl net.inet.ip.fw.enable
net.inet.ip.fw.enable: 1
</code></pre><p>When we do NAT we are acting as a gateway between the traffic on the NATd
interface and the real interface. For any packets to be passed we need to
enable forwarding.</p>
<pre><code># sysctl net.inet.ip.forwarding=1
# sysctl net.inet6.ip6.forwarding=1
</code></pre><h2 id="ipfw-rule-set">ipfw rule set</h2>
<p>We need to create an IPFW NAT instance configured with the interface we want to
NAT (wlan0 in this case) and configure rules to pass all traffic from the
bridge through the NAT.</p>
<pre><code># ipfw nat 1 config if wlan0
# ipfw add 101 nat 1 ip from 10.0.4.0/24 to any out via wlan0
# ipfw add 103 nat 1 ip from any to any in via wlan0
</code></pre><p>I like to leave a gap between rules like this so I can insert an ipfw log
command for the eventual case that nothing makes sense and everything is
broken.</p>
<h2 id="set-up-interfaces">set up interfaces</h2>
<p>A bridge is the center of our guest network, we will give it the default root
address that all of our guests will speak to.</p>
<pre><code># ifconfig bridge create
bridge0
# ifconfig bridge0 inet 10.0.4.1/24 up
</code></pre><p>Our jail will use an epair interface to speak to the outside world. They come
as an a and a b part, ifconfig only tells us about the a part when it clones
the interface. When we give a vnet jail an interface it is no longer visible to
the host system. An epair gives us two interfaces that act like a virtual
ethernet cable, we stick one end into the jail and the other is connected to
the bridge.</p>
<pre><code># ifconfig epair create
epair0a
</code></pre><p>Our virtual machine will use a tap interface to access the world. The tap
interface needs to be brought up. There is a helpful sysctl that is off by
default which will trigger the interface to be brought up when it is first
opened. I like to set this to one, otherwise I find myself debugging networking
inside the VM alot with little success.</p>
<pre><code># ifconfig tap create
tap0
# sysctl net.link.tap.up_on_open=1
</code></pre><p>With all the interfaces set up we need to add them to our bridge.</p>
<pre><code># ifconfig bridge0 addm epair0a addm tap0
</code></pre><h2 id="create-jail">Create jail</h2>
<p>Never spoken about is the bsdinstall jail command. It takes a directory and
installs a jail into it. This command will ask you some questions, it would be
cool if it didn't, that would make automating jail creation in scripts much
easier for me.</p>
<pre><code># mkdir testjail
# bsdinstall jail testjail
</code></pre><p>We make our jail persist so it will stick around as we experiment. The
following command creates the jail on the host:</p>
<pre><code># jail -c name=testjail persist vnet path=testjail vnet.interface=epair0b 
</code></pre><p>Now we can jexec into the jail and configure the epair. When you bring one end
of an epair up, the other end comes up, when it goes down the other end goes
down. We just need to configure an address and a default route in our jail.</p>
<pre><code># jexec testjail sh
[testjail] # ifconfig epair0b inet 10.0.4.4/24 up
[testjail] # route add default 10.0.4.1
[testjail] # ping -c 1 10.0.4.1
[testjail] # ping -c 1 192.168.1.1
[testjail] # ping -c 1 8.8.8.8
</code></pre><p>With this setup the jail can speak to our bridge, the local network and the
wider Internet.</p>
<h2 id="create-and-config-a-vm">Create and config a VM</h2>
<p>The FreeBSD offers prebuilt virtual machine images, The latest current one is
available from a url like this:</p>
<pre><code># fetch ftp://ftp.freebsd.org/pub/FreeBSD/snapshots/VM-IMAGES/13.0-CURRENT/amd64/Latest/FreeBSD-13.0-CURRENT-amd64.raw.xz
</code></pre><p>It would be cool if there was a latest symlink that gave you a new head VM from
one static place. The image comes xz compressed, we need to unpack it and I
like to move it to a consistent place:</p>
<pre><code># xz -d FreeBSD-13.0-CURRENT-amd64.raw.xz
# mv FreeBSD-13.0-CURRENT-amd64.raw /vms/freebsd-current
</code></pre><p>bhyve requires we load the vmm kernel module, with that we can use the
excellent vmrun.sh script to launch our vm.</p>
<pre><code># kldload vmm
# sh /usr/share/examples/bhyve/vmrun.sh -c 4 -m 1024 -t tap0 -d /vms/freebsd-current freebsd-current
</code></pre><p>Once that comes up you can log in and do some manual config.</p>
<pre><code>[vm] # ifconfig vtnet0 inet 10.0.4.5/24 up
[vm] # route add default 10.0.4.1
[vm] # ping 8.8.8.8
</code></pre><p>For DNS in both the jail and the virtual machines I have to manually set up the
name server local from my network.</p>
<p>/etc/resolv.conf</p>
<pre><code>search lan
nameserver 192.168.1.1
</code></pre><p>This won't be valid as I move to other networks, but I am sure I will remember
after only a little confusion and debugging.</p>
<h2 id="conclusion">Conclusion</h2>
<p>That is all it takes. The NAT configuration is 3 firewall rules and enabling
forwarding. None of this is persistent and that isn't great practice for a
production environment, but it you just want to experiment with ipfw and NAT,
or spin up a VM for today knowing how to do this in a non-persistent way is
really helpful.</p>

		
	<section>
	
</section></section></div>]]>
            </description>
            <link>https://adventurist.me/posts/00304</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710548</guid>
            <pubDate>Thu, 02 Jul 2020 06:25:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting your head around story points]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23710537">thread link</a>) | @thip
<br/>
July 1, 2020 | https://davidcapper.dev/posts/getting-your-head-around-story-points | <a href="https://web.archive.org/web/*/https://davidcapper.dev/posts/getting-your-head-around-story-points">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://davidcapper.dev/assets/aron-visuals-BXOXnQ26B7o-unsplash.jpg" alt="hourglass">
<em>Photo by <a href="https://unsplash.com/@aronvisuals">Aron Visuals</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></em></p>

<p>Human beings are not very good at seeing into the future. Unless you have a crystal ball or know how to read tea leaves, trying to predict when an event will happen with any degree of accuracy is very difficult. Unfortunately, as software developers, we are regularly asked to do this. Stakeholders usually want to know when they can expect the completion of features. It can make them nervous if we tell them that we don‚Äôt know for sure, or give a timeframe that sounds worryingly large to them to account for our uncertainty.</p>

<p>Story points attempt to solve this by sidestepping time-based estimates, and focusing instead upon estimating complexity - on the basis that we are better at judging how complicated a piece of work is than how long it will take to complete.  Estimating complexity allows us to abstract away things that we can‚Äôt reasonably predict (and often throw off our predictions) such as illness and distractions, and focus on the things that we can - like whether one task is going to be bigger than another.</p>

<p>Once we have a way to quantify complexity, it is possible to begin to measure how much of it can be tackled over time - this is known as velocity. Measuring a team‚Äôs velocity allows us to build forecasts of how much work they are likely to be able to complete in the future. Note the word <em>likely</em> in that last sentence. Story points are not a silver bullet that will let you make perfect predictions about when a task will be finished - but in my experience, they are a significant step up from trying to estimate time directly.</p>

<p>They help you shift from hand-waving and guessing, to evidence-based reasoning about a teams capacity. Over time I‚Äôve found that the accuracy of story point-based predictions tend to improve as teams gain practice and experience, and as the error in velocity averages away as more data gets added to the calculation.</p>

<p>Story points can be a contentious topic amongst software professionals; a lot have had bad experiences with them, and don‚Äôt see how they can ever help on a project. While I don‚Äôt think story points will be a good fit for <em>all</em> projects, I do believe that they can be useful on <em>a lot</em> of projects - especially when teams are inexperienced and haven‚Äôt had a chance to build up some discipline.</p>

<p>I regularly hear two objections to story points that, in my opinion, betray underlying flaws in peoples thinking rather than a problem with the technique itself:</p>

<p>Firstly: that the complexity of a task is different depending on whether you have more or less experience, often stated as ‚Äòmy points are different from your points‚Äô. Secondly: that there is ultimately no real difference between complexity and time - ‚Äòfive points is about a day, this task will take about a day, so I vote five points‚Äô.</p>

<p>The first objection is problematic because you should be estimating for the team, not individuals. If a task is going to be harder for a particular person to complete, then the team should be working with them to help. If you expect someone to struggle to complete work by themselves with no assistance when it would benefit them, then you have more significant problems on your team than estimation. It would be best if you focused on fostering collaboration and knowledge sharing before worrying about anything else.</p>

<p>The second objection is harder to help people move past.  The cognitive leap from time-based estimation, to complexity-based estimation, is quite a large one. The easiest way that I have found to help people get into the right frame of mind is by agreeing on a story to use as a reference at the beginning of estimation sessions. The question then becomes ‚Äòhow much larger is the story we are currently estimating than our reference story?‚Äô When they don‚Äôt have a lot of experience with relative complexity, people often find ranking stories, and then fitting points to them later much more straightforward than coming up with points on the spot (as you would with planning poker).</p>

<p>With a bit of time and practice, most teams can build up an implicit understanding of how story points relate to the complexity of individual pieces of work in their backlog.  As a team becomes more practised, a satisfying moment eventually occurs: everyone‚Äôs estimates begin to converge. You know that your team is getting the hang of things when everyone is consistently voting for the same number of story points on each piece of work that comes up; and when any significant variation that occurs is the result of someone knowing something that the others haven‚Äôt considered.</p>

<p>Whether or not you use story points on your project, I think there are some ideas we can learn from them that are universally applicable. Almost all projects benefit when we can quantify changes to them over time. Reflecting upon, and learning from our experiences is a crucial part of agile development, and doing this with data can give us confidence in our conclusions, and justification for our predictions.</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://davidcapper.dev/posts/getting-your-head-around-story-points</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710537</guid>
            <pubDate>Thu, 02 Jul 2020 06:22:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Book Review: A Philosophy of Software Design]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23710374">thread link</a>) | @signa11
<br/>
July 1, 2020 | http://www.pathsensitive.com/2018/10/book-review-philosophy-of-software.html | <a href="https://web.archive.org/web/*/http://www.pathsensitive.com/2018/10/book-review-philosophy-of-software.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>

<p>I‚Äôm trying to read all the good writing about software design. This is very easy because not very much has been written: it turns out that it‚Äôs much easier to write an article about how to write a Tetris AI as a containerized Kotlin microservice than it is to shed insight on how to write good code. And so, when I heard about John Ousterhout‚Äôs new book ‚ÄúA Philosophy of Software Design,‚Äù I ordered my copy immediately.</p>

<center><img height="200" src="https://images-na.ssl-images-amazon.com/images/I/61iOSX4WNiL._SX404_BO1,204,203,200_.jpg" width="161"></center>

<p>I remember John Ousterhout from Stanford‚Äôs grad student visit day as the tall guy who introduced himself with a self-deprecating joke and invited all the Ph. D. admits over to dinner at his house. I know him also as the father of <a href="http://kayousterhout.org/">Kay Ousterhout</a>, whom I recently met as a fellow speaker at Strange Loop, and Amy Ousterhout, whom together are the first pair of sisters to both win the prestigious Hertz Fellowship.</p>

<p>At 170 pages, ‚ÄúA Philosophy of Software Design‚Äù (henceforth: PoSD) is a humble book. John‚Äôs background is in systems rather than in software engineering or programming languages, and he never claims special expertise. But his practitioner cred is immense. I enjoy tearing apart open-source projects and turning them into case studies of what not to do, so much that my students have requested I write a case study about good code for once. RAMCloud, Ousterhout‚Äôs distributed in-memory storage system, is now on my shortlist: from a 5-minute glance, it‚Äôs among the cleanest and best-documented code I‚Äôve seen. And, given that he‚Äôs a busy professor managing a large lab, he‚Äôs written a surprising amount of it himself. He‚Äôs had plenty of impact too: he‚Äôs the creator of the Tcl language and its Tk framework, which I learned in 2005 as The Way to Write GUIs(‚Ñ¢).</p>

<p>PoSD is best read as a tactical guide of how-to‚Äôs. About a quarter of it is spent on naming and comments, and much of the rest is about specific patterns. His few attempts to jump from tactical advice to principles are either done by trying to blur together similar-sounding tips, or are hamstrung by his inability to see the meaning of a program beyond the code (more on that later). He demonstrates the lack of principles comically in Chapter 19, where he promises to apply the books‚Äô ‚Äúprinciples‚Äù to several software trends, and then fills the rest of the chapter with standard (but solid) advice on unit-testing and OOP, with nary a reference to the rest of the book. On the whole, the book‚Äôs advice is higher-level than beginner books like Clean Code, but most of its contents will be familiar to a senior software engineer, and the novel parts are hit-and-miss.</p>

<p>Following other books like <a href="http://shop.oreilly.com/product/0636920022251.do"><i>Code Simplicity</i></a>, PoSD starts with a high-minded explanation of the benefits of good code and the dangers of complexity. Its early chapters are a grand tour of the basic concepts of software organization: separating levels of abstraction, isolating complexity, and when to break up functions. Chapter 5 is one of the most approachable introductions I‚Äôve seen to Parnas‚Äôs ideas about information hiding. But it‚Äôs Chapter 4 where he introduces the book‚Äôs central idea: deep modules. An interface, explains Ousterhout, is not just the function signatures written in the code. It also includes informal elements: high-level behavior, constraints on ordering; anything a developer needs to know to use it. Many modules are shallow: they take a lot to explain, but don‚Äôt actually do that much. A good module is deep: the interface should be much simpler than the implementation.</p>

<p>Beautiful, obvious, and impossible to disagree with. Unfortunately, it‚Äôs also objectively wrong.</p>

<h2>
When specifications are longer than the code</h2>

<p>It sounds pretty nice to say ‚Äúinterfaces should be shorter than the implementation?‚Äù How do you test it?</p>

<p>To Ousterhout, where the interface is just a comment and some discussion about whether it‚Äôs simple to use and think about. Intuition and experience are the sole arbiters here. And this reveals his major blind spot.</p>

<p>I‚Äôve <a href="http://www.pathsensitive.com/2018/01/the-three-levels-of-software-why-code.html">explained</a> <a href="http://www.pathsensitive.com/2018/01/the-design-of-software-is-thing-apart.html">before</a>&nbsp;that the important information of software design is not in the code (Level 2), but in the logic: the specifications and reasoning that are rarely written down concretely, but shape the code nonetheless. I group these artifacts into the aggregate ‚ÄúLevel 3 constructs.‚Äù The ‚Äúinformal interface‚Äù Ousterhout describes is such a Level 3 construct, but they‚Äôre just as real as the code, and, contrary to Ousterhout, there are plenty of programming languages that do let you write them down and check them.</p>

<p>Experience doing this gives us concrete grounding when we talk software design. It‚Äôs how we move into <a href="https://terrytao.wordpress.com/career-advice/theres-more-to-mathematics-than-rigour-and-proofs/">post-rigorous</a> stage of software engineering, and know what we mean when we use terms like ‚Äúinterface‚Äù and ‚Äúcomplexity.‚Äù It defends us against making confused and contradictory statements. Ousterhout lacks this insight, and that‚Äôs how he gets burned.</p>

<p>I‚Äôm going to pause for a moment and tell you: I like this book overall. It's well-written, and there‚Äôs a lot of advice in the book that I consider useful even though it‚Äôs on shaky ground, and more that doesn‚Äôt depend on this at all. Still, Ousterhout makes a big deal out of it, and so I‚Äôll be taking a couple pages to explain why it‚Äôs wrong. These ideas are important, because they‚Äôre part of what leads to the higher levels of mastery.</p>

<p>My view is that Ousterhout‚Äôs ‚Äúinformal interface‚Äù is just the translation into English of a formal specification. Any question we have about interfaces can be answered by asking the question ‚Äúwhat would a specification look like?‚Äù While I can‚Äôt prove the correspondence without peaking into Ousterhout‚Äôs head more than I‚Äôve gotten to in our back-and-forth, I‚Äôve found this lens unreasonably effective in helping to explain software design. And so, for the remainder of this post, I‚Äôll be using the words ‚Äúspec‚Äù and ‚Äúinterface‚Äù interchangeably.</p>

<p>I agree that the spec should usually be much simpler than the code. But anyone with experience actually formalizing specs can tell you that there are interesting cases where the specification is and should be more complicated than the implementation.</p>

<p>That's right: there are times when it‚Äôs actually desirable to have a specification more complicated than the code. Two major reasons are <b>ghost state </b>and <b>imprecision</b>. Ghost state is a concept from verification that describes certain kinds of ‚Äúsubtle‚Äù code. It‚Äôs an interesting subject that deserves its own blog post; I won‚Äôt mention it again. (Short version: it‚Äôs when a simple action like flipping a bit actually represents something conceptually complicated.)</p>

<p>Imprecision is a bigger one. For example:</p>

<ul>
<li>Specification: The temperature of the Fudarkameter will be between 60 and 90 degrees.</li>
<li>Implementation: The temperature of the Fudarkameter is 70 degrees.</li>
</ul><p>
The specification is longer precisely because it creates an abstraction barrier. If you design the rest of the system assuming the Fudarkameter is exactly 70 degrees, then the Fudarkameter becomes much harder to change or replace. By weakening the assumptions placed on a module, code becomes more evolvable.</p>

<p>On top of these, there‚Äôs another fundamental reason: It is much easier to describe something from the inside than from the outside. It is much easier to show you an apple than to answer every question you may ask of it. (Where are the seeds? How will it roll when I drop it?) And while there is more you can say <a href="http://yudkowsky.net/rational/virtues/">about a single apple</a> than all the apples in the world, there are more things that may be true about some apple than about a single apple.</p>

<p>As an example, let‚Äôs take a stack data structure, something I hope we can all agree is a useful abstraction. A stack is a sequence with push and pop operations, following the last-in-first-out ordering. The linked-list implementation is very short: just adding and removing elements off the front of the list. But if you use a stack, and you don‚Äôt want to use internal details of this implementation, then you need a way to think about it that doesn‚Äôt reference the underlying sequence. One solution is to use the <a href="http://www.cs.unc.edu/~stotts/204/ADTs/">stack axioms</a>, which say things like ‚ÄúIf you push something onto a stack and then pop from the stack, you get the old value back‚Äù and ‚ÄúIf you‚Äôve ever pushed something onto a stack, then it‚Äôs not empty.‚Äù We‚Äôve gone from the internal view of explaining how the stack operations manipulate memory, to the external view of explaining their interactions and observable behaviors.</p>

<p>In my public correspondence with Prof. Ousterhout, I illustrated this by writing down an implementation and interface for a stack data structure, including the stack axioms. My implementation was 30 tokens; the interface was 54.</p>

<p>Perhaps you can find a shorter way to explain stacks, but this is not looking good. It seems that Ousterhout‚Äôs advice, held under a microscope, is actually telling us we should not use stacks in our code (or, at least, only use the more complicated implementations, like lock-free concurrent stacks).</p>

<h3>
<b>A ‚ÄúSimple‚Äù API</b></h3>

<p>It‚Äôs easy for the interface for stacks to be larger than the implementation because they‚Äôre so small. Now, let‚Äôs look at something larger. I don‚Äôt need to look very hard for an example, because Ousterhout gives me one.</p>

<blockquote>
<p>The mechanism for file IO provided by the Unix operating system and its descendants, such as Linux, is a beautiful example of a deep interface. There are only five basic system calls for I/O, with simple signatures: </p>

<div>
<pre><span>int</span> <span>open</span><span>(</span><span>const</span> <span>char</span><span>*</span> <span>path,</span> <span>int</span> <span>flags,</span> <span>mode_t</span> <span>permissions);</span>
<span>ssize_t</span> <span>read</span><span>(</span><span>int</span> <span>fd,</span> <span>void</span><span>*</span> <span>buffer,</span> <span>size_t</span> <span>count);</span>
<span>ssize_t</span> <span>write</span><span>(</span><span>int</span> <span>fd,</span> <span>const</span> <span>void</span><span>*</span> <span>buffer,</span> <span>size_t</span> <span>count);</span>
<span>off_t</span> <span>lseek</span><span>(</span><span>int</span> <span>fd,</span> <span>off_t</span> <span>offset,</span> <span>int</span> <span>referencePosition);</span>
<span>int</span> <span>close</span><span>(</span><span>int</span> <span>fd);</span>
</pre>
</div>
</blockquote>

<p>The POSIX file API is a great example, but not of a deep interface. Rather, it‚Äôs a great example of how code with a very complicated interface may look deceptively simple when reduced to C-style function signatures. It‚Äôs a stateful API with interesting orderings and interactions between calls. The flags and permissions parameters of <span>open</span> hide an enormous amount of complexity, with hidden requirements ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.pathsensitive.com/2018/10/book-review-philosophy-of-software.html">http://www.pathsensitive.com/2018/10/book-review-philosophy-of-software.html</a></em></p>]]>
            </description>
            <link>http://www.pathsensitive.com/2018/10/book-review-philosophy-of-software.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710374</guid>
            <pubDate>Thu, 02 Jul 2020 05:46:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Salted Passwordless Authentication]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23710334">thread link</a>) | @msurdi
<br/>
July 1, 2020 | https://msurdi.github.io/posts/4-salted-passwordless-authentication/ | <a href="https://web.archive.org/web/*/https://msurdi.github.io/posts/4-salted-passwordless-authentication/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
      <article>
        
        <time datetime="2020-07-02T00:00:00.000Z">July, 2020</time>
        <section>
          <h2>Intro</h2>
<p>In this post, I want to describe the strategy I've used in the last
implementation of one of my side projects. The side project is not important at
all, it's mostly a TODO/GTD task manager, but I use it as a test bed for
anything I'm interested in learning or trying out. The source code is
<a href="https://github.com/msurdi/wipku">here</a> and it is deployed
<a href="https://wipku.herokuapp.com/">here</a> if you want to try this out.</p>
<h2>Disclaimer</h2>
<p>I'm not a security expert, I'm just a web developer and probably not even a good
one, I want to describe this with the intention that somebody that understands more
about this could point out issues and help me make the approach more secure and
more easy to use.</p>
<h2>The problem with passwords</h2>
<p>Personally I don't like passwords, because a) I don't want to use the same
password everywhere, 2) Using different passwords everywhere is impossible
unless you 2a) use a password manager and/or 2b) use a
<a href="http://www.davidgumpper.com/security/developing-a-password-schema/">schema</a>
based on the website or something else that lets you generate the passwords
quickly and consistently for a any given website. And that's just what I don't
like as a user.</p>
<p>As a developer I don't like passwords because its very difficult and risky to
implement all the logic for generating them (salts, algorithms, lengths, etc),
storing them and implementing registration forms, login forms, password reset
forms, etc. So unless you use an existing solution from a CMS or big framework
(<a href="https://www.djangoproject.com/">Django</a>, <a href="https://rubyonrails.org/">Rails</a>,
<a href="https://strapi.io/">Strapi</a>, etc.. ) where you have a "Golden Path" for this,
you're in a pretty bad situation.</p>
<h2>Existing solutions research</h2>
<p>I was looking for a passwordless way to authenticate users without depending on
any third party <a href="https://en.wikipedia.org/wiki/OAuth">oauth</a> provider. While
researching about this, I've found that it seems the most common approach to
this is:</p>
<ol>
<li>Ask the user for email address.</li>
<li>Generate from the server a link with a token and send it by email to the user.</li>
<li>When the user clicks on the link, sign the user in, either in the newly
opened tab/browser or in the original one, or both.</li>
</ol>
<p>This approach is very simple, and I think there are many sites using it. The
first time I came across a login system like this was when I signed up to try
out Zeit's PaaS platform <a href="https://vercel.com/login?with-email=1">here</a>, now
called Vercel, hopefully will still have this name when you read this.</p>
<p>When I was investigating more about this approach, the first question to came to
my mind was wether I should log-in the user in the newly opened tab after the
user has clicked in the email link (thus what do I do in his previous tab?) or
wether again to follow Zeit's approach and in this new tab tell the user
"Awesome, you're now logged in, please close this tab and go back to the other
one". The first approach has an important drawback which is that the link might
have opened on a completely different browser, even on a completely different
device if the user clicked the link on his phone. The second approach I think is
even worse because anyone could go to the website, enter somebody else's email
and if that person happens to accidentally click this email then somebody
somewhere might get logged in as him.</p>
<p>There might be workarounds such as
comparing IP addresses, browser fingerprinting, etc, etc... but it gets risky
and complex in my opinion. Also, the user might not have even clicked in the
link but his antivirus might have made a request to the link, or anything in
between him and his email client. Not great.</p>
<h2>The salted passwordless approach</h2>
<p>So I kept investigating and trying out things and finally came to the following
process I want to describe here with the hope that somebody else will help me
understand more about its drawbacks and why it might not be a good idea, or if
seems to be a good one then help me to improve it.</p>
<p>Also, I'm not sure if this already exists under some well known industry name
and I've just missed that out. Thus I'm basically reinventing the square wheel
here.</p>
<p>So, the process goes like this:</p>
<ol>
<li>The application prompts the user for an email address.</li>
<li>The application saves in the browser's localStorage (or just in memory) the
email address, and randomly generated salt.</li>
<li>The application contacts the backend, submitting the email address and the
generated salt.</li>
<li>The application shows the user a dialog of the kind "We've just sent you an
access code to your email, enter it below".</li>
<li>The server generates an access code and then saves in the database the tuple
consistig of (time, email, salt, code), this is the "authentication request".</li>
<li>The server sends an email to the user, containing just the code, which would
be something like "09124".</li>
<li>The user enters this code in the screen resulting from step 4.</li>
<li>The application submits to the server the tuple (code, email, salt).</li>
<li>If the code, the salt, the email and the expiration (time since request was
created) are valid, then create a session, otherwise fail the login.</li>
</ol>
<p>What problems does this process solve?</p>
<ol>
<li>No need for a password, which was the first requirement.</li>
<li>No need to implement password recovery processes, registration processes, etc.</li>
<li>No need to permanently store any sensitive information about the user. You
might not even need to store the email address (you could use a hash of it as
the user ID).</li>
<li>If the email with the access code is intercepted, there is no risk for the
user: whoever intercepted the email would also need access to the user's
browser localStorage (or memory) to get the salt, otherwise the server won't
validate that access code and thus wont create a session.</li>
<li>We don't have the problem of the user opening the "magic link" in a different
browser, given there is no magic link at all.</li>
</ol>
<p>What drawbacks does this process have?</p>
<ol>
<li>The user will not be able to log in if he is having any kind of problem with
his email, or his email provider is slow to delivery new messages, etc.</li>
</ol>
<h2>Conclusions</h2>
<p>So far I'm pretty excited about this solution and that's probably bad for me,
because I might be missing something out, and that's the main motivation of
writing this down here. Unless there is some big security issue I'm not aware
of, I think the trade-off/drawbacks of the approach are quite acceptable for the
usability and implementation benefits.</p>

        </section>
      </article>
    
        </div></div>]]>
            </description>
            <link>https://msurdi.github.io/posts/4-salted-passwordless-authentication/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710334</guid>
            <pubDate>Thu, 02 Jul 2020 05:37:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Moving from Statistics to Machine Learning, the Final Stage of Grief]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 32 (<a href="https://news.ycombinator.com/item?id=23710210">thread link</a>) | @yoloswagins
<br/>
July 1, 2020 | https://ryxcommar.com/2019/07/14/on-moving-from-statistics-to-machine-learning-the-final-stage-of-grief/ | <a href="https://web.archive.org/web/*/https://ryxcommar.com/2019/07/14/on-moving-from-statistics-to-machine-learning-the-final-stage-of-grief/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-47">

	<!-- .entry-header -->

	<div>
		
<p>I‚Äôve spent the last few months preparing for and applying for data science jobs. It‚Äôs possible the data science world may reject me and my lack of both experience and a credential above a bachelors degree, in which case I‚Äôll do something else. Regardless of what lies in store for my future, I think I‚Äôve gotten a good grasp of the mindset underlying machine learning and how it differs from traditional statistics, so I thought I‚Äôd write about it for those who have a similar background to me considering a similar move.<sup>1</sup></p>



<p>This post is geared toward people who are excellent at statistics but don‚Äôt really ‚Äúget‚Äù machine learning and want to understand the gist of it in about 15 minutes of reading. If you have a traditional academic stats backgrounds (be it econometrics, biostatistics, psychometrics, etc.), there are two good reasons to learn more about data science:</p>



<ul><li>First, data science jobs tend to pay more than other quantitative jobs. It‚Äôs a bit taboo to bring this up‚Äì after all, aren‚Äôt we all supposed to be doing this out of passion and love? I‚Äôm not going to pretend that making more money is a bad reason to pursue something, and I reserve no judgment for those whose primary motivation is to earn more.</li><li>Second, data scientists genuinely do some pretty interesting things and have a very interesting approach to working with data, even if my gut reaction is to barf when someone says ‚Äúteaching the model‚Äù instead of ‚Äúestimating the parameters.‚Äù</li></ul>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>Q: What's the difference between statistics and machine learning?</p><p>A: About $50,000/year</p></div>‚Äî Senior OLS Engineer (@ryxcommar) <a href="https://twitter.com/ryxcommar/status/1131244580115046405?ref_src=twsrc%5Etfw">May 22, 2019</a></blockquote></div>
</div></figure>



<p>The world of data science is, in many ways, hiding in plain sight from the more academically-minded quantitative disciplines. I‚Äôm not going to spend much time covering the different algorithms that data scientists use: partly because a lot of the algorithms they use are the same as what statisticians use, but also because the algorithms aren‚Äôt the point of this post. In this post I‚Äôll be writing a short guide on how to translate your statistics skills into data science very quickly.</p>



<p>After finishing this post, I recommend downloading (for free) and reading through <a href="https://web.stanford.edu/~hastie/ElemStatLearn/">The Elements of Statistical Learning</a> (herein TESL). It is an excellent and comprehensive textbook that covers all the major machine learning topics, and is geared toward people with a strong math background, especially linear algebra.</p>



<h2>Philosophical Differences Between Statistics and Machine Learning</h2>



<figure></figure>



<p>The main difference between machine learning and statistics is what I‚Äôd call ‚ÄúŒ≤-hat versus y-hat.‚Äù (I‚Äôve also heard it described as inference versus prediction.) Basically, academia cares a lot about what the estimated parameters look like (Œ≤-hat), and machine learning cares more about being able to estimate a dependent variable given some inputs (y-hat). There are handful of other differences, but they are rooted in this. Once you understand this, combined with your background in stats, you will basically understand machine learning.</p>



<h4> Œ≤-Hat Versus Y-Hat</h4>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>My date: I am studying machine learning</p><p>Me [trying to impress her]: I too am studying how to do regressions in California</p></div>‚Äî Senior OLS Engineer (@ryxcommar) <a href="https://twitter.com/ryxcommar/status/1145076273410129921?ref_src=twsrc%5Etfw">June 29, 2019</a></blockquote></div>
</div></figure>



<p>Once you stop caring about your parameters, you can start making them look like nonsense, i.e. by adding <a href="https://en.wikipedia.org/wiki/Bias_of_an_estimator">bias</a> (the parameter is wrong) or <a href="https://en.wikipedia.org/wiki/Consistent_estimator">inconsistency</a> (the parameter doesn‚Äôt converge over infinite observations). In some cases, you can even turn the model into more or less a complete black box that just spits out a y-hat; this is what neural networks are, basically. Traditionally, it‚Äôs a cardinal sin in academia to use parameters like these because you can‚Äôt say anything interesting about the parameters, but the trick in machine learning is that you don‚Äôt need to say anything about the parameters. In machine learning, your focus is on describing y-hat, not Œ≤-hat.</p>



<p>Why so much love for y-hat? The friendly, less cynical answer is that within the last decade, everyone got their hands on a crap-ton of data and computational power, and they want to do cool and useful things with it. Machine learning is a pretty natural way to leverage all this data and power because machine learning has tools to deal with multicollinearity and to find really deep, hidden correlations and patterns in data. As you can imagine, machine learning doesn‚Äôt let you side-step the dirty work of specifying your data and models (a.k.a. ‚Äú<a href="https://en.wikipedia.org/wiki/Feature_engineering">feature engineering</a>,‚Äù according to data scientists), but it makes it a lot easier to just run things without thinking too hard about how to set it up. In statistics, bad results can be wrong, and being right for bad reasons isn‚Äôt acceptable. In machine learning, bad results are wrong if they catastrophically fail to predict the future, and nobody cares much how your crystal ball works, they only care that it works.</p>



<figure><img src="https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fgilpress%2Ffiles%2F2016%2F03%2FTime-1200x511.jpg" alt="Time"><figcaption>For those of you who have never done anything outside a classroom setting, this is literally every data related task, whether you‚Äôre an accountant working in Excel or a PhD data scientist working for 6-figures.<br><a href="https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#9b3182c6f637">(Source: Forbes.)</a></figcaption></figure>



<p>This newfound love for y-hat is a bit opportunistic, but in fairness, y-hat tends to be more important than Œ≤-hat for a wide array of business use cases. For example:</p>



<ul><li>Recommender systems (such as Youtube showing you more videos you might like, or showing  a customer items they might want to buy next).</li><li>Computer vision (such as optical character recognition or facial recognition).</li><li>Forecasting (such as estimating how much a customer will buy at a store, or how likely someone is to default on a loan).</li></ul>



<p>None of these tasks require having a human interpret the parameters and figure out what‚Äôs driving what to get a sufficiently acceptable answer; it‚Äôs all predictive.</p>



<h4>Letting Go of  Œ≤-Hat</h4>



<p>There are a lot of things that data scientists do that made literally zero sense to me before I grasped how to think in terms of y-hat.</p>



<p>The big one that made no sense to me the first time I encountered it back in 2017 is that data scientists split their data into <a href="https://medium.com/datadriveninvestor/data-science-essentials-why-train-validation-test-data-b7f7d472dc1f">‚Äútraining data,‚Äù ‚Äúvalidation data,‚Äù and ‚Äútesting data.‚Äù</a> The reason this does not make sense to Œ≤-hat-brained people is because adding more observations should get you closer to the true parameter because, you know, the law of large numbers. There are two issues with the old school thought process. The first is that there is no ‚Äútrue‚Äù parameter if your parameters are intentionally allowed to be a little biased. The second is that there is no guarantee of convergence to anything if your parameters are allowed to be asymptotically inconsistent.</p>



<p>I‚Äôm sure you‚Äôre asking: ‚Äúwhy allow your parameters to be biased?‚Äù Good question. The most straightforward answer is that there is a bias-variance trade-off. <a href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff">The Wikipedia article </a>does a good job both illustrating and explaining it. For Œ≤-hat purposes, the notion of allowing any bias is crazy. For y-hat purposes, adding a little bias in exchange for a huge reduction in variance can improve the predictive power of your model.</p>



<figure><div>

</div></figure>



<h4>Adding Bias to OLS with Ridge Regression</h4>



<p>Ridge regression is the most straightforward example of adding bias. If you understand OLS, you‚Äôre like two paragraphs of reading away from understanding ridge regression.</p>



<p>Basically, instead of just solving for the Œ≤ vector that minimizes the sum of squared residuals as one does with OLS, i.e. <img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D_%7B%5Crm+ols%7D+%3D+%7B%5Crm+argmin%7D_%7B%5Cboldsymbol%7B%5Cbeta%7D%7D+%5Csum_%7Bi%3D1%7D%5En+%28y_i+-+x_i+%5E%7B%5Crm+T%7D++%5Cbeta%29%5E2&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="\hat{\boldsymbol{\beta}}_{\rm ols} = {\rm argmin}_{\boldsymbol{\beta}} \sum_{i=1}^n (y_i - x_i ^{\rm T}  \beta)^2" title="\hat{\boldsymbol{\beta}}_{\rm ols} = {\rm argmin}_{\boldsymbol{\beta}} \sum_{i=1}^n (y_i - x_i ^{\rm T}  \beta)^2">, you can also add a ‚Äúpenalty‚Äù to large squared Œ≤‚Äôs while trying to find the Œ≤-hat that minimizes the objective function. So you add <img src="https://s0.wp.com/latex.php?latex=%5Clambda+%5Csum_%7Bj%3D1%7D%5EK++%5Cbeta%5E2&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="\lambda \sum_{j=1}^K  \beta^2" title="\lambda \sum_{j=1}^K  \beta^2"> to the objective function, where Œª is some constant. Then, last but not least, you ‚Äústandardize‚Äù each column <img src="https://s0.wp.com/latex.php?latex=X_j&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="X_j" title="X_j">, which means transforming it to <img src="https://s0.wp.com/latex.php?latex=Z_j+%5Csim+N%280%2C1%29&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="Z_j \sim N(0,1)" title="Z_j \sim N(0,1)"> by subtracting each column by the column‚Äôs mean and dividing by the column‚Äôs standard deviation: <img src="https://s0.wp.com/latex.php?latex=z_%7Bi%2Cj%7D+%3D+%28x_%7Bi%2Cj%7D+-+%5Cmu_j%29+%2F+%5Csigma_j&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="z_{i,j} = (x_{i,j} - \mu_j) / \sigma_j" title="z_{i,j} = (x_{i,j} - \mu_j) / \sigma_j"> (the purpose of this is to make it so the parameters measure the <em>relative</em> impacts to the overall result, as opposed to the nominal impacts, otherwise the penalty wouldn‚Äôt work the way you‚Äôd probably want it to). This gives you the ridge regression estimator:</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D_%7B%5Crm+ridge%7D+%3D+%7B%5Crm+argmin%7D_%5Cbeta+%5Csum_%7Bi%3D1%7D%5En+%28y_i+-+z_i+%5E%7B%5Crm+T%7D++%5Cbeta%29%5E2+%2B+%5Clambda+%5Csum_%7Bj%3D1%7D%5EK++%5Cbeta%5E2&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="\hat{\boldsymbol{\beta}}_{\rm ridge} = {\rm argmin}_\beta \sum_{i=1}^n (y_i - z_i ^{\rm T}  \beta)^2 + \lambda \sum_{j=1}^K  \beta^2" title="\hat{\boldsymbol{\beta}}_{\rm ridge} = {\rm argmin}_\beta \sum_{i=1}^n (y_i - z_i ^{\rm T}  \beta)^2 + \lambda \sum_{j=1}^K  \beta^2"></p>



<p>At Œª=0, the summation of squared Œ≤‚Äôs you just tacked onto the objective function equals zero regardless of what the Œ≤-hat vector is, so you just have OLS again. As Œª‚Üí‚àû, the penalties for all nonzero Œ≤‚Äôs become so huge that the only way for the penalties to not overwhelm the objective function is to have all the parameters Œ≤-hat = 0. And the closed-form solution to the objective function, it turns out, is pretty similar to OLS‚Äôs closed-form solution:   <img src="https://s0.wp.com/latex.php?latex=%5Chat%7B%5Cboldsymbol%7B%5Cbeta%7D%7D_%7B%5Crm+ridge%7D+%3D+%28%5Cmathbf+Z%5E%7B%5Crm+T%7D+%5Cmathbf+Z-%5Clambda+%5Cmathbf+I%29%5E%7B-1%7D+%5Cmathbf+Z%5E%7B%5Crm+T%7D+%5Cmathbf+y&amp;bg=ffffff&amp;fg=6e7381&amp;s=0" alt="\hat{\boldsymbol{\beta}}_{\rm ridge} = (\mathbf Z^{\rm T} \mathbf Z-\lambda \mathbf I)^{-1} \mathbf Z^{\rm T} \mathbf y" title="\hat{\boldsymbol{\beta}}_{\rm ridge} = (\mathbf Z^{\rm T} \mathbf Z-\lambda \mathbf I)^{-1} \mathbf Z^{\rm T} \mathbf y">.</p>



<p>All pretty straightforward, but the real question is why would you do this? Well, if you don‚Äôt care about the interpretability/bias of the parameters but you want the model to predict out-of-sample better than regular OLS, you can find some value of  Œª through <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">cross-validation</a> that gives you a better fit than  Œª=0, i.e. minimizing the <a href="https://en.wikipedia.org/wiki/Mean_squared_prediction_error">prediction errors</a>. But in order to cross-validate the data, you need to split your data into data you use to estimate the parameters (training data) and data to perform the cross-validation on (validation data). This process is what sets your Œª.</p>



<p>Ridge regression is OLS with L2 regularization, which is penalization by the square of the parameter. L1 regularization takes the absolute value of the parameters as the penalty instead of the square (i.e. <a href="https://en.wikipedia.org/wiki/Lasso_(statistics)">lasso</a>). And of course, L1 and L2 regularization can be used in contexts other than linear regression, such as logistic regression. These regularization methods are especially good at dealing with multicollinearity, which is definitely something you‚Äôd come across with thousands of columns of corporate data and no compelling way to decide which are the best columns to use.<sup>2</sup></p>



<p>I could go on, but regurgitating all of TESL isn‚Äôt why I wrote this blog. I like showing ridge regression as an example of machine learning because it‚Äôs very similar to OLS, but is totally and unabashedly modified for predictive purposes, instead of inferential purposes. Œ≤-hat is never the ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ryxcommar.com/2019/07/14/on-moving-from-statistics-to-machine-learning-the-final-stage-of-grief/">https://ryxcommar.com/2019/07/14/on-moving-from-statistics-to-machine-learning-the-final-stage-of-grief/</a></em></p>]]>
            </description>
            <link>https://ryxcommar.com/2019/07/14/on-moving-from-statistics-to-machine-learning-the-final-stage-of-grief/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710210</guid>
            <pubDate>Thu, 02 Jul 2020 05:11:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Stories for WordPress by Google and open source]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23710051">thread link</a>) | @nilsandrey
<br/>
July 1, 2020 | https://google.github.io/web-stories-wp/beta/ | <a href="https://web.archive.org/web/*/https://google.github.io/web-stories-wp/beta/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    <header>
        
        
        <ul>
            <li><a href="#about">About</a></li>
            <li><a href="#get-started">Get Started</a></li>
            <li><a href="#faq">FAQ</a></li>
            <li><a href="https://github.com/google/web-stories-wp">GitHub</a></li>
            <li><a href="https://github.com/google/web-stories-wp/releases/download/v1.0.0-beta.1/web-stories.zip">Download Beta</a></li>
        </ul>
    </header>

    <section>
        <div>
            <h2>Stories Editor</h2>
            <h3><span>Get</span> <span>Ready</span> <span>to</span> <span>Tell</span> <span>Stories</span> <span>on</span> <span>WordPress</span></h3>
            <p>We're not quite ready for prime time yet, but if you like to live dangerously, we invite you to try our first public beta.</p>
            
        </div>
        
        
    </section>

    <section>
        <h2><a id="about">About</a></h2>
        <p>With Stories for WordPress, we're bringing first-class Web Stories support to WordPress.</p>
    </section>

    <amp-animation id="videoAnim" layout="nodisplay">
        
    </amp-animation>    
    <section>
        <amp-position-observer intersection-ratios="0.4" on="enter:videoAnim.start" layout="nodisplay" once="">
        </amp-position-observer>
        <p>WYSIWYG all the way</p>
        <amp-video width="1920" height="1200" layout="responsive" title="Stories for WordPress in action" src="./assets/wysiwyg.mp4" loop="" muted="" autoplay="">
    </amp-video></section>

    <amp-animation id="templateAnim" layout="nodisplay">
    
    </amp-animation>
    <section>
        <amp-position-observer intersection-ratios="0.5" on="enter:templateAnim.start" layout="nodisplay" once="">
        </amp-position-observer>
        <p>Expressive Templates</p>
        <ul>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/1.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/2.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/3.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/4.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/5.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/6.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/7.png"></amp-img></li>
            <li><amp-img layout="responsive" width="542" height="840" src="./assets/templates/8.png"></amp-img></li>
        </ul>
    </section>

     <section>
        <h2><a id="get-started">Get Started</a></h2>
        <div>
            <p>Welcome</p>
            <h3>Tips to make the most of the Beta</h3>
            <p>Welcome! Starting on a new tool can be daunting, so we created a Web Story (naturally!) with some tips to help you get started. We can't wait to see your stories!</p>
            <p>Click <a href="https://google.github.io/web-stories-wp/beta/tips.html">here</a> or on the image to view.</p>
        </div>
        
     </section>

     <section>
        <h2><a id="faq">FAQ</a></h2>
        <dl>
            <dt>Where can I learn more about Web Stories?</dt>
            <dd><a href="https://amp.dev/about/stories/">Web Stories</a> are tappable, engaging visual stories brought to the web. They‚Äôre powered by AMP technology, so learn more about them on <a href="https://amp.dev/about/stories/">amp.dev</a>.</dd>
        
            <dt>How do I install the Stories for WordPress plugin?</dt>
            <dd>
                As soon as we‚Äôre graduating from beta, the plugin will be available on WordPress.org. While we‚Äôre in beta, the plugin has to be downloaded as zip. After that:

                <ol>
                    <li>Navigate to Plugins &gt; Add New.</li>
                    <li>Click the Upload Plugin button at the top of the screen.</li>
                    <li>Select the zip file from your local filesystem.</li>
                    <li>Click the Install Now button.</li>
                    <li>When installation is complete, you‚Äôll see ‚ÄúPlugin installed successfully.‚Äù Click the Activate Plugin button at the bottom of the page.</li>
                </ol>
            </dd>
        
            <dt>I found a bug or missing feature! How do I report it?</dt>
            <dd>Awesome! That‚Äôs exactly what the beta is for. Please submit feedback and <a href="https://github.com/google/web-stories-wp/issues">file a bug or feature request on Github</a> for now - we'll follow up with an easier-to-use feedback form in the next days. Your help is greatly appreciated.</dd>

            <dt>When is the final version shipping, and what will be included?</dt>
            <dd>Later this summer. In addition to stabilization, performance fixes and bug fixes, the final version will also include animation and page attachment support.</dd>
        </dl>
     </section>

     



</div>]]>
            </description>
            <link>https://google.github.io/web-stories-wp/beta/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23710051</guid>
            <pubDate>Thu, 02 Jul 2020 04:37:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build Time Series Charts with Apache Superset]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23709687">thread link</a>) | @ceohockey60
<br/>
July 1, 2020 | https://preset.io/blog/2020-06-26-timeseries-chart/ | <a href="https://web.archive.org/web/*/https://preset.io/blog/2020-06-26-timeseries-chart/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="analyzing-time-series-data-with-superset"><a href="#analyzing-time-series-data-with-superset" aria-label="analyzing time series data with superset permalink"></a>Analyzing Time Series data with Superset</h2>
<p>In the <a href="https://preset.io/blog/2020-06-08-first-chart/">previous blog post</a>, we learned how to start to create charts in <a href="https://superset.incubator.apache.org/">Superset</a> and specifically <a href="https://preset.io/blog/2020-06-08-first-chart/">how to create a composition charts</a> to understand understand how data is formed. This, in turn, can be used to determine which chart type is the most appropriate.</p>
<p>In this blog article we will explore the topic of time series data, visualization options, and how to best represent time series data in order to facilitate trend analysis. Data used in the examples below is available in a <a href="https://raw.githubusercontent.com/eugeniamz/ce_test_db/master/Covid19_CasesTS_data.csv">GitHub repository</a> ‚Äî you can also <a href="https://www.youtube.com/watch?v=r4sjmAKaJ6M&amp;t=3s">view instructions</a> on how to import the file into your own database.</p>
<h2 id="why-time-series-charts"><a href="#why-time-series-charts" aria-label="why time series charts permalink"></a>Why Time Series Charts</h2>
<p>Time series data is important because it is used to understand and analyze data behavior over time. Using historical data, time series charts enable companies to spot trends, changes in behavior, and compare different metrics to visualize correlations. Examples of time series analysis includes website visits, sales trends, and IoT (Internet of Things) data.</p>
<p>In a time series chart, you represent a independent variable (time) vs. dependent variables (metrics) to analyze behavior over time.</p>
<p>In the example of Covid-19 data, a time series chart will enable you to answer critical questions, such as:</p>
<ul>
<li>Are the number of Confirmed Cases decreasing? (trend)</li>
<li>Did we flatten the curve? (trends)</li>
<li>Is there a correlation between confirmed cases and deaths?</li>
</ul>
<h2 id="times-series-analysis-with-superset"><a href="#times-series-analysis-with-superset" aria-label="times series analysis with superset permalink"></a>Times Series Analysis with Superset</h2>
<p>Superset has a rich library of time series graphs for different use cases, such as: Line Charts, Area Charts, Time Series Bar Charts, Dual Line Charts, Calendar Heat Maps, Horizon Charts, and more. In this article, we will show examples of some of these charts and how changing a visualization type can dramatically change how data is displayed for trend analysis.</p>
<h3 id="data-requirement-for-time-series-charts"><a href="#data-requirement-for-time-series-charts" aria-label="data requirement for time series charts permalink"></a>Data Requirement for Time Series Charts</h3>
<div><p><a href="https://preset.io/static/5a17c1be58c04aebf85fae427033adba/f84ea/image0.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/5a17c1be58c04aebf85fae427033adba/f84ea/image0.png" srcset="https://preset.io/static/5a17c1be58c04aebf85fae427033adba/7b5b4/image0.png 188w,
https://preset.io/static/5a17c1be58c04aebf85fae427033adba/a80c4/image0.png 376w,
https://preset.io/static/5a17c1be58c04aebf85fae427033adba/f84ea/image0.png 632w" sizes="(max-width: 632px) 100vw, 632px">
  </span>
  </a></p></div>
<p><strong>Time Field:</strong> This is a independent variable and is represented on the X-axis. Options in the Time Column drop-down are fields that have the option temporal in the Columns field within the data source. The Time Grain drop-down indicates the data aggregated label used when displaying the metrics.</p>
<p><strong>Metrics:</strong> This is a required field and represents the dependent variables that will be displayed on the Y-axis.</p>
<p>All the other fields are optional, but it is important to keep in mind that an efficient chart is a simple chart ‚Äî therefore, be sure to reduce the use of filters, granularity, and limit the series represented in the Group By and Series limit fields. By default, the Series limit field uses the first metric value to cut off values but, alternatively, the Sort By field allows you to filter data with an additional data point.</p>
<h2 id="time-series-bar-chart"><a href="#time-series-bar-chart" aria-label="time series bar chart permalink"></a>Time Series Bar Chart</h2>
<p>Time series bar charts represent categories by vertical charts.</p>
<div><p><a href="https://preset.io/static/4b72eaa35dfd978add023bf3488ba556/823b0/image1.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/4b72eaa35dfd978add023bf3488ba556/f6afc/image1.png" srcset="https://preset.io/static/4b72eaa35dfd978add023bf3488ba556/7b5b4/image1.png 188w,
https://preset.io/static/4b72eaa35dfd978add023bf3488ba556/a80c4/image1.png 376w,
https://preset.io/static/4b72eaa35dfd978add023bf3488ba556/f6afc/image1.png 752w,
https://preset.io/static/4b72eaa35dfd978add023bf3488ba556/823b0/image1.png 954w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<p>In this example, you can see that the numbers of dates (last 3 months ~90 bars) are too wide to be represented on the screen ‚Äî this is a good opportunity to reduce the date granularity in order to reduce the data points on the X-axis.</p>
<div><p><a href="https://preset.io/static/6625d81f550bc233e42ed2c04e0ac8a0/2f950/image2.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/6625d81f550bc233e42ed2c04e0ac8a0/f6afc/image2.png" srcset="https://preset.io/static/6625d81f550bc233e42ed2c04e0ac8a0/7b5b4/image2.png 188w,
https://preset.io/static/6625d81f550bc233e42ed2c04e0ac8a0/a80c4/image2.png 376w,
https://preset.io/static/6625d81f550bc233e42ed2c04e0ac8a0/f6afc/image2.png 752w,
https://preset.io/static/6625d81f550bc233e42ed2c04e0ac8a0/3f9be/image2.png 1128w,
https://preset.io/static/6625d81f550bc233e42ed2c04e0ac8a0/a34ba/image2.png 1504w,
https://preset.io/static/6625d81f550bc233e42ed2c04e0ac8a0/2f950/image2.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<p>Changing granularity to <strong><em>Week</em></strong> will reduce the number of data points on the X-axis and will make the graph clear to follow and integrate in a dashboard.</p>
<div><p><a href="https://preset.io/static/3a0fbb4f274dec4b85248badf7579e4b/2f950/image3.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/3a0fbb4f274dec4b85248badf7579e4b/f6afc/image3.png" srcset="https://preset.io/static/3a0fbb4f274dec4b85248badf7579e4b/7b5b4/image3.png 188w,
https://preset.io/static/3a0fbb4f274dec4b85248badf7579e4b/a80c4/image3.png 376w,
https://preset.io/static/3a0fbb4f274dec4b85248badf7579e4b/f6afc/image3.png 752w,
https://preset.io/static/3a0fbb4f274dec4b85248badf7579e4b/3f9be/image3.png 1128w,
https://preset.io/static/3a0fbb4f274dec4b85248badf7579e4b/a34ba/image3.png 1504w,
https://preset.io/static/3a0fbb4f274dec4b85248badf7579e4b/2f950/image3.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<h2 id="line-chart"><a href="#line-chart" aria-label="line chart permalink"></a>Line Chart</h2>
<p>Line charts are used if you want to compare several series at the same time.</p>
<div><p><a href="https://preset.io/static/7e892a48698908b23493a1d04e2538e0/2f950/image4.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/7e892a48698908b23493a1d04e2538e0/f6afc/image4.png" srcset="https://preset.io/static/7e892a48698908b23493a1d04e2538e0/7b5b4/image4.png 188w,
https://preset.io/static/7e892a48698908b23493a1d04e2538e0/a80c4/image4.png 376w,
https://preset.io/static/7e892a48698908b23493a1d04e2538e0/f6afc/image4.png 752w,
https://preset.io/static/7e892a48698908b23493a1d04e2538e0/3f9be/image4.png 1128w,
https://preset.io/static/7e892a48698908b23493a1d04e2538e0/a34ba/image4.png 1504w,
https://preset.io/static/7e892a48698908b23493a1d04e2538e0/2f950/image4.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<p>However, adding too many series (e.g., many distinct values in the Group By field) could make it difficult to understand and conceptualize the series. In this case, it is useful to use Series Limit to reduce the number of series.</p>
<div><p><a href="https://preset.io/static/994c47a1fd8c9fc046bd2f6685c7e6f6/2f950/image5.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/994c47a1fd8c9fc046bd2f6685c7e6f6/f6afc/image5.png" srcset="https://preset.io/static/994c47a1fd8c9fc046bd2f6685c7e6f6/7b5b4/image5.png 188w,
https://preset.io/static/994c47a1fd8c9fc046bd2f6685c7e6f6/a80c4/image5.png 376w,
https://preset.io/static/994c47a1fd8c9fc046bd2f6685c7e6f6/f6afc/image5.png 752w,
https://preset.io/static/994c47a1fd8c9fc046bd2f6685c7e6f6/3f9be/image5.png 1128w,
https://preset.io/static/994c47a1fd8c9fc046bd2f6685c7e6f6/a34ba/image5.png 1504w,
https://preset.io/static/994c47a1fd8c9fc046bd2f6685c7e6f6/2f950/image5.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<h2 id="area-chart"><a href="#area-chart" aria-label="area chart permalink"></a>Area Chart</h2>
<p>Area chart are similar to line chart in that they represent variables with the same scale, but area charts stack the metrics on top of each other. An area chart in Superset can be stream, stack, or expand.</p>
<p>By simply changing the Visualization Type, we can display the line chart above as an area chart</p>
<div><p><a href="https://preset.io/static/40ccbd87f3bb57a2373fe8ee3871523e/2f950/image6.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/40ccbd87f3bb57a2373fe8ee3871523e/f6afc/image6.png" srcset="https://preset.io/static/40ccbd87f3bb57a2373fe8ee3871523e/7b5b4/image6.png 188w,
https://preset.io/static/40ccbd87f3bb57a2373fe8ee3871523e/a80c4/image6.png 376w,
https://preset.io/static/40ccbd87f3bb57a2373fe8ee3871523e/f6afc/image6.png 752w,
https://preset.io/static/40ccbd87f3bb57a2373fe8ee3871523e/3f9be/image6.png 1128w,
https://preset.io/static/40ccbd87f3bb57a2373fe8ee3871523e/a34ba/image6.png 1504w,
https://preset.io/static/40ccbd87f3bb57a2373fe8ee3871523e/2f950/image6.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<p>By customizing the chart, we can view different variations. Here is a Stream Area Chart (Customize ‚Üí Stacked Style ‚Üí stream):</p>
<div><p><a href="https://preset.io/static/8cc038830ff4853e98eeb7afde98c760/2f950/image6_5.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/8cc038830ff4853e98eeb7afde98c760/f6afc/image6_5.png" srcset="https://preset.io/static/8cc038830ff4853e98eeb7afde98c760/7b5b4/image6_5.png 188w,
https://preset.io/static/8cc038830ff4853e98eeb7afde98c760/a80c4/image6_5.png 376w,
https://preset.io/static/8cc038830ff4853e98eeb7afde98c760/f6afc/image6_5.png 752w,
https://preset.io/static/8cc038830ff4853e98eeb7afde98c760/3f9be/image6_5.png 1128w,
https://preset.io/static/8cc038830ff4853e98eeb7afde98c760/a34ba/image6_5.png 1504w,
https://preset.io/static/8cc038830ff4853e98eeb7afde98c760/2f950/image6_5.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<p>...and this chart is customized as an Expanded Area Chart <em>(Customize ‚Üí Stacked Style ‚Üí expand)</em> where the Y values are not the metrics value, but the % of contribution on the total of the metric:</p>
<div><p><a href="https://preset.io/static/b1b84f3c572f493c7e4dc04cedbcb962/2f950/image7.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/b1b84f3c572f493c7e4dc04cedbcb962/f6afc/image7.png" srcset="https://preset.io/static/b1b84f3c572f493c7e4dc04cedbcb962/7b5b4/image7.png 188w,
https://preset.io/static/b1b84f3c572f493c7e4dc04cedbcb962/a80c4/image7.png 376w,
https://preset.io/static/b1b84f3c572f493c7e4dc04cedbcb962/f6afc/image7.png 752w,
https://preset.io/static/b1b84f3c572f493c7e4dc04cedbcb962/3f9be/image7.png 1128w,
https://preset.io/static/b1b84f3c572f493c7e4dc04cedbcb962/a34ba/image7.png 1504w,
https://preset.io/static/b1b84f3c572f493c7e4dc04cedbcb962/2f950/image7.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<h2 id="chart-with-two-metrics-of-different-scales"><a href="#chart-with-two-metrics-of-different-scales" aria-label="chart with two metrics of different scales permalink"></a>Chart with Two Metrics of Different Scales</h2>
<p> In many cases, you may want to compare two or more metrics of different scales; consequently, there is need for a second Y-axis. Provided that the data source is the same, the Dual Line Chart in Preset is ideal in such a scenario.</p>
<div><p><a href="https://preset.io/static/95a02e57cb6ce0fa77c2d5b5273815a7/2f950/image8.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/95a02e57cb6ce0fa77c2d5b5273815a7/f6afc/image8.png" srcset="https://preset.io/static/95a02e57cb6ce0fa77c2d5b5273815a7/7b5b4/image8.png 188w,
https://preset.io/static/95a02e57cb6ce0fa77c2d5b5273815a7/a80c4/image8.png 376w,
https://preset.io/static/95a02e57cb6ce0fa77c2d5b5273815a7/f6afc/image8.png 752w,
https://preset.io/static/95a02e57cb6ce0fa77c2d5b5273815a7/3f9be/image8.png 1128w,
https://preset.io/static/95a02e57cb6ce0fa77c2d5b5273815a7/a34ba/image8.png 1504w,
https://preset.io/static/95a02e57cb6ce0fa77c2d5b5273815a7/2f950/image8.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<h2 id="smoothing-the-curve"><a href="#smoothing-the-curve" aria-label="smoothing the curve permalink"></a>Smoothing the Curve</h2>
<p>Sometimes when looking at data points on a per day basis, it is difficult to determine trends and data variance. For example, the chart below shows the top American states with new Covid-19 cases on a per day basis (taken over the last month). This view makes it difficult to discern a clear trend.</p>
<div><p><a href="https://preset.io/static/f4cc2d0abd922a476354b9eb9697e6b5/2f950/image9.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/f4cc2d0abd922a476354b9eb9697e6b5/f6afc/image9.png" srcset="https://preset.io/static/f4cc2d0abd922a476354b9eb9697e6b5/7b5b4/image9.png 188w,
https://preset.io/static/f4cc2d0abd922a476354b9eb9697e6b5/a80c4/image9.png 376w,
https://preset.io/static/f4cc2d0abd922a476354b9eb9697e6b5/f6afc/image9.png 752w,
https://preset.io/static/f4cc2d0abd922a476354b9eb9697e6b5/3f9be/image9.png 1128w,
https://preset.io/static/f4cc2d0abd922a476354b9eb9697e6b5/a34ba/image9.png 1504w,
https://preset.io/static/f4cc2d0abd922a476354b9eb9697e6b5/2f950/image9.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<p>In order to gain a greater insight into this data, we recommend smoothing out the short-term fluctuations between data points by applying a moving average. The moving average‚Äîavailable in the <em>Advance Analytics function</em>‚Äîapplies the average between defined X periods instead of marking actual data points by date.</p>
<p>If we apply this technique to the previous chart by using the moving average over the last 7 days, the lines in the chart will be smoothed out and facilitate the recognition of trends.</p>
<div><p><a href="https://preset.io/static/e15c3088380b6e2e365bb2c66bea4b7b/2f950/image10.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/e15c3088380b6e2e365bb2c66bea4b7b/f6afc/image10.png" srcset="https://preset.io/static/e15c3088380b6e2e365bb2c66bea4b7b/7b5b4/image10.png 188w,
https://preset.io/static/e15c3088380b6e2e365bb2c66bea4b7b/a80c4/image10.png 376w,
https://preset.io/static/e15c3088380b6e2e365bb2c66bea4b7b/f6afc/image10.png 752w,
https://preset.io/static/e15c3088380b6e2e365bb2c66bea4b7b/3f9be/image10.png 1128w,
https://preset.io/static/e15c3088380b6e2e365bb2c66bea4b7b/a34ba/image10.png 1504w,
https://preset.io/static/e15c3088380b6e2e365bb2c66bea4b7b/2f950/image10.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<h2 id="time-comparison"><a href="#time-comparison" aria-label="time comparison permalink"></a>Time Comparison</h2>
<p>Sometimes looking at a trend is not enough to see how the data values are changing. In those cases, we recommend using the line chart count with Time Comparison function. This creates a second dotted line in the chart that shifts the time as specified.</p>
<div><p><a href="https://preset.io/static/f8c04e90b9c60a300652acc2ddd8db61/2f950/image11.png" target="_blank" rel="noopener">
    <span>
    <span></span>
    <img alt="GitHub API doc" title="image_tooltip" src="https://preset.io/static/f8c04e90b9c60a300652acc2ddd8db61/f6afc/image11.png" srcset="https://preset.io/static/f8c04e90b9c60a300652acc2ddd8db61/7b5b4/image11.png 188w,
https://preset.io/static/f8c04e90b9c60a300652acc2ddd8db61/a80c4/image11.png 376w,
https://preset.io/static/f8c04e90b9c60a300652acc2ddd8db61/f6afc/image11.png 752w,
https://preset.io/static/f8c04e90b9c60a300652acc2ddd8db61/3f9be/image11.png 1128w,
https://preset.io/static/f8c04e90b9c60a300652acc2ddd8db61/a34ba/image11.png 1504w,
https://preset.io/static/f8c04e90b9c60a300652acc2ddd8db61/2f950/image11.png 1600w" sizes="(max-width: 752px) 100vw, 752px">
  </span>
  </a></p></div>
<h2 id="summary"><a href="#summary" aria-label="summary permalink"></a>Summary</h2>
<p>In this article we summarized the importance of Time Series Visualizations and how powerful they are in terms of visualizing time series data. There are many other visualizations in Superset for your time series data ‚Äî as a first step, try changing the visualization type to see the different representations available to you.</p>
<p>In the next blog article we will discuss <strong><em>Geospatial Visualization Types</em></strong>.</p></div></div>]]>
            </description>
            <link>https://preset.io/blog/2020-06-26-timeseries-chart/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23709687</guid>
            <pubDate>Thu, 02 Jul 2020 03:32:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decision Tree in Sklearn ‚Äì A Complete Guide]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23709650">thread link</a>) | @min2bro
<br/>
July 1, 2020 | https://kanoki.org/2020/05/13/decision-tree-in-sklearn/ | <a href="https://web.archive.org/web/*/https://kanoki.org/2020/05/13/decision-tree-in-sklearn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<p>In this post we are going to see how to build a basic decision tree classifier using scikit-learn package and how to use it for doing multi-class classification on a dataset.</p>

<p>Decision trees is an efficient and non-parametric method that can be applied either to classification or to regression tasks.</p>

<p>To predict the dependent variable the input space is split into local regions because they are hierarchical data structures for supervised learning</p>

<p>Decision tree is a simple to learn and easy to interpret and Visualize the decisions in a tree format. It has the advantage of producing comprehensible classification/regression model with satisfactory accuracy level.</p>

<p>We will be exploring the DecisionTreeClassifier function of sklearn and all the parameters of it. You will also see how to Visualize the decision tree Rules and the Boundaries that model is creating to classify the different Classes(targets)</p>

<h2 id="decision-tree-classifier-in-sklearn"><strong>Decision Tree Classifier in Sklearn</strong></h2>

<div><div><pre><code>sklearn.tree.DecisionTreeClassifier(_criterion='gini'_,&nbsp;_splitter='best'_,&nbsp;_max_depth=None_,
&nbsp;
_min_samples_split=2_,&nbsp;_min_samples_leaf=1_,&nbsp;_min_weight_fraction_leaf=0.0_,&nbsp;_max_features=None_,&nbsp;

_random_state=None_,&nbsp;_max_leaf_nodes=None_,&nbsp;_min_impurity_decrease=0.0_,&nbsp;_min_impurity_split=None_,&nbsp;

_class_weight=None_,&nbsp;&nbsp;_ccp_alpha=0.0_)
</code></pre></div></div>

<h2 id="parameters"><strong>Parameters</strong></h2>

<h3 id="criterion"><strong>criterion</strong></h3>

<p>Gini or entropy and default is Gini.</p>

<p>One of the Critical factor is to choose which feature for splitting the nodes in subsets and for making that decision we choose out of these two criteria</p>

<ul>
  <li>Information Theory (Entropy)</li>
  <li>Distance Based (Gini)</li>
</ul>

<p>Both are impurity measures and it looks like the selection of impurity measure has little effect on the performance of single decision tree algorithms</p>

<p>The impurity is measured before and after splitting a node according to each possible attribute.</p>

<p>The attribute which presents the greater gain in purity, i.e., that maximizes the difference of impurity taken before and after splitting the node, is chosen</p>

<p>Entropy might be a little slower to compute because it makes use of the logarithm</p>

<h3 id="splitter"><strong>Splitter</strong></h3>

<p>Strategy to choose out of best or random. Default is best</p>

<p>If the best strategy is chosen then it will split on the most important feature first</p>

<p>it will choose a feature on random for splitting the node if splitter set to random which could lead to accuracy and more depth in the decision tree</p>

<h3 id="max_depth"><strong>max_depth</strong></h3>

<p>The maximum depth of the tree.</p>

<p>One of the stopping criteria that let you decide when to terminate the tree building process. A tree can be grown until a maximum depth is reached.</p>

<p>A tree can be grown to a maximum depth of N-1 where N is the number of samples</p>

<p>Beside max_depth there are other stopping criteria as well so in reality a tree will never go a maximum depth of N-1</p>

<p>Mostly we try to pick the optimal depth based on cross-validation and decides the reasonable max_depth value</p>

<h3 id="min_samples_split"><strong>min_samples_split</strong></h3>

<p>The minimum number of samples required at an Internal node for splitting. Say for example min_samples_split = 5 and there are 8 samples at a decision node then the split is allowed otherwise if &lt;5 then not allowed.</p>

<p>if <strong>min_sample_leaf</strong> = 2 and one leaf has 1 sample and other has 6 samples then the split is not allowed</p>

<p>so min_samples_split depends on the min-sample_leaf defined as well</p>

<p><img src="https://kanoki.org/images/2020/05/image-6.png" alt=""></p>

<h3 id="min_samples_leaf"><strong>min_samples_leaf</strong></h3>

<p>The minimum number of samples required at a leaf node</p>

<h3 id="min_weight_fraction_leaf"><strong>min_weight_fraction_leaf</strong></h3>

<p>The minimum weighted fraction</p>

<div><div><pre><code>`fit`(_self_,&nbsp;_X_,&nbsp;_y_,&nbsp;_sample_weight=None_,&nbsp;_check_input=True_,&nbsp;_X_idx_sorted=None_)
</code></pre></div></div>

<p>this parameter decides the required fraction of samples (or weights) in each leaf node</p>

<p>It uses the weight defined for each sample thru the fit method that has a <strong>sample_weight</strong> which lets you specify the weight of each of the samples and accepts values in an array like format for n_samples</p>

<p>if a minimum weight fraction is set and the sample weight is None then it will assume a uniform weight for all the samples</p>

<h3 id="max_features"><strong>max_features</strong></h3>

<p>It defines the number of features to be used for best split.</p>

<p>It is used to control the over-fitting. For example if the shape of your data is 30 and max_feature is set to 5.</p>

<p>So Every time at a decision node you will choose maximum of 5 features that are selected randomly for splitting</p>

<h3 id="random_state"><strong>random_state</strong></h3>

<p>It is the seed used by the random number generator. it is basically used to make the result or outcome of the classifier consistent.</p>

<p>It hardly matters what number you select but if you select the same number each time then the output remains deterministic</p>

<h3 id="max_leaf_node"><strong>max_leaf_node</strong></h3>

<p>maximum leaf node. It is one of the stopping criteria to grow a tree wih max_leaf_node.</p>

<p>By default it is set to None which means it will grow to unlimited leaf nodes and other stopping criteria will be considered</p>

<p>from the official <a href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html">documentation</a> the formula for weighted impurity decrease is as follows:</p>

<div><div><pre><code>N_t / N * (impurity - N_t_R / N_t * right_impurity
                    - N_t_L / N_t * left_impurity)
</code></pre></div></div>

<p>This formula takes into account how much the parent node makes up of the total tree (N_t / N) and the weighted impurity decrease from the child nodes.</p>

<p>If the final impurity decrease is less than the minimum impurity decrease parameter, then the split will not be performed</p>

<h3 id="class_weight"><strong>class_weight</strong></h3>

<p>By default all the classes have same weight i.e. 1</p>

<p>The class_weight parameter deals well with unbalanced classes by giving
more weight to the under represented classes.</p>

<p>It is used for re-weighting the splitting criterion</p>

<p>Higher the class_weight more you want to put emphasis on that class.</p>

<p>For multi-output, class_weights will be multiplied with <strong>sample_weight</strong> (passed through the fit method) if <strong>sample_weight</strong> is specified</p>

<h2 id="get-started"><strong>Get Started</strong></h2>

<p>We will use the wine dataset from sklearn.</p>

<p>Let‚Äôs load the data and then will split into train and test sets</p>

<div><div><pre><code>from sklearn import datasets
from sklearn.tree import DecisionTreeClassifier
wine_data = datasets.load_wine()
</code></pre></div></div>

<p>Let‚Äôs check out the important keys in this dataset</p>



<div><div><pre><code>dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])
</code></pre></div></div>

<p>So we have data, target variables with their names stored in target_names and feature names</p>

<p>Let‚Äôs find out the features in the data that we will use to train the decision tree classifier</p>



<div><div><pre><code>['alcohol',
 'malic_acid',
 'ash',
 'alcalinity_of_ash',
 'magnesium',
 'total_phenols',
 'flavanoids',
 'nonflavanoid_phenols',
 'proanthocyanins',
 'color_intensity',
 'hue',
 'od280/od315_of_diluted_wines',
 'proline']
</code></pre></div></div>

<p>Here are the different classes or targets in which each of these data is classified to i.e. class_0, class_1 and class_2</p>



<div><div><pre><code>**array(['class_0', 'class_1', 'class_2'], dtype='&lt;U7')**
</code></pre></div></div>

<p>Finally lets check the data by importing it into a Dataframe object. So you can visualize how the data looks like</p>

<div><div><pre><code>import pandas as pd
pd.DataFrame(wine_data.data,columns=wine_data.feature_names)
</code></pre></div></div>

<p>We can see there are 178 rows and 13 features in this dataset.</p>

<p><img src="https://kanoki.org/images/2020/05/image-7.png" alt=""></p>

<h2 id="train-test-split"><strong>Train Test Split</strong></h2>

<p>We have split the data into training and test set using sklearn train_test_split</p>

<div><div><pre><code>from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,
stratify=y)
</code></pre></div></div>

<h2 id="accuracy-score-and-cross-validation"><strong>Accuracy Score and Cross Validation</strong></h2>

<p>Lets measure the testing accuracy using sklearn accuracy_score.</p>

<p>For that we are going to instantiate the Decision tree classifier and then use the fit method on Train data.</p>

<p>Predict method of decision tree classifier will find the target class for the test data</p>

<p>Finally we will calculate the accuracy on our test data prediction</p>

<div><div><pre><code>from sklearn.metrics import accuracy_score

clf = DecisionTreeClassifier() #Instantiate Decision tree classifier
clf.fit(X_train, y_train)      # Use fit method on the train data

y_pred = clf.predict(X_test)   # Predict the target class of test data
accuracy_score(y_test, y_pred)  # Measure Accuracy
</code></pre></div></div>

<p>Let‚Äôs evaluate the cross validation score as well</p>

<div><div><pre><code>from sklearn.model_selection import cross_val_score
scores = cross_val_score(clf, X_test, y_test, cv=5)
print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))
</code></pre></div></div>

<h2 id="visualize-decision-tree-using-plot_tree"><strong>Visualize Decision Tree using plot_tree</strong></h2>

<p>You can also Visualize the final decision tree by using the plot_tree function of the sklearn.</p>

<p>There are other ways to visualize using pydot and graphviz but I‚Äôm not going to discuss those methods in this post</p>

<div><div><pre><code>%matplotlib inline
from matplotlib.pyplot import figure
from sklearn.tree import plot_tree
figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')
plot_tree(clf.fit(wine_data.data, wine_data.target))
</code></pre></div></div>

<p><img src="https://kanoki.org/images/2020/05/image.png" alt=""></p>

<h2 id="gridsearchcv"><strong>GridSearchCV</strong></h2>

<p>Hyper parameters selection is an important part for model selection. how would you know what combinations of these parameters will give you the best outcome?</p>

<p>One way is randomly selecting these values and see which combinations of parameters will give best result.</p>

<p>Isn‚Äôt that tedious to do? So Grid Search in Scikit-learn exactly does the same thing and helps to find the best estimator</p>

<div><div><pre><code>from sklearn.model_selection import GridSearchCV, cross_val_score
param_grid = {'criterion':['gini','entropy'], 'max_depth' :
[3,5,7,20]}
grid_search = GridSearchCV(clf,param_grid=param_grid,cv=5)
grid_search.fit(X_train, y_train)
</code></pre></div></div>

<p><img src="https://kanoki.org/images/2020/05/image-1.png" alt=""></p>

<p>You can see all the criteria and their respective score that gridsearch used to evaluate the best estimate by accessing the params and mean_test_score of grid search object</p>

<p>The params and the mean_test_score keys will give you the parameters and their corresponding results</p>

<div><div><pre><code>grid_search.cv_results_['params']
grid_search.cv_results_['mean_test_score']
</code></pre></div></div>

<div><div><pre><code>([{'criterion': 'gini', 'max_depth': 3},
  {'criterion': 'gini', 'max_depth': 5},
  {'criterion': 'gini', 'max_depth': 7},
  {'criterion': 'gini', 'max_depth': 20},
  {'criterion': 'entropy', 'max_depth': 3},
  {'criterion': 'entropy', 'max_depth': 5},
  {'criterion': 'entropy', 'max_depth': 7},
  {'criterion': 'entropy', 'max_depth': 20}],
 array([0.89466667, 0.878     , 0.88666667, 0.87866667, 0.93533333,
        0.91933333, 0.93533333, 0.91933333]))
</code></pre></div></div>

<h3 id="get-best-estimator"><strong>Get Best Estimator</strong></h3>

<p>We will use the best_estimator_ attribute to find the ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kanoki.org/2020/05/13/decision-tree-in-sklearn/">https://kanoki.org/2020/05/13/decision-tree-in-sklearn/</a></em></p>]]>
            </description>
            <link>https://kanoki.org/2020/05/13/decision-tree-in-sklearn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23709650</guid>
            <pubDate>Thu, 02 Jul 2020 03:25:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Supabase Alpha ‚Äì June 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23709312">thread link</a>) | @kiwicopple
<br/>
July 1, 2020 | https://supabase.io/blog/2020/07/01/supabase-alpha-june-2020 | <a href="https://web.archive.org/web/*/https://supabase.io/blog/2020/07/01/supabase-alpha-june-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>We're now 4 months into building <a href="https://supabase.io/">Supabase</a>, which means another major update. Here's a few things we think you'll love in this release.</p><h3>4 minute demo</h3><p>Watch a full demo:</p><h3>View relational data</h3><p>We're sometimes asked how we will make Postgres as simple as Firebase, since Postgres is a relational database. This month we're making our first steps to prove that relational databases can be even easier to use than document stores. We're releasing an excel-like editing interface which can drill down into your relational data.</p><h3>Manage JSON data</h3><p>Postgres is an amazing database, giving the flexibility of a document store with the power of a RDBMS. If you use <code>JSON</code> data in Postgres, then we want to make that easy too. Supabase detects when your column is <code>JSON</code> or <code>JSONB</code>, and provides an easy way to edit and view your data. More improvements coming soon for this feature!</p><h3>Choose your region</h3><p>If you noticed a bit of latency on Supabase, it's because your projects were previously set up in Singapore. It was always our intention that you'd be able to choose your database region, and this month we've delivered it. In the next releases we'll even allow you to go multi-region, instantly replicating your database close to your customers.</p><h3>Backups</h3><p>A guiding principle at Supabase is zero lock-in. So this month we are exposing your daily database backups on the dashboard, giving you a simple way to migrate off Supabase. We have a lot more to build in this space (<code>WAL-G!</code>), so watch this space.</p><h3>Kaizen</h3><p>We have a number of small improvements:</p><ul><li>Improved SQL editor - with better syntax highlighting</li><li>Improved API docs - with more code snippets</li><li>UX improvements - with a simplified and consistent UX</li></ul><h3>Hiring</h3><ul><li>This month we <a href="https://supabase.io/blog/2020/06/15/supabase-steve-chavez">welcome Steve Chavez to the team</a>. Steve is a maintainer of PostgREST, one of the core tools which makes Supabase possible. </li><li>We're hiring a part-time designer or UX expert. See more <a href="https://news.ycombinator.com/item?id=23708351" target="_blank" rel="noopener noreferrer">here</a>.</li></ul><h3>Get started</h3><ul><li>Start using Supabase today: <a href="https://app.supabase.io/">app.supabase.io</a></li><li>Make sure to <a href="https://github.com/supabase/supabase" target="_blank" rel="noopener noreferrer">star us on GitHub</a></li><li>Follow us <a href="https://twitter.com/supabase_io" target="_blank" rel="noopener noreferrer">on Twitter</a></li><li>Become a <a href="https://github.com/sponsors/supabase" target="_blank" rel="noopener noreferrer">sponsor</a></li></ul></section></div>]]>
            </description>
            <link>https://supabase.io/blog/2020/07/01/supabase-alpha-june-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-23709312</guid>
            <pubDate>Thu, 02 Jul 2020 02:25:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop Blocking Things at the Last Minute]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23708609">thread link</a>) | @svmanager
<br/>
July 1, 2020 | https://staysaasy.com/management/2020/07/01/Dont-Block-Projects.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/07/01/Dont-Block-Projects.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>One of the most frustrating and common experiences in the workplace is getting work blocked near the finish line. Examples:</p>
<ul>
  <li>A feature is developed over the course of 3 months. In the launch meeting a manager swoops in and declares it can‚Äôt be released for security reasons.</li>
  <li>You ask your manager for feedback on a proposal. They don‚Äôt respond. You ask again. They give a cursory glance and say ‚Äúlooks good‚Äù. A week later you say you‚Äôre ready to send it out. Suddenly they flood the document with feedback which ruins your timeline.</li>
  <li>An entire division works on a project for weeks. The minute they make it live the VP of the division storms in and yells ‚Äúrevert!‚Äù. The VP is displeased with the styling and insists it can‚Äôt be shipped that way.</li>
</ul>

<p>There‚Äôs usually one of 3 main causes for this anti-pattern:</p>
<ul>
  <li>Problem 1: Laziness/mis-calculation/ego. The stakeholder thinks it‚Äôs more efficient for them to engage with something closer to the finish line than early stage. This is often a gross mis-calculation. Projects are like cruise ships - you want to get to your destination with a lot of little steering along the way, not heroics after things have veered off course.</li>
  <li>Problem 2: Bad process. A critical stakeholder isn‚Äôt procedurally involved at the right time. If you find yourself blocking projects regularly, it‚Äôs your responsibility to fix this. <a href="https://staysaasy.com/process/2020/04/06/Creating-Good-Process.html">Create good process</a>.</li>
  <li>Problem 3: Micromanagement. The project/proposal didn‚Äôt actually need the manager‚Äôs feedback, they just can‚Äôt help having to put their stamp on everything.</li>
</ul>

<p>The solutions are simple but hard to master:</p>
<ul>
  <li>Answer 1: If you don‚Äôt think you need to be involved early, imagine the project goes live without your feedback at all. If you‚Äôre comfortable with that, you probably don‚Äôt need to be involved early (or at all). If you do need to give feedback, do it early and along the way.</li>
  <li>Answer 2: Make sure you have a process that involves necessary stakeholders at the right time.</li>
  <li>Answer 3: Don‚Äôt micromanage.</li>
</ul>

<p>If you mess up and find yourself giving major feedback near the finish line of a project, find ways to say yes and make sure you‚Äôre empathizing with the frustration that‚Äôs resulting from the late stage changes.</p>



<p>Some people actually take pride in blocking projects. Stakeholders who repeatedly view themselves as ‚Äúsaving the day‚Äù when it comes to tanking momentum and releases. They see themselves as a fountain of unique knowledge that prevent disasters.</p>

<p>This is almost always a result of incentives that are grossly mis-aligned. Some organizations have stakeholders who show up late in the game, who are not responsible for other teams being productive, who have 0 incentive to facilitate work and all the incentive to block things.</p>

<p>Companies should incentivize these stakeholders not only for preventing problematic releases, but also for the amount of things teams can get done to their requirements.  This ties their success to both risk management and enablement.</p>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/07/01/Dont-Block-Projects.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23708609</guid>
            <pubDate>Thu, 02 Jul 2020 00:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rich app, poor app ‚Äì social capital as currency]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23708585">thread link</a>) | @latc
<br/>
July 1, 2020 | https://4thquadrant.io/articles/mental-models/rich-app-poor-app-social-capital-as-currency/ | <a href="https://web.archive.org/web/*/https://4thquadrant.io/articles/mental-models/rich-app-poor-app-social-capital-as-currency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_29_01b">

<div>
<p>When it comes to the most popular platforms in the world, the motives behind certain feature roll-outs or a lack of early monetisation often seems to elude logic. Why hasn‚Äôt Whatsapp enabled payments sooner and Twitter moved toward monetisation more aggressively? Why did Facebook quietly roll back its influencer platform a few years ago? More recently, I find myself questioning why Instagram waited years to introduce the Checkout function that would have made it an intimidating e-commerce competitor much earlier in the game.&nbsp;</p>



<p>All of these seemingly spotlight decisions fall into a deliberate strategy tied to the lifeblood of these platforms, social capital. The long game is to cultivate social capital, gamify its distribution and eventually convert it into economic capital. Although social capital, in essence, is ephemeral and intangible, society‚Äôs collective agreement that it holds value makes it so ‚Äì much like money. In that sense, Social Media did for social capital what fiat did for economic capital. No longer as difficult to quantify, it has become the world‚Äôs mirror economy with value as tangible to an individual as monetary worth. The most explicit manifestation of this has been the rise of the influencer economy, the traditionally unspoken dynamics of social hierarchies and celebrity culture on steroids and now accessible to the masses.&nbsp;</p>



<p>For social media platforms, social capital is the fuel in their engine. Their business is the pursuit of the perpetual growth of collective social capital on their platform. As the platforms reach stages of greater maturity, the conversion funnel reaches its final stages as well ‚Äì the very stage Instagram is at the beginning of right now as it attempts to complete the loop of social to economic value creation. In essence, this is the fluid direction of influencer recommendations into convertible commercial transactions within the app. But the question remains ‚Äì could Instagram have implemented this feature successfully years before this point? The science behind this kind of decision is delicate, social capital must be cultivated and morphed in a way that value is not depleted from or ported away from the platform. Flow theory, a psychological concept of the mind‚Äôs ideal state of engagement provides a contextual model for how social media platforms like Instagram have achieved this balance.&nbsp;</p>



<h3>Gamifying social capital: creating a state of flow&nbsp;</h3>



<p>Flow theory, a broader psychological theory on how the optimal balance of skill and challenge creates a state of complete immersion is a core focus of gamification as it is applied in gaming itself, but also across various industries. When it comes to social media, platforms have built their networks through the gamification of social capital, building an immersive and engaging game-like experience around the act of accruing social capital ‚Äì ‚Äúhow many likes did it get?‚Äù now a popular criteria for validity. Both gaming and social media tactically withhold and subsequently trigger endorphins to create products that are addictive by nature.&nbsp; A comparison of how flow is cultivated across gaming and social media reveals a lot about the very habits many of us participate in, on a daily basis.&nbsp;</p>



<p><strong>Skill &amp; Challenge</strong></p>



<p><strong>In gaming ‚Äì</strong> the game must produce a task challenging enough for the player but not so challenging that the player‚Äôs skill level is incapable of completing the task</p>



<p><strong>In social media:</strong> building social capital (offline or online) inherently carries a degree of challenge that requires great effort to meet. The challenge is derived from your context (i.e. your friends or others on the platform) who may have larger followings or more liked photos. As a user‚Äôs ‚Äòsuccess‚Äô scales, their field of comparison grows with them, and thereby the challenge increases. This is the mechanism by which individuals are incentivised to perpetually grow their own social capital and therefore the platform‚Äôs collective capital.&nbsp;</p>



<p><strong>Engagement</strong></p>



<p><strong>In gaming:</strong> the task has to be active and engaging</p>



<p><strong>In social media:</strong> A challenge in itself is not rewarding enough to prompt or incentivise users to continue their accrual of social capital. The natural feedback loop of validation through followers, likes and other features create psychological self-fulfilment. Sometimes there is economic utility to be derived by those who seek to leverage their social capital beyond just validation. Pursuit of this feedback loop keeps the users active and engaged in the activities of the platform.&nbsp;</p>



<p><strong>Reward</strong></p>



<p><strong>In gaming ‚Äì</strong> the task has to have clear parameters for success. These clear parameters help to enter and maintain a ‚Äòflow state‚Äô as they indicate progress and quality.</p>



<p><strong>In social media:</strong> Success on social media platforms is measured by metrics like number of followers, likes and views. For users reaping economic rewards as well, the utility of their social capital can also be measured in sponsorships, ads and other forms of social media-driven income. While the latter is not as publicly available information, both types can lead to strong signalling of one‚Äôs success on social media.&nbsp;</p>



<p><strong>Motivation</strong></p>



<p><strong>In gaming ‚Äì</strong>&nbsp; the player must be intrinsically motivated to complete the task</p>



<p><strong>In social media: </strong>Where flow theory in gaming requires a complete blueprint of gamification to tap into the intrinsic motivation of players, socialising is a natural state of flow humans have always engaged in. The activity of building social capital is, for the most part, natural and instinctive especially when paired with the platform‚Äôs circular feedback loop for validation and reward.</p>



<h3>Making decisions and maintaining flow: the final stages</h3>



<p>Given that social media by its very nature can keep participants engaged without too much intervention, the most important element of gamification becomes the conversion of social capital into economic value. This has to be achieved without drowning the platform in mechanisms which disturb the state of flow already established.&nbsp;&nbsp;</p>



<p>The original set of features introduced by the platform for the accumulation of social capital has a shelf life, after which users will tire of it or reach a point of saturation that skews the effort to return balance necessary for flow. At this point platforms need to extend the avenues of creation, either by innovating existing features or introducing new features. This is the kind of thinking that drives Instagram to introduce ‚Äòstories‚Äô as opposed to just static posts for the feed.</p>



<p>However as the features start compounding, there is an inevitable layering of game theory mechanics which could heavily influence the state of flow. For this reason, the introduction of new features has to avoid detracting from the existing balance of social capital accumulation. If a feature presented a challenge greater than the effort or skill the user was willing to part with ‚Äì participation and therefore total social capital on the platform would take a hit.&nbsp;&nbsp;&nbsp;</p>



<p>In a similar sense, the introduction of the Instagram Checkout was a thoughtful and timely implementation over many years of incremental introductions that maintained the state of flow for users. Instagram prioritised the maintenance of social capital within its ecosystem, choosing not to risk the pre-emptive roll out of a feature that would deplete social capital or endanger the state of flow it was cultivating.&nbsp;&nbsp;</p>



<p>When users began tapping into off-platform mechanisms to convert their social capital into economic capital as a result of this, Instagram didn‚Äôt put up any barriers. Instagram would have seen this as priming its users for a later stage of its own conversion funnel without taking on any of the risk of disturbing its own state of flow. In 2016, when Instagram introduced Shopping tags for feed posts and later the Shopping tab in 2018, features that led to external stores for point of purchase, it was encouraging this behaviour ‚Äì all the while knowing it would eventually incorporate these tested habits back into its own environment.&nbsp;</p>



<h3>Social to economic capital: a delicate conversion</h3>



<p>Given that maintaining a state of flow is a key decision metric behind the strategies of killer platforms, a nuanced understanding of it better places us to predict how other platforms like Whatsapp and Twitter may navigate this delicate balance moving forward.&nbsp;</p>



<p>With 89% of influencers using Instagram, it ranks as the number one platform for influencer marketing ‚Äì no better testament to the economic rewards Instagram will reap as it begins cashing in its unparalleled social capital. Whilst we do not have many points of comparison for social media platforms at the scale of Instagram, the social capital it has been able to accrue is an undeniably powerful metric. Instagram in 2019 brought in 20 billion USD in revenue which accounts for more than a quarter of Facebook‚Äôs revenue in that year, only projected to grow further from there.&nbsp;</p>



<p>The careful transition of Instagram towards the full conversion funnel ensures its now end to end e-commerce experience is revered as a perfectly convenient segway for users as opposed to an uncomfortable push for higher revenues.&nbsp;</p>



<div id="slimcalltoaction"><p>This is box title</p><p>If you enjoyed this article, take advantage of our 14 days free trial to explore our exclusive content. View our subscription options <a href="https://4thquadrant.io/subscribe">here.</a></p></div>





<p>
<h3><span>Down the Rabbit Hole</span></h3>
</p>



<h3>1. Reverse network effects and the conundrum of maintaining palatable signal to noise ratios</h3>



<p>Network effects have seen social networks grow to valuations of billions and connect millions of users. It is tempting to believe that these platforms will remain fail-proof in perpetuity. The value created in a network relies on ‚Äòconnection, content and clout‚Äô.</p>



<p>‚ÄúAcross these three drivers, a network with greater scale provides greater value in the form of:</p>



<ol><li>More prospective connections for the user</li><li>A larger corpus of potentially relevant content</li><li>Access to a larger base of potential followers (greater clout), for ‚Ä¶</li></ol></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://4thquadrant.io/articles/mental-models/rich-app-poor-app-social-capital-as-currency/">https://4thquadrant.io/articles/mental-models/rich-app-poor-app-social-capital-as-currency/</a></em></p>]]>
            </description>
            <link>https://4thquadrant.io/articles/mental-models/rich-app-poor-app-social-capital-as-currency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23708585</guid>
            <pubDate>Thu, 02 Jul 2020 00:33:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Went Viral on Hacker News ‚Äì Here is what happened]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23708394">thread link</a>) | @remotists
<br/>
July 1, 2020 | https://www.shivaprabhakaran.com/post/went-viral-on-hacker-news | <a href="https://web.archive.org/web/*/https://www.shivaprabhakaran.com/post/went-viral-on-hacker-news">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.10.5"><div dir="ltr"><div><p id="viewer-foo">Yesterday at around 18:00, I started writing a post on my new Substack newsletter around mental models &amp; decision making. Little did I know that this post will go on to feature on the front page of Hacker News. </p><div id="viewer-d2uba"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.shivaprabhakaran.com/post/went-viral-on-hacker-news" data-pin-media="https://static.wixstatic.com/media/4a0eb5_6e27eaddd0f645a69d779893476f53b1~mv2.png/v1/fit/w_488,h_42,al_c,q_80/file.png" src="https://static.wixstatic.com/media/4a0eb5_6e27eaddd0f645a69d779893476f53b1~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 01-.283 0l-.374-.374a.2.2 0 010-.283l4.356-4.355h-3.786a.2.2 0 01-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 01-.2.2h-.529a.2.2 0 01-.2-.2zm-6.5 6.9v.529a.2.2 0 01-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 01.283 0l.374.374a.2.2 0 010 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z"></path></svg></div></div></div></div><p id="viewer-6a974">When I woke up today, I checked my Substack and this is what I found.</p><div id="viewer-dh0j"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.shivaprabhakaran.com/post/went-viral-on-hacker-news" data-pin-media="https://static.wixstatic.com/media/4a0eb5_518d658332ea46c8a71153d485e49ad4~mv2.png/v1/fit/w_867,h_566,al_c,q_80/file.png" src="https://static.wixstatic.com/media/4a0eb5_518d658332ea46c8a71153d485e49ad4~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 01-.283 0l-.374-.374a.2.2 0 010-.283l4.356-4.355h-3.786a.2.2 0 01-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 01-.2.2h-.529a.2.2 0 01-.2-.2zm-6.5 6.9v.529a.2.2 0 01-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 01.283 0l.374.374a.2.2 0 010 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z"></path></svg></div></div></div></div><p id="viewer-cmeq6">While it is great that I got a lot of traffic from Hacker News, I didn't get a lot of subscribers primarily because I didn't add a subscribe button on the post. I gained just 53 and I have since then added the button to the post.</p><div id="viewer-89lvi"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.shivaprabhakaran.com/post/went-viral-on-hacker-news" data-pin-media="https://static.wixstatic.com/media/4a0eb5_2a066eb3044f40b2819008945d7b9013~mv2.png/v1/fit/w_795,h_699,al_c,q_80/file.png" src="https://static.wixstatic.com/media/4a0eb5_2a066eb3044f40b2819008945d7b9013~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 01-.283 0l-.374-.374a.2.2 0 010-.283l4.356-4.355h-3.786a.2.2 0 01-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 01-.2.2h-.529a.2.2 0 01-.2-.2zm-6.5 6.9v.529a.2.2 0 01-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 01.283 0l.374.374a.2.2 0 010 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z"></path></svg></div></div></div></div><p id="viewer-57fh3">I also noticed that there is a discrepancy between data from Google Analytics and Substack's native analytics. While Substack shows the traffic to be around 20k, GA on the other hand shows only 10k.</p><div id="viewer-euios"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.shivaprabhakaran.com/post/went-viral-on-hacker-news" data-pin-media="https://static.wixstatic.com/media/4a0eb5_98ea421214a44d0881fc294f95050d70~mv2.png/v1/fit/w_1142,h_646,al_c,q_80/file.png" src="https://static.wixstatic.com/media/4a0eb5_98ea421214a44d0881fc294f95050d70~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 01-.283 0l-.374-.374a.2.2 0 010-.283l4.356-4.355h-3.786a.2.2 0 01-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 01-.2.2h-.529a.2.2 0 01-.2-.2zm-6.5 6.9v.529a.2.2 0 01-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 01.283 0l.374.374a.2.2 0 010 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z"></path></svg></div></div></div></div><p id="viewer-91ono">Here is a further break down with the source/medium which shows that majority of the traffic was from Hacker News followed by Twitter, Indie Hackers and Reddit.</p><div id="viewer-31i0"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.shivaprabhakaran.com/post/went-viral-on-hacker-news" data-pin-media="https://static.wixstatic.com/media/4a0eb5_af728d07a45a42198ce909e127ba3e43~mv2.png/v1/fit/w_1115,h_527,al_c,q_80/file.png" src="https://static.wixstatic.com/media/4a0eb5_af728d07a45a42198ce909e127ba3e43~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 01-.283 0l-.374-.374a.2.2 0 010-.283l4.356-4.355h-3.786a.2.2 0 01-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 01-.2.2h-.529a.2.2 0 01-.2-.2zm-6.5 6.9v.529a.2.2 0 01-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 01.283 0l.374.374a.2.2 0 010 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z"></path></svg></div></div></div></div><p id="viewer-elfoi">While I am happy that this went viral, there are a few things that I wish I had done. </p><ol><li id="viewer-8kssf"><p>Add a subscribe button in the post. </p></li><li id="viewer-7d7o9"><p>Add a sponsor/affiliate link in the post</p></li><li id="viewer-5l8vh"><p>Structure the post a little better.</p></li><li id="viewer-el4ov"><p>Respond to comments on HN to drive engagement.</p></li></ol><p id="viewer-4bovn">Here is the original post: <a href="https://models.substack.com/p/circle-of-competence-avoid-ambiguity" target="_blank" rel="noopener">https://models.substack.com/p/circle-of-competence-avoid-ambiguity</a></p><p id="viewer-4ftbm">If you like that post, consider subscribing. I'll answer any questions you may have in the comments. </p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.shivaprabhakaran.com/post/went-viral-on-hacker-news</link>
            <guid isPermaLink="false">hacker-news-small-sites-23708394</guid>
            <pubDate>Thu, 02 Jul 2020 00:10:30 GMT</pubDate>
        </item>
    </channel>
</rss>
