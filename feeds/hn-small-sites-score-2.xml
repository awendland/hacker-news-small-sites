<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 04 Oct 2020 08:26:25 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 04 Oct 2020 08:26:25 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Why Privacy Is the Most Important Concept of Our Time]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24661271">thread link</a>) | @umilegenio
<br/>
October 2, 2020 | https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/ | <a href="https://web.archive.org/web/*/https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-25770" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>I have always believed in the importance of privacy, but I felt that common definitions (e.g., <em>the right to be left alone</em>) were lacking. In fact, I think that the whole conceptualization of privacy as simply a right of an individual as partial and limiting. It could be because privacy, as <a href="https://en.wikipedia.org/wiki/Privacy">it is intended nowadays, originated from the Anglo-American world (that is what Wikipedia says</a>). </p>



<p>You might say that then, maybe, I am not really thinking about privacy, but rather something else. That might be true, so let‚Äôs not talk about privacy, instead let‚Äôs talk about <a href="https://en.wikipedia.org/wiki/Definitions_of_fascism#Umberto_Eco">Ur-Privacy</a>, the properties of any version of the concept of privacy you might have. Take this as the opinion of a random guy that cares about the issue.</p>



<div><h2>What is Ur-Privacy</h2><p><em>A few principles for privacy</em></p></div>







<p><strong>Privacy is about boundaries.</strong> <strong>It is not about hiding something from someone but allowing to create a space with rules</strong> <strong>decided by its members</strong>. I like to compare it to borders. Some people say that borders are a restriction, something that limit freedom of movement and we do not need in the contemporary world. As if they were arbitrary obstacles put there by the ancient petty Greek gods. It almost makes sense if you do not think about them, after all you are actually stopped at a border.</p>



<p>However, that is not true, that is not why they exist. Borders delimit the area that a certain state control, an area where a specific set of rules and laws applies. There was a time before borders, in fact most of human history did not have clear borders. It was not a time of freedom, but anarchy, where bands of barbarians could roam into your home and pillage everything.</p>



<p>In this context is also important to remember that before the <a href="https://en.wikipedia.org/wiki/Peace_of_Westphalia">Peace of Westphalia</a> modern European states were plagued by continual wars. The short version is that this was due to the combination of two facts:</p>



<ul><li>modernity begets differences, different kings choose different religions<sup><a id="link_1" href="#note_1" data-type="internal" data-id="#note_1">1</a></sup> and separated societies</li><li>however, the legitimacy of kings was still based on shared medieval ideals, like the concept of divine rule</li></ul>



<p>In short, the issue was not that leaders wanted to make war all the time, they needed to do so because the legitimacy of their power depended, at least on some level, to what the rest of the European world was doing. If you claim to be a divine king there better be agreement on what the divine is, otherwise a guy that picks a different religion can also rightly pick a different king. To change the situation this peace treaty established the principle that the internal affairs of a state are the exclusive interest of said state.</p>



<p>The connection with privacy is that without clear rules on what is private and what is public, nobody knows which stuff belongs to whom and this means that all belong to the strongest. <strong>Somebody might say that what you do in private, it is not private at all but political, it concerns the society at large. Therefore it must be regulated according to their rules</strong>.</p>



<p><strong>Privacy is about control</strong>. <strong>Without privacy we cannot decide for ourselves how to live our lives.</strong> If there is no privacy all become public. Whoever has more power and an interest can affect your life according to their own rules. Then, I have to care about what other people think, otherwise they will control how I can behave. As before the peace of Westphalia, the issue is not that other people are bad, <em>they have to do it</em>. When everything is subject to public scrutiny, you either control the rules and judge others or you are judged and controlled by others.</p>



<p>Think about this way: we say a lot of things in our private lives that are not meant to be taken literally. In private we say something and then we add: <em>you know what I mean</em>. And that is actually true. We can do that because the people we talk to in private know us; they understand the context in which our words must be understood. When I was a child I would sometimes say and think that I wanted to kill my brother. I did not meant literally and everybody knew it. If I said the same thing now, in public, to somebody that does not know me, the phrase would be different. It would be a <a href="https://en.wikipedia.org/wiki/Threat">threat</a>.</p>



<p>Why is that? They are the exact same words. You know why, of course. I am different and the context is different. The real meaning of something, whether an action or a word, is not absolute, in most cases is relative. When we speak in public, we share a different context, therefore our words have a different meaning.</p>



<p>So even I say something as an hyperbole or as an potentially implicit threat (e.g., <em>they must be stopped at all costs</em>!), they might protest. You might say that they are overreacting, that it was just a joke, but <em>how can they be sure of it</em>? <strong>They do not know me.</strong> <strong>And it is true that acts of violence are prepared by violent words</strong>. Even if you are unsure if something is really violent, you have to take a stand. You have to make clear that any attack against you is not permissible. Otherwise, <a href="https://en.wikipedia.org/wiki/Christchurch_mosque_shootings" data-type="URL" data-id="https://en.wikipedia.org/wiki/Christchurch_mosque_shootings">somebody, maybe a crazy guy, might think that it is permissible and the right course of action</a>. Somebody might feel legitimate to take your land and kingdom.</p>



<p>A clear example of the loss of privacy is the <em>rise of violent rhetoric</em>. Everybody swears and everybody threaten. However, for the most part they do not mean it. We know that because the actual rate of violence has not risen. We simply talk in public as we talk in private, because our private lives have become more public. I mean, some bosses want even to look at your Facebook profile<sup><a href="#note_2">2</a></sup><a id="link_2" href="https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/note_2">.</a></p>



<div><h2>Privacy Affects Everything</h2><p><em>Defending privacy would require all-around changes</em></p></div>







<p><strong>Privacy is the most important concept of our time, because it allows to define everything else. Without privacy we do not know what rules applies. Our lives will be judged according to the rules, even the whims, of somebody else.</strong></p>



<p>People lost jobs and had their lives ruined, because the mob judged something they said in private in a different way from what they expected. And they paid a price. You might say: that was fair. We might judge ourselves by our intentions, but others by their actions, which are real and objective.</p>







<p>I, for once, disagree with XKCD and this view. There are a couple of different issues here:</p>



<ul><li>how we should react to speech we disagree with</li><li>what was meant to be shared among friends was taken out of context and made public</li></ul>



<p>This complicates the whole matter. At a first glance the first issue should not matter here, because we are talking about privacy. However, this is a bit more complicated. Violations of privacy can affect other rights and freedom. Freedom of speech is a right regarding the public sphere. You have always been able to say everything in private, for the simple fact that people cannot control that. If now the private becomes public, then either we get absolute freedom of speech (a sort of <em>speech anarchy</em>, if you will) or we lose freedom of speech.</p>



<p>Okay, then we demand to not violate privacy even in the case of bad speech. If you said something bad in private then I cannot demand your boss to fire you. I cannot do that even by maintaining privacy: <em>trust me on this, they say something really bad</em>,<em> you should fire them</em>. This is a practical example of how privacy might affect everything.</p>



<p>This is crucial, but we have to understand that simply enforcing privacy in the traditional way is not enough anymore. To protect privacy we need to re-interpret some rights we have. For instance, traditionally there have been exceptions to privacy for public interest. If you heard somebody famous saying something controversial in private you could go public about. The issue is that few people (i.e., the press) had that power. Now we all have it. <strong>So, to defend privacy we need to accept shared norms of behavior</strong>. We cannot expect consequences outside the context that caused them.</p>



<p>This is hard to do, because people have different idea of public interest. It is not true that we judge other by their actions. We judge others by <em>our intentions</em>. So, we must be strict about the norm that the answer to some speech should be only some other form speech. In other words, if somebody offended you with some method, you should respond with the same method. If somebody said something bad, you cannot shove them. <strong>Actions by a mob in order to punish an alleged transgressor, punish a convicted transgressor, or intimidate them is not an answer to a bad argument, it is a<a href="https://en.wikipedia.org/wiki/Lynching"> lynching</a></strong>.</p>



<p>There is a difference between killing somebody and just ruining their lives. However, it is still bad. It is still lynching, something we do to one to control one hundred. Making somebody lose their livelihood because of something said in private it is not fair, because they said in a different context. They were not prepared to be judged by their worst enemies. And they should not have. </p>



<p>The philosopher Jeremy Bentham described the perfect prison as the <a href="https://en.wikipedia.org/wiki/Panopticon">Panopticon</a>. A prison where in every cell there was a one-way mirror. This way the guards could watch the inmates without being seen. Therefore the inmates would have to behave as if they were always watched. That kind of sounds like the world right now. And I am ready to lose the power to punish bad people in order to protect me from people that think I am a bad guy.</p>



<p><em>Given the discussion on Hacker News, I think that I was a bit unclear here. The connection between privacy and freedom of speech is just an example. My point is that privacy affects how we enjoy other rights, too. Even though that might not seem obvious at first.  </em></p>



<div><h2>What Should We Do?</h2><p>A modest proposal</p></div>







<p>So what has to be done to defend privacy? <strong>There should be clear boundaries about private, social and public spaces</strong>:</p>



<ul><li>a private space regards only you or your family</li><li>a social space is something involving a community, either a virtual one like a forum or a real one like a city</li><li>a public space is a space for all actors of society</li></ul>



<p>By clear boundaries I mean that we should create rules, ‚Ä¶</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/">https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/</a></em></p>]]>
            </description>
            <link>https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661271</guid>
            <pubDate>Fri, 02 Oct 2020 10:55:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flatpak: A security nightmare ‚Äì two years later]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24661126">thread link</a>) | @krimeo
<br/>
October 2, 2020 | https://www.flatkill.org/2020/ | <a href="https://web.archive.org/web/*/https://www.flatkill.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>Two years ago I <a href="https://flatkill.org/">wrote</a> about then heavily-pushed Flatpak, self-proclaimed "Future of Apps on Linux". The article criticized the following three major flows in Flatpak:</p><ul>
<li>Most of the apps have full access to the host system but users are misled to believe the apps are sandboxed
</li><li>The flatpak runtimes and apps do not get security updates
</li><li>Flatpak breaks many aspects of desktop integration
</li></ul>

<!-- <p>A lot has changed in the 2 years (the company behind Flatpak is now just another IBM's brand for one thing) so let's see how Flatpak developers addressed these fundamental issues.</p> -->
<p>So let's see how Flatpak developers addressed these fundamental issues.</p>

<h2>The sandbox is STILL a lie</h2>

<p>Almost all popular apps on Flathub still come with <span>filesystem=host</span> or <span>filesystem=home</span> permissions, in other words, <b>write access to the user home directory</b> (and more) so all it takes to escape the sandbox is trivial <span>echo download_and_execute_evil &gt;&gt; ~/.bashrc</span>. That's it.</p>


<p>The most popular applications on Flathub still suffer from this - Gimp, VSCodium, PyCharm, Octave, Inkscape, Audacity, VLC are still not sandboxed.</p>

<p>And, indeed, users are still mislead by the reassuring blue "sandboxed" icon. Two years is not enough to add a warning that an application is <b>not</b> sandboxed if it comes with dangerous permissions (like full access to your home directory)? Seriously?</p>

<img src="https://www.flatkill.org/2020/sandboxlie.png" alt="sandboxlie">

<h2>Flatpak apps and runtimes STILL contain long known security holes</h2>
<p>It took me about 20 minutes to find the first vulnerability in a Flathub application with full host access and I didn't even bother to use a vulnerability scanner.</p>

A perfect example is <a href="https://www.cvedetails.com/cve/CVE-2019-17498">CVE-2019-17498</a> with public exploit <a href="https://github.com/github/securitylab/tree/main/SecurityExploits/libssh2/out_of_bounds_read_disconnect_CVE-2019-17498">available</a> for some 8 months. The first app on Flathub I find to use libssh2 library is Gitg and, indeed, it does ship with unpatched libssh2.

<p>But is it just this one application? Let's look at the <b>official runtimes</b> at the heart of Flatpak (org.freedesktop.Platform and org.gnome.Platform <b>3.36</b> - as of time of writing used by most of the applications on Flathub). The first unpatched vulnerable dependency I found in the offical runtime is ffmpeg in version 4.2.1 with no security patches backported, <a href="https://www.cvedetails.com/cve/CVE-2020-12284">CVE-2020-12284</a>.</p><p>Recently I stumbled upon an article from 2011 which started what is today known as flatpak, <a href="https://people.gnome.org/~alexl/glick2">in the words of the project founder:</a></p>

<p><a href="https://people.gnome.org/~alexl/glick2"><b><i>"Another problem is with security (or bugfix) updates in bundled libraries. With bundled libraries its much harder to upgrade a single library, as you need to find and upgrade each app that uses it. Better tooling and upgrader support can lessen the impact of this, but not completely eliminate it."</i></b></a></p>

<p>After reading that it comes as no surprise flatpak still suffers from the same security issues as 2 years ago because flatpak developers knew about these problems from the beginning.</p>

<h2>Local root exploits are NOT considered a minor issue anymore!</h2>
<p>Great! Two years ago I wrote about a trivial local root exploit using flatpak to install suid binaries (<a href="https://www.cvedetails.com/cve/CVE-2017-9780/">CVE-2017-9780</a>) and how it was downplayed by Flatpak developers as a minor security issue <a href="https://github.com/flatpak/flatpak/releases/tag/0.8.7">here</a>. I am happy to see at least the attitude to local root exploits has changed and today <a href="https://github.com/containers/bubblewrap/security/advisories/GHSA-j2qp-rvxj-43vj">local root exploits</a> are considered high severity.

</p><h2>Desktop integration</h2>
<p>System and user fonts are now available to flatpak applications and basic font rendering settings are respected as well, however do not expect your changes in /etc/fonts, typically setting a proper fallback font for CJK characters, to work with flatpak.  KDE applications in flatpak are still ignoring themes, fonts and icon settings (tested with Qt5ct). Applications installed from the distribution sources do not have these problems, of course. <a href="https://www.flatkill.org/2020/desktopbrokenation.mp4">A quick screen capture to demonstrate</a>.</p>

<p>More importantly, fcitx, <i>the</i> IME for Chinese is still broken - it has been 2 years. Here is the <a href="https://github.com/flatpak/flatpak/issues/2031">issue</a> I linked 2 years ago - especially of interest is <a href="https://github.com/flatpak/flatpak/issues/2031#issuecomment-655134889">the following comment</a> directly from fcitx developer:

</p><p><i>"Because fcitx im module in flatpak is from 4.2.97 and using a different dbus object path. <b>It need to be the same version of fcitx on your host</b>."</i></p>

So I need to run multiple fcitx daemons on my desktop and switch between them as I switch flatpak apps depending on which fcitx libraries are bundled with that app or maybe in the future of linux apps it's not possible to type chinese anymore and it's fine?

<p>While the "bundle everything" approach has proven very useful on servers it clearly does not work for desktop applications, let's keep linking system libraries in desktop applications (and use the bundled libraries as a fallback only) to avoid introducing all these problems to Linux desktop.</p>



</div>]]>
            </description>
            <link>https://www.flatkill.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661126</guid>
            <pubDate>Fri, 02 Oct 2020 10:35:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Node.js malware caught posting IPs, username, and device info on GitHub]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660810">thread link</a>) | @axsharma
<br/>
October 2, 2020 | https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/ | <a href="https://web.archive.org/web/*/https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <!-- .entry-header -->

                
                        <div>
                                    <p><img width="1024" height="683" src="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg" alt="red and blue hearts illustration" loading="lazy" srcset="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg 1024w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-300x200.jpg 300w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-768x512.jpg 768w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1536x1024.jpg 1536w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-2048x1365.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg 1024w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-300x200.jpg 300w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-768x512.jpg 768w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1536x1024.jpg 1536w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-2048x1365.jpg 2048w" data-src="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">                </p>
            
                                            </div>

            

        <!-- end slider-section -->
                                    

    <div>
        <div>
            




<p>Multiple NodeJS packages laden with malicious code have been spotted on npm registry.</p>



<p>These ‚Äútyposquatting‚Äù packages served no purpose other than collecting data from the user‚Äôs device and broadcasting it on public GitHub pages.</p>



<p>The findings were spotted by Sonatype‚Äôs <a href="https://blog.sonatype.com/sonatype-spots-malicious-npm-packages" target="_blank" rel="noreferrer noopener">automated malware detection systems</a> and further investigated by the company‚Äôs Security Research team which includes me. </p>



<p>The packages previously present on the open source npm registry included:</p>



<ol><li><a rel="noreferrer noopener" href="https://www.npmjs.com/package/electorn" target="_blank">electorn</a> (intentional misspelling of a legitimate package ‚Äúelectron‚Äù)</li><li><a rel="noreferrer noopener" href="https://www.npmjs.com/package/loadyaml" target="_blank">loadyaml</a> </li><li>loadyml</li><li>lodashs (intentional misspelling of a legitimate package ‚Äúlodash‚Äù)</li></ol>



<p>All four packages were published by the same user ‚Äúsimplelive12‚Äù and have now been removed, with the first two having been taken down by npm as of October 1, 2020. The previous two packages were unpublished by the author themselves.</p>



<p>Once installed, <code>electorn</code> ran a script in the background <strong>every</strong> <strong>hour</strong> which collected the logged-in user‚Äôs IP, geolocation data, username, path to home directory, and CPU model information.</p>



<figure><img loading="lazy" width="1024" height="356" src="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png" alt="" srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-1-300x104.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-1-768x267.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1-1536x534.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image-1-2048x712.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-1-300x104.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-1-768x267.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1-1536x534.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image-1-2048x712.png 2048w" data-src="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>The malicious code within <code>electorn</code> and 3 other identical packages which exfiltrated user information</figcaption></figure>



<p>This information, part of which constitutes the device ‚Äúfingerprint‚Äù was uploaded and published on <a rel="noreferrer noopener" href="http://web.archive.org/web/20201001065601/https://github.com/h4ppyl1ve/collect/issues/4" target="_blank">GitHub</a> in real-time.</p>



<p>Some of the information being published is base64-encoded but this can be trivially decoded by anyone who has access to it:</p>



<figure><img loading="lazy" width="1024" height="488" src="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png" alt="" srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-300x143.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-768x366.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1536x732.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image.png 1632w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-300x143.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-768x366.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1536x732.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image.png 1632w" data-src="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>Sonatype‚Äôs Security Research team has accounted for these malicious packages into their products, and had notified both npm and GitHub teams of the malicious activity stemming from the components. This led to the takedown of these malicious packages. </p>



<p>To this date, all 4 packages have scored a little over <strong>400</strong> total downloads.</p>



<p>It is not exactly clear what was the purpose of collecting this data and why was it being published on the web for the world to see, however, incidents like these highlight the potential of typosquatting attacks on the open-source ecosystem.</p>



<p>We can only imagine what the next possible version of these packages could have been capable of ‚Äì possibly carrying out even more sinister activities. </p>



<p>By tricking an unsuspecting developer into mistakenly installing a misspelled package, attackers can push their malicious code ‚Äúdownstream‚Äù into any other open-source projects that use the misspelled malicious component as a transitive dependency.</p>



<p>Adopting DevSecOps best practices and building security early on into your software development lifecycle can prevent ‚Äúcounterfeit components‚Äù such as electorn and loadyaml from entering, and thriving in your software supply chains.</p>



<p>The complete research findings are available on the <a href="https://blog.sonatype.com/sonatype-spots-malicious-npm-packages" target="_blank" rel="noreferrer noopener">Sonatype blog</a>.</p>
                <div>
                    <h3>About the author</h3>
                                        
        <div>

                <p><a href="https://securityreport.com/author/ax-sharma/"><img alt="" src="https://secure.gravatar.com/avatar/d0d95768ca47b1764f5fb964cf860afa?s=150&amp;d=retro&amp;r=pg" srcset="https://secure.gravatar.com/avatar/d0d95768ca47b1764f5fb964cf860afa?s=300&amp;d=retro&amp;r=pg 2x" height="150" width="150" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></a>
                </p>
                <div>
                    <h4>
                        <a href="https://securityreport.com/author/ax-sharma/">Ax Sharma</a>
                    </h4>

                    
                    
                                            <p>
                        <a href="https://axsharma.com/" target="_blank">https://axsharma.com/</a>
                        </p>
                                        <div>
                        <p>Ax Sharma is a Security Researcher, Engineer, and Tech Columnist. His works and expert analyses have frequently been featured by leading media outlets like Fortune, The Register, TechRepublic, CIO, etc.</p>
<p>Ax‚Äôs expertise lies in vulnerability research, reverse engineering, software development, and web app security. He‚Äôs an active community member of the OWASP Foundation and the British Association of Journalists (BAJ).</p>
<p>Send any tips via email or Twitter DM.</p>
                    </div>
                    
                                    </div>
        </div>

                                            </div>
                                            
                        
	<nav role="navigation" aria-label="Continue Reading">
		<h2>Continue Reading</h2>
		
	</nav>                    </div><!-- .entry-content -->
    </div>
                        </div></div>]]>
            </description>
            <link>https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660810</guid>
            <pubDate>Fri, 02 Oct 2020 09:47:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Please Stop Imposing American Views about Race on Us]]>
            </title>
            <description>
<![CDATA[
Score 297 | Comments 214 (<a href="https://news.ycombinator.com/item?id=24660682">thread link</a>) | @dgellow
<br/>
October 2, 2020 | https://www.persuasion.community/p/please-stop-imposing-american-views | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/please-stop-imposing-american-views">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/e3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:18107111,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>Construction workers reopen Winston Churchill statue in Parliament Square after it was covered with metal panels to protect it against defacement by protestors.</em></p><p>Over the past couple of months, many Britons have imported American discourse on race wholesale. When asked to analyze the experiences of black people in the United Kingdom, we now talk with an American accent.</p><p>Take a look, for instance, at a meme that has been circulating among some of my white friends on Facebook and Instagram:</p><blockquote><p>I have privilege as a White person because I can do all of these things without thinking twice about it ‚Ä¶ I can go jogging (#AmaudArbery). I can relax in the comfort of my own home (#BothemSean and #AtatianaJefferson). I can ask for help after being in a car crash (#Jonathan Ferrell and #RenishaMcBride). I can have a cellphone (#StephonClark). I can leave a party to get to safety (#JordanEdwards). I can play loud music (#JordanDavis). I can sell CDs (#AltonSterling). I can sleep (#AiyanaJones). I can walk from the corner store (#MikeBrown).</p></blockquote><p>The post goes on and on, like an interminable spoken-word poem. All the individuals listed are American, but most of the people who have shared this on my timeline are British. In trying to express their solidarity with black Britons, they are affirming a supposedly transcendental truth: to be black is to live in perpetual terror of being murdered by the state. </p><p>But Britain is not America. And importing American race discourse into the United Kingdom not only prevents us from recognizing the specific ways in which racial injustice manifests in this country‚Äîit cloaks the reality of black British lives behind an abstraction that flattens our humanity. </p><p>Britain has a long and painful history of anti-black racism. In the twentieth century alone, the growing black presence led to a long catalogue of abuses: the 1919 race riots in Liverpool, Cardiff and London; the 1958 race riots in Nottingham and Notting Hill; the 1969 police murder of David Oluwale, a Nigerian immigrant who was tortured, pissed on and finally drowned in a river in Leeds. I could list other examples. It is not hard to see why the horrific killing of George Floyd has evoked such strong feelings in this country as well.</p><p>But for all of the country‚Äôs flaws, Britain is not America. Trying to understand its racial dynamics through the lens of another country‚Äôs does more to obscure than to illuminate the situation that black Britons like myself actually face.</p><p>The average black American in the United States can trace his ancestry further back than the average white American. Most black Americans are descended from enslaved Africans. Their forebears suffered through the segregation and racial terror of the Jim Crow era. The majority of black people in the United Kingdom, by contrast, are immigrants or the children of immigrants. Though many of them have certainly had harrowing experiences with injustice or discrimination, they do not have the same history of racist disadvantage.</p><p>To understand the experience of black Britons, it is not only necessary to grasp how different their history is from that of black Americans: we need to understand the diversity captured by the label ‚Äúblack British.‚Äù For example, around two out of every three students with Congolese or Somali origins get free school meals, a standard indicator that their parents are poor. Among students with Nigerian or Ghanaian origins, only one in five do. It is also noteworthy that black Caribbean students are twice as likely to be excluded from school as black African students. </p><p>The discrepancy in educational attainment is just as stark. On average, 58% of black African students graduate from middle school at grade level (defined as achieving A* to C grades at GCSE)‚Äîabout the same number as white students. But black Caribbean students are significantly less likely to do so‚Äîwhile those whose parents hail from Nigeria actually outperform their white peers by a considerable margin. </p><p>None of this is to disavow the label ‚Äúblack British.‚Äù But we need to invest it with the nuance consonant with its reality‚Äîand to cast doubt on the idea that every discrepancy in representation must be explained by structural injustice or white supremacy.</p><p>There has, for example, been a lot of concern about the underrepresentation of black Britons in professions like the arts and publishing. But why would you choose to go into theater or journalism‚Äîrather than law, medicine or finance‚Äîif you are a talented child of ambitious but not well off immigrants? </p><p>This is not a flippant question. While representation can be important, anybody who actually wants to improve the condition of black Britons should at least be a little curious about why they are overrepresented in some prestigious professions and underrepresented in others. In a country in which black people make up only three percent of the population, for example, six percent of junior doctors are black. Would the country‚Äîor the black community‚Äîreally benefit if more black Britons chose to ditch medicine for the theater? The debate is worth having. But in the place of that debate, there have only been pious paeans to diversity.</p><p>The stereotype of the West African parent who wants their child to study law or medicine bears some relation to reality; but the widespread view of black people as perennial victims devoid of agency is a defamatory abstraction. The black person in Britain, like Ralph Ellison‚Äôs iconic protagonist, is ‚Äúinvisible because no one wants to see him.‚Äù</p><p>So much of the British reaction to the death of George Floyd has constituted a failure of nerve. Desperately seeking to assuage their feelings of guilt, to do <em>something</em>, many Britons have sacrificed their critical faculties to a narrative that does not actually help black people‚Äîa narrative that, by reducing us to passive abstractions, only makes us more invisible.</p><p>Racists assume that black people are all the same. Ironically, anti-racists sometimes do so too. But anybody who is truly committed to racial equality needs to recognize that this kind of simplification neither serves justice nor reflects the truth.</p><p><strong>Tomiwa Owolade is a writer who lives in London.</strong></p></div></div>]]>
            </description>
            <link>https://www.persuasion.community/p/please-stop-imposing-american-views</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660682</guid>
            <pubDate>Fri, 02 Oct 2020 09:20:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quick Test to Figure Out Why You Feel Down Lately]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660666">thread link</a>) | @azarai
<br/>
October 2, 2020 | https://mindfuldevmag.com/issues/issue-8-readers-questions/felling-down-figure-out-why-test | <a href="https://web.archive.org/web/*/https://mindfuldevmag.com/issues/issue-8-readers-questions/felling-down-figure-out-why-test">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            <div>
                                                                            
                                                                         <p>Feeling down lately?</p>
<p>But you don‚Äôt know why?</p>
<p>This quick test helps you to figure it out and gives you tips on getting up again.</p>
<h2>Quick Test</h2>
<blockquote>
<p>Did you sleep 7-8 hours a night for most of the last 7 days?</p>
</blockquote>
<p>Sleep is essential, and we should not skip on that. While we sleep, our brain processes the day and also cleans itself of toxic waste (<a href="https://www.scientificamerican.com/article/deep-sleep-gives-your-brain-a-deep-clean1/#:~:text=Why%20sleep%20has%20restorative%E2%80%94or,is%20hugely%20improved%20during%20sleep.">see</a>)</p>
<blockquote>
<p>Did you drink less than 10 drinks of alcohol in the last 7 days?</p>
</blockquote>
<p>There is nothing to say against a drink or two. But if you take it too far, you start to feel down, groggy and more. Moreover, alcohol can be addictive, and you don‚Äôt want to become an alcoholic.</p>
<blockquote>
<p>Did you drink too much caffeine in the last 7 days? (Coffee, black tea, energy drinks, etc.)</p>
</blockquote>
<p>Caffeine is a short energy booster, but it comes with downsides too. It blocks the body‚Äôs desire to rest for a short time, but then your body is twice as tired, wanting to rest.</p>
<p>Now, if you drink caffeine again, you start a vicious cycle. You‚Äôll only feel productive when you got your dose of caffeine. Otherwise, you feel tired again.</p>
<p>Over time you need to consume more and more caffeine to even get the effect.</p>
<p>Rest. Your body needs rest, and you should give it.</p>
<blockquote>
<p>Do you think you‚Äôre eating healthy in the last 7 days?</p>
</blockquote>
<p>Your body needs proper nutrition to function.</p>
<p>A diet of chips, chocolate bars, ice cream, or fast food is not the right thing to fuel your body the energy it needs.</p>
<p>Once in a while, it is fine but don‚Äôt thrive on it.</p>
<blockquote>
<p>Have you gone outside in the last 7 days?</p>
</blockquote>
<p>Pandemic here, pandemic there. But even without it, many of us don‚Äôt go outside enough‚Äîespecially people working from home.</p>
<p>But we need movement and fresh air. So, enjoy a long walk in nature, or a park or forest near you. Or just stroll through your city.</p>
<blockquote>
<p>Have you exercised in the last 7 days?</p>
</blockquote>
<p>Move your ass. Doesn‚Äôt matter what kind of exercise you like, do it. Movement is king.</p>
<p>Not only will it lift your mood. It will also help you to think fresh and clear again.</p>
<blockquote>
<p>Have you meditated in the last 7 days? Or journaled, etc.</p>
</blockquote>
<p>Meditation is a great tool to clear your thoughts and calming down. But you don‚Äôt need to sit still.</p>
<p>You can do <a href="https://mindfuldevmag.com/issues/issue-3-mindfulness-for-skeptics/walking-meditation">walking meditations</a> or journaling or other kinds of activities that help you to focus and clear your mind.</p>
<blockquote>
<p>Have you done anything to actively relax?</p>
</blockquote>
<p>This can be taking massages, doing yoga, taking a hot bath, sauna, or anything else that helps you relax.</p>
<p>Take your time and do it on purpose.</p>
<p>Btw watching tv might feel like relaxation, but it mostly is not. Our brain‚Äôs on alert mode.</p>
<p>Can‚Äôt decide on one?</p>
<p>Go for a walk in the next park.</p>
<blockquote>
<p>Have you talked to other people or met with your friends? Preferably IRL</p>
</blockquote>
<p>Even the most introverted of us love to talk to somebody. Sure, I can go without days of talking to somebody except my family. But even that has its limit.</p>
<p>Talk or, better yet, meet your friends, and have a great time. None handy at the moment? Talk to your neighbor, cashiers, or anybody else you can have interactions with.</p>
<blockquote>
<p>If you‚Äôre in a relationship, are you with the right person?</p>
</blockquote>
<p>If your relationship sucks, your mood will drop too. But if it is a loveable and stable one, it can lift you up and help through darker times.</p>
<blockquote>
<p>Have you helped someone in the last days with something you‚Äôre good at?</p>
</blockquote>
<p>Believe it or not. It‚Äôs humans to help others and feel good about it at the same time. It‚Äôs totally refreshing and re-energizing.</p>
<blockquote>
<p>Have you made any new experiences in the last month?</p>
</blockquote>
<p>Doing the same old from day to day, week to week, and month to month can drag you down. It feels like a rut. Being stuck.</p>
<p>Energize your life and go for new experiences. Go for a hike, visit a new city, test a new restaurant. Whatever it is, pick something new.</p>
<blockquote>
<p>Are you working on stuff that‚Äôs meaningful to you?</p>
</blockquote>
<p>Does your job or the things you work on in your spare time give you enough meaning? Or does it feel like working for the devil?</p>
<p>Does it fulfill you?</p>
<blockquote>
<p>Does your current situation allow you to do what you really want to do in life?</p>
</blockquote>
<p>If not, think about what you could start to change? What are thing top 3 things holding you back?</p>
<p>How could you remove them?</p>
<blockquote>
<p>Did you create anything in the last week?</p>
</blockquote>
<p>Does not matter what it is. Maybe you draw comics or paint art, make music, build websites, or whatever.</p>
<p>Let your creativity go wild, and your mood will go up.</p>
<blockquote>
<p>Are your working on too many things at the same time?</p>
</blockquote>
<p>Pursuing multiple things at the same time makes you feel like nothing moves forward. Often paired with getting frustrated and then feeling down.</p>
<p>Set your focus on one thing for now and work on that. The down feelings will fade.</p>
<blockquote>
<p>Do you have the feeling that you accomplished something?</p>
</blockquote>
<p>Sometimes we hustle and hustle but have the feeling we got nowhere. Just being tired and running towards a burnout.</p>
<p>Think about what small things you could add that make you feel to have accomplished something? Must not be work-related. It could also be private things you pushed for years in front of you.</p>
<h2>All Positive But Still Feeling Down?</h2>
<p>If you answered all questions positively and are still feeling down, it might be time to visit a therapist. There is no shame in that. We all need help sometimes.</p>
<p>Find someone near you or use an online service like <a href="https://www.talkspace.com/">talkspace</a>.</p>
                                     
                                     <hr>
                                     
                                                                          
                                     
                                       
                                       
                            </div>

                    </div></div>]]>
            </description>
            <link>https://mindfuldevmag.com/issues/issue-8-readers-questions/felling-down-figure-out-why-test</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660666</guid>
            <pubDate>Fri, 02 Oct 2020 09:17:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I can't write a JavaScript for loop, and it does not matter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24660465">thread link</a>) | @slorber
<br/>
October 2, 2020 | https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj | <a href="https://web.archive.org/web/*/https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>I've been using JavaScript daily for 7 years, and I'm not able to remember the syntax of a JavaScript for loop.</p>
<p>Despite this fact, I'm a rather successful freelance developer. Recently I even had the awesome opportunity to work for Facebook, as the <a target="_blank" href="https://github.com/facebook/docusaurus/issues/2336">Docusaurus lead maintainer</a>, writing the code for the framework that powers the documentation sites of Babel, Prettier, Jest, ReactNative...</p>
<p>I'll explain why I'm not able to remember such syntax, and why it does not matter much.</p>
<hr>

<p><strong>TLDR</strong>: I'm a functional programmer</p>
<p>I've really started programming at the beginning of my engineer degree, around 2004 (before that, I was only able to hack some scripts for Counter-Strike console or IRC).</p>
<p>Most of our school teaching was based on Java, but we also saw a bit of C, C++, OCaml. </p>
<p>The first loop syntax I learned probably looked like this one:</p>
<pre><code>List&lt;Integer&gt; numbers = Lists.newArrayList(<span>1</span>, <span>2</span>, <span>3</span>);

<span>for</span> (<span>int</span> i = <span>0</span>; i &lt; numbers.length; i++) {
   System.out.println(numbers.get(i));
}
</code></pre>
<p>Before I came out of school, Java 6 brought some new, simpler syntax:</p>
<pre><code>List&lt;Integer&gt; numbers = Lists.newArrayList(<span>1</span>, <span>2</span>, <span>3</span>);

<span>for</span> (Integer number : numbers) {
   System.out.println(number);
}
</code></pre>
<p>At my first job, the <a target="_blank" href="https://github.com/google/guava">Google Guava</a> lib brought some new verbose functional syntax to Java, and I was able to do weird things with it üòÖ.</p>
<pre><code>List&lt;Integer&gt; numbers = Lists.newArrayList(<span>1</span>, <span>2</span>, <span>3</span>);

Lists.newArrayList(Collections2.transform(numbers, <span>new</span> Function&lt;Integer,Void&gt;() {
  <span>@Override</span>
  <span><span>public</span> Void <span>apply</span><span>(Integer number)</span> </span>{
    System.out.println(number);
    <span>return</span> <span>null</span>;
  }
}));
</code></pre>
<p>This Guava lib got me intrigued by functional programming, and lead me to become a Scala developer since 2012, and I was finally able to use functional programming concepts (loops, but not only) without the ugly Java/Guava syntax.</p>
<pre><code>val numbers = List(1, 2, 3)
numbers.foreach(println)
</code></pre>
<p>In 2013, <a target="_blank" href="https://reactjs.org/blog/2013/06/05/why-react.html">ReactJS came out</a>, and this totally changed my career path. At this time, I didn't like JavaScript much and was only able to hack some inline JQuery things in server-rendered pages. But as a startup CTO, I saw my team struggle with architecture, BackboneJS and RequireJS, and thought I had to become better at frontend to lead them.</p>
<p>AngularJS looked like the safer choice at this time, but a Scala developer colleague really pushed for React, which looked fancy and risky. All things made sense with the visionary post of David Nolen (<a target="_blank" href="https://swannodette.github.io/2013/12/17/the-future-of-javascript-mvcs/">The Future of JavaScript MVC Frameworks</a>), and we finally adopted React in January 2014, as it seemed we would be able to use our functional programming knowledge to the frontend app as well, and make the UI more predictable.</p>
<p>Fast forward, it wasn't easy to be a React early-adopter for our critical app. All companies were building their own state management solution, trying to figure things out, <a target="_blank" href="https://github.com/stample/atom-react">and so we did</a>, based on the ideas of David Nolen to hold a single immutable state in an atom (I was able to get a <a target="_blank" href="https://www.youtube.com/watch?v=zxN8FYYBcrI">hacky time-travel working</a> before Redux). </p>
<p>Since then both the JavaScript language and the ReactJS ecosystem have progressed a lot, and it's very common to use functional programming principles nowadays.</p>

<p>As a long-time functional programmer, <strong>I simply don't write for loops</strong> very often. </p>
<p>Like anything you don't use regularly, you end up forgetting the syntax.</p>
<p>Today, many of us use ES5+ syntax (or Lodash/Ramda...) and some functional constructs. Using <code>map</code>, <code>forEach</code>, <code>filter</code> are the most illustrated examples in the JS community.</p>
<pre><code><span>const</span> numbers = [<span>1</span>, <span>2</span>, <span>3</span>]
numbers.forEach(<span><span>number</span> =&gt;</span> <span>console</span>.log(number));
</code></pre>
<p>But we can go much further than that once we are more experienced with functional programming, and almost never write any for loops anymore. </p>
<p>Don't get me wrong, it's not necessarily a goal to not write for loops anymore, and I'm not telling you that you should remove all for loops of your production codebase.</p>
<p>Very often there's an alternative syntax possible for your loops that might be more expressive and easier to understand. After a while, you end up seeing a for loop as an implementation detail of a more elegant functional abstraction.</p>
<p>This more expressive syntax is not only for loops, and you can as well see a functional abstraction being an implementation detail of another higher-level abstraction.</p>
<p>Let's consider we want to increment the age of 2 brothers.</p>
<pre><code><span>const</span> brothers = {
  <span>id1</span>: {<span>name</span>: <span>"S√©bastien"</span>, <span>age</span>: <span>34</span>},
  <span>id2</span>: {<span>name</span>: <span>"Antoine"</span>, <span>age</span>: <span>23</span>}
};
</code></pre>
<p>I very often see the <code>array.reduce()</code> operator used when a more expressive alternative was possible.</p>
<pre><code><span><span>function</span> <span>incrementBrothersAges</span>(<span></span>) </span>{
  <span>return</span> <span>Object</span>.entries(brothers)
    .reduce(<span>(<span>acc,[id,brother]</span>) =&gt;</span> {
      acc[id] = {...brother, <span>age</span>: brother.age + <span>1</span>};
      <span>return</span> acc;  
    },{})
}
</code></pre>
<p>You know what? <strong>I really struggled to write this code</strong>. </p>
<p>My first attempt was not working at all (TypeScript would have helped).</p>
<pre><code><span><span>function</span> <span>incrementBrothersAges</span>(<span></span>) </span>{
  <span>return</span> <span>Object</span>.entries(brothers)
      
      .reduce(<span>(<span>[id,brother],  acc</span>) =&gt;</span> {
        acc[id] = {...brother, <span>age</span>: brother.age + <span>1</span>};
        
      },{});
}
</code></pre>
<p>Yet, writing this kind of transform is idiomatic for me, using higher-level functional programming abstractions, such as <code>mapValues</code> (included in lodash).</p>
<pre><code><span><span>function</span> <span>incrementBrothersAges</span>(<span></span>) </span>{
  <span>return</span> mapValues(
    brothers, 
    <span><span>brother</span> =&gt;</span> ({...brother, <span>age</span>: brother.age + <span>1</span>})
  );
}
</code></pre>
<p>And I think nobody would argue that this is harder to read and maintain right? If junior developers are not familiar with functional programming, they'll catch up fast and get used to it. This might even be harder to learn <code>reduce</code>.</p>

<p>I don't write for loops (or <code>reduce</code>), but I know the concepts. I know that these loops exist in different syntaxes, that can be useful for different use cases, and how to make a choice with a good tradeoff (performance, readability...).</p>
<p>I'll illustrate this with a concrete example from my daily work that actually led me to write this article.</p>
<p>I had this async function that performs some long task for a given country.</p>
<pre><code><span>async</span> <span><span>function</span> <span>runCountryTask</span>(<span>country</span>) </span>{

  
  <span>const</span> taskDuration = <span>1000</span> + <span>Math</span>.random() * <span>4000</span>;
  <span>await</span> <span>new</span> <span>Promise</span>(<span><span>resolve</span> =&gt;</span> <span>setTimeout</span>(resolve, taskDuration));

  <span>console</span>.log(<span>`Task completed for <span>${country}</span>`</span>);
}
</code></pre>
<p>This task had to be run for many countries, but the tasks should be run sequentially, not in parallel.</p>
<p>As I know the concepts, and I knew that the following would not work, as <code>Promise.all</code> would run all tasks in parallel.</p>
<pre><code><span>async</span> <span><span>function</span> <span>runAllCountryTasks</span>(<span></span>) </span>{
  <span>const</span> countries = [<span>"FR"</span>, <span>"EN"</span>, <span>"US"</span>, <span>"DE"</span>, <span>"UK"</span>, <span>"IT"</span>];

  
  <span>await</span> <span>Promise</span>.all(countries.map(runCountryTask))
}
</code></pre>
<p>I also knew that there were multiple possible solutions to solve this problem:</p>
<ul>
<li>use a third-party dependency exposing the higher-level async primitive I need</li>
<li>use <code>Promise.then()</code> recursively</li>
<li>use async/await, using a for loop syntax to iterate over a fixed-size array</li>
</ul>
<p>I didn't want to introduce a new third party dependency just for a tiny utility function. </p>
<p>I also knew that using <code>Promise.then()</code> recursively could be harder to read, write, and maintain. There are many ways to write such a recursion, one of them could be:</p>
<pre><code><span>async</span> <span><span>function</span> <span>forEachAsyncSequential</span>(<span>array, asyncFn</span>) </span>{
  <span>await</span> array.reduce(<span>(<span>acc, item</span>) =&gt;</span> {
    <span>return</span> acc.then(<span>() =&gt;</span> asyncFn(item))
  }, <span>Promise</span>.resolve());
}
</code></pre>
<p>So I opted for a basic for loop, as it seemed the right tradeoff. </p>
<p>As I'm totally unable to remember the syntax (<code>in</code> vs <code>of</code>, can I actually use <code>const</code>?), I had to actually google it, and it didn't take me long to be able to write the TypeScript code that will be shipped in production.</p>
<pre><code><span>export</span> <span>async</span> <span><span>function</span> <span>forEachAsyncSequencial</span>&lt;<span>T</span>&gt;(<span>
  array: T[],
  asyncFn: (t: T) =&gt; <span>Promise</span>&lt;<span>void</span>&gt;,
</span>): <span>Promise</span>&lt;<span>void</span>&gt; </span>{
  <span>for</span> (<span>const</span> item <span>of</span> array) {
    <span>await</span> asyncFn(item);
  }
}
</code></pre>
<pre><code><span>async</span> <span><span>function</span> <span>runAllCountryTasks</span>(<span></span>) </span>{
  <span>const</span> countries = [<span>"FR"</span>, <span>"EN"</span>, <span>"US"</span>, <span>"DE"</span>, <span>"UK"</span>, <span>"IT"</span>];

  
  <span>await</span> forEachAsyncSequencial(countries, runCountryTask);
}
</code></pre>
<p>Believe me or not, but I think It's the only for loop I actually wrote in JavaScript this year. And once it's written, I won't need to write it ever again (at least for this project), as it's now part of my functional programming abstractions, that I can reuse anywhere I need.</p>
<p><a target="_blank" href="https://jsfiddle.net/y17c6et8/1/">JsFiddle playground</a></p>
<hr>

<p>It's not very important to remember every syntax details to be productive in your daily work, particularly when you don't use them often (on purpose), as you prefer to work with more expressive, higher-level abstractions. </p>
<p>I had to google many things to write this article:</p>
<ul>
<li>Syntax for declaring a Java list</li>
<li>Syntax for iterating a Java list</li>
<li>Does <code>System.out.println</code> accept an Integer?</li>
<li>Syntax for Scala string interpolation</li>
<li>Is there a <code>forEach</code> in Guava (actually found <a target="_blank" href="https://stackoverflow.com/questions/38251257/guava-iterators-for-nested-foreach">my own StackOverflow question</a>)</li>
<li>What are the possible syntaxes for iterating over a JavaScript array</li>
<li>Signature of <code>array.reduce()</code></li>
</ul>
<p>Not remembering all this does not matter much, as long as I know what to look for.</p>
<p>In the same way, I don't know much about many other JavaScript things:</p>
<ul>
<li>prototypes: I think I never hard to use them directly in my entire life, and I'm fine</li>
<li>classes: used them temporarily when I really had to in React</li>
<li>JavaScript quirks: I know some of them, but simply avoid the others by using ESLint, <code>===</code>, TypeScript... it's not worth knowing all of them</li>
<li>...</li>
</ul>
<p>The knowledge and concepts you learn are more easily transposable from one language to another. I was able to learn React and contribute to its ecosystem quickly, thanks to my functional programming background. </p>
<p>I would argue that knowing how to do a recursive algorithm is more important than knowing the syntax of a for loop of a particular language. You will likely write many recursive algorithms in your career: the concept of recursion is not going anywhere anytime soon. But it's way more likely that you switch from one language to another from time to time. </p>
<p>Hopefully, writing this post will help me remember the syntax for a while until I forget it again ü§™.</p>
<hr>
<p>üôè If you like this post, please like it, share it or comment it üôè: </p>
<ul>
<li><a target="_blank" href="https://twitter.com/sebastienlorber/status/1311948662843551744">Tweet</a></li>
<li><a target="_blank" href="https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj">Hashnode</a></li>
<li><a target="_blank" href="https://dev.to/sebastienlorber/i-can-t-write-a-javascript-for-loop-and-it-does-not-matter-11jb">Dev</a></li>
<li><a target="_blank" href="https://www.reddit.com/r/javascript/comments/j3r08h/i_cant_write_a_javascript_for_loop_and_it_does/">Reddit</a></li>
<li><a target="_blank" href="https://news.ycombinator.com/item?id=24660465">HackerNews</a></li>
</ul>
<p>For more content like this, subscribe to <a target="_blank" href="https://mailchi.mp/4ea4df0b54f7/sebastienlorber">my mailing list</a> and follow me on <a target="_blank" href="https://twitter.com/sebastienlorber">Twitter</a>.</p>
</div></div>]]>
            </description>
            <link>https://daily.sebastienlorber.com/i-cant-write-a-javascript-for-loop-and-it-does-not-matter-ckfrzpby8004iv6s19cxq04vj</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660465</guid>
            <pubDate>Fri, 02 Oct 2020 08:41:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust programming language exploit mitigations]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24659489">thread link</a>) | @lukastyrychtr
<br/>
October 1, 2020 | https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/ | <a href="https://web.archive.org/web/*/https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>By  on <time itemprop="datePublished" datetime="2020-09-16T00:00:00-07:00">September 16, 2020</time>. <a href="https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/#disqus_thread" data-disqus-identifier="/2020/09/16/rust-lang-exploit-mitigations/"></a></p><div itemprop="articleBody">
    <p>The Rust programming language provides memory[1] and thread[2] safety
guarantees via its ownership[3], references and borrowing[4], and slice
types[5] features. However, Unsafe Rust[6] introduces unsafe blocks, unsafe
functions and methods, unsafe traits, and new types that are not subject to
the borrowing rules.</p>

<p>Parts of the Rust standard library are implemented as safe abstractions over
unsafe code (and historically have been vulnerable to memory corruption[7]).
Furthermore, the Rust code and documentation encourage creating safe
abstractions over unsafe code. This can cause a false sense of security if
unsafe code is not properly reviewed and tested.</p>

<p>Unsafe Rust introduces features that do not provide the same memory and
thread safety guarantees. This causes programs or libraries to be
susceptible to memory corruption (CWE-119)[8] and concurrency issues
(CWE-557)[9]. Modern C and C++ compilers provide exploit mitigations to
increase the difficulty to exploit vulnerabilities resulting from these
issues. Therefore, the Rust compiler must also support these exploit
mitigations in order to mitigate vulnerabilities resulting from the use of
Unsafe Rust. This post is going to document these exploit mitigations and
how they apply to Rust.</p>

<h2 id="exploit-mitigations">Exploit mitigations</h2>

<p>This section documents the exploit mitigations applicable to the Rust
compiler when building programs for the Linux operating system on the AMD64
architecture and equivalent.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> All examples in this section were
built using the Rust compiler version 1.40.0 (2019-12-19) on Debian testing
(Bullseye).</p>

<p>The Rust Programming Language currently has no specification. The Rust
compiler (i.e., rustc) is the language reference implementation. All
references to ‚Äúthe Rust compiler‚Äù in this post refer to the language
reference implementation.</p>

<p>Table I <br>
Summary of exploit mitigations supported by the Rust compiler when building
programs for the Linux operating system on the AMD64 architecture and
equivalent.</p>
<table>
  <tbody><tr>
   <td><strong>Exploit mitigation</strong>
   </td>
   <td><strong>Supported and enabled by default</strong>
   </td>
   <td><strong>Since</strong>
   </td>
  </tr>
  <tr>
   <td>Position-independent executable
   </td>
   <td>Yes
   </td>
   <td>0.12.0 (2014-10-09)
   </td>
  </tr>
  <tr>
   <td>Integer overflow checks
   </td>
   <td>Yes (enabled when debug assertions are enabled, and disabled when debug assertions are disabled)
   </td>
   <td>1.1.0 (2015-06-25)
   </td>
  </tr>
  <tr>
   <td>Non-executable memory regions
   </td>
   <td>Yes
   </td>
   <td>1.8.0 (2016-04-14)
   </td>
  </tr>
  <tr>
   <td>Stack clashing protection
   </td>
   <td>Yes
   </td>
   <td>1.20.0 (2017-08-31)
   </td>
  </tr>
  <tr>
   <td>Read-only relocations and immediate binding
   </td>
   <td>Yes
   </td>
   <td>1.21.0 (2017-10-12)
   </td>
  </tr>
  <tr>
   <td>Heap corruption protection
   </td>
   <td>Yes
   </td>
   <td>1.32.0 (2019-01-17) (via operating system default or specified allocator)
   </td>
  </tr>
  <tr>
   <td>Stack smashing protection
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Forward-edge control flow protection
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Backward-edge control flow protection (e.g., shadow and safe stack)
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
</tbody></table>

<p id="fn:1">1. See
<a href="https://github.com/rust-lang/rust/tree/master/compiler/rustc_target/src/spec">https://github.com/rust-lang/rust/tree/master/compiler/rustc_target/src/spec</a>
for a list of targets and their default options. <a href="#fnref:1" role="doc-backlink">‚Ü©</a></p>

<h3 id="position-independent-executable">Position-independent executable</h3>

<p>Position-independent executable increases the difficulty of the use of code
reuse exploitation techniques, such as return-oriented programming (ROP) and
variants, by generating position-independent code for the executable, and
instructing the dynamic linker to load it similarly to a shared object at a
random load address, thus also benefiting from address-space layout
randomization (ASLR). This is also referred to as ‚Äúfull ASLR‚Äù.</p>

<p>The Rust compiler supports position-independent executable, and enables it
by default since version 0.12.0 (2014-10-09)[10]‚Äì[13].</p>

<div><div><pre><code>$ readelf -h target/release/hello-rust | grep Type:
  Type:                              DYN (Shared object file)
</code></pre></div></div>
<p>Fig. 1.‚ÄÉChecking if an executable is a position-independent executable.</p>

<p>An executable with an object type of <code>ET_DYN</code> (i.e., shared object) and not
<code>ET_EXEC</code> (i.e., executable) is a position-independent executable (see Fig.
1).</p>

<h3 id="integer-overflow-checks">Integer overflow checks</h3>

<p>Integer overflow checks protects programs from undefined and unintended
behavior (which may cause vulnerabilities) by checking for results of signed
and unsigned integer computations that cannot be represented in their type,
resulting in an overflow or wraparound.</p>

<p>The Rust compiler supports integer overflow checks, and enables it when
debug assertions are enabled since version 1.0.0 (2015-05-15)[14]‚Äì[17], but
support for it was not completed until version 1.1.0 (2015-06-25)[16]. An
option to control integer overflow checks was later stabilized in version
1.17.0 (2017-04-27)[18]‚Äì[20].</p>

<div><div><pre><code><span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>u</span><span>:</span> <span>u8</span> <span>=</span> <span>255</span><span>;</span>
    <span>println!</span><span>(</span><span>"u: {}"</span><span>,</span> <span>u</span> <span>+</span> <span>1</span><span>);</span>
<span>}</span>
</code></pre></div></div>
<p>Fig. 2.‚ÄÉhello-rust-integer program.</p>

<div><div><pre><code>$ cargo run
   Compiling hello-rust-integer v0.1.0 (/home/rcvalle/hello-rust-integer)
    Finished dev [unoptimized + debuginfo] target(s) in 0.23s
     Running `target/debug/hello-rust-integer`
thread 'main' panicked at 'attempt to add with overflow', src/main.rs:3:23
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace.
</code></pre></div></div>
<p>Fig. 3.‚ÄÉBuild and execution of hello-rust-integer with debug assertions
enabled.</p>

<div><div><pre><code>$ cargo run --release
   Compiling hello-rust-integer v0.1.0 (/home/rcvalle/hello-rust-integer)
    Finished release [optimized] target(s) in 0.23s
     Running `target/release/hello-rust-integer`
u: 0
</code></pre></div></div>
<p>Fig. 4.‚ÄÉBuild and execution of hello-rust-integer with debug assertions
disabled.</p>

<p>Integer overflow checks are enabled when debug assertions are enabled (see
Fig. 3), and disabled when debug assertions are disabled (see Fig. 4). To
enable integer overflow checks independently, use the option to control
integer overflow checks, scoped attributes, or explicit checking methods
such as <code>checked_add</code><sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</p>

<p>It is recommended that explicit wrapping methods such as <code>wrapping_add</code> be
used when wrapping semantics are intended, and that explicit checking and
wrapping methods always be used when using Unsafe Rust.</p>

<p id="fn:2">2. See <a href="https://doc.rust-lang.org/std/primitive.u32.html">https://doc.rust-lang.org/std/primitive.u32.html</a> for more
information on the checked, overflowing, saturating, and wrapping methods
(using u32 as an example). <a href="#fnref:2" role="doc-backlink">‚Ü©</a></p>

<h3 id="non-executable-memory-regions">Non-executable memory regions</h3>

<p>Non-executable memory regions increase the difficulty of exploitation by
limiting the memory regions that can be used to execute arbitrary code. Most
modern processors provide support for the operating system to mark memory
regions as non executable, but it was previously emulated by software, such
as in grsecurity/PaX‚Äôs
<a href="https://pax.grsecurity.net/docs/pageexec.txt">PAGEEXEC</a> and
<a href="https://pax.grsecurity.net/docs/segmexec.txt">SEGMEXEC</a>, on processors that
did not provide support for it. This is also known as ‚ÄúNo Execute (NX) Bit‚Äù,
‚ÄúExecute Disable (XD) Bit‚Äù, ‚ÄúExecute Never (XN) Bit‚Äù, and others.</p>

<p>The Rust compiler supports non-executable memory regions, and enables it by
default since its initial release, version 0.1 (2012-01-20)[21], [22], but
has regressed since then[23]‚Äì[25], and enforced by default since version
1.8.0 (2016-04-14)[25].</p>

<div><div><pre><code>$ readelf -l target/release/hello-rust | grep -A 1 GNU_STACK
  GNU_STACK      0x0000000000000000 0x0000000000000000 0x0000000000000000
                 0x0000000000000000 0x0000000000000000  RW     0x10
</code></pre></div></div>
<p>Fig. 5.‚ÄÉChecking if non-executable memory regions are enabled for a given
binary.</p>

<p>The presence of an element of type <code>PT_GNU_STACK</code> in the program header
table with the <code>PF_X</code> (i.e., executable) flag unset indicates non-executable
memory regions<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> are enabled for a given binary (see Fig. 5).
Conversely, the presence of an element of type <code>PT_GNU_STACK</code> in the program
header table with the <code>PF_X</code> flag set or the absence of an element of type
<code>PT_GNU_STACK</code> in the program header table indicates non-executable memory
regions are not enabled for a given binary.</p>

<p id="fn:3">3. See the Appendix section for more information on why it affects other
memory regions besides the stack. <a href="#fnref:3" role="doc-backlink">‚Ü©</a></p>

<h3 id="stack-clashing-protection">Stack clashing protection</h3>

<p>Stack clashing protection protects the stack from overlapping with another
memory region‚Äîallowing arbitrary data in both to be overwritten using each
other‚Äîby reading from the stack pages as the stack grows to cause a page
fault when attempting to read from the guard page/region. This is also
referred to as ‚Äústack probes‚Äù or ‚Äústack probing‚Äù.</p>

<p>The Rust compiler supports stack clashing protection via stack probing, and
enables it by default since version 1.20.0 (2017-08-31)[26]‚Äì[29].</p>

<p><img src="https://rcvalle.blog/assets/2020/09/16/rust-lang-exploit-mitigations/image1.png" alt="Screenshot listing cross references to __rust_probestack in hello-rust." title="Cross references to __rust_probestack in hello-rust.">
Fig. 6. Cross references to <code>__rust_probestack</code> in hello-rust.</p>

<div><div><pre><code><span>fn</span> <span>hello</span><span>()</span> <span>{</span>
    <span>println!</span><span>(</span><span>"Hello, world!"</span><span>);</span>
<span>}</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>_</span><span>:</span> <span>[</span><span>u64</span><span>;</span> <span>1024</span><span>]</span> <span>=</span> <span>[</span><span>0</span><span>;</span> <span>1024</span><span>];</span>
    <span>hello</span><span>();</span>
<span>}</span>
</code></pre></div></div>
<p>Fig 7. Modified hello-rust.</p>

<p><img src="https://rcvalle.blog/assets/2020/09/16/rust-lang-exploit-mitigations/image2.png" alt="Screenshot listing cross references to __rust_probestack in modified hello-rust." title="Cross references to __rust_probestack in modified hello-rust.">
Fig. 8. Cross references to <code>__rust_probestack</code> in modified hello-rust.</p>

<p>To check if stack clashing protection is enabled for a given binary, search
for cross references to <code>__rust_probestack</code>. The <code>__rust_probestack</code> is
called in the prologue of functions whose stack size is larger than a page
size (see Fig. 6), and can be forced for illustration purposes by modifying
the hello-rust example as seen in Fig. 7 and Fig. 8.</p>

<h3 id="read-only-relocations-and-immediate-binding">Read-only relocations and immediate binding</h3>

<p><strong>Read-only relocations</strong> protect segments containing relocations and
relocation information (i.e., <code>.init_array</code>, <code>.fini_array</code>, <code>.dynamic</code>, and
<code>.got</code>) from being overwritten by marking these segments read only. This is
also referred to as ‚Äúpartial RELRO‚Äù.</p>

<p>The Rust compiler supports read-only relocations, and enables it by default
since version 1.21.0 (2017-10-12)[30], [31].</p>

<div><div><pre><code>$ readelf -l target/release/hello-rust | grep GNU_RELRO
  GNU_RELRO      0x000000000002ee00 0x000000000002fe00 0x000000000002fe00
</code></pre></div></div>
<p>Fig. 9.‚ÄÉChecking if read-only relocations is enabled for a given binary.</p>

<p>The presence of an element of type <code>PT_GNU_RELRO</code> in the program header
table indicates read-only relocations are enabled for a given binary (see
Fig. 9). Conversely, the absence of an element of type <code>PT_GNU_RELRO</code> in the
program header table indicates read-only relocations are not enabled for a
given binary.</p>

<p><strong>Immediate binding</strong> protects additional segments containing relocations
(i.e., <code>.got.plt</code>) from being overwritten by instructing the dynamic linker
to perform all relocations before transferring control to the program during
startup, so all segments containing relocations can be marked ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/">https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/</a></em></p>]]>
            </description>
            <link>https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24659489</guid>
            <pubDate>Fri, 02 Oct 2020 06:16:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interview with Transport Tycoon creator Chris Sawyer]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24658958">thread link</a>) | @wizardfeet
<br/>
October 1, 2020 | https://lifeandtimes.games/episodes/files/28 | <a href="https://web.archive.org/web/*/https://lifeandtimes.games/episodes/files/28">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://pdcn.co/e/traffic.megaphone.fm/ADL8847793182.mp3" target="_blank">Click/tap here to download this episode.</a></p><p><a href="https://ratethispodcast.com/ltvg" target="_blank"><img src="https://storage.googleapis.com/rtp-assets/buttons/lifetimevideogames.png" width="198" height="56" alt="Rate This Podcast"></a></p>
<p><img alt="A screenshot of the main menu from Transport Tycoon for DOS" src="https://lifeandtimes.games/episodes/files/transport-tycoon-dos-screenshot-main-menu.png" width="276" height="212"></p><p>On the rise and, um...<em>fade out(?)</em> of Chris Sawyer, the genius creator of bestselling, critically-acclaimed simulation games Transport Tycoon and RollerCoaster Tycoon ‚Äî who made a career out of working at the cutting-edge, in bare metal assembly code that he wrote and optimised (and optimised again) on his own.</p><p>Until the cutting-edge left him behind.</p><p><strong>Hello Hacker News readers! As of this update, the post there erroneously labels this as an interview. It's not. Chris doesn't do interviews, except via an intermediary (which doesn't really work in an audio format), so the story is based entirely on my in-depth research and analysis. I hope you still enjoy it and learn something interesting. (I have stories on many other things that do involve interviews, though, like </strong><strong><a href="https://lifeandtimes.games/episodes/files/27" title="Episodes:27 - Links">1990 golf game Links</a></strong><strong>, Bungie's </strong><strong><a href="https://lifeandtimes.games/episodes/files/25" title="Episodes:25 - Pimps at Sea">fake game Pimps at Sea</a></strong><strong>, and </strong><strong><a href="https://lifeandtimes.games/episodes/files/22" title="Episodes:22 - Wololo">the "Wololo" sound effect</a></strong><strong> from Age of Empires.)</strong></p><p>Chris was only a design consultant on 2004 game RollerCoaster Tycoon 3, but its remastered "Complete" edition has just come out on Nintendo Switch and the PC version is free on the Epic Games Store right now (until October 2). The original two games are also still sold via the likes of Steam and GOG.</p><p>Transport Tycoon, meanwhile, lives on in open-source project <a href="https://www.openttd.org/" target="_blank">OpenTTD</a> and in a mobile port (<a href="https://play.google.com/store/apps/details?id=com.thirtyonex.TransportTycoon&amp;hl=en_US" target="_blank">Android</a>, <a href="https://apps.apple.com/us/app/transport-tycoon/id634013256" target="_blank">iOS</a>) of the original game by Chris's company 31X. You can see a snippet of his source code in the image below:</p><div><p><img alt="cstg_code1" src="https://lifeandtimes.games/episodes/files/cstg_code1.jpg" width="1262" height="1775"></p></div><div><p>Thanks as always to my supporters on Patreon ‚Äî especially my $10+ backers Carey Clanton, Rob Eberhardt, Simon Moss, Vivek Mohan, Wade Tregaskis, and Seth Robinson. If you'd like to become a supporter, for as little as $1 a month, head to <a href="https://www.patreon.com/lifeandtimesofvideogames">my Patreon page</a> and sign up. Or for one-off donations you can use <a href="https://paypal.me/mossrc">paypal.me/mossrc</a>.</p><p>Please remember to tell other people about the show, and to leave a review by following the links at <a href="https://ratethispodcast.com/ltvg">ratethispodcast.com/ltvg</a>.</p><p>I'm currently writing a new book called Shareware Heroes: Independent Games at the Dawn of the Internet. You can learn more and/or pre-order your copy <a href="https://unbound.com/books/shareware-heroes/" target="_blank">from Unbound</a>.</p></div><hr>
<h3>(Partial) Transcript</h3>
<p><strong><em>[Most episode transcripts/scripts are reserved for my Patreon supporters (at least for the time being), but I like to give you at least a taster here ‚Äî or in this case, the first half of the episode.]</em></strong></p><p><em>Welcome to the Life and Times of Video Games, an audio series about video games and the video game industry, as they were in the past and how they‚Äôve come to be the way they are today. I'm Richard Moss, and this is episode 28, Transport Tycoon, or the tale of the great optimiser and his two greatest works.</em></p><p>We‚Äôll get going in just a moment. </p><p>*pause for pre-roll ad/cross-promo slot*</p><p>***</p><p>You may have heard the expression that every overnight sensation is a decade in the making ‚Äî a decade of hard work, toiling in obscurity‚Ä¶or <em>relative</em> obscurity, honing a talent, perfecting a craft, <em>optimising</em> a skill set and envisioning whatever it is that breaks through.</p><p>In reality the actual duration is rarely a decade ‚Äî it‚Äôs five years or eight years or eighteen years, or however long it takes for the pieces to all fall into place: the talent, timing, and product. But the idea bears repeating: the greatest accolades, the greatest achievements, the greatest games are the product of hard work built atop years of invisible labour.</p><p>And such it was that Chris Sawyer, like John Romero, Carol Shaw, Gunpei Yokoi, and many others before and since ‚Äî such it was that in 1994 Chris Sawyer suddenly shifted from a little-known (though well-respected) figure in the games industry, a programmer who converted Amiga games to the PC, to become an industry icon.</p><p>Nineteen-ninety-four was the year when his first original game was published, the year when big-name PC game publisher Microprose put his transportation-focused business simulation game Transport Tycoon, an incredible solo development effort, in a box and sold it in stores to widespread acclaim. </p><p><img alt="SCR1" src="https://lifeandtimes.games/episodes/files/scr1.jpg" width="866" height="362"><br><em>Transport Tycoon, the game that made Chris Sawyer into a games industry icon (</em><em><a href="https://www.tt-forums.net/viewtopic.php?f=47&amp;t=29058" target="_blank">image source</a></em><em>)</em><br></p><div><p>The game itself had taken Chris just a year to develop, but the journey to making it had begun much earlier.</p><p>Chris had started programming as a teenager in 1981, largely out of curiosity, through trying to make things appear on the screen on a range of different computers he‚Äôd encountered. There was the Commodore PET at his high school, the Sinclair ZX81 demonstration unit in a W H Smiths store, and the Texas Instruments TI99/4A one of his neighbours owned, as well as the Commodore VIC-20 a different neighbour had. And eventually, after diligently saving up his pocket money, he‚Äôd become engrossed in a machine of his own, a Camputers Lynx, a now-forgotten, obscure-even-then 8-bit computer with fancier graphics and more horsepower than the leading systems of its day (the leading systems at the time being the Apple II, ZX Spectrum, and Commodore 64).</p><p>Here, in 1983, is where the journey really starts ‚Äî where Chris set off towards the lands where he‚Äôd make his name. And I find it fascinating how serendipitous this was ‚Äî for, you see, Chris‚Äôs two great successes, Transport Tycoon and RollerCoaster Tycoon, were both made possible by his phenomenal systems knowledge; by his immense capacity to hand-code complex interactions of data at low levels of abstraction.</p><p>And here is where he began to learn those skills, to internalise them to the point of becoming natural talents. He later told Arcade Attack in an interview that he‚Äôd not had access to an assembler for that Lynx computer, so when he‚Äôd wanted to move beyond coding in BASIC he‚Äôd needed to write his programs byte-by-byte in machine code ‚Äî the lowest-level programming language, the numerical instructions that computers themselves use. And with scant resources available to teach him these skills, he mostly figured it out on his own, just trying different things until he got his ideas to work. Always chasing the next exhilarating breakthrough.</p><p>Chris continued to dabble in machine code, though somewhat less than before, when he upgraded to a similarly-obscure machine called the Memotech MTX500, which actually did come with a built-in assembler, which enabled him to write programs in the abbreviation-heavy Z80 assembly language. Programs that, beginning in 1984, he very often had published commercially.</p></div><p><img alt="Memotech_MTX500-wide" src="https://lifeandtimes.games/episodes/files/memotech_mtx500-wide.jpg" width="1020" height="584"><br><em>The Memotech MTX500 (</em><em><a href="https://en.wikipedia.org/wiki/File:Memotech_MTX500.jpg" target="_blank">Image source</a></em><em>)</em><br></p><div><p>Chris had sent Memotech cassette tapes of some games he‚Äôd made through copying the designs of popular titles, like Missile Kommand, which was the 1980 Atari arcade game converted to the capabilities of the MTX500, using a mix of BASIC and machine code, with the name intentionally misspelled (a ‚Äòk‚Äô rather than a ‚Äòc‚Äô) as though that somehow made his unapologetic, blatant clone of another‚Äôs work okay. </p><p>But this was the wild west of the computer games business, and Memotech weren‚Äôt much concerned. Or at least their games guy Jim Wills wasn‚Äôt much concerned, neither at this point nor a few months later when he left to start a company called Megastar Games. Jim liked Chris‚Äôs work enough to publish it, for meagre royalties but invaluable experience. And so Chris was commercially published with his unlicensed MTX500 versions of Missile Command, Q*bert, Manic Miner, and a few others.</p><p>After high school he enrolled in a computer science and microprocessor systems degree, where he studied the fundamentals of both software and hardware design in computers ‚Äî an experience he found invaluable, as it taught him how to push computers further by learning how their hardware worked. And it taught him the theories behind the sorts of nitty-gritty software-systems things he‚Äôd already been practising at home: optimisation, sorting, algorithms, and even more varieties of machine code.</p></div><p><img alt="escape-from-zarcos-memotech-mtx500" src="https://lifeandtimes.games/episodes/files/escape-from-zarcos-memotech-mtx500.png" width="1044" height="788"><em><br>Escape from Zarcos, Chris Sawyer clone of Manic Miner for the Memotech MTX500</em><br></p><div><p>At home, meanwhile, he‚Äôd shifted over to the Amstrad CPC, which technologically-speaking wasn‚Äôt hugely different to the Memotech system he‚Äôd been on before ‚Äî but it was a modest upgrade, and unlike his previous computers it was actually a popular system. And for Chris it was a gateway to the PC, because in the course of studying at university and making computer games on the side he wound up getting an Amstrad-made IBM-PC clone.</p><p>Chris had during this period been getting his games published through Ariolasoft, a German company with a UK subsidiary that promised him a job programming games for them once he graduated. Except some promises can‚Äôt be kept, especially in an industry that moves as fast as computer games publishing.</p><p>The home computer business was by that point deep into its transition from 8-bit to 16-bit hardware, and that transition came with adjustments to the standard of game graphics and design required, and to the way marketing and sales worked, and the cost of publishing, and so on, and Ariolasoft wasn‚Äôt doing too well at managing the transition. </p><p>So Chris didn‚Äôt have a job waiting for him after all, and he‚Äôd missed out on all the great electronics engineering jobs his classmates applied for. (Oops!) But not to worry ‚Äî he‚Äôd made enough connections and enough headway as a programmer that he could get himself a business agent, and that agent in turn connected him to the booming Amiga-to-PC games porting industry.</p><p>He later said he‚Äôd thought it a ‚Äústop-gap‚Äù measure, just ‚Äúa bit of fun‚Äù while he looked for more permanent employment in the electronics industry. But Chris took to his new conversions work like a duck to water. The kid who‚Äôd had to get creative and remain patient to make anything work on his Camputers Lynx machine now excelled in an environment where he had to contend with the vast gap in multimedia capabilities between the Amiga and the PC.</p><p>PCs of the day were pathetically inept as games machines, compared to a system like the Amiga. Whereas the PC had just a CPU, and maybe, in a minority of machines, a dedicated sound card like the SoundBlaster 16, every Amiga came with a custom chipset that contained audio and video co-processors that could take some strain off the ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lifeandtimes.games/episodes/files/28">https://lifeandtimes.games/episodes/files/28</a></em></p>]]>
            </description>
            <link>https://lifeandtimes.games/episodes/files/28</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658958</guid>
            <pubDate>Fri, 02 Oct 2020 04:45:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Jargon File]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24658797">thread link</a>) | @purec
<br/>
October 1, 2020 | http://jargon-file.org/archive/jargon-4.4.7.dos.txt | <a href="https://web.archive.org/web/*/http://jargon-file.org/archive/jargon-4.4.7.dos.txt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://jargon-file.org/archive/jargon-4.4.7.dos.txt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658797</guid>
            <pubDate>Fri, 02 Oct 2020 04:12:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: How to compute a factorial with Œª calculus in a post card]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24658404">thread link</a>) | @martyalain
<br/>
October 1, 2020 | http://lambdaway.free.fr/lambdawalks/?view=lambdafact | <a href="https://web.archive.org/web/*/http://lambdaway.free.fr/lambdawalks/?view=lambdafact">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://lambdaway.free.fr/lambdawalks/?view=lambdafact</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658404</guid>
            <pubDate>Fri, 02 Oct 2020 03:10:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big O, Little N]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24657747">thread link</a>) | @adamzerner
<br/>
October 1, 2020 | https://adamzerner.bearblog.dev/big-o-little-n/ | <a href="https://web.archive.org/web/*/https://adamzerner.bearblog.dev/big-o-little-n/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p>I remember when I was first learning about hash tables. I thought I stumbled across an ingenious optimization for dealing with hash collisions. Before explaining my optimization, let me first briefly explain how hash tables work and what hash collisions are. I also made a video if you're interested.</p>
<p><a href="http://www.youtube.com/watch?v=pM9zhZB2KkM" title="Hash Tables"><img alt="" src="http://img.youtube.com/vi/pM9zhZB2KkM/0.jpg"></a></p>
<p>Say that we have a hash that maps someone's name to their age. <code>"adam"</code> is <code>27</code>, so we want to enter that into our hash.</p>
<p><img alt="" src="https://i.ibb.co/qWdjbhM/Slice.png"></p>
<p>Here's what happens:</p>
<ul>
<li><code>"adam"</code> gets put through a hash function.</li>
<li>The hash function spits out <code>7</code>.</li>
<li><code>7</code> is the index of the array where we are going to store <code>"adam"</code>'s value.</li>
<li>So we store <code>27</code> into <code>array[7]</code>.</li>
</ul>
<p>If we run <code>hash.get("adam")</code> in the future and need to look up the value for <code>"adam"</code>, we:</p>
<ul>
<li>Run <code>"adam"</code> through the hash function.</li>
<li>Get <code>7</code> as the output.</li>
<li>This means we have to look at <code>array[7]</code> to get the value.</li>
<li>So we look at <code>array[7]</code> to get our value.</li>
</ul>
<p>Hopefully if we have a key of <code>"alice"</code> or <code>"bob"</code> it'll hash to a different index. But... what happens if it hashes to the same index? That's called a hash collision.</p>
<p><img alt="" src="https://i.ibb.co/sJbJKnD/Slice.png"></p>
<p>A common approach is that if there's a collision, you store the values in a linked list.</p>
<p><img alt="" src="https://i.ibb.co/VJsSW3T/Slice.png"></p>
<p>Fair enough. That makes sense.</p>
<p>But wait!!! It takes <code>O(n)</code> time to look up a value in a linked list. Can't we use a binary search tree to speed that up to <code>O(log n)</code>???</p>
<p><img alt="" src="https://i.ibb.co/R3Vrc10/Slice.png"></p>
<p>Or... can't we take it a step further and use a <em>hash inside of a hash</em> to get the lookup time all the way down to <code>O(1)</code>?!</p>
<p><img alt="" src="https://i.ibb.co/7CyYNWY/Slice.png"></p>
<p>I hate to say it, but however many years ago when I had these thoughts, there were a few moments where I thought I was a genius. Now when I look back at that former self, I facepalm.</p>
<p>It is true that going from a linked list to a BST to a hash takes you from <code>O(n)</code> to <code>O(logn)</code> to <code>O(1)</code> lookup time. However, since collisions are rare, <code>n</code> is going to be small. And when <code>n</code> is small, <code>O(n)</code> might be faster than <code>O(1)</code>.</p>
<p>To understand why that is, think back to what Big-O really means. I think it helps to think about it as a "math thing" instead of a "programming thing". Consider two functions:</p>
<pre><code>f(n) = 4n + 1000
g(n) = 2n^2 + 5
</code></pre>
<p>Big-O of <code>f</code> is <code>O(n)</code> and Big-O of <code>g</code> is <code>O(n^2)</code>. We just focus on the part that "really matters". When <code>n</code> gets really big, the fact that it's <code>4n</code> doesn't really matter. Nor does the <code>+ 1000</code>.</p>
<p>But what about when <code>n</code> is small? Well, let's look at happens when <code>n</code> is <code>5</code>:</p>
<pre><code>f(5) = 4(5) + 1000 = 20 + 1000 = 1020
g(5) = 2(5^2) + 5 = 2(25) + 5 = 50 + 5 = 55
</code></pre>
<p>Look at that! The <code>O(n^2)</code> function is almost 20 times faster than the <code>O(n)</code> function!</p>
<p>And <em>that</em> is basically why they use a linked list instead of a BST or hash to handle collisions. Since <code>n</code> is small, Big-O isn't the right question to ask.</p>
<hr>
<p>Here's another example. I just wrote the following code while prepping for an interview:</p>
<pre><code>const isVowel = (char) =&gt; ["a", "e", "i", "o", "u"].includes(char);
</code></pre>
<p>Normally I wouldn't think twice about it, but since interviewers care so much about time complexity, I stopped to think about whether it could be improved.</p>
<p>And it hit me that it's actually <code>O(n)</code>(<a href="https://news.ycombinator.com/item?id=24660824">caveat</a>), because we've got an array and have to iterate over every element to see if the element matches <code>char</code>. It's easy to overlook this because we're using <code>includes</code> and not writing the code ourselves.</p>
<p>So then I thought that maybe we could use a hash instead to get <code>O(1)</code> lookup. Something like this:</p>
<pre><code>const isVowel = (char) =&gt; {
  const vowels = {
    a: true,
    e: true,
    i: true,
    o: true,
    u: true,
  };

  return !!vowels[char];
};
</code></pre>
<p>But then I realized that this is the same mistake I made with the hash collision stuff however many years ago. <em><code>n</code> is small, so Big-O isn't the question we should be asking</em>. Here <code>n</code> is <code>5</code>.</p>
<p>I think that the array approach would actually be faster than the hash approach, even though it's <code>O(n)</code> instead of <code>O(1)</code>. The reason for this is called locality.</p>
<p>If you dive deep under the hood, when you look up an element in an array, the CPU actually grabs a bunch of adjacent elements as well as the one you wanted, and it stores the adjacent elements in a cache. So here when we look up <code>"a"</code> in the array, it'll probably grab <code>"a"</code>, <code>"e"</code>, <code>"i"</code>, <code>"o"</code>, and <code>"u"</code>. And so next time when we want to grab <code>"e"</code>, it can take it from the cache, which is a lot faster. This works because the elements in the array are close to each other in the physical memory. But with a hash, my understanding is that they wouldn't be so close, and thus we wouldn't benefit from this spatial locality effect.</p>
<p>I'm no low-level programming wiz so I'm not sure about any of this. That's ok, I think it's beside the point of this post. The real point of this post is that when you have a little <code>n</code>, Big-O doesn't matter.</p>
</div>
</div></div>]]>
            </description>
            <link>https://adamzerner.bearblog.dev/big-o-little-n/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657747</guid>
            <pubDate>Fri, 02 Oct 2020 00:59:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Designer's Guide to JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24657624">thread link</a>) | @philipcdavis
<br/>
October 1, 2020 | https://react.design/javascript | <a href="https://web.archive.org/web/*/https://react.design/javascript">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>You can learn the basics of JavaScript quickly. You don't need a engineering degree, or a front end bootcamp.</p><p>Learning the basics of JavaScript is enough to get started with modern frameworks like React.js. Once you know the basics, you can do some truly amazing things.</p><p>You can quickly spin up interactive prototypes.<br>You can use live data sets.<br>You can create web, mobile, and desktop apps.<br>You can define interfaces in high fidelity.<br>You can write scripts to automate daily tasks.<br>You can make plugins for design tools like Sketch and Figma.<br>You can build with modern frameworks like React.js.</p><p>You can't learn JavaScript in a day, but you can learn it quickly. The best way to learn is to build. This guide is meant to give you enough information to start building. </p><h2>Editor</h2><p><img src="https://react.design/assets/javascript/theme.png">
</p><p>Before we write any code, it's a good idea to get comfortable with your text editor. I'd recommend using a text editor like <a href="https://code.visualstudio.com/">VSCode</a>, or <a href="https://atom.io/">Atom</a> as you write JavaScript. They're both free and support lots of plugins to make things easier. You can also find lots of nice themes. Here's a <a href="https://marketplace.visualstudio.com/items?itemName=Framer.framer-syntax">theme</a> for VSCode that I like.</p><p>Learning keyboard shortcuts, and customizing the look of your editor will make for a much more enjoyable coding experience.</p><h2>Setup</h2><p>JavaScript is a scripting language that for our intents and purposes, will be executed by the browser.</p><p>There are multiple ways to include javascript inside your webpage. The way we will use javascript will be by including <code>&lt;script&gt;</code> tags right before the closing <code>&lt;/body&gt;</code> tag. </p><pre><code><span>&lt;!</span><span>DOCTYPE</span><span> </span><span>html</span><span>&gt;</span><span>
</span><span></span><span>&lt;</span><span>html</span><span>&gt;</span><span>
</span><span>  </span><span>&lt;</span><span>head</span><span>&gt;</span><span>&lt;/</span><span>head</span><span>&gt;</span><span>
</span><span>  </span><span>&lt;</span><span>body</span><span>&gt;</span><span>
</span>    
<span>    </span><span>&lt;</span><span>script</span><span>&gt;</span><span>
</span><span>        </span><span>// Javascript will go here</span><span>
</span><span>        </span><span>console</span><span>.</span><span>log</span><span>(</span><span>"Hello friend!"</span><span>)</span><span>
</span><span>    </span><span>&lt;/</span><span>script</span><span>&gt;</span><span>
</span><span>  </span><span>&lt;/</span><span>body</span><span>&gt;</span><span>
</span><span></span><span>&lt;/</span><span>html</span><span>&gt;</span></code></pre><p>We√¢‚Ç¨‚Ñ¢ll put our javascript inside here, but we could also reference an external file.
<code>console.log()</code> is a helpful tool for debugging. Here I'm writing "Hello Friend!" To the console. You an access the console in Chrome using the <code>CMD+Option+J</code> shortcut.</p><p><img src="https://react.design/assets/javascript/console.png">
</p><p>There are 5 core concepts in JavaScript that are important to understand.</p><p><strong>1. Variables</strong><br><strong>2. Data Structures</strong><br><strong>3. Loops</strong><br><strong>4. Conditionals</strong><br><strong>5. Functions</strong></p><h2>Variables</h2><p>Variables are containers that hold values. These values can take lots of different forms. If you wanted a variable to hold a number you could write it as <code>var num = 20;</code>. If I use <code>console.log(num)</code> it should show me the number twenty.</p><p>Variables can be referenced later. <code>var double = num * 2; // 40</code></p><p>Variables can hold lots of different data types. I want to discuss a few different common ways to hold data. There are primitive data types like numbers, which we used earlier, There are strings, which are just a way to store text, and booleans which are values that are either true or false.</p><pre><code><span>var</span><span> days </span><span>=</span><span> </span><span>40</span><span>;</span><span> </span><span>// Number</span><span>
</span><span></span><span>var</span><span> label </span><span>=</span><span> </span><span>"Hello"</span><span>;</span><span> </span><span>// String</span><span>
</span><span></span><span>var</span><span> hidden </span><span>=</span><span> </span><span>true</span><span>;</span><span> </span><span>// Boolean</span></code></pre><h2>Data Structures</h2><p>In addition to primitive data types there are others that have more complex structures. Two of these important types are objects (sometimes called object literals) and arrays. </p><p>Objects can be defined using curly braces. 
<code>var obj = {}</code></p><p>What goes inside the curly braces are a collection of key value pairs. The key goes first, followed by a colon, and then the value. </p><pre><code><span>var</span><span> obj </span><span>=</span><span> </span><span>{</span><span>
</span><span>  key</span><span>:</span><span> value
</span><span></span><span>}</span></code></pre><p>Keys are labels that help you find the data you want to store. Keys in a single object must be unique. Values can be any data type. Numbers, strings, arrays, and even other objects. 
Here's an example Object with multiple key value pairs in action:</p><pre><code><span>var</span><span> profile </span><span>=</span><span> </span><span>{</span><span>
</span><span>	name</span><span>:</span><span> </span><span>'Philip'</span><span>,</span><span> 
</span><span>	age</span><span>:</span><span> </span><span>25</span><span>,</span><span> 
</span><span>	contact</span><span>:</span><span> </span><span>{</span><span>
</span><span>		twitter</span><span>:</span><span> </span><span>'philipcdavis'</span><span>,</span><span> 
</span><span>		email</span><span>:</span><span> </span><span>'reactfordesigners@gmail.com'</span><span>
</span><span>	</span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>Name, age, contact, twitter, and email are all different keys in this object. The values are all different and many have different value types. Some are strings, some are numbers, and some are other objects.</p><p>This nested structure is common and you will see it a lot when working with data sets.</p><p>There are two ways to access a value inside an object. The first way is sometimes called dot notation: <code>profile.name</code>. The second way is by using brackets <code>profile['name']</code>. Bracket notion is useful when your key name is dynamic.</p><p>The other data type that√¢‚Ç¨‚Ñ¢s important to know about is the Array. You define an array with square brackets. </p><p><code>var myArr = [];</code></p><p>You can store any type of data inside these arrays and they don't need to all be the same type (though they usually are). An example array might look like this: </p><pre><code><span>var</span><span> teams </span><span>=</span><span> </span><span>[</span><span>'lakers'</span><span>,</span><span> </span><span>'nuggets'</span><span>,</span><span> </span><span>'rockets'</span><span>]</span><span>;</span></code></pre><p>Instead of using keys, arrays use a built in index to keep track of location. The index of arrays starts at 0. If we wanted to access the second value of this array (nuggets) we could do so by typing <code>teams[1];</code></p><p>If your data was as simple as this, using objects and arrays might seem unnecessary. They start to shine when you have data sets that are larger. To work with more data, we'll probably want to use a loop</p><h2>Loops</h2><p>Loops enable you to run a block of code multiple times. You can use a loop with objects and arrays to execute a block of code on each item in the structure. </p><p>To loop through each value in an array you can use a for loop that executes a block. </p><pre><code><span>for</span><span> </span><span>(</span><span>var</span><span> i</span><span>=</span><span>0</span><span>;</span><span> i</span><span>&lt;</span><span>teams</span><span>.</span><span>length</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>    </span><span>// Block to be executed</span><span>
</span><span></span><span>}</span></code></pre><p>What goes into the parenthesis determines how many times the block of code is executed. The first value is a counter variable. <code>i</code> is often used to refer to the fact that it's used as the index value of the array. We will start the counter at 0. </p><p>The next value is called the conditional. Once the conditional is false, the loop will end. We can set the value to be <code>i &lt; teams.length</code>. The <code>.length</code> is a helper value built into every array that will tell you how many items are in the array. Once the value of the counter is as great as the length of the array, we can stop looping. The last value <code>i++</code> is what we want to happen after our loop runs. We want our counter to increase in value by one every time the loop runs.</p><p>If we log a string, you can see that it will print out 4 times.
If we log the value i, you can see that it increments up. If you combine this incremented value i with our array, you can see how we can access each value in our array.</p><pre><code><span>for</span><span> </span><span>(</span><span>var</span><span> i</span><span>=</span><span>0</span><span>;</span><span>i</span><span>&lt;</span><span>teams</span><span>.</span><span>length</span><span>;</span><span>i</span><span>++</span><span>)</span><span> </span><span>{</span><span> 
</span><span>	</span><span>console</span><span>.</span><span>log</span><span>(</span><span>teams</span><span>[</span><span>i</span><span>]</span><span>)</span><span>
</span><span></span><span>}</span><span>;</span></code></pre><p>There are other types of loops but they all are doing something pretty similar, running a block of code multiple times. That√¢‚Ç¨‚Ñ¢s the essential work of a loop.</p><h2>Conditionals</h2><p>Next up on our list is conditionals. The most common type of conditional is the if/else statement. </p><pre><code><span>if</span><span> </span><span>(</span><span>conditional</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>console</span><span>.</span><span>log</span><span>(</span><span>'the conditional evaluated to true'</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span>
</span><span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>'the conditional evaluated to false'</span><span>)</span><span>;</span><span>
</span><span></span><span>}</span></code></pre><p>If the <code>conditional</code> value in the parenthesis evaluates to true, the block inside the first set of curly brackets is run, otherwise the else block is run.</p><p>Let√¢‚Ç¨‚Ñ¢s use it in combination with our loop to log only the first two items in our array. Because we don√¢‚Ç¨‚Ñ¢t need the else here, we can remove it, and we√¢‚Ç¨‚Ñ¢ll get the same result.</p><pre><code><span>for</span><span> </span><span>(</span><span>var</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i</span><span>&lt;</span><span>teams</span><span>.</span><span>length</span><span>;</span><span> i</span><span>++</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>if</span><span> </span><span>(</span><span>i </span><span>&lt;</span><span> </span><span>2</span><span>)</span><span> </span><span>{</span><span>
</span><span>	  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>teams</span><span>[</span><span>i</span><span>]</span><span>)</span><span>;</span><span>
</span><span>	</span><span>}</span><span>
</span><span></span><span>}</span></code></pre><p>You√¢‚Ç¨‚Ñ¢ll use these conditionals to to control what gets executed when.</p><h2>Functions</h2><p>Functions allow you to create reusable and modular code.</p><p>Another way to say it is that they are blocks of code than can be executed whenever they are needed. </p><p>Here's what one looks like</p><pre><code><span>function</span><span> </span><span>add</span><span> </span><span>(</span><span>a</span><span>,</span><span> b</span><span>)</span><span> </span><span>{</span><span>
</span><span>	</span><span>var</span><span> total </span><span>=</span><span> a </span><span>+</span><span> b</span><span>;</span><span>
</span><span>	</span><span>return</span><span> total</span><span>;</span><span>
</span><span></span><span>}</span><span> </span></code></pre><p>Here we have a simple function that takes two input values, adds them together, and then returns the total. We√¢‚Ç¨‚Ñ¢ll use generic names for our input arguments. You can name these pretty much whatever you want, but they will be used within our block so if your function is complex, it√¢‚Ç¨‚Ñ¢s good to have descriptive names. Because this is a pretty simple function we're using <code>a</code> and <code>b</code>. </p><p>What we've created is a function declaration. In order to execute, or invoke our function we can call <code>add(2,50)</code>.
<code>console.log(add(2,50)) // 52</code></p><p><code>console.log</code> is itself a function. Functions can be stored in variables, objects, arrays, or even passed into other functions.</p><p>One other important thing to note about functions is how they affect variables inside them. If you define a variable within a function, the variable cannot be used outside the function. That's because javascript has a function based scope.</p><hr><p>Javascript is a really fun language to learn. If you feel comfortable with the material above you can do a lot! Most of JavaScript is just building on to these core concepts.</p><h2>Modern JavaScript</h2><p>In 2015 a set of new syntax and features were introduced that made writing JavaScript easier. Many of the following updates are meant to help you write code faster and cleaner. If you're using modern frameworks like React you'll often see them in examples.</p><h3>Const / Let</h3><p>This is just a new way to write variables. </p><pre><code><span>const</span><span> height </span><span>=</span><span> </span><span>30</span><span>;</span><span>
</span><span></span><span>let</span><span> height </span><span>=</span><span> </span><span>30</span><span>;</span></code></pre><p><code>const</code> values cannot be reassigned after the initial assignment. This is usually the default way of creating variables. </p><p><code>let</code> values can be reassigned but are scoped to conditionals, the same way all variables are scoped to functions. If you declare one inside an if/else statement it won't be available outside the statement.</p><h3>Arrow Functions</h3><p>This a shorthand for writing functions.
Instead of writing:</p><pre><code><span>const</span><span> </span><span>add</span><span> </span><span>=</span><span> </span><span>function</span><span>(</span><span>a</span><span>,</span><span>b</span><span>)</span><span>{</span><span> </span><span>return</span><span> a </span><span>+</span><span> b </span><span>}</span></code></pre><p>You can use an arrow function which looks like this:</p><pre><code><span>const</span><span> </span><span>add</span><span> </span><span>=</span><span> </span><span>(</span><span>a</span><span>,</span><span>b</span><span>)</span><span> </span><span>=&gt;</span><span> a </span><span>+</span><span> b</span></code></pre><p>If your function takes a single parameter you can omit the parenthesis.</p><pre><code><span>const</span><span> </span><span>getStyle</span><span> </span><span>=</span><span> </span><span>a</span><span> </span><span>=&gt;</span><span> a</span><span>.</span><span>style</span></code></pre><h3>Template Literals</h3><p>Previously is you wanted dynamic strings, you would insert values using the following syntax.</p><pre><code><span>const</span><span> dynamicString </span><span>=</span><span> </span><span>"Hello my name is"</span><span> </span><span>+</span><span> firstName </span><span>+</span><span> </span><span>". Welcome!"</span></code></pre><p>Using template literals, you can use the backtick for strings, and <code>${}</code> to insert variables.</p><pre><code><span>const</span><span> dynamicString </span><span>=</span><span> </span><span>`</span><span>Hello my name is </span><span>${</span><span>firstName</span><span>}</span><span>. Welcome!</span><span>`</span></code></pre><h3>Imports and Exports</h3><p>Instead of using large javascript files, you'll often want to break your code into smaller modules and export anything that other modules need to access.</p><pre><code><span>// Colors.js</span><span>
</span><span></span><span>export</span><span> </span><span>const</span><span> colors </span><span>=</span><span> </span><span>{</span><span>
</span><span>	blue</span><span>:</span><span> </span><span>"#EA3232"</span><span>,</span><span>
</span><span>	red</span><span>:</span><span> </span><span>"#4062F3"</span><span>,</span><span>
</span><span>	yellow</span><span>:</span><span> </span><span>"#FFAD05"</span><span>,</span><span>
</span><span></span><span>}</span></code></pre><p>In a different file you can import these colors using the following syntax.</p><pre><code><span>import</span><span> </span><span>{</span><span>colors</span><span>}</span><span> </span><span>from</span><span> </span><span>'./Color'</span></code></pre><p>You can also define default exports ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://react.design/javascript">https://react.design/javascript</a></em></p>]]>
            </description>
            <link>https://react.design/javascript</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657624</guid>
            <pubDate>Fri, 02 Oct 2020 00:32:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatic-Differentiation-Worked-Examples]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24657571">thread link</a>) | @formalsystem
<br/>
October 1, 2020 | http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/ | <a href="https://web.archive.org/web/*/http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <h3>automatic-differentiation-worked-examples</h3>
  
<p>‚Äì forwards and reverse</p>
<h2 id="introduction">Introduction</h2>
<p>This article demonstrates how to perform source transformations on a program to generate forward mode and reverse mode derivative programs (automatic differentiation, or ‚ÄúAD‚Äù). My aim is to write the shortest possible article that communicates all the essential features of a source-to-source AD system with a particular focus on making the reverse mode transformation clear.</p>
<p>The goal of brevity means that a lot of possible commentary has been omitted. If you find this makes some part of the article hard to understand then please <a href="http://web.jaguarpaw.co.uk/~tom/contact">contact me</a> and I‚Äôll do my best to clarify. In particular this article contains hardly any mathematical content at all. I hope that the reader who is familiar with multivariate calculus will be able to obtain an intuitive understanding of how AD relates to mathematical techniques he or she is already familiar with. A more in-depth description of the relationship will have to wait for another article.</p>
<h2 id="the-program">The program</h2>
<p>Let‚Äôs consider the following pseudocode program that performs some elementary arithmetic through a sequence of assignment statements.</p>
<pre><code>p = 7 * x
r = 1 / y
q = p * x * 5
v = 2 * p * q + 3 * r</code></pre>
<p><code>x</code> and <code>y</code> are not defined in the program so I‚Äôm going to informally consider them to be ‚Äúinputs‚Äù; <code>v</code> is not used anywhere so I‚Äôm going to consider it to be the ‚Äúoutput‚Äù. (I won‚Äôt burden the article by formalising these notions here.)</p>
<h2 id="preparation">Preparation</h2>
<p>We‚Äôll do a small amount of preparation to our original program which will preserve its behaviour and get it into a form in which it is straightforward to apply the automatic differentiation (AD) algorithms. It is possible to apply AD algorithms without doing these transformations first but then the AD algorithms would have to do equivalent operations implicitly. Doing these transformations first is a kind of <a href="https://en.wikipedia.org/wiki/Separation_of_concerns">separation of concerns</a>.</p>
<h3 id="use-prefix-functions-with-exactly-one-argument">Use prefix functions with exactly one argument</h3>
<p>Let‚Äôs use prefix functions instead of <a href="https://en.wikipedia.org/wiki/Infix_notation">infix operators</a>. Infix operators are more familiar for arithmetic but the AD algorithms will be clearer to present if we use prefix functions. Additionally I want every function to have exactly one argument (although that argument may be a tuple). Single-argument style will make the reverse mode transformation much clearer (although it does not make any difference for forward mode). For example, <code>x1 + x2</code> would become <code>add (x1, x2)</code>. Our program becomes</p>
<pre><code>p = mul (7, x)
r = div (1, y)
q = mul (mul (p, x), 5)
v = add (mul (mul (2, p), q), mul (3, r))</code></pre>
<h3 id="no-nested-subexpressions">No nested subexpressions</h3>
<p>Next let‚Äôs convert to a form where every function is applied to (tuples of) variables and constants only, i.e.&nbsp;where there are no nested sub-expressions (besides potentially nested tuples). We assign each nested sub-expression to an intermediate variable. For example</p>
<pre><code>a = add (add (b, c), d)</code></pre>
<p>would become</p>
<pre><code>i = add (b, c)
a = add (i, d)</code></pre>
<p>The choice of <code>i</code> is arbitrary; it just has to be a variable that‚Äôs not used elsewhere in our program. This form without nested subexpressions is a lot like <a href="https://en.wikipedia.org/wiki/A-normal_form">ANF</a> from the field of functional compiler construction. It‚Äôs also a lot like the <a href="https://en.wikipedia.org/wiki/Static_single_assignment_form">SSA form</a> of assembly language. After removing nested subexpressions, our program becomes</p>
<pre><code>p = mul (7, x)
r = div (1, y)
i1 = mul (p, x)
q = mul (i1, 5)
i2 = mul (2, p)
i3 = mul (i2, q)
i4 = mul (3, r)
v = add (i3, i4)</code></pre>
<h2 id="differentiation-line-by-line">Differentiation line-by-line</h2>
<p>We have performed all the transformations needed to prepare our program and we are ready to proceed to differentiation. We will differentiate the program line-by-line, that is, both the forward mode and reverse mode differentiation algorithms will generate one line of derivative code for each line of input code. But what <em>is</em> the derivative of an assignment statement? For forward mode, the derivatives correspond quite closely to what you might be familiar with from a first multivariate calculus course..</p>
<h3 id="examples">Examples</h3>
<h4 id="addition">Addition</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = add (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>dy = add (dx1, dx2)</code></pre>
<h4 id="multiplication">Multiplication</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = mul (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>dy = add (mul (x2, dx1), mul (x1, dx2))</code></pre>
<h4 id="division">Division</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = div (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>dy = add (div (dx1, x2), negate (mul (div (x1, mul (x2, x2)), dx2)))</code></pre>
<h2 id="forward-mode">Forward mode</h2>
<p>The forward mode transformation applies the appropriate differentiation rule to each line in the input program (listed on the left) to obtain a derivative line (listed on the right). To each line we apply exactly one rule and the form of the rule does not depend on any of the other lines.</p>
<pre><code>p = mul (7, x)   | dp = mul (7, dx)
r = div (1, y)   | dr = negate (div (dy, mul (y, y)))
i1 = mul (p, x)  | di1 = add (mul (dp, x), mul (p, dx))
q = mul (i1, 5)  | dq = mul (di1, 5)
i2 = mul (2, p)  | di2 = mul (2, dp)
i3 = mul (i2, q) | di3 = add (mul (di2, q), mul (i2, dq))
i4 = mul (3, r)  | di4 = mul (3, dr)
v = add (i3, i4) | dv = add (di3, di4)</code></pre>
<p>If we form a new program consisting of the sequence of assignments on the left followed by the sequence of assignments on the right then we have a program that calculates the forward derivative! The ‚Äúinputs‚Äù of this program are <code>x</code>, <code>y</code>, <code>dx</code> and <code>dy</code>. The ‚Äúoutputs‚Äù are <code>v</code> and <code>dv</code>.</p>
<p>(The derivatives of constants are zero and I‚Äôve left terms that are zero out for simplicity.)</p>
<p>In fact we can be a little more clever. We can interleave the assignments, so an assignment from the left is immediately followed by its corresponding assignment from the right, that is</p>
<pre><code>p = mul (7, x)
dp = mul (7, dx)
r = div (1, y)
dr = negate (div (dy, mul (y, y)))
i1 = mul (p, x)
di1 = add (mul (dp, x), mul (p, dx))
q = mul (i1, 5)
dq = mul (di1, 5)
i2 = mul (2, p)
di2 = mul (2, dp)
i3 = mul (i2, q)
di3 = add (mul (di2, q), mul (i2, dq))
i4 = mul (3, r)
di4 = mul (3, dr)
v = add (i3, i4)
dv = add (di3, di4)</code></pre>
<p>This interleaving demonstrates an important property of the automatic derivative: that it uses space proportional to the space usage of the original program. Specifically, as soon as we no longer need a variable that was assigned in the original program we no longer need the corresponding <code>d</code> version either.</p>
<p>We can also see another important property of the forward derivative: it runs in time proportional to the run time of the original program (assuming that the derivative of every primitive runs in time proportional to the run time of the primitive itself).</p>
<h2 id="reverse-mode-requires-two-additional-ideas">Reverse mode requires two additional ideas</h2>
<p>Now that we‚Äôve shown how to generate the forward mode derivative we can move on to the reverse mode derivative. Reverse mode requires two additional ideas:</p>
<ol type="1">
<li><p>We need to convert our original program to ‚Äúexplicit duplication‚Äù form: if a variable is used more than once then we make that explicit in the structure of the program. This is unusual but straightforward.</p></li>
<li><p>We need to use a form of the derivative that will be unfamiliar to most readers. It will appear quite bizarre when seeing it for the first time but it is crucial to implementing the reverse mode derivative.</p></li>
</ol>
<h2 id="explicit-duplication-form">Explicit duplication form</h2>
<p>Before applying the reverse mode AD transformation we will convert to ‚Äúexplicit duplication‚Äù form. Again, the transformation is not strictly required but if we omit it then the differentiation pass will have to do it implicitly. We take the ANF form of the program and insert explicit duplications (<code>dup</code>) for any variable that is used more that once. Recall that after removing nested subexpressions our program was</p>
<pre><code>p = mul (7, x)
r = div (1, y)
i1 = mul (p, x)
q = mul (i1, 5)
i2 = mul (2, p)
i3 = mul (i2, q)
i4 = mul (3, r)
v = add (i3, i4)</code></pre>
<p>We can see that <code>x</code> and <code>p</code> appear on the right hand side (i.e.&nbsp;are consumed) twice each. Therefore, they will need explicit duplication, so that each variable in the resulting program is used only once. With explicit duplication the program looks like</p>
<pre><code>(x1, x2) = dup x
p = mul (7, x1)
(p1, p2) = dup p
r = div (1, y)
i1 = mul (p1, x2)
q = mul (i1, 5)
i2 = mul (2, p2)
i3 = mul (i2, q)
i4 = mul (3, r)
v = add (i3, i4)</code></pre>
<p>(If a variable were used <span><em>n</em></span> times then we would have to insert <span><em>n</em>‚ÄÖ‚àí‚ÄÖ1</span> <code>dup</code>s for it. In our example no variable is used more than twice.)</p>
<p>Notice that now not only is every variable defined exactly once, but every variable is also <em>used</em> exactly once (except the inputs and outputs, <code>x</code>, <code>y</code> and <code>v</code> ‚Äì I won‚Äôt say more here about how exactly these seemingly special cases fit into the story). This property is important for a reason which will be explained when we come to generate the reverse mode program.</p>
<h2 id="differentiation-line-by-line-1">Differentiation line-by-line</h2>
<p>The line-by-line differentiation rules for generating the reverse mode need another article to explain thoroughly, but in this article I will hope to provide some basic intuition via examples and the informal notion that the reverse mode program calculates how sensitive the output is to different variables. For example, if the variable <code>y</code> appears in the original program then the variable <code>d_dy</code> will appear in the reverse mode program and measures ‚Äúhow sensitive the output is to small changes in <code>y</code>‚Äù. (I‚Äôll abbreviate this to ‚Äú<code>d_dy</code> is the sensitivity to <code>y</code>‚Äù.)</p>
<h3 id="examples-1">Examples</h3>
<h4 id="addition-1">Addition</h4>
<p>If a line of our pseudocode program is</p>
<pre><code>y = add (x1, x2)</code></pre>
<p>then the derivatives are</p>
<pre><code>d_dx1 = d_dy
d_dx2 = d_dy</code></pre>
<p>because the sensitivity to <code>x1</code> is the same as the sensitivity to <code>y</code> (and likewise for <code>x2</code>). This is written on a single line as</p>
<pre><code>(d_dx1, d_dx2) = dup (d_dy)</code></pre>
<h4 id="multiplication-1">Multiplication</h4>
<p>If a line of our program was</p>
<pre><code>y = mul (x1, x2)</code></pre>
<p>then the derivative line is</p>
<pre><code>(d_dx1, d_dx2) = (mul (x2, d_dy), mul (x1, d_dy))</code></pre>
<p>because the sensitivity to <code>x1</code> is <code>x2</code> times the sensitivity to <code>y</code> (and similarly for <code>x2</code>).</p>
<h4 id="duplication">Duplication</h4>
<p>If a line of our program was</p>
<pre><code>(x1, x2) = dup (x)</code></pre>
<p>then the derivative line is</p>
<pre><code>d_dx = add (d_dx1, d_dx2)</code></pre>
<p>because the sensitivity to <code>x</code> is the sensitivity to <code>x1</code> plus the sensitivity to <code>x2</code>.</p>
<h2 id="generating-reverse-mode-code">Generating reverse mode code</h2>
<p>Like forward mode before it, the reverse mode transformation applies the appropriate differentiation rule to each line in the input program (listed on the left) to obtain a ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/">http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/</a></em></p>]]>
            </description>
            <link>http://h2.jaguarpaw.co.uk/posts/automatic-differentiation-worked-examples/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657571</guid>
            <pubDate>Fri, 02 Oct 2020 00:21:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Community Moderation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24657148">thread link</a>) | @minimaxir
<br/>
October 1, 2020 | https://www.joinclubhouse.com/on-community-moderation | <a href="https://web.archive.org/web/*/https://www.joinclubhouse.com/on-community-moderation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Oct 1, 2020</p>
      <p>Since <a href="https://www.joinclubhouse.com/check-1-2-3">our last blog post</a>, Clubhouse has gone from a small community of beta testers to a growing network of communities, made up of people with vastly different opinions, experiences, worldviews and perspectives. This past week, people on Clubhouse have hosted several intense conversations on topics of identity, ethnicity, gender, racism, and religion. These conversations led to a number of serious incident reports, and we received questions and concerns from our community about how we plan to scale safety and moderation on Clubhouse. In the wake of this, we wanted to share some thoughts regarding what we stand for as a company, what we will and will not tolerate, what we are doing to prevent abuse, and how we plan to empower conversation hosts with better moderation tools as we grow.</p>
      <p>First, we unequivocally condemn Anti-Blackness, Anti-Semitism, and all other forms of racism, hate speech and abuse on Clubhouse. Our <a href="http://community.joinclubhouse.com/">Community Guidelines</a> and <a href="http://tos.joinclubhouse.com/">Terms of Service</a> make this clear, and we have trust and safety procedures in place to address any violation of these rules. People who violate them are warned, suspended, or removed completely from the platform, depending on the severity of the offense. This is a critical area of investment for us as a company and we are working hard to continue building tools and policies that are robust and that account for the unique dynamics of real-time voice conversations and group discussions.</p>
      <p>Second, we celebrate the fact that Clubhouse is not one single community, but a network of interconnected and diverse communities. As these communities grow, we need to provide moderators and club leaders with better tools and infrastructure to bring people together. Our goal is to empower them to host important, and even difficult, conversations‚Äîbecause some of the most powerful moments on Clubhouse happen when you find yourself speaking with a room full of people whose backgrounds and experiences are completely different from your own. These conversations often go on for hours, spilling out into breakout rooms full of people connecting, debating, evolving their worldviews and recognizing their blindspots. Our hope for Clubhouse is that it can be a new type of network based on empathy, discussion and sensemaking, rather than polarization. We think social media needs more of this.</p>
      <p>PREVENTING ABUSE</p>
      <p>Our Terms of Service and Community Guidelines define what type of behavior is allowed on Clubhouse and we are committed to addressing behavior that violates these rules. Here is what we‚Äôre doing to help with that:</p>
      <ul>
          <li><u>We‚Äôre taking action on all incident reports.</u> Any time someone reports a violation of our Terms of Service or Community Guidelines, we immediately investigate it. We don‚Äôt discuss these investigations publicly for user privacy reasons, but they are happening, and when rules are violated, corrective action is taken. This week, we‚Äôre also shipping real-time systems to investigate incidents more quickly and empower moderators to restrict and end rooms.</li>
          <li><u>We‚Äôre continuing to scale our trust and safety operations</u>. This is an ongoing effort for us that spans people, policy and product. On the people side, we‚Äôre focused on:</li>
          <ul>
              <li><u>Adding advisors.</u> We are building a team of advisors with deep expertise in trust, safety, diversity and inclusion to provide ongoing advice and input.</li>
              <li><u>Engaging directly with the community.</u> Since the earliest days of Clubhouse we‚Äôve been engaging deeply with a diverse cross-section of our community to understand their needs‚Äîthrough weekly Town Halls, New User Orientation sessions and deeper discussions, both on Clubhouse and off. We plan to continue the dialogue and see how these formats can be improved. We also use these discussions to continuously evolve our Terms of Service, Privacy Policy and Community Guidelines. These will be living documents.</li>
              <li><u>Growing our team.</u> Our trust and safety efforts are staffed to respond swiftly to incident reports, and we plan to proactively scale this operation as we grow. </li>
            </ul>
          
          <li><u>We‚Äôre shipping a wave of new safety features</u>. Over the past couple months we introduced blocking, muting, in-room reporting, and the ability for moderators to end a room. This week we are shipping a wave of new enhancements to make in-room reporting more real-time, specific and robust. We are also making the Community Guidelines accessible from every room and shipping new features to empower Clubhouse moderators.</li>
        </ul>
      
      <p>EMPOWERING MODERATORS AND CLUB LEADERS</p>
      <p>As we take these steps, we want to avoid conflating abuse with other things that can feel uncomfortable‚Äîlike differences in opinion or conversational style. Abuse, racism, religious intolerance, sexism and hate speech are never okay. Targeted and coordinated harassment is never okay. But what about general rudeness? Or holding opposing political viewpoints? While these things might seem jarring, we don‚Äôt believe they should be banned. We want to make sure that when you use Clubhouse, you get to choose your communities, your rooms, and your style of conversation. Here‚Äôs what we‚Äôre working on to enable this:</p>
      <ul>
          <li><u>Allowing clubs to set their own norms.</u> With our next release, club founders will be able to write rules that are specific to their clubs‚Äîto share their community values, communicate their norms, and define the dos and don'ts for speaking. When people join the club they'll be asked to agree to the rules. And when the club hosts a public conversation, non-members will be asked to agree to the rules before speaking. We think this will help people create intentional gathering spaces that cater to many interests and styles. These rules will supplement the Community Guidelines, which still apply to everyone.</li>
          <li><u>Hosting formal moderator training sessions.</u> There is no single way to moderate, and each room can have its own style. To help with this, we‚Äôre going to start offering regular moderator training sessions on the app, to ensure that people who wish to host discussions are equipped with the tools and knowledge they need.</li>
          <li><u>Improving moderator tooling.</u> Great moderators create great conversations, and we need to empower them with the right tools. This week we are building infrastructure that will allow us to notify moderators when there is a safety concern related to their room. Moderators can also tap the ‚ÄúEnd Room‚Äù button anytime if they feel the conversation is getting out of hand.</li>
          <li><u>Adding moderator badges.</u> This is a small thing, but it‚Äôs easier to provide a speaker with feedback when you know who‚Äôs in charge of the room. These will be live in the next release.</li>
        </ul>
      
      <p>The world is not a monoculture, and we want Clubhouse to reflect that. Ideally the experience is more like a town square, where people with different backgrounds, religions, political affiliations, sexual orientations, genders, ethnicities, and ideas about the world come together to share their views, be heard and learn. Some of these communities come together to debate. Some come to relax and joke around. Others hold listening parties and fireside chats. We think many styles should be supported, and we‚Äôre working on tools to help everyone create their own space, deepen friendships, meet new people and have meaningful discussions‚Äîin the way that suits them best.</p>
      <p>Clubhouse is nothing without the community, and we are immensely grateful for all of your ideas, emails, tweets, support and critiques. We‚Äôll continue working around the clock on all of this as we open it up to more of the world. Thank you! üôèüèΩ</p>

    </div></div>]]>
            </description>
            <link>https://www.joinclubhouse.com/on-community-moderation</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657148</guid>
            <pubDate>Thu, 01 Oct 2020 23:11:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VMware Fusion 12 Metal Support]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24656836">thread link</a>) | @wila
<br/>
October 1, 2020 | https://www.vimalin.com/blog/fusion-12-0-metal-support/ | <a href="https://web.archive.org/web/*/https://www.vimalin.com/blog/fusion-12-0-metal-support/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>			<div>
				
				<article id="post-1344">	
			<figure>
		<img width="1136" height="918" src="https://www.vimalin.com/wp-content/uploads/2020/10/image.png?is-pending-load=1" alt="VMware Fusion 12 Metal Support" loading="lazy" data-lazy-srcset="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?w=1136&amp;ssl=1 1136w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=300%2C242&amp;ssl=1 300w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1 1024w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=768%2C621&amp;ssl=1 768w" data-lazy-sizes="(max-width: 1136px) 100vw, 1136px" data-lazy-src="https://www.vimalin.com/wp-content/uploads/2020/10/image.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">		</figure>
			<div>
					
				
									<div>
				
<p>Ok.. I‚Äôm so ecstatic.. a quick blog post must be written‚Ä¶</p>



<p>On VMworld‚Äôs ‚ÄúWhat‚Äôs New with VMware Workstation and VMware Fusion‚Äù, Michael Roy dropped a bomb in his last ‚ÄúOne more thing‚Äù note.</p>



<p>He showed off ‚ÄúMetal Support‚Äù in a macOS guest‚Ä¶ Now we have been told for years that we cannot get 3D Acceleration in a macOS guest, so seeing that was already pretty great. Something to look forward to.<br>In that same presentation he also showed the .vmx settings in order to get that working. Once the feature lands‚Ä¶ </p>



<p>So of course immediately after the presentation I _had_ to try, even while it is only supposed to be working in a future version of VMware Fusion 12.0.<br>I got a ‚ÄúInvalid configuration‚Äù error (or something along those lines). <br>OK.<br>Silly me did not look at the vmware.log file, so today I was poking Michael a bit on twitter and asking about how well Metal works on Big Sur beta 9 and that it is ‚Äúso hard to wait‚Äù and he tells me ‚Äúbut you can try it yourself already‚Äù‚Ä¶ üòÆ</p>



<figure><div>
<blockquote data-width="500" data-dnt="true"><div lang="en" dir="ltr"><p>You can totally use it today actually, but AutoFit doesn't work (needs new tools that haven't shipped yet‚Ä¶ future versions won't require Tools at all)</p><p>svga.present="FALSE"<br>appleGPU0.present="TRUE"</p><p>appleGPU0.screenWidth=1680 appleGPU0.screenHeight=1050</p></div>‚Äî Michael Roy (@mikeroySoft) <a href="https://twitter.com/mikeroySoft/status/1311754703055675392?ref_src=twsrc%5Etfw">October 1, 2020</a></blockquote>
</div></figure>



<p>OMG.. that‚Äôs when I realized that I had missed a detail..</p>



<figure><div>
<blockquote data-width="500" data-dnt="true"><div lang="en" dir="ltr"><p>Ohh‚Ä¶ I had not put the svga.present="FALSE" line and now I see what other precondition I missed (silly me)‚Ä¶</p><p>vmx| I005: AppleGPU: Apple GPU support is not available: requires macOS 11.</p><p>Looks like I will update that box to macOS 11 right now.</p></div>‚Äî Wil van Antwerpen (@wilva) <a href="https://twitter.com/wilva/status/1311759349572870144?ref_src=twsrc%5Etfw">October 1, 2020</a></blockquote>
</div></figure>



<p>Also my host wasn‚Äôt running Big Sur yet (I had only run it in a VM)<br>‚Ä¶ so‚Ä¶ next hour or so I was frantically busy installing Big Sur Beta 9 on my 2014 Mac Mini and YES‚Ä¶ IT DOES WORK and it is SOOOO SMOOTH</p>



<figure><img loading="lazy" width="1024" height="827" src="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1" alt="" srcset="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1 1024w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=300%2C242&amp;ssl=1 300w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=768%2C621&amp;ssl=1 768w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?w=1136&amp;ssl=1 1136w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;ssl=1 1024w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=300%2C242&amp;ssl=1 300w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=768%2C621&amp;ssl=1 768w, https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?w=1136&amp;ssl=1 1136w" data-lazy-src="https://i2.wp.com/www.vimalin.com/wp-content/uploads/2020/10/image.png?resize=1024%2C827&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>This is the best thing since sliced bread.</p>



<div><p>THANK YOU VMware Fusion team!</p><p>In summary:<br>This is not an officially released feature, treat it what it is: Experimental<br>Required: minimum of macOS Big Sur as host OS<br>Required: minimum VMware Fusion 12.0<br>Guest OS support: So far I have only gotten this to work with a macOS Big Sur guest (but I haven‚Äôt tried others beyond macOS Mojave)</p><p>You have to add the following lines to the .vmx file of your VM in order to test this:<br><code>svga.present="FALSE"<br>appleGPU0.present="TRUE"<br>appleGPU0.screen0.width = "1680"<br>appleGPU0.screen0.height = "1050"</code></p></div>



<p>To be honest I don‚Äôt even have the lines with width and height, but that‚Äôs how you can define that for now.<br>It will only get better from here on once it is officially supported.</p>
			</div>
					
			<hr>
			
					</div>
</article>						</div>	
			
		<!--/Blog Content-->
		         				</div></div>]]>
            </description>
            <link>https://www.vimalin.com/blog/fusion-12-0-metal-support/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656836</guid>
            <pubDate>Thu, 01 Oct 2020 22:28:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using artificial intelligence to make publishing profitable]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24656437">thread link</a>) | @Sanksshep
<br/>
October 1, 2020 | https://www.aiplusinfo.com/blog/using-artificial-intelligence-to-make-publishing-profitable | <a href="https://web.archive.org/web/*/https://www.aiplusinfo.com/blog/using-artificial-intelligence-to-make-publishing-profitable">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-1fd98981423ebe5f9a2e"><p><h2>Artificial Intelligence has significant implications in making publishing profitable ‚Äì from automation to improvements in advertising. Let‚Äôs dive into what AI is, as well as the potential applications within the publishing industry to make it profitable.</h2></p></div><div data-block-type="2" id="block-yui_3_17_2_1_1601450467819_4883"><div><h3><strong>What is AI?</strong></h3><p>Artificial intelligence, or AI, refers to the ability of tools or technology to perform tasks that would normally require human intelligence to complete.&nbsp;</p><p>Machine learning is a subset of AI in the computer science space ‚Äì where the platform or model learns from an existing data set so that it can understand the underlying trends and patterns. This knowledge is then used by the machine learning models to make predictions or determine outcomes from the new data it encounters.</p><p>In other words, the computer model uses statistical techniques to learn how to get better at a task, whether that be categorizing data or predicting if a client is a good fit for a certain product. For the model to learn to do this without specific programming, it must analyze existing data that is already pre-labeled.</p><p>Deep learning is another subset of artificial intelligence that involves the creation of a neural network, which has layers and layers of data processing. This type of AI can make deep connections and gain valuable insights from a dataset since it processes information almost like the human brain does.</p><h3><strong>Goals of Artificial Intelligence in Publishing</strong></h3><p>The goals of artificial intelligence in publishing include automating story production and evaluating content automatically.&nbsp;</p><p>The Associated Press started using AI back in 2015 for story automation. They understood that machine learning could create content such as public company earnings report recaps since they need details and accuracy but do not require much creativity.&nbsp;</p><p>They took this further in 2016 when they developed an AI platform that could report on Minor League Baseball games ‚Äì the machine learning model could incorporate statistics and highlights that, again, are strictly fact-based.&nbsp;</p><p>This is just the beginning for automatic story production, and as artificial intelligence platforms become more accessible there will be more publishers utilize it to create automated content.</p><p>Another goal of artificial intelligence in publishing is evaluating content. A machine learning model can help an editor when making decisions regarding moderation and editing.&nbsp;</p><p>AI can be used to automate complex tasks, such as comparing the characteristics of a manuscript to those of a bestseller to see where improvements can be made. This can help editors focus on the most marketable content and save time and effort narrowing them down.&nbsp;</p><p>Automated text analysis can optimize plagiarism detection as well as copyright enforcement! Artificial intelligence can eliminate some of the tedious work involved with researching copyrights and ensuring that the content being published is 100% authentic.&nbsp;</p><p>Comment moderation can be significantly improved as a result of artificial intelligence. Machine learning models can save publishers valuable time and resources by automatically detective inappropriate or abusive labels and comments ‚Äì and removing them.&nbsp;</p><p>Reducing the workload of human moderators can allow publishers to open more content for commenting and facilitate a wider scope of articles. The New York Times has already implemented automation within the moderation space, and this has allowed them to open up more content for commenting ‚Äì where previously they capped it at 10% of their articles.&nbsp;</p><h3><strong>Artificial Intelligence and Advertising</strong></h3><p>Artificial intelligence can also help publishing firms when it comes to advertising. It can improve everything from engagement to the structuring and design of content.&nbsp;</p><p>AI platforms allow publishers to personalize content for marketing campaigns since statistics have shown that personal advertisements have a higher level of engagement ‚Äì and therefore, a better return on investment.</p><p>Machine learning models will analyze content and engagement to curate newsletters and articles that fit right in with your audience segment. Research performed by McKinsey found that this level of personalization is essential and can increase the efficiency of marketing budgets by up to 30%!</p><p>This type of personalization can also be used for the automation of recommendations. You can gain insights into what your readers like based on their browsing history, and then the machine learning model can identify trends and patterns.&nbsp;</p><p>With this information, you can give your readers personalized recommendations on other content they may enjoy. This will help your firm boost engagement as well as make your advertisements much more personalized.&nbsp;</p><h3><strong>Conclusion</strong></h3><p>These are just a few aspects in which artificial intelligence can impact publishing by reorganizing the workforce towards better things with the help of automation and improve revenue by personalizing content and experiences for a diverse set of users. Publishing companies can benefit a lot by using artificial intelligence in tough economic climates and weather the storm and keep the lights on. </p></div></div></div>]]>
            </description>
            <link>https://www.aiplusinfo.com/blog/using-artificial-intelligence-to-make-publishing-profitable</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656437</guid>
            <pubDate>Thu, 01 Oct 2020 21:42:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asynchronous Development for Hybrid Remote Dev Teams]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24656046">thread link</a>) | @davetwichell
<br/>
October 1, 2020 | https://linearb.io/blog/asynchronous-development/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/asynchronous-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<p>Hope and optimism are default settings for my LinearB co-founder, Ori Keren. For Ori, one silver lining in this tumultuous year is that 2020 ushered in the age of the hybrid remote work model. </p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1024x429.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-300x126.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-768x322.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1536x644.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM.png.webp 1908w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1024x429.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1024x429.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-300x126.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-768x322.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM-1536x644.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-4.48.18-PM.png 1908w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Asynch-2.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>‚ÄúHybrid remote is how software development teams were always meant to work. It just took 20 years and a global pandemic for us to figure that out.‚Äù </p>



<p>Ori believes that, to be highly successful, developers need uninterrupted time to get into a deep state of focus on their task at hand. Getting in ‚Äúthe zone‚Äù is hard and when you get interrupted you can‚Äôt easily get your deep focus back. </p>



<p>Remote work has eliminated most dev interruptions, right? Not so fast. </p>



<p>Company culture is a powerful force. Like gravity, we don‚Äôt see or or think about most days but it effects everything we do. </p>



<div><p>According to Ori, culture is even more powerful than a global pandemic or a new trend like hybrid remote. </p><p>‚ÄúWorking remote was great for our dev team at first. Once we got over the initial disruption of getting equipment and finding a quiet place to work at home, team productivity soared. But then we started noticing our efficiency going down.‚Äù </p></div>



<div><p>What happened? Our in-the-office culture grabbed hold and brought us right back to where we were in March. </p><p>‚ÄúAll of the interruptions crept back in‚Ä¶ scheduled meetings, impromptu Zoom status meetings‚Ä¶‚Äù </p><p>In other words, we were a hybrid remote company with an in-the-office mindset and process. </p><p>You can see the effects here in our Cycle Time trend chart. </p></div>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1024x586.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-300x172.png.webp 300w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-768x440.png.webp 768w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1536x879.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-2048x1172.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1024x586.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1024x586.png 1024w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-300x172.png 300w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-768x440.png 768w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-1536x879.png 1536w, https://linearb.io/wp-content/uploads/2020/10/Group-1129-1-2048x1172.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>







<div><p>‚ÄúBeing a remote employee used to be a semi-unique experience that came with a certain level of trust, preparation and experience. Then the entire global dev community went remote at the same time, without preparation or understanding of what needs to change.‚Äù</p><p>Hybrid remote can be a business advantage for companies embracing it. But only if we adapt our culture and process to make it work. </p></div>



<p>This is how Asynchronous Development was born. </p>







<h2>What is Asynchronous Development?</h2>



<p>Async Dev is an approach to development grounded in asynchronous communication. It works for hybrid remote, full remote and any dev teams that wants to unlock the full creative power of their developers. </p>







<iframe width="560" height="465" src="https://www.youtube.com/embed/w0pw0dcFZ-w?rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>







<p>Async Dev builds on the foundation Agile put in place. Since the Agile Manifesto was published 20 years ago, software development has gone through some drastic changes. Many of those changes like asynchronous communication tools (e.g. Slack &amp; Teams) becoming the default form of communication and hiring remote developers were forced into the spotlight in 2020. </p>



<p>Ori  started wrote the Async Dev manifesto to help engineering and product leaders see how they can change the way they work to turn this new situation into an opportunity. </p>



<p><strong><em>Below Ori explains how Async Dev builds on the Agile and DevOps movements and talk through each of the five core tenets of Async Dev. Listen to the accompanying 60~ second audio clip from Ori in each section or just read the blog</em></strong>. </p>







<h2>The Async Dev Movement</h2>



<p>Hybrid remote development is not new, but 2020 accelerated the adoption of many of the practices already in place. As these hybrid remote methods are normalized globally, we also have to accept the way we work, the processes, and the ceremonies have changed as well. </p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1024x489.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-300x143.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-768x367.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1536x734.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-2048x978.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1024x489.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1024x489.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-768x367.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-1536x734.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-9.12.03-AM-2048x978.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/10/history-1.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>Asynchronous Development acknowledges the importance of movements like Agile and DevOps and offers a new way of looking at development that is a better fit for 2020.&nbsp;</p>











<h2>The 5 Tenets of Asynchronous Development</h2>



<p>There are 5 core tenets of Async Dev that we have adopted to transform the hybrid remote reality into an opportunity to strengthen the alignment between development and the business.</p>







<div><div>
<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1024x521.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-300x153.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-768x391.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1536x782.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-2048x1043.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1024x521.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1024x521.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-300x153.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-768x391.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-1536x782.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-23-at-2.21.30-PM-2048x1043.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>
</div></div>







<ol><li>Asynchronous is the default form of communication</li><li>Git is the central element of your development process</li><li>Project Management tools are for planning, not status updates</li><li>Continuous improvement is a daily practice</li><li>Dev teams are the core of the business</li></ol>











<figure><blockquote><p>LinearB built a new kind of project board exclusively for hybrid remote dev teams.</p><p><span><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noreferrer noopener">Get our Devboard free</a></span></p></blockquote></figure>







<h2>Tenet 1 ‚Äì Asynchronous is the default form of communication</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1024x462.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-300x135.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-768x347.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1536x693.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM.png.webp 1950w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1024x462.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1024x462.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-300x135.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-768x347.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM-1536x693.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-9.39.22-AM.png 1950w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet-1.mp3"></audio><figcaption>Click here to listen to Ori</figcaption></figure>







<p>Asynchronous communication means using collaboration tools and mentions by default. It helps reduce context switching, avoid unnecessary interruptions, and increases productivity. </p>



<p>After LinearB went full remote back in April of 2020, we analyzed our development team‚Äôs metrics to understand exactly how this change effected the productivity and efficiency of the team. </p>



<p>In true Asynchronous fashion, 92% of developers at LinearB were writing more code, while PR sizes and Cycle Times increased. This clearly tells us that fewer interruptions means greater individual productivity. It also clearly shows what we needed to adapt the way worked to the new circumstances if we were going to continue delivering at the same level as pre-wfh. </p>



<p>At LinearB we have started taking a closer look at the function of the daily stand-up and how to use that time to best suit our team. Now that we are a hybrid remote development team with up to the minute updates on issue statuses using LinearB, we use our stand-up time to connect on a personal level, and then just talk about blockers. It‚Äôs not perfect, but it‚Äôs been a nice adaptation to our new reality.</p>







<h2>Tenet 2 ‚Äì Git is the central element of your development process</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1024x580.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-300x170.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-768x435.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1536x869.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM.png.webp 1802w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1024x580.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1024x580.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-300x170.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-768x435.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM-1536x869.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.31.21-AM.png 1802w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet-2_2-1.mp3"></audio><figcaption>Click here to hear Ori</figcaption></figure>







<p>Whether you use GitHub, GitLab, Bitbucket, Azure DevOps or other git flavor, most of the stages of the development cycle either start or involve your git system. How you choose to configure, deploy and utilize it has a great impact on your dev process. </p>



<p>In addition the most up to date status of work progress resides in the git system. Fortunately git was built with open source in mind so most of the phases (coding, review, merge) do not require mandatory synchronous communication and can be executed in different places and different times.</p>











<h2>Tenet 3 ‚Äì Project Management tools are for planning, not status updates</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1024x581.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-300x170.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-768x436.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1536x871.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM.png.webp 1714w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1024x581.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1024x581.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-300x170.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-768x436.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM-1536x871.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.46.33-AM.png 1714w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet3_2.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>Whether your team uses Jira, Trello or something else, project management tools are great for planning an iteration or the next week, but trying to use them to enrich dozens of micro decisions that dev teams are taking every day will slow down productivity. </p>



<p>Every update to the work status while in ‚Äòbuilding mode‚Äô should be with dev first in mind, meaning it should automatically reflect the status based on actual git activity and it should mainly serve the people that build and ship the software.</p>







<figure><blockquote><p>Does your current project board</p><p>give you more questions than answers?</p><p><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noreferrer noopener">Try the LinearB Devboard free</a></p></blockquote></figure>







<h2>Tenet 4 ‚Äì Continuous improvement is a daily practice</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1024x596.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-300x175.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-768x447.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1536x895.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM.png.webp 1724w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1024x596.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1024x596.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-300x175.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-768x447.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM-1536x895.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-10.57.03-AM.png 1724w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/10/tenet4new.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>Data should always be accessible to everyone ‚Äì no gate keepers, not just data engineers, and not just reviewed in meetings by management.</p>



<p>Your KPIs and how you decide to utilized them will define your culture. </p>



<p>Key Principles for Data Usage: </p>



<ul><li>Team-based data over developer stack ranking</li><li>Measure process over output</li><li>Measure empiric over subjective</li><li>Focus on leading indicators vs. lagging indicators</li><li>Establish baseline data points and trends</li><li>Make sure it‚Äôs actionable</li></ul>







<p>Data should be used in an ethical way and cannot replace good managers with good soft skills and human interaction.</p>







<figure><blockquote><p>High-risk code &amp; stuck PR Slack Alerts are pretty amazing.</p><p><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noreferrer noopener">Get them Free with LinearB</a></p></blockquote></figure>







<h2>Tenet 5 ‚Äì Dev teams are the core of the business</h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1024x552.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-300x162.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-768x414.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1536x828.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM.png.webp 1988w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1024x552.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1024x552.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-300x162.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-768x414.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM-1536x828.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-24-at-11.18.49-AM.png 1988w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>



<figure><audio controls="" src="https://linearb.io/wp-content/uploads/2020/09/Tenet-5_1.mp3"></audio><figcaption><em>Click here to hear Ori</em></figcaption></figure>







<p>The best companies in the world evolved from developers that were highly aligned with business and market needs. Dev-led companies empower developers to make decisions on behalf of customers and the business by giving them context instead of instructions.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1024x460.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-300x135.png.webp 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-768x345.png.webp 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1536x689.png.webp 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-2048x919.png.webp 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1024x460.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1024x460.png 1024w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-300x135.png 300w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-768x345.png 768w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-1536x689.png 1536w, https://linearb.io/wp-content/uploads/2020/09/Screen-Shot-2020-09-28-at-5.02.39-PM-2048x919.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>







<p>We believe that ‚Äòdevelopers‚Äô and ‚Äòbusiness‚Äô are not disjoint sets and sometimes the most important business decisions are hiding in code lines. That is why the best businesses should focus on pushing context to dev teams, and dev teams should provide transparency into their decision making so both can enjoy a refinement cycle.</p>



<p>This is probably the hardest part of making Async Dev a reality because, as dev leaders, it is the element we have least control over. We need buy-in from throughout the business. </p>







<h3><strong>Here are 5 practical steps you can take today to start practicing Async Dev:</strong></h3>







<h4>1) Cut status updates from your daily stand-up</h4>



<p>Instead focus on what matters ‚Äì who needs help and whether you‚Äôre going to ship on time. Async Dev means never spending valuable meeting time on status updates when everyone could take 5 minutes on their own before the meeting to see what happened yesterday and what‚Äôs happening today. <a href="https://linearb.io/blog/make-daily-better/" target="_blank" rel="noreferrer noopener">Click here to get 16 tips</a> for how to run a better daily stand-up. </p>







<h4>2) Decouple learning and improvement from your retro. </h4>



<p>We‚Äôre not saying to cancel your retro. Getting together every few weeks to discuss learnings is great. But if you un-gate your team metrics so everyone can see bottlenecks and suggestions for how to improve each day, then improvement can be led everyone on your team (not just managers) and become part of the fabric of your team culture. <a href="https://linearb.io/blog/data-driven-dev-team/" target="_blank" rel="noreferrer noopener">Click here to see how to use data in your day-to-day</a> practices without damaging culture. </p>







<h4>3) Combine quantitative signals &amp; qualitative assessments for team health</h4>



<p>Use multiple data points to identify signs of overload and burnout. Face to face conversation is not the only way to see if a teammate is struggling. Looking at your WIP balance across the team and consecutive days worked, in combination with 1:1 conversation, can tell you a lot about a person‚Äôs work health. <a href="https://linearb.io/blog/dev-team-health/" target="_blank" rel="noreferrer noopener">Click here to see which data points can help you ‚Ä¶</a></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/asynchronous-development/">https://linearb.io/blog/asynchronous-development/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/asynchronous-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24656046</guid>
            <pubDate>Thu, 01 Oct 2020 20:53:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interviewing During Covid ‚Äì Google/Apple/ByteDance/Databricks/Citadel/HRT/JS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24655799">thread link</a>) | @oneraynyday
<br/>
October 1, 2020 | https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/ | <a href="https://web.archive.org/web/*/https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><strong>I interviewed for Google√¢‚Ç¨‚Ñ¢s Tensorflow, Apple√¢‚Ç¨‚Ñ¢s MLPT (Machine Learning Platform &amp; Technology), Bytedance√¢‚Ç¨‚Ñ¢s ad infrastructure, Databrick√¢‚Ç¨‚Ñ¢s ML team, Citadel Securities as a quantitative research analyst, Hudson River Trading(HRT) as an algorithm engineer, and Jane Street√¢‚Ç¨‚Ñ¢s research desk as SWE. I received offers from all of the companies except for Jane Street. Here√¢‚Ç¨‚Ñ¢s my experience interviewing during COVID.</strong></p>

<p><em>Disclaimer: I won√¢‚Ç¨‚Ñ¢t be walking on the edge of leaking confidential information like an idiot(yes, I signed an NDA for all of these companies). Don√¢‚Ç¨‚Ñ¢t expect to get any hints for your interviews.</em></p>

<p>The structure of this blog is inspired by my friend <a href="https://medium.com/@XiaohanZeng/i-interviewed-at-five-top-companies-in-silicon-valley-in-five-days-and-luckily-got-five-job-offers-25178cf74e0f">Han√¢‚Ç¨‚Ñ¢s medium blogpost.</a></p>

<p><img src="http://oneraynyday.github.io/assets/interviews.png" alt="interviews"></p>



<ul id="markdown-toc">
  <li><a href="#table-of-contents" id="markdown-toc-table-of-contents">Table of Contents</a></li>
  <li><a href="#preparation" id="markdown-toc-preparation">Preparation</a>    <ul>
      <li><a href="#algorithms" id="markdown-toc-algorithms">Algorithms</a></li>
      <li><a href="#systems-design" id="markdown-toc-systems-design">Systems Design</a></li>
      <li><a href="#math-questions" id="markdown-toc-math-questions">Math Questions</a></li>
    </ul>
  </li>
  <li><a href="#the-interview-process" id="markdown-toc-the-interview-process">The interview process</a>    <ul>
      <li><a href="#more-interview-rounds-during-covid" id="markdown-toc-more-interview-rounds-during-covid">More interview rounds during COVID</a></li>
      <li><a href="#dealing-with-time-zones" id="markdown-toc-dealing-with-time-zones">Dealing with time zones</a></li>
      <li><a href="#which-ones-were-the-hardest" id="markdown-toc-which-ones-were-the-hardest">Which ones were the hardest?</a></li>
    </ul>
  </li>
  <li><a href="#making-a-decision" id="markdown-toc-making-a-decision">Making a decision</a>    <ul>
      <li><a href="#the-culture-and-the-small-things-count" id="markdown-toc-the-culture-and-the-small-things-count">The culture and the √¢‚Ç¨≈ìsmall√¢‚Ç¨ÔøΩ things count</a></li>
    </ul>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
</ul>



<p><strong>Working on machine learning infrastructure is 99% systems engineering and 1% machine learning.</strong> My experience on machine learning infrastructure teams has taught me this, and preparing for systems engineering topics was the right way to go. I did the following to prepare:</p>

<h2 id="algorithms">Algorithms</h2>

<p><strong>~50 leetcode hard questions</strong>. Some of them are DP, some are graph based, some of them are just NP-hard problems that are a pain to code(which is the point), and some include devising some clever data structure that supports a very specific access pattern. I gave myself roughly 40 minutes to solve these problems. ~15%(7 questions) of the time I couldn√¢‚Ç¨‚Ñ¢t figure out the correct solution because time limit exceeded, memory limit exceeded, or I was just flat out wrong. I directly read the solutions and learned the tricks necessary to solve the type of problems moving forward. Don√¢‚Ç¨‚Ñ¢t bother with medium or easy questions since hard questions often contain medium/easy tasks as subroutines, and these companies probably wouldn√¢‚Ç¨‚Ñ¢t ask you easy leetcode questions anyways.</p>

<p>I wrote the solutions in either python and C++(sometimes both) and went back to polish my code for minor optimizations or readability improvements. For C++, I made sure I wasn√¢‚Ç¨‚Ñ¢t using raw pointers unless appropriate and I was using C++17 (<code>constexpr</code> functions, <code>std::array</code> instead of raw arrays, smart pointers, template type deduction with lambdas, etc) features. The reason I wasn√¢‚Ç¨‚Ñ¢t using C++20 was because the online coding platforms(like coderpad) likely use stable distributions of GCC and clang, which means some of the new features are in their experimental phase. <strong>I didn√¢‚Ç¨‚Ñ¢t want to encounter a bug with concepts or <code>std::ranges</code>  in the middle of the interview.</strong> (In fact, I found a <a href="https://stackoverflow.com/questions/62398252/why-likely-attribute-in-c20-raises-a-warning-here">bug with attributes</a> recently in a new version of gcc)</p>

<p>I also spent a few days on problems elsewhere:</p>

<ul>
  <li><a href="https://codingcompetitions.withgoogle.com/codejam/archive">Codejam problems</a>. Round 1 and 2 are feasible, but round 3 was very difficult. I√¢‚Ç¨‚Ñ¢d suggest studying round 1√¢‚Ç¨‚Ñ¢s if you only care about interviews.</li>
  <li><a href="https://codeforces.com/">Codeforce contests</a>. There are 3 tiers(or Divs, as they call it), and for interviews I suggest Div 3 and Div 2. Don√¢‚Ç¨‚Ñ¢t bother with the D+ questions in Div 2, and definitely don√¢‚Ç¨‚Ñ¢t bother with Div 1.</li>
</ul>

<h2 id="systems-design">Systems Design</h2>

<p>Working at Airbnb has made me pretty familiar with high level distributed systems design, but of course I worked only with a subset of them. I think Martin Kleppman√¢‚Ç¨‚Ñ¢s book <a href="https://www.google.com/books/edition/Designing_Data_Intensive_Applications/p1heDgAAQBAJ?hl=en">Designing Data Intensive Applications</a> is a great read, but you√¢‚Ç¨‚Ñ¢ll have to pick and choose which sections you want to go over as it√¢‚Ç¨‚Ñ¢s a pretty dense book. If you don√¢‚Ç¨‚Ñ¢t have time, maybe just try understanding how Kubernetes works with Marko Luksa√¢‚Ç¨‚Ñ¢s <a href="https://www.manning.com/books/kubernetes-in-action">Kubernetes in Action</a>, which is a much easier read. You can then draw parallels with the distributed design for K8s against whatever systems design question the interviewer has for you.</p>

<p>Make sure you know some fundamental ideas about distributed systems like the <strong>map reduce paradigm</strong>, <strong>sharding</strong>, <strong>asynchronous and synchronous follower replicas</strong>, <strong>CAP theorem</strong>, etc. <em>What you don√¢‚Ç¨‚Ñ¢t want to do is read 3 sentences about each of the terms above and regurgitate it in your interviews. Interviewers have been doing this for a while, they know you don√¢‚Ç¨‚Ñ¢t actually understand the concepts.</em> Don√¢‚Ç¨‚Ñ¢t be that guy.</p>

<h2 id="math-questions">Math Questions</h2>

<p><strong>These are only asked in finance firms.</strong> Honestly, these are just all over the place. I read this green book called <a href="http://quantfinanceinterviews.com/">A Practical Guide to Quantitative Finance Interviews</a> by Xinfeng Zhou, but only doing a single problem in each section by myself. Hedge funds will quiz you on discrete math to probability theory to geometry to information theory to literally anything. My advice is if you√¢‚Ç¨‚Ñ¢re a software engineer interviewing for a hybrid of finance and tech places, timebox yourself in this category.</p>

<hr>

<p>I have not seen an interview question this cycle that was an exact question I√¢‚Ç¨‚Ñ¢ve seen online or in books. Your mileage may vary.</p>



<p>Interviewing and talking with all of these companies was a great experience, even with COVID in place. Obviously, as shelter-in-place continues, these companies are conducting virtual on-site interviews and trying to make this process as smooth as possible. Without getting into the specifics, I√¢‚Ç¨‚Ñ¢ll outline some common things I√¢‚Ç¨‚Ñ¢ve noticed during the process in the COVID era.</p>

<ul>
  <li>Many companies use Zoom or Google Hangouts for their on-sites.</li>
  <li>They give you ~15 minute breaks in between interviews for water breaks.</li>
  <li>Some companies give you a longer lunch break (45 mins to an hour).</li>
  <li>If you√¢‚Ç¨‚Ñ¢re interviewing for a company in another time zone, prepare to wake up in the early AM√¢‚Ç¨‚Ñ¢s or interview in the late afternoon (sometimes after dinner).</li>
  <li>Conveying an idea takes slightly longer because you√¢‚Ç¨‚Ñ¢re not drawing on a whiteboard. Some companies have virtual whiteboard apps and others allow the use of Zoom whiteboards.</li>
  <li><strong>Some companies added more interview rounds for virtual on-sites.</strong> Apparently more people are getting into companies with subpar technical skills during COVID and they√¢‚Ç¨‚Ñ¢re making the process more selective. I think this can also be due to the increase in competition due to unemployment rates increasing.</li>
  <li>Feedback and communications with recruiters is generally faster.</li>
</ul>

<h2 id="more-interview-rounds-during-covid">More interview rounds during COVID</h2>

<p>The bolded text might scare you as a potential candidate, but don√¢‚Ç¨‚Ñ¢t worry too much. The added questions aren√¢‚Ç¨‚Ñ¢t testing you if you know how to implement a bloom filter or a fibonacci heap or something niche. They usually test on the <em>coding abilities of the person and how well they√¢‚Ç¨‚Ñ¢d actually ramp up in a novel, collaborative environment</em>. This can manifest itself in multiple ways - live debugging session with a new codebase, reading documentation to work with new technology, or a collaborative brainstorming sesion for a hard(er) problem. If you√¢‚Ç¨‚Ñ¢re a decent software engineer you shouldn√¢‚Ç¨‚Ñ¢t worry about these as much.</p>

<h2 id="dealing-with-time-zones">Dealing with time zones</h2>

<p><em>One of the biggest struggles I had during the interview process was adjusting my sleep schedule to wake up at 5-6AM to make sure I√¢‚Ç¨‚Ñ¢m awake and on time for the interviews in New York/Chicago (I√¢‚Ç¨‚Ñ¢m in California so this was a 3 hour gap)</em>. Usually, companies would fly you out the day-of or the day before the on-site. I√¢‚Ç¨‚Ñ¢ve always felt tired after a plane flight and was able to get a good night√¢‚Ç¨‚Ñ¢s rest before the interviews in the past. With COVID, everything is virtual and the companies expect you to interview at their hours.</p>

<p>Even with slowly adjusting my sleep schedule over a week or two I still had trouble with sleep. Personally, I get pretty nervous before an on-site and I√¢‚Ç¨‚Ñ¢d need to feel adequately tired to get a good night√¢‚Ç¨‚Ñ¢s rest instead of tossing and turning in bed. With the clock turned 3 hours back, I suddenly found myself not tired enough to sleep on time the night before the interview(even with a whole week of adjusting). This led to me consistently getting 6-7 hours of sleep instead of the 9 hours of sleep I usually get on game day, which really sucked.</p>

<p>Ultimately, I have no idea how much the sleep problem really affected my performance, but it was enough to shake my confidence going in.</p>

<p><em>NOTE: +1 to Citadel for proactively breaking my on-site over multiple days so I can have a sane sleep schedule for their interviews. This might depend on the specific team you√¢‚Ç¨‚Ñ¢re interviewing with.</em></p>

<h2 id="which-ones-were-the-hardest">Which ones were the hardest?</h2>

<p>This is subjective, and the question can be broken up into multiple components:</p>

<ul>
  <li><strong>Time pressure - Jane Street</strong>. This is probably why I failed their interviews, which were a bit longer than usual. I tend to explain my approach before coding anything to get a confirmation on the interviewer√¢‚Ç¨‚Ñ¢s side that I√¢‚Ç¨‚Ñ¢m on the right track. I probably spent too much time explaining and didn√¢‚Ç¨‚Ñ¢t have enough time to finish the code for some interviews.</li>
  <li><strong>Math questions - Citadel</strong>. They asked me some <em>really</em> interesting math problems that aren√¢‚Ç¨‚Ñ¢t related to finance at all. I don√¢‚Ç¨‚Ñ¢t think they expect the interviewer to get 100% of the questions since whenever I solved one the interviewer was ready with another. HRT also asked some.</li>
  <li><strong>Systems design - HRT</strong>.</li>
  <li><strong>Outside-the-box problems - Databricks</strong>. They conduct one of the most unique interviews I√¢‚Ç¨‚Ñ¢ve ever had.</li>
  <li><strong>Language specific questions - Citadel/HRT</strong>. Grilled me a lot on low level C++ stuff.</li>
  <li><strong>Length of interview - HRT</strong>. I started at 8AM PST (I requested to move it to 8AM from 7AM) and finished at ~2:30PM. <strong>That is a whopping 6 hours and 30 minutes.</strong> I also did a coding challenge and 2 phone screens before I moved to on-site, totalling almost 10 hours for interviews.</li>
  <li><strong>General algorithm questions - Jane Street/HRT</strong>. I think Jane Street was a bit harder given the time pressure. The flavor of algorithm questions are also different between these firms.</li>
</ul>

<p>Once again, this breakdown is <strong>subjective</strong>. I obviously have a lot of experience interviewing with Silicon Valley companies so the novelty of questions from the finance companies added to the difficulty.</p>



<p>This was the hardest part for me. I spent two weeks suffering from analysis paralysis. I would ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/">https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/</a></em></p>]]>
            </description>
            <link>https://oneraynyday.github.io/misc/2020/09/30/Interviewing-During-Covid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655799</guid>
            <pubDate>Thu, 01 Oct 2020 20:24:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asteroids: By the Numbers]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24655752">thread link</a>) | @rbanffy
<br/>
October 1, 2020 | http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1 | <a href="https://web.archive.org/web/*/http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-3855344372715435262"><p>
By 1979, arcade games were rapidly becoming more complex and colorful, and a game like <i>Asteroids </i>might have seemed quaint by comparison to the likes of <i><a href="http://www.retrogamedeconstructionzone.com/2019/09/galaxian-aesthetics-of-simple-patterns.html">Galaxian</a>, <a href="http://www.retrogamedeconstructionzone.com/2019/09/star-fire-weirdness-of-pseudo-3d.html">Star Fire</a></i>, or <i>Radar Scope.&nbsp; </i>But beneath its simple exterior lies a challenging shooter with surprisingly complex physics.&nbsp; The image below shows a sample still from it, including the player's ship (the triangle on the left), three sizes of asteroids, and an alien ship.</p><p><a href="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s1600/Asteroids_sample%2B%25282%2529.png"><img data-original-height="461" data-original-width="598" height="492" src="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s640/Asteroids_sample%2B%25282%2529.png" width="640"></a></p>

<p>
The goal of the game is to maximize your score, destroying as many asteroids and aliens as possible before you run out of ships.&nbsp; When an asteroid is hit by something (usually the player's bullets), large asteroids turn into two medium ones and medium asteroids turn into two small ones, while small asteroids and aliens are destroyed when hit.</p><p><a href="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s1600/Asteroids%2BPlay.gif"><img data-original-height="357" data-original-width="600" height="237" src="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s400/Asteroids%2BPlay.gif" width="400"></a></p>
<p>
For the designers of the game, balancing the relative sizes of the objects would have been important in such a dense field, because it determines how often things run into one another other.&nbsp; The table below outlines the sizes of the objects in <i>Asteroids</i>, expressed relative to the length of the player's ship.</p><table>
<caption>The approximate horizontal lengths of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Length (in player ship lengths)</th>
    </tr>
<tr>
    <td>Screen</td>
    <td>25 x 36</td>
    </tr>
<tr>
    <td>Large Asteroids</td>
    <td>2.4</td>
    </tr>
<tr>
    <td>Medium Asteroid</td>
    <td>1.2</td>
    </tr>
<tr>
    <td>Small Asteroid</td>
    <td>0.6</td>
    </tr>
<tr>
    <td>Alien Ship (large)</td>
    <td>1.5</td>
    </tr>
<tr>
    <td>Alien Ship (small)</td>
    <td>0.75</td>
    </tr>
</tbody>
    </table>
<p>
Notice how the medium asteroid is twice the size of the small one, and the large is twice the size of the medium.&nbsp; If you think about it, this doesn't actually make much physical sense -- you can break a two-dimensional object into four pieces half its size, not two.&nbsp; But the size ratios do make game sense, because what really matters to the player is not how much area an asteroid takes up, but how likely it is to hit them.</p><p><a href="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"><img data-original-height="281" data-original-width="170" src="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"></a></p>

<p>
In the picture above, you can see that while the four small asteroids take up less area on the screen than the big one, they present the same cross section to your ship.&nbsp; This means that breaking up the asteroids doesn't greatly increase the probability that the player will be struck by one.&nbsp; If the asteroids had been broken up into four half-sized pieces at each blow, each large asteroid would result in sixteen small ones (that's four times the cross section!) and the player would be quickly overwhelmed.&nbsp; Note that the small asteroids do move faster than the large ones, and speed increases the chance of getting hit, but I'll return to that in a moment.</p>

<p>
Another big reason that size matters in <i>Asteroids</i>&nbsp;is that it determines how close something has to be before you're likely to be able to hit it.&nbsp; In 1979, vector arcade cabinet screens had an effective resolution of 1024 x 768, and the player's ship was only connected graphically by about 20 points.&nbsp; This meant, in turn, that there were only a limited number of orientations that they could render for the ship, in this case intervals of 5 degrees.&nbsp; To see how this might affect gameplay, imagine your ship is located at the fixed position shown in the picture below.&nbsp; Anything located entirely between the two solid lines will not be accessible by your bullets because your ship can't turn to the appropriate angle to hit it.&nbsp; This restriction isn't a big deal for large asteroids, which are still accessible over most of the screen, but small asteroids can be out of reach of your guns at relatively close range, sometimes as close as 7 ship lengths away!&nbsp; So even if you aim as accurately as possible, chances are you won't be able to hit a small asteroid on the other side of the screen, at least not on your first shot.&nbsp; This is probably one of the reasons that <i>Asteroids</i>&nbsp;allows you to fire up to four bullets in succession: even if you can't hit an object right away, it will eventually move into your line of fire.</p>

<p><a href="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s1600/Asteroids_hittable%2B%25285%2529.png"><img data-original-height="397" data-original-width="1024" height="248" src="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s640/Asteroids_hittable%2B%25285%2529.png" width="640"></a></p>
<p>
And what about speed?&nbsp; There is some variability in the speeds of individual asteroids, but small asteroids can move as much as 63% faster than large ones (see the table below), meaning that even if four small asteroids present the same cross section for hitting your ship as a large one does, their higher speed means they're more likely to hit you.&nbsp; The reasoning for this is simple: the faster something moves, the longer the path it can traverse in a given amount of time, and the larger the likelihood that you'll be in that path.&nbsp; Fortunately, even the fastest asteroids are much slower than your ship, which can traverse the screen in about two seconds; so if you're skilled enough, you should be able to maneuver around the asteroid field without a problem.</p><table>
<caption>The approximate speeds of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Speed (in ship lengths per second)</th>
    </tr>
<tr>
    <td>Your ship</td>
    <td>0 - 17</td>
    </tr>
<tr>
    <td>Asteroids</td>
    <td>4 - 6.5</td>
    </tr>
<tr>
    <td>Alien ships (both sizes)</td>
    <td>4 - 6.5 (depending on your score)</td>
    </tr>
<tr>
    <td>Bullets</td>
    <td>17 (ship at rest)&nbsp;</td></tr>
</tbody></table>
<p>
One other interesting thing about speed: notice in the table above that the speed of a bullet, when fired at rest, is the same as your ship's maximum speed.&nbsp; This means that when you're moving rapidly and fire a bullet in the opposite direction of your motion, the two speeds should cancel for a stationary observer and the bullet should appear roughly stationary.</p>

<p><a href="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s1600/Asteroids_bullet_stationary.gif"><img data-original-height="175" data-original-width="468" height="239" src="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s640/Asteroids_bullet_stationary.gif" width="640"></a></p>


<div><p>
Sure enough, when I fire a bullet while moving quickly in the opposite direction, it just floats near where I fired it, allowing me to place bullets like mines for the asteroids to run into.</p>
<p>
The developers of <i>Asteroids </i>wanted the game to simulate the real laws of physics (<a href="http://www.technologyuk.net/computing/computer-gaming/gaming-landmarks-1960-1985/asteroids.shtml">see here</a>), and I think in many respects they succeeded, at least compared to most other arcade games of the time.&nbsp; It's not entirely realistic, however.&nbsp; In my article on <a href="http://www.retrogamedeconstructionzone.com/2019/10/impossible-motion-in-video-games.html">motion in early arcade games</a>, I discussed how the acceleration of the ship in <i>Asteroids</i> is too rapid for a human-occupied vehicle.&nbsp; We might suppose that the vehicle is automated, but even then, engineering spacecraft to withstand 30+ g's of acceleration is a non-trivial challenge.</p><p><a href="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s1600/Acceleration%2BAsteroids.gif"><img data-original-height="175" data-original-width="634" height="176" src="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s640/Acceleration%2BAsteroids.gif" width="640"></a></p>
<p>
Another issue is the way the asteroids break up.&nbsp; In physics, there's a principle called the conservation of momentum that says that when objects interact with one another or break apart, the total mass times the velocity must remain the same after the interaction as it was before.&nbsp; In layman's terms, this means that things can't suddenly go from moving one direction to moving in another unless there is something else carry its previous momentum.&nbsp; In the example shown below, an asteroid does just that, and the only thing that could have absorbed its previous momentum is the bullet.&nbsp; But the bullet is so tiny that it's difficult to imagine how that would be possible.</p><p><a href="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s1600/Asteroids_momentum.gif"><img data-original-height="248" data-original-width="533" height="185" src="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s400/Asteroids_momentum.gif" width="400"></a></p>

<p>
These are mere quibbles, however, and shouldn't dissuade you from giving the game a try.&nbsp; <i>Asteroids </i>ended up being one of Atari's biggest arcade hits, selling over 70,000 cabinets, and remains one of their most recognizable games to this day.&nbsp; Many gamers who grew up in the '80s, myself included, are more familiar with the Atari 2600 version of the game.&nbsp; Unfortunately, the designers had to make a lot of sacrifices in game physics in order to make it work on a home console, so I think the arcade version is really the way to go.&nbsp; Outside of visiting a vintage arcade, your best bet is probably the <a href="https://www.mamedev.org/">Multiple Arcade Machine Emulator</a> (MAME).&nbsp; Happy hunting!</p></div><div><p><span>NOTE: &nbsp;A previous version of this article stated that the game has limited pixel resolution, but <i>Asteroids </i>uses a vector display that is not composed of pixels. &nbsp;The resolution of the <i>Asteroids </i>vector display is 1024 x 768.</span></p><p><a href="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s1600/Asteroids_loop_transparent.gif"><img data-original-height="151" data-original-width="600" height="160" src="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s640/Asteroids_loop_transparent.gif" width="640"></a></p>
<br></div>
</div>
</div></div>]]>
            </description>
            <link>http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655752</guid>
            <pubDate>Thu, 01 Oct 2020 20:19:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use the internet, not just companies (2018)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24655745">thread link</a>) | @downshun
<br/>
October 1, 2020 | https://sive.rs/netskill | <a href="https://web.archive.org/web/*/https://sive.rs/netskill">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<article>
<header>


<small>2018-02-12</small>
</header>

<p>
	I‚Äôve been online since 1994, and seen so many companies come and go.
</p><p>
	In the year 2000, the place to be was mp3.com.
	Every musician would keep all of their music and fans there.
	A few years later, it was gone ‚Äî shut down ‚Äî all music and fan lists deleted.
</p><p>
	In 2005, it was MySpace.
	Again, musicians kept all of their music, photos, and fans there.
	A few years later, it was gone.
	Not shut down, but basically moot.
	There was no way to communicate with all of those people, because you didn‚Äôt have their direct contact info ‚Äî you only had their MySpace inbox, which nobody checked anymore.
</p><p>
	As I‚Äôm writing this now in 2018, it‚Äôs Facebook, YouTube, and Spotify.
	Just like with mp3.com and MySpace, people act like these websites are everything, and keep all of their music, photos, and fans there.
	By the time you read this, they might be gone.
</p><p>
<strong>
	Don‚Äôt depend on a company.
	They come and go.
</strong>
	Think long-term.
	You‚Äôre going to be creating stuff, making fans, and building relationships for the rest of your life ‚Äî much longer than these companies will last.
</p><p>
<strong>
	So have your own website.
</strong>
	Instead of sending your fans to some company‚Äôs site, send them to yours.
	Get everyone‚Äôs direct contact information so you don‚Äôt have to go through a company to reach them.
</p><p>
<strong>
	Your website should be the definitive place to get everything you create.
</strong>
	If you put your stuff on some company‚Äôs site, have it be secondary ‚Äî a copy of the stuff that‚Äôs already on your site.
	That way you can use the popular networks without depending on them.
</p><p>
	Only rely on open standards that aren‚Äôt owned by any company ‚Äî like email and the web.
</p>
<h3>
	Email skills:
</h3>
<p>
	Go into your email settings, and make sure you <strong>have a signature</strong>.
	You need this because you‚Äôre going to be emailing people who have no idea who or where you are!
	Give them some context.
	Your signature should say who, what, and where, with a URL or two.
	For example:
</p>
<pre>--
Maya Danub√©, fragrant jazz bass clarinet, New York City
http://mayadanube.com  <a href="https://sive.rs/cdn-cgi/l/email-protection" data-cfemail="adc0c8edc0ccd4ccc9ccc3d8cfc883cec2c0">[email&nbsp;protected]</a>  (917)611-5310
Watch &amp; listen: https://www.youtube.com/user/mayadanube
Friend me, baby: https://www.facebook.com/mayadanube
</pre>
<p>
	When you email people, write a <strong>descriptive subject</strong>.
	Never ‚Äúhey‚Äù or ‚Äúbooking‚Äù.
	Try ‚ÄúAvailable June 6 for showcase?‚Äù or ‚Äúintroduction to photographer‚Äù.
	This is considerate.
	Now when your email is one of hundreds in an inbox, it will say exactly what is contained inside.
</p><p>
	Make it <strong>as short as possible</strong>.
	The shorter your email, the more likely it will get a response.
	Be direct.
	Five sentences is ideal.
	If your email is too long, they are likely to procrastinate, and never get back to it.
</p><p>
	Use short paragraphs.
	Leave plenty of space.
	Reading a screen is different from reading a book.
</p>
<h3>
	Web skills:
</h3>
<p>
<strong>
	Know how to update your website.
</strong>
	Don‚Äôt depend on someone else to do this for you.
	Know how to add new songs or videos, and how to make any changes.
</p><p>
<strong>
	Know your URLs.
</strong>
	Telling someone to go search for you is like telling them to look up your phone number.
	Instead, know your exact URLs (yoursite.com, twitter.com/something, facebook.com/whatever) so you can give it to people directly.
	If you don‚Äôt, they‚Äôll probably never bother to go search for you.
</p><p>
<strong>
	Know how to make an MP3.
</strong>
	Give it a good filename like YOUR_NAME-Song_Title.mp3 (not mix7.mp3)
	Don‚Äôt use spaces in the filename.
	Edit the ID3 tags to put your full name and URL in the info, so whoever has this MP3 knows who it is and how to find you.
</p><p>
	Sorry if these sound too basic to you.
	But you‚Äôd be surprised by how many people don‚Äôt know these skills, and so are silently handicapped when interacting with the world.
</p>
<img alt="" src="https://sive.rs/images/internet-skills.gif">


</article>



</div></div>]]>
            </description>
            <link>https://sive.rs/netskill</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655745</guid>
            <pubDate>Thu, 01 Oct 2020 20:18:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why plain text emails perform better than HTML designed ones]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24655493">thread link</a>) | @pau_alcala
<br/>
October 1, 2020 | https://blog.palabra.io/plain-text-engagement | <a href="https://web.archive.org/web/*/https://blog.palabra.io/plain-text-engagement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><em>By <a href="https://www.linkedin.com/in/naara-abril-taker/">Abril Taker</a> - Content Creator at <a href="https://www.palabra.io/?utm_medium=plain-text&amp;utm_source=blog">Palabra</a></em></p><p>Plain text sounds boring? Well, let me tell you that plain text is more important than you can imagine. At <a href="https://www.palabra.io/?utm_medium=plain-text&amp;utm_source=blog">Palabra</a> we love plain text to send every email, specially our onboarding sequences. And in this article we‚Äôll share why we think you should start using it too.</p><h2>Isn‚Äôt plain text for grannies?üëµüèº</h2><p>Plain text has been around since the beginnings of the Internet. So it is understandable that some people think it is obsolete. Maybe there was a time where HTML emails were on a boom, but plain text today is more functional than ever.</p><p>Before we continue we‚Äôd like all of us to be in the same page about what plain text is:</p><p>The term Plain text, when we talk about an email, refers to the composition that consists of the copy within the style. Which means that it does not include complex formatting or styled fonts. Although it can have images and links.</p><p>Even if plain text could sound boring at first compared with HTML emails, you will discover that their use can bring many benefits in general, and especially for onboarding sequences.</p><h2>Use plain text for onboarding sequences üèÜ</h2><p>When you have a service or a product that depends, on a large portion, of having a constant flow of users, you might want to apply an onboarding sequence in order to avoid the churn rate and to connect with your community.</p><p>If you‚Äôre still in the early stage of your strategy, we recommend to read our article about <strong><a href="https://blog.palabra.io/questions-onboarding">5 questions to ask yourself before creating an onboarding email sequence</a></strong>, it will guide you in the process.</p><p>Over the years, new technologies have risen in the field of user experience. We now have many tools to call the attention of customers. This means people are getting a bunch of emails that now look like ads delivered right to your inbox.</p><p>Onboarding should look nothing like ads. That's when you start a close relationship with early users, you educate them about how to use your product better, and open communication channels.</p><h2>5 reasons why plain text is always a good idea</h2><h3>üì© It ensures deliverability</h3><p>The number one thing that you need to do to engage with someone is to get their attention. And for that, you need to get them to open your emails.</p><p>As we said before, HTML emails have images, links, GIFs, all sorts of things that attract the attention of email filters. So they‚Äôre more susceptible to being redirected to the spam folder if they have broken links or suspicious behaviours.</p><p>Since plain text emails don‚Äôt contain much more information than text, it‚Äôs much more likely that they will not alert spam filters.</p><p>Also, plain text emails seem more ‚Äúreal‚Äù to your email filters. And that's also handy for your readers!</p><h3>üìú It feels more personal</h3><p>Once your customers open your emails, you don‚Äôt want them to say ‚Äúugh, another stupid corporative email. DELETE‚Äù. That‚Äôs probably the worst case scenario.</p><p>Plain text has been proved to have higher click-through rates. Not just because they can pass spam filters, but also because they feel more personal. They look like something a real person sends, to offer information instead of driving sales.</p><p>Then, when you receive a plain text email, it is more associated with a regular person, someone who just wants to talk and know about you as an individual (and not as a target). Your users can perceive you more relatable, human and trust-worthy ‚ú®.</p><h3>üó£Ô∏è Starts 1-1 conversations</h3><p>As you can see, there‚Äôs a progression. And with plain text you help your emails to be delivered and opened. Do you know what is even better? If your users answer the email!</p><p>We like plain text precisely because of this. Through this kind of emails, we‚Äôve received feedback from our users that was very valuable for us to grow as a company and as a team. They respond because there's a real email address from a real person to answer to.</p><p>We send onboarding emails that appeal to conversation. Having a dialog is the fuel to power the relationship with the users. We try to build a space where the user can feel part of the process and can say something to improve the use of a tool that is so necessary in his life.</p><h3>üë©üèº‚Äçü¶Ω Is more accessible</h3><p>Now we want to highlight something that usually goes unnoticed. Plain text is readable for accessibility systems. This kind of emails has an ethical benefit, because they‚Äôre reachable for people with different needs.</p><p>When you send an HTML email, you‚Äôre making it more difficult for a blind person, for example, to understand your message.</p><p>At this point, it is good to ask ourselves if our emails can be accessed by a blind person using a screen reader.</p><h3>üîÆ Adapts to new technology</h3><p>From the previous point it follows the fact that plain text is more readable. I personally was surprised to discover that you can read your emails in smartwatches and smart assisters,or that you can obtain a more comprehensible preview of the content.</p><p>I know, it is super obvious when you think about it. But we do not always have in mind that there are other kinds of displays where people read their emails or notifications. And that we have to be ahead of the new possibilities, because we don‚Äôt know what type of devices will be developed in the future.</p><p>In this case, keeping it simple will ensure you that people can read your messages.</p><p>So, now you know, don‚Äôt be shy and start sending those emails and talking to your users. You may be pleasantly surprised with what you discover.</p><hr><p>Hope you enjoyed this post! If you are curious about what you can do with Palabra or would just like to try it go ahead and <a href="https://www.palabra.io/?utm_medium=plain-text&amp;utm_source=blog">create an account here</a>.</p></section></div>]]>
            </description>
            <link>https://blog.palabra.io/plain-text-engagement</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655493</guid>
            <pubDate>Thu, 01 Oct 2020 19:54:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Next-Gen Rust Web Apps]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654891">thread link</a>) | @yannikyeo
<br/>
October 1, 2020 | https://blog.shortepic.com/blog/first/ | <a href="https://web.archive.org/web/*/https://blog.shortepic.com/blog/first/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>This is an homage to this absolute <a href="http://www.sheshbabu.com/posts/rust-wasm-yew-single-page-application/">work of art</a> by Shesh Babu.</p>

<p>Rust's strong typing and fearless concurrency means we can skip virtual DOM differencing. </p>
<p>In the JavaScript world, avoiding the vDOM is the bread and butter of <a href="https://svelte.dev/">Svelte</a> 
started by Rich Harris, which uses compile-time code generation to assist.</p>
<p>When I can't have static typing I love Clojure, and have spent some time reviewing and 
playing with the stupendous full-stack Clojure SPA framework <a href="http://book.fulcrologic.com/">Fulcro</a> 
by Tony Kay (and associated back-end enabler <a href="https://blog.wsscode.com/pathom/">Pathom</a> 
by Wilker Lucio). It does use vDOM, leveraging Clojure immutable/concurrent data structures 
for time travel superpowers.</p>
<p>For me, the major innovation (among many) in Fulcro is the use of a browser-side normalised database 
which is queried to populate properties for components. This means that updating (<em>mutating</em>) 
a uniquely-keyed item results in the update trivially propagating to any and all components 
referencing the data through that identifier. In Shesh Babu's language: all state is App state.</p>
<p>This article, or series of articles, is going to share my findings and thinking on the 
state of the nation in Rust front-end frameworks which are avoiding the vDOM strategy.</p>
<p>There are actually two Rust front-end frameworks with significant progress already, and they are 
awesome:</p>
<ul>
<li><a href="https://crates.io/crates/mogwai">mogwai</a> by Schell Scivally</li>
<li><a href="https://crates.io/crates/valerie">valerie</a> by Emmanuel Antony</li>
</ul>

<p>The official React site offers a <a href="https://reactjs.org/tutorial/tutorial.html">guided introduction</a> 
by progressively implementing a client-side tic-tac-toe game (also known as <em>noughts and crosses</em>). 
They don't explore a back-end, routing or forms, or many of the other SPA complexities. </p>
<p>For us, it is just enough to highlight the potential of the two Rust frameworks above and paint 
a picture of how those advanced extensions can be easily incorporated, and gives us a solid 
reference point from the old world.</p>

<p>This is the first in a series of articles showing how the two frameworks might attack the example 
application, and then show some code which extends the frameworks to incorporate Fulcro-like app 
state.</p>
<p>My code will concentrate on the ergonomics of the frameworks from the perspective of the SPA-writer.</p>
<p>Next up, I'll show an implementation of the game in Valerie.</p>
<p><a href="https://blog.shortepic.com/blog/second/">On to the first code sample</a>.</p>

  </article></div>]]>
            </description>
            <link>https://blog.shortepic.com/blog/first/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654891</guid>
            <pubDate>Thu, 01 Oct 2020 19:02:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Incarceration in Real Numbers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654820">thread link</a>) | @tmsh
<br/>
October 1, 2020 | https://mkorostoff.github.io/incarceration-in-real-numbers/ | <a href="https://web.archive.org/web/*/https://mkorostoff.github.io/incarceration-in-real-numbers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div id="prisoners">
    
    
    
    

    <div>
      <p>The United States holds more people in jails and prisons than any other country by far, both in absolute numbers and as a percentage of population.</p>
    </div>

    <div id="per-one-hundred">
      <div id="per-one-hundred-inner">
        <h2>Incarcerated per 100,000 residents <sup>[<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#incarceration-rates" target="_blank"></a>]</sup></h2>
        <p><span>USA (698)</span></p>
        <p><span>El Salvador (590)</span></p>
        <p><span>Turkmenistan (552)</span></p>
        <p><span>Thailand (531)</span></p>
        <p><span>Rwanda (511)</span></p>
        <p><span>Cuba (510)</span></p>
        <p><span>Panama (401)</span></p>
        <p><span>Costa Rica (374)</span></p>
        <p><span>Cayman Islands (365)</span></p>
        <p><span>Russia (363)</span></p>
        <p><span>Belize (356)</span></p>
        <p><span>Brazil (348)</span></p>
        <p><span>Belarus (343)</span></p>
        <p><span>Nicaragua (332)</span></p>
        <p><span>Turkey (324)</span></p>
        <p><span>Puerto Rico (313)</span></p>
        <p><span>Brunei Darussalam (307)</span></p>
        <p><span>Cape Verde (296)</span></p>
        <p><span>Uruguay (295)</span></p>
        <p><span>Namibia (295)</span></p>
        <p><span>Iran (294)</span></p>
        <p><span>Trinidad and Tobago (292)</span></p>
        <p><span>Guyana (284)</span></p>
        <p><span>Peru (278)</span></p>
        <p><span>South Africa (275)</span></p>
        <p><span>Georgia (262)</span></p>
        <p><span>Taiwan (258)</span></p>
        <p><span>Swaziland (258)</span></p>
        <p><span>Greenland (249)</span></p>
        <p><span>Colombia (246)</span></p>
        <p><span>French Guiana (243)</span></p>
        <p><span>Gabon (241)</span></p>
        <p><span>Morocco (237)</span></p>
        <p><span>Dominican Republic (237)</span></p>
        <p><span>Cura√É¬ßao (236)</span></p>
        <p><span>Azerbaijan (235)</span></p>
        <p><span>Israel (234)</span></p>
        <p><span>Bahrain (234)</span></p>
        <p><span>Ecuador (233)</span></p>
        <p><span>Macau (233)</span></p>
        <p><span>Chile (232)</span></p>
        <p><span>Argentina (230)</span></p>
        <p><span>Malaysia (230)</span></p>
        <p><span>Honduras (229)</span></p>
        <p><span>Lithuania (221)</span></p>
        <p><span>Cambodia (220)</span></p>
        <p><span>Martinique (215)</span></p>
        <p><span>Fiji (210)</span></p>
        <p><span>Botswana (208)</span></p>
        <p><span>Mauritius (203)</span></p>
        <p><span>New Zealand (201)</span></p>
        <p><span>Paraguay (199)</span></p>
        <p><span>Singapore (199)</span></p>
        <p><span>Jordan (198)</span></p>
        <p><span>Saudi Arabia (197)</span></p>
        <p><span>Czech Republic (197)</span></p>
        <p><span>Poland (195)</span></p>
        <p><span>Tunisia (195)</span></p>
        <p><span>Slovakia (195)</span></p>
        <p><span>Moldova (194)</span></p>
        <p><span>New Caledonia (189)</span></p>
        <p><span>Estonia (187)</span></p>
        <p><span>Latvia (183)</span></p>
        <p><span>Montenegro (183)</span></p>
        <p><span>Suriname (183)</span></p>
        <p><span>Philippines (179)</span></p>
        <p><span>Venezuela (178)</span></p>
        <p><span>Albania (177)</span></p>
        <p><span>Hungary (173)</span></p>
        <p><span>Myanmar (171)</span></p>
        <p><span>Australia (170)</span></p>
        <p><span>Mexico (163)</span></p>
        <p><span>Kyrgyzstan (161)</span></p>
        <p><span>Bolivia (158)</span></p>
        <p><span>Kazakhstan (156)</span></p>
        <p><span>Serbia (156)</span></p>
        <p><span>Algeria (151)</span></p>
        <p><span>Uzbekistan (150)</span></p>
        <p><span>Scotland (149)</span></p>
        <p><span>Ukraine (148)</span></p>
        <p><span>Bhutan (145)</span></p>
        <p><span>Lebanon (144)</span></p>
        <p><span>Guatemala (143)</span></p>
        <p><span>England &amp; Wales (140)</span></p>
        <p><span>Nauru (140)</span></p>
        <p><span>Libya (139)</span></p>
        <p><span>Jamaica (138)</span></p>
        <p><span>Malta (131)</span></p>
        <p><span>Laos (130)</span></p>
        <p><span>Vietnam (128)</span></p>
        <p><span>Ethiopia (127)</span></p>
        <p><span>Micronesia (127)</span></p>
        <p><span>Guernsey (127)</span></p>
        <p><span>Iraq (126)</span></p>
        <p><span>Portugal (125)</span></p>
        <p><span>Bulgaria (125)</span></p>
        <p><span>Isle of Man (125)</span></p>
        <p><span>Spain (124)</span></p>
        <p><span>Uganda (124)</span></p>
        <p><span>Cameroon (124)</span></p>
        <p><span>Zambia (123)</span></p>
        <p><span>Tajikistan (121)</span></p>
        <p><span>China (120)</span></p>
        <p><span>Kuwait (117)</span></p>
        <p><span>Egypt (116)</span></p>
        <p><span>Zimbabwe (114)</span></p>
        <p><span>North Macedonia (112)</span></p>
        <p><span>Mongolia (110)</span></p>
        <p><span>Canada (107)</span></p>
        <p><span>Romania (107)</span></p>
        <p><span>Hong Kong (106)</span></p>
        <p><span>France (105)</span></p>
        <p><span>Sri Lanka (105)</span></p>
        <p><span>Luxembourg (105)</span></p>
        <p><span>UAE (104)</span></p>
        <p><span>Kenya (102)</span></p>
        <p><span>Italy (101)</span></p>
        <p><span>Indonesia (99)</span></p>
        <p><span>Austria (98)</span></p>
        <p><span>Belgium (95)</span></p>
        <p><span>Greece (95)</span></p>
        <p><span>Kosovo (95)</span></p>
        <p><span>Madagascar (93)</span></p>
        <p><span>Angola (93)</span></p>
        <p><span>Lesotho (92)</span></p>
        <p><span>Afghanistan (87)</span></p>
        <p><span>Cyprus (86)</span></p>
        <p><span>Burundi  (85)</span></p>
        <p><span>Monaco (83)</span></p>
        <p><span>Cote d'Ivoire  (82)</span></p>
        <p><span>Switzerland  (81)</span></p>
        <p><span>Haiti  (80)</span></p>
        <p><span>Croatia  (79)</span></p>
        <p><span>Ireland (79)</span></p>
        <p><span>Nepal  (79)</span></p>
        <p><span>Northern Ireland (78)</span></p>
        <p><span>Germany  (77)</span></p>
        <p><span>Armenia  (76)</span></p>
        <p><span>Malawi (76)</span></p>
        <p><span>Slovenia (69)</span></p>
        <p><span>Benin  (68)</span></p>
        <p><span>Senegal  (68)</span></p>
        <p><span>Djibouti (66)</span></p>
        <p><span>Togo (66)</span></p>
        <p><span>Andorra  (64)</span></p>
        <p><span>Denmark  (63)</span></p>
        <p><span>Equatorial Guinea  (63)</span></p>
        <p><span>Mozambique (63)</span></p>
        <p><span>Papua New Guinea (62)</span></p>
        <p><span>Sweden (61)</span></p>
        <p><span>Netherlands  (61)</span></p>
        <p><span>Norway (60)</span></p>
        <p><span>Sierra Leone (60)</span></p>
        <p><span>Syria  (60)</span></p>
        <p><span>Chad (59)</span></p>
        <p><span>Tanzania (59)</span></p>
        <p><span>Finland  (53)</span></p>
        <p><span>Mauritania (53)</span></p>
        <p><span>Qatar  (53)</span></p>
        <p><span>Yemen  (53)</span></p>
        <p><span>Bangladesh (52)</span></p>
        <p><span>Ghana  (52)</span></p>
        <p><span>Sudan  (52)</span></p>
        <p><span>Timor-Leste (52)</span></p>
        <p><span>Liberia  (50)</span></p>
        <p><span>South Sudan  (50)</span></p>
        <p><span>Niger  (44)</span></p>
        <p><span>Burkina Faso (39)</span></p>
        <p><span>Japan  (39)</span></p>
        <p><span>Pakistan (38)</span></p>
        <p><span>Iceland  (37)</span></p>
        <p><span>Nigeria  (36)</span></p>
        <p><span>Oman (36)</span></p>
        <p><span>India  (34)</span></p>
        <p><span>Mali (33)</span></p>
        <p><span>Gambia (31)</span></p>
        <p><span>Liechtenstein  (31)</span></p>
        <p><span>Democratic Republic of Congo (29)</span></p>
        <p><span>Guinea (28)</span></p>
        <p><span>Congo (27)</span></p>
        <p><span>Central African Republic (16)</span></p>
        <p><span>Guinea Bissau  (10)</span></p>
        <p><span>San Marino (6)</span></p>
      <p><a onclick="toggleExpand('per-one-hundred', 'per-one-hundred-inner')">Expand ‚ñº</a>
      </p></div>
    </div>

    <div id="country-rank">
      <div id="country-rank-inner">
        <h2>Number of people incarcerated <sup>[<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#incarceration-rates" target="_blank"></a>]</sup></h2>
        <p>USA (2.3M)</p>
        <p><span>China (1.7M)</span></p>
        <p><span>Brazil (747K)</span></p>
        <p><span>Russian Federation (524K)</span></p>
        <p><span>India (466K)</span></p>
        <p><span>Thailand (368K)</span></p>
        <p><span>Indonesia (267K)</span></p>
        <p><span>Turkey (265K)</span></p>
        <p><span>Iran (240K)</span></p>
        <p><span>Philippines (215K)</span></p>
        <p><span>Mexico (203K)</span></p>
        <p><span>South Africa (163K)</span></p>
        <p><span>Vietnam (124K)</span></p>
        <p><span>Colombia (123K)</span></p>
        <p><span>Ethiopia (114K)</span></p>
        <p><span>Egypt (106K)</span></p>
        <p><span>Argentina (103K)</span></p>
        <p><span>Myanmar  (92K)</span></p>
        <p><span>Peru (91K)</span></p>
        <p><span>Bangladesh (88K)</span></p>
        <p><span>Morocco (86K)</span></p>
        <p><span>United Kingdom: England &amp; Wales (83K)</span></p>
        <p><span>Pakistan (77K)</span></p>
        <p><span>Poland (74K)</span></p>
        <p><span>Malaysia (74K)</span></p>
        <p><span>Nigeria (73K)</span></p>
        <p><span>France (71K)</span></p>
        <p><span>Rwanda (65K)</span></p>
        <p><span>Germany (64K)</span></p>
        <p><span>Algeria (63K)</span></p>
        <p><span>Saudi Arabia (61K)</span></p>
        <p><span>Taiwan (61K)</span></p>
        <p><span>Italy (61K)</span></p>
        <p><span>Spain (58K)</span></p>
        <p><span>Cuba (57K)</span></p>
        <p><span>Venezuela (57K)</span></p>
        <p><span>Uganda (55K)</span></p>
        <p><span>Republic of  (55K)</span></p>
        <p><span>Ukraine (53K)</span></p>
        <p><span>Kenya (51K)</span></p>
        <p><span>Japan (49K)</span></p>
        <p><span>Iraq (45K)</span></p>
        <p><span>Uzbekistan (44K)</span></p>
        <p><span>Australia (43K)</span></p>
        <p><span>Chile (43K)</span></p>
        <p><span>Ecuador (40K)</span></p>
        <p><span>Canada (40K)</span></p>
        <p><span>El Salvador (38K)</span></p>
        <p><span>Cambodia (37K)</span></p>
        <p><span>Tanzania (36K)</span></p>
        <p><span>Belarus (33K)</span></p>
        <p><span>Afghanistan (31K)</span></p>
        <p><span>Cameroon (31K)</span></p>
        <p><span>Turkmenistan (30K)</span></p>
        <p><span>Kazakhstan (29K)</span></p>
        <p><span>Dominican Republic (26K)</span></p>
        <p><span>Guatemala (25K)</span></p>
        <p><span>Madagascar (25K)</span></p>
        <p><span>Angola (24K)</span></p>
        <p><span>Nepal (24K)</span></p>
        <p><span>Sri Lanka (23K)</span></p>
        <p><span>Azerbaijan (23K)</span></p>
        <p><span>Zambia (23K)</span></p>
        <p><span>Tunisia (23K)</span></p>
        <p><span>Cote d'Ivoire (21K)</span></p>
        <p><span>Czech Republic (21K)</span></p>
        <p><span>Sudan (21K)</span></p>
        <p><span>Nicaragua (21K)</span></p>
        <p><span>Romania (21K)</span></p>
        <p><span>Democratic Republic of Congo (21K)</span></p>
        <p><span>Honduras (21K)</span></p>
        <p><span>Jordan (20K)</span></p>
        <p><span>Mozambique (20K)</span></p>
        <p><span>Zimbabwe (19K)</span></p>
        <p><span>Israel (19K)</span></p>
        <p><span>Costa Rica (19K)</span></p>
        <p><span>Bolivia (18K)</span></p>
        <p><span>Panama (17K)</span></p>
        <p><span>Hungary (17K)</span></p>
        <p><span>Ghana (15K)</span></p>
        <p><span>Malawi (15K)</span></p>
        <p><span>Yemen (14K)</span></p>
        <p><span>Paraguay (14K)</span></p>
        <p><span>Portugal (13K)</span></p>
        <p><span>Singapore (12K)</span></p>
        <p><span>Senegal (12K)</span></p>
        <p><span>Belgium (11K)</span></p>
        <p><span>Serbia (11K)</span></p>
        <p><span>Burundi (11K)</span></p>
        <p><span>Slovakia (11K)</span></p>
        <p><span>Syria (11K)</span></p>
        <p><span>Puerto Rico  (10K)</span></p>
        <p><span>Netherlands (10K)</span></p>
        <p><span>Uruguay (10K)</span></p>
        <p><span>Greece (10K)</span></p>
        <p><span>Kyrgyzstan (10K)</span></p>
        <p><span>New Zealand (10K)</span></p>
        <p><span>United Arab Emirates (10K)</span></p>
        <p><span>Georgia (10K)</span></p>
        <p><span>Niger (10K)</span></p>
        <p><span>Tajikistan (9K)</span></p>
        <p><span>Libya (9K)</span></p>
        <p><span>Bulgaria (9K)</span></p>
        <p><span>Laos (9K)</span></p>
        <p><span>Haiti (9K)</span></p>
        <p><span>Chad (9K)</span></p>
        <p><span>Austria (9K)</span></p>
        <p><span>United Kingdom: Scotland (8K)</span></p>
        <p><span>Hong Kong  (8K)</span></p>
        <p><span>Benin (8K)</span></p>
        <p><span>Burkina Faso (8K)</span></p>
        <p><span>Namibia (7K)</span></p>
        <p><span>South Sudan (7K)</span></p>
        <p><span>Lebanon (7K)</span></p>
        <p><span>Switzerland (7K)</span></p>
        <p><span>Moldova  (7K)</span></p>
        <p><span>Sweden (6K)</span></p>
        <p><span>Lithuania (6K)</span></p>
        <p><span>Mali (5K)</span></p>
        <p><span>Togo (5K)</span></p>
        <p><span>Papua New Guinea (5K)</span></p>
        <p><span>Albania (5K)</span></p>
        <p><span>Sierra Leone (5K)</span></p>
        <p><span>Kuwait (5K)</span></p>
        <p><span>Gabon (4K)</span></p>
        <p><span>Botswana (4K)</span></p>
        <p><span>Trinidad and Tobago (4K)</span></p>
        <p><span>Ireland, Republic of (4K)</span></p>
        <p><span>Jamaica (4K)</span></p>
        <p><span>Guinea  (4K)</span></p>
        <p><span>Denmark (4K)</span></p>
        <p><span>Latvia (4K)</span></p>
        <p><span>Bahrain (3K)</span></p>
        <p><span>Swaziland/eSwatini (3K)</span></p>
        <p><span>Mongolia (3K)</span></p>
        <p><span>Croatia (3K)</span></p>
        <p><span>Norway (3K)</span></p>
        <p><span>Finland (3K)</span></p>
        <p><span>Mauritius (3K)</span></p>
        <p><span>Estonia (2K)</span></p>
        <p><span>Liberia (2K)</span></p>
        <p><span>North Macedonia (2K)</span></p>
        <p><span>Mauritania (2K)</span></p>
        <p><span>Armenia (2K)</span></p>
        <p><span>Guyana (2K)</span></p>
        <p><span>Lesotho (2K)</span></p>
        <p><span>Fiji (2K)</span></p>
        <p><span>Maldives (2K)</span></p>
        <p><span>Bahamas (2K)</span></p>
        <p><span>Bosnia and Herzegovina: Federation (2K)</span></p>
        <p><span>Kosovo/Kosova (2K)</span></p>
        <p><span>Macau  (2K)</span></p>
        <p><span>Cape Verde  (2K)</span></p>
        <p><span>United Kingdom: Northern Ireland (1K)</span></p>
        <p><span>Slovenia (1K)</span></p>
        <p><span>Brunei Darussalam (1K)</span></p>
        <p><span>Oman (1K)</span></p>
        <p><span>Belize (1K)</span></p>
        <p><span>Congo  (1K)</span></p>
      <p><a onclick="toggleExpand('country-rank', 'country-rank-inner')">Expand ‚ñº</a>
      </p></div>
    </div>

    <div>
      <p>There are more incarcerated people than members of almost any profession. There are more incarcerated people than military personnel. There are more incarcerated people than bus drivers, bar tenders, and hair dressers combined. [<a target="_blank" href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#incarceration-compared-to-professions"></a>]</p>
    </div>

    <div>
      <p>
        More Americans are incarcerated today than there have been Americans killed in all of the wars in all of history combined.
      </p>
    </div>

    <div id="casualties">
      <div>
        <h2>Incarceration compared to casualties of war <sup>[<a target="_blank" href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#american-war-dead"></a>]</sup></h2>
        <p>Americans currently incarcerated (2.3M)</p>
        <p>American war dead, all of history combined (1.3M)</p>
        <p>American war wounded, all of history combined (1.5M)</p>
      </div>
    </div>

    <div>
      <p>While the incarcerated population is unfathomably large, it is just the tip of the iceberg.</p>
    </div>

    <div id="correctional-population">
      <div>
        <h2>The total correctional population <sup>[<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#total-correctional-population" target="_blank"></a>]</sup></h2>
        <div>

          <div>
            <p>Currently incarcerated (2.3M)</p>
          </div>

          <div>
            <p>Will be incarcerated this year (4.9M)</p>
          </div>

          <div>
            <p>Alive currently, will go to prison ever (10.9M)</p>
          </div>

          <div>
            <p>Has a criminal record (77M)</p>
          </div>

          <div>
            <p>Ever had an immediate family member incarcerated (113M)</p>
          </div>

        </div>
      </div>
    </div>

    <div>
      <p>Almost no one gets a trial.</p>
    </div>

    <div>
      <p><img src="https://mkorostoff.github.io/incarceration-in-real-numbers/img/person/blue.svg">Notice that the background icons have changed. The blue icons are the portion of incarcerated people who got trials, around 2%.</p>
    </div>

    <div>
      <p>Almost all accused people are extorted into taking plea bargains under the threat of a longer sentence, the ruinous cost of mounting a defense, and the wildly under-resourced public defender system. [<a href="https://github.com/MKorostoff/incarceration-in-real-numbers/blob/master/SOURCES.md#plea-bargains" target="_blank"></a>]</p>
    </div>

    <div>
      <p>No other country on earth incarcerates so many people without trial. ‚Ä¶</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mkorostoff.github.io/incarceration-in-real-numbers/">https://mkorostoff.github.io/incarceration-in-real-numbers/</a></em></p>]]>
            </description>
            <link>https://mkorostoff.github.io/incarceration-in-real-numbers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654820</guid>
            <pubDate>Thu, 01 Oct 2020 18:57:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hosting a blog on Azure for $2.5 per month]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654536">thread link</a>) | @fleide
<br/>
October 1, 2020 | https://www.eiden.ca/azure-static-blog/ | <a href="https://web.archive.org/web/*/https://www.eiden.ca/azure-static-blog/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
        <p>High level picture of hosting a static site (blog) on Azure with details on how to wire a custom domain (root and www) with HTTPS support. It‚Äôs actually easier that it sounds.</p>

<!--more-->

<p>Let‚Äôs start by noting that $2 out of the $2.5 mentioned in the title are for the custom domain name and associated SSL certificate (for HTTPS). Static content hosting, CDN (<a href="https://en.wikipedia.org/wiki/Content_delivery_network">content delivery network</a>) and networking in Azure cost less than 50 cents per month for this application. To be fair, this is not the most read blog of the Internet.</p>

<p>Also I‚Äôm using <a href="https://jekyllrb.com/">Jekyll</a> for this blog, and it‚Äôs been good to me so far.</p>

<h2 id="summary">Summary</h2>

<p>The main components used are:</p>

<ul>
  <li>From non-Microsoft providers
    <ul>
      <li>a <strong>custom domain name</strong> from a registrar of our choosing (I‚Äôm using <a href="https://www.gandi.net/en-CA">Gandi</a>) - here <code>eiden.ca</code></li>
      <li>a <strong>SSL certificate</strong> to enable HTTPS, I recommend Namecheap (<a href="https://www.namecheap.com/security/ssl-certificates/comodo/positivessl/">PositiveSSL</a>) to procure one. This certificate will need to be generated for the custom domain name we created above (we‚Äôll see how). <strong>THIS IS IF</strong> you want HTTPS for the <strong>root</strong> of the custom domain (<a href="https://eiden.ca/">https://eiden.ca</a>), even if you just want it to redirect to <strong>www</strong>. This was a must have for me, and the reason for the existence of this very article. If you don‚Äôt care about the root, you can use the <a href="https://docs.microsoft.com/en-us/azure/cdn/cdn-custom-ssl?tabs=option-1-default-enable-https-with-a-cdn-managed-certificate">managed certificate included</a> in Azure CDN (which at the time of writing doesn‚Äôt support root).</li>
    </ul>
  </li>
  <li>In Azure
    <ul>
      <li>a <strong>Storage Account</strong> with <a href="https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blob-static-website">static web hosting</a> enabled. That feature allows to serve static content (html, css, javascript, images) directly from a container</li>
      <li>a <strong>Key Vault</strong> to help generate the certificate and store it once issued by the provider</li>
      <li>a <strong>CDN Profile</strong>, to cache the content and optimize performance and cost. The CDN profile loads our content from the storage account, distributes in its worldwide network, and serves to visitors in a scalable fashion automatically</li>
      <li>a <strong>DNS Zone</strong>, to manage the name resolution of our custom domain and point the traffic towards the CDN profile</li>
    </ul>
  </li>
</ul>

<p>On a picture:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png" alt="Schema of the solution, all details will be explained below in this post"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png">figure 1 : Schema of the solution</a></em></p>

<p>Let‚Äôs jump into it.</p>

<h2 id="step-1-and-2--starting-with-the-static-website-and-the-cdn-profile">Step 1 and 2 : Starting with the Static Website and the CDN Profile</h2>

<p>First we will follow the <strong>parts 1 and 2</strong> from this <a href="https://www.wrightfully.com/azure-static-website-custom-domain-https">awesome tutorial</a> from John M. Wright to get the storage account and CDN profile set up. <strong>Let‚Äôs not go further than part 2</strong>, we‚Äôll switch to another guide for the following step.</p>

<p>In part 2, I‚Äôve personally used the <code>Azure CDN from Microsoft</code> and it went great.</p>

<p>At this point, what we should have is this:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step1.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step1.png" alt="Step 1 : a storage account with static hosting and a CDN endpoint"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step1.png">figure 2 : a storage account with static hosting and a CDN endpoint</a></em></p>

<p>We can already see our content online at the following URLs:</p>

<ul>
  <li><code>https://&lt;sa&gt;.web.core.windows.net</code>, directly from the storage account</li>
  <li><code>https://&lt;cdn&gt;.azureedge.net</code>, from the CDN endpoint</li>
</ul>

<p>To be noted that to upload our content to the <code>$web</code> container of the storage account, the best option is to use the <a href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli">Azure CLI</a> or <a href="https://azure.microsoft.com/en-us/features/storage-explorer/">Azure Storage Explorer</a>. I tend to default on PowerShell but here <code>Set-AzStorageBlobContent</code> doesn‚Äôt manage the content-types of the files it uploads.</p>

<p>The syntax in the CLI is straightforward (in a PowerShell host, cmd or bash terminal) :</p>

<pre><code># Here the parameter syntax is PowerShell and I'm already logged in the CLI via az login
$contentLocalPath = "C:\..."
$storageAccountName = "mystorageaccount"
az storage blob upload-batch -s $contentLocalPath -d '$web' --account-name $storageAccountName
</code></pre>

<h2 id="step-3--adding-a-dns-zone">Step 3 : Adding a DNS Zone</h2>

<p>To add the DNS Zone, let‚Äôs switch to the <strong>part 3</strong> of this <a href="https://the.aamodt.family/rune/2020/01/08/tutorial-azure-website.html#step-3-set-up-dns-configuration">exhaustive guide</a> from Rune Aamodt.</p>

<p>Here we will <strong>not only</strong> create a record for the <strong>www subdomain</strong> (type <code>CNAME</code>, alias record set to the CDN endpoint) like in the guide, but also for the <strong>root (apex) domain</strong> (type <code>A</code>, alias record set to the same CDN endpoint).</p>

<p>This is how it should look now (<strong>bold</strong> being the ones we created above):</p>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>TTL</th>
      <th>Value</th>
      <th>Alias resource type</th>
      <th>Alias target</th>
      <th>Comment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>@</strong></td>
      <td><strong>A</strong></td>
      <td>3600</td>
      <td>-</td>
      <td>Azure CDN</td>
      <td>eiden-ca</td>
      <td><strong>Root/apex domain record</strong></td>
    </tr>
    <tr>
      <td>@</td>
      <td>NS</td>
      <td>172800</td>
      <td>ns1-07.azure-dns.com‚Ä¶</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Azure stuff</td>
    </tr>
    <tr>
      <td>@</td>
      <td>SOA</td>
      <td>3600</td>
      <td>Email:‚Ä¶ Host: ns1-07.azure-dns.com‚Ä¶</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Azure stuff</td>
    </tr>
    <tr>
      <td>@</td>
      <td>MX</td>
      <td>3600</td>
      <td>10 spool.mail.gandi.net.,50 fb.mail.gandi.net.</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Gandi stuff, for the email addresses of the domain</td>
    </tr>
    <tr>
      <td>@</td>
      <td>TXT</td>
      <td>3600</td>
      <td>‚Äúv=spf1 include:_mailcust.gandi‚Ä¶</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Gandi stuff, for the email addresses of the domain</td>
    </tr>
    <tr>
      <td>cdnverify</td>
      <td>CNAME</td>
      <td>3600</td>
      <td>cdnverify.eiden-ca.azure‚Ä¶</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Verification record created automatically for alias record sets</td>
    </tr>
    <tr>
      <td>sa</td>
      <td>CNAME</td>
      <td>3600</td>
      <td>external.simpleanalytics.com.</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Record required by the analytics provider I use here</td>
    </tr>
    <tr>
      <td><strong>www</strong></td>
      <td><strong>CNAME</strong></td>
      <td>3600</td>
      <td>-</td>
      <td>Azure CDN</td>
      <td>eiden-ca</td>
      <td><strong>www subdomain record</strong></td>
    </tr>
    <tr>
      <td>cdnverify.www</td>
      <td>CNAME</td>
      <td>3600</td>
      <td>cdnverify.eiden-ca.azure‚Ä¶</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>Verification record created automatically for alias record sets</td>
    </tr>
  </tbody>
</table>

<p>This is where we will have to log in to the admin portal of our Domain Registrar (Gandi for me) to switch our custom domain to use <strong>external nameservers</strong>. We will provide the 4 Azure ones listed in our DNS zone.</p>

<p>This can be a frustrating step since making changes to DNS records can take hours to take effect. Let‚Äôs try and be patient‚Ä¶</p>

<p>On <strong>Gandi</strong> it looks like this:</p>

<p><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3_gandi.jpg" alt="Step 3 : Screenshot of the admin portal in Gandi"></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3_gandi.jpg">figure 3 : updating nameservers in Gandi</a></em></p>

<p>Now that we have the DNS Zone setup, the situation looks like that:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3.png" alt="Step 3 : A DNS Zone is added to the picture, but the CDN profile still needs to be updated"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step3.png">figure 4 : A DNS Zone is added to the picture, but the CDN profile still needs to be updated</a></em></p>

<p>Now let‚Äôs head back to the CDN endpoint to add the custom domains we just created here.</p>

<h2 id="step-4--enabling-https-for-the-cdn-endpoint-custom-domains">Step 4 : Enabling HTTPS for the CDN Endpoint Custom Domains</h2>

<p>We will head back to the first tutorial, but <strong>before let‚Äôs quickly sum up the situation</strong>. As I mentioned in the summary, Azure CDN offers managed certificate for HTTPS, but at the time of writing they are not available for the root / apex domain.</p>

<p>This is why we need to bring our own certificate.</p>

<p>Before heading back into the tutorial, let‚Äôs review the 3 high level steps of that process:</p>

<ol>
  <li>In an Azure Key Vault, we will create a new certificate that will be issued by a <strong>non-integrated</strong> CA (Namecheap). <strong>Contrary</strong> to what‚Äôs in the guide, use <strong>PKCS#12</strong> (even if we don‚Äôt understand the details, it‚Äôs just easier)</li>
  <li>We will then download the CSR (<code>Certificate Signing Request</code>) from Azure Key Vault, upload it to our SSL certificate provider to get processed, get the PKCS#12 file generated there back into Azure Key Vault (<code>merge signed request</code>)</li>
  <li>Back in the CDN Endpoint, we will create the custom domains (root and www), with HTTPS, using our own certificate hosted in Key Vault</li>
</ol>

<p>So let‚Äôs head back to <a href="https://www.wrightfully.com/azure-static-website-custom-domain-https">the tutorial</a> from John for <strong>part 4 and 5</strong> (sorry there‚Äôs no direct links) that explains everything in details.</p>

<h2 id="step-5--adding-cdn-rules">Step 5 : Adding CDN rules</h2>

<p>Finally, we need to add some rules in the CDN Rules engine to sort traffic coming from the root and subdomain on both HTTP and HTTPS. I wanted everything to end on <code>https://www.eiden.ca</code>, but you can adapt the rules below for a different result:</p>

<ul>
  <li>Rule 1 : <code>http://</code> requests need to be redirect to <code>https://www...</code></li>
  <li>Rule 2 : root requests need to be redirected to <code>https://www...</code></li>
</ul>

<p>For that we can get inspiration from the <a href="https://the.aamodt.family/rune/2020/01/08/tutorial-azure-website.html#step-5-enforce-https">step 5</a> of the second guide to get something looking like that:</p>

<p><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step5_rules.jpg" alt="Step 5 : Screenshot of the CDN endpoint rules engine configuration, details below"></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/step5_rules.jpg">figure 5 : Rules to manage traffic across domains and protocols</a></em></p>

<p>The details of these rules:</p>

<ul>
  <li>Rule 1
    <ul>
      <li>Name : <strong>http2https</strong></li>
      <li>If Request <strong>protocol</strong>
        <ul>
          <li>Operator : <code>Equals</code></li>
          <li>Request URL : <code>HTTP</code></li>
        </ul>
      </li>
      <li>Then URL redirect
        <ul>
          <li>Type : <code>Moved (301)</code></li>
          <li>Protocol : <code>HTTPS</code></li>
          <li>Hostname : <code>www.eiden.ca</code></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Rule 2
    <ul>
      <li>Name : <strong>root2www</strong></li>
      <li>If Request <strong>URL</strong>
        <ul>
          <li>Operator : <code>Begins with</code></li>
          <li>Request URL : <code>https://eiden.ca</code></li>
          <li>Case transform : <code>To lowercase</code></li>
        </ul>
      </li>
      <li>Then URL redirect
        <ul>
          <li>Type : <code>Moved (301)</code></li>
          <li>Protocol : <code>HTTPS</code></li>
          <li>Hostname : <code>www.eiden.ca</code></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>The picture is now complete:</p>

<p><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png"><img src="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png" alt="Schema of the solution, everything has been explained above"></a></p>

<p><em><a href="https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202009_azure_static_blog/overall_schema.png">figure 6 : The whole thing wired up together</a></em></p>

<h2 id="step-6--flushing-the-cdn-profile">Step 6 : Flushing the CDN profile</h2>

<p>As discussed earlier, the CDN caches our files to serve them in an optimal fashion. Like any cache, it will need to be expired and reloaded when new content is uploaded to the storage account. This is not done automatically.</p>

<p>In the Azure CDN world, this operation is called a <strong>purge</strong>. It can be done in <a href="https://docs.microsoft.com/en-us/azure/cdn/cdn-purge-endpoint">the Azure portal</a> or via script.</p>

<p>In my case I‚Äôm using the <a href="https://docs.microsoft.com/en-us/powershell/azure/new-azureps-module-az?view=azps-4.7.0">PowerShell Az module</a> (not to be mistaken with the AzureRM module) to do that every time I publish a new article:</p>

<pre><code># Already logged via Connect-AzAccount

$cdnProfileName = "eiden-ca"

Get-AzCdnProfile `
  | Where-Object {$_.Name -eq $cdnProfileName} `
  | Get-AzCdnEndpoint `
  | Unpublish-AzCdnEndpointContent -PurgeContent "/*"

</code></pre>

<h2 id="closing">Closing</h2>

<p>So really, $2.5 per month?</p>

<ul>
  <li><a href="https://www.namecheap.com/security/ssl-certificates/comodo/positivessl/">Namecheap</a> SSL Certificate : $9 per year</li>
  <li><a href="https://www.gandi.net/en-CA">Gandi</a> custom domain (<code>.ca</code>) : $15 per year</li>
  <li>Everything <a href="https://azure.microsoft.com/en-us/free/">Azure</a> : $.5 per month</li>
</ul>

<p><strong>Total : $2.5 per month!</strong></p>

      </article></div>]]>
            </description>
            <link>https://www.eiden.ca/azure-static-blog/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654536</guid>
            <pubDate>Thu, 01 Oct 2020 18:34:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to build an open source business]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654427">thread link</a>) | @mattgreg
<br/>
October 1, 2020 | https://www.ockam.io/learn/blog/zero_ipo/ | <a href="https://web.archive.org/web/*/https://www.ockam.io/learn/blog/zero_ipo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p font-family="body" font-weight="body" font-size="body" color="text">Ockam‚Äôs Zero-to-IPO map is a key strategy input to our tactical short, medium and long-term business planning. It focuses on the one-thing that <em>really</em> matters, at specific points in time. We live our values at Ockam, and as an open source company, we want to share our roadmap.</p><p font-family="body" font-weight="body" font-size="body" color="text">As outlined in the progression below, we‚Äôve plotted a course from stoking awareness to operating an enterprise sales machine.</p><p font-family="body" font-weight="body" font-size="body" color="text"><span>
      <a href="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/dbe83/map.png">
    <span></span>
  </a><a href="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/e3189/map.png" rel="noopener noreferrer" target="_blank"><img src="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/e3189/map.png" alt="Zero to IPO map" title="Zero to IPO map" srcset="https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/a2ead/map.png 259w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/6b9fd/map.png 518w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/e3189/map.png 1035w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/44d59/map.png 1553w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/a6d66/map.png 2070w,https://www.ockam.io/static/6a42376b8825dbf0d0fb048487413853/dbe83/map.png 3652w" sizes="(max-width: 1035px) 100vw, 1035px" loading="lazy"></a>
  
    </span></p><p font-family="body" font-weight="body" font-size="body" color="text">The time scale for our route to IPO is, as you‚Äôd expect, years long. Given that startups plan around funding cycles, let‚Äôs plot funding cycles as waypoints on our course. It can generally be assumed that there is 18-24 months between these waypoints.</p><p font-family="body" font-weight="body" font-size="body" color="text"><span>
      <a href="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/4eef4/funding.png">
    <span></span>
  </a><a href="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/e3189/funding.png" rel="noopener noreferrer" target="_blank"><img src="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/e3189/funding.png" alt="Funding time scale" title="Funding time scale" srcset="https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/a2ead/funding.png 259w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/6b9fd/funding.png 518w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/e3189/funding.png 1035w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/44d59/funding.png 1553w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/a6d66/funding.png 2070w,https://www.ockam.io/static/f9b1d634d67c6a0cf8c599df614453fa/4eef4/funding.png 3660w" sizes="(max-width: 1035px) 100vw, 1035px" loading="lazy"></a>
  
    </span></p><p font-family="body" font-weight="body" font-size="body" color="text">The cloud, edge, and open source landscape continues to evolve - which means that we need to chart our own course into the future. However, Ockam‚Äôs route to IPO also considers the various ways that other companies have run the gauntlet from Zero-to-IPO. I‚Äôve been fortunate to have been ‚Äòin the rooms where it happened‚Äô. Over the past 10 years I‚Äôve directly worked with well over 100 companies that were underpinned by open source software projects. I‚Äôve seen spectacular successes, breathtaking failures, modest acquisitions, and some companies that simply fade into the darkness. I'll save those stories for another time, maybe over a beer.</p><p font-family="body" font-weight="body" font-size="body" color="text">In the image below are experiences that I‚Äôve drawn from the previous decade in the open source, cloud, and developer tool space.</p><p font-family="body" font-weight="body" font-size="body" color="text"><span>
      <a href="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/8ddda/rooms.png">
    <span></span>
  </a><a href="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/e3189/rooms.png" rel="noopener noreferrer" target="_blank"><img src="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/e3189/rooms.png" alt="Rooms where it happened" title="Rooms where it happened" srcset="https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/a2ead/rooms.png 259w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/6b9fd/rooms.png 518w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/e3189/rooms.png 1035w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/44d59/rooms.png 1553w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/a6d66/rooms.png 2070w,https://www.ockam.io/static/61433a9b6094d6dc270ffe138701bb4c/8ddda/rooms.png 3724w" sizes="(max-width: 1035px) 100vw, 1035px" loading="lazy"></a>
  
    </span></p><p font-family="body" font-weight="body" font-size="body" color="text">Let‚Äôs dive into each stage, in turn, to unpack what we are doing, when we are doing it, and how we are going to measure it.</p><h2 id="motion" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">In order to recruit our team, or for a developer to consider using Ockam, first they have to know we exist. We create and distribute a tremendous amount of content at Ockam with one goal - driving developer awareness.</p><p font-family="body" font-weight="body" font-size="body" color="text">For example, The first product Ockam shipped was <a href="https://www.ockam.io/learn/guides/team/values_and_virtues_on_the_Ockam_Team/">a blog on our Values</a>. The second was a white paper that shared our vision. Even this post is an example!  We have a learning library that outlines our thesis on the open source ecosystem, teaches computer science fundamentals, gives insights into our team culture, and demonstrates our technology. We‚Äôve sat down for dozens of podcasts and interviews over the past two years. Ockam‚Äôs content is based around teaching. Being an effective listener and a great teacher are core underpinnings when building an open source community.</p><h2 id="metrics" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">To gauge awareness we track activity including page views on ockam.io, 'contact us' webform inquiries, GitHub stars, social media mentions, followers and, most importantly, applications to join our team.</p><h2 id="motion-1" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion-1"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">This is a critically important step in our progression to IPO. Building Ockam's community is a never-ending endeavor. It takes years of focus and unrelenting attention to get this step right. For example, Kafka spent it's first 5 years in this phase as an Apache project before Confluent was started.</p><p font-family="body" font-weight="body" font-size="body" color="text">We have three code interfaces to Ockam, which means that there are three different personas in our community:</p><p font-family="body" font-weight="body" font-size="body" color="text"><strong>Application layer developers</strong></p><p font-family="body" font-weight="body" font-size="body" color="text">Ockam‚Äôs users build systems and applications with our simple APIs, OckamD binary downloads, and hosted cloud services.</p><p font-family="body" font-weight="body" font-size="body" color="text">To simplify what‚Äôs going on at this stage, we create packages that any developer can grab in the middle of the night, on the other side of the world, and get a quick win for their demo day at work. You‚Äôve got a job to be done, and we‚Äôve got a simple solution for you. You can get it right now and we will measure your time to a technical-win in the scale of minutes.</p><p font-family="body" font-weight="body" font-size="body" color="text"><strong>Partners</strong></p><p font-family="body" font-weight="body" font-size="body" color="text">Community partners build add-ons, connectors, and plug-ins to connect Ockam to other codebases, cloud services and hardware components. Examples include InfluxData, Confluent - Kafka, Microchip, NXP, MacOS, and Microsoft Azure.</p><p font-family="body" font-weight="body" font-size="body" color="text"><strong>Open source developers</strong></p><p font-family="body" font-weight="body" font-size="body" color="text">Ockam‚Äôs open source builders are engaged in development of Ockam's core codebase. They attend our monthly community meetings, and are hands-on with our OSS codebase on GitHub. Their participation ranges from updating a typo in documentation, to building complex features.</p><h2 id="metrics-1" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics-1"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">We track Monthly Active Users across all three personas in our community:</p><p font-family="body" font-weight="body" font-size="body" color="text">Binary downloads, account signups, or SaaS service IOPS are all indicators of usage. As hinted above, time to ‚Äòtechnical win‚Äô, for an individual developer is also paramount. We‚Äôve defined time to ‚Äòtechnical win‚Äô as the time it takes to go from an individual developer‚Äôs initial discovery to a working prototype that includes Ockam features.</p><p font-family="body" font-weight="body" font-size="body" color="text">The easiest user growth to track is the number of partner integrations. Since partners engage with us 1:1 on an integration, we are highly selective and deliberate about the partnerships that we support. Eventually the development of our technical partnerships will become programmatic. Programmatic examples from my past include the partner program for Heroku Add-ons and the Azure Marketplace partner portal.</p><p font-family="body" font-weight="body" font-size="body" color="text">We also track the intersection of partnerships and usage. For example, the number of Ockam Daemons that run alongside Influx Telegraf, or the number of IOPS in Ockam Routers that securely move packets to a Kafka Connector.</p><p font-family="body" font-weight="body" font-size="body" color="text">Finally open source activity and engagement is transparent through the tools in GitHub. Check out <a href="https://github.com/ockam-network">how we are doing</a> with stars, forks and commits.</p><h2 id="motion-2" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion-2"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">This is a really fun stage for a product-and-pricing-nut like me. By this point in our journey we have users, but not customers. To satisfy investor expectations and to further fund product development, we start to feed our product development machine with revenue.</p><p font-family="body" font-weight="body" font-size="body" color="text">This stage is far simpler than it‚Äôs often made out to be. Here‚Äôs my basic formula;</p><ul><li>If you are an individual developer, then Ockam is free.</li><li>If you are a commercial enterprise, but have not yet had a ‚Äòtechnical win‚Äô with Ockam, then Ockam is free.</li><li>If you are a commercial enterprise, and have had a ‚Äòtechnical win‚Äô with Ockam, then you pay.</li></ul><p font-family="body" font-weight="body" font-size="body" color="text">From here things get a bit more complicated. Services need to be packaged and priced. This, in my opinion, is the most challenging, but also the most fun part of product development. The classic product marketing mix (aka the 4P‚Äôs) framework is durable and applies for Ockam‚Äôs planned product offerings. In this phase we are packaging <strong>P</strong>roducts (say S, M, L sizes), establishing a <strong>P</strong>rice for each product, <strong>P</strong>romoting the product through rigorous segmentation and targeting, and <strong>P</strong>lacing it into various channels and partner marketplaces for distribution.</p><p font-family="body" font-weight="body" font-size="body" color="text">Ockam‚Äôs SaaS products will have a freemium pricing and packaging structure. It‚Äôs worth calling out that freemium is not a pricing strategy. It‚Äôs a customer acquisition tactic that aligns with the formula above.</p><h2 id="metrics-2" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics-2"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">Monthly Recurring Revenue (MRR) is the top line / key metric during this phase.</p><p font-family="body" font-weight="body" font-size="body" color="text">The free-to-paid funnel is another key metric since it is a leading indicator and helps to forecast MRR. We will track both conversion and velocity of our freemium SaaS users.</p><p font-family="body" font-weight="body" font-size="body" color="text">The metrics we track in the Self-Serve SaaS phase allow us to A/B test in our demand generation funnel. A/B testing allows us to optimize month-over-month revenue growth.  The target is 10-15% MoM growth.</p><h2 id="motion-3" color="heading" font-family="heading" font-weight="heading">Motion<a href="#motion-3"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">Inside Sales is a channel strategy for specific types of large customers we already have. This is mainly a cultivate-and-grow tactic. Our bottoms-up, Self Serve SaaS product model feeds leads to our Inside Sales Team. This team is technical, includes sales engineers and provides world-class support.</p><p font-family="body" font-weight="body" font-size="body" color="text">There are two separate objectives during this phase.</p><ul><li>Increase MRR through an increase in our customer base, and in the average ticket size.</li><li>Learn about Customer Acquisition Costs (CAC) for specific segments, prior to launching the Enterprise Sales phase.</li></ul><p font-family="body" font-weight="body" font-size="body" color="text">Monthly recurring revenue is still our top priority during the Inside Sales phase.</p><p font-family="body" font-weight="body" font-size="body" color="text">What‚Äôs less obvious is the second objective. Understanding CAC prepares us for an all-in Enterprise Sales motion. Moving from here onto the Enterprise Sales waypoint is probably the most challenging. It‚Äôs fraught with peril. Many, many smart companies, with great products, and ‚Äòdeveloper love‚Äô die right here.</p><p font-family="body" font-weight="body" font-size="body" color="text">How can that be? It‚Äôs because Inside Sales is bottoms-up and Enterprise Sales is tops-down. This means entirely new buyers, new product-marketing mix, and new internal talent. We must hold onto our developer roots, while we also learn to sell to the suits. While we are executing on Inside Sales we are doing the primary research that will help spawn a new company from our company.</p><p font-family="body" font-weight="body" font-size="body" color="text">This is fantastically difficult - mostly from a cultural standpoint. Fortunately there are a lot of people with a lot of scar tissue from the past 10 years - including myself - and we will push through. The key is patience. We need to use our inside sales motion to find specific beachheads to land our Enterprise Sales motion.</p><h2 id="metrics-3" color="heading" font-family="heading" font-weight="heading">Metrics<a href="#metrics-3"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">MRR carries over as our key metric from the Self Serve SaaS phase.</p><p font-family="body" font-weight="body" font-size="body" color="text">CAC analysis for multiple customer segments.</p><h2 id="anti-metrics" color="heading" font-family="heading" font-weight="heading">Anti-Metrics<a href="#anti-metrics"></a></h2><p font-family="body" font-weight="body" font-size="body" color="text">There will be noise in our Inside Sales data!</p><p font-family="body" font-weight="body" font-size="body" color="text">The noise is any sale that looks like it could be Enterprise Sales. Up to this point, non-recurring engineering (NRE) and enterprise-like sales don‚Äôt count as Enterprise Sales, as we define the term in the next section. Typically they are one-off deals because the motion to win these deals isn‚Äôt scalable. We will do large custom deals to gain access to smart teams that deploy interesting technology. I prefer to categorize this class of revenue as ‚Äòbusiness development‚Äô or even R&amp;D.</p><p font-family="body" font-weight="body" font-size="body" color="text">Why is this an anti-metric? Because other Open Source startups typically stand up a couple one-off enterprises like sales as a way to puff themselves up and to convince themselves that they are ready to move to the next phase. I strongly caution my future self to parse the noise from the signal prior to launching Enterprise Sales.</p><p font-family="body" font-weight="body" font-size="body" color="text">Furthermore, there are other Open Source companies that entirely bypass the Self Serve SaaS phase in favor of the chunky revenue that comes with Enterprise Sales. Those companies tend not to be product companies. They become ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ockam.io/learn/blog/zero_ipo/">https://www.ockam.io/learn/blog/zero_ipo/</a></em></p>]]>
            </description>
            <link>https://www.ockam.io/learn/blog/zero_ipo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654427</guid>
            <pubDate>Thu, 01 Oct 2020 18:26:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is the difference between Docker and a Virtual Machine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654229">thread link</a>) | @championshuttle
<br/>
October 1, 2020 | https://itsopensource.com/what-is-the-difference-between-docker-and-a-virtual-machine/ | <a href="https://web.archive.org/web/*/https://itsopensource.com/what-is-the-difference-between-docker-and-a-virtual-machine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>While in principle they are very similar, it might be more common to know about Virtual Machines than Docker Containers. Virtual Machines are like Inception, but with computers; you‚Äôre running another computer inside your computer. A usual use-case for this setup that‚Äôs applicable even to people not working in tech, is for example, you have a Windows machine (your Host OS) and you want to somehow have Ubuntu (your Guest OS) just to test a software that only runs on Linux machines. You just want to quickly try it out, so you don‚Äôt want to go through the process of installing another OS in your system (dual booting).</p>
<p><span>
      <a href="https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/f67cc/ubuntu-vm.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Running an Ubuntu session using VirtualBox" title="Running an Ubuntu session using VirtualBox" src="https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/88218/ubuntu-vm.jpg" srcset="https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/7237a/ubuntu-vm.jpg 148w,
https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/0cfdf/ubuntu-vm.jpg 295w,
https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/88218/ubuntu-vm.jpg 590w,
https://itsopensource.com/static/44eafcd1b741ccc88a5bf2b7440aea18/f67cc/ubuntu-vm.jpg 800w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>Now let‚Äôs discuss the underlying technology a bit. A virtual machine is a system which emulates a computer system. It has its own CPU, memory, hard disk, network and other hardware resources which are managed by a ‚Äòvirtualization layer‚Äô. This layer then translates these requests to the physical hardware (host computer).</p>
<p>If you have tried running a VM in your machine, you know how your machine started heating up. This whole process is resource-intensive, because hey, you‚Äôre practically running a full version of another machine! That‚Äôs definitely something you won‚Äôt do when you want to solve a bigger use-case that requires this setup.</p>
<p><span>
      <a href="https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/a8246/vm-architecture.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Virtual Machine Simple Architecture" title="Virtual Machine Simple Architecture" src="https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/a8246/vm-architecture.png" srcset="https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/00d96/vm-architecture.png 148w,
https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/0b23c/vm-architecture.png 295w,
https://itsopensource.com/static/a36cdb7beaa411e06c9fcb56decfd989/a8246/vm-architecture.png 400w" sizes="(max-width: 400px) 100vw, 400px" loading="lazy">
  </a>
    </span></p>
<p>What if my colleagues also want to try that software? Do they also have to install the same heavy thing on their system? What if their hardware can‚Äôt handle it?</p>
<p>That‚Äôs where Docker comes in. It‚Äôs like milk, but the leanest version with the least amount of fat that you can find (sort of).</p>
<p>With Docker, you can run applications on your host operating system (e.g. Windows), in what is called a Container. A container is almost similar to an operating system minus the graphical user interface (the stuff you can click). It technically functions just like running a session on a VM, but here‚Äôs the magic: unlike in a VM where you have to run a session of an entire OS to use an application, with Docker, you are able to run the application in light-weight containers AND control it from the host OS. The part where you see another OS running? The part where you turn on Ubuntu on your VM Manager that you installed on your Windows machine? That part has been scrapped, making the whole setup way lighter. Instead, you just write some commands on the command line and you go directly into running your application.</p>
<p><em>Whuuuut?</em></p>
<p>Let‚Äôs try to visualize that with this image, compared to our previous one.</p>
<p><span>
      <a href="https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/11d19/docker-vm.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Docker vs VM Visualized" title="Docker vs VM Visualized" src="https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/799d3/docker-vm.png" srcset="https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/00d96/docker-vm.png 148w,
https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/0b23c/docker-vm.png 295w,
https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/799d3/docker-vm.png 590w,
https://itsopensource.com/static/8570b603ddc9ec9226dcfc0c3e0b0ceb/11d19/docker-vm.png 800w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>The game-changing advantage of Docker is that it allows you to package any software with all of its dependencies into a single standardized unit called image.</p>
<p>Virtual machines run on a host OS and make guest OS available inside each VM, each OS needs to be booted individually. On the other hand, Docker containers are hosted on a single docker engine on a host OS. All the containers share the docker instance. Sharing the engine between containers makes them light and decreases the boot time. While Docker Containers boot in a few seconds, VMs take a few minutes to boot. </p>
<p><span>
      <a href="https://itsopensource.com/static/632533cd83014f756c2c557efb650694/7217d/docker-architecture.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Docker Architecture" title="Docker Architecture" src="https://itsopensource.com/static/632533cd83014f756c2c557efb650694/7217d/docker-architecture.png" srcset="https://itsopensource.com/static/632533cd83014f756c2c557efb650694/00d96/docker-architecture.png 148w,
https://itsopensource.com/static/632533cd83014f756c2c557efb650694/0b23c/docker-architecture.png 295w,
https://itsopensource.com/static/632533cd83014f756c2c557efb650694/7217d/docker-architecture.png 500w" sizes="(max-width: 500px) 100vw, 500px" loading="lazy">
  </a>
    </span></p>
<p>Now that we have that background, let‚Äôs take a look at some real examples of how these can be applied:</p>
<p><strong>Virtual machine</strong></p>
<p>You have a Windows machine and want to try out GIMP on Ubuntu. Here‚Äôs how the process will look like:</p>
<ol>
<li>Install an Ubuntu VM on a Windows machine</li>
<li>Go inside the VM window and operate Ubuntu</li>
<li>Install GIMP there and use it.</li>
</ol>
<p>The host OS (Windows) is totally unaware of what is being done inside VM (Ubuntu).</p>
<p><strong>Docker</strong></p>
<p>You use Wordpress.com and discovered that there is an open source version of it that you can run yourself, so you want to test it out on your own computer first. Now, setting up a Wordpress site has dependencies, that is, your system needs to have Apache, MySQL database and PHP installed.</p>
<p>Using Docker, here‚Äôs how the process will look like.</p>
<ol>
<li>Create a container using a <a href="https://hub.docker.com/_/wordpress">Wordpress image</a>. We‚Äôre able to jump directly to this step because the Wordpress image has already been packaged by the Docker community. It contains all the dependencies needed to run Wordpress.</li>
<li>Run Wordpress on your browser!</li>
</ol>
<p>In a nutshell, Docker containers support OS virtualization, and VM supports hardware virtualization.</p></section></div>]]>
            </description>
            <link>https://itsopensource.com/what-is-the-difference-between-docker-and-a-virtual-machine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654229</guid>
            <pubDate>Thu, 01 Oct 2020 18:09:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startup Lessons I Needed to Learn First Hand (But Maybe You Don‚Äôt)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24654192">thread link</a>) | @jlrubin
<br/>
October 1, 2020 | http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/ | <a href="https://web.archive.org/web/*/http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="content">

<div>
	<div id="primary">
		<main id="main" role="main">

			
<article id="post-1586">
		<!-- .entry-header -->

	
	<div>
		
<p>When I stepped down as CEO in 2018, I wrote a post mortem and shared it privately with founder friends who directly asked <a rel="noreferrer noopener" href="http://www.nancyhua.com/2020/01/06/2019-2020-post-pre-mortems/" target="_blank">when I blogged here</a>. The company got acquired in 2019 and now I‚Äôm sharing the post mortem publicly because readers told me they saw novel concepts in my document they hadn‚Äôt heard elsewhere (as I write this I wonder if it‚Äôs because I was wrong. LMK!). </p>



<p>I used to abhor failure, but publicly releasing this post mortem no longer holds charge for me. Through Apptimize, I‚Äôve learned and changed such that my subsequent companies will be very different. One of my biggest learnings is that I‚Äôd played a finite game and missed <a rel="noreferrer noopener" href="https://youtu.be/3QyurhNwk14?t=56" target="_blank">the infinite game</a>. I didn‚Äôt know those concepts at the time and saw ‚Äúproduct innovation‚Äù as a separate category of work. After shifting my reference frame, I now know innovation as a sign of infinite game behavior. Anyway, I hope the below is useful to founders whose sales motions aren‚Äôt getting easier years into their venture backed company and want to consider frameworks for evaluating their position.&nbsp;</p>



<p>=================</p>



<p><strong>Startup Post Mortem, </strong>written Q3 2018</p>



<p>At times, the company we founded in 2013 seemed to be doing well by various objective metrics‚Äî we had a prestigious customers list ranging from CNN to Comcast, we raised 3 funding rounds summing to over $20MM in venture capital investment, and our revenue grew exponentially for the first few years (obviously easier to 3x when x is small). As the cofounder and CEO, I always bet on our ability to figure it out and be a financial success. I put in the first $50K and bought our domain for an additional $10K, which isn‚Äôt much money in the scheme of startup funding, but this was before we had users, before we‚Äôd gotten into Y Combinator, before it was anyone other than me and my cofounder. I used to be a trader, so I wasn‚Äôt goofing around‚Äî I fully expected to eventually make tons of money off our startup. I wrote a draft S-1 for how we would IPO, I didn‚Äôt pay myself for the first year, I was the lowest paid person in the company for years, and I guarded our equity like it was the blood of my children. I always wanted more equity because I valued it so highly. When founder friends told me to pay myself more, I asked for more equity instead. When we raised an oversubscribed Series B, founder friends told me to ask if I could sell some of my shares or take money off the table, but again I asked for more equity instead. Suggestions to get cash seemed ridiculous to me because I didn‚Äôt think I deserved cash yet; we weren‚Äôt a success and I, more than anyone, knew all our warts. When we were getting acquired, founder friends suggested I block the acquisition unless I made money off it, but that also sounded ridiculous to me because I felt I deserved money least of all. I‚Äôm sure my VC‚Äôs would‚Äôve agreed.</p>



<p>Our company didn‚Äôt exit at anywhere near as well as I‚Äôd pitched, and I felt sad to fail after so many years of everyone working so hard. For years, we worked weekends and holidays, regularly in the office till 10pm. My VP of marketing was back at work weeks after birthing each of her babies, working through her pregnancies, and we forced anyone who entered my house or office to do user tests. Had it all been a waste? Should we have spent that time partying instead? Being successful is important to me and I felt ashamed my company wasn‚Äôt a financial success despite how hard everyone worked on it and how much money we raised. Sure, I could twist the story to make it sound like a success in terms of learning and building, and we made a product people used, and we got acquired, but the fact is that the company didn‚Äôt make money the way I‚Äôd imagined and pitched. I felt scared my investors would view me as a failure and dislike me or view me as incompetent. We should‚Äôve done better‚Äî we had some of the smartest people you‚Äôd ever meet working on this problem that I convinced them was important enough to warrant their time and resources. How had I been so wrong about the financial outcome?&nbsp;</p>



<p><strong>Two Key Qualifying Questions:</strong></p>



<p>One of my investors put it well: everyone in a company is either a) making the product or b) selling the product. I learned there were 2 key questions that separated successful vs unsuccessful hires in our company:</p>



<ol><li>How hard is it to make this product?</li><li>How hard is it to sell this product?</li></ol>



<p>Our product was both hard to make and hard to sell. What do I mean by this and how does this impact the hiring profile?</p>



<p><strong>Product vs Sales Driven Company:</strong></p>



<p>On the spectrum of how hard it is to build a product, web forms are on the easier side. Easy products are anything that a person could do with a series of google docs and sheets, anything that you‚Äôre 100% sure is possible to make. On the harder side, there are products like a rocket or a flying car, where it‚Äôs &lt;100% guaranteed the engineering will get there in the time required. If the product is easy to build, then engineering is easier and it‚Äôs more on the sales and marketing teams to drive the company forward and show why your company is better even though others can make this commoditizable product (through network effect/ better land grab execution, brand/ trust, integrations/ partnerships, ‚Äúthought leadership,‚Äù customer service/ support, etc).&nbsp;</p>



<p>In contrast, the harder a product is to build, the better engineers you need and the more everything depends on the product team shipping something 10x better.&nbsp;</p>



<p>Our product was nowhere as hard to build as a rocket, but it was harder than a webapp, and we made design choices that increased the difficulty of building and maintaining our product in exchange for gaining competitive advantage, which was high at one point but eroded. This means our company had to be product driven. But after the first few years, we failed to be product driven because 1) I struggled to hire product leadership that was technical enough and 2) I was short term focused on revenue goals. Single-threaded on sales, I didn‚Äôt focus on the product roadmap because all I cared about were short term goals to lead us to the next funding round because I was mainly driven by my fear of the startup failing versus any love for shipping a better product.&nbsp;</p>



<p><strong>Transactional vs. Consultative Sales:</strong></p>



<p>Everyone in B2B SaaS knows from SaaStr etc you‚Äôre supposed to distinguish between sales people who sold to technical vs non-technical teams, and differentiate sales candidates based on the price point they were comfortable selling at, but I learned an additional point of differentiation: how consultative must the sale be? On the spectrum of how hard it is to sell a product, widgets like video conferencing software are on the easier end, easy to explain and demo. On the harder end, there‚Äôs consulting services to suggest TBD process improvements. Even harder is stuff that‚Äôs a new category where you have to educate the buyer on the need. The hardest sales require founders to drive sales; the salesperson needs to be at least as smart as the buyer so they can credibly educate the buyer on how the product will urgently impact their revenue. Buyers of video conferencing software don‚Äôt expect to get promoted because they chose Zoom over Webex or talk about the impact of their choice at a conference, but buyers of analytics software do want to hear how they‚Äôre going to become Chief Product Officer vs VP, that they‚Äôre going to show their CEO a powerpoint with graphs clearly illustrating the revenue their analytics choices have created for their team, and how they‚Äôre going to speak at the conference on their data driven decision making processes.</p>



<p>If the product fulfills a clear, established need, you can hire a wider variety of salespeople. But when the product‚Äôs harder to sell, you need a ‚Äúconsultative‚Äù salesperson, a specific profile correlated but distinct from price point. When the product differences/ usage/ impact are hard to explain, or there‚Äôs no category yet, or it‚Äôs not a drastic, budgeted need, you need sales people who are like consultants, subject matter experts who are smarter than the buyers.&nbsp;</p>



<p>If the sales person is interested in presenting a custom, strategic overview of how our product impacts the buyer‚Äôs product strategy, they eventually want to become customer success managers. Other than our first business hire, who was more like a cofounder to me and eventually founded his own company, I couldn‚Äôt get anyone to do both sales and customer success at the same time. I think our deals weren‚Äôt big enough and our customer success process was in the awkward gap between easy and hard‚Äî not hard enough to warrant consulting services, but not easy enough to remain a yearly check-in to upgrade the account.&nbsp;</p>



<figure><img loading="lazy" width="1024" height="856" src="http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups--1024x856.png" alt="" srcset="http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups--1024x856.png 1024w, http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups--400x334.png 400w, http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups--768x642.png 768w, http://www.nancyhua.com/wp-content/uploads/2020/10/Pros-and-cons-of-product-vs.-sales-driven-startups-.png 1404w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"><figcaption><em>Pros and cons of product vs. sales driven startups</em></figcaption></figure>



<p><strong>Fear/ Ego:</strong></p>



<p>Shifting gears from the tactical company building stuff to the touchy feely, the following section is philosophical.</p>



<p>It had started out really fun. In the 2nd year of the company, one executive told me that she got all her social fulfillment from our work. We were always together, working from my house on weekends, engineers sleeping over when they got tired, cooking together, talking about each other‚Äôs love languages, a group of friends going on an adventure together.&nbsp;</p>



<p>But now I see that I didn‚Äôt start the company with a pure heart. I started the company because I thought it‚Äôd be successful and I wanted to prove I could contribute something to the world, not because I specifically cared about our product or market, which I learned matters for me as time passes.&nbsp;</p>



<p>I thought I could get passionate about anything, and that was true at first, but it drained me to force myself to be an expert on our product for years because it wasn‚Äôt something I would‚Äôve done if it weren‚Äôt for the company, the team, and my ego. For years, I always knew the most about our market and would send links to the rest of the team for news that had come out, anything they ‚Ä¶</p></div></article></main></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/">http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/</a></em></p>]]>
            </description>
            <link>http://www.nancyhua.com/2020/10/01/startup-lessons-i-needed-to-learn-first-hand-but-maybe-you-dont/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654192</guid>
            <pubDate>Thu, 01 Oct 2020 18:06:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programmers need to think like hackers]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24654136">thread link</a>) | @gexos
<br/>
October 1, 2020 | https://gexos.org/2020/10/01/Programmers-need-to-think-like-hackers!/ | <a href="https://web.archive.org/web/*/https://gexos.org/2020/10/01/Programmers-need-to-think-like-hackers!/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://gexos.org/2020/10/01/Programmers-need-to-think-like-hackers!/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654136</guid>
            <pubDate>Thu, 01 Oct 2020 18:01:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Is Not Your Ideal]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24653013">thread link</a>) | @amortize
<br/>
October 1, 2020 | https://sujithjay.com/not-aws | <a href="https://web.archive.org/web/*/https://sujithjay.com/not-aws">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span> 01 Oct 2020  ‚Ä¢ <span>
  
    
    
    <a href="https://sujithjay.com/tag/product"><code><nobr>PRODUCT</nobr></code>&nbsp;</a>
  
    
    
    <a href="https://sujithjay.com/tag/management"><code><nobr>MANAGEMENT</nobr></code>&nbsp;</a>
  
</span></span></p><p>Let me start with an assertion. Every platform engineering team <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> in every organisation aspires to be like AWS <sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</p>

<p>Every platform team wants to be like AWS, because like AWS, they provide infrastructure abstractions to users. AWS provides infrastructure via the abstractions of VMs and disks and write-capacity-units, while platform teams provide infrastructure using higher abstractions which solve service definitions, database or message queue provisioning, and service right-sizing <sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>.</p>

<p>This similarity prompts leaders of platform engineering teams to model their teams as agnostic providers of universal, non-leaky (within SLO bounds), self-served abstractions for their engineering organisation. Platform teams structured as such detached units struggle to define cohesive roadmaps which provide increasing value to business. But how does your platform differ from AWS?</p>

<h2 id="your-platform-vs-the-platform">Your Platform vs. The Platform</h2>

<h3 id="1-the-middle-ground">1. The Middle Ground</h3>
<p>As an agnostic service provider, AWS can afford to cater to median use-cases. The reason platform engineering teams exist is to bridge the gap between PaaS abstractions which work for the median use-case to your business‚Äô specific use-cases. AWS can afford to target the median (economy of scale etc.), but you cannot.</p>

<p><img src="https://sujithjay.com/public/notaws/Median.jpeg" alt="AWS can afford to stay within a single œÉ. You cannot."></p>
<p><span> AWS can afford to stay within a single œÉ. You cannot.</span>
</p>

<p>Agnostic platform engineering teams which emulate AWS try to get away from this responsibility by proposing abstractions which target the median use-case. A tell-tale sign of this is when the lack in wide usability of internal abstractions is compensated for by extensive onboarding &amp; repeated training. This is also a side-effect of the relative valuation of engineering time vs. the time of another function <sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>.</p>

<h3 id="2-follow-the-money">2. Follow the Money</h3>
<p>The dictum ‚Äòfollow the money‚Äô works beautifully for customer-front products. When faced with a choice between two competing features to prioritise, a common tactical play is to make something which leads to more (immediate &amp; long-term) revenue. The proxy for increased revenue could be increased acquisition conversion, better retention or improved user experience ‚Äì metrics which ensure increased revenue for the company over time. In short, revenue growth is the north star <sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>.</p>

<p>Not so much in platform engineering. There is no revenue since your customers are internal, captive ones. Captive audiences are forced to use a solution by the force of dictum and lack of choice. The metrics used in platform products are proxies for usability and user satisfaction ‚Äì but there are no foolproof ways to measure it for captive audiences. For captive audiences, solutions can not compete and better solutions cannot win. Like a command economy, platform products are designed rather than evolved. Design takes priority over market economy. So why is design bad?</p>

<h2 id="bad-design">Bad Design</h2>
<p>For design to work, there has to be an objective function against which we can design. A specification is an objective function against which engineering teams design a solution. Since we do not have reliable metrics <sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup> to rely on for platform engineering, how do we come up with specifications? And without rigorous specifications, new features created by the platform run a high risk of not solving worthwhile problems for the users.The current accepted methodology among platform engineering leaders to solve this paucity of specifications is to rely on user-interviews. This is, as mentioned before, an unreliable source since captive users do not have the best view of the ideal state of tooling and abstractions that could be available to them.</p>

<p>The only way to flip this situation is to let go of command-economy-style designed abstractions, and to let your platform self-organise along the principle of markets. How does that look in practice?</p>

<h3 id="1-market-ftw">1. Market, FTW</h3>
<p>Camille Fournier mentions in <a href="https://medium.com/@skamille/product-for-internal-platforms-9205c3a08142">Product for Internal Platforms</a> how her team partners with customer teams to develop prototypes for specific problems. These specific solutions are later honed and iterated on to become general solutions provided by your team. I would go a step further on this route, where possible. Partner to prototype with multiple teams facing related problems to develop multiple specific solutions. These specific solutions can be seen as competing candidates to solve a general problem. Bring in user-interviews at this point to gauge pain-points, and iterate individually on these specific solutions. This switches the economy of your team to a self-organised market. Once considerable thought and iteration has gone into each solution, it is time to assimilate. Assimilate the best solution(s) while migrating the rest to the chosen solution. As emphasised in <a href="https://medium.com/@skamille/product-for-internal-platforms-9205c3a08142">Product for Internal Platforms</a>, an early investment of time into migration strategies is essential for such a scheme to sustain.</p>

<p>In platforms designed with experimentation, you will find that innovation continues to thrive at the edges of the platform‚Äôs domain while the stable core of the platform is subject to periodic rework or maintenance. The use-cases a platform supports grows in a controlled manner to address an ever-growing percent of the consumers, and does not stagnate after addressing just the median users.</p>

<h3 id="2-overloaded-use-cases">2. Overloaded Use-cases</h3>
<p>Although agnostic platform engineering teams might only be catering to very specific median use-cases, the customer teams with specific needs cannot afford to be blocked and they cannot stop delivering their deliverables. These teams sometimes create their own solutions, and in such cases the above strategy of assimilation works wonders. You get a prototype for free on which the team can iterate on. However, this scenario is rarer in cases where it requires specific skills to build such solutions, such as in data platforms. One common pattern in such knowledge-constricted situations is that users find ways to overload the existing solutions with minor tweaks to fit their use-case. Look out for such overloaded use-cases within your platform, for they are excellent guides to unmet needs of the users. You can leverage them to advocate for newer features to explicitly support those use-cases.</p>

<h3 id="3-listen-to-them-only-at-the-start">3. Listen To Them (Only At The Start!)</h3>
<p>As a parting note, I will take a jab at user-interviews again. The above tactics work when you are trying to scale your platform from 1 to N. When taking a platform from 0 to 1, the only solution to creating specifications is to listen to the users. Give them exactly what they want. Listen to their exact demands. A propensity of platform product managers is to rely on this excessively at a much later stage in the product‚Äôs lifecycle. User-interviews have their place in evolving products, but the over-reliance on the methodology is a bane to platform product management.</p>

<p><strong>P.S.</strong> As I read back the above essay, the heavy influence of <a href="https://medium.com/@skamille/product-for-internal-platforms-9205c3a08142">Product for Internal Platforms</a> is clear. I would like to say that was the intention: to reassert the ideas in it which resounded with me, while stating a few of my own.</p>

<h3 id="footnotes">Footnotes</h3>


  </div>









      </div></div>]]>
            </description>
            <link>https://sujithjay.com/not-aws</link>
            <guid isPermaLink="false">hacker-news-small-sites-24653013</guid>
            <pubDate>Thu, 01 Oct 2020 16:37:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling a Lisp to x86-64: Let expressions]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 30 (<a href="https://news.ycombinator.com/item?id=24652842">thread link</a>) | @todsacerdoti
<br/>
October 1, 2020 | https://bernsteinbear.com/blog/compiling-a-lisp-7/ | <a href="https://web.archive.org/web/*/https://bernsteinbear.com/blog/compiling-a-lisp-7/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-0/">first</a></em> ‚Äì <em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-6/">previous</a></em></p>

<p>Welcome back to the ‚ÄúCompiling a Lisp‚Äù series. Last time we added a reader
(also known as a parser) to our compiler. This time we‚Äôre going to compile a
new form: <em>let</em> expressions.</p>

<p>Let expressions are a way to bind variables to values in a particular scope.
For example:</p>

<div><div><pre><code><span>(</span><span>let</span> <span>((</span><span>a</span> <span>1</span><span>)</span> <span>(</span><span>b</span> <span>2</span><span>))</span>
  <span>(</span><span>+</span> <span>a</span> <span>b</span><span>))</span>
</code></pre></div></div>

<p>Binds <code>a</code> to <code>1</code> and <code>b</code> to <code>2</code>, but only for the body of the <code>let</code> ‚Äî the
rest of the S-expression ‚Äî and then executes the body.</p>

<p>This is similar in C to opening a new block:</p>

<div><div><pre><code><span>int</span> <span>result</span><span>;</span>
<span>{</span>
  <span>int</span> <span>a</span> <span>=</span> <span>1</span><span>;</span>
  <span>int</span> <span>b</span> <span>=</span> <span>2</span><span>;</span>
  <span>result</span> <span>=</span> <span>a</span> <span>+</span> <span>b</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>but it‚Äôs a little different because C has a divide between <em>statements</em> and
<em>expressions</em>, whereas Lisp does not.</p>

<p>It‚Äôs <em>also</em> different because let-expressions do not make previous binding
names available to expressions being bound. For example, the following program
should fail because it cannot find the name <code>a</code>:</p>



<p>There is a form that makes bindings available serially, but that is called
<code>let*</code> and we are not implementing that today.</p>

<p>For completeness‚Äô sake, there is also <code>let rec</code>, which makes names available
serially and also within the same binding. This is useful for binding recursive
or mutually recursive functions. Again, we are not implementing that today.</p>

<h3 id="name-binding-implementation-strategy">Name binding implementation strategy</h3>

<p>You‚Äôll notice two new things about let expressions:</p>

<ol>
  <li>They introduce ways to bind names to values, something we have to figure out
how to keep track of</li>
  <li>In order to use those names we have to figure out how to look up what the
name means</li>
</ol>

<p>In more technical terms, we have to add <em>environments</em> to our compiler. We can
then use those environments to map <em>names</em> to <em>stack locations</em>.</p>

<p>‚ÄúEnvironment‚Äù is just a fancy word for ‚Äúlook-up table‚Äù. In order to implement
this table, we‚Äôre going to make an <em>association list</em>.</p>

<p>An <em>association list</em> is a list of <code>(key value)</code> pairs. Adding a pair means
tacking it on at the end (or beginning) of the list. Searching through the
table involves a linear scan, checking if keys match.</p>

<blockquote>
  <p>You may be wondering why we‚Äôre using this data structure to implement
environments. Didn‚Äôt I even take a data structures course in college?
Shouldn‚Äôt I know that <em>linear</em> equals <em>slow</em> and that I should <em>obviously</em>
use a hash table?</p>

  <p>Well, hash tables have costs too. They are hard to implement right; they have
high overhead despite being technically constant time; they incur higher
space cost per entry.</p>

  <p>For a compiler as small as this, a tuned hash table could easily be as long
as the rest of the compiler. Since we‚Äôre also compiling small <em>programs</em>,
we‚Äôll worry about time complexity later. It is only an implementation detail.</p>
</blockquote>

<p>In order to do this, we‚Äôll first draw up an association list. We‚Äôll use a
linked list, just like cons cells:</p>

<div><div><pre><code><span>// Env</span>

<span>typedef</span> <span>struct</span> <span>Env</span> <span>{</span>
  <span>const</span> <span>char</span> <span>*</span><span>name</span><span>;</span>
  <span>word</span> <span>value</span><span>;</span>
  <span>struct</span> <span>Env</span> <span>*</span><span>prev</span><span>;</span>
<span>}</span> <span>Env</span><span>;</span>
</code></pre></div></div>

<p>I‚Äôve done the usual thing and overloaded <code>Env</code> to mean both ‚Äúa node in the
environment‚Äù and ‚Äúa whole environment‚Äù. While one little <code>Env</code> struct only
holds a one name and one value, it also points to the rest of them, eventually
ending with <code>NULL</code>.</p>

<p>This <code>Env</code> will map names (symbols) to <em>stack offsets</em>. This is because we‚Äôre
going to continue our strategy of <em>not doing register allocation</em>.</p>

<p>To manipulate this data structure, we will also have two functions<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>:</p>

<div><div><pre><code><span>Env</span> <span>Env_bind</span><span>(</span><span>const</span> <span>char</span> <span>*</span><span>name</span><span>,</span> <span>word</span> <span>value</span><span>,</span> <span>Env</span> <span>*</span><span>prev</span><span>);</span>
<span>bool</span> <span>Env_find</span><span>(</span><span>Env</span> <span>*</span><span>env</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>key</span><span>,</span> <span>word</span> <span>*</span><span>result</span><span>);</span>
</code></pre></div></div>

<p><code>Env_bind</code> creates a new node from the given name and value, borrowing a
reference to the name, and prepends it to <code>prev</code>. Instead of returning an
<code>Env*</code>, it returns a whole struct. We‚Äôll learn more about why later, but the
‚ÄúTL;DR‚Äù is that I think it requires less manual cleanup.</p>

<p><code>Env_find</code> takes an <code>Env*</code> and searches through the linked list for a <code>name</code>
matching the given <code>key</code>. If it finds a match, it returns <code>true</code> and stores the
<code>value</code> in <code>*result</code>. Otherwise, it returns <code>false</code>.</p>

<p>We can stop at the first match because Lisp allows name <em>shadowing</em>. Shadowing
occurs when a binding at a inner scope has the same name as a binding at an
outer scope. The inner binding takes precedence:</p>

<div><div><pre><code><span>(</span><span>let</span> <span>((</span><span>a</span> <span>1</span><span>))</span>
  <span>(</span><span>let</span> <span>((</span><span>a</span> <span>2</span><span>))</span>
    <span>a</span><span>))</span>
<span>; =&gt; 2</span>
</code></pre></div></div>

<p>Let‚Äôs learn about how these functions are implemented.</p>

<h3 id="name-binding-implementation">Name binding implementation</h3>

<p><code>Env_bind</code> is a little silly looking, but it‚Äôs equivalent to prepending a
node onto a chain of linked-list nodes. It returns a struct <code>Env</code> containing
the parameters passed to the function. I opted <em>not</em> to return a heap pointer
(allocated with <code>malloc</code>, etc) so that this can be easily stored in a
stack-allocated variable.</p>

<div><div><pre><code><span>Env</span> <span>Env_bind</span><span>(</span><span>const</span> <span>char</span> <span>*</span><span>name</span><span>,</span> <span>word</span> <span>value</span><span>,</span> <span>Env</span> <span>*</span><span>prev</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span><span>Env</span><span>){.</span><span>name</span> <span>=</span> <span>name</span><span>,</span> <span>.</span><span>value</span> <span>=</span> <span>value</span><span>,</span> <span>.</span><span>prev</span> <span>=</span> <span>prev</span><span>};</span>
<span>}</span>
</code></pre></div></div>

<p><em>Note</em> that we‚Äôre <strong>pre</strong>pending, not <strong>ap</strong>pending, so that names we add deeper
in a let chain shadow names from outside.</p>

<p><code>Env_find</code> does a recursive linear search through the linked list nodes. It may
look familiar to you if you‚Äôve already written such a function in your life.</p>

<div><div><pre><code><span>bool</span> <span>Env_find</span><span>(</span><span>Env</span> <span>*</span><span>env</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>key</span><span>,</span> <span>word</span> <span>*</span><span>result</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>env</span> <span>==</span> <span>NULL</span><span>)</span>
    <span>return</span> <span>false</span><span>;</span>
  <span>if</span> <span>(</span><span>strcmp</span><span>(</span><span>env</span><span>-&gt;</span><span>name</span><span>,</span> <span>key</span><span>)</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
    <span>*</span><span>result</span> <span>=</span> <span>env</span><span>-&gt;</span><span>value</span><span>;</span>
    <span>return</span> <span>true</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>Env_find</span><span>(</span><span>env</span><span>-&gt;</span><span>prev</span><span>,</span> <span>key</span><span>,</span> <span>result</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>We search for the node with the string <code>key</code> and return the stack offset associated
with it.</p>

<p>Alright, now we‚Äôve got names and data structures. Let‚Äôs implement some name
resolution and name binding.</p>

<h3 id="compiling-name-resolution">Compiling name resolution</h3>

<p>Up until now, <code>Compile_expr</code> could only compile integers, characters, booleans,
<code>nil</code>, and some primitive call expressions (via <code>Compile_call</code>). Now we‚Äôre
going to add a new case: symbols.</p>

<p>When a symbol is compiled, the compiler will look up its stack offset in the
current environment and emit a load. This opcode, <code>Emit_load_reg_indirect</code>, is
very similar to <code>Emit_add_reg_indirect</code> that we implemented for primitive
binary functions.</p>

<div><div><pre><code><span>int</span> <span>Compile_expr</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>node</span><span>,</span> <span>word</span> <span>stack_index</span><span>,</span>
                 <span>Env</span> <span>*</span><span>varenv</span><span>)</span> <span>{</span>
  <span>// ...</span>
  <span>if</span> <span>(</span><span>AST_is_symbol</span><span>(</span><span>node</span><span>))</span> <span>{</span>
    <span>const</span> <span>char</span> <span>*</span><span>symbol</span> <span>=</span> <span>AST_symbol_cstr</span><span>(</span><span>node</span><span>);</span>
    <span>word</span> <span>value</span><span>;</span>
    <span>if</span> <span>(</span><span>Env_find</span><span>(</span><span>varenv</span><span>,</span> <span>symbol</span><span>,</span> <span>&amp;</span><span>value</span><span>))</span> <span>{</span>
      <span>Emit_load_reg_indirect</span><span>(</span><span>buf</span><span>,</span> <span>/*dst=*/</span><span>kRax</span><span>,</span> <span>/*src=*/</span><span>Ind</span><span>(</span><span>kRbp</span><span>,</span> <span>value</span><span>));</span>
      <span>return</span> <span>0</span><span>;</span>
    <span>}</span>
    <span>return</span> <span>-</span><span>1</span><span>;</span>
  <span>}</span>
  <span>assert</span><span>(</span><span>0</span> <span>&amp;&amp;</span> <span>"unexpected node type"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>If the variable is not in the environment, this is a compiler error and we
return <code>-1</code> to signal that. This is not a tremendously helpful signal. Maybe
soon we will add more helpful error messages.</p>

<p>Ah, yes, <code>varenv</code>. You will, like I had to, go and add an <code>Env*</code> parameter to
all relevant <code>Compile_XYZ</code> functions and then plumb it through the recursive
calls. Have fun!</p>

<h3 id="compiling-let-finally">Compiling let, finally</h3>

<p>Now that we can resolve the names, let‚Äôs go ahead and compile the expressions
that bind them.</p>

<p>We‚Äôll have to add a case in <code>Compile_expr</code>. We could add it in the body of
<code>Compile_expr</code> itself, but there is some helpful setup in <code>Compile_call</code>
already. It‚Äôs a bit of a misnomer, since it‚Äôs not a call, but oh well.</p>

<div><div><pre><code><span>int</span> <span>Compile_call</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>callable</span><span>,</span> <span>ASTNode</span> <span>*</span><span>args</span><span>,</span>
                 <span>word</span> <span>stack_index</span><span>,</span> <span>Env</span> <span>*</span><span>varenv</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>AST_is_symbol</span><span>(</span><span>callable</span><span>))</span> <span>{</span>
    <span>// ...</span>
    <span>if</span> <span>(</span><span>AST_symbol_matches</span><span>(</span><span>callable</span><span>,</span> <span>"let"</span><span>))</span> <span>{</span>
      <span>return</span> <span>Compile_let</span><span>(</span><span>buf</span><span>,</span> <span>/*bindings=*/</span><span>operand1</span><span>(</span><span>args</span><span>),</span>
                         <span>/*body=*/</span><span>operand2</span><span>(</span><span>args</span><span>),</span> <span>stack_index</span><span>,</span>
                         <span>/*binding_env=*/</span><span>varenv</span><span>,</span>
                         <span>/*body_env=*/</span><span>varenv</span><span>);</span>
    <span>}</span>
  <span>}</span>
  <span>assert</span><span>(</span><span>0</span> <span>&amp;&amp;</span> <span>"unexpected call type"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>We have two cases to handle: no bindings and some bindings. We‚Äôll tackle these
recursively, with no bindings being the base case. For that reason, I added a
helper function <code>Compile_let</code>.</p>

<p>As with all of the other compiler functions, we pass it an machine code buffer,
a stack index, and an environment. Unlike other functions, we passed it two
expressions and two environments.</p>

<p>I split up the bindings and the body so we can more easily recurse on the
bindings as we go through them. When we get to the end (the base case), the
bindings will be <code>nil</code> and we can just compile the <code>body</code>.</p>

<p>We have two environments for the reason I mentioned above: when we‚Äôre
evaluating the expressions that we‚Äôre binding the names to, we can‚Äôt add
bindings iteratively. We have to evaluate them in the parent environment. It‚Äôll
be come clearer in a moment how that works.</p>

<p>We‚Äôll tackle the simple case first ‚Äî no bindings:</p>

<div><div><pre><code><span>int</span> <span>Compile_let</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>bindings</span><span>,</span> <span>ASTNode</span> <span>*</span><span>body</span><span>,</span>
                <span>word</span> <span>stack_index</span><span>,</span> <span>Env</span> <span>*</span><span>binding_env</span><span>,</span> <span>Env</span> <span>*</span><span>body_env</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>AST_is_nil</span><span>(</span><span>bindings</span><span>))</span> <span>{</span>
    <span>// Base case: no bindings. Compile the body</span>
    <span>_</span><span>(</span><span>Compile_expr</span><span>(</span><span>buf</span><span>,</span> <span>body</span><span>,</span> <span>stack_index</span><span>,</span> <span>body_env</span><span>));</span>
    <span>return</span> <span>0</span><span>;</span>
  <span>}</span>
  <span>// ...</span>
<span>}</span>
</code></pre></div></div>

<p>In that case, we compile the body using the <code>body_env</code> as the environment. This
is the environment that we will have added all of the bindings to.</p>

<p>In the case where we <em>do</em> have bindings, we can take the first one off and pull
it apart:</p>

<div><div><pre><code>  <span>// ...</span>
  <span>assert</span><span>(</span><span>AST_is_pair</span><span>(</span><span>bindings</span><span>));</span>
  <span>// Get the next binding</span>
  <span>ASTNode</span> <span>*</span><span>binding</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>bindings</span><span>);</span>
  <span>ASTNode</span> <span>*</span><span>name</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>binding</span><span>);</span>
  <span>assert</span><span>(</span><span>AST_is_symbol</span><span>(</span><span>name</span><span>));</span>
  <span>ASTNode</span> <span>*</span><span>binding_expr</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>AST_pair_cdr</span><span>(</span><span>binding</span><span>));</span>
  <span>// ...</span>
</code></pre></div></div>

<p>Once we have the <code>binding_expr</code>, we should compile it. The result will end up
in <code>rax</code>, per our internal compiler convention. We‚Äôll then store it in the next
available stack location:</p>

<div><div><pre><code>  <span>// ...</span>
  <span>// Compile the binding expression</span>
  <span>_</span><span>(</span><span>Compile_expr</span><span>(</span><span>buf</span><span>,</span> <span>binding_expr</span><span>,</span> <span>stack_index</span><span>,</span> <span>binding_env</span><span>));</span>
  <span>Emit_store_reg_indirect</span><span>(</span><span>buf</span><span>,</span> <span>/*dst=*/</span><span>Ind</span><span>(</span><span>kRbp</span><span>,</span> <span>stack_index</span><span>),</span>
                          <span>/*src=*/</span><span>kRax</span><span>);</span>
  <span>// ...</span>
</code></pre></div></div>

<p>We‚Äôre compiling this binding expression in <code>binding_env</code>, the parent
environment, because we don‚Äôt want the previous bindings to be visible.</p>

<p>Once we‚Äôve generated code to store it on the stack, we should register that
stack location with the binding name in the environment:</p>

<div><div><pre><code>  <span>// ...</span>
  <span>// Bind the name</span>
  <span>Env</span> <span>entry</span> <span>=</span> <span>Env_bind</span><span>(</span><span>AST_symbol_cstr</span><span>(</span><span>name</span><span>),</span> <span>stack_index</span><span>,</span> <span>body_env</span><span>);</span>
  <span>// ...</span>
</code></pre></div></div>

<p>Note that we‚Äôre binding it in the <code>body_env</code> because we want this to be
available to the body, but not the other bindings.</p>

<p>At this point we‚Äôve done all the work required for ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bernsteinbear.com/blog/compiling-a-lisp-7/">https://bernsteinbear.com/blog/compiling-a-lisp-7/</a></em></p>]]>
            </description>
            <link>https://bernsteinbear.com/blog/compiling-a-lisp-7/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652842</guid>
            <pubDate>Thu, 01 Oct 2020 16:26:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Data Science Pull Requests‚Äì Review and merge code, data and experiments]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24652832">thread link</a>) | @Dean-DAGsHub
<br/>
October 1, 2020 | https://dagshub.com/blog/data-science-pull-requests/ | <a href="https://web.archive.org/web/*/https://dagshub.com/blog/data-science-pull-requests/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <h3 id="a-step-forward-for-mlops-and-unlocking-open-source-data-science">A step forward for MLOps and unlocking Open Source Data Science</h3><p>Today, we're releasing Data Science Pull Requests (DS PRs), which are Pull Requests (PRs), re-imagined for the data science (DS) workflow. This new capability unlocks a standard review process for data science teams, enabling them to merge data across different branches and accept data contributions across forks. This provides a better collaborative experience for teams in data science organizations and enables truly Open Source Data Science (OSDS) projects. </p><p>For more details, read on...</p><h2 id="introduction">Introduction</h2><p>When we started DAGsHub, we were focused on making data science collaboration possible. Specifically, we deeply <em>care</em> and <em>rely on</em> Open Source Software (OSS), and we set out on a mission to make OSDS as accessible and prevalent as OSS is today.</p><p>This meant that we were concerned about <strong><em>discoverability </em></strong>of data science projects and experiments to work on, <strong><em>understandability</em></strong> of the context of an experiment, <strong><em>reproducibility</em> of </strong>its results, and finally, <strong><em>contributability</em></strong> of code-, data- and models- changed back to the original project.</p><p>When reviewing these processes and the existing solutions some things become clear:</p><ul><li><em><strong>Discoverability </strong></em>means being able to answer the question "<em>What should I do next?</em>" ‚Äì finding a project to work on, and within that project finding what experiments might be interesting or important. <br>It is solved mainly by <strong>experiment tracking</strong> systems, many of them using proprietary or black box formats that are hard to understand and migrate to/from.<p>DAGsHub goes beyond this by creating an experiment tracking system that relies on simple open formats (<code>YAML</code> and <code>CSV</code>). This means you don't need to add obscure lines of code ‚Äì everything works by automatically scanning and analyzing the git commits pushed into the platform.</p></li><li><em><strong>Understandability</strong></em> means being able to answer the question "<em>How should I do what I want to do?</em>" ‚Äì this usually consists of reviewing why, how, and what was already done in a project or experiment. The solution for this step is mostly manual and relies on self-documenting one's work and discussions with collaborators.<p>DAGsHub improves on this by providing a convenient interface into projects' code, data, models, and pipelines which give users a window into their projects' components, and how they interact with each other.</p></li><li><em><strong>Reproducibility</strong></em> means setting up an exact copy of the experiment you want to work on. Many times this process is reduced to a Git commit and the experiment parameters (logged in the experiment tracking system). However, the true standard for reproducibility involves <em><strong>easily </strong></em>retrieving the same version of data, models, and other artifacts. It is best solved by using Git with some dedicated data versioning solution.<p>DAGsHub solves this by relying on open source tools such as Git and DVC to provide the standard discussed above ‚Äì a complete copy of your project (code, data, models, parameters, and other artifacts) with one (or two) commands.</p></li><li><em><strong>Contributability</strong></em> means that you can take a new experiment or result, and incorporate them back into the project you started from so that you don't need to maintain your result separately. Today, this is entirely manual, full of friction, and fundamentally <strong>non-existent</strong>.</li></ul><p>We have many more things to build, but it was clear that one aspect needed to be covered first ‚Äì a <strong><em>CONTRIBUTION </em></strong>mechanism.</p><h2 id="contributing-data-science-pull-requests">Contributing ‚Äì Data Science Pull Requests</h2><p>The final step of the collaborative process is arguably the most important one. Without it, the workflow is one-sided, a monologue, which means collaboration isn't happening. Practically, <strong><em>Contributing</em></strong> can be broken down into two tasks - <strong>reviewing</strong> and <strong>merging </strong>contributions.</p><p>In software, both reviewing and merging are a part of the <strong>pull request</strong> process, but their focus was solely on code. </p><blockquote>Data Science Pull Requests let you <strong>review experiments<u>,</u></strong> <strong>code, data, models, </strong>and your<strong> pipelines</strong>, and <strong><u>merge changes to all of them automatically.</u></strong> </blockquote><h3 id="data-science-review">Data Science Review</h3><p>If you've ever worked on a data science project with other people or tried reviewing someone else's data science work, you know how hard it is to get the information you need to understand someone else's work, or explain your own, so that the review process is meaningful. The process is slow and manual because systems are not built for review.</p><p>An automatic review process means changes and updates can be discussed and integrated faster into your project.<strong> You need to quickly see what has changed, discuss it, in context, and decide how to move forward.</strong></p><p>What this means in practice:</p><ul><li>Commenting on experiments, in context ‚Äì you can look at the new experiments that are being contributed as part of the DS PR, and compare them to the base experiment in the original project. See all the visualization and information, and add comments on these within the PR discussion with links to the relevant comparison/visualization.</li></ul><figure><img src="https://dagshub.com/blog/content/images/2020/09/exp-comment-long-hq.gif" alt="Commenting on experiments"><figcaption>Commenting on experiments in DS PRs</figcaption></figure><ul><li>See what data and models have changed (not just code) ‚Äì view what data, model, and artifact files were added, removed, or modified. This means you can easily pinpoint changes and focus the discussion on what's important.</li></ul><figure><img src="https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png" alt="Viewing data changes in a DAGsHub project" srcset="https://dagshub.com/blog/content/images/size/w600/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png 1000w, https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-18.51.25.png 1189w" sizes="(min-width: 720px) 720px"><figcaption>Data Comparison Example</figcaption></figure><ul><li>Compare and diff notebooks side-by-side ‚Äì notebooks are an important part of many data science projects. However, for a very long time, they haven't received adequate treatment in the review process, relying on diffs to the raw <code>JSON</code> file, which were mostly unreadable. You can now review the changes in an intuitive UI as part of the DS PR. Another benefit of this is that if you require a special visualization, you can commit a notebook with that visualization, and view the changes conveniently.</li></ul><figure><img src="https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png" alt="Notebook comparison" srcset="https://dagshub.com/blog/content/images/size/w600/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 1000w, https://dagshub.com/blog/content/images/size/w1600/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 1600w, https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.04.33.png 2298w" sizes="(min-width: 720px) 720px"><figcaption>Notebook Diffing Example</figcaption></figure><p>After reviewing a collaborator's work, we need a way to incorporate those changes, automatically. That's why we built data science merging.</p><h3 id="data-science-merging">Data Science Merging</h3><p>Merging code is possible with Git, but as we already discussed, that is not the full picture for data science projects. With DS PRs, you can merge your data and other artifacts as well. </p><h4 id="data-merging">Data Merging</h4><p>Everyone knows about bugs in code, but you might also have data bugs that you're not aware of. Examples include data that is not up to date, biased, or mislabeled. Assuming you found out about such a bug and you wanted to fix it ‚Äì that would usually mean you need to agree on and perform some manual operation to update or add new data. With data merging, once you accept a DS PR, the new data would automatically be copied into your project in an entirely automatic process.</p><h4 id="artifact-merging">Artifact Merging</h4><p>This doesn't end with just the <em>raw data ‚Äì </em>data merging lets you merge models and any other artifact of your data pipeline (e.g. preprocessed data or 3d models). Take a case where one of the steps in a pipeline takes 2 weeks to run and results in some trained model or a processed dataset. If only raw data was merged, you'd have to run that excruciating 2-week process again. Artifact merging means that after a DS PR is merged, the resulting project is as reproducible as the original contribution.</p><p>After accepting a DS PR you are in the same state of your DS project, as you would after accepting a PR in a software project.</p><figure><img src="https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png" alt="Data Merging on DAGsHub" srcset="https://dagshub.com/blog/content/images/size/w600/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 600w, https://dagshub.com/blog/content/images/size/w1000/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 1000w, https://dagshub.com/blog/content/images/size/w1600/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 1600w, https://dagshub.com/blog/content/images/2020/09/Screen-Shot-2020-09-25-at-19.23.30.png 1846w" sizes="(min-width: 720px) 720px"><figcaption>Data Science Merging ‚Äì Note that 171 MB of data will be copied on accepting this DS PR</figcaption></figure><p>Data merging means you can accept data and models from contributors with ease, without giving each one full access to your data storage. This can reduce friction and speed up team efforts.</p><p>This last capability is especially useful for OSDS.</p><h2 id="what-does-this-mean-for-osds">What does this mean for OSDS?</h2><p><a href="https://dagshub.com/blog/a-case-for-open-source-data-science/">Open Source Data Science (OSDS) has the potential to have a similar effect on the world</a>, as Open Source Software (OSS) had. It is DAGsHub's stated goal to promote OSDS and build the technology to make it as easy as possible. OSDS must come first, and industry workflows will mirror those in OSDS projects, as they have for OSS. </p><p>But let's face it ‚Äì OSDS doesn't <em>really</em> exist yet. If you maintain some OSDS project and you want to accept contributions from people (like you would for OSS) ‚Äì you have to do it entirely manually or <strong>resort to accepting only code changes</strong> (no way to accept data bug fixes ‚Äì and we all know there are plenty).</p><p>From the individual contributor side, if you want to improve your ML portfolio by contributing to some OSDS project, you're also stuck. You have to either fork the project and not contribute your changes (which means their quality is never reviewed ‚Äì you don't learn as much) or go through a painstaking manual effort<sup>[1]</sup>.</p><blockquote>DS PRs make OSDS possible by providing a standard interface and workflow to review and accept contributions from anyone, anywhere, and for any type of data science component.</blockquote><p><strong>We'd love to support open source data science projects that want to accept data science contributions from the community. Please reach out to us at <a href="mailto:osds@dagshub.com">osds@dagshub.com</a> if this is relevant for you.</strong></p><h2 id="thank-you-">Thank You!</h2><p>Thank you to all the people that gave us feedback before and while we were building DS PRs. We'd love to get your feedback as well on how DS PRs could be improved for the community ‚Äì the best way to do this is to join our <a href="https://discord.com/invite/9gU36Y6">Discord channel</a>. Looking forward to hearing your thoughts and seeing what people build with open source data science.</p><hr><!--kg-card-begin: markdown--><p>
[1] Kaggle is worth a mention here ‚Äì It is a common way to show some of your DS chops. However, it's competitive (as opposed to collaborative). Furthermore, data science projects in the wild rarely have one all-encompassing metric to optimize at the expense of everything else - 80% of the work is just gathering data and deciding what is even worth optimizing! 
Our goal with DAGsHub is to enable a collaborative way to showcase your capabilities while encouraging interoperability ‚Äì i.e. working together rather than everyone doing their own thing and ending up with a ton of fragmentation.
</p><!--kg-card-end: markdown-->
                <section>
                  
                  <ul>
                      <li>
                        <a href="https://dagshub.com/blog/tag/data-science/" title="Data Science">Data Science</a>
                      </li>
                      <li>
                        <a href="https://dagshub.com/blog/tag/data-science-workflow/" title="Data Science Workflow">Data Science Workflow</a>
                      </li>
                      <li>
               ‚Ä¶</li></ul></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dagshub.com/blog/data-science-pull-requests/">https://dagshub.com/blog/data-science-pull-requests/</a></em></p>]]>
            </description>
            <link>https://dagshub.com/blog/data-science-pull-requests/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652832</guid>
            <pubDate>Thu, 01 Oct 2020 16:26:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A look at PostGIS vs. Geocoder in Rails]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24652608">thread link</a>) | @leighhalliday
<br/>
October 1, 2020 | https://pganalyze.com/blog/postgis-rails-geocoder | <a href="https://web.archive.org/web/*/https://pganalyze.com/blog/postgis-rails-geocoder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>
This article sets out to compare PostGIS in Rails with Geocoder and to highlight a couple of the areas where you'll want to (or need to) reach for one over the other. I will also present some of the terminology and libraries that I found along the way of working on this project and article as I set out to understand PostGIS better and how it is integrated with Rails.</p>

<p><span>
      <span></span>
  <img alt="PostGIS vs. Geocoder in Rails" title="PostGIS vs. Geocoder in Rails" src="https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/29d31/postgis_rails_geocoder_pganalyze.jpg" srcset="https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/e52aa/postgis_rails_geocoder_pganalyze.jpg 175w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/70ebb/postgis_rails_geocoder_pganalyze.jpg 350w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/29d31/postgis_rails_geocoder_pganalyze.jpg 700w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/9ecec/postgis_rails_geocoder_pganalyze.jpg 1050w, https://pganalyze.com/static/383f2659b144f300d98f78a94aefe750/e5166/postgis_rails_geocoder_pganalyze.jpg 1200w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
    </span>
Picture via <a href="https://unsplash.com/@anniespratt">Annie Spratt</a> on Unsplash</p>
<p>I have built a number of Rails applications over the years that show locations on a map, have nearby search functionality, and I had never used <a href="https://postgis.net/">PostGIS</a> before! How was this possible? The reason is that there is a Ruby gem named <a href="https://github.com/alexreisner/geocoder">Geocoder</a> which enables you to do these sorts of queries, and it's quite efficient! That said, there is a reason that PostGIS exists. For more complex geo queries I‚Äôd recommend reaching beyond Geocoder to PostGIS.</p>
<p>As an example, if you wanted to find homes which have a school within 1km of them, or if you wanted to draw an oddly shaped polygon on a map and search within it, this is the world where PostGIS shines and makes these complex geo queries possible.</p>
<p>In this article we will be covering:</p>
<ul>
<li>PostGIS in Rails setup</li>
<li>Finding nearby records (Geocoder + PostGIS)</li>
<li>Finding records within a bounding box (Geocoder + PostGIS)</li>
<li>Finding records within a polygon (PostGIS)</li>
<li>Finding nearby related records (PostGIS)</li>
</ul>
<p>The source code referenced in this article can be <a href="https://github.com/pganalyze-resources/rails-postgis-demo">found here</a>.</p>
<h2 id="installing-postgis"><a href="#installing-postgis" aria-label="installing postgis permalink"></a>Installing PostGIS</h2>
<p>Postgres comes with a number of built-in extensions that you can enable, but unfortunately PostGIS (Spatial and Geographic objects for Postgres) isn't one of them. In order to enable this extension, you will have to use a Postgres install with PostGIS support. I recommend using the <a href="https://registry.hub.docker.com/r/postgis/postgis">official postgis docker image</a>, but luckily many hosted Postgres solutions come with PostGIS already available. If you are not sure, you can query the available extensions with the following query:</p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span>
<span>from</span> pg_available_extensions
<span>where</span> name <span>like</span> <span>'%postgis%'</span></code></pre></div>
<p>If you'd like to see if the extension is <em>already</em> enabled, you can run this query:</p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span> <span>from</span> pg_extension</code></pre></div>
<p>And finally, to enable this extension, you can use the command <code>create extension postgis</code>, but since we're working within Rails, there is a Gem that will take care of this step for us as we'll see below.</p>
<h2 id="activerecord-postgis-adapter"><a href="#activerecord-postgis-adapter" aria-label="activerecord postgis adapter permalink"></a>ActiveRecord PostGIS Adapter</h2>
<p>If you have confirmed that your version of Postgres supports the <code>postgis</code> extension, you're ready to integrate it with your Rails application. This can be done by using the <a href="https://github.com/rgeo/activerecord-postgis-adapter">activerecord-postgis-adapter</a> gem. Two things need to be done to get up and running. The first is to update the <code>adapter</code> within <code>config/database.yml</code> to be set to <code>postgis</code>. Next, if this is a new application, you can run <code>rails db:create</code> as normal, but if it is an existing one, you'll have to run the command <code>rake db:gis:setup</code>. This command is enabling the postgis extension in your database.</p>
<h2 id="our-example-data"><a href="#our-example-data" aria-label="our example data permalink"></a>Our Example Data</h2>
<p>We'll be working with sample data for a realtor website that allows us to find homes in a variety of ways, including homes that are nearby a local school. There are two models: <code>homes</code> and <code>schools</code>. The Rails migration to create these tables is below:</p>
<div data-language="ruby"><pre><code><span>class</span> <span>CreateHomes</span> <span>&lt;</span> <span>ActiveRecord</span><span>:</span><span>:</span><span>Migration</span><span>[</span><span>6.0</span><span>]</span>
  <span>def</span> <span><span>change</span></span>
    create_table <span>:homes</span> <span>do</span> <span>|</span>t<span>|</span>
      t<span>.</span>string <span>:name</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>string <span>:status</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>bigint <span>:price</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>integer <span>:beds</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> default<span>:</span> <span>0</span>
      t<span>.</span>integer <span>:baths</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> default<span>:</span> <span>0</span>
      t<span>.</span>st_point <span>:coords</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> geographic<span>:</span> <span>true</span>
      t<span>.</span>float <span>:longitude</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>float <span>:latitude</span><span>,</span> null<span>:</span> <span>false</span>
      t<span>.</span>timestamps

      t<span>.</span>index <span>:coords</span><span>,</span> using<span>:</span> <span>:gist</span>
      t<span>.</span>index <span>%i[latitude longitude]</span>
      t<span>.</span>index <span>:status</span>
      t<span>.</span>index <span>:price</span>
    <span>end</span>

    create_table <span>:schools</span> <span>do</span> <span>|</span>t<span>|</span>
      t<span>.</span>st_point <span>:coords</span><span>,</span> null<span>:</span> <span>false</span><span>,</span> geographic<span>:</span> <span>true</span>

      t<span>.</span>index <span>:coords</span><span>,</span> using<span>:</span> <span>:gist</span>
      t<span>.</span>timestamps
    <span>end</span>
  <span>end</span>
<span>end</span></code></pre></div>
<p>By using <code>activerecord-postgis-adapter</code> we are able to define PostGIS columns within our migration file. When working with PostGIS you can store a point (latitude + longitude) as a single column of type <code>ts_point</code>, whereas when working with <a href="https://github.com/alexreisner/geocoder">Geocoder</a> the latitude and longitude are stored as floats in separate columns. Because we are comparing the two approaches, we will store the data both ways, but typically you would choose one approach or the other.</p>
<p>PostGIS <strong>geographic</strong> columns can be indexed using <a href="https://www.postgresql.org/docs/current/gist-intro.html">GiST</a> style indexes. GiST indexes are required over B-Tree indexes when working with geographic data because coordinates cannot be easily sorted along a single axis (such as numbers, letters, dates, etc...) in a way that would allow the database to speed up common geographic operations.</p>
<p>The example project for this article contains a seeds file (run with <code>rake db:seed</code>) which will generate 100k homes and 100 schools in and around the Atlanta, Georgia area.</p>
<h2 id="building-a-geo-helper-class-with-postgis"><a href="#building-a-geo-helper-class-with-postgis" aria-label="building a geo helper class with postgis permalink"></a>Building a Geo Helper Class with PostGIS</h2>
<p>The Rails PostGIS adapter is based on a library named <a href="https://github.com/rgeo/rgeo">RGeo</a>, which while incredibly powerful, I found a little bit confusing due to a lack of documentation. I ended up building a small helper class to generate different geo objects for me. The first thing to point out is what <a href="https://en.wikipedia.org/wiki/Spatial_reference_system">SRID</a> is. Just like the imperial and metric systems are used to measure and weigh amounts using an agreed upon reference point, coordinates also need a coordinate reference system to ensure that the latitude and longitude that one uses means the same thing to different people when referring to a single place on earth. <a href="https://spatialreference.org/ref/epsg/wgs-84/">4326</a> is the spatial system used for GPS satellite navigation systems and the one we will be using within this article.</p>
<p>One last thing to define is what <a href="https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry">WKT</a> is. Well-known Text representation of geometry is a string representation of a point, line string, and polygon (among other things) that we will be using in our examples in this article. This is the format Postgres (PostGIS) receives and displays geographic data types in.</p>
<div data-language="ruby"><pre><code><span>class</span> <span>Geo</span>
  <span>SRID</span> <span>=</span> <span>4326</span>

  <span>def</span> <span><span>self</span><span>.</span><span>factory</span></span>
    <span>@@factory</span> <span>||</span><span>=</span> <span>RGeo</span><span>:</span><span>:</span><span>Geographic</span><span>.</span>spherical_factory<span>(</span>srid<span>:</span> <span>SRID</span><span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>pairs_to_points</span></span><span>(</span>pairs<span>)</span>
    pairs<span>.</span>map <span>{</span> <span>|</span>pair<span>|</span> point<span>(</span>pair<span>[</span><span>0</span><span>]</span><span>,</span> pair<span>[</span><span>1</span><span>]</span><span>)</span> <span>}</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>point</span></span><span>(</span>longitude<span>,</span> latitude<span>)</span>
    factory<span>.</span>point<span>(</span>longitude<span>,</span> latitude<span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>line_string</span></span><span>(</span>points<span>)</span>
    factory<span>.</span>line_string<span>(</span>points<span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>polygon</span></span><span>(</span>points<span>)</span>
    line <span>=</span> line_string<span>(</span>points<span>)</span>
    factory<span>.</span>polygon<span>(</span>line<span>)</span>
  <span>end</span>

  <span>def</span> <span><span>self</span><span>.</span><span>to_wkt</span></span><span>(</span>feature<span>)</span>
    <span>"srid=<span><span>#{</span><span>SRID</span><span>}</span></span>;<span><span>#{</span>feature<span>}</span></span>"</span>
  <span>end</span>
<span>end</span></code></pre></div>
<h2 id="finding-nearby-records-with-postgis-and-geocoder"><a href="#finding-nearby-records-with-postgis-and-geocoder" aria-label="finding nearby records with postgis and geocoder permalink"></a>Finding Nearby Records with PostGIS and Geocoder</h2>
<p>One of the most common geo queries used in applications is to find all records within X distance from a known point (the user's location, an event, a search, etc...). Because we installed <code>Geocoder</code> and added <code>reverse_geocoded_by :latitude, :longitude</code> to our <code>Home</code> class, we can use the <code>nearby</code> method to find all homes within 5km of this latitude and longitude (which happens to be Atlanta, Georgia). Geocoder likes to have arrays with latitude and then longitude, as opposed to PostGIS which <strong>prefers the exact opposite</strong> order!</p>
<div data-language="ruby"><pre><code><span>Home</span><span>.</span>near<span>(</span><span>[</span><span>33.753746</span><span>,</span> <span>-</span><span>84.386330</span><span>]</span><span>,</span> <span>5</span><span>)</span><span>.</span>count<span>(</span><span>:all</span><span>)</span> </code></pre></div>
<p>This query ran in about 5ms on my computer (searching through 100k records)... pretty fast! The reason it is fast is because we added an index on the latitude and longitude fields, but also because Geocoder applies a bounding box filter which utilises the index. Remember the Spatial Reference System (SRID) that we mentioned above? Because our coordinates do not take place on a <a href="https://en.wikipedia.org/wiki/Cartesian_coordinate_system">Cartesian plane</a>, we can‚Äôt use a standard distance formula to calculate the <a href="https://www.mathsisfun.com/algebra/distance-2-points.html">distance between two points</a>. Although we won‚Äôt venture further into the math of this query below, it takes into consideration the Earth‚Äôs spherical nature when calculating the distance between two coordinates as specified by latitude and longitude. <a href="https://www.movable-type.co.uk/scripts/latlong.html">This article</a> dives into more detail on these calculations if you are interested.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>FROM</span> <span>"homes"</span> <span>WHERE</span> <span>(</span>homes<span>.</span>latitude <span>BETWEEN</span> <span>33.708779919704064</span> <span>AND</span> <span>33.798712080295935</span> <span>AND</span> homes<span>.</span>longitude <span>BETWEEN</span> <span>-</span><span>84.44041260768655</span> <span>AND</span> <span>-</span><span>84.33224739231345</span> <span>AND</span> <span>(</span><span>6371.0</span> <span>*</span> <span>2</span> <span>*</span> ASIN<span>(</span>SQRT<span>(</span>POWER<span>(</span>SIN<span>(</span><span>(</span><span>33.753746</span> <span>-</span> homes<span>.</span>latitude<span>)</span> <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span> <span>/</span> <span>2</span><span>)</span><span>,</span> <span>2</span><span>)</span> <span>+</span> COS<span>(</span><span>33.753746</span> <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span><span>)</span> <span>*</span> COS<span>(</span>homes<span>.</span>latitude <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span><span>)</span> <span>*</span> POWER<span>(</span>SIN<span>(</span><span>(</span><span>-</span><span>84.38633</span> <span>-</span> homes<span>.</span>longitude<span>)</span> <span>*</span> PI<span>(</span><span>)</span> <span>/</span> <span>180</span> <span>/</span> <span>2</span><span>)</span><span>,</span> <span>2</span><span>)</span><span>)</span><span>)</span><span>)</span> <span>BETWEEN</span> <span>0.0</span> <span>AND</span> <span>5</span><span>)</span></code></pre></div>
<p>We'll have to build our own <code>near</code> query when working with PostGIS, but don't worry, it's pretty straight forward! The <code>g_near</code> method lives within the <code>Home</code> model, and takes advantage of the <a href="https://postgis.net/docs/ST_DWithin.html">ST_DWithin</a> function provided by PostGIS. Remember that we have to convert our point into the correct WKT format so that PostGIS understands the data we are passing it.</p>
<div data-language="ruby"><pre><code><span>def</span> <span><span>self</span><span>.</span><span>g_near</span></span><span>(</span>point<span>,</span> distance<span>)</span>
  where<span>(</span>
    <span>'ST_DWithin(coords, :point, :distance)'</span><span>,</span>
    <span>{</span> point<span>:</span> <span>Geo</span><span>.</span>to_wkt<span>(</span>point<span>)</span><span>,</span> distance<span>:</span> distance <span>*</span> <span>1000</span> <span>}</span> 
  <span>)</span>
<span>end</span>

<span>Home</span><span>.</span>g_near<span>(</span><span>Geo</span><span>.</span>point<span>(</span><span>-</span><span>84.386330</span><span>,</span> <span>33.753746</span><span>)</span><span>,</span> <span>5</span><span>)</span><span>.</span>count </code></pre></div>
<p>This query performs just about as fast as the Geocoder version (because of our GiST index on the <code>coords</code> column), but is definitely a little easier on the eyes to read.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>FROM</span> <span>"homes"</span> <span>WHERE</span> <span>(</span>ST_DWithin<span>(</span>coords<span>,</span> <span>'srid=4326;POINT (-84.38633 33.753746)'</span><span>,</span> <span>5000</span><span>)</span><span>)</span></code></pre></div>
<h2 id="finding-records-within-a-bounding-box-with-postgis-and-geocoder"><a href="#finding-records-within-a-bounding-box-with-postgis-and-geocoder" aria-label="finding records within a bounding box with postgis and geocoder permalink"></a>Finding Records Within a Bounding Box with PostGIS and Geocoder</h2>
<p>Geocoder provides us a way to find all records within a bounding box (roughly a rectangle, ignoring projection onto a sphere), and we just have to pass it the bottom left (south west) and top right (north east) coordinates.</p>
<div data-language="ruby"><pre><code><span>Home</span><span>.</span>within_bounding_box<span>(</span>
  <span>[</span><span>33.7250057553</span><span>,</span> <span>-</span><span>84.4224209302</span><span>]</span><span>,</span>
  <span>[</span><span>33.774350796</span><span>,</span> <span>-</span><span>84.3570139222</span><span>]</span>
<span>)</span><span>.</span>count </code></pre></div>
<p>Because it can use the index on latitude and longitude, it is quite efficient.</p>
<div data-language="sql"><pre><code><span>SELECT</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>FROM</span> <span>"homes"</span> <span>WHERE</span> <span>(</span>homes<span>.</span>latitude <span>BETWEEN</span> <span>33.7250057553</span> <span>AND</span> <span>33.774350796</span> <span>AND</span> homes<span>.</span>longitude <span>BETWEEN</span> <span>-</span><span>84.4224209302</span> <span>AND</span> <span>-</span><span>84.3570139222</span><span>)</span></code></pre></div>
<p>To perform a bounding box query using PostGis, we'll create a method named <code>g_within_box</code> inside of the <code>Home</code> model, and utilize a PostGIS function named <a href="https://postgis.net/docs/ST_MakeEnvelope.html">ST_MakeEnvelope</a> along with the <code>&amp;&amp;</code> operator.</p>
<div data-language="ruby"><pre><code><span>def</span> <span><span>self</span><span>.</span><span>g_within_box</span></span><span>(</span>sw_point<span>,</span> ne_point<span>)</span>
  where<span>(</span>
    <span>"coords &amp;&amp; ST_MakeEnvelope(:sw_lon, ‚Ä¶</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pganalyze.com/blog/postgis-rails-geocoder">https://pganalyze.com/blog/postgis-rails-geocoder</a></em></p>]]>
            </description>
            <link>https://pganalyze.com/blog/postgis-rails-geocoder</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652608</guid>
            <pubDate>Thu, 01 Oct 2020 16:11:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building your own air pollution monitor with a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24652488">thread link</a>) | @stevenhubertron
<br/>
October 1, 2020 | https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
	<article>
		<div>

			<section>
				<p>With all the wildfires happening around the US this summer (2020) I finally got motivated enough to put together an air quality monitor home base station to see air quality in person, on the web and on my phone. &nbsp;If you has a Raspberry Pi plus a few other items you can set this up in an afternoon. I have it tuned to measure PM1.0, PM2.5, PM10, and Carbon Monoxide inside my house. </p><p>As an example, here is what I see in my Adafruit Dashboard</p><figure><img src="https://www.drkpxl.com/content/images/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png" alt="" srcset="https://www.drkpxl.com/content/images/size/w600/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 600w, https://www.drkpxl.com/content/images/size/w1000/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 1000w, https://www.drkpxl.com/content/images/size/w1600/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 1600w, https://www.drkpxl.com/content/images/2020/09/Screen-Shot-2020-09-14-at-2.54.09-PM.png 2024w" sizes="(min-width: 720px) 720px"><figcaption>My Adafruit dashboard.&nbsp;</figcaption></figure><p>I already had most of the the supplies but here is a list of what you will need:</p><ul><li><a href="https://shop.pimoroni.com/products/raspberry-pi-zero-wh-with-pre-soldered-header">Raspberry Pi Zero WH</a></li><li><a href="https://shop.pimoroni.com/products/enviro?variant=31155658489939">Enviro+</a></li><li><a href="https://shop.pimoroni.com/products/pms5003-particulate-matter-sensor-with-cable">PMS50003</a> Particulate Matter Sensor with cable</li><li>A free <a href="https://io.adafruit.com/">Adafruit IO</a> account</li></ul><p>Once you get it all plugged into, the Enviro+ into the Pi, and the PMS5003 into the Enviropi you can get the OS setup with a standard install.</p><p>I'll assume you know how to get Raspberry setup on your PI as well as SSH into it. If not there are a great number of <a href="https://desertbot.io/blog/headless-raspberry-pi-4-ssh-wifi-setup">tutorials</a> <a href="https://www.tomshardware.com/reviews/raspberry-pi-headless-setup-how-to,6028.html">out</a> <a href="https://medium.com/@jay_proulx/headless-raspberry-pi-zero-w-setup-with-ssh-and-wi-fi-8ddd8c4d2742">there</a>.</p><p>Once you are SSHed in, you can follow along with the instructions on the Pimoroni site or just run this script after an <code>apt upgrade</code> and <code>apt update</code></p><pre><code>git clone https://github.com/pimoroni/enviroplus-python
cd enviroplus-python
sudo ./install.sh</code></pre><p>This will install all the various code and samples to get playing with the sensors. The Enviro+ has a bunch of different sensors and LCDs in one making it extremely easy.</p><p>My goals for the setup are:</p><figure><img src="https://www.drkpxl.com/content/images/2020/09/IMG_5163-1.jpg" alt="" srcset="https://www.drkpxl.com/content/images/size/w600/2020/09/IMG_5163-1.jpg 600w, https://www.drkpxl.com/content/images/size/w1000/2020/09/IMG_5163-1.jpg 1000w, https://www.drkpxl.com/content/images/2020/09/IMG_5163-1.jpg 1500w" sizes="(min-width: 720px) 720px"></figure><h3 id="lcd">LCD</h3><p>The LCD displays PM10, PM2.5 and PM1, temp, and noise level on the screen by default. If the pollution spikes, or the gas spikes the LCD will turn red and display a warning.</p><h3 id="adafruit-io">Adafruit IO</h3><p>All the LCD data <strong>plus</strong> Carbon Monoxide, CPU Temp, and CPU load so that I just have a view that everything is healthy on the Pi.</p><figure><img src="https://www.drkpxl.com/content/images/2020/09/IMG_5168.jpg" alt="" srcset="https://www.drkpxl.com/content/images/size/w600/2020/09/IMG_5168.jpg 600w, https://www.drkpxl.com/content/images/size/w1000/2020/09/IMG_5168.jpg 1000w, https://www.drkpxl.com/content/images/2020/09/IMG_5168.jpg 1123w" sizes="(min-width: 720px) 720px"></figure><h3 id="ifttt">IFTTT</h3><p>Push alerts to high pollution or gas to my phone so I can be notified immediately if something is at issue.</p><h2 id="key-code-snippets">Key Code Snippets</h2><h3 id="get-the-cpu-temp">Get the CPU Temp</h3><figure><pre><code>def cpu_report_func():
    # Get CPU Info
    cpu = CPUTemperature()
    aio.send('cpu-temp', round(cpu.temperature * 1.8 + 32))
    aio.send('cpu', psutil.cpu_percent())</code></pre><figcaption>Get CPU temp, convert to F and send both temp and usage to Adafruit</figcaption></figure><h3 id="get-noise">Get Noise</h3><figure><pre><code>def noise_func():
    # Get Noise
    global noise_amount, noise_display
    noise_amount = noise.get_amplitude_at_frequency_range(20, 8000)
    noise_display = str(int(round(noise_amount * 100))) + " db"
    aio.send('noise', int(round(noise_amount * 100)))</code></pre><figcaption>Get noise within a wide range, round it and send off to display and Adafruit</figcaption></figure><h3 id="get-ambient-temps-w-corrections">Get Ambient Temps w/ Corrections</h3><pre><code>def temp_func():
    # Read Temp, convert to F and adjust
    global tempf_display
    # Tuning factor for compensation. Decrease this number to adjust the
    # temperature down, and increase to adjust up
    factor = 0.6

    cpu_temp = CPUTemperature().temperature
    cpu_temps.append(cpu_temp)
    avg_cpu_temp = sum(cpu_temps) / float(len(cpu_temps))
    raw_temp = bme280.get_temperature()
    comp_temp = raw_temp - ((avg_cpu_temp - raw_temp) / factor)
    # Convert to America
    tempf = round(comp_temp * 1.8 + 32)
    
    tempf_display = "" + str(tempf) + " F"
    print(tempf_display)

    # Clean up Array so it doesn't overflow memory
    if (len(cpu_temps) &gt; 10):
        cpu_temps.pop(0)
        aio.send('temp', tempf)</code></pre><p>The thing you would think would be the easiest is actually the hardest due mainly to the fact the themometer is so close to the CPU that it's picking up ambient heat from it. What this does (and is heavily cribbed from the Pimoroni example) is use the CPU temp as a baseline measure that fills up an array, correct for it and convert it to F. Since this "app" is basically one big loop I want to clear the array out after 10 readings or 10 minutes. That should give me enough history to get a good average and the temps I see pass the gut check. </p><p>The <code>factor</code> float may need to be adjusted for your specfic needs. For example if you don't have the Pi in a Lego case, or have different airflow the factor you need to adjust it to may need to be different. </p><h3 id="get-gas-specfically-reducing-aka-carbon-monoxide">Get Gas, specfically Reducing AKA Carbon Monoxide </h3><figure><pre><code>def gas_func():
    global gas_reading, gas_average, gas_warning_amount
    # Get Gas
    gas_reading = gas.read_all()
    gas_array.append(gas_reading.reducing)
    # If the array is larger than 8 items dump the first one
    if (len(gas_array) &gt; 8):
        gas_array.pop(0)
        #print("Popped!")
        aio.send('gas', round(gas_reading.reducing))
    gas_average = (sum(gas_array) / len(gas_array))
    gas_warning_amount = str(round(gas_reading.reducing))
</code></pre><figcaption>Get an average gas reading, current reading and send to Adafruit</figcaption></figure><h3 id="get-air-pollution">Get Air Pollution</h3><figure><pre><code>def pollution_func():
    global pm25, pm10_display, pm25_display, pm1_display
    # Read Particulate Matter
    readings = pms5003.read()
    pm25 = readings.pm_ug_per_m3(2.5)
    pm10 = readings.pm_ug_per_m3(10)
    pm1 = readings.pm_ug_per_m3(1)
    # Send to Adafruit
    aio.send('pollution.pm25', pm25)
    aio.send('pollution.pm1', pm1)
    aio.send('pollution.pm10', pm10)
    # Draw on Screen
    pm10_display = "PM10: " + str(pm10) + " ug/m3"
    pm25_display = "PM25: " + str(pm25) + " ug/m3"
    pm1_display = "PM10: " + str(pm1) + " ug/m3"</code></pre><figcaption>Get the standard ug/m3 readings, send to Adafruit and display</figcaption></figure><h3 id="display-logic">Display Logic</h3><pre><code># Display output of sensors on display
        disp.set_backlight(1)
        if (gas_reading.reducing &gt; (gas_average * 1.05) and len(gas_array) == 8):
            print("High Pollution Warning")
            draw.rectangle((0, 0, 160, 80), (255, 0, 0))
            draw.text((10, 20), warning, font=font, fill=text_colour)
            draw.text((10, 40), gas_warning_amount, font=font, fill=text_colour)
        elif (pm25 &gt; 50):
            draw.rectangle((0, 0, 160, 80), (255, 0, 0))
            draw.text((10, 20), warning, font=font, fill=text_colour)
            draw.text((10, 40), pm25_display, font=font, fill=text_colour)
        else:
            draw.rectangle((0, 0, 160, 80), back_colour)
            draw.text((0, 0), pm10_display, font=font, fill=text_colour)
            draw.text((0, 20), pm25_display, font=font, fill=text_colour)
            draw.text((0, 40), pm1_display, font=font, fill=text_colour)
            draw.text((0, 60), tempf_display, font=font, fill=text_colour)
            draw.text((80, 60), noise_display, font=font, fill=text_colour)
        disp.display(img)
        time.sleep(60)</code></pre><p>This is a basic if else statement that has the following rules:</p><ul><li>If gas is higher than the average + 5% (indicating a spike) push an alarm to the Pi's display</li><li>If gas is ok, but PM2.5 pikes over 50 push an alarm to the Pi's display</li><li>Otherwise just show the PM numbers, Temp and Noise</li></ul><p>As you can see it's all pretty straightforward code in one big loop. If you just copy and paste the code following, add your Adafruit key, and do some additional setup in Adafruit IO you can have this up and running very quickly.</p><h2 id="the-complete-code">The Complete Code</h2><pre><code>import psutil
from gpiozero import CPUTemperature
import time
import datetime
from Adafruit_IO import Client
from bme280 import BME280
from enviroplus.noise import Noise
import colorsys
import sys
import ST7735
try:
    # Transitional fix for breaking change in LTR559
    from ltr559 import LTR559
    ltr559 = LTR559()
except ImportError:
    import ltr559

try:
    from smbus2 import SMBus
except ImportError:
    from smbus import SMBus


from pms5003 import PMS5003, ReadTimeoutError as pmsReadTimeoutError, SerialTimeoutError
from enviroplus import gas
from subprocess import PIPE, Popen
from PIL import Image
from PIL import ImageDraw
from PIL import ImageFont
from fonts.ttf import RobotoMedium as UserFont
from datetime import timedelta



# Initial Setup of sensors / API
bus = SMBus(1)
bme280 = BME280(i2c_dev=bus)
aio = Client('XXX', 'aio_XXX')
pms5003 = PMS5003()
noise = Noise()

# Create LCD class instance.
disp = ST7735.ST7735(
    port=0,
    cs=1,
    dc=9,
    backlight=12,
    rotation=270,
    spi_speed_hz=10000000
)

# Create array for averages
gas_array = []
cpu_temps = []

# Initialize display.
disp.begin()

# Width and height to calculate text position.
WIDTH = disp.width
HEIGHT = disp.height

# New canvas to draw on.
img = Image.new('RGB', (WIDTH, HEIGHT), color=(0, 0, 0))
draw = ImageDraw.Draw(img)

# Text settings.
font_size = 20
small_font_size = 12
font = ImageFont.truetype(UserFont, font_size)
small_font = ImageFont.truetype(UserFont, small_font_size)
text_colour = (255, 255, 255)
back_colour = (0, 0, 0)
#size_x, size_y = draw.textsize(message, font)
warning = "Warning!"

# Calculate text position
#x = (WIDTH - size_x) / 2
#y = (HEIGHT / 2) - (size_y / 2)
x = 0
y = 0


def warm_func():
    currentTime = datetime.datetime.now()
    draw.rectangle((0, 0, 160, 80), (30, 160, 30))
    draw.text((10, 20), "Warming Up", font=font, fill=text_colour)
    draw.text((0, 66), currentTime.strftime("%a, %b %d %I:%M:%S %p"), font=small_font, fill=text_colour)
    disp.display(img)
    print("Warming Up at " + currentTime.strftime("%a, %b %d %I:%M:%S %p"))

def cpu_report_func():
    # Get CPU Info
    cpu = CPUTemperature()
    aio.send('cpu-temp', round(cpu.temperature * 1.8 + 32))
    aio.send('cpu', psutil.cpu_percent())

def noise_func():
    # Get Noise
    global noise_amount, noise_display
    noise_amount = noise.get_amplitude_at_frequency_range(20, 8000)
    noise_display = str(int(round(noise_amount * 100))) + " db"
    aio.send('noise', int(round(noise_amount * 100)))

def temp_func():
    # Read Temp, convert to F and adjust
    global tempf_display
    # Tuning factor for compensation. Decrease this number to adjust the
    # temperature down, and increase to adjust up
    factor = 0.6

    cpu_temp = CPUTemperature().temperature
    #print("CPU Temp: " + str(cpu_temp))
    cpu_temps.append(cpu_temp)
    avg_cpu_temp = sum(cpu_temps) / float(len(cpu_temps))
    raw_temp = bme280.get_temperature()
    comp_temp = raw_temp - ((avg_cpu_temp - raw_temp) / factor)
    # Convert to America
    tempf = round(comp_temp * 1.8 + 32)
    
    tempf_display = "" + str(tempf) + " F"
    print(tempf_display)

    # Clean up Array ‚Ä¶</code></pre></section></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/">https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/</a></em></p>]]>
            </description>
            <link>https://www.drkpxl.com/pollution-gas-and-noise-monitoring-with-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652488</guid>
            <pubDate>Thu, 01 Oct 2020 16:03:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testing TikTok‚Äôs multi-billion dollar algorithm]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651822">thread link</a>) | @ailon
<br/>
October 1, 2020 | https://blog.ailon.org/testing-tiktoks-multi-billion-dollar-algorithm-af38fdd8225?source=friends_link&sk=a736bbdd904768fa4d7bcfb536615573 | <a href="https://web.archive.org/web/*/https://blog.ailon.org/testing-tiktoks-multi-billion-dollar-algorithm-af38fdd8225?source=friends_link&sk=a736bbdd904768fa4d7bcfb536615573">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p id="aae4">Almost a month ago my wife wanted to register on TikTok and was experiencing some odd difficulties. As our family‚Äôs tech-support person I ended up registering myself in the process of helping her. After posting a random TikTok (again, to help with some issues) I realized that it‚Äôs a good opportunity to put TikTok‚Äôs mighty algorithm to the test.</p><p id="8ee7">Since I went deep(ish) into my music making hobby this year, I decided to make <a href="https://www.tiktok.com/@ailonid" rel="noopener">my TikTok</a> focused on that. Both as a content consumer and creator. To try to preserve the ‚Äúpurity‚Äù of the experiment I decided not to tell anyone about my TikTok for the duration of this experiment. Well, my wife knew, obviously, and ‚Äúcontaminated‚Äù the results a bit. But I don‚Äôt think that was a major factor. So, here‚Äôs what I find out‚Ä¶</p><h2 id="168f">TikTok‚Äôs Algorithm for Consumers</h2><p id="571d">In the onboarding process you get asked very little. You pick some very wide-ranging themes of interest like entertainment, sports, music, etc. And that‚Äôs about it. Not surprisingly the initial experience is quite random ‚Äî you get a bunch of half-naked beautiful people, kitty-puppy videos, poor dad joke reenactments and alike.</p><p id="c9fc">I tried not to ‚Äúlike‚Äù any of the above and not to follow any celebrities. I went into search and tried to look up people posting TikToks about music production, music theory, audio engineering, music business and similar. After I followed a bunch of those not much changed in the first couple of days. But then my ‚ÄúFor You‚Äù feed (TikTok‚Äôs algorithmic feed) improved dramatically and became quite on-point.</p><p id="8d99">Interestingly, I was traveling for a couple of days (yes, this still happens once in a while in our neck of the woods) and didn‚Äôt use TikTok for a day or two. When I launched it after the break I got quite an increase in ‚Äúfunny‚Äù videos again. I guess this is AI‚Äôs idea of how to best ‚Äúreactivate‚Äù churning users. But after a day or two it got back to my regular programming.</p><p id="a2bb">So, from the consumer‚Äôs side the algorithm works quite well. On the other hand, so does the algorithm on YouTube or Instagram. As <a href="https://twitter.com/mattcutts" rel="noopener">Matt Cutts</a> (one of the early Googlers) <a href="https://youtu.be/kpmbptHDVJg?t=1335" rel="noopener">said on TWiT</a>:</p><blockquote><p id="8242">You can probably do a pretty good approximation [of TikTok‚Äôs algorithm] in like a thousand lines of code. You are looking for engagement, you are looking for growth, you are looking at the first derivative‚Ä¶ it‚Äôs gonna be pretty simple‚Ä¶</p></blockquote><p id="4112">In any case, it does work fine but this wasn‚Äôt the most interesting part to me. I‚Äôd be more surprised if it didn‚Äôt work well for consumers.</p><p id="cde4">What I was more interested in is the constant stream of raving comments on how well it works for creators ‚Äî ‚Äúnobodies‚Äù can reach millions with a good video, they said. Let‚Äôs see how that works‚Ä¶</p><h2 id="3e43">TikTok‚Äôs Algorithm for Creators</h2><p id="1833">I tried to post TikToks regularly. Not exactly every day but so far I posted 17 videos in about 4 weeks.</p><p id="8bc1">Quite obviously TikTok‚Äôs ‚Äúhook‚Äù is that they over-expose TikToks from newbies and make you feel really good in your first few days. (How do they deal with bots and trolls trying to abuse this is an interesting question but beside the point here.) My first 5 TikToks (the first one was just a random test) got between 500 and 700 views. Not bad for someone with 1 follower. But then the views started to go down.</p><p id="2433">Obviously, I didn‚Äôt produce any stunning content and I don‚Äôt think I deserve more views from the algorithm pushing me. But I‚Äôve noticed something peculiar‚Ä¶</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2070/1*TlzZOu5ZTizu7xsCT9oaNQ.png" width="1035" height="483" srcset="https://miro.medium.com/max/552/1*TlzZOu5ZTizu7xsCT9oaNQ.png 276w, https://miro.medium.com/max/1104/1*TlzZOu5ZTizu7xsCT9oaNQ.png 552w, https://miro.medium.com/max/1280/1*TlzZOu5ZTizu7xsCT9oaNQ.png 640w, https://miro.medium.com/max/1400/1*TlzZOu5ZTizu7xsCT9oaNQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*TlzZOu5ZTizu7xsCT9oaNQ.png?q=20"></p></div></div></div><figcaption>Typical stats for most of my recent TikToks</figcaption></figure><p id="2de3">While all of my TikToks (except one) are in [mostly broken] English, and I added relevant hashtags and descriptions in English, they were primarily shown in my home country of Lithuania. That‚Äôs a very small niche. Add that TikToks were for a niche subject of ‚Äúmusic-making‚Äù and you get close to zero of overlap.</p><p id="2d64">Interestingly, I got similar results on a couple of videos that I posted from Poland and Germany.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1012/1*A0bxyk6k9iMsg6XC5xs4kg.png" width="506" height="368" srcset="https://miro.medium.com/max/552/1*A0bxyk6k9iMsg6XC5xs4kg.png 276w, https://miro.medium.com/max/1012/1*A0bxyk6k9iMsg6XC5xs4kg.png 506w" sizes="506px" data-old-src="https://miro.medium.com/max/60/1*A0bxyk6k9iMsg6XC5xs4kg.png?q=20"></p></div></div><figcaption>Stats for TikTok posted from Germany</figcaption></figure><p id="d459">As you can see there‚Äôs Germany present here but the majority is still from Lithuania. The one from Poland had more Polish viewers but still fewer than Lithuanians. (FYI, the population of Poland is about 14x of Lithuania)</p><p id="569a">So the ‚Äúalmighty algorithm‚Äù somehow prioritizes your profile‚Äôs country over everything else. Not very smart, if you ask me. You may not notice this if you live in the US or some other big country, or if you create content for your local market. But, anecdotally, it feels like TikTok‚Äôs algorithm is quite discriminatory towards people from small countries trying to create global content.</p><p id="9aa2">To add insult to injury, I‚Äôm pretty sure TikTok never asked me for my country (I registered with email address, not phone or other account), and it doesn‚Äôt require location permissions (kudos for that). So basically they took my IP address at the time of registration and hard-coded my profile‚Äôs country to what they got from the IP lookup. Good thing I didn‚Äôt register at the office as many services think we are in Norway based on that IP. Or maybe that‚Äôs a bad thing given my goals.</p><blockquote><p id="e552"><strong>Untested pro-tip</strong>: create your account over VPN to US (or whatever location you care about) for better distribution.</p></blockquote><p id="5b0f">The bottom line is that TikTok‚Äôs algorithm still gave me more exposure than probably any other service would, considering I didn‚Äôt do anything to assist it (I didn‚Äôt tell anyone about my TikTok, remember?). Having said that, it handicapped me for no apparent reason purely based on my home country.</p><p id="2686">And that‚Äôs the main problem with all the algorithmic social media ‚Äî you are at the mercy of a bunch of ‚Äúif-then‚Äù statements with their bugs, quirks, and oddities.</p><p id="cef8">Now that you know <a href="https://www.tiktok.com/@ailonid" rel="noopener">I have TikTok</a>, we can proceed to the phase 2 of the experiment. If you are even remotely interested in music production and don‚Äôt live in Lithuania, please <a href="https://www.tiktok.com/@ailonid" rel="noopener">follow me on TikTok @ailonid</a> and in another month I will report if having followers outside of Lithuania had any impact on the algorithm.</p></div></div></div>]]>
            </description>
            <link>https://blog.ailon.org/testing-tiktoks-multi-billion-dollar-algorithm-af38fdd8225?source=friends_link&amp;sk=a736bbdd904768fa4d7bcfb536615573</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651822</guid>
            <pubDate>Thu, 01 Oct 2020 15:13:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Julian Assange Acted Responsibly]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651796">thread link</a>) | @DiogenesKynikos
<br/>
October 1, 2020 | https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen | <a href="https://web.archive.org/web/*/https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div data-css-88vvl0=""><p data-pos="0-0" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Der Bieler Professor Christian Grothoff hat keine Ahnung, wer M.√Ç&nbsp;I.√Ç&nbsp;A. ist. Schade eigentlich. Schon allein wegen ihres spektakul√É¬§ren, verst√É¬∂renden und kontrovers diskutierten Ausblicks auf das Trump-Zeitalter aus dem Jahr 2010, des zehn√Ç¬≠min√É¬ºtigen Videos zu ihrer Single √Ç¬´Born Free√Ç¬ª. Darin werden in einer alternativen Realit√É¬§t Rothaarige als verfolgte ethnische Minderheit von para√Ç¬≠milit√É¬§rischen US-Truppen zu Tode gejagt.</p><figure data-pos="0-1" data-css-1esus25=""><a data-css-11au926=""><span data-css-mcluq8=""><svg width="26" height="36.01" viewBox="0 0 26 36"><path d="M25.956 18.188L.894 35.718V.66" fill="#fff"></path></svg></span><span data-css-fijd0m="">Dies ist ein Vimeo-Video. Wenn Sie das Video abspielen, kann Vimeo Sie tracken.</span><span data-css-1bqahl="" role="img" aria-label=""></span></a><figcaption data-css-s9b1dj="" data-css-qc9yqx="">M.I.A, Born Free</figcaption></figure><p data-pos="0-2" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Daf√É¬ºr weiss M.√Ç&nbsp;I.√Ç&nbsp;A. aber, wer Christian Grothoff ist.</p><p data-pos="0-3" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">M.√Ç&nbsp;I.√Ç&nbsp;A.√Ç&nbsp;√¢‚Ç¨‚Äú jene englische Rapperin, die 2012 von der NFL auf eine Million Dollar Schaden√Ç¬≠ersatz verklagt worden war, weil sie w√É¬§hrend ihres Super-Bowl-Pausen√Ç¬≠auftritts mit Nicki Minaj und Madonna den Mittel√Ç¬≠finger <a href="https://www.youtube.com/watch?v=qlEUz1IlN70&amp;ab_channel=ATownHR23" data-css-9r2oe9="" data-css-1exity3="">in die Kameras gehalten hatte</a>. Oder 2016: Verklagt vom Fussball√Ç¬≠club Paris Saint-Germain, weil sie im Video zu ihrem Song √Ç¬´Borders√Ç¬ª ein T-Shirt des franz√É¬∂sischen Vereins trug und dabei den Schrift√Ç¬≠zug des Sponsors √Ç¬´Fly Emirates√Ç¬ª <a href="https://www.youtube.com/watch?v=r-Nw7HbaeWY&amp;ab_channel=MIAVEVO" data-css-9r2oe9="" data-css-1exity3="">in √Ç¬´Fly Pirates√Ç¬ª abge√É¬§ndert hatte</a>. </p><p data-pos="0-4" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Die 45-j√É¬§hrige Musikerin und politische Aktivistin setzt sich derzeit mit zahl√Ç¬≠reichen K√É¬ºnstlerinnen, darunter <a href="https://www.washingtonpost.com/entertainment/dissident-ai-weiwei-protests-possible-extradition-of-assange/2020/09/28/89e17c56-0183-11eb-b92e-029676f9ebec_story.html" data-css-9r2oe9="" data-css-1exity3="">Ai Weiwei oder Designerin Vivienne Westwood</a>, daf√É¬ºr ein, dass Wikileaks-Gr√É¬ºnder Julian Assange nicht an die USA ausgeliefert wird. Seit dem 7.√Ç&nbsp;September l√É¬§uft an einem Londoner Gericht die zweite Runde des Auslieferungs√Ç¬≠verfahrens, das wegen Covid-19 im April unterbrochen worden war. Die USA beschuldigen Assange, mit der Ver√É¬∂ffentlichung von 250√¢‚Ç¨‚Ñ¢000√Ç&nbsp;Depeschen aus US-Botschaften das Leben von Diplomaten und amerikanischen Helfern weltweit gef√É¬§hrdet zu haben.</p><h2 data-css-153qrt7="" data-css-qc9yqx=""><a data-css-1i4zy90="" id="der-zeuge-aus-der-schweiz"></a>Der Zeuge aus der Schweiz</h2><p data-pos="0-6" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">M.√Ç&nbsp;I.√Ç&nbsp;A. war es m√É¬∂glich, das Verfahren per Video√Ç¬≠stream live zu verfolgen√Ç&nbsp;√¢‚Ç¨‚Äú was alles andere als selbst√Ç¬≠verst√É¬§ndlich ist: Im Gericht waren f√É¬ºr die neue Anh√É¬∂rungs√Ç¬≠runde nur noch f√É¬ºnf Journalistinnen und ein paar wenige G√É¬§ste zugelassen, diversen Prozess√Ç¬≠beobachtern wie Amnesty International wurde am ersten Anh√É¬∂rungs√Ç¬≠tag kurzfristig der Zugang verweigert, zugesagte Beobachter√Ç¬≠pl√É¬§tze wurden gestrichen, ihnen wurde zusammen mit vierzig anderen Organisationen oder akkreditierten Medien die M√É¬∂glichkeit entzogen, <a href="https://www.amnesty.org/en/latest/news/2020/09/why-are-amnesty-international-monitors-not-able-to-observe-the-assange-hearing/" data-css-9r2oe9="" data-css-1exity3="">das Verfahren wenigstens per Stream verfolgen zu k√É¬∂nnen</a>.</p><p data-pos="0-7" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Dieser Vorgang wurde laut Amnesty International <a href="https://www.amnesty.org/en/latest/news/2020/09/why-are-amnesty-international-monitors-not-able-to-observe-the-assange-hearing/" data-css-9r2oe9="" data-css-1exity3="">nicht weiter begr√É¬ºndet</a> und sei √Ç¬´sehr beunruhigend√Ç¬ª. √Ç¬´Mit diesem Schritt missachtet das Gericht das Grund√Ç¬≠prinzip der √É‚Äìffentlichkeit√Ç¬ª, schrieb die Menschenrechts√Ç¬≠organisation: √Ç¬´Konkret, dass internationale Prozess√Ç¬≠beobachterinnen nachvollziehen k√É¬∂nnen, ob nationales und internationales Recht eingehalten wird.√Ç¬ª Und dies in einem Verfahren, in dem die Recht√Ç¬≠sprechung sowieso ziemlich eigenwillig interpretiert wird. Assange, dem der Zugang zu seinen eigenen Anw√É¬§lten in den letzten sechs Monaten verweigert worden war, sitzt mittlerweile seit 16√Ç&nbsp;Monaten ohne juristische Grundlage in Isolations√Ç¬≠haft, was√Ç&nbsp;√¢‚Ç¨‚Äú Grundlage hin oder her√Ç&nbsp;√¢‚Ç¨‚Äú als Folter gesehen werden muss. (Sein Vergehen, <a href="https://www.forbes.com/sites/thomasbrewster/2019/05/01/assange-given-50-weeks-in-prison-for-breaking-bail/#2af1cd5fa1d8" data-css-9r2oe9="" data-css-1exity3="">der Verstoss gegen Kautionsauflagen</a>, wird in Grossbritannien normaler√Ç¬≠weise nicht einmal mit einer kurzen Gef√É¬§ngnis√Ç¬≠strafe geahndet.)</p><p data-pos="0-8" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">M.√Ç&nbsp;I.√Ç&nbsp;A. also war es m√É¬∂glich, den Prozess live zu verfolgen.</p><p data-pos="0-9" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Und am Morgen des 21.√Ç&nbsp;September twitterte die Rapperin:</p><div data-css-wnj6iv="" data-pos="0-10"><p data-css-87w1y="" data-css-5rrfwp="">√Ç¬´Ich beobachtete diesen Zeugen. Ziemlich intensive Befragung, sogar die Richterin wurde w√É¬ºtend wegen des schonungs√Ç¬≠losen Kreuz√Ç¬≠verh√É¬∂rs, das er zu erdulden hatte. Ich empfehle es allen: Studiert bei Professor Dr.√Ç&nbsp;Christian Grothoff. Grothoff ist Professor der Informatik in der Schweiz. Er war brillant.√Ç¬ª</p><figcaption data-css-s9b1dj="" data-css-qc9yqx=""><a href="https://twitter.com/MIAuniverse/status/1308129185240580096" data-css-9r2oe9="" data-css-1exity3="">Tweet von @MIAuniverse</a></figcaption></div><p data-pos="0-11" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Am Tag darauf rief ich den Informatik√Ç¬≠professor an. </p><figure data-pos="0-12" data-css-j57vv8=""><figcaption data-css-s9b1dj="" data-css-qc9yqx="">√Ç¬´Mit dem n√É¬∂tigen Fach√Ç¬≠wissen l√É¬§sst sich alles Schritt f√É¬ºr Schritt nachvollziehen√Ç¬ª: Christian Grothoff. <span data-css-puup3u="">Martin Gross/youtube/gnunet</span></figcaption></figure><p data-pos="0-13" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´K√É¬∂nnen Sie mir sagen, was da los war?√Ç¬ª, fragte ich.</p><p data-pos="0-14" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Ja, nat√É¬ºrlich√Ç¬ª, sagt er. √Ç¬´Nach meinem Auftritt vor Gericht ist es mir jetzt erlaubt, meine Erkenntnisse mit der Presse zu teilen.√Ç¬ª</p><p data-pos="0-15" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Sie waren Zeuge im Assange-Prozess?√Ç¬ª</p><p data-pos="0-16" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Ja√Ç¬ª, sagte Professor Grothoff. √Ç¬´Ich habe meine Expertise dem Gericht zur Verf√É¬ºgung gestellt, einen dicken Stapel Unterlagen.√Ç¬ª</p><p data-pos="0-17" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Was f√É¬ºr eine Expertise?√Ç¬ª</p><p data-pos="0-18" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Ich sollte im Auftrag der Verteidigung nach bestem Wissen und Gewissen analysieren, wie es dazu kam, dass die Diplomaten√Ç¬≠depeschen, die Chelsea Manning Wikileaks √É¬ºbergeben hatte, sp√É¬§ter komplett ungeschw√É¬§rzt im Internet kursierten. Das ist ja eigentlich einer der zentralen Anklage√Ç¬≠punkte: Diese Publikation der gesamten Depeschen. Wer hat sie zuerst ins Netz gestellt? Wikileaks, wie es die USA behaupten?√Ç¬ª</p><p data-pos="0-19" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Haben Sie eine Antwort gefunden?√Ç¬ª</p><p data-pos="0-20" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Mit dem n√É¬∂tigen Fach√Ç¬≠wissen l√É¬§sst sich alles Schritt f√É¬ºr Schritt nachvollziehen.√Ç¬ª</p><p data-pos="0-21" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Wir trafen uns einen Tag sp√É¬§ter zum Abend√Ç¬≠essen in einem chinesischen Imbiss in der Berner Altstadt.</p><h2 data-css-153qrt7="" data-css-qc9yqx=""><a data-css-1i4zy90="" id="die-hauptschuld-liegt-beim-guardian"></a>√Ç¬´Die Hauptschuld liegt beim √¢‚Ç¨¬πGuardian√¢‚Ç¨¬∫√Ç¬ª</h2><p data-pos="0-23" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Und die Geschichte, die der Bieler Professor Christian Grothoff an jenem Abend im September zu erz√É¬§hlen hat, ist h√É¬∂chst erstaunlich.</p><figure data-pos="0-24" data-css-j57vv8=""><figcaption data-css-s9b1dj="" data-css-qc9yqx="">Assange-Unterst√É¬ºtzerinnen: Chelsea Manning (Mitte) und Dame Vivienne Westwood, hier mit ihrem Mann Andreas Kronthaler. <span data-css-puup3u="">David M. Benett/Getty Images</span></figcaption></figure><p data-pos="0-25" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Zehn Jahre lang <a href="https://www.bbc.com/news/technology-37165230" data-css-9r2oe9="" data-css-1exity3="">behaupteten die US-Beh√É¬∂rden (ohne jemals einen einzigen Beweis daf√É¬ºr zu erbringen</a>), dass Julian Assange Menschen√Ç¬≠leben gef√É¬§hrdet habe, weil er die ihm von Chelsea Manning anvertrauten diplomatischen Depeschen der US-Regierung komplett und einfach so ins Netz gestellt habe, und deswegen sei Assange kein Journalist.</p><p data-pos="0-26" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Die Erz√É¬§hlung von der Gef√É¬§hrdung hat sich bis heute gehalten, obwohl Mitarbeitende des State Department bereits Ende 2010 gegen√É¬ºber dem US-Kongress hatten durchsickern lassen (w√É¬§hrend die Obama-Administration √É¬∂ffentlich das Gegenteil behauptete), <a href="https://www.reuters.com/article/us-wikileaks-damage-idUSTRE70H6TO20110118" data-css-9r2oe9="" data-css-1exity3="">dass Wikileaks die USA zwar blossgestellt habe, dabei aber niemand zu Schaden gekommen sei</a>.</p><p data-pos="0-27" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Bei seiner Analyse fand Grothoff zudem heraus: Die Behauptung√Ç&nbsp;√¢‚Ç¨‚Äú ein zentraler Anklage√Ç¬≠punkt der US-Justiz√Ç&nbsp;√¢‚Ç¨‚Äú, Wikileaks habe als erste Quelle die Depeschen komplett und unbearbeitet ins Netz gestellt und sei deshalb unter dem √Ç¬´Espionage Act√Ç¬ª zu verfolgen, ist nachweislich falsch. Mit dem n√É¬∂tigen Fach√Ç¬≠wissen sei im Netz nachvollziehbar und unzweifelhaft belegbar, so Grothoff in seiner Expertise, dass Wikileaks erst im Nachgang die gesamten Depeschen publiziert habe√Ç&nbsp;√¢‚Ç¨‚Äú nachdem diese von anderen Quellen bereits online gestellt worden waren.</p><p data-pos="0-28" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Der Informatiker Christian Grothoff mit akademischen und beruflichen Stationen in Los Angeles, Denver, M√É¬ºnchen und Rennes ist ein international angesehener Fachmann unter anderem f√É¬ºr Verschl√É¬ºsselungs√Ç¬≠techniken, aber auch in der Analyse von Peer-to-Peer-Netzwerken und der √É≈ìberlastung von Servern zum Beispiel durch sogenannte DDOS-Angriffe.</p><p data-pos="0-29" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Kurz: Grothoff vereint so ziemlich das ganze Fach√Ç¬≠wissen, das in dieser Angelegenheit gefragt ist.</p><p data-pos="0-30" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Es ist im √É≈ìbrigen so, dass Assange die diplomatischen Depeschen derart gut gesch√É¬ºtzt hat√Ç¬ª, sagte Grothoff im Gespr√É¬§ch mit der Republik und auch vor Gericht, √Ç¬´dass sie auch von der NSA nicht h√É¬§tten geknackt werden k√É¬∂nnen.√Ç¬ª</p><p data-pos="0-31" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Das Bild, das Grothoff stattdessen zeichnet, ist ein Armuts√Ç¬≠zeugnis f√É¬ºr den Journalismus: Die Journalisten des √Ç¬´Guardian√Ç¬ª, mit denen sich Assange bald √É¬ºberwarf, hefteten sich wie Blut√Ç¬≠sauger an den Wikileaks-Gr√É¬ºnder, um mit seiner Hilfe die grossen Geschichten fahren zu k√É¬∂nnen. Der √Ç¬´Guardian√Ç¬ª-Journalist David Leigh √É¬ºbte dabei massiven Druck auf Assange aus: Er solle ihm das Passwort f√É¬ºr die verschl√É¬ºsselten Depeschen nennen, f√É¬ºr den Fall, dass Assange verhaftet werde und dann keine weiteren Geschichten mehr publiziert werden k√É¬∂nnten.</p><p data-pos="0-32" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Die Quelle daf√É¬ºr: das Buch √Ç¬´Wikileaks: Inside Julian Assange√¢‚Ç¨‚Ñ¢s War on Secrecy√Ç¬ª, das David Leigh im Februar 2011 selbst publiziert hatte. Dort steht auch, Assange habe schliesslich eingewilligt, Leigh das Passwort auszuh√É¬§ndigen√Ç&nbsp;√¢‚Ç¨‚Äú mit der eindringlichen Bitte, es niemals irgendwo als Ganzes aufzuschreiben.</p><p data-pos="0-33" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Assange, das steht in meiner Expertise f√É¬ºr das Gericht, ist verantwortungs√Ç¬≠voll mit den Daten umgegangen√Ç¬ª, sagt Grothoff. √Ç¬´Das l√É¬§sst sich alles nachvollziehen und belegen.√Ç¬ª Doch was nach der Passwort√Ç¬≠√É¬ºbergabe passiert sei, k√É¬∂nne er als Fachmann nur als √Ç¬´grob fahrl√É¬§ssig√Ç¬ª bezeichnen, und zwar nicht von Wikileaks, sondern vom √Ç¬´Guardian√Ç¬ª: √Ç¬´Der Journalist David Leigh schwatzt Julian Assange das Passwort ab√Ç&nbsp;√¢‚Ç¨‚Äú und dann publiziert er es ein paar Monate sp√É¬§ter als Kapitel√Ç¬≠titel in seinem Buch √¢‚Ç¨¬πInside Wikileaks√¢‚Ç¨¬∫.√Ç¬ª</p><p data-pos="0-34" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Ja, Sie haben richtig gelesen.</p><p data-pos="0-35" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Das Passwort, 58√Ç&nbsp;Buchstaben, Ziffern und Sonder√Ç¬≠zeichen, als √É≈ìberschrift in einem Buch. Der √Ç¬´Guardian√Ç¬ª-Journalist habe sp√É¬§ter behauptet, er sei davon ausgegangen, das Passwort sei veraltet gewesen. Als Verschl√É¬ºsselungs√Ç¬≠experte, sagte Grothoff, m√É¬ºsse er entgegnen, dass man in der Pflicht sei, sich zu informieren, mit welcher Technik man es zu tun habe, wenn man mit derartig sensiblen Daten operiere. </p><p data-pos="0-36" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Es dauerte nicht lange, da wurde in den Medien (namentlich im √Ç¬´Freitag√Ç¬ª und im √Ç¬´Spiegel√Ç¬ª) ein Zusammen√Ç¬≠hang zwischen dem Passwort aus dem Buch des √Ç¬´Guardian√Ç¬ª-Journalisten und der Depeschen-Datei hergestellt, die nach massiven sogenannten DDOS-Angriffen auf den Wikileaks-Server (Angriffe, um den Server lahmzulegen) und Spiegelungen ebenjenes Servers durch Dritte irgendwo unkontrolliert als Kopie in den Weiten des Netzes umherschwirrte. Am 1.√Ç&nbsp;September 2011 sei diese dann unverschl√É¬ºsselt auf einer Plattform namens √Ç¬´Cryptome√Ç¬ª aufgetaucht. </p><p data-pos="0-37" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Tats√É¬§chlich sagte der Betreiber von √Ç¬´Cryptome√Ç¬ª nun vor dem Londoner Gericht aus, er habe als Erster die Depeschen vollumf√É¬§nglich, ungeschw√É¬§rzt und unverschl√É¬ºsselt hochgeladen√Ç&nbsp;√¢‚Ç¨‚Äú <a href="https://www.fr24news.com/a/2020/09/us-never-asked-wikileaks-rival-to-remove-leaking-cables-court-says-julian-assange.html" data-css-9r2oe9="" data-css-1exity3="">und bis heute habe die US-Regierung bei ihm nichts von sich h√É¬∂ren lassen</a>.</p><p data-pos="0-38" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">√Ç¬´Die Depeschen finden sich immer noch dort√Ç¬ª, sagt Grothoff. </p><p data-pos="0-39" data-css-aphf9g="" data-css-qc9yqx="" data-css-1ax1725="">Es sei problemlos chronologisch aufzuzeigen, sagte Informatik√Ç¬≠professor Grothoff im Berner Imbiss, dass die Haupt√Ç¬≠schuld f√É¬ºr die Publikation der gesamten Depeschen beim √Ç¬´Guardian√Ç¬ª liege. √Ç¬´W√É¬§re man ‚Ä¶</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen">https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen</a></em></p>]]>
            </description>
            <link>https://www.republik.ch/2020/10/01/julian-assange-ist-verantwortungsvoll-mit-den-daten-umgegangen</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651796</guid>
            <pubDate>Thu, 01 Oct 2020 15:11:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on QA]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24651571">thread link</a>) | @tigranhakobian
<br/>
October 1, 2020 | https://blog.superannotate.com/how-to-detect-mislabeled-annotations | <a href="https://web.archive.org/web/*/https://blog.superannotate.com/how-to-detect-mislabeled-annotations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><em>Manual QA is a significant part of the annotation pipeline. Annotation companies report that 40 percent of the annotation time can be spent on manual QA. As a result, finding ways to reduce QA testing time can have a significant impact on annotation costs.&nbsp;</em></p>
<!--more--><p><em>At SuperAnnotate, we‚Äôve developed a tool to accelerate the QA process. This article discusses SuperAnnotate‚Äôs features that speed up the quality assurance process substantially. It presents several automation tools within the platform listing specific use cases in which a major acceleration of the QA process can be obtained. We also explored various ML algorithms that can detect over 90 percent of mislabeled instances in data while accelerating the QA process up to 4 times.&nbsp;</em></p>
<h3><strong><span>Outline</span></strong></h3>
<ul>
<li><em>Problem with noisy annotation in data&nbsp;</em></li>
<li><em>Manual QA acceleration</em></li>
<li><em>QA automation</em></li>
<li><em>Conclusion</em></li>
</ul>
<h2><span>Problem with annotation noise in data</span></h2>
<p><strong><span>1.1. The importance of model accuracy and the impact of annotation noise&nbsp;&nbsp;</span></strong></p>
<p>In real-world applications, the performance of machine learning (ML) systems is of crucial importance. ML models heavily rely on the quality of annotated data, but obtaining high-quality annotations is costly and requires extensive manual labor.&nbsp;</p>
<p><span>In any annotation pipeline, regardless of the data collection method, i.e., human or machine, several factors inject annotation noise in data. As a result, even the most celebrated datasets contain mislabeled annotations.</span></p>

<p><img src="https://lh3.googleusercontent.com/mL1r0JU9VM5-WflEsLU04zQ7vhYhl8cKRux8LvOnUTYEKZvnIUD9Gv8HmkVTqPfgoDtEkb_5ApX3SjgJjdTAHNfG6I-5Q7_fag_cra8IhXTWp-uVdrvQCf7kzoqt03BwtgKlTb4i" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"><em>Figure: Ambiguous or Mislabeled annotations from ImageNet. Source (</em><a href="https://arxiv.org/abs/2001.10528"><em><span>Pleiss et al</span></em></a><em>.)</em></p>

<p><span>Recent studies show that both natural and malicious corruptions of annotations tend to radically degrade the performance of machine learning systems. Deep Neural Networks (DNNs) tend to memorize noisy labels in data, resulting in less generalizable features and poor model performance (<a href="https://arxiv.org/abs/1611.03530">Zhang et al.</a>)</span></p>
<p><span>Therefore, extensive quality control of annotated data is required to clean annotation noise and improve model performance.</span><em><br></em></p>

<p><img src="https://lh4.googleusercontent.com/7BKHH4Am8Z_PZebzMe7mkbGCA6J_UyNRZE-ClAMwP5qVo52ZEuybUx81EOWYSdKrz2Mz7P4zf2cHuoz9nlyl4Alg-D16cD58mSCLf1CAOUwwDEp2MUkIsaTi37D6y9aliNShqdUz" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: Accuracy drop in multiple datasets when injecting label noise. Source (</em><a href="https://arxiv.org/abs/1611.03530"><em><span>Rolnick et al.</span></em></a><em>)</em></p>

<h2>Manual QA Acceleration</h2>
<p><strong><span>2.1 SuperAnnotate‚Äôs QA pipeline&nbsp;</span></strong></p>
<p><span>Quality Assurance of annotated data is time-consuming and requires particular attention. Annotation tools need to provide reliable and scalable QA pipelines to accelerate the QA process. <a href="https://annotate.online/login">SuperAnnotate</a> provides interlinked annotation and QA processes within the same platform. As a result, QA systems do not require additional management.</span></p>
<p><span>The design of SuperAnnotate‚Äôs QA system guarantees an efficient process and ensures a minimal probability of error.&nbsp;</span></p>
<p><strong><span>2.2 Pinning images to reduce common errors&nbsp;</span></strong></p>
<p><span>Sharing repetitive labeling mistakes across the annotation team is essential to reduce systematic errors throughout single or multiple annotation projects. </span>SuperAnnotate‚Äôs pin functionality is designed specifically for this cause.&nbsp;</p>
<p>Once the reviewer notices a recurring error, they can share this information through pinned annotations instead of extensive project instructions. Pinned annotations will appear first in the annotation editor to immediately grab the annotation team‚Äôs attention.&nbsp;</p>
<p>This functionality is highly efficient since it allows the project coordinator to instantly share common instructions, eliminating the spread of systematic errors.&nbsp;</p>

<p><img src="https://lh6.googleusercontent.com/g1sh6D7Xy1hLYBMczMWfFGdO1_1gktJn7dNF1Spx3lwUxeZd8isGaMHgYLB1GoT0lY8jJKTemdqvtExgPJIocgjNEFuzYGjbPQYeRo31873mdN3U4U10DMjW7DZOnr1eAh5_o-bc" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: Pin functionality</em></p>

<p><strong><span>2.3 Approve/Disapprove functionality</span></strong></p>
<p>Apart from various image-level QA tools, SuperAnnotate also provides instance-level QA functionalities. The latter is designed to help the QA focus on a specific instance area. As a result, no error is overlooked, at the time a meticulous QA is time-efficient.</p>
<p>Additionally, the Approve/Disapprove functionality works on the level of individual instances<span>.</span> If a QA specialist disapproves of an annotation, they can send it back to the Annotator for correction. The QA specialist can send the annotation back to the Annotator as many times as needed until the annotation is corrected. Once approved, the annotations can be exported from the platform.</p>

<p><img src="https://lh4.googleusercontent.com/BpQPXRUuTMRYUP-YGJTSRJwFUtdLr6wsB5LVwn66wK6TqFJCTRW5LLwhTp4sRttqgzQaCngKzm7Z6ONZBpPhwzxifj1KlBRs5_FOl_Nk0cFpaC_jn7-l9CMn1WJX2FENx9f9NI24" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p>Figure: Approve/Disapprove functionality</p>

<p><span>The QA mode is another useful tool for manual instance inspection. When enabled, the annotations are visually isolated from the background. This allows the user to distinguish between instances and the underlying objects, making the instance inspection easier.</span></p>
<p><span>All listed features extensively accelerate the manual QA process. However, machine learning techniques that automatically detect annotation noise can provide an additional level of automation.</span></p>

<h2><span>QA Automation</span></h2>
<p><strong><span>3.1 ML for QA Automation</span></strong></p>
<p><span>QA of annotated data takes around 40 percent of the annotation time.</span></p>
<p><span>On average, only a small fraction of annotated data contains noise. Still, QA is applied to the entire dataset, and monitoring clean data costs the annotators extra time and resources. An automation method could substantially cut down the QA process of clean data by isolating a set of risky annotations. So, our goal is to determine ML techniques that identify noisy annotations in data with high precision and recall.</span></p>
<p><strong><span>3.2 Current research</span></strong></p>
<p><span>Learning on datasets that contain annotation noise has been an active research area in ML. Several methods use predictions from DNNs to detect label noise and modify training loss (Reed et al., 2015; Tanaka et al., 2018). These methods do not perform well under high noise ratio as the domination of noisy annotations in data causes overfitting of DNNs. Another approach is to treat small loss samples as clean annotations and allow only clean samples to contribute to the training loss (Jiang et al., 2017). Ultimately, this research area‚Äôs core challenge is to design a reliable criterion capable of identifying the annotation noise.</span></p>
<p><span>A significant amount of research in this area is focused on classification with noisy labels. The proposed methods range from detecting and correcting noisy samples to using noise-robust loss functions. Unsupervised and semi-supervised learning techniques are also relevant to this task since those require few or no labels. Mislabeled samples that are detected without label correction can be used as unlabeled data in a semi-supervised setting (Li et al. 2020).&nbsp;</span></p>
<p><span>Going beyond classification makes things far more challenging. In classification, the existence of an object per image is guaranteed. So, the noisiness criterion can be defined between predicted and annotated image labels. However, in more complex tasks such as object detection, the correspondence between predicted and annotated instances is less trivial. Even though research in this area is in its initial state, several methods suggest valid measures to indicate both localization and label noise in object detection (Pleiss et al 2020, Chadwick et al. 2019).</span></p>
<p><strong><span>3.3&nbsp; Proposed method</span></strong></p>
<p>Consider the task of object detection on a dataset that contains mislabeled annotations. Several techniques use DNN predictions to identify label noise in data. Based on this concept, we propose the following algorithm.</p>
<ul>
<li>For each bounding box annotation, we obtain the matching prediction that has the maximum IOU.&nbsp;</li>
<li><span>Compute <strong>L2 distance</strong> between one hot vector of an annotated class and Fast RCNN softmax logits of the matched prediction. </span>This distance serves as a mislabel metric for annotations. We treat this number as the probability of annotation being mislabeled. As we aim to achieve maximal recall and precision in mislabel detection, we select an optimal threshold to attain the desired objective. This defines the split of data between clean and mislabeled annotations by the given criterion.</li>
</ul>

<p><img src="https://lh6.googleusercontent.com/JJtyM51584r8uJCIbHuW0UKhdgxQIIMm4G23vuD8lxnn5yrYHONPRytIxl-9QjFodM51zy7d8pvswhiMYokXY8XOz-DxqTd4ua-_DHGemiuXULNKqCbq_ePQfzulkbsrNu_jyX0D" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: L2 distance on gt one hot and prediction logits</em></p>

<p>Along with mislabeled detections, we also suggest considering the most confident predictions as missing annotations.&nbsp;</p>
<p><strong><span>3.4 Experiments and results</span></strong></p>
<p>To evaluate the performance of our method, we used PASCAL VOC as a toy dataset. When we manually injected asymmetric label noise in 20 percent of bbox annotations, the described mislabel criterion resulted in the precision-recall curve shown below.</p>
<p><img src="https://lh5.googleusercontent.com/OhgoPNrwmPWqR21Y1jnMY-1rbgKV8cxdFd8F0lZsVCZTcrN9C77EBX-0yqvZfVbYOVAFH_pxHNh88T7r26Gbp6hxWWdF5XqyLkN8SS5G46q512ZOHILlP1wmeR20aCo2QDWsOMms" width="400" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: PR curve with optimal mismatch threshold selected</em></p>

<p>Here, recall determines the portion of annotation noise captured, and precision identifies the fraction of data validated as clean.</p>
<p><span>Based on the PR curve above, using optimal mislabel threshold results in over 93 percent recall. This proves the reliability of our method, as we capture the dominant fraction of annotation noise. Along with high recall, we obtained over 75 percent precision, which attributes to validating ¬æ of annotations as clean. This cuts manual inspection time over the whole dataset by a margin of 4, resulting in extensive automation for the manual QA.&nbsp;</span></p>
<p>Note that detected risky annotations contain clean samples apart from correctly detected mislabeled instances. Those are the images that were hard to capture by the detection model and thus are misclassified as risky. Distinguishing between these two categories is a challenging problem for further research.&nbsp;</p>
<p>You can find the source code for the discussed experiments at our <a href="https://github.com/superannotateai/qa-automation"><span>GitHub repository</span></a>.</p>
<p>Also, consider our <a href="https://colab.research.google.com/drive/1Xbt3dxkmX4ozQhdY_vnHXAH67OUeg0Nj#scrollTo=7unkuuiqLdqd&amp;uniqifier=2"><span>Colab tutorial</span></a> as a step-by-step guide to reproduce the given results.&nbsp;</p>
<p><strong><span>3.5 Automate Approve/Disapprove functionality&nbsp;</span></strong></p>
<p>Once mislabeled annotations are captured by ML techniques, SuperAnnotate allows users to import the detected information to the platform through the <strong>error </strong>key of SA formatted annotations. Just set the <strong>error</strong> key in mislabeled annotations and import SA formatted JSONs to SuperAnnotate via Python SDK.&nbsp;</p>

<p><img src="https://lh3.googleusercontent.com/to5CwRUFKERkSeyPgA1Nzl84I0ijhR8bQCpsUHhIxi_zhsm7FnNGOxSJ-i0V8HXnJSzN4VOxDnVgj_JWo2QCwQF6ECSjO4CrLShBB9V3YPHp8SWxO9D2CEwC6UbfqClElWgxIOf3" width="654" height="183" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: JSON Code Block</em></p>

<p><img src="https://lh3.googleusercontent.com/0SJ8E5OnOSxB50Fh_4d4_qjJNT0lygY1yHzFGuFlZ9fMDjIGyUGQDqxGsDDG9j2dMcfmf6PLOHvj3JRJ4F3UtaQup-muynR2TFd18W6vbjI1ANF8Ll99dK_b8v1GIzkBUbpwVaPn" width="654" height="121" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: SDK Code Block</em></p>

<p><span>Discussed pipeline provides complete automation of Approve/Disapprove functional.</span></p>

<p><img src="https://lh5.googleusercontent.com/w9VXvs6INaP4WaEADW2pW6fEVj6s8sj5FZd44gN-10LcKplspRX3N7tt-aRuV1BUmNFzANwQTjKgq9rt-EbND0_SpY2z5Ikcpc3xo6wZHQMm2-TB3iY6ao5LboT86FK8qaw8ZwPu" width="720" alt="How to Detect 93% of Mislabeled Annotations While Spending 4x Less Time on Quality Assurance"></p>
<p><em>Figure: Before v.s After autoqa in SA platform&nbsp;</em></p>

<h3><span>Conclusion</span></h3>
<p><span>QA automation is of crucial importance as it constitutes a significant portion of annotation time. This article shows that using proper algorithms and associated tools can help us detect mislabeled annotations with high precision while spending 4x less time on QA.</span></p></span>
</p>


</div></div>]]>
            </description>
            <link>https://blog.superannotate.com/how-to-detect-mislabeled-annotations</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651571</guid>
            <pubDate>Thu, 01 Oct 2020 14:57:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CodeShip Status ‚Äì Critical Security Notification]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24651240">thread link</a>) | @jwilk
<br/>
October 1, 2020 | https://www.codeshipstatus.com/incidents/91bvlfw9xlm9 | <a href="https://web.archive.org/web/*/https://www.codeshipstatus.com/incidents/91bvlfw9xlm9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
              Dear CodeShip users,</p><p>We are reaching out to inform you of additional information we have uncovered as a result of our continuing investigation of the recent GitHub breach. To provide maximum transparency, we are reporting on the results of our investigation, the impact on users, actions you must take to protect yourself/your organization, and actions we will take to strengthen our security processes going forward.</p><p>On Wednesday, September 16, 2020, CloudBees was notified by GitHub of suspicious activities targeting CodeShip business accounts connected to GitHub via the CodeShip GitHub app and now deprecated CodeShip OAuth tokens. CloudBees immediately initiated an investigation conducted by our security and engineering teams, and on September 27, we identified additional evidence of malicious activity against a failover CodeShip database. On September 29, we uncovered evidence to indicate that a malicious actor had access to this failover instance during the period of June 2019 to June 2020. At this time and to the best of our knowledge, we have no evidence of malicious activity or attempts within CodeShip systems since June 2020. </p><p>*What type of data was affected?*</p><p>The impacted accounts are those of CodeShip users. No other products or accounts were affected and CodeShip is in no way integrated with other CloudBees products or systems.</p><p>*For all CodeShip users:*</p><p>CodeShip users hashed account passwords, one-time password (OTP) recovery codes, and the OTP secret keys used to seed two-factor authentication all may have been exposed.</p><p>Business contact information for invoicing purposes such as company contact name, company name, VAT number, postal address, phone number also may have been exposed. No payment information, such as bank account numbers or credit card numbers, was exposed. No other CloudBees product other than CodeShip was impacted. Also, the logging system was not accessed for any customers.</p><p>*For CodeShip Basic users:*</p><p>Any information contained in CodeShip users‚Äô pipelines may have been exposed. This includes scripts, environment variables, access tokens and other similar data.</p><p>*For CodeShip Pro users:*</p><p>AES encryption keys may have been exposed.</p><p>*Steps you should take*</p><p>Although at this time we have no evidence that the data potentially exfiltrated has been used, all CodeShip users may have been affected (including free, Basic and Pro accounts) and should take the following steps:</p><p>- Immediately rotate any keys or other secrets for cloud providers, third-party tools, or anything else that you used in your CodeShip pipelines.</p><p>- If using CodeShip Pro, rotate your AES key and re-encrypt your secrets.</p><p>- Immediately identify any other sensitive information that is stored in your pipelines and replace them within your pipelines and on any external systems.</p><p>- Determine whether any of your systems accessible from CodeShip have experienced unauthorized access, by contacting your provider or carefully review your access records.</p><p>- Verify that the source code held in repositories that are linked to your CodeShip account have retained their full integrity.</p><p>- Reset your CodeShip 2FA: <a target="_blank" href="https://documentation.codeship.com/general/about/2fa/">https://documentation.codeship.com/general/about/2fa/</a></p><p>At this time and to the best of our knowledge, we have no evidence of malicious activity or attempts within CodeShip systems since June 2020. We are continuing to monitor the situation.</p><p>*Steps we are taking*</p><p>As soon as we were notified by GitHub on September 16, we proceeded to rotate all our applications' internal secrets and rebuilt all our AWS AMIs. We are continuing to scrutinize our AWS security logs to monitor for suspicious activity, such as outbound connections to known malicious IPs. To date, we have not found any such activity.</p><p>We want you to be assured that we are taking steps to increase the security strength of the CodeShip product, including but not limited to:</p><p>- Validation that our product threat modeling and large-scope security reviews are systematically implemented.</p><p>- Validation that the application of production security standards to all operational processes and artifacts is systematically implemented.</p><p>- Enhancement of strict restrictions on access to production data and strict segregation of sensitive data.</p><p>- Improvement of existing SIRT processes to ensure faster and better forensic investigation.</p><p>*Who to contact *</p><p> We will update here with any new developments. </p><p>If you still have questions, please contact <a target="_blank" href="mailto:security@codeship.com">security@codeship.com</a>.</p><p>Last but not least, I‚Äôd like to apologize for the impact this is having on you. In the decade that CloudBees has been operating SaaS applications, we have always taken full responsibility for our products and we do so today. Please be assured that we will do everything we can to prevent this from happening again. </p><p>- Sacha Labourey, CEO, CloudBees
            </p></div></div>]]>
            </description>
            <link>https://www.codeshipstatus.com/incidents/91bvlfw9xlm9</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651240</guid>
            <pubDate>Thu, 01 Oct 2020 14:32:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Memgraph DB 1.1 Up to 50% Better Memory Usage and Higher Throughput]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24651091">thread link</a>) | @karimtr
<br/>
October 1, 2020 | https://memgraph.com/blog/memgraph-1-1-benchmarks | <a href="https://web.archive.org/web/*/https://memgraph.com/blog/memgraph-1-1-benchmarks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Introduction</h2>
<p>At Memgraph, we put great effort into delivering a high-performance in-memory graph storage and analytics engine. We do this by investing a lot of time optimizing and continuously improving various aspects of the Memgraph core engine. In this blog post, we will explore some of the improvements we have made on the storage layer and their impact on performance and memory usage.</p>
<p>The two most significant improvements we introduced in recent years are a new storage engine and a new way of storing properties on both nodes and edges.  Prior to version v0.50.0 Memgraph had an <a href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control">MVCC</a> storage where copies of nodes and edges were used to version the data. <strong>Memgraph v0.50.0</strong> introduced a new way of managing graph data where each node or edge consists of the latest version of data, and associated changes of data required to reconstruct previous versions.</p>
<p><img src="https://i.imgur.com/bQbvvp6.png" alt=""></p>
<p><strong>Memgraph v1.1.0</strong> introduced a new way of storing properties. Each node or edge has a property store that takes at least 16B of memory. Memgraph tries to hold properties data in 16B on the stack, if possible. If the properties data exceeds 16B, the first 8B of the stack buffer indicates the total number of bytes required for the storage of properties, and the second 8B a pointer to the array on the heap that stores properties. This technique is called small buffer optimization.</p>
<p><img src="https://i.imgur.com/LWP2te8.png" alt=""></p>
<p>Additionally, there were various other smaller improvements of existing internal data structures, most notably the <a href="https://en.wikipedia.org/wiki/Skip_list">skip list</a> which is used as an indexing data structure. The combined result was a massive improvement in memory usage with a substantial reduction in memory fragmentation while ensuring equivalent or better performance. Before jumping into the analysis and explanations, let‚Äôs have a look at the benchmark setup.</p>
<h2>Setup</h2>
<h3>Target Systems</h3>
<p>The benchmark tests different Memgraph versions. The release dates and details of each version are the following:</p>
<ul>
<li><strong>v0.15.2</strong>, October 23, 2019, the last version of Memgraph that used an in-memory storage engine based on copies of nodes/edges.</li>
<li><strong>v0.50.0</strong>, December 11, 2019, introduced the new in-memory storage engine based on data changes and a C-based storage API.</li>
<li><strong>v1.0.0</strong>, April 6, 2020, introduced a Python-based storage API.</li>
<li><strong>v1.1.0</strong>, July 1, 2020, added encoding and compression to node and edge properties.</li>
</ul>
<p>The <a href="https://docs.memgraph.com/memgraph/changelog">Memgraph Changelog Docs</a> page contains more details about changes in each version.</p>
<h3>Hardware</h3>
<ul>
<li>Server: HP DL360 G6</li>
<li>CPU: 2x Intel Xeon X5650 6C12T @ 2.67GHz</li>
<li>RAM: 144GB</li>
<li>Disk: 120GB SSD</li>
<li>OS: Debian 9 Stretch</li>
</ul>
<h3>Workload</h3>
<p>The benchmark consists of several different queries that test the performance of the graph database. Typical graph database workloads consist of READ, CREATE, and ANALYZE queries.</p>
<p>Memgraph is particularly well suited for hybrid transactional-analytical workloads where it‚Äôs crucial to ingest data as fast as possible and simultaneously deliver analytics as quickly as possible. For this reason, we are mostly interested in traversal queries (1-Hop, 2-Hop, etc.) which represent the majority of analytical queries.</p>
<p>In the following table, you can find the exact queries we have used for benchmarking.</p>
<pre><code>|            Query Name             |                                                Query                                                        |  Query Type |
| --------------------------------- | ----------------------------------------------------------------------------------------------------------- | ----------- |
| Aggregation                       | `MATCH (n:User) RETURN n.age, COUNT(*);`                                                                    | ANALYZE     |
| 1-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;(n:User) RETURN n.id;`                                                          | ANALYZE     |
| 2-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;()--&gt;(n:User) RETURN DISTINCT n.id;`                                            | ANALYZE     |
| 3-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;()--&gt;()--&gt;(n:User) RETURN DISTINCT n.id;`                                       | ANALYZE     |
| 4-Hop Expand                      | `MATCH (s:User {id: $id})--&gt;()--&gt;()--&gt;()--&gt;(n:User) RETURN DISTINCT n.id;`                                  | ANALYZE     |
| 2-Hop Variable Expand             | `MATCH (s:User {id: $id})-[*1..2]-&gt;(n:User) RETURN DISTINCT n.id;`                                          | ANALYZE     |
| 2-Hop Variable Expand with Result | `MATCH (s:User {id: $id})-[*1..2]-&gt;(n:User) RETURN DISTINCT n.id, n;`                                       | ANALYZE     |
| Shortest Path                     | `MATCH p=(n:User {id: $from})-[*bfs..15]-&gt;(m:User {id: $to}) RETURN extract(n in nodes(p) | n.id) AS path;` | ANALYZE     |
| Insert New Relationship           | `MATCH (n:User {id: $from}), (m:User {id: $to}) WITH n, m CREATE (n)-[e:Temp]-&gt;(m) RETURN e;`               | CREATE      |
| Find Node                         | `MATCH (n:User {id : $id}) RETURN n;`                                                                       | READ        |
| Insert a New Node                 | `CREATE (n:UserTemp {id : $id}) RETURN n;`                                                                  | CREATE      |
</code></pre>
<p>The benchmarking harness executed all queries against the <a href="https://snap.stanford.edu/data/soc-Pokec.html">Pokec dataset</a> which contains 1.6M nodes and 30.6M edges. Given that the goal of each benchmark is to saturate the target system to extract its peak characteristics, we took great care in carefully designing and polishing our setup. Some of the essential elements of the harness are:</p>
<ul>
<li>optimized C/C++ client to minimize client overhead.</li>
<li>fresh dataset load before each execution.</li>
<li>concurrent execution (up to 12 cores) to push Memgraph to its limits.</li>
</ul>
<h2>Data Import Analysis</h2>
<p>Before delving deep into the workload queries execution analysis, a couple of notes about the data import.</p>
<p>The harness imported data in a real-time manner, equivalent to normal query execution by running queries. The data was imported using 8 concurrent clients.  Throughput and peak memory usage were measured during the data import. A couple of interesting insights emerged. On the memory usage side, there is already a massive difference between Memgraph versions. <strong>Before v0.50.0</strong>, Memgraph stored all data modifications as whole copies of the modified objects. By removing the need to make whole copies of database objects, versions <strong>after v0.50.0</strong> provide a significantly less memory usage. The same benefits apply to the runtime environment since the import uses regular queries.</p>
<p><img src="https://i.imgur.com/VfDzuCw.png" alt=""></p>
<p>At this point, you might be wondering about the import speed. As the chart below shows, throughput on basic CREATE queries also improved. Since data copying is generally a fast operation, throughput improvement is not huge but is still significant. One important thing to notice is the difference between v1.0.0 and v1.1.0. <strong>v1.1.0</strong> has almost the same throughput as versions before even though more work is involved in property compression.</p>
<p><img src="https://i.imgur.com/hsh6uDj.png" alt=""></p>
<h2>Query Execution Analysis</h2>
<p>Let‚Äôs start analyzing the <strong>workload queries</strong>. The following radar chart shows peak memory usage during query execution across different Memgraph versions. Keep in mind that less is better.</p>
<p>As you can see, <strong>v1.1.0 uses ~50%</strong> less memory compared to v0.15.2. v0.50.0 and v1.0.0 fall in-between with almost no difference because not much from the storage perspective changed between these two versions. The most significant difference is between v0.15.2 and v0.50.0 (introduction of the new storage engine), and v1.0.0 and v1.1.0 (introduction of encoded and compressed properties).</p>
<p><img src="https://i.imgur.com/4ETpDXT.png" alt=""></p>
<p>On the other hand, while looking at memory, it‚Äôs also critical to observe what is happening with the throughput. Generally, there is a well-known trade-off between space and time. But, as you can see in the following chart, v1.1.0 has the best performance. Please note that in this case, more is better.</p>
<p><img src="https://i.imgur.com/c0nBqJS.png" alt=""></p>
<p>Of course, not all queries yield significant throughput improvements. E.g., the <code>Insert New Node</code> query performance stayed similar across different Memgraph versions. Nonetheless, the following chart illustrates well how Memgraph scales with the number of concurrent requests.</p>
<p><img src="https://i.imgur.com/vIy7rTM.png" alt=""></p>
<p>The new storage engine also introduced a feature where it is possible to disable storing properties on edges. Sometimes graph datasets don‚Äôt have any data attached to edges. Memgraph offers a configuration option to remove all associated data structures required to store data on edges. As you can see in the following chart, by not having properties on edges, memory usage goes down by almost 50% (in addition to the reductions mentioned above). v0.15.2 can‚Äôt disable the property storage on edges, so the chart shows nothing there. Using all the improvements in new versions of Memgraph you can store the same dataset in 3.36x less memory (comparing v0.15.2 with properties enabled and v1.1.0 with properties disabled).</p>
<p><img src="https://i.imgur.com/PtQviBf.png" alt=""></p>
<p>The rest of the charts show performance for each query with regards to linear scalability. Linear scalability is the ability of a system to handle more work by adding more resources linearly. E.g., by doubling the number of cores, the system is capable of executing twice as many queries. In practice, it‚Äôs impossible to reach perfect linear scalability due to various overheads.  The real question is how far Memgraph is from linear scalability? As you can see below, not by a lot.</p>
<p>The following chart shows throughput data for the simple read query (Find Node). The node lookup inside Memgraph has an O(logN) complexity.</p>
<p><img src="https://i.imgur.com/0z46Rg5.png" alt=""></p>
<p>In the next case, instead of reading, Memgraph creates an edge. The operation contains two node lookups and one edge write. Which means it‚Äôs very similar to the Find Node query. Instead of one lookup, the action has two lookups and one write. The chart looks very similar to the Find Node chart.</p>
<p><img src="https://i.imgur.com/ZWzeFc6.png" alt=""></p>
<p>By moving towards more complex queries, there is a more significant scalability difference between previous versions of Memgraph and the latest ones. v0.15.2 is far behind the latest versions.</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://memgraph.com/blog/memgraph-1-1-benchmarks">https://memgraph.com/blog/memgraph-1-1-benchmarks</a></em></p>]]>
            </description>
            <link>https://memgraph.com/blog/memgraph-1-1-benchmarks</link>
            <guid isPermaLink="false">hacker-news-small-sites-24651091</guid>
            <pubDate>Thu, 01 Oct 2020 14:19:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ElasticSearch Query Builder]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650651">thread link</a>) | @piranha
<br/>
October 1, 2020 | https://solovyov.net/blog/2020/elasticsearch-query-builder/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/elasticsearch-query-builder/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p>This post strives to be useful to anyone who uses ElasticSearch, but all examples are going to be in Clojure since it‚Äôs what we use.</p>
<p>ElasticSearch is a wildly useful database (if I may say so), but at times it feels like its query language evolved rather than was planned. This manifests in it being rather ad-hoc and non-orthogonal. Plus using JSON with its low expressiveness adds quite a bit of verbosity. All of this leads to code which builds ES queries being messy and unpleasant to use.</p>
<h2 id="jump-in">Jump in</h2>
<p>Certainly, this was our case a few years ago. Our code was a bunch of functions calling one another, which sounds like functional programming and should be fine, right? Well, as always, the devil is in the detail, and:</p>
<ul>
<li><code>if</code>/<code>case</code>/<code>cond</code> everywhere, various cases were piling on top of each other</li>
<li><a href="https://solovyov.net/blog/2020/higher-order-functions/">functions parametrized with functions</a> ‚Äî it‚Äôs a good tool if you make some higher-order well-documented/understood function, but your business logic should be free of this stuff in general; makes logic hard to be understood</li>
<li>code factorization was quite a bit off: function boundaries felt a bit random</li>
<li>it was written at the start of the current codebase, grew with it and just happened, was never planned</li>
</ul>
<p>Our use case, by the way, is a product filtering API (facets and all that stuff) for an ecommerce site, <a href="https://kasta.ua/">Kasta</a>. Apply some filters and retrieve some aggregations, which is enough of a problem to need a proper solution.</p>
<h2 id="what-is-out-there">What is out there</h2>
<p>So where to go? I looked around and saw stuff like <a href="https://elasticsearch-dsl.readthedocs.io/en/latest/">elasticsearch-dsl</a>, which was just like ES data structures, but methods on mutable objects. Ugh. Also, <a href="https://elastic-builder.js.org/docs/">ElasticBuilder</a>, which is similar, but with different names, so you have to remember two layers of abstraction. Thanks, but no.</p>
<p>And there are a lot of articles on how to make a query to get what you need from ES, but nobody wrote an article on how to make an ES query builder! Well, except for me. :-)</p>
<h2 id="solution">Solution</h2>
<p>What I like in terms of API is <a href="https://github.com/seancorfield/honeysql">HoneySQL</a>, which is a compiler from maps/vectors to SQL queries. This got me thinking and it turns out that a good question is half of the answer.</p>
<p>What we need is a compiler from our API interface ‚Äî GET request query string ‚Äî to an ES query.</p>
<p>Rephrased like this it makes the task almost a walk in the park. A long-long walk, but much less ‚Äúhere be dragons‚Äù if-peppered abomination of the past. And the design cornerstones are:</p>
<ul>
<li>branchless pipeline</li>
<li><a href="https://clojuredocs.org/clojure.core/defmulti">multimethods</a></li>
<li>small dictionary of verbs on top of ES incantations</li>
</ul>
<h3 id="data-format">Data format</h3>
<p>Some time ago I stumbled upon a great article about working with ES, and one of its parts <a href="https://project-a.github.io/on-site-search-design-patterns-for-e-commerce/#generic-faceted-search">describes a data model</a> they have used. It proposes that instead of a map like <code>{:brand "wow" :color "red"}</code> you use a following structure:</p>
<pre><code>{:facets [{:name "brand"
           :value "wow"}
          {:name "color"
           :value "red"}]}
</code></pre>
<p>This allows you to query all those facets with a single definition, rather than sending a separate aggregation for every field. More than that, you don‚Äôt need to know which facets are available for filtering upfront, since you‚Äôll receive all of them from ES.</p>
<p>In practice, two lists of facets are needed - regular ones and ranged facets. Regular facets are aggregated by <code>terms</code> aggregation, and ranged are aggregated by a combo of <code>ranges</code> and <code>percentiles</code>.</p>
<h3 id="verbs">Verbs</h3>
<p>So we have several functions like <code>not</code>, <code>and</code>, <code>or</code>, <code>term=</code>. They signal intent rather than what ES is doing inside and make reading aggregations and filters much easier. Or should I say <code>should</code> easier? Or <code>must</code> easier? :-) You can understand what‚Äôs it doing without opening ES docs. Some examples:</p>
<pre><code>(defn or* [&amp; clauses]
  (let [clauses (filterv identity clauses)]
    (cond
      (empty? clauses)
      {:bool {}}

      (= 1 (count clauses))
      (first clauses)

      :else
      {:bool {:should               clauses
              :minimum_should_match 1}})))


(defn facet= [k v]
  {:nested {:path  "facets"
            :query (and* (term= "facets.id" k)
                         (term= "facets.value" v))}})
</code></pre>
<p>What they accomplish is that most of our lower-level use cases are covered with ‚Äúloaded‚Äù terminology rather than ‚Äúneutral‚Äù (and often cryptic) ES maps.</p>
<h3 id="pipeline">Pipeline</h3>
<p>The pipeline is 4 steps:</p>
<ul>
<li><code>qs-&gt;query</code> parses query string, cookies, headers into a basic query data structure</li>
<li><code>make-aggs-q</code> loops through supplied filters and known aggregations, and builds an ES query</li>
<li>then a query is executed</li>
<li><code>aggs-&gt;response</code> converts ES response to what our API returns</li>
</ul>
<p>We represent a user query internally with a map like that:</p>
<pre><code>{:base    {"menu" "pants"}
 :filters {"1" #{"123" "456"}}
 :sort    :default
 :cursor  "ZXCVB"
 :limit   100}
</code></pre>
<p>This is easier to interact with than with just a raw query string.</p>
<h3 id="make-aggs-q">make-aggs-q</h3>
<p>This part is the most convoluted one. It builds the essence of an ES query for aggregations, and consists of:</p>
<ul>
<li>loop over known non-facet aggregations</li>
<li>loop over every facet which was used as a filter in a query</li>
<li>query for regular facets</li>
<li>query for ranged facets</li>
</ul>
<p>What is a facet aggregation is described in <a href="#data-format">data format</a> section. All other aggregations are non-facet and should be explicitly mentioned. Those are filters such as price, depot (whenever they are on stock in our warehouse rather than supplier‚Äôs one), supplier, etc. When I look there it feels like most of them need to be in facets. Historical reasons. :)</p>
<p>Every loop then delegates to <code>make-agg</code> multimethod, which builds its piece of the query. Here is an example of a filter for colors - it‚Äôs one of the simplest aggregations, just generates a list of colors available for selected products.</p>
<pre><code>(def NESTED-AGG :_nest)

(defn agg-filter [agg filter-data]
  {:filter filter-data
   :aggs   {NESTED-AGG agg}})

(defmethod make-agg :color [filter-name _ filters options]
  [filter-name
   (-&gt; {:terms {:field "color_group"
                :size  (:max-buckets options)}}
       (agg-filter (filters/make filters)))])

</code></pre>
<p><code>filters</code> are filters for the given query except for the one for the given aggregation, so that you‚Äôll receive all possible values for the current aggregation in a given context. So we apply them with an <code>agg-filter</code> function.</p>
<p><code>-&gt;</code> could be confusing, but look at it as a pipeline operator: every function you give it is executed in order.</p>
<p>ElasticSearch aggregation rules are nested, read on to discover why we need <code>NESTED-AGG</code>.</p>
<h3 id="aggs-response">aggs-&gt;response</h3>
<p>This stage loops over response and converts data from ES into API response format. Fortunately most parts of the response are independent, so it‚Äôs pretty clean and simple: it‚Äôs a loop, which calls <code>extract-agg</code> on every aggregation:</p>
<pre><code>(defn agg-recur [{:keys [doc_count] :as agg}]
  (loop [agg agg]
    (if-let [nested (get agg NESTED-AGG)]
      (recur nested)
      (if-not (:doc_count agg)
        (assoc agg :doc_count doc_count)
        agg))))

(defn aggs-&gt;response [query es-response]
  (for [[k agg] (:aggregations es-response)
     (extract-agg k (agg-recur agg) query))
</code></pre>
<p><code>agg-recur</code> is a way to get to the real data: ES aggregations are very nested. To get through we use key <code>:_nest</code> (value of <code>NESTED-AGG</code>), and then use this <code>agg-recur</code> function.</p>
<p>Unfortunately, there is no good way to pass additional information from <code>make-agg</code> to <code>extract-agg</code>, so it‚Äôs stringly-typed, as is <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.x/returning-aggregation-type.html">recommended by ES</a>. Look at our <code>extract-agg</code> multimethod (<code>defmulti</code> defines dispatcher, this is a function which determines which method to call):</p>
<pre><code>(defmulti extract-agg
  (fn [filter-name data query]
    (condp #(str/starts-with? %2 %1) filter-name
      "facet_"      :facet
      "percentile_" :percentile
      "range_"      :range
      :else         filter-name)))
</code></pre>
<p><code>extract-agg</code> methods extract data, sort if necessary (so brands are alphabet-sorted rather than count of matches-sorted), fix up document count (in case of nested aggregations). Here‚Äôs an example processing <code>:depot</code>:</p>
<pre><code>(defmethod extract-agg :depot [filter-name agg query]
  (let [cnt (-&gt; agg :real_count :doc_count)]
    [{:id        filter-name
      :widget    :toggle
      :values    [{:key       "true"
                   :doc_count cnt}]
      :doc_count cnt}]))
</code></pre>
<p>That part is pretty simple since you just have to massage data into whatever you need for the API. :)</p>
<h2 id="divide-and-conquer">Divide and conquer</h2>
<p>There is nothing new under the sun. If only the right idea would appear right at the start. :-) Just factor your functions correctly and you‚Äôre golden.</p>
<p>In the end what we‚Äôve got is a straightforward pipeline, no parametrization with functions, every chunk of a query is as simple as it gets, and extensibility is just great! It‚Äôs been in production for 1.5 years now with no significant changes to the logic, received some new features, and doesn‚Äôt feel like it was holding us back.</p>
<p>I hope this post can serve as an inspiration for your code. If you feel confused or have questions, please contact me by email ‚Äî I would love to make this post more approachable.</p>
</div></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/elasticsearch-query-builder/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650651</guid>
            <pubDate>Thu, 01 Oct 2020 13:38:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ontario police used Covid-19 database illegally, civil rights groups find]]>
            </title>
            <description>
<![CDATA[
Score 248 | Comments 70 (<a href="https://news.ycombinator.com/item?id=24650515">thread link</a>) | @seigando
<br/>
October 1, 2020 | https://www.cbc.ca/news/canada/toronto/covid-police-database-1.5745481 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/toronto/covid-police-database-1.5745481">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Police forces across&nbsp;Ontario&nbsp;engaged in broad, illegal searches&nbsp;of a now-defunct COVID-19 database, two civil rights groups alleged Wednesday, claiming the use of the portal violated individual privacy rights for months.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5704129.1598642644!/cumulusImage/httpImage/image.jpg_gen/derivatives/16x9_780/shutterstock-medium-file-typing-on-laptop.jpg"></p></div><figcaption>The Canadian Civil Liberties Association and the Canadian&nbsp;Constitution Foundation say in separate reports that many services used the database to look at COVID-19 test results for wide geographic areas and sometimes pulled up personal information unrelated to active calls.<!-- --> <!-- -->(maradon 333 / Shutterstock)</figcaption></figure><p><span><p>Police forces across&nbsp;Ontario&nbsp;engaged in broad, illegal searches&nbsp;of a now-defunct COVID-19 database, two civil rights groups alleged Wednesday, claiming the use of the portal violated individual privacy rights for months.</p>  <p>The Canadian Civil Liberties Association (CCLA) and the Canadian&nbsp;Constitution Foundation (CCF) said in separate reports that many services used the database to look at COVID-19 test results for wide geographic areas and sometimes pulled up personal information unrelated to active calls.</p>  <p>"People weren't told that when they went for COVID tests that&nbsp;this information was being shared with police and they certainly weren't asked for their consent," said Abby Deshman, the criminal&nbsp;justice program director for the CCLA.&nbsp;</p>  <p>"That should be a decision every person makes about what they&nbsp;want to do with their own personal medical information."</p>  <p>In early April, the&nbsp;Ontario&nbsp;government passed an emergency order&nbsp;that allowed police to obtain the names, addresses and dates of birth of Ontarians who had tested positive for COVID-19. The portal was aimed at helping to protect first responders.</p>  <p>Police access to that database ended on Aug. 17, after a legal&nbsp;challenge was filed by a group of human rights&nbsp; organizations.</p>  <p>The group, which included the CCLA, argued that allowing police&nbsp;to access personal health records violated individuals'<br> constitutional rights to privacy and equality.</p>  <h2>Police conducted 95,000 searches of database</h2>  <p>Data released in the context of the legal action showed that&nbsp; Ontario&nbsp;police services conducted over 95,000 searches of the&nbsp;database while it was active.</p>  <p>The CCF filed a freedom of information act request to the&nbsp;province related to police use of the database.&nbsp;</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>Police were caught using the COVID-19 database to look up names&nbsp;unrelated to active calls, to do wholesale postal&nbsp; code searches for COVID-19 cases, and to even do broad based searches outside officers' own cities.<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Christine Van Geyn, Canadian Constitution Foundation</cite></span></blockquote>    <p>On Wednesday, the CCF made public a June memo from the Solicitor&nbsp;General's office to chiefs of police that warned against using the&nbsp;database beyond the "express purpose" of the emergency order.</p>  <p>The CCF said the memo revealed a "shocking misuse" of personal&nbsp;health information by police.</p>  <p>"Police were caught using the COVID-19 database to look up names&nbsp;unrelated to active calls, to do wholesale postal&nbsp; code searches for COVID-19 cases, and to even do broad based searches outside officers' own cities," said CCF litigation director, Christine Van&nbsp;Geyn.&nbsp;<span><ul><li><a href="https://www.cbc.ca/news/canada/toronto/covid-ont-police-database-1.5690220" data-contentid="" flag="" text="Ontario ends police access to COVID-19 database after legal challenge"><span>Ontario ends police access to COVID-19 database after legal challenge</span></a></li></ul></span></p>  <p>The CCF said it has filed a complaint with&nbsp;Ontario's privacy&nbsp;commissioner over violations of the Personal Health Information Protection Act, and with the&nbsp;Ontario&nbsp;Independent Police Review Director for officer misconduct.</p>  <p>Meanwhile, the CCLA sent letters to 37 police forces, asking them&nbsp;for details of how the database was used and if any information was retained from it.</p>  <p>Twenty-three responded and Deshman said she expects more to do&nbsp;so.</p>  <h2>Thunder Bay, Durham police conducted more than 40% of searches</h2>  <p>Many forces found the database difficult to use and resorted to&nbsp;problematic broad searches in an attempt to find workarounds, the CCLA said.</p>  <p>The association notes that more than 40 per cent of the 95,000&nbsp;searches of the database were conducted by either the Thunder Bay police or Durham Region police.&nbsp;</p>    <p>In Durham Region, police continued to run unauthorized searches&nbsp;even after provincial audits called attention to the inappropriate&nbsp;searches taking place, the CCLA said. The force's access to the portal was cut off by the province as a result, the CCLA said.</p>  <p>"Durham is a particularly concerning example," said Deshman.&nbsp;"In those cases there needs to be disclosure (to citizens whose information was accessed) and accountability by following up with the individuals in the police service that looked up information inappropriately."</p>  <h2>Anyone concerned can contact police, privacy commissioner&nbsp;</h2>  <p>Holly Walbourne, the legal counsel for Thunder Bay police, said&nbsp;in a letter sent to the groups that filed the legal challenge that&nbsp;the force understood their concerns but that police had "lawful authority" to use the database to protect first responders.</p>    <p>Durham police Supt. Peter Cousins wrote a report to the force's&nbsp;police services board on the issue on Sept. 1 saying&nbsp; access to theportal and its information was treated "seriously and with due care."&nbsp;</p>  <p>Toronto police never used the database because of "issues with&nbsp;the accuracy and reliability of the information," the CCLA reported. York Region police said they asked the province to revoke access to the database after an internal review found the risks associated with accessing personal health information outweighed any benefits.</p>  <p>Deshman said anyone concerned about police access to the province's COVID-19 database should contact their local police force&nbsp;and the&nbsp;Ontario&nbsp;Privacy Commissioner.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/toronto/covid-police-database-1.5745481</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650515</guid>
            <pubDate>Thu, 01 Oct 2020 13:23:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Not PHP?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650385">thread link</a>) | @muglug
<br/>
October 1, 2020 | https://mattbrown.dev/articles/why-not-php | <a href="https://web.archive.org/web/*/https://mattbrown.dev/articles/why-not-php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <article>
                                
                <p>
                    October 1, 2020 - 
                                            4&nbsp;minute&nbsp;read
                                    </p>
                                <!--
	title: Why not PHP?
	date: 2020-10-01
    author: Matt Brown
    author_link: https://twitter.com/mattbrowndev
-->
<p>I was intrigued by <a href="https://matklad.github.io/2020/09/20/why-not-rust.html">Why Not Rust</a>, a list of compelling disadvantages written by someone who uses Rust a lot, and the author of <a href="https://github.com/rust-analyzer/rust-analyzer">a popular Rust static analysis tool</a>. I have a similar relationship to PHP ‚Äì I use it every day (at <a href="https://vimeo.com/">Vimeo</a>), and I‚Äôm the author of <a href="https://psalm.dev/">a popular PHP static analysis tool</a>.</p>
<p>The similarities end there, though ‚Äì Rust and PHP are very different languages, with very different reputations in the wider programming community. Rust has been getting a lot of hype in the last few years, while PHP has been getting the opposite. Indeed, a lot has been written about PHP from a place of contempt. Here‚Äôs my attempt to argue against PHP, but from a place of admiration:</p>
<h2 id="its-mainly-for-serving-simple-http-requests">It‚Äôs mainly for serving simple HTTP&nbsp;requests</h2>
<p>PHP was originally designed for the then-nascent world wide web, and its popularity has risen (and, lately, fallen) with the popularity of server-rendered HTML.</p>
<p>Its process model (no shared memory between requests) makes it ideal for serving HTML on a case-by-case basis. If that‚Äôs what you‚Äôre after, it‚Äôs incredibly easy to get started.</p>
<p>On the one hand that means the average PHP programmer never has to worry about memory-related race conditions within a single request, because they simply can‚Äôt happen.</p>
<p>But all of PHP‚Äôs optimisations for serving individual HTML requests will get in the way if you do, in fact, want to run your own service with shared memory between requests, or any other long-running process. While PHP <em>can</em> do that, its implementation won‚Äôt be half as pretty as it would be in a language like Go.</p>
<h2 id="its-relatively-old">It‚Äôs (relatively)&nbsp;old</h2>
<p>New programming languages are often a thoughtful combination of languages that came before them. Writing code in a recently-written language can expose you to new idioms, and helps you see the world of programming through a different lens.</p>
<p>PHP is not a new language ‚Äì it‚Äôs 26 years old, and pretty thoroughly-cooked at this point.</p>
<h2 id="no-large-corporate-backers">No large corporate&nbsp;backers</h2>
<p>Some languages come directly from large profitable companies that devote considerable resources to their development (e.g. Go, TypeScript, C#, Swift, Java, Kotlin) while others are sort of adopted by companies (Python at Dropbox, OCaml at Jane St, JS interpreters at Google &amp; Mozilla).</p>
<p>PHP hasn‚Äôt had a large corporate backer for a while. As far as I know, only one PHP core engineer is <a href="https://blog.jetbrains.com/phpstorm/2019/01/nikita-popov-joins-phpstorm-team/">paid to work on the language full-time</a>.</p>
<p>Large corporate sponsors can be great for a language. Sponsorship sends a message to other companies that ‚Äúwe trust X to help run our billion-dollar business‚Äù and also ‚Äúif you use X you‚Äôll benefit from the work we‚Äôre putting into it‚Äù.</p>
<p>PHP‚Äôs community is pretty strong, though, and has produced some <a href="https://getcomposer.org/">great</a> <a href="https://phpunit.de/">pieces</a> of <a href="https://symfony.com/">software</a> that have moved the entire ecosystem forward.</p>
<h2 id="many-beginners-few-experts">Many beginners, few&nbsp;experts</h2>
<p>PHP is very easy to get into, and it‚Äôs easy to make things in PHP that other people find useful.</p>
<p>PHP‚Äôs community is also sort of like a high school, where other language communities (e.g. Rust) are like universities: the teachers in a high school can make you a productive member of society, but if you‚Äôre looking to surround yourself with professors who are specialists in things you find interesting, universities are a better bet.</p>
<p>This reputation problem isn‚Äôt unique to PHP ‚Äì other popular interpreted languages like Ruby have it too ‚Äì but it can deter people who want to feel smart when writing code.</p>
<p>JavaScript had this problem for years, but in the last decade several big internet companies have thrown tons of money at its language ecosystem, and JavaScript experts are now plentiful.</p>
<h2 id="it-has-many-minor-potholes">It has many minor&nbsp;potholes</h2>
<p>API inconsistency comes up repeatedly in peoples‚Äô criticism of PHP. While it‚Äôs something the vast majority of PHP developers get used to quickly, there‚Äôs no getting around the clunkiness of some core library functions: <code>strpos($haystack, $needle)</code> vs <code>in_array($needle, $haystack)</code> and <code>array_map($callback, $array)</code> vs <code>array_filter($array, $callback)</code>.</p>
<hr>
<h2 id="where-do-we-go-from-here">Where do we go from&nbsp;here?</h2>
<p>People have been predicting its demise for a couple of decades, but PHP‚Äôs still a pretty popular option. Why? Despite everything written above, there‚Äôs never been a better time to start a new PHP project.</p>
<p>PHP now has a huge ecosystem of open-source packages, and its main download hub has been accessed <a href="https://packagist.org/statistics">over a billion times last month</a> by developers around the world. That‚Äôs up roughly 50% from the year before, and doubly impressive once you factor in all the things PHP can do natively.</p>
<p>There‚Äôs also good reason to be optimistic about PHP‚Äôs future. Ten years ago, things were looking much more dire, but the community has invested a lot of time and effort into improving things:</p>
<ul>
<li>
<strong>Package management</strong><br>
<a href="https://getcomposer.org/">Composer</a>, introduced in 2012, has made setting up a new project a breeze</li>
<li>
<strong>Static analysis</strong><br>
A bunch of great competing static analysis tools (including my own, <a href="https://psalm.dev/">Psalm</a>) have been released in the last five years</li>
<li>
<strong>Raw performance</strong><br>
At Vimeo time spent in PHP itself has roughly halved since we upgraded from PHP 5 to PHP 7. Each new version squeezes out a little more speed, and PHP handily outperforms similar interpreted languages like Ruby, Python and Node</li>
<li>
<strong>Standard ways to write modern PHP</strong><br>
<a href="https://www.php-fig.org/psr/">PSR</a> emerged from a primordial soup of spaghetti code, and now pretty much all modern PHP looks very similar</li>
</ul>
<hr>
<p><a href="https://www.reddit.com/r/PHP/comments/j37zih/why_not_php/">Discuss on /r/php</a></p>
            </article>
        </div></div>]]>
            </description>
            <link>https://mattbrown.dev/articles/why-not-php</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650385</guid>
            <pubDate>Thu, 01 Oct 2020 13:07:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russian Opposition Leader Navalny on His Poisoning: ‚ÄúPutin Was Behind the Crime‚Äù]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650372">thread link</a>) | @rerx
<br/>
October 1, 2020 | https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;54d78056-207d-4c6f-b894-b46c2774c039&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;12351542-b015-4f5c-8965-83eb2bdccdc3&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/54d78056-207d-4c6f-b894-b46c2774c039_w948_r1.77_fpx58_fpy45.jpg" srcset="https://cdn.prod.www.spiegel.de/images/54d78056-207d-4c6f-b894-b46c2774c039_w520_r1.77_fpx58_fpy45.jpg 520w, https://cdn.prod.www.spiegel.de/images/54d78056-207d-4c6f-b894-b46c2774c039_w948_r1.77_fpx58_fpy45.jpg 948w" width="948" height="536" sizes="948px">
</span>
</span>
</span>

</p>
<figcaption>
<span>
Foto:‚ÄÇ<p>Peter Rigaud / DER SPIEGEL</p>
</span>
</figcaption>
</figure>
</div><div>
<p>It's six o'clock in the morning on Wednesday when Alexei Navalny shows up at the Berlin editorial office of DER SPIEGEL for an interview. The office is located a few hundred meters from Charit√© University Hospital, where Navalny spent a month receiving treatment, hovering between life and death.</p>


<div>
<p>Navalny, who was poisoned with the nerve agent Novichok, was only released from the hospital last week.</p><p>Four agents from the State Office of Criminal Investigation (LKA) accompanied him during his visit. Navalny, who wasn't able to walk not long ago, took the stairs to the office rather than the elevator.</p><p>Alexei Navalny, 44, is Russia's most prominent opposition politician. Following the attempt on his life on August 20 in the Siberian city of Tomsk, however, he is now squarely in the international spotlight. German Chancellor Angela Merkel intervened for him to be allowed to leave Russia for treatment in Germany. Because he was poisoned with a substance that can essentially only come from state-run laboratories in Russia, the question of Russian President Vladimir Putin's personal responsibility is one that many around the world are asking. It's not the first time that a Russian opposition politician was to be killed, but it is the first time that the circumstances seem to so clearly point at the Kremlin.</p>
</div>

<div>
<p>The interview with DER SPIEGEL is the first that Navalny has given since the attack. He is alert at the meeting and he remembers many things - and yet the impact of the poisoning is still clear. Scars on his neck show where he was hooked up to a ventilator. When he pours water from the bottle into his glass, it is obvious that it requires effort and he has to use both hands. But he refuses assistance. "My physical therapist says I should try to do everything myself," he says</p><p>Navalny&nbsp;seems more nervous than he did at previous meetings. His face is gaunter and his figure more angular after losing 12 kilos. But his voice is the same as it has always been, as is his humor, his irony. Sitting next to him is his spokeswoman, Kira Yarmysh, who was with him on the plane on August 20 when he first began showing signs of having been poisoned.</p>
</div>

<p>Before the interview begins, he has something he wants to say.</p>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;02a833ee-fba3-4850-98b7-7c4ed3654454&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;a388a95a-55fe-4743-aa4e-d446c12c4916&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w683_r1.3714859437751004_fpx36.46_fpy50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w488_r1.3714859437751004_fpx36.46_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w616_r1.3714859437751004_fpx36.46_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w683_r1.3714859437751004_fpx36.46_fpy50.jpg 718w," width="683" height="498" sizes="683px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w488_r1.3714859437751004_fpx36.46_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w616_r1.3714859437751004_fpx36.46_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/02a833ee-fba3-4850-98b7-7c4ed3654454_w683_r1.3714859437751004_fpx36.46_fpy50.jpg 718w," title="This photo was taken in Navalny's hotel room in Tomsk, where his team secured water bottles and other objects. One of the bottles contained traces of the poison." alt="This photo was taken in Navalny's hotel room in Tomsk, where his team secured water bottles and other objects. One of the bottles contained traces of the poison.">
</span>
</span>
</span>
</p><figcaption>
<p>This photo was taken in Navalny's hotel room in Tomsk, where his team secured water bottles and other objects. One of the bottles contained traces of the poison.</p>
<span>
Foto:‚ÄÇAFP
</span>
</figcaption>
</div>
</div>
</div>
</figure><p><strong>Navalny:</strong> It is important to me that this interview appears in the German press. I have never been closely associated with Germany. I don't know anyone here. I didn't know a single politician. And yet it turned out - you see, my voice is trembling, I have become so emotional - that German politicians and Angela Merkel have taken an interest in my fate and saved my life. The doctors at Charit√© saved my life a second time and, more importantly, they gave me back my personality. So, the first thing I want to say is: I feel a tremendous gratitude to all Germans. I know it sounds a bit overblown, but Germany has become a special country for me. I had few connections here before and only visited Berlin for the first time three years ago! And then so much human compassion from so many people.</p>

<div>
<p><strong>DER SPIEGEL:</strong> Our readers will be happy to hear that. How are you doing Mr. Navalny?</p><p><strong>Navalny:</strong> Much better than three weeks ago, and it is getting better each day. Not long ago, I could only climb 10 steps, but now I can make it up to the 5th floor. The most important thing for me is that my mental abilities have returned. Well, maybe we will find the opposite to be true during this interview (<em>laughs</em>).</p><p><strong>DER SPIEGEL:</strong> You wrote on Instagram that you are no longer able to stand on one foot.</p><p><strong>Navalny:</strong> Now I can again. My next challenge is to stand on one leg and stretch the other leg forward, which I practice every day. These are actually exercises that ninety-year-olds do in the park.</p><p><strong>DER SPIEGEL:</strong> Are you able to sleep well?</p><p><strong>Navalny:</strong> That's my biggest problem. I used to laugh about people with sleep problems because I never had them myself. But then came the coma, the anesthesia, the weaning off of the sedatives, that long hovering state when I was neither asleep nor awake. I haven't been able to sleep without sleeping pills since.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;ae3d6308-8e23-4f16-b6a0-25e3b742c41c&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;ceb52055-f551-451b-932f-4be2851ee145&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w683_r1.3742454728370221_fpx62.38_fpy49.9.jpg" srcset="https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w488_r1.3742454728370221_fpx62.38_fpy49.9.jpg 488w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w616_r1.3742454728370221_fpx62.38_fpy49.9.jpg 616w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w683_r1.3742454728370221_fpx62.38_fpy49.9.jpg 718w," width="683" height="497" sizes="683px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w488_r1.3742454728370221_fpx62.38_fpy49.9.jpg 488w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w616_r1.3742454728370221_fpx62.38_fpy49.9.jpg 616w, https://cdn.prod.www.spiegel.de/images/ae3d6308-8e23-4f16-b6a0-25e3b742c41c_w683_r1.3742454728370221_fpx62.38_fpy49.9.jpg 718w," title="Navalny was flown from Omsk to Berlin on this chartered plane." alt="Navalny was flown from Omsk to Berlin on this chartered plane.">
</span>
</span>
</span>
</p><figcaption>
<p>Navalny was flown from Omsk to Berlin on this chartered plane.</p>
<span>
Foto:‚ÄÇKira Yarmysh / dpa
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p><strong>DER SPIEGEL:</strong> When you lost consciousness, you were a figure in Russian politics. When you woke from the coma, you were a global political figure. Chancellor Merkel even visited you at your bedside. What did you talk about?</p><p><strong>Navalny:</strong> That was last week. It was totally unexpected. The door opened, my doctor came in - and Merkel. It was a private meeting with my family - my wife Julia and my son Zahar were there. I can't tell you the details, but we didn't discuss anything secret or sensational. The visit was a gesture. I was impressed by how precisely she knows Russia and my case. She knows some of the details better than I do. She really has a deep understanding of what is going on in Russia. And when you talk to her, you understand why she has been at the top in Germany for so long. I thanked her for her efforts and she said: "I only did my duty."</p><p><strong>DER SPIEGEL:</strong> What has daily life been like for you since you left the hospital? Where are you living?</p><p><strong>Navalny:</strong> I live with my wife and my son here. My daughter has returned to Stanford University. We've rented an apartment. My everyday life is monotonous. I exercise daily - that's all I do. In the morning, I take a walk in the park - that's my job. Then I do the exercises with the doctor. In the evening, I go for another walk. During the day, I try to work on the computer. The doctors say I can be restored to 90 percent of my former self, maybe even 100 percent, but nobody really knows for sure. Basically, I'm a bit of a guinea pig. After all, there aren't many people you can observe who are still alive after being poisoned with a nerve agent. At some point, I will probably be written about in medical journals. And I am happy to share my experiences. Seriously: The Russian leadership has developed such a penchant for poisoning that it is not going to stop doing so anytime soon. My medical history will be instructive.</p><p><strong>DER SPIEGEL:</strong> Going by your posts on social media, it appears that you left your bed in the hospital often.</p><p><strong>Navalny:</strong> The doctors and nurses at Charit√© are the most tolerant people in the world. I was a difficult patient. I would get up at night in the intensive care unit, and one time I tore all the tubes out of my body and started bleeding. Later, when I was already conscious and could recognize and talk to the people around me, I had hysterical fits. I said I was healthy and wanted to go to a hotel. Weeks later, I understood that this strange behavior was a consequence of the poisoning.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;39d3599b-4262-4232-b6f7-b6016c2162e6&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;af4cd678-faa0-4983-a94b-e66a219e0438&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w718_r1.4145383104125737_fpx49.45_fpy50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w488_r1.4145383104125737_fpx49.45_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w616_r1.4145383104125737_fpx49.45_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w718_r1.4145383104125737_fpx49.45_fpy50.jpg 718w" width="718" height="508" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w488_r1.4145383104125737_fpx49.45_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w616_r1.4145383104125737_fpx49.45_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/39d3599b-4262-4232-b6f7-b6016c2162e6_w718_r1.4145383104125737_fpx49.45_fpy50.jpg 718w" title="A first sign of life: Navalny with his children Daria and Zahar and his wife Yulia in his room at Berlin's Charit√© University Hospital" alt="A first sign of life: Navalny with his children Daria and Zahar and his wife Yulia in his room at Berlin's Charit√© University Hospital">
</span>
</span>
</span>
</p><figcaption>
<p>A first sign of life: Navalny with his children Daria and Zahar and his wife Yulia in his room at Berlin's Charit√© University Hospital</p>
<span>
Foto:‚ÄÇAlexei Navalny / ddp media
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p><strong>DER SPIEGEL:</strong> Let's go over what happened to you, and we'll start with your last memory before you lost consciousness. It's August 20, at eight o'clock in the morning. You're sitting in a plane from Tomsk to Moscow. You had spent a few days in Siberia. What was going through your head?</p><p><strong>Navalny:</strong> It was a wonderful day. I'm on my way home, with a strenuous and successful business trip behind me. We shot videos for the regional election campaign, and everything had gone according to plan. I'm sitting comfortably in my seat and I'm looking forward to a quiet flight during which I can watch a series. Once I get back to Moscow, I am looking forward to recording my weekly YouTube show and then spending the weekend with my family. I feel good, as I did at the airport. And then‚Ä¶ it's hard to describe because there is nothing to compare it with. Organophosphorus compounds attack your nervous system like a DDos attack attacks the computer - it's an overload that breaks you. You can no longer concentrate. I can feel that something is&nbsp;wrong. I break out in a cold sweat. I ask Kira beside me for a tissue. Then I say to her: Speak to me. I need to hear a voice - something's wrong with me. She looks at me like I'm crazy and starts talking.</p><p><strong>DER SPIEGEL:</strong> What happened then?</p><p><strong>Navalny:</strong> I don't understand what is happening to me. The stewards come by with the trolley. I first want to ask them for water, but I then say: No, let me by, I'm going to the bathroom. I wash myself with cold water, sit down and wait and then wash myself again. And then I think: If I don't get out now, I'll never get out. The most important feeling was: You are feeling no pain, but you know you're dying. And I mean, right now, yet nothing hurts. I leave the toilet, turn to the steward - and instead of asking for help, I say, to my own surprise: "I've been poisoned. I'm dying." And then I lay down on the ground in front of him to die. He‚Äôs the last thing I see - a face that looks at me with slight astonishment and a light smile. He says: "Poisoned?" and by that he probably means I was served bad chicken.</p><p>And the last thing I hear, already on the floor is: Do you have heart problems? But my heart doesn't hurt. Nothing hurts. All I know is that I am dying. Then I hear voices growing ever quieter, and a woman calling: "Don't leave us! Don't leave us!" Then it's over. I know I'm dead. Only later would it turn out that I was wrong.</p><p><strong>DER SPIEGEL:</strong> There's a video shot by a passenger in which your screams can be heard on the plane. It sounds horrible, almost like the cries of an animal.</p><p><strong>Navalny:</strong> I've watched it - it's circulating on the internet under the title: "Navalny screaming in pain." But it wasn't pain. It was something else, worse. Pain makes you feel like you're alive. But in this case, you sense: This is the end.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;fe4efb86-8391-4038-9e36-19f7e61bb096&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;0426e0e5-5e8b-4ece-ba4b-9acc5b143706&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w655_r0.8652575957727873_fpx44.89_fpy38.84.jpg" srcset="https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w488_r0.8652575957727873_fpx44.89_fpy38.84.jpg 488w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w616_r0.8652575957727873_fpx44.89_fpy38.84.jpg 616w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w655_r0.8652575957727873_fpx44.89_fpy38.84.jpg 718w," width="655" height="757" sizes="655px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w488_r0.8652575957727873_fpx44.89_fpy38.84.jpg 488w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w616_r0.8652575957727873_fpx44.89_fpy38.84.jpg 616w, https://cdn.prod.www.spiegel.de/images/fe4efb86-8391-4038-9e36-19f7e61bb096_w655_r0.8652575957727873_fpx44.89_fpy38.84.jpg 718w," title="Navalny posted photos of himself on Instagram showing him on the balcony of his room." alt="Navalny posted photos of himself on Instagram showing him on the balcony of his room.">
</span>
</span>
</span>
</p><figcaption>
<p>Navalny posted photos of himself on Instagram showing him on the ‚Ä¶</p></figcaption></div></div></div></figure></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4">https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/world/alexei-navalny-on-his-poisoning-i-assert-that-putin-was-behind-the-crime-a-ae5923d5-20f3-4117-80bd-39a99b5b86f4</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650372</guid>
            <pubDate>Thu, 01 Oct 2020 13:06:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China forces international birding organization to eject Taiwan, gags employees]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24650128">thread link</a>) | @ilamont
<br/>
October 1, 2020 | https://www.cips-cepi.ca/2020/09/30/ruffled-feathers-why-chinese-interference-in-international-bird-conservation-is-a-threat-to-world-peace/ | <a href="https://web.archive.org/web/*/https://www.cips-cepi.ca/2020/09/30/ruffled-feathers-why-chinese-interference-in-international-bird-conservation-is-a-threat-to-world-peace/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<hr>



<p><strong>The&nbsp;</strong><a href="https://www.theguardian.com/world/2020/sep/25/hawk-or-dove-birdwatching-worlds-feathers-ruffled-over-taiwan-independence"><strong>ejection</strong></a><strong>&nbsp;of Taiwan‚Äôs Chinese Wild Bird Federation (CWBF) from BirdLife International and the subsequent&nbsp;</strong><a href="https://www.reuters.com/article/us-taiwan-environment-politics/british-bird-group-issues-gag-order-over-taiwan-china-issue-idUSKBN2690BX"><strong>gag order</strong></a><strong>&nbsp;asking BirdLife employees to refrain from speaking to the press may appear at first glance to be the smallest of China‚Äôs many micro-aggressions, but is indicative of a serious security threat.&nbsp;</strong></p>



<hr>



<p>BirdLife notified the CWBF on September 7 that their 24-year-old partnership had ended. The reason? BirdLife asked the Taiwanese partner to change their official Chinese name and to sign a document promising to neither promote the independence of Taiwan from China nor to advocate the legitimacy of the Republic of China (Taiwan‚Äôs official name). It didn‚Äôt matter that the Federation had never taken a political stance on Taiwan‚Äôs status. It didn‚Äôt matter that they had already changed their English name three times at the behest of BirdLife, even twisting facts to alter the name from ‚ÄúWild Bird Federation Taiwan‚Äù to ‚ÄúChinese Wild Bird Federation‚Äù in 2007. BirdLife wouldn‚Äôt even give them time, as a democratically run NGO, to debate this at the Annual General Meeting. They simply kicked them out of the nest.&nbsp;</p>



<hr>



<p><strong>Recommended: </strong><a href="https://www.cips-cepi.ca/2020/09/29/mbss-admits-full-responsibility-for-the-khashoggi-murder-what-this-means-for-the-kingdoms-allies/"><strong>üèÖ2020 CIPS Blog Award Winner! MBS admits ‚Äúfull responsibility‚Äù for the Khashoggi murder: What this means for the Kingdom‚Äôs allies</strong></a></p>



<hr>



<p>Taiwan protested. The&nbsp;<a href="https://focustaiwan.tw/politics/202009150029">Ministry of Foreign Affairs</a>&nbsp;condemned China for interfering in international conservation NGOs and BirdLife for cooperating with China to coerce the CWBF into taking a political stance.&nbsp;On September 19, the General Assembly of the CWBF decided to finally revert to the more accurate name in English as the&nbsp;<a href="https://www.bird.org.tw/news/602?fbclid=IwAR1RgQoW9nXgZCHRBxlGgr7qamTs_nRhbUyffndt5WEbziqkX92HmKTIdDA">Taiwan Wild Bird Federation</a>.&nbsp;</p>



<p><strong>What is BirdLife?</strong></p>



<p>BirdLife, a global coalition of scientific and conservation NGOs, is active in Canada through Nature Canada and Birds Canada. It coordinates the IBA (Important Bird and Biodiversity Areas) program that identifies and manages important bird habitat sites. Because birds do not respect borders, collaboration between countries is central to BirdLife‚Äôs mandate. Since 2000, Taiwan‚Äôs Forestry Bureau has contributed to BirdLife conservation projects in Madagascar, Cambodia, and Sao Tome.&nbsp;</p>



<p>Taiwan is second only to Japan in Asia for bird conservation and scientific research. Taiwan hosts 682 bird species, 29 endemic species, and 43 endangered species. Taiwanese birders are active contributors to eBird, the world‚Äôs most comprehensive citizen science project in ornithology. The CWBF does important work to protect the Chinese Crested Tern and Black-faced Spoonbill. In 2020, the 4,864 Black-faced Spoonbills that wintered in Taiwan accounted for 57.3% of the population of that endangered species. Migratory birds along the East Asian-Australasian Flyway depend on Taiwan because of its strategic location on their pathways that stretch from Siberia to Australia. Taiwan‚Äôs expulsion from BirdLife will hinder cross-border cooperation on conservation, just because China prioritizes its political goals over even pragmatic scientific cooperation. China makes everything into a zero-sum game.&nbsp;</p>



<figure><p>
https://twitter.com/TaiwanBirding/status/1309409778393776128?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1309409778393776128%7Ctwgr%5Eshare_3&amp;ref_url=https%3A%2F%2Fpublish.twitter.com%2F%3Fquery%3Dhttps3A2F2Ftwitter.com2FTaiwanBirding2Fstatus2F1309409778393776128widget%3DTweet
</p></figure>



<p><strong>China Curtails Freedom of International Civil Society</strong></p>



<p>BirdLife is a dangerous precedent for other NGOs. Because China can pressure one leading NGO into cutting out Taiwan, they will feel emboldened to go after other NGOs ‚Äì including in Canada. NGOs hoping to expand into China will hesitate to build partnerships with Taiwan. This is a shame because Taiwanese NGOs have strong expertise as well as the financial means to get things done. It is even more unfortunate because democratic Taiwan, like Canada, actually has real social movements run by civilians without government interference. China, on the other hand, strictly limits the freedoms of Chinese NGOs. Since 2017, when China changed its NGO regulations in line with broader security-related legislation, international NGOs have been required to register with the Ministry of Public Security and must have an approved local partner. This means the Chinese Communist Party can use NGOs to export their standards to the world.&nbsp;</p>



<p>Until now, China has not permitted BirdLife to enter China, which means the closest they get is collaboration with the Hong Kong Birdwatching Society. Maybe that is the point. Quite possibly, BirdLife is negotiating with China and took action against Taiwan as a precondition for collaboration. The cost is high. It means letting China dictate the norms of how international NGOs operate. BirdLife even imported Chinese norms on media freedom by issuing a gag order to their employees. And this is in Great Britain, which takes pride in the Magna Charta as one of the founding documents of democracy.&nbsp;</p>



<p>Because of China‚Äôs sheer size and long coastlines used by migratory birds, BirdLife is badly needed in China. International bird conservation would improve if China were to open up its own borders to free, unfettered cooperation between Chinese and international NGOs. Bird habitats along migration routes would be best protected if China were to set aside politics and collaborate with Taiwanese ornithologists and conservation scientists&nbsp;&nbsp;like Japan and Russia do in spite of long-standing territorial disputes that straddle bird habitats.&nbsp;&nbsp;</p>



<p><strong>The Bigger Picture</strong></p>



<p>China‚Äôs pressure on BirdLife is part of a new strategy. For decades, BirdLife‚Äôs Taiwanese partner could simply accept a compromise name of ‚ÄúChinese Wild Bird Federation‚Äù internationally; and ‚ÄúRepublic of China Wild Bird Federation‚Äù at home. BirdLife and the CWBF could collaborate as long as they remained silent about China-Taiwan relations. The most troubling sign is not the requested name change, but the fact that the CWBF was asked to commit themselves to a political stance. China is trying to shape a world in which even silence is not an option. China‚Äôs goal is to get the entire world to parrot its claims that Taiwan is part of the People‚Äôs Republic of China. This must be seen as part of a larger strategy in which the Chinese military during a global pandemic feels emboldened to practice invasion of Taiwan and to regularly send jets into Taiwanese airspace.&nbsp;</p>



<p>BirdLife should be reminding the world that coastal birds inhabiting wetlands along the Taiwan Straits would be the first victims if China were to ever invade Taiwan. Instead, their abandonment of the Taiwan Wild Bird Federation gives Beijing one more sign that the world does not oppose their strategy to annex Taiwan. Acquiescing to Chinese micro-management of international NGOs is not good for the birds and, in the long run, it is dangerous for the security of the entire region.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>



<hr>



<p><strong>Recommended: </strong><a href="https://www.cips-cepi.ca/2020/09/27/twitter-conference-understanding-the-five-eyes/"><strong>Twitter Conference: Understanding the Five Eyes</strong></a></p>




</div></div></div>]]>
            </description>
            <link>https://www.cips-cepi.ca/2020/09/30/ruffled-feathers-why-chinese-interference-in-international-bird-conservation-is-a-threat-to-world-peace/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650128</guid>
            <pubDate>Thu, 01 Oct 2020 12:31:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Segment Tree ‚Äì Competitive Programming Algorithms]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24650084">thread link</a>) | @pmoriarty
<br/>
October 1, 2020 | https://cp-algorithms.com/data_structures/segment_tree.html | <a href="https://web.archive.org/web/*/https://cp-algorithms.com/data_structures/segment_tree.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
    


<p>A Segment Tree is a data structure that allows answering range queries over an array effectively, while still being flexible enough to allow modifying the array. 
This includes finding the sum of consecutive array elements $a[l \dots r]$, or finding the minimum element in a such a range in $O(\log n)$ time. 
Between answering such queries the Segment Tree allows modifying the array by replacing one element, or even change the elements of a whole subsegment (e.g. assigning all elements $a[l \dots r]$ to any value, or adding a value to all element in the subsegment).</p>

<p>In general a Segment Tree is a very flexible data structure, and a huge number of problems can be solved with it. 
Additionally it is also possible to apply more complex operations and answer more complex queries (see <a href="https://cp-algorithms.com/data_structures/segment_tree.html#advanced-versions-of-segment-trees">Advanced versions of Segment Trees</a>).
In particular the Segment Tree can be easily generalized to larger dimensions. 
For instance with a two-dimensional Segment Tree you can answer sum or minimum queries over some subrectangle of a given matrix.
However only in $O(\log^2 n)$ time.</p>

<p>One important property of Segment Trees is, that they require only a linear amount of memory.
The standard Segment Tree requires $4n$ vertices for working on an array of size $n$.</p>

<h2>Simplest form of a Segment Tree</h2>

<p>To start easy, we consider the simplest form of a Segment Tree. 
We want to answer sum queries efficiently. 
The formal definition of our task is:
We have an array $a[0 \dots n-1]$, and the Segment Tree must be able to find the sum of elements between the indices $l$ and $r$ (i.e. computing the sum $\sum_{i=l}^r a[i]$), and also handle changing values of the elements in the array (i.e. perform assignments of the form $a[i] = x$). 
The Segment Tree should be able to process both queries in $O(\log n)$ time.</p>

<h3>Structure of the Segment Tree</h3>

<p>So, what is a Segment Tree?</p>

<p>We compute and store the sum of the elements of the whole array, i.e. the sum of the segment $a[0 \dots n-1]$. 
We then split the array into two halves $a[0 \dots n/2]$ and $a[n/2+1 \dots n-1]$ and compute the sum of each halve and store them. 
Each of these two halves in turn also split in half, their sums are computed and stored. 
And this process repeats until all segments reach size $1$. 
In other words we start with the segment $a[0 \dots n-1]$, split the current segment in half (if it has not yet become a segment containing a single element), and then calling the same procedure for both halves. 
For each such segment we store the sum of the numbers on it.</p>

<p>We can say, that these segments form a binary tree: 
the root of this tree is the segment $a[0 \dots n-1]$, and each vertex (except leaf vertices) has exactly two child vertices. 
This is why the data structure is called "Segment Tree", even though in most implementations the tree is not constructed explicitly (see <a href="https://cp-algorithms.com/data_structures/segment_tree.html#implementation">Implementation</a>).</p>

<p>Here is a visual representation of such a Segment Tree over the array $a = [1, 3, -2, 8, -7]$:</p>

<p><img src="https://raw.githubusercontent.com/e-maxx-eng/e-maxx-eng/master/img/sum-segment-tree.png" alt="&quot;Sum Segment Tree&quot;"></p>

<p>From this short description of the data structure, we can already conclude that a Segment Tree only requires a linear number of vertices. 
The first level of the tree contains a single node (the root), the second level will contain two vertices, in the third it will contain four vertices, until the number of vertices reaches $n$. 
Thus the number of vertices in the worst case can be estimated by the sum $1 + 2 + 4 + \dots + 2^{\lceil\log_2 n\rceil} = 2^{\lceil\log_2 n\rceil + 1} \lt 4n$.</p>

<p>It is worth noting that whenever $n$ is not a power of two, not all levels of the Segment Tree will be completely filled. 
We can see that behavior in the image.
For now we can forget about this fact, but it will become important later during the implementation.</p>

<p>The height of the Segment Tree is $O(\log n)$, because when going down from the root to the leaves the size of the segments decreases approximately by half.</p>

<h3>Construction</h3>

<p>Before constructing the segment tree, we need to decide:</p>

<ol>
<li>the <em>value</em> that gets stored at each node of the segment tree.
For example, in a sum segment tree, a node would store the sum of the elements in its range $[l, r]$.</li>
<li>the <em>merge</em> operation that merges two siblings in a segment tree.
For example, in a sum segment tree, the two nodes corresponding to the ranges $a[l_1 \dots r_1]$ and $a[l_2 \dots r_2]$ would be merged into a node corresponding to the range $a[l_1 \dots r_2]$ by adding the values of the two nodes.</li>
</ol>

<p>Note that a vertex is a "leaf vertex", if its corresponding segment covers only one value in the original array. It is present at the lowermost level of a segment tree. Its value would be equal to the (corresponding) element $a[i]$.</p>

<p>Now, for construction of the segment tree, we start at the bottom level (the leaf vertices) and assign them their respective values. On the basis of these values, we can compute the values of the previous level, using the <code>merge</code> function.
And on the basis of those, we can compute the values of the previous, and repeat the procedure until we reach the root vertex.</p>

<p>It is convenient to describe this operation recursively in the other direction, i.e., from the root vertex to the leaf vertices. The construction procedure, if called on a non-leaf vertex, does the following:</p>

<ol>
<li>recursively construct the values of the two child vertices</li>
<li>merge the computed values of these children.</li>
</ol>

<p>We start the construction at the root vertex, and hence, we are able to compute the entire segment tree.</p>

<p>The time complexity of this construction is $O(n)$, assuming that the merge operation is constant time (the merge operation gets called $n$ times, which is equal to the number of internal nodes in the segment tree).</p>

<h3>Sum queries</h3>

<p>For now we are going to answer sum queries. As an input we receive two integers $l$ and $r$, and we have to compute the sum of the segment $a[l \dots r]$ in $O(\log n)$ time.</p>

<p>To do this, we will traverse the Segment Tree and use the precomputed sums of the segments.
Let's assume that we are currently at the vertex that covers the segment $a[tl \dots tr]$.
There are three possible cases.</p>

<p>The easiest case is when the segment $a[l \dots r]$ is equal to the corresponding segment of the current vertex (i.e. $a[l \dots r] = a[tl \dots tr]$), then we are finished and can return the precomputed sum that is stored in the vertex.</p>

<p>Alternatively the segment of the query can fall completely into the domain of either the left or the right child.
Recall that the left child covers the segment $a[tl \dots tm]$ and the right vertex covers the segment $a[tm + 1 \dots tr]$ with $tm = (tl + tr) / 2$. 
In this case we can simply go to the child vertex, which corresponding segment covers the query segment, and execute the algorithm described here with that vertex.</p>

<p>And then there is the last case, the query segment intersects with both children. 
In this case we have no other option as to make two recursive calls, one for each child.
First we go to the left child, compute a partial answer for this vertex (i.e. the sum of values of the intersection between the segment of the query and the segment of the left child), then go to the right child, compute the partial answer using that vertex, and then combine the answers by adding them. 
In other words, since the left child represents the segment $a[tl \dots tm]$ and the right child the segment $a[tm+1 \dots tr]$, we compute the sum query $a[l \dots tm]$ using the left child, and the sum query $a[tm+1 \dots r]$ using the right child.</p>

<p>So processing a sum query is a function that recursively calls itself once with either the left or the right child (without changing the query boundaries), or twice, once for the left and once for the right child (by splitting the query into two subqueries). 
And the recursion ends, whenever the boundaries of the current query segment coincides with the boundaries of the segment of the current vertex. 
In that case the answer will be the precomputed value of the sum of this segment, which is stored in the tree.</p>

<p>In other words, the calculation of the query is a traversal of the tree, which spreads through all necessary branches of the tree, and uses the precomputed sum values of the segments in the tree.</p>

<p>Obviously we will start the traversal from the root vertex of the Segment Tree.</p>

<p>The procedure is illustrated in the following image.
Again the array $a = [1, 3, -2, 8, -7]$ is used, and here we want to compute the sum $\sum_{i=2}^4 a[i]$.
The colored vertices will be visited, and we will use the precomputed values of the green vertices.
This gives us the result $-2 + 1 = -1$.</p>

<p><img src="https://raw.githubusercontent.com/e-maxx-eng/e-maxx-eng/master/img/sum-segment-tree-query.png" alt="&quot;Sum Segment Tree Query&quot;"></p>

<p>Why is the complexity of this algorithm $O(\log n)$?
To show this complexity we look at each level of the tree. 
It turns out, that for each level we only visit not more than four vertices. 
And since the height of the tree is $O(\log n)$, we receive the desired running time.</p>

<p>We can show that this proposition (at most four vertices each level) is true by induction.
At the first level, we only visit one vertex, the root vertex, so here we visit less than four vertices. 
Now let's look at an arbitrary level.
By induction hypothesis, we visit at most four vertices. 
If we only visit at most two vertices, the next level has at most four vertices. That trivial, because each vertex can only cause at most two recursive calls. 
So let's assume that we visit three or four vertices in the current level. 
From those vertices, we will analyze the vertices in the middle more carefully. 
Since the sum query asks for the sum of a continuous subarray, we know that segments corresponding to the visited vertices in the middle will be completely covered by the segment of the sum query. 
Therefore these vertices will not make any recursive calls. 
So only the most left, and the most right vertex will have the potential to make recursive calls. 
And those will only create at most four recursive calls, so also the next level will satisfy the assertion.
We can say that one branch approaches the left boundary of the query, and the ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cp-algorithms.com/data_structures/segment_tree.html">https://cp-algorithms.com/data_structures/segment_tree.html</a></em></p>]]>
            </description>
            <link>https://cp-algorithms.com/data_structures/segment_tree.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650084</guid>
            <pubDate>Thu, 01 Oct 2020 12:25:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MIT new large tokamak to be the first in history to do self-sustaining reaction]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24650030">thread link</a>) | @vermontdevil
<br/>
October 1, 2020 | https://defector.com/if-scientists-are-to-create-and-harness-the-unfathomable-power-of-a-star-they-must-agree-to-hurl-me-into-it/ | <a href="https://web.archive.org/web/*/https://defector.com/if-scientists-are-to-create-and-harness-the-unfathomable-power-of-a-star-they-must-agree-to-hurl-me-into-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico">
<p>Scientists at the Massachusetts Institute of Technology <a href="https://www.nytimes.com/2020/09/29/climate/nuclear-fusion-reactor.html?smtyp=cur&amp;smid=tw-nytimes&amp;utm_source=Default+audience&amp;utm_campaign=88af7df3e9-EMAIL_CAMPAIGN_2020_09_29_06_13&amp;utm_medium=email&amp;utm_term=0_3cb9478f4c-88af7df3e9-193252502" target="_blank">are developing</a> a type of reactor, called a tokamak, which if it works as intended will generate conditions of sufficient intensity to fuse hydrogen isotopes and harness all the incredible energy released in the process. Their goal is super ambitious: There are other tokamaks, but the MIT scientists expect their large tokamak to be the first in history that is capable of a self-sustaining reaction, and the first that generates more energy than it uses. And they expect to pivot immediately from this historic engineering feat to commercial energy production, and to do all of this on a relatively modest budget, and on a timeline of just three to four years. They expect, in other words, to build the world‚Äôs first fully operational thermonuclear fusion reactor, pumping out infinitely sustainable energy right here in the U.S. of A.</p>



<p>I expect to walk up to this tokamak, engage the help of several brawny nuclear engineers, and to be hurled bodily into the inconceivable heat and indescribable beauty of the radiant plasma cloud magnetically suspended in its core, so that I am instantaneously vaporized and eradicated altogether from this plane of existence. The sooner the better.</p>



<p>Initially it seemed that the best choice for this job would be the International Thermonuclear Experimental Reactor, or ITER, in Provence, France. Whereas the <a href="https://www.psfc.mit.edu/sparc" target="_blank">SPARC tokamak</a> being developed by MIT will be the size of a tennis court, <a href="https://www.iter.org/mach" target="_blank">the ITER</a>, which has been in various phases of development and construction for something like 13 years, will eventually be the size of a soccer field. The specs on this thing <a href="https://www.newyorker.com/magazine/2014/03/03/a-star-in-a-bottle" target="_blank">are mind-boggling</a>:</p>



<blockquote><p>At its core, densely packed high-precision equipment will encase a cavernous vacuum chamber, in which a super-hot cloud of heavy hydrogen will rotate faster than the speed of sound, twisting like a strand of DNA as it circulates. The cloud will be scorched by electric current (a surge so forceful that it will make lightning seem like a tiny arc of static electricity), and bombarded by concentrated waves of radiation. Beams of uncharged particles‚Äîthe energy in them so great it could vaporize a car in seconds‚Äîwill pour into the chamber, adding tremendous heat. In this way, the circulating hydrogen will become ionized, and achieve temperatures exceeding two hundred million degrees Celsius‚Äîmore than ten times as hot as the sun at its blazing core.</p><cite>&nbsp;Raffi Khatchadourian, <em><a href="https://www.newyorker.com/magazine/2014/03/03/a-star-in-a-bottle" target="_blank">The New Yorker</a></em></cite></blockquote>



<p>‚ÄúTremendous heat‚Äù is an understatement of brain-scrambling, laugh-out-loud proportions. This cloud of plasma will be so hot that no physical substance on Earth or known to humankind could contain it for even a fraction of a second: ‚ÄúMetals, plastics, ceramics, concrete, even pure diamond‚Äîall would be obliterated on contact.‚Äù The only way to keep the plasma cloud in place, and thus concentrated enough to trigger nuclear fusion, is to squeeze it into a pocket of space using the ‚Äútitanic forces‚Äù of ‚Äúthe largest system of superconducting magnets in the world,‚Äù actively cooled to deep-space temperatures in order to survive the heat of an actual star.</p>



<p>So in an ultra-secure chamber in a pit in the countryside of Provence, a blob of the hottest substance in our entire solar system will hang in the air, consuming hydrogen isotopes and generating enough energy to turn diamonds into vapor on contact. There are those who would point out that it is probably a bad idea to let humanity just have the Sun, that inevitably some technician is going to want to pull a viral YouTube prank by aiming a beam of the God Cloud at his buddy‚Äôs balls and wind up boring a hole through the planet itself. Or that a janitor will absentmindedly unplug the supercooling systems that allow the mega-magnets to contain the reaction and accidentally atomize the Western Hemisphere. Those people are probably right. Humanity can‚Äôt be counted upon to safely handle livestock‚Äîputting it in charge of a star seems like something that should not be allowed, by the universe.</p>



<p>But since we are building these things anyway, all I ask is that I be lifted by the scruff of my shirt and the seat of my pants by two strong nuclear technicians and, on the count of three, heaved face-first into whichever of the two God Clouds is completed first. It‚Äôs nice to think of all my atoms instantly dispersing into the fabric of the universe, but mostly it will be extremely bitchin‚Äô to be devoured by a star. If this cannot be arranged for whatever reason, I will accept having a beam of the star juice fired into my chest, so that I may utter ‚Äúfuck yeah‚Äù before it is over.</p>
</div></div></div></div></div>]]>
            </description>
            <link>https://defector.com/if-scientists-are-to-create-and-harness-the-unfathomable-power-of-a-star-they-must-agree-to-hurl-me-into-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650030</guid>
            <pubDate>Thu, 01 Oct 2020 12:19:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Neural Network API]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24649616">thread link</a>) | @rajveermalviya
<br/>
October 1, 2020 | https://webmachinelearning.github.io/webnn/ | <a href="https://web.archive.org/web/*/https://webmachinelearning.github.io/webnn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <h2 data-level="1" id="intro"><span>1. </span><span>Introduction</span><a href="#intro"></a></h2>
   <p>We‚Äôre working on this section. Meanwhile, please take a look at the <a href="https://github.com/webmachinelearning/webnn/blob/master/explainer.md">explainer</a>.</p>
   <h2 data-level="2" id="usecases"><span>2. </span><span>Use cases</span><a href="#usecases"></a></h2>
   <h3 data-level="2.1" id="usecases-application"><span>2.1. </span><span>Application Use Cases</span><a href="#usecases-application"></a></h3>
   <p>This section illustrates application-level use cases for neural network
inference hardware acceleration. All applications in those use cases can be
built on top of pre-trained deep neural network (DNN) models.</p>
   <h4 data-level="2.1.1" id="usecase-person-detection"><span>2.1.1. </span><span>Person Detection</span><a href="#usecase-person-detection"></a></h4>
   <p>A user opens a web-based video conferencing application, but she temporarily
leaves from her room. The application is watching whether she is in front of her
PC by using object detection (for example, using object detection approaches
such as <a data-link-type="biblio" href="#biblio-ssd">[SSD]</a> or <a data-link-type="biblio" href="#biblio-yolo">[YOLO]</a> that use a single DNN) to detect regions in a camera
input frame that include persons.</p>
   <p>When she comes back, the application automatically detects her and notifies
other online users that she is active now.</p>
   <h4 data-level="2.1.2" id="usecase-segmentation"><span>2.1.2. </span><span>Semantic Segmentation</span><a href="#usecase-segmentation"></a></h4>
   <p>A user joins a teleconference via a web-based video conferencing application at
her desk since no meeting room in her office is available. During the
teleconference, she does not wish that her room and people in the background are
visible. To protect the privacy of the other people and the surroundings, the
application runs a machine learning model such as <a data-link-type="biblio" href="#biblio-deeplabv3">[DeepLabv3+]</a> or <a data-link-type="biblio" href="#biblio-maskr-cnn">[MaskR-CNN]</a> to semantically split an image into segments and replaces
segments that represent other people and background with another picture.</p>
   <h4 data-level="2.1.3" id="usecase-skeleton-detection"><span>2.1.3. </span><span>Skeleton Detection</span><a href="#usecase-skeleton-detection"></a></h4>
   <p>A web-based video conferencing application tracks a pose of user‚Äôs skeleton by
running a machine learning model, which allows for real-time human pose
estimation, such as <a data-link-type="biblio" href="#biblio-posenet">[PoseNet]</a> to recognize her gesture and body language. When
she raises her hand, her microphone is automatically unmuted and she can start
speaking on the teleconference.</p>
   <h4 data-level="2.1.4" id="usecase-face-recognition"><span>2.1.4. </span><span>Face Recognition</span><a href="#usecase-face-recognition"></a></h4>
   <p>There are multiple people in the conference room and they join an online meeting
using a web-based video conferencing application. The application detects faces
of participants by using object detection (for example, using object detection
approaches such as <a data-link-type="biblio" href="#biblio-ssd">[SSD]</a>) and checks whether each face was present at the
previous meeting or not by running a machine learning model such as <a data-link-type="biblio" href="#biblio-facenet">[FaceNet]</a>,
which verifies whether two faces would be identical or not.</p>
   <h4 data-level="2.1.5" id="usecase-facial-landmarks"><span>2.1.5. </span><span>Facial Landmark Detection</span><a href="#usecase-facial-landmarks"></a></h4>
   <p>A user wants to find new glasses that beautifully fits her on an online glasses
store. The online store offers web-based try-on simulator that runs a machine
learning model such as Face Alignment Network <a data-link-type="biblio" href="#biblio-fan">[FAN]</a> to detect facial landmarks
like eyes, nose, mouth, etc. When she chooses a pair of glasses, the simulator
properly render the selected glasses on the detected position of eyes on her
facial image.</p>
   <h4 data-level="2.1.6" id="usecase-style-transfer"><span>2.1.6. </span><span>Style Transfer</span><a href="#usecase-style-transfer"></a></h4>
   <p>A user is looking for cosmetics on an online store and wondering which color may
fit her face. The online store shows sample facial makeup images of cosmetics,
and offers makeup simulator that runs a machine learning model like <a data-link-type="biblio" href="#biblio-contextualloss">[ContextualLoss]</a> or <a data-link-type="biblio" href="#biblio-pairedcyclegan">[PairedCycleGAN]</a> to transfer the makeup style of the
sample makeup image to her facial image. She can check how the selected makeup
looks like on her face by the simulator.</p>
   <h4 data-level="2.1.7" id="usecase-super-resolution"><span>2.1.7. </span><span>Super Resolution</span><a href="#usecase-super-resolution"></a></h4>
   <p>A web-based video conferencing is receiving a video stream from its peer, but
the resolution of the video becomes lower due to network congestion. To prevent
degradation of the perceived video quality, the application runs a machine
learning model for super-resolution such as <a data-link-type="biblio" href="#biblio-srgan">[SRGAN]</a> to generate
higher-resolution video frames.</p>
   <h4 data-level="2.1.8" id="usecase-image-captioning"><span>2.1.8. </span><span>Image Captioning</span><a href="#usecase-image-captioning"></a></h4>
   <p>For better accessibility, a web-based presentation application provides
automatic image captioning by running a machine learning model such as <a data-link-type="biblio" href="#biblio-im2txt">[im2txt]</a> which predicts explanatory words of the presentation slides.</p>
   <h4 data-level="2.1.9" id="usecase-translation"><span>2.1.9. </span><span>Machine Translation</span><a href="#usecase-translation"></a></h4>
   <p>Multiple people from various countries are talking via a web-based real-time
text chat application. The application translates their conversation by using a
machine learning model such as <a data-link-type="biblio" href="#biblio-gnmt">[GNMT]</a> or <a data-link-type="biblio" href="#biblio-opennmt">[OpenNMT]</a>, which translates every
text into different language.</p>
   <h4 data-level="2.1.10" id="usecase-emotion-analysis"><span>2.1.10. </span><span>Emotion Analysis</span><a href="#usecase-emotion-analysis"></a></h4>
   <p>A user is talking to her friend via a web-based real-time text chat application,
and she is wondering how the friend feels because she cannot see the friend‚Äôs
face. The application analyses the friend‚Äôs emotion by using a machine learning
model such as <a data-link-type="biblio" href="#biblio-deepmoji">[DeepMoji]</a>, which infers emotion from input texts, and displays
an emoji that represents the estimated emotion.</p>
   <h4 data-level="2.1.11" id="usecase-video-summalization"><span>2.1.11. </span><span>Video Summarization</span><a href="#usecase-video-summalization"></a></h4>
   <p>A web-based video conferencing application records received video streams, and
it needs to reduce recorded video data to be stored. The application generates
the short version of the recorded video by using a machine learning model for
video summarization such as <a data-link-type="biblio" href="#biblio-video-summarization-with-lstm">[Video-Summarization-with-LSTM]</a>.</p>
   <h4 data-level="2.1.12" id="usecase-noise-suppression"><span>2.1.12. </span><span>Noise Suppression</span><a href="#usecase-noise-suppression"></a></h4>
   <p>A web-based video conferencing application records received audio streams, but
usually the background noise is everywhere. The application leverages real-time 
noise suppression using Recurrent Neural Network such as <a data-link-type="biblio" href="#biblio-rnnoise">[RNNoise]</a> for 
suppressing background dynamic noise like baby cry or dog barking to improve 
audio experiences in video conferences.</p>
   <h3 data-level="2.2" id="usecases-framework"><span>2.2. </span><span>Framework Use Cases</span><a href="#usecases-framework"></a></h3>
   <p>This section collects framework-level use cases for a dedicated low-level API
for neural network inference hardware acceleration. It is expected that Machine
Learning frameworks will be key consumers of the Web Neural Network API (WebNN
API) and the low-level details exposed through the WebNN API are abstracted out
from typical web developers. However, it is also expected that web developers
with specific interest and competence in Machine Learning will want to interface
with the WebNN API directly instead of a higher-level ML framework.</p>
   <h4 data-level="2.2.1" id="usecase-custom-layer"><span>2.2.1. </span><span>Custom Layer</span><a href="#usecase-custom-layer"></a></h4>
   <p>A web application developer wants to run a DNN model on the WebNN API. However,
she has found that some of activation functions like <a data-link-type="biblio" href="#biblio-leakyrelu">[LeakyReLU]</a>, <a data-link-type="biblio" href="#biblio-elu">[ELU]</a>,
etc. are not included in the WebNN API. To address this issue, she constructs
custom layers of the additional activation functions on top of the WebNN API.
Note that the scope of custom layers may include convolution, normalization,
etc. as well as activation.</p>
   <h4 data-level="2.2.2" id="usecase-network-concat"><span>2.2.2. </span><span>Network Concatenation</span><a href="#usecase-network-concat"></a></h4>
   <p>A web application uses a DNN model, and its model data of upper convolutional
layers and lower fully-connected layers are stored in separate files, since
model data of the fully-connected layers are periodically updated due to fine
tuning at the server side.</p>
   <p>Therefore, the application downloads both partial model files at first and
concatenates them into a single model. When the model is updated, the
application downloads fine-tuned part of the model and replace only the
fully-connected layers with it.</p>
   <h4 data-level="2.2.3" id="usecase-perf-adapt"><span>2.2.3. </span><span>Performance Adaptation</span><a href="#usecase-perf-adapt"></a></h4>
   <p>A web application developer has a concern about performance of her DNN model on
mobile devices. She has confirmed that it may run too slow on mobile devices
which do not have GPU acceleration. To address this issue, her web application
refers to the WebNN API to confirm whether acceleration is available or not, so
that the application can display the warning for devices without acceleration.</p>
   <p>After several weeks, she has developed a tiny DNN model that can even run on
CPU. In order to accommodate CPU execution, she modifies the application
so that the application loads the tiny model in the case of CPU-only devices.</p>
   <h2 data-level="3" id="api"><span>3. </span><span>API</span><a href="#api"></a></h2>
   <h3 data-level="3.1" id="api-navigator"><span>3.1. </span><span>Navigator</span><a href="#api-navigator"></a></h3>
<pre><c- b="">partial</c-> <c- b="">interface</c-> <a data-link-type="interface" href="https://html.spec.whatwg.org/multipage/system-state.html#navigator" id="ref-for-navigator"><c- g="">Navigator</c-></a> {
  <c- b="">readonly</c-> <c- b="">attribute</c-> <a data-link-type="idl-name" href="#ml" id="ref-for-ml"><c- n="">ML</c-></a> <dfn data-dfn-for="Navigator" data-dfn-type="attribute" data-export="" data-readonly="" data-type="ML" id="dom-navigator-ml"><code><c- g="">ml</c-></code><a href="#dom-navigator-ml"></a></dfn>;
};
</pre>
   <h3 data-level="3.2" id="api-ml"><span>3.2. </span><span>ML</span><a href="#api-ml"></a></h3>
<pre><c- b="">interface</c-> <dfn data-dfn-type="interface" data-export="" id="ml"><code><c- g="">ML</c-></code></dfn> {
  <a data-link-type="idl-name" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext"><c- n="">NeuralNetworkContext</c-></a> <dfn data-dfn-for="ML" data-dfn-type="method" data-export="" data-lt="getNeuralNetworkContext()" id="dom-ml-getneuralnetworkcontext"><code><c- g="">getNeuralNetworkContext</c-></code><a href="#dom-ml-getneuralnetworkcontext"></a></dfn>();
};
</pre>
   <h3 data-level="3.3" id="api-operanddescriptor"><span>3.3. </span><span>OperandDescriptor</span><a href="#api-operanddescriptor"></a></h3>
<pre><c- b="">enum</c-> <dfn data-dfn-type="enum" data-export="" id="enumdef-operandlayout"><code><c- g="">OperandLayout</c-></code></dfn> {
  <dfn data-dfn-for="OperandLayout" data-dfn-type="enum-value" data-export="" id="dom-operandlayout-nchw"><code><c- s="">"nchw"</c-></code><a href="#dom-operandlayout-nchw"></a></dfn>,
  <dfn data-dfn-for="OperandLayout" data-dfn-type="enum-value" data-export="" id="dom-operandlayout-nhwc"><code><c- s="">"nhwc"</c-></code><a href="#dom-operandlayout-nhwc"></a></dfn>
};

<c- b="">enum</c-> <dfn data-dfn-type="enum" data-export="" id="enumdef-operandtype"><code><c- g="">OperandType</c-></code></dfn> {
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-float32"><code><c- s="">"float32"</c-></code><a href="#dom-operandtype-float32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-float16"><code><c- s="">"float16"</c-></code><a href="#dom-operandtype-float16"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-int32"><code><c- s="">"int32"</c-></code><a href="#dom-operandtype-int32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-uint32"><code><c- s="">"uint32"</c-></code><a href="#dom-operandtype-uint32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-float32"><code><c- s="">"tensor-float32"</c-></code><a href="#dom-operandtype-tensor-float32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-float16"><code><c- s="">"tensor-float16"</c-></code><a href="#dom-operandtype-tensor-float16"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-int32"><code><c- s="">"tensor-int32"</c-></code><a href="#dom-operandtype-tensor-int32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-quant8-asymm"><code><c- s="">"tensor-quant8-asymm"</c-></code><a href="#dom-operandtype-tensor-quant8-asymm"></a></dfn>
};

<c- b="">dictionary</c-> <dfn data-dfn-type="dictionary" data-export="" id="dictdef-operanddescriptor"><code><c- g="">OperandDescriptor</c-></code></dfn> {
  // The operand type.
  <c- b="">required</c-> <a data-link-type="idl-name" href="#enumdef-operandtype" id="ref-for-enumdef-operandtype"><c- n="">OperandType</c-></a> <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="OperandType " id="dom-operanddescriptor-type"><code><c- g="">type</c-></code><a href="#dom-operanddescriptor-type"></a></dfn>;

  // The dimensions field is only required for tensor operands.
  // The negative value means an unknown dimension.
  <c- b="">sequence</c->&lt;<a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long"><c- b="">long</c-></a>&gt; <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="sequence<long> " id="dom-operanddescriptor-dimensions"><code><c- g="">dimensions</c-></code><a href="#dom-operanddescriptor-dimensions"></a></dfn>;

  // The following two fields are only required for quantized operand.
  // scale: an non-negative floating point value
  // zeroPoint: an integer, in range [0, 255]
  // The real value is (value - zeroPoint) * scale
  <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float"><c- b="">float</c-></a> <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="float " id="dom-operanddescriptor-scale"><code><c- g="">scale</c-></code><a href="#dom-operanddescriptor-scale"></a></dfn>;
  <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long‚ë†"><c- b="">long</c-></a> <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="long " id="dom-operanddescriptor-zeropoint"><code><c- g="">zeroPoint</c-></code><a href="#dom-operanddescriptor-zeropoint"></a></dfn>;
};
</pre>
   <h3 data-level="3.4" id="api-operand"><span>3.4. </span><span>Operand</span><a href="#api-operand"></a></h3>
<pre><c- b="">interface</c-> <dfn data-dfn-type="interface" data-export="" id="operand"><code><c- g="">Operand</c-></code></dfn> {};
</pre>
   <h3 data-level="3.5" id="api-neuralnetworkcontext"><span>3.5. </span><span>NeuralNetworkContext</span><a href="#api-neuralnetworkcontext"></a></h3>
   <p>The <code><a data-link-type="idl" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext‚ë†">NeuralNetworkContext</a></code> defines a set of operations derived from the first-wave models <a data-link-type="biblio" href="#biblio-models">[Models]</a> that address identified <a href="#usecases">¬ß‚ÄØ2 Use cases</a>.</p>
<pre><c- b="">typedef</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-double" id="ref-for-idl-double"><c- b="">double</c-></a> <dfn data-dfn-type="typedef" data-export="" id="typedefdef-number"><code><c- g="">number</c-></code></dfn>;

<c- b="">dictionary</c-> <dfn data-dfn-type="dictionary" data-export="" id="dictdef-namedoperand"><code><c- g="">NamedOperand</c-></code></dfn> {
  <c- b="">required</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString" id="ref-for-idl-DOMString"><c- b="">DOMString</c-></a> <dfn data-dfn-for="NamedOperand" data-dfn-type="dict-member" data-export="" data-type="DOMString " id="dom-namedoperand-name"><code><c- g="">name</c-></code><a href="#dom-namedoperand-name"></a></dfn>;
  <c- b="">required</c-> <a data-link-type="idl-name" href="#operand" id="ref-for-operand"><c- n="">Operand</c-></a> <dfn data-dfn-for="NamedOperand" data-dfn-type="dict-member" data-export="" data-type="Operand " id="dom-namedoperand-operand"><code><c- g="">operand</c-></code><a href="#dom-namedoperand-operand"></a></dfn>;
};

<c- b="">interface</c-> <dfn data-dfn-type="interface" data-export="" id="neuralnetworkcontext"><code><c- g="">NeuralNetworkContext</c-></code></dfn> {
  // Create an Operand object that represents a model input.
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand‚ë†"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="input(name, desc)" id="dom-neuralnetworkcontext-input"><code><c- g="">input</c-></code><a href="#dom-neuralnetworkcontext-input"></a></dfn>(<a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString" id="ref-for-idl-DOMString‚ë†"><c- b="">DOMString</c-></a> <dfn data-dfn-for="NeuralNetworkContext/input(name, desc)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-input-name-desc-name"><code><c- g="">name</c-></code><a href="#dom-neuralnetworkcontext-input-name-desc-name"></a></dfn>, <a data-link-type="idl-name" href="#dictdef-operanddescriptor" id="ref-for-dictdef-operanddescriptor"><c- n="">OperandDescriptor</c-></a> <dfn data-dfn-for="NeuralNetworkContext/input(name, desc)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-input-name-desc-desc"><code><c- g="">desc</c-></code><a href="#dom-neuralnetworkcontext-input-name-desc-desc"></a></dfn>);

  // Create an Operand object that represents a model constant.
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand‚ë°"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="constant(desc, value)" id="dom-neuralnetworkcontext-constant"><code><c- g="">constant</c-></code><a href="#dom-neuralnetworkcontext-constant"></a></dfn>(<a data-link-type="idl-name" href="#dictdef-operanddescriptor" id="ref-for-dictdef-operanddescriptor‚ë†"><c- n="">OperandDescriptor</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(desc, value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-desc-value-desc"><code><c- g="">desc</c-></code><a href="#dom-neuralnetworkcontext-constant-desc-value-desc"></a></dfn>, <a data-link-type="idl-name" href="https://heycam.github.io/webidl/#ArrayBufferView" id="ref-for-ArrayBufferView"><c- n="">ArrayBufferView</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(desc, value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-desc-value-value"><code><c- g="">value</c-></code><a href="#dom-neuralnetworkcontext-constant-desc-value-value"></a></dfn>);

  // Create a single-value tensor from the specified number of the specified type.
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand‚ë¢"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="constant(value, type)|constant(value)" id="dom-neuralnetworkcontext-constant-value-type"><code><c- g="">constant</c-></code><a href="#dom-neuralnetworkcontext-constant-value-type"></a></dfn>(<a data-link-type="idl-name" href="#typedefdef-number" id="ref-for-typedefdef-number"><c- n="">number</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(value, type), NeuralNetworkContext/constant(value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-value-type-value"><code><c- g="">value</c-></code><a href="#dom-neuralnetworkcontext-constant-value-type-value"></a></dfn>, <c- b="">optional</c-> <a data-link-type="idl-name" href="#enumdef-operandtype" id="ref-for-enumdef-operandtype‚ë†"><c- n="">OperandType</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(value, type), NeuralNetworkContext/constant(value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-value-type-type"><code><c- g="">type</c-></code><a href="#dom-neuralnetworkcontext-constant-value-type-type"></a></dfn> = "float32");

  // Create a Model object by identifying output operands.
  <c- b="">Promise</c->&lt;<a data-link-type="idl-name" href="#model" id="ref-for-model"><c- n="">Model</c-></a>&gt; <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="createModel(outputs)" id="dom-neuralnetworkcontext-createmodel"><code><c- g="">createModel</c-></code><a href="#dom-neuralnetworkcontext-createmodel"></a></dfn>(<c- b="">sequence</c->&lt;<a data-link-type="idl-name" href="#dictdef-namedoperand" id="ref-for-dictdef-namedoperand"><c- n="">NamedOperand</c-></a>&gt; <dfn data-dfn-for="NeuralNetworkContext/createModel(outputs)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-createmodel-outputs-outputs"><code><c- g="">outputs</c-></code><a href="#dom-neuralnetworkcontext-createmodel-outputs-outputs"></a></dfn>);
};
</pre>
   <h4 data-level="3.5.1" id="api-neuralnetworkcontext-batchnorm"><span>3.5.1. </span><span>batchNormalization</span><a href="#api-neuralnetworkcontext-batchnorm"></a></h4>
    Normalize the tensor values across dimensions in a batch through a specialized <a data-link-type="biblio" href="#biblio-batchnorm">[BatchNorm]</a> <a href="https://en.wikipedia.org/wiki/Batch_normalization#Batch_Normalizing_Transform">transform</a>. The <em>mean</em> and <em>variance</em> tensors are previously calculated during model training pass. 
<pre><c- b="">partial</c-> <c- b="">interface</c-> <a data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext‚ë°"><c- g="">NeuralNetworkContext</c-></a> {
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand‚ë£"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="batchNormalization(input, mean, variance, scale, bias, axis, epsilon)|batchNormalization(input, mean, variance, scale, bias, axis)|batchNormalization(input, mean, variance, scale, bias)|batchNormalization(input, mean, variance, scale)|batchNormalization(input, mean, variance)" id="dom-neuralnetworkcontext-batchnormalization"><code><c- g="">batchNormalization</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization"></a></dfn>(<a data-link-type="idl-name" href="#operand" id="ref-for-operand‚ë§"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-input"><code><c- g="">input</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-input"></a></dfn>, <a data-link-type="idl-name" href="#operand" id="ref-for-operand‚ë•"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-mean"><code><c- g="">mean</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-mean"></a></dfn>, <a data-link-type="idl-name" href="#operand" id="ref-for-operand‚ë¶"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-variance"><code><c- g="">variance</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-variance"></a></dfn>, 
                             <c- b="">optional</c-> <a data-link-type="idl-name" href="#operand" id="ref-for-operand‚ëß"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-scale"><code><c- g="">scale</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-scale"></a></dfn>, <c- b="">optional</c-> <a data-link-type="idl-name" href="#operand" id="ref-for-operand‚ë®"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-bias"><code><c- g="">bias</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-bias"></a></dfn>, 
                             <c- b="">optional</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long‚ë°"><c- b="">long</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-axis"><code><c- g="">axis</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-axis"></a></dfn> = 1, <c- b="">optional</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float‚ë†"><c- b="">float</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-epsilon"><code><c- g="">epsilon</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-epsilon"></a></dfn> = 1e-5);
};
</pre>
   <div data-algorithm="batchnorm">
     <p><strong>Arguments:</strong></p><ul>
     <li data-md="">
      <p><em>input</em>: an <code><a data-link-type="idl" href="#operand" id="ref-for-operand‚ë†‚ì™">Operand</a></code>. The input N-D tensor.</p>
     </li><li data-md="">
      <p><em>mean</em>: an <code><a data-link-type="idl" href="#operand" id="ref-for-operand‚ë†‚ë†">Operand</a></code>. The 1-D tensor of the batch mean values
whose length is equal to the size of the input dimension denoted by <em>axis</em>.</p>
     </li><li data-md="">
      <p><em>variance</em>: an <code><a data-link-type="idl" href="#operand" id="ref-for-operand‚ë†‚ë°">Operand</a></code>. The 1-D tensor of the batch variance values
whose length is equal to the size of the input ‚Ä¶</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://webmachinelearning.github.io/webnn/">https://webmachinelearning.github.io/webnn/</a></em></p>]]>
            </description>
            <link>https://webmachinelearning.github.io/webnn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649616</guid>
            <pubDate>Thu, 01 Oct 2020 11:18:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Supporting a misbehaving NAND ECC engine in the Linux kernel]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649565">thread link</a>) | @pabs3
<br/>
October 1, 2020 | https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/ | <a href="https://web.archive.org/web/*/https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-13845">
	<!-- .entry-header -->

	
	
	<div>
		<p>Over the years, Bootlin has grown a significant expertise in U-Boot and Linux support for flash memory devices. Thanks to this expertise, we have recently been in charge of rewriting and upstreaming a driver for the <a href="https://www.arasan.com/products/nand-flash/">Arasan NAND controller</a>, which is used in a number of <a href="https://www.xilinx.com/products/silicon-devices/soc.html">Xilinx Zynq SoCs</a>. It turned out that supporting this NAND controller had some interesting challenges to handle its ECC engine peculiarities. In this blog post, we would like to give some background about ECC issues with NAND flash devices, and then dive into the specific issues that we encountered with the Arasan NAND controller, and how we solved them.</p>

<p>NAND flash memories are known to be intrinsically rather unstable: over time, external conditions or repetitive access to a NAND device may result in the data being corrupted. This is particularly true with newer chips, where the number of corruptions usually increases with density, requiring even stronger corrections. To mitigate this, Error Correcting Codes are typically used to detect and correct such corruptions, and since the calculations related to ECC detection and correction are quite intensive, NAND controllers often embed a dedicated engine, the ECC engine, to offload those operations from the CPU.</p>
<p>An ECC engine typically acts as a DMA master, moving, correcting data and calculating syndromes on the fly between the controller FIFO‚Äôs and the user buffer. The engine correction is characterized by two inputs: the size of the data chunks on which the correction applies and the strength of the correction. Old SLC (Single Level Cell) NAND chips typically require a strength of 1 symbol over 4096 (1 bit/512 bytes) while new ones may require much more: 8, 16 or even 24 symbols.</p>
<p>In the write path, the ECC engine reads a user buffer and computes a code for each chunk of data. NAND pages being longer than officially advertised, there is a persistent Out-Of-Band (OOB) area which may be used to store these codes. When reading data, the ECC engine gets fed by the data coming from the NAND bus, including the OOB area. Chunk by chunk, the engine will do some math and correct the data if needed, and then report the number of corrected symbols. If the number of error is higher than the chosen strength, the engine is not capable of any correction and returns an error.</p>

<p>As explained in our introduction, as part of our work on upstreaming the Arasan NAND controller driver, we discovered that this NAND controller IP has a specific behavior in terms of how it reports ECC results: the hardware ECC engine never reports errors. It means the data may be corrected or uncorrectable: the engine behaves the same. From a software point of view, this is a critical flaw and fully relying on such hardware was not an option.</p>
<p>To overcome this limitation, we investigated different solutions, which we detail in the sections below.</p>
<h2>Suppose there will never be any uncorrectable error</h2>
<p>Let‚Äôs be honest, this hypothesis is highly unreliable. Besides that anyway, it would imply that we do not differentiate between written/erased pages and users would receive unclean buffers (with bitflips), which would not work with upper layers such as UBI/UBIFS which expect clean data.</p>
<h2>Keep an history of bitflips of every page</h2>
<p>This way, during a read, it would be possible to compare the evolution of the number of bitflips. If it suddenly drops significantly, the engine is lying and we are facing an error. Unfortunately it is not a reliable solution either because we should either trigger a write operation every time a read happens (slowing down a lot the I/Os and wearing out very quickly the storage device) or loose the tracking after every power cycle which would make this solution very fragile.</p>
<h2>Add a CRC16</h2>
<p>This CRC16 could lay in the OOB area and help to manually verify the data integrity after the engine‚Äôs correction by checking it against the checksum. This could be acceptable, even if not perfect in term of collisions. However, it would not work with existing data while there are many downstreams users of the vendor driver already.</p>
<h2>Use a bitwise XOR between raw and corrected data</h2>
<p>By doing a bitwise XOR between raw and corrected datra, and compare with the number of bitflips reported by the engine, we could detect if the engine is lying on the number of corrected bitflips. This solution has actually been implemented and tested. It involves extra I/Os as the page must be read twice: first with correction and then again without correction. Hence, the NAND bus throughput becomes a limiting factor. In addition, when there are too many bitflips, the engine still tries to correct data and creates bitflips by itself. The result is that, with just a XOR, we cannot discriminate a working correction from a failure. The following figure shows the issue.</p>
<p><a href="https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips.png"><img loading="lazy" src="https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-1024x460.png" alt="Show the engine issue when it creates bitflips when trying to correct uncorrectable data" width="840" height="377" srcset="https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-1024x460.png 1024w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-300x135.png 300w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-768x345.png 768w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips-1200x539.png 1200w, https://bootlin.com/wp-content/uploads/2020/06/arasan-bitflips.png 1458w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"></a></p>
<h2>Rely on the hardware only in the write path</h2>
<p>Using the hardware engine in the write path is fine (and possibly the quickest solution). Instead of trying to workaround the flaws of the read path, we can do the math by software to derive the syndrome in the read path and compare it with the one in the OOB section. If it does not match, it means we are facing an uncorrectable error. This is finally the solution that we have chosen. Of course, if we want to compare software and hardware calculated ECC bytes, we must find a way to reproduce the hardware calculations, and this is what we are going to explore in the next sections.</p>

<p>There is already a BCH library in the Linux kernel on which we could rely on to compute BCH codes. What needed to be identified though, were the BCH initial parameters. In particular:</p>
<ul>
<li>The BCH primary polynomial, from which is derived the generator polynomial. The latter is then used for the computation of BCH codes.</li>
<li>The range of data on which the derivation would apply.</li>
</ul>
<p>There are several thousands possible primary polynomials with a form like <code>x^3 + x^2 + 1</code>. In order to represent these polynomials more easily by software, we use integers or binary arrays. In both cases, each bit represents the coefficient for the order of magnitude corresponding to its position. The above example could be represented by <code>b1101</code> or <code>0xD</code>.</p>
<p>For a given desired BCH code (ie. the ECC chunk size and hence its corresponding Gallois Field order), there is a limited range of possible primary polynomials which can be used. Given <code>eccsize</code> being the amount of data to protect, the Gallois Field order is the smallest integer <code>m</code> so that: <code>2^m &gt; eccsize</code>. Knowing <code>m</code>, one can check <a href="https://www.partow.net/programming/polynomials/index.html">these tables</a> to see examples of polynomials which could match (non exhaustive). The Arasan ECC engine supporting two possible ECC chunk sizes of 512 and 1024 bytes, we had to look at the tables for <code>m = 13</code> and <code>m = 14</code>.</p>
<p>Given the required strength <code>t</code>, the number of needed parity bits <code>p</code> is: <code>p = t x m</code>.</p>
<p>The total amount of manipulated data (ECC chunk, parity bits, eventual padding) <code>n</code>, also called BCH codeword in papers, is: <code>n = 2^m - 1</code>.</p>
<p>Given the size of the codeword <code>n</code> and the number of parity bits <code>p</code>, it is then possible to derive the maximum message length <code>k</code> with: <code>k = n - p</code>.</p>
<p>The theory of BCH also shows that if <code>(n, k)</code> is a valid BCH code, then <code>(n - x, k - x)</code> will also be valid. In our situation this is very interesting. Indeed, we want to protect <code>eccsize</code> number of symbols, but we currently cover <code>k</code> within <code>n</code>. In other words we could use the translation factor <code>x</code> being: <code>x = k - eccsize</code>. If the ECC engine was also protecting some part of the OOB area, <code>x</code> should have been extended a little bit to match the extra range.</p>
<p>With all this theory in mind, we used GNU Octave to <a href="https://github.com/miquelraynal/find-bch-prim-poly/blob/master/find_bch_polynomial.m">brute force the BCH polynomials</a> used by the Arasan ECC engine with the following logic:</p>
<ul>
<li>Write a NAND page with a <code>eccsize</code>-long ECC step full of zeros, and another one full of ones: this is our known set of inputs.</li>
<li>Extract each BCH code of <code>p</code> bits produced by the hardware: this is our known set of outputs.</li>
</ul>
<p>For each possible primary polynomial with the Gallois Field order <code>m</code>, we derive a generator polynomial, use it to encode both input buffers thanks to a regular BCH derivation, and compare the output syndromes with the expected output buffers.</p>
<p>Because the GNU Octave program was not tricky to write, we first tried to match with the output of Linux software BCH engine. Linux using by default the primary polynomial which is the first in GNU Octave‚Äôs list for the desired field order, it was quite easy to verify the algorithm worked.</p>
<p>As unfortunate as it sounds, running this test with the hardware data did not gave any match. Looking more in depth, we realized that visually, there was something like a matching pattern between the output of the Arasan engine and the output of Linux software BCH engine. In fact, both syndromes where identical, the bits being swapped at byte level by the hardware. This observation was made possible because the input buffers have the same values no matter the bit ordering. By extension, we also figured that swapping the bits in the input buffer was also necessary.</p>
<p>The primary polynomial for an <code>eccsize</code> of 512 bytes being already found, we ran again the program with <code>eccsize</code> being 1024 bytes:</p>
<p><code>     eccsize =  1024<br>
     eccstrength =  24<br>
     m =  14<br>
     n =  16383<br>
     p =  336<br>
     k =  16047<br>
     x =  7855<br>
     Trying primary polynomial #1: 0x402b<br>
     Trying primary polynomial #2: 0x4039<br>
     Trying primary polynomial #3: 0x4053<br>
     Trying primary polynomial #4: 0x405f<br>
     Trying primary polynomial #5: 0x407b<br>
     [...]<br>
     Trying primary polynomial #44: 0x43c9<br>
     Trying primary polynomial #45: 0x43eb<br>
     Trying primary polynomial #46: 0x43ed<br>
     Trying primary polynomial #47: 0x440b<br>
     Trying primary polynomial #48: 0x4443<br>
     Primary polynomial found! 0x4443</code></p>

<p>With the two possible primary polynomials in hand, we could finish the support for this ECC engine.</p>
<p>At first, we tried a ‚Äúmixed-mode‚Äù solution: read and correct the data with the hardware engine and then re-read the data in raw mode. Calculate the syndrome over the raw data, derive the number ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/">https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/</a></em></p>]]>
            </description>
            <link>https://bootlin.com/blog/supporting-a-misbehaving-nand-ecc-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649565</guid>
            <pubDate>Thu, 01 Oct 2020 11:08:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Deep Learning Toolchain]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649488">thread link</a>) | @rosshemsley
<br/>
October 1, 2020 | https://rosshemsley.co.uk/posts/deep_learning_toolchain/ | <a href="https://web.archive.org/web/*/https://rosshemsley.co.uk/posts/deep_learning_toolchain/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
Successful model development can be surprisingly dependent on good engineering practices. Despite this, many model implementations scattered about Github are difficult to follow and hard to recreate locally.
</p>

<p>
But what should a <em>good model</em> look like? I would propose that the gold standard for a model implemented on Github could be:
</p>
<ol>
<li> The dependencies may be installed automatically, using a single command.</li>
<li> I can build the model in a sandbox without polluting with my dev. environment.</li>
<li> I can easily retrain (and retune!) the model the model exactly as the author did during their development.</li>
<li> I can easily test the inference pass.</li>
<li> I can easily import the model into my own workflow and use it as part of my own code.</li>
</ol>
<p>
It may be that I've never come across a model that met this standard in practical day-to-day development...! But I claim that achieving these things is surprisingly easy given the modern tools available to us.
</p>
<p>
Furthermore, many may simply respond "just ship everything in a Docker container". My response to this is that Docker is a great tool for
<em>deploying</em> a stable, reproducible environment, but Docker images provide a poor basis for sharing code and enabling collaboration.
In this post, we'll focus on designing models that can be <em>installed and imported with a single command, without Docker, on any OS, on any platform,
using the vanilla tools our language provides</em>.
</p>
<p>
So, let's dive in and look at the tools that I use to train models, and how they can be used to meet the gold standard I gave above.
</p>

<h2>Python 3 for model development</h2>
<p><img src="https://rosshemsley.co.uk/posts/deep_learning_toolchain_images/python_logo.png"></p><p>
It may not be controversial these days, but it's worth highlighting that Python 3 is an excellent choice for prototyping and releasing deep learning models. The key feature here is the library support, which is unmatched by other languages.
I tend to target <strong>Python 3.7.5</strong> or later, because I make heavy use of <em><a href="https://docs.python.org/3/library/dataclasses.html">dataclass</a></em>, and it's recent enough to support type annotations. Ubuntu Focal now includes Python 3.8 by default,
so many users will start being able to support this out of the box.
</p>
<h3>Bonus pionts: type annotations</h3>
<p>
If you use type annotations (correctly) in your model, you will get serious points from me.
It's very common that models use native lists, tensors, and numpy arrays almost interchangeably as function
arguments, and so using type hints can make the data flow in your model easier to follow and debug.
</p>
<div><pre><code data-lang="python"><span>from</span> dataclasses <span>import</span> dataclass
<span>from</span> typing <span>import</span> List, Optional

<span>import</span> numpy <span>as</span> np
<span>from</span> PIL <span>import</span> Image

<span>@dataclass</span>
<span>class</span> <span>DataSample</span>:
    img: Image
    bboxes: List[np<span>.</span>ndarray]
    scores: Optional[List[float]]

<span>...</span>

sample <span>=</span> DataSample(Image(), [np<span>.</span>array([<span>1</span>,<span>2</span>,<span>3</span>,<span>4</span>])], scores<span>=</span>None)</code></pre></div>
<p><em><strong>Above:</strong> an example of using modern Python features to write a clear and simple data container
for a training sample in a model. The dataclass decorator adds all of the utility functions we may want (including
a pretty string reprsentation so we can print the object), and the type annotations make it clear what the user 
should expect the fields to contain.</em></p><h2> Use <em>pyenv</em> to manage Python versions</h2>
<p>
For better or worse, many incompatible versions of Python now exist, and it's easy to get
in a tangle with different Python installs, especially when making system-wide changes.
</p>
<p>
My advice here is to do it properly, and do it once: learn to use <em>pyenv</em> to manage all of your Python
installs.
</p>
<p>
Pyenv is a tool that provides a shim around the <em>python</em> command which redirects it to the correct version 
of Python for the current context. For a given project, you can use <em>pyenv local 3.7.5</em> in a directory
to tell pyenv to use Python 3.7.5 from now on when calling Python in that directory.
</p>
<p>
If you don't have the version of Python installed that you need, you can use pyenv to install it.
If the universe is feeling good to you today, <em>pyenv install 3.7.5</em> should be sufficient to fetch and install Python 3.7.5
for you automatically on any platform.
</p>
<p>
<strong>In practice</strong>, things don't always go so smoothly with pyenv, however I really believe
it's really worth the hassle of spending the time and getting it working - most issues you might enouncter are well understood, and documented on stackoverflow.
</p>
<h3>A few common tips for common pyenv issues</h3>
<ul>
<li><strong>It's not working!</strong> - make sure you have activated it (google "pyenv activate"). Typically you need to add this to e.g. your .bashrc</li>
<li><strong><em>pyenv install</em> failed!</strong> - you may be missing system dependencies. Be patient, and trawl stackoverflow. It can be made to work!</li>
</ul>


<h2>Use <em>poetry</em> to manage your project and dependencies</h2> 
<p>
Keeping your Python project sandboxed is crucial aspect of remaining sane when using Python.
We typically use <em>virtualenvs</em>, or virtual environments, to achieve this. These are are essentially directories containing their own
Python install, and a local copy of all the packages your project needs. 
</p>
<p>
A separate but related problem is ensuring you actually <em>have</em> the dependencies your project needs
installed into that virtualenv. 
</p>
<p>
Once upon a time, you may have used `virtualenv` and `requirements.txt` or `anaconda` or `pipenv` to do these things.
</p>
<p>
Well, my advice is <strong>steer clear from all of them</strong> and move straight to <a href="https://python-poetry.org/">poetry</a>.
It's very much the new kid on the block, but from my perspective it's already miles ahead of the competition.
I have managed to deploy a number of complex Python applications in a professional capacity using
poetry, and I have found it both plays very well with other tools and is generally well designed.
</p>
<p>
Poetry uses the modern <a href="https://snarky.ca/what-the-heck-is-pyproject-toml/">pyproject.toml</a> way of defining a package, and this essentially replaces the old setup.py and friends.
It would be out of scope to explain why pyproject.toml is important and worth learning about, so I recommend some googling here!
</p>
<p>
Ok, so let's create a new project! ... don't forget to `pyenv local 3.7.5` first, to ensure you are using the correct version of Python (if you forgot, you can run it later, and then go
back and edit pyproject.toml to make sure it's set correctly.)
</p>

<p>
Yes, it's as easy as that. Go ahead and move in the directory poetry created for you, and you can now
</p>
<p>
and poetry will automatically create a managed virtualenv for you. Let's now install some of the tools of our trade,
</p><div><pre><code data-lang="bash">$ poetry add torch
$ poetry add numpy</code></pre></div>
<p>
Poetry will install them to the virtualenv and add them to the pyproject.toml. It will 
also <strong>pin</strong> the exact versions of the dependencies into a lock file so that <strong>other users installing your package
can reproduce precisely the same environment as you</strong>. This is perhaps the most important step here, and is worth underscoring:
this is how we are able to achieve <em>reproducibility</em>. 
</p>
<h3>The Best Bit About Poetry</h3>
<p>
Poetry was designed to be good at both developing packages and <em>building/sharing/publishing</em> them.
These latter features are sorely missing from other tools (such as pyenv), and they are really the killer
feature of poetry.
</p>
<p>
Let's suppose you pushed your <em>fancynet</em> package to github (don't forget to check in the lock file!).
Now, <strong>anyone using a recent version of pip can install your package with a single command</strong>,
</p><div><pre><code data-lang="bash">$ pip install git+https://github.com/myusername/fancynet</code></pre></div>
<p>
Pip will fetch the code from github, look into the pyproject.toml, see it uses poetry, and then just do
everything for you, including installing poetry, and fetching the correct versions of the pinned dependencies!
<strong>
This is totally magic and not enough people know this trick.</strong> Go forth and spread this knowledge!
</p>
<p>
If your package reaches a level of maturity where you'd like to publish it to a public package repository (e.g. pypi),
you can use poetry to manage this. To bump the version (you can also bump the minor and major versions this way), use
</p><p>
Then to build and publish to pypi, use
</p><div><pre><code data-lang="bash">$ poetry build
$ poetry publish</code></pre></div><p>
The defaults used by poetry are spookily well designed, and I have never had any problems publishing packages in this way.
</p>

<h2>Use <em>click</em> to manage your entrypoint</h2> 
<p>
An oft-overlooked step in building a good python package is organising the files and "entrypoints" (or "executables"). 
I believe it's worth imagining that someone else is going to use your code at somepoint, and so I try to create nicely named
subdirectories for each part of my model: "datasets", "models", "inference", but also <strong>"cli"</strong>.
In this "cli" directory, I usually have several subdirectories "train", "tune", "test". Each of these contains a single
"__main__.py", which contains the (small!) shim code needed to perform those actions.
</p>
<p>
Inside "__main__.py" I then use <a href="https://click.palletsprojects.com/en/7.x/">click</a> to manage arguments and the entrypoint.
I have found it much easier to use than argparse, and I do think it's worth the effort!
</p>
<div><pre><code data-lang="python"><span>import</span> click
<span>from</span> omegaconf <span>import</span> OmegaConf
<span>from</span> pytorch_lightning <span>import</span> Trainer

<span>from</span> mynet.models <span>import</span> MyNet

<span>@click.command</span>()
<span>@click.option</span>(<span>'--dataset-root-dir'</span>, help<span>=</span><span>'directory containing the dataset'</span>)
<span>@click.option</span>(<span>'--config-path'</span>, default<span>=</span><span>"config.yaml"</span>, help<span>=</span><span>'The config file to use.'</span>)
<span>def</span> <span>train</span>(dataset_root_dir: str, config_path: str):
    cfg <span>=</span> OmegaConf<span>.</span>load(config_path)

    model <span>=</span> MyNet(cfg)
    trainer <span>=</span> Trainer(gpus<span>=</span><span>1</span>, profiler<span>=</span>True)
    trainer<span>.</span>fit(model)

<span>if</span> __name__ <span>==</span> <span>'__main__'</span>:
    train()</code></pre></div>
<p>
Now, if we are developing locally, we can run this using
</p><div><pre><code data-lang="bash">$ poetry run python -m mynet.cli.train --dataset-root-dir /foo/bar/baz</code></pre></div><p>
Which is fine and good, but if we want to go 10X, we can also use a neat future of project.toml and add an entrypoint
</p><div><pre><code data-lang="toml">[<span>tool</span>.<span>poetry</span>.<span>scripts</span>]
<span>train</span> = <span>"mynet.cli.train.__main__:train"</span></code></pre></div><p>
Once we do this, users can run training using
</p><div><pre><code data-lang="bash">$ poetry run train --dataset-root-dir /foo/bar/baz</code></pre></div><p>
or if you "activate" the environment, simply
</p><div><pre><code data-lang="bash">$ train --dataset-root-dir /foo/bar/baz</code></pre></div>

<p>
It's possible to add multiple entrypoints to the pyproject.toml, so you can easily create one for training, tuning, testing.
This is helpful for users trying to discover how to train or evaluate your model from scratch!
</p>
<p>
Do note that if a user installs your package into a shared virtualenv, you may wish to choose a more meaningful name than train!
</p>

<h2>Use <em>pytorch</em> to develop your net</h2>
<p></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rosshemsley.co.uk/posts/deep_learning_toolchain/">https://rosshemsley.co.uk/posts/deep_learning_toolchain/</a></em></p>]]>
            </description>
            <link>https://rosshemsley.co.uk/posts/deep_learning_toolchain/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649488</guid>
            <pubDate>Thu, 01 Oct 2020 10:54:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PowerShell Universal v1.4]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649270">thread link</a>) | @l33t_d0nut
<br/>
October 1, 2020 | https://blog.ironmansoftware.com/powershell-universal-1-4/ | <a href="https://web.archive.org/web/*/https://blog.ironmansoftware.com/powershell-universal-1-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main"><div><h2>PowerShell Universal v1.4</h2><h4>September 30, 2020</h4><p>I‚Äôm pleased to announce another feature-packed <a href="https://ironmansoftware.com/powershell-universal">PowerShell Universal</a> release! Today, we‚Äôre releasing version 1.4 of the ultimate platform for building web-based IT tools. This release contains an extensive list of features as well as bug fixes. This blog post will go over them but I encourage you to <a href="https://ironmansoftware.com/downloads">download or upgrade</a> to take full advantage of everything that has been added.</p><h2 id="release-notes">Release Notes</h2><p>Full release notes can be found <a href="https://docs.ironmansoftware.com/changelog">here</a>.</p><h2 id="downloads">Downloads</h2><ul><li><a href="https://imsreleases.blob.core.windows.net/universal/production/1.4.0/PowerShellUniversal.1.4.0.msi">Windows MSI</a></li><li><a href="https://imsreleases.blob.core.windows.net/universal/production/1.4.0/Universal.win-x64.1.4.0.zip">Windows ZIP</a></li><li><a href="https://imsreleases.blob.core.windows.net/universal/production/1.4.0/Universal.linux-x64.1.4.0.zip">Linux ZIP</a></li><li><a href="https://hub.docker.com/r/ironmansoftware/universal">Docker</a></li></ul><h2 id="platform">Platform</h2><h3 id="environments">Environments</h3><p>We‚Äôve extended the concept of PowerShell Versions and replaced it with Environments. Environments allow you to specify the executable, arguments, modules and variables that are defined whenever you execute an API request, run a job or host a dashboard. The execution environment will automatically create a runspace pool with the assets you define so there is no need to import them every time.</p><p>We‚Äôve standardized environments across all features and now you can select which environment is used in each place.</p><p><a href="https://docs.ironmansoftware.com/config/environments">Learn more about Environments</a></p><p><img src="https://blog.ironmansoftware.com/images/environments.png" alt=""></p><h3 id="windows-authentication-with-iis">Windows Authentication with IIS</h3><p>You can now configure Windows Authentication without IIS. IIS can complicate deployments and if it‚Äôs not something you need, you can now avoid it by simply installing Universal as a service and configuring Windows authentication.</p><p><a href="https://docs.ironmansoftware.com/config/security#windows-authentication-outside-of-iis">Learn more about Windows Authentication without IIS</a></p><h2 id="apis">APIs</h2><h3 id="rate-limiting">Rate Limiting</h3><p>We‚Äôve added the ability to configure rate limiting for APIs. This is an important feature for anyone that may be exposing their API publicly or may call a sensitive resource that you do not want to overload. You can configure rate limits based on HTTP method, endpoint (or pattern), and the number of requests over a period of time.</p><p><a href="https://docs.ironmansoftware.com/api/rate-limiting">Learn more about Rate Limiting</a></p><p><img src="https://blog.ironmansoftware.com/images/ratelimit.png" alt=""></p><h3 id="connection-information">Connection Information</h3><p>You‚Äôll have access to more connection information in your endpoints. Variables are now defined for Local IP Address, Remote IP Address, Local Port and Remote Port.</p><h3 id="updated-endpoint-page">Updated Endpoint Page</h3><p>We‚Äôve enhanced the API page to provide a neat in-browser experience for developing your API. This includes the ability to test your APIs directly in the browser.</p><p><img src="https://blog.ironmansoftware.com/images/apis.png" alt=""></p><h2 id="automation">Automation</h2><h3 id="continuous-schedules">Continuous Schedules</h3><p>You can now define continuous schedules that will run a job over and over again with a configurable delay. It won‚Äôt start another job until the previous one has finished.</p><p><a href="https://docs.ironmansoftware.com/automation/schedules#continuous">Learn more about Scheduling</a></p><p><img src="https://blog.ironmansoftware.com/images/continuous-schedule.png" alt=""></p><h3 id="variables">Variables</h3><p>Variables are now global for the entire Universal platform. By default, your existing Environments will import all variables but you can define specific variables or patterns to use in an environment. This change shouldn‚Äôt affect your jobs but be aware that variables are no longer present only present in jobs but present in any one of the features using an Environment.</p><p><a href="https://docs.ironmansoftware.com/automation/variables">Learn more about Variables</a></p><h2 id="dashboard">Dashboard</h2><h3 id="role-based-access">Role-based Access</h3><p>We‚Äôve added the ability to assign roles to dashboards and pages in the v3 framework. If you assign a role to a dashboard, only users of that role will have access to the entire dashboard. When you assign roles to a page in a dashboard, any authenticated user will be able to access the dashboard but only users in the specified role will have access to the pages.</p><p><a href="https://docs.ironmansoftware.com/dashboard/role-based-access">Learn more about Role-Based Access in Dashboards</a></p><h3 id="chartjs">ChartJS</h3><p>We‚Äôve brought back ChartJS support. This was the primary chart library in UDv2. Many users preferred this library over our Nivo charts integration so we have decided to include it. We‚Äôve also simplified the API to make it even easier to build charts.</p><p><a href="https://docs.ironmansoftware.com/dashboard/components/data-visualization/charts#chartjs">Learn more about ChartJS integration</a></p><p><img src="https://blog.ironmansoftware.com/images/chartjs.png" alt=""></p><h3 id="improved-navigation">Improved Navigation</h3><p>We‚Äôve simplified and extended the built in navigation. You can now more easily define your navigation items for a page. We also support a persistent layout that does not require a click of a hamburger menu to open the navigation.</p><p><a href="https://docs.ironmansoftware.com/dashboard/components/pages#navigation">Learn more about Navigation</a></p><p><img src="https://blog.ironmansoftware.com/images/permanent-drawer.png" alt=""></p><h3 id="redesigned-dashboard-page">Redesigned Dashboard Page</h3><p>The dashboard page has been redesigned to make it easier to see an overview of the dashboards running in your environment.</p><p><img src="https://blog.ironmansoftware.com/images/new-dashboards.png" alt=""></p><h2 id="get-started-now">Get Started Now</h2><p>PowerShell Universal is free to try. <a href="https://ironmansoftware.com/downloads">Download now</a> and start building tools with your existing PowerShell scripts. Please feel free to join our <a href="https://forums.universaldashboard.io/">growing community</a>.</p></div></div></div>]]>
            </description>
            <link>https://blog.ironmansoftware.com/powershell-universal-1-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649270</guid>
            <pubDate>Thu, 01 Oct 2020 10:11:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You can drive more traffic and engagement with content amplification]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649266">thread link</a>) | @JamesConverge
<br/>
October 1, 2020 | https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification | <a href="https://web.archive.org/web/*/https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><strong>Content amplification is one of the most underused&nbsp;pieces of the&nbsp;content marketing puzzle.</strong></p>
<p><strong>Hands down.</strong></p>
<p><span>So many businesses create great content, but then they only publish that content on their own website, and maybe share it once or twice on social media.</span></p>
<p><span>Sorry to break it to you, but with millions of other businesses doing the same thing, that isn't going to help you cut through the noise.&nbsp;</span></p>
<p><span>At all.&nbsp;</span></p>
<p><span>And hoping that someone will just stumble across your content isn‚Äôt a good strategy, either.&nbsp;</span></p>
<p><span>In reality, you need to <strong>AMPLIFY YOUR CONTENT</strong></span><span>.</span></p>
<p><span>Without content amplification, your hard work and effort will remain essentially ‚Äúon the shelf collecting dust".</span></p>
<p><span>Creating content is less than half the battle. If you don't have a distribution, or amplification strategy for your content, then you're missing out on more traffic, more awareness, more backlinks, better SEO and a more engaged audience.</span></p>
<p><span>And, of course, all of the above <em>usually</em> lead to additional commercial benefits such as more customers and more sales.</span></p>
<p><span>In this article, we‚Äôre going to break down content amplification, tell you what it is, how it works, and how you can get the most out of it so your content can start to work harder and more effectively for you.&nbsp;</span></p>
<p><span>We‚Äôre going to answer the most common questions we get that relate to content amplification, such as:</span></p>
<ul>
<li><span>What is content amplification?</span></li>
<li><span>Why is content amplification so important?</span></li>
<li><span>How can I build a content amplification strategy?</span></li>
</ul>
<p><span>But enough with the preamble. Let‚Äôs jump in and get right into the good stuff.&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Mark%20Masters.jpg" alt="" width="1600" height="150"></span></p>
<p><em>"The reason we shy away from content distribution or amplification is that it feels far better to be creative and produce, than it is to encourage people to watch/listen/read, as this side takes far more effort. Then again, the reason we are creating is to motivate people and get them to subscribe, enquire, interact and buy.</em></p>
<p><em>What is really important is to have something to say that can be amplified. Distribution channels work really well, once you have something to distribute. So, make sure that your message links to your values and that can strike a chord with others. This is how you find your allies, make sure your work is seen and people want to feel a part of it and prepared to stand with you."&nbsp;</em></p>
<p><strong><em>Mark Masters - <a href="https://www.wearethemedia.co.uk/">We Are The Media</a></em></strong></p>
<p>What is content amplification, and why is it so important?</p>
<p><span>Content amplification is the act of promoting and distributing your content across multiple channels (paid, owned and earned) so you can increase the reach and impact of both your content and your brand.</span></p>
<p><span>However, amplifying your content does more than simply provide your brand with additional exposure. It also allows you to position yourself as a thought leader, and build valuable backlinks, as well as build relationships, and increase both engagement and conversion rates with your target audience.&nbsp;</span></p>
<p><span>There are many different ways to amplify content. Paying to promote your content on Facebook or Twitter, leveraging influencers to promote your content, publishing your content on </span><a href="https://promos.converge.today/join-converge"><span>other platforms with an already captivated audience</span></a><span> - they‚Äôre all different ways to amplify your content, and we‚Äôll get into them in a bit more detail later on.</span></p>
<p><span>Without amplification, it‚Äôll be much more difficult for you to get the results you want from your content.&nbsp;</span></p>
<p><span>Every single day, there are</span><a href="https://www.worldometers.info/blogs/"><span> millions of new blogs published</span></a><span>. Yes, not all of them will be competing with what you‚Äôve created, but that‚Äôs a lot of potential noise getting in the way of your message. And organic reach is getting lower and lower all the time.</span></p>
<p><span>Because organic reach across the board is down, way down, when it comes to creating content - and you may be producing the best stuff out there - the likelihood is that without amplifying your content, it‚Äôs not going to perform well.&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Cathy%20McPhillips.jpg" alt="" width="1600" height="150"></span></p>
<p><em>‚ÄúYou‚Äôve written an amazing article ‚Äì and now what? You can‚Äôt expect the results to happen without some distribution work on your end. This includes content amplification ‚Äì a multi-channel approach to increase your brand‚Äôs reach. It‚Äôs taking your owned media, and combining it with paid and earned media. It‚Äôs really knowing the right places ‚Äì and people ‚Äì to help amplify your message to your audience.</em></p>
<p><em>Through content amplification, you‚Äôre able to extend your reach into new areas you couldn‚Äôt achieve on your own through organic methods. It‚Äôs getting out of your echo chamber of your current customers and brand loyalists and finding new and relevant customers who wouldn‚Äôt have necessarily heard of you otherwise. Amplification done right brings customers to you who didn‚Äôt yet know how much they needed you.</em></p>
<p><strong><em>Cathy McPhillips - <a href="http://contentmarketinginstitute.com/">Content Marketing Institute</a></em></strong></p>
<p>The problem with organic traffic</p>
<p><span>OK, that‚Äôs a little misleading. There is no problem with organic traffic.</span></p>
<p><span>The problem lies with the expectations people have when it comes to organic traffic. And, frankly, the delusion that generating it is both a) easily achievable and, b) that it is the only traffic source worth aiming for.&nbsp;</span></p>
<p><span>Nope.</span></p>
<p><span>Listen, organic traffic is great. It‚Äôs wonderful. If you‚Äôre getting huge organic traffic and your website and blogs are appearing right at the top of search results for your most relevant and valuable keywords and phrases, then brilliant! You‚Äôve smashed it already.&nbsp;</span></p>
<p><span>Chances are, though, that‚Äôs not the case. Because, 1) only a handful of businesses across the entire planet can claim to have achieved the above. And it‚Äôs a constant battle for them to remain at the top. And, 2) organic reach is in decline </span><a href="https://blog.hootsuite.com/organic-reach-declining/"><span>across the board</span></a><span>.</span></p>
<p><span>We‚Äôre not saying achieving a first page ranking on Google for your content is impossible, but it may take both time and resources that you currently don‚Äôt have to get there. So, before you become a high-ranking Google superstar, you must find another way to get eyeballs on your content.</span></p>
<p><span>You need to amplify content so you can generate the consistent traffic and backlinks you need to get it the awareness and engagement it deserves, and to get it started on the long, arduous climb towards the first page of search results.&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Abby%20Sorensen.jpg" alt="" width="1600" height="150"></span></p>
<p><em>‚ÄúImagine this scenario at the most important trade show in your industry - Your sales team picks up their badges and heads for the show floor, eager to make connections and meet potential buyers. Your product/service is the exact right fit for these prospects, and your message has been carefully crafted to resonate with them. But your booth is set up at the empty convention center across town. Maybe you were trying to stretch your budget. Or maybe you thought your product/service was so exciting that buyers would go out of their way to find you. Your sales team heads back to the office empty-handed, a complete waste of time and energy spent setting up your booth where your buyers were not.</em></p>
<p><em>This is exactly what happens when you create content with no plan to distribute it.<strong> Only a select few companies can afford to buy their way to the top of Google‚Äôs search rankings.</strong> The only way to get the most out of your content is to distribute it where your buyers are likely to be. And while your website might be the most strategized, optimized, digitized, mobilized website in your market, your buyers simply are not likely to spend a great deal of time there (especially if you hit them with gates and form-fills).‚Äù</em></p>
<p><strong><em>Abby Sorensen - <a href="https://www.followyourbuyer.com/">Follow Your Buyer</a></em></strong></p>
<p>Creating content is less than half the battle</p>
<p><span>That‚Äôs right. All that time you spent researching, planning, creating and publishing content is less than half of what‚Äôs required to give your content the best chance of generating the return on investment you want from it.&nbsp;</span></p>
<p><span>Depending on who you talk to and the articles you read, you may have heard people saying content creation is anywhere from 20-40% of the job.</span></p>
<p><span>The rest of it? You guessed it; amplification/distribution/promotion - whatever you call it. Whatever it takes to get your content in front of everyone you want to read it.</span></p>
<p><span>But let‚Äôs not get bogged down in specific percentages. The only thing you need to know is that you need to spend more time promoting your hard work than you do creating it. Because the competition for attention is fierce, and you need to cut through the noise and make sure people are actually engaging with your content. Otherwise why spend the time creating it in the first place?&nbsp;</span></p>
<p><span><img src="https://www.converge.today/uploads/engage/Content%202019/Alexandra%20Cote.jpg" alt="" width="1600" height="150"></span></p>
<p><em>"Beyond simply creating a really good post, you'll also need really great content amplification methods in place. In fact, everything that happens AFTER you publish a piece of content is much more important than the post itself. This is because sharing content across appropriate channels and talking about your findings and products gets your brand in front of more people.</em></p>
<p><em>This being said, content amplification is the core driver behind reaching your business goals and hitting your KPIs. Whether you want to improve your brand awareness, get more qualified leads, gain new partnerships, or just position yourself as a thought leader in the industry, content amplification can help you hit those targets. Do remember to stay away from vanity metrics though. Just because a lot of people like a post of yours on LinkedIn doesn't mean they read your article and it's a far cry from them actually making a purchase.</em></p>
<p><em>The best advice I have to ensure you're seeing real results from your content amplification techniques is to choose the right networks and websites to promote your content. You'll first need a clear image of your buyer persona. By analyzing potential customers and their behavior, you'll see where they spend most of their time and, above all, what determines them to make a purchase decision. Then, all you have to do is craft the right messaging revolving around the benefits they're looking to get and stay consistent on a couple of networks of choice. Feel free to include the same terms and pain points they use and remember to be responsive so the conversation is bidirectional."</em></p>
<p><strong><em><a href="https://mktodyssey.wordpress.com/">Alexandra Cote</a>, B2B and SaaS Content Writer and SEO Strategist</em></strong></p>
<p>Building a content amplification strategy</p>
<p><span>Of course, it‚Äôs easy ‚Ä¶</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification">https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification</a></em></p>]]>
            </description>
            <link>https://www.converge.today/engage-articles/drive-more-traffic-and-engagement-with-content-amplification</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649266</guid>
            <pubDate>Thu, 01 Oct 2020 10:10:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why are secrets in Git such a threat?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649034">thread link</a>) | @oodelally
<br/>
October 1, 2020 | https://www.gitguardian.com/secrets-detection/secret-sprawl | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection/secret-sprawl">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>What are secrets in the software development world?</p><div><p>In the common language, a secret can be any sensitive data that we want to keep private. When discussing secrets in the context of software development, secrets generally refer to digital authentication credentials that grant access to systems or data. These are most commonly API keys, usernames and passwords, or security certificates.</p><p>Secrets exist in the context of applications that are no longer standalone monoliths. Applications nowadays rely on thousands of independent building blocks: cloud infrastructure, databases, SaaS components such as Stripe, Slack, HubSpot‚Ä¶&nbsp;</p><p>Secrets are what tie together these different building blocks of a single application by creating a secure connection between each component.</p></div><p>What is secret sprawl?</p><div><p>Secret sprawl is the unwanted distribution of secrets like API keys and credentials through multiple systems.&nbsp;</p><p>In modern software development, secrets are regularly used by developers and applications. As a result they often get shared through different services like Slack or email and can be stored in multiple locations including different machines, git repositories or inside company wikis. This is a phenomenon we call secret sprawl.</p></div><p>What are some of the best practices to securely manage secrets like API keys?</p><div><p>Storing and managing secrets like API keys and other credentials can be challenging. Even the most careful policies can sometimes be circumvented in exchange for convenience. We have put together a helpful <a href="https://blog.gitguardian.com/secrets-api-management/" target="_blank">cheat sheet</a> and article explaining the <a href="https://blog.gitguardian.com/secrets-api-management/" target="_blank">best practices for managing secrets</a>.</p><p>As a minimum here are some points you should consider:</p></div><div><p>Never store unencrypted secrets in git repositories</p></div><div><p>Avoid git add * commands on git</p></div><div><p>Add sensitive files in .gitignore</p></div><div><p>Don‚Äôt rely on code reviews to discover secrets</p></div><div><p>Use automated secrets scanning on repositories</p></div><div><p>Don‚Äôt share your secrets unencrypted in messaging systems like Slack</p></div><div><p>Store secrets safely (method to be used depends on every use case)</p></div><div><p>Default to minimal permission scope for APIs</p></div><div><p>Whitelist IP addresses where appropriate</p></div><p>What are the threats associated with secret sprawl?</p><div><p>When secrets are sprawled through multiple systems it increases what is referred to as the ‚Äòattack surface‚Äô. This is the amount of points where an unauthorized user could gain access to your systems or data. In the case of secret sprawl, each time a secret enters another system it is another point where an attacker could gain access to your secrets.</p><p>Most internal systems are not an appropriate place to store sensitive information, even if those systems are private. No company wants credit card numbers in plaintext in databases, PII in application logs, bank account credentials in a Google Doc. Secrets benefit from the same kind of protective measures.</p><p>As a general security principle, where feasible, data should remain safe even if it leaves the devices, systems, infrastructure or networks that are under organizations‚Äô control, or if they are compromised. This helps prevent credential stealing, which is a well-known adversary technique described in the MITRE ATT&amp;CK framework:</p></div><p>‚Äú Adversaries may search local file systems and remote file shares for files containing passwords. These can be files created by users to store their own credentials, shared credential stores for a group of individuals, configuration files containing passwords for a system or service, or source code/ binary files containing embedded passwords. ‚Äù<br></p><p>Secrets accessed by malicious threat actors can lead to information leakage and allow lateral movement or privilege escalation, as secrets very often lead to other secrets. Furthermore, once an attacker has the credentials to operate like a valid user, it is extremely difficult to detect the abuse and the threat can become persistent.<br></p><p>What are some of the biggest challenges associated with secret sprawl?</p><div><p>Because secrets tie together each component of an application, developers and ops need access to these secrets to build, connect, test and deploy applications. The result is that secrets need to be both tightly wrapped and also widely distributed. </p><p>Enforcing good security practices at the organization level is hard. Developers today can have large turnovers inside companies, be spread through many different teams and geographies. They have a growing number of technologies they must master and are under hard pressure due to shortened release cycles. This makes secret management very complicated and an ever changing challenge. </p><p>This is further complicated when VCS like git are introduced because secrets can be buried deep inside the history. The actual version of source code might look clean, while the history might present credentials that were added than later removed. Any secret reaching the Version Control System must be considered compromised and the presence of valid secrets in the git history presents a threat!</p></div></div></div>]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection/secret-sprawl</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649034</guid>
            <pubDate>Thu, 01 Oct 2020 09:27:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is it hard to detect API keys in source code?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24649026">thread link</a>) | @oodelally
<br/>
October 1, 2020 | https://www.gitguardian.com/secrets-detection/how-to-detect-secrets-in-source-code | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection/how-to-detect-secrets-in-source-code">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Why is it hard to detect secrets like API keys and other credentials?</p><div><p>Secrets detection is probabilistic‚Äîthat is to say that it is not always possible to determine what is a true secret (or true positive). Because secrets share very few common, distinctive factors, decisions must be taken by aggregating weak signals to make strong predictions. </p><p>One of the most common factors is that almost all secrets are strings that look random. We call these strings high entropy strings. The issue is that this common factor is not very distinctive: 99% of strings that look random in source code aren‚Äôt secrets. They are for example database IDs or other types of false positives. </p><p>Of course, some secrets have fixed patterns: AWS keys often start with AKIA for example. But most secrets do not. The portions of code surrounding them are also very different, depending on what the secrets are used for and how they are used by the developers in the context of specific applications. Usernames and passwords can be used to authenticate in many different ways, and it is really hard to distinguish between real and fake credentials used as placeholders for example. </p><p>All this makes it extremely challenging to accurately capture all true secrets without also capturing false positives. At some point, a line in the sand needs to be drawn that considers the cost of a secret going undetected (a false negative) and compares it to the outcome that too many false positives would create. Different organizations with different people, cultures and workflows will draw different lines!</p></div><p>Why do code reviews fail at finding secrets in source code?</p><p>Code reviews are great overall for detecting logic flaws or maintaining certain good coding practices. But they are not adequate protection for detecting secrets, mostly for two reasons:<br></p><div><p>Reviews generally only consider the net difference between the current and proposed states. Not the entire history of changes. If a commit adds a secret and another one later deletes it, this has a zero net effect that is not of any interest to reviewers. But the vulnerability is there.</p></div><div><p>Reviewers prefer to focus on errors that cannot be automatically detected, like design flaws. As a general principle, security automation should be implemented wherever it can be, so that humans focus on where they bring the most value.</p></div><p>What is a "good" secrets detection algorithm?</p><div><p>Detecting secrets in source code is like finding needles in a haystack: there are a lot more sticks than there are needles, and you don‚Äôt know how many needles might be in the haystack. In the case of secrets detection, you don‚Äôt even know what all the needles look like!</p><p>Ideally, you want your detection system to achieve at the same time:</p></div><div><p>A low number of false alerts raised. We call this high precision. Precision answers the question: ¬´What is the percentage of the secrets that you detect that are actual secrets?¬ª. This question is perfectly legitimate, especially in the context of security teams being overwhelmed with too many alerts.</p></div><div><p>A low number of secrets missed. This is what we call high recall. Considering that a single undetected credential can have a big impact for an organization, some organizations prefer to triage more false alerts but make sure they don‚Äôt miss a secret.</p></div><p>Balancing the equation to ensure that the algorithm captures as many secrets as possible without flagging too many false results is an intricate and extremely difficult challenge. Read more on evaluating <a href="https://blog.gitguardian.com/secrets-detection-accuracy-precision-recall-explained/" target="_blank">secrets detection algorithms</a>.<br></p><p>What is a false positive in secrets detection?</p><div><p>A false positive in secrets detection refers to when a secret candidate is wrongly marked as a true secret when it is in fact a non-sensitive string. </p><p>Typical examples of strings that can be mistaken for true secrets are:</p></div><div><p>UUIDs (Universally Unique Identifiers) that are used for example by databases as unique keys.</p></div><div><p>High entropy URLs or file paths. They often contain random strings that look like keys.</p></div><p>Examples of server-side hooks:<br></p><div><p>Test keys. Service Providers sometimes provide developers with a set of test credentials with a very restricted scope so developers can exercise parts of the API without charging their account</p></div><div><p>Public keys. As surprising as it is, a very small number of keys are really meant to be public (like Firebase keys, see this Stack Overflow <a href="https://stackoverflow.com/questions/37482366/is-it-safe-to-expose-firebase-apikey-to-the-public" target="_blank">conversation</a>).</p></div><p>Are secrets detection algorithms language-dependent?</p><p>Secrets detection is, for the most part, not language specific. Of course, there are some subtleties to take into account, like the way variables are assigned in any programming language. But there is no need to support all the different syntaxes in their greatest details. This means that the same algorithms can be applied to any project, in any programming language, without using things like Abstract Syntax Trees.<br></p></div></div>]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection/how-to-detect-secrets-in-source-code</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649026</guid>
            <pubDate>Thu, 01 Oct 2020 09:26:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why automate secrets scanning throughout your SDLC?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24649022">thread link</a>) | @oodelally
<br/>
October 1, 2020 | https://www.gitguardian.com/secrets-detection/secrets-detection-application-security | <a href="https://web.archive.org/web/*/https://www.gitguardian.com/secrets-detection/secrets-detection-application-security">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>My source code is private, so why is hardcoding credentials in git considered a bad practice?</p><div><p>While private repositories offer some level of protection for your code they still do not have adequate protection to store information as sensitive as secrets. </p><p>Imagine if there was a plain text file with all your credit card numbers within it, you hopefully wouldn‚Äôt put this into the companies git repository. Secrets are just as sensitive.</p><p>A few things to consider when storing secrets in private repositories:</p></div><div><p>Source code is made to be duplicated and distributed, therefore lives in multiple places. Source code is a leaky asset and you never know where it is going to end up. It can be cloned to a compromised workstation or server, intentionally or accidentally published in whole or in part, uploaded to your website, released to a customer, pasted in Slack, or end up in your package manager or mobile application...</p></div><div><p>It would just take one compromised developer account to compromise all the secrets they have access to.</p></div><div><p>Hardcoded credentials make it impossible to know what secrets a developer accessed, and very difficult to rotate keys.</p></div><p>Why automate secrets scanning throughout the Software Development Life Cycle (SLDC)?</p><p>While DevOps, Continuous Integration and Continuous Delivery speed up software development, they can also significantly increase security risks.<br></p><p>‚ÄúDevOps is rapid and requires lots of small, iterative changes. But this increases complexity and opens up a new set of security problems. With DevOps, existing security vulnerabilities can be magnified and manifest themselves in new ways. The speed of software creation can mean new vulnerabilities are created unseen by developers. The solution is to build security monitoring into the DevOps process from the start.‚Äù<br></p><p>Greg Day, RSA Conference Organizer (<a href="https://www.securityroundtable.org/the-biggest-cybersecurity-risks-in-2020/" target="_blank">source</a>)<br></p><p>Security now needs to be part of the SDLC from the start, and part of every incremental change. This concept is called Shifting Left, a development principle which states that security should move from the right (or end) of the SDLC to the left (the beginning). A great deal of automation is needed in order to be able to cope with running security checks at each incremental change. &nbsp;Automation helps streamline the detection, alerting and remediation processes and workflows.<br></p><p>How does secrets detection compare with Static Application Security Testing (SAST)?</p><div><p>Secrets detection is often confused with SAST because both scan through static source code. </p><p>SAST is mostly testing control structure, input validation, error handling, etc. Such vulnerabilities like SQL injection vulnerabilities only express themselves the moment the code is deployed. Exposed secrets are unlike these vulnerabilities, because any secret reaching version control system must be considered compromised and requires immediate attention. This is true even if the code is never deployed. </p><p>Implementing secrets detection is not only about scanning the most actual version of your master branch before deployment. It is also about scanning through every single commit of your git history, covering every branch, even development or test ones.</p><p>To conclude, SAST is concerned only with the current version of a project, the version that is going to be deployed, whereas secrets detection is concerned with the entire history of the project.</p></div><p>What are git hooks?</p><div><p>Git hooks are scripts that are triggered by certain actions in the software development process, like committing or pushing. By automatically pointing out issues in code, they allow reviewers not to waste time on mistakes that can be easily diagnosed by a machine. </p><p>There are client-side hooks, that execute locally on the developers‚Äô workstation, and server-side hooks, that execute on the centralized version control system.</p><p>Examples of client-side hooks:</p></div><p>Examples of server-side hooks:<br></p><p>What is a pre-commit hook?</p><div><p>"The pre-commit hook is run first when committing, before you even type in a commit message. It‚Äôs used to inspect the snapshot that‚Äôs about to be committed, to see if you‚Äôve forgotten something, to make sure tests run, or to examine whatever you need to inspect in the code. </p><p>Exiting non-zero from this hook aborts the commit, although you can bypass it with <span>git commit --no-verify</span>. You can do things like check for code style (run lint or something equivalent), check for trailing whitespace, or check for appropriate documentation on new methods."</p></div><p>Source: <a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks" target="_blank">git-scm</a><br></p><p>What is a pre-receive hook?</p><div><p>A pre-receive hook is a script that runs on the server. It performs checks on the content of the push; if it exits non-zero, the push is rejected. You can use this hook to do things like prevent a PR author from merging their own changes, or require commit messages to follow some specific guidelines. </p><p>Be careful when using pre-receive hooks as they are blocking: if the checks don‚Äôt pass, the server is not updated.</p></div><p>What is a post-receive hook?</p><p>"The post-receive hook runs after the entire process of pushing code to the server is completed and can be used to update other services or notify users. Examples include emailing a list, notifying a continuous integration server, or updating a ticket-tracking system ‚Äì you can even parse the commit messages to see if any tickets need to be opened, modified, or closed. This script can‚Äôt stop the push process, but the client doesn‚Äôt disconnect until it has completed, so be careful if you try to do anything that may take a long time."<br></p><p>Source: <a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks" target="_blank">git-scm</a><br></p><p>Unlike the pre-receive hook, post-receive is non-blocking.<br></p><p>Where in the DevOps pipeline to implement automated secrets scanning? Client-side or server-side?</p><div><p>The earlier a security vulnerability is uncovered, the less costly it is to correct. Hardcoded secrets are no exceptions. If the secret is uncovered after the secret reaches centralized version control server-side, it must be considered compromised, which requires rotating (revoking and redistributing) the exposed credential. This operation can be complex and typically involves multiple stakeholders.</p><p>Client-side secrets detection early in the software development process is a nice-to-have as it will prevent secrets entering the VCS earlier. </p><p>Server-side secrets detection is a must have:</p></div><div><p>&nbsp;Server-side is where the ultimate threat lies. From the server, the code can uncontrollably spread in a lot of different places, with the hardcoded secrets in it.</p></div><div><p>Implementing client-side hooks on an organization level is hard. This is something we have heard many application security professionals claim they are not confident to do, due to the difficulty to deploy and update this on every developer‚Äôs workstation.</p></div><div><p>Client-side hooks can and must be easy to bypass (remember secret detection is probabilistic). Usage of client side hooks largely comes down to the individual developers‚Äô responsibility. Hence the need to have visibility over the later stages.</p></div><p>Should secrets detection be blocking or non-blocking in the SDLC?</p><div><p>From our experience, when trying to impose rules that are too constraining, people will bend them, often in an effort to collaborate better and do their job. Security must not be a blocker. It should allow flexibility and enable information to flow, yet enable visibility and control. </p><p>On one hand, security measures will be bypassed, sometimes for the worst. But on the other hand, it is also good sometimes that the developer can take the responsibility to bypass them. </p><p>Because even the best algorithms can fail and need human judgement. Secrets detection is probabilistic: algorithms achieve a tradeoff between not raising false alerts and not missing keys.</p></div></div></div>]]>
            </description>
            <link>https://www.gitguardian.com/secrets-detection/secrets-detection-application-security</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649022</guid>
            <pubDate>Thu, 01 Oct 2020 09:25:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paralyzed Dutch man can temporarily move and talk again thanks to sleeping pill]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24648831">thread link</a>) | @jacquesm
<br/>
October 1, 2020 | https://www.world-today-news.com/paralyzed-dutch-man-can-temporarily-move-and-talk-again-thanks-to-sleeping-pill-now/ | <a href="https://web.archive.org/web/*/https://www.world-today-news.com/paralyzed-dutch-man-can-temporarily-move-and-talk-again-thanks-to-sleeping-pill-now/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>A Dutch man who has been unable to move and speak for eight years due to brain damage, can temporarily do so after taking the sleeping drug Zolpidem.  Brain scans show that the sleeping pill removes an obstacle to these actions, scientists from Radboudumc and Amsterdam UMC report Thursday.</p>
<p>In men, the brain activity for moving and talking is drowned out by the brain activity for the transfer of information.</p>
<p>‚ÄúYou could compare the brain, as it were, to a large string orchestra‚Äù, explains fellow researcher Hisse Arnts.  ‚ÄúWith Richard (the man, ed.) The first violins play so loud that they drown out the other members of the string orchestra and people can no longer hear each other. Zolpidem ensures that these first violins play more ‚Äòpianissimo‚Äô, so that everyone back within time. ‚Äú</p>
<p>The fact that the man does not go to sleep because of Zolpidem is probably due to the way his brain has become confused, Arnts thinks.  The problem, however, is that the man gets used to the sleeping aid, so that the effect becomes shorter and shorter.  Yet he still receives it regularly and the discovery is a promising starting point for further research.</p>
<p>The man is not the first to return to a normal situation briefly with such a means;  there are similar reports from Italy and South Africa.  But how that is possible has now been determined for the first time on the basis of scans, according to the medical centers.</p>

<p>The man, in his late twenties at the time, suffered a severe lack of oxygen eight years ago due to choking.  He ended up in a nursing home with the very rare diagnosis of akinetic mutism.  Because Richard‚Äôs situation seemed hopeless, it was decided to give him the remedy.</p>

</div><p>    .</p></div>]]>
            </description>
            <link>https://www.world-today-news.com/paralyzed-dutch-man-can-temporarily-move-and-talk-again-thanks-to-sleeping-pill-now/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648831</guid>
            <pubDate>Thu, 01 Oct 2020 08:48:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asteroids: By the Numbers]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24648639">thread link</a>) | @rbanffy
<br/>
October 1, 2020 | http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1 | <a href="https://web.archive.org/web/*/http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-3855344372715435262"><p>
By 1979, arcade games were rapidly becoming more complex and colorful, and a game like <i>Asteroids </i>might have seemed quaint by comparison to the likes of <i><a href="http://www.retrogamedeconstructionzone.com/2019/09/galaxian-aesthetics-of-simple-patterns.html">Galaxian</a>, <a href="http://www.retrogamedeconstructionzone.com/2019/09/star-fire-weirdness-of-pseudo-3d.html">Star Fire</a></i>, or <i>Radar Scope.&nbsp; </i>But beneath its simple exterior lies a challenging shooter with surprisingly complex physics.&nbsp; The image below shows a sample still from it, including the player's ship (the triangle on the left), three sizes of asteroids, and an alien ship.</p><p><a href="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s1600/Asteroids_sample%2B%25282%2529.png"><img data-original-height="461" data-original-width="598" height="492" src="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s640/Asteroids_sample%2B%25282%2529.png" width="640"></a></p>

<p>
The goal of the game is to maximize your score, destroying as many asteroids and aliens as possible before you run out of ships.&nbsp; When an asteroid is hit by something (usually the player's bullets), large asteroids turn into two medium ones and medium asteroids turn into two small ones, while small asteroids and aliens are destroyed when hit.</p><p><a href="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s1600/Asteroids%2BPlay.gif"><img data-original-height="357" data-original-width="600" height="237" src="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s400/Asteroids%2BPlay.gif" width="400"></a></p>
<p>
For the designers of the game, balancing the relative sizes of the objects would have been important in such a dense field, because it determines how often things run into one another other.&nbsp; The table below outlines the sizes of the objects in <i>Asteroids</i>, expressed relative to the length of the player's ship.</p><table>
<caption>The approximate horizontal lengths of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Length (in player ship lengths)</th>
    </tr>
<tr>
    <td>Screen</td>
    <td>25 x 36</td>
    </tr>
<tr>
    <td>Large Asteroids</td>
    <td>2.4</td>
    </tr>
<tr>
    <td>Medium Asteroid</td>
    <td>1.2</td>
    </tr>
<tr>
    <td>Small Asteroid</td>
    <td>0.6</td>
    </tr>
<tr>
    <td>Alien Ship (large)</td>
    <td>1.5</td>
    </tr>
<tr>
    <td>Alien Ship (small)</td>
    <td>0.75</td>
    </tr>
</tbody>
    </table>
<p>
Notice how the medium asteroid is twice the size of the small one, and the large is twice the size of the medium.&nbsp; If you think about it, this doesn't actually make much physical sense -- you can break a two-dimensional object into four pieces half its size, not two.&nbsp; But the size ratios do make game sense, because what really matters to the player is not how much area an asteroid takes up, but how likely it is to hit them.</p><p><a href="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"><img data-original-height="281" data-original-width="170" src="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"></a></p>

<p>
In the picture above, you can see that while the four small asteroids take up less area on the screen than the big one, they present the same cross section to your ship.&nbsp; This means that breaking up the asteroids doesn't greatly increase the probability that the player will be struck by one.&nbsp; If the asteroids had been broken up into four half-sized pieces at each blow, each large asteroid would result in sixteen small ones (that's four times the cross section!) and the player would be quickly overwhelmed.&nbsp; Note that the small asteroids do move faster than the large ones, and speed increases the chance of getting hit, but I'll return to that in a moment.</p>

<p>
Another big reason that size matters in <i>Asteroids</i>&nbsp;is that it determines how close something has to be before you're likely to be able to hit it.&nbsp; In 1979, vector arcade cabinet screens had an effective resolution of 1024 x 768, and the player's ship was only connected graphically by about 20 points.&nbsp; This meant, in turn, that there were only a limited number of orientations that they could render for the ship, in this case intervals of 5 degrees.&nbsp; To see how this might affect gameplay, imagine your ship is located at the fixed position shown in the picture below.&nbsp; Anything located entirely between the two solid lines will not be accessible by your bullets because your ship can't turn to the appropriate angle to hit it.&nbsp; This restriction isn't a big deal for large asteroids, which are still accessible over most of the screen, but small asteroids can be out of reach of your guns at relatively close range, sometimes as close as 7 ship lengths away!&nbsp; So even if you aim as accurately as possible, chances are you won't be able to hit a small asteroid on the other side of the screen, at least not on your first shot.&nbsp; This is probably one of the reasons that <i>Asteroids</i>&nbsp;allows you to fire up to four bullets in succession: even if you can't hit an object right away, it will eventually move into your line of fire.</p>

<p><a href="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s1600/Asteroids_hittable%2B%25285%2529.png"><img data-original-height="397" data-original-width="1024" height="248" src="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s640/Asteroids_hittable%2B%25285%2529.png" width="640"></a></p>
<p>
And what about speed?&nbsp; There is some variability in the speeds of individual asteroids, but small asteroids can move as much as 63% faster than large ones (see the table below), meaning that even if four small asteroids present the same cross section for hitting your ship as a large one does, their higher speed means they're more likely to hit you.&nbsp; The reasoning for this is simple: the faster something moves, the longer the path it can traverse in a given amount of time, and the larger the likelihood that you'll be in that path.&nbsp; Fortunately, even the fastest asteroids are much slower than your ship, which can traverse the screen in about two seconds; so if you're skilled enough, you should be able to maneuver around the asteroid field without a problem.</p><table>
<caption>The approximate speeds of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Speed (in ship lengths per second)</th>
    </tr>
<tr>
    <td>Your ship</td>
    <td>0 - 17</td>
    </tr>
<tr>
    <td>Asteroids</td>
    <td>4 - 6.5</td>
    </tr>
<tr>
    <td>Alien ships (both sizes)</td>
    <td>4 - 6.5 (depending on your score)</td>
    </tr>
<tr>
    <td>Bullets</td>
    <td>17 (ship at rest)&nbsp;</td></tr>
</tbody></table>
<p>
One other interesting thing about speed: notice in the table above that the speed of a bullet, when fired at rest, is the same as your ship's maximum speed.&nbsp; This means that when you're moving rapidly and fire a bullet in the opposite direction of your motion, the two speeds should cancel for a stationary observer and the bullet should appear roughly stationary.</p>

<p><a href="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s1600/Asteroids_bullet_stationary.gif"><img data-original-height="175" data-original-width="468" height="239" src="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s640/Asteroids_bullet_stationary.gif" width="640"></a></p>


<div><p>
Sure enough, when I fire a bullet while moving quickly in the opposite direction, it just floats near where I fired it, allowing me to place bullets like mines for the asteroids to run into.</p>
<p>
The developers of <i>Asteroids </i>wanted the game to simulate the real laws of physics (<a href="http://www.technologyuk.net/computing/computer-gaming/gaming-landmarks-1960-1985/asteroids.shtml">see here</a>), and I think in many respects they succeeded, at least compared to most other arcade games of the time.&nbsp; It's not entirely realistic, however.&nbsp; In my article on <a href="http://www.retrogamedeconstructionzone.com/2019/10/impossible-motion-in-video-games.html">motion in early arcade games</a>, I discussed how the acceleration of the ship in <i>Asteroids</i> is too rapid for a human-occupied vehicle.&nbsp; We might suppose that the vehicle is automated, but even then, engineering spacecraft to withstand 30+ g's of acceleration is a non-trivial challenge.</p><p><a href="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s1600/Acceleration%2BAsteroids.gif"><img data-original-height="175" data-original-width="634" height="176" src="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s640/Acceleration%2BAsteroids.gif" width="640"></a></p>
<p>
Another issue is the way the asteroids break up.&nbsp; In physics, there's a principle called the conservation of momentum that says that when objects interact with one another or break apart, the total mass times the velocity must remain the same after the interaction as it was before.&nbsp; In layman's terms, this means that things can't suddenly go from moving one direction to moving in another unless there is something else carry its previous momentum.&nbsp; In the example shown below, an asteroid does just that, and the only thing that could have absorbed its previous momentum is the bullet.&nbsp; But the bullet is so tiny that it's difficult to imagine how that would be possible.</p><p><a href="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s1600/Asteroids_momentum.gif"><img data-original-height="248" data-original-width="533" height="185" src="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s400/Asteroids_momentum.gif" width="400"></a></p>

<p>
These are mere quibbles, however, and shouldn't dissuade you from giving the game a try.&nbsp; <i>Asteroids </i>ended up being one of Atari's biggest arcade hits, selling over 70,000 cabinets, and remains one of their most recognizable games to this day.&nbsp; Many gamers who grew up in the '80s, myself included, are more familiar with the Atari 2600 version of the game.&nbsp; Unfortunately, the designers had to make a lot of sacrifices in game physics in order to make it work on a home console, so I think the arcade version is really the way to go.&nbsp; Outside of visiting a vintage arcade, your best bet is probably the <a href="https://www.mamedev.org/">Multiple Arcade Machine Emulator</a> (MAME).&nbsp; Happy hunting!</p></div><div><p><span>NOTE: &nbsp;A previous version of this article stated that the game has limited pixel resolution, but <i>Asteroids </i>uses a vector display that is not composed of pixels. &nbsp;The resolution of the <i>Asteroids </i>vector display is 1024 x 768.</span></p><p><a href="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s1600/Asteroids_loop_transparent.gif"><img data-original-height="151" data-original-width="600" height="160" src="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s640/Asteroids_loop_transparent.gif" width="640"></a></p>
<br></div>
</div>
</div></div>]]>
            </description>
            <link>http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648639</guid>
            <pubDate>Thu, 01 Oct 2020 08:15:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russian opposition leader Alexei Navalny describes his poisoning with Novichok]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24648502">thread link</a>) | @FrojoS
<br/>
October 1, 2020 | https://www.spiegel.de/international/world/alexei-navalny-thanks-germany-and-describes-his-poisoning-with-novichok-a-f1249540-76f7-43ce-aa14-358d71256684 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/alexei-navalny-thanks-germany-and-describes-his-poisoning-with-novichok-a-f1249540-76f7-43ce-aa14-358d71256684">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;83eb2320-0da2-4c9c-971a-560530cea088&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;228ec165-7b2d-487b-b370-085f5f8c64f8&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/83eb2320-0da2-4c9c-971a-560530cea088_w948_r1.77_fpx28.11_fpy49.98.jpg" srcset="https://cdn.prod.www.spiegel.de/images/83eb2320-0da2-4c9c-971a-560530cea088_w520_r1.77_fpx28.11_fpy49.98.jpg 520w, https://cdn.prod.www.spiegel.de/images/83eb2320-0da2-4c9c-971a-560530cea088_w948_r1.77_fpx28.11_fpy49.98.jpg 948w" width="948" height="536" sizes="948px" title="Alexei Nawalny" alt="Alexei Nawalny">
</span>
</span>
</span>

</p>
<figcaption>
<p>Alexei Nawalny</p>
<span>
Foto:‚ÄÇPeter Rigaud&nbsp;/ DER SPIEGEL
</span>
</figcaption>
</figure>
</div><div>
<p>In his first media interview following his poisoning, Russian opposition leader Alexei Navalny expresses his "tremendous gratitude to all Germans" in an interview with the newsmagazine DER SPIEGEL. In the interview, he says that although he never had close ties to Germany, it was German politicians and Chancellor Angela Merkel who saved his life. He says the doctors at Berlin's Charit√© University Hospital saved his life for a second time and nursed him back to health. "I know it sounds a bit over the top, but Germany has become a special country for me," Navalny says. Describing the personal visit paid to him by Merkel last week, he says: "I was impressed by the detail she knows about <a href="https://www.spiegel.de/thema/russia_en/" data-link-flag="english">Russia</a> and my case."</p>



<section data-area="contentbox">

</section>
<p>Navalny says he is doing "much better than three weeks ago, and things are getting better each day." The doctors say he could get back to 90 percent of his former self, perhaps even 100 percent, although no one knows for sure. "Basically, I‚Äôm a bit of a guinea pig," he says. "There aren‚Äôt many people you can observe who are still alive after being poisoned with a nerve agent." Describing the moment in the airplane when the poison started to take effect, Navalny says: "You feel no pain, but you know you‚Äôre dying. And I mean, right now. Even though nothing hurts you." You just think: This is the end. "Organophosphorus compounds attack your nervous system like a DDos attack attacks the computer - it's an overload that breaks you," he told DER SPIEGEL.</p>

<div>
<p>"I assert that <a href="https://www.spiegel.de/thema/vladimir_putin_en/" data-link-flag="english">Putin</a> was behind the crime, and I have no other explanation for what happened." Despite the attempt on his life, he says he wants to return to Russia. "And my job now is to remain the guy who isn‚Äôt afraid. And I‚Äôm not afraid! When my hands shake, it‚Äôs not from fear ‚Äì it‚Äôs from this stuff. I would not give Putin the gift of not returning to Russia."</p><p>When asked whether he thinks Germany should stop the completion of the Nord Stream 2 Russian gas pipeline project, Navalny didn‚Äôt want to answer. "That‚Äôs Germany‚Äôs business. Decide for yourself!" Any strategy toward Russia must "take into account the level of insanity that Putin has reached."</p>
</div>

<div>
<p><em>The full interview with Navalny will be posted in English later today.</em></p>
<p><span><svg aria-labelledby="title-4bef5875-3b95-4568-98a1-32d00bb733d1" width="10" height="20" viewBox="0 0 10 20" fill="none" xmlns="http://www.w3.org/2000/svg" role="img"><title id="title-4bef5875-3b95-4568-98a1-32d00bb733d1">Icon: Der Spiegel</title><g id="l-s-flag-4bef5875-3b95-4568-98a1-32d00bb733d1"><path id="vector-4bef5875-3b95-4568-98a1-32d00bb733d1" d="M9.85 16.293v-8H3.212V4.667h3.533v2.24h3.212v-3.2C9.85 2.747 8.993 2 8.03 2H1.713C.749 2 0 2.747 0 3.707v7.253h6.638v4.373H3.105v-2.986H0v3.84c0 .96.75 1.706 1.713 1.706H8.03c.963.107 1.82-.64 1.82-1.6z" fill="#000"></path></g></svg>
</span>
</p></div>

</div>
</section>

</div></div>]]>
            </description>
            <link>https://www.spiegel.de/international/world/alexei-navalny-thanks-germany-and-describes-his-poisoning-with-novichok-a-f1249540-76f7-43ce-aa14-358d71256684</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648502</guid>
            <pubDate>Thu, 01 Oct 2020 07:54:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Baremetal programming on the tinyAVR 0 micro-controllers]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 94 (<a href="https://news.ycombinator.com/item?id=24648397">thread link</a>) | @unwind
<br/>
October 1, 2020 | https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers | <a href="https://web.archive.org/web/*/https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><section><div><h4>All you need is a text editor, a makefile and a USB-serial cable.</h4></div></section><section><div><p><img src="https://www.omzlo.com/uploads/std_attiny-406-macro.jpg" alt=""></p>

<h2 id="introduction">Introduction</h2>

<p>Are you an 8-bit or a 32-bit programmer? </p>

<p>At OMZLO, we have been mainly focussing our development efforts on newer 32-bit Arm-Cortex chips (STM32 and SAMD), which typically offer more RAM, more speed, more peripherals, at a similar or lower price-point than older 8-bit MCUs. But 8-bit MCUs are far from dead. Microchip has notably released a new series of chips, collectively branded as the "tinyAVR 0-series", which offer more modern peripherals than the older AVR chips at a very competitive price point. They seem like the perfect candidate for simple products that don't need all the features and fine-tuning capabilities of the newer 32-bit MCUs. 8-bit MCUs are also substantially simpler to program, which translates into faster development time. </p>

<p>Thanks to the success of the Arduino UNO, there are tons of tutorials online that explain how to program 8-bit Atmega328 microcontrollers and their cousins like the Attiny85 using direct register access, without the Arduino language or any vendor IDE such as Atmel Studio. Just google "atmega328 blinky". All you need is an AVR C-compiler, a text editor, <a href="https://www.nongnu.org/avrdude/">avrdude</a>, and an AVR programmer. Some <a href="https://www.instructables.com/id/Getting-Started-With-the-ATMega328P/">resources</a> even show how to also build the electronics needed to get a basic atmega328 running on a breadboard. However, it's hard to find the same information for these newer "tinyAVR 0" chips.</p>

<p>Of course, Microchip offers all the tools necessary to program these newer "TinyAVR" MCUs with their windows-only IDE. There are also "Arduino cores" for some of these newer "TinyAVR" MCUs that let you program them with the Arduino IDE. But again, if you like to write code for MCUs in "baremetal" style, with your favorite text editor, a makefile, and a c-compiler, there are few resources available online. </p>

<p>In this blog post, we will describe how to program a <a href="https://www.ladyada.net/learn/proj1/blinky.html">blinky</a> firmware on an <strong>Attiny406</strong>, from the ground up, using the simplest tools. Most of the things described here can be easily transposed to other TinyAVR MCUs. Our approach is generally guided toward macOS or Linux users, but should also be applicable in an MS-Windows environment with a few minor changes.</p>

<h2 id="hardware">Hardware</h2>

<p>We decided to play with the <a href="https://www.microchip.com/wwwproducts/en/ATTINY406">Attiny406</a>, with a view of using it in the future to replace the Attiny45 we currently use on the <a href="https://www.omzlo.com/articles/the-piwatcher">PiWatcher</a>, our Raspberry-Pi watchdog. The Attiny406 has 4K of flash space, 256 bytes of RAM, and can run at 20Mhz without an external clock source.</p>

<p>One of the most important differences between the new TinyAVR MCUs and the older classic AVR MCU like the Attiny85 is that the newer chips use a different programming protocol called UPDI, which requires only 3 pins, as opposed to the 6-pin ISP on the classic AVRs.</p>

<p>A little research shows that programming TinyAVRs with UPDI can be achieved with a simple USB-to-serial cable and a resistor, thanks to a python tool called <a href="https://github.com/mraardvark/pyupdi">pyupdi</a>, which suggests the following connection diagram for firmware upload:</p>
<pre>                        Vcc                     Vcc
                        +-+                     +-+
                         |                       |
 +---------------------+ |                       | +--------------------+
 | Serial port         +-+                       +-+  AVR device        |
 |                     |      +----------+         |                    |
 |                  TX +------+   4k7    +---------+ UPDI               |
 |                     |      +----------+    |    |                    |
 |                     |                      |    |                    |
 |                  RX +----------------------+    |                    |
 |                     |                           |                    |
 |                     +--+                     +--+                    |
 +---------------------+  |                     |  +--------------------+
                         +-+                   +-+
                         GND                   GND
</pre>
<h3 id="shematic">shematic</h3>

<p>We created a minimalistic breakout board for the Attiny406. The board can be powered by 5V through USB or a lower 3.3V through dedicated VCC/GND pins. An LED and a button were also fitted on the board. For testing purposes, we decided to embed the 4.7K resistor needed for the UPDI programming directly in the hardware (i.e. resistor <em>R2</em>). 
This gives us the following schematic:</p>

<p><img src="https://www.omzlo.com/uploads/attiny406-schematic.png" alt="schematic"></p>

<h3 id="board">Board</h3>

<p>The resulting breakout board is tiny and fits conveniently on a small breadboard. The design files are <a href="https://aisler.net/p/SIEGFIYL">shared on aisler.net</a>.</p>

<p><img src="https://www.omzlo.com/uploads/std_attiny-406-breadboard.jpg" alt=""></p>

<p>Programming the Attiny406 on the board with a USB-serial cable is done by connecting the headers on the board edge:</p>

<p><img src="https://www.omzlo.com/uploads/attiny406-prog.png" alt=""></p>

<h2 id="software">Software</h2>

<h3 id="pyudpi">pyudpi</h3>

<p>We installed <strong>pyupdi</strong> following the instructions provided on <a href="https://github.com/mraardvark/pyupdi">their webpage</a>. </p>

<p>We connected our USB-Serial cable to the board with the 4 dedicated UPDI pins available on the board. Our USB-Serial converter shows up as the file <code>/dev/tty.usbserial-FTF5HUAV</code> on a MacOS system.</p>

<p>To test that the programmer recognizes the Attiny406, you can issue a command similar to the following, adapting the path for the USB-serial converter to your setup:</p>
<pre>pyupdi -d tiny406 -c /dev/tty.usbserial-FTF5HUAV -i
</pre>
<p>This should result in the following output if all goes well:</p>
<pre>Device info: {'family': 'tinyAVR', 'nvm': 'P:0', 'ocd': 'D:0', 'osc': '3', 'device_id': '1E9225', 'device_rev': '0.1'}
</pre>
<h3 id="the-c-compiler">The C compiler</h3>

<p>The typical <strong>avr-gcc</strong> available on macOS with <a href="https://brew.sh/">homebrew</a> did not seem to recognize the Attiny406 as a compiler target, so we went off to install the avr-gcc compiler provided by Microchip, which is available <a href="https://www.microchip.com/mplab/avr-support/avr-and-arm-toolchains-c-compilers">here</a>. Downloading the compiler requires you to create an account on the Microchip website, which is a bit annoying. </p>

<p><img src="https://www.omzlo.com/uploads/avr-toolchain.png" alt="AVR toolchain link"></p>

<p>Once downloaded, we extracted the provided archive in a dedicated directory. The <code>bin</code> directory in the archive should be added to the <code>PATH</code> variable to make your life easier. Assuming the downloaded compiler is stored in the directory <code>$HOME/Src/avr8-gnu-toolchain-darwin_x86_64</code>, the PATH can be altered by adding the following line to your <code>.bash_profile</code> file:</p>
<pre>export PATH=$PATH:$HOME/Src/avr8-gnu-toolchain-darwin_x86_64/bin/
</pre>
<p>Newer Attiny MCUs are not supported out of the box by the Microchip <strong>avc-gcc</strong> compiler. You need to download a dedicated <em>Attiny Device Pack</em> from <a href="http://packs.download.atmel.com/">their website</a>, as shown below:</p>

<p><img src="https://www.omzlo.com/uploads/microchip-pack-repository.png" alt="AVR toolchain link"></p>

<p>The resulting downloaded <em>Device Pack</em> is named <code>Atmel.ATtiny_DFP.1.6.326.atpack</code> (or similar depending on versioning). Though the extension is <code>.atpack</code>, the file is actually a zip archive. We changed the extension to <code>.zip</code> and extracted the package in the directory <code>$HOME/Src/Atmel.ATtiny_DFP.1.6.326</code> next to the compiler files. </p>

<h3 id="c-program">C program</h3>

<p>We created the following program that blinks the LED on pin PB5 of our Attiny board at a frequency of 1Hz.</p>
<pre><span>#include &lt;avr/io.h&gt;
#include &lt;util/delay.h&gt;
</span>
<span>int</span> <span>main</span><span>()</span> <span>{</span>
    <span>_PROTECTED_WRITE</span><span>(</span><span>CLKCTRL</span><span>.</span><span>MCLKCTRLB</span><span>,</span> <span>0</span><span>);</span> <span>// set to 20Mhz (assuming fuse 0x02 is set to 2)</span>

    <span>PORTB</span><span>.</span><span>DIRSET</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
    <span>for</span> <span>(;;)</span> <span>{</span>
        <span>PORTB</span><span>.</span><span>OUTSET</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
        <span>_delay_ms</span><span>(</span><span>500</span><span>);</span>
        <span>PORTB</span><span>.</span><span>OUTCLR</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
        <span>_delay_ms</span><span>(</span><span>500</span><span>);</span>
    <span>}</span>
<span>}</span>
</pre>
<p>The code looks very similar to what you would see on a classic AVR "blinky" program. One visible change is the use of structures to access various registers of the MCU: e.g instead of setting bits in <code>PORTB</code>, you access <code>PORTB.DIRSET</code>.</p>

<p>The other visible change is the clock setup code <code>_PROTECTED_WRITE(CLKCTRL.MCLKCTRLB, 0)</code>. Out of the box, at reset, the Attiny406 runs at 3.33Mhz, which corresponds to a base frequency of 20Mhz with a 6x clock divider applied. To enable the full 20Mhz speed, the register <code>CLKCTRL.MCLKCTRLB</code> is cleared. Because this register needs to be protected against accidental changes, the Attiny406 requires a specific programming sequence to modify it. Fortunately, this is natively offered by the macro <code>_PROTECTED_WRITE</code>. More details are available in the <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/ATtiny406-DataSheet-DS40001976B.pdf">Attiny406 datasheet</a>.</p>

<p>In comparison with an STM32 or a SAMD21, the code is blissfully simple. </p>

<h3 id="makefile">Makefile</h3>

<p>We assume the following directory structure where:</p>

<ul>
<li><code>Src/Atmel.ATtiny_DFP.1.6.326/</code> is the location of the Microchip <em>Device Pack</em></li>
<li><code>Src/attiny406-test/</code> is the directory where the code above is stored in a file called <code>main.c</code></li>
</ul>

<p>Compiling the code can be done by issuing the following command within <code>attiny406-test/</code> directory,:</p>
<pre>avr-gcc -mmcu=attiny406 -B ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/ -O3 -I ../Atmel.ATtiny_DFP.1.6.326/include/ -DF_CPU=20000000L -o attiny406-test.elf main.c
</pre>
<p>An <code>-O</code> optimization flag is required to make the <code>_delay_ms()</code> function calls work successfully, as well as defining the variable F_CPU to reflect the expected chip clock speed. The rest of the parameters provide the location of the Attiny406 device-specific files we previously extracted from the <em>Device Pack</em>.</p>

<p>Uploading the firmware to the MCU requires a conversion to the intel HEX format and a call to the <strong>pyupdi</strong> tool. To address all these steps, we created a simple Makefile.</p>
<pre><span>OBJS</span><span>=</span>main.o
<span>ELF</span><span>=</span><span>$(</span>notdir <span>$(</span>CURDIR<span>))</span>.elf  
<span>HEX</span><span>=</span><span>$(</span>notdir <span>$(</span>CURDIR<span>))</span>.hex
<span>F_CPU</span><span>=</span>20000000L


<span>CFLAGS</span><span>=</span><span>-mmcu</span><span>=</span>attiny406 <span>-B</span> ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/ <span>-O3</span>
CFLAGS+<span>=</span><span>-I</span> ../Atmel.ATtiny_DFP.1.6.326/include/ <span>-DF_CPU</span><span>=</span><span>$(</span>F_CPU<span>)</span>
<span>LDFLAGS</span><span>=</span><span>-mmcu</span><span>=</span>attiny406 <span>-B</span> ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/
<span>CC</span><span>=</span>avr-gcc
<span>LD</span><span>=</span>avr-gcc

all:    <span>$(</span>HEX<span>)</span>  

<span>$(</span>ELF<span>)</span>: <span>$(</span>OBJS<span>)</span>
                <span>$(</span>LD<span>)</span> <span>$(</span>LDFLAGS<span>)</span> <span>-o</span> <span>$@</span> <span>$(</span>OBJS<span>)</span> <span>$(</span>LDLIBS<span>)</span>

<span>$(</span>HEX<span>)</span>: <span>$(</span>ELF<span>)</span>
                avr-objcopy <span>-O</span> ihex <span>-R</span> .eeprom <span>$&lt;</span> <span>$@</span>

flash:  <span>$(</span>HEX<span>)</span>
                pyupdi <span>-d</span> tiny406 <span>-c</span> /dev/tty.usbserial-FTF5HUAV <span>-f</span> attiny406-test.hex

read-fuses:
                pyupdi <span>-d</span> tiny406 <span>-c</span> /dev/tty.usbserial-FTF5HUAV <span>-fr</span>

clean:
                <span>rm</span> <span>-rf</span> <span>$(</span>OBJS<span>)</span> <span>$(</span>ELF<span>)</span> <span>$(</span>HEX<span>)</span>
</pre>
<p>To compile the code, we simply type <code>make</code>. Uploading is done with <code>make flash</code>. This Makefile can be further enhanced as needed.</p>

<h2 id="conclusion">Conclusion</h2>

<p>With the right tools, baremetal programming on the new TinyAVR MCUs is as simple as on its older AVR cousins. </p>

<p>If you have programming tips for the AVRTiny, please share them with us on <a href="https://twitter.com/OmzloElec">on Twitter</a> or in the comments below.</p>
</div></section><section><div><h4>Comments</h4><div><div><p>Hi, </p>

<p>It's great that ‚Ä¶</p></div></div></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers">https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers</a></em></p>]]>
            </description>
            <link>https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648397</guid>
            <pubDate>Thu, 01 Oct 2020 07:37:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Start your open-source venture with AsyncAPI at Hacktoberfest]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24648373">thread link</a>) | @derberg
<br/>
October 1, 2020 | https://www.asyncapi.com/blog/hacktoberfest-2020 | <a href="https://web.archive.org/web/*/https://www.asyncapi.com/blog/hacktoberfest-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><img src="https://www.asyncapi.com/img/posts/hacktoberfest.webp" alt="Post cover image"><h2 id="what-is-asyncapi">What is AsyncAPI</h2><p>AsyncAPI is a specification for describing your <a href="https://www.asyncapi.com/docs/getting-started/event-driven-architectures/">event-driven architecture</a>. You are probably using already <a href="https://www.asyncapi.com/docs/getting-started/coming-from-openapi/">OpenAPI/Swagger specification</a> for describing your synchronous RESTful APIs. AsyncAPI is something that supplements OpenAPI. As an example, you should use AsyncAPI when your services do not talk to each other directly but through a message broker.</p><p>In contrast to the OpenAPI Initiative, AsyncAPI Initiative is focused not only on creating and evolving the AsyncAPI specification but also on its tooling. It is a vendor-neutral space for the community to work together on the spec and its tools. We work on tools like specification parsers or docs and code generators.</p><p><iframe src="https://www.youtube.com/embed/pU71J-F7pfI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h2 id="what-is-hacktoberfest-and-why-asyncapi-initiative-joins-it">What Is Hacktoberfest And Why AsyncAPI Initiative Joins It</h2><p><a href="https://hacktoberfest.digitalocean.com/">Hacktoberfest</a> is a well-known event that promotes open source contributions. In short, you have the entire October to submit four pull requests to any project you want, and in exchange, you get a super cool t-shirt. Is that it? Is it just for a t-shirt? Nah, the t-shirt is nice but what you also get is easy access to open source world. Maintainers of many projects open up for contributions, and it is a great chance to make your first step to joining this fantastic world.</p><p>AsyncAPI Initiative joins the Hacktoberfest for two main reasons:</p><ul><li>Promote AsyncAPI Initiative as a place where we don't work on the specification only but also build a lot of great tools</li><li>Make it much easier for the community to make the first contribution to one of the AsyncAPI repositories</li></ul><p>In the past, we were also there where you are now, shy and uncertain if we can impact open source community. We want to give you an easy path to take the first baby steps in the world of open source in a welcoming and friendly environment.</p><blockquote><p>Don't forget to <a href="https://hacktoberfest.digitalocean.com/login">sign up</a> to the Hacktoberfest</p></blockquote><p><iframe src="https://www.youtube.com/embed/_1WRr3Ml9t4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h2 id="how-can-you-help">How Can You Help</h2><p>There is always a lot of work waiting out there. For the sake of this special event, we prepared around 75 GitHub issues that you can pick up. They represent different areas (for example, JavaScript or HTML), different difficulty (for example, 50 issues are easy), and different repositories. No matter if they are trivial or demanding, all of them are important for us. Even with trivial ones where you, for example, need to remove a semicolon, we will still be super happy because this will improve the quality of the project (SonarCloud reports). In other words, every single issue from <a href="https://docs.google.com/spreadsheets/d/1vX4J395apexutfQ0OSqPNltFKDacmemHZwCmOXwHNLo/edit?usp=sharing">this</a> list is important.</p><h3 id="1-pick-the-right-issue">1. Pick The Right Issue</h3><p><a href="https://docs.google.com/spreadsheets/d/1vX4J395apexutfQ0OSqPNltFKDacmemHZwCmOXwHNLo/edit?usp=sharing">Here</a> you can find a list of all the issues that you can work on. Most of the issues are about code contribution, but not all of them. There are also issues about documentation or CI/CD configuration (we use GitHub Actions). Just pick the issues you want to work on, one at a time, and let us know in the comments section that you want to work on it.</p><p><iframe src="https://www.youtube.com/embed/Iqs_2BiNEEo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h3 id="2-setup-your-environment-and-create-a-first-pull-request">2. Setup Your Environment And Create A First Pull Request</h3><p>Once you <a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git">install Git</a> on your machine and get a <a href="https://github.com/join">GitHub account</a>, you need first to decide if you are here just for Hacktoberfest or longer, and make sure if your issue is easy and maybe you can complete it in the GitHub UI. </p><p>In case you are here just for the Hacktoberfest, and you picked easy issues that involve changes only to a single file, there is no need to install Git and complicate your life. GitHub UI enables you to <a href="https://docs.github.com/en/free-pro-team@latest/github/managing-files-in-a-repository/editing-files-in-your-repository">make changes to a single file online</a>.</p><p>In case you:</p><ul><li>want to stay with us longer,</li><li>you picked up an issue where you need to make changes to more than just one file,</li><li>you also need to run the project locally to check if it works</li></ul><p>Then follow <a href="https://github.com/asyncapi/.github/blob/master/git-workflow.md">this</a> short instruction on how to fork the repository and set it up locally.</p><p>Once you are ready with your changes, submit a pull request. Be nice and follow our <a href="https://github.com/asyncapi/.github/blob/master/CODE_OF_CONDUCT.md">code of conduct</a> and make sure your pull request is <a href="https://github.com/asyncapi/.github/blob/master/CONTRIBUTING.md#conventional-commits">described properly</a>.</p><p><iframe src="https://www.youtube.com/embed/BsC5tu4M1rw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><h2 id="office-hours">Office Hours</h2><p>Do you feel overwhelmed? No need. You can do it. Just take this blog post seriously. </p><p>Trust me when I write that every pull request is crucial for us.
Trust me when I write that we are a welcoming community.
Don't be afraid that you will waste our time. If we would think about it this way, we would not even join the Hacktoberfest.</p><p>Still not sure if you can make it? Don't worry. We want to host office hours throughout the event, 2x a week, 1h long, and different time zones. You can join whenever you want and ask us anything, or do pair programming with us. We start with the first meeting on <a href="https://calendar.google.com/calendar/u/0?cid=dGJyYmZxNGRlNWJjbmd0OG9rdmV2NGxzdGtAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ">Tuesday 6th, 8AM UTC</a> and then on the following days:</p><ul><li>Tuesday 6th, 8AM UTC</li><li>Thursday 8th, 4PM UTC</li><li>Tuesday 13th, 8AM UTC</li><li>Thursday 15th, 4PM UTC</li><li>Tuesday 20th, 8AM UTC</li><li>Thursday 22nd, 4PM UTC</li><li>Tuesday 27th, 8AM UTC</li><li>Thursday 29th, 4PM UTC</li></ul><p>You can also join us in a more asynchronous discussion on <a href="https://www.asyncapi.com/slack-invite/">Slack</a>. For updates and latest news, the best is to follow our <a href="https://twitter.com/AsyncAPISpec">Twitter account</a>. </p><h2 id="blooper-reel">Blooper Reel</h2><p>Before you jump to your first contribution, have a look at the making of the videos. It was quite fun.</p><p><iframe src="https://www.youtube.com/embed/anjcF2l0lGs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""></iframe></p><p>Enjoy the Hacktoberfest!</p></article></div>]]>
            </description>
            <link>https://www.asyncapi.com/blog/hacktoberfest-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648373</guid>
            <pubDate>Thu, 01 Oct 2020 07:34:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MobX 6]]>
            </title>
            <description>
<![CDATA[
Score 139 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24648363">thread link</a>) | @nikivi
<br/>
October 1, 2020 | https://michel.codes/blogs/mobx6 | <a href="https://web.archive.org/web/*/https://michel.codes/blogs/mobx6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" role="group"><div><section><center><br><small>September 24, 2020</small></center><div><h2>Five years of MobX</h2>
<p>Time flies, and it has been 5.5 years since the first commit to MobX was made to build <a href="https://www.mendix.com/">Mendix Studio</a>.
In those years MobX has been adopted by well-known Software companies like Microsoft (Outlook), Netflix, Amazon and, my personal favorite, it runs in the Battlefield games by EA.
<a href="https://www.amazon.co.uk/MobX-Quick-Start-Guide-Supercharge/dp/1789344832/ref=sr_1_1?crid=BRUIHPUQL64D&amp;dchild=1&amp;keywords=mobx&amp;qid=1600809874&amp;s=books&amp;sprefix=mobx%2Caps%2C138&amp;sr=1-1">Books</a> and video courses have been written, and so have implementations in other languages.</p>
<p><span>
    <span></span>
    <img alt="Battlefield &amp; MobX" title="" src="https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/128ae/dice.jpg" srcset="https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/08cbc/dice.jpg 160w,
https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/37ac5/dice.jpg 320w,
https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/128ae/dice.jpg 640w,
https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/52793/dice.jpg 800w" sizes="(max-width: 640px) 100vw, 640px">
  </span></p>
<p>Yet, since that first commit the philosophy of the MobX hasn't changed: <em>Anything that can be derived from the application state, should be derived. Automatically.</em>.
The API hasn't changed too much since those days either,
and you will find the original <a href="https://www.mendix.com/blog/making-react-reactive-pursuit-high-performing-easily-maintainable-react-apps/">introduction of MobX</a> still pretty recognizable.
If <code>React.createClass</code> still rings a bell that is.</p>
<p>In contrast, the JavaScript eco-system has changed significantly over the years.
TypeScript and Babel have become the de-facto standards.
React went from <code>createClass</code> to classes to hook-based function components.
Yet, relevant JavaScript proposals for observables, Object.observe and decorators have never materialized.</p>
<p>MobX 6 is a new major version that doesn't bring many new features, but is rather a consolidation of MobX on the current state of affairs in JavaScript.
That doesn't come without a few plot twists, so if you are an existing MobX user, please read till the end!</p>
<h2>Bye bye decorators</h2>
<p>Let's start with the bad news: Using decorators is no longer the norm in MobX.
This is good news to some of you, but others will hate it.
Rightfully so, because I concur that the declarative syntax of decorators is still the best that can be offered.
When MobX started, it was a TypeScript only project, so decorators were available.
Still experimental, but obviously they were going to be standardized soon.
That was my expectation at least (I did mostly Java and C# before).
However, that moment still hasn't come yet, and two decorators proposals have been cancelled in the mean time.
Although they still can be transpiled.</p>
<p>So why did we stop using decorators by default?</p>
<p>First of all, the current experimental decorator implementations are incompatible with the soon-to-be-standardized class-fields proposal.
The legacy (Babel) and experimental (TypeScript) decorator implementations will no longer be able to <a href="https://github.com/tc39/proposal-class-fields/issues/151">trap class fields initializations</a>.</p>
<p>Secondly, using decorators has always been a serious hurdle in adopting and advocating MobX.
In Babel, it is quite fragile to set up.
<code>create-react-app</code> doesn't support it out of the box, and many developers rightfully don't like to use non-standard features.
Even though decorators have always been optional in MobX, the fact that they were prominent in the docs left many confused.
Or as one MobX fan <a href="https://github.com/mobxjs/mobx/issues/2325#issuecomment-693130586">puts it</a>:</p>
<p><em>I am guessing this choice [to drop decorators] was probably a good call. Maybe now without decorators I am hopeful I will be able to convey to people how amazing Mobx is and at least I won't hear the decorators excuse anymore. I have never seen an "@" sign scare so many people.</em></p>
<p>So, what does MobX after decorators look like?
Simply put, instead of decorating class members during the class definition, instance members need to be annotated in the constructor instead, using the new <code>makeObservable</code> utility:</p>
<div data-language="typescript"><pre><code><span>import</span> <span>{</span>observable<span>,</span> computed<span>,</span> action<span>,</span> makeObservable<span>}</span> <span>from</span> <span>"mobx"</span>


<span>class</span> <span>TodoStore</span> <span>{</span>
    @observable
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    @computed
    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    @action
    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span>


<span>class</span> <span>TodoStore</span> <span>{</span>
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
        <span>makeObservable</span><span>(</span><span>this</span><span>,</span> <span>{</span>
            todos<span>:</span> observable<span>,</span>
            unfinishedTodoCount<span>:</span> computed<span>,</span>
            addTodo<span>:</span> action
        <span>}</span><span>)</span>
    <span>}</span>

    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>Admittedly, this is a slightly worse DX than before, since member and annotation are no longer co-located.
But the good news is that using <code>makeObservable</code> doesn't require any fancy build setup.
It should work everywhere out of the box.</p>
<p>Migrating an entire code-base from decorators to <code>makeObservable</code> might be challenging, so that is why we released a <a href="https://www.npmjs.com/package/mobx-undecorate">code-mod</a> together with MobX 6 to do that automatically!
Just run the command <code>npx mobx-undecorate</code> inside the folder where your source files live, and after that all decorators should have been magically rewritten!
After that, make sure to <a href="https://mobx.js.org/migrating-from-4-or-5.html#getting-started">update your TypeScript / babel config</a>, and you should be good to go!</p>
<h2>Introducing <code>makeAutoObservable</code></h2>
<p>We realize it is easier to make mistakes now that the annotations are no longer adjacent to the fields they are decorating.
Hence a convenience utility has been introduced that automates the annotation process by picking sane defaults: <code>makeAutoObservable</code>.
It will automatically pick the best annotation for every member of a class, thereby simplifying the above listing to:</p>
<div data-language="typescript"><pre><code><span>class</span> <span>TodoStore</span> <span>{</span>
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
        <span>makeAutoObservable</span><span>(</span><span>this</span><span>)</span>
    <span>}</span>

    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>Note that it is possible to pass a map of <em>overrides</em> as second argument, in case you want to use a modifier.
For example: <code>makeAutoObservable(this, { todos: observable.shallow })</code>.
Pass <code>member: false</code> to have MobX ignore that member entirely.
(Technical fineprint: class methods will not be decorated with <code>action</code>, but with the new <code>autoAction</code>, this annotation will make methods suitable to be used both as a state updating action, or as function that derives information from state).</p>
<p>What I personally like about <code>makeAutoObservable</code> is that it plays really nice with factory functions.
Which is great if you prefer to not use classes (factory functions make it is easy to hide members and prevent issues with <code>this</code> and <code>new</code>. And they compose more easily).
The same store expressed as factory function will look as follows. Pick the style that suits you:</p>
<div data-language="typescript"><pre><code><span>function</span> <span>createTodoStore</span><span>(</span><span>)</span> <span>{</span>
    <span>const</span> store <span>=</span> <span>makeAutoObservable</span><span>(</span><span>{</span>
        todos<span>:</span> <span>[</span><span>]</span> <span>as</span> Todo<span>[</span><span>]</span><span>,</span>
        <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
            <span>return</span> store<span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
        <span>}</span><span>,</span>
        <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
            store<span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
        <span>}</span>
    <span>}</span><span>)</span>
    <span>return</span> store
<span>}</span></code></pre></div>
<h2>Fresh docs!</h2>
<p>Since decorators are no longer the norm, <a href="https://twitter.com/faassen">Martijn Faassen</a>, <a href="https://twitter.com/zangornjak">≈Ωan Gornjak</a> and yours truly went over all the documentation.
We updated all examples and significantly restructured the docs that have grown quite organically over the years.
We feel the current docs are shorter, have less repetition, and better discuss common scenarios.
Also, we marked all non-essential knowledge in the docs with a {üöÄ} rocket emoji, to make it clear which knowledge is optional.
Hopefully it is much quicker now to find your way around in MobX!</p>
<p>On a similar note, we've updated all <a href="https://mobx.js.org/react-integration.html">React related documentation</a> to use function components instead of class components. And added documentation on how to use MobX with hooks, context and effects.
This knowledge existed before (little has changed technically), but was scattered all over the place.
As a result, we now recommend <code>mobx-react-lite</code> over <code>mobx-react</code> for (greenfield) projects that don't use class components.
As a result the separate mobx-react.js.org/ website has been deprecated.
All credits go to <a href="https://twitter.com/danielk_cz">Daniel K</a> for maintaining those two projects!</p>
<p>And finally, there is now a <a href="https://gum.co/fSocU">one pager MobX 6 cheat sheet üë®‚Äçüéì</a> covering all the import mobx / mobx-react(-lite) API's.
(It is a great way to one-time sponser the project in an invoicable way).</p>
<h2>Improved browser support</h2>
<p>A probably little surprising improvement in MobX 6 is that it supports <em>more</em> JavaScript engines than MobX 5.
MobX 5 required proxy support, making MobX unsuitable for Internet Explorer or React Native (depending on the engine).
For this reason MobX 4 was still actively maintained.
However, MobX 6 replaces both at once.</p>
<p>By default MobX 6 will still require Proxies, but it is possible to opt-out from Proxy usage in case you need to support older engines.
And, as a result, it is now possible for MobX 6 to warn in development mode when features that would require proxies are used.
See the documentation for more <a href="https://mobx.js.org/configuration.html#proxy-support">details</a>.</p>
<div data-language="typescript"><pre><code><span>import</span> <span>{</span> configure <span>}</span> <span>from</span> <span>"mobx"</span>

<span>configure</span><span>(</span><span>{</span>
    
    
    
    useProxies<span>:</span> <span>"never"</span>
<span>}</span><span>)</span></code></pre></div>
<h2>Decorators are back!</h2>
<p>Ok, time for the plot twist. MobX 6 stills supports decorators!
The decorator implementation in MobX 6 is entirely different from the one in earlier versions, but does work with the current implementations in TypeScript and Babel.
It basically provides an alternative way to construct the annotations map for <code>makeObservable</code>, and allows us to rewrite the first example as:</p>
<div data-language="typescript"><pre><code><span>class</span> <span>TodoStore</span> <span>{</span>
    @observable
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
        <span>makeObservable</span><span>(</span><span>this</span><span>)</span>
    <span>}</span>

    @computed
    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    @action
    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>Note that we still need to add a constructor to the class, but this time we omit the second argument to <code>makeObservable</code>, so that it will rely on the decorators instead.
We don't recommend this set up for greenfield projects, after all decorators are still experimental, but this is a great compromise for
existing code bases.
Generating constructors without removing decorators is supported by <code>mobx-undecorate</code> as well, and can be achieved by running <code>npx mobx-undecorate --keepDecorators</code>.</p>
<p>And here is even more good news: There is a fresh <a href="https://github.com/tc39/proposal-decorators">decorators proposal</a> being championed by the tireless hero <a href="https://twitter.com/littledan">Daniel Ehrenberg</a>.
I've been a bit involved in it, and the MobX use case has inspired the proposal.
So the benefits of the fresh decorator implementation are that it a) solves the compatibility issue with the class fields spec discussed above, and
b) it also paves the way ‚Ä¶</p></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://michel.codes/blogs/mobx6">https://michel.codes/blogs/mobx6</a></em></p>]]>
            </description>
            <link>https://michel.codes/blogs/mobx6</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648363</guid>
            <pubDate>Thu, 01 Oct 2020 07:33:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Worst Decision of My Career]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24648256">thread link</a>) | @fribmendes
<br/>
October 1, 2020 | https://subvisual.com/blog/posts/the-worst-decision-of-my-career/ | <a href="https://web.archive.org/web/*/https://subvisual.com/blog/posts/the-worst-decision-of-my-career/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article><section><div><div><div><div><div><div>
<p>This is a reflection on software development and complexity. Let's start with
some quotes to make me look smart:</p>
<blockquote>
<p>A complex system that works is invariably found to have evolved from a simple
system that worked. A complex system designed from scratch never works and
cannot be patched up to make it work. You have to start over with a working
simple system -- <em>Gall's law</em></p>
</blockquote>
<p>I only came across this quote recently, but I think that it summarizes what
I've learned these past seven years. Another idea that I've found in a few books
is that programming in isolation is problem-solving, but software engineering
is all about managing complexity. This distinction between programming and
software engineering makes sense to me, probably because of my mental models.
I'm sure we can all disagree on this, but that's not the topic of today.
Complexity is.</p>
<h2>Complexity</h2>
<p>Almost everyone I know in the software industry wants to build products that
solve real and challenging problems. Change the world! The last thing you want
is to build another CRUD application. They are fine, but it gets boring after
a while.</p>
<p>Most of us will get bored without novelty. That's why the software industry has
a recycling mechanism to keep things fresh and interesting for us: every once
in a while a new, or different, language/framework will rise and light the path
for a brighter future, overthrowing the existing standard, demanding that we
learn it to be on top of the game.</p>
<p>We change our tools, but we keep building the same things over and over. I've
been doing this long enough to see that we are just going in circles. Let's be
honest, most of us aren't building life-changing products that wouldn't have
been possible ten years ago, so let's not jump straight into another shiny
technology that just came out and is going to solve all of our problems.</p>
<h2>Solutions, solutions, solutions</h2>
<blockquote>
<p>For a while, the solution to every problem I encountered was a Rails app. --
<em>this one is mine</em></p>
</blockquote>
<p>Over the years, I've seen companies rewrite their products to change languages,
frameworks, or architectures because they were told that the change would make
their product better, run faster, and scale. By the way, you're only a true
Ruby developer after you've heard the question "but does it scale?" at least
one hundred times (kidding, but it'll happen).</p>
<p>Think about it, how many times were you sold a new programming language,
technology, or a concept like microservices, serverless, event sourcing, clean
architecture, micro frontends. There are many preachers in the software world.</p>
<p>At Subvisual, we started using Elixir a lot these past years, so I've learned
a bit about the history of Erlang. If you don't know, Erlang uses the Actor
Model, and the interesting part is that the designers of Erlang only learned
about the Actor Model after having designed Erlang. This is important because
the designers of Erlang didn't start with the intent of applying the Actor
Model; it came as a solution to fault-tolerant distributed programming.</p>
<blockquote>
<p>If all you have is a hammer, everything looks like a nail <em>Abraham Maslow</em></p>
</blockquote>
<p>The designers of Erlang picked the right tool for the job and most of us want
to do the same. Unfortunately, there's usually more than one "tool" that would
be "right," but to know which ones, you need to know what "job" you're solving.
All of us <strong>should</strong> know this, but I keep learning about teams that fail to do
it. There are so many companies, with a handful of experienced developers, that
don't know what they are building, don't have a clear business yet, but their
product is already built on complex architectures and technologies such as
microservices, Kubernetes or event-sourcing.</p>
<h2>Improving</h2>
<p>Every project we start from scratch is an opportunity to do it right. We'll
think to ourselves: <em>This time I won't fall into the same traps! I have learned
my lessons, I've studied the books, and I even met some of my gurus that wrote
them! This time I'll follow "industry standards"!</em></p>
<p><em>I am the "architect"; I will design the perfect system! Without me, none of
this will be possible. Those mindless programmers have no idea what they are
doing. I, and only I, am the true heir of Martin Fowler!</em></p>
<p>This was a bit dramatic, but I needed a break from all of that whining. I know
it's easy to fall into these traps. It's even easier when your company raised
money, and everyone is expecting you to deliver the absolute best product ever
because they are paying you for it! This is why your starting team is so
important; they have to withstand the pressure. They must know that to build
the grand vision, they have to go one step at a time.</p>
<h2>The decision</h2>
<p>I've made many bad decisions, and I've been fortunate enough to suffer the
consequences of those decisions. A lot of developers don't get to experience
consequences, so they never learn.</p>
<p>So what was the worst decision of my career? I don't know. But the title of
this blog post is inspired by something an old colleague said. At the time, we
were working for a product company that reached for event-driven architecture
and event-sourcing too soon. They knew little about their market, and the
choices the software team made were crippling their ability to change. Business
rules were almost set in stone. Migrating data was a pain and the source of
many bugs. And unfortunately, because the team didn't have experience with
event-sourcing, the event store, which kept the state of all services, was also
being used as an event-bus to communicate between services. Because of that, it
was possible to couple one service to the internal state of another, which
happened a lot. This almost invisible coupling made everything worse.</p>
<p>What did we do against such an unpredictable system? We took it apart: merging
services that were too coupled; defining clear boundaries between services;
moving some services away from the event-store into a traditional database;
making some communication channels synchronous; writing integration and
end-to-end tests.</p>
<p>When we were finished it was still an unnecessarily complex system, but it was
one that we could change with some confidence. After that, we defined
a long-term plan for the product's architecture and technology, but we didn't
implement it. We waited for the right moment when something was starting to
slow us down to make a small step in that direction. When the business goals
changed, we changed our long-term plan, and once again made small steps in that
direction when we felt the need for it.</p>
<p>Eventually, complexity found its way again into the codebase, but it was fine
because the codebase was evolving slowing, adding and removing complexity when
necessary.</p>
<h2>Making the right call</h2>
<p>Was that the worst decision of his career? I don't think so. The issue with him
going for event-sourcing and event-driven architecture was that it wasn't the
right moment, but my colleague didn't know that. He thought the goals for the
next years were well defined, but unfortunately, they never are.</p>
<p>Should you use microservices or event-sourcing? Maybe, it depends on the
context and the client. The decisions I make are the best that I can with the
information that I have. For instance, when I'm part of the team that's
starting a product, the technology we pick will depend on how we'll hire: if
you want to build an office in Portugal, we have to make sure we have
developers for that technology available. We have to think things through, and
some things you only learn from experience. This applies to the systems we
design as well. I've seen enough people design around what they believe the
product will become in two years to know that those designs always fail to
accommodate the changes that will come. So we design systems for small,
incremental changes. Do the smallest thing that will get us started and
doesn't compromise our ability to change once we know what the business needs.</p></div></div></div></div></div></div></section></article></div></div></div>]]>
            </description>
            <link>https://subvisual.com/blog/posts/the-worst-decision-of-my-career/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648256</guid>
            <pubDate>Thu, 01 Oct 2020 07:18:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Before You Start Coding]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24647918">thread link</a>) | @dinomad
<br/>
September 30, 2020 | https://scorpil.com/post/before-you-start-coding/ | <a href="https://web.archive.org/web/*/https://scorpil.com/post/before-you-start-coding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="container"><div><article itemscope="" itemtype="http://schema.org/BlogPosting"><div itemprop="articleBody"><p>Full disclosure: things discussed in this post are, to be frank, quite obvious. My intent is not so much to teach a reader something new, as to remind him what might have been forgotten. After all, anyone who does a single kind of work daily for years inevitably develops habits and mental-shortcuts that are <em>usually</em> useful but can misfire from time to time. After all, software development is too complex and too technical to be guided by subconscious intuition.</p><p>Pilots use pre-flight checks to combat this kind of problem, so why not developers? Here‚Äôs a check-list of things I find important to consider <strong>before</strong> writing the first line of code.</p><h3 id="set-your-target-straight">Set your target straight</h3><p>Imagine yourself solving these tasks:</p><ul><li>generating a single-use report for an established company</li><li>writing a feature in proof-of-concept MVP for a startup</li><li>extending at enterprise product that has 20 years of codebase support guarantee in its SLAs</li></ul><p>Clearly, it wouldn‚Äôt be smart to blindly apply the same set of software development best-practices for all three cases. You probably don‚Äôt need a perfectly polished code for a single-use report. A startup that operates in the ‚Äúrush to market before we run out of money" mode is much more worried about the feature working than about its performance. Long-support code needs to be first and foremost maintainable. Also, if you‚Äôre working on a pet-project for fun, you might gasp skip writing tests (unless you enjoy writing tests, in which case I envy you a little bit). Some developers take so much pride in their craft that they lose sight of the forest behind the trees. Following all best practices and writing state-of-the-art code <em>feels</em> right, but logically it‚Äôs not the only option. Sometimes you should consciously generate technical debt. Reality constraints are not something that can be ignored.</p><p>As self-evident as this advice is, we‚Äôve all heard stories where things went wrong because of misaligned goals. ‚ÄúPremature optimization‚Äù is a common special case. Refactoring an old codebase that rarely changes, just so it‚Äôs pretty, is another one. And to not leave you with the thought that goal misalignment is always linked to perfectionism: writing an unsupportable code to meet a <em>fictional</em> deadline, either self-imposed or forced on to developers by impatient management, is the same kind of error.</p><p>You need to know where to go before you can start thinking about how to get there. Think of the most important criteria your solution needs to fulfill and align your decision-making with those.</p><h3 id="consider-alternatives">Consider alternatives</h3><p>You‚Äôve got the task in front of you, requirements are pretty clear, and you vaguely remember how you did something similar a few years before. Or maybe you don‚Äôt know how to solve it at first, but after some googling, you get a general idea. Start coding?</p><p>There are always multiple ways to solve a problem. The first viable solution is unlikely to be an optimal one. By focusing on the first approach discovered you rob yourself of choice. Do a thorough research first, and after you have options in front of you, carefully consider the pros and cons of each. There is no magical number of solutions you need. I often set the minimum bound to three for myself.</p><p>Selecting the right tool for a job is an obvious example of a decision that benefits from upfront research, and even then, in a real-world scenario, a tool that‚Äôs familiar often gets selected over the tool that fits. Don‚Äôt think this advice only applies to ‚Äûmacro‚Äú decisions, it can be applied just as well for your everyday code design choices.</p><h3 id="consult-the-docs-yes-upfront">Consult the docs. Yes, upfront</h3><p>It‚Äôs impossible to keep up with the pace modern tech is moving. Doesn‚Äôt matter how many years of experience you have under your belt, when you pick up the project on a modern stack there will be tools and libraries, released recently, that have slipped under your radar. So most developers are in a constant in-flight-learning mode: picking up knowledge as they search answers on immediate questions. It‚Äôs an efficient way to learn, but it creates a risk of missing an easy solution because of the inability to form the right question.</p><p>Skimming the docs upfront, without digging deep into any particular topic, doesn‚Äôt take much time, but it helps create mental anchors, which your brain will fetch when you encounter the problem. You will have a better starting point for finding the right answer quickly.</p><h3 id="design-your-apis">Design your APIs</h3><p>The hardest part of writing code is to imagine in the minutest details how to handle each workflow, each exceptional situation, and each edge case. Many developers first solve a problem, then write a ‚Äûwrapper‚Äú to expose their work to the outside world through some kind of API (i don‚Äôt mean just REST API, function signatures and interfaces are APIs as well). Often this bottom-up design leads to an API that‚Äôs too ‚Äûtechnical‚Äú, i.e. leaking it‚Äôs abstractions to the consumer. It‚Äôs hard to make your brain switch from one level of abstraction to another.</p><p>Before starting the work on implementation, put yourself in the shoes of the API user first (even if that user is you). What would be the user‚Äôs most common usage pattern? What‚Äôs the absolute minimal required set of parameters the API needs to have? Which terminology makes sense for the user? What input format would be most convenient? What defaults to set? It‚Äôs up to you how thorough you want this process to be.</p><h3 id="split-up-the-work">Split up the work</h3><p>Each entity in a system exponentially increases the number of possible interactions. Code that‚Äôs easy to reason about forms a pyramid of abstraction layers, each one hiding its inner workings from the layer above. Each layer can be reasoned about independently, limiting the amount of ‚Äûmoving parts‚Äú you need to keep track of in your brain. If you succeed in splitting the task into multiple loosely coupled entities upfront, you will simplify your code and work process.</p><p>If the task at hand is large enough, it might make sense to form a tree-like task structure, starting from the highest level of abstraction and moving down the layers until the tasks are small enough. The ‚Äûsmall enough‚Äú parameter depends on your particular codebase, mindset, and type of work you do, but after a bit of practice, you‚Äôll find what granularity suits you the best.</p><p>Each task should be fairly self-sufficient and ideally shouldn‚Äôt stay in ‚Äúkinda-finished‚Äù state for long (‚Äúfinished but not deployed‚Äù, ‚Äúfinished but not reviewed‚Äù, ‚Äúfinished but not tested‚Äù or ‚Äúfinished but waiting for authorization from XYZ department‚Äù). Finished is when you don‚Äôt think about it anymore and it doesn‚Äôt drain your mental resources.</p><p><img src="https://scorpil.com/img/tree.png" alt="Example of a task tree"></p><p>Do you have your own tips and tricks for organizing developer‚Äôs work? Please share!</p></div></article></div></div></div></div>]]>
            </description>
            <link>https://scorpil.com/post/before-you-start-coding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647918</guid>
            <pubDate>Thu, 01 Oct 2020 06:20:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You're Allowed to Write Slow Rust Code]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24647910">thread link</a>) | @ingve
<br/>
September 30, 2020 | https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/ | <a href="https://web.archive.org/web/*/https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog-post">
    
    
    <article>
        <p>There's a thing that comes up from time to time in the Rust community: people wanting to optimize their code. Make the code run faster. Make it allocate less memory. These are worthy goals, but maybe not necessary for all projects. Just because your program is written in Rust, it doesn't have to be optimized to the moon and back to do it's job. In a lot of cases, you'll be fine using <code>.clone()</code>.</p>
<p>There's a fantastic quote from a discussion on the <a href="https://users.rust-lang.org/">Rust user forums</a> which I always think of when these discussions emerge:</p>
<blockquote>
<p>Just because Rust allows you to write super cool non-allocating zero-copy algorithms safely, doesn't mean every algorithm you write should be super cool, zero-copy and non-allocating.<br>
-- <a href="https://users.rust-lang.org/t/feeling-rust-is-so-difficult/29962/15">trentj on The Rust Programming Language Forum</a></p>
</blockquote>
<p>Of course there's a time and place for <em>super cool no-allocating zero-copy algorithms</em>, but very often it's not the time, nor the place. You can write fantastically effective code with Rust, but <strong>you don't have to</strong>! A lot of the time it's entirely fine to just write code that works with minimal effort. You don't have to spend 4 days trying to figure out how lifetimes work just to avoid calling <code>.clone()</code> a few times.</p>
<p>Don't spend time trying to make micro optimizations now. Take the easy route. You'll probably come back to that piece of code in a few months time, smile, and change that <code>.clone()</code> to something more efficient.</p>
<p>Happy coding!</p>
<p><small>NB: Watch this <a href="https://youtu.be/rAl-9HwD858">video by Jon Gjengset</a> if you want a good, pragmatic walk through of lifetimes in Rust.</small></p>

    </article>
</div></div>]]>
            </description>
            <link>https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647910</guid>
            <pubDate>Thu, 01 Oct 2020 06:19:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designed IOS14 Icons to to fight the screen time, clutter and visual fatigue]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24647737">thread link</a>) | @hren
<br/>
September 30, 2020 | https://hren.io/products/iso14-home-screen-icons-set/ | <a href="https://web.archive.org/web/*/https://hren.io/products/iso14-home-screen-icons-set/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>As IOS14 allows the customization of the home screen with the Shortcuts app, this icon set tries to fight the screen time, clutter and fatigue by minimizing visuals.</p><p>The goal is to also lover the Screen Time by only limited to one screen.</p><p>More icons will be added. For icon requests DM on<!-- --> <a href="https://twitter.com/@darjanhren" target="_blank">Twitter</a>.</p><p><a href="https://gum.co/wIROw" target="_blank">Get Calm Icon Set</a></p></div></div></div>]]>
            </description>
            <link>https://hren.io/products/iso14-home-screen-icons-set/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647737</guid>
            <pubDate>Thu, 01 Oct 2020 05:44:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running GitHub Actions for Certain Commit Messages]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24647722">thread link</a>) | @kiyanwang
<br/>
September 30, 2020 | https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages | <a href="https://web.archive.org/web/*/https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            
                <section>
        
        <p>A quick look at how you can configure your GitHub Actions workflows to only run when a certain phrase is present in the commit message.</p>
                    <small>Published 4 days ago</small>
                            <span>|</span>
                <small>Updated 4 days ago</small>
                                                <p><span>
    Tooling
</span>
 
                                     <span>
    GitHub Actions
</span>
 
                            </p>
                        <article>
            <p>I'm going to be honest with you all for a second. I write a lot of <code>wip</code> commits. These commits are normally small changes that I want to push up to GitHub so that:</p>
<ol>
<li>I don't lose things if anything goes wrong and my backup hasn't picked it up.</li>
<li>If I can't describe the change I have just made.</li>
<li>If I'm demonstrating something to somebody on a pull-request.</li>
</ol>
<p>The problem is, my actions are setup to run on <code>push</code>, so every single <code>wip</code> commit gets run through the CI process, whether it be running tests, linting or formatting.</p>
<p>After doing some research, I found a way of preventing these from running on every single commit.</p>
<pre><code data-lang="yml"><span>jobs:</span>
  <span>format:</span>
    <span>runs-on:</span> <span>ubuntu-latest</span>
    <span>if:</span> <span>"! contains(github.event.head_commit.message, 'wip')"</span>
</code></pre>
<p>Now, whenever I push a <code>wip</code> commit or any commit that contains the word <code>wip</code>, it will be marked as skipped inside of GitHub actions.</p>
<p>You could also flip the logic and perhaps do something like:</p>
<pre><code data-lang="yml"><span>jobs:</span>
  <span>format:</span>
    <span>runs-on:</span> <span>ubuntu-latest</span>
    <span>if:</span> <span>"contains(github.event.head_commit.message, '[build]')"</span>
</code></pre>
<p>Any commit that contains <code>[build]</code> will now trigger these jobs, everything else will be skipped.</p>
<p>You can thank me later! üòâ</p>

        </article>
    </section>
        </div>
    </div></div>]]>
            </description>
            <link>https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647722</guid>
            <pubDate>Thu, 01 Oct 2020 05:41:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prime and battery usage on Linux laptops: sometimes it's not what it seems to be]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24646504">thread link</a>) | @todsacerdoti
<br/>
September 30, 2020 | https://nwildner.com/posts/2020-10-01-nvidia-reverseprime/ | <a href="https://web.archive.org/web/*/https://nwildner.com/posts/2020-10-01-nvidia-reverseprime/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><a href="https://wiki.archlinux.org/index.php/PRIME">PRIME</a> is a technology used to manage hybrid graphics. It was meant to be a resource saver since you can configure it to use only the Integrated GPU, and render offload to the dedicated GPU whenever is needed. But that is not what happened in my real life situation.</p>

<p>I was not happy with the fact that my laptop was draining a lot of battery. Not only while using render offload by running software with <code>prime-run</code> and delegating gpu stuff to my dGPU(Nvidia MX150), but using the iGPU(i915 Intel) to daily stuff(terminal, browser) was also draining a lot of battery. Overheating was also a problem and then, i started to investigate.</p>
<p>Using <code>powertop -t 3</code> shown that Firefox was draining as much as <code>800 mW</code> per process(tab) on the <code>Power Est.</code> column. Meanwhile, <code>i915</code> module was using about <code>150 mW</code> alone. That got me thinking if, using the dedicated GPU to render stuff would get it better, but it didn‚Äôt. Launching Firefox with <code>prime-run</code> reduced a little the power usage per tab (opening the same websites), but the Intel module was still draining almost the same amount of power(<code>145 mW</code>) while the <code>nvidia</code> module was using <code>35mW</code>.</p>
<p>Other thing that bugged me was that my system always started with a lot of RAM already compromissed(<code>900MB</code>) on a simple <code>i3</code> setup. Could be the case where my iGPU was already allocating a lot of that resource to itself?</p>
<p>After that, i‚Äôve decided to try some 3D, and <a href="https://veloren.net/">Veloren</a> was the game i‚Äôve chosen. Those were the metrics captured with my status bar and <code>powertop</code>:</p>
<ul>
<li>
<p>Using <code>i915</code> driver:</p>
<ul>
<li>Driver drain reached <code>400mW</code>.</li>
<li><code>1,9 GB</code> Ram used</li>
<li>Battery expected duration after full charge was <code>1:28</code>.</li>
</ul>
</li>
<li>
<p>Using <code>nvidia</code> driver with <code>prime-run</code>.</p>
<ul>
<li><code>i915</code> driver was still draining <code>200 mW</code> approximately, spiking to <code>400</code> sometimes.</li>
<li><code>nvidia</code> driver was using about <code>50mW</code>, spiking to <code>80</code> once in a while.</li>
<li><code>1,7 GB</code> RAM used</li>
<li>About <code>140MB</code> of GDDR used</li>
<li>Battery expected duration after full charge was <code>1:12</code>.</li>
<li>nvidia temperature reached <code>73¬∫C</code>.</li>
</ul>
</li>
</ul>
<p>I know that this doesn‚Äôt seems to be a fair test, comparing a dGPU with an iGPU while executing a game. The point I was trying to prove was: Using the render offload didn‚Äôt really help on reducing resource consumption at all. On the oposite, it seems that it somehow helped me to have resources wasted by doubling energy consumption due to this binding created between modules with the <a href="https://wiki.archlinux.org/index.php/PRIME#PRIME_render_offload">render offload</a> feature.</p>

<p>I was decided to try a new approach and use <a href="https://wiki.archlinux.org/index.php/NVIDIA_Optimus#Use_NVIDIA_graphics_only">Nvidia graphics only</a>. Setup was pretty straightforward and after rebooting, I‚Äôve launched Firefox with the same sites and <code>Power Est.</code> was about <code>570mW</code> per process. Good news, lets try Veloren again:</p>
<ul>
<li>Using <code>nvidia</code> driver only
<ul>
<li><code>nvidia</code> driver was using about <code>120mW</code>.</li>
<li>Battery expected duration after full charge was <code>1:47</code>.</li>
<li><code>1,3 GB</code> RAM used</li>
<li>About <code>140MB</code> of GDDR used</li>
<li>nvidia temperature reached <code>67¬∫C</code>.</li>
</ul>
</li>
</ul>
<p>That‚Äôs a lot better. I also noticed that my system was using only <code>500MB</code> RAM after a fresh start(a <code>400MB</code> difference).</p>
<p><strong>Lesson learned.</strong> Try things by yourself when it comes to power management.</p>

<p>Other things changed on my system after spending the weekend optimizing energy stuff:</p>
<ul>
<li>Not using <a href="https://github.com/tobi-wan-kenobi/bumblebee-status"><code>bumblebee-status</code></a> anymore. It‚Äôs a great bar, full of useful modules, but it was creating some weird spikes on power usage. Migrated to <a href="https://github.com/greshake/i3status-rust/"><code>i3status-rust</code></a> and now my bar isn‚Äôt even listed on the top 20 power usage agressors.
<ul>
<li>All previous tests were done using the same bar.</li>
</ul>
</li>
<li><code>telegram-desktop</code> is a mess on power and cpu usage and i‚Äôm seriously thinking on ditching this software and using it‚Äôs web version only. Firefox is a software I already use so, there‚Äôs nothing to lose.</li>
<li>Try to get used with some lightweight browser like <a href="https://qutebrowser.org/">qutebrowser</a> while on battery, and stop using my bookmark sync of choice. Have to test since not having video acceleration could be a caveat.</li>
<li>Find out why while using specific softwares <code>pulseaudio</code> gets crazy and it spikes with <code>4W</code> of Power Estimated usage.</li>
</ul>
  </div></div>]]>
            </description>
            <link>https://nwildner.com/posts/2020-10-01-nvidia-reverseprime/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646504</guid>
            <pubDate>Thu, 01 Oct 2020 02:06:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our Voice Assistant Spoke to Google Duplex. Here‚Äôs What Happened]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24646421">thread link</a>) | @xingyzt
<br/>
September 30, 2020 | https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/ | <a href="https://web.archive.org/web/*/https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				<div>
				
													<p><img src="https://www.polyai.com/wp-content/uploads/2019/08/nikola-1-500x500.jpg"></p><div>
							<h6>Nikola Mrk≈°iƒá</h6>
							<p><span>
								23 Sep 2020								- 5 minutes read							</span>
						</p></div>
						
										
				</div>
			</div><div>
									<p>This summer, Google has been deploying its AI voice assistant called Duplex to call bars and restaurants in order to update their opening hours on Google Maps listings.<br>
Here‚Äôs a call their system had with our virtual assistant for restaurants.</p>
<p><iframe src="https://player.vimeo.com/video/460586741" width="640" height="360" frameborder="0" allowfullscreen="allowfullscreen"><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">Ôªø</span><span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start">Ôªø</span></iframe></p>
<p>As far as we‚Äôre aware, this is the <strong>first naturally-occurring conversation between AI voice assistants in the wild</strong>. I have never seen anything like this before, and I‚Äôm incredibly proud that PolyAI is sharing this moment in computing history with our friends from Google.</p>
<p>After listening to the call, we‚Äôd say that it went pretty well! Google could have handled the two-part opening hours a bit better, but overall, the interaction was smooth. I want to share a few thoughts on what this means for the future of conversational technologies.</p>
<h3>Human language is a Universal API</h3>
<p>This interaction did not need to be a conversation in the way that we as humans think of it. The caller‚Äôs request was transactional and to the point. An API call or an HTTPS request between two web services would have done the job in 150ms, instead of two minutes of synthesized voice going back and forth across the telephone line. However, such APIs are not always available, or standardised. For instance, there are dozens of reservation APIs for restaurants used in the UK alone, and voice assistants will never integrate with every single one.</p>
<p>This kind of machine-to-machine conversational communication will become more commonplace as AI deployment accelerates. And while it may seem like an overkill from a technical standpoint, there are good reasons for these kinds of interactions to be conversational, rather than API calls.</p>
<p>Imagine you ask your virtual assistant ‚Äî Siri or Alexa, for example ‚Äî to book a hotel room. It can phone multiple hotels to check availability and book without having to integrate into each hotel‚Äôs individual booking API. And logs of the conversation can inform the user of alternative venues for their next trip.</p>
<h3>Welcome to the Uncanny Valley</h3>
<p>Google introduced <a href="https://ai.googleblog.com/2018/05/duplex-ai-system-for-natural-conversation.html">Duplex in May 2018</a> as an ‚ÄòAI system for accomplishing real-world tasks over the phone‚Äô. You may have seen this video of <a href="https://www.youtube.com/watch?v=D5VN56jQMWM">Sundar Pichai at Google I/O</a> using Duplex to make a restaurant reservation.</p>
<p>I‚Äôll be the first to point out how incredible Google‚Äôs TTS (text-to-speech) is in the Duplex/PolyAI call. It sounds like a human, much more so than our assistant does.</p>
<p>According to the <a href="https://en.wikipedia.org/wiki/Uncanny_valley">Uncanny Valley theory</a>, the more human-like a robot is, the more likely people are to feel positive towards it. However, at a certain point of human-likeness, the robot becomes a bit creepy, and people are repulsed by it.</p>
<p><img src="https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley.png" alt="" width="588" height="387" srcset="https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley.png 588w, https://www.polyai.com/wp-content/uploads/2020/09/uncanny-valley-300x197.png 300w" sizes="(max-width: 588px) 100vw, 588px"></p>
<p>In the Google/PolyAI call, Duplex really does sound like a human ‚Äì it does mention that it‚Äôs an automated service, but this is not enough. Why? Because crossing the Uncanny Valley means that a person on the call will treat the bot as though they are human.</p>
<p>Around the 1 minute mark, you‚Äôll hear our voice assistant ask the caller when they‚Äôd like to come in, and Duplex speaks over it. In reality, these are machines ‚Äì no-one‚Äôs getting offended. But when you listen to the call, the Duplex bot comes across as pretty rude. Because it sounds so human, it‚Äôs practically impossible to not attribute human qualities to the bot. And no one wants a rude voice assistant representing their company.</p>
<p><strong>Making customers think that your voice assistant is a real human is a sure-fire way to deliver frustrating customer experiences. At PolyAI, we work hard to make sure our voice assistants sit at the peak right before the Uncanny Valley ‚Äì but without crossing it. Warm and friendly enough to put callers at ease, but not real enough to cause cognitive dissonance.</strong></p>
<h3>The Future of Voice</h3>
<p>Companies are wising up to the benefits of conversational AI in customer communications, and we‚Äôll see a growing number of instances of machines communicating in human language. While this type of transactional communication may seem better suited to quick API calls, voice assistants can get the job done even when such APIs are not available.</p>
<p>We are super excited about the future of voice assistants. Two highly sophisticated voice assistants have now met in the wild, in a rerun of the legendary ‚ÄúDr Livingstone, I presume‚Äù moment (though neither assistant realised they were speaking to one of their own). This is a sign of great things to come. Stay tuned ‚Äì and get in touch with us if you want to build a great voice assistant for your brand.</p>
<p><strong>What do you think of the PolyAI vs Google Duplex call? Let us know on Twitter, <a href="https://twitter.com/poly_ai">@poly_ai</a>.</strong></p>
							</div></div>]]>
            </description>
            <link>https://www.polyai.com/our-voice-assistant-spoke-to-google-duplex-heres-what-happened/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646421</guid>
            <pubDate>Thu, 01 Oct 2020 01:54:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Grand Design (2010)]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24646120">thread link</a>) | @got-any-grapes
<br/>
September 30, 2020 | https://blas.com/the-grand-design/ | <a href="https://web.archive.org/web/*/https://blas.com/the-grand-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<!-- #masthead -->

	<div id="main">

	<div id="primary">
		<div id="content" role="main">

			
				
	<article id="post-5144">
				<!-- .entry-header -->

				<div>
			
<p>Summary</p>



<ol><li>Traditionally these are questions for philosophy, but philosophy is dead. Philosophy has not kept up with modern developments in science, particularly physics. Scientists have become the bearers of the torch of discovery in our quest for knowledge. The purpose of this book is to give the answers that are suggested by recent discoveries and theoretical advances. They lead us to a new picture of the universe and our place in it that is very different from the traditional one, and different even from the picture we might have painted just a decade or two ago.</li></ol>



<p>Key Takeaways</p>



<ol><li>According to the traditional conception of the universe, objects move on well-defined paths and have definite histories. We can specify their precise position at each moment in time. Although that account is successful enough for everyday purposes, it was found in the 1920s that this ‚Äúclassical‚Äù picture could not account for the seemingly bizarre behavior observed on the atomic and subatomic scales of existence. Instead it was necessary to adopt a different framework, called quantum physics. Quantum theories have turned out to be remarkably accurate at predicting events on those scales, while also reproducing the predictions of the old classical theories when applied to the macroscopic world of daily life. But quantum and classical physics are based on very different conceptions of physical reality.</li><li><strong>We will explain Feynman‚Äôs approach in detail, and employ it to explore the idea that the universe itself has no single history, nor even an independent existence. That seems like a radical idea, even to many physicists. Indeed, like many notions in today‚Äôs science, it appears to violate common sense. But common sense is based upon everyday experience, not upon the universe as it is revealed through the marvels of technologies such as those that allow us to gaze deep into the atom or back to the early universe.</strong></li><li><strong>To deal with such paradoxes we shall adopt an approach that we call model-dependent realism. It is based on the idea that our brains interpret the input from our sensory organs by making a model of the world. When such a model is successful at explaining events, we tend to attribute to it, and to the elements and concepts that constitute it, the quality of reality or absolute truth. But there may be different ways in which one could model the same physical situation, with each employing different fundamental elements and concepts. If two such physical theories or models accurately predict the same events, one cannot be said to be more real than the other; rather, we are free to use whichever model is most convenient.</strong><ol><li><em>Model-dependent realism, mental models</em></li></ol></li><li><strong>M-theory is not a theory in the usual sense. It is a whole family of different theories, each of which is a good description of observations only in some range of physical situations. It is a bit like a map. As is well known, one cannot show the whole of the earth‚Äôs surface on a single map. The usual Mercator projection used for maps of the world makes areas appear larger and larger in the far north and south and doesn‚Äôt cover the North and South Poles. To faithfully map the entire earth, one has to use a collection of maps, each of which covers a limited region. The maps overlap each other, and where they do, they show the same landscape. M-theory is similar. The different theories in the M-theory family may look very different, but they can all be regarded as aspects of the same underlying theory. They are versions of the theory that are applicable only in limited ranges‚Äîfor example, when certain quantities such as energy are small. Like the overlapping maps in a Mercator projection, where the ranges of different versions overlap, they predict the same phenomena. But just as there is no flat map that is a good representation of the earth‚Äôs entire surface, there is no single theory that is a good representation of observations in all situations.</strong><ol><li><em>The Mp is Not the Terrain</em></li></ol></li><li>Today most scientists would say a law of nature is a rule that is based upon an observed regularity and provides predictions that go beyond the immediate situations upon which it is based.<ol><li><em>General and broadly applicable</em></li></ol></li><li>Because it is so impractical to use the underlying physical laws to predict human behavior, we adopt what is called an effective theory. In physics, an effective theory is a framework created to model certain observed phenomena without describing in detail all of the underlying processes.</li><li>There is no picture- or theory-independent concept of reality. Instead we will adopt a view that we will call model-dependent realism: the idea that a physical theory or world picture is a model (generally of a mathematical nature) and a set of rules that connect the elements of the model to observations. This provides a framework with which to interpret modern science.</li><li><strong>We make models in science, but we also make them in everyday life. Model-dependent realism applies not only to scientific models but also to the conscious and subconscious mental models we all create in order to interpret and understand the everyday world. There is no way to remove the observer‚Äîus‚Äîfrom our perception of the world, which is created through our sensory processing and through the way we think and reason. Our perception‚Äîand hence the observations upon which our theories are based‚Äîis not direct, but rather is shaped by a kind of lens, the interpretive structure of our human brains.</strong><ol><li><em>Mental Models, Galilean Relativity</em></li></ol></li><li><strong>A model is a good model if it: Is elegant, Contains few arbitrary or adjustable elements, Agrees with and explains all existing observations, Makes detailed predictions about future observations that can disprove or falsify the model if they are not borne out.</strong></li><li>Another of the main tenets of quantum physics is the uncertainty principle, formulated by Werner Heisenberg in 1926. The uncertainty principle tells us that there are limits to our ability to simultaneously measure certain data, such as the position and velocity of a particle. According to the uncertainty principle, for example, if you multiply the uncertainty in the position of a particle by the uncertainty in its momentum (its mass times its velocity) the result can never be smaller than a certain fixed quantity, called Planck‚Äôs constant. That‚Äôs a tongue-twister, but its gist can be stated simply: The more precisely you measure speed, the less precisely you can measure position, and vice versa.</li><li><strong>In other words, nature does not dictate the outcome of any process or experiment, even in the simplest of situations. Rather, it allows a number of different eventualities, each with a certain likelihood of being realized.</strong></li><li>Given the state of a system at some time, the laws of nature determine the probabilities of various futures and pasts rather than determining the future and past with certainty.</li><li><strong>Quantum physics tells us that no matter how thorough our observation of the present, the (unobserved) past, like the future, is indefinite and exists only as a spectrum of possibilities. The universe, according to quantum physics, has no single past, or history. The fact that the past takes no definite form means that observations you make on a system in the present affect its past.</strong></li><li>Electric and magnetic forces are far stronger than gravity, but we don‚Äôt usually notice them in everyday life because a macroscopic body contains almost equal numbers of positive and negative electrical charges. This means that the electric and magnetic forces between two macroscopic bodies nearly cancel each other out, unlike the gravitational forces, which all add up.</li><li>Maxwell‚Äôs equations dictate that electromagnetic waves travel at a speed of about 300,000 kilometers a second, or about 670 million miles per hour. But to quote a speed means nothing unless you specify a frame of reference relative to which the speed is measured. That‚Äôs not something you usually need to think about in everyday life. When a speed limit sign reads 60 miles per hour, it is understood that your speed is measured relative to the road and not the black hole at the center of the Milky Way. But even in everyday life there are occasions in which you have to take into account reference frames. For example, if you carry a cup of tea up the aisle of a jet plane in flight, you might say your speed is 2 miles per hour. Someone on the ground, however, might say you were moving at 572 miles per hour. Lest you think that one or the other of those observers has a better claim to the truth, keep in mind that because the earth orbits the sun, someone watching you from the surface of that heavenly body would disagree with both and say you are moving at about 18 miles per second, not to mention envying your air-conditioning.<ol><li><em>Galilean Relativity</em></li></ol></li><li>Electromagnetic forces are responsible for all of chemistry and biology.</li><li>The histories that contribute to the Feynman sum don‚Äôt have an independent existence, but depend on what is being measured. We create history by our observation, rather than history creating us. The idea that the universe does not have a unique observer-independent history might seem to conflict with certain facts we know. There might be one history in which the moon is made of Roquefort cheese. But we have observed that the moon is not made of cheese, which is bad news for mice. Hence histories in which the moon is made of cheese do not contribute to the present state of our universe, though they might contribute to others. That might sound like science fiction, but it isn‚Äôt.</li><li>What makes this universe interesting is that although the fundamental ‚Äúphysics‚Äù of this universe is simple, the ‚Äúchemistry‚Äù can be complicated. That is, composite objects exist on different scales. At the smallest scale, the fundamental physics tells us that there are just live and dead squares. On a larger scale, there are gliders, blinkers, and still-life blocks. At a still larger scale there are even more complex objects, such as ‚Ä¶</li></ol></div></article></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blas.com/the-grand-design/">https://blas.com/the-grand-design/</a></em></p>]]>
            </description>
            <link>https://blas.com/the-grand-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646120</guid>
            <pubDate>Thu, 01 Oct 2020 01:08:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Computer Dungeon Slash Postmortem]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24646063">thread link</a>) | @panic
<br/>
September 30, 2020 | https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem | <a href="https://web.archive.org/web/*/https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-article_id="496">


    

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image2.png"></p>


        

    


<p>I consider <a href="https://museumofzzt.com/file/c/CDZ20MOZ.ZIP" target="_blank"><i>Computer Dungeon Slash: ZZT 2.0</i></a> my personal best for ZZT games. I've now released two versions, one in September of 2019 and then another with some updates and optimizations in May of 2020. Aside from a couple of smaller errors and special-thanks additions, there's not much more to fix, so this will probably be the final version with any major changes.</p>

<p>Like some of my previous ZZT games, it relies heavily on procedural generation, with apparently such complexity that Dr. Dos called it "basically sorcery" during their <a href="https://museumofzzt.com/article/479/livestream-computer-dungeon-slash-zzt-20">playthrough on Twitch</a>, which I took as a great compliment. He also mentioned that this game, its generators in particular, could use a write-up. So I wrote one!</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image24.png"></p>

<p>In case you're reading this and unfamiliar with this game, it concerns a player finding themselves in the town of Habeas Corpus, where almost everyone and everything has been swallowed by the dungeon.</p>

<p>The player's task is to brave the randomly-generated dungeon, rescuing the town and townspeople from its clutches.</p>

<p>There's not much more plot or lore than the above, since I focused mainly on characterization in my worldbuilding and most of the actual plot isn't revealed until the end.</p>

<p>So what about the workings of this game?</p>

<p>I'll start with "sorcery"--there's something to that, for sure. When I work with procedural generation it feels a bit like alchemy. Scientific, but also a little bit mysterious and magical. I hope this article helps you better understand the scientific side of that coin.</p>

<p>For readers not intimately familiar with ZZT, one reason a veteran ZZTer would call my level generation "sorcery"  is its limitations. ZZT is a 1991 DOS game-creation-system, after all, simple enough for 8-year-old me to use. So if you don't know anything about ZZT coming in, I hope this write-up helps you better understand the absurdity and appeal of working in it and pushing its limits.</p>

<p>Further, if you came into this wanting to know how this stuff works so that you can experiment with it or even improve on it, I want you to be empowered to do so.</p>

<h2>Goals</h2>

<p>With <i>Computer Dungeon Slash: ZZT</i> (called <i>CDZ</i> here for short) I had three goals for generation. I wanted levels to be interesting to look at, fun to play, and fair. What does fair mean?</p>

<p>Most previous ZZT releases with procedural generation would probably not soft-lock players (block them off from finishing the game). In the early 2000s when this fad hit, most ZZTers involved were in high school and "probably not" was enough. But that small chance of soft-locking players with my generators annoyed me even then.</p>

<p>With <i>CDZ</i>, I wanted some certainty that my algorithms absolutely would not soft-lock players.</p>

<p>With these goals in mind, let's look at the tools I had to accomplish them.</p>

<h2>Building Blocks for Procedural Level Generation in ZZT</h2>

<p>ZZT is tile-based, so making it create its own levels is kind of like generating dungeons for classic ASCII roguelikes, except with much more restrictive tools and limits than, for example, C++ or Python. There's no way to easily store level layout data outside of "in the level", and ZZT boasts precious few variables and only ten true-or-false flags. In addition, the entire game is made up of "boards" of only 60x25 tiles! Despite being such a limited system, ZZT lets us do a fair amount.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image4.png">
<img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image7.gif"></p>

<p>Almost any element (terrain or other object) that takes up a space on a board is helpful, but a few basic ones are laid out in a reference image on the left. Fake walls prove pretty invaluable because they don't block objects but help the engine easily keep track of where another terrain type <i>will</i> later appear.</p>

<p>While <i>CDZ</i> uses sliders and boulders to some extent, the classic examples of ZZT level generators using sliders and boulders are probably WiL's <i>Run-On</i> and Benco's <i>Lost</i>.</p>

<p>And of course, one of the elements of play is actually <i>called</i> an object, and can run little scripts in ZZT-OOP, the engine's default "language." ZZT-OOP has a number of helpful commands for procedural generation.</p>

<p>The <code>#change</code> command can change almost any ZZT gameplay element into almost any other, which is invaluable both for structuring and theming levels. <code>#put THING DIRECTION</code> and <code>#become THING</code> allow for level builder objects to modify environments directly, and they have a more complex use we'll go into later.</p>

<p>Procedural level generation in <i>CDZ</i> is random. Appropriately, ZZT-OOP's random directions proved immensely useful in making it happen. A number of situations call for a "four-sided" dice-roll, and ZZT does have an <i>rnd</i> direction (randomly north, south, east, or west), but as the reader may know, <i>rnd</i> is twice as likely to give an east-west result as a north-south. So what to do?</p>

<p>Well, there are also <i>rndne</i> (north or east) and <i>rndp DIRECTION</i> (one of two directions perpendicular to <i>DIRECTION</i>). Because <i>rndne</i> is a valid direction in itself, you can use <i>rndp rndne</i> to get a random cardinal direction with equal probability of each. (I'm ashamed that I didn't realize that one until reading Anna Anthropy's <i>ZZT</i> a few years back.)</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image14.gif"></p>

<p>In ZZT, <code>#if blocked DIRECTION</code> tells an object whether it is blocked in a given direction. And <code>#send OBJECTNAME:LABEL</code> tells another object, <i>OBJECTNAME</i>, to immediately begin executing code starting with <i>:LABEL</i>.</p>

<p>Slime enemies move erratically and leave breakable walls behind, so you can change their color frequently to fill empty spaces with different colors of breakable walls.</p>

<p>One last limitation and one last "coding" trick deserves mention. ZZT has a limit of about 20 kilobytes per board (including code) before the board misbehaves or gets corrupted at runtime. Objects can use the command <code>#bind OBJECTNAME</code> to work from the same exact instance of the same code as the other object <i>OBJECTNAME</i>, saving valuable code space.</p>

<p>Nowadays, one can "pre-bind" objects with external editors, causing them to share identical labels and behaviors but eliminating the need for the 5+ bytes of space that a <code>#bind</code> command needs.</p>

<h2>Two Big Insights</h2>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image18.png">
<img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image20.png"></p>

<p>In addition to the more concrete "tools" above, two big conceptual insights greatly impacted this project. The first is about level connectedness, and it hit me after reading Rabbitboots's musings on house generation in <a href="https://museumofzzt.com/file/d/dood2018.zip" target="_blank"><i>Doodads 2018</i></a>.</p>

<p>Say I have a house with four rooms, and I block off only one doorway in the house, as on the left. Any room in the house can still visit any other.</p>

<p>Rabbitboots goes on to note that if we make a larger house out of smaller ones, the large house remains fully connected.</p>

<p>If House A connects to House B and B connects to House C, then A connects to C.</p>

<p>This was huge for me. It gave me hope that I could avoid soft-locks while also making more interesting, varied levels.</p>

<p>Shortly after the 2019 release, while looking at TriphEd's maze generation in <a href="https://museumofzzt.com/file/b/BACKTRAX.zip" target="_blank"><i>Backtrax</i></a>, I had another "Aha!" moment.</p>


<p>The algorithm is best explained step-by-step, and you can follow along with the following roughly equivalent method if you have a pencil and paper.</p>

<p>(1) Start with a grid of dots. Any size 3 x 3 or up will do.</p>

<p>(2) Connect all the outer dots along the edge so that they make a rectangle.</p>

<p>(3) For each "middle dot" within the square, draw <i>exactly one line</i> from that dot to any dot directly above, below, left, or right of it. Edge dots can receive lines.</p>

<p>If you used a 3 x 3 grid of dots, the end result will resemble the 2 x 2 house above.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/backtrax-levels.gif"></p>

<p>Any edge tile can access any other edge tile in this algorithm. It can leave some squares inaccessible from the edges, but this is acceptable if nothing essential to player progress is placed in those tiles.</p>

<p>In ZZT, you can accomplish this by having objects use <code>#put rndp rndne ELEMENT</code> on a grid, and that's exactly what <i>Backtrax</i> is doing.</p>

<p>A <i>very</i> small set of soft-lock possibilities does exist in <i>Backtrax</i>. Because there's a blocking linewall diagonally southeast of the lower-right-hand wall generator object, the wrong combinations of walls <i>could</i> block the player, but it is <i>incredibly</i> unlikely and easily remedied.</p>

<p>This is the most elegant level generator in ZZT to date--and also, in case it wasn't already elegant enough, it weighs in at only 10.9 kilobytes and re-uses its "grid" after you reach the exit, using a separate trick (that I won't discuss in detail here) to teleport the player back to the start for a new level.</p>

<p>Recognize TriphEd's genius.</p>

<p>After the initial <i>CDZ</i> release, I experimented a lot with this algorithm. Several generators in version 2.0 benefited from its use. We can now move slowly but surely into the actual inner workings of this game.</p>

<h2>Primary Generators</h2>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image6.png"></p>

<p><i>Computer Dungeon Slash</i> level generators have a "primary generator" object that handles a lot of needed dice-rolls and uses <code>#send</code> to communicate its randomization to different groups of objects. It's usually set up as on the left, or similar.</p>

<p>This particular setup involves fake walls placed north, south, east, and west of the primary generator and water (a blocking terrain) in the four corners. To make a four-direction roll, it uses <code>#put rndp rndne gem</code> and then iterates over some variation of:</p>

<code>#if blocked n #send object:option1
#if blocked e #send object:option2
#if blocked s #send object:option3
#if blocked w #send object:option4</code>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image16.png"></p>

<p>The objects referred to in the <code>#send object:option</code> commands  are pre-bound objects with exactly the same code, and positioned so that only one of them will place a wall, generate an important key, etc. at the time they're called. In this example, the pre-bound group of objects has this code:</p><p>

<code>@object
#cycle 1
#end
:option1
#if blocked n become solid
#die
:option2
#if blocked e become solid
#die
:option3
#if blocked s become solid
#die
:option4
#if blocked w become solid
#die</code></p><p>There is a fake wall in the middle of the house, so that only one object becomes a wall, and the rest die. Then the primary generator turns the fake into a solid wall.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image23.gif"></p>

<p>This method also extends to larger houses similar to those in the <i>Doodads 2018</i> example, and can ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem">https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem</a></em></p>]]>
            </description>
            <link>https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646063</guid>
            <pubDate>Thu, 01 Oct 2020 00:59:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ontario doctors sign letter to Premier advising against sweeping lockdowns]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 175 (<a href="https://news.ycombinator.com/item?id=24645821">thread link</a>) | @mrfusion
<br/>
September 30, 2020 | https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html | <a href="https://web.archive.org/web/*/https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>



<div>
    
        <p>Published Sept. 30, 2020 9:40 a.m. ET</p>
        <p>Updated  Sept. 30, 2020 7:26 p.m. ET</p>
    
</div>



  


    
        
        
    
    
    <amp-iframe resizable="" width="16" height="17" layout="responsive" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation" allowfullscreen="" frameborder="0" src="https://ampvideo.ctvnews.ca/content/ctvnews/en/local/ottawa/2020/9/30/1_5126193.vidi.root-responsivegrid-vidicomponent.html?preventDefault=true">
        
        <p>Click to Expand</p>
    </amp-iframe>





    <p>OTTAWA -- 	Twenty-one Ontario doctors have signed a joint letter to Premier Doug Ford, urging him not to issue a new lockdown this fall because of rising COVID-19 case numbers.</p><p>	Daily numbers of new cases have risen dramatically in recent days, with Ontario recording <a href="https://toronto.ctvnews.ca/new-covid-19-cases-in-ontario-reach-highest-mark-ever-1.5122863" target="_blank">700 new cases of COVID-19 on Monday</a> ‚Äì the highest number of new cases recorded in a single day.</p><p>	However, the 21 doctors who signed the letter to the premier say another provincewide lockdown‚Äîsimilar to what was in place in the spring‚Äîwould not be helpful.</p><ul>	<li>		<a href="#Full letter"><i>Read the full letter below</i></a></li></ul><p>	"We are writing this letter in support of the governments‚Äô plan to use a tactical localized approach, rather than sweeping new lockdown measures, to deal with the increasing COVID case numbers in Ontario," the letter says.&nbsp;</p><p>	"Lockdowns have been shown not to eliminate the virus. While they slow the spread of the virus, this only lasts as long as the lockdown lasts. This creates a situation where there is no way to end the lockdown, and society cannot move forward in vitally important ways including in the health sector, the economy and other critically important instrumental goods including education, recreation, and healthy human social interactions."</p><p>	Speaking on Newstalk 580 CFRA's "The Morning Rush with Bill Carroll" in Ottawa, CTV's infectious disease specialist Dr. Neil Rau‚Äîa signatory of the letter‚Äîpointed to two data points to consider when looking at the spread of COVID-19.</p><p>	"We're reacting to increased aggregate case numbers, but the percentage positive is not really as bad as it used to be," he said. "We're testing more people, so we're finding more cases [‚Ä¶] We're driving our numbers up, it's worse than it was in the summer, but it's not what it was last winter and life has to go on."</p><ul>	<li>		<a href="https://www.iheartradio.ca/580-cfra/podcasts/the-morning-rush-dr-neil-rau-interview-why-we-don-t-want-another-lockdown-1.13612912?mode=Article" target="_blank"><strong>LISTEN NOW: "The Morning Rush": Dr. Neil Rau - Why we don't want another lockdown</strong></a></li></ul><p>	Monday's 700 cases in Ontario came from 41,111 total tests, for a positive percentage rate of 1.7 per cent. On April 24, <a href="https://toronto.ctvnews.ca/highest-number-of-new-covid-19-cases-in-a-single-day-reported-by-ontario-health-officials-1.4910216" target="_blank">the previous watermark of 640 new cases in a single day</a>, the result came from 12,295 tests, for a positive percentage rate of 5.2 per cent.</p><p>	Testing capacity was lower in the spring than it is now, and testing criteria has changed over time; however, Dr. Rau and the other signatories of the letter said the increasing case numbers are not leading to unmanageable levels of hospitalizations.</p><p>	"In Ontario and other parts of the world, such as the European Union, increasing case loads are not necessarily translating into unmanageable levels of hospitalizations and ICU admissions," the letter says.</p><p>	The letter also points to other health impacts linked to the lockdown.</p><p>	"Hard data now exist showing the significant negative health effects shutting down society has caused. Overdoses have risen 40% in some jurisdictions. Extensive morbidity has been experienced by those whose surgery has been cancelled, and the ramifications for cancer patients whose diagnostic testing was delayed has yet to be determined," the letter states.</p><p>	"Economic harms are health harms," Dr. Rau told CFRA. "It sounds horrible to say, but it's true. Health is wealth. We all know this."</p><h2>	<strong>LETTER POINTS TO DISAGREEMENT AMONG HEALTH PROFESSIONALS</strong></h2><p>	Other Ontario health professionals have been arguing for increased restrictions as cases rise.</p><p>	Last week, the Ontario Hospital Association released a letter signed by 38 health professionals which <a href="https://ottawa.ctvnews.ca/ontario-hospital-association-calls-for-return-to-restrictions-on-non-essential-businesses-1.5119832" target="_blank">called for immediate restrictions to be re-imposed on non-essential businesses</a>, such as gyms, dine-in restaurants and bars, nightclubs, and theatres. It also calls on restrictions on other places where people can gather, such as places of worship.</p><p>	The letter from the OHA said regions where the speed of transmission was underestimated are ‚Äúnow facing the consequence of increased hospitalization rates, including a rise in intensive care unit (ICU) admissions and more deaths.‚Äù</p><p>	Hospitalizations in Ontario have been increasing, but have not yet reached the same level that was seen in the spring.</p><p>	According to <a href="https://covid-19.ontario.ca/data" target="_blank">data from the Ontario government</a>, there were 128 people in hospital in Ontario with COVID-19 complications on Monday‚Äîthe day 700 new cases were recorded‚Äîup from 65 a week before; however, on April 24‚Äîwhen 640 new cases were recorded‚Äîgovernment data shows that there were 910 people in hospital. The peak for hospitalizations in Ontario came in May, when there were days when more than 1,000 people were hospitalized. That number steadily decreased from May through the summer before it began going up again in September.</p><p>	Speaking on CTV Morning Live Ottawa, infectious disease specialist Dr. Abdu Sharkawy suggested t<a href="https://ottawa.ctvnews.ca/video?clipId=2045684" target="_blank">emporary restrictions on gathering would help curb the spread of COVID-19</a>.&nbsp;</p><p>	"We don't want to see our hospitals overwhelmed," he said. "We're still waiting for flu season and a whole bunch of other respiratory viruses to hit us and our capacity to be challenged. We don't want that to happen. We need everybody to try and simplify their lives and minimize anything that's non-essential."</p><p>	Dr. Sharkawy said regions where cases are rapidly rising may need to impose new restrictions to get the spread of the virus under control.</p><p>	"I think it's abundantly clear that, particularly in hot spots like Ottawa, Toronto and Peel region, the situation is not well controlled," he said. "Sometimes you need blunt instruments, even if they're temporary in nature, to make sure that you curtail the spread of this virus because it gets away from us a lot more quickly than many of us can anticipate sometimes."</p><p>	Dr. Sharkawy suggested hot spots follow the lead of Quebec, which imposed <a href="https://montreal.ctvnews.ca/life-in-the-red-zone-here-s-what-you-can-and-can-t-do-1.5125093" target="_blank">harsh restrictions on three areas in the province</a>, including Montreal and Quebec City, banning private gatherings and closing bars and restaurant dining rooms.</p><p>	"I think we should do it now," Dr. Sharkawy said of Ontario. "I think we all need to adopt an attitude and an approach that recognizes that we have to do what's absolutely necessary to keep everybody safe."</p><h2>	<strong>FULL LETTER FROM ONTARIO DOCTORS TO THE PREMIER</strong></h2><p>	Dear Premier Ford,</p><p>	We are writing this letter in support of the governments‚Äô plan to use a tactical localized approach, rather than sweeping new lockdown measures, to deal with the increasing COVID case numbers in Ontario. Lockdowns have been shown not to eliminate the virus. While they slow the spread of the virus, this only lasts as long as the lockdown lasts. This creates a situation where there is no way to end the lockdown, and society cannot move forward in vitally important ways including in the health sector, the economy and other critically important instrumental goods including education, recreation, and healthy human social interactions.</p><p>	In Ontario the increase in cases at this time are in people under 60 years of age who are unlikely to become very ill. At the peak of the pandemic in Ontario in mid-April, 56% of cases were in ‚â•60 year olds, now in Sept only 14% of cases are in ‚â•60 year olds. In Ontario and other parts of the world, such as the European Union, increasing case loads are not necessarily translating into unmanageable levels of hospitalizations and ICU admissions. This is not a result of a lag in reporting of severe and fatal cases. While we understand the concerns that these cases could spill into vulnerable communities, we also need to balance the actual risk. As the virus circulates at manageable levels within the community, we need to continue the gains we have made in the protection of the vulnerable in long-term care and retirement institutions, and continue to educate other people about their individual risk, so that they can observe appropriate protective measures.</p><p>	Lockdowns have costs that have, to this point, not been included in the consideration of further measures. A full accounting of the implications on health and well-being must be included in the models, and be brought forward for public debate. Hard data now exist showing the significant negative health effects shutting down society has caused. Overdoses have risen 40% in some jurisdictions. Extensive morbidity has been experienced by those whose surgery has been cancelled, and the ramifications for cancer patients whose diagnostic testing was delayed has yet to be determined. A huge concern is the implication of closure of schools, and the ongoing reluctance we have seen in the large urban centers of sending children back to the classroom due to safety concerns. Global data clearly now show that children have an extremely low risk of serious illness, but they are disproportionately harmed by precautions. Children‚Äôs rights to societal care, mental health support and education must be protected. This cannot be achieved with ongoing or rotating lockdown.</p><p>	The invitation and involvement of other health experts to advise the government‚Äôs response beside individuals in Public Health and Infectious Diseases in addition to leaders in the business, securities and arts communities is essential. We also call for increased open debate, in the public forum, that hears voices from outside the medical and public health communities, in order to consider all points of view from society. This is a fundamental principle upon which democratic societies are built. All stakeholders should have an equal right to participation in public discourse when it comes to setting such fundamental and sweeping societal interventions.</p><p>	All have the right to feel their voices have been heard, and moreover to ensure factual credible data is openly debated, in contrast to the personal and political slants that have had apparent significant impacts on the management of the virus to date. Our society has borne enormous pain over the past 6 months. It‚Äôs time to do something different.</p><p>	Sincerely,</p><p>	Jane Batt MD, PhD, FRCPC. Respirologist, Associate Professor, Department of ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html">https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html</a></em></p>]]>
            </description>
            <link>https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24645821</guid>
            <pubDate>Thu, 01 Oct 2020 00:23:56 GMT</pubDate>
        </item>
    </channel>
</rss>
