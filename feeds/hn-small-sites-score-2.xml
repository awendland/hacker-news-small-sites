<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 10 Sep 2020 12:29:54 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 10 Sep 2020 12:29:54 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Deep Diamond (Deep Learning in Clojure Is Fast, Simpler Than Keras)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24406978">thread link</a>) | @tosh
<br/>
September 8, 2020 | https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-is-Fast-and-Simpler-than-Keras | <a href="https://web.archive.org/web/*/https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-is-Fast-and-Simpler-than-Keras">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
You can <a href="https://www.patreon.com/posts/22476035">adopt a pet function!</a>
Support my work <a href="https://patreon.com/draganrocks">on my Patreon page</a>, and access my <a href="https://www.patreon.com/posts/im-ditching-and-22476348">dedicated discussion server</a>. Can't afford to <a href="https://patreon.com/draganrocks">donate</a>? Ask for a free invite.
<p>September 5, 2020</p>
<p>
    Please share: .
</p>

<p>
    <a href="https://aiprobook.com/">New books are available for subscription.</a>
    </p><p><a href="https://aiprobook.com/deep-learning-for-programmers">
            <img src="http://aiprobook.com/img/dlfp-cover.png">
        </a>
        <a href="https://aiprobook.com/numerical-linear-algebra-for-programmers">
            <img src="http://aiprobook.com/img/lafp-cover.png">
        </a>
    </p>


<p>
through the direct equivalent of a fine Convolutional network example in Keras.
</p>

<p>
Good News: <a href="https://github.com/uncomplicate/deep-diamond">Deep Diamond</a>() preview release is in Clojars, and is already quite useful! And fast!
It is yet to be fully polished, but you can try it now and, I hope, you'll like it.
</p>

<p>
It now covers the functionality that is being explained from scratch in the <a href="http://aiprobook.com/">books that I'm writing</a>.
Convolutions work, too; at the speed of Road Runner!
</p>

<p>
In accordance with my philosophy, "less talk, more walk", I introduce Deep Diamond
through the direct equivalent of this fine <a href="https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py">MNIST CNN example in Keras</a>.
</p>

<div id="outline-container-org54ea652">
<h2 id="org54ea652">Specify the network blueprint</h2>
<div id="text-org54ea652">
<p>
We specify the network by plain Clojure vectors and functions, and create the blueprint.
No need for special compilers and whatnot. The structure of internal parts would be
picked up automatically, or we can specify these explicitly.
</p>

<div>
<pre><span>(</span><span>def</span> <span>net-spec</span> <span>[</span><span>(</span>convo <span>[</span>32<span>]</span> <span>[</span>3 3<span>]</span> <span>:relu</span><span>)</span>
               <span>(</span>convo <span>[</span>64<span>]</span> <span>[</span>3 3<span>]</span> <span>:relu</span><span>)</span>
               <span>(</span>pooling <span>[</span>2 2<span>]</span> <span>:max</span><span>)</span>
               <span>(</span>dropout<span>)</span>
               <span>(</span>dense <span>[</span>128<span>]</span> <span>:relu</span><span>)</span>
               <span>(</span>dropout<span>)</span>
               <span>(</span>dense <span>[</span>10<span>]</span> <span>:softmax</span><span>)</span><span>]</span><span>)</span>

<span>(</span><span>defonce</span> <span>net-bp</span>
  <span>(</span>network <span>(</span>desc <span>[</span>128 1 28 28<span>]</span> <span>:float</span> <span>:nchw</span><span>)</span>
           net-spec<span>)</span><span>)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-orgb8d8bce">
<h2 id="orgb8d8bce">Create the network</h2>
<div id="text-orgb8d8bce">
<p>
The blueprint is a Clojure function that can instantiate the network
object that holds the parameter tensors that the network should learn by using
one of the built-in optimization algorithms. In this case, I'll use adaptive moments,
<code>:adam</code>. Xavier initialization is, again, a plain function that initializes
the network with appropriate weights.
</p>

<div>
<pre><span>(</span><span>defonce</span> <span>net</span> <span>(</span>init! <span>(</span>net-bp <span>:adam</span><span>)</span><span>)</span><span>)</span>
</pre>
</div>

<p>
That's it! The network is ready to learn.
</p>
</div>
</div>

<div id="outline-container-orgae4dec0">
<h2 id="orgae4dec0">Train the network on MNIST data (CPU)</h2>
<div id="text-orgae4dec0">
<p>
The original MNIST data is distributed through four binary files that
you can download <a href="http://yann.lecun.com/exdb/mnist/">here</a>. To demonstrate how nice Clojure is, I'm not
using any special MNIST-specific code that is magically imported
from the framework's model Zoo. The complete code, from scratch, is at the
end of the article (I'm just pushing it there so it doesn't steal the spotlight :).
</p>

<div>
<pre><span>(</span>time <span>(</span>train net train-images y-train <span>:crossentropy</span> 12 <span>[]</span><span>)</span><span>)</span>
</pre>
</div>

<p>
The network learns in mini-batches of 128 images of the total of 60000,
with adaptive moments, through 12 full epochs. That makes 5625 forward/backward
update cycles.
</p>

<p>
The total time for that on my old 2013. i7-4790k CPU is: <b>368</b> seconds.
<b>6 minutes for 6000 cycles. A thousand cycles per minute.</b>
</p>

<p>
Isn't that a lot? You should try and run this in Keras with TensorFlow, and
see that we got a pretty nice performance! (I'll publish some comparisons soon,
and in the meantime you can try for yourself!).
</p>
</div>
</div>

<div id="outline-container-org7c0813e">
<h2 id="org7c0813e">Has it learned anything?</h2>
<div id="text-org7c0813e">
<p>
See the metrics:
</p>

<div>
<pre><span>(</span><span>-&gt;&gt;</span> <span>(</span>infer net test-images<span>)</span>
     <span>(</span>dec-categories<span>)</span>
     <span>(</span>classification-metrics test-labels-float<span>)</span>
     <span>:metrics</span><span>)</span>
</pre>
</div>

<pre>{:accuracy 0.9919,
 :f1 0.9918743606319073,
 :ba 0.9954941141884774,
 :sensitivity 0.9918944358825683,
 :specificity 0.9990937924943865,
 :precision 0.9918542861938476,
 :fall-out 9.062075056135655E-4}
</pre>

<p>
Accuracy is 99.2% which is in the ballpark of what the Keras example gives.
</p>
</div>
</div>


<div id="outline-container-org78cec4a">
<h2 id="org78cec4a">GPU</h2>
<div id="text-org78cec4a">
<p>
Want to go faster? No problem, Deep Diamond supports GPU, in the same process,
at the same time, with the same code!
</p>

<div>
<pre><span>(</span><span>defonce</span> <span>gpu</span> <span>(</span>cudnn-factory<span>)</span><span>)</span>

<span>(</span><span>def</span> <span>gpu-net-bp</span> <span>(</span>network gpu
                         <span>(</span>desc <span>[</span>128 1 28 28<span>]</span> <span>:float</span> <span>:nchw</span><span>)</span>
                         net-spec<span>)</span><span>)</span>

<span>(</span><span>defonce</span> <span>gpu-net</span> <span>(</span>init! <span>(</span>gpu-net-bp <span>:adam</span><span>)</span><span>)</span><span>)</span>

<span>(</span><span>def</span> <span>gpu-x-train</span>
  <span>(</span>transfer! train-images <span>(</span>tensor gpu <span>[</span>60000 1 28 28<span>]</span> <span>:float</span> <span>:nchw</span><span>)</span><span>)</span><span>)</span>

<span>(</span><span>def</span> <span>gpu-y-train</span>
 <span>(</span>transfer! y-train <span>(</span>tensor gpu <span>[</span>60000 10<span>]</span> <span>:float</span> <span>:nc</span><span>)</span><span>)</span><span>)</span>

<span>(</span>time <span>(</span>train gpu-net gpu-x-train gpu-y-train <span>:crossentropy</span> 12 <span>[]</span><span>)</span><span>)</span>
</pre>
</div>

<p>
Elapsed time? <b>20 seconds</b> on my Nvidia GTX 1080Ti (which is a few generations old)!
</p>
</div>
</div>

<div id="outline-container-org2c2d651">
<h2 id="org2c2d651">The books</h2>
<div id="text-org2c2d651">
<p>
Should I mention that the book <a href="https://aiprobook.com/deep-learning-for-programmers/">Deep Learning for Programmers: An Interactive Tutorial with
CUDA, OpenCL, DNNL, Java, and Clojure</a> teaches the nuts and bolts of neural networks and deep learning
by showing you how Deep Diamond is built, <b>from scratch</b>? In interactive sessions. Each line of code
can be executed and the results inspected in the plain Clojure REPL. The best way to master something is to build
it yourself!
</p>

<p>
It' simple. But fast and powerful!
</p>

<p>
Please subscribe, read the drafts, get the full book soon, and support my work on this free open source library.
</p>
</div>
</div>

<div id="outline-container-orga8b021d">
<h2 id="orga8b021d">Appendix: Reading, encoding, and decoding data</h2>
<div id="text-orga8b021d">
<p>
The code that reads the raw image data and converts it to proper tensors
should go up in the sequence of execution, but is not that interesting.
</p>

<div>
<pre><span>(</span><span>defonce</span> <span>train-images-file</span> <span>(</span>random-access <span>"data/mnist/train-images.idx3-ubyte"</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>train-labels-file</span> <span>(</span>random-access <span>"data/mnist/train-labels.idx1-ubyte"</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-images-file</span> <span>(</span>random-access <span>"data/mnist/t10k-images.idx3-ubyte"</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-labels-file</span> <span>(</span>random-access <span>"data/mnist/t10k-labels.idx1-ubyte"</span><span>)</span><span>)</span>

<span>(</span><span>defonce</span> <span>train-images</span>
  <span>(</span>map-tensor train-images-file <span>[</span>60000 1 28 28<span>]</span> <span>:uint8</span> <span>:nchw</span> <span>:read</span> 16<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>train-labels</span>
  <span>(</span>map-tensor train-labels-file <span>[</span>60000<span>]</span> <span>:uint8</span> <span>:x</span> <span>:read</span> 8<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-images</span>
  <span>(</span>map-tensor test-images-file <span>[</span>10000 1 28 28<span>]</span> <span>:uint8</span> <span>:nchw</span> <span>:read</span> 16<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-labels</span>
 <span>(</span>map-tensor test-labels-file <span>[</span>10000<span>]</span> <span>:uint8</span> <span>:x</span> <span>:read</span> 8<span>)</span><span>)</span>

<span>(</span><span>defn</span> <span>enc-categories</span> <span>[</span>val-tz<span>]</span>
  <span>(</span><span>let</span> <span>[</span>val-vector <span>(</span>view-vctr val-tz<span>)</span><span>]</span>
    <span>(</span><span>let-release</span> <span>[</span>cat-tz <span>(</span>tensor val-tz <span>[</span><span>(</span>first <span>(</span>shape val-tz<span>)</span><span>)</span> <span>(</span>inc <span>(</span>long <span>(</span>amax val-vector<span>)</span><span>)</span><span>)</span><span>]</span> <span>:flo</span><span>at</span><span> </span><span>:nc</span><span> </span><span>)</span>
                  cat-matrix <span>(</span>view-ge <span>(</span>view-vctr cat-tz<span>)</span> <span>(</span>second <span>(</span>shape cat-tz<span>)</span><span>)</span> <span>(</span>first <span>(</span>shape cat-t<span>z</span><span>)</span><span>)</span><span>)</span><span>]</span>
      <span>(</span><span>dotimes</span> <span>[</span>j <span>(</span>dim val-vector<span>)</span><span>]</span>
        <span>(</span>entry! cat-matrix <span>(</span>entry val-vector j<span>)</span> j 1.0<span>)</span><span>)</span>
      cat-tz<span>)</span><span>)</span><span>)</span>

<span>(</span><span>defn</span> <span>dec-categories</span> <span>[</span>cat-tz<span>]</span>
  <span>(</span><span>let</span> <span>[</span>cat-matrix <span>(</span>view-ge <span>(</span>view-vctr cat-tz<span>)</span> <span>(</span>second <span>(</span>shape cat-tz<span>)</span><span>)</span> <span>(</span>first <span>(</span>shape cat-tz<span>)</span><span>)</span><span>)</span><span>]</span>
    <span>(</span><span>let-release</span> <span>[</span>val-tz <span>(</span>tensor cat-tz <span>[</span><span>(</span>first <span>(</span>shape cat-tz<span>)</span><span>)</span><span>]</span> <span>:float</span> <span>:x</span><span>)</span>
                  val-vector <span>(</span>view-vctr val-tz<span>)</span><span>]</span>
      <span>(</span><span>dotimes</span> <span>[</span>j <span>(</span>dim val-vector<span>)</span><span>]</span>
        <span>(</span>entry! val-vector j <span>(</span>imax <span>(</span>col cat-matrix j<span>)</span><span>)</span><span>)</span><span>)</span>
      val-tz<span>)</span><span>)</span><span>)</span>

<span>(</span><span>defonce</span> <span>train-labels-float</span> <span>(</span>transfer! train-labels <span>(</span>tensor <span>[</span>60000<span>]</span> <span>:float</span> <span>:x</span><span>)</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>y-train</span> <span>(</span>enc-categories train-labels-float<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-labels-float</span> <span>(</span>transfer! test-labels <span>(</span>tensor <span>[</span>10000<span>]</span> <span>:float</span> <span>:x</span><span>)</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>y-test</span> <span>(</span>enc-categories test-labels-float<span>)</span><span>)</span>
</pre>
</div>
</div>
</div>


    </article></div>]]>
            </description>
            <link>https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-is-Fast-and-Simpler-than-Keras</link>
            <guid isPermaLink="false">hacker-news-small-sites-24406978</guid>
            <pubDate>Tue, 08 Sep 2020 10:22:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PandaDoc Employees Arrested in Belarus After Founders Protest Against Violence]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24406366">thread link</a>) | @perch56
<br/>
September 8, 2020 | https://savepandadoc.org/en/ | <a href="https://web.archive.org/web/*/https://savepandadoc.org/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>Friends,</p>
          <p>On&nbsp;September 2, the Belarus government ordered searches to&nbsp;be&nbsp;conducted at&nbsp;the Minsk office of&nbsp;PandaDoc. During the search, more than 20 employees were prevented from leaving and 7 of&nbsp;them were taken into custody and detained for further interrogation. Some of&nbsp;these employees were subsequently taken into custody from their homes.</p>
          <p>Over the next two days, the Financial Investigation Department (FID) arm of&nbsp;the Belarus government interviewed more than one hundred company employees. During those two days, the employees that had been taken into custody were also denied the rights to&nbsp;legal counsel.</p>
          <p>Today, on&nbsp;September 4, 2020 we&nbsp;were told that a&nbsp;criminal case was retroactively initiated against PandaDoc employees under part 4 of&nbsp;article 210 of&nbsp;the Criminal Code of&nbsp;the Republic of&nbsp;Belarus. Our employees are accused of&nbsp;taking one hundred and seven thousand Belarusian rubles (~40k USD) from the corporate accounts of&nbsp;the company in&nbsp;Minsk abusing their positions, thus causing damage to&nbsp;the&nbsp;State. As&nbsp;a&nbsp;result, our employees have now been placed into custody for two months.</p>
          <p>We&nbsp;declare that this accusation by&nbsp;the State of&nbsp;Belarus is&nbsp;completely untrue and has no&nbsp;grounds.</p>
          <p>All the company’s activities in&nbsp;Belarus were conducted since its inception in&nbsp;full compliance with the&nbsp;law. Several international audits and inspections by&nbsp;EY&nbsp;and other reputable companies over the last years prove that the company adhered to&nbsp;all regulations and laws prevalent in&nbsp;Belarus.</p>
          <p>As&nbsp;recent events in&nbsp;Belarus have demonstrated, it&nbsp;is&nbsp;a&nbsp;common practice of&nbsp;the Belarusian government to&nbsp;oppress political opponents. In&nbsp;this case, the authorities have taken four completely innocent people hostage.</p>
          <p>This action is&nbsp;purely an&nbsp;act of&nbsp;repression against the founders of&nbsp;PandaDoc who have been supporting some of&nbsp;the victims of&nbsp;the Belarussian government in&nbsp;the weeks since the stolen Presidential election. The only purpose of&nbsp;this private initiative by&nbsp;Mikita and Sergey has been intended to&nbsp;help stop the violence and is&nbsp;in&nbsp;no&nbsp;way related to&nbsp;PandaDoc.</p>
          <p>In&nbsp;response the government has imprisoned:</p>
          <ul>
            <li><strong>Yulia Shardyko</strong>, Accountant</li>
            <li><strong>Dmitry Rabtsevich</strong>, Director&nbsp;— Minsk office</li>
            <li><strong>Viktor Kuvshinov</strong>, Product director</li>
            <li><strong>Vladislav Mikholap</strong>, HR</li>
          </ul>
          <p>The law in&nbsp;Belarus has ceased to&nbsp;exist. The authorities do&nbsp;not even bother to&nbsp;act according to&nbsp;the prevailing rules and laws of&nbsp;the country. The case and charges are fabricated cases upon political orders ordered from somewhere in&nbsp;the government. This affects everyone in&nbsp;Belarus.</p>
          <h2>We&nbsp;ask of&nbsp;you:</h2>
          <ol>
            <li>Record a&nbsp;video in&nbsp;our support with the tag <strong>#SavePandaDoc</strong>.</li>
            <li>To&nbsp;express your disagreement in&nbsp;the press, media and social networks with the <strong>#SavePandaDoc</strong> tag.</li>
            <li>Connect us&nbsp;to&nbsp;journalists and reporters that you&nbsp;know. Our contact is&nbsp;<a href="mailto:savepandadoc@gmail.com">savepandadoc@gmail.com</a>.</li>
          </ol>
          <p>We&nbsp;are hoping that maximum publicity will show solidarity and pressure to&nbsp;have our colleagues released.</p>
          <p>—&nbsp;Pandas</p>
        </div></div>]]>
            </description>
            <link>https://savepandadoc.org/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24406366</guid>
            <pubDate>Tue, 08 Sep 2020 08:29:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I Link to WayBackMachine Instead of Original Web Content]]>
            </title>
            <description>
<![CDATA[
Score 137 | Comments 82 (<a href="https://news.ycombinator.com/item?id=24406193">thread link</a>) | @puggo
<br/>
September 8, 2020 | https://hawaiigentech.com/post/commentary/why-i-link-to-waybackmachine-instead/ | <a href="https://web.archive.org/web/*/https://hawaiigentech.com/post/commentary/why-i-link-to-waybackmachine-instead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <div>
        <div id="content">
          <article>
    
    

    
    <div>
      <p><img src="https://hawaiigentech.com/post/commentary/why-i-link-to-waybackmachine-instead/wayback.jpg" alt="WayBackMachine"></p>
<hr>
<p>When linking to a page for the <strong>purpose of reference</strong>, it seems better to me to <em><strong>link to the <a href="https://archive.org/">archive</a> of a given page</strong></em>, rather than to the original site itself.</p>
<p>This ensures that after some years have gone by, <strong>my article is guaranteed to be consistent</strong>. Due the  changing nature of the web, there is a chance that after some years, the link could lead to a:</p>
<ul>
<li>404 /  Not Found (most common)</li>
<li>Changed or edited content, or entirely replaced content</li>
<li>Content that, due to a rise in popularity, is now shielded, demanding the user to make an account to read the entire article.</li>
</ul>
<hr>

<p>Take defensive measures. To future-proof your content, rather than reference the general web, its far more reliable to link to an archive.</p>
<h2 id="example">Example:</h2>
<p>The Epoch Times wrote an article on Smartphones data-mining their users. This is the archived article here:</p>
<p><a href="https://web.archive.org/web/20190214015500/https://www.theepochtimes.com/smartphone-app-users-are-data-mined-even-when-not-using-the-apps_2787202.html">The Archive Version (fully readable)</a></p>
<h3 id="article-content-before">Article Content Before</h3>
<p>You can see its perfectly “normal” readable useful  content.</p>
<p><img src="https://hawaiigentech.com/post/commentary/why-i-link-to-waybackmachine-instead/link-content-before.png" alt="Article Link Content Before"></p>
<h3 id="article-content-after">Article Content After</h3>
<p>Now it’s spam from a site suffering financial need.</p>
<p><img src="https://hawaiigentech.com/post/commentary/why-i-link-to-waybackmachine-instead/link-content-after.png" alt="Article Link Content Before"></p>
<p>So in Feb 14 2019 your users would have seen the content you intended. However in Sep 07 2020, your users are being asked to support independent Journalism instead.</p>
<h2 id="if-an-archive-record-doesnt-exist-make-one">If an Archive Record Doesn't Exist, Make One</h2>
<p>Its worth the extra moment, in referencing a site, to make an archive of the page you wish to reference, if one does not exist. After that, immediately use the link from the archive.org entry, rather than the blog, news, info, or forum site you wish to refer to.</p>
<h2 id="in-unstable-times-take-measures-for-stability">In Unstable Times, Take Measures for Stability</h2>
<p>The web is a fast changing place. Even more during the Covid pandemic and suffering financial markets. Since times are financially harder, websites are disappearing, heaping up advertising, demanding user response, and things like this.</p>
<p>To avoid your content losing quality due to these things, linking to a solid, unchanging static copy of the page is far more reliable.</p>

    </div>

    <div>
  <p>
    <span>Author</span>
    <span>Leo Blanchette</span>
  </p>
  <p>
    <span>LastMod</span>
    <span>
        2020-09-07
        
    </span>
  </p>
  
  
</div>

  </article>
        </div>
        

  

  

      </div>
    </div></div>]]>
            </description>
            <link>https://hawaiigentech.com/post/commentary/why-i-link-to-waybackmachine-instead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24406193</guid>
            <pubDate>Tue, 08 Sep 2020 08:03:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Past Attempts of Software Metrics Have Failed Us]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24406030">thread link</a>) | @abyx
<br/>
September 8, 2020 | https://www.usehaystack.io/blog/software-development-metrics-pros-cons-and-why-past-attempts-have-failed | <a href="https://web.archive.org/web/*/https://www.usehaystack.io/blog/software-development-metrics-pros-cons-and-why-past-attempts-have-failed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="0ea0c8ae-8333-a516-8908-f86a85ef9373"><p>TLDR; Software engineering is a black box. It's incredibly complex and nuanced. The industry makes attempts to stack rank and measure via simplified metrics. This is the wrong approach and hurts engineering culture. Software is complex, previous attempts don't take that into account. There is a better solution.</p><p>‍</p><p><strong>Software engineering is a black box because</strong></p><ol role="list"><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#990eff2e60e346b282c47abcb5687b96" target="_blank">Software engineering is complex and invisible</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#d32d356b92594f6cbb8a4993cdf1c2d0" target="_blank">The output of software development varies</a></li></ol><p>‍</p><p><strong>There have been several attempts at quantifying developer productivity. The limited content you'll find fits into a few categories.</strong></p><ol role="list"><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#128c578b6c9c489d8c53525166e0f932" target="_blank">KPIs used to measure software engineer performance</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#8d31dd02f20a42a6b1b586b955207ce4" target="_blank">Methods of measuring developer performance and their fall backs</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#dbf2216d7f134396bcfe69185e96c1a9" target="_blank">Opinion pieces on if measurement is even possible</a></li></ol><p>‍</p><p><strong>You'll notice a pattern prevalent in the space. The industry is obsessed with finding</strong></p><ol role="list"><li>Golden metrics to stack rank and compare teams and individuals.</li><li>KPIs to objectively determine an engineer's performance.</li></ol><p>‍</p><p><strong>The result?</strong></p><p>Attempts to measure software engineer and team productivity using the same, simplified metrics and KPIs.</p><p>‍</p><p><strong>But that's the wrong approach..</strong></p><ol role="list"><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#5f58624ed1f6432087fa3ef21378cf0b" target="_blank">Attempting to stack rank is fundamentally flawed</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#447680dd5e204f8a8bb526db55ebbe5c" target="_blank">'Successful outcomes' are situational</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#ea18251c7c0a4d50a1eb57e1e34f7ff8" target="_blank">Simplified metrics hurt engineering culture</a></li></ol><p>‍</p><p><strong>Focus on productivity, not yard sticks</strong></p><ol role="list"><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#c685ee9fc42c4c678d86b85f01006df8" target="_blank">Measure engineers and teams independently</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#dcd2a669df6a4e97afa9ec24e25fbc14" target="_blank">Compare relative to individual history</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#b0b75fb866ee44d29f9a5862be9e2579" target="_blank">Identify the main risks and bottlenecks of productivity</a></li></ol><p>‍</p><p><strong>Why is this better?</strong></p><ol role="list"><li><a href="https://www.notion.so/usehaystack/Footnotes-f56dc18398104dca8534fc1e1ddd4ff2#95433ef2f1cb46c5ac5b116b3221ac69" target="_blank">Accurately measures productivity</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#f20c40f07837457ea2dc431fbbeb4c6c" target="_blank">Handles situational outcomes</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#0f37d98374d64ea3a76d2b179cc16a74" target="_blank">Supports engineering culture</a></li><li><a href="https://www.notion.so/usehaystack/Footnotes-f56dc18398104dca8534fc1e1ddd4ff2#d09f4a9a554643139c1c3d9f0987e1a4" target="_blank">Enables early risk identification</a></li></ol><p>‍</p><p><strong>Main takeaway:</strong></p><p>From the nature of the work to the culture that supports it, engineering is incredibly complex and nuanced. Previous attempts at measuring engineering performance have done a poor job of taking this complexity into account. Making attempts to measure each engineer and team against the same yard stick not only hurts culture, but gives no true indication of productivity to begin with.</p><p>‍</p><p>To date, the industry has been attempting this 'holy grail' of software development metrics from the wrong perspective. By focusing on drivers and blockers of productivity rather than KPIs and stack ranking; we can start to measure engineers and teams in a healthy way. More importantly, this new perspective enables engineering leaders to introduce a software development metrics to help improve while maintaining the highest impact driver of productivity (culture).</p><p>‍</p><p>Check out Haystack's approach <a href="https://usehaystack.io/">here</a>!</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5ef130052901e5cad8432b81_Haystack_Designed_Presentation.png" alt=""></p></figure><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=3%20git%20signals%20to%20identify%20blockers&amp;utm_campaign=inside%20blog">Haystack</a> helps engineering leaders identify blockers and trends. Directly from Github. Instead of guessing if you're improving, or constantly bothering your team for progress updates, simply use Haystack to get alerts in your inbox every morning. Plus a dashboard to track improvements over time.</p><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=3%20git%20signals%20to%20identify%20blockers&amp;utm_campaign=inside%20blog">Try it for free</a></p><p>‍</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.usehaystack.io/blog/software-development-metrics-pros-cons-and-why-past-attempts-have-failed</link>
            <guid isPermaLink="false">hacker-news-small-sites-24406030</guid>
            <pubDate>Tue, 08 Sep 2020 07:32:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Escape from creek fire]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24405981">thread link</a>) | @twohey
<br/>
September 8, 2020 | https://www.jmeshe.co/escape-from-creek-fire | <a href="https://web.archive.org/web/*/https://www.jmeshe.co/escape-from-creek-fire">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p><span>
By subscribing to the mailing list of
<strong>
Jaymie Shearer
</strong>
your email address is stored securely, opted into new post notifications and related communications. We respect your inbox and privacy, you may unsubscribe at any time.
</span></p><div>
<p><a href="https://www.exposure.co/privacy" rel="noopener" target="_blank" title="Link to Jaymie Shearer Privacy Policy">
Privacy Policy
</a>
<a href="https://www.exposure.co/terms" rel="noopener" target="_blank" title="Link to Jaymie Shearer Terms of Service">
Terms of Service
</a>
<a href="https://www.exposure.co/report" rel="noopener" target="_blank" title="Report a story or story">
Report
</a>
</p></div>

</div>
</div></div>]]>
            </description>
            <link>https://www.jmeshe.co/escape-from-creek-fire</link>
            <guid isPermaLink="false">hacker-news-small-sites-24405981</guid>
            <pubDate>Tue, 08 Sep 2020 07:22:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Invisible Salamanders in AES-GCM-SIV]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24405583">thread link</a>) | @some_furry
<br/>
September 7, 2020 | https://keymaterial.net/2020/09/07/invisible-salamanders-in-aes-gcm-siv/ | <a href="https://web.archive.org/web/*/https://keymaterial.net/2020/09/07/invisible-salamanders-in-aes-gcm-siv/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-95">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>By now, many people have run across the <a href="https://eprint.iacr.org/2019/016.pdf">Invisible Salamander</a> paper about the interesting property of AES-GCM, that allows an attacker to construct a ciphertext that will decrypt with a valid tag under two different keys, provided both keys are known to the attacker. On some level, finding properties like this isn’t too surprising: AES-GCM was designed to be an AEAD, and nowhere in the AEAD definition does it state anything about what attackers with access to the keys can do, since the usual assumption is that attackers don’t have that access, since any Alice-Bob-Message model would be meaningless in that scenario.</p>



<p>What is interesting to me is that this property comes up more often than one would think, I ran across it several times now during my work reviewing cryptographic designs, it’s far from an obscure property for real world systems. The general situation these systems have in common is that they involve three parties: Alice, Bob, and Trent. Trent is a trusted third party for Bob, who is allowed to read messages and scan them, with details like when and why depending on the crypto system in question. While Trent and Bob agree on the ciphertext<em>—</em>say because Trent hands Bob the ciphertext or because Alice presents Trent’s signature on it<em>—</em>Alice has the option of giving Trent and Bob different keys. The challenge for Alice is to come up with a ciphertext that has a valid authentication tag and still decrypts to different messages for Trent and Bob.</p>



<h4>Mitigations</h4>



<p>Before I dive deeper into how to construct invisible salamanders for AES-GCM and AES-GCM-SIV, a few words on how to defend against these problems. The easiest option here is to add a hash of the key to the ciphertext. This technically violates indistinguishability, as the identity of the key is leaked, i.e. an attacker now knows which key was used for the message. If indistinguishability is necessary, using the IV as a salt for the hash works well, constructions like <code>HMAC-SHA-2(key=IV, message=key)</code> (i.e. aka HKDF-expand) work well here, as long as attention is paid on whether or not this key hash can be used in any other context. In general, it shouldn’t because the key already should only be used for AES-GCM/AES-GCM-SIV, but real world systems sometimes have weird properties.</p>



<h4>Constructing Salamanders</h4>



<p>With the mitigation out of the way, onto the fun part: Constructing the messages. In order to understand why and how these attacks work, we first have to talk about <span data-katex-display="false">\mathbb{F}_{2^{128}}</span> and the way AES-GCM and AES-GCM-SIV use this field to construct their respective tags. As a finite field <span data-katex-display="false">\mathbb{F}_{2^{128}}</span> supports addition, multiplication, and division, following the usual field axioms. The field has characteristic 2, which means addition is just the xor operator, and subtraction is the exact same operation as addition. Multiplication and division is somewhat more complicated and not in scope for this article, it suffices to say that multiplication can be implemented with a very fast algorithm if the hardware supports certain instruction sets (carryless multiplication). The division algorithm uses the Euclidean algorithm and will at most take 256 multiplications in a naive implementation, so while slower than the other operations, it will still be extremely fast. I will use <span data-katex-display="false">+</span> for the addition operation and <span data-katex-display="false">\cdot</span> for the multiplication operation. The most important caveat is to not confuse these operations with integer arithmetic.</p>



<h5>AES-GCM</h5>



<p>Next, on to <a href="https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-38d.pdf">AES-GCM</a>. This AEAD is a relatively straightforward implementation of an AEAD that uses a UHF based MAC for authentication. Our IV is 12 byte long, we use a 4 byte counter and CTR mode to encrypt the message. The slightly odd feature is that we start the counter at 2, for reasons we will see later. For authentication, we first derive an authentication key <span data-katex-display="false">H</span> by encrypting the zero block (This is why we don’t start the counter at zero, otherwise the zero IV would be invalid). Now, using the ciphertext blocks, additional data blocks (both padded with zeros as needed for the last block), and adding a special length block containing the size of the additional data and the ciphertext, we get a collection of blocks, all of which I will refer to as <span data-katex-display="false">C_i</span>. To compute the tag, we now compute the polynomial</p>



<p><span data-katex-display="true">GHASH(H, C, T) = C_0\cdot H^{n+1} + C_1\cdot H^{n}+\dots + C_{n-1}\cdot H^2+C_n\cdot H+T</span></p><p>The constant term, <span data-katex-display="false">T</span> is the encrypted counter block associated to the counter variable of 1 (Which is why we started at 2 for the CTR mode). Remember that in characteristic 2 <span data-katex-display="false">+</span> is xor, so we could equivalently say that we compute the polynomial without the constant term and then encrypt it with CTR mode as the first block.</p>



<p>Now, how do we get two different plaintexts to agree on both ciphertext and tag, we first choose two keys and produce the corresponding keystreams, choosing the plaintexts so that the ciphertexts agree (If you want two plaintext that make sense, this part is the hardest step, you first brute force the first few bytes in order to be valid in one format and a comment opening statement in the other, so that you can switch which parts of the ciphertext will appear as valid plaintext and which parts appear as commented out). We leave one ciphertext block open for now, as a sacrificial block that we will modify in order to make the tags turn out to be the same. Next derive the corresponding authentication keys <span data-katex-display="false">H_1</span> and <span data-katex-display="false">H_2</span> and our constant terms <span data-katex-display="false">T_1, T_2</span>. This means, we have <span data-katex-display="false">C_i</span> fixed, except for a specific index, say <span data-katex-display="false">j</span>, and can now solve</p>



<p><span data-katex-display="true">GHASH(H_1, C, T_1) =GHASH(H_2, C, T_2)</span>



<span data-katex-display="true">\sum_{i=0}^n C_i\cdot H_1^{n+1-i}+T_1=\sum_{i=0}^n C_i\cdot H_2^{n+1-i}+T_2</span>



<span data-katex-display="true">C_j\cdot\left(H_1^{n+1-j}+H_2^{n+1-j}\right)=\sum_{\substack{i=0\\i\neq j}}^n C_i\cdot \left(H_1^{n+1-i}+H_2^{n+1-i}\right)+T_1+T_2</span>



<span data-katex-display="true">C_j=\left(H_1^{n+1-j}+H_2^{n+1-j}\right)^{-1}\cdot\left(\sum_{\substack{i=0\\i\neq j}}^n C_i\cdot \left(H_1^{n+1-i}+H_2^{n+1-i}\right)+T_1+T_2\right)</span></p><p>by solving for the sacrificial block <span data-katex-display="false">C_j</span>.</p>



<h5>AES-GCM-SIV</h5>



<p>So far so good, but, what about <a href="https://tools.ietf.org/html/rfc8452">AES-GCM-SIV</a>? GCM is famous for having many weird properties that make it extremely fragile, like leaking the authentication key on a single IV reuse, or allowing for insecure tags smaller than 128 bits. In many ways, AES-GCM-SIV is how AES-GCM should look like for real world applications, much more robust against IV reuse, only revealing the damaging properties of an UHF with a reused IV if both IV and tag are the same. This is accomplished through using the tag as a synthetic IV, meaning the tag is computed over the plaintext, and then used as IV for CTR mode to encrypt. Even though this kind of SIV construction uses MAC-then-Encrypt, they are secure against the usual downsides due to CTR mode always succeeding in constant time, independent of the plaintext. This means the receiver can decrypt the message and validate the tag without revealing information about the plaintext in case of an invalid tag. The library needs to take care that the plaintext is properly discarded and not exposed to the user in case the tag does not validate.</p>



<p>The actual IV for AES-GCM-SIV is used primarily derive a per message key. This means that if the IV of two messages is different, both encryption and authentication keys will be unrelated and can not be used to infer things about each other.</p>



<p>All in all AES-GCM-SIV works like this:</p>



<ul><li><span data-katex-display="false">H, K_E = \operatorname{KDF}(K, IV)</span></li><li><span data-katex-display="false">T=\operatorname{AES}(K_E, P_0\cdot H^{n+1}+\dots+P_n\cdot H)</span></li><li><span data-katex-display="false">C=\operatorname{AES-CTR}(K_E, IV=T)</span></li></ul>



<p>where the plaintext blocks <span data-katex-display="false">P_i</span> again contain additional data and length, and some extra hardening and efficiency tricks having been stripped for clarity.</p>



<p>Our previous approach of first creating the ciphertext and then balancing things out to get the tags to agree clearly cannot work here anymore. The keystream, and therefore the ciphertext, depend on the tag, so if we want to have any chance of finding a salamander, we have to fix the tag before we do any calculation at all. So after having chosen <span data-katex-display="false">T</span>, we decrypt it under each of our keys to get the result of our polynomial <span data-katex-display="false">S_i=\operatorname{AES}^{-1}(K_{E,i}, T)</span>. What we are left with is finding plaintexts <span data-katex-display="false">P_1, P_2</span> such that</p>



<p><span data-katex-display="true">S_i=\sum_{j=0}^n P_{j, i} H_i^{n+1-j}</span></p><p>which gives us a system of two linear equations with <span data-katex-display="false">2n</span> unknowns. But this isn’t all constraints we need to satisfy, since we still need to encrypt these plaintexts once we have the tag balanced. Here, we are lucky that everything is over characteristic 2: The CTR encryption is just an addition of the plaintext and the encrypted counter block <span data-katex-display="false">C_i=\operatorname{AES}(K_E, CB_i)+P_i</span>. To say that two plaintexts result in the same ciphertext under two different keys is just fulfilling the equation</p>



<p><span data-katex-display="true">\operatorname{AES}(K_{E, 1}, CB_{j, 1})+P_{j, 1}=\operatorname{AES}(K_{E, 2}, CB_{j, 2})+P_{j, 2}</span>.</p>



<p>This, like our two equations for the tag, is a linear equation. So in the end, for a plaintext that has a size of <span data-katex-display="false">n</span> blocks, we get <span data-katex-display="false">n+2</span> linear equations with <span data-katex-display="false">2n</span> variables. This means, in almost all cases, we can construct an invisible salamander with only adding two sacrificial blocks, with the same caveat that the two plaintexts need to be partially brute forced.</p>



<h4>Test Code</h4>



<p>I’ve put this to the test and have written code to produce <a href="https://github.com/sophieschmieg/fun-with-gcm/blob/master/FunWithGcm.java">AES-GCM</a> (Java) and <a href="https://github.com/sophieschmieg/fun-with-gcm/blob/master/fun_with_gcm_siv.cc">AES-GCM-SIV</a> (C++) salamanders.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://keymaterial.net/2020/09/07/invisible-salamanders-in-aes-gcm-siv/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24405583</guid>
            <pubDate>Tue, 08 Sep 2020 06:00:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Get Started with Azure Bicep – Alternative to ARM Templates]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24405187">thread link</a>) | @crpietschmann
<br/>
September 7, 2020 | https://build5nines.com/get-started-with-azure-bicep/ | <a href="https://web.archive.org/web/*/https://build5nines.com/get-started-with-azure-bicep/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>Azure Bicep is an abstraction built on top of Azure ARM Templates and Azure Resource Manager that offers a cleaner code syntax with better support for modularity and code re-use. Azure Bicep moves away from the JSON syntax used by ARM Templates and is much easier to both read and write Infrastructure as Code (IaC) in Azure! This is the latest tool from Microsoft for deploying Azure resources in a DevOps process, and its even open source!</p>



<p>Let’s get started!</p>



<blockquote><p><strong>Warning</strong>: Before you start using Azure Bicep, know that it is in an early Alpha state and is not supported for use in production environments just yet. Also, it doesn’t support all the functionality it eventually will. However, it does support some really great features already that makes Azure<a href="https://build5nines.com/what-is-infrastructure-as-code/"> Infrastructure as Code </a>(IaC) even easier to write and read!</p></blockquote>







<br><h2><span id="what_is_azure_bicep"></span>What is Azure Bicep?<span></span></h2>



<p>Azure Bicep is a new declarative Domain Specific Language (DSL) for deploying Azure resources. The goal of this new language is to make it easier to write Infrastructure as Code (IaC) targeting Azure Resource Manager (ARM) using a syntax that’s more friendly than the JSON syntax of Azure ARM Templates.</p>



<p>Azure Bicep works as an abstraction layer built on top of ARM Templates. Anything that can be done with Azure ARM Templates can be done with Azure Bicep as it provides a “transparent abstraction” over ARM (Azure Resource Manager). With this abstraction, all the <code>types</code>, <code>apiVersions</code>, and <code>properties</code> valid within ARM Templates are also valid with Azure Bicep.</p>



<figure></figure>



<p>Azure Bicep is a transpiled language. This means that the Azure Bicep code converted into ARM Template code. Then, the resulting ARM Template code is used to deploy the Azure resources. This transpiling enables Azure Bicep to use it’s own syntax and compiler for authoring Azure Bicep files that compile down to Azure Resource Manager (ARM) JSON as a sort of intermediate language (IL).</p>



<p>The way that Azure Bicep is transpiled into ARM JSON is similar to how there are many different languages that can be written in, then transpiled into JavaScript that can be run within the web browser. One popular example of this type of transpiled language is TypeScript. A transpiled language offers benefits of adding an abstraction layer to make it easier and / or more feature full to write code that then gets compiled down to IL code that gets executed. This is also similar to how C# and VB.NET code compile down to MSIL in .NET code.</p>



<p>In the development world, it’s common to encounter the use of transpiled languages. It’s also common in the DevOps world where YAML and JSON are converted between one or the other. Azure Bicep offers some similarity in how it’s transpiled into ARM JSON. This enables you to use an alternative syntax and feature set for writing declarative Infrastructure as Code than the often-cumbersome ARM JSON syntax.</p>



<blockquote><p>Azure Bicep offers some similarity in how it’s transpiled into ARM JSON. This enables you to use an alternative syntax and feature set for writing declarative Infrastructure as Code than the often-cumbersome ARM JSON syntax.</p></blockquote>



<p>Azure Bicep will have limits in its ability to support features that are not natively supported by ARM Templates when deploying Azure resources. However, Azure Bicep will also be able to implement additional code reuse and other features that the Azure Bicep compiler will be able to translate into valid ARM JSON features. Through all this, Azure Bicep has a goal of offering a cleaner syntax along with better support for modularity and code re-use than is offered by ARM JSON.</p>



<h2><span id="why_use_azure_bicep"></span>Why use Azure Bicep?<span></span></h2>



<p>Azure Resource Manager and ARM Templates are written in a JSON syntax that can be cumbersome to work with. Azure Bicep is a Domain Specific Language (DSL) that offers a transparent abstraction over Azure Resource Manager and ARM Templates that offers support for a cleaner code syntax with better support for modularity and code re-use. Azure Bicep offers a few improvements for authoring Azure IaC over the use of ARM Template JSON.</p>



<br><h3><span id="azure_bicep_benefits"></span>Azure Bicep Benefits<span></span></h3>



<p>Here are the primary benefits of using Azure Bicep that are integrated as core goals into the Azure Bicep project and are the foundations for why Microsoft is building Azure Bicep:</p>



<ol><li>Create a better language for writing Infrastructure as Code (IaC) for describing, validating, and deploying Azure resources.</li><li>The Azure Bicep language is a transparent abstraction that does not require any updates or onboarding to the underlying platform in order to support a new Azure resource <code>type</code> and / or <code>apiVersion</code>.</li><li>Azure Bicep code should be easily understood and straightforward to learn for those both new and experienced with other programming languages.</li><li>Code re-use should be a primary feature allowing users freedom to modularize and re-use code without ‘copy/paste’.</li><li>Azure Bicep tooling should offer a high level of discoverability and validation. The tooling should also be developed alongside the compiler; rather than added afterwards.</li><li>Azure Bicep should enable users to have high confidence that the code is ‘syntactically valid’ before it’s deployed.</li></ol>



<p>Also, Azure Bicep is being specifically designed so that it is not a general-purpose language for meeting any need. It is a Domain Specific Language (DSL) meant for writing declarative IaC. It’s also not meant to provide a model for non-Azure related tasks.</p>



<h2><span id="install_azure_bicep"></span>Install Azure Bicep<span></span></h2>



<p>Azure Bicep is a DevOps tool built for authoring IaC used to deploy Azure resources from any environment. As a result, this means Azure Bicep supports Windows, Linux, and macOS.</p>



<p>The primary component for Azure Bicep is the Bicep CLI. This is the required tool used for compiling Bicep code into ARM JSON; plus, it’s open source and cross-platform.</p>



<p>Let’s take a look at installing Azure Bicep in different environments!</p>



<h3><span id="download_bicep_cli_binaries"></span>Download Bicep CLI Binaries<span></span></h3>



<p>When installing Azure Bicep, you will need to first download the Bicep CLI binary built for your operating system. All the binaries for the different supported operating systems can be downloaded from the official <a href="https://github.com/Azure/bicep/releases" target="_blank" rel="noopener">releases page</a> of the Azure Bicep open source project.</p>



<p>You can either manually download the Bicep CLI binary and install it, or you can use the following helper script examples to install Azure Bicep more easily.</p>



<h3><span id="install_on_windows"></span>Install on Windows<span></span></h3>



<p>On Windows machines, Azure Bicep can be installed using PowerShell with the following script:</p>



<pre><code># Create the install folder
$installPath = "$env:USERPROFILE\.bicep"
$installDir = New-Item -ItemType Directory -Path $installPath -Force
$installDir.Attributes += 'Hidden'
# Fetch the latest Bicep CLI binary
(New-Object Net.WebClient).DownloadFile("https://github.com/Azure/bicep/releases/latest/download/bicep-win-x64.exe", "$installPath\bicep.exe")
# Add bicep to your PATH
$currentPath = (Get-Item -path "HKCU:\Environment" ).GetValue('Path', '', 'DoNotExpandEnvironmentNames')
if (-not $currentPath.Contains("%USERPROFILE%\.bicep")) { setx PATH ($currentPath + ";%USERPROFILE%\.bicep") }
if (-not $env:path.Contains($installPath)) { $env:path += ";$installPath" }
# Verify you can now access the 'bicep' command.
bicep --help
# Done!</code></pre>



<h3><span id="install_on_macos"></span>Install on macOS<span></span></h3>



<p>On macOS machines, Azure Bicep can be installed using the terminal with the following script:</p>



<pre><code># Fetch the latest Bicep CLI binary
curl -Lo bicep https://github.com/Azure/bicep/releases/latest/download/bicep-osx-x64
# Mark it as executable
chmod +x ./bicep
# Add Gatekeeper exception (requires admin)
sudo spctl --add ./bicep
# Add bicep to your PATH (requires admin)
sudo mv ./bicep /usr/local/bin/bicep
# Verify you can now access the 'bicep' command
bicep --help
# Done!</code></pre>



<h3><span id="install_on_linux"></span>Install on Linux<span></span></h3>



<p>On Linux machines, Azure Bicep can be installed using the following script:</p>



<pre><code># Fetch the latest Bicep CLI binary
curl -Lo bicep https://github.com/Azure/bicep/releases/latest/download/bicep-linux-x64
# Mark it as executable
chmod +x ./bicep
# Add bicep to your PATH (requires admin)
sudo mv ./bicep /usr/local/bin/bicep
# Verify you can now access the 'bicep' command
bicep --help
# Done!</code></pre>



<h3><span id="install_in_azure_cloud_shell"></span>Install in Azure Cloud Shell<span></span></h3>



<p>The Azure Cloud Shell runs on Ubuntu server, so to install Azure Bicep, you will need to install the Linux binary for the Bicep CLI. However, you cannot simply use the above script for installing Azure Bicep on Linux due to a limitation of the Azure Cloud Shell that prevents you from modifying the PATH.</p>



<p>Here are some steps you can follow to basically “install” Azure Bicep for use in the Azure Cloud Shell environment:</p>



<ol><li>Connect to the Azure Cloud Shell; either within the Azure Portal or at <code><a href="https://shell.azure.com/" rel="nofollow">https://shell.azure.com</a></code>.</li><li>First, you likely want to create a directory within the Azure Cloud Shell environment to save the Bicep CLI to. For example, creating a <code>~/tools</code> directory:<br><code>mkdir ~/tools</code></li><li>Next, navigate to the directory created and download the Linux binary for the Bicep CLI into the Azure Cloud Shell environment into this directory:</li></ol>



<pre><code># Navigate to "tools" directory
cd ~/tools
# Fetch the latest Bicep CLI binary
curl -Lo bicep https://github.com/Azure/bicep/releases/latest/download/bicep-linux-x64
# Mark it as executable
chmod +x ./bicep</code></pre>



<p>Using the above steps will place the Azure Bicep CLI in the location of <code>~/tools/bicep</code> within you Azure Cloud Shell environments. Once placed here, you can execute the Bicep CLI from anywhere within the Azure Cloud Shell environment by referencing it within the <code>~/tools</code> directory.</p>



<p>For example, when located within the <code>~/bicep</code> directory, you can run the following command to utilize the <code>~/tools/bicep</code> executable to build some Azure Bicep code in the <code>main.bicep</code> file:</p>



<pre><code>chris@Azure:~/bicep$ ~/tools/bicep build main.bicep</code></pre>



<p>With the Azure Bicep CLI installed into the Azure Cloud Shell environment, then you’ll be able to utilize Azure Bicep easily from anywhere without the need to install it on your local machine.</p>



<h2><span id="compiling_and_deploying_azure_bicep_code"></span>Compiling and Deploying Azure Bicep code<span></span></h2>



<p>Azure Bicep code is written in files with the <code>.bicep</code> extension. These Bicep …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://build5nines.com/get-started-with-azure-bicep/">https://build5nines.com/get-started-with-azure-bicep/</a></em></p>]]>
            </description>
            <link>https://build5nines.com/get-started-with-azure-bicep/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24405187</guid>
            <pubDate>Tue, 08 Sep 2020 04:23:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cracking the Culture Interview]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24405093">thread link</a>) | @benshuyichen
<br/>
September 7, 2020 | https://heybenchen.com/cracking-the-culture-interview-1 | <a href="https://web.archive.org/web/*/https://heybenchen.com/cracking-the-culture-interview-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1599532527250/Gm0E0xbTo.jpeg?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>The most successful companies are built upon great working cultures that are thoughtful about the <a target="_blank" href="https://hbr.org/2020/01/the-new-analytics-of-culture">cultural contribution</a> each hire will make to their company. If you're a candidate looking to land your dream job, you'll need to be well prepared for these cultural or behavioral interviews. </p>
<p>As a hiring manager, I've interviewed over 200 engineering candidates and a significant portion of that  has been evaluating the soft skills each candidate embodies. I've rejected extremely strong technical performers and and fought to hire some more junior candidates based on the signal I've identified from the culture interview. Because every company has their own culture, their own values, and their own questions, the culture interview can be extremely hard to prepare for. However, there's still plenty you can do to set yourself up for success instead of jumping in blind.</p>
<p>While my interviewing experience as both a hiring manager and a candidate have been primarily within engineering, I believe the tools in this kit will be mostly applicable across product, design, and other disciplines within product development organizations. </p>
<h2 id="stories-to-prepare">Stories to Prepare</h2>
<p>Why should you prepare stories instead of answers to specific questions? The simple reason is that you can't prepare and memorize an answer to every question an interviewer might ask. Often times these conversations are organic and the real signal comes from how you respond to follow-up questions. The best answers are rooted in real examples from your personal experience and by "loading" these stories into your brain ahead of time, you'll be better equipped to handle questions on the spot.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1599089431543/WeopvfKLq.png?auto=format&amp;q=60" alt="https://cdn.hashnode.com/res/hashnode/image/upload/v1599089431543/WeopvfKLq.png"></p>
<h3 id="story-1-your-career-narrative">Story #1: Your career narrative</h3>
<p>Almost everyone you talk to will give an intro of themselves and then ask you to share a brief intro as well. Depending on who you're talking to, that intro can be anywhere from 30 seconds to 3 minutes. In some cases, a hiring manager or recruiter might ask you to go deeper into your background and spend up to 30 minutes digging into your experiences.</p>
<h4 id="what-to-prepare">What to prepare</h4>
<ol>
<li>A narrative that connects your career together. While many careers are not linear, it can help to show that you were deliberate about the jobs you took and what you wanted to learn at each one. You may find that as you look back on your career, there's a story you can weave together that ties together where you started, where you're at now, and the trajectory you're on. A story that shows strong growth, surmounting challenges, and a high forward trajectory can help get companies excited about you. Finish your story such that the company you're talking to easily makes sense as the next step on your career journey.<ul>
<li>A weak narrative merely lists what's on your resume, e.g., "in 2013 I joined X and did these projects, in 2014 I joined Y and did these projects, and recently I've done Z and B. I want to join this company because it's doing really well."</li>
<li>A stronger narrative gives context on your decisions and motivations, e.g., "In college, I was excited about electronics and human-computer interfaces, so I looked for companies that specialized in consumer hardware. X company was one of the companies that stood out, and when I joined I got to work on the interface for Product P. This taught me [so and so] but after 2 years there, I really wanted to get better at [this other thing], so I reached out to Company Y. From there, I grew into [some role], helped the company do [these things], and now I'm [doing something impressive]. Going forward, I'm looking for an opportunity where I can put my front end architecture skills to good use while learning how to build complex systems at scale. I admire [company name] for being able to build high quality user interfaces while being super fast and reliable. I think this might be a great fit for my expertise and give me opportunities to grow my backend skills."</li>
</ul>
</li>
<li>What specific things you're looking for in your next role. These should apply to more than one company to show that you're not just pandering to the company, but try to be opinionated at the same time.<ul>
<li>A weak answer is too vague, uncertain, or demonstrates that you haven't put much thought to it.<ul>
<li>e.g., "I'm looking for a place where I can advance my career." or "I wanted to get into AI and Machine Learning because it's a really hot industry right now."</li>
</ul>
</li>
<li>A stronger answer shows that you've clearly thought about what you want, have had enough experience to know what you don't want, and implicitly show why the company you're talking to is a good fit.<ul>
<li>e.g., "Over my career, I've found that it's really important for me to have a strong sense of ownership over my work. I enjoy taking an ambiguous customer problem, breaking it down with a PM or designer, and then being able to see the whole project through from start to finish. I like to solve problems and not just execute on tasks, even if that means working through some dealing with a lot of uncertainty at times and wearing many hats."</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="what-the-interviewer-is-looking-for">What the interviewer is looking for</h4>
<ul>
<li>For quick intros, interviewers are generally not evaluating your storytelling ability. Instead, they want to know why you might be a good fit for the role and what your motivations are.</li>
<li>For hiring managers and recruiters, your career narrative can be a useful lens to interpret the interview feedback and make a decision on whether or not to move forward.<ul>
<li>For example, if your background is primarily backend engineering and the interviews demonstrate weakness in UI implementation, then your narrative can help interviewers focus more on your strengths over your weaker areas.</li>
</ul>
</li>
<li>If you under-represent yourself at this stage, you may miss an opportunity to move forward in the interview process or get an offer.<ul>
<li>On the flip side, you should avoid changing your narrative too much simply to suit the role or company you're talking to. It's often better to be rejected for a role that really doesn't fit you than to get a role doing something that doesn't actually align with what you want.</li>
</ul>
</li>
</ul>
<h4 id="questions-that-interviewers-may-ask">Questions that interviewers may ask</h4>
<ul>
<li>Tell me about yourself.</li>
<li>What are you looking for in your next role?</li>
<li>Why are you interested in [company]?</li>
</ul>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1599088479939/uCQDKllBU.png?auto=format&amp;q=60" alt="https://cdn.hashnode.com/res/hashnode/image/upload/v1599088479939/uCQDKllBU.png"></p>
<h3 id="story-2-two-impressive-projects">Story #2: Two Impressive Projects</h3>
<p>You should be prepared to talk in depth about at least two meaningful projects you've worked on where you played a significant role. Why two? If you use the same example for every question, the interviewer may think you're lacking experience or have a weak track record. Having at least two substantial projects in your pocket will help you balance breadth and depth to respond to a variety of questions.</p>
<p>Keep your initial explanation short (between 3-5 minutes) and offer to go deeper afterwards. This will help keep the conversation focused and avoid wasting time on unimportant details.</p>
<p>A good format to use whenever you're giving an example of something that happened is to use the <a target="_blank" href="https://www.mindtools.com/pages/article/situation-behavior-impact-feedback.htm">SBI framework</a> or <a target="_blank" href="https://www.vawizard.org/wiz-pdf/STAR_Method_Interviews.pdf">STAR framework</a>. For these examples I'll use the SBI model. </p>
<h4 id="what-to-prepare">What to prepare</h4>
<ul>
<li><strong>Situation</strong>: Share context on the project before jumping into what you did.<ul>
<li>Where did the project come from?</li>
<li>Why was it important? How did you or your team prioritize it?</li>
<li>What were the goals of the project?</li>
</ul>
</li>
<li><strong>Behavior</strong>: Describe your specific role on that project. If you played a technical role, describe how the system was designed.<ul>
<li>Project management<ul>
<li>What was your role in defining the scope or solution?</li>
<li>How did you ensure the project was on track?</li>
<li>What obstacles came up during the project? How did you overcome them?</li>
</ul>
</li>
<li>System design of the project<ul>
<li>How was the system architected?</li>
<li>What were the biggest points of failure?</li>
<li>How did you approach this design?</li>
<li>Who else was involved in the design?</li>
</ul>
</li>
</ul>
</li>
<li><strong>Impact</strong>: What was the result of this project?<ul>
<li>What went well on that project?<ul>
<li>Did the project succeed?</li>
<li>How did you measure success?</li>
<li>Can you share some of your success metrics and how they performed?</li>
</ul>
</li>
<li>What did you learn on that project?<ul>
<li>What skills did you build?</li>
<li>What didn't go well on that project?</li>
<li>If you were to do the project again, what might you do differently? Try to come up with at least one or two examples.</li>
</ul>
</li>
<li>If the project didn't succeed, why not?<ul>
<li>Demonstrate that you can take ownership of your mistakes and avoid blaming others. Most interviewers are looking for a growth mindset.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="what-interviewers-are-looking-for">What interviewers are looking for</h4>
<ul>
<li>Does the work align with the level and scope of the role?<ul>
<li>Are they applying for a role that's realistic with what they've done historically?</li>
<li>What kind of domain expertise do they have?</li>
<li>Have they had enough technical leadership experience for the role? (More relevant for senior/tech lead roles and above.)</li>
</ul>
</li>
<li>Can the candidate clearly articulate the benefit and impact of their work?<ul>
<li>It's surprising how often some people don't know or think about the result of their work beyond completing the tasks that were assigned to them. Strong candidates think about the entire workflow, from idea conception to evaluating success.</li>
</ul>
</li>
<li>Do they have a growth mindset?<ul>
<li>Are they able to reflect on both the successes and misses of that project?</li>
<li>Do they take credit for all the things that went well and blame others for all the things that didn't go well? (This would be a red flag.)</li>
<li>Can they clearly explain both the technical and non-technical portions of their work?</li>
</ul>
</li>
</ul>
<h4 id="questions-that-interviewers-may-ask">Questions that interviewers may ask</h4>
<ul>
<li>What's the most significant project you worked on in the last year?</li>
<li>Tell me about a project that didn't go as well as you had hoped. What happened?</li>
<li>Give me an example of how you learned an area/product that you knew nothing about. What was the outcome?</li>
</ul>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1599089660735/RwoSL0oEm.png?auto=format&amp;q=60" alt="https://cdn.hashnode.com/res/hashnode/image/upload/v1599089660735/RwoSL0oEm.png"></p>
<h3 id="story-3-resolving-a-conflict">Story #3: Resolving a conflict</h3>
<p>Delivering successful projects often require working with a lot of stakeholders and collaborators. Demonstrate that you can work well with others, share critical feedback, and resolve situations on your own.</p>
<p>I've been surprised at how often candidates talk about a situation where they ultimately failed to resolve a conflict. It can be hard to think of a good example on the spot, so definitely prepare this ahead of time and consider what you want the interviewer to take away.</p>
<h4 id="what-to-prepare">What…</h4></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://heybenchen.com/cracking-the-culture-interview-1">https://heybenchen.com/cracking-the-culture-interview-1</a></em></p>]]>
            </description>
            <link>https://heybenchen.com/cracking-the-culture-interview-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24405093</guid>
            <pubDate>Tue, 08 Sep 2020 04:04:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Multifaceted William Shockley]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24404968">thread link</a>) | @the-mitr
<br/>
September 7, 2020 | http://wwww.tikalon.com/blog/blog.php?article=2020/Shockley | <a href="https://web.archive.org/web/*/http://wwww.tikalon.com/blog/blog.php?article=2020/Shockley">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://wwww.tikalon.com/blog/blog.php?article=2020/Shockley</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404968</guid>
            <pubDate>Tue, 08 Sep 2020 03:31:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tearing Apart the Wyze Outdoor Camera Base Station – Surprise, Its OpenWRT]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24404931">thread link</a>) | @miniman1337
<br/>
September 7, 2020 | https://illumo.com/tearing-apart-the-wyze-outdoor-cam-base-station/ | <a href="https://web.archive.org/web/*/https://illumo.com/tearing-apart-the-wyze-outdoor-cam-base-station/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-96">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>In this blog post we will take a look inside the Wyze Outdoor Base Station and see whats going on. Many people were very excited to hop on board the Wyze train when they announced the outdoor camera – however it has mostly been met with bad reviews and buggy, half baked features. </p>



<figure><img loading="lazy" src="https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-1024x401.jpg" alt="" width="1024" height="401" srcset="https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-1024x401.jpg 1024w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-300x117.jpg 300w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-768x301.jpg 768w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-1536x601.jpg 1536w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-2048x802.jpg 2048w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-1200x470.jpg 1200w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-1980x775.jpg 1980w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>A few small screws removed and we are into the Wyze Base Station</figcaption></figure>



<p>Lets get this thing out of the plastic case to take a closer look, carefully removing the RF1.13 IPX connectors for the antenna signal wire.</p>



<figure><img loading="lazy" src="https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside2-1024x483.jpg" alt="" width="1068" height="503" srcset="https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside2-1024x483.jpg 1024w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside2-300x141.jpg 300w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside2-768x362.jpg 768w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside2-1536x724.jpg 1536w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside2-2048x965.jpg 2048w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside2-1200x566.jpg 1200w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside2-1980x933.jpg 1980w" sizes="(max-width: 1068px) 100vw, 1068px"><figcaption>The guts</figcaption></figure>



<p>We can see that the board is labeled 9531_HL_CORE_AM7</p>



<figure><img loading="lazy" width="403" height="318" src="https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-2.jpg" alt="" srcset="https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-2.jpg 403w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorBasestationInside1-2-300x237.jpg 300w" sizes="(max-width: 403px) 100vw, 403px"><figcaption>The SoC is a Qualcom QCA9531-BL3A</figcaption></figure>



<p>Qualcomm marketing says:</p>



<blockquote><p>The QCA9531 is a highly integrated and feature-rich IEEE 802.11n 2×2 2.4 GHz System-on-a-Chip (SoC) for advanced WLAN platforms.</p><cite><a href="https://www.qualcomm.com/products/qca9531">https://www.qualcomm.com/products/qca9531</a></cite></blockquote>



<p>The Specifications sheet on Qualcomms website is very light on details, but this looks like a common SoC for low end networking and cheapo wireless routers. </p>



<blockquote><p><strong>Specifications:</strong></p><p><strong>CPU Clock Speed:&nbsp;</strong>Up to 650 MHz</p><p><strong>Wi-Fi Standards:&nbsp;</strong>802.11a/b/g,&nbsp;802.11n</p><p><strong>Peak Speed:&nbsp;</strong>300 Mbps</p><p><strong>Channel Utilization:&nbsp;</strong>20/40 MHz</p><p><strong>MIMO Configuration:&nbsp;</strong>2×2 (2-stream)</p><p><strong>Ethernet Standards:&nbsp;</strong>IEEE 802.3</p><p><strong>Ethernet Network:&nbsp;</strong>10/100</p><p><strong>Supported Ports:&nbsp;</strong>5 ports</p><p><strong>USB Version:&nbsp;</strong>USB 2.0</p><p><strong>Memory speed:&nbsp;</strong>300MHz,&nbsp;200MHz</p><p><strong>Memory Type:&nbsp;</strong>DDR1,&nbsp;DDR2</p><p><strong>Supported Interfaces:&nbsp;</strong>JTAG,&nbsp;SPI,&nbsp;UART,&nbsp;USB 2.0,&nbsp;PCIe 1.1</p><p><strong>General Purpose I/Os:&nbsp;</strong>17x</p><p><strong>Package Type:&nbsp;</strong>DRQFN</p><p><strong>Package Size:&nbsp;</strong>12 x 12 mm</p></blockquote>



<figure><img loading="lazy" width="515" height="662" src="https://illumo.com/wp-content/uploads/2020/08/image.png" alt="" srcset="https://illumo.com/wp-content/uploads/2020/08/image.png 515w, https://illumo.com/wp-content/uploads/2020/08/image-233x300.png 233w" sizes="(max-width: 515px) 100vw, 515px"></figure>



<p>It seems like this might be a board built by Nova Electronics that Wyze is putting into a nice package. Looks Familiar right?</p>



<p>The 3 pins on the right side of the board look like they could be SPI – so we tried to solder some pins on and get a terminal open</p>



<p>I guessed the TX / RX pins, and the ground was labeled nicely on the board. For Reference: </p>



<ul><li>Ground to GND (Duh!)</li><li>TX is L1</li><li>RX is L2</li></ul>



<figure><img loading="lazy" src="https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorSPI-1024x485.jpg" alt="" width="610" height="288" srcset="https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorSPI-1024x485.jpg 1024w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorSPI-300x142.jpg 300w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorSPI-768x363.jpg 768w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorSPI-1536x727.jpg 1536w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorSPI-2048x969.jpg 2048w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorSPI-1200x568.jpg 1200w, https://illumo.com/wp-content/uploads/2020/08/WyzeOutdoorSPI-1980x937.jpg 1980w" sizes="(max-width: 610px) 100vw, 610px"><figcaption>Wyze Outdoor Camera Base Station UART / SPI pins</figcaption></figure>



<p>I connected with a cheapo CP2102 USB to UART adapter, set the baud rate to 115200 and was off to the races… kinda</p>



<figure><img src="https://media.discordapp.net/attachments/391521801286451213/742921748214972556/unknown.png" alt=""></figure>



<p>Well this is interesting, this little guy is running OpenWRT.  I guessed all of the normal user / password combos I could think of and didn’t get anywhere – If anyone has any ideas on how to get into this shoot me a message / comment!</p>



<p>Lets watch it boot up and see if there is anything interesting going on here: </p>



<pre>U-Boot 1.1.4-gf13eb91d-dirty (Apr  2 2020 - 14:39:10)

ap147 - Honey Bee 2.0DRAM:
sri
Honey Bee 2.0
ath_ddr_initial_config(195): (16bit) ddr2 init
tap = 0x00000003
Tap (low, high) = (0x6, 0x21)
Tap values = (0x13, 0x13, 0x13, 0x13)
128 MB
Top of RAM usable for U-Boot at: 88000000
Reserving 201k for U-Boot at: 87fcc000
Reserving 192k for malloc() at: 87f9c000
Reserving 44 Bytes for Board Info at: 87f9bfd4
Reserving 36 Bytes for Global Data at: 87f9bfb0
Reserving 128k for boot params() at: 87f7bfb0
Stack Pointer at: 87f7bf98
Now running in RAM - U-Boot at: 87fcc000
Flash Manuf Id 0x1c, DeviceId0 0x70, DeviceId1 0x18
flash size 16MB, sector count = 256
Flash: 16 MB
*** Warning *** : PCIe WLAN Module not found !!!
In:    serial
Out:   serial
Err:   serial
Net:   ath_gmac_enet_initialize...
No valid address in Flash. Using fixed address
No valid address in Flash. Using fixed address
ath_gmac_enet_initialize: reset mask:c02200
Scorpion ----&gt;S27 PHY*
S27 reg init
: cfg1 0x800c0000 cfg2 0x7114
eth0: <redacted>
athrs27_phy_setup ATHR_PHY_CONTROL 4 :1000
athrs27_phy_setup ATHR_PHY_SPEC_STAUS 4 :10
eth0 up
Honey Bee ----&gt;  MAC 1 S27 PHY *
S27 reg init
ATHRS27: resetting s27
ATHRS27: s27 reset done
: cfg1 0x800c0000 cfg2 0x7214
eth1: <redacted>
athrs27_phy_setup ATHR_PHY_CONTROL 0 :1000
athrs27_phy_setup ATHR_PHY_SPEC_STAUS 0 :10
athrs27_phy_setup ATHR_PHY_CONTROL 1 :1000
athrs27_phy_setup ATHR_PHY_SPEC_STAUS 1 :10
athrs27_phy_setup ATHR_PHY_CONTROL 2 :1000
athrs27_phy_setup ATHR_PHY_SPEC_STAUS 2 :10
athrs27_phy_setup ATHR_PHY_CONTROL 3 :1000
athrs27_phy_setup ATHR_PHY_SPEC_STAUS 3 :10
eth1 up
eth0, eth1
Setting 0x181162c0 to 0x50a1a100
update_flag:000
===== fythons! ====
Hit any key to stop autoboot:  0
## Booting image at 9f050000 ...
   Image Name:   MIPS Linux-3.3.8
   Created:      2020-04-02   6:39:26 UTC
   Image Type:   MIPS Linux Multi-File Image (lzma compressed)
   Data Size:    1137996 Bytes =  1.1 MB
   Load Address: 80060000
   Entry Point:  80060000
   Contents:
   Image 0:  1137988 Bytes =  1.1 MB
   Verifying Checksum at 0x9f050040 ...OK
   Uncompressing Multi-File Image ... OK
No initrd
## Transferring control to Linux (at address 80060000) ...
## Giving linux memsize in bytes, 134217728

Starting kernel ...

[    0.000000] Linux version 3.3.8 (bai@bai) (gcc version 4.6.3 20120201 (prerel                                                                                             ease) (Linaro GCC 4.6-2012.02) ) #39 Tue Mar 31 13:44:16 CST 2020
[    0.000000] bootconsole [early0] enabled
[    0.000000] CPU revision is: 00019374 (MIPS 24Kc)
[    0.000000] SoC: Qualcomm Atheros QCA9531 rev 2
[    0.000000] Clocks: CPU:650.000MHz, DDR:597.607MHz, AHB:216.666MHz, Ref:25.00                                                                                             0MHz
[    0.000000] Determined physical RAM map:
[    0.000000]  memory: 08000000 @ 00000000 (usable)
[    0.000000] Initrd not found or empty - disabling initrd
[    0.000000] Zone PFN ranges:
[    0.000000]   Normal   0x00000000 -&gt; 0x00008000
[    0.000000] Movable zone start PFN for each node
[    0.000000] Early memory PFN ranges
[    0.000000]     0: 0x00000000 -&gt; 0x00008000
[    0.000000] Built 1 zonelists in Zone order, mobility grouping on.  Total pag                                                                                             es: 32512
[    0.000000] Kernel command line:  board=AP147 console=ttyS0,115200 mtdparts=s                                                                                             pi0.0:256k(u-boot)ro,64k(u-boot-env),1280k(kernel),6336k(rootfs),2176k(driver),1                                                                                             536k(app),2176k(backd),1536k(backa),256K(config),640k(para),64k(flag),64k(art),1                                                                                             0560k@0x50000(firmware) rootfstype=squashfs,jffs2 noinitrd
[    0.000000] PID hash table entries: 512 (order: -1, 2048 bytes)
[    0.000000] Dentry cache hash table entries: 16384 (order: 4, 65536 bytes)
[    0.000000] Inode-cache hash table entries: 8192 (order: 3, 32768 bytes)
[    0.000000] Primary instruction cache 64kB, VIPT, 4-way, linesize 32 bytes.
[    0.000000] Primary data cache 32kB, 4-way, VIPT, cache aliases, linesize 32                                                                                              bytes
[    0.000000] Writing ErrCtl register=00000000
[    0.000000] Readback ErrCtl register=00000000
[    0.000000] Memory: 126020k/131072k available (2396k kernel code, 5052k reser                                                                                             ved, 662k data, 224k init, 0k highmem)
[    0.000000] SLUB: Genslabs=9, HWalign=32, Order=0-3, MinObjects=0, CPUs=1, No                                                                                             des=1
[    0.000000] NR_IRQS:83
[    0.000000] Calibrating delay loop... 432.53 BogoMIPS (lpj=2162688)
[    0.060000] pid_max: default: 32768 minimum: 301
[    0.060000] Mount-cache hash table entries: 512
[    0.070000] Performance counters: mips/24K PMU enabled, 2 32-bit counters ava                                                                                             ilable to each CPU, irq 13
[    0.080000] Initialized recycle list for cpu 0.
[    0.080000] NET: Registered protocol family 16
[    0.090000] gpiochip_add: registered GPIOs 0 to 17 on device: ath79
[    0.090000] ath79_jtag_function_disable
[    0.100000] MIPS: machine is Qualcomm Atheros AP147 reference board
[    0.110000] ar724x-pci ar724x-pci.0: PCIe link is down
[    0.110000] registering PCI controller with io_map_base unset
[    0.120000] ar71xx: invalid MDIO id 1
[    0.330000] bio: create slab <bio-0> at 0
[    0.330000] PCI host bridge to bus 0000:00
[    0.340000] pci_bus 0000:00: root bus resource [mem 0x10000000-0x11ffffff]
[    0.340000] pci_bus 0000:00: root bus resource [io  0x0000]
[    0.350000] Switching to clocksource MIPS
[    0.350000] NET: Registered protocol family 2
[    0.360000] IP route cache hash table entries: 1024 (order: 0, 4096 bytes)
[    0.360000] TCP established hash table entries: 4096 (order: 3, 32768 bytes)
[    0.370000] TCP bind hash table entries: 4096 (order: 2, 16384 bytes)
[    0.370000] TCP: Hash tables configured (established 4096 bind 4096)
[    0.380000] TCP reno registered
[    0.380000] UDP hash table entries: 256 (order: 0, 4096 bytes)
[    0.390000] UDP-Lite hash table entries: 256 (order: 0, 4096 bytes)
[    0.390000] NET: Registered protocol family 1
[    0.410000] squashfs: version 4.0 (2009/01/31) Phillip Lougher
[    0.420000] JFFS2 version 2.2 (NAND) (SUMMARY) (ZLIB) (LZO) (LZMA) (RTIME) (C                                                                                             MODE_PRIORITY) (c) 2001-2006 Red Hat, Inc.
[    0.430000] msgmni has been set to 246
[    0.430000] io scheduler noop registered
[    0.430000] io scheduler deadline registered (default)
[    0.440000] Serial: 8250/16550 driver, 1 ports, IRQ sharing disabled
[    0.470000] serial8250.0: ttyS0 at MMIO 0x18020000 (irq = 11) is a 16550A
[    0.470000] console [ttyS0] enabled, bootconsole disabled
[    0.470000] console [ttyS0] enabled, bootconsole disabled
[    0.490000] m25p80 spi0.0: found en25qh128a, expected m25p80
[    0.490000] m25p80 spi0.0: en25qh128a (16384 Kbytes)
[    0.500000] 13 cmdlinepart partitions found on MTD device spi0.0
[    0.500000] Creating 13 MTD partitions on "spi0.0":
[    0.510000] 0x000000000000-0x000000040000 : "u-boot"
[    0.520000] 0x000000040000-0x000000050000 : "u-boot-env"
[    …</bio-0></redacted></redacted></pre></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://illumo.com/tearing-apart-the-wyze-outdoor-cam-base-station/">https://illumo.com/tearing-apart-the-wyze-outdoor-cam-base-station/</a></em></p>]]>
            </description>
            <link>https://illumo.com/tearing-apart-the-wyze-outdoor-cam-base-station/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404931</guid>
            <pubDate>Tue, 08 Sep 2020 03:19:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First impressions of NEAR smart contract development in Rust]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24404830">thread link</a>) | @brson
<br/>
September 7, 2020 | https://brson.github.io/2020/09/07/near-smart-contracts-rust | <a href="https://web.archive.org/web/*/https://brson.github.io/2020/09/07/near-smart-contracts-rust">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Rust is increasingly used as a programming language for smart contracts.
Whereas the first generation blockchains used specialized VMs,
newer blockchains are running general purpose VMs,
especially <a href="https://webassembly.org/">WASM</a>.
And of course,
Rust is a modern language that runs just about everywhere,
and is especially good at targetting WASM.
Somewhat serendipitously,
this has made Rust one of the best candidate languages for writing
smart contracts on the new generation of blockchains.</p>

<p>Lately I’ve been learning more about the smart contract programming landscape,
and this post is about my first dive into smart contract programming in
Rust on the <a href="https://github.com/nearprotocol/nearcore">NEAR</a> platform.</p>

<p>NEAR is a sharded, proof-of-stake blockchain that runs WASM.
It not only supports smart contracts written in Rust
(in addition to <a href="https://www.assemblyscript.org/">AssemblyScript</a>),
but is also itself written in Rust.
While one the most prominent Rust blockchain projects,
it is perhaps not yet widely known in the broader blockchain development community.</p>

<p>Based on my experiences here though,
I’m quite enthusiastic about the NEAR developer experience,
and I intend to spend more time hacking on NEAR.</p>

<p>These are my first impressions of NEAR,
as someone with moderate knowledge of blockchains,
but limited previous blockchain programing experience.
I have previously written similarly about my first experiences
with other blockchains: <a href="https://talk.nervos.org/t/experience-report-first-time-building-and-running-ckb/4518/">Nervos</a>, <a href="https://github.com/Aimeedeer/bigannouncement/blob/master/doc/hacklog.md">Ethereum</a>.</p>

<h2 id="starting-at-the-start-of-the-docs">Starting at the start of the docs</h2>

<p>The <a href="https://docs.near.org/">NEAR documentation</a> seems refreshingly thorough,
if a bit confusing to navigate.
There are different docs to follow depending on your role in the network,
whether a validator,
smart contract programmer,
etc.
and I find myself jumping between multiple sections,
without quite understanding how the docs are organized overall,
perhaps because there isn’t a single table of contents that covers the entire site.</p>

<p>Anyway, after browsing the docs to get a general idea of their organization,
I go back to the front page and I click “Basics”.
This seems to be leading me down the path of being a smart contract developer,
not running my own local node,
not building NEAR itself.</p>

<p>For sake of understanding,
I generally want to build the entire stack I’m working on,
but for now I’m going to follow the docs exactly and see where that gets me,
and not build NEAR on my own.</p>

<h2 id="account-creation">Account creation</h2>

<p>Setting up an account is done through a web interface at:</p>

<blockquote>
  <p><a href="https://wallet.testnet.near.org/">https://wallet.testnet.near.org/</a></p>
</blockquote>

<p>I create a testnet account,
<code>floopy.testnet</code>,
and a recovery phrase.</p>

<p>The NEAR explorer page for my account is</p>

<blockquote>
  <p><a href="https://explorer.testnet.near.org/accounts/floopy.testnet">https://explorer.testnet.near.org/accounts/floopy.testnet</a></p>
</blockquote>

<p>Instead of a hash for an ID,
as in most blockchains,
you get an actual string name.
And the system can optionally do account recovery over email or phone.
While this is convenient, it seems suspiciously centralized for a public blockchain,
and I wonder if it is possible to create accounts without any central authority.
I imagine it is, and this website is mostly a convenience, but don’t know yet.</p>

<h2 id="installation">Installation</h2>

<p>Following <a href="https://docs.near.org/docs/development/near-cli">the docs</a>, I install <code>near-cli</code>, a Node app.</p>

<div><div><pre><code>$ npm install -g near-cli
/home/ubuntu/.nvm/versions/node/v12.16.2/bin/near -&gt; /home/ubuntu/.nvm/versions/node/v12.16.2/lib/node_modules/near-cli/bin/near

&gt; node-hid@1.3.0 install /home/ubuntu/.nvm/versions/node/v12.16.2/lib/node_modules/near-cli/node_modules/node-hid
&gt; prebuild-install || node-gyp rebuild


&gt; usb@1.6.3 install /home/ubuntu/.nvm/versions/node/v12.16.2/lib/node_modules/near-cli/node_modules/usb
&gt; prebuild-install --verbose || node-gyp rebuild

prebuild-install info begin Prebuild-install version 5.3.5
prebuild-install info looking for cached prebuild @ /home/ubuntu/.npm/_prebuilds/f5a2d7-usb-v1.6.3-node-v72-linux-x64.tar.gz
prebuild-install http request GET https://github.com/tessel/node-usb/releases/download/v1.6.3/usb-v1.6.3-node-v72-linux-x64.tar.gz
prebuild-install http 200 https://github.com/tessel/node-usb/releases/download/v1.6.3/usb-v1.6.3-node-v72-linux-x64.tar.gz
prebuild-install info downloading to @ /home/ubuntu/.npm/_prebuilds/f5a2d7-usb-v1.6.3-node-v72-linux-x64.tar.gz.26621-920b88608b4cf.tmp
prebuild-install info renaming to @ /home/ubuntu/.npm/_prebuilds/f5a2d7-usb-v1.6.3-node-v72-linux-x64.tar.gz
prebuild-install info unpacking @ /home/ubuntu/.npm/_prebuilds/f5a2d7-usb-v1.6.3-node-v72-linux-x64.tar.gz
prebuild-install info unpack resolved to /home/ubuntu/.nvm/versions/node/v12.16.2/lib/node_modules/near-cli/node_modules/usb/build/Release/usb_bindings.node
prebuild-install info unpack required /home/ubuntu/.nvm/versions/node/v12.16.2/lib/node_modules/near-cli/node_modules/usb/build/Release/usb_bindings.node successfully
prebuild-install info install Successfully installed prebuilt binary!
</code></pre></div></div>

<p>Semes to work fine.</p>

<p>From previous doc reading I know that running a full node typically involves running <a href="https://github.com/near/nearup">nearup</a>.
It appears though that I don’t need that now,
so probably for the purposes of developing on near,
<code>near-cli</code> will just talk to existing public nodes.</p>

<p>At this point I seem to hit the end of the “basics” documentation flow,
without really accomplishing anything,
but I remember <a href="https://docs.near.org/docs/quick-start/new-to-near#how-do-i-get-started">from the beginning of these docs</a> that “choose a starter project”
is step 2.</p>

<p>I back up and choose the <a href="https://examples.near.org/rust-status-message"><code>rust-status-message</code></a> starter project.</p>

<h2 id="running-a-contract">Running a contract</h2>

<p>The examples say to install <code>near-shell</code>,
but that project has been renamed to <code>near-cli</code>.
I see that there are already PRs submitted to fix this,
but they are about a month old.
There are a number of relatively old PRs in NEAR repos that haven’t been reviewed.</p>

<p>I clone the example:</p>

<div><div><pre><code>$ git clone https://github.com/near-examples/rust-status-message
$ cd rust-status-message
</code></pre></div></div>

<p>And build per the instructions:</p>



<p>This is an npm build that wraps a cargo build.
I’m curious if there’s any JavaScript involved,
but I suspect they are just using npm as the primary interface
for the sake of familiarity and for consistency with
the build process for AssemblyScript smart contracts.</p>

<p>Looking at <code>package.json</code> it’s true that npm isn’t doing much here,
but it <em>is</em> adding a post-build step that cargo is incapable of:</p>

<div><div><pre><code><span>  </span><span>"scripts"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"build"</span><span>:</span><span> </span><span>"cargo build --target wasm32-unknown-unknown --release"</span><span>,</span><span>
    </span><span>"postbuild"</span><span>:</span><span> </span><span>"cp target/wasm32-unknown-unknown/release/status_message.wasm ./res/"</span><span>
  </span><span>}</span><span>,</span><span>
</span></code></pre></div></div>

<p>There is an error in the build:</p>

<div><div><pre><code>error[E0463]: can't find crate for `core`
  |
  = note: the `wasm32-unknown-unknown` target may not be installed

error: aborting due to previous error

For more information about this error, try `rustc --explain E0463`.
error: could not compile `byte-tools`.
warning: build failed, waiting for other jobs to finish...
error: build failed
npm ERR! code ELIFECYCLE
npm ERR! errno 101
npm ERR! rust-status-message-builder@1.0.0 build: `cargo build --target wasm32-unknown-unknown --release`
npm ERR! Exit status 101
npm ERR!
npm ERR! Failed at the rust-status-message-builder@1.0.0 build script.
npm ERR! This is probably not a problem with npm. There is likely additional logging output above.
npm WARN Local package.json exists, but node_modules missing, did you mean to install?

npm ERR! A complete log of this run can be found in:
npm ERR!     /home/ubuntu/.npm/_logs/2020-09-06T22_44_16_397Z-debug.log
</code></pre></div></div>

<p>This is an easy error to understand to somebody familiar with embedded Rust development,
but probably not to other newbies.
The toolchain just doesn’t have the <code>wasm32-unknown-unknown</code> target installed.
I don’t know if I missed the documentation that explained this,
but the user experience here could be better.</p>

<p>I add the wasm target:</p>

<div><div><pre><code>$ rustup target add wasm32-unknown-unknown
info: downloading component 'rust-std' for 'wasm32-unknown-unknown'
info: installing component 'rust-std' for 'wasm32-unknown-unknown'
</code></pre></div></div>

<p>After that the build works:</p>

<div><div><pre><code>$ npm run build

&gt; rust-status-message-builder@1.0.0 build /home/ubuntu/near/rust-status-message
&gt; cargo build --target wasm32-unknown-unknown --release

   Compiling near-sdk v0.11.0
   Compiling status-message v0.1.0 (/home/ubuntu/near/rust-status-message)
    Finished release [optimized] target(s) in 3.99s

&gt; rust-status-message-builder@1.0.0 postbuild /home/ubuntu/near/rust-status-message
&gt; cp target/wasm32-unknown-unknown/release/status_message.wasm ./res/
</code></pre></div></div>

<p>I try to deploy to the testnet using a temporary developer account:</p>

<div><div><pre><code>$ near dev-deploy --wasmFile res/status_message.wasm --helperUrl https://near-contract-helper.onrender.com
We would like to collect data on near-cli usage to improve developer experience. We will never send private information. We only collect which commands are run via an anonymous identifier. Would you like to opt in (y/n)?
</code></pre></div></div>

<p>NEAR wants me to opt in to telemetry.
I’m sympathetic,
but since this command presumably will have access to private keys,
I’m not confident that the developers have been suitably careful
about avoiding collection of private data.
For now I say “n”, until I can review that code.</p>

<p>The command continues:</p>

<div><div><pre><code>$ near dev-deploy --wasmFile res/status_message.wasm --helperUrl https://near-contract-helper.onrender.com
We would like to collect data on near-cli usage to improve developer experience. We will never send private information. We only collect which commands are run via an anonymous identifier. Would you like to opt in (y/n)? n
Starting deployment. Account id: dev-1599433413131-7008906, node: https://rpc.testnet.near.org, helper: https://near-contract-helper.onrender.com, file: res/status_message.wasm
Transaction Id 6cT3Su1BTo52i1EwSgaD6Wm9mTvA8238PWQmUFYPkS11
To see the transaction in the transaction explorer, please open this url in your browser
https://explorer.testnet.near.org/transactions/6cT3Su1BTo52i1EwSgaD6Wm9mTvA8238PWQmUFYPkS11
Done deploying to dev-1599433413131-7008906
</code></pre></div></div>

<p><code>near dev-deploy</code> has apparently created a script <code>neardev/dev-account.env</code>
that will set the <code>CONTRACT_NAME</code> environment variable to my
temporary account id, <code>dev-1599433413131-7008906</code>.
I call it with <code>source neardev/dev-account.env</code>.</p>

<p>I call <code>near call</code> to set the status message in the contract:</p>

<div><div><pre><code>$ near call $CONTRACT_NAME set_status …</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://brson.github.io/2020/09/07/near-smart-contracts-rust">https://brson.github.io/2020/09/07/near-smart-contracts-rust</a></em></p>]]>
            </description>
            <link>https://brson.github.io/2020/09/07/near-smart-contracts-rust</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404830</guid>
            <pubDate>Tue, 08 Sep 2020 02:54:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[URL query parameters and how laxness creates de facto requirements on the web]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 46 (<a href="https://news.ycombinator.com/item?id=24404814">thread link</a>) | @oftenwrong
<br/>
September 7, 2020 | https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>URL query parameters and how laxness creates de facto requirements on the web</h2>

	<p><small>September  7, 2020</small></p>
</div><div><p>One of the ways that <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a> (the code behind <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a>) is unusual is that it strictly validates the query parameters
it receives on URLs, including on HTTP <code>GET</code> requests for ordinary
pages. If a HTTP request has unexpected and unsupported query
parameters, such a <code>GET</code> request will normally fail. When I made
this decision it seemed the cautious and conservative approach, but
<a href="https://utcc.utoronto.ca/~cks/space/blog/web/CautionIsAMistakeToday">this caution has turned out to be a mistake on the modern web</a>. In practice, all sorts of sites will
generate versions of your URLs with all sorts of extra query
parameters tacked on, give them to people, and expect them to work.
If your website refuses to play along, (some) people won't get to
see your content. <strong>On today's web, you need to accept (and then
ignore) arbitrary query parameters on your URLs</strong>.</p>

<p>(Today's new query parameter is 's=NN', for various values of NN
like '04' and '09'. I'm not sure what's generating these URLs, but
it may be Slack.)</p>

<p>You might wonder how we got here, and that is a story of lax behavior
(or, if you prefer, being liberal in what you accept). In the
beginning, both Apache (for static web pages) and early web
applications often ignored extra query parameters on URLs, at least
on <code>GET</code> requests. I suspect that other early web servers also
imitated Apache here, but I have less exposure to their behavior
than Apache's. My guess is that this behavior wasn't deliberate,
it was just the simplest way to implement both Apache and early
web applications; you paid attention to what you cared about and
didn't bother to explicitly check that nothing else was supplied.</p>

<p>When people noticed that this behavior was commonplace and widespread,
they began using it. I believe that one of the early uses was for
embedding 'where this link was shared' information for your own web
analytics (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/AnalyticsVsSecurity">cf</a>), either based on your logs
or using JavaScript embedded in the page. In the way of things,
once this was common enough other people began helpfully tagging
the links that were shared through them for you, which is why I
began to see various 'utm_*' query parameters on inbound
requests to <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a> even though I never
published such URLs.
Web developers don't leave attractive nuisances alone for long, so
soon enough people were sticking on extra query parameters to your
URLs that were mostly for them and not so much for you. Facebook
may have been one of the early pioneers here with their 'fbclid'
parameter, but other websites have hopped on this particular train
since then (as I saw recently with these 's=NN' parameters).</p>

<p>At this point, the practice of other websites and services adding
random query parameters to your URLs that pass through them is so
wide spread and common that accepting random query parameters is
pretty much a practical requirement for any web content serving
software that wants to see wide use and not be irritating to the
people operating it. If, like <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a>, you stick to your guns and
refuse to accept some or all of them, you will drop some amount of
your incoming requests from real people, disappointing would be
readers.</p>

<p>This practical requirement for URL handling is not documented in
any specification, and it's probably not in most 'best practices'
documentation. People writing new web serving systems that are
tempted to be strict and safe and cautious get to learn about it
the hard way.</p>

<p>In general, any laxness in actual implementations of a system can
create a similar spiral of de facto requirements. Something that
is permitted and is useful to people will be used, and then supporting
that becomes a requirement. This is especially the case in a
distributed system like the web, where any attempt to tighten the
rules would only be initially supported by a minority of websites.
These websites would be 'outvoted' by the vast majority of websites
that allow the lax behavior and support it, because that's what
happens when the vast majority work and the minority don't.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404814</guid>
            <pubDate>Tue, 08 Sep 2020 02:50:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to negotiate a higher salary and why you should]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24404769">thread link</a>) | @yacc79
<br/>
September 7, 2020 | https://www.dollartrak.com/negotiate-salary-to-achieve-your-financial-goals/ | <a href="https://web.archive.org/web/*/https://www.dollartrak.com/negotiate-salary-to-achieve-your-financial-goals/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
<p>Many people concentrate on saving and investing as a way to achieve their financial goals.  Both of these are easier to grow with a higher income.  No matter what your <a href="https://www.dollartrak.com/set-and-achieve-financial-goals/">financial goals</a> are, negotiating a higher salary will make them easier to achieve.</p>



<p>The time you spend researching your fair market value, preparing requests for raises, and making requests for adjustments might very well be the most valuable use of your time.</p>



<p>Considering the importance of salary you would think that people would constantly be on top of their market value ensuring they are compensated fairly.  In my experience this is often not the case.</p>



<h2>Many People are Underpaid and Don’t Even Know it</h2>



<p>Like most people I knew, I never talked about my salary with my friends or co-workers.  It’s taboo for many Americans.  This lack of transparency makes it easy to be underpaid while being unaware of it.  This benefits your employer, but not you!</p>



<p>Once I took on a senior leadership position I begun to understand the severity of differences in how people are compensated for similar positions.  In some cases employees with the same job title were compensated double what others were.</p>



<p>I am sure that most people are aware these inequities exist and might blame them on <a href="https://www.wsj.com/articles/study-finds-salary-history-bans-boost-pay-for-african-americans-women-11592472602?mod=e2fb" target="_blank" rel="noreferrer noopener">discrimination</a>, differences in quality of work, education or level of education.  In my experience a lack of salary negotiation and keeping their salary up to date is the main driver. </p>



<p>Negotiating your salary can be uncomfortable, and asking for raises can be even more so.  This doesn’t mean you shouldn’t do it though!  Many will shy away from it and those that do not will end up making much more money over time to do the same job.</p>



<h2>Increases in Salary Compound Over Your Career</h2>



<p>As people get further along in their careers these differences can grow to nearly overwhelming numbers.  Employees can literally make over double what others make for the same job.  This is because of the compounding nature of raises on your salary over the course of your career.</p>



<p>Raises are generally given on a percentage basis of your current salary.  What this means is every single time you get a raise you are also getting a raise on all of your previous raises.  This adds up the same way compound interest adds up.  Over time the numbers can get large and with a 40 year long career for many there can be a lot of time for this to happen.</p>



<h2>Examples of Compounding Salary</h2>



<p>Lets look at a few simple scenarios over a 20 year job with a company.  The first scenario shows the affect of negotiating a higher starting salary and the second one shows the affect of negotiating occasional large raises.</p>



<h3>Affect of Negotiating a Higher Starting Salary</h3>



<p>Jack and Jill both were offered the same job, but Jill negotiated a very modest 10% higher salary than Jack.  They both did well and received 3% raises over the course of 20 years working for the company.</p>



<figure><table><tbody><tr><td></td><td>Base</td><td>Year 5</td><td>Year 10</td><td>Year 15</td><td>Year 20</td><td>Total</td></tr><tr><td>Jack</td><td>$45000</td><td>$52,167</td><td>$60,476</td><td>$70,108</td><td>$81,275</td><td>$1.29M</td></tr><tr><td>Jill</td><td>$50,000</td><td>$57,963</td><td>$67,195</td><td>$77,898</td><td>$90,305</td><td>$1.43M</td></tr></tbody></table><figcaption>3% annual raises over 20 years</figcaption></figure>



<p>The $5,000 starting difference turns into a little over $9,000 a year difference over 20 years.  This resulted in Jill making an extra $140,000 over the course of her job with this company.</p>



<h3>Affects of Negotiating Larger Raises</h3>



<p>Here we will modify the above table to show Jill negotiating a 10% raise for herself every 5 years while Jack happily accepts the standard 3%.</p>



<figure><table><tbody><tr><td></td><td>Base</td><td>Year 5</td><td>Year 10</td><td>Year 15</td><td>Year 20</td><td>Total</td></tr><tr><td>Jack</td><td>$45000</td><td>$52,167</td><td>$60,476</td><td>$70,108</td><td>$81,275</td><td>$1.29M</td></tr><tr><td>Jill</td><td>$50,000</td><td>$61,903</td><td>$76,640</td><td>$94,884</td><td>$117,473</td><td>$1.63M</td></tr></tbody></table><figcaption>3% annual raises over 20 years, Jill get’s 10% every 5 years</figcaption></figure>



<p>After 20 years with a salary of $81,275 jack would need a whopping 45% raise just to catch up to Jill and still would be behind by $340,000 in lifetime earnings!</p>



<h2>How do I Keep My Salary Up to Date</h2>



<h3>Know Your Fair Market Value</h3>



<p>This always starts with knowing what your fair market value is.  There are several websites that can help here.  I like <a rel="noreferrer noopener" href="https://www.glassdoor.com/" target="_blank">Glassdoor</a> and <a rel="noreferrer noopener" href="https://www.salary.com/" target="_blank">Salary.com</a>.  Do a little research and come up with a range that you feel is reasonable.  </p>



<figure><img loading="lazy" width="640" height="548" src="https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/image.png?resize=640%2C548&amp;ssl=1" data-src="https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/image.png?resize=640%2C548&amp;ssl=1" alt="salary chart" data-srcset="https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/image.png?w=731&amp;ssl=1 731w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/image.png?resize=300%2C257&amp;ssl=1 300w" data-sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"><figcaption>Taken from salary.com</figcaption></figure>



<p>You should be honest with yourself about your skills and experience, but I recommend starting at the high end of the range and working down from there.  If someone else can make $100,000 a year doing your job, why not you?</p>



<h3>Getting Your Salary Right to Start</h3>



<p>In my experience the majority of people will accept the first salary offer given.  This is generally a mistake.  Why would a hiring manager make you his absolute top dollar offer to start?  He is generally wise to leave a little room for negotiation for the candidates that do counteroffer.  Some candidates will want to counteroffer no matter what you offer them first!</p>



<p>Once you accept a lower salary it is VERY difficult to get it corrected.  You may have some success here at smaller companies but with larger companies and their bureaucracy don’t get your hopes up.  In my experience the best way to fix this is to find a new job.  You can avoid it by knowing your market value and negotiating a proper base to start.</p>



<h3>Constantly Update Skills</h3>



<p>The job market is always changing.  You need to keep up with it and try to stay out in front of it to maximize your earning potential.  Whatever field you are in set annual goals to achieve certifications, complete continuing education, learn a new tool or attend a conference.  </p>



<p>While one of these things by itself may not change your career, the culmination of annual self improvement over 5 to 10 years can make a massive difference in your marketability.  Senior level employees with relevant certifications and experience can be worth many times what an entry level employee is.</p>



<h3>Take Advantage of Your Time at Work</h3>



<p>You are going to be there for 8 hours a day so you might as well make the most of it.  Always seek out new projects that allow you to learn and develop your skills.  Ask about company paid training, certification or tuition.  Look for ways to add value above and beyond normal for your task.</p>



<p>Most employers will provide you with the tools, money or time to improve your skills because it directly benefits them.  If they won’t help you out here, you may want to re-consider if working there is good for your long term success.</p>



<h3>Write Down Accomplishments as They Happen</h3>



<p>Many companies do a once per year salary adjustment.  Isn’t it basically impossible to remember what all you did when walking into this conversation?</p>



<figure><img loading="lazy" width="640" height="426" src="https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/checklist.jpg?resize=640%2C426&amp;ssl=1" data-src="https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/checklist.jpg?resize=640%2C426&amp;ssl=1" alt="checklist" data-srcset="https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/checklist-scaled.jpg?resize=1024%2C681&amp;ssl=1 1024w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/checklist-scaled.jpg?resize=300%2C200&amp;ssl=1 300w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/checklist-scaled.jpg?resize=768%2C511&amp;ssl=1 768w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/checklist-scaled.jpg?resize=1536%2C1022&amp;ssl=1 1536w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/checklist-scaled.jpg?resize=2048%2C1363&amp;ssl=1 2048w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/checklist-scaled.jpg?w=1280&amp;ssl=1 1280w, https://i1.wp.com/www.dollartrak.com/wp-content/uploads/2020/06/checklist-scaled.jpg?w=1920&amp;ssl=1 1920w" data-sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1"><figcaption>Keep a running list of your accomplishments</figcaption></figure>



<p>The best way to remember it all is to write it down as it happens.  Keep a running log of your accomplishments. Write them all down and come into the annual review process armed with the information you need.</p>



<h3>Frequently Update Your Fair Market Value</h3>



<p>Your fair market value is likely always changing.  Make sure to check the websites and understand if you are compensated fairly on a regular basis.  Always do this before an annual review.  </p>



<p>If the market has shifted for your skill set, or a new skill you learned is valuable, make sure your employer knows!  This is the time to ask for a larger than standard raise.  That new certification you acquired could be a great reason to go after a 5 or 10% raise this year.</p>



<h2>Asking for an Adjustment When You are Underpaid</h2>



<p>If you want to stick it out with your company, but found that you were underpaid you will need to ask for an adjustment to market value.  I find that the request should have the following basic supporting documentation:</p>



<ol><li>Report’s on salary range for your job from multiple sources.  If you are underpaid, show them multiple sources that validate this.  The more you can find the better.</li><li>Detail any recent skills you have developed or certifications that you have obtained. </li><li>List of recent accomplishments at work that show you have gone above and beyond.  You have been keeping the list like I recommend above right?</li></ol>



<p>I have asked for larger raises(&gt;10%) multiple times in my career and always gotten what I wanted by using the above method.  I have also been asked for raises by quite a few employees over the years.  Those with accompanying documentation like above were taken much more seriously.</p>



<h2>Leave If Your Employer Doesn’t Value You Correctly</h2>



<p>Some employers will never pay you fair market value.  This could be because they don’t value you fairly or because they don’t need the skills you have.  They may also just not have the money in the budget for someone of your skill level.  </p>



<p>Don’t let their decisions hold you back.  If they won’t pay you fairly then be prepared to get up and leave.  If you have been updating your skills regularly as I mentioned above you may find that moving to a better position is surprisingly easy.</p>



<h2>Conclusion</h2>



<p>I hope this has shed a little light onto the importance of salary negotiations when being hired and frequently during the course of your career.  If you ignore these conversations because they can be uncomfortable you will pay dearly for it over the long term.  </p>



<p>Ultimately, your <a href="https://www.dollartrak.com/2020/06/09/net-worth-explained/">net worth</a> can be dramatically reduced and result in you having to work for many extra years in order to meet your <a href="https://www.dollartrak.com/set-and-achieve-financial-goals/">financial goals</a>.  You should take charge of this part of your career before you look back and wish you had.</p>

			</div></div>]]>
            </description>
            <link>https://www.dollartrak.com/negotiate-salary-to-achieve-your-financial-goals/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404769</guid>
            <pubDate>Tue, 08 Sep 2020 02:40:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git/serve: A Git server for Plan 9]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24404681">thread link</a>) | @todsacerdoti
<br/>
September 7, 2020 | https://orib.dev/gitserve.html | <a href="https://web.archive.org/web/*/https://orib.dev/gitserve.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>A while ago, I released <a href="https://orib.dev/git9.html">git9</a>, a git client for
Plan 9. However, it always felt like it was missing something: A git server.
over a few weekends of work, I sat down and put one together. This Labor
Day weekend, I took the opportunity to labor on it, and got something working.</p>

<h3>usage</h3>

<p><code>Git/serve</code> is a git server designed to fit into the Plan
9 ecosystem, allowing hosting of, and interacting with, code on a Plan 9
server, while still allowing legacy clients running on Unix to get a copy
of the code.</p>

<p><code>Git/serve</code> only speaks the <code>git://</code> protocol.
But because it runs behind
<a href="http://man.9front.org/8/listen">aux/listen</a>
and 
<a href="http://man.9front.org/8/tlssrv"><code>tlssrv</code></a>, we
effectively get two additional protocols for free: <code>gits://</code>, or
TLS-encrypted <code>git://</code>, and <code>hjgit://</code>, which is
<code>git://</code> but with Plan 9 authentication to support user login
over TLS. Unfortunately, only the unencrypted <code>git://</code> protocol
is supported out of the box by upstream git. There may be ways to solve
this, using <a href="https://rovaughn.github.io/2015-2-9.html">custom
transports</a>, and a unix port of tlsclient</p>

<p>To start a <code>git://</code> server, just run it under aux/listen1.
To enable encryption and user authentication, run it under
<code>tlssrv -a</code>. This doesn't need a certificate, because
the Plan 9 authentication generates the secret used for TLS. And,
finally, if you just want encryption, you can use <code>tlsclient</code>
with a certificate.</p>

<pre># git:// server, serving every repository under the current directory
% aux/listen1 'tcp!*!9418' git/serve -r `{pwd}

# gits:// server, doing the same: But with encryption.
% aux/listen1 'tcp!*!9418' tlsclient -c /path/to/cert.pem git/serve -r `{pwd}

# hjgit:// server doing the same: Requires account on server to connect
% aux/listen1 'tcp!*!9418' tlsclient -a git/serve -r `{pwd}
</pre>

<p>If you want to allow people to write, you can just add the
<code>-w</code> flag to git/serve. While you can do this on
any of the protocols, keep in mind that only <code>hjgit://</code>
authenticates the users. Push to the world, but don't let the
world push to you!</p>



<p>All the protocols git uses are closely related. The <code>ssh://</code>
protocol is just the <code>git://</code> protocol, with the command selected
sightly differently. The smart <code>http://</code> protocols are the same
as the <code>git://</code> protocol, with a different handshake, and split
over multiple post requests.</p>

<p>Git9 implements the git protocol in under 500 lines of C. The
full code is available on github, in
<a href="https://github.com/oridb/git9/blob/1770b8f94bb1d97fdeb6f7db293ed36da9751826/serve.c">serve.c</a>.
</p>

<p>The protocol look something like this for pushing:</p>

<pre>&lt;=w= 0030:	"git-fetch-pack /oridb/git9\0host=github.com\n"
=r=&gt; 0086:	"747e9e80f710c0b8bbd928080745915ad2493322 HEAD\n"
=r=&gt; 009d:	"747e9e80f710c0b8bbd928080745915ad2493322 refs/heads/master\n"
&lt;=w= 0076:	"747e9e80f710c0b8bbd928080745915ad2493322 dc802c499dc7164aa208b919a07c5bd18701b0e1 refs/heads/master\0report-status\n"
&lt;=w= 0000
&lt;=w= <pack-data>
=r=&gt; 000e:	unpack ok
=r=&gt; 0019:	ok refs/heads/master
</pack-data></pre>

<p>And this for pulling:</p>

<pre>&lt;=w= 0030:	"git-upload-pack /oridb/git9\0host=github.com\n"
=r=&gt; 013b:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 HEAD\n"
=r=&gt; 003f:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 refs/heads/master\n"
=r=&gt; 0000
&lt;=w= 0032:	"want 5d761590cfdce23e4b17e94050b0776c8804d4a1\n"
&lt;=w= 0032:	"want 8f0eb1386a2c748cb7bf26917684479ff8c6d5b5\n"
&lt;=w= 0032:	"want dc4a9d467c6a28dab3927c8611a1bfbc571f1568\n"
&lt;=w= 0000
&lt;=w= 0033:	"have dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
&lt;=w= 0009:	"done\n"
=r=&gt; 0031:	"ACK dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
<pack-data>
</pack-data></pre>

<p>The git protocol consists of pkt-lines, which are strings with a
hex-formatted length prefix.  The length prefix includes itself.  So,
the string <code>"hi"</code> would be formatted as
<code>0006hi</code>. A zero lenth packet where the length prefix
is not included is special. This is called a 'flush packet', and
is used to terminate a phase of negotiation.</p>

<p> All negotiation is with these packet lines, at
which git flips over to pure binary mode to transfer a pack file
over.</p>

<p>In the <code>git://</code> protocol, the client always starts off
by saying which action it wants to do: Either it wants the server to
fetch a pack from the client, or it wants the server to upload a pack
to the client.  That's this line:</p><pre>&lt;=w= 0030:	"git-fetch-pack /oridb/git9\0host=github.com\n"
</pre>

<p>The upload side of this protocol is simpler on the server side so
we'll go through it first.</p>

<h3>pushing</h3>

<p>In the upload protocol, the server begins by sending a list of
references that the client may update. In <code>git/serve</code>
we grab all the refs in the repository, and filter down to just
the ones beginning with <code>heads/</code>.</p>

<pre>	if((nrefs = listrefs(&amp;refs, &amp;names)) == -1)
		sysfatal("listrefs: %r");
	for(i = 0; i &lt; nrefs; i++){
		if(strncmp(names[i], "heads/", strlen("heads/")) != 0)
			continue;
		if(fmtpkt(c, "%H refs/%s\n", refs[i], names[i]) == -1)
			goto error;
	}
	if(flushpkt(c) == -1)
		goto error;
</pre>

<p>With the first phase of the protocol, the client then
sends the list of references it wants to update. This
takes the form of:</p>

<pre>	OLDHASH NEWHASH heads/refs/updateme\n"
</pre>

<p>Because the client knows what the reference versions are on
the server, it can compute what commits are between the version
on the server and the version that it has. If the new hash
is the zero hash, this signals to the server that the reference
should be deleted. This list of updates is terminated with a
flush packet. The code in git9 that handles this is below:

</p><pre>	while(1){
		/* Did we get a packet? */
		if((n = readpkt(c, pkt, sizeof(pkt))) == -1)
			goto error;
		/* Was it a flush packet? */
		if(n == 0)
			break;
		/* Split it up into the 3 parts: old, new, reference */
		if(getfields(pkt, sp, nelem(sp), 1, " \t\n\r") != 3){
			fmtpkt(c, "ERR  protocol garble %s\n", pkt);
			goto error;
		}
		/* verify that these are valid hashes */
		if(hparse(&amp;old, sp[0]) == -1){
			fmtpkt(c, "ERR bad old hash %s\n", sp[0]);
			goto error;
		}
		if(hparse(&amp;new, sp[1]) == -1){
			fmtpkt(c, "ERR bad new hash %s\n", sp[1]);
			goto error;
		}
		/* and valid refs */
		if(!validref(sp[2])){
			fmtpkt(c, "ERR invalid ref %s\n", sp[2]);
			goto error;
		}
		/* and then remember them for when we do the update */
		*cur = erealloc(*cur, (*nupd + 1)*sizeof(Hash));
		*upd = erealloc(*upd, (*nupd + 1)*sizeof(Hash));
		*ref = erealloc(*ref, (*nupd + 1)*sizeof(Hash));
		(*cur)[*nupd] = old;
		(*upd)[*nupd] = new;
		(*ref)[*nupd] = estrdup(sp[2]);
		*nupd += 1;
	}
</pre>

<p>Next, the client uploads the pack. This is a blob containing
the commit data. It goes into <code>.git/objects/packs/recv-$pid.pack</code>,
at least until we can index it and rename it.</p>

<pre>	while(1){
		n = read(c-&gt;rfd, buf, sizeof(buf));
		if(n == 0)
			break;
		if(n == -1 || write(pfd, buf, n) != n)
			return -1;
		packsz += n;
	}
	if(checkhash(pfd, packsz, &amp;h) == -1){
		dprint(1, "hash mismatch\n");
		goto error1;
	}
	if(indexpack(packtmp, idxtmp, h) == -1){
		dprint(1, "indexing failed\n");
		goto error1;
	}
	if(rename(packtmp, idxtmp, h) == -1){
		dprint(1, "rename failed: %r\n");
		goto error2;
	}
</pre>

<p>Finally, we update the references. Note that we haven't
locked the repository yet. This is because none of the data
we have here can conflict: All objects are addressed by hash,
so a race would simply leave us with a duplicate hash in the
packfile. Eventually, a <code>git/repack</code> will clean
that up.</p>

<p>However, updating the references can conflict. So,
for updating the references, we acquire a lock file.
We then read all the references, make sure that they
match the old reference, and then write in the new
reference.</p>

<pre>	for(i = 0; i &lt; nupd; i++){
		if(resolveref(&amp;h, ref[i]) == 0 &amp;&amp; !hasheq(&amp;h, &amp;cur[i])){
			fmtpkt(c, "ERR old ref changed: %s", ref[i]);
			goto error;
		}
		if((o = readobject(upd[i])) == nil){
			fmtpkt(c, "ERR update to nonexistent hash %H", upd[i]);
			goto error;
		}
		if(o-&gt;type != GCommit){
			fmtpkt(c, "ERR not commit: %H", upd[i]);
			goto error;
		}
		unref(o);
		if(snprint(refpath, sizeof(refpath), ".git/%s", ref[i]) == sizeof(refpath)){
			fmtpkt(c, "ERR ref path too long: %s", ref[i]);
			goto error;
		}
		if((fd = create(refpath, OWRITE, 0644)) == -1){
			fmtpkt(c, "ERR open ref: %r");
			goto error;
		}
		if(fprint(fd, "%H", upd[i]) == -1){
			close(fd);
			fmtpkt(c, "ERR upate ref: %r");
			goto error;
		}
		close(fd);
	}
</pre>

<p>And that's pushing.

</p><h3>pulling</h3>

<p>Pulling takes more work on the server side, because the
server needs to compute a reasonable packfile to send to
the client. The protocol itself is still fairly simple.</p>

<p>It begins the same way as pushing, by sending all the
branches that a client may want to obtain from the git
repository.</p>

<pre>=r=&gt; 013b:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 HEAD\n"
=r=&gt; 003f:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 refs/heads/master\n"
=r=&gt; 0000
</pre>

<p>The client then starts telling us what commits they want,
and what commits they have. This lets us find a graph difference
between the server and client graph, and generate a pack file
that contains few, if any, extraneous commits. </p>

<pre>&lt;=w= 0032:	"want 5d761590cfdce23e4b17e94050b0776c8804d4a1\n"
&lt;=w= 0032:	"want 8f0eb1386a2c748cb7bf26917684479ff8c6d5b5\n"
&lt;=w= 0032:	"want dc4a9d467c6a28dab3927c8611a1bfbc571f1568\n"
&lt;=w= 0000
&lt;=w= 0033:	"have dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
&lt;=w= 0009:	"done\n"
=r=&gt; 0031:	"ACK dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
</pre>

<p>Computing the commits that go into a pack is not always trivial.
The comits that the client may be on may have "bubbles" in the graph,
so simply walking back from the start of the graph to the commits
that the client has may end up walking around the commit, leading
to nearly the whole history of the repository being sent, instead
of just one or two commits.</p>

<p>Consider a repo where the server is ahead of the client, and
now the client is trying to pull the changes. The client has commits
<code>c</code>, and we're trying to compute a pack with only the
commits <code>o</code>.</p>


<pre>                o---o
               /     \
    --c---c---c---c---o---o &lt;-- server
                  ^
                client
</pre>

<p>The client does a git/pull, and sends that it has the
commit marked <code>[c]</code>. Since the server has
every commit the client does, and more, it can look at
all ancestors of the client commit. If we're smart, we
would, but a naive …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://orib.dev/gitserve.html">https://orib.dev/gitserve.html</a></em></p>]]>
            </description>
            <link>https://orib.dev/gitserve.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404681</guid>
            <pubDate>Tue, 08 Sep 2020 02:19:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On writing and selling science fiction stories (2018)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24404555">thread link</a>) | @forrestbrazeal
<br/>
September 7, 2020 | https://forrestbrazeal.com/2018/11/08/on-writing-and-selling-science-fiction-stories/ | <a href="https://web.archive.org/web/*/https://forrestbrazeal.com/2018/11/08/on-writing-and-selling-science-fiction-stories/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section>
          <section>
              

              
              
              <article>
                  

<p>Each year, I try to set a few personal goals that stretch me in some way.</p>

<p>In 2017, for example, I <a href="https://forrestbrazeal.com/2017/12/03/how-to-read-100-books-in-a-year-and-still-have-a-life/">read one hundred books</a>, which turned out to be more a test of endurance than skill.</p>

<p>This year, I decided to see if I could write a fictional short story and get it published somewhere. Though I do a fair amount of technical writing in the course of my work, I’d never seriously attempted to write and sell a short story before, or even taken a creative writing class.</p>

<p>This meant I had no knowledge of the market, no connections, and generally no idea what I was doing.</p>

<p>So, a challenge!</p>

<h2 id="goals">Goals</h2>

<p>I decided to focus on the <a href="https://en.wikipedia.org/wiki/Speculative_fiction">speculative fiction genre</a>, partly because it seemed more accessible and mostly because unlike literary journals, the best speculative fiction magazines still pay their authors.</p>

<p>My goals, in descending order of likelihood, were as follows:</p>

<ol>
<li><p>Get something published somewhere, even if unpaid</p></li>

<li><p>Get something published and get paid something for it, even a token amount</p></li>

<li><p>Get something published at <a href="https://www.sfwa.org/about/join-us/sfwa-membership-requirements/#short">Science Fiction Writers of America (SFWA) professional rates</a> (currently 6 cents a word)</p></li>

<li><p>Get at least 1000 words published at SFWA-qualifying markets (the standard for <a href="https://www.sfwa.org/about/join-us/sfwa-membership-requirements/#associate">SFWA associate member status</a>)</p></li>

<li><p>Get at least three stories published, totaling more than 10,000 words, at SFWA-qualifying professional markets (<a href="https://www.sfwa.org/about/join-us/sfwa-membership-requirements/#active">SFWA Active Member status</a>, my self-imposed standard for a legit “professional” science fiction writer)</p></li>
</ol>

<h2 id="results-through-nov-8">Results (through Nov. 8)</h2>

<p>After many form rejections on several terrible stories, I sold my <a href="https://dailysciencefiction.com/science-fiction/biotech/forrest-brazeal/memory-foam">first story</a> on March 23rd, 2018, to Daily Science Fiction (an SWFA pro market). At 1010 words, this sale actually crossed the first four goals off my list at once.</p>

<p>However, I continued to write and improve over the spring and summer of 2018, selling several more stories along the way, eventually totaling more than 16,000 words of fiction. Some publications have long wait times, but by the time “Empathy Bee” <a href="http://www.diabolicalplots.com/the-diabolical-plots-year-five-fiction-lineup/">is published</a> in March 2019, I should have the wordcount needed for active SFWA membership status, my most insane stretch goal.</p>

<h3 id="by-the-numbers">By the numbers</h3>

<ul>
<li><p>Stories Written: 22</p></li>

<li><p>Total Wordcount: ~60,000, the length of a medium-sized novel</p></li>

<li><p>Total Submissions: 70</p></li>

<li><p>Stories Sold: 8</p></li>

<li><p>SFWA-qualifying professional sales: 6</p></li>

<li><p>Rejections: 50 (15 personal)</p></li>

<li><p>Withdrawals: 2</p></li>

<li><p>Still Pending: 10</p></li>

<li><p>Other Results: <a href="https://www.writersofthefuture.com/writers-of-the-future-3rd-quarter-standings-for-year-35/">Honorable Mention, Writers of the Future</a></p></li>
</ul>

<h2 id="what-i-learned">What I Learned</h2>

<h3 id="have-no-ego">Have no ego</h3>

<p>It turns out writing short stories that sell is really, really hard. It’s hard to think of good ideas, it’s hard to write them down in a form that anyone would want to read, and it’s even harder when those readers are magazine editors who get literally hundreds of unsolicited submissions every month. Don’t attempt it if you have an easily bruised sense of self-worth, or you will be depressed a lot.</p>

<p>I’m grateful to have sold some stories this year, but my identity is not tied up in “being a writer”. It can’t be, because I have to…</p>

<h3 id="embrace-failure">Embrace failure</h3>

<p>I learned to view rejections as a badge of honor, which is a helpful mental trick to keep from going insane after a few dozen forms. As I told Jason Bougger in an <a href="http://www.themeofabsence.com/2018/11/author-interview-forrest-brazeal/">author interview</a> over at Theme of Absence, rejections are like the good soreness you feel after working out – it means you’re growing.</p>

<h3 id="keep-your-feedback-loop-short">Keep your feedback loop short</h3>

<p>Early on, when I was getting form rejections from big magazines with no accompanying feedback, I got really frustrated because I knew my work was obviously not up to par – I just didn’t know why. A submission to a smaller publication, Abyss and Apex (who I later ended up selling a different story to!) brought back a personalized rejection with a helpful piece of advice: try signing up for the <a href="https://sff.onlinewritingworkshop.com/">Online Writing Workshop</a>.</p>

<p>At the time I had never heard of writers’ workshops and didn’t really understand why they would be helpful. But I paid a few dollars and signed up. The other writers there provided generous feedback on how to improve my work, and I learned just as much from critiquing their pieces. The OWW membership more than paid for itself when several readers pointed out an obvious plot hole in my story “Empathy Bee”, which subsequently sold in revised form to Diabolical Plots.</p>

<p>Later, once I had professional credits, I was able to join the wonderful <a href="http://www.codexwriters.com/">Codex</a> writers’ community, which has hugely expanded my horizons and understanding of the industry. The more I write, the less I trust myself to be a good judge of my work’s quality, and the more I seek out and appreciate feedback from others.</p>

<h3 id="write-smart-not-just-hard">Write smart, not just hard</h3>

<p>Some writers recommend keeping insane writing regimens, cranking out thousands of words a day, saying it’s the only way to improve. And I wrote a fair amount this year. But stepping back and getting feedback on my work was just as important.</p>

<p>I had a music teacher who used to ask: “Did you practice ten hours, or just the same hour ten times?” When I took time to evaluate my work and deliberately build on it, I improved faster than just by vomiting words indiscriminately onto the page.</p>

<h3 id="keep-reading-good-prose">Keep reading good prose</h3>

<p>No, I didn’t read a hundred books again this year. But I did try to keep my ear filled with good prose. For example, this summer I got on a southern realist kick: Flannery O’Connor, Eudora Welty, Carson McCullers. Studying how those writers crafted characters and situations helped me nail down a couple of southern-set stories that ended up selling. My science fiction writing improved more from reading good writers, period, than from reading science fiction.</p>

<h3 id="just-because-you-wrote-something-good-enough-to-get-published-somewhere-that-doesn-t-mean-the-next-thing-you-write-won-t-be-terrible">Just because you wrote something good enough to get published somewhere, that doesn’t mean the next thing you write won’t be terrible</h3>

<p>This sounds stupid in hindsight, but for a long time I had it in my head that once I sold a story, I’d have figured out what it took to get published, and I wouldn’t have any trouble after that. Instead, I still get tons of rejections, and often my writing seems just as lifeless and terrible to me as it did before I sold my first story.</p>

<p>The good news is that with practice, the overall trend appears to be upward. At least, when I look back at my work from the beginning of the year, I can’t believe how bad it is. So I must be improving, right?</p>

<h2 id="what-s-next">What’s next?</h2>

<p>Like many people who start out in the short fiction game, I would love to publish a novel. So I think that might be a 2019 goal. But I’m sure I’ll continue to write short stories, too. There’s real satisfaction in creating something that you can hold in your head all at once, knowing how it will turn out and why it’s effective.</p>

<p><em>Some of the stories I sold this year are free to read online. You can check them out in my <a href="https://forrestbrazeal.com/bibliography/">bibliography</a></em></p>

              </article>
              <center>
              <p>
                      If you enjoy my articles, comics, and stories, why not sign up for the mailing list?
                  </p>
              
            </center>
              
          </section>
          <br>
          

      </section>

    </div></div>]]>
            </description>
            <link>https://forrestbrazeal.com/2018/11/08/on-writing-and-selling-science-fiction-stories/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404555</guid>
            <pubDate>Tue, 08 Sep 2020 01:53:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Case for Comments in Code]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24404170">thread link</a>) | @eatonphil
<br/>
September 7, 2020 | https://notes.eatonphil.com/the-case-for-comments-in-code.html | <a href="https://web.archive.org/web/*/https://notes.eatonphil.com/the-case-for-comments-in-code.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <p>When I first started programming, especially when asked for code
samples, my comments lacked purpose and would often duplicate in
English what the code clearly indicated. I knew that "commenting is
good" but as a beginner I had no further insight.</p>
<p>Over time with the help of books like Clean Code, I grew disdainful of
comments. Good code should be self-documenting. Whenever I needed to
write a comment to explain something, I'd realize I could easily
rename some key variable or function. I grew more comfortable with
variables and functions with a few words in the title. Better to spend
time on good code structure and naming.</p>
<p>
  I have always left TODOs though, since TODOs can't so easily be
  expressed in variable names. But even these TODOs concerned me
  because they existed in my issue tracker, or maybe should have.
</p><p>As I watched mature open source projects and mature engineers, I came
to value well-documented pull requests. Solid pull requests include or
link to all necessary background, opportunities failed or ignored, how
to use, links to external bugs requiring workarounds and the results
of performance evaluation.</p>
<p>Beyond pull request descriptions, when I really wanted to grease a
pull request I'd use the pull request UI to add comments calling
reviewer attention to key changes in lines of the diff.</p>
<p>Both kinds of guidance are a massive aid to reviewers, saving a lot of
time.</p>
<p>But when I'd find a bug in code -- and I knew there was good pull
request documentation, even for pull requests as recent as six months
ago -- I've been repeatedly failed by the pull request and <em>pull
request comment</em> search exposed by Github and Gitlab.</p>
<p>I <em>knew</em> there were links to documented oddities or bug reports in
pull request threads. But practically speaking, for historic pull
requests, pull request comments are useless.</p>
<p>This is the single biggest reason I've started to push for more
comments in code. More so than all other tools (issue tracker, code
management system, etc.) comments in code have the greatest chance of
still being around and <em>easily searchable</em> if they haven't been
deleted.</p>
<p>
  Don't get me started on pull request documentation in an external
  medium like Slack. It's so rewarding to get or give instant feedback
  on changes on instant messengers, but good luck finding that
  discussion 3 months later.
</p><p>Every time I have to call out a line of code in a pull request, that's
immediate cause for that code to be modified with comments.</p>
<p>Maybe I wouldn't do this if Github/Gitlab exposed a Google Docs-like
interface for browsing code line by line with links to all pull
request comment threads.</p>
<p>Please reply on Twitter with questions or comments.</p>
<blockquote><p lang="en" dir="ltr">The biggest reason to add comments in code (often linking to documented oddities or bug reports) is because it's impossible to search pull request threads historically in every source control management UI I've used.<a href="https://t.co/JlHWfbUH5z">https://t.co/JlHWfbUH5z</a></p>— Phil Eaton (@phil_eaton) <a href="https://twitter.com/phil_eaton/status/1303130504993136642?ref_src=twsrc%5Etfw">September 8, 2020</a></blockquote> 

      </div>
    </div></div>]]>
            </description>
            <link>https://notes.eatonphil.com/the-case-for-comments-in-code.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404170</guid>
            <pubDate>Tue, 08 Sep 2020 00:43:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast.ai and why Python is not the future of ML with Jeremy Howard]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 50 (<a href="https://news.ycombinator.com/item?id=24404002">thread link</a>) | @tosh
<br/>
September 7, 2020 | https://www.wandb.com/podcast/jeremy-howard | <a href="https://web.archive.org/web/*/https://www.wandb.com/podcast/jeremy-howard">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Jeremy Howard is a founding researcher at fast.ai, a research institute dedicated to making Deep Learning more accessible. Previously, he was the CEO and Founder at Enlitic, an advanced machine learning company in San Francisco, California. </p><p>Howard is a faculty member at Singularity University, where he teaches data science. He is also a Young Global Leader with the World Economic Forum, and spoke at the World Economic Forum Annual Meeting 2014 on "Jobs For The Machines." </p><p>Howard advised Khosla Ventures as their Data Strategist, identifying the biggest opportunities for investing in data-driven startups and mentoring their portfolio companies to build data-driven businesses. Howard was the founding CEO of two successful Australian startups, FastMail and Optimal Decisions Group. Before that, he spent eight years in management consulting, at McKinsey &amp; Company and AT Kearney.</p><p><strong>TOPICS COVERED:</strong></p><p>0:00 Introduction</p><p>0:52 Dad things</p><p>2:40 The story of Fast.ai</p><p>4:57 How the courses have evolved over time</p><p>9:24 Jeremy’s top down approach to teaching</p><p>13:02 From Fast.ai the course to Fast.ai the library</p><p>15:08 Designing V2 of the library from the ground up</p><p>21:44 The ingenious type dispatch system that powers Fast.ai</p><p>25:52 Were you able to realize the vision behind v2 of the library</p><p>28:05 Is it important to you that Fast.ai is used by everyone in the world, beyond the context of learning</p><p>29:37 Real world applications of Fast.ai, including animal husbandry</p><p>35:08 Staying ahead of the new developments in the field</p><p>38:50 A bias towards learning by doing</p><p>40:02 What’s next for Fast.ai</p><p>40.35 Python is not the future of Machine Learning</p><p>43:58 One underrated aspect of machine learning</p><p>45:25 Biggest challenge of machine learning in the real world</p><p>Follow Jeremy on Twitter:</p><p><a href="https://twitter.com/jeremyphoward" target="_blank">https://twitter.com/jeremyphoward</a><br></p><p>Links:</p><p>Deep learning R&amp;D &amp; education: <a target="_blank" href="https://t.co/ZvDGNlehRt?amp=1">http://fast.ai</a></p><p>Software: <a target="_blank" href="https://t.co/GMYkPDXNW3?amp=1">http://docs.fast.ai</a></p><p>Book: <a target="_blank" href="https://t.co/1YSqXvWW87?amp=1">http://up.fm/book</a></p><p>Course: <a target="_blank" href="https://t.co/Q2qMl59EfH?amp=1">http://course.fast.ai</a></p><p>Papers:</p><p><a target="_blank" href="https://dl.acm.org/doi/10.1145/2487575.2491127"><strong>The business impact of deep learning</strong></a></p><p><a target="_blank" href="https://dl.acm.org/doi/10.1145/2487575.2491127">https://dl.acm.org/doi/10.1145/2487575.2491127</a></p><p><a target="_blank" href="https://www.linkedin.com/redir/redirect?url=http%3A%2F%2Fwww%2Ejmir%2Eorg%2F2012%2F1%2Fe33%2F&amp;amp;urlhash=gLU-&amp;trk=public_profile_publication-title"><strong>De-identification Methods for Open Health Data</strong></a></p><p><a href="https://www.jmir.org/2012/1/e33/">https://www.jmir.org/2012/1/e33/</a><br></p><p>Visit our podcasts homepage for transcripts and more episodes!</p><p><a target="_blank" href="https://www.wandb.com/podcast">www.wandb.com/podcast</a></p><p> Get our podcast on Soundcloud, Apple, and Spotify!</p><p>Soundcloud: <a target="_blank" href="https://bit.ly/2YnGjIq">https://bit.ly/2YnGjIq</a></p><p>Apple Podcasts: <a target="_blank" href="https://bit.ly/2WdrUvI">https://bit.ly/2WdrUvI</a></p><p>Spotify: <a target="_blank" href="https://bit.ly/2SqtadF">https://bit.ly/2SqtadF</a></p><p>We started Weights and Biases to build tools for Machine Learning practitioners because we care a lot about the impact that Machine Learning can have in the world and we love working in the trenches with the people building these models. One of the most fun things about these building tools has been the conversations with these ML practitioners and learning about the interesting things they’re working on. This process has been so fun that we wanted to open it up to the world in the form of our new podcast called Gradient Dissent. We hope you have as much fun listening to it as we had making it!</p><p>Weights and Biases:</p><p>We’re always free for academics and open source projects. Email carey@wandb.com with any questions or feature suggestions.</p><ul role="list"><li>Blog: <a target="_blank" href="https://www.wandb.com/articles">https://www.wandb.com/articles</a></li><li>Gallery: See what you can create with W&amp;B - <a target="_blank" href="https://app.wandb.ai/gallery">https://app.wandb.ai/gallery</a></li><li>Continue the conversation on our slack community - <a href="http://bit.ly/wandb-forum" target="_blank">http://bit.ly/wandb-forum</a><br></li></ul><p>Host: Lukas Biewald - <a href="https://twitter.com/l2k" target="_blank">https://twitter.com/l2k</a></p><p>Producer: Lavanya Shukla - <a href="https://twitter.com/lavanyaai" target="_blank">https://twitter.com/lavanyaai</a></p><p>TRANSCRIPT:</p><p><strong>Lukas: </strong>You're listening to Gradient Dissent, a show where we learn about making machine learning models work in the real world. I'm your host Lukas Biewald. Jeremy Howard created the Fast.ai course, which is maybe the most popular course to learn machine learning and there are a lot out there. He's also the author of the book Deep Learning for Coders with Fast.ai and PyTorch and in that process, he made the Fast.ai library which lots of people use independently to write deep learning. Before that, he was the CEO and co-founder of Enlitic, an exciting startup that applies deep learning to health care applications. And before that, he was the president of Kaggle, one of the most exciting earliest machine learning companies. I'm super excited to talk to him. So Jeremy, it's nice to talk to you. And in preparing the questions, I realized that every time I've talked to you there have been a few gems that I've remembered that I would never think to ask about. Like one time you told me about how you learned Chinese and another time you gave me Dad parenting advice, very specific advice and it's been actually super helpful. </p><p><strong>Jeremy: </strong>Oh great. Tell me what Dad parenting advice worked out?</p><p><strong>Lukas: </strong>Well, what you told me was when you change diapers, use a blow dryer to change a really frustrating experience to a really joyful experience and it's like such good advice. I don't know how you.. I guess I can imagine how you thought of it, but it's...</p><p><strong>Jeremy: </strong>Yeah, yeah, I know they love the whooshing sound, they love the warmth. I'm kind of obsessed about Dad things. So I'm always happy to talk about Dad things. That is this podcast.</p><p><strong>Lukas: </strong>Can we start with that? Now that my daughter is eight months old. Do you have any suggestions for her?</p><p><strong>Jeremy: </strong>Oh my goodness! Eight months old. You know, it's like the same with any kind of learning. It's all about consistency. So I think that the main thing we did right with Claire was just, you know, this delightful child now is we were just super consistent. Like if we said you can't have X unless you do Y, we would never give her X if she didn't do Y. If you want to take your scooter down to the bottom of the road, you have to carry it back up again. We read this great book that was saying if you're not consistent, it becomes like this thing, it's like a gambler. It's like sometimes you get the thing you want, so you just have to keep trying so that's my number one piece of advice. It's the same with teaching machine learning. We always tell people that tenacity is the most important thing for students. To stick with it, do it every day.</p><p><strong>Lukas: </strong>I guess just in the spirit of questions, I'm genuinely curious about, you know, you've built this amazing framework and teaching thing that I think is maybe the most popular and most appreciated framework. I was wondering if you could start by telling me the story of what inspired you to do that and what was the journey to making Fast.ai, the curriculum and Fast.ai, the ML framework.</p><p><strong>Jeremy: </strong>So it was something that my wife Rachel and I started together. Rachel has a math PhD, super technical background, early data scientist and engineer, Uber. I don't. I have just scraped by a philosophy undergrad and have no technical background. But from both of our different directions, we both had this frustration that neural networks in 2012 were super important, clearly going to change the world, but super inaccessible and so we would go to meetups and try to figure out like how do we... Like I knew the basic idea, I'd coded neural networks 20 years ago, but how do you make them really good? There wasn't any open source software at the time for running on GPUs. You know, Dan Seresen's thing was available, but you had to pay for it. There was no source code and we just thought, oh, we've got to change this, because the history of technology leaps has been that it generally increases inequality because the people with resources can access the new technology and then that leads to societal upheaval and a lot of unhappiness. So we thought, well, we should just do what we can. So we thought how are we going to fix this? Basically the goal was, and still is, to be able to use deep learning without requiring any code so that, you know, because the vast majority of the world can't code, we kind of thought, well, to get there, we should, first of all, see what exists right now? Learn how to use it as best as we can ourselves, teach people how to best use it as we can and then make it better, which requires doing research and then turning that into software and then changing the course to teach the hopefully slightly easier version and repeat that again and again for a few years. And so we're kind of in that process.</p><p><strong>Lukas: </strong>That's so interesting. Do you worry that the stuff you're teaching, you're sort of trying to make it obsolete, right? Because you're trying to build higher level abstractions? Like I think one of the things that people really appreciate your course is that it's really clear, in-depth explanations of how these things work. Do you think that that's eventually going to be not necessary or how do you think about that?</p><p><strong>Jeremy: </strong>Yeah, to some extent. I mean, so if you look at the new book and the new course, chapter one starts with really, really foundational stuff around what is a machine learning algorithm? What do we mean to learn an algorithm? What's the difference between traditional programming and machine learning to solve the same problem? And those kinds of basic foundations I think will always be useful, even at the point you're not using any code. I feel like even right now, if somebody is using like PlatformAI or some kind of code-free framework, you still need to understand these basics of an algorithm can only learn based on the data you provide. It's generally not going to be able to extrapolate to patterns it's not seen yet, stuff like that. Um, but yeah, I mean, we have so far released two new courses every year, you know, a part one and part two every year because every year, it's totally out of date. And we always say to our students at the start of part one, Look, you know, none of the details you're learning are going to be of any use in a year or two's time. There's a time when we're doing Piano and then TensorFlow and Keras, and then playing PyTorch. We always say, look, don't worry too much about the software we're using because none of it's still any good, you know, it's goal changing rapidly, you know, faster than JavaScript frameworks, but the concepts are important and yeah, you can pick up a new library and I don't know by weekend, I …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.wandb.com/podcast/jeremy-howard">https://www.wandb.com/podcast/jeremy-howard</a></em></p>]]>
            </description>
            <link>https://www.wandb.com/podcast/jeremy-howard</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404002</guid>
            <pubDate>Tue, 08 Sep 2020 00:10:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Walmart Sponsored Products Ads Guide]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24403206">thread link</a>) | @WalterJT
<br/>
September 7, 2020 | https://jungletopp.com/walmart-sponsored-products/ | <a href="https://web.archive.org/web/*/https://jungletopp.com/walmart-sponsored-products/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="310ca8db" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<p>What are Walmart Sponsored Products and where do they come into play? Walmart allows advertisers to easily advertise on their platforms with this feature being a really lucrative option for them. We’ll discuss what it entails, how they work and the different ad formats that can be selected for the different types of campaigns you’re choosing to run.&nbsp;</p>



<p>Let’s begin!&nbsp;</p>



<h2><strong>What are Walmart Sponsored Products?&nbsp;</strong></h2>



<p>Walmart Sponsored Products are also called Performance Ads, and they are also known as <a href="https://jungletopp.com/walmart-ad-costs/">cost-per-click ads</a> that can appear on the Walmart Marketplace. They are able to appear within search results, category pages, and product pages on Walmart’s app, mobile site, and desktop site.&nbsp;&nbsp;&nbsp;</p>



<p>When utilizing these types of ads, they are able to increase your visibility by allowing you to reach and engage shoppers at all stages of their shopping journey. The ads appear on the first page of search results too.&nbsp;</p>



<p>If anything, you’re not only advertising your products, but you’re also helping consumers find and purchase products in a much easier and convenient manner. Plus, the advertiser will only have to pay when the shopper clicks on the ad. It’s quite the win-win situation!&nbsp;&nbsp;</p>



<h2><strong>How Do <strong>Walmart Sponsored Products</strong> Work?&nbsp;</strong></h2>



<p>So, how are these sponsored products selected for exposure to your customers? They are actually based on a combination of relevancy and bid. They also rely on the following two factors.&nbsp;</p>



<ul><li>Products being advertised must win the buy box&nbsp;</li><li>Products being advertised must be in stock&nbsp;</li></ul>



<p>These cool ads are designed to help you do the following too.&nbsp;</p>



<ul><li>Boost product sales&nbsp;</li><li>Increase share of wallet&nbsp;</li><li>Uncover new customers&nbsp;</li><li>Grow or protect market share&nbsp;</li><li>Maximize profitable SKUs&nbsp;</li><li>Improve brand and product visibility&nbsp;</li><li>Launch new products or brand extensions&nbsp;</li><li>Present your products to a massive audience already ready to purchase&nbsp;</li></ul>



<p>Which benefit are you to achieve in your <a href="https://jungletopp.com/walmart-search-advertising/">advertising campaign</a>? We’d love to know your thoughts and your mission to execute your own products to potential customers.&nbsp;</p>



<h2><strong>Types of Walmart Sponsored Products</strong></h2>



<p>With all of the great <a href="https://jungletopp.com/walmart-stats/" target="_blank" rel="noreferrer noopener">capabilities</a> this type of advertising has to offer, there are also different formats in the way they can be executed. This is perfect for those who are interested in various campaign ideas and need a mix of how to present their product launches.&nbsp;</p>



<p>These are all of the following ways Walmart Sponsored Products may be used on the online platform.&nbsp;</p>



<p><strong><em>Search In-Grid: </em>&nbsp;</strong>Did you know that one in four online Walmart purchases begin with a search? This type of ad allows for your product to get the premium placement on the first page of search results.&nbsp;</p>



<p><strong><em>Brand Amplifier: </em></strong>This type of ad really helps to provide brand recognition and showcase your product portfolio. The logo, custom headline and up to three of the SKUs appear at the top of relevant search results.&nbsp;</p>



<p><strong><em>Product Carousel: </em></strong>&nbsp;The product appears on search, category and item pages as relevant alternate purchase options. This is an ad that appears as more of a disguise and it gives the customer options.&nbsp;</p>



<p><strong><em>Buy Box: </em></strong>&nbsp;This ad will have your products appear at the most relevant alternate purchase option on product detail pages.&nbsp;</p>



<h2><strong>Two Different Campaign Types</strong></h2>



<p>When looking at how to set up the overall campaigns, there are two different methods that Walmart offers to advertisers. Look at the following to see what will work best for your current needs in product/brand awareness. <strong>&nbsp;</strong></p>



<p><strong><em>Automatic: </em></strong>This is a method in the way a campaign runs where the advertiser doesn’t have to monitor as heavily as if it were manual. It’s set to serve all customers searching for products like yours.&nbsp;</p>



<p>This specific type of campaign is perfect for brands that are new to the advertising field. They hope to widen their existing customer base or are launching a product.&nbsp;</p>



<p>These are a few of its features that advertisers look for when running their campaign.&nbsp;</p>



<ul><li>Easy setup&nbsp;</li><li>No keyword management&nbsp;</li><li>High impression volume&nbsp;</li></ul>



<p><strong><em>Manual: </em></strong>On the other hand, manual advertising is set to serve to customers based on their select keyword choice.&nbsp;</p>



<p>This is an ideal situation for brands who have products with a long history on Walmart or brands that already know the successful keywords in their customer use.&nbsp;&nbsp;</p>



<p>These are a few of its features that advertisers look for when running their campaign.</p>



<ul><li>Access to Walmart’s Keyword Analytics tool</li><li>Select your own keywords&nbsp;</li><li>Full campaign control&nbsp;&nbsp;</li></ul>



<h2><strong>Final Thoughts</strong></h2>



<p>Do you think that Walmart Sponsored Products are right for you?&nbsp;Contact a <a href="https://jungletopp.com/walmart-ads-agency/">Walmart ads agency</a> to talk about launching your ad campaigns.</p>



<p>We find that with the combination of different ways to execute the ads as well as having Walmart being a powerhouse for a variety of products, it’s always going to be desirable to a large number of consumers.&nbsp;</p>



<p>Plus, with the different bidding keywords and use of CPC, advertisers will have much more financial freedom. They’ll also be able to measure their results.&nbsp;</p>



<p>Let us know your final thoughts to this method of advertising and if you have or are considering this method for your own campaign.</p>
<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->		</div>
				</div></div>]]>
            </description>
            <link>https://jungletopp.com/walmart-sponsored-products/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24403206</guid>
            <pubDate>Mon, 07 Sep 2020 21:46:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If you can’t code, what do you do?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24403144">thread link</a>) | @ZnZirconium
<br/>
September 7, 2020 | https://www.cambridgembastories.com/2018/01/25/sudo-hackathon-if-you-cant-code-what-do-you-do/ | <a href="https://web.archive.org/web/*/https://www.cambridgembastories.com/2018/01/25/sudo-hackathon-if-you-cant-code-what-do-you-do/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2024" itemscope="itemscope" itemtype="http://schema.org/Article">

	<!-- .row .post-meta .align-items-top -->
    <div itemprop="description">

		<p><a href="https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?ssl=1"><img data-attachment-id="2026" data-permalink="https://www.cambridgembastories.com/2018/01/25/sudo-hackathon-if-you-cant-code-what-do-you-do/sudo-hackathon/" data-orig-file="https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?fit=660%2C330&amp;ssl=1" data-orig-size="660,330" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Sudo Hackathon" data-image-description="" data-medium-file="https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?fit=300%2C150&amp;ssl=1" data-large-file="https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?fit=610%2C305&amp;ssl=1" loading="lazy" src="https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?resize=610%2C305&amp;ssl=1" alt="Sudo Hackathon" width="610" height="305" srcset="https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?w=660&amp;ssl=1 660w, https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?resize=300%2C150&amp;ssl=1 300w" sizes="(max-width: 610px) 100vw, 610px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?w=660&amp;ssl=1 660w, https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?resize=300%2C150&amp;ssl=1 300w" data-lazy-src="https://i2.wp.com/www.cambridgembastories.com/wp-content/uploads/2018/01/Sudo-Hackathon.jpg?resize=610%2C305&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>
<p>“If you can’t code, what do you do?” I often get this question when I say I went to a hackathon. The simple answer is twofold: partner with developers to make sure you’re getting the right stuff done; and surround great code with a concise and compelling business story. There are other ways to go about it, but in general you have to be enormously flexible and wear many hats with various levels of comfort.</p>
<p>At the Sudo Hackathon, I had the pleasure of working with a genuinely incredible team. The prompt was: “How can virtual reality be utilised in health and infrastructure?” Our team worked on a healthcare tool for macular dystrophy&nbsp;<strong>–</strong> the number one cause of vision loss in people over 50.</p>
<p>Over the weekend, our team created four key deliverables:</p>
<ul>
<li>A retinal-mapping game using Google Cardboard</li>
<li>An algorithm to quickly and precisely define patient blind spot borders</li>
<li>A real-Time video morphing visualization</li>
<li>A 5-minute pitch presentation including business case</li>
</ul>
<p>We were able to track down an eye surgeon and prepare patient-focused and physician-focused questions. The information informed our MVP (minimum viable product), then we just needed the facts to back up our story. For example, sight loss is a 28 billion GBP market in the UK alone. The NHS also had an upcoming grant our product would be eligible for, an incredibly desirable path for extending our runway without diluting our equity.</p>
<p>Up until the last minute we were building, refining, adding, and editing. Our team had that contagious feeling of great code being stitched together. To quote one of my teammates: “This code is magic.” With only one previous run-through, we went in front of the judges, and we WON!</p>
<p>It was a great feeling for everyone on the team to leave the hackathon in equal parts excited and exhausted. Lots of gratitude to Allia for hosting this Serious Impact Challenge Weekend in partnership with the European Union’s European Regional Development Fund. It was an amazing event, and I highly encourage people to check out their <a href="https://www.sudochallenge.com/">next event</a> in Agritech this April.</p>


    </div><!-- .post-content -->

	
        <!-- .row .post-meta .post-meta-footer .align-items-top -->

	
</article></div>]]>
            </description>
            <link>https://www.cambridgembastories.com/2018/01/25/sudo-hackathon-if-you-cant-code-what-do-you-do/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24403144</guid>
            <pubDate>Mon, 07 Sep 2020 21:38:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Amiga and CD-ROMs]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24402543">thread link</a>) | @erickhill
<br/>
September 7, 2020 | https://www.amigalove.com/viewtopic.php?f=6&t=1569 | <a href="https://web.archive.org/web/*/https://www.amigalove.com/viewtopic.php?f=6&t=1569">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.amigalove.com/viewtopic.php?f=6&amp;t=1569</link>
            <guid isPermaLink="false">hacker-news-small-sites-24402543</guid>
            <pubDate>Mon, 07 Sep 2020 20:30:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimize Onboarding]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24402419">thread link</a>) | @tekdude
<br/>
September 7, 2020 | https://staysaasy.com/management/2020/08/28/Optimize-Onboarding.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/08/28/Optimize-Onboarding.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>It takes roughly 2 weeks to form a habit; it takes roughly two weeks to get comfortable in a new environment. A common mistake is to treat a new report’s first couple weeks like college orientation - social, light hearted, get-to-know-you stuff. If your report spends the first two weeks reading C# documentation and having lunch out on the town with the team, guess what, they’ve just normalized that behavior as what the role is.</p>

<p>The answer: start your report doing real work as soon as possible. If they’re a software engineer, they should be committing code week one (ideally day 2 or 3); If they’re a product manager, they should be attending meetings and picking up supporting activities on a similar time frame. Then the tone has been set - working here means getting things done.</p>

<p>This means as manager you need to give your report tractable work in the first week. Managers not being ready for a report to start is the number one reason people end up normalizing underperformance, because they had nothing meaningful to do. If a manager describes a report as not having initiative in the first couple weeks it’s a red flag - it’s the manager’s job to provide new hires with clear paths to contribute immediately.</p>

<p>Another main reason people fall into onboarding traps is because your organization has painfully slow onboarding. Endless HR videos, slow security processes, a mountain of fragile technology setup - these all make for a shitty and counterproductive start at a company. Optimize your onboarding to get people doing what you hired them to do. Look to formalize performance indicators of your onboarding. For example, for engineers this could be time-to-first-commit and time-to-joining-sprints.</p>

<p>This approach holds for managers and executives as well. In that cohort it’s also common and a common red flag for people to spend the first couple weeks putzing around under the guise of “getting to know what’s going on”. Managers and executives should be involved in the decisions of the team from day 1 and developing artifacts - plans, TODO lists, strategy documents - in the first couple weeks. With good managers and executives you see them day 1 adding perspective and insight into conversations, and everyone collectively appreciates that the right person has been hired.</p>

<p>Onboarding is one of the most critical periods in a person’s time at a company. It’s one of the highest ROI periods when managing someone. Take that opportunity to set expectations properly and measure success quantiatively.</p>


    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/08/28/Optimize-Onboarding.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24402419</guid>
            <pubDate>Mon, 07 Sep 2020 20:18:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Entanglement with SVD]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24402242">thread link</a>) | @jonbaer
<br/>
September 7, 2020 | https://www.math3ma.com/blog/understanding-entanglement-with-svd | <a href="https://web.archive.org/web/*/https://www.math3ma.com/blog/understanding-entanglement-with-svd">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div href=""><p><em>Quantum</em> <em>entanglement</em> is, as you know, a phrase that's jam-packed with meaning in physics. But what you might not know is that the linear algebra behind it is quite simple.&nbsp;If you're familiar with singular value decomposition (SVD), then you're 99% there. My goal for this post is to close that 1% gap. In particular, I'd like to explain something called the<em> </em><strong>Schmidt rank</strong> in the hopes of helping the math of entanglement feel a little less... tangly. And to do so, I'll ask that you momentarily forget about the previous sentences. Temporarily ignore the title of this article. Forget we're having a discussion about entanglement. Forget I mentioned that word. And let's start over. Let's just chat math. </p><p>Let's talk about SVD. </p><figure><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5b527d2844acede360b8e7ae_hline.jpg" loading="lazy" alt=""></p></figure><h2>Singular Value Decomposition</h2><p>SVD is arguably one of the most important, well-known tools in linear algebra. You are likely already very familiar with it, but here's a lightning-fast recap. Every matrix $M$ can be factored as $M=UDV^\dagger$ as shown below, called the <strong>singular value decomposition</strong> of $M$. The entries of the diagonal matrix $D$ are nonnegative numbers called <em>singular values</em>, and the number of them is equal to the rank of $M$, say $k$. What's more, $U$ and $V$ have exactly $k$ columns, called the <em>left and right singular vectors</em>, respectively.</p><figure id="w-node-c5cffac943b5-24b29fc4"><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f5562528e82aa6ab6d78ae1_open.png" loading="lazy" alt=""></p></figure><p>There are different ways to think about this, depending on which applications you have in mind. I like to think of singular vectors as encoding meaningful "concepts" inherent to $M$, and of singular values as indicating how important those concepts are. For instance, this perspective arises naturally in a study of the <a href="https://arxiv.org/abs/1810.10531">learning dynamics of deep neural networks</a>. As another example, you can imagine a matrix whose rows are indexed by people, and whose columns are indexed by movies.&nbsp;The $ij$th entry could be a 0 or 1, indicating whether or not person $i$ has watched movie $j$. In an applied setting—a recommender system, for instance—one may wish to compute a <em>truncated SVD </em>of this matrix. Here, only the top largest singular values are kept. The rest are viewed as containing little information and are set to zero. In this way, the diagonal matrix $D$&nbsp;operates on a low-dimensional "feature space," which provides a nice way to <a href="https://developers.google.com/machine-learning/recommendation/collaborative/basics">compress and glean information about the data</a>.</p><p>Either way, I like to think of $D$ as providing a bridge between two worlds: information about the columns of $U$ (e.g. people) and information about the columns of $V$ (e.g. movies). Below is a very <em>non</em>-mathematical cartoon of this. You can imagine the thickness of the blue bridge relates to the number of singular values. Lots of singular values?&nbsp;The bridge is wide and lots of information passes through. Only a few singular values?&nbsp;The bridge is narrow and not much information gets through.</p><figure id="w-node-fc7a2c3b2624-24b29fc4"><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f55643d546e4a903f261c30_bridge2.png" loading="lazy" alt=""></p></figure><p>An actual mathematical picture is found in a <a href="https://www.math3ma.com/blog/matrices-as-tensor-network-diagrams">tensor network diagram</a> representation of SVD.&nbsp;There, $D$&nbsp;really is a bridge! As a visual cue, we might draw the edges adjacent to the blue node as very thick if the number of singular values is large, and draw them to be thin otherwise. This again represents the idea of information "flowing" between systems described by $U$ and $V$.</p><figure id="w-node-235ea1f864dc-24b29fc4"><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f5564d7d7916c43e6f8c4ce_TN2.png" loading="lazy" alt=""></p></figure><p>Alternatively still, if you enjoy thinking of <a href="https://www.math3ma.com/blog/matrices-probability-graphs">matrices as bipartite graphs</a>, then you might have in mind the graphs below. If we have lots of blue nodes—i.e. lots of singular values—then there are lots of pathways between the pink and green nodes (i.e. people and movies). But if we have only a <em>few</em> blue nodes—i.e. a few singular values—then there are fewer pathways between pink and green.</p><figure id="w-node-9ef538caa942-24b29fc4"><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f577be8bc99498290bfcb81_graph2.jpg" loading="lazy" alt=""></p></figure><p>Either way we wish to visualize it, the role of the singular values—that is, the role of the diagonal matrix $D$—is key. Intuitively, they indicate the amount of "interaction" between the information stored by $U$ and $V$, and they mediate how those interactions contribute to the information represented by the original matrix $M$.</p><p><em>And this precisely idea behind the mathematics of entanglement</em>.</p><p>In the context of physics, one simply applies SVD to a particular matrix and then looks at the number of nonzero singular values of that matrix. This is the main idea behind something called the <em>Schmidt rank</em> of a quantum state (explained below), which is an integer that indicates how much entanglement is present. </p><blockquote>Entanglement is measured by the number of nonsingular values of a particular matrix. </blockquote><p>So what makes a physicist's application of SVD different from that of, say, someone building a movie recommender system?&nbsp;Well, in physics, your matrix $M$ presumably encodes information about a physical system and takes spatial considerations into account (ex. particles in a lattice). Its entries may also contain complex numbers, and the sum of their squares should satisfy $\sum_{ij}|M_{ij}|^2=1$. In this case—as I'll explain below—$M$ represents a <strong>quantum state</strong>. But lingo aside, the template is much the same: singular values convey important information about how two things—whether users and movies, or two quantum subsystems—are related.</p><p>I could stop here, but I'd like to dig a little deeper. In the next section, let me restate this punchline using slightly more specialized language.</p><figure><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5b527d2844acede360b8e7ae_hline.jpg" loading="lazy" alt=""></p></figure><h2>Singular Values vs. Schmidt&nbsp;Rank</h2><p>To start, let's back up a bit. In a discussion of physics, what exactly is the matrix to which we apply SVD?&nbsp;In the opening example, we applied SVD to a user-by-movie matrix. But what's going on now?</p><p>Rather than starting with a matrix, we instead start with a <em>unit vector</em>. To that end, suppose $\psi$ is any unit vector in a <strong>tensor product</strong> of vector spaces $\mathbb{C}^n\otimes\mathbb{C}^m$. Here, it's important that our discussion takes place in a tensor product. After all, entanglement is defined <em>between two things</em> (So, if someone were to ask you, "How much entanglement is there?" one proper response would be, "Entanglement <em>between</em> <em>what</em>?"), and in quantum mechanics, the tensor product is the mathematical operation used to combine two systems. Now, if the phrase "tensor product" is unfamiliar to you, I recommend the article "<a href="https://www.math3ma.com/blog/the-tensor-product-demystified">The Tensor Product, Demystified</a>." I&nbsp;think you'll be pleasantly surprised at how easy the concept is!</p><p>Alright, now that we have the vector $\psi$, it's easy to get a linear map $\mathbb{C}^m\to\mathbb{C}^n$ from it. Simply reshape the entries of $\psi$ into an $n\times m$ matrix $M$. (Said more formally, look at $\psi$&nbsp;under the isomorphism $A\otimes B^*\cong\text{hom}(B,A)$ for finite-dimensional vector spaces $A$&nbsp;and $B$.)</p><figure><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f5517185b36106928a313a9_reshape.jpeg" loading="lazy" alt=""></p></figure><p>In the language of physics, $\psi$ is called a <strong>quantum state</strong>, and $M$&nbsp;is simply the matrix associated with it. More generally, the terms&nbsp;"unit vector" and "quantum state" are synonymous. That's because the squares of the entries of any unit vector define a probability distribution, and—in the context of physics—that probability distribution tells you about the <em>state</em> of the system you're studying. (This is the Born rule.)</p><p>But I&nbsp;digress. Let's get back to SVD.</p><p>Suppose the singular value decomposition of our matrix $M$ is given by $UDV^\dagger$. Here I'm using the dagger to denote the conjugate transpose of $V$ since we're allowing $M$ to have complex entries. Now I'd like to use this decomposition&nbsp;to rewrite $M$ in a slightly messier way. Let $\mathbf{u}_i$ and $\mathbf{v}_i$ denote the $i$th columns of $U$ and $V$, respectively, and let $d_i$ denote the $i$th singular value of $M$. Then we can expand the matrix $M$ as the following sum, where $k$&nbsp;is the rank of $M$. </p><figure id="w-node-dc0fefa9bd0b-24b29fc4"><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f556da578cb1b3bbc952fdd_expand2.png" loading="lazy" alt=""></p></figure><p>We're almost at the punchline, but let me first introduce a definition and then make one final cosmetic change.</p><p>For any two vectors $\mathbf{u}$&nbsp;and $\mathbf{v}$, the matrix $\mathbf{uv}^\dagger$ is called their <strong>outer product</strong>. This simple operation is also denoted with a tensor product symbol $\mathbf{u}\otimes \mathbf{v}$ or in physicists' bra-ket notation by $|u\rangle\langle v|$. So for example, if $\mathbf{u}=\begin{bmatrix}1&amp;2&amp;3\end{bmatrix}^\top$ and $\mathbf{v}=\begin{bmatrix}4&amp;5\end{bmatrix}^\top$, then their outer product is the following little matrix.</p><figure id="w-node-c2af2f15f3fb-24b29fc4"><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f551c63f2d18fc4ccbcb28b_outer.jpg" loading="lazy" alt=""></p></figure><p>Why introduce this?&nbsp;Let's think back that expansion of $M$&nbsp;above. Under the correspondence $\mathbf{uv}^\dagger \leftrightarrow \mathbf{u}\otimes \mathbf{v}$, we can write $\psi$&nbsp;explicitly using the columns of $U$ and $V$, weighted by the singular values of $M$ like this:</p><figure id="w-node-3ff996165bf0-24b29fc4"><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f556f9788b112261c051ef6_decomp0.jpg" loading="lazy" alt=""></p></figure><p>At this point, you might think we haven't done much (and we haven't, really), <em>and yet</em> familiar things are now given <em>new names</em>. In the context of physics, the above decomposition of $\psi$ is called its <strong>Schmidt decomposition</strong>. The integer $k$, which is the rank of the original matrix $M$, is called its <strong>Schmidt rank</strong>. And the singular values $d_1,d_2,\ldots, d_k$ are called its <strong>Schmidt coefficients.</strong></p><figure><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f556fb589f1f866fb28a990_decomp1.jpg" loading="lazy" alt=""></p></figure><p>Although terminology is new, the ingredients aren't. And that's the punchline.</p><blockquote>Punchline: the quantum state $\psi$ is said to be <strong>entangled</strong> if its Schmidt rank&nbsp;(i.e. number of singular values) is strictly greater than 1, and is <strong>not entangled</strong> otherwise.</blockquote><p>So, do you see the connection with our discussion above? As we stressed earlier, singular values can be thought of as providing a "bridge" between two subsystems. They are a measure of how much interaction exists between them. In the context of physics, this interaction is understood as entanglement.</p><p>The upshot is that a large number of singular values—i.e. a high Schmidt rank or a "wide bridge"—corresponds to lots of communication between two subsystems. A small number of singular values—i.e. a low Schmidt rank or a "narrow bridge"—corresponds to little communication. At the lowest extreme, <em>one</em> singular value corresponds to <em>zero</em> entanglement, and we might as well omit the thin bridge in the image below.</p><figure><p><img src="https://uploads-ssl.webflow.com/5b1d427ae0c922e912eda447/5f559310bc99491aa62d994a_zero1.jpg" loading="lazy" alt=""></p></figure><p>Indeed, notice that if the Schmidt rank of $\psi$ is equal to <em>one</em>—that is, if $M$&nbsp;is a rank one matrix $M=\mathbf{uv}^\dagger$—then we can write $\psi=\mathbf{u\otimes v}$. In the mathematics literature, vectors of this form (i.e. a tensor product of vectors) are sometimes called <strong>simple tensors</strong>.&nbsp;For this reason, some mathematicians associate entanglement with "linear combinations of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.math3ma.com/blog/understanding-entanglement-with-svd">https://www.math3ma.com/blog/understanding-entanglement-with-svd</a></em></p>]]>
            </description>
            <link>https://www.math3ma.com/blog/understanding-entanglement-with-svd</link>
            <guid isPermaLink="false">hacker-news-small-sites-24402242</guid>
            <pubDate>Mon, 07 Sep 2020 19:58:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Transclude for Networked Writing]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24402202">thread link</a>) | @jil
<br/>
September 7, 2020 | http://subpixel.space/entries/open-transclude/ | <a href="https://web.archive.org/web/*/http://subpixel.space/entries/open-transclude/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>tl;dr: If you follow this blog you’ve seen me experiment with iframe-based citations; this post is about open-sourcing that tooling. <a href="#tutorial-start" target="_self">Skip</a> to demo, implementation tutorial, and GitHub link.</p>

<hr>

<p>Knowledge tooling is happily becoming a hot topic again. With this trend is coming revived interest in <a href="https://en.wikipedia.org/wiki/Project_Xanadu">Xanadu</a>, bi-directional hyperlinking, knowledge databases, visualizing knowledge graphs, and so on. At this moment, I see most of the emphasis being put on tooling for the research side, with Notion, Workflowy, and the new and hyped Roam Research leading the way.</p>

<p><img src="http://subpixel.space/uploads/xanadu-shot.png" alt="Screenshot of the OpenXanadu prototpye"></p>

<p>Where I see less focus is the <em>writing</em> part of the knowledge production process, where older apps like Scrivener are still the thing to beat. And almost nobody at all is working on the reader’s experience. As a blogger who largely caters to a wide audience, I’m especially interested in these areas.</p>

<p>Written information is largely still presented as a single document, and writing tools are geared toward the production of long pages. But before I say what’s wrong with this, let me sing the praises of documents for a moment.</p>

<p>People often get carried away when they discover the original vision of hypertext, which involves a network of documents, portions of which are “transcluded” (included via hypertext) into one another. The implication is that readers could follow any reference and see the source material—and granted, this would be transformative. However, there’s a limit to the effectiveness of the knowledge network as a reading experience. “Hypertext books,” online books which are made up of an abundance of interlinked HTML pages, are mostly unpopular. The failure of this experiment is, in my opinion, very revealing.</p>

<p><img src="http://subpixel.space/uploads/sprawlingplaces-shot.jpg" alt="Screenshot of tinderbox map of hypertext book Sprawling Places by David Kolb">
<span>Tinderbox map of a portion of David Kolb’s hypertext book Sprawling Places</span></p>

<p>Knowledge is not an accumulation of facts, nor is it even a set of facts and their relations. Facts are only rendered meaningful within narratives, and the single-page document is a format very conducive to narrative structure. The hypertext books that have gained popularity (I’m thinking here of <a href="http://meaningness.com/">Meaningness.com</a>) have largely conformed to this in two ways: 1) there is an intended reading order, and 2) the longer essays within the project do most of the heavy lifting in terms of imparting the author’s perspective to readers.</p>

<p>On the other hand, the notion of the “document” that is intrinsic to web development today is overdetermined by the legacy of print media. The web document is a static, <em>finished</em> artifact that does not bring in dynamic data. This is strange because it lives on a medium that is alive, networked, and dynamic, a medium which we increasingly understand more as a <em>space</em> than a thing.</p>

<p>For example, consider how silly it is to include MLA-style citations at the bottom of a text when we have the vast capabilities of linked documents on the web. Why should the reader have to read every citation or trust that an author is not taking a citation out of context, when hyperlinks are available?</p>

<p>This all suggests that a compromise must be struck between the coherence of a text and the new opportunities for knowledge work afforded by the fundamental capabilities of the medium: the internet’s connectivity, the screen’s frame rate.</p>

<hr>

<p>My own blogging is one context in which I’ve seen this tension play out, and have been working to explore ways of making my texts richer. A lot of the ideas I talk about in various pieces of writing are connected to one another. When I publish an essay, I’m not done with it. The ideas live on and get renewed, reused, and recycled in later works. Some sentences contain definitions that are core to my mental models, and there are whole paragraphs that might be useful out of context. I’m building my knowledge network in mind maps and behind various SaaS APIs, but how can I publicly show my thinking to be part a cohesive worldview?</p>

<p>Normally people solve this by simply block quoting themselves, but this is a waste of an opportunity. The indented block quote is a print medium invention <a href="https://en.wikipedia.org/wiki/Block_quotation#Origins">almost as old as typesetting</a>. The block quote is <em>plaintext</em>, it is not actually linked to the original text or its context.</p>

<p>I’ve been experimenting with one idea for a solution, and if you’ve read the last couple blog posts you’ll have seen it there. My stab at an answer is an iframe which shows the quote within its original context and gives a hint at its surroundings. Effectively, it’s a transclusion within my own blog. I’m currently satisfied with what I have as a v1, and am interested to see if others find it useful, so I’m open sourcing it here and including a tutorial.</p>



<p>Open Transclude is a UX pattern, a spec for networked writing within your own blog. Here’s how it looks:</p>



<!-- <script src="/portal.js"></script> -->



<p>What you are looking at is an scroll-locked iframe that links to a quote I picked out of my blog post “Notes on Comparative Psychology.” You can use Open Transclude anywhere you can drop an <code>&lt;a&gt;</code> tag on your own site.</p>

<p>Open Transclude:</p>
<ul>
  <li>Works anywhere on your own domain</li>
  <li>Compatible with most static site generators / templating engines</li>
  <li>12 lines of HTML, 80 lines of SCSS, 22 lines of JS (4.5 kb total)</li>
  <li>Has 0 dependencies&nbsp;— this is native web technology</li>
</ul>

<p>Open Transclude is extremely simple, and the heaviest part of the code is the CSS, which you can simplify at your whim. That’s why I am referring to it as a UX pattern. This is not a protocol. The code is really a commodity. What’s interesting about it is the idea and the design, and this is just one viable implementation! Feel free to adapt it however you like.</p>

<p>The principal improvement over a block quotation is <em>sense of context</em>.</p>

<p>Over on GitHub you’ll find the <a href="https://github.com/tobyshorin/Open-Transclude/">reference implementation for Jekyll</a>. Below is a tutorial for implementing it yourself, by way of also explaining some of the technical design decisions.</p>

<hr>

<h2 id="implementation-recipe">Implementation Recipe</h2>

<p>Here’s what you need to do to get Open Transclude up and running.</p>

<ol>
  <li>Create an anchor tag in the blog post where you want to cite yourself.</li>
  <li>Create the HTML for the reusable transclusion component.</li>
  <li>Call the portal into any document and passing it Jekyll variables.</li>
  <li>A small piece of Javascript which populates your transclusion into the document.</li>
  <li>Create the SCSS file with the component’s styles.</li>
</ol>

<h3 id="1-create-the-anchor-tag-where-you-want-to-cite-yourself">1. <strong>Create the anchor tag where you want to cite yourself</strong></h3>

<p>To quote yourself, you’ll need to create an <code>&lt;a&gt;</code> anchor tag in the markdown file for the post you want to quote. If you wish to highlight a specific piece of text, instead create a <code>&lt;span&gt;&lt;/span&gt;</code> around the section you want to quote. Note that this can <em>only be on your own website</em>—it doesn’t work cross domain.</p>

<p>Here’s what it looks like for the example iframe above.</p>

<figure><pre><code data-lang="markdown">It will, for one thing, become newly conscious of itself, and, to the degree that it is, <span>**it will tend to undermine its own experiential integrity**</span>" (emphasis mine).

<span>&lt;span</span> <span>name=</span><span>"mainstream-magic"</span><span>&gt;</span>Ironically, psychology remains one of the closest things we have to a mainstream magic or a mystical art today. Not only is it plainly the direct descendent of medieval magic, as I learned when I read Ioan Coulianou's <span>*Eros and Magic in the Renaissance*</span> earlier this year. <span>**It is a theory of the self that is phenomenologically accurate, objectively wrong, and is based on magical thinking even as it deconstructs itself**</span>.<span>&lt;/span&gt;</span> Some magical thinking processes that happen in psychotherapy, such as <span>[</span><span>transference to the psychologist</span><span>](</span><span>https://en.wikipedia.org/wiki/Transference#Transference_and_countertransference_during_psychotherapy</span><span>)</span>, are even intended to stay unmentioned to the patient in order to be utilized most effectively by the therapist!</code></pre></figure>

<h3 id="2-create-your-iframe-component">2. Create your iframe component</h3>

<p>This is most useful as a standardized component which can be used across the site, so we are going to take advantage of Jekyll’s templating features. Jekyll and other static site generators like Kirby and Zola support HTML “partials” or “includes” so that you can create reusable components.</p>

<p>In your <code>/_scss</code> or <code>/_sass</code> folder make a new file, <code>portal.scss</code>. I called it “portal” because it’s shorter than “transclusion” and less prone to spelling errors.</p>

<p>Here’s our component:</p>

<figure><pre><code data-lang="html"><span>&lt;div</span> <span>class=</span><span>"portal-container"</span><span>&gt;</span>
    <span>&lt;div</span> <span>class=</span><span>"portal-head"</span><span>&gt;</span>
        <span>&lt;div</span> <span>class=</span><span>"portal-backlink"</span> <span>&gt;</span>
            <span>&lt;div</span> <span>class=</span><span>"portal-title"</span><span>&gt;</span>From <span>&lt;span</span> <span>class=</span><span>"portal-text-title"</span><span>&gt;</span>{{ include.title }}<span>&lt;/span&gt;&lt;/div&gt;</span>
            <span>&lt;a</span> <span>href=</span><span>"{{ include.link }}"</span> <span>class=</span><span>"portal-arrow"</span><span>&gt;</span>Go to text <span>&lt;span</span> <span>class=</span><span>"right-arrow"</span><span>&gt;</span>→<span>&lt;/span&gt;&lt;/a&gt;</span>
        <span>&lt;/div&gt;</span>
    <span>&lt;/div&gt;</span>
    <span>&lt;div</span> <span>id=</span><span>"portal-parent-{{include.anchor}}"</span> <span>class=</span><span>"portal-parent"</span><span>&gt;</span>
        <span>&lt;div</span> <span>class=</span><span>"portal-parent-fader-top"</span><span>&gt;&lt;/div&gt;</span>
        <span>&lt;div</span> <span>class=</span><span>"portal-parent-fader-bottom"</span><span>&gt;&lt;/div&gt;</span>        
        <span>&lt;!-- We'll use Javascript to populate the iframe right here --&gt;</span>
    <span>&lt;/div&gt;</span>    
<span>&lt;/div&gt;</span></code></pre></figure>

<p>You’ll notice immediately that the iframe isn’t there yet. Like I mentioned above, we’re going to be populating it with Javascript.</p>

<p>You’ll also see that in various places we’re using <code>{{ include.___}}</code>. A cool thing about Jekyll includes its that it’s possible to define variables and pass them to our include, so we can create reusable components across our site. Dave Rupert has a <a href="https://daverupert.com/2017/07/jekyll-includes-are-cool/">nice blog post about this</a> called if you want to see more advanced examples!</p>

<h3 id="3-calling-the-component">3. Calling the component</h3>

<p>Anytime you want to pull this component into a blog post, all you have to do is <code>include</code> it in the markdown of another blog post, like this:</p>

<figure><pre><code data-lang="html">  {% include portal.html title="Notes On Comparative Psychology" link="/entries/notes-on-comparative-psychology/#mainstream-magic" anchor="emotional-deficit" %} </code></pre></figure>

<p>When you include it, you’ll need to pass in those three variables - title, link, and anchor, that fill in the includes above. If you’re following along now and making a build in Jekyll, you’ll see an empty, unstyled component with the link. So good so far!</p>

<h3 id="4-populating-with-javascript">4. Populating with Javascript</h3>

<p>This is a good time to address why we need Javascript. Web developers reading this are probably asking why we don’t simply put the full <code>/link#with-anchor</code> into the iframe src and be done with it. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://subpixel.space/entries/open-transclude/">http://subpixel.space/entries/open-transclude/</a></em></p>]]>
            </description>
            <link>http://subpixel.space/entries/open-transclude/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24402202</guid>
            <pubDate>Mon, 07 Sep 2020 19:54:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DIY IoT door monitor with ESP8266]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24402163">thread link</a>) | @christian_fei
<br/>
September 7, 2020 | https://cri.dev/posts/2020-09-03-DIY-IoT-door-monitor-with-ESP8266/ | <a href="https://web.archive.org/web/*/https://cri.dev/posts/2020-09-03-DIY-IoT-door-monitor-with-ESP8266/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Using an ESP8266 for IoT projects makes me go fast while prototyping.</p><p>The compact format is perfect for small DIY devices.</p><p>Wi-Fi connectivity is built-in, and it's super affordable.</p><blockquote><p>The ESP8266 is a low-cost Wi-Fi microchip, with a full TCP/IP stack and microcontroller capability (<a href="https://en.wikipedia.org/wiki/ESP8266">wikipedia</a>)</p></blockquote><hr><h2>Table of Contents</h2><ul><li><a href="#tldr">tldr;</a></li><li><a href="#requirements">Requirements</a></li><li><a href="#circuit-explanation">Circuit explanation</a></li><li><a href="#coding">Coding</a><ul><li><a href="#install-libraries-for-esp8266">Install libraries for ESP8266</a><ul><li><a href="#adding-the-esp8266-board">Adding the ESP8266 Board</a></li><li><a href="#additional-libraries">Additional libraries</a></li></ul></li><li><a href="#flash-it">Flash it</a></li></ul></li><li><a href="#try-it-out">Try it out!</a></li><li><a href="#next-steps">Next steps</a></li><li><a href="#rest-api">REST API</a></li><li><a href="#web-ui">Web UI</a></li><li><a href="#demo">Demo</a></li></ul><h2>tldr;</h2><p>The door monitor running in my home activates a buzzer when the proximity sensor detects that the door is opened.</p><p>Additionally, it creates an AP for Wi-Fi configuration using a Web interface, and can connect to a desired Wi-Fi network afterwards. <a href="#web-ui">Read more about this below</a></p><p>Source code can be found on <a href="https://github.com/christian-fei/door-monitor-esp8266">GitHub christian-fei/door-monitor-esp8266</a></p><pre><code>git clone https://github.com/christian-fei/door-monitor-esp8266.git
</code></pre><p>The worst photo I could take of the "Gate keeper" in action:</p><p><a href="https://github.com/christian-fei/door-monitor-esp8266/blob/master/Gatekeeper.svg"><img src="https://cri.dev/assets/images/posts/door-monitor/project.jpg" alt="project photo"></a></p><p>The Web UI that this thing has (see home-assistant integration <a href="#next-steps">at the end</a>)</p><p><img src="https://cri.dev/assets/images/posts/door-monitor/gate-keeper-ui.png" alt="gate-keeper-ui"></p><h2>Requirements</h2><p>To build your own, this is what you need:</p><ul><li>Microcontroller ESP8266 (LoLin)</li><li>Active Piezo Buzzer</li><li>Proximity Sensor FC-51</li><li>optionally a breadboard</li></ul><p>Arduino IDE or the Arduino Plug-in for VSCode will work fine for flashing the ESP8266.</p><h2>Circuit explanation</h2><p>Here the schematics for the circuit</p><p><img src="https://cri.dev/assets/images/posts/door-monitor/schematics.svg" alt="schematics door monitor"></p><p>The piezo buzzer is connected to GPIO D6, as an <code>OUTPUT</code> pin.</p><p>The proximity sensor is connected to GPIO D5, as an <code>INPUT</code> pin.</p><p>When the proximity sensor detects that the door is open, the GPIO D5 pin will read <code>HIGH</code>.</p><p>This is when the piezo buzzer is activated, and a simple alarm sound is played.</p><h2>Coding</h2><p>Clone the repository</p><pre><code>git clone https://github.com/christian-fei/door-monitor-esp8266.git
</code></pre><p>Open the project with Arduino IDE by clicking on the <a href="https://github.com/christian-fei/door-monitor-esp8266/blob/master/Gatekeeper.ino"><code>Gatekeeper.ino</code></a> file.</p><p>There is no need to change the code.</p><h3>Install libraries for ESP8266</h3><h4>Adding the ESP8266 Board</h4><p>Using the "Library Manager" in the Arduino IDE, you need to install support for ESP8266.</p><p>Here you can find <a href="https://arduino-esp8266.readthedocs.io/en/latest/installing.html#instructions">the official installation guide</a></p><h4>Additional libraries</h4><p>The project uses <a href="https://github.com/me-no-dev/ESPAsyncTCP/archive/master.zip"><code>ESPAsyncTCP</code></a> and <a href="https://github.com/me-no-dev/ESPAsyncWebServer/archive/master.zip"><code>ESPAsyncWebServer</code></a>.</p><p>Download both ZIP files, and add them either to your Arduino IDE installation libraries or via <code>Add .ZIP Library</code>.</p><h3>Flash it</h3><p>Connect your ESP8266 via USB to your PC.</p><p>Select the <code>usbserial</code> port and <code>NodeMCU 1.0 (ESP - 12 E Module)</code> board in the Arduino IDE.</p><p>Click <code>Upload</code> and flash the ESP8266.</p><h2>Try it out!</h2><p>Now you're ready to apply the board near a door you want to monitor.</p><p>The proximity sensor can both be placed on the door itself or on a wall near the door.</p><p>You'll need to calibrate the sensitivity of the sensor by rotating the potentiometer on the FC-51 chip.</p><h2>Next steps</h2><p>From here I went the following route:</p><p>Made the Gatekeeper available as an iframe element in my <a href="https://www.home-assistant.io/">homeassistant</a> installation. The URL I used was <code>http://gatekeeper.fritz.box</code> (after I connected it to my Wi-Fi network using <a href="#web-ui">the Web UI</a>)</p><p>On the Web UI of the Gatekeeper I can "disarm" the alarm sound and check whether the door is open or closed.</p><p>It looks like this:</p><p><img src="https://cri.dev/assets/images/posts/door-monitor/gate-keeper-homeassistant.png" alt="gate-keeper-homeassistant"></p><p>The next challenge is to register the door monitor as a "sensor" (or "entity" I think it's called in homeassistant lingo).</p><h2>REST API</h2><p>The Gatekeeper can already be called via HTTP on its REST API:</p><pre><code>  HTTP GET /
    -&gt; replies with the client html
  HTTP GET /door
    -&gt; returns the status of the door, whether it's "open" or "closed"
  HTTP GET /alarm
    -&gt; returns the status of the alarm, whether it's "on" or "off"
  HTTP POST /toggle-alarm
    -&gt; toggles the alarm and returns the current status of it
  HTTP POST /setup
    -&gt; to save the Wi-Fi credentials and connect to the desired access point
</code></pre><h2>Web UI</h2><p>The Web UI give you the current status of the door.</p><p>It also features a form where you can input the Wi-Fi credentials to connect to your home network.</p><p><img src="https://cri.dev/assets/images/posts/door-monitor/gate-keeper-ui.png" alt="gate-keeper-ui"></p><p>This means that once the door monitor is connected to Wi-Fi, it's accessible via the hostname <code>gatekeeper</code>.</p><p>E.g. with my FritzBox setup, it's available under <code>gatekeeper.fritz.box:80</code></p><h2>Demo</h2></div></div>]]>
            </description>
            <link>https://cri.dev/posts/2020-09-03-DIY-IoT-door-monitor-with-ESP8266/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24402163</guid>
            <pubDate>Mon, 07 Sep 2020 19:50:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disposable Mask Under the Microscope]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24401984">thread link</a>) | @callmekit
<br/>
September 7, 2020 | http://sdymphoto.com/post/2020/09/07/disposable-mask/ | <a href="https://web.archive.org/web/*/http://sdymphoto.com/post/2020/09/07/disposable-mask/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Here is how one type of now ubiquitous blue disposable mask looks under the microscope.</p>
<p>Using 2x objective:
<img src="http://sdymphoto.com/img/2020/Protective%20mask%202x%20x1.4.jpg" alt="Disposable mask using 2x objective"></p>
<p>Using 4x objective:
<img src="http://sdymphoto.com/img/2020/Protective%20mask%204x%20x1.4.jpg" alt="Disposable mask using 4x objective"></p>
<p>If you like this image, prints and apparel available via Redbubble: <a href="https://www.redbubble.com/people/sdymchenko/works/54778063-disposable-protective-face-mask-under-the-microscope">https://www.redbubble.com/people/sdymchenko/works/54778063-disposable-protective-face-mask-under-the-microscope</a></p>
<p>You can license the photos for commercial and personal use via Alamy: <a href="https://www.alamy.com/outer-layer-of-disposable-protective-face-mask-under-the-microscope-horizontal-field-of-view-is-about-6mm-image368204969.html">https://www.alamy.com/outer-layer-of-disposable-protective-face-mask-under-the-microscope-horizontal-field-of-view-is-about-6mm-image368204969.html</a></p>

</div></div>]]>
            </description>
            <link>http://sdymphoto.com/post/2020/09/07/disposable-mask/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401984</guid>
            <pubDate>Mon, 07 Sep 2020 19:29:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doom Eternal – Graphics Study]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 32 (<a href="https://news.ycombinator.com/item?id=24401805">thread link</a>) | @todsacerdoti
<br/>
September 7, 2020 | https://www.simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html | <a href="https://web.archive.org/web/*/https://www.simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="markdown-content">
            


<p>30 Aug 2020 - Simon Coenen - Reading time: <span title="Estimated read time">
  
  
    23 mins
  
</span><span></span> - <a href="#comment-section">Comments</a>
</p>
<p><img src="https://www.simoncoenen.com/images/blog/010_doom_eternal_study/image1.jpeg" alt=""></p>

<h2 id="background">Background</h2>

<p>Doom Eternal is the successor of Doom 2016. It’s developed using the 7th iteration of id Tech, id Software’s in-house game engine. Doom 2016 has inspired me greatly on a technologic level due to its simplicity and elegance while still having a high visual quality. For Doom Eternal, this is no different. Doom Eternal has improved in many areas of which a few are worth investigating which I will try to cover in this frame breakdown.</p>

<!--more-->

<p>This frame breakdown is inspired by <a href="http://www.adriancourreges.com/blog/2016/09/09/doom-2016-graphics-study/">Adrian Courreges’s study on Doom 2016</a>. I believe these graphics studies give a lot of insight into how certain rendering problems are solved in a AAA game and are greatly educational. In this breakdown I aim to stay at a high level and not go too in-depth of each rendering technique/pass. Some passes might not be covered here because they are very similar to Doom 2016 and are well covered in Adrian Courreges’s study.</p>

<p>I do want to stress here that these studies are absolutely nothing more than <strong>educational</strong>. I do not in any way support the reverse engineering for malicious purposes and stealing intellectual property. If you haven’t played the game yet, don’t worry about spoilers! The section I used for this study is in the beginning of the game which doesn’t give away any of the details.</p>

<p>Now, let’s get down to business.</p>

<p>With Id Tech 7, the engine has moved away from OpenGL and is entirely built with a <strong>Vulkan</strong> backend allowing them to make better use of current generation GPU features, bindless resources in particular.</p>

<hr>



<p><img src="https://www.simoncoenen.com/images/blog/010_doom_eternal_study/image2.png" alt=""></p>

<p>We’re looking at a section in the game close to the start. It’s an interior with a few enemies and a large portion of volumetric lighting. Just like its predecessor, Doom Eternal is using a <strong>forward rendering</strong> pipeline. Doom 2016 was mostly forward rendered with a thin G-Buffer for screen space reflections. However this time, everything is fully forward rendered omitting the G-Buffer.</p>

<hr>

<h2 id="step-away-from-mega-texture">Step away from Mega-Texture</h2>

<p>With id Tech 5 used in <a href="https://en.wikipedia.org/wiki/Rage_(video_game)">Rage</a>, there was a texture streaming concept introduced called ‘Mega-Texture’ which was also used in the previous Doom installment. This system works by rendering a so called ‘feedback texture’ each frame that contains the information of what texture data was visible, that texture is analysed next frame to determine which textures get streamed in from disk. This has an obvious flaw because once a texture is on screen, it’s basically already too late to load it and this causes blurry textures the first few frames it is on screen. In id Tech 7, id Software has stepped away from this approach.</p>

<hr>

<h2 id="gpu-skinning">GPU Skinning</h2>

<p>The first thing that happens even before anything gets drawn to a texture, is evaluating skinning. This is commonly done in a vertex shader before shading. An alternative approach used here, is to do skinning beforehand in a compute shader which writes out skinned vertices to a buffer. This has a couple of advantages mainly not having to do skinning in the vertex shader for every geometry pass. This results in having less shader permutations because the vertex shader doesn’t have to know about skinning.</p>

<p>Skinning in a compute shader is not much different from in a vertex shader except that the output gets written to an intermediate buffer which can then be consumed in a vertex shader that can treat it as a regular static mesh. Just like in a vertex shader, for each vertex, a compute shader thread retrieves the transform of each bone affecting the vertex, transforms its position with each bone transform and adds up these positions based on the skin weights stored on the vertex.</p>

<p>János Turánszki wrote a wonderful write-up of how it can be implemented using a compute shader:
<a href="https://wickedengine.net/2017/09/09/skinning-in-compute-shader/">https://wickedengine.net/2017/09/09/skinning-in-compute-shader/</a>.</p>

<p>Another thing that is worth noting here is the use of <strong>Alembic Caches</strong> in Doom Eternal. These caches contain baked animation which get streamed and decompressed at runtime. As <a href="https://www.youtube.com/watch?v=UsmqWSZpgJY">Digital Foundry described in their tech breakdown</a>, this is used for a wide range of animations going from large cinematic pieces to small tentacles on the floor. This is especially useful for animations that are hard to achieve using skinned animation like organics and cloth simulation. You can compare an Alembic Cache with a video that can be played back and is highly compressed by looking ahead. I suggest watching <a href="https://www.youtube.com/watch?v=zlz-7V_XiUA">Axel Gneiting’s talk at Siggraph 2014</a> if you’re interested in learning more.</p>

<hr>

<h2 id="shadow-mapping">Shadow Mapping</h2>

<p>Next up is shadow rendering. There doesn’t seem to be any large changes in how shadow maps are approached in id Tech 7 compared to its predecessor.</p>

<p>As seen below, shadows get rendered in a large 4096x8196px 24-bit depth texture which may vary across quality levels. The texture is persistent across frames and as described in “Devil is in the Details” at Siggraph 2016, the static geometry in the shadow map is cached to save having to redraw the shadow maps each frame. The technique is fairly simple: as long as nothing in the view of the light moves, there is no need to update the shadows. If a dynamic object in the frustum moves, a ‘cached’ shadow map is copied into the actual shadow map and the dynamic geometry is re-drawn on top. This cached shadow map is the same shadow map but only with static geometry because you can make the assumption that these will never change. This saves having to draw the entire scene in the frustum every time it needs to update. Of course, when the light moves, the entire scene has to be redrawn from scratch.</p>

<p>When sampling the shadow map during lighting, a 3x3 PCF sampling approach is used to smoothen the shadow edges. For the sun light, <strong>cascaded shadow maps</strong> are used to distribute the quality better as it covers such a large portion of the environment.</p>

<p>Here is a closer look at the shadow atlas. A light with higher importance, larger screen area or that is closer to the camera, will get a larger portion of the atlas assigned for better resolution. These heuristics are evaluated dynamically.</p>

<p><img src="https://www.simoncoenen.com/images/blog/010_doom_eternal_study/image3.jpeg" alt=""></p>

<hr>

<h2 id="depth-pre-pass-and-velocity">Depth Pre-pass and Velocity</h2>

<p>Opaque geometry gets rendered to a depth-only target starting with the player’s gun, then static geometry, and finally dynamic geometry. A depth pre-pass is common to avoid unnecessary pixel shader calculations later down the pipeline where geometry overlaps. A depth pre-pass is especially important in a forward renderer where redundant pixel calculations are extremely wasteful due to pixel overdraw. With a depth pre-pass, the actual forward lighting pixel shader can reject pixels by comparing with the depth buffer before execution, saving a lot of performance.</p>

<div id="prepassCarousel" data-ride="carousel">
  <ol>
    <li data-target="#prepassCarousel" data-slide-to="0"></li>
    <li data-target="#prepassCarousel" data-slide-to="1"></li>
    <li data-target="#prepassCarousel" data-slide-to="2"></li>
  </ol>
  <div>
    <div>
      <p><img src="https://www.simoncoenen.com/images/blog/010_doom_eternal_study/Prepass0.png"></p><p>First person gun</p>
    </div>
    <div>
      <p><img src="https://www.simoncoenen.com/images/blog/010_doom_eternal_study/Prepass1.png"></p><p>Static objects</p>
    </div>
    <div>
      <p><img src="https://www.simoncoenen.com/images/blog/010_doom_eternal_study/Prepass2.png"></p><p>Dynamic objects</p>
    </div>
  </div>
  <p><a href="#prepassCarousel" role="button" data-slide="prev">
    
    <span>Previous</span>
  </a>
  <a href="#prepassCarousel" role="button" data-slide="next">
    
    <span>Next</span>
  </a>
</p></div>

<p>Besides rendering depth, the pre-pass also renders to another color target. For dynamic geometry, the velocity is rendered using motion vectors which is the position of the current position subtracted from the position of the pixel in the previous frame. We only need the motion on the X and Y axis so the motion is stored in the red and green channel of a 16-bit floating point render target. This information is later used in post processing for applying motion blur and reprojection for temporal anti-aliasing. The image below is exaggerated because this snapshot doesn’t have a lot of motion. Static geometry does not need motion vectors as their motion can be derived from the camera motion because they have only “moved” relative to the camera.</p>

<p><img src="https://www.simoncoenen.com/images/blog/010_doom_eternal_study/image6.jpeg" alt=""></p>

<hr>

<h2 id="hierarchical-z-depth">Hierarchical-Z Depth</h2>

<p>Next up, a hierarchical mip chain of the depth buffer is generated which is similar to a mip map but instead of averaging 4 neighboring pixels, the maximum is taken. This is commonly done in graphics for various purposes like accelerating screen space reflections and occlusion culling. In this case, this mip chain is used to accelerate the light and decal culling which is covered later. More recently, mip generation is done in a single pass by writing into multiple mips at once. In Doom Eternal, it still traditionally does a dispatch for every mip separately.</p>

<p><img src="https://www.simoncoenen.com/images/blog/010_doom_eternal_study/image7.gif" alt=""></p>

<hr>

<h2 id="mesh-decals">Mesh Decals</h2>

<p>Up until what I’ve covered so far, there haven’t been many noticeable changes compared to Doom 2016. However, “mesh decals” is an addition to the mesh rendering pipeline introduced in Doom Eternal. Unlike the common decal workflow - which are placed freely in the environment - a mesh decal is placed during the mesh authoring pipeline by artists and so belong to the mesh. Before, Doom heavily relied on decals and stepped it up with the addition of so called “mesh decals” in this game for even better detailing and flexibility. “Mesh decals” are small decals like bolts, grills, bumps, stickers, … Just like a traditional decal, it can modify any property of the underlying surface like the normal, roughness, base color, …</p>

<p>To achieve this, the following geometry pass renders each of the decals’s ID into an 8-bit render target. Later during shading, this texture is sampled to retrieve the ID which is used to retrieve a projection matrix bound with each draw call. The matrix projects the pixel’s position from world space into texture space. These coordinates are then used to sample the decal and blend with the underlying material. This is extremely fast and allows artists to go crazy with massive amounts of decals. Because the IDs are rendered to an 8-bit texture, the maximum amount of decals per mesh would theoretically be 255.</p>

<p>One requirement for this, is that all decals are bound to the pipeline when drawing meshes. Doom Eternal uses a fully bindless render pipeline which allows them to bind all decal textures at once and dynamically index them in the shader. More on this bindless pipeline later as this is important to pull off other tricks they’ve done in this game.</p>

<p>Below, the mesh decal texture. The different IDs are coloured to visualize it better.</p>

<p><img src="https://www.simoncoenen.com/images/blog/010_doom_eternal_study/image8.jpeg" alt=""></p>

<hr>

<h2 id="light-and-decal-culling">Light and …</h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html">https://www.simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html</a></em></p>]]>
            </description>
            <link>https://www.simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401805</guid>
            <pubDate>Mon, 07 Sep 2020 19:10:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Doom Eternal Renders a Frame]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24401682">thread link</a>) | @corysama
<br/>
September 7, 2020 | https://simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html | <a href="https://web.archive.org/web/*/https://simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="markdown-content">
            


<p>30 Aug 2020 - Simon Coenen - Reading time: <span title="Estimated read time">
  
  
    23 mins
  
</span><span></span> - <a href="#comment-section">Comments</a>
</p>
<p><img src="https://simoncoenen.com/images/blog/010_doom_eternal_study/image1.jpeg" alt=""></p>

<h2 id="background">Background</h2>

<p>Doom Eternal is the successor of Doom 2016. It’s developed using the 7th iteration of id Tech, id Software’s in-house game engine. Doom 2016 has inspired me greatly on a technologic level due to its simplicity and elegance while still having a high visual quality. For Doom Eternal, this is no different. Doom Eternal has improved in many areas of which a few are worth investigating which I will try to cover in this frame breakdown.</p>

<!--more-->

<p>This frame breakdown is inspired by <a href="http://www.adriancourreges.com/blog/2016/09/09/doom-2016-graphics-study/">Adrian Courreges’s study on Doom 2016</a>. I believe these graphics studies give a lot of insight into how certain rendering problems are solved in a AAA game and are greatly educational. In this breakdown I aim to stay at a high level and not go too in-depth of each rendering technique/pass. Some passes might not be covered here because they are very similar to Doom 2016 and are well covered in Adrian Courreges’s study.</p>

<p>I do want to stress here that these studies are absolutely nothing more than <strong>educational</strong>. I do not in any way support the reverse engineering for malicious purposes and stealing intellectual property. If you haven’t played the game yet, don’t worry about spoilers! The section I used for this study is in the beginning of the game which doesn’t give away any of the details.</p>

<p>Now, let’s get down to business.</p>

<p>With Id Tech 7, the engine has moved away from OpenGL and is entirely built with a <strong>Vulkan</strong> backend allowing them to make better use of current generation GPU features, bindless resources in particular.</p>

<hr>



<p><img src="https://simoncoenen.com/images/blog/010_doom_eternal_study/image2.png" alt=""></p>

<p>We’re looking at a section in the game close to the start. It’s an interior with a few enemies and a large portion of volumetric lighting. Just like its predecessor, Doom Eternal is using a <strong>forward rendering</strong> pipeline. Doom 2016 was mostly forward rendered with a thin G-Buffer for screen space reflections. However this time, everything is fully forward rendered omitting the G-Buffer.</p>

<hr>

<h2 id="step-away-from-mega-texture">Step away from Mega-Texture</h2>

<p>With id Tech 5 used in <a href="https://en.wikipedia.org/wiki/Rage_(video_game)">Rage</a>, there was a texture streaming concept introduced called ‘Mega-Texture’ which was also used in the previous Doom installment. This system works by rendering a so called ‘feedback texture’ each frame that contains the information of what texture data was visible, that texture is analysed next frame to determine which textures get streamed in from disk. This has an obvious flaw because once a texture is on screen, it’s basically already too late to load it and this causes blurry textures the first few frames it is on screen. In id Tech 7, id Software has stepped away from this approach.</p>

<hr>

<h2 id="gpu-skinning">GPU Skinning</h2>

<p>The first thing that happens even before anything gets drawn to a texture, is evaluating skinning. This is commonly done in a vertex shader before shading. An alternative approach used here, is to do skinning beforehand in a compute shader which writes out skinned vertices to a buffer. This has a couple of advantages mainly not having to do skinning in the vertex shader for every geometry pass. This results in having less shader permutations because the vertex shader doesn’t have to know about skinning.</p>

<p>Skinning in a compute shader is not much different from in a vertex shader except that the output gets written to an intermediate buffer which can then be consumed in a vertex shader that can treat it as a regular static mesh. Just like in a vertex shader, for each vertex, a compute shader thread retrieves the transform of each bone affecting the vertex, transforms its position with each bone transform and adds up these positions based on the skin weights stored on the vertex.</p>

<p>János Turánszki wrote a wonderful write-up of how it can be implemented using a compute shader:
<a href="https://wickedengine.net/2017/09/09/skinning-in-compute-shader/">https://wickedengine.net/2017/09/09/skinning-in-compute-shader/</a>.</p>

<p>Another thing that is worth noting here is the use of <strong>Alembic Caches</strong> in Doom Eternal. These caches contain baked animation which get streamed and decompressed at runtime. As <a href="https://www.youtube.com/watch?v=UsmqWSZpgJY">Digital Foundry described in their tech breakdown</a>, this is used for a wide range of animations going from large cinematic pieces to small tentacles on the floor. This is especially useful for animations that are hard to achieve using skinned animation like organics and cloth simulation. You can compare an Alembic Cache with a video that can be played back and is highly compressed by looking ahead. I suggest watching <a href="https://www.youtube.com/watch?v=zlz-7V_XiUA">Axel Gneiting’s talk at Siggraph 2014</a> if you’re interested in learning more.</p>

<hr>

<h2 id="shadow-mapping">Shadow Mapping</h2>

<p>Next up is shadow rendering. There doesn’t seem to be any large changes in how shadow maps are approached in id Tech 7 compared to its predecessor.</p>

<p>As seen below, shadows get rendered in a large 4096x8196px 24-bit depth texture which may vary across quality levels. The texture is persistent across frames and as described in “Devil is in the Details” at Siggraph 2016, the static geometry in the shadow map is cached to save having to redraw the shadow maps each frame. The technique is fairly simple: as long as nothing in the view of the light moves, there is no need to update the shadows. If a dynamic object in the frustum moves, a ‘cached’ shadow map is copied into the actual shadow map and the dynamic geometry is re-drawn on top. This cached shadow map is the same shadow map but only with static geometry because you can make the assumption that these will never change. This saves having to draw the entire scene in the frustum every time it needs to update. Of course, when the light moves, the entire scene has to be redrawn from scratch.</p>

<p>When sampling the shadow map during lighting, a 3x3 PCF sampling approach is used to smoothen the shadow edges. For the sun light, <strong>cascaded shadow maps</strong> are used to distribute the quality better as it covers such a large portion of the environment.</p>

<p>Here is a closer look at the shadow atlas. A light with higher importance, larger screen area or that is closer to the camera, will get a larger portion of the atlas assigned for better resolution. These heuristics are evaluated dynamically.</p>

<p><img src="https://simoncoenen.com/images/blog/010_doom_eternal_study/image3.jpeg" alt=""></p>

<hr>

<h2 id="depth-pre-pass-and-velocity">Depth Pre-pass and Velocity</h2>

<p>Opaque geometry gets rendered to a depth-only target starting with the player’s gun, then static geometry, and finally dynamic geometry. A depth pre-pass is common to avoid unnecessary pixel shader calculations later down the pipeline where geometry overlaps. A depth pre-pass is especially important in a forward renderer where redundant pixel calculations are extremely wasteful due to pixel overdraw. With a depth pre-pass, the actual forward lighting pixel shader can reject pixels by comparing with the depth buffer before execution, saving a lot of performance.</p>

<div id="prepassCarousel" data-ride="carousel">
  <ol>
    <li data-target="#prepassCarousel" data-slide-to="0"></li>
    <li data-target="#prepassCarousel" data-slide-to="1"></li>
    <li data-target="#prepassCarousel" data-slide-to="2"></li>
  </ol>
  <div>
    <div>
      <p><img src="https://simoncoenen.com/images/blog/010_doom_eternal_study/Prepass0.png"></p><p>First person gun</p>
    </div>
    <div>
      <p><img src="https://simoncoenen.com/images/blog/010_doom_eternal_study/Prepass1.png"></p><p>Static objects</p>
    </div>
    <div>
      <p><img src="https://simoncoenen.com/images/blog/010_doom_eternal_study/Prepass2.png"></p><p>Dynamic objects</p>
    </div>
  </div>
  <p><a href="#prepassCarousel" role="button" data-slide="prev">
    
    <span>Previous</span>
  </a>
  <a href="#prepassCarousel" role="button" data-slide="next">
    
    <span>Next</span>
  </a>
</p></div>

<p>Besides rendering depth, the pre-pass also renders to another color target. For dynamic geometry, the velocity is rendered using motion vectors which is the position of the current position subtracted from the position of the pixel in the previous frame. We only need the motion on the X and Y axis so the motion is stored in the red and green channel of a 16-bit floating point render target. This information is later used in post processing for applying motion blur and reprojection for temporal anti-aliasing. The image below is exaggerated because this snapshot doesn’t have a lot of motion. Static geometry does not need motion vectors as their motion can be derived from the camera motion because they have only “moved” relative to the camera.</p>

<p><img src="https://simoncoenen.com/images/blog/010_doom_eternal_study/image6.jpeg" alt=""></p>

<hr>

<h2 id="hierarchical-z-depth">Hierarchical-Z Depth</h2>

<p>Next up, a hierarchical mip chain of the depth buffer is generated which is similar to a mip map but instead of averaging 4 neighboring pixels, the maximum is taken. This is commonly done in graphics for various purposes like accelerating screen space reflections and occlusion culling. In this case, this mip chain is used to accelerate the light and decal culling which is covered later. More recently, mip generation is done in a single pass by writing into multiple mips at once. In Doom Eternal, it still traditionally does a dispatch for every mip separately.</p>

<p><img src="https://simoncoenen.com/images/blog/010_doom_eternal_study/image7.gif" alt=""></p>

<hr>

<h2 id="mesh-decals">Mesh Decals</h2>

<p>Up until what I’ve covered so far, there haven’t been many noticeable changes compared to Doom 2016. However, “mesh decals” is an addition to the mesh rendering pipeline introduced in Doom Eternal. Unlike the common decal workflow - which are placed freely in the environment - a mesh decal is placed during the mesh authoring pipeline by artists and so belong to the mesh. Before, Doom heavily relied on decals and stepped it up with the addition of so called “mesh decals” in this game for even better detailing and flexibility. “Mesh decals” are small decals like bolts, grills, bumps, stickers, … Just like a traditional decal, it can modify any property of the underlying surface like the normal, roughness, base color, …</p>

<p>To achieve this, the following geometry pass renders each of the decals’s ID into an 8-bit render target. Later during shading, this texture is sampled to retrieve the ID which is used to retrieve a projection matrix bound with each draw call. The matrix projects the pixel’s position from world space into texture space. These coordinates are then used to sample the decal and blend with the underlying material. This is extremely fast and allows artists to go crazy with massive amounts of decals. Because the IDs are rendered to an 8-bit texture, the maximum amount of decals per mesh would theoretically be 255.</p>

<p>One requirement for this, is that all decals are bound to the pipeline when drawing meshes. Doom Eternal uses a fully bindless render pipeline which allows them to bind all decal textures at once and dynamically index them in the shader. More on this bindless pipeline later as this is important to pull off other tricks they’ve done in this game.</p>

<p>Below, the mesh decal texture. The different IDs are coloured to visualize it better.</p>

<p><img src="https://simoncoenen.com/images/blog/010_doom_eternal_study/image8.jpeg" alt=""></p>

<hr>

<h2 id="light-and-decal-culling">Light and …</h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html">https://simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html</a></em></p>]]>
            </description>
            <link>https://simoncoenen.com/blog/programming/graphics/DoomEternalStudy.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401682</guid>
            <pubDate>Mon, 07 Sep 2020 18:56:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Configs for privacy-hating software, like Firefox and Chrome]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24401340">thread link</a>) | @vital303
<br/>
September 7, 2020 | http://r-36.net/scm/privacy-haters | <a href="https://web.archive.org/web/*/http://r-36.net/scm/privacy-haters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://r-36.net/scm/privacy-haters</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401340</guid>
            <pubDate>Mon, 07 Sep 2020 18:19:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Kubernetes: A single OAuth2 proxy for multiple ingresses]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24401287">thread link</a>) | @theykk
<br/>
September 7, 2020 | https://www.callumpember.com/Kubernetes-A-Single-OAuth2-Proxy-For-Multiple-Ingresses/ | <a href="https://web.archive.org/web/*/https://www.callumpember.com/Kubernetes-A-Single-OAuth2-Proxy-For-Multiple-Ingresses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="article" id="scroll" itemprop="articleBody">
                <p>One of the problems most Kubernetes administrators will eventually face is protecting an Ingress from public access. There are a number of ways to do this, including IP whitelisting, TLS authentication, use an internal only service for the ingress controller, and many more.</p>

<p>One of my favorite ways is to use <a href="https://github.com/pusher/oauth2_proxy">oauth2_proxy</a>. I’ve used it a number of times over the years, but there was always a drawback that bothered me - with the <a href="https://github.com/kubernetes/ingress-nginx/tree/master/docs/examples/auth/oauth-external-auth">documented setup</a> and other countless examples online, they use a deployment of the oauth2_proxy container per deployment/service/ingress that the user is wanting to protect. Although the resource footprint of oauth2_proxy is small, that is needless waste.</p>

<p>Now, onto some oauth2_proxy details. You can use various different providers, like GitHub, Google, GitLab, LinkedIn, Azure and Facebook. What’s one thing nearly every developer in the world has in common? They almost certainly have a GitHub account, so that’s what I use as a provider normally.  There are some strict rules though around GitHub OAuth2 and redirection:</p>

<p><img src="https://www.callumpember.com/assets/attachments/github-oauth2/github-oauth-redirection-rules.png" alt="GitHub OAuth2 Redirection rules"></p>

<p>What this means is that if you are using oauth2_proxy as-is, you need a separate deployment for each domain you want to secure.</p>

<blockquote>
  <p>But I want to secure https://prometheus.mydomain.com, https://grafana.mydomain.com and https://alertmanager.mydomain.com. So I need separate deployments of oauth2_proxy for that?</p>
</blockquote>

<p>Out of the box, sadly yes. But with a slight modification of the deployment, we can use a single oauth2_proxy instance for any domain we want. To do this we do the following:</p>

<ul>
  <li>Attach an nginx sidecar container to the oauth2_proxy deployment. This container will redirect to anything after <code>/redirect/</code> in the request URI.</li>
  <li>Make the oauth2_proxy have it’s own domain</li>
  <li>Add an upstream to oauth2_proxy for the /redirect path</li>
  <li>Set the cookie domain in oauth2_proxy to include all subdomains</li>
  <li>Setup a GitHub OAuth2 app and point it at the oauth2_proxy domain</li>
  <li>In the ingresses that we want to protect, use the following annotations (replace $DNS_ZONE_INTERNAL with your own domain):</li>
</ul>

<figure><pre><code data-lang="yaml"><span>---</span>
<span>nginx.ingress.kubernetes.io/auth-url</span><span>:</span> <span>"</span><span>https://oauth2.$DNS_ZONE_INTERNAL/oauth2/auth"</span>
<span>nginx.ingress.kubernetes.io/auth-signin</span><span>:</span> <span>"</span><span>https://oauth2.$DNS_ZONE_INTERNAL/oauth2/start?rd=/redirect/$http_host$request_uri"</span></code></pre></figure>

<h3 id="oauth2_proxy-deployment">oauth2_proxy deployment:</h3>

<p>Here is a full, working (at least in my cluster) deployment spec for oauth2_proxy with the nginx sidecar.</p>

<p>If you want to use it, you’d need to replace all the variables. I personally use envsubst in my deployment pipelines for this. The variables that need replacing are <code>$DNS_ZONE_INTERNAL</code> <code>$OAUTH2_CLIENT_ID</code> <code>$OAUTH2_CLIENT_SECRET</code> and you would want to set your GitHub org.</p>

<p><a href="https://www.callumpember.com/assets/attachments/github-oauth2/full-deployment.yml.txt">Full Deployment Spec</a></p>

<h3 id="ingress-example">Ingress example</h3>

<p>Once you’ve got the deployment above working, you can protect an ingress like so (key takeaways are the annotations):</p>

<figure><pre><code data-lang="yaml"><span>---</span>

<span>apiVersion</span><span>:</span> <span>extensions/v1beta1</span>
<span>kind</span><span>:</span> <span>Ingress</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>prometheus</span>
  <span>namespace</span><span>:</span> <span>istio-system</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>prometheus</span>
  <span>annotations</span><span>:</span>
    <span>kubernetes.io/ingress.class</span><span>:</span> <span>"</span><span>nginx-public"</span>
    <span>nginx.ingress.kubernetes.io/auth-url</span><span>:</span> <span>"</span><span>https://oauth2.$DNS_ZONE_INTERNAL/oauth2/auth"</span>
    <span>nginx.ingress.kubernetes.io/auth-signin</span><span>:</span> <span>"</span><span>https://oauth2.$DNS_ZONE_INTERNAL/oauth2/start?rd=/redirect/$http_host$escaped_request_uri"</span>
<span>spec</span><span>:</span>
  <span>rules</span><span>:</span>
  <span>-</span> <span>host</span><span>:</span> <span>"</span><span>prometheus.$DNS_ZONE_INTERNAL"</span>
    <span>http</span><span>:</span>
      <span>paths</span><span>:</span>
      <span>-</span> <span>path</span><span>:</span> <span>/</span>
        <span>backend</span><span>:</span>
          <span>serviceName</span><span>:</span> <span>prometheus</span>
          <span>servicePort</span><span>:</span> <span>http</span></code></pre></figure>

<p>Hopefully this saves you some resources in your cluster and some time creating multiple oauth2_proxy deployments!</p>

            </article></div>]]>
            </description>
            <link>https://www.callumpember.com/Kubernetes-A-Single-OAuth2-Proxy-For-Multiple-Ingresses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401287</guid>
            <pubDate>Mon, 07 Sep 2020 18:11:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Polyglot Code Explorer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24401227">thread link</a>) | @derkoe
<br/>
September 7, 2020 | https://blog.korny.info/2020/09/06/introducing-the-polyglot-code-explorer.html | <a href="https://web.archive.org/web/*/https://blog.korny.info/2020/09/06/introducing-the-polyglot-code-explorer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main"><article>
<header>

<time>Sep  6 2020</time>
</header>
<p><img src="https://blog.korny.info/2020-09-01-polyglot-explorer/main_ui_sample.png" alt="Main UI"></p>

<p><em>If you want a quick look at the explorer, you can see <a href="http://polyglot-code-explorer.s3-website.eu-west-2.amazonaws.com/">a simple demo here</a> or <a href="http://polyglot-code-explorer-openmrs.s3-website.eu-west-2.amazonaws.com/">a more complex one here</a>.  There is also a documentation site at  <a href="https://polyglot.korny.info/">https://polyglot.korny.info</a> (currently a work-in-progress).</em></p>

<h2 id="welcome-to-the-polyglot-code-explorer">Welcome to the Polyglot Code Explorer</h2>

<p>The Polyglot Code Explorer is an open-source tool for visualising complex codebases written in multiple programming languages.</p>

<p>In this article I am going to explain its purpose, how you can run it yourself, and what it does.</p>

<h2 id="what-is-it-for">What is it for?</h2>

<p>Fundamentally, I wanted to answer the question:</p>

<blockquote>
  <p>How can we visualise large codebases without needing complex language-specific parsers and logic?</p>
</blockquote>

<p>Partly I wanted to easily spot toxic code - my colleague <a href="https://erik.doernenburg.com/2013/06/toxicity-reloaded/">Erik Dörnenberg wrote some great articles on Toxic code visualisation</a> and I wanted a way to spot some of these problem areas myself.</p>

<p>But also, I just wanted to be able to explore the code quickly.  I'm a visual thinker, so my main focus is on visualisation - especially when trying to spot patterns in millions of lines of code.</p>

<p>It is far quicker for me to look at a diagram and see some unusual colouring in one area, than to see the same information in a table of numbers.</p>

<h3 id="why-polyglot">Why polyglot?</h3>

<p>Polyglot means "speaking multiple languages" - in this case, it means these tools should work, to some degree, for any text-based programming language.</p>

<p>I've worked in many programming languages over the years, and a lot of them don't have good or easy code quality tools - either they are too new for a community to have built them, or they are from ancient projects where even if such tools exist, getting them up and running is a headache.  And each tool probably produces different metrics in different formats - it's hard to get any sort of big-picture view.</p>

<p>Also many real world systems don't use a single language - often it is better to use specialist languages for different tasks, rather than one general-purpose one.  For example one project might have a UI built in JavaScript and HTML, a microservice built in Kotlin and a platform automation tool build in Rust.</p>

<p>Also I was inspired by reading Adam Tornhill's book <a href="https://www.goodreads.com/book/show/23627482-your-code-as-a-crime-scene">"Your code as a crime scene"</a> - he talks about all the things you can learn from really simple metrics like lines of code, and indentation, and change history.  None of these need a complex language parser - and complex language parsers tend to be touchy and flaky.  Most of my code uses no language parser at all, or just a very simple which can distinguish code from comments.</p>

<p>And finally - supporting all the various languages out there is a lot of work!  Quite a few of the other tools I found linked from Erik's articles, and elsewhere, seem to have parsers for a number of languages - but progress is slow, and often they don't keep up with new languages or language changes.  Staying largely language-agnostic makes it much easier for me to maintain my code, and not have to worry about it stagnating.</p>

<h2 id="how-to-run-the-explorer">How to run the Explorer</h2>

<p>The explorer is actually the front end component of three tightly coupled applications:</p>

<p><img src="https://blog.korny.info/2020-09-01-polyglot-explorer/flowchart.png" alt="Tools flowchart"></p>

<ul>
  <li>The Polyglot Code Scanner is a rust application, which scans the source code and produces a JSON data file</li>
  <li>The Polyglot Code Offline Layout tool is a node.js script which adds layout information to the JSON data file</li>
  <li>The Polyglot Code Explorer is a react/D3 web app which provides the user interface for exploring the code</li>
</ul>

<p>The code is open source, you can find it on GitHub:</p>

<ul>
  <li><a href="https://github.com/kornysietsma/polyglot-code-scanner">https://github.com/kornysietsma/polyglot-code-scanner</a></li>
  <li><a href="https://github.com/kornysietsma/polyglot-code-offline-layout">https://github.com/kornysietsma/polyglot-code-offline-layout</a></li>
  <li><a href="https://github.com/kornysietsma/polyglot-code-explorer">https://github.com/kornysietsma/polyglot-code-explorer</a></li>
</ul>

<blockquote>
  <p>I should add a disclaimer - I am not a rust guru, and I am definitely not a react guru!  This is side project code, not commercial-quality - it may well have bugs, mistakes, ugliness, and it has far less testing than I'd usually expect :)</p>
</blockquote>

<p>You may prefer to run these tools from source code - not all the executables have been tested on all platforms! There are some <a href="https://polyglot.korny.info/tools/explorer/howto">more detailed how-to guides on the docs site</a> if you want to build them yourself, or need more details than the brief instructions below.</p>

<h3 id="getting-the-executable-files">Getting the executable files</h3>

<p>Each of the tools is packaged up as an executable file - the Scanner is written in rust, so it's easy to just compile a binary.  The Layout app is a node.js script, I've used <a href="https://www.npmjs.com/package/pkg">pkg</a> to build a bundled executable.  And the Explorer can be run as a static website, so the packages are a zipped up bundle of all files needed to build the website, which you can run yourself.</p>

<ul>
  <li>Scanner executables can be downloaded from <a href="https://github.com/kornysietsma/polyglot-code-scanner/releases">https://github.com/kornysietsma/polyglot-code-scanner/releases</a></li>
  <li>Layout executables can be downloaded from <a href="https://github.com/kornysietsma/polyglot-code-offline-layout/releases">https://github.com/kornysietsma/polyglot-code-offline-layout/releases</a></li>
  <li>Explorer bundles can be downloaded from <a href="https://github.com/kornysietsma/polyglot-code-explorer/releases">https://github.com/kornysietsma/polyglot-code-explorer/releases</a></li>
</ul>

<p>If you are on a Mac you will need to strip Apple's quarantine attributes from the binary files to avoid the "app is from an unknown developer" error:</p>

<div><pre><code><span>tar </span>zxf polyglot-code-scanner-vwhatever-x86_64-apple-darwin.tar.gz
<span>cd </span>polyglot-code-scanner-vwhatever-x86_64-apple-darwin
xattr <span>-d</span> com.apple.quarantine polyglot_code_scanner

unzip polyglot-code-offline-layout-macos.zip
xattr <span>-d</span> com.apple.quarantine polyglot-code-offline-layout
</code></pre></div>
<p>The Explorer is not an executable file - it's a zip file containing the HTML, CSS and JavaScript files needed to run the site.  You can run them locally by running a tiny web server yourself using Python - <a href="https://developer.mozilla.org/en-US/docs/Learn/Common_questions/set_up_a_local_testing_server">there are more detailed instructions here</a> or there's a big list of similar servers in other languages <a href="https://gist.github.com/willurd/5720255">here</a> - I'll use Python 3 below.</p>

<h3 id="running-them">Running them</h3>

<p>A short sample of running these together might help:</p>

<div><pre><code><span>$ </span><span>cd</span> ~/work
<span>$ </span>polyglot_code_scanner <span>--coupling</span> <span>--years</span> 3 <span>-o</span> my_project_1.json ~/src/my_project
<span># this can be slow for big projects, or if you scan back through many years of history</span>
<span># coupling is optional, remove --coupling to speed it up if you don't want it</span>
<span># Check there are no errors and the my_project_1.json file is there</span>

<span>$ </span>polyglot-code-offline-layout <span>-i</span> my_project_1.json <span>-o</span> my_project_2.json
<span># this can be slow for big files</span>
<span># Check there are no errors and the my_project_2.json file is there</span>

<span># the first time, you need to unzip the explorer files</span>
<span>$ </span>unzip ~/downloads/polyglot-code-explorer.zip
Archive:  polyglot-code-explorer.zip
   creating: polyglot-code-explorer/
<span>$ </span>cp my_project_2.json polyglot-code-explorer/data/default.json
<span>$ </span><span>cd </span>polyglot-code-explorer
<span>$ </span>python3 <span>-m</span> http.server
Serving HTTP on 0.0.0.0 port 8000 <span>(</span>http://0.0.0.0:8000/<span>)</span>
</code></pre></div>
<p>Then open a browser to <a href="http://0.0.0.0:8000/">http://0.0.0.0:8000</a> to start exploring!</p>

<h2 id="using-the-ui">Using the UI</h2>

<p>The Explorer front end looks somewhat like this:</p>

<p><img src="https://blog.korny.info/2020-09-01-polyglot-explorer/Main_UI.png" alt="Main UI"></p>

<p>There is more about how to use the UI <a href="http://localhost:2222/tools/explorer/ui">on the docs site</a></p>

<p>The centre of the display shows the files in your project - I'm using a <a href="https://en.wikipedia.org/wiki/Weighted_Voronoi_diagram">Weighted Voronoi Diagram</a> which has the big advantage of showing files roughly in proportional to their size.  And by size I'm using lines of code, which is generally much more useful than bytes - especially as research tends to show that high lines of code is correlated with complexity and defects - so just looking for large lines of code is a good starting point for finding problems.</p>

<h3 id="viewing-by-programming-language">Viewing by programming language</h3>

<p><img src="https://blog.korny.info/2020-09-01-polyglot-explorer/vis_language.png" alt="language visualisation"></p>

<p>This view is very simple - it just colours each file by programming language, showing the 10 most common languages.  Mostly useful for getting an overview of what goes where - it's usually easy to spot the front-end vs back-end code by the colours used.  (only 10 languages are shown because beyond that, it's hard to visually see different colours)</p>

<h3 id="lines-of-code">Lines of code</h3>

<p><img src="https://blog.korny.info/2020-09-01-polyglot-explorer/vis_loc.png" alt="lines of code"></p>

<p>This view is simple enough - it uses a scale from blue for tiny files, through to yellow for giant files.</p>

<p>Note that this is not a linear scale - a lot of these use what I call a "Good/Bad/Ugly" scale - blue (0) is good, red (1000) is bad, and yellow (10000 and above) is just ugly.  If I used a linear scale, it'd be harder to distinguish the good/bad files from each other.  (yes, I could use a log scale, but that has it's own problems)</p>

<h3 id="indentation">Indentation</h3>

<p><img src="https://blog.korny.info/2020-09-01-polyglot-explorer/vis_indentation.png" alt="indentation"></p>

<p>This metric is an interesting one. In <a href="https://doi.org/10.1109/ICPC.2008.13">Hindle, Abram, Michael W. Godfrey, and Richard C. Holt. 2008. ‘Reading Beside the Lines: Indentation as a Proxy for Complexity Metric’</a> they found that indentation is often useful as a way of looking for complexity - which makes common sense; files with a lot of indentation are often files with deeply nested "if" and "case" statements.  You can choose a few sub-visualisations using the drop-down near the top-left - the default shows the standard deviation of indentation, which is often the most useful metric; you can also see the worst indentation in each file, and the "total area" which is useful for showing files which are both large and deeply indented.</p>

<p>Of course this metric can have false positives - heavy indentation might be due to a particular formatting style for long lines, or an actually valid data structure, or other valid reasons.  But it is often surprisingly useful.</p>

<h3 id="age-since-last-change">Age since last change</h3>

<p><img src="https://blog.korny.info/2020-09-01-polyglot-explorer/vis_age.png" alt="age since last change"></p>

<p>This view shows how long it is since each file was changed (from git history) - blue files are recently changed, red files haven't changed in a year, yellow files haven't changed in 4 years.  Note that this is affected by the date selector down the bottom of the page:</p>

<p><img src="https://blog.korny.info/2020-09-01-polyglot-explorer/date_selector.png" alt="date selector"></p>

<p>Files that haven't changed at all in the selected date range will show in grey.  You need to select the whole project (drag the left side of the selector to the left of the screen) to see change information across the whole scanned date range.</p>

<p>This is a good/bad/ugly scale again, largely because generally files that haven't changed for a long time are, in my experience, parts of the system that nobody understands or feels safe to touch.</p>

<p>However this is a bit contentious - it depends a lot on the culture of the organisation, and the kind of code - a lot of research in this field shows the flip-side of this, that files that haven't changed for ages are stable. If they had bugs, people would have touched them …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.korny.info/2020/09/06/introducing-the-polyglot-code-explorer.html">https://blog.korny.info/2020/09/06/introducing-the-polyglot-code-explorer.html</a></em></p>]]>
            </description>
            <link>https://blog.korny.info/2020/09/06/introducing-the-polyglot-code-explorer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401227</guid>
            <pubDate>Mon, 07 Sep 2020 18:03:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google One blocks transnational families]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24401097">thread link</a>) | @alangibson
<br/>
September 7, 2020 | https://landshark.io/2020/09/06/google-one-blocks-transnational-families.html | <a href="https://web.archive.org/web/*/https://landshark.io/2020/09/06/google-one-blocks-transnational-families.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p>Here’s one for the Unfortunate Error Message hall of fame.</p>

<p><img src="https://landshark.io/assets/2020-09-06-google-one-bans-separated-families/no-family-for-you.png" width="400"></p>

<p>I got this while trying to add my wife (who is not from the USA) to my Google One storage plan. Apparently Google never counted on family members living in different countries.</p>

<p>I see this as a rather embarassing example of Conway’s Law. Our family structure isn’t compatible with the structure of Google’s business, so no family plan for us.</p>

<p>Hey Google: things are complicated outside of Mountain View. Try putting a little more effort into covering us edge cases. Don’t make us pay for your convenience.</p>


</div></div>]]>
            </description>
            <link>https://landshark.io/2020/09/06/google-one-blocks-transnational-families.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24401097</guid>
            <pubDate>Mon, 07 Sep 2020 17:45:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Soft Skills for Managers]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24400840">thread link</a>) | @hackitup7
<br/>
September 7, 2020 | https://staysaasy.com/product/2020/09/06/soft-skills-for-managers.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/product/2020/09/06/soft-skills-for-managers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Many of the hard technical skills that make a great manager are testable. You can easily evaluate technical expertise – for example, an engineering manager should demonstrate their ability to produce or at least understand code. Similarly, in-depth discussions will quickly reveal whether someone can clearly and concisely communicate nuanced concepts.</p>

<p>The softer skills of management are more difficult to assess but just as important. Below are a few of the soft skills that I value most highly in managers, some ideas on how to assess them, and common traps.</p>

<h2 id="soft-skill-1-initiative">Soft Skill #1: Initiative</h2>

<p>Managers set the tempo for their teams – if they aren’t actively looking for ways to help the business, they will set an example that being proactive is optional. The sad truth is that once you’re a manager you can survive a long time by simply maintaining existing processes, reacting to personnel issues, or (worse) creating busywork and taking credit. Many managers collect fine paychecks drifting like an inert gas within a broader bureaucratic cloud. To scale a company effectively, managers need to be proactive rather than existing simply to push virtual papers across their desks.</p>

<p>Initiative tends to be pretty obvious when evaluating internal management candidates. For external candidates, I usually ask deep-dive questions about a meaty project from their past. The goal: learn about what they did, their role, and most importantly the “why” behind their decisions, diving into the details of what really went down. A sample prompt: “Tell me about a significant project that you led, and I’ll ask a bunch of questions to dive deeper.” This is usually fun to ask and I expect to learn something new from strong candidates – after all, they know much more than I do about the project they worked on, so if they can’t teach me something that’s a red flag.</p>

<p>Searching for the “why” behind their decisions is a good test for initiative – being able to explain why certain decisions were made indicates that a candidate can think critically about what a project actually needs, rather than just executing on someone else’s plan.</p>

<h2 id="soft-skill-2-emotional-control">Soft Skill #2: Emotional Control</h2>

<p>Management can be stressful, <a href="https://staysaasy.com/scaling/2020/05/07/startup-is-this-normal.html">especially at a high growth startup company</a>. You’re the first point of escalation for all manner of problems: inter- or intra-team conflict, critical last-minute blockers, HR issues, and other corporate delights. You don’t have a safety net to fall back on if a situation gets too heated – you are the safety net.</p>

<p>Managers can’t be emotionally reactive. They need to remain rational even in the face of severe stressors, allowing them to remain unflappable when shit goes down (more calm also comes with experience). Sometimes, the downsides of reacting are minor: if someone says something dumb during a presentation and you visibly scowl, you can cause them to get flustered. Others are much more important: for example, if someone comes into a 1:1 very upset over their compensation, you need to remain calm as it can be disastrous to make promises or comments that could be misconstrued.</p>

<p>This skill is challenging to assess when hiring managers. Unlike in, say, the Marine Corps, it’s frowned upon in the tech industry to throw someone into a stressful situation and assess their emotional control. References are imperfect but can help, and this skillset is one of the reasons that internal manager candidates can be such tempting known quantities.</p>

<p>The very best managers take this a step further and demonstrate durability – the ability to not only exercise control, but to do so repeatedly over months and emerge on the other side energized and positive. High growth companies are challenging, and more significantly, they’re challenging <a href="https://staysaasy.com/scaling/2020/07/29/the-rogue-wave-of-enterprise-saas.html">over a very long time</a> – typically years. People who are a consistent force for optimistic calm are the pillars around which you should build your team.</p>

<h2 id="soft-skill-3-dispassionate-empathy">Soft Skill #3: Dispassionate Empathy</h2>

<p>Managers need dispassionate empathy: the ability to logically breakdown how their teams will react to new situations by viewing things from multiple perspectives – without allowing viewpoints that they’re sympathetic to cloud their judgment. If someone on your team is passed over for a promotion that goes to their teammate, how will they react? If someone gets really tough feedback, how will they handle it? Managers need to be able to assess factors such as incentives and egos as they chart a course for their entire team.</p>

<p>Promotions provide a common example: when you promote someone you’re affirming the behaviors that you will reward (as well as other behaviors that you tolerate…), and everyone else on the team will observe, calculate, and react differently according to their own interpretation. If you promote Alice, will her peer Bob freak out that it was unfair, become apathetic, or work harder? What message will it send to their more junior team member Charlie?</p>

<p>Empathizing with others’ viewpoints dispassionately is surprisingly difficult as there’s little in day-to-day life that prepares you for it. When a friend or family member is in a difficult situation, they’re typically looking for empathy without reservations, and we’re trained as primates to deliver it. Mirroring the emotions of people we’re close to is often a feature, not a bug. Many managers need to fight the urge to over-empathize.</p>

<p>I assess this trait in interviews by asking about challenging situations that occurred on a prior team. Examples include:</p>

<ul>
  <li>Tell me about a time that someone asked for something (eg a raise or promotion), and you didn’t give it to them.</li>
  <li>Tell me about a time when a member of your team was in conflict with a member of another team, and you needed to help out.</li>
  <li>Tell me about a time that someone on your team was underperforming.</li>
</ul>

<p>In asking about these scenarios, I’m first looking for the candidate’s ability to articulate the different motivations or incentives involved: do they understand the situation? Did they view it through others’ eyes rather than just their own? I also assess their ability to discuss the situation in a calm way: are they getting emotionally biased?</p>

<p>While emotional life isn’t as cut and dried as a Python script, I find that most great managers can break down situations like an algorithm: look at all of the different incentives and personalities on the team, add a new decision or situation, and guess at what will happen next.</p>

<h2 id="the-soft-skill-trap">The Soft Skill Trap</h2>

<p>Especially for internal candidates for management positions, beware the most common soft skill trap: mistaking a likeable personality for leadership or management aptitude.</p>

<p>It’s easy to misinterpret a gregarious, likeable personality for innate management skill. “Timmy is a ‘people person’ – of course he’ll be able to manage a team!” This is simply not how life works. Timmy might be great as a manager, or he might suck, but in my experience his likeability is unlikely to correlate strongly with the soft skills that matter.</p>

<p>I blame this phenomenon on Hollywood’s stereotypical portrayal of what it means to be a “leader.” Many great managers are gregarious, sociable, and charismatic, but many others are introverted, quiet in group settings, or somewhat socially awkward. I’ve met managers whom I actually somewhat disliked in a social capacity but who were extremely effective at their jobs. However, I have yet to meet a great manager who didn’t take initiative, couldn’t regulate their own emotions, and didn’t understand the incentives that would motivate their team.</p>

<p><img src="https://staysaasy.com/assets/soft_skills/gladiator.jpg" alt="Gladiator">
Good leader overall, but perhaps too much shouting for your average tech company</p>

<p>There’s also a potential element of bias here: does someone seem like they should be in a leadership position just because they’re really confident? Do they feel like they should be in charge because they’re often the loudest voice in the room? These sorts of subjective judgements are also minefields for bias. For a random example, some of the behaviors that say “leader” in American culture scream “jerk” in East Asian culture. I highly recommend assessing management potential according to the dimensions listed above and trying to remove likeability or sociability from your decision calculus.</p>

<h2 id="takeaways">Takeaways</h2>
<ul>
  <li>Great management requires both hard and soft skills. Soft skills are often harder to assess.</li>
  <li>When assessing a manager’s soft skills, look for the following traits: initiative, emotional control, and an ability to understand how others will perceive and react to situations.</li>
  <li>Promoting from within is a great way to remove manager hiring risk.</li>
  <li>Don’t mistake sociability for management skill.</li>
</ul>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/product/2020/09/06/soft-skills-for-managers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24400840</guid>
            <pubDate>Mon, 07 Sep 2020 17:13:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Got an Offer at Facebook, Turned It Down, and Moved On]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24400606">thread link</a>) | @iuliangulea
<br/>
September 7, 2020 | https://iuliangulea.com/blog/how-i-got-an-offer-at-facebook-turned-it-down-and-went-on/ | <a href="https://web.archive.org/web/*/https://iuliangulea.com/blog/how-i-got-an-offer-at-facebook-turned-it-down-and-went-on/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    
    <p><img src="https://iuliangulea.com/images/offer-from-fb-cover.png" alt="Cover Image"></p>
<p>Software Engineering (SWE) is among the most desired jobs nowadays. It is a vibrant and dynamic domain that changed the way we do things, and that improved our lifestyle. It has its own peculiarities, though, with holy wars between groups of people who argue which programming language is better, with haters of JavaScript, scripting languages, and dynamically typed languages, with complete assholes as well as some very nice and considerate people (although this is not related only to SWE).</p>
<p>Even with a global pandemic, software engineers’ workstyle changed only a little. There are many benefits to working as a software engineer, as well as there are downsides. But this article is not about the perks and drawbacks—you can find a myriad of posts on that subject.</p>
<p>There are lots of questions and answers online about how to get into one of the FAANG (facebook, amazon, apple, netflix, google) companies. This article is my experience and some recommendations.</p>
<h2 id="briefly-about-me">Briefly About Me</h2>
<p>I am a Full Stack Software Engineer with 10+ years of experience and a keen interest (and 8+ years of experience) in Data Visualization. I am a freelancer on <a href="https://toptal.com/">Toptal</a>, and currently, I work for PepsiCo.</p>
<p>My main stack is Python/Django [REST] on the backend, JavaScript/TypeScript, and all major JS frameworks on the frontend. There are many more things. If you are interested, this is my <a href="https://www.toptal.com/resume/iulian-gulea">online</a> resume.</p>
<h2 id="the-beginning-of-search">The Beginning Of Search</h2>
<p>Generally speaking, switching jobs requires effort. You must not only prepare for the interviews but also spend time on operational stuff like searching for companies to apply, adjusting your CV, etc.</p>
<p>In Jun 2019, while I had a nice job at a NY-based startup, but I planned to move with my family to the United States. And the easiest way to do that was to apply to some companies that provide an H1B visa. Due to some circumstances, we had to stay for at least one year at home, so I decided to slowly, but steadily plan my preparation for interviews at the big tech companies.</p>
<h2 id="the-preparation-phase">The Preparation Phase</h2>
<p>After doing some research, I found out the most common stages of the recruitment process:</p>
<ul>
<li>technical</li>
<li>behavioral</li>
<li>management</li>
<li>analytical</li>
<li>system design</li>
<li>object-oriented design</li>
</ul>
<p>You might not go through all of them. It depends on the job position you apply and on the company. What you will for sure have are the <em>behavioral</em> and <em>technical</em> interviews. <em>System design</em> is often present, especially if you apply to a position that requires experienced candidates.</p>
<p>Let’s briefly describe each type of the interview before moving further.</p>
<h3 id="technicalcoding-interview">Technical/Coding Interview</h3>
<p>This type of interview aims at understanding your algorithms skills. Usually, you are given 1, 2, or 3 problems, and you have to solve them in the allocated time (usually somewhere between 15 to 60 mins, depending on the complexity of the problem), considering edge cases and time and space complexity.</p>
<p>There are many platforms online where you can practice solving such problems. Here are just a few to name:</p>
<ul>
<li>LeetCode</li>
<li>HackerRank</li>
<li>Codility</li>
<li>GeeksForGeeks</li>
</ul>
<p>I created a habit of solving at least one problem per day, and in almost ten months, I had solved 299 problems.</p>
<p><img src="https://iuliangulea.com/images/leetcode-submissions.png#c" alt="Image of submissions on leetcode"></p>
<p><img src="https://iuliangulea.com/images/leetcode-solved-problem-types.png#c" alt="Image with amount and types of problems solved on leetcode"></p>
<p>Another thing to note is that a candidate usually has several technical interviews: over the phone and onsite.</p>
<h3 id="behavioral-interview">Behavioral Interview</h3>
<p>This type of interview aims at understanding the competency and soft-skills part of your professional profile. How good can you get along with people, how do you perform and behave in different situations with your coworkers, etc. Some developers see this interview as a useless step (or one with minimal importance). That is a delusional thought. Developers have to work in teams the same way as people in many other professions, and understanding “the human” side of a potential employee is essential.</p>
<p>To prepare for this step, there are lots of resources online about behavioral interviews. _ “Cracking the Coding Interview”_ by Gayle Laakmann McDowell is a book that might help you as well. Actually, it is an exhaustive resource to prepare for interviews, so check it out.</p>
<h3 id="management-interview">Management Interview</h3>
<p>I had this type of interview only at one company. It is about looking for examples of how you deal with different scenarios, usually around being a team player, helpful and engaging. I didn’t really see a difference from a behavioral interview, but it was explicitly labeled a “Management Interview,” so there it is.</p>
<h3 id="analytical-interview">Analytical Interview</h3>
<p>This type of interview aims to understand how you work with data, how you make sense of it, and if you have made any data-driven decisions in your previous work. It has minor aspects of a behavioral interview as well, but more focused on your analytical skills.</p>
<h3 id="system-design-interview">System Design Interview</h3>
<p>This type of interview is about designing scalable, distributed systems. It might be tough to prepare for because sometimes you might not have the experience of working on a distributed system. Therefore, you must learn the theory only, without having practical experience.</p>
<p>This step is also more challenging because there are a lot of concepts, use cases, and tools that solve various problems, and you need to know what those are to be able to design a viable solution.</p>
<p>To prepare for this interview, I took the long route (since I had plenty of time). There are many great (and free!) resources on GitHub, and here are the ones that I used:</p>
<ul>
<li><a href="https://github.com/binhnguyennus/awesome-scalability">Awesome Scalability</a> - a reading list on scalability, availability, principles of distributed systems, best case practices at different companies, and many more. I was reading five articles a day and was almost done with the relevant concepts in 7 months. It gave me a broad perspective on what tools exist out there, what problems other teams and companies face, and how to approach solving those problems.</li>
<li><a href="https://github.com/donnemartin/system-design-primer">The System Design Primer</a> - a similar resource, but much more concise, and focused on the theoretical aspects of the concepts more (rather than providing real-life examples from companies, as in the previous link). But the main advantage of it is that it has examples of system design questions and answers.</li>
<li><a href="https://github.com/yangshun/tech-interview-handbook">Tech Interview Handbook</a> offers full support in preparation for the interviews, but I used it for some hints only.</li>
</ul>
<h3 id="object-oriented-design-interview">Object-Oriented Design Interview</h3>
<p>In OOD, you have to design the interface of some API or class. It aims at understanding how you think in terms of code and how you structure it. There should be some resources online on the topic, but I haven’t prepared for this one additionally since that is what I do as part of my job.</p>
<h2 id="quitting-and-searching">Quitting And Searching</h2>
<p>In March 2020, I decided to quit my job at the NY startup and enjoy some time while I was going to search for a job. I was okay financially and was quite confident I would get a job at some company. But then the pandemic hit, and I got a bit nervous.</p>
<p>Anyway, I needed companies that can sponsor a visa. That’s pretty much all big tech firms. Here is the list of companies and openings I have applied to:</p>
<ul>
<li>Full Stack Developer @ Google in Zurich</li>
<li>Software Engineer, Core Languages @ Google in Munich</li>
<li>Software Engineer, Engineering Productivity @ Google in Munich</li>
<li>Senior Backend Engineer @ Airbnb in Dublin</li>
<li>Software Developer - Frontend Tools for AWS @ Amazon in Berlin</li>
<li>Software Developer Engineer - Backend @ Amazon in Berlin</li>
<li>Developer Support Engineer @ Facebook in Dublin</li>
<li>Enterprise Engineer @ Facebook in Dublin</li>
<li>Full Stack Software Engineer - Python/JS @ Apple in Zurich</li>
</ul>
<p>Out of these, I had referrals at all companies except Airbnb. So I got a reply from Google for the Full Stack role, both Amazon jobs, the Airbnb one, and Facebook’s Developer Support Engineer. The only email I received from Apple was the one in which they asked me about feedback on the recruitment process. That was weird.</p>
<p>So, it was exciting, and I was looking forward to it!</p>
<h2 id="interviewing">Interviewing</h2>
<p>If you have worked for a corporation, you probably know that things there take time to progress. The most responsible and fast were Google and Facebook, followed by Airbnb, and Amazon being the least responsive and considerate.</p>
<p>The first step at all companies except Amazon was a phone call to discuss about my application. I perceived this step as an ice-breaker where the recruiter gets to know you, that you are a real person, and that you have intelligible English.</p>
<p>After that, there were coding rounds, but things started to diverge, so I’ll describe the experience with each company separately:</p>
<h3 id="google">Google</h3>
<p>Google was among my favorites. The experience with the recruiter was among the best I had. Initially, we had a call to introduce myself, and the recruiter told me about the process.</p>
<p>The next step was a coding round with an interviewer. I was delighted about how it went. The code was well commented and organized in testable functions. I walked the interviewer throughout the whole thinking process by telling how and why I’m writing that code. I did introduce a small bug (incorrect upper bound in python’s <code>range()</code> function) that the interviewer showed me immediately, which I fixed. Also, while I was close to finalizing the problem, I figured out some use cases that wouldn’t pass, so I clarified the expected outcome and did the corresponding changes. I even answered a follow-up question, but I didn’t get to code it because of a lack of time.</p>
<p>After waiting for one week, it turned out that I didn’t pass. And the feedback was a bit suspicious to me:</p>
<ul>
<li>the pace was a bit on the slow side</li>
<li>I didn’t account for a bug (the one that he told me about the moment I did it)</li>
<li>I didn’t think about the design of the algorithm and data structures at the abstract level before coding (this one is subjective since I did think and explain my choices)</li>
</ul>
<p>Anyway, it seemed very unfair. The only thing I could do is to tell about this to the recruiter, so hopefully, other candidates will be evaluated more fairly.</p>
<h3 id="amazon">Amazon</h3>
<p>With Amazon, I had the least pleasant experience as a candidate. It took ages until they were responding to emails and moving with the recruitment process. So, after the intro call, I had two rounds of coding exercises for two …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://iuliangulea.com/blog/how-i-got-an-offer-at-facebook-turned-it-down-and-went-on/">https://iuliangulea.com/blog/how-i-got-an-offer-at-facebook-turned-it-down-and-went-on/</a></em></p>]]>
            </description>
            <link>https://iuliangulea.com/blog/how-i-got-an-offer-at-facebook-turned-it-down-and-went-on/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24400606</guid>
            <pubDate>Mon, 07 Sep 2020 16:40:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Generate Passive Income]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24400148">thread link</a>) | @sjohn93
<br/>
September 7, 2020 | https://www.startupjohn.com/blog/the-10-best-ways-to-generate-passive-income | <a href="https://web.archive.org/web/*/https://www.startupjohn.com/blog/the-10-best-ways-to-generate-passive-income">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <p><span data-preserver-spaces="true">What comes in your mind when you hear the term Passive Income? Well, if you think it is easy money that can be earned while sitting on a beach without doing anything, you are wrong. Yes, it can be an excellent supplementary source of funds for a lot of people, but it requires lots of work as well. Passive income demands an upfront investment and a lot of nourishing in the start. However, after some time, these income streams can sustain themselves and bring you a significant amount of money. We will show the 10 best ways to generate passive income in this article.</span></p>
<p><strong><span data-preserver-spaces="true">What is Passive Income?&nbsp;</span></strong></p>
<p><span data-preserver-spaces="true">People love to hear about this earning method, yet it is the most misunderstood concept. In simple words, Passive income is when you keep getting paid for work, even after it is completed. It involves royalties from movies, books, songs, etc. It also includes the wealth that comes from investments in the real state or business investments where your physical presence is not necessary.&nbsp;</span></p>
<p><strong><span data-preserver-spaces="true">Why is it important?&nbsp;</span></strong></p>
<p><span data-preserver-spaces="true">The reason why everyone must start working on Passive Income ideas is its unmatchable significance. Let's suppose you wake up one day, and out of nowhere, you find out that you are fired from your job. That's where Passive Income proves its worth. The most recent example is the recent lockdown that was imposed by the government due to the Coronavirus outbreak. A lot of people have gone through a financial crisis during this pandemic, except the individuals who had secondary earning sources. So, whenever you lose your job or face any kind of financial hardship, passive income will ensure the cash flow does not stop.&nbsp;</span></p>
<p><strong><span data-preserver-spaces="true">How to generate Passive Income?&nbsp;</span></strong></p>
<p><span data-preserver-spaces="true">This is the most common question asked by the people who are willing to earn through different sources. There are a lot of Passive Income ideas and strategies that can help everyone. Some of them may require a lot of investment, but you can start making money even with as little as $5! Sounds unbelievable, right? We have discussed more of such strategies below.&nbsp;</span></p>
<ol>
<li><strong><span data-preserver-spaces="true">Rental Income:&nbsp;&nbsp;</span></strong><span data-preserver-spaces="true">A cash flowing rental property is an excellent way to earn passive income, but it requires a lot of work. Before investing in a real state, you must learn how to make it a profitable investment, otherwise, there are a lot of risks involved. Also, if you want to make it truly passive, outsourcing your property to a management company is the best option. However, this is not something you can start with a little extra cash.&nbsp;</span></li>
<li><strong><span data-preserver-spaces="true">Dividend Stocks:&nbsp;</span></strong><span data-preserver-spaces="true">This is an authentic and tested way to earn passive income. Your job will be to do extensive research and find good stocks where you can invest money and receive a significant number of dividends. If you keep investing in dividend stocks, you can accumulate a good residual revenue with time. Choosing the right company to invest in is the tricky part. If you succeed in selecting the right company, you will receive payment at regular intervals.&nbsp;</span></li>
<li><strong><span data-preserver-spaces="true">Peer-to-peer Lending:&nbsp;</span></strong><span data-preserver-spaces="true">Peer to peer, commonly known as P2P is the method of lending money to borrowers who do not qualify for conventional loans. This kind of lending is usually facilitated by a third-party agent, such as LendingClub. As a lender, your income source will be the interest payments made on the loans. However, there is some risk factor as the loan is unsecured.&nbsp;</span></li>
<li><strong><span data-preserver-spaces="true">Affiliate Marketing:&nbsp;</span></strong><span data-preserver-spaces="true">If you are a social media influencer, a blogger, or a website owner, this method can be the best option for you to earn some extra cash. It is a commission-based job, where you promote a third party's product on your website, and on every purchase, you will get your share. The most popular affiliate partner is Amazon, but there are other platforms like Awin, ShareASale, and eBay as well. Please remember that you will need to invest a lot of time in the start to attract traffic on your website.&nbsp;</span></li>
<li><strong><span data-preserver-spaces="true">Investing in CDs:&nbsp;</span></strong><span data-preserver-spaces="true">If you are a risk-averse person, investing in Certificates of Deposits (CD) can be a pretty good option for you. It is often more profitable to go with an online bank than your local bank. This way, you will be able to select the best rate of return available in your country.&nbsp;</span></li>
<li><strong><span data-preserver-spaces="true">Selling Information Product:&nbsp;</span></strong><span data-preserver-spaces="true">If you are good at something, you can always record an audio or a video course and sell it to interested people. Also, writing an E-book can be a pretty good source for earning passive income. The only problem with this method is that you must put a lot of effort into creating such a product. Some popular examples in this regard are Udemy, Coursera, Skillshare, etc.&nbsp;</span></li>
<li><strong><span data-preserver-spaces="true">REIT:&nbsp;</span></strong><span data-preserver-spaces="true">Real Estate Investment Trusts are specially made for people who are not comfortable investing directly in the real state. REITs have a kind of legal structure that enables them to pay little to no corporate income tax if they pass along most of their revenue to shareholders. You can easily purchase the shares of REITs from the Stock Market just like other companies.&nbsp;</span></li>
<li><strong><span data-preserver-spaces="true">Invest in a Business:&nbsp;</span></strong><span data-preserver-spaces="true">This is another great way to make passive income. You can invest in a business and be a silent partner. This is the riskiest method we have discussed until now, but if you are a risk-taker, you will understand the high returns that are associated with high risk. For example, did you know that Uber and Lyft were looking for private investors once? Well, both of these companies are worth billions now!&nbsp;</span></li>
<li><strong><span data-preserver-spaces="true">Car Advertisement:&nbsp;</span></strong><span data-preserver-spaces="true">Earning money while driving your car around town - doesn't it sound fascinating? Well, it surely does, and a lot of people are doing it. You can contact any experienced advertising agency, and after making some inquiries, they will link you to one of their advertisers.&nbsp;</span></li>
<li><strong><span data-preserver-spaces="true">Renting out a room in your house:&nbsp;</span></strong><span data-preserver-spaces="true">This is a straightforward method of earning passive income. In simple words, you are taking advantage of the space that you were probably not using anyway.&nbsp;</span></li>
</ol>
<p><span data-preserver-spaces="true">The ideas discussed above are only a few out of hundreds through which you can make passive income easily. It is about time we start looking for additional income sources that can improve our living. However, there is no such thing as easy money. If you are looking for high returns, make sure to put the significant effort.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Disclaimer:&nbsp;</span><strong><span data-preserver-spaces="true">This is not a financial advice.&nbsp;</span></strong><span data-preserver-spaces="true">StartupJohn doesn`t bear any responsibility for any financial losses you might incur as a result of this article and website. StartupJohn or anyone involved with StartupJohn will not accept any liability for loss or damage as a result of reliance on the information including data contained within this website.</span></p>
            </div></div>]]>
            </description>
            <link>https://www.startupjohn.com/blog/the-10-best-ways-to-generate-passive-income</link>
            <guid isPermaLink="false">hacker-news-small-sites-24400148</guid>
            <pubDate>Mon, 07 Sep 2020 15:42:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Heroku terminates Ruqqus site and account without a warning or an explanation]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24400102">thread link</a>) | @ecmascript
<br/>
September 7, 2020 | https://ruqqus.com/post/301l/you-cant-cancel-freedom-that-easily | <a href="https://web.archive.org/web/*/https://ruqqus.com/post/301l/you-cant-cancel-freedom-that-easily">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body">
<p>At 16:09 EDT on 04 Sep 2020 (about 26 hours ago), SalesForce (the owner of web hosting company Heroku) notified us that they had suspended the Ruqqus live and test server environments, with account termination to follow twenty-four hours later.</p>
<p>At the time of this writing, we have not been given a reason as to why we were being kicked. I do not believe we violated Heroku ToS (though Heroku may think otherwise) and we did not exceed Heroku usage limits. Our account manager was friendly but was unfortunately unable to provide us with any information. It is my opinion that by not warning us first (ex. "please remove X which violates Heroku's acceptable use policy") that Heroku actually violated their own terms of service.</p>
<p>We immediately downloaded all of the Ruqqus data, and began working on setting up shop at another host.</p>
<p>I'd like to give a massive shoutout to <a href="https://ruqqus.com/@p2hang"><img src="https://ruqqus.com/@p2hang/pic/profile">@p2hang</a> for lending his considerable expertise in support of getting Ruqqus operational as quickly as possible. He is the third recipient of the super-rare Fire Extinguisher badge.</p>
<p>All (or at least, almost all) functionality is restored. There are a few things which aren't quite yet back to normal, which I hope to fix over the course of tonight and tomorrow.</p>
<p>Known issues:</p>
<ul>
<li>
<p><del>hCaptcha verification issues on attempted signups</del></p>
</li>
<li>
<p><del>Custom guild colors are currently disabled. This was an intentional decision by me, as there were issues loading the style files needed for custom coloring, so it was easier to just disable that for the sake of getting up and running.</del></p>
</li>
<li>
<p><del>Notification bell stuck on.</del></p>
</li>
<li>
<p><del>Lastly, and most importantly, we have no idea how well the current server will be able to handle user load. For that reason, I will be continuing to monitor and make adjustments as needed. Performance may be spotty and unreliable as load resumes.~~ ~~Doesn't seem to be an issue, but we'll have to see how it goes with everyone trying to get on.</del> There are some load/efficiency problems that I'm trying to sort out.</p>
</li>
<li>
<p><del>hCaptcha on signup is malfunctioning.</del></p>
</li>
<li>
<p><del><a href="http://i.ruqqus.com/">i.ruqqus.com</a> image uploads don't save.</del></p>
</li>
<li>
<p>The most recent 30k or so comments didn't make it into the new host. Also possibly some post votes. I <em>think</em> all the comment votes made it in. The missing data is something I'm still working on, but you will probably see rep fluctuating unpredictably as vanished stuff is no longer counted.</p>
</li>
</ul>
<hr>
<p>If you'd like to contribute to the future of freedom, please consider donating via <a href="https://patreon.com/ruqqus" rel="nofollow noopener" target="_blank">Patreon</a> or <a href="https://paypal.me/ruqqus" rel="nofollow noopener" target="_blank">Paypal</a> to help cover current and future server costs. <a href="https://ruqqus.com/help/donate">Cryptocurrency is also accepted</a>.</p>
</div></div>]]>
            </description>
            <link>https://ruqqus.com/post/301l/you-cant-cancel-freedom-that-easily</link>
            <guid isPermaLink="false">hacker-news-small-sites-24400102</guid>
            <pubDate>Mon, 07 Sep 2020 15:35:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The prisoner's dilemma of training your employees]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399867">thread link</a>) | @akdas
<br/>
September 7, 2020 | https://hiringfor.tech/2020/09/07/the-prisoners-dilemma-of-training-your-employees.html | <a href="https://web.archive.org/web/*/https://hiringfor.tech/2020/09/07/the-prisoners-dilemma-of-training-your-employees.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content"><figure id="cover-img">
  <p><img src="https://hiringfor.tech/assets/images/posts/2020-09-07-the-prisoners-dilemma-of-training-your-employees.jpg" alt="A chessboard with some pieces on it"></p>
  <figcaption>
    <p>Training your employees doesn’t have to be a game of chess. Photo by <a href="https://unsplash.com/@csolorzanoe?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Charlie Solorzano</a> on <a href="https://unsplash.com/@csolorzanoe?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>
  </figcaption>
</figure>

<p>A common trope in hiring is the lack of experienced candidates. This is certainly thought to be true for the entire tech industry, but it’s especially compounded for minority candidates: “it’s a pipeline problem”. On the flip side, the question inexperienced developers face is how they can gain experience without having prior experience.</p>

<p>No matter what type of experienced candidate you’re trying to hire, <strong>your company needs to invest in its junior employees</strong>. That means provide them with mentorship, formal training, and the opportunity to work on meaningful projects. But, there are some common objections:</p>

<ul>
  <li>
    <p>Building up experienced candidates takes time, when you need them <em>now</em>!</p>
  </li>
  <li>
    <p>Employees will take the investment you put into them and go to another company. Now, the other company will get an experienced candidate without paying the upfront cost.</p>
  </li>
</ul>

<p>It sounds like you’re better off asking developers to level up on their own time.</p>

<p>However, <strong>like many hard problems, the root cause is systemic</strong>. If every company invested in their industries, there would be a large pool of experienced candidates moving from employer to employer. This is, fundamentally, the <em>only</em> way to end up with experienced candidates in the system.</p>

<h2 id="the-prisoners-dilemma">The prisoner’s dilemma</h2>

<p>The problem is <a href="https://en.wikipedia.org/wiki/Prisoner%27s_dilemma">a prisoner’s dilemma</a>: it’s best for all the employers to work together, training their employees. In return, they all get access to the trained candidates who move around in the future. But, like in the prisoner’s dilemma, one company doesn’t know what the other companies will do, so the best strategy seems to not reward other companies with trained candidates.</p>

<p>Luckily, there’s a silver lining here. It still makes sense to invest in your employees for two reasons.</p>

<p>Most importantly, your employees will be happier! You’ll still have to compete on pay, of course, but if someone is being treated well, wouldn’t they want to stay around for at least a little longer?</p>

<p>Besides, you’re not alone, even today. The big tech companies, like Google and Facebook, are absolutely investing in their employees. These companies have extensive formal training programs, structured mentorship and a wide variety of interesting problems for engineers to solve. In fact, investing in your employees may be another plus for those looking to jump out of the big tech companies.</p>

<p>Basically, if you’re not investing in your employees, you’re already falling behind.</p>

<h2 id="effective-investment">Effective investment</h2>

<p>Finally, there’s the question of <em>how</em>: how do you build up your employees into experienced engineers. I’ve already talked about a few ways, but let’s get into some more detail.</p>

<p>First, provide <em>formal</em> training programs, including mentorship. This means giving developers access to the experienced engineers in your company, and giving the experience engineers guidance on how to mentor others. But, it also means classes and educational material employees can take advantage of. Think paid classes to learn a new skill, the way I learned mobile development.</p>

<p>Next, send engineers to conferences, or better yet, coach them to speak at conferences and other industry events. Engineers need access to resources outside your company too. As a side effect, the company ends up with representation within these industry events, which can help with recruitment down the line.</p>

<p>Finally, let developers stretch themselves on harder projects. With the right guardrails and mentorship, this is exactly how engineers gain experience.</p>

<hr>

<p>Investing in your employees is key to creating an industry with a healthy level of experienced engineers to draw from. Along the way, the investment results in happier employees and more recruitment opportunities. And despite the fact it seems less than ideal to do this investment alone, you’re not actually alone: the most coveted companies are already ahead of the game here.</p>
</section></div>]]>
            </description>
            <link>https://hiringfor.tech/2020/09/07/the-prisoners-dilemma-of-training-your-employees.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399867</guid>
            <pubDate>Mon, 07 Sep 2020 15:01:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[URL query parameters and how laxness creates de facto requirements on the web]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24399774">thread link</a>) | @todsacerdoti
<br/>
September 7, 2020 | https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>URL query parameters and how laxness creates de facto requirements on the web</h2>

	<p><small>September  7, 2020</small></p>
</div><div><p>One of the ways that <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a> (the code behind <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a>) is unusual is that it strictly validates the query parameters
it receives on URLs, including on HTTP <code>GET</code> requests for ordinary
pages. If a HTTP request has unexpected and unsupported query
parameters, such a <code>GET</code> request will normally fail. When I made
this decision it seemed the cautious and conservative approach, but
<a href="https://utcc.utoronto.ca/~cks/space/blog/web/CautionIsAMistakeToday">this caution has turned out to be a mistake on the modern web</a>. In practice, all sorts of sites will
generate versions of your URLs with all sorts of extra query
parameters tacked on, give them to people, and expect them to work.
If your website refuses to play along, (some) people won't get to
see your content. <strong>On today's web, you need to accept (and then
ignore) arbitrary query parameters on your URLs</strong>.</p>

<p>(Today's new query parameter is 's=NN', for various values of NN
like '04' and '09'. I'm not sure what's generating these URLs, but
it may be Slack.)</p>

<p>You might wonder how we got here, and that is a story of lax behavior
(or, if you prefer, being liberal in what you accept). In the
beginning, both Apache (for static web pages) and early web
applications often ignored extra query parameters on URLs, at least
on <code>GET</code> requests. I suspect that other early web servers also
imitated Apache here, but I have less exposure to their behavior
than Apache's. My guess is that this behavior wasn't deliberate,
it was just the simplest way to implement both Apache and early
web applications; you paid attention to what you cared about and
didn't bother to explicitly check that nothing else was supplied.</p>

<p>When people noticed that this behavior was commonplace and widespread,
they began using it. I believe that one of the early uses was for
embedding 'where this link was shared' information for your own web
analytics (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/AnalyticsVsSecurity">cf</a>), either based on your logs
or using JavaScript embedded in the page. In the way of things,
once this was common enough other people began helpfully tagging
the links that were shared through them for you, which is why I
began to see various 'utm_*' query parameters on inbound
requests to <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a> even though I never
published such URLs.
Web developers don't leave attractive nuisances alone for long, so
soon enough people were sticking on extra query parameters to your
URLs that were mostly for them and not so much for you. Facebook
may have been one of the early pioneers here with their 'fbclid'
parameter, but other websites have hopped on this particular train
since then (as I saw recently with these 's=NN' parameters).</p>

<p>At this point, the practice of other websites and services adding
random query parameters to your URLs that pass through them is so
wide spread and common that accepting random query parameters is
pretty much a practical requirement for any web content serving
software that wants to see wide use and not be irritating to the
people operating it. If, like <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a>, you stick to your guns and
refuse to accept some or all of them, you will drop some amount of
your incoming requests from real people, disappointing would be
readers.</p>

<p>This practical requirement for URL handling is not documented in
any specification, and it's probably not in most 'best practices'
documentation. People writing new web serving systems that are
tempted to be strict and safe and cautious get to learn about it
the hard way.</p>

<p>In general, any laxness in actual implementations of a system can
create a similar spiral of de facto requirements. Something that
is permitted and is useful to people will be used, and then supporting
that becomes a requirement. This is especially the case in a
distributed system like the web, where any attempt to tighten the
rules would only be initially supported by a minority of websites.
These websites would be 'outvoted' by the vast majority of websites
that allow the lax behavior and support it, because that's what
happens when the vast majority work and the minority don't.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399774</guid>
            <pubDate>Mon, 07 Sep 2020 14:50:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Would you have survived the Titanic?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24399573">thread link</a>) | @aliabd
<br/>
September 7, 2020 | https://www.gradio.app/hub/hub-titanic#2 | <a href="https://web.archive.org/web/*/https://www.gradio.app/hub/hub-titanic#2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.gradio.app/hub/hub-titanic#2</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399573</guid>
            <pubDate>Mon, 07 Sep 2020 14:20:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Playwright and Puppeteer – Intercept Request and Response]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399552">thread link</a>) | @hlenke
<br/>
September 7, 2020 | https://theheadless.dev/posts/request-interception/ | <a href="https://web.archive.org/web/*/https://theheadless.dev/posts/request-interception/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>When we browse the web, a series of HTTP requests and responses are exchanged between our browser and the pages we are visiting. There are scenarios in which it is useful to monitor or manipulate this traffic, instead of letting it happen as-is.</p> <h2 id="request-interception"><a href="#request-interception">#</a> Request interception</h2> <p>Request interception enables us to observe which requests and responses are being exchanged as part of our script's execution. For example, this is how we could print them out when we load our <a href="https://danube-webshop.herokuapp.com/" target="_blank" rel="noopener noreferrer">test website</a>:</p>  <p>We might want to intervene and filter the outgoing requests. For example, when <a href="https://theheadless.dev/posts/basics-scraping.html">scraping web pages</a>, we might want to block unnecessary elements from loading in order to speed up the procedure and lower bandwidth usage.</p> <p>In the following snippet we are going to abort all requests for images on our test website. We will identify them based off of their <a href="https://pptr.dev/#?product=Puppeteer&amp;version=v5.2.1&amp;show=api-httprequestresourcetype" target="_blank" rel="noopener noreferrer"><code>resourceType</code></a>, while letting all other requests through without modification.</p>  <p>As a result, you will see the website logo not being loaded.</p> <p><img src="https://theheadless.dev/request-interception-image.png" alt="test site without images"></p> <p>Similarly, switching the <code>resourceType</code> to <code>stylesheet</code> would result in the target website loading without any CSS styling.</p> <p><img src="https://theheadless.dev/request-interception-css.png" alt="test site without css"></p> <h2 id="response-interception"><a href="#response-interception">#</a> Response interception</h2> <p>Isolating one or more software components from their dependencies makes them easier to test. We can do so by substituting interactions with such dependencies with simulated, simplified ones. This is also known as <em>stubbing</em>.</p> <p>Puppeteer makes it easy for us, as for every request we can intercept we also can stub a response. This functionality is <a href="https://github.com/microsoft/playwright/issues/1774" target="_blank" rel="noopener noreferrer">not yet available in Playwright</a>.</p> <p>Every time we load it, our test website is sending a request to its backend to fetch a list of best selling books. For our example, we are going to intercept this response and modify it to return a single book we define on the fly.</p>  <p>Here is what the homepage will look like with our stubbed response:</p> <p><img src="https://theheadless.dev/response-interception.png" alt="test site with stubbed response"></p> <p>Run the above examples as follows:</p>  <h2 id="takeaways"><a href="#takeaways">#</a> Takeaways</h2> <ol><li>Puppeteer and Playwright give us control over outgoing HTTP requests.</li> <li>With Puppeteer we can easily stub HTTP responses.</li></ol> <h2 id="further-reading"><a href="#further-reading">#</a> Further reading</h2> <ol><li>Official documentation on this topic from <a href="https://pptr.dev/#?product=Puppeteer&amp;version=v5.2.1&amp;show=api-class-httprequest" target="_blank" rel="noopener noreferrer">Puppeteer</a> and <a href="https://playwright.dev/#version=v1.3.0&amp;path=docs%2Fnetwork.md&amp;q=handle-requests" target="_blank" rel="noopener noreferrer">Playwright</a>.</li> <li><a href="https://martinfowler.com/articles/mocksArentStubs.html" target="_blank" rel="noopener noreferrer">Mocks Aren't Stubs</a> by Martin Fowler.</li></ol></div></div>]]>
            </description>
            <link>https://theheadless.dev/posts/request-interception/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399552</guid>
            <pubDate>Mon, 07 Sep 2020 14:16:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Slow Is Smooth, Smooth Is Fast; We Spend 25% of Our Time Refactoring]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399511">thread link</a>) | @lanecwagner
<br/>
September 7, 2020 | https://qvault.io/2020/09/01/slow-is-smooth-smooth-is-fast-25-of-our-time-refactoring/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/09/01/slow-is-smooth-smooth-is-fast-25-of-our-time-refactoring/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p><a href="https://app.qvault.io/">My team</a> has been spending less of our “free” time working on bugs and features from the backlog, and more time refactoring our codebases and test suites. As a result, and perhaps somewhat counterintuitively, we’ve noticed a significant increase in our throughput of features and bug fixes.</p>



<p>As it turns out, its easy to find bugs and add features to a well-written codebase that the entire team is familiar with. Go figure.</p>



<p>My team started a loose goal to spend 25% of our time refactoring, revisiting, and restyling existing code and tests. Let’s go over some of the benefits we’ve seen since making the change.</p>



<h2>Context and Caveats</h2>



<p>I’ve found that in articles like this it’s important to give as much context to the situation as possible, as certain development methodologies may work better or worse in teams with a different size, tech stack, or development process. Here are some notable things about our situation:</p>



<ul><li>3 engineers on my team, ~16 in the company</li><li>Tech stack – Go, Postgres, ElasticSearch and RabbitMQ</li><li>Microservices architecture on Kubernetes</li><li>Kanban-style development process – <a href="https://qvault.io/2020/05/18/leave-scrum-to-rugby-i-like-getting-stuff-done/">no scrum</a></li><li>Our team is responsible for ~14 repositories</li><li>Each repo represents a small service in a data pipeline process that handles sorting and NLP of social media posts</li></ul>



<div><figure><img loading="lazy" src="https://qvault.io/wp-content/uploads/2020/09/go_kubernetes-1024x592.png" alt="Go Kubernetes" width="512" height="296" srcset="https://qvault.io/wp-content/uploads/2020/09/go_kubernetes-1024x592.png 1024w, https://qvault.io/wp-content/uploads/2020/09/go_kubernetes-300x173.png 300w, https://qvault.io/wp-content/uploads/2020/09/go_kubernetes-768x444.png 768w, https://qvault.io/wp-content/uploads/2020/09/go_kubernetes-150x87.png 150w, https://qvault.io/wp-content/uploads/2020/09/go_kubernetes.png 1245w" sizes="(max-width: 512px) 100vw, 512px" title="go kubernetes"></figure></div>



<h2>Code Familiarity</h2>



<p>With only 3 engineers on the pipeline team and ~14 repositories (Mostly REST APIs and ETL processes), it was hard for all three of us to be super familiar with all the code. When we needed a new microservice, one team member typically wrote the first iteration, and one other team member did a quick code review. The engineer who did the first iteration would then be primarily responsible for bug fixes and new features relating to that project.</p>



<p>By focusing more of our time on reviewing and refactoring existing code, it gave us a chance to hop into projects that we never would have had a reason to become familiar with. Not only does getting more eyes on a project mean the overall code quality will likely go up, but it also means we aren’t hosed when the original maintainer has gone.</p>



<h2>Slow to Fix Bugs</h2>



<p>When you get deep into spaghetti code, it can be really hard to find bugs. Not only that but in a messy codebase, sometimes fixing a bug can actually <em>add</em> to the “uncleanliness” of the code. You may have to exacerbate or extend an already bad architectural pattern in order to get a bug fix in.</p>



<p>Ideally, you would do the refactoring first and then fix the bug (assuming the bug still exists after a good refactoring). Unfortunately, oftentimes there isn’t enough time to refactor a project before fixing a critical bug. For this reason, we should always be refactoring so that bug fixes can happen quickly and won’t make the code quality worse than it is.</p>



<h2>Slow to Add Features</h2>



<p>I don’t want to beat a dead horse, the reasoning here is largely the same as with bug fixes. Adding features to a messy codebase just makes it messier. It’s like frosting a cake that’s been thrown on the ground – it might taste marginally better but now it’s even harder to clean up.</p>



<div><figure><img loading="lazy" width="500" height="261" src="https://qvault.io/wp-content/uploads/2020/09/happy_birthday_to_ground.gif" alt="Happy Birthday to the Ground" title="happy birthday to ground"></figure></div>



<h2>Try It Yourself</h2>



<p>Since adding a consistent refactoring process to our team’s routine, we’ve been able to put <em>more</em> features through to production while spending <em>less</em> time working on them. Let me know what you think and if you have a different experience.</p>





		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/09/01/slow-is-smooth-smooth-is-fast-25-of-our-time-refactoring/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399511</guid>
            <pubDate>Mon, 07 Sep 2020 14:11:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons Learned from SSH Credential Honeypots]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399463">thread link</a>) | @ProfDreamer
<br/>
September 7, 2020 | https://systemoverlord.com/2020/09/04/lessons-learned-from-ssh-credential-honeypots.html | <a href="https://web.archive.org/web/*/https://systemoverlord.com/2020/09/04/lessons-learned-from-ssh-credential-honeypots.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  <div>
    <p>For the past few months, I’ve been running a handful of SSH Honeypots on some
cloud providers, including <a href="https://cloud.google.com/">Google Cloud</a>,
<a href="https://m.do.co/c/b2cffefc9c81">DigitalOcean</a>, and
<a href="https://shareasale.com/r.cfm?b=1380239&amp;u=2497236&amp;m=46483&amp;urllink=&amp;afftrack=">NameCheap</a>.
As opposed to more complicated honeypots looking at attacker behavior, I decided
to do something simple and was only interested in where they were coming from,
what tools might be in use, and what credentials they are attempting to use to
authenticate.  My dataset includes 929,554 attempted logins over a period of a
little more than 3 months.</p>

<p>If you’re looking for a big surprise, I’ll go ahead and let you down easy: my
analysis hasn’t located any new botnets or clusters of attackers.  But it’s been
a fascinating project nonetheless.</p>

<!--more-->

<h2 id="honeypot-design">Honeypot Design</h2>

<p>With a mere 200ish lines of Go, I implemented a honeypot server using the
<a href="https://pkg.go.dev/golang.org/x/crypto/ssh?tab=doc"><code>golang.org/x/crypto/ssh</code></a>
library as the underlying implementation.  I advertised a portable OpenSSH
version as the server version string (sent to clients on connection).  I then
logged each connection to a SQLite database, including the timestamp, IP
address, client version, and credentials used to (attempt to) authenticate.</p>

<h2 id="analysis-of-credentials">Analysis of Credentials</h2>

<p>In a surprise to absolutely nobody, <code>root</code> is by far the most commonly tried
username for login sessions.  I suspect there must be many attackers trying
lists of passwords with just <code>root</code> as the username, as 78% of attempted logins
were with username <code>root</code>.  None of the remainder of the top 10 are particularly
surprising, although <code>usuario</code> was not one I expected to see.  (It is Spanish
for <code>user</code>.)</p>

<p>Blank passwords are the most common attempted passwords, followed by other
obvious choices, like <code>123456</code> and <code>password</code>.  Just off the top 10 list was a
surprising choice of password: <code>J5cmmu=Kyf0-br8CsW</code>.  Interestingly, a Google
search for this password only finds other people with experience running
credential honeypots.  It doesn’t appear in any of the password wordlists I
have, including <a href="https://github.com/danielmiessler/SecLists">SecLists</a> and
others.  If anyone knows what this is a password for, I’d love to know.</p>

<p>There were a number of other interesting passwords such as <code>7ujMko0admin</code>, used
for a bunch of networked DVRs, and also known to be used by malware attacking
IoT devices.  There are other passwords that don’t look obvious to a US-centric
view of the world, like:</p>

<ul>
  <li><code>baikal</code> – a lake in Siberia</li>
  <li><code>prueba</code> – Spanish for test</li>
  <li><code>caonima</code> – a Mandarin profanity written in Pinyin</li>
  <li><code>meiyoumima</code> – Mandarin for “no password”</li>
  <li><code>woaini</code> – Mandarin for “I love you”</li>
  <li><code>poiuyt</code> – <strike>The name for an optical illusion also known as the "devil's tuning
fork"</strike> <strong>Edit:</strong> multiple redditors pointed out this is the begginning
of the top row of the keyboard from right to left.</li>
</ul>

<p>There are also dozens and dozens of keyboard walks, like <code>1q2w3e</code>, <code>1qaz@WSX</code>,
and <code>!QAZ2wsx</code>.  There are many more that took me much longer to realize they
were keyboard walks, such as <code>4rfv$RFV</code> and <code>qpwoei</code>.</p>

<p>It has actually fascinated me to look at some of the less obvious passwords and
discern their background.  Many are inexplicable, but I assume they are from
hardcoded passwords in devices or something along those lines.  Or perhaps
someone let their cat walk across the keyboard to generate it.  I’ve certainly
had that experience.</p>

<p>Overall, the top 10 usernames and top 10 passwords (not necessarily together)
are:</p>

<table>
  <thead>
    <tr>
      <th>Username</th>
      <th>Count</th>
      <th>Password</th>
      <th>Count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>root</code></td>
      <td>729108</td>
      <td>&lt;blank&gt;</td>
      <td>40556</td>
    </tr>
    <tr>
      <td><code>admin</code></td>
      <td>23302</td>
      <td><code>123456</code></td>
      <td>14542</td>
    </tr>
    <tr>
      <td><code>user</code></td>
      <td>8420</td>
      <td><code>admin</code></td>
      <td>7757</td>
    </tr>
    <tr>
      <td><code>test</code></td>
      <td>7547</td>
      <td><code>123</code></td>
      <td>7355</td>
    </tr>
    <tr>
      <td><code>oracle</code></td>
      <td>6211</td>
      <td><code>1234</code></td>
      <td>7099</td>
    </tr>
    <tr>
      <td><code>ftpuser</code></td>
      <td>4012</td>
      <td><code>root</code></td>
      <td>6999</td>
    </tr>
    <tr>
      <td><code>ubuntu</code></td>
      <td>3657</td>
      <td><code>password</code></td>
      <td>6118</td>
    </tr>
    <tr>
      <td><code>guest</code></td>
      <td>3606</td>
      <td><code>test</code></td>
      <td>5671</td>
    </tr>
    <tr>
      <td><code>postgres</code></td>
      <td>3455</td>
      <td><code>12345</code></td>
      <td>5223</td>
    </tr>
    <tr>
      <td><code>usuario</code></td>
      <td>2876</td>
      <td><code>guest</code></td>
      <td>4423</td>
    </tr>
  </tbody>
</table>

<p>There were a total of 128,588 unique pairings of username and password
attempted, though only 38,112 were attempted 5 or more times.  You can
<a href="https://systemoverlord.com/static/attachments/gopot/creds.csv">download the full list of pairs with counts</a>
here, but I’ve omitted those attempted less than 5 times in case a legitimate
user typo’d an IP or otherwise was mistaken.  The top 25 pairings are:</p>

<table>
  <thead>
    <tr>
      <th>username</th>
      <th>password</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>root</td>
      <td>&nbsp;</td>
      <td>37580</td>
    </tr>
    <tr>
      <td>root</td>
      <td>root</td>
      <td>4213</td>
    </tr>
    <tr>
      <td>user</td>
      <td>user</td>
      <td>2794</td>
    </tr>
    <tr>
      <td>root</td>
      <td>123456</td>
      <td>2569</td>
    </tr>
    <tr>
      <td>test</td>
      <td>test</td>
      <td>2532</td>
    </tr>
    <tr>
      <td>admin</td>
      <td>admin</td>
      <td>2531</td>
    </tr>
    <tr>
      <td>root</td>
      <td>admin</td>
      <td>2185</td>
    </tr>
    <tr>
      <td>guest</td>
      <td>guest</td>
      <td>2143</td>
    </tr>
    <tr>
      <td>root</td>
      <td>password</td>
      <td>2128</td>
    </tr>
    <tr>
      <td>oracle</td>
      <td>oracle</td>
      <td>1869</td>
    </tr>
    <tr>
      <td>ubuntu</td>
      <td>ubuntu</td>
      <td>1811</td>
    </tr>
    <tr>
      <td>root</td>
      <td>1234</td>
      <td>1681</td>
    </tr>
    <tr>
      <td>root</td>
      <td>123</td>
      <td>1658</td>
    </tr>
    <tr>
      <td>postgres</td>
      <td>postgres</td>
      <td>1594</td>
    </tr>
    <tr>
      <td>support</td>
      <td>support</td>
      <td>1535</td>
    </tr>
    <tr>
      <td>jenkins</td>
      <td>jenkins</td>
      <td>1360</td>
    </tr>
    <tr>
      <td>admin</td>
      <td>password</td>
      <td>1241</td>
    </tr>
    <tr>
      <td>root</td>
      <td>12345</td>
      <td>1177</td>
    </tr>
    <tr>
      <td>pi</td>
      <td>raspberry</td>
      <td>1160</td>
    </tr>
    <tr>
      <td>root</td>
      <td>12345678</td>
      <td>1126</td>
    </tr>
    <tr>
      <td>root</td>
      <td>123456789</td>
      <td>1069</td>
    </tr>
    <tr>
      <td>ubnt</td>
      <td>ubnt</td>
      <td>1069</td>
    </tr>
    <tr>
      <td>admin</td>
      <td>1234</td>
      <td>1012</td>
    </tr>
    <tr>
      <td>root</td>
      <td>1234567890</td>
      <td>967</td>
    </tr>
    <tr>
      <td>ec2-user</td>
      <td>ec2-user</td>
      <td>963</td>
    </tr>
  </tbody>
</table>

<p>Again, no real surprises here.  <code>ubnt</code> is a little bit higher than I would have
thought (for Ubiquiti networking gear) but I suppose there’s a fair bit of their
gear on the internet.  It’s interesting to see the mix of “lazy admin” and
“default credentials” here.  It’s <em>mildly</em> interesting to me that all substrings
of the first 10 digits (3 or longer) are included, <em>except</em> for 7 digits.  I
guess 7 digit passwords are less common?</p>

<h2 id="timing-information">Timing Information</h2>

<p>Though I imagine these kind of untargeted scans are long-term processes
continually running, I decided to check and see what the timing looked like
anyway.  Neither the day of week analysis nor the hour of day analysis look
like there’s any significant variance.</p>

<p><img src="https://systemoverlord.com/img/gopot/days_of_week.png" alt="Day of Week">
<img src="https://systemoverlord.com/img/gopot/hours.png" alt="Hour of Day"></p>

<p>Looking at the number of login requests over the time period where I’ve been
running the honeypots shows the traffic to be intermittent.  While I didn’t
expect the number to be constant, the variance is much higher than I expected.
I imagine a larger sample size and more nodes would probably make the results
more even.</p>

<p><img src="https://systemoverlord.com/img/gopot/dates.png" alt="Day of Study"></p>

<h2 id="analysis-of-sources">Analysis of Sources</h2>

<p>So where are all of these requests coming from?  I want to start by noting that
<em>none</em> of my analysis is an attempt to attribute the actors making the requests
– that’s just not possible with this kind of data.  There’s two ways to look at
the source of requests – in terms of the network, and in terms of the (assumed)
geography.  My analysis relied on the IP to ASN and IP to Country data provided
by <a href="https://iptoasn.com/">iptoasn.com</a>.</p>

<p>Looking at the country-level data, networks from China lead the pack by a long
shot (62% of all login attempts), followed by the US.</p>

<p><img src="https://systemoverlord.com/img/gopot/countries.png" alt="Countries"></p>

<table>
  <thead>
    <tr>
      <th>Country</th>
      <th>Count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>CN</td>
      <td>577789</td>
    </tr>
    <tr>
      <td>US</td>
      <td>87589</td>
    </tr>
    <tr>
      <td>TW</td>
      <td>48645</td>
    </tr>
    <tr>
      <td>FR</td>
      <td>39072</td>
    </tr>
    <tr>
      <td>RU</td>
      <td>30929</td>
    </tr>
    <tr>
      <td>NL</td>
      <td>29920</td>
    </tr>
    <tr>
      <td>JP</td>
      <td>28033</td>
    </tr>
    <tr>
      <td>DE</td>
      <td>15408</td>
    </tr>
    <tr>
      <td>IN</td>
      <td>13921</td>
    </tr>
    <tr>
      <td>LT</td>
      <td>6623</td>
    </tr>
  </tbody>
</table>

<p>Again, I’m not claiming that these countries mean anything other than location
of the autonomous system (AS) that originates the requests.  I also did not do
individual IP geolocation, so the results should be taken with a small grain of
salt.</p>

<p>So what networks are sourcing this traffic?  I have the <a href="https://systemoverlord.com/static/attachments/gopot/asns.csv">full AS counts and
data</a>, but the top networks are:</p>

<table>
  <thead>
    <tr>
      <th>AS Name</th>
      <th>Country</th>
      <th>ASN</th>
      <th>Count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>CHINANET-BACKBONE No.31,Jin-rong Street</td>
      <td>CN</td>
      <td>4134</td>
      <td>202024</td>
    </tr>
    <tr>
      <td>CHINANET-JS-AS-AP AS Number for CHINANET jiangsu province backbone</td>
      <td>CN</td>
      <td>23650</td>
      <td>186274</td>
    </tr>
    <tr>
      <td>CHINA169-BACKBONE CNCGROUP China169 Backbone</td>
      <td>CN</td>
      <td>4837</td>
      <td>122192</td>
    </tr>
    <tr>
      <td>HINET Data Communication Business Group</td>
      <td>TW</td>
      <td>3462</td>
      <td>48492</td>
    </tr>
    <tr>
      <td>OVH</td>
      <td>FR</td>
      <td>16276</td>
      <td>30865</td>
    </tr>
    <tr>
      <td>VECTANT ARTERIA Networks Corporation</td>
      <td>JP</td>
      <td>2519</td>
      <td>27481</td>
    </tr>
    <tr>
      <td>DIGITALOCEAN-ASN - DigitalOcean, LLC</td>
      <td>US</td>
      <td>14061</td>
      <td>26965</td>
    </tr>
    <tr>
      <td>MICROSOFT-CORP-MSN-AS-BLOCK - Microsoft Corporation</td>
      <td>US</td>
      <td>8075</td>
      <td>20370</td>
    </tr>
    <tr>
      <td>RMINJINERING</td>
      <td>RU</td>
      <td>49877</td>
      <td>16710</td>
    </tr>
    <tr>
      <td>AS38994</td>
      <td>NL</td>
      <td>38994</td>
      <td>14482</td>
    </tr>
    <tr>
      <td>XMGBNET Golden-Bridge Netcom communication Co.,LTD.</td>
      <td>CN</td>
      <td>45058</td>
      <td>12418</td>
    </tr>
    <tr>
      <td>CNNIC-ALIBABA-CN-NET-AP Hangzhou Alibaba Advertising Co.,Ltd.</td>
      <td>CN</td>
      <td>37963</td>
      <td>12045</td>
    </tr>
    <tr>
      <td>CNNIC-TENCENT-NET-AP Shenzhen Tencent Computer Systems Company Limited</td>
      <td>CN</td>
      <td>45090</td>
      <td>10804</td>
    </tr>
    <tr>
      <td>CNIX-AP China Networks Inter-Exchange</td>
      <td>CN</td>
      <td>4847</td>
      <td>10000</td>
    </tr>
    <tr>
      <td>PONYNET - FranTech Solutions</td>
      <td>US</td>
      <td>53667</td>
      <td>9317</td>
    </tr>
    <tr>
      <td>ITTI</td>
      <td>US</td>
      <td>44685</td>
      <td>7960</td>
    </tr>
    <tr>
      <td>CHINA169-BJ China Unicom Beijing Province Network</td>
      <td>CN</td>
      <td>4808</td>
      <td>7835</td>
    </tr>
    <tr>
      <td>AS12876</td>
      <td>FR</td>
      <td>12876</td>
      <td>7262</td>
    </tr>
    <tr>
      <td>AS209605</td>
      <td>LT</td>
      <td>209605</td>
      <td>6586</td>
    </tr>
    <tr>
      <td>CONTABO</td>
      <td>DE</td>
      <td>51167</td>
      <td>6261</td>
    </tr>
  </tbody>
</table>

<p><img src="https://systemoverlord.com/img/gopot/asns.png" alt="AS Graph"></p>

<p>Chinanet is no surprise given the high ratio of China in general.  OVH is a
low-cost host known to have liberal AUP, so is popular for both malicious and
research purposes.  DigitalOcean and Microsoft, of course, are popular cloud
providers.  Surprisingly, AWS only sourced about 600 connections, unless they
have a large number of IPs on a non-Amazon ASN.</p>

<p>Overall, traffic came from 27,448 unique IPv4 addresses.  Of those, more than 11
thousand sent only a single request.  At the other end of the spectrum, the top
IP source sent 64,969 login requests.</p>

<p>Most hosts sent relatively few requests, the large numbers are outliers:</p>

<p><img src="https://systemoverlord.com/img/gopot/ipcnts.png" alt="IP Count Graph"></p>

<p>Surely, by now a thought has crossed your mind: how many of these requests are
coming from Tor?  Surely the Tor network is a wretched hive of scum and villany,
and the source of much malicious traffic, right?</p>

<p><img src="https://systemoverlord.com/img/gopot/tor.png" alt="Tor Graph"></p>

<p>Not at all.  Only 219 of the unique source IPs were identified as Tor exit
nodes, representing only 0.8% of the sources.  On a per-request basis, even a
smaller percentage of requests is seen from Tor exit nodes.</p>

<h2 id="client-software">Client Software</h2>

<p>Remember – this is self-reported by the client application, and just like I can
spoof the server version string, so can clients.  But I still thought it would
be interesting to take a brief look at those.</p>

<table>
  <thead>
    <tr>
      <th>client</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>SSH-2.0-PuTTY</code></td>
      <td>309797</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-PUTTY</code></td>
      <td>182465</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-libssh2_1.4.3</code></td>
      <td>135502</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-Go</code></td>
      <td>125254</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-libssh-0.6.3</code></td>
      <td>62117</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-libssh2_1.7.0</code></td>
      <td>23799</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-libssh2_1.9.0</code></td>
      <td>21627</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-OpenSSH_7.3</code></td>
      <td>9954</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-OpenSSH_7.4p1</code></td>
      <td>8949</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-libssh2_1.8.0</code></td>
      <td>5284</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-JSCH-0.1.45</code></td>
      <td>3469</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-PuTTY_Release_0.70</code></td>
      <td>2080</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-PuTTY_Release_0.63</code></td>
      <td>1813</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-OpenSSH_5.3</code></td>
      <td>1212</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-paramiko_1.8.1</code></td>
      <td>1140</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-PuTTY_Release_0.62</code></td>
      <td>1130</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-OpenSSH_4.3</code></td>
      <td>795</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-PuTTY_Release_0.66</code></td>
      <td>694</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-OpenSSH_7.9p1 Raspbian-10+deb10u2</code></td>
      <td>690</td>
    </tr>
    <tr>
      <td><code>SSH-2.0-libssh_0.11</code></td>
      <td>660</td>
    </tr>
  </tbody>
</table>

<p>You know, I didn’t expect that.  <a href="https://www.putty.org/">PuTTY</a> as the top
client strings.  (Also not sure what to make of the case difference.)  I wonder
if people are building the PuTTY SSH library into a tool for scanning or
wrapping the binary in some kind of script.</p>

<p>Go, paramiko, and libssh are less surprising, as they’re libraries designed for
integration.  It’s hard to know if the OpenSSH requests are linked into a
scanning tool or just wrapped versions of the SSH client.  At some point in the
future, I might dive more into this and trying to figure out which software uses
which libraries (at least for the publicly-known tools).</p>

<h2 id="summary">Summary</h2>

<p>I was hoping to find something earth-shattering in this research.  Instead, I
found things that were much as expected – common usernames and passwords,
widespread scanning, large numbers of requests.  One thing’s for sure though:
connect it to the internet and someone’s going to pwn it.</p>

  </div>
  

</div></div>]]>
            </description>
            <link>https://systemoverlord.com/2020/09/04/lessons-learned-from-ssh-credential-honeypots.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399463</guid>
            <pubDate>Mon, 07 Sep 2020 14:00:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React-konva – 2d canvas components for React]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24399448">thread link</a>) | @lavrton
<br/>
September 7, 2020 | https://konvajs.org/docs/react/Intro.html | <a href="https://web.archive.org/web/*/https://konvajs.org/docs/react/Intro.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://konvajs.org/docs/react/Intro.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399448</guid>
            <pubDate>Mon, 07 Sep 2020 13:57:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing Interplanetary Trajectories Resilient to Missed Thrust Events Usin ETF]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399346">thread link</a>) | @gereshes
<br/>
September 7, 2020 | https://gereshes.com/2020/09/07/designing-trajectories-resilient-to-missed-thrust-events-using-expected-thrust-fraction-asc-2020/ | <a href="https://web.archive.org/web/*/https://gereshes.com/2020/09/07/designing-trajectories-resilient-to-missed-thrust-events-using-expected-thrust-fraction-asc-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p><span>Note: This post is adapted from my&nbsp;conference</span> <a href="https://www.researchgate.net/publication/343658815_Designing_Trajectories_Resilient_to_Missed_Thrust_Events_Using_Expected_Thrust_Fraction" target="_blank" rel="noopener noreferrer">paper</a>, <span>which was presented at the Astrodynamics Specialists Conference in Summer 2020. You can read the full paper</span> <a href="https://www.researchgate.net/publication/343658815_Designing_Trajectories_Resilient_to_Missed_Thrust_Events_Using_Expected_Thrust_Fraction" target="_blank" rel="noopener noreferrer">here.</a></p>
<h3><span>Abstract – Designing Trajectories Resilient to Missed Thrust Events Using Expected Thrust Fraction</span></h3>
<p><span>With the adoption of efficient low-thrust propulsion methods, the probability of a</span> <a href="https://gereshes.com/2019/09/02/missed-thrust-events-in-deep-space-trajectories/" target="_blank" rel="noopener noreferrer">missed thrust event</a>&nbsp;<span>occurring has become a significant concern for short and long-duration missions. If the missed thrust events take place during a critical portion of the trajectory, the mission can be compromised. Therefore, it is essential to develop trajectories that are resilient to missed thrust events. This paper investigates the use of expected thrust fraction, which embeds the stochastic nature of missed thrust events into a deterministic optimal control problem. The performance of trajectories designed using expected thrust fraction is compared with traditionally designed trajectories to measure changes in resiliency to missed thrust events. In this investigation, trajectories designed using expected thrust fraction arrive with a median lateness half that of traditionally designed trajectories. Using expected thrust fraction can help astrodynamicists mitigate risks posed by the use of low-thrust propulsion.</span></p>
<p><img loading="lazy" src="https://i1.wp.com/gereshes.com/wp-content/uploads/2020/07/Earth_Return_Orbiter_pillars.jpg?resize=1024%2C576&amp;ssl=1" alt="" width="1024" height="576" srcset="https://i1.wp.com/gereshes.com/wp-content/uploads/2020/07/Earth_Return_Orbiter_pillars.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/gereshes.com/wp-content/uploads/2020/07/Earth_Return_Orbiter_pillars.jpg?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/gereshes.com/wp-content/uploads/2020/07/Earth_Return_Orbiter_pillars.jpg?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/gereshes.com/wp-content/uploads/2020/07/Earth_Return_Orbiter_pillars.jpg?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/gereshes.com/wp-content/uploads/2020/07/Earth_Return_Orbiter_pillars.jpg?w=1921&amp;ssl=1 1921w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></p>
<h3><span>Key Takeaways</span></h3>
<p><span>The full paper is online&nbsp;</span><a href="https://www.researchgate.net/publication/343658815_Designing_Trajectories_Resilient_to_Missed_Thrust_Events_Using_Expected_Thrust_Fraction" target="_blank" rel="noopener noreferrer">here</a>, <span>but here are, in my opinion, the most interesting aspects</span></p>
<ul>
<li><span>The stochastic nature of missed thrust events can be embedded into a&nbsp; time-varying duty cycle</span></li>
<li><span>It makes trajectories more resilient to&nbsp; missed thrust events</span></li>
<li><span>The risk of a mission and mass delivered can be traded between</span></li>
</ul>
<h3><span>Presentation</span></h3>
<p><span>Due to COVID-19, this conference was held virtually, and I have uploaded a video of my presentation below.</span></p>
<p><span><iframe width="1170" height="659" src="https://www.youtube.com/embed/GqvoaGvDrdE?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<h3>Want More Gereshes?</h3>
<p>If you want to receive new Gereshes blog post directly to your email when they come out, you can sign up for that&nbsp;<a href="https://tinyletter.com/gereshes">here!</a></p>
<p>Don’t want another email? That’s ok, Gereshes also has a&nbsp;<a href="https://twitter.com/gereshes" target="_blank" rel="noreferrer noopener">twitter account</a>&nbsp;and&nbsp;<a href="https://www.reddit.com/r/gereshes" target="_blank" rel="noreferrer noopener">subreddit!</a></p>

					</div></div>]]>
            </description>
            <link>https://gereshes.com/2020/09/07/designing-trajectories-resilient-to-missed-thrust-events-using-expected-thrust-fraction-asc-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399346</guid>
            <pubDate>Mon, 07 Sep 2020 13:39:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Moonlander: A next-generation ergonomic keyboard]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399196">thread link</a>) | @magnetised
<br/>
September 7, 2020 | https://www.zsa.io/moonlander/ | <a href="https://web.archive.org/web/*/https://www.zsa.io/moonlander/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><strong>Ergonomic:</strong> Type at shoulder width, reassign keys, tilt and tent it.</p><p><strong>Mechanical:</strong> For the most enjoyable typing experience.</p><p><strong>Dynamic:</strong> Adjust the angle of the whole keyboard, or just the thumb cluster.</p><p><strong>Portable:</strong> Folds into a compact package. Carrying case included.</p><p><strong>Gamer-friendly:</strong> Plug in just the left side to get your game on.</p><p><strong>Built to last:</strong> Backed by a solid two-year warranty.<!-- --> <br>No fine print.</p></div></div></div></div>]]>
            </description>
            <link>https://www.zsa.io/moonlander/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399196</guid>
            <pubDate>Mon, 07 Sep 2020 13:12:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tooltips in Tooltips]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399125">thread link</a>) | @knowingathing
<br/>
September 7, 2020 | https://philip.design/blog/tooltips-in-tooltips/ | <a href="https://web.archive.org/web/*/https://philip.design/blog/tooltips-in-tooltips/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <div>
            <p>With the recent release of <a target="_blank" href="https://store.steampowered.com/app/1158310/Crusader_Kings_III/">Crusader Kings 3</a> by Paradox Interactive, a new UI paradigm in the game stopped me in my tracks. There are a lot of lessons that web designers can learn from video game user interface design and while they aren’t always transferrable, they are worth exploring. In this case it’s the idea of having <i>tooltips within tooltips.</i></p>

            <p><img src="https://philip.design/blog/tooltips-in-tooltips/tooltips.png"></p><figcaption>Tooltips within tooltips! Image taken from <a target="_blank" href="https://www.crusaderkings.com/news/dev-diary-16-tutorials-and-tooltips-and-encyclopedias-oh-my">this dev diary</a></figcaption>

            

            <p>Tooltips have become a standard component in user interface design. The majority of web UI frameworks include some form of tooltip, with Bootstrap having <i>two</i> types (Tooltips and Popovers). Wikipedia uses tooltips when hovering over links:</p>

            <p><img src="https://philip.design/blog/tooltips-in-tooltips/droplet2.png"></p><figcaption>Image taken from this <a target="_blank" href="https://en.wikipedia.org/wiki/Respiratory_droplet">Wikipedia article</a></figcaption>

            <br>

            <h2>What about nested tooltips... on the web?</h2>
            <h3>Hover over "small droplets" to begin (sorry mobile users)</h3>
            <br>
            
            <div><p>The virus is spread primarily via
                </p><p>small droplets
                    <span>
                        <img src="https://philip.design/blog/tooltips-in-tooltips/droplet.png">
                        <p>A respiratory droplet is a small aqueous droplet produced by exhalation, consisting of

                            <span>saliva

                                <span>

                                    <img src="https://philip.design/blog/tooltips-in-tooltips/saliva.jpg">

                                    <span><b>Saliva</b> (commonly referred to as <b>spit</b>) is an extracellular fluid produced and secreted by salivary glands in the mouth. In
                                        <span>humans,

                                            <span>

                                                <span>

                                                    <img src="https://philip.design/blog/tooltips-in-tooltips/humans.jpg">
                                                    <span><b>Humans</b> (Homo sapiens) are highly intelligent primates that have become the dominant species on Earth. They are the only extant members of the subtribe Hominina and—together with chimpanzees, gorillas, and orangutans—are part of the family Hominidae (the great apes, or hominids).</span>
                                                    
                                                </span>                                                
                                                
                                            </span>
                                        </span>

                                        saliva is 99.5⁠% water plus electrolytes, mucus, white blood cells, epithelial cells (from which DNA can be extracted), enzymes (such as amylase and lipase), antimicrobial agents such as secretory IgA, and lysozymes.</span>
                                    
                                    
                                </span>
                            </span>

                            or mucus and other matter derived from

                            <span>respiratory tract

                                <span>

                                    <span>The <b>respiratory tract</b> is the subdivision of the respiratory system involved with the process of respiration in mammals. The respiratory tract is lined with respiratory mucosa or respiratory epithelium.</span>
                                    
                                    <img src="https://philip.design/blog/tooltips-in-tooltips/tract.svg">
                                    
                                </span>
                            </span>
                            
                            surfaces. Droplet sizes range from &lt;5 µm to 1000 µm. Large droplets fall to the ground or another surface before drying, but smaller ones fall slowly and dry so quickly...
                    
                        </p>
                        
                </span></p><p>
                from coughing, sneezing, and talking. The droplets are usually not airborne, however those standing in close proximity may inhale them and become infected. People may also become infected by touching a contaminated surface and then touching their face. The transmission may also occur through aerosols that can stay suspended in the air for longer periods of time in enclosed spaces. It is most contagious during the first three days after the onset of symptoms, although spread is possible before symptoms appear, and from people who are asymptomatic.
            </p></div>
            <figcaption>Images and content taken from <a target="_blank" href="https://en.wikipedia.org/">Wikipedia</a></figcaption>

            

            <p>Did you find it intuitive? Could you easily traverse up and down the tooltip chain? Note: this is a HTML/CSS example that I quickly put together so it’s rough around the edges.</p>

            <p>I found it suprisingly intuitive and easy to use. When you hover to reveal the first tooltip, you keep your cursor nice and still. After that, you locate a piece of information you want to learn more about and you hover over that. It might overlap the first tooltip, but that’s fine. You’ve chosen to seek more information.</p>

            <p>Another reason I like this idea, is that it matches how I think. When learning something new, there might be a supporting concept or idea I don't fully grasp. A nested tooltip is a great solution.</p>

            <p>In the context of a complex grand strategy game like CK3, having explanatory text is necessary. The designers and developers at Paradox elegantly solved this by implementing tooltips within tooltips. Kudos to them.</p>

            <h3>Potential issues</h3>
            <ul>
                <li><b>Accessibility.</b> Well anything is possible with Javascript right? You could tab through the tooltips to get them working.</li>
                <li><b>User experience.</b> It can be frustrating to move your cursor 1 pixel outside of the bounds of the element which removes the tooltip.</li>
                <li><b>How deep do you go?</b> The designer should use discretion. An infinitely deep tooltip chain doesn't make sense. There might be some sweet number here like, 2 or 3 nested tooltips.</li>
                <li><b>Touch?</b> I'm not sure how mobile works. You could just treat them as tappable elements.</li>
            </ul>

            <p>I guess the question is: could the web embrace nested tooltips?</p>

            <h4>Leave a comment :)</h4>
            <br>
            
        </div>
    </div></div>]]>
            </description>
            <link>https://philip.design/blog/tooltips-in-tooltips/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399125</guid>
            <pubDate>Mon, 07 Sep 2020 12:59:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This Week in Java]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24399095">thread link</a>) | @olegchir
<br/>
September 7, 2020 | https://darkest.land/2020/09/07/this-week-in-java-1/ | <a href="https://web.archive.org/web/*/https://darkest.land/2020/09/07/this-week-in-java-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    	    
    
<ul><li>OpenJDK finished the migration <a href="https://github.com/openjdk/jdk">to the GitHub</a>.</li><li><a href="https://spring.io/blog/2020/09/02/hello-azure-spring-cloud">Azure Spring Cloud</a>&nbsp;is out. It’s a platform for deploying and managing Spring Boot and Spring Cloud-powered services and software built on Microsoft Azure. It is jointly built, operated, and supported by Microsoft and VMware.</li><li><a href="https://www.eclipse.org/eclipse/news/4.17/jdt.php?v=rc1">Eclipse IDE 4.17 Release Candidate 1</a>&nbsp;is out. It introduces some new features, including support for&nbsp;<a href="https://openjdk.java.net/jeps/358">JEP 358: Helpful NullPointerExceptions</a>.</li><li>GitHub&nbsp;<a href="https://github.blog/2020-07-08-introducing-the-github-availability-report/">released a new report</a>&nbsp;about the latest incidents and availability problems.</li><li>On July 10, 2020, JetBrains hosted a Technology Day for Java. Presentations and videos for them are now&nbsp;<a href="https://pages.jetbrains.com/technology-day-java-2020">available here</a>.</li><li>A new <a href="https://github.com/linux-china/mybatis-r2dbc">R2DBC adapter for MyBatis</a> is out. A lot of Chinese in the README 😛</li><li><a href="https://www.eclipse.org/ditto/2020-08-31-release-announcement-120.html">Eclipse Ditto</a>&nbsp;1.2.0 is out. Eclipse Ditto is an open-source framework for creating and managing digital twins in the IoT. The new release is focused on “At least once” (QoS 1) processing, injecting timestamps and metadata, HTTP auth of push connections with client certificates.</li><li>Big Data Tools&nbsp;<a href="https://blog.jetbrains.com/idea/2020/09/big-data-tools-eap-10/">update is out</a>: SSH tunnels, filters and limits for Spark Monitoring apps tab, user-defined modules, and a ton of fixes and improvements.</li><li><a href="https://spring.io/blog/2020/09/03/spring-tools-4-7-2-released">Spring Tools 4.7.2</a>&nbsp;has been released. This release introduces an entirely new wizard in Eclipse to add Spring Boot starter modules to existing projects and an early experimental version of Spring Boot OCI image building support combined with Docker.</li><li><a href="https://www.dirigible.io/release/2020/09/02/news_new_release_5_2.html">Eclipse Dirigible 5.2 is out</a>. A new release brings us OData generation from the Entity Data Model and expanded OData support overall. Dirigible is a Cloud Development Platform that provides its development tools and a runtime environment.</li><li>A new open source Kubernetes&nbsp;<a href="https://filippobuletto.github.io/kubectl-java-test/">kubectl plugin</a>&nbsp;has been released. It is written in Java and ran using jbang.</li><li>A new cool&nbsp;<a href="https://www.youtube.com/watch?v=TYENQucbOOY">demo project</a>&nbsp;that demonstrates a wave effect by generating irregular contours connected using smooth QuadCurve Bezier paths. The waves animate by adjusting the control points of the contour itself.</li><li>Another cool&nbsp;<a href="https://www.youtube.com/watch?v=0vUUTWhIsIU">demo project</a>. It’s a Special Effect demonstrated in JavaFX for shrouding a standard GUI with a colorized shadow (making it opaque to the viewer) and then adding a “spotlight”, which dynamically interacts with the underlying GUI Nodes via line of sight connections.</li><li>A new exciting command-line utility is out. It can automatically add missing import statements in a Java file. Check it&nbsp;<a href="https://github.com/nicolascouvrat/javaimports">on Github</a>&nbsp;or read an announcement&nbsp;<a href="https://www.reddit.com/r/java/comments/ijleh5/ive_created_a_cli_utility_to_automatically_add/">on Reddit</a>.</li></ul>







<ul><li>Chaos Probe is out: a new stability analysis tool for deep learning models built using JavaFX. You can check a demo&nbsp;<a href="https://www.youtube.com/watch?v=Pab2fLwxI_g">on YouTube</a>. It is an application written entirely in Java and JavaFX, 14 which provides an interactive visualization of deep learning models (Keras) designed for image classification.</li><li>Google’s deep-learning model called&nbsp;<a href="https://arxiv.org/abs/2007.14062">BigBird</a>&nbsp;allows Transformer neural networks to process sequences up to 8x longer than previously possible. It may increase performance on several NLP tasks, including question-answering and document summarization.</li></ul>







<ul><li>I found a Reddit&nbsp;<a href="https://www.reddit.com/r/java/comments/ij5qek/an_openjdk_14_docker_image_thats_33_slimmer_than/">thread</a>&nbsp;dedicated to finding the slimmest JDK docker image.</li><li>A new&nbsp;<a href="https://www.reddit.com/r/java/comments/ii939b/i_created_a_sample_http_server_using_jetty_with/">thread on Reddit</a>&nbsp;about the small experimental HTTP server that uses Project Loom.</li><li>The same Redditor opened two random questions on how to use Java on&nbsp;<a href="https://www.reddit.com/r/java/comments/iku9yl/running_java_on_gpus/">GPUs</a>&nbsp;and&nbsp;<a href="https://www.reddit.com/r/java/comments/ikucup/running_java_on_fpgas/">FPGAs</a>.</li></ul>







<ul><li><a href="https://snyk.io/">Snyk</a>&nbsp;has&nbsp;<a href="https://snyk.io/blog/snyks-developer-first-prioritization-capabilities/">released</a>&nbsp;new tools for prioritizing security vulnerabilities. You can accelerate triaging with features like “Priority Score”, “Exploit Maturity”, and so on.</li><li><a href="https://aws.amazon.com/blogs/opensource/building-resilient-services-at-prime-video-with-chaos-engineering/">AWSSSMChaosRunner</a>&nbsp;is out. It’s a chaos engineering library by AWS. It will allow us to execute commands on a specific set of EC2 instances remotely. All the library sources are open, but this doesn’t make much sense because you still must use it against proprietary technologies.</li><li>Google&nbsp;<a href="https://cloud.google.com/blog/products/data-analytics/multi-language-sdks-for-building-cloud-pipelines">announced</a>&nbsp;a new service-oriented architecture Runner v2 to the&nbsp;<a href="https://cloud.google.com/dataflow">Dataflow</a>&nbsp;– their GCP service for executing Apache Beam pipelines.</li><li>Amazon AWS announces&nbsp;<a href="https://aws.amazon.com/blogs/aws/aws-announces-aws-contact-center-intelligence-solutions/">AWS Contact Center Intelligence solutions</a>. New&nbsp;<a href="https://aws.amazon.com/machine-learning/contact-center-intelligence/">Contact Center Intelligence (CCI)</a>&nbsp;solutions will provide the power of AI for contact centers. You can use Amazon Kendra, Amazon Translate, Amazon Transcribe, and partner services of companies like Accenture, Acqueon, Slalom, and Vonage.</li></ul>







<ul><li>A new episode of Josh Long’s&nbsp;<a href="https://spring.io/blog/2020/09/04/a-bootiful-podcast-springone-2020-josh-s-book-reactive-spring-and-microsoft-java-architect-and-fellow-java-champion-jonathan-giles">“A Bootiful Podcast.”</a>&nbsp;We will discuss SpringOne 2020, Josh’s book “Reactive Spring,” with Microsoft Java Architect and fellow Java Champion Jonathan Giles.</li><li><a href="https://adambien.blog/roller/abien/entry/unit_tests_considered_harmful_an">“Unit Tests Considered Harmful.”</a>&nbsp;It’s a new Adam Bien’s podcast episode on Airhacks.</li><li>A new&nbsp;<a href="https://soundcloud.com/infoq-channel/yan-cui-on-serverless-orchestration-choreography-distributed-tracking-cold-starts-and-more">podcast by Yan Cui</a>&nbsp;on Serverless Orchestration &amp; Choreography, Distributed Tracking, Cold Starts, and more.</li><li>A&nbsp;<a href="https://www.youtube.com/watch?v=cceRz3LToIo">video tutorial</a>&nbsp;on how to get started with native Java Applications using NetBeans IDE, GraalVM and Gluon.</li></ul>







<ul><li>A new episode of Josh Long’s&nbsp;<a href="https://spring.io/blog/2020/09/02/this-week-in-spring-springone-2020-edition-september-1st-2020">“This Week in Spring.”</a></li><li>A new episode of&nbsp;<a href="https://blog.jetbrains.com/idea/2020/09/java-annotated-monthly-september-2020/">Java Annotated Monthly</a>&nbsp;by Trisha Gee.</li><li><a href="https://chrzaszcz.dev/2020/08/kafka-testing/">“How to test the application’s integration with Kafka and Testcontainers”</a> by Łukasz Chrząszcz.</li><li>Vlad Mihalcea wrote&nbsp;<a href="https://vladmihalcea.com/encrypt-decrypt-json-jpa/">a new tutorial</a>&nbsp;on how to encrypt and decrypt JSON properties with JPA.</li><li>A&nbsp;<a href="https://blog.rajanpanchal.net/write-your-first-aws-lambda-in-java">short tutorial</a>&nbsp;on how to write your first AWS Lambda in Java.</li><li>This&nbsp;<a href="https://blog.jetbrains.com/idea/2020/09/everyday-refactorings-in-intellij-idea/">blog post</a>&nbsp;reveals a bunch of neat everyday refactorings for IntelliJ IDEA.</li><li>Java Architecture for XML Binding (JAXB) API was deprecated in Java 9 and removed from Java SE 11. What should we do now? Check out&nbsp;<a href="https://adambien.blog/roller/abien/entry/from_pojo_to_xml_and">a small example</a>&nbsp;on Adam Bien’s website.</li><li>Michael Scharhag’s&nbsp;<a href="https://www.javacodegeeks.com/2020/08/ocr-in-java-with-tess4j.html">“OCR in Java with Tess4J”</a>. You will write a simple app to turn a JPEG file into text. Tess4J is a Java JNA wrapper for Tesseract OCR API. Tesseract is a famous optical character recognition engine; 94% of its code is in C++.</li><li>Michael Scherlag’s&nbsp;<a href="https://www.javacodegeeks.com/2020/08/extending-junit-5.html">“Extending JUnit 5”</a>. You will write a custom extension and use it within the @ExtendWith annotation.</li><li><a href="https://blog.frankel.ch/github-actions-maven-releases/">A quick tutorial</a>&nbsp;on how to build Maven projects with Github Actions.</li><li>A new official Vaadin&nbsp;<a href="https://vaadin.com/learn/tutorials/hazelcast">tutorial</a>&nbsp;on how to use it with Hazelcast.</li><li><a href="https://www.java67.com/2012/08/5-thread-interview-questions-answers-in.html">Top 12 Java Thread, Concurrency and Multithreading Interview Questions For experienced Programmers</a>. These questions are pretty basic, but still quite interesting for anyone who never tried to write a complex concurrent app.</li></ul>

    
            
    
    		    
</div></div>]]>
            </description>
            <link>https://darkest.land/2020/09/07/this-week-in-java-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24399095</guid>
            <pubDate>Mon, 07 Sep 2020 12:55:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Named Parameters in C++20]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 75 (<a href="https://news.ycombinator.com/item?id=24398756">thread link</a>) | @ibobev
<br/>
September 7, 2020 | https://pdimov.github.io/blog/2020/09/07/named-parameters-in-c20/ | <a href="https://web.archive.org/web/*/https://pdimov.github.io/blog/2020/09/07/named-parameters-in-c20/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span>07 Sep 2020</span></p><p>A programming language supports <em>named parameters</em> when one
can call a function supplying the parameters by name, as in
the following hypothetical example (using C++ syntax):</p>

<div><div><pre><code>void f( int x, int y );

int main()
{
    f( x = 1, y = 2 );
}
</code></pre></div></div>

<p>C++ is obviously not such a language and there have been
numerous proposals to rectify this omission, unfortunately none
of them successful. The latest attempt is Axel Naumann’s paper
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0671r2.html">Self-explanatory Function Arguments</a>,
which tries to attack the problem from another angle by just
allowing normal function calls to be tagged with the parameter
name, as in</p>



<p>enabling compilers to issue helpful warnings when a name doesn’t
match, but not allowing one to omit, or reorder, arguments.</p>

<p>Even in this limited form, named parameters would still be immensely
useful, but this is not what this post is about. What this post is
about is that we can already achieve something very close to named
parameters in C++20, by using a C99 feature called <em>designated
initializers</em>.</p>

<p>Designated initializers allow one to initialize structures by
member name, as in the following example:</p>

<div><div><pre><code>struct A
{
    int x;
    int y;
};

A a1 = { .x = 1, .y = 2 };
A a2 = { .x = 3 }; // a2.y == 0
A a3 = { .y = 4 }; // a3.x == 0
A a4 = { .y = 5, .x = 6 }; // valid C, invalid C++ (reorder)
</code></pre></div></div>

<p>C++ introduces a restriction C doesn’t have: the initializers
must follow the declaration order, similarly to how class member
initalizers are executed in member declaration order. But in
exchange, it allows us to supply default values:</p>

<div><div><pre><code>struct A
{
    int x = 0;
    int y = 0;
};

A a3 = { .y = 4 }; // a3.x == 0, no warning
</code></pre></div></div>

<p>You can already see where this is going. Instead of</p>



<p>we declare</p>



<p>and then call it like this:</p>

<div><div><pre><code>int main()
{
    f({ .x = 1, .y = 2 });
}
</code></pre></div></div>

<p>This works under <a href="https://godbolt.org/z/YfWj3W">GCC</a> and
<a href="https://godbolt.org/z/vbnz4T">Clang</a> even without <code>-std=c++20</code> because
they support designated initializers in earlier language modes as
an extension, and it works under <a href="https://godbolt.org/z/bKozaW">MSVC</a>
with <code>-std:c++latest</code>.</p>

<p>For a more realistic example, consider this snippet, taken from real
code, that sets a 10 second
<a href="https://www.boost.org/doc/libs/1_74_0/libs/beast/doc/html/beast/using_websocket/timeouts.html">timeout</a>
on a <a href="https://boost.org/libs/beast">Boost.Beast</a> websocket:</p>

<div><div><pre><code>#include &lt;boost/beast/websocket/stream.hpp&gt;
#include &lt;boost/beast/core/tcp_stream.hpp&gt;
#include &lt;chrono&gt;

void f1(boost::beast::websocket::stream&lt;boost::beast::tcp_stream&gt;&amp; ws)
{
    auto opt = boost::beast::websocket::stream_base::timeout();

    opt.keep_alive_pings = true;
    opt.idle_timeout = std::chrono::seconds(10);

    ws.set_option(opt);
}
</code></pre></div></div>

<p>Here’s how we can reformulate it by using the above idiom and <code>&lt;chrono&gt;</code>
literals:</p>

<div><div><pre><code>#include &lt;boost/beast/websocket/stream.hpp&gt;
#include &lt;boost/beast/core/tcp_stream.hpp&gt;
#include &lt;chrono&gt;

using namespace std::chrono_literals;

void f2(boost::beast::websocket::stream&lt;boost::beast::tcp_stream&gt;&amp; ws)
{
    ws.set_option({ .idle_timeout = 10s, .keep_alive_pings = true });
}
</code></pre></div></div>

<p>Apart from the slightly awkward <code>({ ... })</code> syntax and the need to observe
the right parameter order, that’s not that far from the ideal; and it’s
considerably better than <code>f1</code>.</p>

<p>This also works for constructors. Consider this hypothetical <code>vector</code> class
that is like <code>std::vector</code>, except with its various constructor overloads
replaced with one taking named parameters:</p>

<div><div><pre><code>template&lt;class T, class A = std::allocator&lt;T&gt;&gt; class vector
{
private:

    struct params
    {
        std::size_t size = 0;
        T element{};
        std::size_t capacity = 0;
        A allocator{};
    };

public:

    explicit vector( params p );
};
</code></pre></div></div>

<p>This is <a href="https://godbolt.org/z/x17fdY">how it’s used</a>:</p>

<div><div><pre><code>auto f()
{
    vector&lt;int&gt; v{{ .size = 4, .element = 11, .capacity = 64 }};
    return v;
}
</code></pre></div></div>

<p>Again, apart from the odd <code>{{ ... }}</code> syntax, not that bad.</p>


</div>

<!--

<div class="related">
  <h2>Related posts</h2>
  <ul class="related-posts">
    
    
      <li>
        <h3>
          <a href="/blog/2020/09/06/why-use-the-boost-license/">
            Why You Should Use the Boost Software License
            <small>06 Sep 2020</small>
          </a>
        </h3>
      </li>
    
    
    
      <li>
        <h3>
          <a href="/blog/2020/09/05/from-simd-to-ast-extraction/">
            From SIMD to AST Extraction
            <small>05 Sep 2020</small>
          </a>
        </h3>
      </li>
    
    
    
      <li>
        <h3>
          <a href="/blog/2020/07/24/compilers-do-static-analysis/">
            Compilers Do Static Analysis, They Just Don't Tell You
            <small>24 Jul 2020</small>
          </a>
        </h3>
      </li>
    
    
  </ul>
</div>

-->

      </div></div>]]>
            </description>
            <link>https://pdimov.github.io/blog/2020/09/07/named-parameters-in-c20/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398756</guid>
            <pubDate>Mon, 07 Sep 2020 11:51:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Colorizing SVG Icons with CSS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24398685">thread link</a>) | @jansan
<br/>
September 7, 2020 | https://www.iconfu.com/docs/css_colorizable_svgs/examples | <a href="https://web.archive.org/web/*/https://www.iconfu.com/docs/css_colorizable_svgs/examples">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
    <div>
      
      <div id="ifu-css-colorizable-svgs-examples">
  <div>
    <div>
      <h2>Coloring Individual Icons</h2>
      <p>When displaying the same colorizable SVG multiple times, each time a different set of colors can be applied with CSS. Below, the same "hipster" SVG is displayed four times, with different colors for skin, hair, glasses and shirt. The shading is done automatically by the SVG.</p>
      <p>Each of the icons has a unique id, so a CSS id selector can be used to apply the specific colors for each icon.</p>
    </div>
    


  </div>

  <div>
    <div>
      <h2>Coloring Groups of Icons</h2>
      <p>Groups of icons can share the same color scheme, and a group of icons can be displayed multiple times with different color schemes. Below, both company info cards show the same set of colorizable SVGs. A CSS color scheme to match the
        corporate identity is applied on each side.</p>
      <p>For coloring groups of icons a CSS class selector is used. This way each icon with class <code>green-company</code> has a different color scheme than
        an icon with class <code>blue-company</code></p>
    </div>
    


  </div>

  <div>
    <div>
      <h2>Dynamic Color Changing</h2>
      <p>Colors can be changed dynamically while the icons are displayed. Click on the toggle button below to switch between light and dark mode. The color scheme of the icons will change depending on the selected mode.</p>
      <p>The gradient on the icons is defined by three color values. If the switch is toggled, the class <code>dark-mode</code> is set to the documents's body.
        This will activate a "dark-mode" CSS rule which overrides the default color with a dark mode color.</p>
    </div>
    


  </div>

  <div>
    <div>
      <h2>Mouse Interaction and Dynamic Color Changing</h2>
      <p>In this example we use a button state for changing icon colors. Move the mouse over the icons and press and click on them to trigger the color changes.</p>
      <p>The SVG is placed on a button, so we can use the buttons's pseudo class selectors (<code>:hover</code>, <code>:active</code>, and <code>:disabled</code>) to specify different colors.</p>
    </div>
    


  </div>

  <div>
    <div>
      <h2>Text Color as Icon Color</h2>
      <p>When exporting icons as CSS styleable SVGs, you can optionally set the icons' main color as the "free color". For this color the value of current CSS text color will be used.</p>
      <p>Clicking on a color swatch below will set the <code>color</code> attribute of the icons array to the background color of the color swatch. The icons will inherit the color and change accordingly.</p>
    </div>
    


  </div>
</div>
    </div>

    </div></div>]]>
            </description>
            <link>https://www.iconfu.com/docs/css_colorizable_svgs/examples</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398685</guid>
            <pubDate>Mon, 07 Sep 2020 11:37:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Think Real Hard]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24398649">thread link</a>) | @codesuki
<br/>
September 7, 2020 | https://www.benkuhn.net/thinkrealhard/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/thinkrealhard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Famous physicist Murray Gell-Mann is supposed to have <a href="http://wiki.c2.com/?FeynmanAlgorithm" target="_blank">suggested</a> that Richard Feynman solved problems with the following cutting edge technique:</p><blockquote><ol><li>Write down the problem.</li><li>Think real hard.</li><li>Write down the solution.</li></ol></blockquote><p>Usually when people quote this, it’s to make a joke about how smart Feynman was. (If I tried this, I wouldn’t come up with quantum electrodynamics! I must not be able to think hard enough.) That’s one reading, but I prefer a different one.</p><p>When I started programming professionally, I was really excited about figuring out how to become a better programmer. (I still am!) So I asked a lot of people, “how can I become a better programmer?” But nobody gave me very satisfactory answers. They would tell me to play around with obscure programming languages, or study algorithms, or read papers, or do a bunch of other stuff that felt tangential and didn’t really move the needle.</p><p>In retrospect, I wish those people had just told me “think real hard.” I was looking for an easy way out—One Weird Trick to Programming Better—but programming is too hard for that.</p><p>That’s my preferred reading of the Feynman Algorithm: there is no one weird trick.</p><p>On the other hand, I <em>have</em> gotten a ton better at programming in the last four years. Not through any specific piece of advice, or any weird trick. Rather, it’s come by constantly trying to learn small new things, make small tool improvements, make my models a little deeper, work a little faster, come up with slightly better ideas. By, literally, thinking real hard, for a long, long time. The Feynman Algorithm works!</p><p>(That’s not to say good advice is impossible. I’m sure if <a href="http://www.informatika.bg/jeffdean" target="_blank">Jeff Dean</a> watched me go through my programming day, he would have tons of great tactical tips that would help me a lot. But even that depends on Jeff Dean being able to know which of his 10,000 tactical tips would be most useful to me. And the real difference between us isn’t the tactical tips, it’s the underlying models that generate the tips in the first place. Those seem to be nearly impossible to communicate.)</p><p>A lot of the things people ask for advice on fall into this category. “How can I be happier?” “How can I be more productive?” “How can I have a bigger impact on the world?” Sure, there are basic life hacks like sleeping well or getting exercise. But 99% of the “secret”—the thing that separates me from Gell-Mann, or Jeff Dean—is tacit knowledge. It often can’t be articulated any better than “think real hard.” But, believe it or not, thinking real hard, for real long, <em>does</em> work.</p></article></div>]]>
            </description>
            <link>https://www.benkuhn.net/thinkrealhard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398649</guid>
            <pubDate>Mon, 07 Sep 2020 11:30:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On All That Fuckery]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24398645">thread link</a>) | @MarcScott
<br/>
September 7, 2020 | https://www.katfukui.com/on-all-that-fuckery | <a href="https://web.archive.org/web/*/https://www.katfukui.com/on-all-that-fuckery">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><undefined><span role="img" aria-label="warning">⚠️</span> </undefined><em>CW: racist, sexist, transphobic, hateful language and online abuse</em></p><p><span>
      <a href="https://www.katfukui.com/static/78121b0fe29ffe99a14ba6f375152534/b54cd/screenshot-fuckery.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="&quot;you faggots are just giving her the material for her next talk on sexism/hate threats and all that fuckery.&quot;" title="&quot;you faggots are just giving her the material for her next talk on sexism/hate threats and all that fuckery.&quot;" src="https://www.katfukui.com/static/78121b0fe29ffe99a14ba6f375152534/e5715/screenshot-fuckery.png" srcset="https://www.katfukui.com/static/78121b0fe29ffe99a14ba6f375152534/8514f/screenshot-fuckery.png 192w,https://www.katfukui.com/static/78121b0fe29ffe99a14ba6f375152534/804b2/screenshot-fuckery.png 384w,https://www.katfukui.com/static/78121b0fe29ffe99a14ba6f375152534/e5715/screenshot-fuckery.png 768w,https://www.katfukui.com/static/78121b0fe29ffe99a14ba6f375152534/4ad3a/screenshot-fuckery.png 1152w,https://www.katfukui.com/static/78121b0fe29ffe99a14ba6f375152534/71c1d/screenshot-fuckery.png 1536w,https://www.katfukui.com/static/78121b0fe29ffe99a14ba6f375152534/b54cd/screenshot-fuckery.png 1662w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>From July 14 to August 17, 2020 (at time of publish), I experienced targeted harassment on GitHub—the company I'm employed at—via coordination happening on several "technology" 4chan threads about me. I wanted to share this story publicly to reiterate the bullshit marginalized folks in tech have to go through in order to be successful, visible, and just <em>exist</em>.</p><p>So as the dude in the screenshot says, I have plenty of material to write a post on <em>all that fuckery</em>.</p><p><span role="img" aria-label="wavy dash">〰️</span></p><p>The first round of trolling occurred in issues and PRs on <a href="https://github.com/katmeister/tokyo-2019">one of my repositories</a> that documents the food I ate with my friends on our spring Tokyo 2019 trip. It was only slightly concerning at first, until I realized that 40+ people were posting, commenting, and emoji reacting.</p><p><span>
      <a href="https://www.katfukui.com/static/b4fa0c9a46ca93a988fba3001fb34071/917ef/gh-screenshots.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="screenshots from GitHub" title="screenshots from GitHub" src="https://www.katfukui.com/static/b4fa0c9a46ca93a988fba3001fb34071/e5715/gh-screenshots.png" srcset="https://www.katfukui.com/static/b4fa0c9a46ca93a988fba3001fb34071/8514f/gh-screenshots.png 192w,https://www.katfukui.com/static/b4fa0c9a46ca93a988fba3001fb34071/804b2/gh-screenshots.png 384w,https://www.katfukui.com/static/b4fa0c9a46ca93a988fba3001fb34071/e5715/gh-screenshots.png 768w,https://www.katfukui.com/static/b4fa0c9a46ca93a988fba3001fb34071/4ad3a/gh-screenshots.png 1152w,https://www.katfukui.com/static/b4fa0c9a46ca93a988fba3001fb34071/71c1d/gh-screenshots.png 1536w,https://www.katfukui.com/static/b4fa0c9a46ca93a988fba3001fb34071/917ef/gh-screenshots.png 2095w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p><undefined>Here are a few examples. The most irritating ones used tech jargon ("fixing bloat") to mask their pathetic actions. As a bystander, you might not realize until viewing the proposed changes... and seeing all content deleted. This is also the most irritating because there is no obviously hateful or violent content, and can be written off as "just a joke." <span role="img" aria-label="face with rolling eyes">🙄</span></undefined></p><p>This is a specific type of trolling I was experiencing, called "dogpiling":</p><blockquote><p>Dogpiling: When a group of trolls works together to overwhelm a target through a barrage of disingenuous questions, threats, slurs, insults, and other tactics meant to shame, silence, discredit, or drive a target offline. — <a href="https://onlineharassmentfieldmanual.pen.org/defining-online-harassment-a-glossary-of-terms/">PEN America</a></p></blockquote><p>This is not a new tactic used to silence, but it was the first time I've personally experienced it. Good thing I designed a lot of our moderation tools and have talked about the <a href="https://youtu.be/5CSQYMOWOtQ?t=580">taxonomy of online abuse</a> before, and recognized this type of harassment quickly. I was able to get help from amazing coworkers, <a href="https://twitter.com/cheshire137">Sarah Vessels</a> and <a href="https://twitter.com/deniseyu21">Denise Yu</a>, to query my repo's referral data. The traffic was coming from 4chan... two 4chan threads totaling nearly 500 disturbing comments.</p><p>Seeing this shit was absolutely surreal. The GitHub content was annoying, but this made me feel sick. I still remember the feeling of being so overwhelmed and just sobbing at my desk. Reading disgusting, racist, sexist comments about me. Seeing screenshots of my face plastered across the threads. Understanding the exact moment where the dogpiling was coordinated. Realizing this was likely to keep happening (and it did).</p><p>And what still really creeps me out is that these people felt so emboldened to troll an EMPLOYEE using their actual GitHub accounts with legitimate work and contributions. <u>These harassers are everyday software engineers.</u></p><p>I'm not famous and I don't have a very large platform, so why me?</p><p>Upon reading the threads, there were some pretty clear reasons why this happened to me. I'll dig deeply into each one. <em>HUGE shoutout to my kat-ops counterpart <a href="https://twitter.com/pifafu">Kathy Zheng</a> for helping me compile screenshots!</em></p><h2>I'm a woman.</h2><p><undefined>Well, this was the most obvious reason. Women disproportionately experience online harassment, and very much so for sexual harassment. I included a few snippets but won't spend too much time on this one because it was some boring, basic bitch shit that we've all seen before <span role="img" aria-label="">🤷🏻‍♀️</span></undefined></p><p><span>
      <a href="https://www.katfukui.com/static/8c70cf424f0092c01e2bab74df31a7a1/4f046/screenshots-incels.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="sexist comments" title="sexist comments" src="https://www.katfukui.com/static/8c70cf424f0092c01e2bab74df31a7a1/e5715/screenshots-incels.png" srcset="https://www.katfukui.com/static/8c70cf424f0092c01e2bab74df31a7a1/8514f/screenshots-incels.png 192w,https://www.katfukui.com/static/8c70cf424f0092c01e2bab74df31a7a1/804b2/screenshots-incels.png 384w,https://www.katfukui.com/static/8c70cf424f0092c01e2bab74df31a7a1/e5715/screenshots-incels.png 768w,https://www.katfukui.com/static/8c70cf424f0092c01e2bab74df31a7a1/4ad3a/screenshots-incels.png 1152w,https://www.katfukui.com/static/8c70cf424f0092c01e2bab74df31a7a1/71c1d/screenshots-incels.png 1536w,https://www.katfukui.com/static/8c70cf424f0092c01e2bab74df31a7a1/4f046/screenshots-incels.png 3311w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><h2>I'm an Asian woman.</h2><p>I mean, I shouldn't have been surprised at this one, but here we are. I have a lot of privilege as an Asian American, but was quickly reminded how easy I can be reduced to stereotypes and slurs. And that the gross fetishization of Asian women still makes me a target:</p><p><span>
      <a href="https://www.katfukui.com/static/fb87155ab684bb443d4d7e156d69f4fe/91945/screenshots-asian-slurs.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="asian slurs" title="asian slurs" src="https://www.katfukui.com/static/fb87155ab684bb443d4d7e156d69f4fe/e5715/screenshots-asian-slurs.png" srcset="https://www.katfukui.com/static/fb87155ab684bb443d4d7e156d69f4fe/8514f/screenshots-asian-slurs.png 192w,https://www.katfukui.com/static/fb87155ab684bb443d4d7e156d69f4fe/804b2/screenshots-asian-slurs.png 384w,https://www.katfukui.com/static/fb87155ab684bb443d4d7e156d69f4fe/e5715/screenshots-asian-slurs.png 768w,https://www.katfukui.com/static/fb87155ab684bb443d4d7e156d69f4fe/4ad3a/screenshots-asian-slurs.png 1152w,https://www.katfukui.com/static/fb87155ab684bb443d4d7e156d69f4fe/71c1d/screenshots-asian-slurs.png 1536w,https://www.katfukui.com/static/fb87155ab684bb443d4d7e156d69f4fe/91945/screenshots-asian-slurs.png 2944w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>There was one in particular I wanted to highlight:</p><p><span>
      <a href="https://www.katfukui.com/static/b7462864208b987ab4889dcf7a278076/07a9c/screenshots-asian-slurs2.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="So half-human?" title="So half-human?" src="https://www.katfukui.com/static/b7462864208b987ab4889dcf7a278076/e5715/screenshots-asian-slurs2.png" srcset="https://www.katfukui.com/static/b7462864208b987ab4889dcf7a278076/8514f/screenshots-asian-slurs2.png 192w,https://www.katfukui.com/static/b7462864208b987ab4889dcf7a278076/804b2/screenshots-asian-slurs2.png 384w,https://www.katfukui.com/static/b7462864208b987ab4889dcf7a278076/e5715/screenshots-asian-slurs2.png 768w,https://www.katfukui.com/static/b7462864208b987ab4889dcf7a278076/4ad3a/screenshots-asian-slurs2.png 1152w,https://www.katfukui.com/static/b7462864208b987ab4889dcf7a278076/07a9c/screenshots-asian-slurs2.png 1440w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>This one in particular stood out to me because it's a very specific type of harassment I've received my whole life, usually from East Asians. This piece of trash is stating that I'm subhuman because of my Vietnamese heritage. Tbh, this hits harder than boring 'ol "chink." The colorism here makes me think this was an Asian dude. And speaking of which:  </p><p><span>
      <a href="https://www.katfukui.com/static/3eee0f75ebc7aeae694e1262392cf0a7/71c1d/screenshots-mrasian.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="asian slurs" title="asian slurs" src="https://www.katfukui.com/static/3eee0f75ebc7aeae694e1262392cf0a7/e5715/screenshots-mrasian.png" srcset="https://www.katfukui.com/static/3eee0f75ebc7aeae694e1262392cf0a7/8514f/screenshots-mrasian.png 192w,https://www.katfukui.com/static/3eee0f75ebc7aeae694e1262392cf0a7/804b2/screenshots-mrasian.png 384w,https://www.katfukui.com/static/3eee0f75ebc7aeae694e1262392cf0a7/e5715/screenshots-mrasian.png 768w,https://www.katfukui.com/static/3eee0f75ebc7aeae694e1262392cf0a7/4ad3a/screenshots-mrasian.png 1152w,https://www.katfukui.com/static/3eee0f75ebc7aeae694e1262392cf0a7/71c1d/screenshots-mrasian.png 1536w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>I also received an email from what appears to be an MRAsian... It's sadly not uncommon to see Asian men upholding white supremacy and targeting Asian women for living our damn lives.</p><h2>I have a "radical" profile README.</h2><p>My GitHub <a href="http://github.com/katmeister">profile README</a> includes my pronouns, support for #BlackLivesMatter, my values, and social links. The amount of transphobic and anti-Black racist comments because of this was sickening. Attacking allyship is yet another tactic to silence and isolate us.</p><p><span>
      <a href="https://www.katfukui.com/static/a7ab50905868d6c10c38a7153e01cfbe/16bd1/screenshots-readme.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="attacks on my GitHub personal README" title="attacks on my GitHub personal README" src="https://www.katfukui.com/static/a7ab50905868d6c10c38a7153e01cfbe/e5715/screenshots-readme.png" srcset="https://www.katfukui.com/static/a7ab50905868d6c10c38a7153e01cfbe/8514f/screenshots-readme.png 192w,https://www.katfukui.com/static/a7ab50905868d6c10c38a7153e01cfbe/804b2/screenshots-readme.png 384w,https://www.katfukui.com/static/a7ab50905868d6c10c38a7153e01cfbe/e5715/screenshots-readme.png 768w,https://www.katfukui.com/static/a7ab50905868d6c10c38a7153e01cfbe/4ad3a/screenshots-readme.png 1152w,https://www.katfukui.com/static/a7ab50905868d6c10c38a7153e01cfbe/71c1d/screenshots-readme.png 1536w,https://www.katfukui.com/static/a7ab50905868d6c10c38a7153e01cfbe/16bd1/screenshots-readme.png 2922w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><h2>I'm not a "real developer"</h2><p>Yikes, there were a <em>lot</em><undefined> of comments about this. The dismissal of my skills and claiming I can only write Markdown is an intentional tactic to tear down my value and diminish my success. Very funny, as I've been writing code to production since 2016, despite not being a skilled developer. <span role="img" aria-label="">🤷🏻‍♀️</span></undefined></p><p><span>
      <a href="https://www.katfukui.com/static/4aaf585e0e3766626332768d1b1cd811/60708/screenshots-not-developer.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="not a real developer" title="not a real developer" src="https://www.katfukui.com/static/4aaf585e0e3766626332768d1b1cd811/e5715/screenshots-not-developer.png" srcset="https://www.katfukui.com/static/4aaf585e0e3766626332768d1b1cd811/8514f/screenshots-not-developer.png 192w,https://www.katfukui.com/static/4aaf585e0e3766626332768d1b1cd811/804b2/screenshots-not-developer.png 384w,https://www.katfukui.com/static/4aaf585e0e3766626332768d1b1cd811/e5715/screenshots-not-developer.png 768w,https://www.katfukui.com/static/4aaf585e0e3766626332768d1b1cd811/4ad3a/screenshots-not-developer.png 1152w,https://www.katfukui.com/static/4aaf585e0e3766626332768d1b1cd811/71c1d/screenshots-not-developer.png 1536w,https://www.katfukui.com/static/4aaf585e0e3766626332768d1b1cd811/60708/screenshots-not-developer.png 2872w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>Also, I think this comment deserves a blockquote:</p><blockquote><p>women unironically think that's all there is to development - forking, pushing some spelling changes, etc</p><p>they literally have no concept of how involved any of it is</p><p>isn't it hilarious that these useless parasites are consuming at least 50% of employer resources? all the while shitting on actually productive geeks for political brownie points?   </p></blockquote><p><undefined>Just... let that one sit. <span role="img" aria-label="nauseated face">🤢</span></undefined></p><h2>I'm ruining GitHub as an employee...</h2><p>There's a recurring narrative that I'm just a diversity hire who is ruining the coding sanctity of GitHub. I don't deserve to work at this company because I do nothing, while the engineers in this thread sit in their "1 room apartments." Damn, it's not my fault you aren't talented or successful. It also appears some watched my talks—thanks for the views.</p><p><span>
      <a href="https://www.katfukui.com/static/23790c8be2d72cba09953ecb50c03cfc/40493/screenshots-ruining-gh.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="I'm ruining GitHub as an employee" title="I'm ruining GitHub as an employee" src="https://www.katfukui.com/static/23790c8be2d72cba09953ecb50c03cfc/e5715/screenshots-ruining-gh.png" srcset="https://www.katfukui.com/static/23790c8be2d72cba09953ecb50c03cfc/8514f/screenshots-ruining-gh.png 192w,https://www.katfukui.com/static/23790c8be2d72cba09953ecb50c03cfc/804b2/screenshots-ruining-gh.png 384w,https://www.katfukui.com/static/23790c8be2d72cba09953ecb50c03cfc/e5715/screenshots-ruining-gh.png 768w,https://www.katfukui.com/static/23790c8be2d72cba09953ecb50c03cfc/4ad3a/screenshots-ruining-gh.png 1152w,https://www.katfukui.com/static/23790c8be2d72cba09953ecb50c03cfc/71c1d/screenshots-ruining-gh.png 1536w,https://www.katfukui.com/static/23790c8be2d72cba09953ecb50c03cfc/40493/screenshots-ruining-gh.png 2955w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>I'd like to point out that the idea of avoiding "diversity hires" as to not lower the bar of quality is still a prevalent sentiment within tech. Again, these are not just nameless 4chan trolls—they're people in our industry.</p><h2>... and should be punished.</h2><p>Yeah, these are gross. Apparently I should get fired and deserve the harassment because I'm an attention seeking whore on a programming platform! The platform I work on and create more value to developers than you ever will in your life!!</p><p><span>
      <a href="https://www.katfukui.com/static/e7904e47d6c1e3ff58827b2096c64f78/50e7d/screenshots-ugh.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="I should get no sympathy for abuse, should be fired, should kill myself" title="I should get no sympathy for abuse, should be fired, should kill myself" src="https://www.katfukui.com/static/e7904e47d6c1e3ff58827b2096c64f78/e5715/screenshots-ugh.png" srcset="https://www.katfukui.com/static/e7904e47d6c1e3ff58827b2096c64f78/8514f/screenshots-ugh.png 192w,https://www.katfukui.com/static/e7904e47d6c1e3ff58827b2096c64f78/804b2/screenshots-ugh.png 384w,https://www.katfukui.com/static/e7904e47d6c1e3ff58827b2096c64f78/e5715/screenshots-ugh.png 768w,https://www.katfukui.com/static/e7904e47d6c1e3ff58827b2096c64f78/4ad3a/screenshots-ugh.png 1152w,https://www.katfukui.com/static/e7904e47d6c1e3ff58827b2096c64f78/71c1d/screenshots-ugh.png 1536w,https://www.katfukui.com/static/e7904e47d6c1e3ff58827b2096c64f78/50e7d/screenshots-ugh.png 1738w" sizes="(max-width: 768px) 100vw, 768px" loading="lazy">
  </a>
    </span></p><p>That wasn't every screenshot from the threads, but is a good summary. The sheer volume of comments was definitely one of the more overwhelming aspects of this fuckery. Thanks for reading along this far.</p><h2>So if it wasn't clear:</h2><p><undefined>I was targeted by racist techies because of my background and visibility in order to be silenced and driven out of this industry. <span role="img" aria-label="middle finger">🖕</span></undefined></p><p>It was particularly cruel to harass me on the platform I work on everyday, where I design for open source communities. I couldn't focus at work and ended up taking two weeks off. This experience has really impacted the way I view tech and my place in it—but I'll save that for another post. </p><p>I've already accepted that this won't be my last brush with online harassment, so long as I'm still a visible Asian woman in tech. And this is going to continue happening to me and less privileged tech workers for just existing and being successful. All we can do is protect and support each other, because it's not our job to fix this problem.</p><p>It's your move next, tech. Here are my suggestions, you can have them for free:  </p><h2>To the most privileged tech leaders:</h2><p>When these events happen to your employees, are you investing actual money to support them? Are you monitoring content, encouraging time off, creating company policies, and covering their therapy? In lucky cases like mine, where the bulk of harassment may happen on the platform the victim works on, are you actively fixing pain points your employee experienced? Make sure you have a policy and detailed playbook, and definitely don't expect your marginalized employees to fix these problems for you. Don't wait until an incident arises—<strong>it's always an "edge case" until someone's personal safety is threatened.</strong></p><p>By not having intentional protections for the most vulnerable in place, you're preventing employees from being productive at work (because they're dealing with bullshit!). And you're absolutely driving away diverse talent from joining your company. It's actually fucking up your business. Access and representation in tech isn't a pipeline or qualification problem. <strong>It's a white supremacy problem.</strong></p><blockquote><p>And what still really creeps me out is that these people felt so emboldened to troll an EMPLOYEE using their actual GitHub accounts with legitimate work and contributions. <u>These harassers are everyday software engineers.</u></p></blockquote><p>Lastly, I want to circle back to this point about users with legitimate coding work harassing me. It's easy to dismiss these trolls as incel 4channers that we shun and don't associate with. Lol no. These are your people. They work at your companies and write your code. They are harassing or doxxing your other employees. This toxic behavior is still very much a part of your tech culture, and you keep rewarding it.</p><p>Fix. This. Shit.</p></article></div>]]>
            </description>
            <link>https://www.katfukui.com/on-all-that-fuckery</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398645</guid>
            <pubDate>Mon, 07 Sep 2020 11:29:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Steps to Develop Global State for React with Hooks Without Context]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24398532">thread link</a>) | @mehdios
<br/>
September 7, 2020 | https://blog.asayer.io/steps-to-develop-global-state-for-react-with-hooks-without-context | <a href="https://web.archive.org/web/*/https://blog.asayer.io/steps-to-develop-global-state-for-react-with-hooks-without-context">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><h2 id="introduction">Introduction</h2><p>Developing with React hooks is fun for me. I have been developing several libraries. The very first library was a library for global state. It’s naively called “react-hooks-global-state” which turns out to be too long to read.</p><p>The initial version of the library was published in Oct 2018. Time has passed since then, I learned a lot, and now v1.0.0 of the library is published (<a href="https://github.com/dai-shi/react-hooks-global-state" target="_blank" rel="noreferrer">react-hooks-global-state</a>).</p><p>This post shows simplified versions of the code step by step. It would help understand what this library is aiming at, while the real code is a bit complex in TypeScript.</p><h2 id="step-1-global-variable">Step 1: Global variable</h2><div><pre><p><span>1</span><span>let</span><span> globalState </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  count</span><span>:</span><span> </span><span>0</span><span>,</span><span></span></p><p><span>3</span><span>  text</span><span>:</span><span> </span><span>'hello'</span><span>,</span><span></span></p><p><span>4</span><span></span><span>}</span><span>;</span></p></pre></div><p>Let’s have a global variable like the above. We assume this structure throughout this post. One would create a React hook to read this global variable.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>useGlobalState</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>return</span><span> globalState</span><span>;</span><span></span></p><p><span>3</span><span></span><span>}</span><span>;</span></p></pre></div><p>This is not actually a React hook because it doesn’t depend on any React primitive hooks.</p><p>Now, this is not what we usually want, because it doesn’t re-render when the global variable changes.</p><h2 id="step-2-re-render-on-updates">Step 2: Re-render on updates</h2><p>We need to use React <code>useState</code> hook to make it reactive.</p><div><pre><p><span>1</span><span>const</span><span> listeners </span><span>=</span><span> </span><span>new</span><span> </span><span>Set</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>const</span><span> </span><span>useGlobalState</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>  </span><span>const</span><span> </span><span>[</span><span>state</span><span>,</span><span> setState</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>globalState</span><span>)</span><span>;</span><span></span></p><p><span>5</span><span>  </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>6</span><span>    </span><span>const</span><span> </span><span>listener</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>7</span><span>      </span><span>setState</span><span>(</span><span>globalState</span><span>)</span><span>;</span><span></span></p><p><span>8</span><span>    </span><span>}</span><span>;</span><span></span></p><p><span>9</span><span>    listeners</span><span>.</span><span>add</span><span>(</span><span>listener</span><span>)</span><span>;</span><span></span></p><p><span>10</span><span>    </span><span>listener</span><span>(</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>11</span><span>    </span><span>return</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> listeners</span><span>.</span><span>delete</span><span>(</span><span>listener</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>12</span><span>  </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>13</span><span>  </span><span>return</span><span> state</span><span>;</span><span></span></p><p><span>14</span><span></span><span>}</span><span>;</span></p></pre></div><p>This allows to update React state from outside. If you update the global variable, you need to notify listeners. Let’s create a function for updating.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>setGlobalState</span><span> </span><span>=</span><span> </span><span>(</span><span>nextGlobalState</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  globalState </span><span>=</span><span> nextGlobalState</span><span>;</span><span></span></p><p><span>3</span><span>  listeners</span><span>.</span><span>forEach</span><span>(</span><span>listener</span><span> </span><span>=&gt;</span><span> </span><span>listener</span><span>(</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span></span><span>}</span><span>;</span></p></pre></div><p>With this, we can change <code>useGlobalState</code> to return a tuple like <code>useState</code>.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>useGlobalState</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>const</span><span> </span><span>[</span><span>state</span><span>,</span><span> setState</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>globalState</span><span>)</span><span>;</span><span></span></p><p><span>3</span><span>  </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>    </span><span></span></p><p><span>5</span><span>  </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>6</span><span>  </span><span>return</span><span> </span><span>[</span><span>state</span><span>,</span><span> setGlobalState</span><span>]</span><span>;</span><span></span></p><p><span>7</span><span></span><span>}</span><span>;</span></p></pre></div><h2 id="step-3-container">Step 3: Container</h2><p>Usually, the global variable is in a file scope. Let’s put it in a function scope to narrow down the scope a bit and make it more reusable.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>createContainer</span><span> </span><span>=</span><span> </span><span>(</span><span>initialState</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>let</span><span> globalState </span><span>=</span><span> initialState</span><span>;</span><span></span></p><p><span>3</span><span>  </span><span>const</span><span> listeners </span><span>=</span><span> </span><span>new</span><span> </span><span>Set</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span></span></p><p><span>5</span><span>  </span><span>const</span><span> </span><span>setGlobalState</span><span> </span><span>=</span><span> </span><span>(</span><span>nextGlobalState</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>6</span><span>    globalState </span><span>=</span><span> nextGlobalState</span><span>;</span><span></span></p><p><span>7</span><span>    listeners</span><span>.</span><span>forEach</span><span>(</span><span>listener</span><span> </span><span>=&gt;</span><span> </span><span>listener</span><span>(</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>8</span><span>  </span><span>}</span><span>;</span><span></span></p><p><span>9</span><span></span></p><p><span>10</span><span>  </span><span>const</span><span> </span><span>useGlobalState</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>11</span><span>    </span><span>const</span><span> </span><span>[</span><span>state</span><span>,</span><span> setState</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>globalState</span><span>)</span><span>;</span><span></span></p><p><span>12</span><span>    </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>13</span><span>      </span><span>const</span><span> </span><span>listener</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>14</span><span>        </span><span>setState</span><span>(</span><span>globalState</span><span>)</span><span>;</span><span></span></p><p><span>15</span><span>      </span><span>}</span><span>;</span><span></span></p><p><span>16</span><span>      listeners</span><span>.</span><span>add</span><span>(</span><span>listener</span><span>)</span><span>;</span><span></span></p><p><span>17</span><span>      </span><span>listener</span><span>(</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>18</span><span>      </span><span>return</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> listeners</span><span>.</span><span>delete</span><span>(</span><span>listener</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>19</span><span>    </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>20</span><span>    </span><span>return</span><span> </span><span>[</span><span>state</span><span>,</span><span> setGlobalState</span><span>]</span><span>;</span><span></span></p><p><span>21</span><span>  </span><span>}</span><span>;</span><span></span></p><p><span>22</span><span></span></p><p><span>23</span><span>  </span><span>return</span><span> </span><span>{</span><span></span></p><p><span>24</span><span>    setGlobalState</span><span>,</span><span></span></p><p><span>25</span><span>    useGlobalState</span><span>,</span><span></span></p><p><span>26</span><span>  </span><span>}</span><span>;</span><span></span></p><p><span>27</span><span></span><span>}</span><span>;</span></p></pre></div><p>We don’t go in detail about TypeScript in this post, but this form allows to annotate types of <code>useGlobalState</code> by inferring types of <code>initialState</code>.</p><h2 id="step-4-scoped-access">Step 4: Scoped access</h2><p>Although we can create multiple containers, usually we put several items in a global state.</p><p>Typical global state libraries have some functionality to scope only a part of the state. For example, React Redux uses selector interface to get a derived value from a global state.</p><p>We take a simpler approach here, which is to use a string key of a global state. In our example, it’s like <code>count</code> and <code>text</code>.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>createContainer</span><span> </span><span>=</span><span> </span><span>(</span><span>initialState</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>let</span><span> globalState </span><span>=</span><span> initialState</span><span>;</span><span></span></p><p><span>3</span><span>  </span><span>const</span><span> listeners </span><span>=</span><span> </span><span>Object</span><span>.</span><span>fromEntries</span><span>(</span><span>Object</span><span>.</span><span>keys</span><span>(</span><span>initialState</span><span>)</span><span>.</span><span>map</span><span>(</span><span>key</span><span> </span><span>=&gt;</span><span> </span><span>[</span><span>key</span><span>,</span><span> </span><span>new</span><span> </span><span>Set</span><span>(</span><span>)</span><span>]</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span></span></p><p><span>5</span><span>  </span><span>const</span><span> </span><span>setGlobalState</span><span> </span><span>=</span><span> </span><span>(</span><span>key</span><span>,</span><span> nextValue</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>6</span><span>    globalState </span><span>=</span><span> </span><span>{</span><span> </span><span>...</span><span>globalState</span><span>,</span><span> </span><span>[</span><span>key</span><span>]</span><span>:</span><span> nextValue </span><span>}</span><span>;</span><span></span></p><p><span>7</span><span>    listeners</span><span>[</span><span>key</span><span>]</span><span>.</span><span>forEach</span><span>(</span><span>listener</span><span> </span><span>=&gt;</span><span> </span><span>listener</span><span>(</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>8</span><span>  </span><span>}</span><span>;</span><span></span></p><p><span>9</span><span></span></p><p><span>10</span><span>  </span><span>const</span><span> </span><span>useGlobalState</span><span> </span><span>=</span><span> </span><span>(</span><span>key</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>11</span><span>    </span><span>const</span><span> </span><span>[</span><span>state</span><span>,</span><span> setState</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>globalState</span><span>[</span><span>key</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>12</span><span>    </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>13</span><span>      </span><span>const</span><span> </span><span>listener</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>14</span><span>        </span><span>setState</span><span>(</span><span>globalState</span><span>[</span><span>key</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>15</span><span>      </span><span>}</span><span>;</span><span></span></p><p><span>16</span><span>      listeners</span><span>[</span><span>key</span><span>]</span><span>.</span><span>add</span><span>(</span><span>listener</span><span>)</span><span>;</span><span></span></p><p><span>17</span><span>      </span><span>listener</span><span>(</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>18</span><span>      </span><span>return</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> listeners</span><span>[</span><span>key</span><span>]</span><span>.</span><span>delete</span><span>(</span><span>listener</span><span>)</span><span>;</span><span> </span><span></span></p><p><span>19</span><span>    </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>20</span><span>    </span><span>return</span><span> </span><span>[</span><span>state</span><span>,</span><span> </span><span>(</span><span>nextValue</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>setGlobalState</span><span>(</span><span>key</span><span>,</span><span> nextValue</span><span>)</span><span>]</span><span>;</span><span></span></p><p><span>21</span><span>  </span><span>}</span><span>;</span><span></span></p><p><span>22</span><span></span></p><p><span>23</span><span>  </span><span>return</span><span> </span><span>{</span><span></span></p><p><span>24</span><span>    setGlobalState</span><span>,</span><span></span></p><p><span>25</span><span>    useGlobalState</span><span>,</span><span></span></p><p><span>26</span><span>  </span><span>}</span><span>;</span><span></span></p><p><span>27</span><span></span><span>}</span><span>;</span></p></pre></div><p>We omit the use of useCallback in this code for simplicity, but it’s generally recommended for a library.</p><h2 id="step-5-functional-updates">Step 5: Functional Updates</h2><p>React <code>useState</code> allows <a href="https://reactjs.org/docs/hooks-reference.html#functional-updates" target="_blank" rel="noreferrer">functional updates</a>. Let’s implement this feature.</p><div><pre><p><span>1</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span>  </span><span>const</span><span> </span><span>setGlobalState</span><span> </span><span>=</span><span> </span><span>(</span><span>key</span><span>,</span><span> nextValue</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>    </span><span>if</span><span> </span><span>(</span><span>typeof</span><span> nextValue </span><span>===</span><span> </span><span>'function'</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>5</span><span>      globalState </span><span>=</span><span> </span><span>{</span><span> </span><span>...</span><span>globalState</span><span>,</span><span> </span><span>[</span><span>key</span><span>]</span><span>:</span><span> </span><span>nextValue</span><span>(</span><span>globalState</span><span>[</span><span>key</span><span>]</span><span>)</span><span> </span><span>}</span><span>;</span><span></span></p><p><span>6</span><span>    </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span></span></p><p><span>7</span><span>      globalState </span><span>=</span><span> </span><span>{</span><span> </span><span>...</span><span>globalState</span><span>,</span><span> </span><span>[</span><span>key</span><span>]</span><span>:</span><span> nextValue </span><span>}</span><span>;</span><span></span></p><p><span>8</span><span>    </span><span>}</span><span></span></p><p><span>9</span><span>    listeners</span><span>[</span><span>key</span><span>]</span><span>.</span><span>forEach</span><span>(</span><span>listener</span><span> </span><span>=&gt;</span><span> </span><span>listener</span><span>(</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>10</span><span>  </span><span>}</span><span>;</span><span></span></p><p><span>11</span><span></span></p><p><span>12</span><span>  </span></p></pre></div><h2 id="step-6-reducer">Step 6: Reducer</h2><p>Those who are familiar with Redux may prefer reducer interface. React hook useReducer also has basically the same interface.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>createContainer</span><span> </span><span>=</span><span> </span><span>(</span><span>reducer</span><span>,</span><span> initialState</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>let</span><span> globalState </span><span>=</span><span> initialState</span><span>;</span><span></span></p><p><span>3</span><span>  </span><span>const</span><span> listeners </span><span>=</span><span> </span><span>Object</span><span>.</span><span>fromEntries</span><span>(</span><span>Object</span><span>.</span><span>keys</span><span>(</span><span>initialState</span><span>)</span><span>.</span><span>map</span><span>(</span><span>key</span><span> </span><span>=&gt;</span><span> </span><span>[</span><span>key</span><span>,</span><span> </span><span>new</span><span> </span><span>Set</span><span>(</span><span>)</span><span>]</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span></span></p><p><span>5</span><span>  </span><span>const</span><span> </span><span>dispatch</span><span> </span><span>=</span><span> </span><span>(</span><span>action</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>6</span><span>    </span><span>const</span><span> prevState </span><span>=</span><span> globalState</span><span>;</span><span></span></p><p><span>7</span><span>    globalState </span><span>=</span><span> </span><span>reducer</span><span>(</span><span>globalState</span><span>,</span><span> action</span><span>)</span><span>;</span><span></span></p><p><span>8</span><span>    </span><span>Object</span><span>.</span><span>keys</span><span>(</span><span>(</span><span>key</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>9</span><span>      </span><span>if</span><span> </span><span>(</span><span>prevState</span><span>[</span><span>key</span><span>]</span><span> </span><span>!==</span><span> globalState</span><span>[</span><span>key</span><span>]</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>10</span><span>        listeners</span><span>[</span><span>key</span><span>]</span><span>.</span><span>forEach</span><span>(</span><span>listener</span><span> </span><span>=&gt;</span><span> </span><span>listener</span><span>(</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>11</span><span>      </span><span>}</span><span></span></p><p><span>12</span><span>    </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>13</span><span>  </span><span>}</span><span>;</span><span></span></p><p><span>14</span><span></span></p><p><span>15</span><span>  </span><span></span></p><p><span>16</span><span></span></p><p><span>17</span><span>  </span><span>return</span><span> </span><span>{</span><span></span></p><p><span>18</span><span>    useGlobalState</span><span>,</span><span></span></p><p><span>19</span><span>    dispatch</span><span>,</span><span></span></p><p><span>20</span><span>  </span><span>}</span><span>;</span><span></span></p><p><span>21</span><span></span><span>}</span><span>;</span></p></pre></div><h2 id="step-6-concurrent-mode">Step 6: Concurrent Mode</h2><p>In order to get benefits from Concurrent Mode, we need to use React state instead of an external variable. The current solution to it is to link a React state to our global state.</p><p>The implementation is very tricky, but in essence we create a hook to create a state and link it.</p><div><pre><p><span>1</span><span>const</span><span> </span><span>useGlobalStateProvider</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>    </span><span>const</span><span> </span><span>[</span><span>state</span><span>,</span><span> dispatch</span><span>]</span><span> </span><span>=</span><span> </span><span>useReducer</span><span>(</span><span>patchedReducer</span><span>,</span><span> globalState</span><span>)</span><span>;</span><span></span></p><p><span>3</span><span>    </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>      linkedDispatch </span><span>=</span><span> dispatch</span><span>;</span><span></span></p><p><span>5</span><span>      </span><span></span></p><p><span>6</span><span>    </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>7</span><span>    </span><span>const</span><span> prevState </span><span>=</span><span> </span><span>useRef</span><span>(</span><span>state</span><span>)</span><span>;</span><span></span></p><p><span>8</span><span>    </span><span>Object</span><span>.</span><span>keys</span><span>(</span><span>(</span><span>key</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>9</span><span>      </span><span>if</span><span> </span><span>(</span><span>prevState</span><span>.</span><span>current</span><span>[</span><span>key</span><span>]</span><span> </span><span>!==</span><span> state</span><span>[</span><span>key</span><span>]</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>10</span><span>        </span><span></span></p><p><span>11</span><span>        listeners</span><span>[</span><span>key</span><span>]</span><span>.</span><span>forEach</span><span>(</span><span>listener</span><span> </span><span>=&gt;</span><span> </span><span>listener</span><span>(</span><span>state</span><span>[</span><span>key</span><span>]</span><span>)</span><span>)</span><span>;</span><span></span></p><p><span>12</span><span>      </span><span>}</span><span></span></p><p><span>13</span><span>    </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>14</span><span>    prevState</span><span>.</span><span>current</span><span> </span><span>=</span><span> state</span><span>;</span><span></span></p><p><span>15</span><span>    </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>16</span><span>      globalState </span><span>=</span><span> state</span><span>;</span><span></span></p><p><span>17</span><span>    </span><span>}</span><span>,</span><span> </span><span>[</span><span>state</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>18</span><span>  </span><span>}</span><span>;</span></p></pre></div><p>The <code>patchedReducer</code> is required to allow <code>setGlobalState</code> to update global state. The <code>useGlobalStateProvider</code> hook should be used in a stable component such as an app root component.</p><p>Note that this is not a well-known technique, and there might be some limitations. For instance, invoking listeners in render is not actually recommended.</p><p>To support Concurrent Mode in a proper way, we would need core support. Currently, <code>useMutableSource</code> hook is proposed in <a href="https://github.com/reactjs/rfcs/pull/147" target="_blank" rel="noreferrer">this RFC</a>.</p><h2 id="closing-notes">Closing notes</h2><p>This is mostly how <a href="https://github.com/dai-shi/react-hooks-global-state" target="_blank" rel="noreferrer">react-hooks-global-state</a> is implemented. The real code in the library is a bit more complex in TypeScript, contains <code>getGlobalState</code> for reading global state from outside, and has limited support for Redux middleware and DevTools.</p><p>Finally, I have developed some other libraries around global state and React context, as listed below.</p><ul><li><a href="https://github.com/dai-shi/reactive-react-redux" target="_blank" rel="noreferrer">https://github.com/dai-shi/reactive-react-redux</a></li><li><a href="https://github.com/dai-shi/react-tracked" target="_blank" rel="noreferrer">https://github.com/dai-shi/react-tracked</a></li><li><a href="https://github.com/dai-shi/use-context-selector" target="_blank" rel="noreferrer">https://github.com/dai-shi/use-context-selector</a></li></ul><h2 id="frontend-monitoring">Frontend Monitoring</h2><p><a href="https://asayer.io/" target="_blank" rel="noreferrer">Asayer</a> is a frontend monitoring tool that replays everything your users do and shows how your web app behaves for every issue. It lets you reproduce issues, aggregate JS errors and monitor your web app’s performance. </p><p>Happy debugging, for modern frontend teams - <a href="https://asayer.io/register.html" target="_blank" rel="noreferrer">Start monitoring your web app for free</a>.</p></div></article></div>]]>
            </description>
            <link>https://blog.asayer.io/steps-to-develop-global-state-for-react-with-hooks-without-context</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398532</guid>
            <pubDate>Mon, 07 Sep 2020 11:06:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Computer vision model to identify the Australian Aboriginal Flag [follow up]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24398504">thread link</a>) | @thomasfromcdnjs
<br/>
September 7, 2020 | https://ajaxdavis.com/post/An-Open-Source-Computer-vision-model-to-identify-the-Australian-Aboriginal-Flag-Tutorial/ | <a href="https://web.archive.org/web/*/https://ajaxdavis.com/post/An-Open-Source-Computer-vision-model-to-identify-the-Australian-Aboriginal-Flag-Tutorial/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
<blockquote>
<p>This project was based on a <a href="https://news.ycombinator.com/item?id=24187794">Hacker News discussion</a>, thank you for all your input!</p>
</blockquote>
<p>I've been recently paying attention to the <a href="https://clothingthegap.com.au/pages/free-the-flag">#freetheflag</a> debate, in short;</p>
<blockquote>
<p>The Aboriginal flag <a href="https://www.legislation.gov.au/Details/F2008L00209">of Australia</a> is widely used by indigenous Australians as a symbol of their heritage. Though, the flag is actually copyrighted by an <a href="https://aiatsis.gov.au/explore/articles/aboriginal-flag#:~:text=Flag%20copyright,the%20author%20of%20the%20flag.&amp;text=The%20copyright%20license%20for%20the,to%20Carroll%20and%20Richardson%20Flags.">indigenous individual</a> who has exclusive control of the licensing rightfully. This has become a debate because a lot of Aboriginals believe they should have a right to print or copy the Aboriginal flag as they would like.</p>
</blockquote>
<p>(Just a quick shout out to my mob, the <a href="https://en.wikipedia.org/wiki/Kuku_Yalanji">Kuku Yalanji</a> people of Far North Queensland)</p>
<p>Over the years I've been trying to learn machine learning but never got anywhere because I couldn't think of a use case. I recently read a cool post from <a href="https://clothingthegap.com.au/pages/aboriginal-flag-timeline">Clothing The Gap</a> which gives an overview of the current copyright debate. They had an image that contains the "Aboriginal flag" done by a European artist several years earlier and how this could maybe be used to invalidate copyright as the design was perhaps already in existence. This gave me the idea to think about if there were perhaps other artworks throughout history that may have contained the flag design.</p>
<p>My main idea was that if I could use machine learning to train a computer vision model to find Aboriginal flags. I could then run it over historical archives of images/paintings to see if I can find any other places the Aboriginal flag seemingly appeared throughout history. Such that in a court case one might overturn the copyright by simply saying they were printing an "Indonesian symbol from the 14th century" (just a potential example)</p>
<p><img src="https://i.imgur.com/nJwFE7K.jpg" alt="asdas"></p>
<p>If you look at the top left of the image, you will see an Aboriginal flag in this painting. I considered my model training a success once it could find the flag in this sample</p>
<p>It does actually work and as you can see in the above image, the model is able to draw a bounding box around the "flag".</p>
<p>I've only scanned 100,000 historical images so far and yet to find any pre-existing artworks that contain the flag. I still have a couple of million images to get through and hope to add a couple million more.</p>
<p>But here is a gallery of false positives, images that the model thought were aboriginal flags but not quite... (if you look at the images for long enough you can see why maybe the model thought it was an aboriginal flag)</p>
<p><a href="https://imgur.com/a/Q22VnGK">Results</a></p>
<p>I've also saved some of the resulting data in a <a href="https://airtable.com/shrHq7PG7CF7axGB4">table</a> for anyone who wants to take a closer look.</p>
<p>I will keep working on the project to improve the results, and all of the code is open-source and free to use.</p>
<p>The rest of this post is for people who would like to run the code themselves and learn how to train an object recognition model from scratch. It is less than 20 lines of code in total and I've made everything as simple as possible with all resources available in the repo.</p>
<p>If anyone would like to help me train a better model then please <a href="https://ajaxdavis.com/cdn-cgi/l/email-protection#5c283433313d2f3d302b2532383d2a352f1c3b313d3530723f3331">reach out</a>!</p>
<h2>Technical</h2>
<p>I had no prior experience in computer vision, so I had no idea how I might train a model to do this. I managed to do it in a week, it is super easy for anyone with a bit of programming knowledge. The CV community is big and beautiful and I managed to get my idea working with PyTorch in a night. (I spent a few nights on Tensorflow and didn't get very far)</p>
<p>This tutorial is self-contained and can be found in the <a href="https://github.com/australia/aboriginal-flag-cv-model">repo</a>.</p>
<p>Again, the tutorial contains very little code thanks to a few open-source projects it depends on.</p>
<p>I also had a problem with the complexity of the language in the CV community so I'm going to purposely oversimplify things here.</p>
<p>This is super easy and you could likely have it working in under an hour. (Then add ML to your <a href="https://jsonresume.org/">resume</a>)</p>
<p>We are going to split the tutorial into three steps;</p>
<ol>
<li><strong>Classification</strong> - We need to manually draw boxes around the objects we are looking for in some sample images. The machine learning will use this human-curated data to train itself.</li>
<li><strong>Training</strong> - Once we have a classified data-set of images, we can use <a href="https://pytorch.org/">PyTorch</a> to train a reusable model.</li>
<li><strong>Identification</strong> - Now that we have a model, we want to see if it can correctly find the desired object in a given sample image</li>
</ol>
<p>Let's do it!</p>
<h2>Getting Started</h2>
<pre><code>

git <span>clone</span> https://github.com/australia/aboriginal-flag-cv-model
<span>cd</span> aboriginal-flag-cv-model
pip3 install -r requirements.txt
</code></pre>
<h3>Classification</h3>
<p>For the purposes of this tutorial, we are just going to train a model to find Aboriginal flags. But after you've finished this, you should be able to train a model to detect any object you would like. (Simple things, not hard things like if a person is <em>sad</em>).</p>
<p>So the initial classification is a human step, but it's kinda fun to do and will help you understand what the model can detect.</p>
<p>We start with an <code>images</code> folder which is in the <a href="https://github.com/australia/aboriginal-flag-cv-model">repo</a>.</p>
<pre><code>/images
  1.jpg
  2.jpg
</code></pre>
<p>Essentially we have to use our monkey minds to draw bounding boxes around images that contain the desired object we are looking for.</p>
<p>And generate an associated XML file for each file that describes those bounding boxes.</p>
<p>After we are finished our directory should look like</p>
<pre><code>/images
  1.jpg
  1.xml
  2.jpg
  2.xml
</code></pre>
<p>The easiest program to do this in (and a kind of nostalgic UI) is called <code>labelImg</code></p>
<p><a href="https://github.com/tzutalin/labelImg">https://github.com/tzutalin/labelImg</a></p>
<p>You will have to figure out how to install and run it yourself.</p>
<p>Once open, point it at the <code>images</code> folder from the <a href="https://github.com/australia/aboriginal-flag-cv-model">repo</a>, once you figure out how to use the program, you will start drawing boxes and saving the XML to the <code>images</code> directory. And by the end of it, it should look like the directory structure above.</p>
<p><img src="https://i.imgur.com/yWL5vcb.jpg" alt="labelImg screenshot"></p>
<p>The XML contains a label that you will be able to define when drawing bounding boxes. The model will require you later to use the same label in the training, for this example you should just use the label <code>aboriginal_flag</code>.</p>
<p><img src="https://i.imgur.com/xc7RMDR.jpg" alt="labelImg screenshot"></p>
<p>The way you draw your boxes does change the outcome of the model, for the Aboriginal flag I tended to;</p>
<ul>
<li>Leave a bit of outer space around the shape of the flag</li>
<li>Choose images at all angles and depths</li>
<li>Didn't worry if a limb or object was in front of the flag</li>
<li>Chose real flags, paintings of flags, full-scale images of the flag</li>
<li>A mixture of single or multiple instances of the object</li>
</ul>
<p>Once you have your images and associated XML files generated, you are ready to start training.</p>
<blockquote>
<p>If you get too lazy to classify the 40 images in the <a href="https://github.com/australia/aboriginal-flag-cv-model">repo</a>, just copy the files in <code>images_classified</code> into <code>images</code>. I do recommend classifying them manually your self to see how small nuances might influence the learning model. Choosing images of different shapes, colors, angles, sizes, depth and so on will make your model more robust.</p>
</blockquote>
<h3>Training</h3>
<p>So next we want to generate a model, and PyTorch/Detecto makes this easy by letting us generate one file to store all of our learned data  in e.g. <code>model.pth</code></p>
<p>We point PyTorch/Detecto at our classified data set and it should spit out a <code>model.pth</code> which we will use later to find our object (flag) in samples.</p>
<p>What really makes this whole tutorial so easy is the fact we will be using a python library called <a href="https://github.com/alankbi/detecto">Detecto</a> written by <a href="https://github.com/alankbi/">Alan Bi</a> (thanks man, beautiful job)</p>
<p>The entire code to go from the <code>dataset</code>(folder of images and XML) to a<code>reusable object recognition model</code> is below.</p>
<p>WARNING: You might need a decent computer to even run 3 epochs let alone 6 so if you just want to get a copy of a decently trained model, just download my <a href="https://drive.google.com/file/d/1WrL1lV85njUwLR_pYaDD7fh1TV0lFKEN/view?usp=sharing">pre-trained model.pth</a></p>
<pre><code>



<span>from</span> detecto <span>import</span> core
<span>from</span> detecto.core <span>import</span> Model



dataset = core.Dataset(<span>'images_classified/'</span>)


model = Model([<span>'aboriginal_flag'</span>])








model.fit(dataset, epochs=<span>3</span>, verbose=<span>True</span>)





model.save(<span>'model.pth'</span>)





</code></pre>
<p>To run it from within the <a href="https://github.com/australia/aboriginal-flag-cv-model">repo</a>;</p>
<pre><code>python3 train.py // Should output a file called model.pth
</code></pre>
<blockquote>
<p>The PTH file type is primarily associated with PyTorch. PTH is a data file for Machine Learning with PyTorch. PyTorch is an open source machine learning library based on the Torch library. It is primarily developed by Facebooks artificial intelligence research group.</p>
</blockquote>
<p>(If the above code didn't run for you, please make an <a href="https://github.com/australia/aboriginal-flag-cv-model/issues">issue</a>.</p>
<p>Now onto the fun part, let's see if our generated model can find what we are looking for!</p>
<h3>Identification</h3>
<p>So now we should have a <code>model.pth</code> and a <code>samples/sample.jpg</code> in the <a href="https://github.com/australia/aboriginal-flag-cv-model">repo</a>, let's run it to see if our model is smart enough to find the object.</p>
<p>Finding the objects coordinates in the picture is easy, but we also want to draw a box around the coordinates which requires just a bit more code.</p>
<p>To run it from the repo</p>
<pre><code>python3 findFlag.py
</code></pre>
<p>The code for that file is below, I've commented in how it works.</p>
<pre><code>

<span>from</span> detecto.core <span>import</span> Model
<span>import</span> cv2 



model = Model.load(<span>'model.pth'</span>, [<span>'aboriginal_flag'</span>])



image = cv2.imread(<span>"samples/sample.jpg"</span>)






labels, boxes, scores = model.predict(image)







print(labels, boxes, scores)




<span>for</span> idx, s <span>in</span> enumerate(scores):
    <span>if</span> s &gt; <span>0.3</span>: 
        rect = boxes[idx]
        start_point = (rect[<span>0</span>].int(), rect[<span>1</span>].int())
        end_point = (rect[<span>2</span>].int(), rect[<span>3</span>].int())
        cv2.rectangle(image, start_point, end_point, (<span>0</span>, <span>0</span>, <span>255</span>), <span>2</span>)

cv2.imshow(<span>"Image"</span> + str(idx), image)

cv2.waitKey(<span>0</span>)

</code></pre>
<p>If you are having a good day, an image should have appeared on your screen. And if you are having a lucky day, then the Python script should have also drawn a rectangle over the image.</p>
<p>That is all there is really, you obviously can just take the outputted prediction data (boxes and scores) and save it to where ever you would like e.g. a database.</p>
<p>If something didn't work feel free to complain in the tutorial repo <a href="https://github.com/australia/aboriginal-flag-cv-model/issues">issues</a>.</p>
<h3>Conclusion</h3>
<p>I do hope it worked, those steps above worked for me. I drew an Aboriginal flag on paper and took selfies at many angles and the model picked it up. (I manually classified 150 images instead of 40 though) (and if I call recall correctly, around 10 epochs)</p>
<p><img src="https://i.imgur.com/Xcg422N.png" alt="ajax davis"></p>
<p>This tutorial is meant to be a complete noob guide (written by a noob), how I've described things, and the way they are in computer vision - are two different things.</p>
<p>This task has allowed me to introduce myself to the computer vision sector and I'm sure I will learn more over …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ajaxdavis.com/post/An-Open-Source-Computer-vision-model-to-identify-the-Australian-Aboriginal-Flag-Tutorial/">https://ajaxdavis.com/post/An-Open-Source-Computer-vision-model-to-identify-the-Australian-Aboriginal-Flag-Tutorial/</a></em></p>]]>
            </description>
            <link>https://ajaxdavis.com/post/An-Open-Source-Computer-vision-model-to-identify-the-Australian-Aboriginal-Flag-Tutorial/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398504</guid>
            <pubDate>Mon, 07 Sep 2020 10:59:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi 3B+ Hackable Linux Handheld]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 90 (<a href="https://news.ycombinator.com/item?id=24398485">thread link</a>) | @mmerlin
<br/>
September 7, 2020 | http://yarh.io/yarh-io-mki.html | <a href="https://web.archive.org/web/*/http://yarh.io/yarh-io-mki.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <section id="top-section">
        <div id="top-section-top">
            <nav>
                
            </nav>
            <p id="heading">
                
                <h2>Raspberry Pi 3B+ Hackable Linux Handheld<br></h2>
            </p>
        </div>
    </section>
    <section id="yarh-io-mki">
        <div>
            <div>
                <div>
                    <p><a href="http://yarh.io/assets/img/yarh-white-hand-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="http://yarh.io/assets/img/yarh-white-hand-large-t-001.png"></a></p>
                    <div>
                        <p>YARH.IO is a fully hackable and custamizable Raspberry Pi based handheld, running Raspberry Pi OS and supporting all other Operating Systems available for Raspberry Pi.</p>
                        <p>The dream of a hackable&nbsp;Linux powered handheld has been around for many years, and many attempts have been made to create a working device. While some of the devices have reached the market, none of them withstood the test
                            of real world user experience.<br></p>
                        <p>YARH.IO project has taken on the challenge of building a fully functioning device by combining the best of Raspberry Pi design and 3D printing technology.&nbsp;<br></p>
                        <p>This project takes hackability to the next level by ensuring that every single component needed to build YARH.IO can be easily sourced, with no custom PCBs and just a bit of wire soldering required.&nbsp;</p>
                    </div>
                </div>
                <div>
                    <div>
                        <p>YARH.IO handheld and its unique modular design with exposed interfaces offers unprecedented connectivity with unlimited platforms and devices.<br></p>
                        <p>This model is powered by&nbsp;Raspberry Pi 3B+ and&nbsp;has the best ratio of functionality and computing power requirements for a mobile device. When it comes to the battery powered devices, the overall power consumption and longer
                            battery are more important then the extra processing power or memory.</p>
                        <p>For this model, the width of the main module is based on the keyboard dimensions for improved handling. The 5" Resistive Touch Screen 800x480 HDMI TFT LCD Display&nbsp;is a good option for YARH.IO as it&nbsp;will allow you to perform
                            all of the usual tasks with ease.&nbsp;<br></p>
                    </div>
                    <p><a href="http://yarh.io/assets/img/yarh-red-right-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="http://yarh.io/assets/img/yarh-red-right-large-t-001.png"></a></p>
                </div>
                <div>
                    <p><a href="http://yarh.io/assets/img/yarh-white-left-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="http://yarh.io/assets/img/yarh-white-left-large-t-001.png"></a></p>
                    <div>
                        <p>Fosmon Portable Lightweight Mini Wireless Bluetooth Keyboard Controller has been selected as the best option for YARH.IO's multifunctional design. If you are using Vim, tmux, and Emacs everyday, the available modifier keys will
                            help you get the most out of the device.</p>
                        <p>In addition to the keyboard, YARH.IO's pointing device will allow you to effortlessly browse the internet and engage with other applications with graphical interface.&nbsp;&nbsp;<br></p>
                        <p>A single removable rechargeable battery will allow you to quickly replace an empty battery with a fully charged one. A high capacity Fenix ARB-L21-5000 5000mAh Li-ion Rechargeable Battery was chosen as the best option as it fits
                            the main module perfectly. For the charger/5v power supply the internals of a Fenix ARE-D1 Smart Charger were used.</p>
                    </div>
                </div>
                <div>
                    <div>
                        <p>The RTC is a must have for a handheld device that is not continuously connected to the internet. YARH.IO includes a DS3231 High Precision RTC Clock Module.</p>
                        <p>Raspberry Pi GPIO connectors have been made available on the bottom sides of the main module and extension module for connecting all of your Raspberry Pi add-on boards.</p>
                        
                    </div>
                    <p><a href="http://yarh.io/assets/img/yarh-black-top-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="http://yarh.io/assets/img/yarh-black-top-large-t-001.png"></a></p>
                </div>
                <div>
                    <p><a href="http://yarh.io/assets/img/yarh-black-back-open-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="http://yarh.io/assets/img/yarh-black-back-open-large-t-001.png"></a></p>
                    <div>
                        <p>YARH.IO features modular design, where the main module includes Raspberry Pi board, screen, power supply, battery, and RTC and GPIO connector with cables.&nbsp;</p>
                        <p>The main module can be used as a fully functioning handheld computer&nbsp;with the touch screen and onscreen keyboard available for the performance of your basic tasks.</p>
                        <p>One shared USB connector is available on the bottom of the main module, allows connecting USB devices like&nbsp;hard drives or Cellular/WiFi adaptors and mounted inside the extension module.</p>
                        <p>Raspberry Pi GPIO connector is also available on the bottom of the main module, allowing for different add-on modules,&nbsp;<br>including Lora radios, RFID readers/writers, and IR transivers, to&nbsp;be mounted inside the extension
                            module. This configuration works extremely well with Pi-DAC+, creating a great handheld audio player.</p>
                    </div>
                </div>
                <div>
                    <p><a href="http://yarh.io/assets/img/yarh-black-keyboard-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="http://yarh.io/assets/img/yarh-black-keyboard-large-t-001.png"></a></p>
                    <div>
                        <p>No 'click' assembly here. This is a fully hackable device with stainless steel socket cap screw used&nbsp;throughout to allow for multiple assembly and disassembly cycles.&nbsp;The Military/Industrial aesthetic can be felt throughout
                            the YARH.IO project design.&nbsp;<br></p>
                        <p>The sturdy housing parts are 3D printed using PLA, ABS, and ASA plastic.&nbsp;<br></p>
                        
                    </div>
                </div>
                <div>
                    <p><a href="http://yarh.io/assets/img/yarh-black-back-keyboard-open-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="http://yarh.io/assets/img/yarh-black-back-keyboard-open-large-t-001.png"></a></p>
                    <p>The list of parts used for the YARH.IO project can be purchased from Amazon and other online stores.</p>
                </div>
                <div>
                    
                    <p><a href="http://yarh.io/assets/img/yarh-black-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="http://yarh.io/assets/img/yarh-black-large-t-001.png"></a></p>
                </div>
                <div>
                    <p><a href="http://yarh.io/assets/img/yarh-white-front-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="http://yarh.io/assets/img/yarh-white-front-large-t-001.png"></a></p>
                    <div>
                        <p>YARH.IO MKI Project at a Glance.&nbsp;</p>
                        <p>The outcome of this YARH.IO model is a successful handheld device with the potential to connect an unlimited range of extension devices and modules. It is a ruggedly designed and fully hackable device that can be 3D printed and
                            assembled in the field.<br></p>
                        <p>As an experimental model YARH.IO's future development will continue to increase usability and functionality of the device. One of the areas of improvement is the adaptation of IPS type screen for wider viewing angles.&nbsp;<br></p>
                        <p>Other future development will focus on adding new compartment modules to accommodate additional I/O, storage and communication devices.&nbsp;<br></p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <section id="yarh-io-mki-gallery">
        
    </section>
    <section id="yarh-io-mki-downloads">
        
    </section>
    <section id="footer">
        <div>
            <div>
                <div>
                    <div>
                        <p>© 2019-2020 YARH.IO | info@yarh.io</p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    
    
    
    


</div>]]>
            </description>
            <link>http://yarh.io/yarh-io-mki.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398485</guid>
            <pubDate>Mon, 07 Sep 2020 10:56:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Many Ways to Start an Xserver]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24398154">thread link</a>) | @gbrown_
<br/>
September 7, 2020 | https://nixers.net/Thread-How-Many-Ways-To-Start-An-Xserver | <a href="https://web.archive.org/web/*/https://nixers.net/Thread-How-Many-Ways-To-Start-An-Xserver">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://nixers.net/Thread-How-Many-Ways-To-Start-An-Xserver</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398154</guid>
            <pubDate>Mon, 07 Sep 2020 09:49:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microcentury]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24398092">thread link</a>) | @susam
<br/>
September 7, 2020 | https://susam.in/blog/microcentury/ | <a href="https://web.archive.org/web/*/https://susam.in/blog/microcentury/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>By <b>Susam Pal</b> on 17 Jul 2020</p>
<h2 id="optimal-lecture-time"><a href="#optimal-lecture-time">Optimal Lecture Time</a></h2>

<p>
I recently found this interesting paragraph from an article titled <a href="https://www.ams.org/notices/199701/comm-rota.pdf">Ten Lessons I
Wish I Had Been Taught</a> that is based on a talk presented by
Gian-Carlo Rota in Apr 1996:
</p>

<blockquote>
Running overtime is the one unforgivable error a lecturer can make.
After fifty minutes (one microcentury as von Neumann used to say)
everybody's attention will turn elsewhere even if we are trying to prove
the Riemann hypothesis. One minute overtime can destroy the best of
lectures.
</blockquote>

<p>
That's fine advice. In fact, the whole article is full of good advice
like this. Although it was written primarily for mathematicians, a lot
of what is said in the article applies quite well to professionals in
other fields too.
</p>

<p>
The excerpt I have quoted above got me thinking about exactly how long a
microcentury is. It couldn't be exactly 50 minutes, could it?
</p>


<h2 id="wiktionary-on-microcentury"><a href="#wiktionary-on-microcentury">Wiktionary on Microcentury</a></h2>
<p>
The English Wiktionary entry for <a href="https://en.wiktionary.org/wiki/microcentury">microcentury</a>
(as of <a href="https://en.wiktionary.org/w/index.php?title=microcentury&amp;oldid=59316064">revision
59316064</a> on 7 May 2020) mentions:
</p>

<blockquote>
A time period of a millionth of a century, equal to 52 minutes and 34 seconds.
</blockquote>

<blockquote>
Not a standard unit of measurement, and used mostly humorously to denote
the maximum length of a lecture.
</blockquote>

<p>
This looks incorrect to me. This is based on the oversimplified
assumption that a century contains 36500 days, that is, it assumes that
a century is a span of 100 years where each year has exactly 365 days.
If a century were to have exactly 36500 days, then indeed it would have
3 153 600 000 seconds and one millionth of it would be
3153.6 seconds which is equivalent to 52 minutes 33.6 seconds. This
looks consistent with the Wiktionary entry. However, an actual century
on the calendar does not have exactly 36500 days. Some years are leap
years, so the actual number of days in a century is more than that.
</p>


<h2 id="assumptions"><a href="#assumptions">Assumptions</a></h2>
<p>
Let us find out how long a microcentury is as accurately as possible. We
will count the leap years. We will ignore leap seconds because they are
irregularly spaced and unpredictable. We will also ignore the following
gap between 2 Sep 1752 and 14 Sep 1752 when the British Empire switched
from the Julian calendar to the Gregorian calendar:
</p><pre><samp>$ <kbd>cal 9 1752</kbd>
   September 1752
Su Mo Tu We Th Fr Sa
       1  2 14 15 16
17 18 19 20 21 22 23
24 25 26 27 28 29 30</samp>
</pre>

<p>
The above output can be obtained by running the <code>cal</code> command
as shown above on a Unix or Linux system. Ignoring this gap is
equivalent to assuming that we are working with the Gregorian calender
since the year 1 AD.
</p>

<p>
We will call a year that is a multiple of 100 to be a <em>centurial
year</em>. Further, we will not debate whether a centurial year begins a
new century or ends one, that is, we don't care whether the current
century runs from 2001 to 2100 or if it runs from 2000 to 2099. The
computation presented in the next section works equally well for any
span of 100 years.
</p>


<h2 id="computation"><a href="#computation">Computation</a></h2>
<p>
Any span of 100 years contains exactly one centurial year, that is, a
year that is a multiple of 100. A centurial year is a leap year <em>if
and only if</em> it is also a multiple of 400. Apart from the centurial
year, a century contains 24 occurrences of years that are multiples of 4
and these are all leap years. From these facts, we can conclude that a
span of 100 years contains:
</p>

<ul>
  <li>
    Exactly 25 leap years if the centurial year within the span is a
    multiple of 400.
  </li>
  <li>
    Exactly 24 leap years, otherwise.
  </li>
</ul>

<p>
Therefore a century has either 36524 days or 36525 days. In other words,
a century has either 3 155 673 600 seconds or
3 155 760 000 seconds. Here is a
quick demonstration of this with a simple Python program:
</p>

<pre><code>#!/usr/bin/env python3

import datetime

for year in range(1, 2400, 100):
    delta = datetime.date(year + 100, 1, 1) - datetime.date(year, 1, 1)
    print('{:04}-{:04}: {} d = {} s'
          .format(year, year + 100, delta.days, delta.total_seconds()))</code>
</pre>

<p>
Here is the output of this program:
</p>

<pre><samp>0001-0101: 36524 d = 3155673600.0 s
0101-0201: 36524 d = 3155673600.0 s
0201-0301: 36524 d = 3155673600.0 s
0301-0401: 36525 d = 3155760000.0 s
0401-0501: 36524 d = 3155673600.0 s
0501-0601: 36524 d = 3155673600.0 s
0601-0701: 36524 d = 3155673600.0 s
0701-0801: 36525 d = 3155760000.0 s
0801-0901: 36524 d = 3155673600.0 s
0901-1001: 36524 d = 3155673600.0 s
1001-1101: 36524 d = 3155673600.0 s
1101-1201: 36525 d = 3155760000.0 s
1201-1301: 36524 d = 3155673600.0 s
1301-1401: 36524 d = 3155673600.0 s
1401-1501: 36524 d = 3155673600.0 s
1501-1601: 36525 d = 3155760000.0 s
1601-1701: 36524 d = 3155673600.0 s
1701-1801: 36524 d = 3155673600.0 s
1801-1901: 36524 d = 3155673600.0 s
1901-2001: 36525 d = 3155760000.0 s
2001-2101: 36524 d = 3155673600.0 s
2101-2201: 36524 d = 3155673600.0 s
2201-2301: 36524 d = 3155673600.0 s
2301-2401: 36525 d = 3155760000.0 s</samp>
</pre>

<p>
Thus one millionth of a century has 3155.6736 or 3155.7600 seconds, that
is 52 minutes 35.6736 seconds or 52 minutes 35.7600 seconds.
</p>


<h2 id="Conclusion"><a href="#conclusion">Conclusion</a></h2>

<p>
If we round off the number of seconds in a microcentury to one decimal
place, we can say that a microcentury has 52 minutes 35.7 seconds.
</p>



</div></div>]]>
            </description>
            <link>https://susam.in/blog/microcentury/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398092</guid>
            <pubDate>Mon, 07 Sep 2020 09:38:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Transclude for Networked Writing]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24398014">thread link</a>) | @Frodo478
<br/>
September 7, 2020 | http://subpixel.space/entries/open-transclude/ | <a href="https://web.archive.org/web/*/http://subpixel.space/entries/open-transclude/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>tl;dr: If you follow this blog you’ve seen me experiment with iframe-based citations; this post is about open-sourcing that tooling. <a href="#tutorial-start" target="_self">Skip</a> to demo, implementation tutorial, and GitHub link.</p>

<hr>

<p>Knowledge tooling is happily becoming a hot topic again. With this trend is coming revived interest in <a href="https://en.wikipedia.org/wiki/Project_Xanadu">Xanadu</a>, bi-directional hyperlinking, knowledge databases, visualizing knowledge graphs, and so on. At this moment, I see most of the emphasis being put on tooling for the research side, with Notion, Workflowy, and the new and hyped Roam Research leading the way.</p>

<p><img src="http://subpixel.space/uploads/xanadu-shot.png" alt="Screenshot of the OpenXanadu prototpye"></p>

<p>Where I see less focus is the <em>writing</em> part of the knowledge production process, where older apps like Scrivener are still the thing to beat. And almost nobody at all is working on the reader’s experience. As a blogger who largely caters to a wide audience, I’m especially interested in these areas.</p>

<p>Written information is largely still presented as a single document, and writing tools are geared toward the production of long pages. But before I say what’s wrong with this, let me sing the praises of documents for a moment.</p>

<p>People often get carried away when they discover the original vision of hypertext, which involves a network of documents, portions of which are “transcluded” (included via hypertext) into one another. The implication is that readers could follow any reference and see the source material—and granted, this would be transformative. However, there’s a limit to the effectiveness of the knowledge network as a reading experience. “Hypertext books,” online books which are made up of an abundance of interlinked HTML pages, are mostly unpopular. The failure of this experiment is, in my opinion, very revealing.</p>

<p><img src="http://subpixel.space/uploads/sprawlingplaces-shot.jpg" alt="Screenshot of tinderbox map of hypertext book Sprawling Places by David Kolb">
<span>Tinderbox map of a portion of David Kolb’s hypertext book Sprawling Places</span></p>

<p>Knowledge is not an accumulation of facts, nor is it even a set of facts and their relations. Facts are only rendered meaningful within narratives, and the single-page document is a format very conducive to narrative structure. The hypertext books that have gained popularity (I’m thinking here of <a href="http://meaningness.com/">Meaningness.com</a>) have largely conformed to this in two ways: 1) there is an intended reading order, and 2) the longer essays within the project do most of the heavy lifting in terms of imparting the author’s perspective to readers.</p>

<p>On the other hand, the notion of the “document” that is intrinsic to web development today is overdetermined by the legacy of print media. The web document is a static, <em>finished</em> artifact that does not bring in dynamic data. This is strange because it lives on a medium that is alive, networked, and dynamic, a medium which we increasingly understand more as a <em>space</em> than a thing.</p>

<p>For example, consider how silly it is to include MLA-style citations at the bottom of a text when we have the vast capabilities of linked documents on the web. Why should the reader have to read every citation or trust that an author is not taking a citation out of context, when hyperlinks are available?</p>

<p>This all suggests that a compromise must be struck between the coherence of a text and the new opportunities for knowledge work afforded by the fundamental capabilities of the medium: the internet’s connectivity, the screen’s frame rate.</p>

<hr>

<p>My own blogging is one context in which I’ve seen this tension play out, and have been working to explore ways of making my texts richer. A lot of the ideas I talk about in various pieces of writing are connected to one another. When I publish an essay, I’m not done with it. The ideas live on and get renewed, reused, and recycled in later works. Some sentences contain definitions that are core to my mental models, and there are whole paragraphs that might be useful out of context. I’m building my knowledge network in mind maps and behind various SaaS APIs, but how can I publicly show my thinking to be part a cohesive worldview?</p>

<p>Normally people solve this by simply block quoting themselves, but this is a waste of an opportunity. The indented block quote is a print medium invention <a href="https://en.wikipedia.org/wiki/Block_quotation#Origins">almost as old as typesetting</a>. The block quote is <em>plaintext</em>, it is not actually linked to the original text or its context.</p>

<p>I’ve been experimenting with one idea for a solution, and if you’ve read the last couple blog posts you’ll have seen it there. My stab at an answer is an iframe which shows the quote within its original context and gives a hint at its surroundings. Effectively, it’s a transclusion within my own blog. I’m currently satisfied with what I have as a v1, and am interested to see if others find it useful, so I’m open sourcing it here and including a tutorial.</p>



<p>Open Transclude is a UX pattern, a spec for networked writing within your own blog. Here’s how it looks:</p>



<!-- <script src="/portal.js"></script> -->



<p>What you are looking at is an scroll-locked iframe that links to a quote I picked out of my blog post “Notes on Comparative Psychology.” You can use Open Transclude anywhere you can drop an <code>&lt;a&gt;</code> tag on your own site.</p>

<p>Open Transclude:</p>
<ul>
  <li>Works anywhere on your own domain</li>
  <li>Compatible with most static site generators / templating engines</li>
  <li>12 lines of HTML, 80 lines of SCSS, 22 lines of JS (4.5 kb total)</li>
  <li>Has 0 dependencies&nbsp;— this is native web technology</li>
</ul>

<p>Open Transclude is extremely simple, and the heaviest part of the code is the CSS, which you can simplify at your whim. That’s why I am referring to it as a UX pattern. This is not a protocol. The code is really a commodity. What’s interesting about it is the idea and the design, and this is just one viable implementation! Feel free to adapt it however you like.</p>

<p>The principal improvement over a block quotation is <em>sense of context</em>.</p>

<p>Over on GitHub you’ll find the <a href="https://github.com/tobyshorin/Open-Transclude/">reference implementation for Jekyll</a>. Below is a tutorial for implementing it yourself, by way of also explaining some of the technical design decisions.</p>

<hr>

<h2 id="implementation-recipe">Implementation Recipe</h2>

<p>Here’s what you need to do to get Open Transclude up and running.</p>

<ol>
  <li>Create an anchor tag in the blog post where you want to cite yourself.</li>
  <li>Create the HTML for the reusable transclusion component.</li>
  <li>Call the portal into any document and passing it Jekyll variables.</li>
  <li>A small piece of Javascript which populates your transclusion into the document.</li>
  <li>Create the SCSS file with the component’s styles.</li>
</ol>

<h3 id="1-create-the-anchor-tag-where-you-want-to-cite-yourself">1. <strong>Create the anchor tag where you want to cite yourself</strong></h3>

<p>To quote yourself, you’ll need to create an <code>&lt;a&gt;</code> anchor tag in the markdown file for the post you want to quote. If you wish to highlight a specific piece of text, instead create a <code>&lt;span&gt;&lt;/span&gt;</code> around the section you want to quote. Note that this can <em>only be on your own website</em>—it doesn’t work cross domain.</p>

<p>Here’s what it looks like for the example iframe above.</p>

<figure><pre><code data-lang="markdown">It will, for one thing, become newly conscious of itself, and, to the degree that it is, <span>**it will tend to undermine its own experiential integrity**</span>" (emphasis mine).

<span>&lt;span</span> <span>name=</span><span>"mainstream-magic"</span><span>&gt;</span>Ironically, psychology remains one of the closest things we have to a mainstream magic or a mystical art today. Not only is it plainly the direct descendent of medieval magic, as I learned when I read Ioan Coulianou's <span>*Eros and Magic in the Renaissance*</span> earlier this year. <span>**It is a theory of the self that is phenomenologically accurate, objectively wrong, and is based on magical thinking even as it deconstructs itself**</span>.<span>&lt;/span&gt;</span> Some magical thinking processes that happen in psychotherapy, such as <span>[</span><span>transference to the psychologist</span><span>](</span><span>https://en.wikipedia.org/wiki/Transference#Transference_and_countertransference_during_psychotherapy</span><span>)</span>, are even intended to stay unmentioned to the patient in order to be utilized most effectively by the therapist!</code></pre></figure>

<h3 id="2-create-your-iframe-component">2. Create your iframe component</h3>

<p>This is most useful as a standardized component which can be used across the site, so we are going to take advantage of Jekyll’s templating features. Jekyll and other static site generators like Kirby and Zola support HTML “partials” or “includes” so that you can create reusable components.</p>

<p>In your <code>/_scss</code> or <code>/_sass</code> folder make a new file, <code>portal.scss</code>. I called it “portal” because it’s shorter than “transclusion” and less prone to spelling errors.</p>

<p>Here’s our component:</p>

<figure><pre><code data-lang="html"><span>&lt;div</span> <span>class=</span><span>"portal-container"</span><span>&gt;</span>
    <span>&lt;div</span> <span>class=</span><span>"portal-head"</span><span>&gt;</span>
        <span>&lt;div</span> <span>class=</span><span>"portal-backlink"</span> <span>&gt;</span>
            <span>&lt;div</span> <span>class=</span><span>"portal-title"</span><span>&gt;</span>From <span>&lt;span</span> <span>class=</span><span>"portal-text-title"</span><span>&gt;</span>{{ include.title }}<span>&lt;/span&gt;&lt;/div&gt;</span>
            <span>&lt;a</span> <span>href=</span><span>"{{ include.link }}"</span> <span>class=</span><span>"portal-arrow"</span><span>&gt;</span>Go to text <span>&lt;span</span> <span>class=</span><span>"right-arrow"</span><span>&gt;</span>→<span>&lt;/span&gt;&lt;/a&gt;</span>
        <span>&lt;/div&gt;</span>
    <span>&lt;/div&gt;</span>
    <span>&lt;div</span> <span>id=</span><span>"portal-parent-{{include.anchor}}"</span> <span>class=</span><span>"portal-parent"</span><span>&gt;</span>
        <span>&lt;div</span> <span>class=</span><span>"portal-parent-fader-top"</span><span>&gt;&lt;/div&gt;</span>
        <span>&lt;div</span> <span>class=</span><span>"portal-parent-fader-bottom"</span><span>&gt;&lt;/div&gt;</span>        
        <span>&lt;!-- We'll use Javascript to populate the iframe right here --&gt;</span>
    <span>&lt;/div&gt;</span>    
<span>&lt;/div&gt;</span></code></pre></figure>

<p>You’ll notice immediately that the iframe isn’t there yet. Like I mentioned above, we’re going to be populating it with Javascript.</p>

<p>You’ll also see that in various places we’re using <code>{{ include.___}}</code>. A cool thing about Jekyll includes its that it’s possible to define variables and pass them to our include, so we can create reusable components across our site. Dave Rupert has a <a href="https://daverupert.com/2017/07/jekyll-includes-are-cool/">nice blog post about this</a> called if you want to see more advanced examples!</p>

<h3 id="3-calling-the-component">3. Calling the component</h3>

<p>Anytime you want to pull this component into a blog post, all you have to do is <code>include</code> it in the markdown of another blog post, like this:</p>

<figure><pre><code data-lang="html">  {% include portal.html title="Notes On Comparative Psychology" link="/entries/notes-on-comparative-psychology/#mainstream-magic" anchor="emotional-deficit" %} </code></pre></figure>

<p>When you include it, you’ll need to pass in those three variables - title, link, and anchor, that fill in the includes above. If you’re following along now and making a build in Jekyll, you’ll see an empty, unstyled component with the link. So good so far!</p>

<h3 id="4-populating-with-javascript">4. Populating with Javascript</h3>

<p>This is a good time to address why we need Javascript. Web developers reading this are probably asking why we don’t simply put the full <code>/link#with-anchor</code> into the iframe src and be done with it. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://subpixel.space/entries/open-transclude/">http://subpixel.space/entries/open-transclude/</a></em></p>]]>
            </description>
            <link>http://subpixel.space/entries/open-transclude/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24398014</guid>
            <pubDate>Mon, 07 Sep 2020 09:23:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Threat modelling case study: bicycles]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 98 (<a href="https://news.ycombinator.com/item?id=24397852">thread link</a>) | @calpaterson
<br/>
September 7, 2020 | http://calpaterson.com/bicycle-threat-model.html | <a href="https://web.archive.org/web/*/http://calpaterson.com/bicycle-threat-model.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <p>August 2020</p>
        <p id="article-description">How to avoid buying your bike again every 6-12
        months and tips for how to apply the same reasoning to other things, like
        computers</p>
        <hr>
        <figure>
            <img src="http://calpaterson.com/assets/solitary-wheel.jpeg" alt="a solitary wheel left behind after the rest of the bike was nicked">
            <figcaption>
                Rucksack Rupert strikes again
            </figcaption>
        </figure>
        <p>Some very commonly repeated advice on preventing someone from nicking your
        bike:</p>
        <blockquote>
            <p>Buy a good [~10% of bicycle value] lock, ideally one with a high
            "SoldSecure" rating and lock your bicycle somewhere inside the rear
            triangle and the rear wheel.</p>
        </blockquote>
        <p>I've seen this advice repeated in cycling magazines, in quality newspapers,
        sometimes even by the police and of course on internet forums.</p>
        <p>The above would imply that if you own a £400 bicycle (<a href="https://www.statista.com/statistics/395884/bicycle-average-prices-in-the-european-union-eu-by-country/">a
        typical price in the UK</a>) you'd buy a £40 lock and put it in the right
        place.</p>
        <p>However, it is a cold fact that a cordless angle grinder can defeat any
        bicycle lock, no matter how expensive (<a href="https://www.youtube.com/watch?v=pywN558dJaU&amp;t=198">see this video for a
        demonstration</a>). You can buy a used cordless angle grinder on eBay for less
        than £100. Even U-locks - traditionally thought to be the strongest type of
        lock - are opened in seconds with a sub-£100 angle grinder.</p>
        <p>There is other advice floating around of doubtful value, for example:</p>
        <blockquote>
            <p>Add your bicycle to a national register</p>
        </blockquote>
        <p>But cases where BikeRadar manage to reunite bicycles with their owners seem
        to be the exception rather than the rule. Probably this is because, as with
        cars, the first thing you do with a stolen bicycle is take it across a border
        to somewhere different.</p>
        <blockquote>
            <p>Lock your bicycle inside a secure building or place, away from sight</p>
        </blockquote>
        <p>This prevents opportunistic theft but if this space is shared with others
        (apartment blocks and offices) it in fact serves to increase the economies of
        scale for prepared thieves who break into your storage area late at night with
        a van. It's not uncommon for office bicycle stores (with many fancy, expensive
        bikes inside) to be emptied out completely overnight by professional
        thieves.</p>
        <h2>A threat model, by user persona</h2>
        <p>I think the advice above is poor because it doesn't come from a systematic
        consideration of the problem <em>from the point of view of thieves</em>.</p>
        <p>To come up with better advice requires a threat model, which is a piece of
        jargon for taking a holistic view of the danger posed by attackers. I think one
        of the simplest and most straightforward ways to do threat modelling is by
        <em>user persona</em>, whereby you consider each kind of attacker in turn,
        making some reasonable assumptions about their level of motivation and
        methods.</p>
        <p>As far as bicycle theft is concerned there are three basic types of
        thief.</p>
        <h3>"No-tools Nigel", the rank opportunist</h3>
        <p>Nigel has just his two hands and is simply looking for a ride home or maybe
        something he can sell to a friend for some quick cash.</p>
        <p>Nigel will steal any unlocked bicycle.</p>
        <p>Nigel is also able to take any bicycle parts that can be removed without
        tools. That means any quick-release wheels or thumbscrew saddles. In an urban
        area your parked bicycle may be passed by a Nigel as often as a few times an
        hour so anything that is not bolted down won't last very long.</p>
        <h3>"Rucksack Rupert", the thief with a few hand tools</h3>
        <p>Rupert has a small pair of shears; 4, 5 and 6mm Allen keys and a 15mm
        spanner for wheel nuts.</p>
        <p>Rupert will make his way through cable locks with his shears. If there is a
        valuable part that can be removed with hand tools he will take it. He is
        particularly keen on premium saddles and name brand wheels.</p>
        <h3>"Powertool Percy", the professional with a complete set of tools</h3>
        <p>Percy has a small collection of electric and air tools including an angle
        grinder as well as bolt-cutters and an air-jack. He has access to <a href="https://en.wikipedia.org/wiki/Fence_(criminal)">criminal fences</a> which he
        can use to sell stolen bicycles quickly. Percy often arrives in his van and
        this allows him to steal multiple bikes at once.</p>
        <p>No bicycle is safe from Percy. No lock can hold against his angle grinder.
        Often he finds if he's wearing a hi-vis jacket he can even get away with using
        his power tools in broad daylight. He's willing to chance that if the bicycle
        seems valuable enough.</p>
        <h2>Coming up with better advice based on Nigel, Rupert and Percy</h2>
        <p>In order to keep your bicycle safe you need to take steps against all three
        levels of imaginary thieves.</p>
        <p>"No-tools Nigel" will be warded off simply by:</p>
        <ul>
            <li>Locking your bicycle whenever you leave it - even if just for a
            minute</li>
            <li>Ensuring you leave nothing on your bicycle that can be removed without
            tools
                <ul>
                    <li>replace quick-release wheel skewers with bolts</li>
                    <li>take your lights with you when you park in public</li>
                    <li>make sure your saddle is not on a thumbscrew</li>
                </ul>
            </li>
        </ul>
        <p>"Rucksack Rupert" will be deterred by:</p>
        <ul>
            <li>Not using a cable lock!</li>
            <li>Making sure that nothing good can be removed from your bicycle with
            hand tools
                <ul>
                    <li>Lock both wheels <em>and the frame</em> to the bike stand -
                    don't rely on bolts</li>
                </ul>
            </li>
        </ul>
        <p>"Powertool Percy" will be kept at bay by:</p>
        <ul>
            <li>Nothing, save ensuring that your bicycle doesn't look valuable enough
            to be worth his time
                <ul>
                    <li>this probably means keeping its value down below a few hundred
                    pounds</li>
                </ul>
            </li>
        </ul>
        <h2>The virtue of the "bicycle shaped object"</h2>
        <p>Valuable bicycles (&gt;£1000) have an extremely short half-life in urban
        areas. The sad truth is that the Percys of the world are common enough and
        resourceful enough that a bicycle worth over a thousand pounds isn't really
        safe anywhere in a large town. <strong>This includes most e-bikes.</strong> You
        might notice that cycle couriers who have e-bikes tend to eat lunch while
        looking directly at their locked e-bike, so that it never goes out of their
        sight. Few people in other lines of work can do the same.</p>
        <p>If the tyres are inflated, my own commuter bicycle is probably worth £30 to
        the right buyer. My bicycle is so low-end that cycling snobs refer to it as a
        mere "bicycle shaped object". Rather selfishly I am glad that such snobs exist
        as having a lot of more valuable bicycles around provides me with good ambient
        security. No thief is going to bother cutting my locks when there is a
        Campagnolo on the next rack.</p>
        <p>One father I know had his primary-school-age daughter "decorate" his
        commuting bicycle with girly stickers and pink glitter. If anyone examines his
        bicycle closely he looks like a complete loon but I think his motivation is
        right: it's going to be much less appealing to steal when it's covered in Miffy
        stickers.</p>
        <h3>Insurance - not usually worth it</h3>
        <p>What about bicycle insurance? It's fairly expensive here in the UK, usually
        10-15% of the bicycle's value annually and insurers typically only pay out when
        the whole bicycle is taken (so if if your front wheel is nicked, you're on your
        own) and when you can demonstrate that it was locked to their standards. Often
        these standards require that it is locked up indoors which means you're
        chancing it whenever you park away from your home or office.</p>
        <h2>Lists of "best practices" vs having your own threat model</h2>
        <p>The same thing goes for securing your bicycle as for securing other things:
        pat, concrete pieces of security advice are something to treat with a bit of
        doubt.</p>
        <p>In bicycles the common mantra is "spend 10% on a lock" but in computing the
        mantras are slogans such as "use a strong password", "back up your important
        data" or "use encryption" but these can all be just as vapid.</p>
        <p>"Strong passwords!" as a slogan fails to address the fact that the average
        internet user has hundreds of logins for various sites (my own password manager
        has over 700 sites recorded). The majority of internet users decide on a single
        "strong password" and then use it everywhere. They are only a single bad
        sysadmin or javascript injection away from losing access to every account on
        every website they have.</p>
        <p>Backing up your important data is only an aid to your security if the backup
        is stored as securely as the original. Much user data is stolen or exposed
        through poorly secured backups on shared fileservers. A huge number of people
        have passport and utility bill scans in their Dropbox - again, behind the same
        email and password they use everywhere. Companies can be surprisingly sloppy
        with backups too: often dumped into cloud storage somewhere once before the Big
        Migration and never removed.</p>
        <p>Encryption is troublesome as it can give undue confidence that can backfire
        spectacularly: a quarter of a million American diplomatic cables were
        inadvertantly published in unredacted form when a Guardian journalist <a href="https://en.wikipedia.org/wiki/WikiLeaks:_Inside_Julian_Assange%27s_War_on_Secrecy">
        included the password for an widely-distributed encrypted file in his book</a>.
        Apparently he thought the file's password was somehow temporary. It wasn't.</p>
        <p>Instead of following such "best practices" it's much more intellectually
        robust to <strong>come up with your own threat model</strong> - then you can
        decide your own concrete steps instead of just following the security steps of
        others which might be inapplicable or even wrong.</p>
        <h2>Some hints on coming up with your own …</h2></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://calpaterson.com/bicycle-threat-model.html">http://calpaterson.com/bicycle-threat-model.html</a></em></p>]]>
            </description>
            <link>http://calpaterson.com/bicycle-threat-model.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24397852</guid>
            <pubDate>Mon, 07 Sep 2020 08:58:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data analysis made easy: Text2Code for Jupyter notebook]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24397670">thread link</a>) | @dsr12
<br/>
September 7, 2020 | https://madewithml.com/projects/2283/data-analysis-made-easy-text2code-for-jupyter-notebook/ | <a href="https://web.archive.org/web/*/https://madewithml.com/projects/2283/data-analysis-made-easy-text2code-for-jupyter-notebook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

          <!-- Links -->
          <div>

            <!-- Details -->
            
              <!-- <h5>Details</h5> -->
              <div>
                <div>
                  <div>
                    
                      <p><img src="https://github.com/deepklarity/jupyter-text2code/blob/master/mopp-demo.gif?raw=true" alt=""></p>

<p>A ready-to-install jupyter extension which converts english queries into relevant code. Built as a proof of concept for the problem we personally face of <strong>forgetting less-used syntaxes of pandas and plotly libraries</strong> which is often used in Exploratory Data Analysis. This tool allows us to query in a generic language without having to remember the syntax.</p>

<p>Inspired by cool GPT-3 demos and not having the access to the API, here is an attempt by us to build a Text2Code extension using publicly available libraries. The approach isn't generative, but relies on identifying &amp; matching from a set of predefined <em>intents</em> and generating the relevant code by extracting relevant entities and inserting them in a template. Adding new intents and extending the functionality is easy once the pipeline is in place. </p>

<p>Technologies used:</p>

<ul>
<li>Universal Sentence Encoder</li>
<li>Spacy</li>
<li>Faiss</li>
<li>Jupyter extension</li>
</ul>

                    
                  </div>
                </div>
              </div>
            

            <!-- Comments -->
            
            
            <p><i></i>Don't forget to tag
              
              <a href="https://madewithml.com/@dk-crazydiv/" target="_blank">@dk-crazydiv</a>
              
              ,
              
              
              <a href="https://madewithml.com/@deepak-deepklarity/" target="_blank">@deepak-deepklarity</a>
              
               in
              your comment, otherwise they may not be notified.
            </p>
            

          </div>

        </div></div>]]>
            </description>
            <link>https://madewithml.com/projects/2283/data-analysis-made-easy-text2code-for-jupyter-notebook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24397670</guid>
            <pubDate>Mon, 07 Sep 2020 08:32:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SEO Doesn't Matter Anymore]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24397541">thread link</a>) | @puggo
<br/>
September 7, 2020 | https://hawaiigentech.com/post/no-more-seo/ | <a href="https://web.archive.org/web/*/https://hawaiigentech.com/post/no-more-seo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><img src="https://hawaiigentech.com/post/no-more-seo/seo-joke.png" alt="Seo is a Joke"></p>
<hr>
<h2 id="seo-search-engine-optimization-is-the-art-of-enticing-machines-so-as-to-entice-people">SEO (Search Engine Optimization): is the art of enticing machines so as to entice people.</h2>
<p><em>But it’s no longer needed.</em></p>
<p>Granted, the usual stuff applies: Fast page load, responsiveness for mobile devices, spelling and grammer…still apply.</p>
<p><em><strong>But gone are the days</strong></em> of the subtler forms of SEO, where you cared about keyword density, backlinks, and similar things.</p>
<hr>
<h2 id="the-algorithms-and-ai-are-more-advanced-now">The Algorithms and AI Are More Advanced Now</h2>
<p>The algorithms are practically sentient…</p>
<p><img src="https://hawaiigentech.com/post/no-more-seo/webcrawler.jpg" alt="The Algorithms Are Practically Sentient"></p>
<p>At this time, it is now better for you to write content like a human, with personality, and natural.</p>
<p>If you know a subject well, Google especially can sense that. If you are faking, google can sense that too.</p>
<p>Bing search engine likely has comparable talents. Other <em>search engines don’t even matter anymore</em>, as they (such as Duckduckgo and Yahoo) actually source their results from Bing.</p>
<p>Whereas domain authority was previously calculated by backlinks and social network cues, the algos can now sense from your writing alone, along with a multitude of other cues…if you are who you say you are.</p>
<p>On this subject, here is some light reading for you… <a href="https://web.archive.org/web/20200831214216/https://static.googleusercontent.com/media/guidelines.raterhub.com/en//searchqualityevaluatorguidelines.pdf">https://web.archive.org/web/20200831214216/https://static.googleusercontent.com/media/guidelines.raterhub.com/en//searchqualityevaluatorguidelines.pdf</a> (E-A-T)</p>
<hr>
<h3 id="backlinks-hardly-matter">Backlinks… Hardly Matter</h3>
<p>Before, in SEO, you had the burden of building backlinks. Backlinks helped search engines understand the context of your site and it’s possible popularity and authority.</p>
<p>This, too, could be farmed artificially.</p>
<p>It doesn’t matter now.</p>
<hr>
<h3 id="keyword-density-dont-need-it">Keyword Density? Don't Need It</h3>
<p>If I were to speak, talk, express myself to you in a awkward, silly, repetitive, redundant manner, you might not like, appreciate, understand me very well.</p>
<p>If I spoke to you with no less than 1000 words, you might be annoyed. You would, most likely, be very, annoyed, angered, frustrated, sad.</p>
<p>You get it? The Algorithms practically have emotions now. They don’t want to hear you talk like that either.</p>
<p>They don’t like SEO tricks.</p>
<p>Don’t use them.</p>
<hr>

<p>Unless you really are a popular person, don’t bother. Sure, social network traffic is great. But artificial popularity on a social network (ie, an army of admiring sock puppets talking about you… doesn’t help anymore). Search engines know who’s real and who’s not (mostly).</p>
<hr>
<h2 id="finally-you-can-be-you">Finally, You Can Be You</h2>
<p>Now that search engines are smarter, you are officially relieved of the burden of SEO. You can be your best you, and you will now thrive for it.</p>
<p>The fakers…they will sink in results. Why? Because nobody likes a cheat, fraud, fake, keyword stuffer, SEO “Expert”.</p>
<hr>
<h3 id="ohjust-one-more-thing">Oh…Just One More Thing</h3>
<p>Don’t ever pay an “SEO Expert” again. He’s not applicable anymore.</p>

    </div></div>]]>
            </description>
            <link>https://hawaiigentech.com/post/no-more-seo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24397541</guid>
            <pubDate>Mon, 07 Sep 2020 08:04:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pragmatic MVU with React and TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24397443">thread link</a>) | @asp_net
<br/>
September 7, 2020 | https://thomasbandt.com/model-view-update-with-react-and-typescript | <a href="https://web.archive.org/web/*/https://thomasbandt.com/model-view-update-with-react-and-typescript">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <article>
    
    <p>With the introduction of hooks, React got some compelling new instruments – including useReducer, which can be used to implement Model-View-Update within a React component.</p>
    
    <p>While probably intended to "hook up" developers experienced in working with Redux, <a href="https://reactjs.org/docs/hooks-reference.html#usereducer">useReducer</a> at the same time opens the door for implementing The Elm Architecture, aka Model-View-Update (MVU) quickly and pragmatically.</p>
<h2>The Core Idea</h2>
<p>If you don't know what MVU is and want to learn more first, check out my article on <a href="https://thomasbandt.com/model-view-update">how it works</a>. If you are impatient, I can offer you a shortcut:</p>
<p><img src="https://thomasbandt.com/upload/mvu.png" alt="MVU"></p>
<p>From my perspective, the whole thing's essential idea is to make changes to the state explicit and easy to reason about. That is achieved through:</p>
<ol>
<li>Data is flowing uni-directionally.</li>
<li>Having a view that is a function of the state (model).</li>
<li>Having an update function that is the only place where state changes.</li>
<li>Communicating through messages.</li>
</ol>
<p>It is fair to argue that 1. and 2. are already core principles of React itself. However, <code>useReducer</code> adds 3. and 4. to the game.</p>
<h2>A Practical Example</h2>
<p>Without further ado, let's go through it based on a little example, a login form.</p>
<h3>What Are The Requirements?</h3>
<ol>
<li>There are a user name and a password field, and a submit button.</li>
<li>The button must only be enabled when the user name and password are provided.</li>
<li>When the button is clicked, some work shall be done (e.g., validation/network request).</li>
</ol>
<h3>The State</h3>
<pre><code>interface State {
  userName: string;
  password: string;
  isValid: boolean;
}

const initialState: State = {
  userName: "",
  password: "",
  isValid: false,
};
</code></pre>
<p>That's as unspectacular as necessary, as the core information we are working with is defined at a central place. So whenever you want to access the user name or password, you don't need to go to the form itself.</p>
<h3>The Messages</h3>
<pre><code>type UserNameChangedMsg = {
  type: "UserNameChangedMsg";
  userName: string;
};

type PasswordChangedMsg = {
  type: "PasswordChangedMsg";
  password: string;
};

type Msg = UserNameChangedMsg | PasswordChangedMsg;
</code></pre>
<p>While the definition of messages is not as lean as in other languages (in F#, this would have been a three-liner), TypeScript, fortunately, supports <a href="https://mariusschulz.com/articles/tagged-union-types-in-typescript">Tagged Union Types</a>, which do the job.</p>
<h3>The View</h3>
<pre><code>export default function () {
  const [state, dispatch] = useReducer(update, initialState);

  return (
    &lt;div&gt;
      &lt;input
        type="text"
        placeholder="User name"
        defaultValue={state.userName}
        onChange={(e) =&gt;
          dispatch({ type: "UserNameChangedMsg", userName: e.target.value })
        }
      /&gt;
      &lt;input
        type="password"
        placeholder="Password"
        defaultValue={state.password}
        onChange={(e) =&gt;
          dispatch({ type: "PasswordChangedMsg", password: e.target.value })
        }
      /&gt;
      &lt;button disabled={!state.isValid} onClick={() =&gt; signIn(state)}&gt;
        Sign in
      &lt;/button&gt;
    &lt;/div&gt;
  );
}
</code></pre>
<p>Now things are getting more interesting. Let's go through it:</p>
<pre><code>const [state, dispatch] = useReducer(update, initialState);
</code></pre>
<p>There it is, our <code>useReducer</code> hook. Calling it returns two things: The current <code>state</code> and a <code>dispatch</code> function.</p>
<p>The <code>state</code> can be used to render the view depending on its properties. For example, as required, the sign-in button is only enabled when <code>state.isValid</code> is set to <code>true</code>.</p>
<p>The <code>dispatch</code> function is used to "fire" messages: Whenever the user changes the user name or the password, the corresponding message is being dispatched. Note that it contains the element's value as its payload, for example, in the case of the password:</p>
<pre><code>onChange={(e) =&gt;
  dispatch({ type: "PasswordChangedMsg", password: e.target.value })
}
</code></pre>
<p>Now, two questions come up: What happens when a message is being dispatched? And how does <code>state.isValid</code> ever become true?</p>
<h3>The Update Function</h3>
<pre><code>function validate(state: State): boolean {
  return state.userName.length &gt; 0 &amp;&amp; state.password.length &gt; 0;
}

function update(state: State, msg: Msg) {
  switch (msg.type) {
    case "UserNameChangedMsg": {
      const newState = { ...state, userName: msg.userName };
      return { ...newState, isValid: validate(newState) };
    }
    case "PasswordChangedMsg": {
      const newState = { ...state, password: msg.password };
      return { ...newState, isValid: validate(newState) };
    }
  }
  return assertUnreachable(msg);
}
</code></pre>
<p>Here it is, the U of MVU, our <code>update</code> function. Its signature is defined by the <code>useReducer</code> hook: It accepts the latest known state and a message it is supposed to process.</p>
<p>Based on some magic of the TypeScript compiler, it is possible to switch through the messages based on the discriminant property type, which all of them provide.</p>
<p>Depending on the message type, we now know what should be changed, <code>userName</code> or <code>password</code>, and so we do. We also set the <code>isValid</code> property, which becomes only true when both the user name and the password contain at least one character.</p>
<p>Side note: The whole thing is exhaustive, which is achieved by the little helper function <code>assertUnreachable()</code>:</p>
<pre><code>function assertUnreachable(x: never): never {
  throw new Error("Didn't expect to get here");
}
</code></pre>
<p>Whenever our tagged union <code>Msg</code> gets a new case, the compiler will notice, and the build will fail â€“ until we add that case to the switch.</p>
<h3>Commands?</h3>
<p>If you already know about MVU, you might have noticed that there are no commands yet. And there won't be any â€“ the <code>useReducer</code> hook doesn't know about the concept of commands. That's why I call it a pragmatic approach.</p>
<p>But that's not the end of the world as it is possible to work around it for most cases. For example, when our sign-in button is enabled and gets clicked, we call another function and pass the current state:</p>
<pre><code>function signIn(state: State) {
  // Do something here ...
}
</code></pre>
<p>We could validate the credentials, make network requests, or do whatever we like. And if the result would be a change of our state, we could pass the dispatch function and dispatch a message from within here.</p>
<h2>Conclusion</h2>
<p>The example may seem relatively trivial, even too insignificant to use that MVU approach. But if you chose to go down that route, it will come with all the benefits listed above â€“ even for such a relatively simple component.</p>
<p>And once you follow the pattern in more and more components of your application, you will notice that behavior reasoning will become much more straightforward.</p>
<p>PS: See <a href="https://gist.github.com/aspnetde/93bf9cbbac76b7c36b59015ec47cabdf">here</a> for the complete code of the component.</p>

    
</article>




        </div></div>]]>
            </description>
            <link>https://thomasbandt.com/model-view-update-with-react-and-typescript</link>
            <guid isPermaLink="false">hacker-news-small-sites-24397443</guid>
            <pubDate>Mon, 07 Sep 2020 07:45:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things I Learned to Become a Senior Software Engineer]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 116 (<a href="https://news.ycombinator.com/item?id=24397269">thread link</a>) | @janvdberg
<br/>
September 7, 2020 | https://neilkakkar.com/things-I-learned-to-become-a-senior-software-engineer.html | <a href="https://web.archive.org/web/*/https://neilkakkar.com/things-I-learned-to-become-a-senior-software-engineer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In 2018, I started working at Bloomberg. Things have changed a lot since. I’m not the most junior member in the company anymore and I’ve mentored quite a few new engineers, which has been amazing. It helped me observe how others differ from me, absorb their best practices, and figure out things I’ve unconsciously been doing pretty well.</p>

<p>Yearly work reviews are a good way to condense these lessons I’ve learned.  They’re valuable for pattern matching, too. Only when I zoom out do certain patterns become visible. I can then <a href="https://neilkakkar.com/the-human-log.html">start tracking these patterns consciously</a>.</p>

<p>The broad theme for this year is zooming out and challenging the boundaries. It’s also about zooming in, and adding nuance to the sections from last year. It’s more fun if you’ve <a href="https://neilkakkar.com/year-in-review-2019.html">read last year’s review first</a>: You can then diff my growth.<sup id="fnref:2"><a href="#fn:2">1</a></sup></p>

<p>It all began with a question: How do I grow further?</p>





<nav>

  <h4>Table of Contents</h4>

<ul id="markdown-toc">
  <li><a href="#growing-using-different-ladders-of-abstraction" id="markdown-toc-growing-using-different-ladders-of-abstraction">Growing using different ladders of abstraction</a></li>
  <li><a href="#learning-what-people-around-me-are-doing" id="markdown-toc-learning-what-people-around-me-are-doing">Learning what people around me are doing</a></li>
  <li>
<a href="#learning-good-habits-of-mind" id="markdown-toc-learning-good-habits-of-mind">Learning good habits of mind</a>    <ul>
      <li><a href="#thinking-well" id="markdown-toc-thinking-well">Thinking Well</a></li>
      <li><a href="#strategies-for-making-day-to-day-more-effective" id="markdown-toc-strategies-for-making-day-to-day-more-effective">Strategies for making day-to-day more effective</a></li>
    </ul>
  </li>
  <li><a href="#acquiring-new-tools-for-thought--mental-models" id="markdown-toc-acquiring-new-tools-for-thought--mental-models">Acquiring new tools for thought &amp; mental models</a></li>
  <li><a href="#protect-your-slack" id="markdown-toc-protect-your-slack">Protect your slack</a></li>
  <li><a href="#ask-questions" id="markdown-toc-ask-questions">Ask Questions</a></li>
  <li><a href="#noticing-confusion" id="markdown-toc-noticing-confusion">Noticing Confusion</a></li>
  <li><a href="#force-multipliers" id="markdown-toc-force-multipliers">Force multipliers</a></li>
  <li><a href="#on-ownership" id="markdown-toc-on-ownership">On Ownership</a></li>
  <li><a href="#embrace-fear" id="markdown-toc-embrace-fear">Embrace fear</a></li>
  <li>
<a href="#adding-nuance" id="markdown-toc-adding-nuance">Adding nuance</a>    <ul>
      <li><a href="#writing-code" id="markdown-toc-writing-code">Writing Code</a></li>
      <li><a href="#testing" id="markdown-toc-testing">Testing</a></li>
      <li>
<a href="#design" id="markdown-toc-design">Design</a>        <ul>
          <li><a href="#gathering-requirements" id="markdown-toc-gathering-requirements">Gathering Requirements</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#some-hacks-that-have-worked-very-well-for-me" id="markdown-toc-some-hacks-that-have-worked-very-well-for-me">Some hacks that have worked very well for me</a></li>
  <li><a href="#super-powers" id="markdown-toc-super-powers">Super powers</a></li>
  <li>
<a href="#some-gotchas-with-growing" id="markdown-toc-some-gotchas-with-growing">Some gotchas with growing</a>    <ul>
      <li><a href="#sometimes-i-feel-i-need-to-know-the-answer-to-everything" id="markdown-toc-sometimes-i-feel-i-need-to-know-the-answer-to-everything">Sometimes, I feel I need to know the answer to everything</a></li>
      <li><a href="#sometimes-i-lose-my-cool" id="markdown-toc-sometimes-i-lose-my-cool">Sometimes, I lose my cool</a></li>
      <li><a href="#neophilia" id="markdown-toc-neophilia">Neophilia</a></li>
    </ul>
  </li>
  <li><a href="#questions" id="markdown-toc-questions">Questions</a></li>
</ul>

</nav>

<!-- works only once jQuery is loaded -->


<h2 id="growing-using-different-ladders-of-abstraction">Growing using different ladders of abstraction</h2>

<p>Entering my second year, I had all the basics in place. I had picked all the low hanging fruit, and my rate of growth slowed down. Not good. The big question in my mind was “How do I grow further?”</p>

<p>There was only so much I could do to improve my coding skills. Most blogs epousing techniques to write cleaner code, repeating yourself, not repeating yourself, etc. are micro-optimisations. Almost none of them would make me instantly impactful.<sup id="fnref:3"><a href="#fn:3">2</a></sup></p>

<p>However, I did figure out something insightful. I’m working inside the software development lifecycle, but this lifecycle is part of a bigger lifecycle: the product and infrastructure development lifecycle. I decided to go broader instead of deeper. Surprisingly, the breadth provided more depth to what I knew.</p>

<p>I zoomed out in 3 broad directions: learning what people around me are doing, learning good habits of mind, and acquiring new tools for thought.</p>

<h2 id="learning-what-people-around-me-are-doing">Learning what people around me are doing</h2>

<p>Since we’re not in a closed system, it makes sense to better understand the job of the product managers, the sales people, and the analysts. In the end it’s a business making money through products. The goal isn’t to write code, it’s to be a profitable business.<sup id="fnref:15"><a href="#fn:15">3</a></sup></p>

<p>Most big companies aren’t doing just one thing, which means there are different paths to making money in the same company. Everyone is on at least one path - if they weren’t, they wouldn’t be here.<sup id="fnref:1"><a href="#fn:1">4</a></sup> Tracking these paths, and the path I’m on was pretty valuable. It helped me see how I matter, and what levers I can pull to become more effective. Sometimes, it’s about making the sales jobs easier, so they can make more sales. Other times, it’s about building a new feature for clients. And some other times, it’s about improving a feature that keeps breaking.</p>

<p>Product managers are the best source for this. They know how the business makes money, who are the clients, and what do clients need.</p>

<p>Over the year, I setup quite a few meetings with everyone on my path. A second benefit this gave me was the context of other’s jobs. It helped me communicate better. Framing things in the right way is powerful.</p>

<p>For example, one conversation helped me appreciate why Sarah in Sales wants a bulk update tool. Some companies have lots of employees, and  updating them one by one is a pain. The code I write would literally ease Sarah’s pain.</p>

<!-- More recently, I got a chance to sit in on a few product scoping meetings between teams. This gave me a lot more appreciation for the job my PM and TLs do. Communication is surprisingly hard, and aligning different teams takes skill. -->

<!-- Force multiplier in team vs force multiplier in the entire chain. -->

<h2 id="learning-good-habits-of-mind">Learning good habits of mind</h2>

<p>Software engineering entails thinking well and making the right decisions. Programming is implementing those decisions.</p>

<p>A habit of mind is something your brain does regularly. This could be thinking of X whenever you see Y happen, or applying thinking tool X to problem Y. In short, habits of mind facilitate better thinking.</p>

<p>I suspected if I learn the general skill, I should be able to apply it better to software engineering.</p>

<h3 id="thinking-well">Thinking Well</h3>

<p>Software engineering is an excellent field to practice thinking well in. The feedback loops are shorter, and gauging correctness doesn’t take too long.</p>

<p>I dived into cognitive science studies. It’s a permanent skill that’s worth exploring - a force multiplier for whatever I end up doing, and pays dividends throughout my life. One output was <a href="https://neilkakkar.com/Bayes-Theorem-Framework-for-Critical-Thinking.html">a framework for critical thinking</a>. It’s compounding, <a href="https://neilkakkar.com/year-in-review-2019.html#compounding-is-powerful-building-intuition-for-compounding-even-more-so">and compounding is powerful</a>.</p>

<p>There’s lots of good things that came out of this, which I’ll talk about in a bit. They deserve their own section.</p>

<h3 id="strategies-for-making-day-to-day-more-effective">Strategies for making day-to-day more effective</h3>

<p>The other side of the coin is habits that allow you to think well. It starts with noticing little irritations during the day, inefficiencies in meetings, and then figuring out strategies to avoid them. These strategic improvements are underrated.</p>

<p>You decide what to do, and then let it run on automatic, freeing up the brain to think of more fun stuff. Of course, that’s what a habit is, too.</p>

<p>Some good habits I’ve noticed:</p>

<ul>
  <li>Never leave a meeting without making the decision / having a next action</li>
  <li>Decide who is going to get it done. Things without an owner rarely get done.</li>
  <li>Document design decisions made during a project</li>
</ul>

<p>This pattern became visible during the review, so I’m keen to pay attention and collect more strategies next year. Having an excellent scrum master who holds me accountable has helped me get better at following these strategies.</p>



<p>New tools for thought are related to thinking well, but more specific to software engineering. Tools for thought help me think better about specific engineering problems.</p>

<p>I’ve adopted a just-in-time approach to this. I look for new tools only when I get stuck on something, or when I find out my abstractions and design decisions aren’t working well.</p>

<p>For example, I was recently struggling with a domain with lots of complex business logic. Edge cases were the norm, and we wanted to design a system that handles this cleanly. That’s when I read about <a href="https://amzn.to/2FdCYUQ" target="_blank" rel="noopener">Domain Driven Design</a><sup id="fnref:25"><a href="#fn:25">5</a></sup>. I could instantly put it to practice and make a big difference. Subsequently, I grasped these concepts better. I acquired a new mental model of how to create enterprise software.</p>

<p>The second way I keep learning and acquiring new mental models is via reading what surfaces on Hacker News. They are interesting ideas, some of which I’ve put to practice, but this is a lot less effective than the technique above. The only reason I still do this is to <a href="https://neilkakkar.com/rationality.html#map-and-the-territory">map the territory</a> - it keeps me aware of techniques that exist, so when I face a problem, I know there’s a method that might help.</p>

<p>The final way I acquire better mental models is by learning new diverse languages. The diversity bit is important. Learning yet another dialect of lisp has a lot less benefit than say, learning C++03, a functional programming language, a dynamic typed language, and a lisp. Today, <a href="https://www.hillelwayne.com/post/j-notation/" target="_blank" rel="noopener">J seems interesting</a>, and one I might consider learning. It’s a thinking model I haven’t used before.</p>

<p>I’ve gotten lots of value from doing this. Each language has its own vocabulary and grammar, and <a href="https://neilkakkar.com/vocabulary-mental-model.html">vocabulary is a meta-mental model</a>. It’s a new lens to look at how to do things.</p>

<p>When memory management is in your control, you understand how pointers and allocators work. When Python then abstracts this away, you appreciate the complexity reduction. When maps and filters in a functional language show up, you appreciate how Python’s for loops can be improved. Indeed, that’s what list comprehensions are. And then you notice how some things are easier with object oriented programming. There’s no one magic tool that fits everything well. And then you understand that despite this, you don’t have to switch tools. You can adapt best practices from one into another to solve your problems: like writing functional javascript. It’s the principles that matter more than their expression.</p>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/divider.jpg" alt="">
    
    
    
</figure>

<p>Broadly, that’s all I did this year. What follow are insights that sprang forth thanks to zooming out.</p>

<h2 id="protect-your-slack">Protect your slack</h2>

<p>When I say slack, I don’t mean the company, but the adjective.</p>

<p>One thing that gives me high output and productivity gains is to “slow down”. Want to get more done? Slow down.</p>

<p>Caveats apply, but here’s what I mean:</p>

<p>I’ve noticed people rush to solve problems. It can be something they’ve done before, or something we have a template for. It feels pretty good to smash through things. I’ve done that before, too! However, there’s very specific cases where this makes sense.<sup id="fnref:11"><a href="#fn:11">6</a></sup></p>

<p>Whenever I’m working on something new, I take the time to learn things about the system I’m working on, and things closely related to it. If it’s too massive, I optimise for learning as much as I can. Every time I revisit the system, I aim to learn more.</p>

<p>When <a href="https://www.lesswrong.com/posts/yLLkWMDbC9ZNKbjDG/slack" target="_blank" rel="noopener">there is slack</a>, you get a chance to experiment, learn, and think things through. This means you get enough time to get things done.</p>

<p>When there is no slack, deadlines are tight, and all your focus goes into getting shit done.</p>

<p>Protecting your slack means not letting deadlines wrap tight around you. Usually, this is as simple (or hard) as communicating.<sup id="fnref:16"><a href="#fn:16">7</a></sup></p>

<p>Slack might have a negative connotation with “slackers”, but protecting slack is a super power. It’s a long term investment into building yourself up at the cost of short term efficiency.</p>

<p>When I’m quickly dishing out stories, I also have a much harder time fixing bugs. I don’t take the time to create proper mental models of the system, which means my assumptions don’t match the code, and this mismatch is where most bugs lie.</p>

<p>I protect my slack, so I can take the time out to prioritise …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neilkakkar.com/things-I-learned-to-become-a-senior-software-engineer.html">https://neilkakkar.com/things-I-learned-to-become-a-senior-software-engineer.html</a></em></p>]]>
            </description>
            <link>https://neilkakkar.com/things-I-learned-to-become-a-senior-software-engineer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24397269</guid>
            <pubDate>Mon, 07 Sep 2020 07:11:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tech Debt is an unfortunate abstraction, let's not use it]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24396959">thread link</a>) | @liveweird
<br/>
September 6, 2020 | https://no-kill-switch.ghost.io/tech-debt-is-an-unfortunate-abstraction/ | <a href="https://web.archive.org/web/*/https://no-kill-switch.ghost.io/tech-debt-is-an-unfortunate-abstraction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-post-id="5f554d9876722a003999c80f">
	

	<section>
		<p><em>Disclaimer: this blog post was triggered/inspired by an article you can find <a href="https://thehftguy.com/2020/08/26/technical-debt-doesnt-exist/">here</a>. I strongly encourage you to get familiar with it - whatever I put below is built on it as a foundation, so all the kudos go to <strong>The HFT Guy</strong>.</em></p><hr><p>Mental models are extremely powerful thought constructs. They do guide &amp; simplify our reasoning, but they also prime us. Bias us. And when treated as axioms, dangerously narrow down our thinking horizons.</p><p>All of the above applies to the popular concept of <strong>"technical debt" (TD)</strong>. I won't cover its meaning and history (there are tons of online materials on those) - instead, I'd like to focus on why the concept of TD is far less useful than we tend to think and actually quite harmful for our daily work.</p><p>Why so? Mainly because:</p><ol><li>there's no code w/o technical debt - TD is <strong>a "local" maintainability factor</strong> (a multiplier - that can span from very low to extremely high values) for a particular piece of a system; hence it's not separable from good (/healthy) code; consider it an inevitable "property" of any code</li><li>mentally dividing work between "fixing/fighting TD" and "developing features" usually leads to: never doing anything about TD and just going short-cuts all the time (<em>"I'll just do it the quick'n'dirty style, we'll need to refactor all that anyway ... some day"</em>)</li><li>we tend to brand as TD <strong>everything "we don't like at the moment"</strong> (a code written by someone else, a code that uses a library we find passé atm, etc.) - which leads to several types of immature &amp; unprofessional practices and massive wastes ("lava flow" effect, stacking unnecessary abstractions, etc.)</li><li>for the reasons stated above, TD is highly subjective and prone to individual judgment, hence nearly impossible to reliably quantify &amp; measure (regardless of whether you estimate the cost of its reduction or its actual impact on the development process); but it looks like <strong>a great candidate for a universal excuse</strong> (and it's frequently used that way)</li><li>it conveniently puts engineers in "we VS the debt" mode by giving the common enemy (that won't speak up) - some ephemeral "entity" you can stand in opposition to; this detail is important: no-one ever openly admits to the ownership over the TD, it just pops up out of the thin air and hinders the work of poor engineers ...</li></ol><p>Nevertheless, peeling TD out of its name won't make all its negative consequences disappear, right? Naming it explicitly at least makes discussing it (among engineers) easier &amp; (hopefully) more conclusive.</p><p>But maybe there's a better way to tame it? E.g. by ...</p><ul><li>... treating it as something inevitable (as there's no and there'll never be perfect, debt-less code)</li><li>... containing it within component/element/unit boundaries</li><li>... and coming up with a way to "reset" it (once in a while) within those local boundaries?</li></ul><p>I've already written (over four years ago) about some particular concept that can help with that - <a href="https://no-kill-switch.ghost.io/wiping-the-tech-debt-out-with-immutable-code/"><strong>the immutable code</strong></a>. It may sound weird at first glance, but apparently many companies adopt a similar standpoint:</p><ul><li>they create software with the EXPIRY date (on the level of module/component/piece) and re-create it every few years (because business/scale conditions do change anyway) - as a normal business-as-usual activity</li><li>they optimize not for "perfect architectures" but for future re-writes on the level of module/component/piece (e.g. by enforcing explicit contracts - so after a single component replacement, the whole system doesn't collapse like a house of cards)</li></ul><p>That's (creating with a re-write in mind) actually something I've already covered in <a href="https://no-kill-switch.ghost.io/are-the-software-product-companies-doomed-to-collapse/"><strong>the different post in the past</strong></a>, so feel free to reach there for more details.</p><p>Great! But what if my system wasn't written in a re-write-friendly way? What if there are no explicit contracts, dependencies are out of control, the only units of abstractions are the language's syntactic constructs (a flat list, w/o hierarchy or varying perspectives) and it's not possible to map certain capabilities/duties?</p><p>HA! And now we've reached a conclusion I was looking for - the main pre-requisite to build a future-proof solution with a TAMEABLE technical debt is ... <strong>by doing a deliberate design</strong>. It can be done up-front or in an evolutionary way - the mode doesn't matter that much. The truly crucial elements are:</p><ul><li>capability-driven composition (driven by purpose, function) with explicit boundaries and dependencies</li><li>the ubiquitous language used everywhere</li><li>wide (expressive) but shallow (w/o internal details) contracts treated as a binding promise to all the consumers</li></ul><p>That's also why so many attempts to reduce technical debt by purely technical refactoring (e.g. splitting big classes, harmonizing conventions, simplifying the flow in complicated procedures) are a pure waste w/o any noticeable positive long-term effect.</p>
	</section>

	
</article></div>]]>
            </description>
            <link>https://no-kill-switch.ghost.io/tech-debt-is-an-unfortunate-abstraction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24396959</guid>
            <pubDate>Mon, 07 Sep 2020 06:02:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Workflow for Publishing Articles]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24396916">thread link</a>) | @amitmerchant
<br/>
September 6, 2020 | https://www.amitmerchant.com/my-workflow-for-publishing-articles/ | <a href="https://web.archive.org/web/*/https://www.amitmerchant.com/my-workflow-for-publishing-articles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>After writing &amp; publishing articles for about two years (consistently), Iâ€™ve sort of created a system when it comes to publishing an article. From ideation to hitting the publish button.</p>

<p>Of course, this system is ever-evolving and over the years, Iâ€™ve tried to tweak it to suit my needs. And today, I think it has reached to a point where I can share it with you and allow you to peek into this very â€œsystemâ€�.</p>

<h2 id="ideation">Ideation</h2>

<p>A couple of years ago, when I started this blog, I was used to writing casually and back then i.e. I was only used to post articles whenever I feel like. But from the previous two years, things have changed. Iâ€™ve started to take it more seriously and started publishing articles quite frequently. Almost daily (of course, with a few exceptions).</p>

<p>You might be asking how Iâ€™ve started writing so much? And where do I get ideas from?</p>

<p>The answer to all these questions is <strong><em>â€œFrom teaching things to myselfâ€�</em></strong>. In a nutshell, whenever Iâ€™m in a situation where I donâ€™t get certain concepts correctly, I would first try to understand the topic thoroughly. And when things get clear for me, I would try to depict the concept in my words. In a way that can make me understand whenever I look upon it next time.</p>

<p>That means I primarily write articles for myself only. And if anyone gets benefitted from my articles, it would be an added bonus!</p>

<h2 id="writing-the-article">Writing the Article</h2>

<p>Next, for writing articles, Iâ€™m using <a href="https://code.visualstudio.com/">VS Code</a> because articles are written in <a href="https://daringfireball.net/projects/markdown/">Markdown</a> and nothing is better than the VS Codeâ€™s built-in support for Markdown in my opinion. To get started with a brand new article, all I need to do is whip up a blank Markdown file and pour my heart out in it. Itâ€™s as simple as that.</p>

<p>To make this even better, I use a VS Code extension called <a href="https://marketplace.visualstudio.com/items?itemName=yzhang.markdown-all-in-one">Markdown All in One</a> which add some essential things such as keyboard shortcuts, table of contents, auto preview, and more when it comes to Markdown. It saves tonnes of time fiddling around some Markdown quirks.</p>

<h2 id="fixing-the-article">Fixing the Article</h2>

<p>Once the article has been written, I head to <a href="https://www.grammarly.com/">grammarly.com</a> and paste in my entire article to check for spelling and grammatical mistakes. And once it detects those errors, it can fix those in a cinch.</p>

<p>On top of this, it also suggests alternative words and removal of unnecessary words which can make the entire reading experience a pleasant one.</p>

<blockquote>
  <p>Back then, I was not very concerned regarding making my articles grammar-correct. But over time, I realised itâ€™s important from the perspective of a reader because Iâ€™m also an avid reader myself. And so the grammar correction step entered into my workflow.</p>
</blockquote>



<p>Now is the time to create a nice social banner for the article. It looks something like so on Twitter.</p>

<p><img src="https://www.amitmerchant.com/images/social-banner-demo.png" alt=""></p>

<p>A lot of content creators ignore this but in my opinion, it is a really important thing if youâ€™re posting your articles across different social media platforms. It can make your article stand out because images can grab usersâ€™ attention more quickly than the text.</p>

<p>I use a service called <a href="https://crello.com/">Crello</a> where I create social banners every time I write a new article. The banner contains nothing but the title of the article but alas! in big and attention-grabbing fonts. Itâ€™s all handmade.</p>

<h2 id="publishing-the-article">Publishing the Article</h2>

<p>At this moment, everything is in the place and the article is ready to be published. For publishing the article, all it takes is a simple <code>git push</code> in my case as Iâ€™ve hosted my blog on GitHub Pages and it triggers the new build on every Git push.</p>

<p>Once the code is pushed, it would take 30-45 seconds to make the article live on the holy internet!</p>

<p>And that completes my entire workflow from <em>ideation</em> to <em>publishing an article</em>. Iâ€™ve been following this workflow from the past two years and it has suited me very well and Iâ€™m hoping the continue it for some more time!</p>

    </div></div>]]>
            </description>
            <link>https://www.amitmerchant.com/my-workflow-for-publishing-articles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24396916</guid>
            <pubDate>Mon, 07 Sep 2020 05:49:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Never Lose a Part Again, with the Ultimate Component Storage System]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24396611">thread link</a>) | @kevinqqsam
<br/>
September 6, 2020 | https://www.hackster.io/news/never-lose-a-part-again-with-the-ultimate-component-storage-system-00987cde6744 | <a href="https://web.archive.org/web/*/https://www.hackster.io/news/never-lose-a-part-again-with-the-ultimate-component-storage-system-00987cde6744">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><p><span>The creator of </span><a href="https://www.instructables.com/id/The-Ultimate-Component-Storage-System/" rel="nofollow">this project</a><span>, APTechnologies, came up with the idea for the storage cabinet by observing that he would run into trouble when organizing his component library. Rather than having to go across the workshop to get each part, he wanted a way to consolidate everything into one place for easy finding. The system works by first having the user search for a part on an adjacent screen, and then the associated bin will light up if the component is found in the system.</span></p><h3 id="toc-designing-the-cabinet-0"><a href="#toc-designing-the-cabinet-0"><i></i></a><span>Designing the Cabinet</span></h3><p>The storage solution is comprised of a 35 x 12 grid of drawers, which gives ample space for parts. The drawers are laid out according to the spacing between the LEDs in the strip (30 LEDs/meter). They are meant to be printed individually and then slotted in, plus they come in several different sizes.</p><h3 id="toc-fabrication-1"><a href="#toc-fabrication-1"><i></i></a><span>Fabrication</span></h3><p>Each drawer was 3D-printed on a Prusa Mk2S with PLA filament at a .2mm layer height. In order to minimize filament consumption, wall thicknesses are kept very thin, but even with this savings, 5kg of filament was required to fabricate the parts. There is also a small articulating arm that juts out from the side for the HDMI display.</p><h3 id="toc-software-2"><a href="#toc-software-2"><i></i></a><span>Software</span></h3><p>The primary way to interact with the system is through the terminal, which runs a Python 3 script. It begins by checking the text file for data integrity, where it then gets parsed and loaded into an object. Data is stored in CSV-style fashion, with the ID being the first column, the associated LEDs in the second, and finally the quantity in the third column. All subsequent values are optional and simply loaded by the user when the parts is located. A regex is used to parse the user's request, including searching for a component, changing its quantity, adding a new part, and removing a component.</p><h3 id="toc-electronics-3"><a href="#toc-electronics-3"><i></i></a><span>Electronics</span></h3><p>According to the project's creator, the choice for hardware components was quite straightforward. He used a Raspberry Pi 4 Model B in conjunction with a generic HDMI monitor to show the command line interface. For power delivery, he opted for a simple 5V adapter to power both the Raspberry Pi 4 and NeoPixel strip. Since the Pi outputs 3.3v signals from its GPIO pins, a level-shifter is needed, in this case a 74AHCT125. There is an option to use an Arduino Uno via UART if the NeoPixel strip is too unreliable, since the Arduino Uno can supply stricter timings.</p><h3 id="toc-usage-4"><a href="#toc-usage-4"><i></i></a><span>Usage</span></h3><p><span>To add a new part, the command </span><code>PI&lt;ledn&gt;:PI&lt;ledn+k&gt;, &lt;quantity&gt;[, optional parameters]:add</code><span> is sent, which adds a new component to the library. Other commands such as ID&lt;id number&gt; (search for part by ID) and ID&lt;id number&gt;:rm (remove part with that ID) exist to manage added components in the library.</span></p><h3 id="toc-possible-additions-5"><a href="#toc-possible-additions-5"><i></i></a><span>Possible Additions</span></h3><p>Although the system works well for one place and a small collection of components, it tends to scale poorly when there's a large library or multiple users want to interact with it. One way to solve this issue is to replace the single text file with a relational database such as MySQL, where parts can be stored and indexed in a single table, and other data can be referenced. This gives a very powerful interface for the software to easily search, add, and modify parts without having to read and rewrite the text file constantly.</p></div></section><section></section><div><div><a href="https://www.hackster.io/gatoninja236"></a><div><p><span><a href="https://www.hackster.io/gatoninja236">Arduino “having11” Guy</a><span></span></span></p><p>18 year-old IoT and embedded systems enthusiast. Also an interned at Hackster.io and love working on projects and sharing knowledge.</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.hackster.io/news/never-lose-a-part-again-with-the-ultimate-component-storage-system-00987cde6744</link>
            <guid isPermaLink="false">hacker-news-small-sites-24396611</guid>
            <pubDate>Mon, 07 Sep 2020 04:21:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[U.S. Blacklisting China's Chipmaker SMIC (Asia AI News)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24396448">thread link</a>) | @asiaainews
<br/>
September 6, 2020 | http://newsletter.asiaainews.com/issues/u-s-mulls-blacklisting-smic-biofourmis-raises-100m-via-softbank-others-275601 | <a href="https://web.archive.org/web/*/http://newsletter.asiaainews.com/issues/u-s-mulls-blacklisting-smic-biofourmis-raises-100m-via-softbank-others-275601">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://newsletter.asiaainews.com/issues/u-s-mulls-blacklisting-smic-biofourmis-raises-100m-via-softbank-others-275601</link>
            <guid isPermaLink="false">hacker-news-small-sites-24396448</guid>
            <pubDate>Mon, 07 Sep 2020 03:42:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The corporate / academic / public AI value gap]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24396354">thread link</a>) | @bpodgursky
<br/>
September 6, 2020 | https://bpodgursky.com/2020/09/07/the-corporate-academic-public-ai-value-gap/ | <a href="https://web.archive.org/web/*/https://bpodgursky.com/2020/09/07/the-corporate-academic-public-ai-value-gap/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>There is a huge gap between the benefits of Artificial Intelligence the public is being sold, the benefits of AI which are being marketed to corporate adopters, and the actual motivations of AI researchers.</p>



<ul><li>Tech providers pitch AI as a driver of innovation (self-driving cars) and global good (mitigating global warming).&nbsp; But the B2B case-studies pitched to corporate clients more often pitch AI solutions as <em>better automation, </em>mostly enabling cost-reduction (specifically, reducing human-in-the-loop labor).</li><li>While many AI researchers are motivated by genuine interest in improving the human condition, other motivations diverge — a desire to push the bounds of what we <em>can </em>do, a genuine belief in transhumanism (the desire for AI to replace, or transform into something entirely unrecognizable, humanity), or simply because AI pays bigly.</li></ul>



<p>These drivers — replacing human employment, and perhaps humans themselves — are, to put it mildly — not visions the public has bought into.</p>



<p>But these internal motivations are drowned out by the marketing AI pitch by which AI is sold to the public: “AI will solve [hunger/the environment/war/global warming]”.&nbsp; This leaves the people not “in the know” about AI progress — 99% of the population — not even <em>thinking </em>to use democracy to direct AI research towards a world the (average) person actually wants to live in.</p>



<p>This is not particularly fair.</p>



<p><strong>Marketed AI vs Profitable AI</strong></p>



<p>To the public, the tech giants selling AI solutions (Google, Microsoft, and Apple) pitch visions of AI <em>for good</em>.&nbsp;&nbsp;</p>



<p>The public face of these advertising campaigns is usually brand advertising, perhaps pitching consumers on a software ecosystem (Android, iOS), but rarely selling any specific product.&nbsp; This makes it easy to sell the public a <em>vision </em>of the future in HDR, backed by inspirational hipster soundtracks.</p>



<p>You all know what I’m talking about — you’ve seen them on TV and in movie theaters — but the imagery is so<em> honed, </em>so <em>heroic, </em>that we should look at the pictures anyway.</p>



<p>Google’s AI will do revolutionary things, like fix farming, improve birthday parties, and help us not walk off cliffs:&nbsp;</p>



<figure><img src="https://lh4.googleusercontent.com/jId-kNaiaBP0HNR6FjXXaS3HPKHoVr_tLUjEjjGS5sZ23IF1718IWzLeD719RSqO2Aj6vx3oDgeedE_Yjg5xcdNzl2IC71KP79uS0gUjyHSMEkLI1VALL8iqmwdhWXxTdGN7Qm2j" alt=""></figure>



<p>Microsoft’s AI is safe.&nbsp; You can tell because this man is looking <a href="https://www.microsoft.com/en-us/ai?activetab=pivot1%3aprimaryr5">very thoughtfully</a> into the distance:</p>



<figure><img src="https://lh5.googleusercontent.com/JKMsdtPMVmd5PHVOAgCleWpG4WctVm-3rGxiM70Tg0HsmDgdxYysjqjGR_zn0I8SEs-lLQxpOyKqxFI_RioIuGDGUFMillFX4T7IxZPI6jHpNiQ10YWpCoodiWli-Z8IxlRVFxq4" alt=""></figure>



<p>But if that is not enough to convince you, here is a bird:</p>



<figure><img src="https://lh5.googleusercontent.com/_NtL_Yy86NCoL4J_2kOpzAObYf9KTQ2D0i98JV4PnuAAE-yCqqAOXv7NGB_BSL8KJ-zBLGuiuqI5-fqmFkXLDVIONHPvvUWY6XWzjKC6D0LRaIVXjixdCWaidceDERUBRz-OyjP0" alt=""></figure>



<p>Microsoft goes into detail on their “AI for Good” page.&nbsp; The testimonials highlight the power of AI as applied to:</p>



<ul><li>Environmental sustainability (image recognition of land use, wildlife tracking, maximizing farm yields)</li><li>Healthcare (dredging through data to find diseases)</li><li>Accessibility (machine translation, text to speech)</li><li>Humanitarian action and Cultural Heritage preservation</li></ul>



<p>Even the Chinese search engine Baidu, not exactly known for their humanitarian work, <a href="https://internetofbusiness.com/baidu-becomes-first-chinese-firm-to-join-us-safe-a-i-consortium/">has joined</a> the OpenAI “safe AI” consortium, which is nominally dedicated to developing and selling only <em>safe </em>AI.</p>



<p>The theme among all these public “good AI” initiatives — the sales pitch to the public — is:</p>



<blockquote><p>“We’re developing advanced AI, but we’re partnering with NGOs, hospitals, and more, to make this AI work <em>for </em>people, not against them.&nbsp; Look at all the good we can do!”</p></blockquote>



<p>This isn’t fake.&nbsp; Microsoft <em>is </em>working with nonprofits, NGOs, and more, to deploy for-the-people AI.&nbsp; But these applications don’t get us closer to the <em>real </em>question:</p>



<p>“What solutions are <em>normal</em> companies <em>actually deploying </em>with AI-as-a-service cloud technology?”</p>



<p>We can peek behind the curtain at Amazon.&nbsp; Amazon’s AWS has been for the last decade synonymous with “the cloud”, and still has a full 50% market share.&nbsp; The bleeding edge of AWS are plug-and-play machine learning and AI tools: Amazon Forecast (machine learning), Amazon Polly (text to speech), Amazon Rekognition (video object recognition), Amazon Comprehend (natural language processing), and more.</p>



<p>And Amazon, alone and refreshingly among tech giants, <a href="https://www.computerworld.com/article/3463071/aws-is-ethical-about-ai-but-we-just-don-t-talk-about-it-say-apac-execs.html">doesn’t even pretend</a> to care why their customers use AI:</p>



<blockquote><p>“We certainly don’t want to do evil; everything we’ve released to customers to innovate [helps] to lift the bar on what’s actually happening in the industry. It’s really up to the individual organisation how they use that tech”</p></blockquote>



<p>Amazon sells AI to C-suites, and we know what the hooks are, because the marketing pitches are online.&nbsp; AWS <a href="https://aws.amazon.com/machine-learning/customers/?customer-references-cards.sort-by=item.additionalFields.publishedDate&amp;customer-references-cards.sort-order=desc&amp;awsf.customer-references-category=category%23ai-ml&amp;awsm.page-customer-references-cards=2">publishes case studies</a> about how their plug-and-play AI and ML solutions are used by customers.&nbsp;</p>



<p>We can look at a typical example <a href="https://aws.amazon.com/solutions/case-studies/dxc/?did=cr_card&amp;trk=cr_card">here</a>, outlining how DXC used AWS’s ML and AI toolkits to improve customer service call center interactions.&nbsp; Fair warning:&nbsp; the full read is catastrophically boring — which is to be expected when AI used not to expand the horizon of what is possible… but instead used to excise human labor from work which is already being done:</p>



<blockquote><p>“DXC has also reduced the lead time to edit and change call flow messaging on its IVR system. With its previous technology, it took two months to make changes to IVR scripts because DXC had to retain a professional voice-over actor and employ a specialized engineer to upload any change. With Amazon Polly, it only takes hours”</p></blockquote>



<blockquote><p>Using Amazon Connect, DXC has been able to automate password resets, so the number of calls that get transferred to an agent has dropped by 30–60 percent.</p></blockquote>



<blockquote><p>DXC anticipates an internal cost reduction of 30–40 percent as a result of implementing Amazon Connect, thanks to increased automation and improved productivity on each call.</p></blockquote>



<p>In total, what did DXC do with its deployed AI solution?&nbsp; AI is being used to:</p>



<ul><li>Replace a voice-over actor</li><li>Eliminate an operations engineer</li><li>Eliminate customer service agents</li></ul>



<p>There’s nothing evil in streamlining operations.&nbsp; But because of the split messaging being used to <em>sell </em>AI research to the public vs to industry — on one hand, visions of environmental sustainability and medical breakthroughs, and on the other hand, the mundane breakthrough of applying a scalpel to a call center’s staffing — the public has little insight (other than nagging discomfort) into automation end-game.&nbsp;&nbsp;</p>



<p>The complete lack of (organized) public anger or federal AI policy — or even an <em>attempt </em>at a policy — speaks to the success of this doublespeak.</p>



<p><strong>Research motivations</strong></p>



<p>So why are actual engineers and researchers <em>building </em>AI solutions?</p>



<p>I could dredge forums and form theories, but I decided to just <a href="https://www.reddit.com/r/artificial/comments/gz5so7/why_are_you_personally_working_on_ai/">ask on reddit</a>, in a quick and completely unscientific test.&nbsp; Feel free to read all the responses — I’ve tried to aggregate them here and distill them into the four main themes.&nbsp; Weighted by upvotes, here’s the summary:</p>



<figure><img src="https://lh4.googleusercontent.com/DvF1XOwrQOuSnpwX0z5y1YLq3keBLTdqSQqyOKj1FrdmNANo2gVWZXWjHnp282aio1EzBBfWMYNPfof4MKZDdeJoQKe18Znbw0jI-iI2QxmmeVkF-MTWGGOsnF1xAaSlMUCtiilV" alt=""></figure>



<p>Preface: none of these are radical new revelations.&nbsp; They match, in degrees, what you’d find with a more exhaustive dragnet of public statements, blogs, or after liquoring up the academic research mainstream.</p>



<p>Walking down the list:</p>



<p><strong>1. Improving the human condition</strong></p>



<p>A plurality goal is to better the human condition, which is promising.&nbsp; An archetypal response is a vision of a future without work (or at least, without universal work):</p>



<blockquote><p>“I believe the fundamental problem of the human race is that pretty much everyone has to work for us to survive.</p><p>So I want to work on fixing that.”</p></blockquote>



<p>It’s not a vision without controversy — it’s an open question whether people can really live fulfilled lives in a world where they <em>aren’t</em> <em>really needed —</em> but at minimum it’s a vision many could get behind, and is at root predicated in a goal of human dignity.</p>



<p><strong>2. It pays</strong></p>



<p>Close behind are crude economics.&nbsp; Top comment:</p>



<blockquote><p> “Dat money”</p></blockquote>



<p>I don’t intend to sound negative — capitalism is the lever which moves the world, and in capitalism, money follows value.&nbsp; But as shown by AWS, value can come from either revolutionary invention (delivering novel value), or cost excision (delivering <em>cheaper </em>value).</p>



<p>Either direction pays the bills (and engineers), and few megacorp engineers care to peek behind the curtain at which specific aspect of the AI product delivered to clients pays the bills.</p>



<p><strong>3. Transhumanism</strong></p>



<p>Here’s where the interests of true believers in AI diverge from the mainstream.&nbsp; Top comment:</p>



<blockquote><p>“I don’t really care about modern ML solutions, I am only concerned with AGI. Once we understand the mechanisms behind our own intelligence, we move to the next phase in our species’ evolution. It’s the next paradigm shift. Working on anything else wouldn’t be worth it since the amount of value it brings is so vast.”</p></blockquote>



<p>“I’m in it for the money” is just realism.&nbsp; “A world without work” and “making cheddar” are motivations which appeal to the mainstream, and is at least comprehensible (if frustrating) to those whose jobs are on the line.&nbsp;&nbsp;</p>



<p><a href="https://en.wikipedia.org/wiki/Transhumanism">Transhumanism</a> is different.&nbsp; There’s a prevalent (although possibly not majority) philosophy among many AI researchers, practitioners, and enthusiasts, that the goal of developing strong (human-level) AI is not a tool <em>for </em>humans, but an end unto itself.&nbsp; The goal is the creation of a grander intelligence beyond our own:</p>



<blockquote><p>“Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an ‘intelligence explosion,’ and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make.”</p></blockquote>



<p>Or, step-by-step:</p>



<ul><li>Humans create AI 1.0 with IQ human + 1</li><li>AI 1.0 creates AI 2.0, which is slightly smarter</li><li>AI 2.0 creates AI 3.0, which is WAY smarter</li><li>AI 3.0 creates AI 4.0, which is incomprehensibly smarter</li></ul>



<p>And whatever comes next… we can’t predict.</p>



<p>This is not a complete summary of transhumanism.&nbsp; There’s a spectrum of goals, and widespread desire for AI which can integrate <em>with</em> humans — think, nanobots in the brain, neural augmentation, or wholesale digital brain uploads.&nbsp; But either way — whether the goal is to retrofit or replace …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bpodgursky.com/2020/09/07/the-corporate-academic-public-ai-value-gap/">https://bpodgursky.com/2020/09/07/the-corporate-academic-public-ai-value-gap/</a></em></p>]]>
            </description>
            <link>https://bpodgursky.com/2020/09/07/the-corporate-academic-public-ai-value-gap/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24396354</guid>
            <pubDate>Mon, 07 Sep 2020 03:20:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[David Graeber on harmful jobs, odious debt, and fascists who mind global warming]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24396247">thread link</a>) | @kunfuu
<br/>
September 6, 2020 | https://www.disenz.net/en/david-graeber-on-harmful-jobs-odious-debt-and-fascists-who-believe-in-global-warming/ | <a href="https://web.archive.org/web/*/https://www.disenz.net/en/david-graeber-on-harmful-jobs-odious-debt-and-fascists-who-believe-in-global-warming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>It was a warm spring evening in London and David Graeber, an anthropology professor at the LSE, was sitting on a rooftop. Our conversation was transmitted through the Internet because of the global travel ban due to the coronavirus pandemic. However, we did not only talk about the new virus and its consequences for society, politics, and the economy. We took the rare opportunity to discuss most of his published works – from the <em>Fragments of Anarchist Anthropology</em> and <em>Debt</em> to <em>Utopia of Rule</em>s, and his most recent book <em>The Bullshit Jobs</em>. All of which have become even more relevant during the corona-crisis.</p>



<p>Professor Graeber presents himself as an anthropologist and anarchist. However, he will not be happy if you refer to him as an “anarchist anthropologist” because there is no such discipline, which he explained during the conversation. The professor is also an activist. He joined many social movements and protests in the last few decades and is often credited as the author of the unofficial slogan from the Occupy Wall Street movement: We are the 99 percent. But he insists that the slogan – as well as everything else in the movement – was a collective effort.</p>



<p>How can democratic governments use this health crisis to enforce authoritarian measures on their citizens? Why don’t the health and care workers strike, during the pandemic, for higher wages? What would happen if we closed Wall Street for a few months? Why do we only see flying cars as special effects in science fiction movies? How can anarchistic principles bring order into chaos during the crisis? Why do we not want to depend on the Chinese and US armies to save our planet?</p>



<p>And finally – how can a drunken rant become a best-selling book?</p>



<figure><img src="https://www.disenz.net/wp-content/uploads/2020/05/DG-in-office-IMG_2027.JPG-1-2-768x1024.jpeg" alt="" width="561" height="748" srcset="https://www.disenz.net/wp-content/uploads/2020/05/DG-in-office-IMG_2027.JPG-1-2-768x1024.jpeg 768w, https://www.disenz.net/wp-content/uploads/2020/05/DG-in-office-IMG_2027.JPG-1-2-225x300.jpeg 225w, https://www.disenz.net/wp-content/uploads/2020/05/DG-in-office-IMG_2027.JPG-1-2-rotated.jpeg 864w" sizes="(max-width: 561px) 100vw, 561px"><figcaption>David Graeber in his office</figcaption></figure>



<p><strong>Everybody seems to be speaking the same language during the coronavirus pandemic – from progressive and conservative governments to ISIS and the anarchists: stay at home, wash your hands, avoid other people … And people have been listening to the officials without much protest. They stayed at home and accepted the new rules. We have not seen anything like this for a long while. What has happened?</strong></p>



<p>Well, there are just not all that many people who are quite crazy enough to ignore medical advice during a pandemic.</p>



<p>It brings to mind the 19<sup>th</sup> century French political thinker Henry Saint-Simon—who might have been the first person to come up with the notion of withering away of the state. He argued that if the state was refounded on scientific basis, eventually it would not need to rely on coercion, and therefore, it wouldn’t even be a state in the contemporary sense of having a monopoly of violence.</p>



<p><strong>Why?</strong></p>



<p>For the same reason, he said, that doctor doesn’t have to threaten to beat you up to convince you to the medicine they prescribe. You know the doctor knows something you don’t know, and you assume the doctor is acting in your best interest. Saint-Simon argued once the state was rationally founded on scientific principles, citizens would act in the same way, and coercive enforcement would become unnecessary. Maybe they’d be a few nutty people who refuse to take their medicine but not enough to make much difference.</p>



<p>Obviously this was all very optimistic and naive—that’s why Marx dismissed people like Saint Simon as “utopian socialists”. But there are certain branches of the government that still claim to operate on such basis. And one could make the argument that they’re not by their nature part of government at all.</p>



<p>During the student movement in the UK in 2010 we talked about this a lot, we were mostly anarchists, but we believed in a public health system, and a public university system. Was this hypocritical? None of us felt it was, but we talked a lot about why. Perhaps the problem is that states don’t allow the existence of public institutions – that is, ones which are both universal and non-profit-oriented – that they don’t control. That doesn’t mean those institutions are somehow of the same nature as the army, or prison system, which are entirely creatures of the state.</p>



<blockquote><p>The idea that knowledge is always a form of power is very flattering to academics, who have a great deal of one and very little of the other, so it’s hardly surprising they like it so much.</p></blockquote>



<p><strong>Yes and of course Foucault would say the authority that does not need a violent force to enforce itself is the scariest kind of all.</strong></p>



<p>He would. Though I think Foucault is often misinterpreted in this regard, to assume that any truth discourse is a form of power, and every form of power is violent and objectionable in itself. True, he sometimes sounds as if that’s what he’s saying. But if specifically challenged, he’d always say, no, no, obviously not.</p>



<p>The idea that knowledge is always a form of power is very flattering to academics, who have a great deal of one and very little of the other, so it’s hardly surprising they like it so much. Foucault himself had his own immediate concerns – he was diagnosed as a homosexual in his youth, and wanted to understand how it came about that his most intimate desires could be considered a disease.</p>



<p>He effectively dedicated his life to trying to understand that. But many on the academic left forget that, such diagnoses were not just abstractions, they ultimately relied on force of law, on the threat of physical violence, even if the doctor isn’t personally carrying a gun. A kind of vulgar Foucauldianismn has encouraged us to overlook how much the threat of force really does still lurk behind most of the institutions he describes.</p>



<p>The Panopticon was a prison after all. Normally if you think someone might be staring at you at any moment, you just go someplace else. Actually things have gotten rather worse in that respect since Foucault’s time. There didn’t used to be actual armed guards in schools and hospitals; now in many places there are.</p>



<p><strong>Many governments all over the world are using public health to enforce measures that could not have been imaginable in democratic societies only a few months ago. In Slovenia, for example, individuals are fined when they try to protest against the government actions. Not for protesting, of course. That would be undemocratic. But for violating the law on infectious diseases. So the only groups of people that are allowed move freely are the police, the army, and the politicians.</strong></p>



<p>That does not surprise me. You can learn a lot of things about your state by comparing how they treat a political assembly, and any other kind.</p>



<p><strong>In what way?</strong></p>



<p>In liberal democracies, the entire justification for a country’s legal structure is, typically, some kind of ideal of human freedom and liberty. The American bill of rights begins with the freedom of speech, freedom of press, and freedom of assembly. In practice, the assembly of people that gather in order to protest – which is the very essence of what is supposed to be American – is considered <em>less</em> legitimate than an assembly of people who want to sell you something.</p>



<p>You point this out to most middle-class Americans, they seem incredulous. Poor ones not so much, they don’t assume the rules are fair. Anyway: they’ll say “but of course you have the right to assemble, you just need a permit, what’s wrong with that?” So you have to say “all right, if you have to ask police permission to print something, that’s called not having freedom of the press. If you have to ask police permission to say something..” And they’ll say, “but that’s different! There are traffic issues. You can’t just gather. It gets in the way of people walking down the street” Which is funny, because I don’t remember anywhere in the constitution it says anything about the right to unimpeded traffic flow.</p>



<p>We learned that lesson during the Occupy movement. It was startling, after they evicted our camp, how many middle class Americans just shrugged their shoulders when they went on to rip up the Bill of Rights, the very thing they teach their children to be so proud of…</p>



<blockquote><p>The Anonymous movement has shown that you can have meaningful and impactful protests online. And people all across the world are inventing new ways to protest from their home.</p></blockquote>



<p><strong>You were trying to occupy a public space?</strong></p>



<p>Any space. After they evicted us from Zuccotti Park, we tried to reestablish a new camp because… well, it was crucial that everyone knew where we were. That was what was so effective about the original occupation: anyone in the city who felt they wanted to get involved knew where they could go and plug in instantly.</p>



<p>At first we thought we could relocate to a huge lot near Wall Street that belong to the Episcopalian Church, they agreed, but huge pressure was place on the Church hierarchy and eventually they reversed themselves. We had a march led by several bishops trying to occupy anyway; the cops beat us up, and the media refused to show any footage of the priests but only anyone in masks to make us look violent and scary.</p>



<p>Then we occupied a park that was open all night and they changed the rules of the park. We then got a legal ruling from a judge that we could sleep on the sidewalk as long as we do not take more than half of it. So the city just passed an order that Lower Manhattan was an emergency zone where legal decisions do not apply. So we decided to occupy the stairs of the building where the Bill of Rights was actually signed, which is right near Wall Street incidentally, but wasn’t under city jurisdiction. We were immediately were surrounded by SWAT teams and after two days they found a way to force us from there.</p>



<p>We tried everything to set up a legal alternative. But the state completely simply shredded the very legal principles that they teach children are what makes them proud to be Americans, and the media didn’t even cover it.</p>



<p><strong>But what can you occupy when you are not allowed to even leave your own apartment?</strong></p>



<p>There are always things you can do. The Anonymous movement has shown that you …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.disenz.net/en/david-graeber-on-harmful-jobs-odious-debt-and-fascists-who-believe-in-global-warming/">https://www.disenz.net/en/david-graeber-on-harmful-jobs-odious-debt-and-fascists-who-believe-in-global-warming/</a></em></p>]]>
            </description>
            <link>https://www.disenz.net/en/david-graeber-on-harmful-jobs-odious-debt-and-fascists-who-believe-in-global-warming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24396247</guid>
            <pubDate>Mon, 07 Sep 2020 02:52:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My thoughts about editors in 2020]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24395863">thread link</a>) | @todsacerdoti
<br/>
September 6, 2020 | https://phaazon.net/blog/editors-in-2020 | <a href="https://web.archive.org/web/*/https://phaazon.net/blog/editors-in-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><h2><em>editor, vim, neovim, atom, vs-code, emacs, intellij-idea</em></h2><h2>2020-09-07 00:03:00 UTC, by Dimitri Sabadie — <a href="https://phaazon.net/blog/feed">feed</a></h2><hr><div><p>I have been trying a lot of editors lately. When I say “trying”, I really meant I spent some time configuring and using those editors. The ones I spent time using are:</p>
<ul>
<li><a href="https://neovim.io/">neovim</a>, my main, daily editor I use for pretty much almost all projects I work on.</li>
<li><a href="https://www.jetbrains.com/idea">IntelliJ IDEA</a>, that I currently use at work to hack on Java codebases.</li>
<li><a href="https://code.visualstudio.com/">VS Code</a>, that I have been trying mainly in Rust, TOML and Markdown.</li>
<li><a href="https://www.gnu.org/software/emacs">emacs</a>, that I highly hacked around to play on my Haskell and Rust codebases (and YAML / Markdown / TOML too).</li>
<li><a href="https://github.com/hlissner/doom-emacs">DOOM Emacs</a>, that I tried when I saw a colleague in a previous company I worked in (I was impressed by the “united” feeling of the UI and by how everything looked so slick). So I gave it a try.</li>
<li><a href="https://atom.io/">atom</a>, <a href="https://github.com/">GitHub</a>’s take on editors. Same thing, mostly Rust, Haskell, etc.</li>
<li>A bunch of others that I won’t talk about because I quickly stopped using.</li>
</ul>
<p>The goal of this article is to create a temporal “snapshot” of my views on editors and what I think about the current situation. I have been using vim and especially neovim for more than a decade. I need to explain about my current workflow and what I cherish in editing before talking about each editors. Expect a point of view from a neovimer which is looking around at lots of editors.</p>
<blockquote>
<p>This is only a personal workflow / point of view that works well <em>for me right now</em>. It doesn’t mean it will for you and it doesn’t mean a different workflow would be worse.</p>
</blockquote>
<!-- vim-markdown-toc GFM -->
<ul>
<li><a href="#what-i-think-powerful-editing-should-be">What I think powerful editing should be</a>
<ul>
<li><a href="#keyboard-layout">Keyboard layout</a></li>
<li><a href="#modal-editors">Modal editors</a></li>
<li><a href="#how-i-like-to-move-around">How I like to move around</a></li>
<li><a href="#all-the-other-modal-candies">All the other modal candies</a></li>
</ul></li>
<li><a href="#the-editors">The editors</a>
<ul>
<li><a href="#neovim">neovim</a>
<ul>
<li><a href="#my-neovim-setup">My neovim setup</a></li>
<li><a href="#what-i-like-about-neovim">What I like about neovim</a></li>
<li><a href="#what-i-dislike-about-neovim">What I dislike about neovim</a></li>
</ul></li>
<li><a href="#intellij-idea">IntelliJ IDEA</a>
<ul>
<li><a href="#what-i-like-about-intellij-idea">What I like about IntelliJ IDEA</a></li>
<li><a href="#what-i-dislike-about-intellij-idea">What I dislike about IntelliJ IDEA</a></li>
</ul></li>
<li><a href="#vs-code">VS Code</a>
<ul>
<li><a href="#what-i-like-about-vs-code">What I like about VS Code</a></li>
<li><a href="#what-i-dislike-about-vs-code">What I dislike about VS Code</a></li>
</ul></li>
<li><a href="#emacs-and-doom-emacs">emacs and DOOM emacs</a>
<ul>
<li><a href="#what-i-like-about-emacs--doom-emacs">What I like about emacs / DOOM emacs</a></li>
<li><a href="#what-i-dislike-about-emacs--doom-emacs">What I dislike about emacs / DOOM Emacs</a></li>
</ul></li>
<li><a href="#atom">atom</a>
<ul>
<li><a href="#what-i-like-about-atom">What I like about atom</a></li>
<li><a href="#what-i-dislike-about-atom">What I dislike about atom</a></li>
</ul></li>
</ul></li>
<li><a href="#wrap-it-up">Wrap it up</a></li>
</ul>
<!-- vim-markdown-toc -->

<h2 id="keyboard-layout">Keyboard layout</h2>
<p>I am French and I’m using a keyboard layout that is made to type very quickly in French and to code. With hindsight, since I type more often in English than in French, maybe I should have picked another keyboard layout, but the coding experience in my keyboard layout is really great, so I stick around.</p>
<p>The keyboard layout is <strong>bépo</strong>. I learned bépo the “recommended” way — i.e.&nbsp;you have to practice <em>typing</em> (« dactylographie » in French). It means that I use all my fingers to type on a keyboard, and that each key on the keyboard is assigned <em>a single finger</em> that will press it. That helps a lot with muscle memory and to reduce wrist pain (my wrists barely move when I type on a keyboard), among other things. The typing speed is a side-effect of being accurate and having good comfort (if you are curious, I’m pretty fast but there are faster people — I type at around 120 to 130 words per minute). Because I think the speed doesn’t matter when programming, I think the most important part to remember here is the comfort: the wrists don’t move and my fingers fly around the keyboard, whatever the speed.</p>
<h2 id="modal-editors">Modal editors</h2>
<p>I think a modal editor is superior, for various reasons. The first one is that I truly <strong>hate</strong> having to use a <em>mouse</em> for something that can be done without having to move around hundred of pixels with your cursor and clicking on buttons. For instance, running an application, on my current machines, is simply typing <code>alt d</code>, the name of the program (I typically use completion, so I never type fully the name of the program) and hit enter. All this without moving my hands from the keyboard. And I do that for programs like <code>firefox</code>, <code>kdenlive</code>, etc. but for terminal applications, I simply type and complete them in my terminal, which I open simply with <code>alt return</code>.</p>
<p>So, using a mouse to move around a cursor in an editor feels like completely suboptimal to me, especially because we write code (i.e.&nbsp;we type on a keyboard) most of the time, so moving around with the mouse implies several back and forth movements between the keyboard and the mouse. Maybe you don’t care and it’s cool to you, but to me, this is truly <em>horror land</em>. I feel <em>very</em> uncomfortable when doing this.</p>
<p>Also, <em>modern editors</em> that are not modal typically make people move by using the arrows keys, which are either far on your keyboard, or — like my keyboard, a 60% home made one — not in direct access and then require a function key to enable them.</p>
<p>So that’s the first reason why I like modal editors. They make a smarter use of your keyboard for simple yet recurrent features, like moving around — e.g.&nbsp;<code>h j k l</code>. The second reason why I like them is because of the facts they have a completely new mode for non-modal editor (i.e.&nbsp;the <em>normal</em> mode), you have a whole keyboard / lots of keys to bind actions to and do lots of things people usually do with the mouse. Being able to split an editor into several buffers, move around the buffers, go at the beginning of the paragraph, search and replace, register actions into macros and replay them, etc. All this without even moving the wrists. The learning curve is steep if you’re used to the mouse, but once you’ve passed the mental barrier, really, and this is a personal opinion, but I truly think that using the mouse again after that feels like handicap to me.</p>
<h2 id="how-i-like-to-move-around">How I like to move around</h2>
<p>When I look at people coding, I see several kind of programmers:</p>
<ul>
<li>The ones who move with the arrows or with <code>h j k l</code> in modal editors. You can spot them very easily at how the cursor moves in a document. It typically implies keeping a key pressed until the cursor reach a given row, then pressing another key until the cursor reach a given column and then adjust if they went passed the location they had in mind.</li>
<li>People using the mouse, by clicking at the place they want to put the cursor at.</li>
<li>People using <em>relative numbers</em>. That’s an enhancement of the first group: they typically use relative numbers to know which lines they want to jump to very quickly, so that they don’t have to press the up / down keys for ages until reaching the line they want to. Instead, they look at the number on the lines, press that number, and the direction, and bam, they are on the lines. They then use typical motions from vim like <code>$</code> (go to end of line), <code>f</code> (go to the first occurrence of the next character typed after <code>f</code>, like <code>f(</code> will make your cursor go to the next <code>(</code>), <code>%</code> (go to the matching delimiter) or <code>w</code> (go to the beginning of the next word) / <code>b</code> (go to the beginning of the previous word), etc. to move faster on the same line (it works across lines too).</li>
</ul>
<p>I think that represents 99,9% of what I see people do. Obviously, you will get that I don’t belong to the second set of people… but I don’t really belong to any, actually. How I move is, I guess, convoluted for most people and I know some people won’t understand how it can feel. I use <code>h j k l</code> and all the motions from vim described in the third group (and even more; I full lecture of four hours would be required to explain all of them :D), but it all depends on the <em>distance</em> I need to travel. If my cursor is on a word and I want to move to the beginning of a word located very closely to my cursor on the same line, I’ll simply type <code>www</code> if it’s three words apart (or <code>3w</code> if I’m feeling funny). If the distance is higher, I use a tool called [EasyMotion].</p>
<p>Easymotion really is a wonderful tool. The idea is that it has several modes, depending on the kind of move you want to perform:</p>
<ul>
<li><em>By lines</em>: this mode allows you to jump to any line in the current (or all open) buffers.</li>
<li><em>By words</em>: tihs mode allows you to jump to any “word” in the current (or all open) buffers.</li>
<li><em>By characters</em>: when the <em>word</em> mode doesn’t help with jumping to a special operator or character (because it’s not recognized as a word), this mode allows you to jump to any character in the current or (or all open) buffers.</li>
<li>It has other modes but I have never really found useful cases for them.</li>
</ul>
<p>The way I typically do it is by mapping the three modes to <code>&lt;leader&gt;l</code>, <code>&lt;leader&gt;w&gt;</code> and <code>&lt;leader&gt;c</code> (in my case, <code>&lt;leader&gt;</code> is the <em>space</em> key).</p>
<p>Typing <code>SPC l</code> in my current buffer results in this:</p>
<figure>
<img src="https://phaazon.net/media/uploads/easymotion_lines.png" alt=""><figcaption>EasyMotion lines</figcaption>
</figure>
<p>Typing any highlighted character will make my cursor jump to it. The same applies for words, with <code>SPC w</code>:</p>
<figure>
<img src="https://phaazon.net/media/uploads/easymotion_words.png" alt=""><figcaption>EasyMotion words</figcaption>
</figure>
<p>For the <em>character</em> mode, after pressing <code>SPC c</code>, I have to press another character (the one I want to jump to). Let’s say we want to jump to a <code>#</code> (which is not part of words): <code>SPC c #</code>:</p>
<figure>
<img src="https://phaazon.net/media/uploads/easymotion_chars.png" alt=""><figcaption>EasyMotion characters</figcaption>
</figure>
<p>This way of moving is not intuitive at first, but once you get used to it… it’s a <em>must have</em>.</p>
<h2 id="all-the-other-modal-candies">All the other modal candies</h2>
<p>Among all the things that I like about modal editing, here is a non-exhaustive list of features I expect to have around my fingers:</p>
<ul>
<li><code>C-i</code> and <code>C-o</code>: those allows me to jump to something / a file / a place in a buffer and then go back to where I was right before with <code>C-o</code> (read it like <em>out</em>) or go back again with <code>C-i</code> (read it like <em>in</em>).</li>
<li>Macros and registers: those allow me to yank content into different registers (like clipboards) by assigning a single key to paste their content. For instance, I can put a few lines in my <code>t</code> register with <code>"tyi(</code> (“put in the <code>t</code> register the <code>y</code>ank <code>i</code>nside matching <code>(</code>), and paste that content later with <code>"tp</code>. Macros allow more powerful editing control by assigning a key to set of actions with the <code>q</code> keyword (<code>qa</code> will register all the next keystrokes and actions into the <code>a</code> macro). Then simply replay the macro with <code>@a</code>, for instance.</li>
<li>Obviously, all the basic vim motions, like <code>d</code> to delete, <code>y</code> to yank, <code>c</code> to change, <code>t</code> to go to the character right before the one you search, <code>%</code> to go to the other delimiter, etc. And more complex text manipulation, such as “Let’s change what’s inside this function parameter list, delimited by <code>(</code>”: <code>ci(</code>.</li>
</ul>
<p>It would take too much time to list everything, but the main idea is: I need the modal features when editing code.</p>

<p>So let’s talk about the list of editors I mentioned in the preface. The idea is to give <em>my own opinion</em> on those …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://phaazon.net/blog/editors-in-2020">https://phaazon.net/blog/editors-in-2020</a></em></p>]]>
            </description>
            <link>https://phaazon.net/blog/editors-in-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24395863</guid>
            <pubDate>Mon, 07 Sep 2020 00:50:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostgreSQL B-Tree index deduplication]]>
            </title>
            <description>
<![CDATA[
Score 183 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24395825">thread link</a>) | @petergeoghegan
<br/>
September 6, 2020 | https://blog.rustprooflabs.com/2020/09/postgres-beta3-btree-dedup | <a href="https://web.archive.org/web/*/https://blog.rustprooflabs.com/2020/09/postgres-beta3-btree-dedup">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <p>By Ryan Lambert -- Published September 06, 2020</p><p>PostgreSQL 13 development is coming along nicely, Postgres 13 Beta3 was
<a href="https://www.postgresql.org/about/news/2060/">released on 8/13/2020</a>.
The Postgres Beta 1 and 2 releases were released in May and June 2020.
One of the features that has my interest in Postgres 13 is the B-Tree deduplication effort.  B-Tree indexes are the default indexing method
in Postgres, and are likely the most-used indexes in production 
environments.
Any improvements to this part of the database are likely to have wide-reaching benefits.
Removing duplication from indexes keeps their physical size smaller,
reduces I/O overhead, and should help keep <code>SELECT</code> queries fast!</p>
<!--endteaser-->

<blockquote>
<p>This post is part of the series <a href="https://blog.rustprooflabs.com/2018/06/pg-series-toc"><em>PostgreSQL:  From Idea to Database</em></a>.</p>
</blockquote>
<p>There is a good summary of the what and how of this improvement
in <a href="https://www.cybertec-postgresql.com/en/b-tree-index-deduplication/">Laurenz Albe's post</a> from early in June 2020, presumably using
Pg13 Beta1.  <a href="https://www.highgo.ca/2020/07/06/features-in-pg13-deduplication-in-b-tree-indexes/">Hamid Akhtar's post in July</a>
covered this feature using Pg13 Beta2 and a different approach including
a look at the performance using <code>EXPLAIN</code>.
This post takes yet another look at this improvement using Pg13 Beta3.
I intend to see how well this improvement pans out on a data set I use in production.  For that task my go-to is
<a href="https://www.openstreetmap.org/">OpenStreetMap</a> data loaded to Postgres/PostGIS <a href="https://blog.rustprooflabs.com/2020/01/postgis-osm-load-2020">using osm2pgsql</a>.</p>
<h2>Install Postgres 13 Beta 3</h2>
<p>The first step is to install the two versions of Postgres (12 and 13beta3) 
on a single Ubuntu 18 host.  In the past when I have tested pre-production
releases I have built Postgres from source instead of using <code>apt</code>.
This time around I decided to use <code>apt install</code>, so am including the
basic process for that.</p>
<p>The advised way to install PostgreSQL is from the pgdg (PostgreSQL Global Development Group) repositories,
see <a href="https://wiki.postgresql.org/wiki/Apt">the Postgres wiki</a> for more.
To enable the beta versions, the line needed in <code>/etc/apt/sources.list.d/pgdg.list</code> is:</p>
<pre><code>deb http://apt.postgresql.org/pub/repos/apt/bionic-pgdg main 13
</code></pre>
<p>With that in place, update the sources and install Postgres and PostGIS.</p>
<pre><code>sudo apt update
# Postgres 12
sudo apt install postgresql-12 postgresql-12-postgis-3
# Postgres 13 (Currently Beta)
sudo apt install postgresql-13 postgresql-13-postgis-3
</code></pre>
<p>On Ubuntu, installing multiple versions will create multiple instances running on different ports. The test server I'm using to write this post
currently has three versions of Postgres installed, only two are currently running. Postgres 12 was installed first so "won" the default port of 5432.  Postgres 11 was installed second and was assigned 5433, and Pg13 beta 3 was installed last and was assigned port 5434.  The <code>pg_lsclusters</code> is avaiable on Debian/Ubuntu hosts as part of the wrapper around <code>pg_ctl</code>.</p>
<pre><code>sudo -u postgres pg_lsclusters
Ver Cluster Port Status Owner    Data directory              Log file
11  main    5433 down   postgres /var/lib/postgresql/11/main /var/log/postgresql/postgresql-11-main.log
12  main    5432 online postgres /var/lib/postgresql/12/main /var/log/postgresql/postgresql-12-main.log
13  main    5434 online postgres /var/lib/postgresql/13/main /var/log/postgresql/postgresql-13-main.log
</code></pre>
<blockquote>
<p>This post does not use Postgres 11 beyond this example.</p>
</blockquote>
<p>When working with multiple versions installed it is helpful to verify
versions match what you expect them to be.
First, the port 5432 for Postgres 12 version.</p>
<pre><code>psql -d pgosm -p 5432 -c "select version();"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”�
â”‚                                   version                                    â”‚
â•žâ•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•¡
â”‚ PostgreSQL 12.4 (Ubuntu 12.4-1.pgdg18.04+1) on x86_64-pc-linux-gnu, compiledâ€¦â”‚
â”‚â€¦ by gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0, 64-bit                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>Now, port 5434 for Postgres 13 version.</p>
<pre><code>psql -d pgosm -p 5434 -c "select version();"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”�
â”‚                                   version                                    â”‚
â•žâ•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•¡
â”‚ PostgreSQL 13beta3 (Ubuntu 13~beta3-1.pgdg18.04+1) on x86_64-pc-linux-gnu, câ€¦â”‚
â”‚â€¦ompiled by gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0, 64-bit                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h2>Create Indexes</h2>
<p>Both versions of Postgres were loaded with the same Colorado OpenStreetMap
data loaded <a href="https://blog.rustprooflabs.com/2020/01/postgis-osm-load-2020">using osm2pgsql</a>.
The osm2pgsql does not create any B-Tree indexes on its own, only the GIST
indexes on geometries.
For this post, we examine B-Tree index sizes created on four columns:
<code>osm_id</code>, <code>highway</code>, <code>waterway</code>, and <code>natural</code>.
Looking at the stats on the <code>public.planet_osm_line</code> table I can make 
a couple guesses where we will and will not see gains based on <code>n_distinct</code>.
I can guess we will not see major gains in the
<code>osm_id</code>, there is only a small amount of duplication in those values.
The other three columns (<code>highway</code>, <code>natural</code> and <code>waterway</code>) have a small number of distinct values
and varying amounts of <code>NULL</code> values.  These three columns would all
be candidates for partial indexes to avoid indexing the <code>NULL</code> values,
thus reducing the size of the created index.
I have hopes to see the benefits in Postgres 13 on these columns, possibly
making the use of partial indexes less frequent.</p>
<pre><code> SELECT attname, n_distinct, null_frac
    FROM pg_catalog.pg_stats
    WHERE tablename = 'planet_osm_line'
        AND attname IN ('osm_id', 'highway', 'waterway', 'natural')
;

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”�
â”‚ attname  â”‚ n_distinct â”‚ null_frac  â”‚
â•žâ•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•ªâ•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•ªâ•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•�â•¡
â”‚ osm_id   â”‚  -0.833553 â”‚          0 â”‚
â”‚ highway  â”‚         26 â”‚ 0.41616666 â”‚
â”‚ natural  â”‚          4 â”‚      0.994 â”‚
â”‚ waterway â”‚          9 â”‚     0.6663 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3>Index on <code>osm_id</code></h3>
<p>First up is the <code>osm_id</code> column, a nearly unique set of positive and 
negative values.  The index to create in both versions:</p>
<pre><code>CREATE INDEX ix_osm_line_osm_id ON public.planet_osm_line (osm_id);
</code></pre>
<p>The following query is used throughout to report out index sizes.
The query itself will not be repeated, as only the filter would change.</p>
<pre><code>SELECT ai.schemaname AS s_name, ai.relname AS t_name,
        ai.indexrelname AS index_name,
        pg_size_pretty(pg_relation_size(quote_ident(ai.schemaname)::text || '.' || quote_ident(ai.indexrelname)::text)) AS index_size,
        pg_relation_size(quote_ident(ai.schemaname)::text || '.' || quote_ident(ai.indexrelname)::text) AS index_size_bytes
    FROM pg_catalog.pg_stat_all_indexes ai
    WHERE ai.indexrelname LIKE 'ix_osm_line%'
    ORDER BY index_name
;
</code></pre>
<p>Due to the low number of duplicates, it is no surprise that the
show only a tiny reduction in the size.  The reduction
would not be detectable from only the <code>index_size</code> column (in MB), the
<code>index_size_bytes</code> shows the slight reduction in size (29,515,776 bytes vs. 29,384,704 bytes).</p>
<p>Pg 12.</p>
<pre><code>â”Œâ”€[ RECORD 1 ]â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”�
â”‚ s_name           â”‚ public             â”‚
â”‚ t_name           â”‚ planet_osm_line    â”‚
â”‚ index_name       â”‚ ix_osm_line_osm_id â”‚
â”‚ index_size       â”‚ 28 MB              â”‚
â”‚ index_size_bytes â”‚ 29515776           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<p>Pg 13.</p>
<pre><code>â”Œâ”€[ RECORD 1 ]â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”�
â”‚ s_name           â”‚ public             â”‚
â”‚ t_name           â”‚ planet_osm_line    â”‚
â”‚ index_name       â”‚ ix_osm_line_osm_id â”‚
â”‚ index_size       â”‚ 28 MB              â”‚
â”‚ index_size_bytes â”‚ 29384704           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>
<h3>Index on <code>highway</code></h3>
<p>The <code>highway</code> data in the <code>planet_osm_line</code> data is a good example of when
a
<a href="https://www.postgresql.org/docs/current/indexes-partial.html">partial index</a>
might typically be a good idea to minimize index size.  My hunch (and hope)
is that the de-duplication will make a partial index here a moot point by reducing the size required to index a large number of <code>NULL</code> values.</p>
<p>Create two indexes, one partial covering the non-<code>NULL</code> values and one full
index on the entire table.</p>
<pre><code>CREATE INDEX ix_osm_line_highway_partial 
    ON public.planet_osm_line (highway)
    WHERE highway IS NOT NULL;
CREATE INDEX ix_osm_line_highway_full
    ON public.planet_osm_line (highway);
</code></pre>
<p>The two indexes in Postgres 12, notice the partial index cuts out about 1/3 of the size from the full index.</p>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”…</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.rustprooflabs.com/2020/09/postgres-beta3-btree-dedup">https://blog.rustprooflabs.com/2020/09/postgres-beta3-btree-dedup</a></em></p>]]>
            </description>
            <link>https://blog.rustprooflabs.com/2020/09/postgres-beta3-btree-dedup</link>
            <guid isPermaLink="false">hacker-news-small-sites-24395825</guid>
            <pubDate>Mon, 07 Sep 2020 00:39:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Play “The Endov Society” Built with Epic Online Services and Godot]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24395776">thread link</a>) | @follower
<br/>
September 6, 2020 | https://rancidbacon.itch.io/the-endov-society | <a href="https://web.archive.org/web/*/https://rancidbacon.itch.io/the-endov-society">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>THIS IS NOT A TECH DEMO.</h3>
<h3>THIS IS THE ENDOV SOCIETY.</h3>

<h3>will you survive the dystopian total surveillance future...</h3>
<h4>...and will you contribute to it in order to survive?</h4>
<p><strong>I did.</strong><br></p>
<p>Download an Extreme Early Access edition of "The Endov Society" the online interactive video game software provided for entertainment purposes like no other...<br></p>
<p>Join/find/create lobbies with up to 32 members! <strong>Unlock achievements!</strong> Change outfits! <strong>Get surveilled!</strong> Become more or less suspicious! <strong>Get promoted!</strong></p>
<p>Also features an episodic story that will have <em>you</em> asking "Is this a demonstration?".</p>
<p>Available for:</p>
<ul><li>Linux </li><li>Mac (10.13+; runs under WINE on older versions)</li><li>Windows</li></ul>
<p><em>Note: This is an online only, multiplayer game. Online features are implemented via Epic Online Services. No Epic or other account required.</em><br></p></div></div>]]>
            </description>
            <link>https://rancidbacon.itch.io/the-endov-society</link>
            <guid isPermaLink="false">hacker-news-small-sites-24395776</guid>
            <pubDate>Mon, 07 Sep 2020 00:29:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Computational Thinking]]>
            </title>
            <description>
<![CDATA[
Score 315 | Comments 32 (<a href="https://news.ycombinator.com/item?id=24395700">thread link</a>) | @guiambros
<br/>
September 6, 2020 | https://mitmath.github.io/18S191/Fall20/ | <a href="https://web.archive.org/web/*/https://mitmath.github.io/18S191/Fall20/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<!-- Content appended here -->
<div>
<p>Welcome to the new course <strong>MIT 18.S191</strong>, the debut edition, <strong>Fall 2020</strong>!</p>
<p> This is an introductory course on Computational Thinking. We use the <a href="http://www.julialang.org/">Julia programming language</a> to approach real-world problems in varied areas applying data analysis and computational and mathematical modeling.  In this class you will learn computer science, software, algorithms, applications, and mathematics as an integrated whole.</p>
<p>Topics include:</p>
<ul>
<li><p>Image analysis</p>
</li>
<li><p>Particle dynamics and ray tracing</p>
</li>
<li><p>Epidemic propagation</p>
</li>
<li><p>Climate modeling</p>
</li>
</ul>
<h2 id="professors"><a href="#professors">Professors</a></h2>
<p><a href="http://math.mit.edu/~edelman">Alan Edelman</a>, <a href="http://sistemas.fciencias.unam.mx/~dsanders/">David P. Sanders</a>, <a href="https://www.3blue1brown.com/about">Grant Sanderson</a>, &amp; <a href="https://eapsweb.mit.edu/people/jars">James Schloss</a></p>
<h2 id="introduction_video"><a href="#introduction_video">Introduction video</a></h2>
<iframe id="course-intro" width="800" height="474" src="https://www.youtube.com/embed/vxjRWtWoD_w" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<h2 id="logistics"><a href="#logistics">Logistics</a></h2>
<p>Course materials will be published on the accompanying website: <a href="https://mitmath.github.io/18S191/Fall20/">https://mitmath.github.io/18S191/Fall20/</a></p>
<p>TR 2:30–3:30pm EST, online (Go to the lecture page on this site to stream it.)</p>
<ul>
<li><p>Tuesdays: Prerecorded videos, released on YouTube and played live on this site.</p>
</li>
<li><p>Thursdays: Live sessions (same YouTube link 2:30–3) and MIT-only discussion (3-3:30); link to follow</p>
</li>
</ul>
<p>Start date: September 1, 2020</p>
<p>Office hours TBD.</p>
<h3 id="discussion_forum_and_homework_submission"><a href="#discussion_forum_and_homework_submission">Discussion forum and homework submission</a></h3>
<ul>
<li><p><a href="https://discord.gg/Z5qnVf8">Discord</a>: discussion (we encourage you to hang out here during class!)</p>
</li>
<li><p><a href="https://piazza.com/class/kd33x1xnfyq3b1">Piazza</a>: (MIT only) allows for anonymity to other students, discussion</p>
</li>
<li><p><a href="https://canvas.mit.edu/courses/5637">Canvas</a>: (MIT only) homework submission. If you're a non-MIT student, please find a partner to cross-grade homeworks via Discord.</p>
</li>
</ul>
<h3 id="evaluation"><a href="#evaluation">Evaluation</a></h3>
<ul>
<li><p>12 weekly problem sets with equal weight; your lowest score will be dropped. </p>
</li>
<li><p>Released on Thursdays and due before the following Thursday's class. (No problem set during Thanskgiving week.)</p>
</li>
<li><p>No exams</p>
</li>
</ul>
<p>Problem sets consist of code. MIT students enrolled in the course must submit homeworks via Canvas. If you are not a student then we encourage you to join the Discord and find a cross-grading partner.</p>
<div>
  <p>
    Last modified: September 10, 2020. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>.
  </p>
</div>
</div><!-- CONTENT ENDS HERE -->

    </div></div>]]>
            </description>
            <link>https://mitmath.github.io/18S191/Fall20/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24395700</guid>
            <pubDate>Mon, 07 Sep 2020 00:08:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elixir Is Erlang, not Ruby]]>
            </title>
            <description>
<![CDATA[
Score 401 | Comments 282 (<a href="https://news.ycombinator.com/item?id=24395695">thread link</a>) | @stanislavb
<br/>
September 6, 2020 | https://preslav.me/2020/09/06/elixir-is-not-ruby-elixir-is-erlang/ | <a href="https://web.archive.org/web/*/https://preslav.me/2020/09/06/elixir-is-not-ruby-elixir-is-erlang/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>Try to remember the first time you heard about this fascinating language called <a href="https://elixir-lang.org/">Elixir</a>. Chances are, you had by the time been developing software using Ruby. If that's the case, Elixir seems to have appeared out of nowhere until suddenly, it became the solution for all your previous problems. It is fast, clean, scales extremely well. It was <strong>almost</strong> like the Ruby you've always wanted to have, but never got.</p><p>I say <strong>almost</strong>, because as much as you want it to be, <strong>Elixir is not Ruby</strong>. The familiar syntax has definitely helped the language win the hearts of the broader developer community. Yet, under the hood, <strong>Elixir is all about Erlang.</strong> The <a href="https://elixir-lang.org/">Erlang</a> that everyone tells stories about, as if it were some mythical creature, but no one dares to touch.</p><figure><img src="https://preslav.me/content/images/2020/09/book-cover.png" alt="" width="500" height="700"><figcaption>Elixir for Non-Ruby Programmers</figcaption></figure><p>Why am I saying all of this? First, because I would love to see greater adoption of Elixir outside Ruby/Rails community. It was among that group of people where the idea first sparked, and I fully respect the fact. Nevertheless, I would love to see it growing out. As someone who discovered Elixir after years of doing Java, &nbsp;.NET and more recently, Go, I can say that there is enough goodness in it for everyone. Moreover, bringing people with different backgrounds (both technical and non-technical) will lead to an explosion of new ideas. Having more diverse minds will help us better understand and make use of the elephant in the room-Erlang.</p><p>This brings me to my second point. Erlang is not obscure at all, once you give it enough attention. It is actually oddly satisfying, once you start reading code written in it. I have had my few a-ha moments, when I figured the original inspiration for most constructs in Elixir. The point is, we shouldn't fear Erlang, but try to understand it. This applies both to when things go well, as well as when they go south.</p><p>My biggest hope of all is that by understanding Erlang well enough, the Elixir community will start looking for new uses for it. Uses that go beyond being a scalable replacement for Rails apps. More daring and more ambitious uses, where Erlang's resilience model can prove to be critical for the success of the mission. I'd love to see it used in transportation, space, as well as the domain that started it all- telecommunications.</p><blockquote>“Shoot for the moon. Even if you miss it you will land among the stars.”<br><strong>Les Brown</strong></blockquote>
                <section>
                  
                  <ul>
                      <li>
                        <a href="https://preslav.me/tag/elixir/" title="Elixir">Elixir</a>
                      </li>
                      <li>
                        <a href="https://preslav.me/tag/programming/" title="Programming">Programming</a>
                      </li>
                      <li>
                        <a href="https://preslav.me/tag/ruby/" title="Ruby">Ruby</a>
                      </li>
                      <li>
                        <a href="https://preslav.me/tag/erlang/" title="Erlang">Erlang</a>
                      </li>
                      <li>
                        <a href="https://preslav.me/tag/2-cents/" title="2 Cents">2 Cents</a>
                      </li>
                  </ul>
                </section>
            </div></div>]]>
            </description>
            <link>https://preslav.me/2020/09/06/elixir-is-not-ruby-elixir-is-erlang/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24395695</guid>
            <pubDate>Mon, 07 Sep 2020 00:07:39 GMT</pubDate>
        </item>
    </channel>
</rss>
